[{"id": "1908.00045", "submitter": "Itay Safran", "authors": "Itay Safran, Ohad Shamir", "title": "How Good is SGD with Random Shuffling?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of stochastic gradient descent (SGD) on smooth and\nstrongly-convex finite-sum optimization problems. In contrast to the majority\nof existing theoretical works, which assume that individual functions are\nsampled with replacement, we focus here on popular but poorly-understood\nheuristics, which involve going over random permutations of the individual\nfunctions. This setting has been investigated in several recent works, but the\noptimal error rates remain unclear. In this paper, we provide lower bounds on\nthe expected optimization error with these heuristics (using SGD with any\nconstant step size), which elucidate their advantages and disadvantages. In\nparticular, we prove that after $k$ passes over $n$ individual functions, if\nthe functions are re-shuffled after every pass, the best possible optimization\nerror for SGD is at least $\\Omega\\left(1/(nk)^2+1/nk^3\\right)$, which partially\ncorresponds to recently derived upper bounds. Moreover, if the functions are\nonly shuffled once, then the lower bound increases to $\\Omega(1/nk^2)$. Since\nthere are strictly smaller upper bounds for repeated reshuffling, this proves\nan inherent performance gap between SGD with single shuffling and repeated\nshuffling. As a more minor contribution, we also provide a non-asymptotic\n$\\Omega(1/k^2)$ lower bound (independent of $n$) for the incremental gradient\nmethod, when no random shuffling takes place. Finally, we provide an indication\nthat our lower bounds are tight, by proving matching upper bounds for\nunivariate quadratic functions.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 18:43:01 GMT"}, {"version": "v2", "created": "Tue, 28 Jan 2020 13:04:20 GMT"}, {"version": "v3", "created": "Tue, 9 Jun 2020 08:49:25 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2021 16:25:46 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Safran", "Itay", ""], ["Shamir", "Ohad", ""]]}, {"id": "1908.00080", "submitter": "Faraz Hussain", "authors": "M.G. Sarwar Murshed, Christopher Murphy, Daqing Hou, Nazar Khan,\n  Ganesh Ananthanarayanan, Faraz Hussain", "title": "Machine Learning at the Network Edge: A Survey", "comments": "35 pages, 4 figures; restructured text to combine ML/DL into a single\n  section; updated tables/figures; added a new table summarizing major ML edge\n  applications, fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource-constrained IoT devices, such as sensors and actuators, have become\nubiquitous in recent years. This has led to the generation of large quantities\nof data in real-time, which is an appealing target for AI systems. However,\ndeploying machine learning models on such end-devices is nearly impossible. A\ntypical solution involves offloading data to external computing systems (such\nas cloud servers) for further processing but this worsens latency, leads to\nincreased communication costs, and adds to privacy concerns. To address this\nissue, efforts have been made to place additional computing devices at the edge\nof the network, i.e close to the IoT devices where the data is generated.\nDeploying machine learning systems on such edge computing devices alleviates\nthe above issues by allowing computations to be performed close to the data\nsources. This survey describes major research efforts where machine learning\nsystems have been deployed at the edge of computer networks, focusing on the\noperational aspects including compression techniques, tools, frameworks, and\nhardware used in successful applications of intelligent edge systems.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 20:23:00 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 18:55:40 GMT"}, {"version": "v3", "created": "Mon, 21 Sep 2020 23:00:32 GMT"}, {"version": "v4", "created": "Sun, 23 May 2021 19:52:16 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Murshed", "M. G. Sarwar", ""], ["Murphy", "Christopher", ""], ["Hou", "Daqing", ""], ["Khan", "Nazar", ""], ["Ananthanarayanan", "Ganesh", ""], ["Hussain", "Faraz", ""]]}, {"id": "1908.00086", "submitter": "Zitao Liu", "authors": "Guowei Xu, Wenbiao Ding, Jiliang Tang, Songfan Yang, Gale Yan Huang,\n  Zitao Liu", "title": "Learning Effective Embeddings From Crowdsourced Labels: An Educational\n  Case Study", "comments": null, "journal-ref": "2019 IEEE 35th International Conference on Data Engineering", "doi": "10.1109/ICDE.2019.00208", "report-no": null, "categories": "cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representation has been proven to be helpful in numerous machine\nlearning tasks. The success of the majority of existing representation learning\napproaches often requires a large amount of consistent and noise-free labels.\nHowever, labels are not accessible in many real-world scenarios and they are\nusually annotated by the crowds. In practice, the crowdsourced labels are\nusually inconsistent among crowd workers given their diverse expertise and the\nnumber of crowdsourced labels is very limited. Thus, directly adopting\ncrowdsourced labels for existing representation learning algorithms is\ninappropriate and suboptimal. In this paper, we investigate the above problem\nand propose a novel framework of \\textbf{R}epresentation \\textbf{L}earning with\ncrowdsourced \\textbf{L}abels, i.e., \"RLL\", which learns representation of data\nwith crowdsourced labels by jointly and coherently solving the challenges\nintroduced by limited and inconsistent labels. The proposed representation\nlearning framework is evaluated in two real-world education applications. The\nexperimental results demonstrate the benefits of our approach on learning\nrepresentation from limited labeled data from the crowds, and show RLL is able\nto outperform state-of-the-art baselines. Moreover, detailed experiments are\nconducted on RLL to fully understand its key components and the corresponding\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 03:01:06 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Xu", "Guowei", ""], ["Ding", "Wenbiao", ""], ["Tang", "Jiliang", ""], ["Yang", "Songfan", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1908.00096", "submitter": "Jan Philip G\\\"opfert", "authors": "Christina G\\\"opfert, Jan Philip G\\\"opfert, Barbara Hammer", "title": "Adversarial Robustness Curves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of adversarial examples has led to considerable uncertainty\nregarding the trust one can justifiably put in predictions produced by\nautomated systems. This uncertainty has, in turn, lead to considerable research\neffort in understanding adversarial robustness. In this work, we take first\nsteps towards separating robustness analysis from the choice of robustness\nthreshold and norm. We propose robustness curves as a more general view of the\nrobustness behavior of a model and investigate under which circumstances they\ncan qualitatively depend on the chosen norm.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 21:02:36 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["G\u00f6pfert", "Christina", ""], ["G\u00f6pfert", "Jan Philip", ""], ["Hammer", "Barbara", ""]]}, {"id": "1908.00105", "submitter": "Marco Henrique De Almeida In\\'acio", "authors": "Marco Henrique de Almeida In\\'acio and Rafael Izbicki and Rafael Bassi\n  Stern", "title": "Conditional independence testing: a predictive perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional independence testing is a key problem required by many machine\nlearning and statistics tools. In particular, it is one way of evaluating the\nusefulness of some features on a supervised prediction problem. We propose a\nnovel conditional independence test in a predictive setting, and show that it\nachieves better power than competing approaches in several settings. Our\napproach consists in deriving a p-value using a permutation test where the\npredictive power using the unpermuted dataset is compared with the predictive\npower of using dataset where the feature(s) of interest are permuted. We\nconclude that the method achives sensible results on simulated and real\ndatasets.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 21:19:23 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["In\u00e1cio", "Marco Henrique de Almeida", ""], ["Izbicki", "Rafael", ""], ["Stern", "Rafael Bassi", ""]]}, {"id": "1908.00151", "submitter": "Martin Sundermeyer", "authors": "Martin Sundermeyer, Maximilian Durner, En Yen Puang, Zoltan-Csaba\n  Marton, Narunas Vaskevicius, Kai O. Arras, Rudolph Triebel", "title": "Multi-path Learning for Object Pose Estimation Across Domains", "comments": "To appear at CVPR 2020; Code will be available here:\n  https://github.com/DLR-RM/AugmentedAutoencoder/tree/multipath", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a scalable approach for object pose estimation trained on\nsimulated RGB views of multiple 3D models together. We learn an encoding of\nobject views that does not only describe an implicit orientation of all objects\nseen during training, but can also relate views of untrained objects. Our\nsingle-encoder-multi-decoder network is trained using a technique we denote\n\"multi-path learning\": While the encoder is shared by all objects, each decoder\nonly reconstructs views of a single object. Consequently, views of different\ninstances do not have to be separated in the latent space and can share common\nfeatures. The resulting encoder generalizes well from synthetic to real data\nand across various instances, categories, model types and datasets. We\nsystematically investigate the learned encodings, their generalization, and\niterative refinement strategies on the ModelNet40 and T-LESS dataset. Despite\ntraining jointly on multiple objects, our 6D Object Detection pipeline achieves\nstate-of-the-art results on T-LESS at much lower runtimes than competing\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 00:01:14 GMT"}, {"version": "v2", "created": "Fri, 3 Apr 2020 07:00:33 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Sundermeyer", "Martin", ""], ["Durner", "Maximilian", ""], ["Puang", "En Yen", ""], ["Marton", "Zoltan-Csaba", ""], ["Vaskevicius", "Narunas", ""], ["Arras", "Kai O.", ""], ["Triebel", "Rudolph", ""]]}, {"id": "1908.00156", "submitter": "Hrushikesh Mhaskar", "authors": "Hrushikesh Mhaskar", "title": "A direct approach for function approximation on data defined manifolds", "comments": "Version 1 was submitted on August 1, 2019 under the title Deep\n  Gaussian networks for function approximation on data defined manifolds. This\n  version is accepted for publication in Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In much of the literature on function approximation by deep networks, the\nfunction is assumed to be defined on some known domain, such as a cube or a\nsphere. In practice, the data might not be dense on these domains, and\ntherefore, the approximation theory results are observed to be too\nconservative. In manifold learning, one assumes instead that the data is\nsampled from an unknown manifold; i.e., the manifold is defined by the data\nitself. Function approximation on this unknown manifold is then a two stage\nprocedure: first, one approximates the Laplace-Beltrami operator (and its\neigen-decomposition) on this manifold using a graph Laplacian, and next,\napproximates the target function using the eigen-functions. Alternatively, one\nestimates first some atlas on the manifold and then uses local approximation\ntechniques based on the local coordinate charts.\n  In this paper, we propose a more direct approach to function approximation on\n\\emph{unknown}, data defined manifolds without computing the\neigen-decomposition of some operator or an atlas for the manifold, and without\nany kind of training in the classical sense. Our constructions are universal;\ni.e., do not require the knowledge of any prior on the target function other\nthan continuity on the manifold. We estimate the degree of approximation. For\nsmooth functions, the estimates do not suffer from the so-called saturation\nphenomenon. We demonstrate via a property called good propagation of errors how\nthe results can be lifted for function approximation using deep networks where\neach channel evaluates a Gaussian network on a possibly unknown manifold.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 00:42:26 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 00:18:59 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 23:35:18 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 04:50:57 GMT"}], "update_date": "2020-08-21", "authors_parsed": [["Mhaskar", "Hrushikesh", ""]]}, {"id": "1908.00173", "submitter": "Jianlei Yang", "authors": "Xucheng Ye, Pengcheng Dai, Junyu Luo, Xin Guo, Yingjie Qi, Jianlei\n  Yang, Yiran Chen", "title": "Accelerating CNN Training by Pruning Activation Gradients", "comments": "accepted by ECCV 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sparsification is an efficient approach to accelerate CNN inference, but it\nis challenging to take advantage of sparsity in training procedure because the\ninvolved gradients are dynamically changed. Actually, an important observation\nshows that most of the activation gradients in back-propagation are very close\nto zero and only have a tiny impact on weight-updating. Hence, we consider\npruning these very small gradients randomly to accelerate CNN training\naccording to the statistical distribution of activation gradients. Meanwhile,\nwe theoretically analyze the impact of pruning algorithm on the convergence.\nThe proposed approach is evaluated on AlexNet and ResNet-\\{18, 34, 50, 101,\n152\\} with CIFAR-\\{10, 100\\} and ImageNet datasets. Experimental results show\nthat our training approach could substantially achieve up to $5.92 \\times$\nspeedups at back-propagation stage with negligible accuracy loss.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 01:48:11 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 12:18:17 GMT"}, {"version": "v3", "created": "Mon, 20 Jul 2020 11:13:05 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ye", "Xucheng", ""], ["Dai", "Pengcheng", ""], ["Luo", "Junyu", ""], ["Guo", "Xin", ""], ["Qi", "Yingjie", ""], ["Yang", "Jianlei", ""], ["Chen", "Yiran", ""]]}, {"id": "1908.00177", "submitter": "Tommy Tram", "authors": "Tommy Tram, Ivo Batkovic, Mohammad Ali, Jonas Sj\\\"oberg", "title": "Learning When to Drive in Intersections by Combining Reinforcement\n  Learning and Model Predictive Control", "comments": "6 pages, 5 figures, 1 table, Accepted to IEEE Intelligent Transport\n  Systems Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a decision making algorithm intended for automated\nvehicles that negotiate with other possibly non-automated vehicles in\nintersections. The decision algorithm is separated into two parts: a high-level\ndecision module based on reinforcement learning, and a low-level planning\nmodule based on model predictive control. Traffic is simulated with numerous\npredefined driver behaviors and intentions, and the performance of the proposed\ndecision algorithm was evaluated against another controller. The results show\nthat the proposed decision algorithm yields shorter training episodes and an\nincreased performance in success rate compared to the other controller.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 02:00:49 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Tram", "Tommy", ""], ["Batkovic", "Ivo", ""], ["Ali", "Mohammad", ""], ["Sj\u00f6berg", "Jonas", ""]]}, {"id": "1908.00187", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Graph Neural Networks for Small Graph and Giant Network Representation\n  Learning: An Overview", "comments": "30 pages. arXiv admin note: text overlap with arXiv:1908.00187", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks denote a group of neural network models introduced for\nthe representation learning tasks on graph data specifically. Graph neural\nnetworks have been demonstrated to be effective for capturing network structure\ninformation, and the learned representations can achieve the state-of-the-art\nperformance on node and graph classification tasks. Besides the different\napplication scenarios, the architectures of graph neural network models also\ndepend on the studied graph types a lot. Graph data studied in research can be\ngenerally categorized into two main types, i.e., small graphs vs. giant\nnetworks, which differ from each other a lot in the size, instance number and\nlabel annotation. Several different types of graph neural network models have\nbeen introduced for learning the representations from such different types of\ngraphs already. In this paper, for these two different types of graph data, we\nwill introduce the graph neural networks introduced in recent years. To be more\nspecific, the graph neural networks introduced in this paper include IsoNN,\nSDBN, LF&ER, GCN, GAT, DifNN, GNL, GraphSage and seGEN. Among these graph\nneural network models, IsoNN, SDBN and LF&ER are initially proposed for small\ngraphs and the remaining ones are initially proposed for giant networks\ninstead. The readers are also suggested to refer to these papers for detailed\ninformation when reading this tutorial paper.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 02:35:12 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1908.00195", "submitter": "Waheed Bajwa", "authors": "Alireza Nooraiepour, Waheed U. Bajwa, and Narayan B. Mandayam", "title": "Learning-Aided Physical Layer Attacks Against Multicarrier\n  Communications in IoT", "comments": "15 pages; 20 figures; 3 tables; preprint of a paper accepted for\n  publication in IEEE Trans. Cognitive Commun. Netw", "journal-ref": "IEEE Trans. Cognitive Commun. Netw., vol. 7, no. 1, pp. 239-254,\n  Mar. 2021", "doi": "10.1109/TCCN.2020.2990657", "report-no": null, "categories": "cs.LG cs.CR eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-of-Things (IoT) devices that are limited in power and processing are\nsusceptible to physical layer (PHY) spoofing (signal exploitation) attacks\nowing to their inability to implement a full-blown protocol stack for security.\nThe overwhelming adoption of multicarrier techniques such as orthogonal\nfrequency division multiplexing (OFDM) for the PHY layer makes IoT devices\nfurther vulnerable to PHY spoofing attacks. These attacks which aim at\ninjecting bogus/spurious data into the receiver, involve inferring transmission\nparameters and finding PHY characteristics of the transmitted signals so as to\nspoof the received signal. Non-contiguous (NC) OFDM systems have been argued to\nhave low probability of exploitation (LPE) characteristics against classic\nattacks based on cyclostationary analysis, and the corresponding PHY has been\ndeemed to be secure. However, with the advent of machine learning (ML)\nalgorithms, adversaries can devise data-driven attacks to compromise such\nsystems. It is in this vein that PHY spoofing performance of adversaries\nequipped with supervised and unsupervised ML tools are investigated in this\npaper. The supervised ML approach is based on deep neural networks (DNN) while\nthe unsupervised one employs variational autoencoders (VAEs). In particular,\nVAEs are shown to be capable of learning representations from NC-OFDM signals\nrelated to their PHY characteristics such as frequency pattern and modulation\nscheme, which are useful for PHY spoofing. In addition, a new metric based on\nthe disentanglement principle is proposed to measure the quality of such\nlearned representations. Simulation results demonstrate that the performance of\nthe spoofing adversaries highly depends on the subcarriers' allocation\npatterns. Particularly, it is shown that utilizing a random subcarrier\noccupancy pattern secures NC-OFDM systems against ML-based attacks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 03:34:57 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 19:28:50 GMT"}], "update_date": "2021-03-18", "authors_parsed": [["Nooraiepour", "Alireza", ""], ["Bajwa", "Waheed U.", ""], ["Mandayam", "Narayan B.", ""]]}, {"id": "1908.00200", "submitter": "Edward Raff", "authors": "Edward Raff, William Fleming, Richard Zak, Hyrum Anderson, Bill\n  Finlayson, Charles Nicholas, Mark McLean", "title": "KiloGrams: Very Large N-Grams for Malware Classification", "comments": "Appearing in LEMINCS @ KDD'19, August 5th, 2019, Anchorage, Alaska,\n  United States", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  N-grams have been a common tool for information retrieval and machine\nlearning applications for decades. In nearly all previous works, only a few\nvalues of $n$ are tested, with $n > 6$ being exceedingly rare. Larger values of\n$n$ are not tested due to computational burden or the fear of overfitting. In\nthis work, we present a method to find the top-$k$ most frequent $n$-grams that\nis 60$\\times$ faster for small $n$, and can tackle large $n\\geq1024$. Despite\nthe unprecedented size of $n$ considered, we show how these features still have\npredictive ability for malware classification tasks. More important, large\n$n$-grams provide benefits in producing features that are interpretable by\nmalware analysis, and can be used to create general purpose signatures\ncompatible with industry standard tools like Yara. Furthermore, the counts of\ncommon $n$-grams in a file may be added as features to publicly available\nhuman-engineered features that rival efficacy of professionally-developed\nfeatures when used to train gradient-boosted decision tree models on the EMBER\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 03:58:11 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Raff", "Edward", ""], ["Fleming", "William", ""], ["Zak", "Richard", ""], ["Anderson", "Hyrum", ""], ["Finlayson", "Bill", ""], ["Nicholas", "Charles", ""], ["McLean", "Mark", ""]]}, {"id": "1908.00213", "submitter": "Shunta Saito", "authors": "Seiya Tokui, Ryosuke Okuta, Takuya Akiba, Yusuke Niitani, Toru Ogawa,\n  Shunta Saito, Shuji Suzuki, Kota Uenishi, Brian Vogel, Hiroyuki Yamazaki\n  Vincent", "title": "Chainer: A Deep Learning Framework for Accelerating the Research Cycle", "comments": "Accepted for Applied Data Science Track in KDD'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software frameworks for neural networks play a key role in the development\nand application of deep learning methods. In this paper, we introduce the\nChainer framework, which intends to provide a flexible, intuitive, and high\nperformance means of implementing the full range of deep learning models needed\nby researchers and practitioners. Chainer provides acceleration using Graphics\nProcessing Units with a familiar NumPy-like API through CuPy, supports general\nand dynamic models in Python through Define-by-Run, and also provides add-on\npackages for state-of-the-art computer vision models as well as distributed\ntraining.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 05:07:00 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Tokui", "Seiya", ""], ["Okuta", "Ryosuke", ""], ["Akiba", "Takuya", ""], ["Niitani", "Yusuke", ""], ["Ogawa", "Toru", ""], ["Saito", "Shunta", ""], ["Suzuki", "Shuji", ""], ["Uenishi", "Kota", ""], ["Vogel", "Brian", ""], ["Vincent", "Hiroyuki Yamazaki", ""]]}, {"id": "1908.00219", "submitter": "Nemanja Djuric", "authors": "Henggang Cui, Thi Nguyen, Fang-Chieh Chou, Tsung-Han Lin, Jeff\n  Schneider, David Bradley, Nemanja Djuric", "title": "Deep Kinematic Models for Kinematically Feasible Vehicle Trajectory\n  Predictions", "comments": "Accepted for publication at IEEE International Conference on Robotics\n  and Automation (ICRA) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-driving vehicles (SDVs) hold great potential for improving traffic\nsafety and are poised to positively affect the quality of life of millions of\npeople. To unlock this potential one of the critical aspects of the autonomous\ntechnology is understanding and predicting future movement of vehicles\nsurrounding the SDV. This work presents a deep-learning-based method for\nkinematically feasible motion prediction of such traffic actors. Previous work\ndid not explicitly encode vehicle kinematics and instead relied on the models\nto learn the constraints directly from the data, potentially resulting in\nkinematically infeasible, suboptimal trajectory predictions. To address this\nissue we propose a method that seamlessly combines ideas from the AI with\nphysically grounded vehicle motion models. In this way we employ best of the\nboth worlds, coupling powerful learning models with strong feasibility\nguarantees for their outputs. The proposed approach is general, being\napplicable to any type of learning method. Extensive experiments using deep\nconvnets on real-world data strongly indicate its benefits, outperforming the\nexisting state-of-the-art.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 05:44:56 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 22:39:56 GMT"}, {"version": "v3", "created": "Sat, 24 Oct 2020 20:30:48 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Cui", "Henggang", ""], ["Nguyen", "Thi", ""], ["Chou", "Fang-Chieh", ""], ["Lin", "Tsung-Han", ""], ["Schneider", "Jeff", ""], ["Bradley", "David", ""], ["Djuric", "Nemanja", ""]]}, {"id": "1908.00261", "submitter": "Gaurav Mahajan", "authors": "Alekh Agarwal, Sham M. Kakade, Jason D. Lee, Gaurav Mahajan", "title": "On the Theory of Policy Gradient Methods: Optimality, Approximation, and\n  Distribution Shift", "comments": "Corollary 6.1 added for a cleaner comparison to prior work.\n  $\\epsilon_{\\mathrm{bias}}$ is now used instead of\n  $\\epsilon_{\\mathrm{approx}}$ to denote the transfer approximation error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods are among the most effective methods in challenging\nreinforcement learning problems with large state and/or action spaces. However,\nlittle is known about even their most basic theoretical convergence properties,\nincluding: if and how fast they converge to a globally optimal solution or how\nthey cope with approximation error due to using a restricted class of\nparametric policies. This work provides provable characterizations of the\ncomputational, approximation, and sample size properties of policy gradient\nmethods in the context of discounted Markov Decision Processes (MDPs). We focus\non both: \"tabular\" policy parameterizations, where the optimal policy is\ncontained in the class and where we show global convergence to the optimal\npolicy; and parametric policy classes (considering both log-linear and neural\npolicy classes), which may not contain the optimal policy and where we provide\nagnostic learning results. One central contribution of this work is in\nproviding approximation guarantees that are average case -- which avoid\nexplicit worst-case dependencies on the size of state space -- by making a\nformal connection to supervised learning under distribution shift. This\ncharacterization shows an important interplay between estimation error,\napproximation error, and exploration (as characterized through a precisely\ndefined condition number).\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 08:22:18 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 15:54:51 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 06:47:50 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2020 22:50:05 GMT"}, {"version": "v5", "created": "Wed, 14 Oct 2020 18:56:23 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Agarwal", "Alekh", ""], ["Kakade", "Sham M.", ""], ["Lee", "Jason D.", ""], ["Mahajan", "Gaurav", ""]]}, {"id": "1908.00286", "submitter": "Floris Den Hengst", "authors": "Floris den Hengst, Mark Hoogendoorn, Frank van Harmelen, Joost Bosman", "title": "Reinforcement Learning for Personalized Dialogue Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.HC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Language systems have been of great interest to the research community and\nhave recently reached the mass market through various assistant platforms on\nthe web. Reinforcement Learning methods that optimize dialogue policies have\nseen successes in past years and have recently been extended into methods that\npersonalize the dialogue, e.g. take the personal context of users into account.\nThese works, however, are limited to personalization to a single user with whom\nthey require multiple interactions and do not generalize the usage of context\nacross users. This work introduces a problem where a generalized usage of\ncontext is relevant and proposes two Reinforcement Learning (RL)-based\napproaches to this problem. The first approach uses a single learner and\nextends the traditional POMDP formulation of dialogue state with features that\ndescribe the user context. The second approach segments users by context and\nthen employs a learner per context. We compare these approaches in a benchmark\nof existing non-RL and RL-based methods in three established and one novel\napplication domain of financial product recommendation. We compare the\ninfluence of context and training experiences on performance and find that\nlearning approaches generally outperform a handcrafted gold standard.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:19:27 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Hengst", "Floris den", ""], ["Hoogendoorn", "Mark", ""], ["van Harmelen", "Frank", ""], ["Bosman", "Joost", ""]]}, {"id": "1908.00325", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef", "title": "Estimating the Standard Error of Cross-Validation-Based Estimators of\n  Classification Rules Performance", "comments": "The paper is currently under review in Pattern Recognition Letters\n  (PRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First, we analyze the variance of the Cross Validation (CV)-based estimators\nused for estimating the performance of classification rules. Second, we propose\na novel estimator to estimate this variance using the Influence Function (IF)\napproach that had been used previously very successfully to estimate the\nvariance of the bootstrap-based estimators. The motivation for this research is\nthat, as the best of our knowledge, the literature lacks a rigorous method for\nestimating the variance of the CV-based estimators. What is available is a set\nof ad-hoc procedures that have no mathematical foundation since they ignore the\ncovariance structure among dependent random variables. The conducted\nexperiments show that the IF proposed method has small RMS error with some\nbias. However, surprisingly, the ad-hoc methods still work better than the\nIF-based method. Unfortunately, this is due to the lack of enough smoothness if\ncompared to the bootstrap estimator. This opens the research for three points:\n(1) more comprehensive simulation study to clarify when the IF method win or\nloose; (2) more mathematical analysis to figure out why the ad-hoc methods work\nwell; and (3) more mathematical treatment to figure out the connection between\nthe appropriate amount of \"smoothness\" and decreasing the bias of the IF\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 11:00:36 GMT"}, {"version": "v2", "created": "Tue, 8 Sep 2020 15:41:03 GMT"}, {"version": "v3", "created": "Wed, 9 Sep 2020 16:39:01 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Yousef", "Waleed A.", ""]]}, {"id": "1908.00355", "submitter": "Dan Teng", "authors": "Dan Teng, Sakyasingha Dasgupta", "title": "Continual Learning via Online Leverage Score Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to mimic the human ability of continual acquisition and transfer of\nknowledge across various tasks, a learning system needs the capability for\ncontinual learning, effectively utilizing the previously acquired skills. As\nsuch, the key challenge is to transfer and generalize the knowledge learned\nfrom one task to other tasks, avoiding forgetting and interference of previous\nknowledge and improving the overall performance. In this paper, within the\ncontinual learning paradigm, we introduce a method that effectively forgets the\nless useful data samples continuously and allows beneficial information to be\nkept for training of the subsequent tasks, in an online manner. The method uses\nstatistical leverage score information to measure the importance of the data\nsamples in every task and adopts frequent directions approach to enable a\ncontinual or life-long learning property. This effectively maintains a constant\ntraining size across all tasks. We first provide mathematical intuition for the\nmethod and then demonstrate its effectiveness in avoiding catastrophic\nforgetting and computational efficiency on continual learning of classification\ntasks when compared with the existing state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 12:21:52 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Teng", "Dan", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1908.00361", "submitter": "C\\'esar Lincoln Cavalcante Mattos", "authors": "Thiago de P. Vasconcelos, Daniel A. R. M. A. de Souza, C\\'esar L. C.\n  Mattos and Jo\\~ao P. P. Gomes", "title": "No-PASt-BO: Normalized Portfolio Allocation Strategy for Bayesian\n  Optimization", "comments": "8 pages, currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization (BO) is a framework for black-box optimization that is\nespecially suitable for expensive cost functions. Among the main parts of a BO\nalgorithm, the acquisition function is of fundamental importance, since it\nguides the optimization algorithm by translating the uncertainty of the\nregression model in a utility measure for each point to be evaluated.\nConsidering such aspect, selection and design of acquisition functions are one\nof the most popular research topics in BO. Since no single acquisition function\nwas proved to have better performance in all tasks, a well-established approach\nconsists of selecting different acquisition functions along the iterations of a\nBO execution. In such an approach, the GP-Hedge algorithm is a widely used\noption given its simplicity and good performance. Despite its success in\nvarious applications, GP-Hedge shows an undesirable characteristic of\naccounting on all past performance measures of each acquisition function to\nselect the next function to be used. In this case, good or bad values obtained\nin an initial iteration may impact the choice of the acquisition function for\nthe rest of the algorithm. This fact may induce a dominant behavior of an\nacquisition function and impact the final performance of the method. Aiming to\novercome such limitation, in this work we propose a variant of GP-Hedge, named\nNo-PASt-BO, that reduce the influence of far past evaluations. Moreover, our\nmethod presents a built-in normalization that avoids the functions in the\nportfolio to have similar probabilities, thus improving the exploration. The\nobtained results on both synthetic and real-world optimization tasks indicate\nthat No-PASt-BO presents competitive performance and always outperforms\nGP-Hedge.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 12:37:00 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Vasconcelos", "Thiago de P.", ""], ["de Souza", "Daniel A. R. M. A.", ""], ["Mattos", "C\u00e9sar L. C.", ""], ["Gomes", "Jo\u00e3o P. P.", ""]]}, {"id": "1908.00412", "submitter": "Huyen Pham", "authors": "Huyen Pham (LPSM (UMR\\_8001), UP, FiME Lab), Xavier Warin (EDF, FiME\n  Lab), Maximilien Germain (EDF, LPSM (UMR\\_8001))", "title": "Neural networks-based backward scheme for fully nonlinear PDEs", "comments": "to appear in SN Partial Differential Equations and Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE math.AP math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a numerical method for solving high dimensional fully nonlinear\npartial differential equations (PDEs). Our algorithm estimates simultaneously\nby backward time induction the solution and its gradient by multi-layer neural\nnetworks, while the Hessian is approximated by automatic differentiation of the\ngradient at previous step. This methodology extends to the fully nonlinear case\nthe approach recently proposed in \\cite{HPW19} for semi-linear PDEs. Numerical\ntests illustrate the performance and accuracy of our method on several examples\nin high dimension with nonlinearity on the Hessian term including a linear\nquadratic control problem with control on the diffusion coefficient,\nMonge-Amp{\\`e}re equation and Hamilton-Jacobi-Bellman equation in portfolio\noptimization.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 08:09:13 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 13:28:26 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 15:12:30 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Pham", "Huyen", "", "LPSM"], ["Warin", "Xavier", "", "EDF, FiME\n  Lab"], ["Germain", "Maximilien", "", "EDF, LPSM"]]}, {"id": "1908.00420", "submitter": "David Eriksson", "authors": "David Eriksson, David Bindel, Christine A. Shoemaker", "title": "pySOT and POAP: An event-driven asynchronous framework for surrogate\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes Plumbing for Optimization with Asynchronous Parallelism\n(POAP) and the Python Surrogate Optimization Toolbox (pySOT). POAP is an\nevent-driven framework for building and combining asynchronous optimization\nstrategies, designed for global optimization of expensive functions where\nconcurrent function evaluations are useful. POAP consists of three components:\na worker pool capable of function evaluations, strategies to propose\nevaluations or other actions, and a controller that mediates the interaction\nbetween the workers and strategies. pySOT is a collection of synchronous and\nasynchronous surrogate optimization strategies, implemented in the POAP\nframework. We support the stochastic RBF method by Regis and Shoemaker along\nwith various extensions of this method, and a general surrogate optimization\nstrategy that covers most Bayesian optimization methods. We have implemented\nmany different surrogate models, experimental designs, acquisition functions,\nand a large set of test problems. We make an extensive comparison between\nsynchronous and asynchronous parallelism and find that the advantage of\nasynchronous computation increases as the variance of the evaluation time or\nnumber of processors increases. We observe a close to linear speed-up with 4,\n8, and 16 processors in both the synchronous and asynchronous setting.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 18:06:18 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Eriksson", "David", ""], ["Bindel", "David", ""], ["Shoemaker", "Christine A.", ""]]}, {"id": "1908.00449", "submitter": "Jacob Harer", "authors": "Jacob Harer, Chris Reale and Peter Chin", "title": "Tree-Transformer: A Transformer-Based Method for Correction of\n  Tree-Structured Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many common sequential data sources, such as source code and natural\nlanguage, have a natural tree-structured representation. These trees can be\ngenerated by fitting a sequence to a grammar, yielding a hierarchical ordering\nof the tokens in the sequence. This structure encodes a high degree of\nsyntactic information, making it ideal for problems such as grammar correction.\nHowever, little work has been done to develop neural networks that can operate\non and exploit tree-structured data. In this paper we present the\nTree-Transformer \\textemdash{} a novel neural network architecture designed to\ntranslate between arbitrary input and output trees. We applied this\narchitecture to correction tasks in both the source code and natural language\ndomains. On source code, our model achieved an improvement of $25\\%$\n$\\text{F}0.5$ over the best sequential method. On natural language, we achieved\ncomparable results to the most complex state of the art systems, obtaining a\n$10\\%$ improvement in recall on the CoNLL 2014 benchmark and the highest to\ndate $\\text{F}0.5$ score on the AESW benchmark of $50.43$.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 15:05:41 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Harer", "Jacob", ""], ["Reale", "Chris", ""], ["Chin", "Peter", ""]]}, {"id": "1908.00493", "submitter": "Mohamed Mahmoud", "authors": "Mohamed El-Geish", "title": "Learning Joint Acoustic-Phonetic Word Embeddings", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most speech recognition tasks pertain to mapping words across two modalities:\nacoustic and orthographic. In this work, we suggest learning encoders that map\nvariable-length, acoustic or phonetic, sequences that represent words into\nfixed-dimensional vectors in a shared latent space; such that the distance\nbetween two word vectors represents how closely the two words sound. Instead of\ndirectly learning the distances between word vectors, we employ weak\nsupervision and model a binary classification task to predict whether two\ninputs, one of each modality, represent the same word given a distance\nthreshold. We explore various deep-learning models, bimodal contrastive losses,\nand techniques for mining hard negative examples such as the semi-supervised\ntechnique of self-labeling. Our best model achieves an $F_1$ score of 0.95 for\nthe binary classification task.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 16:42:47 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["El-Geish", "Mohamed", ""]]}, {"id": "1908.00510", "submitter": "Amrit Singh Bedi", "authors": "Hrusikesha Pradhan, Amrit Singh Bedi, Alec Koppel, and Ketan Rajawat", "title": "Adaptive Kernel Learning in Heterogeneous Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider learning in decentralized heterogeneous networks: agents seek to\nminimize a convex functional that aggregates data across the network, while\nonly having access to their local data streams. We focus on the case where\nagents seek to estimate a regression \\emph{function} that belongs to a\nreproducing kernel Hilbert space (RKHS). To incentivize coordination while\nrespecting network heterogeneity, we impose nonlinear proximity constraints. To\nsolve the constrained stochastic program, we propose applying a functional\nvariant of stochastic primal-dual (Arrow-Hurwicz) method which yields a\ndecentralized algorithm. To handle the fact that agents' functions have\ncomplexity proportional to time (owing to the RKHS parameterization), we\nproject the primal iterates onto subspaces greedily constructed from kernel\nevaluations of agents' local observations. The resulting scheme, dubbed\nHeterogeneous Adaptive Learning with Kernels (HALK), when used with constant\nstep-sizes, yields $\\mathcal{O}(\\sqrt{T})$ attenuation in sub-optimality and\nexactly satisfies the constraints in the long run, which improves upon the\nstate of the art rates for vector-valued problems.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 17:07:49 GMT"}, {"version": "v2", "created": "Fri, 5 Jun 2020 10:28:14 GMT"}, {"version": "v3", "created": "Thu, 26 Nov 2020 14:00:56 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 13:56:07 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Pradhan", "Hrusikesha", ""], ["Bedi", "Amrit Singh", ""], ["Koppel", "Alec", ""], ["Rajawat", "Ketan", ""]]}, {"id": "1908.00598", "submitter": "Janis Postels", "authors": "Janis Postels, Francesco Ferroni, Huseyin Coskun, Nassir Navab and\n  Federico Tombari", "title": "Sampling-free Epistemic Uncertainty Estimation Using Approximated\n  Variance Propagation", "comments": "International Conference on Computer Vision 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a sampling-free approach for computing the epistemic uncertainty\nof a neural network. Epistemic uncertainty is an important quantity for the\ndeployment of deep neural networks in safety-critical applications, since it\nrepresents how much one can trust predictions on new data. Recently promising\nworks were proposed using noise injection combined with Monte-Carlo sampling at\ninference time to estimate this quantity (e.g. Monte-Carlo dropout). Our main\ncontribution is an approximation of the epistemic uncertainty estimated by\nthese methods that does not require sampling, thus notably reducing the\ncomputational overhead. We apply our approach to large-scale visual tasks\n(i.e., semantic segmentation and depth regression) to demonstrate the\nadvantages of our method compared to sampling-based approaches in terms of\nquality of the uncertainty estimates as well as of computational overhead.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 19:53:35 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 09:21:15 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 20:18:54 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Postels", "Janis", ""], ["Ferroni", "Francesco", ""], ["Coskun", "Huseyin", ""], ["Navab", "Nassir", ""], ["Tombari", "Federico", ""]]}, {"id": "1908.00615", "submitter": "Thibault F\\'evry", "authors": "Thibault F\\'evry, Jason Phang, Nan Wu, S. Gene Kim, Linda Moy,\n  Kyunghyun Cho, Krzysztof J. Geras", "title": "Improving localization-based approaches for breast cancer screening exam\n  classification", "comments": "MIDL 2019 [arXiv:1907.08612]", "journal-ref": null, "doi": null, "report-no": "MIDL/2019/ExtendedAbstract/HyxoAR_AK4", "categories": "eess.IV cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We trained and evaluated a localization-based deep CNN for breast cancer\nscreening exam classification on over 200,000 exams (over 1,000,000 images).\nOur model achieves an AUC of 0.919 in predicting malignancy in patients\nundergoing breast cancer screening, reducing the error rate of the baseline (Wu\net al., 2019a) by 23%. In addition, the models generates bounding boxes for\nbenign and malignant findings, providing interpretable predictions.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 20:34:23 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["F\u00e9vry", "Thibault", ""], ["Phang", "Jason", ""], ["Wu", "Nan", ""], ["Kim", "S. Gene", ""], ["Moy", "Linda", ""], ["Cho", "Kyunghyun", ""], ["Geras", "Krzysztof J.", ""]]}, {"id": "1908.00625", "submitter": "Juliana Siqueira-Gay", "authors": "J. Siqueira-Gay, M. A. Giannotti, M. Sester", "title": "Learning about spatial inequalities: Capturing the heterogeneity in the\n  urban environment", "comments": null, "journal-ref": null, "doi": "10.1016/j.jclepro.2019.117732", "report-no": null, "categories": "physics.soc-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transportation systems can be conceptualized as an instrument of spreading\npeople and resources over the territory, playing an important role in\ndeveloping sustainable cities. The current rationale of transport provision is\nbased on population demand, disregarding land use and socioeconomic\ninformation. To meet the challenge to promote a more equitable resource\ndistribution, this work aims at identifying and describing patterns of urban\nservices supply, their accessibility, and household income. By using a\nmultidimensional approach, the spatial inequalities of a large city of the\nglobal south reveal that the low-income population has low access mainly to\nhospitals and cultural centers. A low-income group presents an intermediate\nlevel of accessibility to public schools and sports centers, evidencing the\ndiverse condition of citizens in the peripheries. These complex outcomes\ngenerated by the interaction of land use and public transportation emphasize\nthe importance of comprehensive methodological approaches to support decisions\nof urban projects, plans and programs. Reducing spatial inequalities,\nespecially providing services for deprived groups, is fundamental to promote\nthe sustainable use of resources and optimize the daily commuting.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 16:39:28 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Siqueira-Gay", "J.", ""], ["Giannotti", "M. A.", ""], ["Sester", "M.", ""]]}, {"id": "1908.00633", "submitter": "Conner DiPaolo", "authors": "Conner DiPaolo, Weiqing Gu", "title": "A Randomized Algorithm for Preconditioner Selection", "comments": "20(+1) pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of choosing a preconditioner $\\boldsymbol{M}$ to use when solving a\nlinear system $\\boldsymbol{Ax}=\\boldsymbol{b}$ with iterative methods is\ndifficult. For instance, even if one has access to a collection\n$\\boldsymbol{M}_1,\\boldsymbol{M}_2,\\ldots,\\boldsymbol{M}_n$ of candidate\npreconditioners, it is currently unclear how to practically choose the\n$\\boldsymbol{M}_i$ which minimizes the number of iterations of an iterative\nalgorithm to achieve a suitable approximation to $\\boldsymbol{x}$. This paper\nmakes progress on this sub-problem by showing that the preconditioner stability\n$\\|\\boldsymbol{I}-\\boldsymbol{M}^{-1}\\boldsymbol{A}\\|_\\mathsf{F}$, known to\nforecast preconditioner quality, can be computed in the time it takes to run a\nconstant number of iterations of conjugate gradients through use of sketching\nmethods. This is in spite of folklore which suggests the quantity is\nimpractical to compute, and a proof we give that ensures the quantity could not\npossibly be approximated in a useful amount of time by a deterministic\nalgorithm. Using our estimator, we provide a method which can provably select\nthe minimal stability preconditioner among $n$ candidates using floating point\noperations commensurate with running on the order of $n\\log n$ steps of the\nconjugate gradients algorithm. Our method can also advise the practitioner to\nuse no preconditioner at all if none of the candidates appears useful. The\nalgorithm is extremely easy to implement and trivially parallelizable. In one\nof our experiments, we use our preconditioner selection algorithm to create to\nthe best of our knowledge the first preconditioned method for kernel regression\nreported to never use more iterations than the non-preconditioned analog in\nstandard tests.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 21:11:30 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["DiPaolo", "Conner", ""], ["Gu", "Weiqing", ""]]}, {"id": "1908.00636", "submitter": "Dongrui Wu", "authors": "Yuqi Cui, Jian Huang and Dongrui Wu", "title": "Optimize TSK Fuzzy Systems for Classification Problems: Mini-Batch\n  Gradient Descent with Uniform Regularization and Batch Normalization", "comments": null, "journal-ref": "IEEE Trans. on Fuzzy Systems, 28(12):3065-3075, 2020", "doi": "10.1109/TFUZZ.2020.2967282", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Takagi-Sugeno-Kang (TSK) fuzzy systems are flexible and interpretable machine\nlearning models; however, they may not be easily optimized when the data size\nis large, and/or the data dimensionality is high. This paper proposes a\nmini-batch gradient descent (MBGD) based algorithm to efficiently and\neffectively train TSK fuzzy classifiers. It integrates two novel techniques: 1)\nuniform regularization (UR), which forces the rules to have similar average\ncontributions to the output, and hence to increase the generalization\nperformance of the TSK classifier; and, 2) batch normalization (BN), which\nextends BN from deep neural networks to TSK fuzzy classifiers to expedite the\nconvergence and improve the generalization performance. Experiments on 12 UCI\ndatasets from various application domains, with varying size and\ndimensionality, demonstrated that UR and BN are effective individually, and\nintegrating them can further improve the classification performance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 21:28:46 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 04:41:37 GMT"}, {"version": "v3", "created": "Thu, 9 Jan 2020 16:57:29 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Cui", "Yuqi", ""], ["Huang", "Jian", ""], ["Wu", "Dongrui", ""]]}, {"id": "1908.00637", "submitter": "Sacha Sokoloski", "authors": "Sacha Sokoloski and Ruben Coen-Cagli", "title": "Conditional Finite Mixtures of Poisson Distributions for\n  Context-Dependent Neural Correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel recordings of neural spike counts have revealed the existence of\ncontext-dependent noise correlations in neural populations. Theories of\npopulation coding have also shown that such correlations can impact the\ninformation encoded by neural populations about external stimuli. Although\nstudies have shown that these correlations often have a low-dimensional\nstructure, it has proven difficult to capture this structure in a model that is\ncompatible with theories of rate coding in correlated populations. To address\nthis difficulty we develop a novel model based on conditional finite mixtures\nof independent Poisson distributions. The model can be conditioned on context\nvariables (e.g. stimuli or task variables), and the number of mixture\ncomponents in the model can be cross-validated to estimate the dimensionality\nof the target correlations. We derive an expectation-maximization algorithm to\nefficiently fit the model to realistic amounts of data from large neural\npopulations. We then demonstrate that the model successfully captures\nstimulus-dependent correlations in the responses of macaque V1 neurons to\noriented gratings. Our model incorporates arbitrary nonlinear\ncontext-dependence, and can thus be applied to improve predictions of neural\nactivity based on deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 21:29:31 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 14:33:10 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sokoloski", "Sacha", ""], ["Coen-Cagli", "Ruben", ""]]}, {"id": "1908.00673", "submitter": "Tony Lei", "authors": "FangYuan Lei, Xun Liu, QingYun Dai, Bingo Wing-Kuen Ling, Huimin Zhao,\n  Yan Liu", "title": "Hybrid Low-order and Higher-order Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With higher-order neighborhood information of graph network, the accuracy of\ngraph representation learning classification can be significantly improved.\nHowever, the current higher order graph convolutional network has a large\nnumber of parameters and high computational complexity. Therefore, we propose a\nHybrid Lower order and Higher order Graph convolutional networks (HLHG)\nlearning model, which uses weight sharing mechanism to reduce the number of\nnetwork parameters. To reduce computational complexity, we propose a novel\nfusion pooling layer to combine the neighborhood information of high order and\nlow order. Theoretically, we compare the model complexity of the proposed model\nwith the other state-of-the-art model. Experimentally, we verify the proposed\nmodel on the large-scale text network datasets by supervised learning, and on\nthe citation network datasets by semi-supervised learning. The experimental\nresults show that the proposed model achieves highest classification accuracy\nwith a small set of trainable weight parameters.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 01:20:54 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Lei", "FangYuan", ""], ["Liu", "Xun", ""], ["Dai", "QingYun", ""], ["Ling", "Bingo Wing-Kuen", ""], ["Zhao", "Huimin", ""], ["Liu", "Yan", ""]]}, {"id": "1908.00683", "submitter": "Farhad Pourkamali-Anaraki", "authors": "Farhad Pourkamali-Anaraki", "title": "Large-Scale Sparse Subspace Clustering Using Landmarks", "comments": "9 pages, accepted for publication in 2019 IEEE International Workshop\n  on Machine Learning for Signal Processing (MLSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subspace clustering methods based on expressing each data point as a linear\ncombination of all other points in a dataset are popular unsupervised learning\ntechniques. However, existing methods incur high computational complexity on\nlarge-scale datasets as they require solving an expensive optimization problem\nand performing spectral clustering on large affinity matrices. This paper\npresents an efficient approach to subspace clustering by selecting a small\nsubset of the input data called landmarks. The resulting subspace clustering\nmethod in the reduced domain runs in linear time with respect to the size of\nthe original data. Numerical experiments on synthetic and real data demonstrate\nthe effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 02:39:40 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Pourkamali-Anaraki", "Farhad", ""]]}, {"id": "1908.00690", "submitter": "Bret Nestor", "authors": "Bret Nestor, Matthew B. A. McDermott, Willie Boag, Gabriela Berner,\n  Tristan Naumann, Michael C. Hughes, Anna Goldenberg, Marzyeh Ghassemi", "title": "Feature Robustness in Non-stationary Health Records: Caveats to\n  Deployable Model Performance in Common Clinical Machine Learning Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When training clinical prediction models from electronic health records\n(EHRs), a key concern should be a model's ability to sustain performance over\ntime when deployed, even as care practices, database systems, and population\ndemographics evolve. Due to de-identification requirements, however, current\nexperimental practices for public EHR benchmarks (such as the MIMIC-III\ncritical care dataset) are time agnostic, assigning care records to train or\ntest sets without regard for the actual dates of care. As a result, current\nbenchmarks cannot assess how well models trained on one year generalise to\nanother. In this work, we obtain a Limited Data Use Agreement to access year of\ncare for each record in MIMIC and show that all tested state-of-the-art models\ndecay in prediction quality when trained on historical data and tested on\nfuture data, particularly in response to a system-wide record-keeping change in\n2008 (0.29 drop in AUROC for mortality prediction, 0.10 drop in AUROC for\nlength-of-stay prediction with a random forest classifier). We further develop\na simple yet effective mitigation strategy: by aggregating raw features into\nexpert-defined clinical concepts, we see only a 0.06 drop in AUROC for\nmortality prediction and a 0.03 drop in AUROC for length-of-stay prediction. We\ndemonstrate that this aggregation strategy outperforms other automatic feature\npreprocessing techniques aimed at increasing robustness to data drift. We\nrelease our aggregated representations and code to encourage more deployable\nclinical prediction models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 03:03:25 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Nestor", "Bret", ""], ["McDermott", "Matthew B. A.", ""], ["Boag", "Willie", ""], ["Berner", "Gabriela", ""], ["Naumann", "Tristan", ""], ["Hughes", "Michael C.", ""], ["Goldenberg", "Anna", ""], ["Ghassemi", "Marzyeh", ""]]}, {"id": "1908.00695", "submitter": "Johannes Schmidt-Hieber", "authors": "Johannes Schmidt-Hieber", "title": "Deep ReLU network approximation of functions on a manifold", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whereas recovery of the manifold from data is a well-studied topic,\napproximation rates for functions defined on manifolds are less known. In this\nwork, we study a regression problem with inputs on a $d^*$-dimensional manifold\nthat is embedded into a space with potentially much larger ambient dimension.\nIt is shown that sparsely connected deep ReLU networks can approximate a\nH\\\"older function with smoothness index $\\beta$ up to error $\\epsilon$ using of\nthe order of $\\epsilon^{-d^*/\\beta}\\log(1/\\epsilon)$ many non-zero network\nparameters. As an application, we derive statistical convergence rates for the\nestimator minimizing the empirical risk over all possible choices of bounded\nnetwork parameters.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 04:01:13 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Schmidt-Hieber", "Johannes", ""]]}, {"id": "1908.00698", "submitter": "Robert M\\\"uller", "authors": "Robert M\\\"uller, Stefan Langer, Fabian Ritz, Christoph Roch, Steffen\n  Illium, Claudia Linnhoff-Popien", "title": "Soccer Team Vectors", "comments": "11 pages, 1 figure; This paper was presented at the 6th Workshop on\n  Machine Learning and Data Mining for Sports Analytics at ECML/PKDD 2019,\n  W\\\"urzburg, Germany, 2019", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2019. Communications in Computer and Information Science, vol 1168. Springer,\n  Cham", "doi": "10.1007/978-3-030-43887-6_19", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present STEVE - Soccer TEam VEctors, a principled approach\nfor learning real valued vectors for soccer teams where similar teams are close\nto each other in the resulting vector space. STEVE only relies on freely\navailable information about the matches teams played in the past. These vectors\ncan serve as input to various machine learning tasks. Evaluating on the task of\nteam market value estimation, STEVE outperforms all its competitors. Moreover,\nwe use STEVE for similarity search and to rank soccer teams.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 13:46:16 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 12:51:09 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["M\u00fcller", "Robert", ""], ["Langer", "Stefan", ""], ["Ritz", "Fabian", ""], ["Roch", "Christoph", ""], ["Illium", "Steffen", ""], ["Linnhoff-Popien", "Claudia", ""]]}, {"id": "1908.00700", "submitter": "Guannan Liang", "authors": "Qianqian Tong, Guannan Liang and Jinbo Bi", "title": "Calibrating the Adaptive Learning Rate to Improve Convergence of ADAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods (AGMs) have become popular in optimizing the\nnonconvex problems in deep learning area. We revisit AGMs and identify that the\nadaptive learning rate (A-LR) used by AGMs varies significantly across the\ndimensions of the problem over epochs (i.e., anisotropic scale), which may lead\nto issues in convergence and generalization. All existing modified AGMs\nactually represent efforts in revising the A-LR. Theoretically, we provide a\nnew way to analyze the convergence of AGMs and prove that the convergence rate\nof \\textsc{Adam} also depends on its hyper-parameter $\\epsilon$, which has been\noverlooked previously. Based on these two facts, we propose a new AGM by\ncalibrating the A-LR with an activation ({\\em softplus}) function, resulting in\nthe \\textsc{Sadam} and \\textsc{SAMSGrad} methods \\footnote{Code is available at\nhttps://github.com/neilliang90/Sadam.git.}. We further prove that these\nalgorithms enjoy better convergence speed under nonconvex, non-strongly convex,\nand Polyak-{\\L}ojasiewicz conditions compared with \\textsc{Adam}. Empirical\nstudies support our observation of the anisotropic A-LR and show that the\nproposed methods outperform existing AGMs and generalize even better than\nS-Momentum in multiple deep learning tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 04:20:34 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 15:13:36 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Tong", "Qianqian", ""], ["Liang", "Guannan", ""], ["Bi", "Jinbo", ""]]}, {"id": "1908.00704", "submitter": "Alireza Naghizadeh", "authors": "Alireza Naghizadeh and Mohammadsajad Abavisani and Dimitris N. Metaxas", "title": "Greedy AutoAugment", "comments": "Pattern Recognition Letters (2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major problem in data augmentation is to ensure that the generated new\nsamples cover the search space. This is a challenging problem and requires\nexploration for data augmentation policies to ensure their effectiveness in\ncovering the search space. In this paper, we propose Greedy AutoAugment as a\nhighly efficient search algorithm to find the best augmentation policies. We\nuse a greedy approach to reduce the exponential growth of the number of\npossible trials to linear growth. The Greedy Search also helps us to lead the\nsearch towards the sub-policies with better results, which eventually helps to\nincrease the accuracy. The proposed method can be used as a reliable addition\nto the current artifitial neural networks. Our experiments on four datasets\n(Tiny ImageNet, CIFAR-10, CIFAR-100, and SVHN) show that Greedy AutoAugment\nprovides better accuracy, while using 360 times fewer computational resources.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 05:28:03 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 01:34:48 GMT"}], "update_date": "2020-10-08", "authors_parsed": [["Naghizadeh", "Alireza", ""], ["Abavisani", "Mohammadsajad", ""], ["Metaxas", "Dimitris N.", ""]]}, {"id": "1908.00709", "submitter": "Xin He", "authors": "Xin He, Kaiyong Zhao, Xiaowen Chu", "title": "AutoML: A Survey of the State-of-the-Art", "comments": "automated machine learning (AutoML), published in journal of\n  Knowledge-Based Systems", "journal-ref": "Knowledge-Based Systems, Volume 212, 5 January 2021, 106622", "doi": "10.1016/j.knosys.2020.106622", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning (DL) techniques have penetrated all aspects of our lives and\nbrought us great convenience. However, building a high-quality DL system for a\nspecific task highly relies on human expertise, hindering the applications of\nDL to more areas. Automated machine learning (AutoML) becomes a promising\nsolution to build a DL system without human assistance, and a growing number of\nresearchers focus on AutoML. In this paper, we provide a comprehensive and\nup-to-date review of the state-of-the-art (SOTA) in AutoML. First, we introduce\nAutoML methods according to the pipeline, covering data preparation, feature\nengineering, hyperparameter optimization, and neural architecture search (NAS).\nWe focus more on NAS, as it is currently very hot sub-topic of AutoML. We\nsummarize the performance of the representative NAS algorithms on the CIFAR-10\nand ImageNet datasets and further discuss several worthy studying directions of\nNAS methods: one/two-stage NAS, one-shot NAS, and joint hyperparameter and\narchitecture optimization. Finally, we discuss some open problems of the\nexisting AutoML methods for future research.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 05:56:13 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 16:11:15 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 13:05:19 GMT"}, {"version": "v4", "created": "Thu, 27 Feb 2020 15:00:06 GMT"}, {"version": "v5", "created": "Wed, 8 Jul 2020 11:43:36 GMT"}, {"version": "v6", "created": "Fri, 16 Apr 2021 03:38:23 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["He", "Xin", ""], ["Zhao", "Kaiyong", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1908.00722", "submitter": "Robin Strudel", "authors": "Robin Strudel, Alexander Pashevich, Igor Kalevatykh, Ivan Laptev,\n  Josef Sivic, Cordelia Schmid", "title": "Learning to combine primitive skills: A step towards versatile robotic\n  manipulation", "comments": "ICRA 2020. See the project webpage at\n  https://www.di.ens.fr/willow/research/rlbc/", "journal-ref": "IEEE ROBOTICS AND AUTOMATION LETTERS, JULY 2020. 4637-4643", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manipulation tasks such as preparing a meal or assembling furniture remain\nhighly challenging for robotics and vision. Traditional task and motion\nplanning (TAMP) methods can solve complex tasks but require full state\nobservability and are not adapted to dynamic scene changes. Recent learning\nmethods can operate directly on visual inputs but typically require many\ndemonstrations and/or task-specific reward engineering. In this work we aim to\novercome previous limitations and propose a reinforcement learning (RL)\napproach to task planning that learns to combine primitive skills. First,\ncompared to previous learning methods, our approach requires neither\nintermediate rewards nor complete task demonstrations during training. Second,\nwe demonstrate the versatility of our vision-based task planning in challenging\nsettings with temporary occlusions and dynamic scene changes. Third, we propose\nan efficient training of basic skills from few synthetic demonstrations by\nexploring recent CNN architectures and data augmentation. Notably, while all of\nour policies are learned on visual inputs in simulated environments, we\ndemonstrate the successful transfer and high success rates when applying such\npolicies to manipulation tasks on a real UR5 robotic arm.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:04:17 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 16:02:27 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 14:26:45 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Strudel", "Robin", ""], ["Pashevich", "Alexander", ""], ["Kalevatykh", "Igor", ""], ["Laptev", "Ivan", ""], ["Sivic", "Josef", ""], ["Schmid", "Cordelia", ""]]}, {"id": "1908.00733", "submitter": "Mohammad Sadegh Aliakbarian", "authors": "Mohammad Sadegh Aliakbarian, Fatemeh Sadat Saleh, Mathieu Salzmann,\n  Lars Petersson, Stephen Gould, Amirhossein Habibian", "title": "Learning Variations in Human Motion via Mix-and-Match Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human motion prediction is a stochastic process: Given an observed sequence\nof poses, multiple future motions are plausible. Existing approaches to\nmodeling this stochasticity typically combine a random noise vector with\ninformation about the previous poses. This combination, however, is done in a\ndeterministic manner, which gives the network the flexibility to learn to\nignore the random noise. In this paper, we introduce an approach to\nstochastically combine the root of variations with previous pose information,\nwhich forces the model to take the noise into account. We exploit this idea for\nmotion prediction by incorporating it into a recurrent encoder-decoder network\nwith a conditional variational autoencoder block that learns to exploit the\nperturbations. Our experiments demonstrate that our model yields high-quality\npose sequences that are much more diverse than those from state-of-the-art\nstochastic motion prediction techniques.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:48:48 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2020 22:03:12 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Aliakbarian", "Mohammad Sadegh", ""], ["Saleh", "Fatemeh Sadat", ""], ["Salzmann", "Mathieu", ""], ["Petersson", "Lars", ""], ["Gould", "Stephen", ""], ["Habibian", "Amirhossein", ""]]}, {"id": "1908.00734", "submitter": "Marco Schreyer", "authors": "Marco Schreyer, Timur Sattarov, Christian Schulze, Bernd Reimer, and\n  Damian Borth", "title": "Detection of Accounting Anomalies in the Latent Space using Adversarial\n  Autoencoder Neural Networks", "comments": "11 pages, 9 figures, 2nd KDD Workshop on Anomaly Detection in\n  Finance, August 05, 2019, Anchorage, Alaska", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of fraud in accounting data is a long-standing challenge in\nfinancial statement audits. Nowadays, the majority of applied techniques refer\nto handcrafted rules derived from known fraud scenarios. While fairly\nsuccessful, these rules exhibit the drawback that they often fail to generalize\nbeyond known fraud scenarios and fraudsters gradually find ways to circumvent\nthem. In contrast, more advanced approaches inspired by the recent success of\ndeep learning often lack seamless interpretability of the detected results. To\novercome this challenge, we propose the application of adversarial autoencoder\nnetworks. We demonstrate that such artificial neural networks are capable of\nlearning a semantic meaningful representation of real-world journal entries.\nThe learned representation provides a holistic view on a given set of journal\nentries and significantly improves the interpretability of detected accounting\nanomalies. We show that such a representation combined with the networks\nreconstruction error can be utilized as an unsupervised and highly adaptive\nanomaly assessment. Experiments on two datasets and initial feedback received\nby forensic accountants underpinned the effectiveness of the approach.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:50:29 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Schreyer", "Marco", ""], ["Sattarov", "Timur", ""], ["Schulze", "Christian", ""], ["Reimer", "Bernd", ""], ["Borth", "Damian", ""]]}, {"id": "1908.00735", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt, Barbara Hammer", "title": "Efficient computation of counterfactual explanations of LVQ models", "comments": "Short version accepted at ESANN-2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of machine learning in practice and legal regulations like\nEU's GDPR cause the necessity to be able to explain the prediction and behavior\nof machine learning models. A prominent example of particularly intuitive\nexplanations of AI models in the context of decision making are counterfactual\nexplanations. Yet, it is still an open research problem how to efficiently\ncompute counterfactual explanations for many models.\n  We investigate how to efficiently compute counterfactual explanations for an\nimportant class of models, prototype-based classifiers such as learning vector\nquantization models. In particular, we derive specific convex and non-convex\nprograms depending on the used metric.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 07:51:37 GMT"}, {"version": "v2", "created": "Mon, 27 Jan 2020 09:47:49 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "1908.00754", "submitter": "Abon Chaudhuri", "authors": "Abon Chaudhuri", "title": "A Visual Technique to Analyze Flow of Information in a Machine Learning\n  System", "comments": "Published in Visualization and Data Analysis (VDA), part of IS&T\n  Electronic Imaging Symposium 2018", "journal-ref": null, "doi": "10.2352/ISSN.2470-1173.2018.01.VDA-380", "report-no": null, "categories": "cs.LG cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning (ML) algorithms and machine learning based software systems\nimplicitly or explicitly involve complex flow of information between various\nentities such as training data, feature space, validation set and results.\nUnderstanding the statistical distribution of such information and how they\nflow from one entity to another influence the operation and correctness of such\nsystems, especially in large-scale applications that perform classification or\nprediction in real time. In this paper, we propose a visual approach to\nunderstand and analyze flow of information during model training and serving\nphases. We build the visualizations using a technique called Sankey Diagram -\nconventionally used to understand data flow among sets - to address various use\ncases of in a machine learning system. We demonstrate how the proposed\ntechnique, tweaked and twisted to suit a classification problem, can play a\ncritical role in better understanding of the training data, the features, and\nthe classifier performance. We also discuss how this technique enables\ndiagnostic analysis of model predictions and comparative analysis of\npredictions from multiple classifiers. The proposed concept is illustrated with\nthe example of categorization of millions of products in the e-commerce domain\n- a multi-class hierarchical classification problem.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 08:31:36 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Chaudhuri", "Abon", ""]]}, {"id": "1908.00762", "submitter": "Kamel Jebreen Mr", "authors": "Kamel Jebreen and Badih Ghattas", "title": "Inferring linear and nonlinear Interaction networks using neighborhood\n  support vector machines", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider modelling interaction between a set of variables\nin the context of time series and high dimension. We suggest two approaches.\nThe first is similar to the neighborhood lasso when the lasso model is replaced\nby a support vector machine (SVMs). The second is a restricted Bayesian network\nadapted for time series. We show the efficiency of our approaches by\nsimulations using linear, nonlinear data set and a mixture of both.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 09:00:14 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Jebreen", "Kamel", ""], ["Ghattas", "Badih", ""]]}, {"id": "1908.00766", "submitter": "S{\\l}awomir Kapka", "authors": "S{\\l}awomir Kapka, Mateusz Lewandowski", "title": "Sound source detection, localization and classification using\n  consecutive ensemble of CRNN models", "comments": "5 pages, 3 figures, conference", "journal-ref": "Proceedings of the Detection and Classification of Acoustic Scenes\n  and Events 2019 Workshop (DCASE2019), New York University, NY, USA, October\n  2019", "doi": "10.33682/1syg-dy60", "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our method for DCASE2019 task3: Sound Event\nLocalization and Detection (SELD). We use four CRNN SELDnet-like single output\nmodels which run in a consecutive manner to recover all possible information of\noccurring events. We decompose the SELD task into estimating number of active\nsources, estimating direction of arrival of a single source, estimating\ndirection of arrival of the second source where the direction of the first one\nis known and a multi-label classification task. We use custom consecutive\nensemble to predict events' onset, offset, direction of arrival and class. The\nproposed approach is evaluated on the TAU Spatial Sound Events 2019 - Ambisonic\nand it is compared with other participants' submissions.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 09:10:08 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 09:55:34 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Kapka", "S\u0142awomir", ""], ["Lewandowski", "Mateusz", ""]]}, {"id": "1908.00780", "submitter": "Puyu Wang", "authors": "Puyu Wang and Hai Zhang", "title": "Differential Privacy for Sparse Classification Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a differential privacy version of convex and\nnonconvex sparse classification approach. Based on alternating direction method\nof multiplier (ADMM) algorithm, we transform the solving of sparse problem into\nthe multistep iteration process. Then we add exponential noise to stable steps\nto achieve privacy protection. By the property of the post-processing holding\nof differential privacy, the proposed approach satisfies the\n$\\epsilon-$differential privacy even when the original problem is unstable.\nFurthermore, we present the theoretical privacy bound of the differential\nprivacy classification algorithm. Specifically, the privacy bound of our\nalgorithm is controlled by the algorithm iteration number, the privacy\nparameter, the parameter of loss function, ADMM pre-selected parameter, and the\ndata size. Finally we apply our framework to logistic regression with $L_1$\nregularizer and logistic regression with $L_{1/2}$ regularizer. Numerical\nstudies demonstrate that our method is both effective and efficient which\nperforms well in sensitive data analysis.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 09:57:04 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Wang", "Puyu", ""], ["Zhang", "Hai", ""]]}, {"id": "1908.00812", "submitter": "Eirina Bourtsoulatze", "authors": "Eirina Bourtsoulatze, Aaron Chadha, Ilya Fadeev, Vasileios Giotsas,\n  Yiannis Andreopoulos", "title": "Deep Video Precoding", "comments": "16 pages, 14 figures, 11 tables, to appear in IEEE Trans. Circ. Syst.\n  for Video Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several groups are currently investigating how deep learning may advance the\nstate-of-the-art in image and video coding. An open question is how to make\ndeep neural networks work in conjunction with existing (and upcoming) video\ncodecs, such as MPEG AVC, HEVC, VVC, Google VP9 and AOM AV1, as well as\nexisting container and transport formats, without imposing any changes at the\nclient side. Such compatibility is a crucial aspect when it comes to practical\ndeployment, especially due to the fact that the video content industry and\nhardware manufacturers are expected to remain committed to these standards for\nthe foreseeable future. We propose to use deep neural networks as precoders for\ncurrent and future video codecs and adaptive video streaming systems. In our\ncurrent design, the core precoding component comprises a cascaded structure of\ndownscaling neural networks that operates during video encoding, prior to\ntransmission. This is coupled with a precoding mode selection algorithm for\neach independently-decodable stream segment, which adjusts the downscaling\nfactor according to scene characteristics, the utilized encoder, and the\ndesired bitrate and encoding configuration. Our framework is compatible with\nall current and future codec and transport standards, as our deep precoding\nnetwork structure is trained in conjunction with linear upscaling filters\n(e.g., the bilinear filter), which are supported by all web video players.\nResults with FHD and UHD content and widely-used AVC, HEVC and VP9 encoders\nshow that coupling such standards with the proposed deep video precoding allows\nfor 15% to 45% rate reduction under encoding configurations and bitrates\nsuitable for video-on-demand adaptive streaming systems. The use of precoding\ncan also lead to encoding complexity reduction, which is essential for\ncost-effective cloud deployment of complex encoders like H.265/HEVC and VP9.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 11:44:14 GMT"}, {"version": "v2", "created": "Fri, 13 Dec 2019 20:10:34 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Bourtsoulatze", "Eirina", ""], ["Chadha", "Aaron", ""], ["Fadeev", "Ilya", ""], ["Giotsas", "Vasileios", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1908.00825", "submitter": "Abdul-Saboor Sheikh", "authors": "Romain Guigour\\`es, Yuen King Ho, Evgenii Koriagin, Abdul-Saboor\n  Sheikh, Urs Bergmann, Reza Shirvany", "title": "A Hierarchical Bayesian Model for Size Recommendation in Fashion", "comments": null, "journal-ref": "In: Proceedings of the 12th ACM Conference on Recommender Systems.\n  ACM, 2018. S. 392-396", "doi": "10.1145/3240323.3240388", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a hierarchical Bayesian approach to tackle the challenging\nproblem of size recommendation in e-commerce fashion. Our approach jointly\nmodels a size purchased by a customer, and its possible return event: 1. no\nreturn, 2. returned too small 3. returned too big. Those events are drawn\nfollowing a multinomial distribution parameterized on the joint probability of\neach event, built following a hierarchy combining priors. Such a model allows\nus to incorporate extended domain expertise and article characteristics as\nprior knowledge, which in turn makes it possible for the underlying parameters\nto emerge thanks to sufficient data. Experiments are presented on real\n(anonymized) data from millions of customers along with a detailed discussion\non the efficiency of such an approach within a large scale production system.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 12:31:22 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Guigour\u00e8s", "Romain", ""], ["Ho", "Yuen King", ""], ["Koriagin", "Evgenii", ""], ["Sheikh", "Abdul-Saboor", ""], ["Bergmann", "Urs", ""], ["Shirvany", "Reza", ""]]}, {"id": "1908.00865", "submitter": "Guilherme Fran\\c{c}a", "authors": "Guilherme Fran\\c{c}a, Daniel P. Robinson, Ren\\'e Vidal", "title": "Gradient flows and proximal splitting methods: A unified view on\n  accelerated and stochastic optimization", "comments": "the paper was reorganized; new additional material; matches published\n  version", "journal-ref": "Phys. Rev. E 103, 053304 (2021)", "doi": "10.1103/PhysRevE.103.053304", "report-no": null, "categories": "math.OC cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization is at the heart of machine learning, statistics and many applied\nscientific disciplines. It also has a long history in physics, ranging from the\nminimal action principle to finding ground states of disordered systems such as\nspin glasses. Proximal algorithms form a class of methods that are broadly\napplicable and are particularly well-suited to nonsmooth, constrained,\nlarge-scale, and distributed optimization problems. There are essentially five\nproximal algorithms currently known: Forward-backward splitting, Tseng\nsplitting, Douglas-Rachford, alternating direction method of multipliers, and\nthe more recent Davis-Yin. These methods sit on a higher level of abstraction\ncompared to gradient-based ones, with deep roots in nonlinear functional\nanalysis. We show that all of these methods are actually different\ndiscretizations of a single differential equation, namely, the simple gradient\nflow which dates back to Cauchy (1847). An important aspect behind many of the\nsuccess stories in machine learning relies on \"accelerating\" the convergence of\nfirst-order methods. We show that similar discretization schemes applied to\nNewton's equation with an additional dissipative force, which we refer to as\naccelerated gradient flow, allow us to obtain accelerated variants of all these\nproximal algorithms -- the majority of which are new although some recover\nknown cases in the literature. Furthermore, we extend these methods to\nstochastic settings, allowing us to make connections with Langevin and\nFokker-Planck equations. Similar ideas apply to gradient descent, heavy ball,\nand Nesterov's method which are simpler. Our results therefore provide a\nunified framework from which several important optimization methods are nothing\nbut simulations of classical dissipative systems.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:01:11 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 15:10:43 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 20:54:13 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 17:10:30 GMT"}, {"version": "v5", "created": "Mon, 10 May 2021 16:36:34 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fran\u00e7a", "Guilherme", ""], ["Robinson", "Daniel P.", ""], ["Vidal", "Ren\u00e9", ""]]}, {"id": "1908.00868", "submitter": "Owen Howell", "authors": "Owen Howell and Cui Wenping and Robert Marsland III and Pankaj Mehta", "title": "Machine Learning as Ecology", "comments": null, "journal-ref": null, "doi": "10.1088/1751-8121/ab956e", "report-no": null, "categories": "cs.LG cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning methods have had spectacular success on numerous problems.\nHere we show that a prominent class of learning algorithms - including Support\nVector Machines (SVMs) -- have a natural interpretation in terms of ecological\ndynamics. We use these ideas to design new online SVM algorithms that exploit\necological invasions, and benchmark performance using the MNIST dataset. Our\nwork provides a new ecological lens through which we can view statistical\nlearning and opens the possibility of designing ecosystems for machine\nlearning.\n  Supplemental code is found at https://github.com/owenhowell20/EcoSVM.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:08:17 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 13:52:08 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Howell", "Owen", ""], ["Wenping", "Cui", ""], ["Marsland", "Robert", "III"], ["Mehta", "Pankaj", ""]]}, {"id": "1908.00876", "submitter": "Henrik Skibbe", "authors": "Henrik Skibbe, Akiya Watakabe, Ken Nakae, Carlos Enrique Gutierrez,\n  Hiromichi Tsukada, Junichi Hata, Takashi Kawase, Rui Gong, Alexander\n  Woodward, Kenji Doya, Hideyuki Okano, Tetsuo Yamamori, Shin Ishii", "title": "MarmoNet: a pipeline for automated projection mapping of the common\n  marmoset brain from whole-brain serial two-photon tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the connectivity in the brain is an important prerequisite for\nunderstanding how the brain processes information. In the Brain/MINDS project,\na connectivity study on marmoset brains uses two-photon microscopy fluorescence\nimages of axonal projections to collect the neuron connectivity from defined\nbrain regions at the mesoscopic scale. The processing of the images requires\nthe detection and segmentation of the axonal tracer signal. The objective is to\ndetect as much tracer signal as possible while not misclassifying other\nbackground structures as the signal. This can be challenging because of imaging\nnoise, a cluttered image background, distortions or varying image contrast\ncause problems.\n  We are developing MarmoNet, a pipeline that processes and analyzes tracer\nimage data of the common marmoset brain. The pipeline incorporates\nstate-of-the-art machine learning techniques based on artificial convolutional\nneural networks (CNN) and image registration techniques to extract and map all\nrelevant information in a robust manner. The pipeline processes new images in a\nfully automated way.\n  This report introduces the current state of the tracer signal analysis part\nof the pipeline.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:20:27 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Skibbe", "Henrik", ""], ["Watakabe", "Akiya", ""], ["Nakae", "Ken", ""], ["Gutierrez", "Carlos Enrique", ""], ["Tsukada", "Hiromichi", ""], ["Hata", "Junichi", ""], ["Kawase", "Takashi", ""], ["Gong", "Rui", ""], ["Woodward", "Alexander", ""], ["Doya", "Kenji", ""], ["Okano", "Hideyuki", ""], ["Yamamori", "Tetsuo", ""], ["Ishii", "Shin", ""]]}, {"id": "1908.00951", "submitter": "Lionel Yelibi", "authors": "Lionel Yelibi, Tim Gebbie", "title": "Agglomerative Likelihood Clustering", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP physics.data-an stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of fast time-series data clustering. Building on\nprevious work modeling the correlation-based Hamiltonian of spin variables we\npresent an updated fast non-expensive Agglomerative Likelihood Clustering\nalgorithm (ALC). The method replaces the optimized genetic algorithm based\napproach (f-SPC) with an agglomerative recursive merging framework inspired by\nprevious work in Econophysics and Community Detection. The method is tested on\nnoisy synthetic correlated time-series data-sets with built-in cluster\nstructure to demonstrate that the algorithm produces meaningful non-trivial\nresults. We apply it to time-series data-sets as large as 20,000 assets and we\nargue that ALC can reduce compute time costs and resource usage cost for large\nscale clustering for time-series applications while being serialized, and hence\nhas no obvious parallelization requirement. The algorithm can be an effective\nchoice for state-detection for online learning in a fast non-linear data\nenvironment because the algorithm requires no prior information about the\nnumber of clusters.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 16:48:45 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 08:04:18 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 02:46:45 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Yelibi", "Lionel", ""], ["Gebbie", "Tim", ""]]}, {"id": "1908.00963", "submitter": "Mathukumalli Vidyasagar", "authors": "Shantanu Prasad Burnwal and Mathukumalli Vidyasagar", "title": "Deterministic Completion of Rectangular Matrices Using Asymmetric\n  Ramanujan Graphs: Exact and Stable Recovery", "comments": "The original submission 1908.00963 has been split into two parts. The\n  replacement submission is Part-1 of the revised version. Part-2 can also be\n  found on arXiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the matrix completion problem: Suppose $X \\in {\\mathbb\nR}^{n_r \\times n_c}$ is unknown except for a known upper bound $r$ on its rank.\nBy measuring a small number $m \\ll n_r n_c$ of elements of $X$, is it possible\nto recover $X$ exactly with noise-free measurements, or to construct a good\napproximation of $X$ with noisy measurements? Existing solutions to these\nproblems involve sampling the elements uniformly and at random, and can\nguarantee exact recovery of the unknown matrix only with high probability. In\nthis paper, we present a \\textit{deterministic} sampling method for matrix\ncompletion. We achieve this by choosing the sampling set as the edge set of an\nasymmetric Ramanujan bigraph, and constrained nuclear norm minimization is the\nrecovery method. Specifically, we derive sufficient conditions under which the\nunknown matrix is completed exactly with noise-free measurements, and is\napproximately completed with noisy measurements, which we call \"stable\"\ncompletion.\n  The conditions derived here are only sufficient and more restrictive than\nrandom sampling. To study how close they are to being necessary, we conducted\nnumerical simulations on randomly generated low rank matrices, using the LPS\nfamilies of Ramanujan graphs. These simulations demonstrate two facts: (i) In\norder to achieve exact completion, it appears sufficient to choose the degree\n$d$ of the Ramanujan graph to be $\\geq 3r$. (ii) There is a \"phase transition,\"\nwhereby the likelihood of success suddenly drops from 100\\% to 0\\% if the rank\nis increased by just one or two beyond a critical value. The phase transition\nphenomenon is well-known and well-studied in vector recovery using\n$\\ell_1$-norm minimization. However, it is less studied in matrix completion\nand nuclear norm minimization, and not much understood.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 17:32:56 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 16:56:17 GMT"}, {"version": "v3", "created": "Sun, 26 Apr 2020 15:18:12 GMT"}, {"version": "v4", "created": "Thu, 21 May 2020 11:20:07 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Burnwal", "Shantanu Prasad", ""], ["Vidyasagar", "Mathukumalli", ""]]}, {"id": "1908.00966", "submitter": "Chun-An Chou", "authors": "Chun-An Chou and Qingtao Cao and Shao-Jen Weng and Che-Hung Tsai", "title": "Mixed-Integer Optimization Approach to Learning Association Rules for\n  Unplanned ICU Transfer", "comments": null, "journal-ref": "Artificial Intelligence in Medicine, 2020", "doi": "10.1016/j.artmed.2020.101806", "report-no": null, "categories": "cs.LG math.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After admission to emergency department (ED), patients with critical\nillnesses are transferred to intensive care unit (ICU) due to unexpected\nclinical deterioration occurrence. Identifying such unplanned ICU transfers is\nurgently needed for medical physicians to achieve two-fold goals: improving\ncritical care quality and preventing mortality. A priority task is to\nunderstand the crucial rationale behind diagnosis results of individual\npatients during stay in ED, which helps prepare for an early transfer to ICU.\nMost existing prediction studies were based on univariate analysis or multiple\nlogistic regression to provide one-size-fit-all results. However, patient\ncondition varying from case to case may not be accurately examined by the only\njudgment. In this study, we present a new decision tool using a mathematical\noptimization approach aiming to automatically discover rules associating\ndiagnostic features with high-risk outcome (i.e., unplanned transfers) in\ndifferent deterioration scenarios. We consider four mutually exclusive patient\nsubgroups based on the principal reasons of ED visits: infections,\ncardiovascular/respiratory diseases, gastrointestinal diseases, and\nneurological/other diseases at a suburban teaching hospital. The analysis\nresults demonstrate significant rules associated with unplanned transfer\noutcome for each subgroups and also show comparable prediction accuracy,\ncompared to state-of-the-art machine learning methods while providing\neasy-to-interpret symptom-outcome information.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 17:45:50 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Chou", "Chun-An", ""], ["Cao", "Qingtao", ""], ["Weng", "Shao-Jen", ""], ["Tsai", "Che-Hung", ""]]}, {"id": "1908.01000", "submitter": "Fan-Yun Sun", "authors": "Fan-Yun Sun, Jordan Hoffmann, Vikas Verma, Jian Tang", "title": "InfoGraph: Unsupervised and Semi-supervised Graph-Level Representation\n  Learning via Mutual Information Maximization", "comments": "ICLR 2020 (spotlight)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies learning the representations of whole graphs in both\nunsupervised and semi-supervised scenarios. Graph-level representations are\ncritical in a variety of real-world applications such as predicting the\nproperties of molecules and community analysis in social networks. Traditional\ngraph kernel based methods are simple, yet effective for obtaining fixed-length\nrepresentations for graphs but they suffer from poor generalization due to\nhand-crafted designs. There are also some recent methods based on language\nmodels (e.g. graph2vec) but they tend to only consider certain substructures\n(e.g. subtrees) as graph representatives. Inspired by recent progress of\nunsupervised representation learning, in this paper we proposed a novel method\ncalled InfoGraph for learning graph-level representations. We maximize the\nmutual information between the graph-level representation and the\nrepresentations of substructures of different scales (e.g., nodes, edges,\ntriangles). By doing so, the graph-level representations encode aspects of the\ndata that are shared across different scales of substructures. Furthermore, we\nfurther propose InfoGraph*, an extension of InfoGraph for semi-supervised\nscenarios. InfoGraph* maximizes the mutual information between unsupervised\ngraph representations learned by InfoGraph and the representations learned by\nexisting supervised methods. As a result, the supervised encoder learns from\nunlabeled data while preserving the latent semantic space favored by the\ncurrent supervised task. Experimental results on the tasks of graph\nclassification and molecular property prediction show that InfoGraph is\nsuperior to state-of-the-art baselines and InfoGraph* can achieve performance\ncompetitive with state-of-the-art semi-supervised models.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 06:28:43 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 16:24:01 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 16:20:00 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Sun", "Fan-Yun", ""], ["Hoffmann", "Jordan", ""], ["Verma", "Vikas", ""], ["Tang", "Jian", ""]]}, {"id": "1908.01007", "submitter": "Spencer Frazier", "authors": "Spencer Frazier, Mark Riedl", "title": "Improving Deep Reinforcement Learning in Minecraft with Action Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep reinforcement learning agents complex behaviors in 3D virtual\nenvironments requires significant computational resources. This is especially\ntrue in environments with high degrees of aliasing, where many states share\nnearly identical visual features. Minecraft is an exemplar of such an\nenvironment. We hypothesize that interactive machine learning IML, wherein\nhuman teachers play a direct role in training through demonstrations, critique,\nor action advice, may alleviate agent susceptibility to aliasing. However,\ninteractive machine learning is only practical when the number of human\ninteractions is limited, requiring a balance between human teacher effort and\nagent performance. We conduct experiments with two reinforcement learning\nalgorithms which enable human teachers to give action advice, Feedback\nArbitration and Newtonian Action Advice, under visual aliasing conditions. To\nassess potential cognitive load per advice type, we vary the accuracy and\nfrequency of various human action advice techniques. Training efficiency,\nrobustness against infrequent and inaccurate advisor input, and sensitivity to\naliasing are examined.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 18:36:44 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Frazier", "Spencer", ""], ["Riedl", "Mark", ""]]}, {"id": "1908.01009", "submitter": "Xiangju Qin", "authors": "Xiangju Qin, Paul Blomstedt and Samuel Kaski", "title": "Scalable Bayesian Non-linear Matrix Completion", "comments": "7 pages, 1 figures, 2 tables. The paper has been accepted for\n  publication in the proceedings of the 28th International Joint Conference on\n  Artificial Intelligence (IJCAI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion aims to predict missing elements in a partially observed\ndata matrix which in typical applications, such as collaborative filtering, is\nlarge and extremely sparsely observed. A standard solution is matrix\nfactorization, which predicts unobserved entries as linear combinations of\nlatent variables. We generalize to non-linear combinations in massive-scale\nmatrices. Bayesian approaches have been proven beneficial in linear matrix\ncompletion, but not applied in the more general non-linear case, due to limited\nscalability. We introduce a Bayesian non-linear matrix completion algorithm,\nwhich is based on a recent Bayesian formulation of Gaussian process latent\nvariable models. To solve the challenges regarding scalability and computation,\nwe propose a data-parallel distributed computational approach with a restricted\ncommunication scheme. We evaluate our method on challenging out-of-matrix\nprediction tasks using both simulated and real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 16:48:31 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Qin", "Xiangju", ""], ["Blomstedt", "Paul", ""], ["Kaski", "Samuel", ""]]}, {"id": "1908.01010", "submitter": "Bangti Jin", "authors": "Chen Zhang and Bangti Jin", "title": "Probabilistic Residual Learning for Aleatoric Uncertainty in Image\n  Restoration", "comments": "this version is outdated, and we are completely reorganizing the\n  paper and split it into several different pieces of work. Thus, we prefer to\n  withdraw it from arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aleatoric uncertainty is an intrinsic property of ill-posed inverse and\nimaging problems. Its quantification is vital for assessing the reliability of\nrelevant point estimates. In this paper, we propose an efficient framework for\nquantifying aleatoric uncertainty for deep residual learning and showcase its\nsignificant potential on image restoration. In the framework, we divide the\nconditional probability modeling for the residual variable into a deterministic\nhomo-dimensional level, a stochastic low-dimensional level and a merging level.\nThe low-dimensionality is especially suitable for sparse correlation between\nimage pixels, enables efficient sampling for high dimensional problems and acts\nas a regularizer for the distribution. Preliminary numerical experiments show\nthat the proposed method can give not only state-of-the-art point estimates of\nimage restoration but also useful associated uncertainty information.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 16:06:07 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 13:42:49 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Zhang", "Chen", ""], ["Jin", "Bangti", ""]]}, {"id": "1908.01022", "submitter": "Ross Allen", "authors": "Ross E. Allen, Jayesh K. Gupta, Jaime Pena, Yutai Zhou, Javona White\n  Bear, Mykel J. Kochenderfer", "title": "Health-Informed Policy Gradients for Multi-Agent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a definition of system health in the context of multiple\nagents optimizing a joint reward function. We use this definition as a credit\nassignment term in a policy gradient algorithm to distinguish the contributions\nof individual agents to the global reward. The health-informed credit\nassignment is then extended to a multi-agent variant of the proximal policy\noptimization algorithm and demonstrated on particle and multiwalker robot\nenvironments that have characteristics such as system health, risk-taking,\nsemi-expendable agents, continuous action spaces, and partial observability. We\nshow significant improvement in learning performance compared to policy\ngradient methods that do not perform multi-agent credit assignment.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 19:20:29 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:12:54 GMT"}, {"version": "v3", "created": "Thu, 19 Mar 2020 20:44:39 GMT"}, {"version": "v4", "created": "Mon, 4 Jan 2021 20:16:46 GMT"}], "update_date": "2021-01-06", "authors_parsed": [["Allen", "Ross E.", ""], ["Gupta", "Jayesh K.", ""], ["Pena", "Jaime", ""], ["Zhou", "Yutai", ""], ["Bear", "Javona White", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1908.01031", "submitter": "Adam Gudy\\'s", "authors": "Adam Gudy\\'s, Marek Sikora, {\\L}ukasz Wr\\'obel", "title": "RuleKit: A Comprehensive Suite for Rule-Based Learning", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": "10.1016/j.knosys.2020.105480", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rule-based models are often used for data analysis as they combine\ninterpretability with predictive power. We present RuleKit, a versatile tool\nfor rule learning. Based on a sequential covering induction algorithm, it is\nsuitable for classification, regression, and survival problems. The presence of\na user-guided induction facilitates verifying hypotheses concerning data\ndependencies which are expected or of interest. The powerful and flexible\nexperimental environment allows straightforward investigation of different\ninduction schemes. The analysis can be performed in batch mode, through\nRapidMiner plug-in, or R package. A documented Java API is also provided for\nconvenience. The software is publicly available at GitHub under GNU AGPL-3.0\nlicense.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 19:53:46 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Gudy\u015b", "Adam", ""], ["Sikora", "Marek", ""], ["Wr\u00f3bel", "\u0141ukasz", ""]]}, {"id": "1908.01034", "submitter": "Vasilis Kontonis", "authors": "Vasilis Kontonis, Christos Tzamos, Manolis Zampetakis", "title": "Efficient Truncated Statistics with Unknown Truncation", "comments": "to appear at 60th Annual IEEE Symposium on Foundations of Computer\n  Science (FOCS), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating the parameters of a Gaussian distribution\nwhen samples are only shown if they fall in some (unknown) subset $S \\subseteq\n\\R^d$. This core problem in truncated statistics has long history going back to\nGalton, Lee, Pearson and Fisher. Recent work by Daskalakis et al. (FOCS'18),\nprovides the first efficient algorithm that works for arbitrary sets in high\ndimension when the set is known, but leaves as an open problem the more\nchallenging and relevant case of unknown truncation set.\n  Our main result is a computationally and sample efficient algorithm for\nestimating the parameters of the Gaussian under arbitrary unknown truncation\nsets whose performance decays with a natural measure of complexity of the set,\nnamely its Gaussian surface area. Notably, this algorithm works for large\nfamilies of sets including intersections of halfspaces, polynomial threshold\nfunctions and general convex sets. We show that our algorithm closely captures\nthe tradeoff between the complexity of the set and the number of samples needed\nto learn the parameters by exhibiting a set with small Gaussian surface area\nfor which it is information theoretically impossible to learn the true Gaussian\nwith few samples.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:05:52 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kontonis", "Vasilis", ""], ["Tzamos", "Christos", ""], ["Zampetakis", "Manolis", ""]]}, {"id": "1908.01039", "submitter": "Chloe Hsu", "authors": "Chloe Ching-Yun Hsu, Michaela Hardt, Moritz Hardt", "title": "Linear Dynamics: Clustering without identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear dynamical systems are a fundamental and powerful parametric model\nclass. However, identifying the parameters of a linear dynamical system is a\nvenerable task, permitting provably efficient solutions only in special cases.\nThis work shows that the eigenspectrum of unknown linear dynamics can be\nidentified without full system identification. We analyze a computationally\nefficient and provably convergent algorithm to estimate the eigenvalues of the\nstate-transition matrix in a linear dynamical system.\n  When applied to time series clustering, our algorithm can efficiently cluster\nmulti-dimensional time series with temporal offsets and varying lengths, under\nthe assumption that the time series are generated from linear dynamical\nsystems. Evaluating our algorithm on both synthetic data and real\nelectrocardiogram (ECG) signals, we see improvements in clustering quality over\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:15:56 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 13:46:48 GMT"}, {"version": "v3", "created": "Sat, 29 Feb 2020 08:51:25 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Hsu", "Chloe Ching-Yun", ""], ["Hardt", "Michaela", ""], ["Hardt", "Moritz", ""]]}, {"id": "1908.01046", "submitter": "Anthony Corso", "authors": "Anthony Corso, Peter Du, Katherine Driggs-Campbell, Mykel J.\n  Kochenderfer", "title": "Adaptive Stress Testing with Reward Augmentation for Autonomous Vehicle\n  Validation", "comments": "Appears in IEEE ITSC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining possible failure scenarios is a critical step in the evaluation\nof autonomous vehicle systems. Real-world vehicle testing is commonly employed\nfor autonomous vehicle validation, but the costs and time requirements are\nhigh. Consequently, simulation-driven methods such as Adaptive Stress Testing\n(AST) have been proposed to aid in validation. AST formulates the problem of\nfinding the most likely failure scenarios as a Markov decision process, which\ncan be solved using reinforcement learning. In practice, AST tends to find\nscenarios where failure is unavoidable and tends to repeatedly discover the\nsame types of failures of a system. This work addresses these issues by\nencoding domain relevant information into the search procedure. With this\nmodification, the AST method discovers a larger and more expressive subset of\nthe failure space when compared to the original AST formulation. We show that\nour approach is able to identify useful failure scenarios of an autonomous\nvehicle policy.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:39:59 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2019 18:27:43 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Corso", "Anthony", ""], ["Du", "Peter", ""], ["Driggs-Campbell", "Katherine", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1908.01050", "submitter": "Maciej Wielgosz", "authors": "Marcin Radzio, Maciej Wielgosz, Matej Mertik", "title": "Falls Prediction in eldery people using Gated Recurrent Units", "comments": "short concept paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Falls prevention, especially in older people, becomes an increasingly\nimportant topic in the times of aging societies. In this work, we present Gated\nRecurrent Unit-based neural networks models designed for predicting falls\n(syncope). The cardiovascular systems signals used in the study come from\nGravitational Physiology, Aging and Medicine Research Unit, Institute of\nPhysiology, Medical University of Graz. We used two of the collected signals,\nheart rate, and mean blood pressure. By using bidirectional GRU model, it was\npossible to predict the syncope occurrence approximately ten minutes before the\nmanual marker.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:52:04 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Radzio", "Marcin", ""], ["Wielgosz", "Maciej", ""], ["Mertik", "Matej", ""]]}, {"id": "1908.01052", "submitter": "Gabrielle Liu", "authors": "Gabrielle K. Liu", "title": "Weight Friction: A Simple Method to Overcome Catastrophic Forgetting and\n  Enable Continual Learning", "comments": "9 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, deep neural networks have found success in replicating\nhuman-level cognitive skills, yet they suffer from several major obstacles. One\nsignificant limitation is the inability to learn new tasks without forgetting\npreviously learned tasks, a shortcoming known as catastrophic forgetting. In\nthis research, we propose a simple method to overcome catastrophic forgetting\nand enable continual learning in neural networks. We draw inspiration from\nprinciples in neurology and physics to develop the concept of weight friction.\nWeight friction operates by a modification to the update rule in the gradient\ndescent optimization method. It converges at a rate comparable to that of the\nstochastic gradient descent algorithm and can operate over multiple task\ndomains. It performs comparably to current methods while offering improvements\nin computation and memory efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 20:55:46 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 20:41:24 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Liu", "Gabrielle K.", ""]]}, {"id": "1908.01059", "submitter": "Xin Wang", "authors": "Xin Wang, Hideaki Ishii, Linkang Du, Peng Cheng, Jiming Chen", "title": "Privacy-preserving Distributed Machine Learning via Local Randomization\n  and ADMM Perturbation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.3009007", "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.MA cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of training data, distributed machine learning (DML)\nis becoming more competent for large-scale learning tasks. However, privacy\nconcerns have to be given priority in DML, since training data may contain\nsensitive information of users. In this paper, we propose a privacy-preserving\nADMM-based DML framework with two novel features: First, we remove the\nassumption commonly made in the literature that the users trust the server\ncollecting their data. Second, the framework provides heterogeneous privacy for\nusers depending on data's sensitive levels and servers' trust degrees. The\nchallenging issue is to keep the accumulation of privacy losses over ADMM\niterations minimal. In the proposed framework, a local randomization approach,\nwhich is differentially private, is adopted to provide users with\nself-controlled privacy guarantee for the most sensitive information. Further,\nthe ADMM algorithm is perturbed through a combined noise-adding method, which\nsimultaneously preserves privacy for users' less sensitive information and\nstrengthens the privacy protection of the most sensitive information. We\nprovide detailed analyses on the performance of the trained model according to\nits generalization error. Finally, we conduct extensive experiments using\nreal-world datasets to validate the theoretical results and evaluate the\nclassification performance of the proposed framework.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 06:31:16 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 07:47:40 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Wang", "Xin", ""], ["Ishii", "Hideaki", ""], ["Du", "Linkang", ""], ["Cheng", "Peng", ""], ["Chen", "Jiming", ""]]}, {"id": "1908.01061", "submitter": "Martin Strohmeier", "authors": "Martin Strohmeier, Matthew Smith, Vincent Lenders, Ivan Martinovic", "title": "Classi-Fly: Inferring Aircraft Categories from Open Data using Machine\n  Learning", "comments": "10 pages, 6 figures, 8 tables, 40 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, air traffic communication data has become easy to access,\nenabling novel research in many fields. Exploiting this new data source, a wide\nrange of applications have emerged, from weather forecasting to stock market\nprediction, or the collection of information about military and government\nmovements. Typically these applications require knowledge about the metadata of\nthe aircraft, specifically its operator and the aircraft category.\n  armasuisse Science + Technology, the R\\&D agency for the Swiss Armed Forces,\nhas been developing Classi-Fly, a novel approach to obtain metadata about\naircraft based on their movement patterns. We validate Classi-Fly using several\nhundred thousand flights collected through open source means, in conjunction\nwith ground truth from publicly available aircraft registries containing more\nthan two million aircraft. Classi-Fly obtains the correct aircraft category\nwith an accuracy of over 88%, demonstrating that it can improve the meta data\nnecessary for applications working with air traffic communication. Finally, we\nshow that it is feasible to automatically detect specific flights such as\npolice and surveillance missions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 17:31:25 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 15:08:01 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Strohmeier", "Martin", ""], ["Smith", "Matthew", ""], ["Lenders", "Vincent", ""], ["Martinovic", "Ivan", ""]]}, {"id": "1908.01071", "submitter": "Yanting Ma", "authors": "Yanting Ma, Shuchin Aeron, and Hassan Mansour", "title": "On the modes of convergence of Stochastic Optimistic Mirror Descent\n  (OMD) for saddle point problems", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study the convergence of Mirror Descent (MD) and\nOptimistic Mirror Descent (OMD) for saddle point problems satisfying the notion\nof coherence as proposed in Mertikopoulos et al. We prove convergence of OMD\nwith exact gradients for coherent saddle point problems, and show that monotone\nconvergence only occurs after some sufficiently large number of iterations.\nThis is in contrast to the claim in Mertikopoulos et al. of monotone\nconvergence of OMD with exact gradients for coherent saddle point problems.\nBesides highlighting this important subtlety, we note that the almost sure\nconvergence guarantees of MD and OMD with stochastic gradients for strictly\ncoherent saddle point problems that are claimed in Mertikopoulos et al. are not\nfully justified by their proof. As such, we fill out the missing details in the\nproof and as a result have only been able to prove convergence with high\nprobability.\n  We would like to note that our analysis relies heavily on the core ideas and\nproof techniques introduced in Zhou et al. and Mertikopoulos et al., and we\nonly aim to re-state and correct the results in light of what we were able to\nprove rigorously while filling in the much needed missing details in their\nproofs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 21:30:56 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Ma", "Yanting", ""], ["Aeron", "Shuchin", ""], ["Mansour", "Hassan", ""]]}, {"id": "1908.01073", "submitter": "MohammadHossein AskariHemmat", "authors": "MohammadHossein AskariHemmat, Sina Honari, Lucas Rouhier, Christian S.\n  Perone, Julien Cohen-Adad, Yvon Savaria, Jean-Pierre David", "title": "U-Net Fixed-Point Quantization for Medical Image Segmentation", "comments": "Accepted to MICCAI 2019's Hardware Aware Learning for Medical Imaging\n  and Computer Assisted Intervention", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model quantization is leveraged to reduce the memory consumption and the\ncomputation time of deep neural networks. This is achieved by representing\nweights and activations with a lower bit resolution when compared to their high\nprecision floating point counterparts. The suitable level of quantization is\ndirectly related to the model performance. Lowering the quantization precision\n(e.g. 2 bits), reduces the amount of memory required to store model parameters\nand the amount of logic required to implement computational blocks, which\ncontributes to reducing the power consumption of the entire system. These\nbenefits typically come at the cost of reduced accuracy. The main challenge is\nto quantize a network as much as possible, while maintaining the performance\naccuracy. In this work, we present a quantization method for the U-Net\narchitecture, a popular model in medical image segmentation. We then apply our\nquantization algorithm to three datasets: (1) the Spinal Cord Gray Matter\nSegmentation (GM), (2) the ISBI challenge for segmentation of neuronal\nstructures in Electron Microscopic (EM), and (3) the public National Institute\nof Health (NIH) dataset for pancreas segmentation in abdominal CT scans. The\nreported results demonstrate that with only 4 bits for weights and 6 bits for\nactivations, we obtain 8 fold reduction in memory requirements while loosing\nonly 2.21%, 0.57% and 2.09% dice overlap score for EM, GM and NIH datasets\nrespectively. Our fixed point quantization provides a flexible trade off\nbetween accuracy and memory requirement which is not provided by previous\nquantization methods for U-Net such as TernaryNet.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 21:39:56 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 16:51:58 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["AskariHemmat", "MohammadHossein", ""], ["Honari", "Sina", ""], ["Rouhier", "Lucas", ""], ["Perone", "Christian S.", ""], ["Cohen-Adad", "Julien", ""], ["Savaria", "Yvon", ""], ["David", "Jean-Pierre", ""]]}, {"id": "1908.01080", "submitter": "Sanidhya Mangal", "authors": "Sanidhya Mangal, Rahul Modak, Poorva Joshi", "title": "LSTM Based Music Generation System", "comments": "6 pages, 11 figures", "journal-ref": "IARJSET: Vol. 6, Issue 5 (2019) 47-54", "doi": "10.17148/IARJSET.2019.6508", "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, music was treated as an analogue signal and was generated\nmanually. In recent years, music is conspicuous to technology which can\ngenerate a suite of music automatically without any human intervention. To\naccomplish this task, we need to overcome some technical challenges which are\ndiscussed descriptively in this paper. A brief introduction about music and its\ncomponents is provided in the paper along with the citation and analysis of\nrelated work accomplished by different authors in this domain. Main objective\nof this paper is to propose an algorithm which can be used to generate musical\nnotes using Recurrent Neural Networks (RNN), principally Long Short-Term Memory\n(LSTM) networks. A model is designed to execute this algorithm where data is\nrepresented with the help of musical instrument digital interface (MIDI) file\nformat for easier access and better understanding. Preprocessing of data before\nfeeding it into the model, revealing methods to read, process and prepare MIDI\nfiles for input are also discussed. The model used in this paper is used to\nlearn the sequences of polyphonic musical notes over a single-layered LSTM\nnetwork. The model must have the potential to recall past details of a musical\nsequence and its structure for better learning. Description of layered\narchitecture used in LSTM model and its intertwining connections to develop a\nneural network is presented in this work. This paper imparts a peek view of\ndistributions of weights and biases in every layer of the model along with a\nprecise representation of losses and accuracy at each step and batches. When\nthe model was thoroughly analyzed, it produced stellar results in composing new\nmelodies.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 22:10:19 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Mangal", "Sanidhya", ""], ["Modak", "Rahul", ""], ["Joshi", "Poorva", ""]]}, {"id": "1908.01087", "submitter": "Nesreen Ahmed", "authors": "Nesreen K. Ahmed, Nick Duffield", "title": "Adaptive Shrinkage Estimation for Streaming Graphs", "comments": "This paper is accepted at NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks are a natural representation of complex systems across the sciences,\nand higher-order dependencies are central to the understanding and modeling of\nthese systems. However, in many practical applications such as online social\nnetworks, networks are massive, dynamic, and naturally streaming, where\npairwise interactions among vertices become available one at a time in some\narbitrary order. The massive size and streaming nature of these networks allow\nonly partial observation, since it is infeasible to analyze the entire network.\nUnder such scenarios, it is challenging to study the higher-order structural\nand connectivity patterns of streaming networks. In this work, we consider the\nfundamental problem of estimating the higher-order dependencies using adaptive\nsampling. We propose a novel adaptive, single-pass sampling framework and\nunbiased estimators for higher-order network analysis of large streaming\nnetworks. Our algorithms exploit adaptive techniques to identify edges that are\nhighly informative for efficiently estimating the higher-order structure of\nstreaming networks from small sample data. We also introduce a novel\nJames-Stein shrinkage estimator to reduce the estimation error. Our approach is\nfully analytic, computationally efficient, and can be incrementally updated in\na streaming setting. Numerical experiments on large networks show that our\napproach is superior to baseline methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 23:02:16 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:06:30 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 23:44:44 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 22:59:24 GMT"}], "update_date": "2020-10-28", "authors_parsed": [["Ahmed", "Nesreen K.", ""], ["Duffield", "Nick", ""]]}, {"id": "1908.01089", "submitter": "Chirag Gupta", "authors": "Chirag Gupta, Sivaraman Balakrishnan, Aaditya Ramdas", "title": "Path Length Bounds for Gradient Descent and Flow", "comments": "55 pages. Accepted for publication at the Journal of Machine Learning\n  Research (JMLR, 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive bounds on the path length $\\zeta$ of gradient descent (GD) and\ngradient flow (GF) curves for various classes of smooth convex and nonconvex\nfunctions. Among other results, we prove that: (a) if the iterates are linearly\nconvergent with factor $(1-c)$, then $\\zeta$ is at most $\\mathcal{O}(1/c)$; (b)\nunder the Polyak-Kurdyka-Lojasiewicz (PKL) condition, $\\zeta$ is at most\n$\\mathcal{O}(\\sqrt{\\kappa})$, where $\\kappa$ is the condition number, and at\nleast $\\widetilde\\Omega(\\sqrt{d} \\wedge \\kappa^{1/4})$; (c) for quadratics,\n$\\zeta$ is $\\Theta(\\min\\{\\sqrt{d},\\sqrt{\\log \\kappa}\\})$ and in some cases can\nbe independent of $\\kappa$; (d) assuming just convexity, $\\zeta$ can be at most\n$2^{4d\\log d}$; (e) for separable quasiconvex functions, $\\zeta$ is\n${\\Theta}(\\sqrt{d})$. Thus, we advance current understanding of the properties\nof GD and GF curves beyond rates of convergence. We expect our techniques to\nfacilitate future studies for other algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 23:07:42 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 03:54:14 GMT"}, {"version": "v3", "created": "Thu, 1 Oct 2020 22:41:40 GMT"}, {"version": "v4", "created": "Fri, 19 Mar 2021 18:09:00 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gupta", "Chirag", ""], ["Balakrishnan", "Sivaraman", ""], ["Ramdas", "Aaditya", ""]]}, {"id": "1908.01091", "submitter": "Cuong Nguyen", "authors": "Cuong V. Nguyen, Alessandro Achille, Michael Lam, Tal Hassner, Vijay\n  Mahadevan, Stefano Soatto", "title": "Toward Understanding Catastrophic Forgetting in Continual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the relationship between catastrophic forgetting and properties of\ntask sequences. In particular, given a sequence of tasks, we would like to\nunderstand which properties of this sequence influence the error rates of\ncontinual learning algorithms trained on the sequence. To this end, we propose\na new procedure that makes use of recent developments in task space modeling as\nwell as correlation analysis to specify and analyze the properties we are\ninterested in. As an application, we apply our procedure to study two\nproperties of a task sequence: (1) total complexity and (2) sequential\nheterogeneity. We show that error rates are strongly and positively correlated\nto a task sequence's total complexity for some state-of-the-art algorithms. We\nalso show that, surprisingly, the error rates have no or even negative\ncorrelations in some cases to sequential heterogeneity. Our findings suggest\ndirections for improving continual learning benchmarks and methods.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 23:30:35 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Nguyen", "Cuong V.", ""], ["Achille", "Alessandro", ""], ["Lam", "Michael", ""], ["Hassner", "Tal", ""], ["Mahadevan", "Vijay", ""], ["Soatto", "Stefano", ""]]}, {"id": "1908.01109", "submitter": "Zhuodong Tang", "authors": "Ningyuan Chen, Guillermo Gallego, Zhuodong Tang", "title": "The Use of Binary Choice Forests to Model and Estimate Discrete Choices", "comments": "86 pages, 10 figures, 26 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show the equivalence of discrete choice models and a forest of binary\ndecision trees. This suggests that standard machine learning techniques based\non random forests can serve to estimate discrete choice models with an\ninterpretable output: the underlying trees can be viewed as the internal choice\nprocess of customers. Our data-driven theoretical results show that random\nforests can predict the choice probability of any discrete choice model\nconsistently. Moreover, our algorithm predicts unseen assortments with\nmechanisms and errors that can be theoretically analyzed. We also prove that\nthe splitting criterion in random forests, the Gini index, is capable of\nrecovering preference rankings of customers. The framework has unique practical\nadvantages: it can capture behavioral patterns such as irrationality or\nsequential searches; it handles nonstandard formats of training data that\nresult from aggregation; it can measure product importance based on how\nfrequently a random customer would make decisions depending on the presence of\nthe product; it can also incorporate price information and customer features.\nOur numerical results show that using random forests to estimate customer\nchoices can outperform the best parametric models in synthetic and real\ndatasets when presented with enough data or when the underlying discrete choice\nmodel cannot be correctly specified by existing parametric models.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 02:34:49 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 01:43:31 GMT"}, {"version": "v3", "created": "Thu, 14 Nov 2019 10:05:29 GMT"}, {"version": "v4", "created": "Sat, 3 Apr 2021 03:07:27 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Chen", "Ningyuan", ""], ["Gallego", "Guillermo", ""], ["Tang", "Zhuodong", ""]]}, {"id": "1908.01112", "submitter": "Yinchuan Li", "authors": "Xinyi Li, Yinchuan Li, Xiao-Yang Liu and Christina Dan Wang", "title": "Risk Management via Anomaly Circumvent: Mnemonic Deep Learning for\n  Midterm Stock Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Midterm stock price prediction is crucial for value investments in the stock\nmarket. However, most deep learning models are essentially short-term and\napplying them to midterm predictions encounters large cumulative errors because\nthey cannot avoid anomalies. In this paper, we propose a novel deep neural\nnetwork Mid-LSTM for midterm stock prediction, which incorporates the market\ntrend as hidden states. First, based on the autoregressive moving average model\n(ARMA), a midterm ARMA is formulated by taking into consideration both hidden\nstates and the capital asset pricing model. Then, a midterm LSTM-based deep\nneural network is designed, which consists of three components: LSTM, hidden\nMarkov model and linear regression networks. The proposed Mid-LSTM can avoid\nanomalies to reduce large prediction errors, and has good explanatory effects\non the factors affecting stock prices. Extensive experiments on S&P 500 stocks\nshow that (i) the proposed Mid-LSTM achieves 2-4% improvement in prediction\naccuracy, and (ii) in portfolio allocation investment, we achieve up to 120.16%\nannual return and 2.99 average Sharpe ratio.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 03:00:56 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Li", "Xinyi", ""], ["Li", "Yinchuan", ""], ["Liu", "Xiao-Yang", ""], ["Wang", "Christina Dan", ""]]}, {"id": "1908.01113", "submitter": "Yuntian Chen", "authors": "Yuntian Chen, Haibin Chang, Meng Jin, Dongxiao Zhang", "title": "Ensemble Neural Networks (ENN): A gradient-free stochastic method", "comments": null, "journal-ref": "Neural Networks, 110, 170-185 (2019)", "doi": "10.1016/j.neunet.2018.11.009", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this study, an efficient stochastic gradient-free method, the ensemble\nneural networks (ENN), is developed. In the ENN, the optimization process\nrelies on covariance matrices rather than derivatives. The covariance matrices\nare calculated by the ensemble randomized maximum likelihood algorithm (EnRML),\nwhich is an inverse modeling method. The ENN is able to simultaneously provide\nestimations and perform uncertainty quantification since it is built under the\nBayesian framework. The ENN is also robust to small training data size because\nthe ensemble of stochastic realizations essentially enlarges the training\ndataset. This constitutes a desirable characteristic, especially for real-world\nengineering applications. In addition, the ENN does not require the calculation\nof gradients, which enables the use of complicated neuron models and loss\nfunctions in neural networks. We experimentally demonstrate benefits of the\nproposed model, in particular showing that the ENN performs much better than\nthe traditional Bayesian neural networks (BNN). The EnRML in ENN is a\nsubstitution of gradient-based optimization algorithms, which means that it can\nbe directly combined with the feed-forward process in other existing (deep)\nneural networks, such as convolutional neural networks (CNN) and recurrent\nneural networks (RNN), broadening future applications of the ENN.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 03:11:32 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Chen", "Yuntian", ""], ["Chang", "Haibin", ""], ["Jin", "Meng", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "1908.01146", "submitter": "Wentai Wu", "authors": "Wentai Wu, Ligang He, Weiwei Lin, Yi Su, Yuhua Cui, Carsten Maple and\n  Stephen Jarvis", "title": "Developing an Unsupervised Real-time Anomaly Detection Scheme for Time\n  Series with Multi-seasonality", "comments": "14 pages, 11 figures. IEEE Transactions on Knowledge and Data\n  Engineering (2020)", "journal-ref": null, "doi": "10.1109/TKDE.2020.3035685", "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  On-line detection of anomalies in time series is a key technique used in\nvarious event-sensitive scenarios such as robotic system monitoring, smart\nsensor networks and data center security. However, the increasing diversity of\ndata sources and the variety of demands make this task more challenging than\never. Firstly, the rapid increase in unlabeled data means supervised learning\nis becoming less suitable in many cases. Secondly, a large portion of time\nseries data have complex seasonality features. Thirdly, on-line anomaly\ndetection needs to be fast and reliable. In light of this, we have developed a\nprediction-driven, unsupervised anomaly detection scheme, which adopts a\nbackbone model combining the decomposition and the inference of time series\ndata. Further, we propose a novel metric, Local Trend Inconsistency (LTI), and\nan efficient detection algorithm that computes LTI in a real-time manner and\nscores each data point robustly in terms of its probability of being anomalous.\nWe have conducted extensive experimentation to evaluate our algorithm with\nseveral datasets from both public repositories and production environments. The\nexperimental results show that our scheme outperforms existing representative\nanomaly detection algorithms in terms of the commonly used metric, Area Under\nCurve (AUC), while achieving the desired efficiency.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 10:38:22 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 16:38:35 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 10:33:06 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Wu", "Wentai", ""], ["He", "Ligang", ""], ["Lin", "Weiwei", ""], ["Su", "Yi", ""], ["Cui", "Yuhua", ""], ["Maple", "Carsten", ""], ["Jarvis", "Stephen", ""]]}, {"id": "1908.01165", "submitter": "Utpal Garain", "authors": "Akshay Chaturvedi, Abijith KP, and Utpal Garain", "title": "Exploring the Robustness of NMT Systems to Nonsensical Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural machine translation (NMT) systems have been shown to give undesirable\ntranslation when a small change is made in the source sentence. In this paper,\nwe study the behaviour of NMT systems when multiple changes are made to the\nsource sentence. In particular, we ask the following question \"Is it possible\nfor an NMT system to predict same translation even when multiple words in the\nsource sentence have been replaced?\". To this end, we propose a soft-attention\nbased technique to make the aforementioned word replacements. The experiments\nare conducted on two language pairs: English-German (en-de) and English-French\n(en-fr) and two state-of-the-art NMT systems: BLSTM-based encoder-decoder with\nattention and Transformer. The proposed soft-attention based technique achieves\nhigh success rate and outperforms existing methods like HotFlip by a\nsignificant margin for all the conducted experiments. The results demonstrate\nthat state-of-the-art NMT systems are unable to capture the semantics of the\nsource language. The proposed soft-attention based technique is an\ninvariance-based adversarial attack on NMT systems. To better evaluate such\nattacks, we propose an alternate metric and argue its benefits in comparison\nwith success rate.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 12:59:40 GMT"}, {"version": "v2", "created": "Tue, 29 Oct 2019 13:05:38 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 14:23:26 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Chaturvedi", "Akshay", ""], ["KP", "Abijith", ""], ["Garain", "Utpal", ""]]}, {"id": "1908.01176", "submitter": "Rachana Sathish", "authors": "Rachana Sathish, Ronnie Rajan, Anusha Vupputuri, Nirmalya Ghosh and\n  Debdoot Sheet", "title": "Adversarially Trained Convolutional Neural Networks for Semantic\n  Segmentation of Ischaemic Stroke Lesion using Multisequence Magnetic\n  Resonance Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Ischaemic stroke is a medical condition caused by occlusion of blood supply\nto the brain tissue thus forming a lesion. A lesion is zoned into a core\nassociated with irreversible necrosis typically located at the center of the\nlesion, while reversible hypoxic changes in the outer regions of the lesion are\ntermed as the penumbra. Early estimation of core and penumbra in ischaemic\nstroke is crucial for timely intervention with thrombolytic therapy to reverse\nthe damage and restore normalcy. Multisequence magnetic resonance imaging (MRI)\nis commonly employed for clinical diagnosis. However, a sequence singly has not\nbeen found to be sufficiently able to differentiate between core and penumbra,\nwhile a combination of sequences is required to determine the extent of the\ndamage. The challenge, however, is that with an increase in the number of\nsequences, it cognitively taxes the clinician to discover symptomatic\nbiomarkers in these images. In this paper, we present a data-driven fully\nautomated method for estimation of core and penumbra in ischaemic lesions using\ndiffusion-weighted imaging (DWI) and perfusion-weighted imaging (PWI) sequence\nmaps of MRI. The method employs recent developments in convolutional neural\nnetworks (CNN) for semantic segmentation in medical images. In the absence of\navailability of a large amount of labeled data, the CNN is trained using an\nadversarial approach employing cross-entropy as a segmentation loss along with\nlosses aggregated from three discriminators of which two employ relativistic\nvisual Turing test. This method is experimentally validated on the ISLES-2015\ndataset through three-fold cross-validation to obtain with an average Dice\nscore of 0.82 and 0.73 for segmentation of penumbra and core respectively.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 13:48:27 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Sathish", "Rachana", ""], ["Rajan", "Ronnie", ""], ["Vupputuri", "Anusha", ""], ["Ghosh", "Nirmalya", ""], ["Sheet", "Debdoot", ""]]}, {"id": "1908.01219", "submitter": "Christopher Sweet", "authors": "Christopher Sweet, Stephen Moskal, Shanchieh Jay Yang", "title": "On the Veracity of Cyber Intrusion Alerts Synthesized by Generative\n  Adversarial Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recreating cyber-attack alert data with a high level of fidelity is\nchallenging due to the intricate interaction between features, non-homogeneity\nof alerts, and potential for rare yet critical samples. Generative Adversarial\nNetworks (GANs) have been shown to effectively learn complex data distributions\nwith the intent of creating increasingly realistic data. This paper presents\nthe application of GANs to cyber-attack alert data and shows that GANs not only\nsuccessfully learn to generate realistic alerts, but also reveal feature\ndependencies within alerts. This is accomplished by reviewing the intersection\nof histograms for varying alert-feature combinations between the ground truth\nand generated datsets. Traditional statistical metrics, such as conditional and\njoint entropy, are also employed to verify the accuracy of these dependencies.\nFinally, it is shown that a Mutual Information constraint on the network can be\nused to increase the generation of low probability, critical, alert values. By\nmapping alerts to a set of attack stages it is shown that the output of these\nlow probability alerts has a direct contextual meaning for Cyber Security\nanalysts. Overall, this work provides the basis for generating new cyber\nintrusion alerts and provides evidence that synthesized alerts emulate critical\ndependencies from the source dataset.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 18:56:43 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Sweet", "Christopher", ""], ["Moskal", "Stephen", ""], ["Yang", "Shanchieh Jay", ""]]}, {"id": "1908.01228", "submitter": "Christina Lee Yu", "authors": "Nirandika Wanigasekara, Christina Lee Yu", "title": "Nonparametric Contextual Bandits in an Unknown Metric Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a nonparametric contextual multi-arm bandit problem where each arm\n$a \\in [K]$ is associated to a nonparametric reward function $f_a: [0,1] \\to\n\\mathbb{R}$ mapping from contexts to the expected reward. Suppose that there is\na large set of arms, yet there is a simple but unknown structure amongst the\narm reward functions, e.g. finite types or smooth with respect to an unknown\nmetric space. We present a novel algorithm which learns data-driven\nsimilarities amongst the arms, in order to implement adaptive partitioning of\nthe context-arm space for more efficient learning. We provide regret bounds\nalong with simulations that highlight the algorithm's dependence on the local\ngeometry of the reward functions.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 20:24:27 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Wanigasekara", "Nirandika", ""], ["Yu", "Christina Lee", ""]]}, {"id": "1908.01241", "submitter": "Christina Lee Yu", "authors": "Devavrat Shah, Christina Lee Yu", "title": "Iterative Collaborative Filtering for Sparse Noisy Tensor Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the task of tensor estimation, i.e. estimating a low-rank 3-order $n\n\\times n \\times n$ tensor from noisy observations of randomly chosen entries in\nthe sparse regime. We introduce a generalization of the collaborative filtering\nalgorithm for sparse tensor estimation and argue that it achieves sample\ncomplexity that nearly matches the conjectured computationally efficient lower\nbound on the sample complexity. Our algorithm uses the matrix obtained from the\nflattened tensor to compute similarity, and estimates the tensor entries using\na nearest neighbor estimator. We prove that the algorithm recovers the tensor\nwith maximum entry-wise error and mean-squared-error (MSE) decaying to $0$ as\nlong as each entry is observed independently with probability $p =\n\\Omega(n^{-3/2 + \\kappa})$ for any arbitrarily small $\\kappa> 0$. Our analysis\nsheds insight into the conjectured sample complexity lower bound, showing that\nit matches the connectivity threshold of the graph used by our algorithm for\nestimating similarity between coordinates.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 22:27:26 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 04:28:39 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Shah", "Devavrat", ""], ["Yu", "Christina Lee", ""]]}, {"id": "1908.01242", "submitter": "Vinay Prabhu", "authors": "Vinay Uday Prabhu", "title": "Kannada-MNIST: A new handwritten digits dataset for the Kannada language", "comments": "The companion github repository for this paper is :\n  https://github.com/vinayprabhu/Kannada_MNIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we disseminate a new handwritten digits-dataset, termed\nKannada-MNIST, for the Kannada script, that can potentially serve as a direct\ndrop-in replacement for the original MNIST dataset. In addition to this\ndataset, we disseminate an additional real world handwritten dataset (with\n$10k$ images), which we term as the Dig-MNIST dataset that can serve as an\nout-of-domain test dataset. We also duly open source all the code as well as\nthe raw scanned images along with the scanner settings so that researchers who\nwant to try out different signal processing pipelines can perform end-to-end\ncomparisons. We provide high level morphological comparisons with the MNIST\ndataset and provide baselines accuracies for the dataset disseminated. The\ninitial baselines obtained using an oft-used CNN architecture ($96.8\\%$ for the\nmain test-set and $76.1\\%$ for the Dig-MNIST test-set) indicate that these\ndatasets do provide a sterner challenge with regards to generalizability than\nMNIST or the KMNIST datasets. We also hope this dissemination will spur the\ncreation of similar datasets for all the languages that use different symbols\nfor the numeral digits.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2019 22:33:52 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Prabhu", "Vinay Uday", ""]]}, {"id": "1908.01251", "submitter": "Miles Lopes", "authors": "Miles E. Lopes, Suofei Wu, Thomas C. M. Lee", "title": "Measuring the Algorithmic Convergence of Randomized Ensembles: The\n  Regression Setting", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When randomized ensemble methods such as bagging and random forests are\nimplemented, a basic question arises: Is the ensemble large enough? In\nparticular, the practitioner desires a rigorous guarantee that a given ensemble\nwill perform nearly as well as an ideal infinite ensemble (trained on the same\ndata). The purpose of the current paper is to develop a bootstrap method for\nsolving this problem in the context of regression --- which complements our\ncompanion paper in the context of classification (Lopes 2019). In contrast to\nthe classification setting, the current paper shows that theoretical guarantees\nfor the proposed bootstrap can be established under much weaker assumptions. In\naddition, we illustrate the flexibility of the method by showing how it can be\nadapted to measure algorithmic convergence for variable selection. Lastly, we\nprovide numerical results demonstrating that the method works well in a range\nof situations.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 00:45:59 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Lopes", "Miles E.", ""], ["Wu", "Suofei", ""], ["Lee", "Thomas C. M.", ""]]}, {"id": "1908.01253", "submitter": "Fei Wang", "authors": "Fei Wang, Ling Zhou, Lu Tang, and Peter X.-K. Song", "title": "Method of Contraction-Expansion (MOCE) for Simultaneous Inference in\n  Linear Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous inference after model selection is of critical importance to\naddress scientific hypotheses involving a set of parameters. In this paper, we\nconsider high-dimensional linear regression model in which a regularization\nprocedure such as LASSO is applied to yield a sparse model. To establish a\nsimultaneous post-model selection inference, we propose a method of contraction\nand expansion (MOCE) along the line of debiasing estimation that enables us to\nbalance the bias-and-variance trade-off so that the super-sparsity assumption\nmay be relaxed. We establish key theoretical results for the proposed MOCE\nprocedure from which the expanded model can be selected with theoretical\nguarantees and simultaneous confidence regions can be constructed by the joint\nasymptotic normal distribution. In comparison with existing methods, our\nproposed method exhibits stable and reliable coverage at a nominal significance\nlevel with substantially less computational burden, and thus it is trustworthy\nfor its application in solving real-world problems.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 01:35:41 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Wang", "Fei", ""], ["Zhou", "Ling", ""], ["Tang", "Lu", ""], ["Song", "Peter X. -K.", ""]]}, {"id": "1908.01287", "submitter": "Xuehang Zheng", "authors": "Il Yong Chun, Xuehang Zheng, Yong Long, Jeffrey A. Fessler", "title": "BCD-Net for Low-dose CT Reconstruction: Acceleration, Convergence, and\n  Generalization", "comments": "Accepted to MICCAI 2019, and the authors indicated by asterisks (*)\n  equally contributed to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining accurate and reliable images from low-dose computed tomography (CT)\nis challenging. Regression convolutional neural network (CNN) models that are\nlearned from training data are increasingly gaining attention in low-dose CT\nreconstruction. This paper modifies the architecture of an iterative regression\nCNN, BCD-Net, for fast, stable, and accurate low-dose CT reconstruction, and\npresents the convergence property of the modified BCD-Net. Numerical results\nwith phantom data show that applying faster numerical solvers to model-based\nimage reconstruction (MBIR) modules of BCD-Net leads to faster and more\naccurate BCD-Net; BCD-Net significantly improves the reconstruction accuracy,\ncompared to the state-of-the-art MBIR method using learned transforms; BCD-Net\nachieves better image quality, compared to a state-of-the-art iterative NN\narchitecture, ADMM-Net. Numerical results with clinical data show that BCD-Net\ngeneralizes significantly better than a state-of-the-art deep (non-iterative)\nregression NN, FBPConvNet, that lacks MBIR modules.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 07:10:24 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Chun", "Il Yong", ""], ["Zheng", "Xuehang", ""], ["Long", "Yong", ""], ["Fessler", "Jeffrey A.", ""]]}, {"id": "1908.01289", "submitter": "Ellen Novoseller", "authors": "Ellen R. Novoseller, Yibing Wei, Yanan Sui, Yisong Yue, and Joel W.\n  Burdick", "title": "Dueling Posterior Sampling for Preference-Based Reinforcement Learning", "comments": "To appear in Conference on Uncertainty in Artificial Intelligence\n  (UAI), 2020. 9 pages before references and appendix; 51 pages total; 7\n  figures; 4 tables. This replacement incorporates reviewer comments, and in\n  comparison to version 1, extends the theoretical and empirical analyses and\n  adds mathematical detail. Code:\n  https://github.com/ernovoseller/DuelingPosteriorSampling", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In preference-based reinforcement learning (RL), an agent interacts with the\nenvironment while receiving preferences instead of absolute feedback. While\nthere is increasing research activity in preference-based RL, the design of\nformal frameworks that admit tractable theoretical analysis remains an open\nchallenge. Building upon ideas from preference-based bandit learning and\nposterior sampling in RL, we present DUELING POSTERIOR SAMPLING (DPS), which\nemploys preference-based posterior sampling to learn both the system dynamics\nand the underlying utility function that governs the preference feedback. As\npreference feedback is provided on trajectories rather than individual\nstate-action pairs, we develop a Bayesian approach for the credit assignment\nproblem, translating preferences to a posterior distribution over state-action\nreward models. We prove an asymptotic Bayesian no-regret rate for DPS with a\nBayesian linear regression credit assignment model. This is the first regret\nguarantee for preference-based RL to our knowledge. We also discuss possible\navenues for extending the proof methodology to other credit assignment models.\nFinally, we evaluate the approach empirically, showing competitive performance\nagainst existing baselines.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 07:51:36 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 05:27:33 GMT"}, {"version": "v3", "created": "Sat, 30 May 2020 05:26:41 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 16:09:49 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Novoseller", "Ellen R.", ""], ["Wei", "Yibing", ""], ["Sui", "Yanan", ""], ["Yue", "Yisong", ""], ["Burdick", "Joel W.", ""]]}, {"id": "1908.01297", "submitter": "Heng Chang", "authors": "Heng Chang, Yu Rong, Tingyang Xu, Wenbing Huang, Honglei Zhang, Peng\n  Cui, Wenwu Zhu, Junzhou Huang", "title": "A Restricted Black-box Adversarial Framework Towards Attacking Graph\n  Embedding Models", "comments": "Accepted by the AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the great success of graph embedding model on both academic and industry\narea, the robustness of graph embedding against adversarial attack inevitably\nbecomes a central problem in graph learning domain. Regardless of the fruitful\nprogress, most of the current works perform the attack in a white-box fashion:\nthey need to access the model predictions and labels to construct their\nadversarial loss. However, the inaccessibility of model predictions in real\nsystems makes the white-box attack impractical to real graph learning system.\nThis paper promotes current frameworks in a more general and flexible sense --\nwe demand to attack various kinds of graph embedding model with black-box\ndriven. To this end, we begin by investigating the theoretical connections\nbetween graph signal processing and graph embedding models in a principled way\nand formulate the graph embedding model as a general graph signal process with\ncorresponding graph filter. As such, a generalized adversarial attacker:\nGF-Attack is constructed by the graph filter and feature matrix. Instead of\naccessing any knowledge of the target classifiers used in graph embedding,\nGF-Attack performs the attack only on the graph filter in a black-box attack\nfashion. To validate the generalization of GF-Attack, we construct the attacker\non four popular graph embedding models. Extensive experimental results validate\nthe effectiveness of our attacker on several benchmark datasets. Particularly\nby using our attack, even small graph perturbations like one-edge flip is able\nto consistently make a strong attack in performance to different graph\nembedding models.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 09:03:20 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 01:48:02 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 20:27:20 GMT"}, {"version": "v4", "created": "Tue, 3 Dec 2019 00:13:29 GMT"}, {"version": "v5", "created": "Tue, 17 Dec 2019 20:48:26 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Chang", "Heng", ""], ["Rong", "Yu", ""], ["Xu", "Tingyang", ""], ["Huang", "Wenbing", ""], ["Zhang", "Honglei", ""], ["Cui", "Peng", ""], ["Zhu", "Wenwu", ""], ["Huang", "Junzhou", ""]]}, {"id": "1908.01300", "submitter": "Sai Raam Venkatraman", "authors": "Sairaam Venkatraman, S. Balasubramanian, R. Raghunatha Sarma", "title": "Building Deep, Equivariant Capsule Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capsule networks are constrained by the parameter-expensive nature of their\nlayers, and the general lack of provable equivariance guarantees. We present a\nvariation of capsule networks that aims to remedy this. We identify that\nlearning all pair-wise part-whole relationships between capsules of successive\nlayers is inefficient. Further, we also realise that the choice of prediction\nnetworks and the routing mechanism are both key to equivariance. Based on\nthese, we propose an alternative framework for capsule networks that learns to\nprojectively encode the manifold of pose-variations, termed the\nspace-of-variation (SOV), for every capsule-type of each layer. This is done\nusing a trainable, equivariant function defined over a grid of\ngroup-transformations. Thus, the prediction-phase of routing involves\nprojection into the SOV of a deeper capsule using the corresponding function.\nAs a specific instantiation of this idea, and also in order to reap the\nbenefits of increased parameter-sharing, we use type-homogeneous\ngroup-equivariant convolutions of shallower capsules in this phase. We also\nintroduce an equivariant routing mechanism based on degree-centrality. We show\nthat this particular instance of our general model is equivariant, and hence\npreserves the compositional representation of an input under transformations.\nWe conduct several experiments on standard object-classification datasets that\nshowcase the increased transformation-robustness, as well as general\nperformance, of our model to several capsule baselines.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 09:14:29 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 15:14:40 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 04:26:10 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Venkatraman", "Sairaam", ""], ["Balasubramanian", "S.", ""], ["Sarma", "R. Raghunatha", ""]]}, {"id": "1908.01314", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu, Bo Zhang, Ruijun Xu", "title": "MoGA: Searching Beyond MobileNetV3", "comments": "Accepted by ICASSP2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of MobileNets has laid a solid foundation for neural network\napplications on mobile end. With the latest MobileNetV3, neural architecture\nsearch again claimed its supremacy in network design. Unfortunately, till today\nall mobile methods mainly focus on CPU latencies instead of GPU, the latter,\nhowever, is much preferred in practice for it has faster speed, lower overhead\nand less interference. Bearing the target hardware in mind, we propose the\nfirst Mobile GPU-Aware (MoGA) neural architecture search in order to be\nprecisely tailored for real-world applications. Further, the ultimate objective\nto devise a mobile network lies in achieving better performance by maximizing\nthe utilization of bounded resources. Urging higher capability while\nrestraining time consumption is not reconcilable. We alleviate the tension by\nweighted evolution techniques. Moreover, we encourage increasing the number of\nparameters for higher representational power. With 200x fewer GPU days than\nMnasNet, we obtain a series of models that outperform MobileNetV3 under the\nsimilar latency constraints, i.e., MoGA-A achieves 75.9% top-1 accuracy on\nImageNet, MoGA-B meets 75.5% which costs only 0.5 ms more on mobile GPU. MoGA-C\nbest attests GPU-awareness by reaching 75.3% and being slower on CPU but faster\non GPU.The models and test code is made available here\nhttps://github.com/xiaomi-automl/MoGA.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 10:40:04 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 15:22:20 GMT"}, {"version": "v3", "created": "Mon, 14 Oct 2019 07:24:44 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 04:11:41 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Xu", "Ruijun", ""]]}, {"id": "1908.01321", "submitter": "Shujaat Khan Engr", "authors": "Shujaat Khan, Jawwad Ahmad, Alishba Sadiq, Imran Naseem, Muhammad\n  Moinuddin", "title": "Spatio-Temporal RBF Neural Networks", "comments": "Published in 2018 3rd International Conference on Emerging Trends in\n  Engineering, Sciences and Technology (ICEEST)", "journal-ref": "2018 3rd International Conference on Emerging Trends in\n  Engineering, Sciences and Technology (ICEEST)", "doi": "10.1109/ICEEST.2018.8643322", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein, we propose a spatio-temporal extension of RBFNN for nonlinear system\nidentification problem. The proposed algorithm employs the concept of\ntime-space orthogonality and separately models the dynamics and nonlinear\ncomplexities of the system. The proposed RBF architecture is explored for the\nestimation of a highly nonlinear system and results are compared with the\nstandard architecture for both the conventional and fractional gradient\ndecent-based learning rules. The spatio-temporal RBF is shown to perform better\nthan the standard and fractional RBFNNs by achieving fast convergence and\nsignificantly reduced estimation error.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 11:47:31 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Khan", "Shujaat", ""], ["Ahmad", "Jawwad", ""], ["Sadiq", "Alishba", ""], ["Naseem", "Imran", ""], ["Moinuddin", "Muhammad", ""]]}, {"id": "1908.01342", "submitter": "Shuai Yang", "authors": "Shuai Yang, Hao Wang, Yuhong Zhang, Pei-Pei Li, Yi Zhu and Xuegang Hu", "title": "Semi-supervised representation learning via dual autoencoders for domain\n  adaptation", "comments": "This paper has been accepted by the journal of KNOWLEDGE-BASED\n  SYSTEMS (KBS) 2019", "journal-ref": "Knowledge-Based Systems(2019)", "doi": "10.1016/j.knosys.2019.105161", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation aims to exploit the knowledge in source domain to promote\nthe learning tasks in target domain, which plays a critical role in real-world\napplications. Recently, lots of deep learning approaches based on autoencoders\nhave achieved a significance performance in domain adaptation. However, most\nexisting methods focus on minimizing the distribution divergence by putting the\nsource and target data together to learn global feature representations, while\nthey do not consider the local relationship between instances in the same\ncategory from different domains. To address this problem, we propose a novel\nSemi-Supervised Representation Learning framework via Dual Autoencoders for\ndomain adaptation, named SSRLDA. More specifically, we extract richer feature\nrepresentations by learning the global and local feature representations\nsimultaneously using two novel autoencoders, which are referred to as\nmarginalized denoising autoencoder with adaptation distribution (MDAad) and\nmulti-class marginalized denoising autoencoder (MMDA) respectively. Meanwhile,\nwe make full use of label information to optimize feature representations.\nExperimental results show that our proposed approach outperforms several\nstate-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 13:49:34 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 02:56:43 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 02:49:04 GMT"}, {"version": "v4", "created": "Fri, 25 Oct 2019 08:13:48 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Yang", "Shuai", ""], ["Wang", "Hao", ""], ["Zhang", "Yuhong", ""], ["Li", "Pei-Pei", ""], ["Zhu", "Yi", ""], ["Hu", "Xuegang", ""]]}, {"id": "1908.01384", "submitter": "Yawei Zhao", "authors": "Yawei Zhao, En Zhu, Xinwang Liu, Chang Tang, Deke Guo, Jianping Yin", "title": "Simultaneous Clustering and Optimization for Evolving Datasets", "comments": "Accepted by IEEE Transactions on Knowledge and Data Engineering\n  (TKDE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous clustering and optimization (SCO) has recently drawn much\nattention due to its wide range of practical applications. Many methods have\nbeen previously proposed to solve this problem and obtain the optimal model.\nHowever, when a dataset evolves over time, those existing methods have to\nupdate the model frequently to guarantee accuracy; such updating is\ncomputationally infeasible. In this paper, we propose a new formulation of SCO\nto handle evolving datasets. Specifically, we propose a new variant of the\nalternating direction method of multipliers (ADMM) to solve this problem\nefficiently. The guarantee of model accuracy is analyzed theoretically for two\nspecific tasks: ridge regression and convex clustering. Extensive empirical\nstudies confirm the effectiveness of our method.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 18:45:42 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zhao", "Yawei", ""], ["Zhu", "En", ""], ["Liu", "Xinwang", ""], ["Tang", "Chang", ""], ["Guo", "Deke", ""], ["Yin", "Jianping", ""]]}, {"id": "1908.01394", "submitter": "Andrea Schioppa", "authors": "Andrea Schioppa", "title": "Learning to Transport with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare several approaches to learn an Optimal Map, represented as a\nneural network, between probability distributions. The approaches fall into two\ncategories: ``Heuristics'' and approaches with a more sound mathematical\njustification, motivated by the dual of the Kantorovitch problem. Among the\nalgorithms we consider a novel approach involving dynamic flows and reductions\nof Optimal Transport to supervised learning.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 20:29:28 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Schioppa", "Andrea", ""]]}, {"id": "1908.01425", "submitter": "Ksenia Korovina", "authors": "Ksenia Korovina, Sailun Xu, Kirthevasan Kandasamy, Willie Neiswanger,\n  Barnabas Poczos, Jeff Schneider, Eric P. Xing", "title": "ChemBO: Bayesian Optimization of Small Organic Molecules with\n  Synthesizable Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.chem-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In applications such as molecule design or drug discovery, it is desirable to\nhave an algorithm which recommends new candidate molecules based on the results\nof past tests. These molecules first need to be synthesized and then tested for\nobjective properties. We describe ChemBO, a Bayesian optimization framework for\ngenerating and optimizing organic molecules for desired molecular properties.\nWhile most existing data-driven methods for this problem do not account for\nsample efficiency or fail to enforce realistic constraints on synthesizability,\nour approach explores the synthesis graph in a sample-efficient way and\nproduces synthesizable candidates. We implement ChemBO as a Gaussian process\nmodel and explore existing molecular kernels for it. Moreover, we propose a\nnovel optimal-transport based distance and kernel that accounts for graphical\ninformation explicitly. In our experiments, we demonstrate the efficacy of the\nproposed approach on several molecular optimization problems.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 00:12:54 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 00:36:27 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Korovina", "Ksenia", ""], ["Xu", "Sailun", ""], ["Kandasamy", "Kirthevasan", ""], ["Neiswanger", "Willie", ""], ["Poczos", "Barnabas", ""], ["Schneider", "Jeff", ""], ["Xing", "Eric P.", ""]]}, {"id": "1908.01456", "submitter": "Sanjay Madria", "authors": "Md. Yasin Kabir and Sanjay Madria", "title": "A Deep Learning Approach for Tweet Classification and Rescue Scheduling\n  for Effective Disaster Management", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a challenging and complex task to acquire information from different\nregions of a disaster-affected area in a timely fashion. The extensive spread\nand reach of social media and networks allow people to share information in\nreal-time. However, the processing of social media data and gathering of\nvaluable information require a series of operations such as (1) processing each\nspecific tweet for a text classification, (2) possible location determination\nof people needing help based on tweets, and (3) priority calculations of rescue\ntasks based on the classification of tweets. These are three primary challenges\nin developing an effective rescue scheduling operation using social media data.\nIn this paper, first, we propose a deep learning model combining attention\nbased Bi-directional Long Short-Term Memory (BLSTM) and Convolutional Neural\nNetwork (CNN) to classify the tweets under different categories. We use\npre-trained crisis word vectors and global vectors for word representation\n(GLoVe) for capturing semantic meaning from tweets. Next, we perform feature\nengineering to create an auxiliary feature map which dramatically increases the\nmodel accuracy. In our experiments using real data sets from Hurricanes Harvey\nand Irma, it is observed that our proposed approach performs better compared to\nother classification methods based on Precision, Recall, F1-score, and\nAccuracy, and is highly effective to determine the correct priority of a tweet.\nFurthermore, to evaluate the effectiveness and robustness of the proposed\nclassification model a merged dataset comprises of 4 different datasets from\nCrisisNLP and another 15 different disasters data from CrisisLex are used.\nFinally, we develop an adaptive multitask hybrid scheduling algorithm\nconsidering resource constraints to perform an effective rescue scheduling\noperation considering different rescue priorities.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 03:45:17 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Kabir", "Md. Yasin", ""], ["Madria", "Sanjay", ""]]}, {"id": "1908.01457", "submitter": "Hayeon Lee", "authors": "Hayeon Lee, Donghyun Na, Hae Beom Lee, Sung Ju Hwang", "title": "Learning to Generalize to Unseen Tasks with Bilevel Optimization", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent metric-based meta-learning approaches, which learn a metric space that\ngeneralizes well over combinatorial number of different classification tasks\nsampled from a task distribution, have been shown to be effective for few-shot\nclassification tasks of unseen classes. They are often trained with episodic\ntraining where they iteratively train a common metric space that reduces\ndistance between the class representatives and instances belonging to each\nclass, over large number of episodes with random classes. However, this\ntraining is limited in that while the main target is the generalization to the\nclassification of unseen classes during training, there is no explicit\nconsideration of generalization during meta-training phase. To tackle this\nissue, we propose a simple yet effective meta-learning framework for\nmetricbased approaches, which we refer to as learning to generalize (L2G), that\nexplicitly constrains the learning on a sampled classification task to reduce\nthe classification error on a randomly sampled unseen classification task with\na bilevel optimization scheme. This explicit learning aimed toward\ngeneralization allows the model to obtain a metric that separates well between\nunseen classes. We validate our L2G framework on mini-ImageNet and\ntiered-ImageNet datasets with two base meta-learning few-shot classification\nmodels, Prototypical Networks and Relation Networks. The results show that L2G\nsignificantly improves the performance of the two methods over episodic\ntraining. Further visualization shows that L2G obtains a metric space that\nclusters and separates unseen classes well.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 04:04:09 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Lee", "Hayeon", ""], ["Na", "Donghyun", ""], ["Lee", "Hae Beom", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1908.01462", "submitter": "Jie Lin", "authors": "Jie Lin, Dan-Bo Zhang, Shuo Zhang, Xiang Wang, Tan Li, Wan-su Bao", "title": "Quantum-enhanced least-square support vector machine: simplified quantum\n  algorithm and sparse solutions", "comments": "9 pages and 0 figures", "journal-ref": null, "doi": "10.1016/j.physleta.2020.126590", "report-no": null, "categories": "quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum algorithms can enhance machine learning in different aspects. Here,\nwe study quantum-enhanced least-square support vector machine (LS-SVM).\nFirstly, a novel quantum algorithm that uses continuous variable to assist\nmatrix inversion is introduced to simplify the algorithm for quantum LS-SVM,\nwhile retaining exponential speed-up. Secondly, we propose a hybrid\nquantum-classical version for sparse solutions of LS-SVM. By encoding a large\ndataset into a quantum state, a much smaller transformed dataset can be\nextracted using quantum matrix toolbox, which is further processed in classical\nSVM. We also incorporate kernel methods into the above quantum algorithms,\nwhich uses both exponential growth Hilbert space of qubits and infinite\ndimensionality of continuous variable for quantum feature maps. The quantum\nLS-SVM exploits quantum properties to explore important themes for SVM such as\nsparsity and kernel methods, and stresses its quantum advantages ranging from\nspeed-up to the potential capacity to solve classically difficult machine\nlearning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 04:29:55 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Lin", "Jie", ""], ["Zhang", "Dan-Bo", ""], ["Zhang", "Shuo", ""], ["Wang", "Xiang", ""], ["Li", "Tan", ""], ["Bao", "Wan-su", ""]]}, {"id": "1908.01499", "submitter": "Natalia Soboleva", "authors": "Natalia Soboleva and Konstantin Yakovlev", "title": "GAN Path Finder: Preliminary results", "comments": "Camera-ready version of the paper as to appear in KI 2019 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  2D path planning in static environment is a well-known problem and one of the\ncommon ways to solve it is to 1) represent the environment as a grid and 2)\nperform a heuristic search for a path on it. At the same time 2D grid resembles\nmuch a digital image, thus an appealing idea comes to being -- to treat the\nproblem as an image generation task and to solve it utilizing the recent\nadvances in deep learning. In this work we make an attempt to apply a\ngenerative neural network as a path finder and report preliminary results,\nconvincing enough to claim that this direction of research is worth further\nexploration.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 07:41:41 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Soboleva", "Natalia", ""], ["Yakovlev", "Konstantin", ""]]}, {"id": "1908.01536", "submitter": "Liam Hiley BSc", "authors": "Liam Hiley and Alun Preece and Yulia Hicks and David Marshall and\n  Harrison Taylor", "title": "Discriminating Spatial and Temporal Relevance in Deep Taylor\n  Decompositions for Explainable Activity Recognition", "comments": "5 pages, 2 figures, published at IJCAI19 ExAI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current techniques for explainable AI have been applied with some success to\nimage processing. The recent rise of research in video processing has called\nfor similar work n deconstructing and explaining spatio-temporal models. While\nmany techniques are designed for 2D convolutional models, others are inherently\napplicable to any input domain. One such body of work, deep Taylor\ndecomposition, propagates relevance from the model output distributively onto\nits input and thus is not restricted to image processing models. However, by\nexploiting a simple technique that removes motion information, we show that it\nis not the case that this technique is effective as-is for representing\nrelevance in non-image tasks. We instead propose a discriminative method that\nproduces a na\\\"ive representation of both the spatial and temporal relevance of\na frame as two separate objects. This new discriminative relevance model\nexposes relevance in the frame attributed to motion, that was previously\nambiguous in the original explanation. We observe the effectiveness of this\ntechnique on a range of samples from the UCF-101 action recognition dataset,\ntwo of which are demonstrated in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 09:42:25 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 14:36:13 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Hiley", "Liam", ""], ["Preece", "Alun", ""], ["Hicks", "Yulia", ""], ["Marshall", "David", ""], ["Taylor", "Harrison", ""]]}, {"id": "1908.01580", "submitter": "Wan-Duo Ma", "authors": "Wan-Duo Kurt Ma, J.P. Lewis, and W. Bastiaan Kleijn", "title": "The HSIC Bottleneck: Deep Learning without Back-Propagation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the HSIC (Hilbert-Schmidt independence criterion) bottleneck for\ntraining deep neural networks. The HSIC bottleneck is an alternative to the\nconventional cross-entropy loss and backpropagation that has a number of\ndistinct advantages. It mitigates exploding and vanishing gradients, resulting\nin the ability to learn very deep networks without skip connections. There is\nno requirement for symmetric feedback or update locking. We find that the HSIC\nbottleneck provides performance on MNIST/FashionMNIST/CIFAR10 classification\ncomparable to backpropagation with a cross-entropy target, even when the system\nis not encouraged to make the output resemble the classification labels.\nAppending a single layer trained with SGD (without backpropagation) to reformat\nthe information further improves performance.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 12:23:24 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 10:38:45 GMT"}, {"version": "v3", "created": "Thu, 5 Dec 2019 09:24:24 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Ma", "Wan-Duo Kurt", ""], ["Lewis", "J. P.", ""], ["Kleijn", "W. Bastiaan", ""]]}, {"id": "1908.01581", "submitter": "Quanshi Zhang", "authors": "Ruofan Liang, Tianlin Li, Longfei Li, Jing Wang, Quanshi Zhang", "title": "Knowledge Consistency between Neural Networks and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to analyze knowledge consistency between pre-trained deep\nneural networks. We propose a generic definition for knowledge consistency\nbetween neural networks at different fuzziness levels. A task-agnostic method\nis designed to disentangle feature components, which represent the consistent\nknowledge, from raw intermediate-layer features of each neural network. As a\ngeneric tool, our method can be broadly used for different applications. In\npreliminary experiments, we have used knowledge consistency as a tool to\ndiagnose representations of neural networks. Knowledge consistency provides new\ninsights to explain the success of existing deep-learning techniques, such as\nknowledge distillation and network compression. More crucially, knowledge\nconsistency can also be used to refine pre-trained networks and boost\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 12:25:37 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 17:30:39 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Liang", "Ruofan", ""], ["Li", "Tianlin", ""], ["Li", "Longfei", ""], ["Wang", "Jing", ""], ["Zhang", "Quanshi", ""]]}, {"id": "1908.01642", "submitter": "Yoni Sher", "authors": "Yoni Sher", "title": "Review of Algorithms for Compressive Sensing of Images", "comments": "14 pages, 8 figures, all data available in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We provide a comprehensive review of classical algorithms for compressive\nsensing of images, focused on Total variation methods, with a view to\napplication in LiDAR systems. Our primary focus is providing a full review for\nbeginners in the field, as well as simulating the kind of noise found in real\nLiDAR systems. To this end, we provide an overview of the theoretical\nbackground, a brief discussion of various considerations that come in to play\nin compressive sensing, and a standardized comparison of off-the-shelf methods,\nintended as a quick-start guide to choosing algorithms for compressive sensing\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 14:24:57 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Sher", "Yoni", ""]]}, {"id": "1908.01656", "submitter": "Simone Disabato", "authors": "Simone Disabato, Manuel Roveri, Cesare Alippi", "title": "Distributed Deep Convolutional Neural Networks for the\n  Internet-of-Things", "comments": null, "journal-ref": "in IEEE Transactions on Computers, vol. 70, no. 8, pp. 1239-1252,\n  1 Aug. 2021", "doi": "10.1109/TC.2021.3062227", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Severe constraints on memory and computation characterizing the\nInternet-of-Things (IoT) units may prevent the execution of Deep Learning\n(DL)-based solutions, which typically demand large memory and high processing\nload. In order to support a real-time execution of the considered DL model at\nthe IoT unit level, DL solutions must be designed having in mind constraints on\nmemory and processing capability exposed by the chosen IoT technology. In this\npaper, we introduce a design methodology aiming at allocating the execution of\nConvolutional Neural Networks (CNNs) on a distributed IoT application. Such a\nmethodology is formalized as an optimization problem where the latency between\nthe data-gathering phase and the subsequent decision-making one is minimized,\nwithin the given constraints on memory and processing load at the units level.\nThe methodology supports multiple sources of data as well as multiple CNNs in\nexecution on the same IoT system allowing the design of CNN-based applications\ndemanding autonomy, low decision-latency, and high Quality-of-Service.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 12:19:52 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 18:41:23 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Disabato", "Simone", ""], ["Roveri", "Manuel", ""], ["Alippi", "Cesare", ""]]}, {"id": "1908.01667", "submitter": "Chris Finlay", "authors": "Aram-Alexandre Pooladian, Chris Finlay, Tim Hoheisel, Adam Oberman", "title": "A principled approach for generating adversarial images under non-smooth\n  dissimilarity metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks perform well on real world data but are prone to\nadversarial perturbations: small changes in the input easily lead to\nmisclassification. In this work, we propose an attack methodology not only for\ncases where the perturbations are measured by $\\ell_p$ norms, but in fact any\nadversarial dissimilarity metric with a closed proximal form. This includes,\nbut is not limited to, $\\ell_1, \\ell_2$, and $\\ell_\\infty$ perturbations; the\n$\\ell_0$ counting \"norm\" (i.e. true sparseness); and the total variation\nseminorm, which is a (non-$\\ell_p$) convolutional dissimilarity measuring local\npixel changes. Our approach is a natural extension of a recent adversarial\nattack method, and eliminates the differentiability requirement of the metric.\nWe demonstrate our algorithm, ProxLogBarrier, on the MNIST, CIFAR10, and\nImageNet-1k datasets. We consider undefended and defended models, and show that\nour algorithm easily transfers to various datasets. We observe that\nProxLogBarrier outperforms a host of modern adversarial attacks specialized for\nthe $\\ell_0$ case. Moreover, by altering images in the total variation\nseminorm, we shed light on a new class of perturbations that exploit\nneighboring pixel information.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 14:57:01 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 17:21:21 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Pooladian", "Aram-Alexandre", ""], ["Finlay", "Chris", ""], ["Hoheisel", "Tim", ""], ["Oberman", "Adam", ""]]}, {"id": "1908.01672", "submitter": "Chen Wang", "authors": "Chen Wang, Chengyuan Deng, Suzhen Wang", "title": "Imbalance-XGBoost: Leveraging Weighted and Focal Losses for Binary\n  Label-Imbalanced Classification with XGBoost", "comments": "11 pages, to be submitted to peer-reviewed journal/conference soon", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The paper presents Imbalance-XGBoost, a Python package that combines the\npowerful XGBoost software with weighted and focal losses to tackle binary\nlabel-imbalanced classification tasks. Though a small-scale program in terms of\nsize, the package is, to the best of the authors' knowledge, the first of its\nkind which provides an integrated implementation for the two losses on XGBoost\nand brings a general-purpose extension on XGBoost for label-imbalanced\nscenarios. In this paper, the design and usage of the package are described\nwith exemplar code listings, and its convenience to be integrated into\nPython-driven Machine Learning projects is illustrated. Furthermore, as the\nfirst- and second-order derivatives of the loss functions are essential for the\nimplementations, the algebraic derivation is discussed and it can be deemed as\na separate algorithmic contribution. The performances of the algorithms\nimplemented in the package are empirically evaluated on Parkinson's disease\nclassification data set, and multiple state-of-the-art performances have been\nobserved. Given the scalable nature of XGBoost, the package has great\npotentials to be applied to real-life binary classification tasks, which are\nusually of large-scale and label-imbalanced.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:01:28 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Wang", "Chen", ""], ["Deng", "Chengyuan", ""], ["Wang", "Suzhen", ""]]}, {"id": "1908.01675", "submitter": "Thomas McAndrew PhD", "authors": "Thomas McAndrew, Nicholas G. Reich", "title": "Adaptively stacking ensembles for influenza forecasting with incomplete\n  data", "comments": "V0.2 added small paragraph on BMA and acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seasonal influenza infects between 10 and 50 million people in the United\nStates every year, overburdening hospitals during weeks of peak incidence.\nNamed by the CDC as an important tool to fight the damaging effects of these\nepidemics, accurate forecasts of influenza and influenza-like illness (ILI)\nforewarn public health officials about when, and where, seasonal influenza\noutbreaks will hit hardest. Multi-model ensemble forecasts---weighted\ncombinations of component models---have shown positive results in forecasting.\nEnsemble forecasts of influenza outbreaks have been static, training on all\npast ILI data at the beginning of a season, generating a set of optimal weights\nfor each model in the ensemble, and keeping the weights constant. We propose an\nadaptive ensemble forecast that (i) changes model weights week-by-week\nthroughout the influenza season, (ii) only needs the current influenza season's\ndata to make predictions, and (iii) by introducing a prior distribution,\nshrinks weights toward the reference equal weighting approach and adjusts for\nobserved ILI percentages that are subject to future revisions. We investigate\nthe prior's ability to impact adaptive ensemble performance and, after finding\nan optimal prior via a cross-validation approach, compare our adaptive\nensemble's performance to equal-weighted and static ensembles. Applied to\nforecasts of short-term ILI incidence at the regional and national level in the\nUS, our adaptive model outperforms a naive equal-weighted ensemble, and has\nsimilar or better performance to the static ensemble, which requires multiple\nyears of training data. Adaptive ensembles are able to quickly train and\nforecast during epidemics, and provide a practical tool to public health\nofficials looking for forecasts that can conform to unique features of a\nspecific season.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 18:02:57 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 19:01:30 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["McAndrew", "Thomas", ""], ["Reich", "Nicholas G.", ""]]}, {"id": "1908.01678", "submitter": "Melih Yesilli", "authors": "Melih C. Yesilli, Firas A. Khasawneh, Andreas Otto", "title": "Chatter Detection in Turning Using Machine Learning and Similarity\n  Measures of Time Series via Dynamic Time Warping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chatter detection from sensor signals has been an active field of research.\nWhile some success has been reported using several featurization tools and\nmachine learning algorithms, existing methods have several drawbacks such as\nmanual preprocessing and requiring a large data set. In this paper, we present\nan alternative approach for chatter detection based on K-Nearest Neighbor (kNN)\nalgorithm for classification and the Dynamic Time Warping (DTW) as a time\nseries similarity measure. The used time series are the acceleration signals\nacquired from the tool holder in a series of turning experiments. Our results,\nshow that this approach achieves detection accuracies that in most cases\noutperform existing methods. We compare our results to the traditional methods\nbased on Wavelet Packet Transform (WPT) and the Ensemble Empirical Mode\nDecomposition (EEMD), as well as to the more recent Topological Data Analysis\n(TDA) based approach. We show that in three out of four cutting configurations\nour DTW-based approach attains the highest average classification rate reaching\nin one case as high as 99% accuracy. Our approach does not require feature\nextraction, is capable of reusing a classifier across different cutting\nconfigurations, and it uses reasonably sized training sets. Although the\nresulting high accuracy in our approach is associated with high computational\ncost, this is specific to the DTW implementation that we used. Specifically, we\nhighlight available, very fast DTW implementations that can even be implemented\non small consumer electronics. Therefore, further code optimization and the\nsignificantly reduced computational effort during the implementation phase make\nour approach a viable option for in-process chatter detection.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:09:49 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Yesilli", "Melih C.", ""], ["Khasawneh", "Firas A.", ""], ["Otto", "Andreas", ""]]}, {"id": "1908.01686", "submitter": "Hari Prasanna Das", "authors": "Hari Prasanna Das, Pieter Abbeel and Costas J. Spanos", "title": "Likelihood Contribution based Multi-scale Architecture for Generative\n  Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative modeling using flows has gained popularity owing to the\ntractable exact log-likelihood estimation with efficient training and synthesis\nprocess. However, flow models suffer from the challenge of having high\ndimensional latent space, same in dimension as the input space. An effective\nsolution to the above challenge as proposed by Dinh et al. (2016) is a\nmulti-scale architecture, which is based on iterative early factorization of a\npart of the total dimensions at regular intervals. Prior works on generative\nflows involving a multi-scale architecture perform the dimension factorization\nbased on a static masking. We propose a novel multi-scale architecture that\nperforms data dependent factorization to decide which dimensions should pass\nthrough more flow layers. To facilitate the same, we introduce a heuristic\nbased on the contribution of each dimension to the total log-likelihood which\nencodes the importance of the dimensions. Our proposed heuristic is readily\nobtained as part of the flow training process, enabling versatile\nimplementation of our likelihood contribution based multi-scale architecture\nfor generic flow models. We present such an implementation for the original\nflow introduced in Dinh et al. (2016), and demonstrate improvements in\nlog-likelihood score and sampling quality on standard image benchmarks. We also\nconduct ablation studies to compare proposed method with other options for\ndimension factorization.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 15:14:18 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 06:18:38 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Das", "Hari Prasanna", ""], ["Abbeel", "Pieter", ""], ["Spanos", "Costas J.", ""]]}, {"id": "1908.01718", "submitter": "Yifei Huang", "authors": "Yifei Huang, Matt Shum, Xi Wu, Jason Zezhong Xiao", "title": "Discovery of Bias and Strategic Behavior in Crowdsourced Performance\n  Assessment", "comments": "International Workshop of Talent and Management Computing, KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the industry trend of shifting from a traditional hierarchical approach\nto flatter management structure, crowdsourced performance assessment gained\nmainstream popularity. One fundamental challenge of crowdsourced performance\nassessment is the risks that personal interest can introduce distortions of\nfacts, especially when the system is used to determine merit pay or promotion.\nIn this paper, we developed a method to identify bias and strategic behavior in\ncrowdsourced performance assessment, using a rich dataset collected from a\nprofessional service firm in China. We find a pattern of \"discriminatory\ngenerosity\" on the part of peer evaluation, where raters downgrade their peer\ncoworkers who have passed objective promotion requirements while overrating\ntheir peer coworkers who have not yet passed. This introduces two types of\nbiases: the first aimed against more competent competitors, and the other\nfavoring less eligible peers which can serve as a mask of the first bias. This\npaper also aims to bring angles of fairness-aware data mining to talent and\nmanagement computing. Historical decision records, such as performance ratings,\noften contain subjective judgment which is prone to bias and strategic\nbehavior. For practitioners of predictive talent analytics, it is important to\ninvestigate potential bias and strategic behavior underlying historical\ndecision records.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 16:51:09 GMT"}, {"version": "v2", "created": "Sat, 12 Oct 2019 06:13:31 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Huang", "Yifei", ""], ["Shum", "Matt", ""], ["Wu", "Xi", ""], ["Xiao", "Jason Zezhong", ""]]}, {"id": "1908.01753", "submitter": "Hayden Schaeffer", "authors": "Hayden Schaeffer and Scott G. McCalla", "title": "Extending the step-size restriction for gradient descent to avoid strict\n  saddle points", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide larger step-size restrictions for which gradient descent based\nalgorithms (almost surely) avoid strict saddle points. In particular, consider\na twice differentiable (non-convex) objective function whose gradient has\nLipschitz constant L and whose Hessian is well-behaved. We prove that the\nprobability of initial conditions for gradient descent with step-size up to 2/L\nconverging to a strict saddle point, given one uniformly random initialization,\nis zero. This extends previous results up to the sharp limit imposed by the\nconvex case. In addition, the arguments hold in the case when a learning rate\nschedule is given, with either a continuous decaying rate or a piece-wise\nconstant schedule.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 17:50:55 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Schaeffer", "Hayden", ""], ["McCalla", "Scott G.", ""]]}, {"id": "1908.01755", "submitter": "Lesia Semenova", "authors": "Lesia Semenova, Cynthia Rudin, and Ronald Parr", "title": "A study in Rashomon curves and volumes: A new perspective on\n  generalization and model simplicity in machine learning", "comments": "Revisited sections 3, 4, 5, 6, 7, and 8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Rashomon effect occurs when many different explanations exist for the\nsame phenomenon. In machine learning, Leo Breiman used this term to\ncharacterize problems where many accurate-but-different models exist to\ndescribe the same data. In this work, we study how the Rashomon effect can be\nuseful for understanding the relationship between training and test\nperformance, and the possibility that simple-yet-accurate models exist for many\nproblems. We consider the Rashomon set - the set of almost-equally-accurate\nmodels for a given problem - and study its properties and the types of models\nit could contain. We present the Rashomon ratio as a new measure related to\nsimplicity of model classes, which is the ratio of the volume of the set of\naccurate models to the volume of the hypothesis space; the Rashomon ratio is\ndifferent from standard complexity measures from statistical learning theory.\nFor a hierarchy of hypothesis spaces, the Rashomon ratio can help modelers to\nnavigate the trade-off between simplicity and accuracy. In particular, we find\nempirically that a plot of empirical risk vs. Rashomon ratio forms a\ncharacteristic $\\Gamma$-shaped Rashomon curve, whose elbow seems to be a\nreliable model selection criterion. When the Rashomon set is large, models that\nare accurate - but that also have various other useful properties - can often\nbe obtained. These models might obey various constraints such as\ninterpretability, fairness, or monotonicity.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 17:52:53 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 03:34:43 GMT"}, {"version": "v3", "created": "Fri, 9 Apr 2021 23:32:21 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Semenova", "Lesia", ""], ["Rudin", "Cynthia", ""], ["Parr", "Ronald", ""]]}, {"id": "1908.01760", "submitter": "V\\'it R\\r{u}\\v{z}i\\v{c}ka", "authors": "V\\'it R\\r{u}\\v{z}i\\v{c}ka, Eunsu Kang, David Gordon, Ankita Patel,\n  Jacqui Fashimpaur, Manzil Zaheer", "title": "The Myths of Our Time: Fake News", "comments": "5 pages, 5 figures, in proceedings of International Symposium on\n  Electronic Art 2019 (ISEA)", "journal-ref": "Proceedings of International Symposium on Electronic Art 2019\n  (ISEA), pages 494-498", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the purpose of most fake news is misinformation and political\npropaganda, our team sees it as a new type of myth that is created by people in\nthe age of internet identities and artificial intelligence. Seeking insights on\nthe fear and desire hidden underneath these modified or generated stories, we\nuse machine learning methods to generate fake articles and present them in the\nform of an online news blog. This paper aims to share the details of our\npipeline and the techniques used for full generation of fake news, from dataset\ncollection to presentation as a media art project on the internet.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 17:59:44 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["R\u016f\u017ei\u010dka", "V\u00edt", ""], ["Kang", "Eunsu", ""], ["Gordon", "David", ""], ["Patel", "Ankita", ""], ["Fashimpaur", "Jacqui", ""], ["Zaheer", "Manzil", ""]]}, {"id": "1908.01768", "submitter": "Soheil Khorram", "authors": "Midia Yousefi, Soheil Khorram, John H.L. Hansen", "title": "Probabilistic Permutation Invariant Training for Speech Separation", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Single-microphone, speaker-independent speech separation is normally\nperformed through two steps: (i) separating the specific speech sources, and\n(ii) determining the best output-label assignment to find the separation error.\nThe second step is the main obstacle in training neural networks for speech\nseparation. Recently proposed Permutation Invariant Training (PIT) addresses\nthis problem by determining the output-label assignment which minimizes the\nseparation error. In this study, we show that a major drawback of this\ntechnique is the overconfident choice of the output-label assignment,\nespecially in the initial steps of training when the network generates\nunreliable outputs. To solve this problem, we propose Probabilistic PIT\n(Prob-PIT) which considers the output-label permutation as a discrete latent\nrandom variable with a uniform prior distribution. Prob-PIT defines a\nlog-likelihood function based on the prior distributions and the separation\nerrors of all permutations; it trains the speech separation networks by\nmaximizing the log-likelihood function. Prob-PIT can be easily implemented by\nreplacing the minimum function of PIT with a soft-minimum function. We evaluate\nour approach for speech separation on both TIMIT and CHiME datasets. The\nresults show that the proposed method significantly outperforms PIT in terms of\nSignal to Distortion Ratio and Signal to Interference Ratio.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 17:42:31 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Yousefi", "Midia", ""], ["Khorram", "Soheil", ""], ["Hansen", "John H. L.", ""]]}, {"id": "1908.01769", "submitter": "Abu Reyan Ahmed", "authors": "Sabin Devkota, Reyan Ahmed, Felice De Luca, Katherine E. Isaacs,\n  Stephen Kobourov", "title": "Stress-Plus-X (SPX) Graph Layout", "comments": "25 pages, 12 figures, accepted in the 27th International Symposium on\n  Graph Drawing and Network Visualization (GD 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stress, edge crossings, and crossing angles play an important role in the\nquality and readability of graph drawings. Most standard graph drawing\nalgorithms optimize one of these criteria which may lead to layouts that are\ndeficient in other criteria. We introduce an optimization framework,\nStress-Plus-X (SPX), that simultaneously optimizes stress together with several\nother criteria: edge crossings, minimum crossing angle, and upwardness (for\ndirected acyclic graphs). SPX achieves results that are close to the\nstate-of-the-art algorithms that optimize these metrics individually. SPX is\nflexible and extensible and can optimize a subset or all of these criteria\nsimultaneously. Our experimental analysis shows that our joint optimization\napproach is successful in drawing graphs with good performance across\nreadability criteria.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 22:31:02 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 03:32:21 GMT"}, {"version": "v3", "created": "Tue, 13 Aug 2019 22:39:49 GMT"}, {"version": "v4", "created": "Mon, 19 Aug 2019 22:31:37 GMT"}, {"version": "v5", "created": "Fri, 23 Aug 2019 17:13:17 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Devkota", "Sabin", ""], ["Ahmed", "Reyan", ""], ["De Luca", "Felice", ""], ["Isaacs", "Katherine E.", ""], ["Kobourov", "Stephen", ""]]}, {"id": "1908.01794", "submitter": "Ran Zhao", "authors": "Qidi Peng, Nan Rao, Ran Zhao", "title": "Some Developments in Clustering Analysis on Stochastic Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some developments on clustering stochastic processes and come with\nthe conclusion that asymptotically consistent clustering algorithms can be\nobtained when the processes are ergodic and the dissimilarity measure satisfies\nthe triangle inequality. Examples are provided when the processes are\ndistribution ergodic, covariance ergodic and locally asymptotically\nself-similar, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 18:16:36 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Peng", "Qidi", ""], ["Rao", "Nan", ""], ["Zhao", "Ran", ""]]}, {"id": "1908.01815", "submitter": "Taha Shangipour Ataei", "authors": "Taha Shangipour Ataei, Kamyar Darvishi, Soroush Javdan, Behrouz\n  Minaei-Bidgoli, Sauleh Eetemadi", "title": "Pars-ABSA: an Aspect-based Sentiment Analysis dataset for Persian", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increased availability of online reviews, sentiment analysis had\nbeen witnessed a booming interest from the researchers. Sentiment analysis is a\ncomputational treatment of sentiment used to extract and understand the\nopinions of authors. While many systems were built to predict the sentiment of\na document or a sentence, many others provide the necessary detail on various\naspects of the entity (i.e. aspect-based sentiment analysis). Most of the\navailable data resources were tailored to English and the other popular\nEuropean languages. Although Persian is a language with more than 110 million\nspeakers, to the best of our knowledge, there is a lack of public dataset on\naspect-based sentiment analysis for Persian. This paper provides a manually\nannotated Persian dataset, Pars-ABSA, which is verified by 3 native Persian\nspeakers. The dataset consists of 5,114 positive, 3,061 negative and 1,827\nneutral data samples from 5,602 unique reviews. Moreover, as a baseline, this\npaper reports the performance of some state-of-the-art aspect-based sentiment\nanalysis methods with a focus on deep learning, on Pars-ABSA. The obtained\nresults are impressive compared to similar English state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 16:19:07 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 08:09:31 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2019 14:35:42 GMT"}], "update_date": "2019-12-12", "authors_parsed": [["Ataei", "Taha Shangipour", ""], ["Darvishi", "Kamyar", ""], ["Javdan", "Soroush", ""], ["Minaei-Bidgoli", "Behrouz", ""], ["Eetemadi", "Sauleh", ""]]}, {"id": "1908.01817", "submitter": "Naomi Saphra", "authors": "Naomi Saphra, Adam Lopez", "title": "Sparsity Emerges Naturally in Neural Language Models", "comments": "Published in the ICML 2019 Workshop on Identifying and Understanding\n  Deep Learning Phenomena: https://openreview.net/forum?id=H1ets1h56E", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Concerns about interpretability, computational resources, and principled\ninductive priors have motivated efforts to engineer sparse neural models for\nNLP tasks. If sparsity is important for NLP, might well-trained neural models\nnaturally become roughly sparse? Using the Taxi-Euclidean norm to measure\nsparsity, we find that frequent input words are associated with concentrated or\nsparse activations, while frequent target words are associated with dispersed\nactivations but concentrated gradients. We find that gradients associated with\nfunction words are more concentrated than the gradients of content words, even\ncontrolling for word frequency.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:06:15 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Saphra", "Naomi", ""], ["Lopez", "Adam", ""]]}, {"id": "1908.01819", "submitter": "Andrea Zugarini", "authors": "Giuseppe Marra and Andrea Zugarini and Stefano Melacci and Marco\n  Maggini", "title": "An Unsupervised Character-Aware Neural Approach to Word and Context\n  Representation Learning", "comments": null, "journal-ref": "Lecture Notes in Computer Science, vol 11141. Springer, Cham 2018", "doi": "10.1007/978-3-030-01424-7_13", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last few years, neural networks have been intensively used to develop\nmeaningful distributed representations of words and contexts around them. When\nthese representations, also known as \"embeddings\", are learned from\nunsupervised large corpora, they can be transferred to different tasks with\npositive effects in terms of performances, especially when only a few\nsupervisions are available. In this work, we further extend this concept, and\nwe present an unsupervised neural architecture that jointly learns word and\ncontext embeddings, processing words as sequences of characters. This allows\nour model to spot the regularities that are due to the word morphology, and to\navoid the need of a fixed-sized input vocabulary of words. We show that we can\nlearn compact encoders that, despite the relatively small number of parameters,\nreach high-level performances in downstream tasks, comparing them with related\nstate-of-the-art approaches or with fully supervised methods.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 09:34:11 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Marra", "Giuseppe", ""], ["Zugarini", "Andrea", ""], ["Melacci", "Stefano", ""], ["Maggini", "Marco", ""]]}, {"id": "1908.01821", "submitter": "Ozan \\.Irsoy", "authors": "Ozan \\.Irsoy, Rakesh Gosangi, Haimin Zhang, Mu-Hsin Wei, Peter Lund,\n  Duccio Pappadopulo, Brendan Fahy, Neophytos Nephytou, Camilo Ortiz", "title": "Dialogue Act Classification in Group Chats with DAG-LSTMs", "comments": "Appeared in SIGIR 2019 Workshop on Conversational Interaction Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue act (DA) classification has been studied for the past two decades\nand has several key applications such as workflow automation and conversation\nanalytics. Researchers have used, to address this problem, various traditional\nmachine learning models, and more recently deep neural network models such as\nhierarchical convolutional neural networks (CNNs) and long short-term memory\n(LSTM) networks. In this paper, we introduce a new model architecture,\ndirected-acyclic-graph LSTM (DAG-LSTM) for DA classification. A DAG-LSTM\nexploits the turn-taking structure naturally present in a multi-party\nconversation, and encodes this relation in its model structure. Using the STAC\ncorpus, we show that the proposed method performs roughly 0.8% better in\naccuracy and 1.2% better in macro-F1 score when compared to existing methods.\nThe proposed method is generic and not limited to conversation applications.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 17:12:38 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["\u0130rsoy", "Ozan", ""], ["Gosangi", "Rakesh", ""], ["Zhang", "Haimin", ""], ["Wei", "Mu-Hsin", ""], ["Lund", "Peter", ""], ["Pappadopulo", "Duccio", ""], ["Fahy", "Brendan", ""], ["Nephytou", "Neophytos", ""], ["Ortiz", "Camilo", ""]]}, {"id": "1908.01832", "submitter": "Bilge Sipal", "authors": "Bilge Sipal, Ozcan Sari, Asena Teke, Nurullah Demirci", "title": "Word Sense Disambiguation using Diffusion Kernel PCA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major problems in natural language processing (NLP) is the word\nsense disambiguation (WSD) problem. It is the task of computationally\nidentifying the right sense of a polysemous word based on its context.\nResolving the WSD problem boosts the accuracy of many NLP focused algorithms\nsuch as text classification and machine translation. In this paper, we\nintroduce a new supervised algorithm for WSD, that is based on Kernel PCA and\nSemantic Diffusion Kernel, which is called Diffusion Kernel PCA (DKPCA). DKPCA\ngrasps the semantic similarities within terms, and it is based on PCA. These\nproperties enable us to perform feature extraction and dimension reduction\nguided by semantic similarities and within the algorithm. Our empirical results\non SensEval data demonstrate that DKPCA achieves higher or very close accuracy\nresults compared to SVM and KPCA with various well-known kernels when the\nlabeled data ratio is meager. Considering the scarcity of labeled data, whereas\nlarge quantities of unlabeled textual data are easily accessible, these are\nhighly encouraging first results to develop DKPCA further.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 07:16:55 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Sipal", "Bilge", ""], ["Sari", "Ozcan", ""], ["Teke", "Asena", ""], ["Demirci", "Nurullah", ""]]}, {"id": "1908.01841", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi and Erik T. Mueller", "title": "DLGNet: A Transformer-based Model for Dialogue Response Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Neural dialogue models, despite their successes, still suffer from lack of\nrelevance, diversity, and in many cases coherence in their generated responses.\nThese issues can attributed to reasons including (1) short-range model\narchitectures that capture limited temporal dependencies, (2) limitations of\nthe maximum likelihood training objective, (3) the concave entropy profile of\ndialogue datasets resulting in short and generic responses, and (4) the\nout-of-vocabulary problem leading to generation of a large number of <UNK>\ntokens. On the other hand, transformer-based models such as GPT-2 have\ndemonstrated an excellent ability to capture long-range structures in language\nmodeling tasks. In this paper, we present DLGNet, a transformer-based model for\ndialogue modeling. We specifically examine the use of DLGNet for multi-turn\ndialogue response generation. In our experiments, we evaluate DLGNet on the\nopen-domain Movie Triples dataset and the closed-domain Ubuntu Dialogue\ndataset. DLGNet models, although trained with only the maximum likelihood\nobjective, achieve significant improvements over state-of-the-art multi-turn\ndialogue models. They also produce best performance to date on the two datasets\nbased on several metrics, including BLEU, ROUGE, and distinct n-gram. Our\nanalysis shows that the performance improvement is mostly due to the\ncombination of (1) the long-range transformer architecture with (2) the\ninjection of random informative paddings. Other contributing factors include\nthe joint modeling of dialogue context and response, and the 100% tokenization\ncoverage from the byte pair encoding (BPE).\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 21:53:09 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 23:08:10 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1908.01842", "submitter": "Minshuo Chen", "authors": "Minshuo Chen, Haoming Jiang, Wenjing Liao, Tuo Zhao", "title": "Nonparametric Regression on Low-Dimensional Manifolds using Deep ReLU\n  Networks : Function Approximation and Statistical Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real world data often exhibit low-dimensional geometric structures, and can\nbe viewed as samples near a low-dimensional manifold. This paper studies\nnonparametric regression of H\\\"{o}lder functions on low-dimensional manifolds\nusing deep ReLU networks. Suppose $n$ training data are sampled from a\nH\\\"{o}lder function in $\\mathcal{H}^{s,\\alpha}$ supported on a $d$-dimensional\nRiemannian manifold isometrically embedded in $\\mathbb{R}^D$, with sub-gaussian\nnoise. A deep ReLU network architecture is designed to estimate the underlying\nfunction from the training data. The mean squared error of the empirical\nestimator is proved to converge in the order of\n$n^{-\\frac{2(s+\\alpha)}{2(s+\\alpha) + d}}\\log^3 n$. This result shows that deep\nReLU networks give rise to a fast convergence rate depending on the data\nintrinsic dimension $d$, which is usually much smaller than the ambient\ndimension $D$. It therefore demonstrates the adaptivity of deep ReLU networks\nto low-dimensional geometric structures of data, and partially explains the\npower of deep ReLU networks in tackling high-dimensional data with\nlow-dimensional geometric structures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 20:22:29 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 19:44:12 GMT"}, {"version": "v3", "created": "Thu, 2 Apr 2020 19:39:43 GMT"}, {"version": "v4", "created": "Mon, 22 Feb 2021 04:07:11 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Chen", "Minshuo", ""], ["Jiang", "Haoming", ""], ["Liao", "Wenjing", ""], ["Zhao", "Tuo", ""]]}, {"id": "1908.01843", "submitter": "Jie Zhou", "authors": "Jie Zhou, Xu Han, Cheng Yang, Zhiyuan Liu, Lifeng Wang, Changcheng Li,\n  Maosong Sun", "title": "GEAR: Graph-based Evidence Aggregating and Reasoning for Fact\n  Verification", "comments": "Accepted by ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fact verification (FV) is a challenging task which requires to retrieve\nrelevant evidence from plain text and use the evidence to verify given claims.\nMany claims require to simultaneously integrate and reason over several pieces\nof evidence for verification. However, previous work employs simple models to\nextract information from evidence without letting evidence communicate with\neach other, e.g., merely concatenate the evidence for processing. Therefore,\nthese methods are unable to grasp sufficient relational and logical information\namong the evidence. To alleviate this issue, we propose a graph-based evidence\naggregating and reasoning (GEAR) framework which enables information to\ntransfer on a fully-connected evidence graph and then utilizes different\naggregators to collect multi-evidence information. We further employ BERT, an\neffective pre-trained language representation model, to improve the\nperformance. Experimental results on a large-scale benchmark dataset FEVER have\ndemonstrated that GEAR could leverage multi-evidence information for FV and\nthus achieves the promising result with a test FEVER score of 67.10%. Our code\nis available at https://github.com/thunlp/GEAR.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 08:25:16 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Zhou", "Jie", ""], ["Han", "Xu", ""], ["Yang", "Cheng", ""], ["Liu", "Zhiyuan", ""], ["Wang", "Lifeng", ""], ["Li", "Changcheng", ""], ["Sun", "Maosong", ""]]}, {"id": "1908.01851", "submitter": "Sangchul Hahn", "authors": "Sangchul Hahn and Heeyoul Choi", "title": "Self-Knowledge Distillation in Natural Language Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since deep learning became a key player in natural language processing (NLP),\nmany deep learning models have been showing remarkable performances in a\nvariety of NLP tasks, and in some cases, they are even outperforming humans.\nSuch high performance can be explained by efficient knowledge representation of\ndeep learning models. While many methods have been proposed to learn more\nefficient representation, knowledge distillation from pretrained deep networks\nsuggest that we can use more information from the soft target probability to\ntrain other neural networks. In this paper, we propose a new knowledge\ndistillation method self-knowledge distillation, based on the soft target\nprobabilities of the training model itself, where multimode information is\ndistilled from the word embedding space right below the softmax layer. Due to\nthe time complexity, our method approximates the soft target probabilities. In\nexperiments, we applied the proposed method to two different and fundamental\nNLP tasks: language model and neural machine translation. The experiment\nresults show that our proposed method improves performance on the tasks.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 15:17:27 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Hahn", "Sangchul", ""], ["Choi", "Heeyoul", ""]]}, {"id": "1908.01875", "submitter": "Matteo Foglio", "authors": "Matteo Foglio, Lorenzo Semeria, Guido Muscioni, Riccardo Pressiani,\n  Tanya Berger-Wolf", "title": "Animal Wildlife Population Estimation Using Social Media Images\n  Collections", "comments": "KDD19 Workshop on Data Mining and AI for Conservation, Earth Day (5\n  August 2019), Anchorage, AL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are losing biodiversity at an unprecedented scale and in many cases, we do\nnot even know the basic data for the species. Traditional methods for wildlife\nmonitoring are inadequate. Development of new computer vision tools enables the\nuse of images as the source of information about wildlife. Social media is the\nrich source of wildlife images, which come with a huge bias, thus thwarting\ntraditional population size estimate approaches. Here, we present a new\nframework to take into account the social media bias when using this data\nsource to provide wildlife population size estimates. We show that,\nsurprisingly, this is a learnable and potentially solvable problem.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:53:32 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2019 16:37:38 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Foglio", "Matteo", ""], ["Semeria", "Lorenzo", ""], ["Muscioni", "Guido", ""], ["Pressiani", "Riccardo", ""], ["Berger-Wolf", "Tanya", ""]]}, {"id": "1908.01878", "submitter": "Kaichao You", "authors": "Kaichao You, Mingsheng Long, Jianmin Wang, Michael I. Jordan", "title": "How Does Learning Rate Decay Help Modern Neural Networks?", "comments": "title changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning rate decay (lrDecay) is a \\emph{de facto} technique for training\nmodern neural networks. It starts with a large learning rate and then decays it\nmultiple times. It is empirically observed to help both optimization and\ngeneralization. Common beliefs in how lrDecay works come from the optimization\nanalysis of (Stochastic) Gradient Descent: 1) an initially large learning rate\naccelerates training or helps the network escape spurious local minima; 2)\ndecaying the learning rate helps the network converge to a local minimum and\navoid oscillation. Despite the popularity of these common beliefs, experiments\nsuggest that they are insufficient in explaining the general effectiveness of\nlrDecay in training modern neural networks that are deep, wide, and nonconvex.\nWe provide another novel explanation: an initially large learning rate\nsuppresses the network from memorizing noisy data while decaying the learning\nrate improves the learning of complex patterns. The proposed explanation is\nvalidated on a carefully-constructed dataset with tractable pattern complexity.\nAnd its implication, that additional patterns learned in later stages of\nlrDecay are more complex and thus less transferable, is justified in real-world\ndatasets. We believe that this alternative explanation will shed light into the\ndesign of better training strategies for modern neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:56:41 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 06:53:59 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["You", "Kaichao", ""], ["Long", "Mingsheng", ""], ["Wang", "Jianmin", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1908.01901", "submitter": "Charles Delahunt", "authors": "Charles B. Delahunt, Mayoore S. Jaiswal, Matthew P. Horning, Samantha\n  Janko, Clay M. Thompson, Sourabh Kulhare, Liming Hu, Travis Ostbye, Grace\n  Yun, Roman Gebrehiwot, Benjamin K. Wilson, Earl Long, Stephane Proux,\n  Dionicia Gamboa, Peter Chiodini, Jane Carter, Mehul Dhorda, David Isaboke,\n  Bernhards Ogutu, Wellington Oyibo, Elizabeth Villasis, Kyaw Myo Tun,\n  Christine Bachman, David Bell, Courosh Mehanian", "title": "Fully-automated patient-level malaria assessment on field-prepared thin\n  blood film microscopy images, including Supplementary Information", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malaria is a life-threatening disease affecting millions. Microscopy-based\nassessment of thin blood films is a standard method to (i) determine malaria\nspecies and (ii) quantitate high-parasitemia infections. Full automation of\nmalaria microscopy by machine learning (ML) is a challenging task because\nfield-prepared slides vary widely in quality and presentation, and artifacts\noften heavily outnumber relatively rare parasites. In this work, we describe a\ncomplete, fully-automated framework for thin film malaria analysis that applies\nML methods, including convolutional neural nets (CNNs), trained on a large and\ndiverse dataset of field-prepared thin blood films. Quantitation and species\nidentification results are close to sufficiently accurate for the concrete\nneeds of drug resistance monitoring and clinical use-cases on field-prepared\nsamples. We focus our methods and our performance metrics on the field use-case\nrequirements. We discuss key issues and important metrics for the application\nof ML methods to malaria microscopy.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 23:25:48 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Delahunt", "Charles B.", ""], ["Jaiswal", "Mayoore S.", ""], ["Horning", "Matthew P.", ""], ["Janko", "Samantha", ""], ["Thompson", "Clay M.", ""], ["Kulhare", "Sourabh", ""], ["Hu", "Liming", ""], ["Ostbye", "Travis", ""], ["Yun", "Grace", ""], ["Gebrehiwot", "Roman", ""], ["Wilson", "Benjamin K.", ""], ["Long", "Earl", ""], ["Proux", "Stephane", ""], ["Gamboa", "Dionicia", ""], ["Chiodini", "Peter", ""], ["Carter", "Jane", ""], ["Dhorda", "Mehul", ""], ["Isaboke", "David", ""], ["Ogutu", "Bernhards", ""], ["Oyibo", "Wellington", ""], ["Villasis", "Elizabeth", ""], ["Tun", "Kyaw Myo", ""], ["Bachman", "Christine", ""], ["Bell", "David", ""], ["Mehanian", "Courosh", ""]]}, {"id": "1908.01920", "submitter": "Andrew Bennett", "authors": "Andrew Bennett and Nathan Kallus", "title": "Policy Evaluation with Latent Confounders via Optimal Balance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating novel contextual bandit policies using logged data is crucial in\napplications where exploration is costly, such as medicine. But it usually\nrelies on the assumption of no unobserved confounders, which is bound to fail\nin practice. We study the question of policy evaluation when we instead have\nproxies for the latent confounders and develop an importance weighting method\nthat avoids fitting a latent outcome regression model. We show that unlike the\nunconfounded case no single set of weights can give unbiased evaluation for all\noutcome models, yet we propose a new algorithm that can still provably\nguarantee consistency by instead minimizing an adversarial balance objective.\nWe further develop tractable algorithms for optimizing this objective and\ndemonstrate empirically the power of our method when confounders are latent.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 01:17:57 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Bennett", "Andrew", ""], ["Kallus", "Nathan", ""]]}, {"id": "1908.02029", "submitter": "Martin Tveten", "authors": "Martin Tveten and Ingrid K. Glad", "title": "Online Detection of Sparse Changes in High-Dimensional Data Streams\n  Using Tailored Projections", "comments": "26 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When applying principal component analysis (PCA) for dimension reduction, the\nmost varying projections are usually used in order to retain most of the\ninformation. For the purpose of anomaly and change detection, however, the\nleast varying projections are often the most important ones. In this article,\nwe present a novel method that automatically tailors the choice of projections\nto monitor for sparse changes in the mean and/or covariance matrix of\nhigh-dimensional data. A subset of the least varying projections is almost\nalways selected based on a criteria of the projection's sensitivity to changes.\n  Our focus is on online/sequential change detection, where the aim is to\ndetect changes as quickly as possible, while controlling false alarms at a\nspecified level. A combination of tailored PCA and a generalized log-likelihood\nmonitoring procedure displays high efficiency in detecting even very sparse\nchanges in the mean, variance and correlation. We demonstrate on real data that\ntailored PCA monitoring is efficient for sparse change detection also when the\ndata streams are highly auto-correlated and non-normal. Notably, error control\nis achieved without a large validation set, which is needed in most existing\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 09:06:45 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Tveten", "Martin", ""], ["Glad", "Ingrid K.", ""]]}, {"id": "1908.02065", "submitter": "Hagen Triendl", "authors": "Matthias Bal, Hagen Triendl, Mariana Assmann, Michael Craig, Lawrence\n  Phillips, Jarvist Moore Frost, Usman Bashir, Noor Shaker and Vid Stojevic", "title": "Sparse hierarchical representation learning on molecular graphs", "comments": "4 pages, 2 figures, accepted as a DLG 2019 workshop paper at KDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Architectures for sparse hierarchical representation learning have recently\nbeen proposed for graph-structured data, but so far assume the absence of edge\nfeatures in the graph. We close this gap and propose a method to pool graphs\nwith edge features, inspired by the hierarchical nature of chemistry. In\nparticular, we introduce two types of pooling layers compatible with an\nedge-feature graph-convolutional architecture and investigate their performance\nfor molecules relevant to drug discovery on a set of two classification and two\nregression benchmark datasets of MoleculeNet. We find that our models\nsignificantly outperform previous benchmarks on three of the datasets and reach\nstate-of-the-art results on the fourth benchmark, with pooling improving\nperformance for three out of four tasks, keeping performance stable on the\nfourth task, and generally speeding up the training process.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 10:36:41 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Bal", "Matthias", ""], ["Triendl", "Hagen", ""], ["Assmann", "Mariana", ""], ["Craig", "Michael", ""], ["Phillips", "Lawrence", ""], ["Frost", "Jarvist Moore", ""], ["Bashir", "Usman", ""], ["Shaker", "Noor", ""], ["Stojevic", "Vid", ""]]}, {"id": "1908.02096", "submitter": "Luca Zanetti", "authors": "Mihai Cucuringu, Huan Li, He Sun, Luca Zanetti", "title": "Hermitian matrices for clustering directed graphs: insights and\n  applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering is a basic technique in machine learning, and has widespread\napplications in different domains. While spectral techniques have been\nsuccessfully applied for clustering undirected graphs, the performance of\nspectral clustering algorithms for directed graphs (digraphs) is not in general\nsatisfactory: these algorithms usually require symmetrising the matrix\nrepresenting a digraph, and typical objective functions for undirected graph\nclustering do not capture cluster-structures in which the information given by\nthe direction of the edges is crucial. To overcome these downsides, we propose\na spectral clustering algorithm based on a complex-valued matrix representation\nof digraphs. We analyse its theoretical performance on a Stochastic Block Model\nfor digraphs in which the cluster-structure is given not only by variations in\nedge densities, but also by the direction of the edges. The significance of our\nwork is highlighted on a data set pertaining to internal migration in the\nUnited States: while previous spectral clustering algorithms for digraphs can\nonly reveal that people are more likely to move between counties that are\ngeographically close, our approach is able to cluster together counties with a\nsimilar socio-economical profile even when they are geographically distant, and\nillustrates how people tend to move from rural to more urbanised areas.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 12:06:44 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Cucuringu", "Mihai", ""], ["Li", "Huan", ""], ["Sun", "He", ""], ["Zanetti", "Luca", ""]]}, {"id": "1908.02105", "submitter": "David K.E. Green", "authors": "David K. E. Green and Filip Rindler", "title": "Model inference for Ordinary Differential Equations by parametric\n  polynomial kernel regression", "comments": "23 pages, 7 figures. Submission to 3rd International Conference on\n  Uncertainty Quantification in Computational Sciences and Engineering\n  (UNCECOMP), Crete, Greece, 24-26 June 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model inference for dynamical systems aims to estimate the future behaviour\nof a system from observations. Purely model-free statistical methods, such as\nArtificial Neural Networks, tend to perform poorly for such tasks. They are\ntherefore not well suited to many questions from applications, for example in\nBayesian filtering and reliability estimation.\n  This work introduces a parametric polynomial kernel method that can be used\nfor inferring the future behaviour of Ordinary Differential Equation models,\nincluding chaotic dynamical systems, from observations. Using numerical\nintegration techniques, parametric representations of Ordinary Differential\nEquations can be learnt using Backpropagation and Stochastic Gradient Descent.\nThe polynomial technique presented here is based on a nonparametric method,\nkernel ridge regression. However, the time complexity of nonparametric kernel\nridge regression scales cubically with the number of training data points. Our\nparametric polynomial method avoids this manifestation of the curse of\ndimensionality, which becomes particularly relevant when working with large\ntime series data sets.\n  Two numerical demonstrations are presented. First, a simple regression test\ncase is used to illustrate the method and to compare the performance with\nstandard Artificial Neural Network techniques. Second, a more substantial test\ncase is the inference of a chaotic spatio-temporal dynamical system, the\nLorenz--Emanuel system, from observations. Our method was able to successfully\ntrack the future behaviour of the system over time periods much larger than the\ntraining data sampling rate. Finally, some limitations of the method are\npresented, as well as proposed directions for future work to mitigate these\nlimitations.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 12:31:11 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Green", "David K. E.", ""], ["Rindler", "Filip", ""]]}, {"id": "1908.02138", "submitter": "Stevan Tomic", "authors": "Stevan Tomic, Federico Pecora and Alessandro Saffiotti", "title": "Robby is Not a Robber (anymore): On the Use of Institutions for Learning\n  Normative Behavior", "comments": "16 pages, 11 figures, Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future robots should follow human social norms in order to be useful and\naccepted in human society. In this paper, we leverage already existing social\nknowledge in human societies by capturing it in our framework through the\nnotion of social norms. We show how norms can be used to guide a reinforcement\nlearning agent towards achieving normative behavior and apply the same set of\nnorms over different domains. Thus, we are able to: (1) provide a way to\nintuitively encode social knowledge (through norms); (2) guide learning towards\nnormative behaviors (through an automatic norm reward system); and (3) achieve\na transfer of learning by abstracting policies; Finally, (4) the method is not\ndependent on a particular RL algorithm. We show how our approach can be seen as\na means to achieve abstract representation and learn procedural knowledge based\non the declarative semantics of norms and discuss possible implications of this\nin some areas of cognitive science.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 23:46:55 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Tomic", "Stevan", ""], ["Pecora", "Federico", ""], ["Saffiotti", "Alessandro", ""]]}, {"id": "1908.02144", "submitter": "Robert Pinsler", "authors": "Robert Pinsler, Jonathan Gordon, Eric Nalisnick, Jos\\'e Miguel\n  Hern\\'andez-Lobato", "title": "Bayesian Batch Active Learning as Sparse Subset Approximation", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging the wealth of unlabeled data produced in recent years provides\ngreat potential for improving supervised models. When the cost of acquiring\nlabels is high, probabilistic active learning methods can be used to greedily\nselect the most informative data points to be labeled. However, for many\nlarge-scale problems standard greedy procedures become computationally\ninfeasible and suffer from negligible model change. In this paper, we introduce\na novel Bayesian batch active learning approach that mitigates these issues.\nOur approach is motivated by approximating the complete data posterior of the\nmodel parameters. While naive batch construction methods result in correlated\nqueries, our algorithm produces diverse batches that enable efficient active\nlearning at scale. We derive interpretable closed-form solutions akin to\nexisting active learning procedures for linear models, and generalize to\narbitrary models using random projections. We demonstrate the benefits of our\napproach on several large-scale regression and classification tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:36:27 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 18:07:51 GMT"}, {"version": "v3", "created": "Mon, 6 Jan 2020 15:07:07 GMT"}, {"version": "v4", "created": "Mon, 8 Feb 2021 16:21:08 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Pinsler", "Robert", ""], ["Gordon", "Jonathan", ""], ["Nalisnick", "Eric", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""]]}, {"id": "1908.02166", "submitter": "Nir Billfeld", "authors": "Nir Billfeld, Moshe Kim", "title": "Semiparametric Wavelet-based JPEG IV Estimator for endogenously\n  truncated data", "comments": "18 pages", "journal-ref": "IEEE Access, 7, 99602-99621 (2019)", "doi": "10.1109/ACCESS.2019.2929571", "report-no": null, "categories": "stat.ME cs.CV cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new and an enriched JPEG algorithm is provided for identifying redundancies\nin a sequence of irregular noisy data points which also accommodates a\nreference-free criterion function. Our main contribution is by formulating\nanalytically (instead of approximating) the inverse of the transpose of\nJPEGwavelet transform without involving matrices which are computationally\ncumbersome. The algorithm is suitable for the widely-spread situations where\nthe original data distribution is unobservable such as in cases where there is\ndeficient representation of the entire population in the training data (in\nmachine learning) and thus the covariate shift assumption is violated. The\nproposed estimator corrects for both biases, the one generated by endogenous\ntruncation and the one generated by endogenous covariates. Results from\nutilizing 2,000,000 different distribution functions verify the applicability\nand high accuracy of our procedure to cases in which the disturbances are\nneither jointly nor marginally normally distributed.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 13:54:52 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Billfeld", "Nir", ""], ["Kim", "Moshe", ""]]}, {"id": "1908.02172", "submitter": "Ke Li Kl", "authors": "Ran Wang, Suhe Ye, Ke Li and Sam Kwong", "title": "Bayesian Network Based Label Correlation Analysis For Multi-label\n  Classifier Chain", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifier chain (CC) is a multi-label learning approach that constructs a\nsequence of binary classifiers according to a label order. Each classifier in\nthe sequence is responsible for predicting the relevance of one label. When\ntraining the classifier for a label, proceeding labels will be taken as\nextended features. If the extended features are highly correlated to the label,\nthe performance will be improved, otherwise, the performance will not be\ninfluenced or even degraded. How to discover label correlation and determine\nthe label order is critical for CC approach. This paper employs Bayesian\nnetwork (BN) to model the label correlations and proposes a new BN-based CC\nmethod (BNCC). First, conditional entropy is used to describe the dependency\nrelations among labels. Then, a BN is built up by taking nodes as labels and\nweights of edges as their dependency relations. A new scoring function is\nproposed to evaluate a BN structure, and a heuristic algorithm is introduced to\noptimize the BN. At last, by applying topological sorting on the nodes of the\noptimized BN, the label order for constructing CC model is derived.\nExperimental comparisons demonstrate the feasibility and effectiveness of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 14:07:18 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Wang", "Ran", ""], ["Ye", "Suhe", ""], ["Li", "Ke", ""], ["Kwong", "Sam", ""]]}, {"id": "1908.02246", "submitter": "Ping Li", "authors": "Xiao-Tong Yuan and Ping Li", "title": "On Convergence of Distributed Approximate Newton Methods: Globalization,\n  Sharper Bounds and Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DANE algorithm is an approximate Newton method popularly used for\ncommunication-efficient distributed machine learning. Reasons for the interest\nin DANE include scalability and versatility. Convergence of DANE, however, can\nbe tricky; its appealing convergence rate is only rigorous for quadratic\nobjective, and for more general convex functions the known results are no\nstronger than those of the classic first-order methods. To remedy these\ndrawbacks, we propose in this paper some new alternatives of DANE which are\nmore suitable for analysis. We first introduce a simple variant of DANE\nequipped with backtracking line search, for which global asymptotic convergence\nand sharper local non-asymptotic convergence rate guarantees can be proved for\nboth quadratic and non-quadratic strongly convex functions. Then we propose a\nheavy-ball method to accelerate the convergence of DANE, showing that nearly\ntight local rate of convergence can be established for strongly convex\nfunctions, and with proper modification of algorithm the same result applies\nglobally to linear prediction models. Numerical evidence is provided to confirm\nthe theoretical and practical advantages of our methods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 16:36:30 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Yuan", "Xiao-Tong", ""], ["Li", "Ping", ""]]}, {"id": "1908.02252", "submitter": "Guangyi Zhang", "authors": "Guangyi Zhang, Vandad Davoodnia, Alireza Sepas-Moghaddam, Yaoxue\n  Zhang, and Ali Etemad", "title": "Classification of Hand Movements from EEG using a Deep Attention-based\n  LSTM Network", "comments": null, "journal-ref": null, "doi": "10.1109/JSEN.2019.2956998", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classifying limb movements using brain activity is an important task in\nBrain-computer Interfaces (BCI) that has been successfully used in multiple\napplication domains, ranging from human-computer interaction to medical and\nbiomedical applications. This paper proposes a novel solution for\nclassification of left/right hand movement by exploiting a Long Short-Term\nMemory (LSTM) network with attention mechanism to learn the\nelectroencephalogram (EEG) time-series information. To this end, a wide range\nof time and frequency domain features are extracted from the EEG signals and\nused to train an LSTM network to perform the classification task. We conduct\nextensive experiments with the EEG Movement dataset and show that our proposed\nsolution our method achieves improvements over several benchmarks and\nstate-of-the-art methods in both intra-subject and cross-subject validation\nschemes. Moreover, we utilize the proposed framework to analyze the information\nas received by the sensors and monitor the activated regions of the brain by\ntracking EEG topography throughout the experiments.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 16:42:46 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 09:59:28 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Zhang", "Guangyi", ""], ["Davoodnia", "Vandad", ""], ["Sepas-Moghaddam", "Alireza", ""], ["Zhang", "Yaoxue", ""], ["Etemad", "Ali", ""]]}, {"id": "1908.02254", "submitter": "S M Nadim Uddin", "authors": "S. M. A. Sharif, Ghulam Mujtaba, S. M. Nadim Uddin", "title": "EdgeNet: A novel approach for Arabic numeral classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Despite the importance of handwritten numeral classification, a robust and\neffective method for a widely used language like Arabic is still due. This\nstudy focuses to overcome two major limitations of existing works: data\ndiversity and effective learning method. Hence, the existing Arabic numeral\ndatasets have been merged into a single dataset and augmented to introduce data\ndiversity. Moreover, a novel deep model has been proposed to exploit diverse\ndata samples of unified dataset. The proposed deep model utilizes the low-level\nedge features by propagating them through residual connection. To make a fair\ncomparison with the proposed model, the existing works have been studied under\nthe unified dataset. The comparison experiments illustrate that the unified\ndataset accelerates the performance of the existing works. Moreover, the\nproposed model outperforms the existing state-of-the-art Arabic handwritten\nnumeral classification methods and obtain an accuracy of 99.59% in the\nvalidation phase. Apart from that, different state-of-the-art classification\nmodels have studied with the same dataset to reveal their feasibility for the\nArabic numeral classification. Code available at\nhttp://github.com/sharif-apu/EdgeNet.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 10:17:43 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Sharif", "S. M. A.", ""], ["Mujtaba", "Ghulam", ""], ["Uddin", "S. M. Nadim", ""]]}, {"id": "1908.02256", "submitter": "Ravi Raju", "authors": "Ravi Raju, Mikko Lipasti", "title": "BlurNet: Defense by Filtering the Feature Maps", "comments": "10 pages, 4 figures, Accepted at DSN 2020 workshop: Dependable and\n  Secure Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the field of adversarial machine learning has been garnering\nattention by showing that state-of-the-art deep neural networks are vulnerable\nto adversarial examples, stemming from small perturbations being added to the\ninput image. Adversarial examples are generated by a malicious adversary by\nobtaining access to the model parameters, such as gradient information, to\nalter the input or by attacking a substitute model and transferring those\nmalicious examples over to attack the victim model. Specifically, one of these\nattack algorithms, Robust Physical Perturbations ($RP_2$), generates\nadversarial images of stop signs with black and white stickers to achieve high\ntargeted misclassification rates against standard-architecture traffic sign\nclassifiers. In this paper, we propose BlurNet, a defense against the $RP_2$\nattack. First, we motivate the defense with a frequency analysis of the first\nlayer feature maps of the network on the LISA dataset, which shows that high\nfrequency noise is introduced into the input image by the $RP_2$ algorithm. To\nremove the high frequency noise, we introduce a depthwise convolution layer of\nstandard blur kernels after the first layer. We perform a blackbox transfer\nattack to show that low-pass filtering the feature maps is more beneficial than\nfiltering the input. We then present various regularization schemes to\nincorporate this low-pass filtering behavior into the training regime of the\nnetwork and perform white-box attacks. We conclude with an adaptive attack\nevaluation to show that the success rate of the attack drops from 90\\% to 20\\%\nwith total variation regularization, one of the proposed defenses.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 16:55:47 GMT"}, {"version": "v2", "created": "Sat, 16 May 2020 20:39:13 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Raju", "Ravi", ""], ["Lipasti", "Mikko", ""]]}, {"id": "1908.02269", "submitter": "Julien Roy", "authors": "Julien Roy, Paul Barde, F\\'elix G. Harvey, Derek Nowrouzezahrai and\n  Christopher Pal", "title": "Promoting Coordination through Policy Regularization in Multi-Agent Deep\n  Reinforcement Learning", "comments": "23 pages, 16 figures. This revised version contains additional\n  results and minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-agent reinforcement learning, discovering successful collective\nbehaviors is challenging as it requires exploring a joint action space that\ngrows exponentially with the number of agents. While the tractability of\nindependent agent-wise exploration is appealing, this approach fails on tasks\nthat require elaborate group strategies. We argue that coordinating the agents'\npolicies can guide their exploration and we investigate techniques to promote\nsuch an inductive bias. We propose two policy regularization methods: TeamReg,\nwhich is based on inter-agent action predictability and CoachReg that relies on\nsynchronized behavior selection. We evaluate each approach on four challenging\ncontinuous control tasks with sparse rewards that require varying levels of\ncoordination as well as on the discrete action Google Research Football\nenvironment. Our experiments show improved performance across many cooperative\nmulti-agent problems. Finally, we analyze the effects of our proposed methods\non the policies that our agents learn and show that our methods successfully\nenforce the qualities that we propose as proxies for coordinated behaviors.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 17:48:17 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 20:33:08 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 19:24:21 GMT"}, {"version": "v4", "created": "Mon, 9 Nov 2020 16:30:41 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Roy", "Julien", ""], ["Barde", "Paul", ""], ["Harvey", "F\u00e9lix G.", ""], ["Nowrouzezahrai", "Derek", ""], ["Pal", "Christopher", ""]]}, {"id": "1908.02334", "submitter": "Emily Diller", "authors": "Emily E Diller, Sha Cao, Beth Ey, Robert Lober, Jason G Parker", "title": "Predicted disease compositions of human gliomas estimated from\n  multiparametric MRI can predict endothelial proliferation, tumor grade, and\n  overall survival", "comments": "13 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV physics.med-ph stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background and Purpose: Biopsy is the main determinants of glioma clinical\nmanagement, but require invasive sampling that fail to detect relevant features\nbecause of tumor heterogeneity. The purpose of this study was to evaluate the\naccuracy of a voxel-wise, multiparametric MRI radiomic method to predict\nfeatures and develop a minimally invasive method to objectively assess\nneoplasms.\n  Methods: Multiparametric MRI were registered to T1-weighted gadolinium\ncontrast-enhanced data using a 12 degree-of-freedom affine model. The\nretrospectively collected MRI data included T1-weighted, T1-weighted gadolinium\ncontrast-enhanced, T2-weighted, fluid attenuated inversion recovery, and\nmulti-b-value diffusion-weighted acquired at 1.5T or 3.0T. Clinical experts\nprovided voxel-wise annotations for five disease states on a subset of patients\nto establish a training feature vector of 611,930 observations. Then, a\nk-nearest-neighbor (k-NN) classifier was trained using a 25% hold-out design.\nThe trained k-NN model was applied to 13,018,171 observations from seventeen\nhistologically confirmed glioma patients. Linear regression tested overall\nsurvival (OS) relationship to predicted disease compositions (PDC) and\ndiagnostic age (alpha = 0.05). Canonical discriminant analysis tested if PDC\nand diagnostic age could differentiate clinical, genetic, and microscopic\nfactors (alpha = 0.05).\n  Results: The model predicted voxel annotation class with a Dice similarity\ncoefficient of 94.34% +/- 2.98. Linear combinations of PDCs and diagnostic age\npredicted OS (p = 0.008), grade (p = 0.014), and endothelia proliferation (p =\n0.003); but fell short predicting gene mutations for TP53BP1 and IDH1.\n  Conclusions: This voxel-wise, multi-parametric MRI radiomic strategy holds\npotential as a non-invasive decision-making aid for clinicians managing\npatients with glioma.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 19:10:32 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Diller", "Emily E", ""], ["Cao", "Sha", ""], ["Ey", "Beth", ""], ["Lober", "Robert", ""], ["Parker", "Jason G", ""]]}, {"id": "1908.02337", "submitter": "Lili Zhao", "authors": "Lili Zhao and Dai Feng", "title": "DNNSurv: Deep Neural Networks for Survival Analysis Using Pseudo Values", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been increasing interest in modelling survival data using deep\nlearning methods in medical research. Current approaches have focused on\ndesigning special cost functions to handle censored survival data. We propose a\nvery different method with two steps. In the first step, we transform each\nsubject's survival time into a series of jackknife pseudo conditional survival\nprobabilities and then use these pseudo probabilities as a quantitative\nresponse variable in the deep neural network model. By using the pseudo values,\nwe reduce a complex survival analysis to a standard regression problem, which\ngreatly simplifies the neural network construction. Our two-step approach is\nsimple, yet very flexible in making risk predictions for survival data, which\nis very appealing from the practice point of view. The source code is freely\navailable at http://github.com/lilizhaoUM/DNNSurv.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 19:16:58 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 18:57:05 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Zhao", "Lili", ""], ["Feng", "Dai", ""]]}, {"id": "1908.02338", "submitter": "Paul Fergus Dr", "authors": "Paul Fergus, Carl Chalmers, Casimiro Curbelo Montanez, Denis Reilly,\n  Paulo Lisboa and Beth Pineles", "title": "Modelling Segmented Cardiotocography Time-Series Signals Using\n  One-Dimensional Convolutional Neural Networks for the Early Detection of\n  Abnormal Birth Outcomes", "comments": "11 Pages, 12 Figures (excluding profile pictures), accepted for\n  publication in IEEE Transactions in Emerging Topics in Computational\n  Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gynaecologists and obstetricians visually interpret cardiotocography (CTG)\ntraces using the International Federation of Gynaecology and Obstetrics (FIGO)\nguidelines to assess the wellbeing of the foetus during antenatal care. This\napproach has raised concerns among professionals with regards to inter- and\nintra-variability where clinical diagnosis only has a 30\\% positive predictive\nvalue when classifying pathological outcomes. Machine learning models, trained\nwith FIGO and other user derived features extracted from CTG traces, have been\nshown to increase positive predictive capacity and minimise variability. This\nis only possible however when class distributions are equal which is rarely the\ncase in clinical trials where case-control observations are heavily skewed in\nfavour of normal outcomes. Classes can be balanced using either synthetic data\nderived from resampled case training data or by decreasing the number of\ncontrol instances. However, this either introduces bias or removes valuable\ninformation. Concerns have also been raised regarding machine learning studies\nand their reliance on manually handcrafted features. While this has led to some\ninteresting results, deriving an optimal set of features is considered to be an\nart as well as a science and is often an empirical and time consuming process.\nIn this paper, we address both of these issues and propose a novel CTG analysis\nmethodology that a) splits CTG time-series signals into n-size windows with\nequal class distributions, and b) automatically extracts features from\ntime-series windows using a one dimensional convolutional neural network\n(1DCNN) and multilayer perceptron (MLP) ensemble. Collectively, the proposed\napproach normally distributes classes and removes the need to handcrafted\nfeatures from CTG traces.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 19:20:23 GMT"}, {"version": "v2", "created": "Sat, 22 Aug 2020 09:03:21 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Fergus", "Paul", ""], ["Chalmers", "Carl", ""], ["Montanez", "Casimiro Curbelo", ""], ["Reilly", "Denis", ""], ["Lisboa", "Paulo", ""], ["Pineles", "Beth", ""]]}, {"id": "1908.02341", "submitter": "Nilesh Tripuraneni", "authors": "Nilesh Tripuraneni, Lester Mackey", "title": "Single Point Transductive Prediction", "comments": "37th International Conference on Machine Learning (ICML 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard methods in supervised learning separate training and prediction: the\nmodel is fit independently of any test points it may encounter. However, can\nknowledge of the next test point $\\mathbf{x}_{\\star}$ be exploited to improve\nprediction accuracy? We address this question in the context of linear\nprediction, showing how techniques from semi-parametric inference can be used\ntransductively to combat regularization bias. We first lower bound the\n$\\mathbf{x}_{\\star}$ prediction error of ridge regression and the Lasso,\nshowing that they must incur significant bias in certain test directions. We\nthen provide non-asymptotic upper bounds on the $\\mathbf{x}_{\\star}$ prediction\nerror of two transductive prediction rules. We conclude by showing the efficacy\nof our methods on both synthetic and real data, highlighting the improvements\nsingle point transductive prediction can provide in settings with distribution\nshift.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 19:34:30 GMT"}, {"version": "v2", "created": "Sun, 9 Feb 2020 04:44:37 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2020 03:17:34 GMT"}, {"version": "v4", "created": "Mon, 29 Jun 2020 04:54:59 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Tripuraneni", "Nilesh", ""], ["Mackey", "Lester", ""]]}, {"id": "1908.02386", "submitter": "Seyed Hamed Fatemi Langroudi", "authors": "Hamed F. Langroudi, Zachariah Carmichael, David Pastuch, Dhireesha\n  Kudithipudi", "title": "Cheetah: Mixed Low-Precision Hardware & Software Co-Design Framework for\n  DNNs on the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-precision DNNs have been extensively explored in order to reduce the size\nof DNN models for edge devices. Recently, the posit numerical format has shown\npromise for DNN data representation and compute with ultra-low precision in\n[5..8]-bits. However, previous studies were limited to studying posit for DNN\ninference only. In this paper, we propose the Cheetah framework, which supports\nboth DNN training and inference using posits, as well as other commonly used\nformats. Additionally, the framework is amenable for different quantization\napproaches and supports mixed-precision floating point and fixed-point\nnumerical formats. Cheetah is evaluated on three datasets: MNIST, Fashion\nMNIST, and CIFAR-10. Results indicate that 16-bit posits outperform 16-bit\nfloating point in DNN training. Furthermore, performing inference with\n[5..8]-bit posits improves the trade-off between performance and\nenergy-delay-product over both [5..8]-bit float and fixed-point.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 22:28:29 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Langroudi", "Hamed F.", ""], ["Carmichael", "Zachariah", ""], ["Pastuch", "David", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1908.02388", "submitter": "Adrien Ali Taiga", "authors": "Adrien Ali Ta\\\"iga, William Fedus, Marlos C. Machado, Aaron Courville,\n  Marc G. Bellemare", "title": "Benchmarking Bonus-Based Exploration Methods on the Arcade Learning\n  Environment", "comments": "Accepted at the second Exploration in Reinforcement Learning Workshop\n  at the 36th International Conference on Machine Learning, Long Beach,\n  California", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an empirical evaluation of recently developed exploration\nalgorithms within the Arcade Learning Environment (ALE). We study the use of\ndifferent reward bonuses that incentives exploration in reinforcement learning.\nWe do so by fixing the learning algorithm used and focusing only on the impact\nof the different exploration bonuses in the agent's performance. We use\nRainbow, the state-of-the-art algorithm for value-based agents, and focus on\nsome of the bonuses proposed in the last few years. We consider the impact\nthese algorithms have on performance within the popular game Montezuma's\nRevenge which has gathered a lot of interest from the exploration community,\nacross the the set of seven games identified by Bellemare et al. (2016) as\nchallenging for exploration, and easier games where exploration is not an\nissue. We find that, in our setting, recently developed bonuses do not provide\nsignificantly improved performance on Montezuma's Revenge or hard exploration\ngames. We also find that existing bonus-based methods may negatively impact\nperformance on games in which exploration is not an issue and may even perform\nworse than $\\epsilon$-greedy exploration.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 22:36:35 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 14:39:25 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Ta\u00efga", "Adrien Ali", ""], ["Fedus", "William", ""], ["Machado", "Marlos C.", ""], ["Courville", "Aaron", ""], ["Bellemare", "Marc G.", ""]]}, {"id": "1908.02400", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh, Dianne P O'Leary", "title": "Refining the Structure of Neural Networks Using Matrix Conditioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have proven to be exceptionally useful in performing\nmany machine learning tasks. However, for each new dataset, choosing an\neffective size and structure of the model can be a time-consuming process of\ntrial and error. While a small network with few neurons might not be able to\ncapture the intricacies of a given task, having too many neurons can lead to\noverfitting and poor generalization. Here, we propose a practical method that\nemploys matrix conditioning to automatically design the structure of layers of\na feed-forward network, by first adjusting the proportion of neurons among the\nlayers of a network and then scaling the size of network up or down. Results on\nsample image and non-image datasets demonstrate that our method results in\nsmall networks with high accuracies. Finally, guided by matrix conditioning, we\nprovide a method to effectively squeeze models that are already trained. Our\ntechniques reduce the human cost of designing deep learning models and can also\nreduce training time and the expense of using neural networks for applications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 23:45:34 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""], ["O'Leary", "Dianne P", ""]]}, {"id": "1908.02419", "submitter": "Kenji Kawaguchi", "authors": "Kenji Kawaguchi, Jiaoyang Huang", "title": "Gradient Descent Finds Global Minima for Generalizable Deep Neural\n  Networks of Practical Sizes", "comments": "Accepted. All the results remain the same. Additional explanations\n  were added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we theoretically prove that gradient descent can find a global\nminimum of non-convex optimization of all layers for nonlinear deep neural\nnetworks of sizes commonly encountered in practice. The theory developed in\nthis paper only requires the practical degrees of over-parameterization unlike\nprevious theories. Our theory only requires the number of trainable parameters\nto increase linearly as the number of training samples increases. This allows\nthe size of the deep neural networks to be consistent with practice and to be\nseveral orders of magnitude smaller than that required by the previous\ntheories. Moreover, we prove that the linear increase of the size of the\nnetwork is the optimal rate and that it cannot be improved, except by a\nlogarithmic factor. Furthermore, deep neural networks with the trainability\nguarantee are shown to generalize well to unseen test samples with a natural\ndataset but not a random dataset.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 20:19:39 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 18:27:14 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 19:40:44 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Kawaguchi", "Kenji", ""], ["Huang", "Jiaoyang", ""]]}, {"id": "1908.02426", "submitter": "Jing Cheng", "authors": "Jing Cheng, Haifeng Wang, Leslie Ying, Dong Liang", "title": "Model Learning: Primal Dual Networks for Fast MR imaging", "comments": "accepted in MICCAI2019. arXiv admin note: text overlap with\n  arXiv:1906.08143", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic resonance imaging (MRI) is known to be a slow imaging modality and\nundersampling in k-space has been used to increase the imaging speed. However,\nimage reconstruction from undersampled k-space data is an ill-posed inverse\nproblem. Iterative algorithms based on compressed sensing have been used to\naddress the issue. In this work, we unroll the iterations of the primal-dual\nhybrid gradient algorithm to a learnable deep network architecture, and\ngradually relax the constraints to reconstruct MR images from highly\nundersampled k-space data. The proposed method combines the theoretical\nconvergence guarantee of optimi-zation methods with the powerful learning\ncapability of deep networks. As the constraints are gradually relaxed, the\nreconstruction model is finally learned from the training data by updating in\nk-space and image domain alternatively. Experi-ments on in vivo MR data\ndemonstrate that the proposed method achieves supe-rior MR reconstructions from\nhighly undersampled k-space data over other state-of-the-art image\nreconstruction methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 02:59:08 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Cheng", "Jing", ""], ["Wang", "Haifeng", ""], ["Ying", "Leslie", ""], ["Liang", "Dong", ""]]}, {"id": "1908.02427", "submitter": "Franklin Abodo", "authors": "Franklin Abodo, Andrew Berthaume, Stephen Zitzow-Childs and Leonardo\n  Bobadilla", "title": "Strengthening the Case for a Bayesian Approach to Car-following Model\n  Calibration and Validation using Probabilistic Programming", "comments": "IEEE 22nd Intelligent Transportation Systems Conference, ITSC 2019, 2\n  figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compute and memory constraints have historically prevented traffic simulation\nsoftware users from fully utilizing the predictive models underlying them. When\ncalibrating car-following models, particularly, accommodations have included 1)\nusing sensitivity analysis to limit the number of parameters to be calibrated,\nand 2) identifying only one set of parameter values using data collected from\nmultiple car-following instances across multiple drivers. Shortcuts are further\nmotivated by insufficient data set sizes, for which a driver may have too few\ninstances to fully account for the variation in their driving behavior. In this\npaper, we demonstrate that recent technological advances can enable\ntransportation researchers and engineers to overcome these constraints and\nproduce calibration results that 1) outperform industry standard approaches,\nand 2) allow for a unique set of parameters to be estimated for each driver in\na data set, even given a small amount of data. We propose a novel calibration\nprocedure for car-following models based on Bayesian machine learning and\nprobabilistic programming, and apply it to real-world data from a naturalistic\ndriving study. We also discuss how this combination of mathematical and\nsoftware tools can offer additional benefits such as more informative model\nvalidation and the incorporation of true-to-data uncertainty into simulation\ntraces.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 03:04:38 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Abodo", "Franklin", ""], ["Berthaume", "Andrew", ""], ["Zitzow-Childs", "Stephen", ""], ["Bobadilla", "Leonardo", ""]]}, {"id": "1908.02436", "submitter": "Megha Nawhal", "authors": "Zhiwei Deng, Megha Nawhal, Lili Meng, Greg Mori", "title": "Continuous Graph Flow", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose Continuous Graph Flow, a generative continuous flow\nbased method that aims to model complex distributions of graph-structured data.\nOnce learned, the model can be applied to an arbitrary graph, defining a\nprobability density over the random variables represented by the graph. It is\nformulated as an ordinary differential equation system with shared and reusable\nfunctions that operate over the graphs. This leads to a new type of neural\ngraph message passing scheme that performs continuous message passing over\ntime. This class of models offers several advantages: a flexible representation\nthat can generalize to variable data dimensions; ability to model dependencies\nin complex data distributions; reversible and memory-efficient; and exact and\nefficient computation of the likelihood of the data. We demonstrate the\neffectiveness of our model on a diverse set of generation tasks across\ndifferent domains: graph generation, image puzzle generation, and layout\ngeneration from scene graphs. Our proposed model achieves significantly better\nperformance compared to state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 04:24:48 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 04:34:55 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Deng", "Zhiwei", ""], ["Nawhal", "Megha", ""], ["Meng", "Lili", ""], ["Mori", "Greg", ""]]}, {"id": "1908.02441", "submitter": "Jiwoong Park", "authors": "Jiwoong Park, Minsik Lee, Hyung Jin Chang, Kyuewang Lee, Jin Young\n  Choi", "title": "Symmetric Graph Convolutional Autoencoder for Unsupervised Graph\n  Representation Learning", "comments": "10 pages, 3 figures, ICCV 2019 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a symmetric graph convolutional autoencoder which produces a\nlow-dimensional latent representation from a graph. In contrast to the existing\ngraph autoencoders with asymmetric decoder parts, the proposed autoencoder has\na newly designed decoder which builds a completely symmetric autoencoder form.\nFor the reconstruction of node features, the decoder is designed based on\nLaplacian sharpening as the counterpart of Laplacian smoothing of the encoder,\nwhich allows utilizing the graph structure in the whole processes of the\nproposed autoencoder architecture. In order to prevent the numerical\ninstability of the network caused by the Laplacian sharpening introduction, we\nfurther propose a new numerically stable form of the Laplacian sharpening by\nincorporating the signed graphs. In addition, a new cost function which finds a\nlatent representation and a latent affinity matrix simultaneously is devised to\nboost the performance of image clustering tasks. The experimental results on\nclustering, link prediction and visualization tasks strongly support that the\nproposed model is stable and outperforms various state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 05:08:15 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Park", "Jiwoong", ""], ["Lee", "Minsik", ""], ["Chang", "Hyung Jin", ""], ["Lee", "Kyuewang", ""], ["Choi", "Jin Young", ""]]}, {"id": "1908.02569", "submitter": "Kyungmin Kim", "authors": "Kyung-Min Kim, Donghyun Kwak, Hanock Kwak, Young-Jin Park, Sangkwon\n  Sim, Jae-Han Cho, Minkyu Kim, Jihun Kwon, Nako Sung, and Jung-Woo Ha", "title": "Tripartite Heterogeneous Graph Propagation for Large-scale Social\n  Recommendation", "comments": "6 pages, accepted for RecSys 2019 LBR Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks (GNNs) have been emerging as a promising method for\nrelational representation including recommender systems. However, various\nchallenging issues of social graphs hinder the practical usage of GNNs for\nsocial recommendation, such as their complex noisy connections and high\nheterogeneity. The oversmoothing of GNNs is an obstacle of GNN-based social\nrecommendation as well. Here we propose a new graph embedding method\nHeterogeneous Graph Propagation (HGP) to tackle these issues. HGP uses a\ngroup-user-item tripartite graph as input to reduce the number of edges and the\ncomplexity of paths in a social graph. To solve the oversmoothing issue, HGP\nembeds nodes under a personalized PageRank based propagation scheme, separately\nfor group-user graph and user-item graph. Node embeddings from each graph are\nintegrated using an attention mechanism. We evaluate our HGP on a large-scale\nreal-world dataset consisting of 1,645,279 nodes and 4,711,208 edges. The\nexperimental results show that HGP outperforms several baselines in terms of\nAUC and F1-score metrics.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 08:27:07 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Kim", "Kyung-Min", ""], ["Kwak", "Donghyun", ""], ["Kwak", "Hanock", ""], ["Park", "Young-Jin", ""], ["Sim", "Sangkwon", ""], ["Cho", "Jae-Han", ""], ["Kim", "Minkyu", ""], ["Kwon", "Jihun", ""], ["Sung", "Nako", ""], ["Ha", "Jung-Woo", ""]]}, {"id": "1908.02570", "submitter": "Shakila Khan Rumi", "authors": "Shakila Khan Rumi, Flora D. Salim", "title": "Modelling Regional Crime Risk using Directed Graph of Check-ins", "comments": "4 Pages, This paper has been accepted to publish in Proceedings of\n  the 29th ACM International Conference on Information and Knowledge Management\n  (CIKM' 20)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The location-based social network, Foursquare, reflects the human activities\nof a city. The mobility dynamics inferred from Foursquare helps us\nunderstanding urban social events like crime In this paper, we propose a\ndirected graph from the aggregated movement between regions using Foursquare\ndata. We derive region risk factor from the movement direction, quantity and\ncrime history in different periods of the day. Later, we propose a new set of\nfeatures, DIrected graph Flow FEatuRes (DIFFER) which are associated with\nregion risk factor. The reliable correlations between DIFFER and crime count\nare observed. We verify the effectiveness of the DIFFER in monthly crime count\nusing Linear, XGBoost, and Random Forest regression in two cities, Chicago and\nNew York City.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 02:34:38 GMT"}, {"version": "v2", "created": "Wed, 12 Aug 2020 02:46:33 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Rumi", "Shakila Khan", ""], ["Salim", "Flora D.", ""]]}, {"id": "1908.02573", "submitter": "Akifumi Okuno", "authors": "Akifumi Okuno, Hidetoshi Shimodaira", "title": "Hyperlink Regression via Bregman Divergence", "comments": "41 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collection of $U \\: (\\in \\mathbb{N})$ data vectors is called a $U$-tuple,\nand the association strength among the vectors of a tuple is termed as the\n\\emph{hyperlink weight}, that is assumed to be symmetric with respect to\npermutation of the entries in the index. We herein propose Bregman hyperlink\nregression (BHLR), which learns a user-specified symmetric similarity function\nsuch that it predicts the tuple's hyperlink weight from data vectors stored in\nthe $U$-tuple. BHLR is a simple and general framework for hyper-relational\nlearning, that minimizes Bregman-divergence (BD) between the hyperlink weights\nand estimated similarities defined for the corresponding tuples; BHLR\nencompasses various existing methods, such as logistic regression ($U=1$),\nPoisson regression ($U=1$), link prediction ($U=2$), and those for\nrepresentation learning, such as graph embedding ($U=2$), matrix factorization\n($U=2$), tensor factorization ($U \\geq 2$), and their variants equipped with\narbitrary BD. Nonlinear functions (e.g., neural networks), can be employed for\nthe similarity functions. However, there are theoretical challenges such that\nsome of different tuples of BHLR may share data vectors therein, unlike the\ni.i.d. setting of classical regression. We address these theoretical issues,\nand proved that BHLR equipped with arbitrary BD and $U \\in \\mathbb{N}$ is (P-1)\nstatistically consistent, that is, it asymptotically recovers the underlying\ntrue conditional expectation of hyperlink weights given data vectors, and (P-2)\ncomputationally tractable, that is, it is efficiently computed by stochastic\noptimization algorithms using a novel generalized minibatch sampling procedure\nfor hyper-relational data. Consequently, theoretical guarantees for BHLR\nincluding several existing methods, that have been examined experimentally, are\nprovided in a unified manner.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 01:38:21 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 07:34:57 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Okuno", "Akifumi", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1908.02575", "submitter": "Oscar Correa", "authors": "Oscar Correa and Jeffrey Chan and Vinh Nguyen", "title": "Alternative Blockmodelling", "comments": "56 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many approaches have been proposed to discover clusters within networks.\nCommunity finding field encompasses approaches which try to discover clusters\nwhere nodes are tightly related within them but loosely related with nodes of\nother clusters. However, a community network configuration is not the only\npossible latent structure in a graph. Core-periphery and hierarchical network\nconfigurations are valid structures to discover in a relational dataset. On the\nother hand, a network is not completely explained by only knowing the\nmembership of each node. A high level view of the inter-cluster relationships\nis needed. Blockmodelling techniques deal with these two issues. Firstly,\nblockmodelling allows finding any network configuration besides to the\nwell-known community structure. Secondly, blockmodelling is a summary\nrepresentation of a network which regards not only membership of nodes but also\nrelations between clusters. Finally, a unique summary representation of a\nnetwork is unlikely. Networks might hide more than one blockmodel. Therefore,\nour proposed problem aims to discover a secondary blockmodel representation of\na network that is of good quality and dissimilar with respect to a given\nblockmodel. Our methodology is presented through two approaches, (a) inclusion\nof cannot-link constraints and (b) dissimilarity between image matrices. Both\napproaches are based on non-negative matrix factorisation NMF which fits the\nblockmodelling representation. The evaluation of these two approaches regards\nquality and dissimilarity of the discovered alternative blockmodel as these are\nthe requirements of the problem.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 06:49:47 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Correa", "Oscar", ""], ["Chan", "Jeffrey", ""], ["Nguyen", "Vinh", ""]]}, {"id": "1908.02588", "submitter": "Luke Snyder", "authors": "Luke S. Snyder, Yi-Shan Lin, Morteza Karimzadeh, Dan Goldwasser, and\n  David S. Ebert", "title": "Interactive Learning for Identifying Relevant Tweets to Support\n  Real-time Situational Awareness", "comments": "12 pages, 8 figures, 3 tables, IEEE VIS VAST 2019, TVCG", "journal-ref": null, "doi": "10.1109/TVCG.2019.2934614", "report-no": null, "categories": "cs.SI cs.CL cs.HC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various domain users are increasingly leveraging real-time social media data\nto gain rapid situational awareness. However, due to the high noise in the\ndeluge of data, effectively determining semantically relevant information can\nbe difficult, further complicated by the changing definition of relevancy by\neach end user for different events. The majority of existing methods for short\ntext relevance classification fail to incorporate users' knowledge into the\nclassification process. Existing methods that incorporate interactive user\nfeedback focus on historical datasets. Therefore, classifiers cannot be\ninteractively retrained for specific events or user-dependent needs in\nreal-time. This limits real-time situational awareness, as streaming data that\nis incorrectly classified cannot be corrected immediately, permitting the\npossibility for important incoming data to be incorrectly classified as well.\nWe present a novel interactive learning framework to improve the classification\nprocess in which the user iteratively corrects the relevancy of tweets in\nreal-time to train the classification model on-the-fly for immediate predictive\nimprovements. We computationally evaluate our classification model adapted to\nlearn at interactive rates. Our results show that our approach outperforms\nstate-of-the-art machine learning models. In addition, we integrate our\nframework with the extended Social Media Analytics and Reporting Toolkit\n(SMART) 2.0 system, allowing the use of our interactive learning framework\nwithin a visual analytics system tailored for real-time situational awareness.\nTo demonstrate our framework's effectiveness, we provide domain expert feedback\nfrom first responders who used the extended SMART 2.0 system.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 09:01:19 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 19:11:52 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Snyder", "Luke S.", ""], ["Lin", "Yi-Shan", ""], ["Karimzadeh", "Morteza", ""], ["Goldwasser", "Dan", ""], ["Ebert", "David S.", ""]]}, {"id": "1908.02612", "submitter": "Sungrack Yun", "authors": "Sungrack Yun, Janghoon Cho, Jungyun Eum, Wonil Chang, Kyuwoong Hwang", "title": "An End-to-End Text-independent Speaker Verification Framework with a\n  Keyword Adversarial Network", "comments": "Will be appeared in INTERSPEECH 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an end-to-end text-independent speaker verification\nframework by jointly considering the speaker embedding (SE) network and\nautomatic speech recognition (ASR) network. The SE network learns to output an\nembedding vector which distinguishes the speaker characteristics of the input\nutterance, while the ASR network learns to recognize the phonetic context of\nthe input. In training our speaker verification framework, we consider both the\ntriplet loss minimization and adversarial gradient of the ASR network to obtain\nmore discriminative and text-independent speaker embedding vectors. With the\ntriplet loss, the distances between the embedding vectors of the same speaker\nare minimized while those of different speakers are maximized. Also, with the\nadversarial gradient of the ASR network, the text-dependency of the speaker\nembedding vector can be reduced. In the experiments, we evaluated our speaker\nverification framework using the LibriSpeech and CHiME 2013 dataset, and the\nevaluation results show that our speaker verification framework shows lower\nequal error rate and better text-independency compared to the other approaches.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 11:05:20 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Yun", "Sungrack", ""], ["Cho", "Janghoon", ""], ["Eum", "Jungyun", ""], ["Chang", "Wonil", ""], ["Hwang", "Kyuwoong", ""]]}, {"id": "1908.02614", "submitter": "Shikang Liu", "authors": "Shikang Liu, David Hachen, Omar Lizardo, Christian Poellabauer, Aaron\n  Striegel, Tijana Milenkovic", "title": "The power of dynamic social networks to predict individuals' mental\n  health", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precision medicine has received attention both in and outside the clinic. We\nfocus on the latter, by exploiting the relationship between individuals' social\ninteractions and their mental health to develop a predictive model of one's\nlikelihood to be depressed or anxious from rich dynamic social network data. To\nour knowledge, we are the first to do this. Existing studies differ from our\nwork in at least one aspect: they do not model social interaction data as a\nnetwork; they do so but analyze static network data; they examine \"correlation\"\nbetween social networks and health but without developing a predictive model;\nor they study other individual traits but not mental health. In a systematic\nand comprehensive evaluation, we show that our predictive model that uses\ndynamic social network data is superior to its static network as well as\nnon-network equivalents when run on the same data.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 00:50:36 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Liu", "Shikang", ""], ["Hachen", "David", ""], ["Lizardo", "Omar", ""], ["Poellabauer", "Christian", ""], ["Striegel", "Aaron", ""], ["Milenkovic", "Tijana", ""]]}, {"id": "1908.02620", "submitter": "Yunxiang Zhang", "authors": "Yunxiang Zhang, Chenglong Zhao, Bingbing Ni, Jian Zhang, Haoran Deng", "title": "Exploiting Channel Similarity for Accelerating Deep Convolutional Neural\n  Networks", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the limitations of existing magnitude-based pruning algorithms in\ncases where model weights or activations are of large and similar magnitude, we\npropose a novel perspective to discover parameter redundancy among channels and\naccelerate deep CNNs via channel pruning. Precisely, we argue that channels\nrevealing similar feature information have functional overlap and that most\nchannels within each such similarity group can be removed without compromising\nmodel's representational power. After deriving an effective metric for\nevaluating channel similarity through probabilistic modeling, we introduce a\npruning algorithm via hierarchical clustering of channels. In particular, the\nproposed algorithm does not rely on sparsity training techniques or complex\ndata-driven optimization and can be directly applied to pre-trained models.\nExtensive experiments on benchmark datasets strongly demonstrate the superior\nacceleration performance of our approach over prior arts. On ImageNet, our\npruned ResNet-50 with 30% FLOPs reduced outperforms the baseline model.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 12:44:30 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Zhang", "Yunxiang", ""], ["Zhao", "Chenglong", ""], ["Ni", "Bingbing", ""], ["Zhang", "Jian", ""], ["Deng", "Haoran", ""]]}, {"id": "1908.02626", "submitter": "Marco Rudolph", "authors": "Marco Rudolph, Bastian Wandt and Bodo Rosenhahn", "title": "Structuring Autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose Structuring AutoEncoders (SAE). SAEs are neural\nnetworks which learn a low dimensional representation of data which are\nadditionally enriched with a desired structure in this low dimensional space.\nWhile traditional Autoencoders have proven to structure data naturally they\nfail to discover semantic structure that is hard to recognize in the raw data.\nThe SAE solves the problem by enhancing a traditional Autoencoder using weak\nsupervision to form a structured latent space. In the experiments we\ndemonstrate, that the structured latent space allows for a much more efficient\ndata representation for further tasks such as classification for sparsely\nlabeled data, an efficient choice of data to label, and morphing between\nclasses. To demonstrate the general applicability of our method, we show\nexperiments on the benchmark image datasets MNIST, Fashion-MNIST, DeepFashion2\nand on a dataset of 3D human shapes.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 13:29:11 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Rudolph", "Marco", ""], ["Wandt", "Bastian", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "1908.02641", "submitter": "Yair Horesh", "authors": "Yair Horesh, Noa Haas, Elhanan Mishraky, Yehezkel S. Resheff, Shir\n  Meir Lador", "title": "Paired-Consistency: An Example-Based Model-Agnostic Approach to Fairness\n  Regularization in Machine Learning", "comments": "ECML PKDD 2019, Data Science for social good workshop", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2019. Communications in Computer and Information Science, vol 1167. Springer,\n  Cham", "doi": "10.1007/978-3-030-43823-4_47", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As AI systems develop in complexity it is becoming increasingly hard to\nensure non-discrimination on the basis of protected attributes such as gender,\nage, and race. Many recent methods have been developed for dealing with this\nissue as long as the protected attribute is explicitly available for the\nalgorithm. We address the setting where this is not the case (with either no\nexplicit protected attribute, or a large set of them). Instead, we assume the\nexistence of a fair domain expert capable of generating an extension to the\nlabeled dataset - a small set of example pairs, each having a different value\non a subset of protected variables, but judged to warrant a similar model\nresponse. We define a performance metric - paired consistency. Paired\nconsistency measures how close the output (assigned by a classifier or a\nregressor) is on these carefully selected pairs of examples for which fairness\ndictates identical decisions. In some cases consistency can be embedded within\nthe loss function during optimization and serve as a fairness regularizer, and\nin others it is a tool for fair model selection. We demonstrate our method\nusing the well studied Income Census dataset.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 14:01:37 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 21:58:03 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Horesh", "Yair", ""], ["Haas", "Noa", ""], ["Mishraky", "Elhanan", ""], ["Resheff", "Yehezkel S.", ""], ["Lador", "Shir Meir", ""]]}, {"id": "1908.02718", "submitter": "Yan Shu", "authors": "Martin Mihelich, Charles Dognin, Yan Shu, Michael Blot", "title": "A Characterization of Mean Squared Error for Estimator with Bagging", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bagging can significantly improve the generalization performance of unstable\nmachine learning algorithms such as trees or neural networks. Though bagging is\nnow widely used in practice and many empirical studies have explored its\nbehavior, we still know little about the theoretical properties of bagged\npredictions. In this paper, we theoretically investigate how the bagging method\ncan reduce the Mean Squared Error (MSE) when applied on a statistical\nestimator. First, we prove that for any estimator, increasing the number of\nbagged estimators $N$ in the average can only reduce the MSE. This intuitive\nresult, observed empirically and discussed in the literature, has not yet been\nrigorously proved. Second, we focus on the standard estimator of variance\ncalled unbiased sample variance and we develop an exact analytical expression\nof the MSE for this estimator with bagging.\n  This allows us to rigorously discuss the number of iterations $N$ and the\nbatch size $m$ of the bagging method. From this expression, we state that only\nif the kurtosis of the distribution is greater than $\\frac{3}{2}$, the MSE of\nthe variance estimator can be reduced with bagging. This result is important\nbecause it demonstrates that for distribution with low kurtosis, bagging can\nonly deteriorate the performance of a statistical prediction. Finally, we\npropose a novel general-purpose algorithm to estimate with high precision the\nvariance of a sample.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 16:40:07 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Mihelich", "Martin", ""], ["Dognin", "Charles", ""], ["Shu", "Yan", ""], ["Blot", "Michael", ""]]}, {"id": "1908.02723", "submitter": "Ian Fox", "authors": "Ian Fox and Jenna Wiens", "title": "Advocacy Learning: Learning through Competition and Class-Conditional\n  Representations", "comments": "Accepted IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce advocacy learning, a novel supervised training scheme for\nattention-based classification problems. Advocacy learning relies on a\nframework consisting of two connected networks: 1) $N$ Advocates (one for each\nclass), each of which outputs an argument in the form of an attention map over\nthe input, and 2) a Judge, which predicts the class label based on these\narguments. Each Advocate produces a class-conditional representation with the\ngoal of convincing the Judge that the input example belongs to their class,\neven when the input belongs to a different class. Applied to several different\nclassification tasks, we show that advocacy learning can lead to small\nimprovements in classification accuracy over an identical supervised baseline.\nThough a series of follow-up experiments, we analyze when and how such\nclass-conditional representations improve discriminative performance. Though\nsomewhat counter-intuitive, a framework in which subnetworks are trained to\ncompetitively provide evidence in support of their class shows promise, in many\ncases performing on par with standard learning approaches. This provides a\nfoundation for further exploration into competition and class-conditional\nrepresentations in supervised learning.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 16:55:44 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Fox", "Ian", ""], ["Wiens", "Jenna", ""]]}, {"id": "1908.02729", "submitter": "Sho Yaida", "authors": "Judy Hoffman, Daniel A. Roberts, Sho Yaida", "title": "Robust Learning with Jacobian Regularization", "comments": "21 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design of reliable systems must guarantee stability against input\nperturbations. In machine learning, such guarantee entails preventing\noverfitting and ensuring robustness of models against corruption of input data.\nIn order to maximize stability, we analyze and develop a computationally\nefficient implementation of Jacobian regularization that increases\nclassification margins of neural networks. The stabilizing effect of the\nJacobian regularizer leads to significant improvements in robustness, as\nmeasured against both random and adversarial input perturbations, without\nseverely degrading generalization properties on clean data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 17:04:26 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Hoffman", "Judy", ""], ["Roberts", "Daniel A.", ""], ["Yaida", "Sho", ""]]}, {"id": "1908.02781", "submitter": "Amir Mosavi Prof", "authors": "Amir Mosavi, Pinar Ozturk, Kwok-wing Chau", "title": "Flood Prediction Using Machine Learning Models: Literature Review", "comments": "74 pages, 10 figures, 6 tables", "journal-ref": "Water 2018, 10, 1536", "doi": "10.3390/w10111536", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Floods are among the most destructive natural disasters, which are highly\ncomplex to model. The research on the advancement of flood prediction models\ncontributed to risk reduction, policy suggestion, minimization of the loss of\nhuman life, and reduction the property damage associated with floods. To mimic\nthe complex mathematical expressions of physical processes of floods, during\nthe past two decades, machine learning (ML) methods contributed highly in the\nadvancement of prediction systems providing better performance and\ncost-effective solutions. Due to the vast benefits and potential of ML, its\npopularity dramatically increased among hydrologists. Researchers through\nintroducing novel ML methods and hybridizing of the existing ones aim at\ndiscovering more accurate and efficient prediction models. The main\ncontribution of this paper is to demonstrate the state of the art of ML models\nin flood prediction and to give insight into the most suitable models. In this\npaper, the literature where ML models were benchmarked through a qualitative\nanalysis of robustness, accuracy, effectiveness, and speed are particularly\ninvestigated to provide an extensive overview on the various ML algorithms used\nin the field. The performance comparison of ML models presents an in-depth\nunderstanding of the different techniques within the framework of a\ncomprehensive evaluation and discussion. As a result, this paper introduces the\nmost promising prediction methods for both long-term and short-term floods.\nFurthermore, the major trends in improving the quality of the flood prediction\nmodels are investigated. Among them, hybridization, data decomposition,\nalgorithm ensemble, and model optimization are reported as the most effective\nstrategies for the improvement of ML methods.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 18:05:45 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Mosavi", "Amir", ""], ["Ozturk", "Pinar", ""], ["Chau", "Kwok-wing", ""]]}, {"id": "1908.02802", "submitter": "Roozbeh Yousefzadeh", "authors": "Roozbeh Yousefzadeh, Dianne P O'Leary", "title": "Investigating Decision Boundaries of Trained Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models have been the subject of study from various\nperspectives, for example, their training process, interpretation,\ngeneralization error, robustness to adversarial attacks, etc. A trained model\nis defined by its decision boundaries, and therefore, many of the studies about\ndeep learning models speculate about the decision boundaries, and sometimes\nmake simplifying assumptions about them. So far, finding exact points on the\ndecision boundaries of trained deep models has been considered an intractable\nproblem. Here, we compute exact points on the decision boundaries of these\nmodels and provide mathematical tools to investigate the surfaces that define\nthe decision boundaries. Through numerical results, we confirm that some of the\nspeculations about the decision boundaries are accurate, some of the\ncomputational methods can be improved, and some of the simplifying assumptions\nmay be unreliable, for models with nonlinear activation functions. We advocate\nfor verification of simplifying assumptions and approximation methods, wherever\nthey are used. Finally, we demonstrate that the computational practices used\nfor finding adversarial examples can be improved and computing the closest\npoint on the decision boundary reveals the weakest vulnerability of a model\nagainst adversarial attack.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 19:09:22 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Yousefzadeh", "Roozbeh", ""], ["O'Leary", "Dianne P", ""]]}, {"id": "1908.02810", "submitter": "Nithum Thain", "authors": "Flavien Prost, Nithum Thain, Tolga Bolukbasi", "title": "Debiasing Embeddings for Reduced Gender Bias in Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  (Bolukbasi et al., 2016) demonstrated that pretrained word embeddings can\ninherit gender bias from the data they were trained on. We investigate how this\nbias affects downstream classification tasks, using the case study of\noccupation classification (De-Arteaga et al.,2019). We show that traditional\ntechniques for debiasing embeddings can actually worsen the bias of the\ndownstream classifier by providing a less noisy channel for communicating\ngender information. With a relatively minor adjustment, however, we show how\nthese same techniques can be used to simultaneously reduce bias and maintain\nhigh classification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 19:46:11 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Prost", "Flavien", ""], ["Thain", "Nithum", ""], ["Bolukbasi", "Tolga", ""]]}, {"id": "1908.02830", "submitter": "Raphael Brito", "authors": "Raphael C. Brito and Hansenclever F. Bassani", "title": "Self-Organizing Maps with Variable Input Length for Motif Discovery and\n  Word Segmentation", "comments": null, "journal-ref": "IEEE International Joint Conference on Neural Networks (IJCNN),\n  1-8, July 2018", "doi": "10.1109/IJCNN.2018.8489090", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Time Series Motif Discovery (TSMD) is defined as searching for patterns that\nare previously unknown and appear with a given frequency in time series.\nAnother problem strongly related with TSMD is Word Segmentation. This problem\nhas received much attention from the community that studies early language\nacquisition in babies and toddlers. The development of biologically plausible\nmodels for word segmentation could greatly advance this field. Therefore, in\nthis article, we propose the Variable Input Length Map (VILMAP) for Motif\nDiscovery and Word Segmentation. The model is based on the Self-Organizing Maps\nand can identify Motifs with different lengths in time series. In our\nexperiments, we show that VILMAP presents good results in finding Motifs in a\nstandard Motif discovery dataset and can avoid catastrophic forgetting when\ntrained with datasets with increasing values of input size. We also show that\nVILMAP achieves results similar or superior to other methods in the literature\ndeveloped for the task of word segmentation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 20:52:19 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Brito", "Raphael C.", ""], ["Bassani", "Hansenclever F.", ""]]}, {"id": "1908.02831", "submitter": "Scott Gigante", "authors": "Scott Gigante, Adam S. Charles, Smita Krishnaswamy, Gal Mishne", "title": "Visualizing the PHATE of Neural Networks", "comments": null, "journal-ref": "Neural Information Processing Systems (2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding why and how certain neural networks outperform others is key to\nguiding future development of network architectures and optimization methods.\nTo this end, we introduce a novel visualization algorithm that reveals the\ninternal geometry of such networks: Multislice PHATE (M-PHATE), the first\nmethod designed explicitly to visualize how a neural network's hidden\nrepresentations of data evolve throughout the course of training. We\ndemonstrate that our visualization provides intuitive, detailed summaries of\nthe learning dynamics beyond simple global measures (i.e., validation loss and\naccuracy), without the need to access validation data. Furthermore, M-PHATE\nbetter captures both the dynamics and community structure of the hidden units\nas compared to visualization based on standard dimensionality reduction methods\n(e.g., ISOMAP, t-SNE). We demonstrate M-PHATE with two vignettes: continual\nlearning and generalization. In the former, the M-PHATE visualizations display\nthe mechanism of \"catastrophic forgetting\" which is a major challenge for\nlearning in task-switching contexts. In the latter, our visualizations reveal\nhow increased heterogeneity among hidden units correlates with improved\ngeneralization performance. An implementation of M-PHATE, along with scripts to\nreproduce the figures in this paper, is available at\nhttps://github.com/scottgigante/M-PHATE.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 20:53:30 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gigante", "Scott", ""], ["Charles", "Adam S.", ""], ["Krishnaswamy", "Smita", ""], ["Mishne", "Gal", ""]]}, {"id": "1908.02858", "submitter": "Tom Diethe", "authors": "Tom Diethe, Meelis Kull, Niall Twomey, Kacper Sokol, Hao Song, Miquel\n  Perello-Nieto, Emma Tonkin and Peter Flach", "title": "HyperStream: a Workflow Engine for Streaming Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes HyperStream, a large-scale, flexible and robust software\npackage, written in the Python language, for processing streaming data with\nworkflow creation capabilities. HyperStream overcomes the limitations of other\ncomputational engines and provides high-level interfaces to execute complex\nnesting, fusion, and prediction both in online and offline forms in streaming\nenvironments. HyperStream is a general purpose tool that is well-suited for the\ndesign, development, and deployment of Machine Learning algorithms and\npredictive models in a wide space of sequential predictive problems.\n  Source code, installation instructions, examples, and documentation can be\nfound at: https://github.com/IRC-SPHERE/HyperStream.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 22:08:57 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Diethe", "Tom", ""], ["Kull", "Meelis", ""], ["Twomey", "Niall", ""], ["Sokol", "Kacper", ""], ["Song", "Hao", ""], ["Perello-Nieto", "Miquel", ""], ["Tonkin", "Emma", ""], ["Flach", "Peter", ""]]}, {"id": "1908.02876", "submitter": "Shabnam Ghaffarzadegan", "authors": "Bongjun Kim and Shabnam Ghaffarzadegan", "title": "Self-supervised Attention Model for Weakly Labeled Audio Event\n  Classification", "comments": null, "journal-ref": "European Signal Processing Conference, EUSIPCO 2019", "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a novel weakly labeled Audio Event Classification approach based\non a self-supervised attention model. The weakly labeled framework is used to\neliminate the need for expensive data labeling procedure and self-supervised\nattention is deployed to help a model distinguish between relevant and\nirrelevant parts of a weakly labeled audio clip in a more effective manner\ncompared to prior attention models. We also propose a highly effective strongly\nsupervised attention model when strong labels are available. This model also\nserves as an upper bound for the self-supervised model. The performances of the\nmodel with self-supervised attention training are comparable to the strongly\nsupervised one which is trained using strong labels. We show that our\nself-supervised attention method is especially beneficial for short audio\nevents. We achieve 8.8% and 17.6% relative mean average precision improvements\nover the current state-of-the-art systems for SL-DCASE-17 and balanced\nAudioSet.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 23:48:34 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Kim", "Bongjun", ""], ["Ghaffarzadegan", "Shabnam", ""]]}, {"id": "1908.02878", "submitter": "Oscar Casta\\~neda", "authors": "Pengzhi Huang, Oscar Casta\\~neda, Emre G\\\"on\\\"ulta\\c{s}, Sa\\\"id\n  Medjkouh, Olav Tirkkonen, Tom Goldstein, Christoph Studer", "title": "Improving Channel Charting with Representation-Constrained Autoencoders", "comments": "Presented at the 20th IEEE International Workshop on Signal\n  Processing Advances in Wireless Communications (SPAWC), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Channel charting (CC) has been proposed recently to enable logical\npositioning of user equipments (UEs) in the neighborhood of a multi-antenna\nbase-station solely from channel-state information (CSI). CC relies on\ndimensionality reduction of high-dimensional CSI features in order to construct\na channel chart that captures spatial and radio geometries so that UEs close in\nspace are close in the channel chart. In this paper, we demonstrate that\nautoencoder (AE)-based CC can be augmented with side information that is\nobtained during the CSI acquisition process. More specifically, we propose to\ninclude pairwise representation constraints into AEs with the goal of improving\nthe quality of the learned channel charts. We show that such\nrepresentation-constrained AEs recover the global geometry of the learned\nchannel charts, which enables CC to perform approximate positioning without\nglobal navigation satellite systems or supervised learning methods that rely on\nextensive and expensive measurement campaigns.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 23:48:59 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Huang", "Pengzhi", ""], ["Casta\u00f1eda", "Oscar", ""], ["G\u00f6n\u00fclta\u015f", "Emre", ""], ["Medjkouh", "Sa\u00efd", ""], ["Tirkkonen", "Olav", ""], ["Goldstein", "Tom", ""], ["Studer", "Christoph", ""]]}, {"id": "1908.02894", "submitter": "Ellen Vitercik", "authors": "Maria-Florina Balcan, Dan DeBlasio, Travis Dick, Carl Kingsford,\n  Tuomas Sandholm, Ellen Vitercik", "title": "How much data is sufficient to learn high-performing algorithms?\n  Generalization guarantees for data-driven algorithm design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms often have tunable parameters that impact performance metrics such\nas runtime and solution quality. For many algorithms used in practice, no\nparameter settings admit meaningful worst-case bounds, so the parameters are\nmade available for the user to tune. Alternatively, parameters may be tuned\nimplicitly within the proof of a worst-case approximation ratio or runtime\nbound. Worst-case instances, however, may be rare or nonexistent in practice. A\ngrowing body of research has demonstrated that data-driven algorithm design can\nlead to significant improvements in performance. This approach uses a training\nset of problem instances sampled from an unknown, application-specific\ndistribution and returns a parameter setting with strong average performance on\nthe training set.\n  We provide a broadly applicable theory for deriving generalization guarantees\nthat bound the difference between the algorithm's average performance over the\ntraining set and its expected performance. Our results apply no matter how the\nparameters are tuned, be it via an automated or manual approach. The challenge\nis that for many types of algorithms, performance is a volatile function of the\nparameters: slightly perturbing the parameters can cause large changes in\nbehavior. Prior research has proved generalization bounds by employing\ncase-by-case analyses of greedy algorithms, clustering algorithms, integer\nprogramming algorithms, and selling mechanisms. We uncover a unifying structure\nwhich we use to prove extremely general guarantees, yet we recover the bounds\nfrom prior research. Our guarantees apply whenever an algorithm's performance\nis a piecewise-constant, -linear, or -- more generally -- piecewise-structured\nfunction of its parameters. Our theory also implies novel bounds for voting\nmechanisms and dynamic programming algorithms from computational biology.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 01:08:08 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 14:37:55 GMT"}, {"version": "v3", "created": "Sat, 26 Oct 2019 18:41:19 GMT"}, {"version": "v4", "created": "Sun, 25 Apr 2021 22:01:32 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Balcan", "Maria-Florina", ""], ["DeBlasio", "Dan", ""], ["Dick", "Travis", ""], ["Kingsford", "Carl", ""], ["Sandholm", "Tuomas", ""], ["Vitercik", "Ellen", ""]]}, {"id": "1908.02910", "submitter": "Y. X. Rachel Wang", "authors": "Tung-Yu Wu, Y. X. Rachel Wang, Wing H. Wong", "title": "Mini-batch Metropolis-Hastings MCMC with Reversible SGLD Proposal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional MCMC algorithms are computationally intensive and do not scale\nwell to large data. In particular, the Metropolis-Hastings (MH) algorithm\nrequires passing over the entire dataset to evaluate the likelihood ratio in\neach iteration. We propose a general framework for performing MH-MCMC using\nmini-batches of the whole dataset and show that this gives rise to\napproximately a tempered stationary distribution. We prove that the algorithm\npreserves the modes of the original target distribution and derive an error\nbound on the approximation with mild assumptions on the likelihood. To further\nextend the utility of the algorithm to high dimensional settings, we construct\na proposal with forward and reverse moves using stochastic gradient and show\nthat the construction leads to reasonable acceptance probabilities. We\ndemonstrate the performance of our algorithm in both low dimensional models and\nhigh dimensional neural network applications. Particularly in the latter case,\ncompared to popular optimization methods, our method is more robust to the\nchoice of learning rate and improves testing accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 03:06:12 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 14:14:42 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Wu", "Tung-Yu", ""], ["Wang", "Y. X. Rachel", ""], ["Wong", "Wing H.", ""]]}, {"id": "1908.02947", "submitter": "Sourav Mukherjee", "authors": "Sourav Mukherjee, Tim Oates, Ryan Wright", "title": "Graph Node Embeddings using Domain-Aware Biased Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent proliferation of publicly available graph-structured data has\nsparked an interest in machine learning algorithms for graph data. Since most\ntraditional machine learning algorithms assume data to be tabular, embedding\nalgorithms for mapping graph data to real-valued vector spaces has become an\nactive area of research. Existing graph embedding approaches are based purely\non structural information and ignore any semantic information from the\nunderlying domain. In this paper, we demonstrate that semantic information can\nplay a useful role in computing graph embeddings. Specifically, we present a\nframework for devising embedding strategies aware of domain-specific\ninterpretations of graph nodes and edges, and use knowledge of downstream\nmachine learning tasks to identify relevant graph substructures. Using two\nreal-life domains, we show that our framework yields embeddings that are simple\nto implement and yet achieve equal or greater accuracy in machine learning\ntasks compared to domain independent approaches.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 06:45:05 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Mukherjee", "Sourav", ""], ["Oates", "Tim", ""], ["Wright", "Ryan", ""]]}, {"id": "1908.02964", "submitter": "Francois-Xavier Briol", "authors": "Francois-Xavier Briol, Francisco A. Diaz De la O, Peter O. Hristov", "title": "Contributed Discussion of \"A Bayesian Conjugate Gradient Method\"", "comments": "Paper in press at \"Bayesian Analysis\", and will be published\n  alongside \"A Bayesian Conjugate Gradient Method\" by J. Cockayne, C. Oates, I.\n  Ipsen and M. Girolami (doi:10.1214/19-BA1145, arXiv:1801.05242)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We would like to congratulate the authors of \"A Bayesian Conjugate Gradient\nMethod\" on their insightful paper, and welcome this publication which we firmly\nbelieve will become a fundamental contribution to the growing field of\nprobabilistic numerical methods and in particular the sub-field of Bayesian\nnumerical methods. In this short piece, which will be published as a comment\nalongside the main paper, we first initiate a discussion on the choice of\npriors for solving linear systems, then propose an extension of the Bayesian\nconjugate gradient (BayesCG) algorithm for solving several related linear\nsystems simultaneously.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 08:13:13 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Briol", "Francois-Xavier", ""], ["De la O", "Francisco A. Diaz", ""], ["Hristov", "Peter O.", ""]]}, {"id": "1908.02974", "submitter": "Limei Cheng", "authors": "Tianhao Chen, Limei Cheng, Yang Liu, Wenchuan Jia and Shugen Ma", "title": "Incremental Reinforcement Learning --- a New Continuous Reinforcement\n  Learning Frame Based on Stochastic Differential Equation methods", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous reinforcement learning such as DDPG and A3C are widely used in\nrobot control and autonomous driving. However, both methods have theoretical\nweaknesses. While DDPG cannot control noises in the control process, A3C does\nnot satisfy the continuity conditions under the Gaussian policy. To address\nthese concerns, we propose a new continues reinforcement learning method based\non stochastic differential equations and we call it Incremental Reinforcement\nLearning (IRL). This method not only guarantees the continuity of actions\nwithin any time interval, but controls the variance of actions in the training\nprocess. In addition, our method does not assume Markov control in agents'\naction control and allows agents to predict scene changes for action selection.\nWith our method, agents no longer passively adapt to the environment. Instead,\nthey positively interact with the environment for maximum rewards.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 08:38:11 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Chen", "Tianhao", ""], ["Cheng", "Limei", ""], ["Liu", "Yang", ""], ["Jia", "Wenchuan", ""], ["Ma", "Shugen", ""]]}, {"id": "1908.02984", "submitter": "Seokil Hong", "authors": "Dongmin Park, Seokil Hong, Bohyung Han, Kyoung Mu Lee", "title": "Continual Learning by Asymmetric Loss Approximation with Single-Side\n  Overestimation", "comments": "ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic forgetting is a critical challenge in training deep neural\nnetworks. Although continual learning has been investigated as a countermeasure\nto the problem, it often suffers from the requirements of additional network\ncomponents and the limited scalability to a large number of tasks. We propose a\nnovel approach to continual learning by approximating a true loss function\nusing an asymmetric quadratic function with one of its sides overestimated. Our\nalgorithm is motivated by the empirical observation that the network parameter\nupdates affect the target loss functions asymmetrically. In the proposed\ncontinual learning framework, we estimate an asymmetric loss function for the\ntasks considered in the past through a proper overestimation of its unobserved\nsides in training new tasks, while deriving the accurate model parameter for\nthe observable sides. In contrast to existing approaches, our method is free\nfrom the side effects and achieves the state-of-the-art accuracy that is even\nclose to the upper-bound performance on several challenging benchmark datasets.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 09:21:21 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 03:25:38 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Park", "Dongmin", ""], ["Hong", "Seokil", ""], ["Han", "Bohyung", ""], ["Lee", "Kyoung Mu", ""]]}, {"id": "1908.03015", "submitter": "Felix Berkhahn", "authors": "Felix Berkhahn, Richard Keys, Wajih Ouertani, Nikhil Shetty, and\n  Dominik Gei{\\ss}ler", "title": "Augmenting Variational Autoencoders with Sparse Labels: A Unified\n  Framework for Unsupervised, Semi-(un)supervised, and Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a new flavor of Variational Autoencoder (VAE) that interpolates\nseamlessly between unsupervised, semi-supervised and fully supervised learning\ndomains. We show that unlabeled datapoints not only boost unsupervised tasks,\nbut also the classification performance. Vice versa, every label not only\nimproves classification, but also unsupervised tasks. The proposed architecture\nis simple: A classification layer is connected to the topmost encoder layer,\nand then combined with the resampled latent layer for the decoder. The usual\nevidence lower bound (ELBO) loss is supplemented with a supervised loss target\non this classification layer that is only applied for labeled datapoints. This\nsimplicity allows for extending any existing VAE model to our proposed\nsemi-supervised framework with minimal effort. In the context of\nclassification, we found that this approach even outperforms a direct\nsupervised setup.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 11:07:22 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2019 13:58:00 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["Berkhahn", "Felix", ""], ["Keys", "Richard", ""], ["Ouertani", "Wajih", ""], ["Shetty", "Nikhil", ""], ["Gei\u00dfler", "Dominik", ""]]}, {"id": "1908.03032", "submitter": "Michael Rapp", "authors": "Michael Rapp, Eneldo Loza Menc\\'ia, Johannes F\\\"urnkranz", "title": "On the Trade-off Between Consistency and Coverage in Multi-label Rule\n  Learning Heuristics", "comments": "Preprint version. To appear in Proceedings of the 22nd International\n  Conference on Discovery Science, 2019", "journal-ref": "Proc. DS 2019: 96-111", "doi": "10.1007/978-3-030-33778-0_9", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several authors have advocated the use of rule learning algorithms\nto model multi-label data, as rules are interpretable and can be comprehended,\nanalyzed, or qualitatively evaluated by domain experts. Many rule learning\nalgorithms employ a heuristic-guided search for rules that model regularities\ncontained in the training data and it is commonly accepted that the choice of\nthe heuristic has a significant impact on the predictive performance of the\nlearner. Whereas the properties of rule learning heuristics have been studied\nin the realm of single-label classification, there is no such work taking into\naccount the particularities of multi-label classification. This is surprising,\nas the quality of multi-label predictions is usually assessed in terms of a\nvariety of different, potentially competing, performance measures that cannot\nall be optimized by a single learner at the same time. In this work, we show\nempirically that it is crucial to trade off the consistency and coverage of\nrules differently, depending on which multi-label measure should be optimized\nby a model. Based on these findings, we emphasize the need for configurable\nlearners that can flexibly use different heuristics. As our experiments reveal,\nthe choice of the heuristic is not straight-forward, because a search for rules\nthat optimize a measure locally does usually not result in a model that\nmaximizes that measure globally.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 12:13:18 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Rapp", "Michael", ""], ["Menc\u00eda", "Eneldo Loza", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "1908.03054", "submitter": "Shruti Gupta", "authors": "Shruti Gupta, Md. Shah Fahad, Akshay Deepak", "title": "Pitch-Synchronous Single Frequency Filtering Spectrogram for Speech\n  Emotion Recognition", "comments": "11 pages and less than 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNN) are widely used for speech emotion\nrecognition (SER). In such cases, the short time fourier transform (STFT)\nspectrogram is the most popular choice for representing speech, which is fed as\ninput to the CNN. However, the uncertainty principles of the short-time Fourier\ntransform prevent it from capturing time and frequency resolutions\nsimultaneously. On the other hand, the recently proposed single frequency\nfiltering (SFF) spectrogram promises to be a better alternative because it\ncaptures both time and frequency resolutions simultaneously. In this work, we\nexplore the SFF spectrogram as an alternative representation of speech for SER.\nWe have modified the SFF spectrogram by taking the average of the amplitudes of\nall the samples between two successive glottal closure instants (GCI)\nlocations. The duration between two successive GCI locations gives the pitch,\nmotivating us to name the modified SFF spectrogram as pitch-synchronous SFF\nspectrogram. The GCI locations were detected using zero frequency filtering\napproach. The proposed pitch-synchronous SFF spectrogram produced accuracy\nvalues of 63.95% (unweighted) and 70.4% (weighted) on the IEMOCAP dataset.\nThese correspond to an improvement of +7.35% (unweighted) and +4.3% (weighted)\nover state-of-the-art result on the STFT sepctrogram using CNN. Specially, the\nproposed method recognized 22.7% of the happy emotion samples correctly,\nwhereas this number was 0% for state-of-the-art results. These results also\npromise a much wider use of the proposed pitch-synchronous SFF spectrogram for\nother speech-based applications.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 11:49:58 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Gupta", "Shruti", ""], ["Fahad", "Md. Shah", ""], ["Deepak", "Akshay", ""]]}, {"id": "1908.03077", "submitter": "Selvaprabu Nadarajah", "authors": "Qihang Lin, Selvaprabu Nadarajah, Negar Soheili, Tianbao Yang", "title": "A Data Efficient and Feasible Level Set Method for Stochastic Convex\n  Optimization with Expectation Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic convex optimization problems with expectation constraints (SOECs)\nare encountered in statistics and machine learning, business, and engineering.\nIn data-rich environments, the SOEC objective and constraints contain\nexpectations defined with respect to large datasets. Therefore, efficient\nalgorithms for solving such SOECs need to limit the fraction of data points\nthat they use, which we refer to as algorithmic data complexity. Recent\nstochastic first order methods exhibit low data complexity when handling SOECs\nbut guarantee near-feasibility and near-optimality only at convergence. These\nmethods may thus return highly infeasible solutions when heuristically\nterminated, as is often the case, due to theoretical convergence criteria being\nhighly conservative. This issue limits the use of first order methods in\nseveral applications where the SOEC constraints encode implementation\nrequirements. We design a stochastic feasible level set method (SFLS) for SOECs\nthat has low data complexity and emphasizes feasibility before convergence.\nSpecifically, our level-set method solves a root-finding problem by calling a\nnovel first order oracle that computes a stochastic upper bound on the\nlevel-set function by extending mirror descent and online validation\ntechniques. We establish that SFLS maintains a high-probability feasible\nsolution at each root-finding iteration and exhibits favorable iteration\ncomplexity compared to state-of-the-art deterministic feasible level set and\nstochastic subgradient methods. Numerical experiments on three diverse\napplications validate the low data complexity of SFLS relative to the former\napproach and highlight how SFLS finds feasible solutions with small optimality\ngaps significantly faster than the latter method.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 12:59:19 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 01:03:49 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Lin", "Qihang", ""], ["Nadarajah", "Selvaprabu", ""], ["Soheili", "Negar", ""], ["Yang", "Tianbao", ""]]}, {"id": "1908.03097", "submitter": "Minh-Ngoc Tran", "authors": "Minh-Ngoc Tran and Dang H. Nguyen and Duy Nguyen", "title": "Variational Bayes on Manifolds", "comments": "31 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational Bayes (VB) has become a widely-used tool for Bayesian inference\nin statistics and machine learning. Nonetheless, the development of the\nexisting VB algorithms is so far generally restricted to the case where the\nvariational parameter space is Euclidean, which hinders the potential broad\napplication of VB methods. This paper extends the scope of VB to the case where\nthe variational parameter space is a Riemannian manifold. We develop an\nefficient manifold-based VB algorithm that exploits both the geometric\nstructure of the constraint parameter space and the information geometry of the\nmanifold of VB approximating probability distributions. Our algorithm is\nprovably convergent and achieves a convergence rate of order $\\mathcal\nO(1/\\sqrt{T})$ and $\\mathcal O(1/T^{2-2\\epsilon})$ for a non-convex evidence\nlower bound function and a strongly retraction-convex evidence lower bound\nfunction, respectively. We develop in particular two manifold VB algorithms,\nManifold Gaussian VB and Manifold Neural Net VB, and demonstrate through\nnumerical experiments that the proposed algorithms are stable, less sensitive\nto initialization and compares favourably to existing VB methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 14:38:31 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 00:48:23 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Tran", "Minh-Ngoc", ""], ["Nguyen", "Dang H.", ""], ["Nguyen", "Duy", ""]]}, {"id": "1908.03109", "submitter": "Rishiraj Saha Roy", "authors": "Azin Ghazimatin, Rishiraj Saha Roy, Gerhard Weikum", "title": "FAIRY: A Framework for Understanding Relationships between Users'\n  Actions and their Social Feeds", "comments": "WSDM 2019", "journal-ref": "WSDM 2019", "doi": "10.1145/3289600.3290990", "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users increasingly rely on social media feeds for consuming daily\ninformation. The items in a feed, such as news, questions, songs, etc., usually\nresult from the complex interplay of a user's social contacts, her interests\nand her actions on the platform. The relationship of the user's own behavior\nand the received feed is often puzzling, and many users would like to have a\nclear explanation on why certain items were shown to them. Transparency and\nexplainability are key concerns in the modern world of cognitive overload,\nfilter bubbles, user tracking, and privacy risks. This paper presents FAIRY, a\nframework that systematically discovers, ranks, and explains relationships\nbetween users' actions and items in their social media feeds. We model the\nuser's local neighborhood on the platform as an interaction graph, a form of\nheterogeneous information network constructed solely from information that is\neasily accessible to the concerned user. We posit that paths in this\ninteraction graph connecting the user and her feed items can act as pertinent\nexplanations for the user. These paths are scored with a learning-to-rank model\nthat captures relevance and surprisal. User studies on two social platforms\ndemonstrate the practical viability and user benefits of the FAIRY method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 15:08:35 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 15:04:30 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Ghazimatin", "Azin", ""], ["Roy", "Rishiraj Saha", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1908.03129", "submitter": "Tom Edinburgh", "authors": "Tom Edinburgh, Peter Smielewski, Marek Czosnyka, Stephen J. Eglen, Ari\n  Ercole", "title": "DeepClean -- self-supervised artefact rejection for intensive care\n  waveform data using deep generative learning", "comments": "12 pages, 7 figures, 2 tables; typos corrected, minor changes\n  (results unchanged)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Waveform physiological data is important in the treatment of critically ill\npatients in the intensive care unit. Such recordings are susceptible to\nartefacts, which must be removed before the data can be re-used for alerting or\nreprocessed for other clinical or research purposes. Accurate removal of\nartefacts reduces bias and uncertainty in clinical assessment, as well as the\nfalse positive rate of intensive care unit alarms, and is therefore a key\ncomponent in providing optimal clinical care. In this work, we present\nDeepClean; a prototype self-supervised artefact detection system using a\nconvolutional variational autoencoder deep neural network that avoids costly\nand painstaking manual annotation, requiring only easily-obtained 'good' data\nfor training. For a test case with invasive arterial blood pressure, we\ndemonstrate that our algorithm can detect the presence of an artefact within a\n10-second sample of data with sensitivity and specificity around 90%.\nFurthermore, DeepClean was able to identify regions of artefact within such\nsamples with high accuracy and we show that it significantly outperforms a\nbaseline principle component analysis approach in both signal reconstruction\nand artefact detection. DeepClean learns a generative model and therefore may\nalso be used for imputation of missing data.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 15:41:04 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 10:16:14 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 15:55:53 GMT"}, {"version": "v4", "created": "Sun, 5 Jan 2020 18:16:39 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Edinburgh", "Tom", ""], ["Smielewski", "Peter", ""], ["Czosnyka", "Marek", ""], ["Eglen", "Stephen J.", ""], ["Ercole", "Ari", ""]]}, {"id": "1908.03156", "submitter": "Jayadev Acharya", "authors": "Jayadev Acharya, Ananda Theertha Suresh", "title": "Optimal multiclass overfitting by sequence reconstruction from Hamming\n  queries", "comments": "extended the results to unknown test set case", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A primary concern of excessive reuse of test datasets in machine learning is\nthat it can lead to overfitting. Multiclass classification was recently shown\nto be more resistant to overfitting than binary classification. In an open\nproblem of COLT 2019, Feldman, Frostig, and Hardt ask to characterize the\ndependence of the amount of overfitting bias with the number of classes $m$,\nthe number of accuracy queries $k$, and the number of examples in the dataset\n$n$. We resolve this problem and determine the amount of overfitting possible\nin multi-class classification. We provide computationally efficient algorithms\nthat achieve overfitting bias of $\\tilde{\\Theta}(\\max\\{\\sqrt{{k}/{(mn)}},\nk/n\\})$, matching the known upper bounds.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 16:34:06 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 14:04:32 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Acharya", "Jayadev", ""], ["Suresh", "Ananda Theertha", ""]]}, {"id": "1908.03173", "submitter": "Sajjad Abdoli", "authors": "Sajjad Abdoli, Luiz G. Hafemann, Jerome Rony, Ismail Ben Ayed, Patrick\n  Cardinal, Alessandro L. Koerich", "title": "Universal Adversarial Audio Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate the existence of universal adversarial perturbations, which\ncan fool a family of audio classification architectures, for both targeted and\nuntargeted attack scenarios. We propose two methods for finding such\nperturbations. The first method is based on an iterative, greedy approach that\nis well-known in computer vision: it aggregates small perturbations to the\ninput so as to push it to the decision boundary. The second method, which is\nthe main contribution of this work, is a novel penalty formulation, which finds\ntargeted and untargeted universal adversarial perturbations. Differently from\nthe greedy approach, the penalty method minimizes an appropriate objective\nfunction on a batch of samples. Therefore, it produces more successful attacks\nwhen the number of training samples is limited. Moreover, we provide a proof\nthat the proposed penalty method theoretically converges to a solution that\ncorresponds to universal adversarial perturbations. We also demonstrate that it\nis possible to provide successful attacks using the penalty method when only\none sample from the target dataset is available for the attacker. Experimental\nresults on attacking various 1D CNN architectures have shown attack success\nrates higher than 85.0% and 83.1% for targeted and untargeted attacks,\nrespectively using the proposed penalty method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 17:07:30 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 15:52:28 GMT"}, {"version": "v3", "created": "Tue, 26 Nov 2019 21:51:14 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 21:16:48 GMT"}, {"version": "v5", "created": "Tue, 17 Nov 2020 00:42:45 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Abdoli", "Sajjad", ""], ["Hafemann", "Luiz G.", ""], ["Rony", "Jerome", ""], ["Ayed", "Ismail Ben", ""], ["Cardinal", "Patrick", ""], ["Koerich", "Alessandro L.", ""]]}, {"id": "1908.03176", "submitter": "Sobhan Soleymani", "authors": "Sobhan Soleymani, Ali Dabouei, Jeremy Dawson, Nasser M. Nasrabadi", "title": "Defending Against Adversarial Iris Examples Using Wavelet Decomposition", "comments": "The Tenth IEEE International Conference on Biometrics: Theory,\n  Applications, and Systems (BTAS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have presented impressive performance in biometric\napplications. However, their performance is highly at risk when facing\ncarefully crafted input samples known as adversarial examples. In this paper,\nwe present three defense strategies to detect adversarial iris examples. These\ndefense strategies are based on wavelet domain denoising of the input examples\nby investigating each wavelet sub-band and removing the sub-bands that are most\naffected by the adversary. The first proposed defense strategy reconstructs\nmultiple denoised versions of the input example through manipulating the mid-\nand high-frequency components of the wavelet domain representation of the input\nexample and makes a decision upon the classification result of the majority of\nthe denoised examples. The second and third proposed defense strategies aim to\ndenoise each wavelet domain sub-band and determine the sub-bands that are most\nlikely affected by the adversary using the reconstruction error computed for\neach sub-band. We test the performance of the proposed defense strategies\nagainst several attack scenarios and compare the results with five state of the\nart defense strategies.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 17:08:25 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Soleymani", "Sobhan", ""], ["Dabouei", "Ali", ""], ["Dawson", "Jeremy", ""], ["Nasrabadi", "Nasser M.", ""]]}, {"id": "1908.03190", "submitter": "Hayden Schaeffer", "authors": "Yifan Sun, Linan Zhang, and Hayden Schaeffer", "title": "NeuPDE: Neural Network Based Ordinary and Partial Differential Equations\n  for Modeling Time-Dependent Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neural network based approach for extracting models from dynamic\ndata using ordinary and partial differential equations. In particular, given a\ntime-series or spatio-temporal dataset, we seek to identify an accurate\ngoverning system which respects the intrinsic differential structure. The\nunknown governing model is parameterized by using both (shallow) multilayer\nperceptrons and nonlinear differential terms, in order to incorporate relevant\ncorrelations between spatio-temporal samples. We demonstrate the approach on\nseveral examples where the data is sampled from various dynamical systems and\ngive a comparison to recurrent networks and other data-discovery methods. In\naddition, we show that for MNIST and Fashion MNIST, our approach lowers the\nparameter cost as compared to other deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 17:50:22 GMT"}], "update_date": "2019-08-09", "authors_parsed": [["Sun", "Yifan", ""], ["Zhang", "Linan", ""], ["Schaeffer", "Hayden", ""]]}, {"id": "1908.03250", "submitter": "Fabrizio Ventola", "authors": "Fabrizio Ventola, Karl Stelzner, Alejandro Molina and Kristian\n  Kersting", "title": "Random Sum-Product Forests with Residual Links", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tractable yet expressive density estimators are a key building block of\nprobabilistic machine learning. While sum-product networks (SPNs) offer\nattractive inference capabilities, obtaining structures large enough to fit\ncomplex, high-dimensional data has proven challenging. In this paper, we\npresent random sum-product forests (RSPFs), an ensemble approach for mixing\nmultiple randomly generated SPNs. We also introduce residual links, which\nreference specialized substructures of other component SPNs in order to\nleverage the context-specific knowledge encoded within them. Our empirical\nevidence demonstrates that RSPFs provide better performance than their\nindividual components. Adding residual links improves the models further,\nallowing the resulting ResSPNs to be competitive with commonly used structure\nlearning methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 19:55:03 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Ventola", "Fabrizio", ""], ["Stelzner", "Karl", ""], ["Molina", "Alejandro", ""], ["Kersting", "Kristian", ""]]}, {"id": "1908.03263", "submitter": "Ching-An Cheng", "authors": "Ching-An Cheng, Xinyan Yan, Byron Boots", "title": "Trajectory-wise Control Variates for Variance Reduction in Policy\n  Gradient Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods have demonstrated success in reinforcement learning\ntasks that have high-dimensional continuous state and action spaces. However,\npolicy gradient methods are also notoriously sample inefficient. This can be\nattributed, at least in part, to the high variance in estimating the gradient\nof the task objective with Monte Carlo methods. Previous research has\nendeavored to contend with this problem by studying control variates (CVs) that\ncan reduce the variance of estimates without introducing bias, including the\nearly use of baselines, state dependent CVs, and the more recent state-action\ndependent CVs. In this work, we analyze the properties and drawbacks of\nprevious CV techniques and, surprisingly, we find that these works have\noverlooked an important fact that Monte Carlo gradient estimates are generated\nby trajectories of states and actions. We show that ignoring the correlation\nacross the trajectories can result in suboptimal variance reduction, and we\npropose a simple fix: a class of \"trajectory-wise\" CVs, that can further drive\ndown the variance. We show that constructing trajectory-wise CVs can be done\nrecursively and requires only learning state-action value functions like the\nprevious CVs for policy gradient. We further prove that the proposed\ntrajectory-wise CVs are optimal for variance reduction under reasonable\nassumptions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 20:35:53 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Cheng", "Ching-An", ""], ["Yan", "Xinyan", ""], ["Boots", "Byron", ""]]}, {"id": "1908.03265", "submitter": "Liyuan Liu", "authors": "Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu,\n  Jianfeng Gao, Jiawei Han", "title": "On the Variance of the Adaptive Learning Rate and Beyond", "comments": "ICLR 2020. Fix several typos in the previous version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The learning rate warmup heuristic achieves remarkable success in stabilizing\ntraining, accelerating convergence and improving generalization for adaptive\nstochastic optimization algorithms like RMSprop and Adam. Here, we study its\nmechanism in details. Pursuing the theory behind warmup, we identify a problem\nof the adaptive learning rate (i.e., it has problematically large variance in\nthe early stage), suggest warmup works as a variance reduction technique, and\nprovide both empirical and theoretical evidence to verify our hypothesis. We\nfurther propose RAdam, a new variant of Adam, by introducing a term to rectify\nthe variance of the adaptive learning rate. Extensive experimental results on\nimage classification, language modeling, and neural machine translation verify\nour intuition and demonstrate the effectiveness and robustness of our proposed\nmethod. All implementations are available at:\nhttps://github.com/LiyuanLucasLiu/RAdam.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 20:51:17 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 02:35:43 GMT"}, {"version": "v3", "created": "Fri, 17 Apr 2020 15:03:56 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Liu", "Liyuan", ""], ["Jiang", "Haoming", ""], ["He", "Pengcheng", ""], ["Chen", "Weizhu", ""], ["Liu", "Xiaodong", ""], ["Gao", "Jianfeng", ""], ["Han", "Jiawei", ""]]}, {"id": "1908.03270", "submitter": "Josh Payne", "authors": "Mustafa Canim, Ashish Kundu, Josh Payne", "title": "Uncheatable Machine Learning Inference", "comments": "Work-in-progress. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification-as-a-Service (CaaS) is widely deployed today in machine\nintelligence stacks for a vastly diverse set of applications including anything\nfrom medical prognosis to computer vision tasks to natural language processing\nto identity fraud detection. The computing power required for training complex\nmodels on large datasets to perform inference to solve these problems can be\nvery resource-intensive. A CaaS provider may cheat a customer by fraudulently\nbypassing expensive training procedures in favor of weaker, less\ncomputationally-intensive algorithms which yield results of reduced quality.\nGiven a classification service supplier $S$, intermediary CaaS provider $P$\nclaiming to use $S$ as a classification backend, and customer $C$, our work\naddresses the following questions: (i) how can $P$'s claim to be using $S$ be\nverified by $C$? (ii) how might $S$ make performance guarantees that may be\nverified by $C$? and (iii) how might one design a decentralized system that\nincentivizes service proofing and accountability? To this end, we propose a\nvariety of methods for $C$ to evaluate the service claims made by $P$ using\nprobabilistic performance metrics, instance seeding, and steganography. We also\npropose a method of measuring the robustness of a model using a blackbox\nadversarial procedure, which may then be used as a benchmark or comparison to a\nclaim made by $S$. Finally, we propose the design of a smart contract-based\ndecentralized system that incentivizes service accountability to serve as a\ntrusted Quality of Service (QoS) auditor.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 21:29:00 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Canim", "Mustafa", ""], ["Kundu", "Ashish", ""], ["Payne", "Josh", ""]]}, {"id": "1908.03299", "submitter": "Yuma Koizumi", "authors": "Yuma Koizumi, Shoichiro Saito, Hisashi Uematsu, Noboru Harada, and\n  Keisuke Imoto", "title": "ToyADMOS: A Dataset of Miniature-Machine Operating Sounds for Anomalous\n  Sound Detection", "comments": "5 pages, to appear in IEEE WASPAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new dataset called \"ToyADMOS\" designed for anomaly\ndetection in machine operating sounds (ADMOS). To the best our knowledge, no\nlarge-scale datasets are available for ADMOS, although large-scale datasets\nhave contributed to recent advancements in acoustic signal processing. This is\nbecause anomalous sound data are difficult to collect. To build a large-scale\ndataset for ADMOS, we collected anomalous operating sounds of miniature\nmachines (toys) by deliberately damaging them. The released dataset consists of\nthree sub-datasets for machine-condition inspection, fault diagnosis of\nmachines with geometrically fixed tasks, and fault diagnosis of machines with\nmoving tasks. Each sub-dataset includes over 180 hours of normal\nmachine-operating sounds and over 4,000 samples of anomalous sounds collected\nwith four microphones at a 48-kHz sampling rate. The dataset is freely\navailable for download at https://github.com/YumaKoizumi/ToyADMOS-dataset\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 03:52:08 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Koizumi", "Yuma", ""], ["Saito", "Shoichiro", ""], ["Uematsu", "Hisashi", ""], ["Harada", "Noboru", ""], ["Imoto", "Keisuke", ""]]}, {"id": "1908.03367", "submitter": "Pierre Humbert", "authors": "Pierre Humbert (CMLA), Julien Audiffren (CMLA), Laurent Oudre (L2TI),\n  Nicolas Vayatis (CMLA)", "title": "Multivariate Convolutional Sparse Coding with Low Rank Tensor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new multivariate convolutional sparse coding based on\ntensor algebra with a general model enforcing both element-wise sparsity and\nlow-rankness of the activations tensors. By using the CP decomposition, this\nmodel achieves a significantly more efficient encoding of the multivariate\nsignal-particularly in the high order/ dimension setting-resulting in better\nperformance. We prove that our model is closely related to the Kruskal tensor\nregression problem, offering interesting theoretical guarantees to our setting.\nFurthermore, we provide an efficient optimization algorithm based on\nalternating optimization to solve this model. Finally, we evaluate our\nalgorithm with a large range of experiments, highlighting its advantages and\nlimitations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 08:47:45 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Humbert", "Pierre", "", "CMLA"], ["Audiffren", "Julien", "", "CMLA"], ["Oudre", "Laurent", "", "L2TI"], ["Vayatis", "Nicolas", "", "CMLA"]]}, {"id": "1908.03385", "submitter": "Miaojun Bai", "authors": "Miaojun Bai, Yan Zheng and Yun Shen", "title": "Gradient Boosting Survival Tree with Applications in Credit Scoring", "comments": "26 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credit scoring plays a vital role in the field of consumer finance. Survival\nanalysis provides an advanced solution to the credit-scoring problem by\nquantifying the probability of survival time. In order to deal with highly\nheterogeneous industrial data collected in Chinese market of consumer finance,\nwe propose a nonparametric ensemble tree model called gradient boosting\nsurvival tree (GBST) that extends the survival tree models with a gradient\nboosting algorithm. The survival tree ensemble is learned by minimizing the\nnegative log-likelihood in an additive manner. The proposed model optimizes the\nsurvival probability simultaneously for each time period, which can reduce the\noverall error significantly. Finally, as a test of the applicability, we apply\nthe GBST model to quantify the credit risk with large-scale real market\ndatasets. The results show that the GBST model outperforms the existing\nsurvival models measured by the concordance index (C-index), Kolmogorov-Smirnov\n(KS) index, as well as by the area under the receiver operating characteristic\ncurve (AUC) of each time period.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 09:37:28 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 09:54:06 GMT"}, {"version": "v3", "created": "Thu, 13 Feb 2020 23:35:53 GMT"}, {"version": "v4", "created": "Tue, 17 Nov 2020 05:45:16 GMT"}, {"version": "v5", "created": "Mon, 12 Apr 2021 06:51:35 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Bai", "Miaojun", ""], ["Zheng", "Yan", ""], ["Shen", "Yun", ""]]}, {"id": "1908.03405", "submitter": "Patrick Sch\\\"afer", "authors": "P. Sch\\\"afer and U. Leser", "title": "TEASER: Early and Accurate Time Series Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early time series classification (eTSC) is the problem of classifying a time\nseries after as few measurements as possible with the highest possible\naccuracy. The most critical issue of any eTSC method is to decide when enough\ndata of a time series has been seen to take a decision: Waiting for more data\npoints usually makes the classification problem easier but delays the time in\nwhich a classification is made; in contrast, earlier classification has to cope\nwith less input data, often leading to inferior accuracy. The state-of-the-art\neTSC methods compute a fixed optimal decision time assuming that every times\nseries has the same defined start time (like turning on a machine). However, in\nmany real-life applications measurements start at arbitrary times (like\nmeasuring heartbeats of a patient), implying that the best time for taking a\ndecision varies heavily between time series. We present TEASER, a novel\nalgorithm that models eTSC as a two two-tier classification problem: In the\nfirst tier, a classifier periodically assesses the incoming time series to\ncompute class probabilities. However, these class probabilities are only used\nas output label if a second-tier classifier decides that the predicted label is\nreliable enough, which can happen after a different number of measurements. In\nan evaluation using 45 benchmark datasets, TEASER is two to three times earlier\nat predictions than its competitors while reaching the same or an even higher\nclassification accuracy. We further show TEASER's superior performance using\nreal-life use cases, namely energy monitoring, and gait detection.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 10:49:07 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 10:19:56 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sch\u00e4fer", "P.", ""], ["Leser", "U.", ""]]}, {"id": "1908.03440", "submitter": "Paolo Galeone", "authors": "Alessia Bertugli, Paolo Galeone", "title": "Learning to Grasp from 2.5D images: a Deep Reinforcement Learning\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a deep reinforcement learning (DRL) solution to the\ngrasping problem using 2.5D images as the only source of information. In\nparticular, we developed a simulated environment where a robot equipped with a\nvacuum gripper has the aim of reaching blocks with planar surfaces. These\nblocks can have different dimensions, shapes, position and orientation. Unity\n3D allowed us to simulate a real-world setup, where a depth camera is placed in\na fixed position and the stream of images is used by our policy network to\nlearn how to solve the task. We explored different DRL algorithms and problem\nconfigurations. The experiments demonstrated the effectiveness of the proposed\nDRL algorithm applied to grasp tasks guided by visual depth camera inputs. When\nusing the proper policy, the proposed method estimates a robot tool\nconfiguration that reaches the object surface with negligible position and\norientation errors. This is, to the best of our knowledge, the first successful\nattempt of using 2.5D images only as of the input of a DRL algorithm, to solve\nthe grasping problem regressing 3D world coordinates.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 07:53:24 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Bertugli", "Alessia", ""], ["Galeone", "Paolo", ""]]}, {"id": "1908.03442", "submitter": "Rafael Caba\\~nas", "authors": "Andr\\'es R. Masegosa, Rafael Caba\\~nas, Helge Langseth, Thomas D.\n  Nielsen, Antonio Salmer\\'on", "title": "Probabilistic Models with Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in statistical inference have significantly expanded the\ntoolbox of probabilistic modeling. Historically, probabilistic modeling has\nbeen constrained to (i) very restricted model classes where exact or\napproximate probabilistic inference were feasible, and (ii) small or\nmedium-sized data sets which fit within the main memory of the computer.\nHowever, developments in variational inference, a general form of approximate\nprobabilistic inference originated in statistical physics, are allowing\nprobabilistic modeling to overcome these restrictions: (i) Approximate\nprobabilistic inference is now possible over a broad class of probabilistic\nmodels containing a large number of parameters, and (ii) scalable inference\nmethods based on stochastic gradient descent and distributed computation\nengines allow to apply probabilistic modeling over massive data sets. One\nimportant practical consequence of these advances is the possibility to include\ndeep neural networks within a probabilistic model to capture complex non-linear\nstochastic relationships between random variables. These advances in\nconjunction with the release of novel probabilistic modeling toolboxes have\ngreatly expanded the scope of application of probabilistic models, and allow\nthese models to take advantage of the recent strides made by the deep learning\ncommunity. In this paper we review the main concepts, methods and tools needed\nto use deep neural networks within a probabilistic modeling framework.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 12:55:54 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 08:37:56 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 10:06:39 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Masegosa", "Andr\u00e9s R.", ""], ["Caba\u00f1as", "Rafael", ""], ["Langseth", "Helge", ""], ["Nielsen", "Thomas D.", ""], ["Salmer\u00f3n", "Antonio", ""]]}, {"id": "1908.03463", "submitter": "Chaithanya Kumar Mummadi", "authors": "Chaithanya Kumar Mummadi, Tim Genewein, Dan Zhang, Thomas Brox, Volker\n  Fischer", "title": "Group Pruning using a Bounded-Lp norm for Group Gating and\n  Regularization", "comments": "German Conference on Pattern Recognition (GCPR) 2019, 12 main pages,\n  3 pages of appendix, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks achieve state-of-the-art results on several tasks while\nincreasing in complexity. It has been shown that neural networks can be pruned\nduring training by imposing sparsity inducing regularizers. In this paper, we\ninvestigate two techniques for group-wise pruning during training in order to\nimprove network efficiency. We propose a gating factor after every\nconvolutional layer to induce channel level sparsity, encouraging insignificant\nchannels to become exactly zero. Further, we introduce and analyse a bounded\nvariant of the L1 regularizer, which interpolates between L1 and L0-norms to\nretain performance of the network at higher pruning rates. To underline\neffectiveness of the proposed methods,we show that the number of parameters of\nResNet-164, DenseNet-40 and MobileNetV2 can be reduced down by 30%, 69% and 75%\non CIFAR100 respectively without a significant drop in accuracy. We achieve\nstate-of-the-art pruning results for ResNet-50 with higher accuracy on\nImageNet. Furthermore, we show that the light weight MobileNetV2 can further be\ncompressed on ImageNet without a significant drop in performance.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 14:08:35 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Mummadi", "Chaithanya Kumar", ""], ["Genewein", "Tim", ""], ["Zhang", "Dan", ""], ["Brox", "Thomas", ""], ["Fischer", "Volker", ""]]}, {"id": "1908.03491", "submitter": "Jonathan Heek", "authors": "Jonathan Heek and Nal Kalchbrenner", "title": "Bayesian Inference for Large Scale Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian inference promises to ground and improve the performance of deep\nneural networks. It promises to be robust to overfitting, to simplify the\ntraining procedure and the space of hyperparameters, and to provide a\ncalibrated measure of uncertainty that can enhance decision making, agent\nexploration and prediction fairness. Markov Chain Monte Carlo (MCMC) methods\nenable Bayesian inference by generating samples from the posterior distribution\nover model parameters. Despite the theoretical advantages of Bayesian inference\nand the similarity between MCMC and optimization methods, the performance of\nsampling methods has so far lagged behind optimization methods for large scale\ndeep learning tasks. We aim to fill this gap and introduce ATMC, an adaptive\nnoise MCMC algorithm that estimates and is able to sample from the posterior of\na neural network. ATMC dynamically adjusts the amount of momentum and noise\napplied to each parameter update in order to compensate for the use of\nstochastic gradients. We use a ResNet architecture without batch normalization\nto test ATMC on the Cifar10 benchmark and the large scale ImageNet benchmark\nand show that, despite the absence of batch normalization, ATMC outperforms a\nstrong optimization baseline in terms of both classification accuracy and test\nlog-likelihood. We show that ATMC is intrinsically robust to overfitting on the\ntraining data and that ATMC provides a better calibrated measure of uncertainty\ncompared to the optimization baseline.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 15:15:56 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Heek", "Jonathan", ""], ["Kalchbrenner", "Nal", ""]]}, {"id": "1908.03512", "submitter": "Gabriel Spadon", "authors": "Gabriel Spadon, Andre C. P. L. F. de Carvalho, Jose F. Rodrigues-Jr,\n  Luiz G. A. Alves", "title": "Reconstructing commuters network using machine learning and urban\n  indicators", "comments": "28 pages, 5 figures", "journal-ref": "Scientific Reports 9, Article number: 11801 (2019)", "doi": "10.1038/s41598-019-48295-x", "report-no": null, "categories": "physics.soc-ph cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human mobility has a significant impact on several layers of society, from\ninfrastructural planning and economics to the spread of diseases and crime.\nRepresenting the system as a complex network, in which nodes are assigned to\nregions (e.g., a city) and links indicate the flow of people between two of\nthem, physics-inspired models have been proposed to quantify the number of\npeople migrating from one city to the other. Despite the advances made by these\nmodels, our ability to predict the number of commuters and reconstruct mobility\nnetworks remains limited. Here, we propose an alternative approach using\nmachine learning and 22 urban indicators to predict the flow of people and\nreconstruct the intercity commuters network. Our results reveal that\npredictions based on machine learning algorithms and urban indicators can\nreconstruct the commuters network with 90.4% of accuracy and describe 77.6% of\nthe variance observed in the flow of people between cities. We also identify\nessential features to recover the network structure and the urban indicators\nmostly related to commuting patterns. As previously reported, distance plays a\nsignificant role in commuting, but other indicators, such as Gross Domestic\nProduct (GDP) and unemployment rate, are also driven-forces for people to\ncommute. We believe that our results shed new lights on the modeling of\nmigration and reinforce the role of urban indicators on commuting patterns.\nAlso, because link-prediction and network reconstruction are still open\nchallenges in network science, our results have implications in other areas,\nlike economics, social sciences, and biology, where node attributes can give us\ninformation about the existence of links connecting entities in the network.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 16:02:43 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Spadon", "Gabriel", ""], ["de Carvalho", "Andre C. P. L. F.", ""], ["Rodrigues-Jr", "Jose F.", ""], ["Alves", "Luiz G. A.", ""]]}, {"id": "1908.03515", "submitter": "Chieh Wu T", "authors": "Chieh Wu, Zulqarnain Khan, Yale Chang, Stratis Ioannidis, Jennifer Dy", "title": "Deep Kernel Learning for Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a deep learning approach for discovering kernels tailored to\nidentifying clusters over sample data. Our neural network produces sample\nembeddings that are motivated by--and are at least as expressive as--spectral\nclustering. Our training objective, based on the Hilbert Schmidt Information\nCriterion, can be optimized via gradient adaptations on the Stiefel manifold,\nleading to significant acceleration over spectral methods relying on\neigendecompositions. Finally, our trained embedding can be directly applied to\nout-of-sample data. We show experimentally that our approach outperforms\nseveral state-of-the-art deep clustering methods, as well as traditional\napproaches such as $k$-means and spectral clustering over a broad array of\nreal-life and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 16:14:47 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 16:59:58 GMT"}, {"version": "v3", "created": "Thu, 2 Jan 2020 15:32:36 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Wu", "Chieh", ""], ["Khan", "Zulqarnain", ""], ["Chang", "Yale", ""], ["Ioannidis", "Stratis", ""], ["Dy", "Jennifer", ""]]}, {"id": "1908.03560", "submitter": "Mohamed Akrout", "authors": "Mohamed Akrout", "title": "On the Adversarial Robustness of Neural Networks without Weight\n  Transport", "comments": "Accepted for the workshop on Real Neurons & Hidden Units at NeurIPS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks trained with backpropagation, the standard algorithm of deep\nlearning which uses weight transport, are easily fooled by existing\ngradient-based adversarial attacks. This class of attacks are based on certain\nsmall perturbations of the inputs to make networks misclassify them. We show\nthat less biologically implausible deep neural networks trained with feedback\nalignment, which do not use weight transport, can be harder to fool, providing\nactual robustness. Tested on MNIST, deep neural networks trained without weight\ntransport (1) have an adversarial accuracy of 98% compared to 0.03% for neural\nnetworks trained with backpropagation and (2) generate non-transferable\nadversarial examples. However, this gap decreases on CIFAR-10 but is still\nsignificant particularly for small perturbation magnitude less than 1/2.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 17:59:35 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 00:21:17 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Akrout", "Mohamed", ""]]}, {"id": "1908.03568", "submitter": "Ian Osband", "authors": "Ian Osband, Yotam Doron, Matteo Hessel, John Aslanides, Eren Sezener,\n  Andre Saraiva, Katrina McKinney, Tor Lattimore, Csaba Szepesvari, Satinder\n  Singh, Benjamin Van Roy, Richard Sutton, David Silver, Hado Van Hasselt", "title": "Behaviour Suite for Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Behaviour Suite for Reinforcement Learning, or\nbsuite for short. bsuite is a collection of carefully-designed experiments that\ninvestigate core capabilities of reinforcement learning (RL) agents with two\nobjectives. First, to collect clear, informative and scalable problems that\ncapture key issues in the design of general and efficient learning algorithms.\nSecond, to study agent behaviour through their performance on these shared\nbenchmarks. To complement this effort, we open source\ngithub.com/deepmind/bsuite, which automates evaluation and analysis of any\nagent on bsuite. This library facilitates reproducible and accessible research\non the core issues in RL, and ultimately the design of superior learning\nalgorithms. Our code is Python, and easy to use within existing projects. We\ninclude examples with OpenAI Baselines, Dopamine as well as new reference\nimplementations. Going forward, we hope to incorporate more excellent\nexperiments from the research community, and commit to a periodic review of\nbsuite from a committee of prominent researchers.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 08:34:08 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 12:48:44 GMT"}, {"version": "v3", "created": "Fri, 14 Feb 2020 15:18:17 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Osband", "Ian", ""], ["Doron", "Yotam", ""], ["Hessel", "Matteo", ""], ["Aslanides", "John", ""], ["Sezener", "Eren", ""], ["Saraiva", "Andre", ""], ["McKinney", "Katrina", ""], ["Lattimore", "Tor", ""], ["Szepesvari", "Csaba", ""], ["Singh", "Satinder", ""], ["Van Roy", "Benjamin", ""], ["Sutton", "Richard", ""], ["Silver", "David", ""], ["Van Hasselt", "Hado", ""]]}, {"id": "1908.03571", "submitter": "Hongzhi Wang", "authors": "Hongzhi Wang, Yang Song and Shihan Tang", "title": "LSTM-based Flow Prediction", "comments": "8 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a method of prediction on continuous time series variables\nfrom the production or flow -- an LSTM algorithm based on multivariate tuning\n-- is proposed. The algorithm improves the traditional LSTM algorithm and\nconverts the time series data into supervised learning sequences regarding\nindustrial data's features. The main innovation of this paper consists in\nintroducing the concepts of periodic measurement and time window in the\nindustrial prediction problem, especially considering industrial data with time\nseries characteristics. Experiments using real-world datasets show that the\nprediction accuracy is improved, 54.05% higher than that of traditional LSTM\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 13:46:48 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Wang", "Hongzhi", ""], ["Song", "Yang", ""], ["Tang", "Shihan", ""]]}, {"id": "1908.03595", "submitter": "Chen Wang", "authors": "Chen Wang, Chengyuan Deng, Zhoulu Yu, Dafeng Hui, Xiaofeng Gong,\n  Ruisen Luo", "title": "Adaptive Ensemble of Classifiers with Regularization for Imbalanced Data\n  Classification", "comments": "Major revision; Change of authors due to contributions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The dynamic ensemble selection of classifiers is an effective approach for\nprocessing label-imbalanced data classifications. However, such a technique is\nprone to overfitting, owing to the lack of regularization methods and the\ndependence of the aforementioned technique on local geometry. In this study,\nfocusing on binary imbalanced data classification, a novel dynamic ensemble\nmethod, namely adaptive ensemble of classifiers with regularization (AER), is\nproposed, to overcome the stated limitations. The method solves the overfitting\nproblem through implicit regularization. Specifically, it leverages the\nproperties of stochastic gradient descent to obtain the solution with the\nminimum norm, thereby achieving regularization; furthermore, it interpolates\nthe ensemble weights by exploiting the global geometry of data to further\nprevent overfitting. According to our theoretical proofs, the seemingly\ncomplicated AER paradigm, in addition to its regularization capabilities, can\nactually reduce the asymptotic time and memory complexities of several other\nalgorithms. We evaluate the proposed AER method on seven benchmark imbalanced\ndatasets from the UCI machine learning repository and one artificially\ngenerated GMM-based dataset with five variations. The results show that the\nproposed algorithm outperforms the major existing algorithms based on multiple\nmetrics in most cases, and two hypothesis tests (McNemar's and Wilcoxon tests)\nverify the statistical significance further. In addition, the proposed method\nhas other preferred properties such as special advantages in dealing with\nhighly imbalanced data, and it pioneers the research on the regularization for\ndynamic ensemble methods.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 18:52:03 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 01:57:24 GMT"}, {"version": "v3", "created": "Fri, 6 Nov 2020 00:10:02 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Wang", "Chen", ""], ["Deng", "Chengyuan", ""], ["Yu", "Zhoulu", ""], ["Hui", "Dafeng", ""], ["Gong", "Xiaofeng", ""], ["Luo", "Ruisen", ""]]}, {"id": "1908.03620", "submitter": "Boris Kramer", "authors": "Renee Swischuk and Boris Kramer and Cheng Huang and Karen Willcox", "title": "Learning physics-based reduced-order models for a single-injector\n  combustion process", "comments": null, "journal-ref": "AIAA Journal 58:6, 2658-2672, 2020", "doi": "10.2514/1.J058943", "report-no": null, "categories": "physics.comp-ph cs.LG cs.SY eess.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a physics-based data-driven method to learn predictive\nreduced-order models (ROMs) from high-fidelity simulations, and illustrates it\nin the challenging context of a single-injector combustion process. The method\ncombines the perspectives of model reduction and machine learning. Model\nreduction brings in the physics of the problem, constraining the ROM\npredictions to lie on a subspace defined by the governing equations. This is\nachieved by defining the ROM in proper orthogonal decomposition (POD)\ncoordinates, which embed the rich physics information contained in solution\nsnapshots of a high-fidelity computational fluid dynamics (CFD) model. The\nmachine learning perspective brings the flexibility to use transformed physical\nvariables to define the POD basis. This is in contrast to traditional model\nreduction approaches that are constrained to use the physical variables of the\nhigh-fidelity code. Combining the two perspectives, the approach identifies a\nset of transformed physical variables that expose quadratic structure in the\ncombustion governing equations and learns a quadratic ROM from transformed\nsnapshot data. This learning does not require access to the high-fidelity model\nimplementation. Numerical experiments show that the ROM accurately predicts\ntemperature, pressure, velocity, species concentrations, and the limit-cycle\namplitude, with speedups of more than five orders of magnitude over\nhigh-fidelity models. Our ROM simulation is shown to be predictive 200% past\nthe training interval. Moreover, ROM-predicted pressure traces accurately match\nthe phase of the pressure signal and yield good approximations of the\nlimit-cycle amplitude.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 20:44:20 GMT"}, {"version": "v2", "created": "Tue, 13 Aug 2019 12:23:06 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2019 16:30:02 GMT"}, {"version": "v4", "created": "Sat, 11 Jul 2020 21:19:05 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Swischuk", "Renee", ""], ["Kramer", "Boris", ""], ["Huang", "Cheng", ""], ["Willcox", "Karen", ""]]}, {"id": "1908.03627", "submitter": "Jon\\'a\\v{s} Kulh\\'anek", "authors": "Jon\\'a\\v{s} Kulh\\'anek and Erik Derner and Tim de Bruin and Robert\n  Babu\\v{s}ka", "title": "Vision-based Navigation Using Deep Reinforcement Learning", "comments": "ECMR 2019: European Conference on Mobile Robots", "journal-ref": "2019 European Conference on Mobile Robots (ECMR), 2019, p.1-8", "doi": "10.1109/ECMR.2019.8870964", "report-no": null, "categories": "cs.RO cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (RL) has been successfully applied to a variety\nof game-like environments. However, the application of deep RL to visual\nnavigation with realistic environments is a challenging task. We propose a\nnovel learning architecture capable of navigating an agent, e.g. a mobile\nrobot, to a target given by an image. To achieve this, we have extended the\nbatched A2C algorithm with auxiliary tasks designed to improve visual\nnavigation performance. We propose three additional auxiliary tasks: predicting\nthe segmentation of the observation image and of the target image and\npredicting the depth-map. These tasks enable the use of supervised learning to\npre-train a large part of the network and to reduce the number of training\nsteps substantially. The training performance has been further improved by\nincreasing the environment complexity gradually over time. An efficient neural\nnetwork structure is proposed, which is capable of learning for multiple\ntargets in multiple environments. Our method navigates in continuous state\nspaces and on the AI2-THOR environment simulator outperforms state-of-the-art\ngoal-oriented visual navigation methods from the literature.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 13:22:22 GMT"}, {"version": "v2", "created": "Sat, 9 Nov 2019 12:49:43 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Kulh\u00e1nek", "Jon\u00e1\u0161", ""], ["Derner", "Erik", ""], ["de Bruin", "Tim", ""], ["Babu\u0161ka", "Robert", ""]]}, {"id": "1908.03632", "submitter": "Ranya Aloufi", "authors": "Ranya Aloufi, Hamed Haddadi, David Boyle", "title": "Emotionless: Privacy-Preserving Speech Analysis for Voice Assistants", "comments": "5 pages, 4 figures, privacy Preserving Machine Learning Workshop, CCS\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice-enabled interactions provide more human-like experiences in many\npopular IoT systems. Cloud-based speech analysis services extract useful\ninformation from voice input using speech recognition techniques. The voice\nsignal is a rich resource that discloses several possible states of a speaker,\nsuch as emotional state, confidence and stress levels, physical condition, age,\ngender, and personal traits. Service providers can build a very accurate\nprofile of a user's demographic category, personal preferences, and may\ncompromise privacy. To address this problem, a privacy-preserving intermediate\nlayer between users and cloud services is proposed to sanitize the voice input.\nIt aims to maintain utility while preserving user privacy. It achieves this by\ncollecting real time speech data and analyzes the signal to ensure privacy\nprotection prior to sharing of this data with services providers. Precisely,\nthe sensitive representations are extracted from the raw signal by using\ntransformation functions and then wrapped it via voice conversion technology.\nExperimental evaluation based on emotion recognition to assess the efficacy of\nthe proposed method shows that identification of sensitive emotional state of\nthe speaker is reduced by ~96 %.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 21:11:45 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Aloufi", "Ranya", ""], ["Haddadi", "Hamed", ""], ["Boyle", "David", ""]]}, {"id": "1908.03652", "submitter": "Michael Johnson", "authors": "Michael Johnson, Jiongyi Cao, and Hyunseung Kang", "title": "Detecting Heterogeneous Treatment Effect with Instrumental Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is an increasing interest in estimating heterogeneity in causal effects\nin randomized and observational studies. However, little research has been\nconducted to understand heterogeneity in an instrumental variables study. In\nthis work, we present a method to estimate heterogeneous causal effects using\nan instrumental variable approach. The method has two parts. The first part\nuses subject-matter knowledge and interpretable machine learning techniques,\nsuch as classification and regression trees, to discover potential effect\nmodifiers. The second part uses closed testing to test for the statistical\nsignificance of the effect modifiers while strongly controlling familywise\nerror rate. We conducted this method on the Oregon Health Insurance Experiment,\nestimating the effect of Medicaid on the number of days an individual's health\ndoes not impede their usual activities, and found evidence of heterogeneity in\nolder men who prefer English and don't self-identify as Asian and younger\nindividuals who have at most a high school diploma or GED and prefer English.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 22:52:44 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2021 17:05:17 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Johnson", "Michael", ""], ["Cao", "Jiongyi", ""], ["Kang", "Hyunseung", ""]]}, {"id": "1908.03665", "submitter": "Jiaxin Zhang", "authors": "Jiaxin Zhang, Xianglin Liu, Sirui Bi, Junqi Yin, Guannan Zhang and\n  Markus Eisenbach", "title": "Robust data-driven approach for predicting the configurational energy of\n  high entropy alloys", "comments": "28 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High entropy alloys (HEAs) have been increasingly attractive as promising\nnext-generation materials due to their various excellent properties. It's\nnecessary to essentially characterize the degree of chemical ordering and\nidentify order-disorder transitions through efficient simulation and modeling\nof thermodynamics. In this study, a robust data-driven framework based on\nBayesian approaches is proposed and demonstrated on the accurate and efficient\nprediction of configurational energy of high entropy alloys. The proposed\neffective pair interaction (EPI) model with ensemble sampling is used to map\nthe configuration and its corresponding energy. Given limited data calculated\nby first-principles calculations, Bayesian regularized regression not only\noffers an accurate and stable prediction but also effectively quantifies the\nuncertainties associated with EPI parameters. Compared with the arbitrary\ndetermination of model complexity, we further conduct a physical feature\nselection to identify the truncation of coordination shells in EPI model using\nBayesian information criterion. The results achieve efficient and robust\nperformance in predicting the configurational energy, particularly given small\ndata. The developed methodology is applied to study a series of refractory\nHEAs, i.e. NbMoTaW, NbMoTaWV and NbMoTaWTi where it is demonstrated how dataset\nsize affects the confidence we can place in statistical estimates of\nconfigurational energy when data are sparse.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 01:59:28 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Zhang", "Jiaxin", ""], ["Liu", "Xianglin", ""], ["Bi", "Sirui", ""], ["Yin", "Junqi", ""], ["Zhang", "Guannan", ""], ["Eisenbach", "Markus", ""]]}, {"id": "1908.03669", "submitter": "Yunan Wu", "authors": "Yunan Wu and Lan Wang", "title": "A Survey of Tuning Parameter Selection for High-dimensional Regression", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalized (or regularized) regression, as represented by Lasso and its\nvariants, has become a standard technique for analyzing high-dimensional data\nwhen the number of variables substantially exceeds the sample size. The\nperformance of penalized regression relies crucially on the choice of the\ntuning parameter, which determines the amount of regularization and hence the\nsparsity level of the fitted model. The optimal choice of tuning parameter\ndepends on both the structure of the design matrix and the unknown random error\ndistribution (variance, tail behavior, etc). This article reviews the current\nliterature of tuning parameter selection for high-dimensional regression from\nboth theoretical and practical perspectives. We discuss various strategies that\nchoose the tuning parameter to achieve prediction accuracy or support recovery.\nWe also review several recently proposed methods for tuning-free\nhigh-dimensional regression.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 02:22:42 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Wu", "Yunan", ""], ["Wang", "Lan", ""]]}, {"id": "1908.03682", "submitter": "Yang Liu", "authors": "Yang Liu, Jianpeng Zhang, Chao Gao, Jinghua Qu, Lixin Ji", "title": "Natural-Logarithm-Rectified Activation Function in Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activation functions play a key role in providing remarkable performance in\ndeep neural networks, and the rectified linear unit (ReLU) is one of the most\nwidely used activation functions. Various new activation functions and\nimprovements on ReLU have been proposed, but each carry performance drawbacks.\nIn this paper, we propose an improved activation function, which we name the\nnatural-logarithm-rectified linear unit (NLReLU). This activation function uses\nthe parametric natural logarithmic transform to improve ReLU and is simply\ndefined as. NLReLU not only retains the sparse activation characteristic of\nReLU, but it also alleviates the \"dying ReLU\" and vanishing gradient problems\nto some extent. It also reduces the bias shift effect and heteroscedasticity of\nneuron data distributions among network layers in order to accelerate the\nlearning process. The proposed method was verified across ten convolutional\nneural networks with different depths for two essential datasets. Experiments\nillustrate that convolutional neural networks with NLReLU exhibit higher\naccuracy than those with ReLU, and that NLReLU is comparable to other\nwell-known activation functions. NLReLU provides 0.16% and 2.04% higher\nclassification accuracy on average compared to ReLU when used in shallow\nconvolutional neural networks with the MNIST and CIFAR-10 datasets,\nrespectively. The average accuracy of deep convolutional neural networks with\nNLReLU is 1.35% higher on average with the CIFAR-10 dataset.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 03:51:36 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 02:24:49 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Liu", "Yang", ""], ["Zhang", "Jianpeng", ""], ["Gao", "Chao", ""], ["Qu", "Jinghua", ""], ["Ji", "Lixin", ""]]}, {"id": "1908.03747", "submitter": "Sioan Zohar", "authors": "Sioan Zohar and Chun-Hong Yoon", "title": "Bi-cross validation for estimating spectral clustering hyper parameters", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": "10.1017/S0885715620000214", "report-no": null, "categories": "stat.ML cs.LG physics.acc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One challenge impeding the analysis of terabyte scale x-ray scattering data\nfrom the Linac Coherent Light Source LCLS, is determining the number of\nclusters required for the execution of traditional clustering algorithms. Here\nwe demonstrate that previous work using bi-cross validation (BCV) to determine\nthe number of singular vectors directly maps to the spectral clustering problem\nof estimating both the number of clusters and hyper parameter values. These\nresults indicate that the process of estimating the number of clusters should\nnot be divorced from the process of estimating other hyper parameters. Applying\nthis method to LCLS x-ray scattering data enables the identification of dropped\nshots without manually setting boundaries on detector fluence and provides a\npath towards identifying rare and anomalous events.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 13:14:33 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 15:50:22 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2019 18:34:15 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Zohar", "Sioan", ""], ["Yoon", "Chun-Hong", ""]]}, {"id": "1908.03761", "submitter": "Xiaoqiang Wang", "authors": "Xiaoqiang Wang, Liangjun Ke, Zhimin Qiao, and Xinghua Chai", "title": "Large-Scale Traffic Signal Control Using a Novel Multi-Agent\n  Reinforcement Learning", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": "10.1109/TCYB.2020.3015811", "report-no": null, "categories": "cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the optimal signal timing strategy is a difficult task for the\nproblem of large-scale traffic signal control (TSC). Multi-Agent Reinforcement\nLearning (MARL) is a promising method to solve this problem. However, there is\nstill room for improvement in extending to large-scale problems and modeling\nthe behaviors of other agents for each individual agent. In this paper, a new\nMARL, called Cooperative double Q-learning (Co-DQL), is proposed, which has\nseveral prominent features. It uses a highly scalable independent double\nQ-learning method based on double estimators and the UCB policy, which can\neliminate the over-estimation problem existing in traditional independent\nQ-learning while ensuring exploration. It uses mean field approximation to\nmodel the interaction among agents, thereby making agents learn a better\ncooperative strategy. In order to improve the stability and robustness of the\nlearning process, we introduce a new reward allocation mechanism and a local\nstate sharing method. In addition, we analyze the convergence properties of the\nproposed algorithm. Co-DQL is applied on TSC and tested on a multi-traffic\nsignal simulator. According to the results obtained on several traffic\nscenarios, Co- DQL outperforms several state-of-the-art decentralized MARL\nalgorithms. It can effectively shorten the average waiting time of the vehicles\nin the whole road system.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 14:19:21 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 12:01:34 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Wang", "Xiaoqiang", ""], ["Ke", "Liangjun", ""], ["Qiao", "Zhimin", ""], ["Chai", "Xinghua", ""]]}, {"id": "1908.03771", "submitter": "Soon Hoe Lim", "authors": "Soon Hoe Lim, Ludovico Theo Giorgini, Woosok Moon, J.S. Wettlaufer", "title": "Predicting Critical Transitions in Multiscale Dynamical Systems Using\n  Reservoir Computing", "comments": "21 pages", "journal-ref": "Chaos: An Interdisciplinary Journal of Nonlinear Science (2020)", "doi": "10.1063/5.0023764", "report-no": null, "categories": "physics.comp-ph math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of predicting rare critical transition events for a\nclass of slow-fast nonlinear dynamical systems. The state of the system of\ninterest is described by a slow process, whereas a faster process drives its\nevolution and induces critical transitions. By taking advantage of recent\nadvances in reservoir computing, we present a data-driven method to predict the\nfuture evolution of the state. We show that our method is capable of predicting\na critical transition event at least several numerical time steps in advance.\nWe demonstrate the success as well as the limitations of our method using\nnumerical experiments on three examples of systems, ranging from low\ndimensional to high dimensional. We discuss the mathematical and broader\nimplications of our results.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 15:02:43 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 22:22:18 GMT"}, {"version": "v3", "created": "Sat, 1 Aug 2020 08:54:03 GMT"}, {"version": "v4", "created": "Fri, 13 Nov 2020 21:36:38 GMT"}, {"version": "v5", "created": "Sat, 5 Dec 2020 11:31:57 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Lim", "Soon Hoe", ""], ["Giorgini", "Ludovico Theo", ""], ["Moon", "Woosok", ""], ["Wettlaufer", "J. S.", ""]]}, {"id": "1908.03782", "submitter": "Li Zhong", "authors": "Tiantian Zhang, Li Zhong, Bo Yuan", "title": "A Critical Note on the Evaluation of Clustering Algorithms", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental evaluation is a major research methodology for investigating\nclustering algorithms and many other machine learning algorithms. For this\npurpose, a number of benchmark datasets have been widely used in the literature\nand their quality plays a key role on the value of the research work. However,\nin most of the existing studies, little attention has been paid to the\nproperties of the datasets and they are often regarded as black-box problems.\nFor example, it is common to use datasets intended for classification in\nclustering research and assume class la-bels as the ground truth for judging\nthe quality of cluster-ing. In our work, with the help of advanced\nvisualization and dimension reduction techniques, we show that this practice\nmay seriously compromise the research quality and produce misleading results.\nWe suggest that the applicability of existing benchmark datasets should be\ncarefully revisited and significant efforts need to be devoted to improving the\ncurrent practice of experimental evaluation of clustering algorithms to ensure\nan essential match between algorithms and problems.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 16:58:52 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 14:40:41 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Zhang", "Tiantian", ""], ["Zhong", "Li", ""], ["Yuan", "Bo", ""]]}, {"id": "1908.03811", "submitter": "Ginestra Bianconi", "authors": "Filippo Radicchi, Dmitri Krioukov, Harrison Hartle and Ginestra\n  Bianconi", "title": "Classical Information Theory of Networks", "comments": "(19 pages, 4 figures)", "journal-ref": "J. Phys. Complex. 1, 025001 (2020)", "doi": "10.1088/2632-072X/ab9447", "report-no": null, "categories": "physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing information-theoretic frameworks based on maximum entropy network\nensembles are not able to explain the emergence of heterogeneity in complex\nnetworks. Here, we fill this gap of knowledge by developing a classical\nframework for networks based on finding an optimal trade-off between the\ninformation content of a compressed representation of the ensemble and the\ninformation content of the actual network ensemble. In this way not only we\nintroduce a novel classical network ensemble satisfying a set of soft\nconstraints but we are also able to calculate the optimal distribution of the\nconstraints. We show that for the classical network ensemble in which the only\nconstraints are the expected degrees a power-law degree distribution is\noptimal. Also, we study spatially embedded networks finding that the\ninteractions between nodes naturally lead to non-uniform spread of nodes in the\nspace, with pairs of nodes at a given distance not necessarily obeying a\npower-law distribution. The pertinent features of real-world air transportation\nnetworks are well described by the proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 21:35:23 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 18:08:06 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 22:08:23 GMT"}, {"version": "v4", "created": "Thu, 14 May 2020 11:07:21 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Radicchi", "Filippo", ""], ["Krioukov", "Dmitri", ""], ["Hartle", "Harrison", ""], ["Bianconi", "Ginestra", ""]]}, {"id": "1908.03830", "submitter": "Kiran Byadarhaly", "authors": "Harish Kashyap K, Kiran Byadarhaly and Saumya Shah", "title": "Supervised Negative Binomial Classifier for Probabilistic Record Linkage", "comments": null, "journal-ref": null, "doi": null, "report-no": "03a", "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need of the linking records across various databases, we\npropose a novel graphical model based classifier that uses a mixture of Poisson\ndistributions with latent variables. The idea is to derive insight into each\npair of hypothesis records that match by inferring its underlying latent rate\nof error using Bayesian Modeling techniques. The novel approach of using gamma\npriors for learning the latent variables along with supervised labels is unique\nand allows for active learning. The naive assumption is made deliberately as to\nthe independence of the fields to propose a generalized theory for this class\nof problems and not to undermine the hierarchical dependencies that could be\npresent in different scenarios. This classifier is able to work with sparse and\nstreaming data. The application to record linkage is able to meet several\nchallenges of sparsity, data streams and varying nature of the data-sets.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 00:25:13 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["K", "Harish Kashyap", ""], ["Byadarhaly", "Kiran", ""], ["Shah", "Saumya", ""]]}, {"id": "1908.03840", "submitter": "Dilini Rajapaksha", "authors": "Dilini Rajapaksha, Christoph Bergmeir, Wray Buntine", "title": "LoRMIkA: Local rule-based model interpretability with k-optimal\n  associations", "comments": "26 pages, 3 figures", "journal-ref": "journal={Information Sciences}, volume={540}, pages={221--241},\n  year={2020}, publisher={Elsevier}", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As we rely more and more on machine learning models for real-life\ndecision-making, being able to understand and trust the predictions becomes\never more important. Local explainer models have recently been introduced to\nexplain the predictions of complex machine learning models at the instance\nlevel. In this paper, we propose Local Rule-based Model Interpretability with\nk-optimal Associations (LoRMIkA), a novel model-agnostic approach that obtains\nk-optimal association rules from a neighbourhood of the instance to be\nexplained. Compared with other rule-based approaches in the literature, we\nargue that the most predictive rules are not necessarily the rules that provide\nthe best explanations. Consequently, the LoRMIkA framework provides a flexible\nway to obtain predictive and interesting rules. It uses an efficient search\nalgorithm guaranteed to find the k-optimal rules with respect to objectives\nsuch as confidence, lift, leverage, coverage, and support. It also provides\nmultiple rules which explain the decision and counterfactual rules, which give\nindications for potential changes to obtain different outputs for given\ninstances. We compare our approach to other state-of-the-art approaches in\nlocal model interpretability on three different datasets and achieve\ncompetitive results in terms of local accuracy and interpretability.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 02:42:27 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 02:44:10 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Rajapaksha", "Dilini", ""], ["Bergmeir", "Christoph", ""], ["Buntine", "Wray", ""]]}, {"id": "1908.03841", "submitter": "Carolyn Talcott", "authors": "Akos Vertes, Albert-Baskar Arul, Peter Avar, Andrew R. Korte, Lida\n  Parvin, Ziad J. Sahab, Deborah I. Bunin, Merrill Knapp, Denise Nishita,\n  Andrew Poggio, Mark-Oliver Stehr, Carolyn L. Talcott, Brian M. Davis,\n  Christine A. Morton, Christopher J. Sevinsky and Maria I. Zavodszky", "title": "Transcriptional Response of SK-N-AS Cells to Methamidophos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG q-bio.CB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcriptomics response of SK-N-AS cells to methamidophos (an acetylcholine\nesterase inhibitor) exposure was measured at 10 time points between 0.5 and 48\nh. The data was analyzed using a combination of traditional statistical methods\nand novel machine learning algorithms for detecting anomalous behavior and\ninfer causal relations between time profiles. We identified several processes\nthat appeared to be upregulated in cells treated with methamidophos including:\nunfolded protein response, response to cAMP, calcium ion response, and\ncell-cell signaling. The data confirmed the expected consequence of\nacetylcholine buildup. In addition, transcripts with potentially key roles were\nidentified and causal networks relating these transcripts were inferred using\ntwo different computational methods: Siamese convolutional networks and time\nwarp causal inference. Two types of anomaly detection algorithms, one based on\nAutoencoders and the other one based on Generative Adversarial Networks (GANs),\nwere applied to narrow down the set of relevant transcripts.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 02:53:56 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Vertes", "Akos", ""], ["Arul", "Albert-Baskar", ""], ["Avar", "Peter", ""], ["Korte", "Andrew R.", ""], ["Parvin", "Lida", ""], ["Sahab", "Ziad J.", ""], ["Bunin", "Deborah I.", ""], ["Knapp", "Merrill", ""], ["Nishita", "Denise", ""], ["Poggio", "Andrew", ""], ["Stehr", "Mark-Oliver", ""], ["Talcott", "Carolyn L.", ""], ["Davis", "Brian M.", ""], ["Morton", "Christine A.", ""], ["Sevinsky", "Christopher J.", ""], ["Zavodszky", "Maria I.", ""]]}, {"id": "1908.03848", "submitter": "Yuening Li", "authors": "Yuening Li, Ninghao Liu, Jundong Li, Mengnan Du, Xia Hu", "title": "Deep Structured Cross-Modal Anomaly Detection", "comments": "8 pages, in Proceedings of the 2019 International Joint Conference on\n  Neural Networks (IJCNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection is a fundamental problem in data mining field with many\nreal-world applications. A vast majority of existing anomaly detection methods\npredominately focused on data collected from a single source. In real-world\napplications, instances often have multiple types of features, such as images\n(ID photos, finger prints) and texts (bank transaction histories, user online\nsocial media posts), resulting in the so-called multi-modal data. In this\npaper, we focus on identifying anomalies whose patterns are disparate across\ndifferent modalities, i.e., cross-modal anomalies. Some of the data instances\nwithin a multi-modal context are often not anomalous when they are viewed\nseparately in each individual modality, but contains inconsistent patterns when\nmultiple sources are jointly considered. The existence of multi-modal data in\nmany real-world scenarios brings both opportunities and challenges to the\ncanonical task of anomaly detection. On the one hand, in multi-modal data,\ninformation of different modalities may complement each other in improving the\ndetection performance. On the other hand, complicated distributions across\ndifferent modalities call for a principled framework to characterize their\ninherent and complex correlations, which is often difficult to capture with\nconventional linear models. To this end, we propose a novel deep structured\nanomaly detection framework to identify the cross-modal anomalies embedded in\nthe data. Experiments on real-world datasets demonstrate the effectiveness of\nthe proposed framework comparing with the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 04:03:14 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Li", "Yuening", ""], ["Liu", "Ninghao", ""], ["Li", "Jundong", ""], ["Du", "Mengnan", ""], ["Hu", "Xia", ""]]}, {"id": "1908.03849", "submitter": "Yuening Li", "authors": "Yuening Li, Xiao Huang, Jundong Li, Mengnan Du, Na Zou", "title": "SpecAE: Spectral AutoEncoder for Anomaly Detection in Attributed\n  Networks", "comments": "7 pages, in proceedings of the 28th ACM International Conference on\n  Information and Knowledge Management (CIKM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection aims to distinguish observations that are rare and\ndifferent from the majority. While most existing algorithms assume that\ninstances are i.i.d., in many practical scenarios, links describing\ninstance-to-instance dependencies and interactions are available. Such systems\nare called attributed networks. Anomaly detection in attributed networks has\nvarious applications such as monitoring suspicious accounts in social media and\nfinancial fraud in transaction networks. However, it remains a challenging task\nsince the definition of anomaly becomes more complicated and topological\nstructures are heterogeneous with nodal attributes. In this paper, we propose a\nspectral convolution and deconvolution based framework -- SpecAE, to project\nthe attributed network into a tailored space to detect global and community\nanomalies. SpecAE leverages Laplacian sharpening to amplify the distances\nbetween representations of anomalies and the ones of the majority. The learned\nrepresentations along with reconstruction errors are combined with a density\nestimation model to perform the detection. They are trained jointly as an\nend-to-end framework. Experiments on real-world datasets demonstrate the\neffectiveness of SpecAE.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 04:04:29 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 06:41:16 GMT"}, {"version": "v3", "created": "Wed, 9 Oct 2019 05:37:43 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Li", "Yuening", ""], ["Huang", "Xiao", ""], ["Li", "Jundong", ""], ["Du", "Mengnan", ""], ["Zou", "Na", ""]]}, {"id": "1908.03875", "submitter": "Mason A. Porter", "authors": "A. Roxana Pamfil, Sam D. Howison, Mason A. Porter", "title": "Inference of Edge Correlations in Multilayer Networks", "comments": null, "journal-ref": "Phys. Rev. E 102, 062307 (2020)", "doi": "10.1103/PhysRevE.102.062307", "report-no": null, "categories": "cs.SI math.CO physics.data-an physics.soc-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent developments in network analysis have focused on multilayer\nnetworks, which one can use to encode time-dependent interactions, multiple\ntypes of interactions, and other complications that arise in complex systems.\nLike their monolayer counterparts, multilayer networks in applications often\nhave mesoscale features, such as community structure. A prominent type of\nmethod for inferring such structures is the employment of multilayer stochastic\nblock models (SBMs). A common (but {potentially} inadequate) assumption of\nthese models is the sampling of edges in different layers independently,\nconditioned on the community labels of the nodes. In this paper, we relax this\nassumption of independence by incorporating edge correlations into an SBM-like\nmodel. We derive maximum-likelihood estimates of the key parameters of our\nmodel, and we propose a measure of layer correlation that reflects the\nsimilarity between connectivity patterns in different layers. Finally, we\nexplain how to use correlated models for edge \"prediction\" (i.e., inference) in\nmultilayer networks. By taking into account edge correlations, prediction\naccuracy improves both in synthetic networks and in a temporal network of\nshoppers who are connected to previously-purchased grocery products.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 09:26:45 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 03:39:18 GMT"}], "update_date": "2021-01-04", "authors_parsed": [["Pamfil", "A. Roxana", ""], ["Howison", "Sam D.", ""], ["Porter", "Mason A.", ""]]}, {"id": "1908.03883", "submitter": "Stanislav Morozov", "authors": "Stanislav Morozov, Artem Babenko", "title": "Unsupervised Neural Quantization for Compressed-Domain Similarity Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We tackle the problem of unsupervised visual descriptors compression, which\nis a key ingredient of large-scale image retrieval systems. While the deep\nlearning machinery has benefited literally all computer vision pipelines, the\nexisting state-of-the-art compression methods employ shallow architectures, and\nwe aim to close this gap by our paper. In more detail, we introduce a DNN\narchitecture for the unsupervised compressed-domain retrieval, based on\nmulti-codebook quantization. The proposed architecture is designed to\nincorporate both fast data encoding and efficient distances computation via\nlookup tables. We demonstrate the exceptional advantage of our scheme over\nexisting quantization approaches on several datasets of visual descriptors via\noutperforming the previous state-of-the-art by a large margin.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 10:46:16 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Morozov", "Stanislav", ""], ["Babenko", "Artem", ""]]}, {"id": "1908.03891", "submitter": "Gregorz Dudek", "authors": "Grzegorz Dudek", "title": "Data-Driven Randomized Learning of Feedforward Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized methods of neural network learning suffer from a problem with the\ngeneration of random parameters as they are difficult to set optimally to\nobtain a good projection space. The standard method draws the parameters from a\nfixed interval which is independent of the data scope and activation function\ntype. This does not lead to good results in the approximation of the strongly\nnonlinear functions. In this work, a method which adjusts the random\nparameters, representing the slopes and positions of the sigmoids, to the\ntarget function features is proposed. The method randomly selects the input\nspace regions, places the sigmoids in these regions and then adjusts the\nsigmoid slopes to the local fluctuations of the target function. This brings\nvery good results in the approximation of the complex target functions when\ncompared to the standard fixed interval method and other methods recently\nproposed in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 12:07:31 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1908.03901", "submitter": "Tomohiro Hayase", "authors": "Tomohiro Hayase", "title": "Almost Sure Asymptotic Freeness of Neural Network Jacobian with\n  Orthogonal Weights", "comments": "The proof of main theorem use the orthogonal invariance of joint\n  distribution, which need further non-trivial discussion. Thus we withdraw\n  this", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well-conditioned Jacobian spectrum has a vital role in preventing exploding\nor vanishing gradients and speeding up learning of deep neural networks. Free\nprobability theory helps us to understand and handle the Jacobian spectrum. We\nrigorously show almost sure asymptotic freeness of layer-wise Jacobians of deep\nneural networks as the wide limit. In particular, we treat the case that\nweights are initialized as Haar distributed orthogonal matrices.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 13:05:26 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 04:33:36 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 17:33:58 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2020 08:36:48 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Hayase", "Tomohiro", ""]]}, {"id": "1908.03918", "submitter": "Changhao Chen", "authors": "Changhao Chen, Chris Xiaoxuan Lu, Bing Wang, Niki Trigoni, Andrew\n  Markham", "title": "DynaNet: Neural Kalman Dynamical Model for Motion Estimation and\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamical models estimate and predict the temporal evolution of physical\nsystems. State Space Models (SSMs) in particular represent the system dynamics\nwith many desirable properties, such as being able to model uncertainty in both\nthe model and measurements, and optimal (in the Bayesian sense) recursive\nformulations e.g. the Kalman Filter. However, they require significant domain\nknowledge to derive the parametric form and considerable hand-tuning to\ncorrectly set all the parameters. Data driven techniques e.g. Recurrent Neural\nNetworks have emerged as compelling alternatives to SSMs with wide success\nacross a number of challenging tasks, in part due to their ability to extract\nrelevant features from rich inputs. They however lack interpretability and\nrobustness to unseen conditions. In this work, we present DynaNet, a hybrid\ndeep learning and time-varying state-space model which can be trained\nend-to-end. Our neural Kalman dynamical model allows us to exploit the relative\nmerits of each approach. We demonstrate state-of-the-art estimation and\nprediction on a number of physically challenging tasks, including visual\nodometry, sensor fusion for visual-inertial navigation and pendulum control. In\naddition we show how DynaNet can indicate failures through investigation of\nproperties such as the rate of innovation (Kalman Gain).\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 15:03:24 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 16:58:17 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Chen", "Changhao", ""], ["Lu", "Chris Xiaoxuan", ""], ["Wang", "Bing", ""], ["Trigoni", "Niki", ""], ["Markham", "Andrew", ""]]}, {"id": "1908.03932", "submitter": "Saber Salehkaleybar", "authors": "Saber Salehkaleybar, AmirEmad Ghassami, Negar Kiyavash, Kun Zhang", "title": "Learning Linear Non-Gaussian Causal Models in the Presence of Latent\n  Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning causal models from observational data\ngenerated by linear non-Gaussian acyclic causal models with latent variables.\nWithout considering the effect of latent variables, one usually infers wrong\ncausal relationships among the observed variables. Under faithfulness\nassumption, we propose a method to check whether there exists a causal path\nbetween any two observed variables. From this information, we can obtain the\ncausal order among them. The next question is then whether or not the causal\neffects can be uniquely identified as well. It can be shown that causal effects\namong observed variables cannot be identified uniquely even under the\nassumptions of faithfulness and non-Gaussianity of exogenous noises. However,\nwe will propose an efficient method to identify the set of all possible causal\neffects that are compatible with the observational data. Furthermore, we\npresent some structural conditions on the causal graph under which we can learn\ncausal effects among observed variables uniquely. We also provide necessary and\nsufficient graphical conditions for unique identification of the number of\nvariables in the system. Experiments on synthetic data and real-world data show\nthe effectiveness of our proposed algorithm on learning causal models.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 16:28:55 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Salehkaleybar", "Saber", ""], ["Ghassami", "AmirEmad", ""], ["Kiyavash", "Negar", ""], ["Zhang", "Kun", ""]]}, {"id": "1908.03936", "submitter": "Svenja Stark", "authors": "Svenja Stark, Jan Peters and Elmar Rueckert", "title": "Experience Reuse with Probabilistic Movement Primitives", "comments": "8 pages, 5 figures, IROS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquiring new robot motor skills is cumbersome, as learning a skill from\nscratch and without prior knowledge requires the exploration of a large space\nof motor configurations. Accordingly, for learning a new task, time could be\nsaved by restricting the parameter search space by initializing it with the\nsolution of a similar task. We present a framework which is able of such\nknowledge transfer from already learned movement skills to a new learning task.\nThe framework combines probabilistic movement primitives with descriptions of\ntheir effects for skill representation. New skills are first initialized with\nparameters inferred from related movement primitives and thereafter adapted to\nthe new task through relative entropy policy search. We compare two different\ntransfer approaches to initialize the search space distribution with data of\nknown skills with a similar effect. We show the different benefits of the two\nknowledge transfer approaches on an object pushing task for a simulated 3-DOF\nrobot. We can show that the quality of the learned skills improves and the\nrequired iterations to learn a new task can be reduced by more than 60% when\npast experiences are utilized.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 17:04:48 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 14:49:09 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Stark", "Svenja", ""], ["Peters", "Jan", ""], ["Rueckert", "Elmar", ""]]}, {"id": "1908.03963", "submitter": "Afshin Oroojlooy", "authors": "Afshin OroojlooyJadid and Davood Hajinezhad", "title": "A Review of Cooperative Multi-Agent Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Reinforcement Learning has made significant progress in multi-agent\nsystems in recent years. In this review article, we have focused on presenting\nrecent approaches on Multi-Agent Reinforcement Learning (MARL) algorithms. In\nparticular, we have focused on five common approaches on modeling and solving\ncooperative multi-agent reinforcement learning problems: (I) independent\nlearners, (II) fully observable critic, (III) value function factorization,\n(IV) consensus, and (IV) learn to communicate. First, we elaborate on each of\nthese methods, possible challenges, and how these challenges were mitigated in\nthe relevant papers. If applicable, we further make a connection among\ndifferent papers in each category. Next, we cover some new emerging research\nareas in MARL along with the relevant recent papers. Due to the recent success\nof MARL in real-world applications, we assign a section to provide a review of\nthese applications and corresponding articles.\n  Also, a list of available environments for MARL research is provided in this\nsurvey. Finally, the paper is concluded with proposals on the possible research\ndirections.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 21:40:11 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 02:59:54 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 03:06:48 GMT"}, {"version": "v4", "created": "Fri, 30 Apr 2021 04:14:28 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["OroojlooyJadid", "Afshin", ""], ["Hajinezhad", "Davood", ""]]}, {"id": "1908.03971", "submitter": "Sajad Darabi", "authors": "Sajad Darabi, Mohammad Kachuee, Shayan Fazeli, and Majid Sarrafzadeh", "title": "TAPER: Time-Aware Patient EHR Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective representation learning of electronic health records is a\nchallenging task and is becoming more important as the availability of such\ndata is becoming pervasive. The data contained in these records are irregular\nand contain multiple modalities such as notes, and medical codes. They are\npreempted by medical conditions the patient may have, and are typically jotted\ndown by medical staff. Accompanying codes are notes containing valuable\ninformation about patients beyond the structured information contained in\nelectronic health records. We use transformer networks and the recently\nproposed BERT language model to embed these data streams into a unified vector\nrepresentation. The presented approach effectively encodes a patient's visit\ndata into a single distributed representation, which can be used for downstream\ntasks. Our model demonstrates superior performance and generalization on\nmortality, readmission and length of stay tasks using the publicly available\nMIMIC-III ICU dataset. Code avaialble at\nhttps://github.com/sajaddarabi/TAPER-EHR\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 23:15:23 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 02:36:35 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 06:00:56 GMT"}, {"version": "v4", "created": "Sun, 3 May 2020 10:32:10 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Darabi", "Sajad", ""], ["Kachuee", "Mohammad", ""], ["Fazeli", "Shayan", ""], ["Sarrafzadeh", "Majid", ""]]}, {"id": "1908.03973", "submitter": "Ping Lu", "authors": "Ping Lu, Yanyan Zhang, Jianxiong Chen, Yuan Xiao, George Zhao", "title": "Enhanced Seismic Imaging with Predictive Neural Networks for Geophysics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.geo-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a predictive neural network architecture that can be utilized to\nupdate reference velocity models as inputs to the full waveform inversion. Deep\nlearning models are explored to augment velocity model building workflows\nduring processing the 3D seismic volume in salt-prone environments.\nSpecifically, a neural network architecture, with 3D convolutional,\nde-convolutional layers, and 3D max-pooling, is designed to take standard\namplitude 3D seismic volumes as an input. Enhanced data augmentations through\ngenerative adversarial networks and a weighted loss function enable the network\nto train with few sparsely annotated slices. Batch normalization is also\napplied for faster convergence. A 3D probability cube for salt bodies and\ninclusions is generated through ensembles of predictions from multiple models\nin order to reduce variance. Velocity models inferred from the proposed\nnetworks provide opportunities for FWI forward models to converge faster with\nan initial condition closer to the true model. In addition, in each iteration\nstep, the probability cubes of salt bodies and inclusions inferred from the\nproposed networks can be used as a regularization term within the FWI forward\nmodelling, which may result in an improved velocity model estimation while the\noutput of seismic migration can be utilized as an input of the 3D neural\nnetwork for subsequent iterations.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 23:46:05 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 22:32:06 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Lu", "Ping", ""], ["Zhang", "Yanyan", ""], ["Chen", "Jianxiong", ""], ["Xiao", "Yuan", ""], ["Zhao", "George", ""]]}, {"id": "1908.03983", "submitter": "Chuanxing Geng", "authors": "Chuanxing Geng, Lue Tao and Songcan Chen", "title": "Visual and Semantic Prototypes-Jointly Guided CNN for Generalized\n  Zero-shot Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the process of exploring the world, the curiosity constantly drives humans\nto cognize new things. Supposing you are a zoologist, for a presented animal\nimage, you can recognize it immediately if you know its class. Otherwise, you\nwould more likely attempt to cognize it by exploiting the side-information\n(e.g., semantic information, etc.) you have accumulated. Inspired by this, this\npaper decomposes the generalized zero-shot learning (G-ZSL) task into an open\nset recognition (OSR) task and a zero-shot learning (ZSL) task, where OSR\nrecognizes seen classes (if we have seen (or known) them) and rejects unseen\nclasses (if we have never seen (or known) them before), while ZSL identifies\nthe unseen classes rejected by the former. Simultaneously, without violating\nOSR's assumptions (only known class knowledge is available in training), we\nalso first attempt to explore a new generalized open set recognition (G-OSR) by\nintroducing the accumulated side-information from known classes to OSR. For\nG-ZSL, such a decomposition effectively solves the class overfitting problem\nwith easily misclassifying unseen classes as seen classes. The problem is\nubiquitous in most existing G-ZSL methods. On the other hand, for G-OSR,\nintroducing such semantic information of known classes not only improves the\nrecognition performance but also endows OSR with the cognitive ability of\nunknown classes. Specifically, a visual and semantic prototypes-jointly guided\nconvolutional neural network (VSG-CNN) is proposed to fulfill these two tasks\n(G-ZSL and G-OSR) in a unified end-to-end learning framework. Extensive\nexperiments on benchmark datasets demonstrate the advantages of our learning\nframework.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 02:29:16 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 12:58:23 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Geng", "Chuanxing", ""], ["Tao", "Lue", ""], ["Chen", "Songcan", ""]]}, {"id": "1908.03990", "submitter": "Zhiyong Chen", "authors": "Zhiyong Chen, Zongze Ren and Shugong Xu", "title": "A Study on Angular Based Embedding Learning for Text-independent Speaker\n  Verification", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a good speaker embedding is important for many automatic speaker\nrecognition tasks, including verification, identification and diarization. The\nembeddings learned by softmax are not discriminative enough for open-set\nverification tasks. Angular based embedding learning target can achieve such\ndiscriminativeness by optimizing angular distance and adding margin penalty. We\napply several different popular angular margin embedding learning strategies in\nthis work and explicitly compare their performance on Voxceleb speaker\nrecognition dataset. Observing the fact that encouraging inter-class\nseparability is important when applying angular based embedding learning, we\npropose an exclusive inter-class regularization as a complement for angular\nbased loss. We verify the effectiveness of these methods for learning a\ndiscriminative embedding space on ASV task with several experiments. These\nmethods together, we manage to achieve an impressive result with 16.5%\nimprovement on equal error rate (EER) and 18.2% improvement on minimum\ndetection cost function comparing with baseline softmax systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 04:02:41 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Chen", "Zhiyong", ""], ["Ren", "Zongze", ""], ["Xu", "Shugong", ""]]}, {"id": "1908.04000", "submitter": "Priyanga Dilini Talagala", "authors": "Priyanga Dilini Talagala and Rob J. Hyndman and Kate Smith-Miles", "title": "Anomaly Detection in High Dimensional Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The HDoutliers algorithm is a powerful unsupervised algorithm for detecting\nanomalies in high-dimensional data, with a strong theoretical foundation.\nHowever, it suffers from some limitations that significantly hinder its\nperformance level, under certain circumstances. In this article, we propose an\nalgorithm that addresses these limitations. We define an anomaly as an\nobservation that deviates markedly from the majority with a large distance gap.\nAn approach based on extreme value theory is used for the anomalous threshold\ncalculation. Using various synthetic and real datasets, we demonstrate the wide\napplicability and usefulness of our algorithm, which we call the stray\nalgorithm. We also demonstrate how this algorithm can assist in detecting\nanomalies present in other data structures using feature engineering. We show\nthe situations where the stray algorithm outperforms the HDoutliers algorithm\nboth in accuracy and computational time. This framework is implemented in the\nopen source R package stray.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 04:48:03 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Talagala", "Priyanga Dilini", ""], ["Hyndman", "Rob J.", ""], ["Smith-Miles", "Kate", ""]]}, {"id": "1908.04003", "submitter": "Vaibhav Vaibhav", "authors": "Vaibhav, Po-Yao Huang, Robert Frederking", "title": "RWR-GAE: Random Walk Regularization for Graph Auto Encoders", "comments": "6 pages, Empirical paper on improving Graph Embeddings using Random\n  Walk", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Node embeddings have become an ubiquitous technique for representing graph\ndata in a low dimensional space. Graph autoencoders, as one of the widely\nadapted deep models, have been proposed to learn graph embeddings in an\nunsupervised way by minimizing the reconstruction error for the graph data.\nHowever, its reconstruction loss ignores the distribution of the latent\nrepresentation, and thus leading to inferior embeddings. To mitigate this\nproblem, we propose a random walk based method to regularize the\nrepresentations learnt by the encoder. We show that the proposed novel\nenhancement beats the existing state-of-the-art models by a large margin (upto\n7.5\\%) for node clustering task, and achieves state-of-the-art accuracy on the\nlink prediction task for three standard datasets, cora, citeseer and pubmed.\nCode available at https://github.com/MysteryVaibhav/DW-GAE.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 05:02:33 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Vaibhav", "", ""], ["Huang", "Po-Yao", ""], ["Frederking", "Robert", ""]]}, {"id": "1908.04008", "submitter": "Senwei Liang", "authors": "Senwei Liang, Zhongzhan Huang, Mingfu Liang, Haizhao Yang", "title": "Instance Enhancement Batch Normalization: an Adaptive Regulator of Batch\n  Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Batch Normalization (BN)(Ioffe and Szegedy 2015) normalizes the features of\nan input image via statistics of a batch of images and hence BN will bring the\nnoise to the gradient of the training loss. Previous works indicate that the\nnoise is important for the optimization and generalization of deep neural\nnetworks, but too much noise will harm the performance of networks. In our\npaper, we offer a new point of view that self-attention mechanism can help to\nregulate the noise by enhancing instance-specific information to obtain a\nbetter regularization effect. Therefore, we propose an attention-based BN\ncalled Instance Enhancement Batch Normalization (IEBN) that recalibrates the\ninformation of each channel by a simple linear transformation. IEBN has a good\ncapacity of regulating noise and stabilizing network training to improve\ngeneralization even in the presence of two kinds of noise attacks during\ntraining. Finally, IEBN outperforms BN with only a light parameter increment in\nimage classification tasks for different network structures and benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 05:42:09 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 02:52:32 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Liang", "Senwei", ""], ["Huang", "Zhongzhan", ""], ["Liang", "Mingfu", ""], ["Yang", "Haizhao", ""]]}, {"id": "1908.04030", "submitter": "Ronny Hug", "authors": "Ronny Hug, Wolfgang H\\\"ubner, and Michael Arens", "title": "Modeling continuous-time stochastic processes using $\\mathcal{N}$-Curve\n  mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations of sequential data are commonly based on the assumption that\nobserved sequences are realizations of an unknown underlying stochastic\nprocess, where the learning problem includes determination of the model\nparameters. In this context the model must be able to capture the multi-modal\nnature of the data, without blurring between modes. This property is essential\nfor applications like trajectory prediction or human motion modeling. Towards\nthis end, a neural network model for continuous-time stochastic processes\nusable for sequence prediction is proposed. The model is based on Mixture\nDensity Networks using B\\'ezier curves with Gaussian random variables as\ncontrol points (abbrev.: $\\mathcal{N}$-Curves). Key advantages of the model\ninclude the ability of generating smooth multi-mode predictions in a single\ninference step which reduces the need for Monte Carlo simulation, as required\nin many multi-step prediction models, based on state-of-the-art neural\nnetworks. Essential properties of the proposed approach are illustrated by\nseveral toy examples and the task of multi-step sequence prediction. Further,\nthe model performance is evaluated on two real world use-cases, i.e. human\ntrajectory prediction and human motion modeling, outperforming different\nstate-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 07:12:08 GMT"}, {"version": "v2", "created": "Thu, 15 Aug 2019 14:00:57 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 09:40:11 GMT"}, {"version": "v4", "created": "Mon, 16 Sep 2019 09:14:49 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Hug", "Ronny", ""], ["H\u00fcbner", "Wolfgang", ""], ["Arens", "Michael", ""]]}, {"id": "1908.04109", "submitter": "Nicolas Gillis", "authors": "Nicolas Gillis", "title": "Successive Projection Algorithm Robust to Outliers", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NA eess.IV math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The successive projection algorithm (SPA) is a fast algorithm to tackle\nseparable nonnegative matrix factorization (NMF). Given a nonnegative data\nmatrix $X$, SPA identifies an index set $\\mathcal{K}$ such that there exists a\nnonnegative matrix $H$ with $X \\approx X(:,\\mathcal{K})H$. SPA has been\nsuccessfully used as a pure-pixel search algorithm in hyperspectral unmixing\nand for anchor word selection in document classification. Moreover, SPA is\nprovably robust in low-noise settings. The main drawbacks of SPA are that it is\nnot robust to outliers and does not take the data fitting term into account\nwhen selecting the indices in $\\mathcal{K}$. In this paper, we propose a new\nSPA variant, dubbed Robust SPA (RSPA), that is robust to outliers while still\nbeing provably robust in low-noise settings, and that takes into account the\nreconstruction error for selecting the indices in $\\mathcal{K}$. We illustrate\nthe effectiveness of RSPA on synthetic data sets and hyperspectral images.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 12:21:50 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Gillis", "Nicolas", ""]]}, {"id": "1908.04209", "submitter": "Ye Xue", "authors": "Ye Xue, Diego Klabjan, Yuan Luo", "title": "Mixture-based Multiple Imputation Model for Clinical Data with a\n  Temporal Dimension", "comments": null, "journal-ref": null, "doi": "10.1109/BigData47090.2019.9005672", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of missing values in multivariable time series is a key challenge\nin many applications such as clinical data mining. Although many imputation\nmethods show their effectiveness in many applications, few of them are designed\nto accommodate clinical multivariable time series. In this work, we propose a\nmultiple imputation model that capture both cross-sectional information and\ntemporal correlations. We integrate Gaussian processes with mixture models and\nintroduce individualized mixing weights to handle the variance of predictive\nconfidence of Gaussian process models. The proposed model is compared with\nseveral state-of-the-art imputation algorithms on both real-world and synthetic\ndatasets. Experiments show that our best model can provide more accurate\nimputation than the benchmarks on all of our datasets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:47:10 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 18:51:54 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 22:11:55 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Xue", "Ye", ""], ["Klabjan", "Diego", ""], ["Luo", "Yuan", ""]]}, {"id": "1908.04218", "submitter": "Panos Toulis", "authors": "Panos Toulis", "title": "Life After Bootstrap: Residual Randomization Inference in Regression\n  Models", "comments": "7 figures, 7 tables, R package\n  (https://cran.r-project.org/package=RRI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a randomization-based method for inference in regression models.\nThe basis of inference is an invariance assumption on the regression errors,\nsuch as invariance to permutations or random signs. To test significance, the\nrandomization method repeatedly calculates a suitable test statistic over\ntransformations of the regression residuals according to the invariant.\nInversion of the test can produce confidence intervals. We prove general\nconditions for asymptotic validity of this residual randomization test and\nillustrate in many models, including clustered errors with one-way or two-way\nclustering structure. We also show that finite-sample validity is possible\nunder a suitable construction, and illustrate with an exact test for a case of\nthe Behrens-Fisher problem. The proposed method offers four main advantages\nover the bootstrap: (1) it addresses the inference problem in a unified way,\nwhile bootstrap typically needs to be adapted to the task; (2) it can be more\npowerful by exploiting a richer and more flexible set of invariances than\nexchangeability; (3) it does not rely on asymptotic normality; and (4) it can\nbe valid in finite samples. In extensive empirical evaluations, including high\ndimensional regression and autocorrelated errors, the proposed method performs\nfavorably against many alternatives, including bootstrap variants and\nasymptotic robust error methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 16:09:15 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Toulis", "Panos", ""]]}, {"id": "1908.04240", "submitter": "F\\'abio Pinto", "authors": "F\\'abio Pinto, Marco O. P. Sampaio, Pedro Bizarro", "title": "Automatic Model Monitoring for Data Streams", "comments": "9 pages, 9 figures, 2 tables", "journal-ref": "KDD-ADF-2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting concept drift is a well known problem that affects production\nsystems. However, two important issues that are frequently not addressed in the\nliterature are 1) the detection of drift when the labels are not immediately\navailable; and 2) the automatic generation of explanations to identify possible\ncauses for the drift. For example, a fraud detection model in online payments\ncould show a drift due to a hot sale item (with an increase in false positives)\nor due to a true fraud attack (with an increase in false negatives) before\nlabels are available. In this paper we propose SAMM, an automatic model\nmonitoring system for data streams. SAMM detects concept drift using a time and\nspace efficient unsupervised streaming algorithm and it generates alarm reports\nwith a summary of the events and features that are important to explain it.\nSAMM was evaluated in five real world fraud detection datasets, each spanning\nperiods up to eight months and totaling more than 22 million online\ntransactions. We evaluated SAMM using human feedback from domain experts, by\nsending them 100 reports generated by the system. Our results show that SAMM is\nable to detect anomalous events in a model life cycle that are considered\nuseful by the domain experts. Given these results, SAMM will be rolled out in a\nnext version of Feedzai's Fraud Detection solution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 16:47:14 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Pinto", "F\u00e1bio", ""], ["Sampaio", "Marco O. P.", ""], ["Bizarro", "Pedro", ""]]}, {"id": "1908.04267", "submitter": "Amir Mosavi Prof", "authors": "Sevda Shabani, Saeed Samadianfard, Mohammad Taghi Sattari, Shahab\n  Shamshirband, Amir Mosavi, Tibor Kmet, Annamaria R. Varkonyi-Koczy", "title": "Modeling Daily Pan Evaporation in Humid Climates Using Gaussian Process\n  Regression", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": "10.20944/preprints201907.0351.v1", "report-no": null, "categories": "physics.ao-ph cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evaporation is one of the main processes in the hydrological cycle, and it is\none of the most critical factors in agricultural, hydrological, and\nmeteorological studies. Due to the interactions of multiple climatic factors,\nthe evaporation is a complex and nonlinear phenomenon; therefore, the\ndata-based methods can be used to have precise estimations of it. In this\nregard, in the present study, Gaussian Process Regression, Nearest-Neighbor,\nRandom Forest and Support Vector Regression were used to estimate the pan\nevaporation in the meteorological stations of Golestan Province, Iran. For this\npurpose, meteorological data including PE, temperature, relative humidity, wind\nspeed and sunny hours collected from the Gonbad-e Kavus, Gorgan and Bandar\nTorkman stations from 2011 through 2017. The accuracy of the studied methods\nwas determined using the statistical indices of Root Mean Squared Error,\ncorrelation coefficient and Mean Absolute Error. Furthermore, the Taylor charts\nutilized for evaluating the accuracy of the mentioned models. We report that\nGPR for Gonbad-e Kavus Station with input parameters of T, W and S and GPR for\nGorgan and Bandar Torkmen stations with input parameters of T, RH, W, and S had\nthe most accurate performances and proposed for precise estimation of PE. Due\nto the high rate of evaporation in Iran and the lack of measurement\ninstruments, the findings of the current study indicated that the PE values\nmight be estimated with few easily measured meteorological parameters\naccurately.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 10:43:36 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Shabani", "Sevda", ""], ["Samadianfard", "Saeed", ""], ["Sattari", "Mohammad Taghi", ""], ["Shamshirband", "Shahab", ""], ["Mosavi", "Amir", ""], ["Kmet", "Tibor", ""], ["Varkonyi-Koczy", "Annamaria R.", ""]]}, {"id": "1908.04284", "submitter": "Quan Wang", "authors": "Shaojin Ding, Quan Wang, Shuo-yiin Chang, Li Wan, Ignacio Lopez Moreno", "title": "Personal VAD: Speaker-Conditioned Voice Activity Detection", "comments": "Speaker Odyssey 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose \"personal VAD\", a system to detect the voice\nactivity of a target speaker at the frame level. This system is useful for\ngating the inputs to a streaming on-device speech recognition system, such that\nit only triggers for the target user, which helps reduce the computational cost\nand battery consumption, especially in scenarios where a keyword detector is\nunpreferable. We achieve this by training a VAD-alike neural network that is\nconditioned on the target speaker embedding or the speaker verification score.\nFor each frame, personal VAD outputs the probabilities for three classes:\nnon-speech, target speaker speech, and non-target speaker speech. Under our\noptimal setup, we are able to train a model with only 130K parameters that\noutperforms a baseline system where individually trained standard VAD and\nspeaker recognition networks are combined to perform the same task.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 17:54:31 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 18:04:42 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 19:06:18 GMT"}, {"version": "v4", "created": "Wed, 8 Apr 2020 15:41:16 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Ding", "Shaojin", ""], ["Wang", "Quan", ""], ["Chang", "Shuo-yiin", ""], ["Wan", "Li", ""], ["Moreno", "Ignacio Lopez", ""]]}, {"id": "1908.04319", "submitter": "Sean Welleck", "authors": "Sean Welleck, Ilia Kulikov, Stephen Roller, Emily Dinan, Kyunghyun\n  Cho, Jason Weston", "title": "Neural Text Generation with Unlikelihood Training", "comments": "Sean Welleck and Ilia Kulikov contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text generation is a key tool in natural language applications, but it\nis well known there are major problems at its core. In particular, standard\nlikelihood training and decoding leads to dull and repetitive outputs. While\nsome post-hoc fixes have been proposed, in particular top-$k$ and nucleus\nsampling, they do not address the fact that the token-level probabilities\npredicted by the model are poor. In this paper we show that the likelihood\nobjective itself is at fault, resulting in a model that assigns too much\nprobability to sequences containing repeats and frequent words, unlike those\nfrom the human training distribution. We propose a new objective, unlikelihood\ntraining, which forces unlikely generations to be assigned lower probability by\nthe model. We show that both token and sequence level unlikelihood training\ngive less repetitive, less dull text while maintaining perplexity, giving\nsuperior generations using standard greedy or beam search. According to human\nevaluations, our approach with standard beam search also outperforms the\ncurrently popular decoding methods of nucleus sampling or beam blocking, thus\nproviding a strong alternative to existing techniques.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 18:09:04 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 23:57:44 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Welleck", "Sean", ""], ["Kulikov", "Ilia", ""], ["Roller", "Stephen", ""], ["Dinan", "Emily", ""], ["Cho", "Kyunghyun", ""], ["Weston", "Jason", ""]]}, {"id": "1908.04339", "submitter": "Alejandro Newell", "authors": "Alejandro Newell, Lu Jiang, Chong Wang, Li-Jia Li, Jia Deng", "title": "Feature Partitioning for Efficient Multi-Task Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task learning holds the promise of less data, parameters, and time than\ntraining of separate models. We propose a method to automatically search over\nmulti-task architectures while taking resource constraints into consideration.\nWe propose a search space that compactly represents different parameter sharing\nstrategies. This provides more effective coverage and sampling of the space of\nmulti-task architectures. We also present a method for quick evaluation of\ndifferent architectures by using feature distillation. Together these\ncontributions allow us to quickly optimize for efficient multi-task models. We\nbenchmark on Visual Decathlon, demonstrating that we can automatically search\nfor and identify multi-task architectures that effectively make trade-offs\nbetween task resource requirements while achieving a high level of final\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 19:06:32 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Newell", "Alejandro", ""], ["Jiang", "Lu", ""], ["Wang", "Chong", ""], ["Li", "Li-Jia", ""], ["Deng", "Jia", ""]]}, {"id": "1908.04345", "submitter": "Guo-Hua Wang", "authors": "Guo-Hua Wang, Jianxin Wu", "title": "Repetitive Reprediction Deep Decipher for Semi-Supervised Learning", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most recent semi-supervised deep learning (deep SSL) methods used a similar\nparadigm: use network predictions to update pseudo-labels and use pseudo-labels\nto update network parameters iteratively. However, they lack theoretical\nsupport and cannot explain why predictions are good candidates for\npseudo-labels. In this paper, we propose a principled end-to-end framework\nnamed deep decipher (D2) for SSL. Within the D2 framework, we prove that\npseudo-labels are related to network predictions by an exponential link\nfunction, which gives a theoretical support for using predictions as\npseudo-labels. Furthermore, we demonstrate that updating pseudo-labels by\nnetwork predictions will make them uncertain. To mitigate this problem, we\npropose a training strategy called repetitive reprediction (R2). Finally, the\nproposed R2-D2 method is tested on the large-scale ImageNet dataset and\noutperforms state-of-the-art methods by 5 percentage points.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 11:57:16 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 01:59:50 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Wang", "Guo-Hua", ""], ["Wu", "Jianxin", ""]]}, {"id": "1908.04347", "submitter": "Alexander Hepburn", "authors": "Alexander Hepburn, Valero Laparra, Ryan McConville, Raul\n  Santos-Rodriguez", "title": "Enforcing Perceptual Consistency on Generative Adversarial Networks by\n  Using the Normalised Laplacian Pyramid Distance", "comments": null, "journal-ref": "Proceedings of the Northern Lights Deep Learning Workshop. Vol. 1.\n  2020", "doi": "10.7557/18.5124", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years there has been a growing interest in image generation through\ndeep learning. While an important part of the evaluation of the generated\nimages usually involves visual inspection, the inclusion of human perception as\na factor in the training process is often overlooked. In this paper we propose\nan alternative perceptual regulariser for image-to-image translation using\nconditional generative adversarial networks (cGANs). To do so automatically\n(avoiding visual inspection), we use the Normalised Laplacian Pyramid Distance\n(NLPD) to measure the perceptual similarity between the generated image and the\noriginal image. The NLPD is based on the principle of normalising the value of\ncoefficients with respect to a local estimate of mean energy at different\nscales and has already been successfully tested in different experiments\ninvolving human perception. We compare this regulariser with the originally\nproposed L1 distance and note that when using NLPD the generated images contain\nmore realistic values for both local and global contrast. We found that using\nNLPD as a regulariser improves image segmentation accuracy on generated images\nas well as improving two no-reference image quality metrics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 08:33:51 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 10:48:29 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Hepburn", "Alexander", ""], ["Laparra", "Valero", ""], ["McConville", "Ryan", ""], ["Santos-Rodriguez", "Raul", ""]]}, {"id": "1908.04355", "submitter": "Divyam Madaan", "authors": "Divyam Madaan, Jinwoo Shin, Sung Ju Hwang", "title": "Adversarial Neural Pruning with Latent Vulnerability Suppression", "comments": "Accepted to ICML 2020. Code available at\n  https://github.com/divyam3897/ANP_VS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the remarkable performance of deep neural networks on various\ncomputer vision tasks, they are known to be susceptible to adversarial\nperturbations, which makes it challenging to deploy them in real-world\nsafety-critical applications. In this paper, we conjecture that the leading\ncause of adversarial vulnerability is the distortion in the latent feature\nspace, and provide methods to suppress them effectively. Explicitly, we define\n\\emph{vulnerability} for each latent feature and then propose a new loss for\nadversarial learning, \\emph{Vulnerability Suppression (VS)} loss, that aims to\nminimize the feature-level vulnerability during training. We further propose a\nBayesian framework to prune features with high vulnerability to reduce both\nvulnerability and loss on adversarial samples. We validate our\n\\emph{Adversarial Neural Pruning with Vulnerability Suppression (ANP-VS)}\nmethod on multiple benchmark datasets, on which it not only obtains\nstate-of-the-art adversarial robustness but also improves the performance on\nclean examples, using only a fraction of the parameters used by the full\nnetwork. Further qualitative analysis suggests that the improvements come from\nthe suppression of feature-level vulnerability.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 19:33:58 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 08:48:00 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2019 07:14:39 GMT"}, {"version": "v4", "created": "Thu, 2 Jul 2020 13:47:36 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Madaan", "Divyam", ""], ["Shin", "Jinwoo", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1908.04387", "submitter": "Muhammad Hamdan", "authors": "Muhammad K A Hamdan, Daine T. Rover, Matthew J. Darr, and John Just", "title": "Mass Estimation from Images using Deep Neural Network and Sparse Ground\n  Truth", "comments": "9 pages, 19 figures, pre-print NIPS2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Supervised learning is the workhorse for regression and classification tasks,\nbut the standard approach presumes ground truth for every measurement. In real\nworld applications, limitations due to expense or general in-feasibility due to\nthe specific application are common. In the context of agriculture\napplications, yield monitoring is one such example where simple-physics based\nmeasurements such as volume or force-impact have been used to quantify mass\nflow, which incur error due to sensor calibration. By utilizing semi-supervised\ndeep learning with gradient aggregation and a sequence of images, in this work\nwe can accurately estimate a physical quantity (mass) with complex data\nstructures and sparse ground truth. Using a vision system capturing images of a\nsugarcane elevator and running bamboo under controlled testing as a surrogate\nmaterial to harvesting sugarcane, mass is accurately predicted from images by\ntraining a DNN using only final load weights. The DNN succeeds in capturing the\ncomplex density physics of random stacking of slender rods internally as part\nof the mass prediction model, and surpasses older volumetric-based methods for\nmass prediction. Furthermore, by incorporating knowledge about the system\nphysics through the DNN architecture and penalty terms, improvements in\nprediction accuracy and stability, as well as faster learning are obtained. It\nis shown that the classic nonlinear regression optimization can be reformulated\nwith an aggregation term with some independence assumptions to achieve this\nfeat. Since the number of images for any given run are too large to fit on\ntypical GPU vRAM, an implementation is shown that compensates for the limited\nmemory but still achieve fast training times. The same approach presented\nherein could be applied to other applications like yield monitoring on grain\ncombines or other harvesters using vision or other instrumentation.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 02:59:18 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 21:08:43 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2019 17:46:09 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Hamdan", "Muhammad K A", ""], ["Rover", "Daine T.", ""], ["Darr", "Matthew J.", ""], ["Just", "John", ""]]}, {"id": "1908.04389", "submitter": "Moustafa Alzantot", "authors": "Moustafa Alzantot, Amy Widdicombe, Simon Julier, Mani Srivastava", "title": "NeuroMask: Explaining Predictions of Deep Neural Networks through Mask\n  Learning", "comments": null, "journal-ref": "Published in the DAIS 2019 - Workshop on Distributed Analytics\n  InfraStructure and Algorithms for Multi-Organization Federations", "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) deliver state-of-the-art performance in many\nimage recognition and understanding applications. However, despite their\noutstanding performance, these models are black-boxes and it is hard to\nunderstand how they make their decisions. Over the past few years, researchers\nhave studied the problem of providing explanations of why DNNs predicted their\nresults. However, existing techniques are either obtrusive, requiring changes\nin model training, or suffer from low output quality. In this paper, we present\na novel method, NeuroMask, for generating an interpretable explanation of\nclassification model results. When applied to image classification models,\nNeuroMask identifies the image parts that are most important to classifier\nresults by applying a mask that hides/reveals different parts of the image,\nbefore feeding it back into the model. The mask values are tuned by minimizing\na properly designed cost function that preserves the classification result and\nencourages producing an interpretable mask. Experiments using state-of-the-art\nConvolutional Neural Networks for image recognition on different datasets\n(CIFAR-10 and ImageNet) show that NeuroMask successfully localizes the parts of\nthe input image which are most relevant to the DNN decision. By showing a\nvisual quality comparison between NeuroMask explanations and those of other\nmethods, we find NeuroMask to be both accurate and interpretable.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 07:33:30 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Alzantot", "Moustafa", ""], ["Widdicombe", "Amy", ""], ["Julier", "Simon", ""], ["Srivastava", "Mani", ""]]}, {"id": "1908.04392", "submitter": "Amir Mosavi Prof", "authors": "Husein Perez, Joseph H. M. Tah, Amir Mosavi", "title": "Deep Learning for Detecting Building Defects Using Convolutional Neural\n  Networks", "comments": "29 pages, 11 figures", "journal-ref": null, "doi": "10.20944/preprints201908.0068.v1", "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Clients are increasingly looking for fast and effective means to quickly and\nfrequently survey and communicate the condition of their buildings so that\nessential repairs and maintenance work can be done in a proactive and timely\nmanner before it becomes too dangerous and expensive. Traditional methods for\nthis type of work commonly comprise of engaging building surveyors to undertake\na condition assessment which involves a lengthy site inspection to produce a\nsystematic recording of the physical condition of the building elements,\nincluding cost estimates of immediate and projected long-term costs of renewal,\nrepair and maintenance of the building. Current asset condition assessment\nprocedures are extensively time consuming, laborious, and expensive and pose\nhealth and safety threats to surveyors, particularly at height and roof levels\nwhich are difficult to access. This paper aims at evaluating the application of\nconvolutional neural networks (CNN) towards an automated detection and\nlocalisation of key building defects, e.g., mould, deterioration, and stain,\nfrom images. The proposed model is based on pre-trained CNN classifier of\nVGG-16 (later compaired with ResNet-50, and Inception models), with class\nactivation mapping (CAM) for object localisation. The challenges and\nlimitations of the model in real-life applications have been identified. The\nproposed model has proven to be robust and able to accurately detect and\nlocalise building defects. The approach is being developed with the potential\nto scale-up and further advance to support automated detection of defects and\ndeterioration of buildings in real-time using mobile devices and drones.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 16:21:10 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Perez", "Husein", ""], ["Tah", "Joseph H. M.", ""], ["Mosavi", "Amir", ""]]}, {"id": "1908.04412", "submitter": "Alexei Novikov", "authors": "Miguel Moscoso, Alexei Novikov, George Papanicolaou, and Chrysoula\n  Tsogka", "title": "The Noise Collector for sparse recovery in high dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect sparse signals from noisy high-dimensional data is a\ntop priority in modern science and engineering. A sparse solution of the linear\nsystem $A \\rho = b_0$ can be found efficiently with an $l_1$-norm minimization\napproach if the data is noiseless. Detection of the signal's support from data\ncorrupted by noise is still a challenging problem, especially if the level of\nnoise must be estimated. We propose a new efficient approach that does not\nrequire any parameter estimation. We introduce the Noise Collector (NC) matrix\n$C$ and solve an augmented system $A \\rho + C \\eta = b_0 + e$, where $ e$ is\nthe noise. We show that the $l_1$-norm minimal solution of the augmented system\nhas zero false discovery rate for any level of noise and with probability that\ntends to one as the dimension of $ b_0$ increases to infinity. We also obtain\nexact support recovery if the noise is not too large, and develop a Fast Noise\nCollector Algorithm which makes the computational cost of solving the augmented\nsystem comparable to that of the original one. Finally, we demonstrate the\neffectiveness of the method in applications to passive array imaging.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:13:42 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Moscoso", "Miguel", ""], ["Novikov", "Alexei", ""], ["Papanicolaou", "George", ""], ["Tsogka", "Chrysoula", ""]]}, {"id": "1908.04436", "submitter": "Philip Bontrager", "authors": "Philip Bontrager, Ahmed Khalifa, Damien Anderson, Matthew Stephenson,\n  Christoph Salge, Julian Togelius", "title": "Superstition in the Network: Deep Reinforcement Learning Plays Deceptive\n  Games", "comments": "7 pages, 4 figures, Accepted at the 15th AAAI Conference on\n  Artificial Intelligence and Interactive Digital Entertainment (AIIDE 19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has learned to play many games well, but failed\non others. To better characterize the modes and reasons of failure of deep\nreinforcement learners, we test the widely used Asynchronous Actor-Critic (A2C)\nalgorithm on four deceptive games, which are specially designed to provide\nchallenges to game-playing agents. These games are implemented in the General\nVideo Game AI framework, which allows us to compare the behavior of\nreinforcement learning-based agents with planning agents based on tree search.\nWe find that several of these games reliably deceive deep reinforcement\nlearners, and that the resulting behavior highlights the shortcomings of the\nlearning algorithm. The particular ways in which agents fail differ from how\nplanning-based agents fail, further illuminating the character of these\nalgorithms. We propose an initial typology of deceptions which could help us\nbetter understand pitfalls and failure modes of (deep) reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 23:27:26 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Bontrager", "Philip", ""], ["Khalifa", "Ahmed", ""], ["Anderson", "Damien", ""], ["Stephenson", "Matthew", ""], ["Salge", "Christoph", ""], ["Togelius", "Julian", ""]]}, {"id": "1908.04457", "submitter": "Pedro Savarese", "authors": "Pedro Savarese", "title": "On the Convergence of AdaBound and its Connection to SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive gradient methods such as Adam have gained extreme popularity due to\ntheir success in training complex neural networks and less sensitivity to\nhyperparameter tuning compared to SGD. However, it has been recently shown that\nAdam can fail to converge and might cause poor generalization -- this lead to\nthe design of new, sophisticated adaptive methods which attempt to generalize\nwell while being theoretically reliable. In this technical report we focus on\nAdaBound, a promising, recently proposed optimizer. We present a stochastic\nconvex problem for which AdaBound can provably take arbitrarily long to\nconverge in terms of a factor which is not accounted for in the convergence\nrate guarantee of Luo et al. (2019). We present a new $O(\\sqrt T)$ regret\nguarantee under different assumptions on the bound functions, and provide\nempirical results on CIFAR suggesting that a specific form of momentum SGD can\nmatch AdaBound's performance while having less hyperparameters and lower\ncomputational costs.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 02:00:21 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 06:34:54 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Savarese", "Pedro", ""]]}, {"id": "1908.04463", "submitter": "Haibin Chang", "authors": "Hao Xu, Haibin Chang, Dongxiao Zhang", "title": "DL-PDE: Deep-learning based data-driven discovery of partial\n  differential equations from discrete and noisy data", "comments": null, "journal-ref": "Communications in Computational Physics. 2021, 29, 698-728", "doi": "10.4208/cicp.OA-2020-0142", "report-no": null, "categories": "stat.ML cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, data-driven methods have been developed to learn dynamical\nsystems and partial differential equations (PDE). The goal of such work is\ndiscovering unknown physics and the corresponding equations. However, prior to\nachieving this goal, major challenges remain to be resolved, including learning\nPDE under noisy data and limited discrete data. To overcome these challenges,\nin this work, a deep-learning based data-driven method, called DL-PDE, is\ndeveloped to discover the governing PDEs of underlying physical processes. The\nDL-PDE method combines deep learning via neural networks and data-driven\ndiscovery of PDE via sparse regressions. In the DL-PDE, a neural network is\nfirst trained, and then a large amount of meta-data is generated, and the\nrequired derivatives are calculated by automatic differentiation. Finally, the\nform of PDE is discovered by sparse regression. The proposed method is tested\nwith physical processes, governed by groundwater flow equation,\nconvection-diffusion equation, Burgers equation and Korteweg-de Vries (KdV)\nequation, for proof-of-concept and applications in real-world engineering\nsettings. The proposed method achieves satisfactory results when data are noisy\nand limited.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 02:26:14 GMT"}, {"version": "v2", "created": "Mon, 6 Apr 2020 12:17:35 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Xu", "Hao", ""], ["Chang", "Haibin", ""], ["Zhang", "Dongxiao", ""]]}, {"id": "1908.04468", "submitter": "Fred Zhang", "authors": "Zhixian Lei, Kyle Luh, Prayaag Venkat, Fred Zhang", "title": "A Fast Spectral Algorithm for Mean Estimation with Sub-Gaussian Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DS cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the algorithmic problem of estimating the mean of heavy-tailed\nrandom vector in $\\mathbb{R}^d$, given $n$ i.i.d. samples. The goal is to\ndesign an efficient estimator that attains the optimal sub-gaussian error\nbound, only assuming that the random vector has bounded mean and covariance.\nPolynomial-time solutions to this problem are known but have high runtime due\nto their use of semi-definite programming (SDP). Conceptually, it remains open\nwhether convex relaxation is truly necessary for this problem.\n  In this work, we show that it is possible to go beyond SDP and achieve better\ncomputational efficiency. In particular, we provide a spectral algorithm that\nachieves the optimal statistical performance and runs in time $\\widetilde\nO\\left(n^2 d \\right)$, improving upon the previous fastest runtime $\\widetilde\nO\\left(n^{3.5}+ n^2d\\right)$ by Cherapanamjeri el al. (COLT '19). Our algorithm\nis spectral in that it only requires (approximate) eigenvector computations,\nwhich can be implemented very efficiently by, for example, power iteration or\nthe Lanczos method.\n  At the core of our algorithm is a novel connection between the furthest\nhyperplane problem introduced by Karnin et al. (COLT '12) and a structural\nlemma on heavy-tailed distributions by Lugosi and Mendelson (Ann. Stat. '19).\nThis allows us to iteratively reduce the estimation error at a geometric rate\nusing only the information derived from the top singular vector of the data\nmatrix, leading to a significantly faster running time.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 02:56:01 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2020 22:56:41 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Lei", "Zhixian", ""], ["Luh", "Kyle", ""], ["Venkat", "Prayaag", ""], ["Zhang", "Fred", ""]]}, {"id": "1908.04470", "submitter": "Daohong Xiang", "authors": "Jun Fan and Dao-Hong Xiang", "title": "Comparison theorems on large-margin learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies binary classification problem associated with a family of\nloss functions called large-margin unified machines (LUM), which offers a\nnatural bridge between distribution-based likelihood approaches and\nmargin-based approaches. It also can overcome the so-called data piling issue\nof support vector machine in the high-dimension and low-sample size setting. In\nthis paper we establish some new comparison theorems for all LUM loss functions\nwhich play a key role in the further error analysis of large-margin learning\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:06:39 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Fan", "Jun", ""], ["Xiang", "Dao-Hong", ""]]}, {"id": "1908.04471", "submitter": "Kohei Hayashi", "authors": "Kohei Hayashi, Taiki Yamaguchi, Yohei Sugawara, Shin-ichi Maeda", "title": "Einconv: Exploring Unexplored Tensor Network Decompositions for\n  Convolutional Neural Networks", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decomposition methods are widely used for model compression and fast\ninference in convolutional neural networks (CNNs). Although many decompositions\nare conceivable, only CP decomposition and a few others have been applied in\npractice, and no extensive comparisons have been made between available\nmethods. Previous studies have not determined how many decompositions are\navailable, nor which of them is optimal. In this study, we first characterize a\ndecomposition class specific to CNNs by adopting a flexible graphical notation.\nThe class includes such well-known CNN modules as depthwise separable\nconvolution layers and bottleneck layers, but also previously unknown modules\nwith nonlinear activations. We also experimentally compare the tradeoff between\nprediction accuracy and time/space complexity for modules found by enumerating\nall possible decompositions, or by using a neural architecture search. We find\nsome nonlinear decompositions outperform existing ones.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:11:46 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 09:08:40 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Hayashi", "Kohei", ""], ["Yamaguchi", "Taiki", ""], ["Sugawara", "Yohei", ""], ["Maeda", "Shin-ichi", ""]]}, {"id": "1908.04473", "submitter": "Mohammad Shojafar", "authors": "Rahim Taheri, Reza Javidan, Mohammad Shojafar, Zahra Pooranian, Ali\n  Miri, Mauro Conti", "title": "On Defending Against Label Flipping Attacks on Malware Detection Systems", "comments": "21 pages, 6 figures, 4 tables, NCAA Springer Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Label manipulation attacks are a subclass of data poisoning attacks in\nadversarial machine learning used against different applications, such as\nmalware detection. These types of attacks represent a serious threat to\ndetection systems in environments having high noise rate or uncertainty, such\nas complex networks and Internet of Thing (IoT). Recent work in the literature\nhas suggested using the $K$-Nearest Neighboring (KNN) algorithm to defend\nagainst such attacks. However, such an approach can suffer from low to wrong\ndetection accuracy. In this paper, we design an architecture to tackle the\nAndroid malware detection problem in IoT systems. We develop an attack\nmechanism based on Silhouette clustering method, modified for mobile Android\nplatforms. We proposed two Convolutional Neural Network (CNN)-type deep\nlearning algorithms against this \\emph{Silhouette Clustering-based Label\nFlipping Attack (SCLFA)}. We show the effectiveness of these two defense\nalgorithms - \\emph{Label-based Semi-supervised Defense (LSD)} and\n\\emph{clustering-based Semi-supervised Defense (CSD)} - in correcting labels\nbeing attacked. We evaluate the performance of the proposed algorithms by\nvarying the various machine learning parameters on three Android datasets:\nDrebin, Contagio, and Genome and three types of features: API, intent, and\npermission. Our evaluation shows that using random forest feature selection and\nvarying ratios of features can result in an improvement of up to 19\\% accuracy\nwhen compared with the state-of-the-art method in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:31:33 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 13:19:50 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 08:35:34 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Taheri", "Rahim", ""], ["Javidan", "Reza", ""], ["Shojafar", "Mohammad", ""], ["Pooranian", "Zahra", ""], ["Miri", "Ali", ""], ["Conti", "Mauro", ""]]}, {"id": "1908.04494", "submitter": "Mike Wu", "authors": "Mike Wu, Sonali Parbhoo, Michael Hughes, Ryan Kindle, Leo Celi,\n  Maurizio Zazzi, Volker Roth, and Finale Doshi-Velez", "title": "Regional Tree Regularization for Interpretability in Black Box Models", "comments": "AAAI 2020 (Oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of interpretability remains a barrier to the adoption of deep neural\nnetworks. Recently, tree regularization has been proposed to encourage deep\nneural networks to resemble compact, axis-aligned decision trees without\nsignificant compromises in accuracy. However, it may be unreasonable to expect\nthat a single tree can predict well across all possible inputs. In this work,\nwe propose regional tree regularization, which encourages a deep model to be\nwell-approximated by several separate decision trees specific to predefined\nregions of the input space. Practitioners can define regions based on domain\nknowledge of contexts where different decision-making logic is needed. Across\nmany datasets, our approach delivers more accurate predictions than simply\ntraining separate decision trees for each region, while producing simpler\nexplanations than other neural net regularization schemes without sacrificing\npredictive power. Two healthcare case studies in critical care and HIV\ndemonstrate how experts can improve understanding of deep models via our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 05:32:00 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 18:39:11 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2020 17:23:07 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Wu", "Mike", ""], ["Parbhoo", "Sonali", ""], ["Hughes", "Michael", ""], ["Kindle", "Ryan", ""], ["Celi", "Leo", ""], ["Zazzi", "Maurizio", ""], ["Roth", "Volker", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1908.04537", "submitter": "Wenbo Gong", "authors": "Wenbo Gong, Sebastian Tschiatschek, Richard Turner, Sebastian Nowozin,\n  Jos\\'e Miguel Hern\\'andez-Lobato, Cheng Zhang", "title": "Icebreaker: Element-wise Active Information Acquisition with Bayesian\n  Deep Latent Gaussian Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce the ice-start problem, i.e., the challenge of\ndeploying machine learning models when only little or no training data is\ninitially available, and acquiring each feature element of data is associated\nwith costs. This setting is representative for the real-world machine learning\napplications. For instance, in the health-care domain, when training an AI\nsystem for predicting patient metrics from lab tests, obtaining every single\nmeasurement comes with a high cost. Active learning, where only the label is\nassociated with a cost does not apply to such problem, because performing all\npossible lab tests to acquire a new training datum would be costly, as well as\nunnecessary due to redundancy. We propose Icebreaker, a principled framework to\napproach the ice-start problem. Icebreaker uses a full Bayesian Deep Latent\nGaussian Model (BELGAM) with a novel inference method. Our proposed method\ncombines recent advances in amortized inference and stochastic gradient MCMC to\nenable fast and accurate posterior inference. By utilizing BELGAM's ability to\nfully quantify model uncertainty, we also propose two information acquisition\nfunctions for imputation and active prediction problems. We demonstrate that\nBELGAM performs significantly better than the previous VAE (Variational\nautoencoder) based models, when the data set size is small, using both machine\nlearning benchmarks and real-world recommender systems and health-care\napplications. Moreover, based on BELGAM, Icebreaker further improves the\nperformance and demonstrate the ability to use minimum amount of the training\ndata to obtain the highest test time performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 08:49:33 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 09:20:57 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Gong", "Wenbo", ""], ["Tschiatschek", "Sebastian", ""], ["Turner", "Richard", ""], ["Nowozin", "Sebastian", ""], ["Hern\u00e1ndez-Lobato", "Jos\u00e9 Miguel", ""], ["Zhang", "Cheng", ""]]}, {"id": "1908.04538", "submitter": "Esther Puyol-Anton Miss", "authors": "Esther Puyol-Ant\\'on, Bram Ruijsink, James R. Clough, Ilkay Oksuz,\n  Daniel Rueckert, Reza Razavi, Andrew P. King", "title": "Assessing the Impact of Blood Pressure on Cardiac Function Using\n  Interpretable Biomarkers and Variational Autoencoders", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-39074-7_3", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining good cardiac function for as long as possible is a major concern\nfor healthcare systems worldwide and there is much interest in learning more\nabout the impact of different risk factors on cardiac health. The aim of this\nstudy is to analyze the impact of systolic blood pressure (SBP) on cardiac\nfunction while preserving the interpretability of the model using known\nclinical biomarkers in a large cohort of the UK Biobank population. We propose\na novel framework that combines deep learning based estimation of interpretable\nclinical biomarkers from cardiac cine MR data with a variational autoencoder\n(VAE). The VAE architecture integrates a regression loss in the latent space,\nwhich enables the progression of cardiac health with SBP to be learnt. Results\non 3,600 subjects from the UK Biobank show that the proposed model allows us to\ngain important insight into the deterioration of cardiac function with\nincreasing SBP, identify key interpretable factors involved in this process,\nand lastly exploit the model to understand patterns of positive and adverse\nadaptation of cardiac function.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 08:49:58 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Puyol-Ant\u00f3n", "Esther", ""], ["Ruijsink", "Bram", ""], ["Clough", "James R.", ""], ["Oksuz", "Ilkay", ""], ["Rueckert", "Daniel", ""], ["Razavi", "Reza", ""], ["King", "Andrew P.", ""]]}, {"id": "1908.04562", "submitter": "Jenni Raitoharju", "authors": "Jenni Raitoharju and Alexandros Iosifidis", "title": "Null Space Analysis for Class-Specific Discriminant Learning", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we carry out null space analysis for Class-Specific\nDiscriminant Analysis (CSDA) and formulate a number of solutions based on the\nanalysis. We analyze both theoretically and experimentally the significance of\neach algorithmic step. The innate subspace dimensionality resulting from the\nproposed solutions is typically quite high and we discuss how the need for\nfurther dimensionality reduction changes the situation. Experimental evaluation\nof the proposed solutions shows that the straightforward extension of null\nspace analysis approaches to the class-specific setting can outperform the\nstandard CSDA method. Furthermore, by exploiting a recently proposed\nout-of-class scatter definition encoding the multi-modality of the negative\nclass naturally appearing in class-specific problems, null space projections\ncan lead to a performance comparable to or outperforming the most recent CSDA\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 09:34:15 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Raitoharju", "Jenni", ""], ["Iosifidis", "Alexandros", ""]]}, {"id": "1908.04573", "submitter": "Yue Wang", "authors": "Yue Wang, Yao Wan, Chenwei Zhang, Lixin Cui, Lu Bai, and Philip S. Yu", "title": "Competitive Multi-Agent Deep Reinforcement Learning with Counterfactual\n  Thinking", "comments": "This paper is accepted by ICDM'19 as a short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual thinking describes a psychological phenomenon that people\nre-infer the possible results with different solutions about things that have\nalready happened. It helps people to gain more experience from mistakes and\nthus to perform better in similar future tasks. This paper investigates the\ncounterfactual thinking for agents to find optimal decision-making strategies\nin multi-agent reinforcement learning environments. In particular, we propose a\nmulti-agent deep reinforcement learning model with a structure which mimics the\nhuman-psychological counterfactual thinking process to improve the competitive\nabilities for agents. To this end, our model generates several possible actions\n(intent actions) with a parallel policy structure and estimates the rewards and\nregrets for these intent actions based on its current understanding of the\nenvironment. Our model incorporates a scenario-based framework to link the\nestimated regrets with its inner policies. During the iterations, our model\nupdates the parallel policies and the corresponding scenario-based regrets for\nagents simultaneously. To verify the effectiveness of our proposed model, we\nconduct extensive experiments on two different environments with real-world\napplications. Experimental results show that counterfactual thinking can\nactually benefit the agents to obtain more accumulative rewards from the\nenvironments with fair information by comparing to their opponents while\nkeeping high performing efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 10:55:24 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 13:40:16 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Wang", "Yue", ""], ["Wan", "Yao", ""], ["Zhang", "Chenwei", ""], ["Cui", "Lixin", ""], ["Bai", "Lu", ""], ["Yu", "Philip S.", ""]]}, {"id": "1908.04628", "submitter": "Xindi Wang", "authors": "Xindi Wang, Onur Varol, Tina Eliassi-Rad", "title": "L2P: An Algorithm for Estimating Heavy-tailed Outcomes", "comments": "9 pages, 6 figures, 2 tables Nature of changes from previous version:\n  1. Added complexity analysis in Section 2.2 2. Datasets change 3. Added\n  LambdaMART in the baseline methods, also a brief discussion on why LambdaMart\n  failed in our problem. 4. Figure updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world prediction tasks have outcome variables that have\ncharacteristic heavy-tail distributions. Examples include copies of books sold,\nauction prices of art pieces, demand for commodities in warehouses, etc. By\nlearning heavy-tailed distributions, \"big and rare\" instances (e.g., the\nbest-sellers) will have accurate predictions. Most existing approaches are not\ndedicated to learning heavy-tailed distribution; thus, they heavily\nunder-predict such instances. To tackle this problem, we introduce Learning to\nPlace (L2P), which exploits the pairwise relationships between instances for\nlearning. In its training phase, L2P learns a pairwise preference classifier:\nis instance A > instance B? In its placing phase, L2P obtains a prediction by\nplacing the new instance among the known instances. Based on its placement, the\nnew instance is then assigned a value for its outcome variable. Experiments on\nreal data show that L2P outperforms competing approaches in terms of accuracy\nand ability to reproduce heavy-tailed outcome distribution. In addition, L2P\nprovides an interpretable model by placing each predicted instance in relation\nto its comparable neighbors. Interpretable models are highly desirable when\nlives and treasure are at stake.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:20:50 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 13:15:46 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Wang", "Xindi", ""], ["Varol", "Onur", ""], ["Eliassi-Rad", "Tina", ""]]}, {"id": "1908.04705", "submitter": "Yu Emma Wang", "authors": "Yu Emma Wang, Carole-Jean Wu, Xiaodong Wang, Kim Hazelwood, David\n  Brooks", "title": "Exploiting Parallelism Opportunities with Deep Learning Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  State-of-the-art machine learning frameworks support a wide variety of design\nfeatures to enable a flexible machine learning programming interface and to\nease the programmability burden on machine learning developers. Identifying and\nusing a performance-optimal setting in feature-rich frameworks, however,\ninvolves a non-trivial amount of performance profiling efforts and often relies\non domain-specific knowledge. This paper takes a deep dive into analyzing the\nperformance impact of key design features in a machine learning framework and\nquantifies the role of parallelism. The observations and insights distill into\na simple set of guidelines that one can use to achieve much higher training and\ninference speedup. Across a diverse set of real-world deep learning models, the\nevaluation results show that the proposed performance tuning guidelines\noutperform the Intel and TensorFlow recommended settings by 1.29x and 1.34x,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:41:14 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 23:37:48 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Wang", "Yu Emma", ""], ["Wu", "Carole-Jean", ""], ["Wang", "Xiaodong", ""], ["Hazelwood", "Kim", ""], ["Brooks", "David", ""]]}, {"id": "1908.04710", "submitter": "Aur\\'elien Bellet", "authors": "William de Vazelhes and CJ Carey and Yuan Tang and Nathalie Vauquier\n  and Aur\\'elien Bellet", "title": "metric-learn: Metric Learning Algorithms in Python", "comments": "GitHub repository:\n  https://github.com/scikit-learn-contrib/metric-learn", "journal-ref": "Journal of Machine Learning Research (JMLR), 21(138):1-6, 2020", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  metric-learn is an open source Python package implementing supervised and\nweakly-supervised distance metric learning algorithms. As part of\nscikit-learn-contrib, it provides a unified interface compatible with\nscikit-learn which allows to easily perform cross-validation, model selection,\nand pipelining with other machine learning estimators. metric-learn is\nthoroughly tested and available on PyPi under the MIT licence.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:52:31 GMT"}, {"version": "v2", "created": "Wed, 1 Jul 2020 14:33:38 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2020 14:47:52 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["de Vazelhes", "William", ""], ["Carey", "CJ", ""], ["Tang", "Yuan", ""], ["Vauquier", "Nathalie", ""], ["Bellet", "Aur\u00e9lien", ""]]}, {"id": "1908.04741", "submitter": "Stefan Klus", "authors": "Feliks N\\\"uske, Patrick Gel{\\ss}, Stefan Klus, Cecilia Clementi", "title": "Tensor-based computation of metastable and coherent sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.LG cs.NA math.DS physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen rapid advances in the data-driven analysis of\ndynamical systems based on Koopman operator theory -- with extended dynamic\nmode decomposition (EDMD) being a cornerstone of the field. On the other hand,\nlow-rank tensor product approximations -- in particular the tensor train (TT)\nformat -- have become a valuable tool for the solution of large-scale problems\nin a number of fields. In this work, we combine EDMD and the TT format,\nenabling the application of EDMD to high-dimensional problems in conjunction\nwith a large set of features. We derive efficient algorithms to solve the EDMD\neigenvalue problem based on tensor representations of the data, and to project\nthe data into a low-dimensional representation defined by the eigenvectors. We\nextend this method to perform canonical correlation analysis (CCA) of\nnon-reversible or time-dependent systems. We prove that there is a physical\ninterpretation of the procedure and demonstrate its capabilities by applying\nthe method to several benchmark data sets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 15:53:14 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2020 08:12:55 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["N\u00fcske", "Feliks", ""], ["Gel\u00df", "Patrick", ""], ["Klus", "Stefan", ""], ["Clementi", "Cecilia", ""]]}, {"id": "1908.04742", "submitter": "Massimo Caccia", "authors": "Rahaf Aljundi, Lucas Caccia, Eugene Belilovsky, Massimo Caccia, Min\n  Lin, Laurent Charlin, Tinne Tuytelaars", "title": "Online Continual Learning with Maximally Interfered Retrieval", "comments": null, "journal-ref": "NeurIPS 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning, the setting where a learning agent is faced with a never\nending stream of data, continues to be a great challenge for modern machine\nlearning systems. In particular the online or \"single-pass through the data\"\nsetting has gained attention recently as a natural setting that is difficult to\ntackle. Methods based on replay, either generative or from a stored memory,\nhave been shown to be effective approaches for continual learning, matching or\nexceeding the state of the art in a number of standard benchmarks. These\napproaches typically rely on randomly selecting samples from the replay memory\nor from a generative model, which is suboptimal. In this work, we consider a\ncontrolled sampling of memories for replay. We retrieve the samples which are\nmost interfered, i.e. whose prediction will be most negatively impacted by the\nforeseen parameters update. We show a formulation for this sampling criterion\nin both the generative replay and the experience replay setting, producing\nconsistent gains in performance and greatly reduced forgetting. We release an\nimplementation of our method at\nhttps://github.com/optimass/Maximally_Interfered_Retrieval.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 21:16:44 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 20:15:04 GMT"}, {"version": "v3", "created": "Tue, 29 Oct 2019 18:45:10 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Aljundi", "Rahaf", ""], ["Caccia", "Lucas", ""], ["Belilovsky", "Eugene", ""], ["Caccia", "Massimo", ""], ["Lin", "Min", ""], ["Charlin", "Laurent", ""], ["Tuytelaars", "Tinne", ""]]}, {"id": "1908.04748", "submitter": "Michele Santacatterina", "authors": "Nathan Kallus, Michele Santacatterina", "title": "Optimal Estimation of Generalized Average Treatment Effects using Kernel\n  Optimal Matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In causal inference, a variety of causal effect estimands have been studied,\nincluding the sample, uncensored, target, conditional, optimal subpopulation,\nand optimal weighted average treatment effects. Ad-hoc methods have been\ndeveloped for each estimand based on inverse probability weighting (IPW) and on\noutcome regression modeling, but these may be sensitive to model\nmisspecification, practical violations of positivity, or both. The contribution\nof this paper is twofold. First, we formulate the generalized average treatment\neffect (GATE) to unify these causal estimands as well as their IPW estimates.\nSecond, we develop a method based on Kernel Optimal Matching (KOM) to optimally\nestimate GATE and to find the GATE most easily estimable by KOM, which we term\nthe Kernel Optimal Weighted Average Treatment Effect. KOM provides uniform\ncontrol on the conditional mean squared error of a weighted estimator over a\nclass of models while simultaneously controlling for precision. We study its\ntheoretical properties and evaluate its comparative performance in a simulation\nstudy. We illustrate the use of KOM for GATE estimation in two case studies:\ncomparing spine surgical interventions and studying the effect of peer support\non people living with HIV.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 17:09:02 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:21:44 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Kallus", "Nathan", ""], ["Santacatterina", "Michele", ""]]}, {"id": "1908.04752", "submitter": "Xiyan Cai", "authors": "Tongda Xu, Xiyan Cai, Yao Wang, Xiuyuan Wang, Sohae Chung, Els\n  Fieremans, Joseph Rath, Steven Flanagan, Yvonne W Lui", "title": "Identification of relevant diffusion MRI metrics impacting cognitive\n  functions using a novel feature selection method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mild Traumatic Brain Injury (mTBI) is a significant public health problem.\nThe most troubling symptoms after mTBI are cognitive complaints. Studies show\nmeasurable differences between patients with mTBI and healthy controls with\nrespect to tissue microstructure using diffusion MRI. However, it remains\nunclear which diffusion measures are the most informative with regard to\ncognitive functions in both the healthy state as well as after injury. In this\nstudy, we use diffusion MRI to formulate a predictive model for performance on\nworking memory based on the most relevant MRI features. The key challenge is to\nidentify relevant features over a large feature space with high accuracy in an\nefficient manner. To tackle this challenge, we propose a novel improvement of\nthe best first search approach with crossover operators inspired by genetic\nalgorithm. Compared against other heuristic feature selection algorithms, the\nproposed method achieves significantly more accurate predictions and yields\nclinically interpretable selected features.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 04:08:04 GMT"}, {"version": "v2", "created": "Mon, 11 Nov 2019 13:23:34 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Xu", "Tongda", ""], ["Cai", "Xiyan", ""], ["Wang", "Yao", ""], ["Wang", "Xiuyuan", ""], ["Chung", "Sohae", ""], ["Fieremans", "Els", ""], ["Rath", "Joseph", ""], ["Flanagan", "Steven", ""], ["Lui", "Yvonne W", ""]]}, {"id": "1908.04758", "submitter": "Philippe Terrier PhD", "authors": "Philippe Terrier", "title": "Gait recognition via deep learning of the center-of-pressure trajectory", "comments": "A revised and augmented version of this preprint has been published\n  in the journal Applied Sciences in January 2020", "journal-ref": "Appl. Sci. 2020, 10, 774", "doi": "10.3390/app10030774", "report-no": null, "categories": "q-bio.QM cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The fact that every human has a distinctive walking style has prompted a\nproposal to use gait recognition as an identification criterion. Using\nend-to-end learning, I investigated whether the center-of-pressure trajectory\nis sufficiently unique to identify a person with a high certainty. Thirty-six\nadults walked on a treadmill equipped with a force platform that recorded the\npositions of the center of pressure. The raw two-dimensional signals were\nsliced into segments of two gait cycles. A set of 20,250 segments from 30\nsubjects was used to configure and train convolutional neural networks (CNNs).\nThe best CNN classified a separate set containing 2,250 segments with 99.9%\noverall accuracy. A second set of 4,500 segments from the six remaining\nsubjects was then used for transfer learning. Several small subsamples of this\nset were selected randomly and used for fine tuning. Training with two segments\nper subject was sufficient to achieve 100% accuracy. The results suggest that\nevery person produces a unique trajectory of underfoot pressures and that CNNs\ncan learn the distinctive features of these trajectories. Using transfer\nlearning, a few strides could be sufficient to learn and identify new gaits.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:49:57 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 13:47:44 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 13:06:26 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Terrier", "Philippe", ""]]}, {"id": "1908.04759", "submitter": "Supreeth Prajwal Shashikumar", "authors": "Supreeth P. Shashikumar, Christopher Josef, Ashish Sharma and Shamim\n  Nemati", "title": "DeepAISE -- An End-to-End Development and Deployment of a Recurrent\n  Neural Survival Model for Early Prediction of Sepsis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sepsis, a dysregulated immune system response to infection, is among the\nleading causes of morbidity, mortality, and cost overruns in the Intensive Care\nUnit (ICU). Early prediction of sepsis can improve situational awareness\namongst clinicians and facilitate timely, protective interventions. While the\napplication of predictive analytics in ICU patients has shown early promising\nresults, much of the work has been encumbered by high false-alarm rates.\nEfforts to improve specificity have been limited by several factors, most\nnotably the difficulty of labeling sepsis onset time and the low prevalence of\nseptic-events in the ICU. Here, we present DeepAISE (Deep Artificial\nIntelligence Sepsis Expert), a recurrent neural survival model for the early\nprediction of sepsis. We show that by coupling a clinical criterion for\ndefining sepsis onset time with a treatment policy (e.g., initiation of\nantibiotics within one hour of meeting the criterion), one may rank the\nrelative utility of various criteria through offline policy evaluation. Given\nthe optimal criterion, DeepAISE automatically learns predictive features\nrelated to higher-order interactions and temporal patterns among clinical risk\nfactors that maximize the data likelihood of observed time to septic events.\nDeepAISE has been incorporated into a clinical workflow, which provides\nreal-time hourly sepsis risk scores. A comparative study of four baseline\nmodels indicates that DeepAISE produces the most accurate predictions (AUC=0.90\nand 0.87) and the lowest false alarm rates (FAR=0.20 and 0.26) in two separate\ncohorts (internal and external, respectively), while simultaneously producing\ninterpretable representations of the clinical time series and risk factors.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 19:36:39 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Shashikumar", "Supreeth P.", ""], ["Josef", "Christopher", ""], ["Sharma", "Ashish", ""], ["Nemati", "Shamim", ""]]}, {"id": "1908.04766", "submitter": "Zhaohong Deng", "authors": "Zhaohong Deng, Ruixiu Liu, Te Zhang, Peng Xu, Kup-Sze Choi, Bin Qin,\n  Shitong Wang", "title": "Multi-view Clustering with the Cooperation of Visible and Hidden Views", "comments": "This paper has been submitted to IEEE TKDE in Jun. 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view data are becoming common in real-world modeling tasks and many\nmulti-view data clustering algorithms have thus been proposed. The existing\nalgorithms usually focus on the cooperation of different views in the original\nspace but neglect the influence of the hidden information among these different\nvisible views, or they only consider the hidden information between the views.\nThe algorithms are therefore not efficient since the available information is\nnot fully excavated, particularly the otherness information in different views\nand the consistency information between them. In practice, the otherness and\nconsistency information in multi-view data are both very useful for effective\nclustering analyses. In this study, a Multi-View clustering algorithm developed\nwith the Cooperation of Visible and Hidden views, i.e., MV-Co-VH, is proposed.\nThe MV-Co-VH algorithm first projects the multiple views from different visible\nspaces to the common hidden space by using the non-negative matrix\nfactorization (NMF) strategy to obtain the common hidden view data.\nCollaborative learning is then implemented in the clustering procedure based on\nthe visible views and the shared hidden view. The results of extensive\nexperiments on UCI multi-view datasets and real-world image multi-view datasets\nshow that the clustering performance of the proposed algorithm is competitive\nwith or even better than that of the existing algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 14:55:22 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Deng", "Zhaohong", ""], ["Liu", "Ruixiu", ""], ["Zhang", "Te", ""], ["Xu", "Peng", ""], ["Choi", "Kup-Sze", ""], ["Qin", "Bin", ""], ["Wang", "Shitong", ""]]}, {"id": "1908.04769", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li, Nicha C. Dvornek, Juntang Zhuang, Pamela Ventola, and\n  James Duncan", "title": "Graph Embedding Using Infomax for ASD Classification and Brain\n  Functional Difference Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant progress has been made using fMRI to characterize the brain\nchanges that occur in ASD, a complex neuro-developmental disorder. However, due\nto the high dimensionality and low signal-to-noise ratio of fMRI, embedding\ninformative and robust brain regional fMRI representations for both graph-level\nclassification and region-level functional difference detection tasks between\nASD and healthy control (HC) groups is difficult. Here, we model the whole\nbrain fMRI as a graph, which preserves geometrical and temporal information and\nuse a Graph Neural Network (GNN) to learn from the graph-structured fMRI data.\nWe investigate the potential of including mutual information (MI) loss\n(Infomax), which is an unsupervised term encouraging large MI of each nodal\nrepresentation and its corresponding graph-level summarized representation to\nlearn a better graph embedding. Specifically, this work developed a pipeline\nincluding a GNN encoder, a classifier and a discriminator, which forces the\nencoded nodal representations to both benefit classification and reveal the\ncommon nodal patterns in a graph. We simultaneously optimize graph-level\nclassification loss and Infomax. We demonstrated that Infomax graph embedding\nimproves classification performance as a regularization term. Furthermore, we\nfound separable nodal representations of ASD and HC groups in prefrontal\ncortex, cingulate cortex, visual regions, and other social, emotional and\nexecution related brain regions. In contrast with GNN with classification loss\nonly, the proposed pipeline can facilitate training more robust ASD\nclassification models. Moreover, the separable nodal representations can detect\nthe functional differences between the two groups and contribute to revealing\nnew ASD biomarkers.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 05:25:46 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2019 00:22:03 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Dvornek", "Nicha C.", ""], ["Zhuang", "Juntang", ""], ["Ventola", "Pamela", ""], ["Duncan", "James", ""]]}, {"id": "1908.04771", "submitter": "Zhaohong Deng", "authors": "Zhaohong Deng, Chen Cui, Peng Xu, Ling Liang, Haoran Chen, Te Zhang,\n  Shitong Wang", "title": "Multi-View Fuzzy Clustering with The Alternative Learning between Shared\n  Hidden Space and Partition", "comments": "This paper has been submitted to IEEE Transactions on Cybnetics in\n  Apr. 8th 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the multi-view data grows in the real world, multi-view clus-tering has\nbecome a prominent technique in data mining, pattern recognition, and machine\nlearning. How to exploit the relation-ship between different views effectively\nusing the characteristic of multi-view data has become a crucial challenge.\nAiming at this, a hidden space sharing multi-view fuzzy clustering (HSS-MVFC)\nmethod is proposed in the present study. This method is based on the classical\nfuzzy c-means clustering model, and obtains associ-ated information between\ndifferent views by introducing shared hidden space. Especially, the shared\nhidden space and the fuzzy partition can be learned alternatively and\ncontribute to each other. Meanwhile, the proposed method uses maximum entropy\nstrategy to control the weights of different views while learning the shared\nhidden space. The experimental result shows that the proposed multi-view\nclustering method has better performance than many related clustering methods.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 14:44:07 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Deng", "Zhaohong", ""], ["Cui", "Chen", ""], ["Xu", "Peng", ""], ["Liang", "Ling", ""], ["Chen", "Haoran", ""], ["Zhang", "Te", ""], ["Wang", "Shitong", ""]]}, {"id": "1908.04847", "submitter": "Badr-Eddine Ch\\'erief-Abdellatif", "authors": "Badr-Eddine Ch\\'erief-Abdellatif", "title": "Convergence Rates of Variational Inference in Sparse Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational inference is becoming more and more popular for approximating\nintractable posterior distributions in Bayesian statistics and machine\nlearning. Meanwhile, a few recent works have provided theoretical justification\nand new insights on deep neural networks for estimating smooth functions in\nusual settings such as nonparametric regression. In this paper, we show that\nvariational inference for sparse deep learning retains the same generalization\nproperties than exact Bayesian inference. In particular, we highlight the\nconnection between estimation and approximation theories via the classical\nbias-variance trade-off and show that it leads to near-minimax rates of\nconvergence for H\\\"older smooth functions. Additionally, we show that the model\nselection framework over the neural network architecture via ELBO maximization\ndoes not overfit and adaptively achieves the optimal rate of convergence.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 18:50:09 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 21:27:21 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Ch\u00e9rief-Abdellatif", "Badr-Eddine", ""]]}, {"id": "1908.04849", "submitter": "Abir De", "authors": "Abir De and Soumen Chakrabarti", "title": "Differentially Private Link Prediction With Protected Connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Link prediction (LP) algorithms propose to each node a ranked list of nodes\nthat are currently non-neighbors, as the most likely candidates for future\nlinkage. Owing to increasing concerns about privacy, users (nodes) may prefer\nto keep some of their connections protected or private. Motivated by this\nobservation, our goal is to design a differentially private LP algorithm, which\ntrades off between privacy of the protected node-pairs and the link prediction\naccuracy. More specifically, we first propose a form of differential privacy on\ngraphs, which models the privacy loss only of those node-pairs which are marked\nas protected. Next, we develop DPLP , a learning to rank algorithm, which\napplies a monotone transform to base scores from a non-private LP system, and\nthen adds noise. DPLP is trained with a privacy induced ranking loss, which\noptimizes the ranking utility for a given maximum allowed level of privacy\nleakage of the protected node-pairs. Under a recently-introduced latent node\nembedding model, we present a formal trade-off between privacy and LP utility.\nExtensive experiments with several real-life graphs and several LP heuristics\nshow that DPLP can trade off between privacy and predictive performance more\neffectively than several alternatives.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 16:06:10 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 09:48:04 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["De", "Abir", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "1908.04904", "submitter": "Feng Li", "authors": "Xuening Zhu, Feng Li, Hansheng Wang", "title": "Least Squares Approximation for a Distributed System", "comments": null, "journal-ref": "Journal of Computational and Graphical Statistics 2021", "doi": "10.1080/10618600.2021.1923517", "report-no": null, "categories": "stat.ME cs.DC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we develop a distributed least squares approximation (DLSA)\nmethod that is able to solve a large family of regression problems (e.g.,\nlinear regression, logistic regression, and Cox's model) on a distributed\nsystem. By approximating the local objective function using a local quadratic\nform, we are able to obtain a combined estimator by taking a weighted average\nof local estimators. The resulting estimator is proved to be statistically as\nefficient as the global estimator. Moreover, it requires only one round of\ncommunication. We further conduct a shrinkage estimation based on the DLSA\nestimation using an adaptive Lasso approach. The solution can be easily\nobtained by using the LARS algorithm on the master node. It is theoretically\nshown that the resulting estimator possesses the oracle property and is\nselection consistent by using a newly designed distributed Bayesian information\ncriterion (DBIC). The finite sample performance and computational efficiency\nare further illustrated by an extensive numerical study and an airline dataset.\nThe airline dataset is 52 GB in size. The entire methodology has been\nimplemented in Python for a {\\it de-facto} standard Spark system. The proposed\nDLSA algorithm on the Spark system takes 26 minutes to obtain a logistic\nregression estimator, which is more efficient and memory friendly than\nconventional methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:05:21 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2019 01:46:47 GMT"}, {"version": "v3", "created": "Tue, 8 Dec 2020 07:11:52 GMT"}, {"version": "v4", "created": "Tue, 13 Apr 2021 09:53:50 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhu", "Xuening", ""], ["Li", "Feng", ""], ["Wang", "Hansheng", ""]]}, {"id": "1908.04909", "submitter": "Yan Xu", "authors": "Steven Gardner, Oleg Golovidov, Joshua Griffin, Patrick Koch, Wayne\n  Thompson, Brett Wujek and Yan Xu", "title": "Constrained Multi-Objective Optimization for Automated Machine Learning", "comments": "10 pages, 8 figures, accepted at DSAA 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated machine learning has gained a lot of attention recently. Building\nand selecting the right machine learning models is often a multi-objective\noptimization problem. General purpose machine learning software that\nsimultaneously supports multiple objectives and constraints is scant, though\nthe potential benefits are great. In this work, we present a framework called\nAutotune that effectively handles multiple objectives and constraints that\narise in machine learning problems. Autotune is built on a suite of\nderivative-free optimization methods, and utilizes multi-level parallelism in a\ndistributed computing environment for automatically training, scoring, and\nselecting good models. Incorporation of multiple objectives and constraints in\nthe model exploration and selection process provides the flexibility needed to\nsatisfy trade-offs necessary in practical machine learning applications.\nExperimental results from standard multi-objective optimization benchmark\nproblems show that Autotune is very efficient in capturing Pareto fronts. These\nbenchmark results also show how adding constraints can guide the search to more\npromising regions of the solution space, ultimately producing more desirable\nPareto fronts. Results from two real-world case studies demonstrate the\neffectiveness of the constrained multi-objective optimization capability\noffered by Autotune.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:31:45 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Gardner", "Steven", ""], ["Golovidov", "Oleg", ""], ["Griffin", "Joshua", ""], ["Koch", "Patrick", ""], ["Thompson", "Wayne", ""], ["Wujek", "Brett", ""], ["Xu", "Yan", ""]]}, {"id": "1908.04924", "submitter": "Mingyuan Bai", "authors": "Mingyuan Bai, S.T. Boris Choy, Xin Song, Junbin Gao", "title": "Tensor-Train Parameterization for Ultra Dimensionality Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locality preserving projections (LPP) are a classical dimensionality\nreduction method based on data graph information. However, LPP is still\nresponsive to extreme outliers. LPP aiming for vectorial data may undermine\ndata structural information when it is applied to multidimensional data.\nBesides, it assumes the dimension of data to be smaller than the number of\ninstances, which is not suitable for high-dimensional data. For\nhigh-dimensional data analysis, the tensor-train decomposition is proved to be\nable to efficiently and effectively capture the spatial relations. Thus, we\npropose a tensor-train parameterization for ultra dimensionality reduction\n(TTPUDR) in which the traditional LPP mapping is tensorized in terms of\ntensor-trains and the LPP objective is replaced with the Frobenius norm to\nincrease the robustness of the model. The manifold optimization technique is\nutilized to solve the new model. The performance of TTPUDR is assessed on\nclassification problems and TTPUDR significantly outperforms the past methods\nand the several state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 02:04:34 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Bai", "Mingyuan", ""], ["Choy", "S. T. Boris", ""], ["Song", "Xin", ""], ["Gao", "Junbin", ""]]}, {"id": "1908.04970", "submitter": "My Phan", "authors": "My Phan, Yasin Abbasi-Yadkori, Justin Domke", "title": "Thompson Sampling with Approximate Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effects of approximate inference on the performance of Thompson\nsampling in the $k$-armed bandit problems. Thompson sampling is a successful\nalgorithm for online decision-making but requires posterior inference, which\noften must be approximated in practice. We show that even small constant\ninference error (in $\\alpha$-divergence) can lead to poor performance (linear\nregret) due to under-exploration (for $\\alpha<1$) or over-exploration (for\n$\\alpha>0$) by the approximation. While for $\\alpha > 0$ this is unavoidable,\nfor $\\alpha \\leq 0$ the regret can be improved by adding a small amount of\nforced exploration even when the inference error is a large constant.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 06:09:15 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 02:56:12 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Phan", "My", ""], ["Abbasi-Yadkori", "Yasin", ""], ["Domke", "Justin", ""]]}, {"id": "1908.04979", "submitter": "Guoli Song", "authors": "Guoli Song, Shuhui Wang, Qingming Huang, Qi Tian", "title": "Harmonized Multimodal Learning with Gaussian Process Latent Variable\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal learning aims to discover the relationship between multiple\nmodalities. It has become an important research topic due to extensive\nmultimodal applications such as cross-modal retrieval. This paper attempts to\naddress the modality heterogeneity problem based on Gaussian process latent\nvariable models (GPLVMs) to represent multimodal data in a common space.\nPrevious multimodal GPLVM extensions generally adopt individual learning\nschemes on latent representations and kernel hyperparameters, which ignore\ntheir intrinsic relationship. To exploit strong complementarity among different\nmodalities and GPLVM components, we develop a novel learning scheme called\nHarmonization, where latent model parameters are jointly learned from each\nother. Beyond the correlation fitting or intra-modal structure preservation\nparadigms widely used in existing studies, the harmonization is derived in a\nmodel-driven manner to encourage the agreement between modality-specific GP\nkernels and the similarity of latent representations. We present a range of\nmultimodal learning models by incorporating the harmonization mechanism into\nseveral representative GPLVM-based approaches. Experimental results on four\nbenchmark datasets show that the proposed models outperform the strong\nbaselines for cross-modal retrieval tasks, and that the harmonized multimodal\nlearning method is superior in discovering semantically consistent latent\nrepresentation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 06:40:28 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Song", "Guoli", ""], ["Wang", "Shuhui", ""], ["Huang", "Qingming", ""], ["Tian", "Qi", ""]]}, {"id": "1908.05006", "submitter": "Jake Lee", "authors": "Jake H. Lee, Kiri L. Wagstaff", "title": "Visualizing Image Content to Explain Novel Image Discovery", "comments": "Under Review", "journal-ref": null, "doi": "10.1007/s10618-020-00700-0", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The initial analysis of any large data set can be divided into two phases:\n(1) the identification of common trends or patterns and (2) the identification\nof anomalies or outliers that deviate from those trends. We focus on the goal\nof detecting observations with novel content, which can alert us to artifacts\nin the data set or, potentially, the discovery of previously unknown phenomena.\nTo aid in interpreting and diagnosing the novel aspect of these selected\nobservations, we recommend the use of novelty detection methods that generate\nexplanations. In the context of large image data sets, these explanations\nshould highlight what aspect of a given image is new (color, shape, texture,\ncontent) in a human-comprehensible form. We propose DEMUD-VIS, the first method\nfor providing visual explanations of novel image content by employing a\nconvolutional neural network (CNN) to extract image features, a method that\nuses reconstruction error to detect novel content, and an up-convolutional\nnetwork to convert CNN feature representations back into image space. We\ndemonstrate this approach on diverse images from ImageNet, freshwater streams,\nand the surface of Mars.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 07:53:05 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Lee", "Jake H.", ""], ["Wagstaff", "Kiri L.", ""]]}, {"id": "1908.05081", "submitter": "Ke Sun", "authors": "Ke Sun, Zhanxing Zhu, Zhouchen Lin", "title": "AdaGCN: Adaboosting Graph Convolutional Networks into Deep Models", "comments": "Published on International Conference on Learning Representations\n  (ICLR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of deep graph models still remains to be investigated and the\ncrucial part is how to explore and exploit the knowledge from different hops of\nneighbors in an efficient way. In this paper, we propose a novel RNN-like deep\ngraph neural network architecture by incorporating AdaBoost into the\ncomputation of network; and the proposed graph convolutional network called\nAdaGCN~(Adaboosting Graph Convolutional Network) has the ability to efficiently\nextract knowledge from high-order neighbors of current nodes and then\nintegrates knowledge from different hops of neighbors into the network in an\nAdaboost way. Different from other graph neural networks that directly stack\nmany graph convolution layers, AdaGCN shares the same base neural network\narchitecture among all ``layers'' and is recursively optimized, which is\nsimilar to an RNN. Besides, We also theoretically established the connection\nbetween AdaGCN and existing graph convolutional methods, presenting the\nbenefits of our proposal. Finally, extensive experiments demonstrate the\nconsistent state-of-the-art prediction performance on graphs across different\nlabel rates and the computational advantage of our approach\nAdaGCN~\\footnote{Code is available at \\url{https://github.com/datake/AdaGCN}.}\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 11:41:09 GMT"}, {"version": "v2", "created": "Sun, 14 Jun 2020 08:08:04 GMT"}, {"version": "v3", "created": "Mon, 15 Mar 2021 10:19:52 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Sun", "Ke", ""], ["Zhu", "Zhanxing", ""], ["Lin", "Zhouchen", ""]]}, {"id": "1908.05085", "submitter": "Grigorios G. Anagnostopoulos Dr.", "authors": "Grigorios G. Anagnostopoulos, Alexandros Kalousis", "title": "A Reproducible Comparison of RSSI Fingerprinting Localization Methods\n  Using LoRaWAN", "comments": null, "journal-ref": null, "doi": "10.1109/WPNC47567.2019.8970177", "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of fingerprinting localization techniques in outdoor IoT settings has\nstarted to gain popularity over the recent years. Communication signals of Low\nPower Wide Area Networks (LPWAN), such as LoRaWAN, are used to estimate the\nlocation of low power mobile devices. In this study, a publicly available\ndataset of LoRaWAN RSSI measurements is utilized to compare different machine\nlearning methods and their accuracy in producing location estimates. The tested\nmethods are: the k Nearest Neighbours method, the Extra Trees method and a\nneural network approach using a Multilayer Perceptron. To facilitate the\nreproducibility of tests and the comparability of results, the code and the\ntrain/validation/test split of the dataset used in this study have become\navailable. The neural network approach was the method with the highest\naccuracy, achieving a mean error of 358 meters and a median error of 204\nmeters.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 11:59:08 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Anagnostopoulos", "Grigorios G.", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1908.05103", "submitter": "Lucas May Petry", "authors": "Lucas May Petry, Amilcar Soares, Vania Bogorny, Stan Matwin", "title": "Unsupervised Behavior Change Detection in Multidimensional Data Streams\n  for Maritime Traffic Monitoring", "comments": "Extended abstract submitted to the 2019 Montreal Artificial\n  Intelligence Symposium (MAIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The worldwide growth of maritime traffic and the development of the Automatic\nIdentification System (AIS) has led to advances in monitoring systems for\npreventing vessel accidents and detecting illegal activities. In this work, we\ndescribe research gaps and challenges in machine learning for vessel behavior\nchange and event detection, considering several constraints imposed by\nreal-time data streams and the maritime monitoring domain. As a starting point,\nwe investigate how unsupervised and semi-supervised change detection methods\nmay be employed for identifying shifts in vessel behavior, aiming to detect and\nlabel unusual events.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 12:53:20 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Petry", "Lucas May", ""], ["Soares", "Amilcar", ""], ["Bogorny", "Vania", ""], ["Matwin", "Stan", ""]]}, {"id": "1908.05161", "submitter": "Oren Barkan", "authors": "Oren Barkan, Noam Razin, Itzik Malkiel, Ori Katz, Avi Caciularu, Noam\n  Koenigstein", "title": "Scalable Attentive Sentence-Pair Modeling via Distilled Sentence\n  Embedding", "comments": "In Proceedings of AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent state-of-the-art natural language understanding models, such as BERT\nand XLNet, score a pair of sentences (A and B) using multiple cross-attention\noperations - a process in which each word in sentence A attends to all words in\nsentence B and vice versa. As a result, computing the similarity between a\nquery sentence and a set of candidate sentences, requires the propagation of\nall query-candidate sentence-pairs throughout a stack of cross-attention\nlayers. This exhaustive process becomes computationally prohibitive when the\nnumber of candidate sentences is large. In contrast, sentence embedding\ntechniques learn a sentence-to-vector mapping and compute the similarity\nbetween the sentence vectors via simple elementary operations. In this paper,\nwe introduce Distilled Sentence Embedding (DSE) - a model that is based on\nknowledge distillation from cross-attentive models, focusing on sentence-pair\ntasks. The outline of DSE is as follows: Given a cross-attentive teacher model\n(e.g. a fine-tuned BERT), we train a sentence embedding based student model to\nreconstruct the sentence-pair scores obtained by the teacher model. We\nempirically demonstrate the effectiveness of DSE on five GLUE sentence-pair\ntasks. DSE significantly outperforms several ELMO variants and other sentence\nembedding methods, while accelerating computation of the query-candidate\nsentence-pairs similarities by several orders of magnitude, with an average\nrelative degradation of 4.6% compared to BERT. Furthermore, we show that DSE\nproduces sentence embeddings that reach state-of-the-art performance on\nuniversal sentence representation benchmarks. Our code is made publicly\navailable at https://github.com/microsoft/Distilled-Sentence-Embedding.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:06:48 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 17:57:57 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 06:38:18 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Barkan", "Oren", ""], ["Razin", "Noam", ""], ["Malkiel", "Itzik", ""], ["Katz", "Ori", ""], ["Caciularu", "Avi", ""], ["Koenigstein", "Noam", ""]]}, {"id": "1908.05164", "submitter": "Antoine Wehenkel", "authors": "Antoine Wehenkel and Gilles Louppe", "title": "Unconstrained Monotonic Neural Networks", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monotonic neural networks have recently been proposed as a way to define\ninvertible transformations. These transformations can be combined into powerful\nautoregressive flows that have been shown to be universal approximators of\ncontinuous probability distributions. Architectures that ensure monotonicity\ntypically enforce constraints on weights and activation functions, which\nenables invertibility but leads to a cap on the expressiveness of the resulting\ntransformations. In this work, we propose the Unconstrained Monotonic Neural\nNetwork (UMNN) architecture based on the insight that a function is monotonic\nas long as its derivative is strictly positive. In particular, this latter\ncondition can be enforced with a free-form neural network whose only constraint\nis the positiveness of its output. We evaluate our new invertible building\nblock within a new autoregressive flow (UMNN-MAF) and demonstrate its\neffectiveness on density estimation experiments. We also illustrate the ability\nof UMNNs to improve variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:11:31 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 14:25:18 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 10:01:36 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Wehenkel", "Antoine", ""], ["Louppe", "Gilles", ""]]}, {"id": "1908.05227", "submitter": "Subhadeep Dey", "authors": "Subhadeep Dey, Petr Motlicek, Trung Bui and Franck Dernoncourt", "title": "Exploiting semi-supervised training through a dropout regularization in\n  end-to-end speech recognition", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.LG cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore various approaches for semi supervised learning in\nan end to end automatic speech recognition (ASR) framework. The first step in\nour approach involves training a seed model on the limited amount of labelled\ndata. Additional unlabelled speech data is employed through a data selection\nmechanism to obtain the best hypothesized output, further used to retrain the\nseed model. However, uncertainties of the model may not be well captured with a\nsingle hypothesis. As opposed to this technique, we apply a dropout mechanism\nto capture the uncertainty by obtaining multiple hypothesized text transcripts\nof an speech recording. We assume that the diversity of automatically generated\ntranscripts for an utterance will implicitly increase the reliability of the\nmodel. Finally, the data selection process is also applied on these\nhypothesized transcripts to reduce the uncertainty. Experiments on freely\navailable TEDLIUM corpus and proprietary Adobe's internal dataset show that the\nproposed approach significantly reduces ASR errors, compared to the baseline\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 19:21:49 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Dey", "Subhadeep", ""], ["Motlicek", "Petr", ""], ["Bui", "Trung", ""], ["Dernoncourt", "Franck", ""]]}, {"id": "1908.05254", "submitter": "Mike Wu", "authors": "Mike Wu, Sonali Parbhoo, Michael C. Hughes, Volker Roth, Finale\n  Doshi-Velez", "title": "Optimizing for Interpretability in Deep Neural Networks with Tree\n  Regularization", "comments": "arXiv admin note: substantial text overlap with arXiv:1908.04494,\n  arXiv:1711.06178", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep models have advanced prediction in many domains, but their lack of\ninterpretability remains a key barrier to the adoption in many real world\napplications. There exists a large body of work aiming to help humans\nunderstand these black box functions to varying levels of granularity -- for\nexample, through distillation, gradients, or adversarial examples. These\nmethods however, all tackle interpretability as a separate process after\ntraining. In this work, we take a different approach and explicitly regularize\ndeep models so that they are well-approximated by processes that humans can\nstep-through in little time. Specifically, we train several families of deep\nneural networks to resemble compact, axis-aligned decision trees without\nsignificant compromises in accuracy. The resulting axis-aligned decision\nfunctions uniquely make tree regularized models easy for humans to interpret.\nMoreover, for situations in which a single, global tree is a poor estimator, we\nintroduce a regional tree regularizer that encourages the deep model to\nresemble a compact, axis-aligned decision tree in predefined,\nhuman-interpretable contexts. Using intuitive toy examples as well as medical\ntasks for patients in critical care and with HIV, we demonstrate that this new\nfamily of tree regularizers yield models that are easier for humans to simulate\nthan simpler L1 or L2 penalties without sacrificing predictive power.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:35:03 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Wu", "Mike", ""], ["Parbhoo", "Sonali", ""], ["Hughes", "Michael C.", ""], ["Roth", "Volker", ""], ["Doshi-Velez", "Finale", ""]]}, {"id": "1908.05265", "submitter": "Yang Hu", "authors": "Yang Hu and Giovanni Montana", "title": "Skill Transfer in Deep Reinforcement Learning under Morphological\n  Heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning methods for reinforcement learning (RL) domains facilitate\nthe acquisition of new skills using previously acquired knowledge. The vast\nmajority of existing approaches assume that the agents have the same design,\ne.g. same shape and action spaces. In this paper we address the problem of\ntransferring previously acquired skills amongst morphologically different\nagents (MDAs). For instance, assuming that a bipedal agent has been trained to\nmove forward, could this skill be transferred on to a one-leg hopper so as to\nmake its training process for the same task more sample efficient? We frame\nthis problem as one of subspace learning whereby we aim to infer latent factors\nrepresenting the control mechanism that is common between MDAs. We propose a\nnovel paired variational encoder-decoder model, PVED, that disentangles the\ncontrol of MDAs into shared and agent-specific factors. The shared factors are\nthen leveraged for skill transfer using RL. Theoretically, we derive a theorem\nindicating how the performance of PVED depends on the shared factors and agent\nmorphologies. Experimentally, PVED has been extensively validated on four\nMuJoCo environments. We demonstrate its performance compared to a\nstate-of-the-art approach and several ablation cases, visualize and interpret\nthe hidden factors, and identify avenues for future improvements.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:42:43 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 14:31:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Hu", "Yang", ""], ["Montana", "Giovanni", ""]]}, {"id": "1908.05287", "submitter": "Mohsen Shahhosseini", "authors": "Mohsen Shahhosseini, Guiping Hu, Hieu Pham", "title": "Optimizing Ensemble Weights and Hyperparameters of Machine Learning\n  Models for Regression Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregating multiple learners through an ensemble of models aim to make\nbetter predictions by capturing the underlying distribution of the data more\naccurately. Different ensembling methods, such as bagging, boosting, and\nstacking/blending, have been studied and adopted extensively in research and\npractice. While bagging and boosting focus more on reducing variance and bias,\nrespectively, stacking approaches target both by finding the optimal way to\ncombine base learners. In stacking with the weighted average, ensembles are\ncreated from weighted averages of multiple base learners. It is known that\ntuning hyperparameters of each base learner inside the ensemble weight\noptimization process can produce better performing ensembles. To this end, an\noptimization-based nested algorithm that considers tuning hyperparameters as\nwell as finding the optimal weights to combine ensembles (Generalized Weighted\nEnsemble with Internally Tuned Hyperparameters (GEM-ITH)) is designed. Besides,\nBayesian search was used to speed-up the optimizing process, and a heuristic\nwas implemented to generate diverse and well-performing base learners. The\nalgorithm is shown to be generalizable to real data sets through analyses with\nten publicly available data sets.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:01:02 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 18:10:57 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 17:50:15 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 22:50:29 GMT"}, {"version": "v5", "created": "Sun, 19 Jan 2020 20:26:46 GMT"}, {"version": "v6", "created": "Sat, 31 Oct 2020 20:28:35 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Shahhosseini", "Mohsen", ""], ["Hu", "Guiping", ""], ["Pham", "Hieu", ""]]}, {"id": "1908.05304", "submitter": "Jiue-An Yang", "authors": "Jiayi Wang (1), Jiue-An Yang (2), Supun Nakandala (1), Arun Kumar (1),\n  Marta M. Jankowska (2) ((1) Computer Science and Engineering, University of\n  California San Diego, San Diego, USA (2) Qualcomm Institute/Calit2,\n  University of California San Diego, San Diego, USA)", "title": "Predicting Eating Events in Free Living Individuals -- A Technical\n  Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This technical report records the experiments of applying multiple machine\nlearning algorithms for predicting eating and food purchasing behaviors of\nfree-living individuals. Data was collected with accelerometer, global\npositioning system (GPS), and body-worn cameras called SenseCam over a one week\nperiod in 81 individuals from a variety of ages and demographic backgrounds.\nThese data were turned into minute-level features from sensors as well as\nengineered features that included time (e.g., time since last eating) and\nenvironmental context (e.g., distance to nearest grocery store). Algorithms\ninclude Logistic Regression, RBF-SVM, Random Forest, and Gradient Boosting. Our\nresults show that the Gradient Boosting model has the highest mean accuracy\nscore (0.7289) for predicting eating events before 0 to 4 minutes. For\npredicting food purchasing events, the RBF-SVM model (0.7395) outperforms\nothers. For both prediction models, temporal and spatial features were\nimportant contributors to predicting eating and food purchasing events.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:46:21 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Wang", "Jiayi", ""], ["Yang", "Jiue-An", ""], ["Nakandala", "Supun", ""], ["Kumar", "Arun", ""], ["Jankowska", "Marta M.", ""]]}, {"id": "1908.05339", "submitter": "Hyunji Moon", "authors": "Hyunji Moon, Bomi Song, Hyeonseop Lee", "title": "Mixed pooling of seasonality for time series forecasting: An application\n  to pallet transport data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiple seasonal patterns play a key role in time series forecasting,\nespecially for business time series where seasonal effects are often dramatic.\nPrevious approaches including Fourier decomposition, exponential smoothing, and\nseasonal autoregressive integrated moving average (SARIMA) models do not\nreflect the distinct characteristics of each period in seasonal patterns. We\npropose a mixed hierarchical seasonality (MHS) model. Intermediate parameters\nfor each seasonal period are first estimated, and a mixture of intermediate\nparameters is taken. This results in a model that automatically learns the\nrelative importance of each seasonality and addresses the interactions between\nthem. The model is implemented with Stan, a probabilistic language, and was\ncompared with three existing models on a real-world dataset of pallet transport\nfrom a logistic network. Our new model achieved considerable improvements in\nterms of out of sample prediction error (MAPE) and predictive density (ELPD)\ncompared to complete pooling, Fourier decomposition, and SARIMA model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 20:29:41 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2020 14:10:51 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Moon", "Hyunji", ""], ["Song", "Bomi", ""], ["Lee", "Hyeonseop", ""]]}, {"id": "1908.05348", "submitter": "Malte Schilling", "authors": "Malte Schilling, Helge Ritter, Frank W. Ohl", "title": "From Crystallized Adaptivity to Fluid Adaptivity in Deep Reinforcement\n  Learning -- Insights from Biological Systems on Adaptive Flexibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in machine-learning algorithms have led to impressive\nperformance increases in many traditional application scenarios of artificial\nintelligence research. In the area of deep reinforcement learning, deep\nlearning functional architectures are combined with incremental learning\nschemes for sequential tasks that include interaction-based, but often delayed\nfeedback. Despite their impressive successes, modern machine-learning\napproaches, including deep reinforcement learning, still perform weakly when\ncompared to flexibly adaptive biological systems in certain naturally occurring\nscenarios. Such scenarios include transfers to environments different than the\nones in which the training took place or environments that dynamically change,\nboth of which are often mastered by biological systems through a capability\nthat we here term \"fluid adaptivity\" to contrast it from the much slower\nadaptivity (\"crystallized adaptivity\") of the prior learning from which the\nbehavior emerged. In this article, we derive and discuss research strategies,\nbased on analyzes of fluid adaptivity in biological systems and its neuronal\nmodeling, that might aid in equipping future artificially intelligent systems\nwith capabilities of fluid adaptivity more similar to those seen in some\nbiologically intelligent systems. A key component of this research strategy is\nthe dynamization of the problem space itself and the implementation of this\ndynamization by suitably designed flexibly interacting modules.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 07:28:41 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Schilling", "Malte", ""], ["Ritter", "Helge", ""], ["Ohl", "Frank W.", ""]]}, {"id": "1908.05355", "submitter": "Song Mei", "authors": "Song Mei, Andrea Montanari", "title": "The generalization error of random features regression: Precise\n  asymptotics and double descent curve", "comments": "We reorganized the proofs of the main theorem", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods operate in regimes that defy the traditional\nstatistical mindset. Neural network architectures often contain more parameters\nthan training samples, and are so rich that they can interpolate the observed\nlabels, even if the latter are replaced by pure noise. Despite their huge\ncomplexity, the same architectures achieve small generalization error on real\ndata.\n  This phenomenon has been rationalized in terms of a so-called `double\ndescent' curve. As the model complexity increases, the test error follows the\nusual U-shaped curve at the beginning, first decreasing and then peaking around\nthe interpolation threshold (when the model achieves vanishing training error).\nHowever, it descends again as model complexity exceeds this threshold. The\nglobal minimum of the test error is found above the interpolation threshold,\noften in the extreme overparametrization regime in which the number of\nparameters is much larger than the number of samples. Far from being a peculiar\nproperty of deep neural networks, elements of this behavior have been\ndemonstrated in much simpler settings, including linear regression with random\ncovariates.\n  In this paper we consider the problem of learning an unknown function over\nthe $d$-dimensional sphere $\\mathbb S^{d-1}$, from $n$ i.i.d. samples\n$(\\boldsymbol x_i, y_i)\\in \\mathbb S^{d-1} \\times \\mathbb R$, $i\\le n$. We\nperform ridge regression on $N$ random features of the form $\\sigma(\\boldsymbol\nw_a^{\\mathsf T} \\boldsymbol x)$, $a\\le N$. This can be equivalently described\nas a two-layers neural network with random first-layer weights. We compute the\nprecise asymptotics of the test error, in the limit $N,n,d\\to \\infty$ with\n$N/d$ and $n/d$ fixed. This provides the first analytically tractable model\nthat captures all the features of the double descent phenomenon without\nassuming ad hoc misspecification structures.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 21:23:40 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 04:38:06 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 04:18:57 GMT"}, {"version": "v4", "created": "Wed, 9 Dec 2020 08:25:04 GMT"}, {"version": "v5", "created": "Fri, 11 Dec 2020 04:06:17 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Mei", "Song", ""], ["Montanari", "Andrea", ""]]}, {"id": "1908.05357", "submitter": "Hao Chen Dr.", "authors": "Hao Chen and William J. Welch", "title": "Sequential Computer Experimental Design for Estimating an Extreme\n  Probability or Quantile", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A computer code can simulate a system's propagation of variation from random\ninputs to output measures of quality. Our aim here is to estimate a critical\noutput tail probability or quantile without a large Monte Carlo experiment.\nInstead, we build a statistical surrogate for the input-output relationship\nwith a modest number of evaluations and then sequentially add further runs,\nguided by a criterion to improve the estimate. We compare two criteria in the\nliterature. Moreover, we investigate two practical questions: how to design the\ninitial code runs and how to model the input distribution. Hence, we close the\ngap between the theory of sequential design and its application.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 21:40:13 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Chen", "Hao", ""], ["Welch", "William J.", ""]]}, {"id": "1908.05365", "submitter": "Floris Hermsen", "authors": "Floris Hermsen, Peter Bloem, Fabian Jansen, Wolf Vos", "title": "End-to-End Learning from Complex Multigraphs with Latent-Graph\n  Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of end-to-end learning from complex multigraphs with\npotentially very large numbers of edges between two vertices, each edge labeled\nwith rich information. Examples range from communication networks to flights\nbetween airports or financial transaction graphs. We propose Latent-Graph\nConvolutional Networks (L-GCNs), which propagate information from these complex\nedges to a latent adjacency tensor, after which further downstream tasks can be\nperformed, such as node classification. We evaluate the performance of several\nvariations of the model on two synthetic datasets simulating fraud in financial\ntransaction networks, ensuring the model must make use of edge labels in order\nto achieve good classification performance. We find that allowing for nonlinear\ninteractions on a per-neighbor basis boosts performance significantly, while\nshowing promising results in an inductive setting. Finally, we demonstrate the\nuse of L-GCNs on real-world data in the form of an urban transportation\nnetwork.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 22:38:18 GMT"}, {"version": "v2", "created": "Sun, 24 Jan 2021 20:28:53 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Hermsen", "Floris", ""], ["Bloem", "Peter", ""], ["Jansen", "Fabian", ""], ["Vos", "Wolf", ""]]}, {"id": "1908.05368", "submitter": "Shuang Qiu", "authors": "Shuang Qiu, Xiaohan Wei, Zhuoran Yang", "title": "Robust One-Bit Recovery via ReLU Generative Networks: Near-Optimal\n  Statistical Rate and Global Landscape Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the robust one-bit compressed sensing problem whose goal is to\ndesign an algorithm that faithfully recovers any sparse target vector\n$\\theta_0\\in\\mathbb{R}^d$ \\textit{uniformly} via $m$ quantized noisy\nmeasurements. Specifically, we consider a new framework for this problem where\nthe sparsity is implicitly enforced via mapping a low dimensional\nrepresentation $x_0 \\in \\mathbb{R}^k$ through a known $n$-layer ReLU generative\nnetwork $G:\\mathbb{R}^k\\rightarrow\\mathbb{R}^d$ such that $\\theta_0 = G(x_0)$.\nSuch a framework poses low-dimensional priors on $\\theta_0$ without a known\nsparsity basis. We propose to recover the target $G(x_0)$ solving an\nunconstrained empirical risk minimization (ERM). Under a weak\n\\textit{sub-exponential measurement assumption}, we establish a joint\nstatistical and computational analysis. In particular, we prove that the ERM\nestimator in this new framework achieves a statistical rate of\n$m=\\widetilde{\\mathcal{O}}(kn \\log d /\\varepsilon^2)$ recovering any $G(x_0)$\nuniformly up to an error $\\varepsilon$. When the network is shallow (i.e., $n$\nis small), we show this rate matches the information-theoretic lower bound up\nto logarithm factors of $\\varepsilon^{-1}$. From the lens of computation, we\nprove that under proper conditions on the network weights, our proposed\nempirical risk, despite non-convexity, has no stationary point outside of small\nneighborhoods around the true representation $x_0$ and its negative multiple;\nfurthermore, we show that the global minimizer of the empirical risk stays\nwithin the neighborhood around $x_0$ rather than its negative multiple under\nfurther assumptions on the network weights.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 22:56:34 GMT"}, {"version": "v2", "created": "Sat, 30 Nov 2019 20:12:04 GMT"}, {"version": "v3", "created": "Sat, 22 Aug 2020 06:44:50 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Qiu", "Shuang", ""], ["Wei", "Xiaohan", ""], ["Yang", "Zhuoran", ""]]}, {"id": "1908.05372", "submitter": "Zhenyu Zhao", "authors": "Zhenyu Zhao and Totte Harinen", "title": "Uplift Modeling for Multiple Treatments with Cost Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uplift modeling is an emerging machine learning approach for estimating the\ntreatment effect at an individual or subgroup level. It can be used for\noptimizing the performance of interventions such as marketing campaigns and\nproduct designs. Uplift modeling can be used to estimate which users are likely\nto benefit from a treatment and then prioritize delivering or promoting the\npreferred experience to those users. An important but so far neglected use case\nfor uplift modeling is an experiment with multiple treatment groups that have\ndifferent costs, such as for example when different communication channels and\npromotion types are tested simultaneously. In this paper, we extend standard\nuplift models to support multiple treatment groups with different costs. We\nevaluate the performance of the proposed models using both synthetic and real\ndata. We also describe a production implementation of the approach.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 23:35:25 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 03:55:31 GMT"}, {"version": "v3", "created": "Thu, 26 Mar 2020 17:49:57 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Zhao", "Zhenyu", ""], ["Harinen", "Totte", ""]]}, {"id": "1908.05376", "submitter": "Zhenyu Zhao", "authors": "Zhenyu Zhao, Radhika Anand, Mallory Wang", "title": "Maximum Relevance and Minimum Redundancy Feature Selection Methods for a\n  Marketing Machine Learning Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning applications for online product offerings and marketing\nstrategies, there are often hundreds or thousands of features available to\nbuild such models. Feature selection is one essential method in such\napplications for multiple objectives: improving the prediction accuracy by\neliminating irrelevant features, accelerating the model training and prediction\nspeed, reducing the monitoring and maintenance workload for feature data\npipeline, and providing better model interpretation and diagnosis capability.\nHowever, selecting an optimal feature subset from a large feature space is\nconsidered as an NP-complete problem. The mRMR (Minimum Redundancy and Maximum\nRelevance) feature selection framework solves this problem by selecting the\nrelevant features while controlling for the redundancy within the selected\nfeatures. This paper describes the approach to extend, evaluate, and implement\nthe mRMR feature selection methods for classification problem in a marketing\nmachine learning platform at Uber that automates creation and deployment of\ntargeting and personalization models at scale. This study first extends the\nexisting mRMR methods by introducing a non-linear feature redundancy measure\nand a model-based feature relevance measure. Then an extensive empirical\nevaluation is performed for eight different feature selection methods, using\none synthetic dataset and three real-world marketing datasets at Uber to cover\ndifferent use cases. Based on the empirical results, the selected mRMR method\nis implemented in production for the marketing machine learning platform. A\ndescription of the production implementation is provided and an online\nexperiment deployed through the platform is discussed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 00:06:23 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Zhao", "Zhenyu", ""], ["Anand", "Radhika", ""], ["Wang", "Mallory", ""]]}, {"id": "1908.05377", "submitter": "Oindrila Chatterjee", "authors": "Oindrila Chatterjee and Shantanu Chakrabartty", "title": "Resonant Machine Learning Based on Complex Growth Transform Dynamical\n  Systems", "comments": "Version3, accepted in IEEE TNNLS, March 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional energy-based learning models associate a single energy metric to\neach configuration of variables involved in the underlying optimization\nprocess. Such models associate the lowest energy state to the optimal\nconfiguration of variables under consideration, and are thus inherently\ndissipative. In this paper we propose an energy-efficient learning framework\nthat exploits structural and functional similarities between a machine learning\nnetwork and a general electrical network satisfying the Tellegen's theorem. In\ncontrast to the standard energy-based models, the proposed formulation\nassociates two energy components, namely, active and reactive energy to the\nnetwork. This ensures that the network's active-power is dissipated only during\nthe process of learning, whereas the reactive-power is maintained to be zero at\nall times. As a result, in steady-state, the learned parameters are stored and\nself-sustained by electrical resonance determined by the network's nodal\ninductances and capacitances. Based on this approach, this paper introduces\nthree novel concepts: (a) A learning framework where the network's active-power\ndissipation is used as a regularization for a learning objective function that\nis subjected to zero total reactive-power constraint; (b) A dynamical system\nbased on complex-domain, continuous-time growth transforms which optimizes the\nlearning objective function and drives the network towards electrical resonance\nunder steady-state operation; and (c) An annealing procedure that controls the\ntrade-off between active-power dissipation and the speed of convergence. As a\nrepresentative example, we show how the proposed framework can be used for\ndesigning resonant support vector machines (SVMs), where we show that the\nsupport-vectors correspond to an LC network with self-sustained oscillations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 00:20:48 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 20:15:19 GMT"}, {"version": "v3", "created": "Thu, 9 Apr 2020 13:57:11 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Chatterjee", "Oindrila", ""], ["Chakrabartty", "Shantanu", ""]]}, {"id": "1908.05387", "submitter": "Mandana Saebi", "authors": "Mandana Saebi, Giovanni Luca Ciampaglia, Lance M Kaplan, Nitesh V\n  Chawla", "title": "HONEM: Learning Embedding for Higher Order Networks", "comments": null, "journal-ref": "Big Data 8, no. 4 (2020): 255-269", "doi": "10.1089/big.2019.0169", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning on networks offers a powerful alternative to the oft\npainstaking process of manual feature engineering, and as a result, has enjoyed\nconsiderable success in recent years. However, all the existing representation\nlearning methods are based on the first-order network (FON), that is, the\nnetwork that only captures the pairwise interactions between the nodes. As a\nresult, these methods may fail to incorporate non-Markovian higher-order\ndependencies in the network. Thus, the embeddings that are generated may not\naccurately represent of the underlying phenomena in a network, resulting in\ninferior performance in different inductive or transductive learning tasks. To\naddress this challenge, this paper presents HONEM, a higher-order network\nembedding method that captures the non-Markovian higher-order dependencies in a\nnetwork. HONEM is specifically designed for the higher-order network structure\n(HON) and outperforms other state-of-the-art methods in node classification,\nnetwork re-construction, link prediction, and visualization for networks that\ncontain non-Markovian higher-order dependencies.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 01:22:27 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2020 17:10:31 GMT"}], "update_date": "2020-09-04", "authors_parsed": [["Saebi", "Mandana", ""], ["Ciampaglia", "Giovanni Luca", ""], ["Kaplan", "Lance M", ""], ["Chawla", "Nitesh V", ""]]}, {"id": "1908.05426", "submitter": "Yuze Gao", "authors": "Yuze Gao and Yu Yuan", "title": "Feature-Less End-to-End Nested Term Extraction", "comments": null, "journal-ref": "NLPCC XAI 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we proposed a deep learning-based end-to-end method on the\ndomain specified automatic term extraction (ATE), it considers possible term\nspans within a fixed length in the sentence and predicts them whether they can\nbe conceptual terms. In comparison with current ATE methods, the model supports\nnested term extraction and does not crucially need extra (extracted) features.\nResults show that it can achieve high recall and a comparable precision on term\nextraction task with inputting segmented raw text.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 05:38:14 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Gao", "Yuze", ""], ["Yuan", "Yu", ""]]}, {"id": "1908.05428", "submitter": "Yaniv Romano", "authors": "Yaniv Romano, Rina Foygel Barber, Chiara Sabatti, Emmanuel J. Cand\\`es", "title": "With Malice Towards None: Assessing Uncertainty via Equalized Coverage", "comments": "14 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CY stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important factor to guarantee a fair use of data-driven recommendation\nsystems is that we should be able to communicate their uncertainty to decision\nmakers. This can be accomplished by constructing prediction intervals, which\nprovide an intuitive measure of the limits of predictive performance. To\nsupport equitable treatment, we force the construction of such intervals to be\nunbiased in the sense that their coverage must be equal across all protected\ngroups of interest. We present an operational methodology that achieves this\ngoal by offering rigorous distribution-free coverage guarantees holding in\nfinite samples. Our methodology, equalized coverage, is flexible as it can be\nviewed as a wrapper around any predictive algorithm. We test the applicability\nof the proposed framework on real data, demonstrating that equalized coverage\nconstructs unbiased prediction intervals, unlike competitive methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 05:50:27 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Romano", "Yaniv", ""], ["Barber", "Rina Foygel", ""], ["Sabatti", "Chiara", ""], ["Cand\u00e8s", "Emmanuel J.", ""]]}, {"id": "1908.05429", "submitter": "Xin Li", "authors": "Huiting Hong, Xin Li, Yuangang Pan, Ivor Tsang", "title": "Domain-adversarial Network Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network alignment is a critical task to a wide variety of fields. Many\nexisting works leverage on representation learning to accomplish this task\nwithout eliminating domain representation bias induced by domain-dependent\nfeatures, which yield inferior alignment performance. This paper proposes a\nunified deep architecture (DANA) to obtain a domain-invariant representation\nfor network alignment via an adversarial domain classifier. Specifically, we\nemploy the graph convolutional networks to perform network embedding under the\ndomain adversarial principle, given a small set of observed anchors. Then, the\nsemi-supervised learning framework is optimized by maximizing a posterior\nprobability distribution of observed anchors and the loss of a domain\nclassifier simultaneously. We also develop a few variants of our model, such\nas, direction-aware network alignment, weight-sharing for directed networks and\nsimplification of parameter space. Experiments on three real-world social\nnetwork datasets demonstrate that our proposed approaches achieve\nstate-of-the-art alignment results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 05:56:25 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Hong", "Huiting", ""], ["Li", "Xin", ""], ["Pan", "Yuangang", ""], ["Tsang", "Ivor", ""]]}, {"id": "1908.05434", "submitter": "Longshaokan Wang", "authors": "Longshaokan Wang, Eric Laber, Yeng Saanchi, Sherrie Caltagirone", "title": "Sex Trafficking Detection with Ordinal Regression Neural Networks", "comments": "AAAI-20 workshop on Artificial Intelligence for Cyber Security (AICS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sex trafficking is a global epidemic. Escort websites are a primary vehicle\nfor selling the services of such trafficking victims and thus a major driver of\ntrafficker revenue. Many law enforcement agencies do not have the resources to\nmanually identify leads from the millions of escort ads posted across dozens of\npublic websites. We propose an ordinal regression neural network to identify\nescort ads that are likely linked to sex trafficking. Our model uses a modified\ncost function to mitigate inconsistencies in predictions often associated with\nnonparametric ordinal regression and leverages recent advancements in deep\nlearning to improve prediction accuracy. The proposed method significantly\nimproves on the previous state-of-the-art on Trafficking-10K, an\nexpert-annotated dataset of escort ads. Additionally, because traffickers use\nacronyms, deliberate typographical errors, and emojis to replace explicit\nkeywords, we demonstrate how to expand the lexicon of trafficking flags through\nword embeddings and t-SNE.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 06:25:46 GMT"}, {"version": "v2", "created": "Sun, 12 Jan 2020 02:17:39 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Wang", "Longshaokan", ""], ["Laber", "Eric", ""], ["Saanchi", "Yeng", ""], ["Caltagirone", "Sherrie", ""]]}, {"id": "1908.05435", "submitter": "Liwei Wu", "authors": "Liwei Wu, Shuqing Li, Cho-Jui Hsieh, James Sharpnack", "title": "Temporal Collaborative Ranking Via Personalized Transformer", "comments": "plan to submit for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The collaborative ranking problem has been an important open research\nquestion as most recommendation problems can be naturally formulated as ranking\nproblems. While much of collaborative ranking methodology assumes static\nranking data, the importance of temporal information to improving ranking\nperformance is increasingly apparent. Recent advances in deep learning,\nespecially the discovery of various attention mechanisms and newer\narchitectures in addition to widely used RNN and CNN in natural language\nprocessing, have allowed us to make better use of the temporal ordering of\nitems that each user has engaged with. In particular, the SASRec model,\ninspired by the popular Transformer model in natural languages processing, has\nachieved state-of-art results in the temporal collaborative ranking problem and\nenjoyed more than 10x speed-up when compared to earlier CNN/RNN-based methods.\nHowever, SASRec is inherently an un-personalized model and does not include\npersonalized user embeddings. To overcome this limitation, we propose a\nPersonalized Transformer (SSE-PT) model, outperforming SASRec by almost 5% in\nterms of NDCG@10 on 5 real-world datasets. Furthermore, after examining some\nrandom users' engagement history and corresponding attention heat maps used\nduring the inference stage, we find our model is not only more interpretable\nbut also able to focus on recent engagement patterns for each user. Moreover,\nour SSE-PT model with a slight modification, which we call SSE-PT++, can handle\nextremely long sequences and outperform SASRec in ranking results with\ncomparable training speed, striking a balance between performance and speed\nrequirements. Code and data are open sourced at\nhttps://github.com/wuliwei9278/SSE-PT.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 06:35:04 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Wu", "Liwei", ""], ["Li", "Shuqing", ""], ["Hsieh", "Cho-Jui", ""], ["Sharpnack", "James", ""]]}, {"id": "1908.05451", "submitter": "Fangchen Liu", "authors": "Zhiao Huang, Fangchen Liu, Hao Su", "title": "Mapping State Space using Landmarks for Universal Goal Reaching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An agent that has well understood the environment should be able to apply its\nskills for any given goals, leading to the fundamental problem of learning the\nUniversal Value Function Approximator (UVFA). A UVFA learns to predict the\ncumulative rewards between all state-goal pairs. However, empirically, the\nvalue function for long-range goals is always hard to estimate and may\nconsequently result in failed policy. This has presented challenges to the\nlearning process and the capability of neural networks. We propose a method to\naddress this issue in large MDPs with sparse rewards, in which exploration and\nrouting across remote states are both extremely challenging. Our method\nexplicitly models the environment in a hierarchical manner, with a high-level\ndynamic landmark-based map abstracting the visited state space, and a low-level\nvalue network to derive precise local decisions. We use farthest point sampling\nto select landmark states from past experience, which has improved exploration\ncompared with simple uniform sampling. Experimentally we showed that our method\nenables the agent to reach long-range goals at the early training stage, and\nachieve better performance than standard RL algorithms for a number of\nchallenging tasks.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 08:01:56 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Huang", "Zhiao", ""], ["Liu", "Fangchen", ""], ["Su", "Hao", ""]]}, {"id": "1908.05474", "submitter": "Qianggang Ding", "authors": "Qianggang Ding, Sifan Wu, Hao Sun, Jiadong Guo, Shu-Tao Xia", "title": "Adaptive Regularization of Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a variety of regularization techniques have been widely applied in\ndeep neural networks, such as dropout, batch normalization, data augmentation,\nand so on. These methods mainly focus on the regularization of weight\nparameters to prevent overfitting effectively. In addition, label\nregularization techniques such as label smoothing and label disturbance have\nalso been proposed with the motivation of adding a stochastic perturbation to\nlabels. In this paper, we propose a novel adaptive label regularization method,\nwhich enables the neural network to learn from the erroneous experience and\nupdate the optimal label representation online. On the other hand, compared\nwith knowledge distillation, which learns the correlation of categories using\nteacher network, our proposed method requires only a minuscule increase in\nparameters without cumbersome teacher network. Furthermore, we evaluate our\nmethod on CIFAR-10/CIFAR-100/ImageNet datasets for image recognition tasks and\nAGNews/Yahoo/Yelp-Full datasets for text classification tasks. The empirical\nresults show significant improvement under all experimental settings.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 09:58:24 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Ding", "Qianggang", ""], ["Wu", "Sifan", ""], ["Sun", "Hao", ""], ["Guo", "Jiadong", ""], ["Xia", "Shu-Tao", ""]]}, {"id": "1908.05480", "submitter": "Evgeny Burnaev", "authors": "Anna Kuzina and Evgenii Egorov and Evgeny Burnaev", "title": "Bayesian Generative Models for Knowledge Transfer in MRI Semantic\n  Segmentation Problems", "comments": "24 page, 6 figures, 6 tabels", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic segmentation methods based on deep learning have recently\ndemonstrated state-of-the-art performance, outperforming the ordinary methods.\nNevertheless, these methods are inapplicable for small datasets, which are very\ncommon in medical problems. To this end, we propose a knowledge transfer method\nbetween diseases via the Generative Bayesian Prior network. Our approach is\ncompared to a pre-train approach and random initialization and obtains the best\nresults in terms of Dice Similarity Coefficient metric for the small subsets of\nthe Brain Tumor Segmentation 2018 database (BRATS2018).\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 10:27:32 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Kuzina", "Anna", ""], ["Egorov", "Evgenii", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1908.05542", "submitter": "Gregorz Dudek", "authors": "Grzegorz Dudek", "title": "Improving Randomized Learning of Feedforward Neural Networks by\n  Appropriate Generation of Random Parameters", "comments": null, "journal-ref": "15th International Work-Conference on Artificial Neural Networks\n  IWANN 2019. LNCS, vol 11506. Springer, Cham", "doi": "10.1007/978-3-030-20521-8_43", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, a method of random parameters generation for randomized\nlearning of a single-hidden-layer feedforward neural network is proposed. The\nmethod firstly, randomly selects the slope angles of the hidden neurons\nactivation functions from an interval adjusted to the target function, then\nrandomly rotates the activation functions, and finally distributes them across\nthe input space. For complex target functions the proposed method gives better\nresults than the approach commonly used in practice, where the random\nparameters are selected from the fixed interval. This is because it introduces\nthe steepest fragments of the activation functions into the input hypercube,\navoiding their saturation fragments.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 13:52:22 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1908.05557", "submitter": "Anh Truong", "authors": "Anh Truong, Austin Walters, Jeremy Goodsitt, Keegan Hines, C. Bayan\n  Bruss, Reza Farivar", "title": "Towards Automated Machine Learning: Evaluation and Comparison of AutoML\n  Approaches and Tools", "comments": null, "journal-ref": null, "doi": "10.1109/ICTAI.2019.00209", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable growth and interest in industrial applications of\nmachine learning (ML) in recent years. ML engineers, as a consequence, are in\nhigh demand across the industry, yet improving the efficiency of ML engineers\nremains a fundamental challenge. Automated machine learning (AutoML) has\nemerged as a way to save time and effort on repetitive tasks in ML pipelines,\nsuch as data pre-processing, feature engineering, model selection,\nhyperparameter optimization, and prediction result analysis. In this paper, we\ninvestigate the current state of AutoML tools aiming to automate these tasks.\nWe conduct various evaluations of the tools on many datasets, in different data\nsegments, to examine their performance, and compare their advantages and\ndisadvantages on different test cases.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 14:16:09 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 19:31:52 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Truong", "Anh", ""], ["Walters", "Austin", ""], ["Goodsitt", "Jeremy", ""], ["Hines", "Keegan", ""], ["Bruss", "C. Bayan", ""], ["Farivar", "Reza", ""]]}, {"id": "1908.05569", "submitter": "David Mac\\^edo", "authors": "David Mac\\^edo, Tsang Ing Ren, Cleber Zanchettin, Adriano L. I.\n  Oliveira, Teresa Ludermir", "title": "Entropic Out-of-Distribution Detection", "comments": "Accepted for publication in The International Joint Conference on\n  Neural Networks (IJCNN), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Out-of-distribution (OOD) detection approaches usually present special\nrequirements (e.g., hyperparameter validation, collection of outlier data) and\nproduce side effects (e.g., classification accuracy drop, slower\nenergy-inefficient inferences). We argue that these issues are a consequence of\nthe SoftMax loss anisotropy and disagreement with the maximum entropy\nprinciple. Thus, we propose the IsoMax loss and the entropic score. The\nseamless drop-in replacement of the SoftMax loss by IsoMax loss requires\nneither additional data collection nor hyperparameter validation. The trained\nmodels do not exhibit classification accuracy drop and produce fast\nenergy-efficient inferences. Moreover, our experiments show that training\nneural networks with IsoMax loss significantly improves their OOD detection\nperformance. The IsoMax loss exhibits state-of-the-art performance under the\nmentioned conditions (fast energy-efficient inference, no classification\naccuracy drop, no collection of outlier data, and no hyperparameter\nvalidation), which we call the seamless OOD detection task. In future work,\ncurrent OOD detection methods may replace the SoftMax loss with the IsoMax loss\nto improve their performance on the commonly studied non-seamless OOD detection\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 14:54:52 GMT"}, {"version": "v10", "created": "Thu, 26 Nov 2020 22:47:49 GMT"}, {"version": "v11", "created": "Mon, 30 Nov 2020 01:55:08 GMT"}, {"version": "v12", "created": "Sun, 11 Apr 2021 23:32:49 GMT"}, {"version": "v13", "created": "Mon, 24 May 2021 23:15:23 GMT"}, {"version": "v2", "created": "Sat, 17 Aug 2019 02:22:46 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 00:58:03 GMT"}, {"version": "v4", "created": "Wed, 5 Feb 2020 01:18:56 GMT"}, {"version": "v5", "created": "Tue, 18 Feb 2020 23:06:49 GMT"}, {"version": "v6", "created": "Sun, 7 Jun 2020 06:54:51 GMT"}, {"version": "v7", "created": "Thu, 11 Jun 2020 05:59:13 GMT"}, {"version": "v8", "created": "Thu, 23 Jul 2020 17:03:57 GMT"}, {"version": "v9", "created": "Mon, 3 Aug 2020 06:37:15 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Mac\u00eado", "David", ""], ["Ren", "Tsang Ing", ""], ["Zanchettin", "Cleber", ""], ["Oliveira", "Adriano L. I.", ""], ["Ludermir", "Teresa", ""]]}, {"id": "1908.05571", "submitter": "Ola Spjuth", "authors": "Ola Spjuth, Robin Carri\\'on Br\\\"annstr\\\"om, Lars Carlsson, Niharika\n  Gauraha", "title": "Combining Prediction Intervals on Multi-Source Non-Disclosed Regression\n  Datasets", "comments": "Accepted to 8th Symposium on Conformal and Probabilistic Prediction\n  with Applications, Golden Sands, Bulgaria, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conformal Prediction is a framework that produces prediction intervals based\non the output from a machine learning algorithm. In this paper we explore the\ncase when training data is made up of multiple parts available in different\nsources that cannot be pooled. We here consider the regression case and propose\na method where a conformal predictor is trained on each data source\nindependently, and where the prediction intervals are then combined into a\nsingle interval. We call the approach Non-Disclosed Conformal Prediction\n(NDCP), and we evaluate it on a regression dataset from the UCI machine\nlearning repository using support vector regression as the underlying machine\nlearning algorithm, with varying number of data sources and sizes. The results\nshow that the proposed method produces conservatively valid prediction\nintervals, and while we cannot retain the same efficiency as when all data is\nused, efficiency is improved through the proposed approach as compared to\npredicting using a single arbitrarily chosen source.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 15:01:55 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Spjuth", "Ola", ""], ["Br\u00e4nnstr\u00f6m", "Robin Carri\u00f3n", ""], ["Carlsson", "Lars", ""], ["Gauraha", "Niharika", ""]]}, {"id": "1908.05601", "submitter": "Mengnan Du", "authors": "Mengnan Du, Ninghao Liu, Fan Yang, Xia Hu", "title": "Learning Credible Deep Neural Networks with Rationale Regularization", "comments": "ICDM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent explainability related studies have shown that state-of-the-art DNNs\ndo not always adopt correct evidences to make decisions. It not only hampers\ntheir generalization but also makes them less likely to be trusted by\nend-users. In pursuit of developing more credible DNNs, in this paper we\npropose CREX, which encourages DNN models to focus more on evidences that\nactually matter for the task at hand, and to avoid overfitting to\ndata-dependent bias and artifacts. Specifically, CREX regularizes the training\nprocess of DNNs with rationales, i.e., a subset of features highlighted by\ndomain experts as justifications for predictions, to enforce DNNs to generate\nlocal explanations that conform with expert rationales. Even when rationales\nare not available, CREX still could be useful by requiring the generated\nexplanations to be sparse. Experimental results on two text classification\ndatasets demonstrate the increased credibility of DNNs trained with CREX.\nComprehensive analysis further shows that while CREX does not always improve\nprediction accuracy on the held-out test set, it significantly increases DNN\naccuracy on new and previously unseen data beyond test set, highlighting the\nadvantage of the increased credibility.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 12:57:26 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Du", "Mengnan", ""], ["Liu", "Ninghao", ""], ["Yang", "Fan", ""], ["Hu", "Xia", ""]]}, {"id": "1908.05611", "submitter": "Chang-You Tai", "authors": "Chang-You Tai, Meng-Ru Wu, Yun-Wei Chu, Shao-Yu Chu", "title": "GraphSW: a training protocol based on stage-wise training for GNN-based\n  Recommender Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, researchers utilize Knowledge Graph (KG) as side information in\nrecommendation system to address cold start and sparsity issue and improve the\nrecommendation performance. Existing KG-aware recommendation model use the\nfeature of neighboring entities and structural information to update the\nembedding of currently located entity. Although the fruitful information is\nbeneficial to the following task, the cost of exploring the entire graph is\nmassive and impractical. In order to reduce the computational cost and maintain\nthe pattern of extracting features, KG-aware recommendation model usually\nutilize fixed-size and random set of neighbors rather than complete information\nin KG. Nonetheless, there are two critical issues in these approaches: First of\nall, fixed-size and randomly selected neighbors restrict the view of graph. In\naddition, as the order of graph feature increases, the growth of parameter\ndimensionality of the model may lead the training process hard to converge. To\nsolve the aforementioned limitations, we propose GraphSW, a strategy based on\nstage-wise training framework which would only access to a subset of the\nentities in KG in every stage. During the following stages, the learned\nembedding from previous stages is provided to the network in the next stage and\nthe model can learn the information gradually from the KG. We apply stage-wise\ntraining on two SOTA recommendation models, RippleNet and Knowledge Graph\nConvolutional Networks (KGCN). Moreover, we evaluate the performance on six\nreal world datasets, Last.FM 2011, Book-Crossing,movie, LFM-1b 2015,\nAmazon-book and Yelp 2018. The result of our experiments shows that proposed\nstrategy can help both models to collect more information from the KG and\nimprove the performance. Furthermore, it is observed that GraphSW can assist\nKGCN to converge effectively in high-order graph feature.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 05:50:50 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 15:31:49 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Tai", "Chang-You", ""], ["Wu", "Meng-Ru", ""], ["Chu", "Yun-Wei", ""], ["Chu", "Shao-Yu", ""]]}, {"id": "1908.05635", "submitter": "Jennifer Hoyal Cuthill", "authors": "Jennifer F. Hoyal Cuthill, Nicholas Guttenberg, Sophie Ledger, Robyn\n  Crowther, Blanca Huertas", "title": "Deep learning on butterfly phenotypes tests evolution's oldest\n  mathematical model", "comments": "Manuscript and combined supplementary information", "journal-ref": "Sci Adv 5, eaaw4967 (2019)", "doi": "10.1126/sciadv.aaw4967", "report-no": null, "categories": "q-bio.PE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional anatomical analyses captured only a fraction of real phenomic\ninformation. Here, we apply deep learning to quantify total phenotypic\nsimilarity across 2468 butterfly photographs, covering 38 subspecies from the\npolymorphic mimicry complex of $\\textit{Heliconius erato}$ and\n$\\textit{Heliconius melpomene}$. Euclidean phenotypic distances, calculated\nusing a deep convolutional triplet network, demonstrate significant convergence\nbetween interspecies co-mimics. This quantitatively validates a key prediction\nof M\\\"ullerian mimicry theory, evolutionary biology's oldest mathematical\nmodel. Phenotypic neighbor-joining trees are significantly correlated with wing\npattern gene phylogenies, demonstrating objective, phylogenetically informative\nphenome capture. Comparative analyses indicate frequency-dependent, mutual\nconvergence with coevolutionary exchange of wing pattern features. Therefore,\nphenotypic analysis supports reciprocal coevolution, predicted by classical\nmimicry theory but since disputed, and reveals mutual convergence as an\nintrinsic generator for the surprising diversity of M\\\"ullerian mimicry. This\ndemonstrates that deep learning can generate phenomic spatial embeddings which\nenable quantitative tests of evolutionary hypotheses previously only testable\nsubjectively.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 16:55:27 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Cuthill", "Jennifer F. Hoyal", ""], ["Guttenberg", "Nicholas", ""], ["Ledger", "Sophie", ""], ["Crowther", "Robyn", ""], ["Huertas", "Blanca", ""]]}, {"id": "1908.05640", "submitter": "G\\\"okhan \\c{C}apan", "authors": "G\\\"okhan \\c{C}apan, Ilker G\\\"undo\\u{g}du, Ali Caner T\\\"urkmen,\n  \\c{C}a\\u{g}r{\\i} Sofuo\\u{g}lu, Ali Taylan Cemgil", "title": "A Bayesian Choice Model for Eliminating Feedback Loops", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-reinforcing feedback loops in personalization systems are typically\ncaused by users choosing from a limited set of alternatives presented\nsystematically based on previous choices. We propose a Bayesian choice model\nbuilt on Luce axioms that explicitly accounts for users' limited exposure to\nalternatives. Our model is fair---it does not impose negative bias towards\nunpresented alternatives, and practical---preference estimates are accurately\ninferred upon observing a small number of interactions. It also allows\nefficient sampling, leading to a straightforward online presentation mechanism\nbased on Thompson sampling. Our approach achieves low regret in learning to\npresent upon exploration of only a small fraction of possible presentations.\nThe proposed structure can be reused as a building block in interactive\nsystems, e.g., recommender systems, free of feedback loops.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 17:02:25 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 14:18:50 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["\u00c7apan", "G\u00f6khan", ""], ["G\u00fcndo\u011fdu", "Ilker", ""], ["T\u00fcrkmen", "Ali Caner", ""], ["Sofuo\u011flu", "\u00c7a\u011fr\u0131", ""], ["Cemgil", "Ali Taylan", ""]]}, {"id": "1908.05656", "submitter": "Ross Girshick", "authors": "Anton Bakhtin, Laurens van der Maaten, Justin Johnson, Laura\n  Gustafson, Ross Girshick", "title": "PHYRE: A New Benchmark for Physical Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and reasoning about physics is an important ability of\nintelligent agents. We develop the PHYRE benchmark for physical reasoning that\ncontains a set of simple classical mechanics puzzles in a 2D physical\nenvironment. The benchmark is designed to encourage the development of learning\nalgorithms that are sample-efficient and generalize well across puzzles. We\ntest several modern learning algorithms on PHYRE and find that these algorithms\nfall short in solving the puzzles efficiently. We expect that PHYRE will\nencourage the development of novel sample-efficient agents that learn efficient\nbut useful models of physics. For code and to play PHYRE for yourself, please\nvisit https://player.phyre.ai.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 17:58:32 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Bakhtin", "Anton", ""], ["van der Maaten", "Laurens", ""], ["Johnson", "Justin", ""], ["Gustafson", "Laura", ""], ["Girshick", "Ross", ""]]}, {"id": "1908.05659", "submitter": "Hamed Rahimian", "authors": "Hamed Rahimian and Sanjay Mehrotra", "title": "Distributionally Robust Optimization: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The concepts of risk-aversion, chance-constrained optimization, and robust\noptimization have developed significantly over the last decade. Statistical\nlearning community has also witnessed a rapid theoretical and applied growth by\nrelying on these concepts. A modeling framework, called distributionally robust\noptimization (DRO), has recently received significant attention in both the\noperations research and statistical learning communities. This paper surveys\nmain concepts and contributions to DRO, and its relationships with robust\noptimization, risk-aversion, chance-constrained optimization, and function\nregularization.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 00:43:41 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Rahimian", "Hamed", ""], ["Mehrotra", "Sanjay", ""]]}, {"id": "1908.05660", "submitter": "Abhishek Panigrahi", "authors": "Abhishek Panigrahi, Abhishek Shetty and Navin Goyal", "title": "Effect of Activation Functions on the Training of Overparametrized\n  Neural Nets", "comments": "Major update: Several new results, some reorganization and rewriting\n  of previous results, new references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that overparametrized neural networks trained using\ngradient-based methods quickly achieve small training error with appropriate\nhyperparameter settings. Recent papers have proved this statement theoretically\nfor highly overparametrized networks under reasonable assumptions. These\nresults either assume that the activation function is ReLU or they crucially\ndepend on the minimum eigenvalue of a certain Gram matrix depending on the\ndata, random initialization and the activation function. In the later case,\nexisting works only prove that this minimum eigenvalue is non-zero and do not\nprovide quantitative bounds. On the empirical side, a contemporary line of\ninvestigations has proposed a number of alternative activation functions which\ntend to perform better than ReLU at least in some settings but no clear\nunderstanding has emerged. This state of affairs underscores the importance of\ntheoretically understanding the impact of activation functions on training. In\nthe present paper, we provide theoretical results about the effect of\nactivation function on the training of highly overparametrized 2-layer neural\nnetworks. A crucial property that governs the performance of an activation is\nwhether or not it is smooth. For non-smooth activations such as ReLU, SELU and\nELU, all eigenvalues of the associated Gram matrix are large under minimal\nassumptions on the data. For smooth activations such as tanh, swish and\npolynomials, the situation is more complex. If the subspace spanned by the data\nhas small dimension then the minimum eigenvalue of the Gram matrix can be small\nleading to slow training. But if the dimension is large and the data satisfies\nanother mild condition, then the eigenvalues are large. If we allow deep\nnetworks, then the small data dimension is not a limitation provided that the\ndepth is sufficient. We discuss a number of extensions and applications of\nthese results.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 16:22:07 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 14:37:14 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 09:39:17 GMT"}, {"version": "v4", "created": "Fri, 10 Apr 2020 13:22:00 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Panigrahi", "Abhishek", ""], ["Shetty", "Abhishek", ""], ["Goyal", "Navin", ""]]}, {"id": "1908.05699", "submitter": "Guojun Zhang", "authors": "Guojun Zhang and Yaoliang Yu", "title": "Convergence of Gradient Methods on Bilinear Zero-Sum Games", "comments": null, "journal-ref": "ICLR 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.GT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Min-max formulations have attracted great attention in the ML community due\nto the rise of deep generative models and adversarial methods, while\nunderstanding the dynamics of gradient algorithms for solving such formulations\nhas remained a grand challenge. As a first step, we restrict to bilinear\nzero-sum games and give a systematic analysis of popular gradient updates, for\nboth simultaneous and alternating versions. We provide exact conditions for\ntheir convergence and find the optimal parameter setup and convergence rates.\nIn particular, our results offer formal evidence that alternating updates\nconverge \"better\" than simultaneous ones.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 18:27:14 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 22:07:30 GMT"}, {"version": "v3", "created": "Mon, 10 Feb 2020 03:20:37 GMT"}, {"version": "v4", "created": "Tue, 3 Mar 2020 21:10:54 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Zhang", "Guojun", ""], ["Yu", "Yaoliang", ""]]}, {"id": "1908.05717", "submitter": "Jakub Tomczak Ph.D.", "authors": "Amirhossein Habibian, Ties van Rozendaal, Jakub M. Tomczak, Taco S.\n  Cohen", "title": "Video Compression With Rate-Distortion Autoencoders", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": "10.1109/ICCV.2019.00713", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a a deep generative model for lossy video\ncompression. We employ a model that consists of a 3D autoencoder with a\ndiscrete latent space and an autoregressive prior used for entropy coding. Both\nautoencoder and prior are trained jointly to minimize a rate-distortion loss,\nwhich is closely related to the ELBO used in variational autoencoders. Despite\nits simplicity, we find that our method outperforms the state-of-the-art\nlearned video compression networks based on motion compensation or\ninterpolation. We systematically evaluate various design choices, such as the\nuse of frame-based or spatio-temporal autoencoders, and the type of\nautoregressive prior. In addition, we present three extensions of the basic\nmethod that demonstrate the benefits over classical approaches to compression.\nFirst, we introduce semantic compression, where the model is trained to\nallocate more bits to objects of interest. Second, we study adaptive\ncompression, where the model is adapted to a domain with limited variability,\ne.g., videos taken from an autonomous car, to achieve superior compression on\nthat domain. Finally, we introduce multimodal compression, where we demonstrate\nthe effectiveness of our model in joint compression of multiple modalities\ncaptured by non-standard imaging sensors, such as quad cameras. We believe that\nthis opens up novel video compression applications, which have not been\nfeasible with classical codecs.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 15:37:23 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 16:42:58 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Habibian", "Amirhossein", ""], ["van Rozendaal", "Ties", ""], ["Tomczak", "Jakub M.", ""], ["Cohen", "Taco S.", ""]]}, {"id": "1908.05725", "submitter": "Tao Wang", "authors": "Tao Wang, Xinmin Wu, Taiping He", "title": "Trustable and Automated Machine Learning Running with Blockchain and Its\n  Applications", "comments": "10 pages, KDD 2019 AutoML workshop. arXiv admin note: text overlap\n  with arXiv:1903.08801", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning algorithms learn from data and use data from databases that\nare mutable; therefore, the data and the results of machine learning cannot be\nfully trusted. Also, the machine learning process is often difficult to\nautomate. A unified analytical framework for trustable machine learning has\nbeen presented in the literature. It proposed building a trustable machine\nlearning system by using blockchain technology, which can store data in a\npermanent and immutable way. In addition, smart contracts on blockchain are\nused to automate the machine learning process. In the proposed framework, a\ncore machine learning algorithm can have three implementations: server layer\nimplementation, streaming layer implementation, and smart contract\nimplementation. However, there are still open questions. First, the streaming\nlayer usually deploys on edge devices and therefore has limited memory and\ncomputing power. How can we run machine learning on the streaming layer?\nSecond, most data that are stored on blockchain are financial transactions, for\nwhich fraud detection is often needed. However, in some applications, training\ndata are hard to obtain. Can we build good machine learning models to do fraud\ndetection with limited training data? These questions motivated this paper;\nwhich makes two contributions. First, it proposes training a machine learning\nmodel on the server layer and saving the model with a special binary data\nformat. Then, the streaming layer can take this blob of binary data as input\nand score incoming data online. The blob of binary data is very compact and can\nbe deployed on edge devices. Second, the paper presents a new method of\nsynthetic data generation that can enrich the training data set. Experiments\nshow that this synthetic data generation is very effective in applications such\nas fraud detection in financial data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 00:09:12 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Wang", "Tao", ""], ["Wu", "Xinmin", ""], ["He", "Taiping", ""]]}, {"id": "1908.05730", "submitter": "Redha Ali", "authors": "Redha Ali, Russell C. Hardie, Manawaduge Supun De Silva, and Temesguen\n  Messay Kebede", "title": "Skin Lesion Segmentation and Classification for ISIC 2018 by Combining\n  Deep CNN and Handcrafted Features", "comments": "4 pages and 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short report describes our submission to the ISIC 2018 Challenge in Skin\nLesion Analysis Towards Melanoma Detection for Task1 and Task 3. This work has\nbeen accomplished by a team of researchers at the University of Dayton Signal\nand Image Processing Lab. Our proposed approach is computationally efficient\nare combines information from both deep learning and handcrafted features. For\nTask3, we form a new type of image features, called hybrid features, which has\nstronger discrimination ability than single method features. These features are\nutilized as inputs to a decision-making model that is based on a multiclass\nSupport Vector Machine (SVM) classifier. The proposed technique is evaluated on\nonline validation databases. Our score was 0.841 with SVM classifier on the\nvalidation dataset.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 02:48:49 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Ali", "Redha", ""], ["Hardie", "Russell C.", ""], ["De Silva", "Manawaduge Supun", ""], ["Kebede", "Temesguen Messay", ""]]}, {"id": "1908.05744", "submitter": "Sepehr Saadatmand", "authors": "Sepehr Saadatmand, Mohammad Saleh Sanjarinia, Pourya Shamsi, Mehdi\n  Ferdowsi, and Donald C. Wunsch", "title": "Heuristic Dynamic Programming for Adaptive Virtual Synchronous\n  Generators", "comments": "NAPS 2019 Conference. arXiv admin note: substantial text overlap with\n  arXiv:1908.05191; text overlap with arXiv:1908.05199", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a neural network heuristic dynamic programing (HDP) is used for\noptimal control of the virtual inertia based control of grid connected three\nphase inverters. It is shown that the conventional virtual inertia controllers\nare not suited for non inductive grids. A neural network based controller is\nproposed to adapt to any impedance angle. Applying an adaptive dynamic\nprogramming controller instead of a supervised controlled method enables the\nsystem to adjust itself to different conditions. The proposed HDP consists of\ntwo subnetworks, critic network and action network. These networks can be\ntrained during the same training cycle to decrease the training time. The\nsimulation results confirm that the proposed neural network HDP controller\nperforms better than the traditional direct fed voltage and reactive power\ncontrollers in virtual inertia control schemes.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 16:12:58 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Saadatmand", "Sepehr", ""], ["Sanjarinia", "Mohammad Saleh", ""], ["Shamsi", "Pourya", ""], ["Ferdowsi", "Mehdi", ""], ["Wunsch", "Donald C.", ""]]}, {"id": "1908.05751", "submitter": "Johannes G\\\"unther", "authors": "Johannes G\\\"unther, Nadia M. Ady, Alex Kearney, Michael R. Dawson,\n  Patrick M. Pilarski", "title": "Examining the Use of Temporal-Difference Incremental Delta-Bar-Delta for\n  Real-World Predictive Knowledge Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictions and predictive knowledge have seen recent success in improving\nnot only robot control but also other applications ranging from industrial\nprocess control to rehabilitation. A property that makes these predictive\napproaches well suited for robotics is that they can be learned online and\nincrementally through interaction with the environment. However, a remaining\nchallenge for many prediction-learning approaches is an appropriate choice of\nprediction-learning parameters, especially parameters that control the\nmagnitude of a learning machine's updates to its predictions (the learning rate\nor step size). To begin to address this challenge, we examine the use of online\nstep-size adaptation using a sensor-rich robotic arm. Our method of choice,\nTemporal-Difference Incremental Delta-Bar-Delta (TIDBD), learns and adapts step\nsizes on a feature level; importantly, TIDBD allows step-size tuning and\nrepresentation learning to occur at the same time. We show that TIDBD is a\npractical alternative for classic Temporal-Difference (TD) learning via an\nextensive parameter search. Both approaches perform comparably in terms of\npredicting future aspects of a robotic data stream. Furthermore, the use of a\nstep-size adaptation method like TIDBD appears to allow a system to\nautomatically detect and characterize common sensor failures in a robotic\napplication. Together, these results promise to improve the ability of robotic\ndevices to learn from interactions with their environments in a robust way,\nproviding key capabilities for autonomous agents and robots.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 20:42:19 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2020 18:45:15 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["G\u00fcnther", "Johannes", ""], ["Ady", "Nadia M.", ""], ["Kearney", "Alex", ""], ["Dawson", "Michael R.", ""], ["Pilarski", "Patrick M.", ""]]}, {"id": "1908.05759", "submitter": "Mohammad Shojafar", "authors": "Rahim Taheri, Meysam Ghahramani, Reza Javidan, Mohammad Shojafar,\n  Zahra Pooranian, Mauro Conti", "title": "Similarity-based Android Malware Detection Using Hamming Distance of\n  Static Binary Features", "comments": "20 pages, 8 figures, 11 tables, FGCS Elsevier journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we develop four malware detection methods using Hamming\ndistance to find similarity between samples which are first nearest neighbors\n(FNN), all nearest neighbors (ANN), weighted all nearest neighbors (WANN), and\nk-medoid based nearest neighbors (KMNN). In our proposed methods, we can\ntrigger the alarm if we detect an Android app is malicious. Hence, our\nsolutions help us to avoid the spread of detected malware on a broader scale.\nWe provide a detailed description of the proposed detection methods and related\nalgorithms. We include an extensive analysis to asses the suitability of our\nproposed similarity-based detection methods. In this way, we perform our\nexperiments on three datasets, including benign and malware Android apps like\nDrebin, Contagio, and Genome. Thus, to corroborate the actual effectiveness of\nour classifier, we carry out performance comparisons with some state-of-the-art\nclassification and malware detection algorithms, namely Mixed and Separated\nsolutions, the program dissimilarity measure based on entropy (PDME) and the\nFalDroid algorithms. We test our experiments in a different type of features:\nAPI, intent, and permission features on these three datasets. The results\nconfirm that accuracy rates of proposed algorithms are more than 90% and in\nsome cases (i.e., considering API features) are more than 99%, and are\ncomparable with existing state-of-the-art solutions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 03:53:54 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2019 07:26:15 GMT"}], "update_date": "2019-11-28", "authors_parsed": [["Taheri", "Rahim", ""], ["Ghahramani", "Meysam", ""], ["Javidan", "Reza", ""], ["Shojafar", "Mohammad", ""], ["Pooranian", "Zahra", ""], ["Conti", "Mauro", ""]]}, {"id": "1908.05762", "submitter": "Hamed Shahbazi", "authors": "Hamed Shahbazi, Xiaoli Z. Fern, Reza Ghaeini, Rasha Obeidat and Prasad\n  Tadepalli", "title": "Entity-aware ELMo: Learning Contextual Entity Representation for Entity\n  Disambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new local entity disambiguation system. The key to our system is\na novel approach for learning entity representations. In our approach we learn\nan entity aware extension of Embedding for Language Model (ELMo) which we call\nEntity-ELMo (E-ELMo). Given a paragraph containing one or more named entity\nmentions, each mention is first defined as a function of the entire paragraph\n(including other mentions), then they predict the referent entities. Utilizing\nE-ELMo for local entity disambiguation, we outperform all of the\nstate-of-the-art local and global models on the popular benchmarks by improving\nabout 0.5\\% on micro average accuracy for AIDA test-b with Yago candidate set.\nThe evaluation setup of the training data and candidate set are the same as our\nbaselines for fair comparison.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 03:51:25 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 16:49:24 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Shahbazi", "Hamed", ""], ["Fern", "Xiaoli Z.", ""], ["Ghaeini", "Reza", ""], ["Obeidat", "Rasha", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1908.05782", "submitter": "Ouwen Huang", "authors": "Ouwen Huang, Will Long, Nick Bottenus, Gregg E. Trahey, Sina Farsiu,\n  Mark L. Palmeri", "title": "MimickNet, Matching Clinical Post-Processing Under Realistic Black-Box\n  Constraints", "comments": "This work has been submitted to the IEEE Transactions on Medical\n  Imaging on July 1st, 2019 for possible publication. Copyright may be\n  transferred without notice, after which this version may no longer be\n  accessible", "journal-ref": null, "doi": "10.1109/TMI.2020.2970867", "report-no": null, "categories": "eess.IV cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image post-processing is used in clinical-grade ultrasound scanners to\nimprove image quality (e.g., reduce speckle noise and enhance contrast). These\npost-processing techniques vary across manufacturers and are generally kept\nproprietary, which presents a challenge for researchers looking to match\ncurrent clinical-grade workflows. We introduce a deep learning framework,\nMimickNet, that transforms raw conventional delay-and-summed (DAS) beams into\nthe approximate post-processed images found on clinical-grade scanners.\nTraining MimickNet only requires post-processed image samples from a scanner of\ninterest without the need for explicit pairing to raw DAS data. This\nflexibility allows it to hypothetically approximate any manufacturer's\npost-processing without access to the pre-processed data. MimickNet generates\nimages with an average similarity index measurement (SSIM) of 0.930$\\pm$0.0892\non a 300 cineloop test set, and it generalizes to cardiac cineloops outside of\nour train-test distribution achieving an SSIM of 0.967$\\pm$0.002. We also\nexplore the theoretical SSIM achievable by evaluating MimickNet performance\nwhen trained under gray-box constraints (i.e., when both pre-processed and\npost-processed images are available). To our knowledge, this is the first work\nto establish deep learning models that closely approximate current\nclinical-grade ultrasound post-processing under realistic black-box constraints\nwhere before and after post-processing data is unavailable. MimickNet serves as\na clinical post-processing baseline for future works in ultrasound image\nformation to compare against. To this end, we have made the MimickNet software\nopen source.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 22:10:41 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Huang", "Ouwen", ""], ["Long", "Will", ""], ["Bottenus", "Nick", ""], ["Trahey", "Gregg E.", ""], ["Farsiu", "Sina", ""], ["Palmeri", "Mark L.", ""]]}, {"id": "1908.05783", "submitter": "Laurent Risser", "authors": "Laurent Risser, Quentin Vincenot, Jean-Michel Loubes", "title": "Tackling Algorithmic Bias in Neural-Network Classifiers using\n  Wasserstein-2 Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasingly common use of neural network classifiers in industrial and\nsocial applications of image analysis has allowed impressive progress these\nlast years. Such methods are however sensitive to algorithmic bias, i.e. to an\nunder- or an over-representation of positive predictions or to higher\nprediction errors in specific subgroups of images. We then introduce in this\npaper a new method to temper the algorithmic bias in Neural-Network based\nclassifiers. Our method is Neural-Network architecture agnostic and scales well\nto massive training sets of images. It indeed only overloads the loss function\nwith a Wasserstein-2 based regularization term whose gradient can be computed\nat a reasonable algorithmic cost. This makes it possible to use our regularised\nloss with standard stochastic gradient-descent strategies. The good behavior of\nour method is assessed on the Adult census, MNIST, and CelebA datasets.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 22:27:29 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:20:46 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Risser", "Laurent", ""], ["Vincenot", "Quentin", ""], ["Loubes", "Jean-Michel", ""]]}, {"id": "1908.05787", "submitter": "E M Wasifur Rahman Chowdhury", "authors": "Wasifur Rahman, Md. Kamrul Hasan, Sangwu Lee, Amir Zadeh, Chengfeng\n  Mao, Louis-Philippe Morency, Ehsan Hoque", "title": "Integrating Multimodal Information in Large Pretrained Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent Transformer-based contextual word representations, including BERT and\nXLNet, have shown state-of-the-art performance in multiple disciplines within\nNLP. Fine-tuning the trained contextual models on task-specific datasets has\nbeen the key to achieving superior performance downstream. While fine-tuning\nthese pre-trained models is straightforward for lexical applications\n(applications with only language modality), it is not trivial for multimodal\nlanguage (a growing area in NLP focused on modeling face-to-face\ncommunication). Pre-trained models don't have the necessary components to\naccept two extra modalities of vision and acoustic. In this paper, we proposed\nan attachment to BERT and XLNet called Multimodal Adaptation Gate (MAG). MAG\nallows BERT and XLNet to accept multimodal nonverbal data during fine-tuning.\nIt does so by generating a shift to internal representation of BERT and XLNet;\na shift that is conditioned on the visual and acoustic modalities. In our\nexperiments, we study the commonly used CMU-MOSI and CMU-MOSEI datasets for\nmultimodal sentiment analysis. Fine-tuning MAG-BERT and MAG-XLNet significantly\nboosts the sentiment analysis performance over previous baselines as well as\nlanguage-only fine-tuning of BERT and XLNet. On the CMU-MOSI dataset, MAG-XLNet\nachieves human-level multimodal sentiment analysis performance for the first\ntime in the NLP community.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 22:51:21 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 16:50:11 GMT"}, {"version": "v3", "created": "Sat, 21 Nov 2020 13:52:22 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Rahman", "Wasifur", ""], ["Hasan", "Md. Kamrul", ""], ["Lee", "Sangwu", ""], ["Zadeh", "Amir", ""], ["Mao", "Chengfeng", ""], ["Morency", "Louis-Philippe", ""], ["Hoque", "Ehsan", ""]]}, {"id": "1908.05792", "submitter": "Wissam Sid-Lakhdar", "authors": "Wissam M. Sid-Lakhdar, Mohsen Mahmoudi Aznaveh, Xiaoye S. Li, James W.\n  Demmel", "title": "Multitask and Transfer Learning for Autotuning Exascale Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning and transfer learning have proven to be useful in the\nfield of machine learning when additional knowledge is available to help a\nprediction task. We aim at deriving methods following these paradigms for use\nin autotuning, where the goal is to find the optimal performance parameters of\nan application treated as a black-box function. We show comparative results\nwith state-of-the-art autotuning techniques. For instance, we observe an\naverage $1.5x$ improvement of the application runtime compared to the OpenTuner\nand HpBandSter autotuners. We explain how our approaches can be more suitable\nthan some state-of-the-art autotuners for the tuning of any application in\ngeneral and of expensive exascale applications in particular.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 23:14:54 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Sid-Lakhdar", "Wissam M.", ""], ["Aznaveh", "Mohsen Mahmoudi", ""], ["Li", "Xiaoye S.", ""], ["Demmel", "James W.", ""]]}, {"id": "1908.05814", "submitter": "Sanae Amani", "authors": "Sanae Amani, Mahnoosh Alizadeh, Christos Thrampoulidis", "title": "Linear Stochastic Bandits Under Safety Constraints", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bandit algorithms have various application in safety-critical systems, where\nit is important to respect the system constraints that rely on the bandit's\nunknown parameters at every round. In this paper, we formulate a linear\nstochastic multi-armed bandit problem with safety constraints that depend\n(linearly) on an unknown parameter vector. As such, the learner is unable to\nidentify all safe actions and must act conservatively in ensuring that her\nactions satisfy the safety constraint at all rounds (at least with high\nprobability). For these bandits, we propose a new UCB-based algorithm called\nSafe-LUCB, which includes necessary modifications to respect safety\nconstraints. The algorithm has two phases. During the pure exploration phase\nthe learner chooses her actions at random from a restricted set of safe actions\nwith the goal of learning a good approximation of the entire unknown safe set.\nOnce this goal is achieved, the algorithm begins a safe\nexploration-exploitation phase where the learner gradually expands their\nestimate of the set of safe actions while controlling the growth of regret. We\nprovide a general regret bound for the algorithm, as well as a problem\ndependent bound that is connected to the location of the optimal action within\nthe safe set. We then propose a modified heuristic that exploits our problem\ndependent analysis to improve the regret.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 02:08:24 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Amani", "Sanae", ""], ["Alizadeh", "Mahnoosh", ""], ["Thrampoulidis", "Christos", ""]]}, {"id": "1908.05818", "submitter": "Bharath Sriperumbudur", "authors": "Samory Kpotufe and Bharath K. Sriperumbudur", "title": "Gaussian Sketching yields a J-L Lemma in RKHS", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of the paper is to show that Gaussian sketching of a\nkernel-Gram matrix $\\boldsymbol K$ yields an operator whose counterpart in an\nRKHS $\\mathcal H$, is a \\emph{random projection} operator---in the spirit of\nJohnson-Lindenstrauss (J-L) lemma. To be precise, given a random matrix $Z$\nwith i.i.d. Gaussian entries, we show that a sketch $Z\\boldsymbol{K}$\ncorresponds to a particular random operator in (infinite-dimensional) Hilbert\nspace $\\mathcal H$ that maps functions $f \\in \\mathcal H$ to a low-dimensional\nspace $\\mathbb R^d$, while preserving a weighted RKHS inner-product of the form\n$\\langle f, g \\rangle_{\\Sigma} \\doteq \\langle f, \\Sigma^3 g \\rangle_{\\mathcal\nH}$, where $\\Sigma$ is the \\emph{covariance} operator induced by the data\ndistribution. In particular, under similar assumptions as in kernel PCA (KPCA),\nor kernel $k$-means (K-$k$-means), well-separated subsets of feature-space\n$\\{K(\\cdot, x): x \\in \\cal X\\}$ remain well-separated after such operation,\nwhich suggests similar benefits as in KPCA and/or K-$k$-means, albeit at the\nmuch cheaper cost of a random projection. In particular, our convergence rates\nsuggest that, given a large dataset $\\{X_i\\}_{i=1}^N$ of size $N$, we can build\nthe Gram matrix $\\boldsymbol K$ on a much smaller subsample of size $n\\ll N$,\nso that the sketch $Z\\boldsymbol K$ is very cheap to obtain and subsequently\napply as a projection operator on the original data $\\{X_i\\}_{i=1}^N$. We\nverify these insights empirically on synthetic data, and on real-world\nclustering applications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 02:36:25 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 01:58:48 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Kpotufe", "Samory", ""], ["Sriperumbudur", "Bharath K.", ""]]}, {"id": "1908.05823", "submitter": "Meng Tang S", "authors": "Meng Tang, Yimin Liu, Louis J. Durlofsky", "title": "A deep-learning-based surrogate model for data assimilation in dynamic\n  subsurface flow problems", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2020.109456", "report-no": null, "categories": "cs.LG physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A deep-learning-based surrogate model is developed and applied for predicting\ndynamic subsurface flow in channelized geological models. The surrogate model\nis based on deep convolutional and recurrent neural network architectures,\nspecifically a residual U-Net and a convolutional long short term memory\nrecurrent network. Training samples entail global pressure and saturation maps,\nat a series of time steps, generated by simulating oil-water flow in many (1500\nin our case) realizations of a 2D channelized system. After training, the\n`recurrent R-U-Net' surrogate model is shown to be capable of accurately\npredicting dynamic pressure and saturation maps and well rates (e.g.,\ntime-varying oil and water rates at production wells) for new geological\nrealizations. Assessments demonstrating high surrogate-model accuracy are\npresented for an individual geological realization and for an ensemble of 500\ntest geomodels. The surrogate model is then used for the challenging problem of\ndata assimilation (history matching) in a channelized system. For this study,\nposterior reservoir models are generated using the randomized maximum\nlikelihood method, with the permeability field represented using the recently\ndeveloped CNN-PCA parameterization. The flow responses required during the data\nassimilation procedure are provided by the recurrent R-U-Net. The overall\napproach is shown to lead to substantial reduction in prediction uncertainty.\nHigh-fidelity numerical simulation results for the posterior geomodels\n(generated by the surrogate-based data assimilation procedure) are shown to be\nin essential agreement with the recurrent R-U-Net predictions. The accuracy and\ndramatic speedup provided by the surrogate model suggest that it may eventually\nenable the application of more formal posterior sampling methods in realistic\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 03:02:34 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Tang", "Meng", ""], ["Liu", "Yimin", ""], ["Durlofsky", "Louis J.", ""]]}, {"id": "1908.05864", "submitter": "Grzegorz Dudek", "authors": "Grzegorz Dudek", "title": "Generating Random Parameters in Feedforward Neural Networks with Random\n  Hidden Nodes: Drawbacks of the Standard Method and How to Improve It", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard method of generating random weights and biases in feedforward\nneural networks with random hidden nodes, selects them both from the uniform\ndistribution over the same fixed interval. In this work, we show the drawbacks\nof this approach and propose a new method of generating random parameters. This\nmethod ensures the most nonlinear fragments of sigmoids, which are most useful\nin modeling target function nonlinearity, are kept in the input hypercube. In\naddition, we show how to generate activation functions with uniformly\ndistributed slope angles.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 06:43:33 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 12:26:38 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Dudek", "Grzegorz", ""]]}, {"id": "1908.05885", "submitter": "Rasmus Br{\\o}ndum", "authors": "Rasmus Froberg Br{\\o}ndum, Thomas Yssing Michaelsen, Martin B{\\o}gsted", "title": "Regression on imperfect class labels derived by unsupervised clustering", "comments": null, "journal-ref": null, "doi": "10.1093/bib/bbaa014", "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outcome regressed on class labels identified by unsupervised clustering is\ncustom in many applications. However, it is common to ignore the\nmisclassification of class labels caused by the learning algorithm, which\npotentially leads to serious bias of the estimated effect parameters. Due to\nits generality we suggest to redress the situation by use of the simulation and\nextrapolation method. Performance is illustrated by simulated data from\nGaussian mixture models. Finally, we apply our method to a study which\nregressed overall survival on class labels derived from unsupervised clustering\nof gene expression data from bone marrow samples of multiple myeloma patients.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 08:26:03 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Br\u00f8ndum", "Rasmus Froberg", ""], ["Michaelsen", "Thomas Yssing", ""], ["B\u00f8gsted", "Martin", ""]]}, {"id": "1908.05891", "submitter": "Xin Yao", "authors": "Xin Yao, Tianchi Huang, Chenglei Wu, Rui-Xiao Zhang, Lifeng Sun", "title": "Federated Learning with Additional Mechanisms on Clients to Reduce\n  Communication Costs", "comments": "This is a combination version of our papers in VCIP 2018 and ICIP\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) enables on-device training over distributed networks\nconsisting of a massive amount of modern smart devices, such as smartphones and\nIoT (Internet of Things) devices. However, the leading optimization algorithm\nin such settings, i.e., federated averaging (FedAvg), suffers from heavy\ncommunication costs and the inevitable performance drop, especially when the\nlocal data is distributed in a non-IID way. To alleviate this problem, we\npropose two potential solutions by introducing additional mechanisms to the\non-device training.\n  The first (FedMMD) is adopting a two-stream model with the MMD (Maximum Mean\nDiscrepancy) constraint instead of a single model in vanilla FedAvg to be\ntrained on devices. Experiments show that the proposed method outperforms\nbaselines, especially in non-IID FL settings, with a reduction of more than 20%\nin required communication rounds.\n  The second is FL with feature fusion (FedFusion). By aggregating the features\nfrom both the local and global models, we achieve higher accuracy at fewer\ncommunication costs. Furthermore, the feature fusion modules offer better\ninitialization for newly incoming clients and thus speed up the process of\nconvergence. Experiments in popular FL scenarios show that our FedFusion\noutperforms baselines in both accuracy and generalization ability while\nreducing the number of required communication rounds by more than 60%.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 08:51:27 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 16:33:58 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Yao", "Xin", ""], ["Huang", "Tianchi", ""], ["Wu", "Chenglei", ""], ["Zhang", "Rui-Xiao", ""], ["Sun", "Lifeng", ""]]}, {"id": "1908.05915", "submitter": "Carolin Lawrence", "authors": "Carolin Lawrence, Bhushan Kotnis, Mathias Niepert", "title": "Attending to Future Tokens For Bidirectional Sequence Generation", "comments": "Conference on Empirical Methods in Natural Language Processing\n  (EMNLP), 2019, Hong Kong, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural sequence generation is typically performed token-by-token and\nleft-to-right. Whenever a token is generated only previously produced tokens\nare taken into consideration. In contrast, for problems such as sequence\nclassification, bidirectional attention, which takes both past and future\ntokens into consideration, has been shown to perform much better. We propose to\nmake the sequence generation process bidirectional by employing special\nplaceholder tokens. Treated as a node in a fully connected graph, a placeholder\ntoken can take past and future tokens into consideration when generating the\nactual output token. We verify the effectiveness of our approach experimentally\non two conversational tasks where the proposed bidirectional model outperforms\ncompetitive baselines by a large margin.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 10:00:45 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 13:50:11 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Lawrence", "Carolin", ""], ["Kotnis", "Bhushan", ""], ["Niepert", "Mathias", ""]]}, {"id": "1908.05959", "submitter": "Mauricio Orbes Arteaga", "authors": "Mauricio Orbes-Arteaga and Thomas Varsavsky and Carole H. Sudre and\n  Zach Eaton-Rosen and Lewis J. Haddow and Lauge S{\\o}rensen and Mads Nielsen\n  and Akshay Pai and S\\'ebastien Ourselin and Marc Modat and Parashkev Nachev\n  and M. Jorge Cardoso", "title": "Multi-Domain Adaptation in Brain MRI through Paired Consistency and\n  Adversarial Learning", "comments": "Accepted at 1st International Workshop on Domain Adaptation and\n  Representation Transfer held at MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning algorithms trained on medical images will often fail to\ngeneralize across changes in acquisition parameters. Recent work in domain\nadaptation addresses this challenge and successfully leverages labeled data in\na source domain to perform well on an unlabeled target domain. Inspired by\nrecent work in semi-supervised learning we introduce a novel method to adapt\nfrom one source domain to $n$ target domains (as long as there is paired data\ncovering all domains). Our multi-domain adaptation method utilises a\nconsistency loss combined with adversarial learning. We provide results on\nwhite matter lesion hyperintensity segmentation from brain MRIs using the\nMICCAI 2017 challenge data as the source domain and two target domains. The\nproposed method significantly outperforms other domain adaptation baselines.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:06:18 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 09:31:53 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Orbes-Arteaga", "Mauricio", ""], ["Varsavsky", "Thomas", ""], ["Sudre", "Carole H.", ""], ["Eaton-Rosen", "Zach", ""], ["Haddow", "Lewis J.", ""], ["S\u00f8rensen", "Lauge", ""], ["Nielsen", "Mads", ""], ["Pai", "Akshay", ""], ["Ourselin", "S\u00e9bastien", ""], ["Modat", "Marc", ""], ["Nachev", "Parashkev", ""], ["Cardoso", "M. Jorge", ""]]}, {"id": "1908.05968", "submitter": "Ryan McConville", "authors": "Ryan McConville, Raul Santos-Rodriguez, Robert J Piechocki, Ian\n  Craddock", "title": "N2D: (Not Too) Deep Clustering via Clustering the Local Manifold of an\n  Autoencoded Embedding", "comments": "Accepted at ICPR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep clustering has increasingly been demonstrating superiority over\nconventional shallow clustering algorithms. Deep clustering algorithms usually\ncombine representation learning with deep neural networks to achieve this\nperformance, typically optimizing a clustering and non-clustering loss. In such\ncases, an autoencoder is typically connected with a clustering network, and the\nfinal clustering is jointly learned by both the autoencoder and clustering\nnetwork. Instead, we propose to learn an autoencoded embedding and then search\nthis further for the underlying manifold. For simplicity, we then cluster this\nwith a shallow clustering algorithm, rather than a deeper network. We study a\nnumber of local and global manifold learning methods on both the raw data and\nautoencoded embedding, concluding that UMAP in our framework is best able to\nfind the most clusterable manifold in the embedding, suggesting local manifold\nlearning on an autoencoded embedding is effective for discovering higher\nquality discovering clusters. We quantitatively show across a range of image\nand time-series datasets that our method has competitive performance against\nthe latest deep clustering algorithms, including out-performing current\nstate-of-the-art on several. We postulate that these results show a promising\nresearch direction for deep clustering. The code can be found at\nhttps://github.com/rymc/n2d\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:34:18 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 16:08:13 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 11:02:36 GMT"}, {"version": "v4", "created": "Wed, 11 Sep 2019 15:57:51 GMT"}, {"version": "v5", "created": "Wed, 25 Sep 2019 15:33:08 GMT"}, {"version": "v6", "created": "Tue, 30 Jun 2020 07:57:15 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["McConville", "Ryan", ""], ["Santos-Rodriguez", "Raul", ""], ["Piechocki", "Robert J", ""], ["Craddock", "Ian", ""]]}, {"id": "1908.05972", "submitter": "Henrietta Rose Baker Mrs", "authors": "Henrietta Baker, Matthew R. Hallowell and Antoine J.-P. Tixier", "title": "AI-based Prediction of Independent Construction Safety Outcomes from\n  Universal Attributes", "comments": "Accepted for publication in Automation in Construction", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper significantly improves on, and finishes to validate, an approach\nproposed in previous research in which safety outcomes were predicted from\nattributes with machine learning. Like in the original study, we use Natural\nLanguage Processing (NLP) to extract fundamental attributes from raw incident\nreports and machine learning models are trained to predict safety outcomes. The\noutcomes predicted here are injury severity, injury type, body part impacted,\nand incident type. However, unlike in the original study, safety outcomes were\nnot extracted via NLP but were provided by independent human annotations,\neliminating any potential source of artificial correlation between predictors\nand predictands. Results show that attributes are still highly predictive,\nconfirming the validity of the original approach. Other improvements brought by\nthe current study include the use of (1) a much larger dataset featuring more\nthan 90,000 reports, (2) two new models, XGBoost and linear SVM (Support Vector\nMachines), (3) model stacking, (4) a more straightforward experimental setup\nwith more appropriate performance metrics, and (5) an analysis of per-category\nattribute importance scores. Finally, the injury severity outcome is well\npredicted, which was not the case in the original study. This is a significant\nadvancement.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 13:50:15 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 11:19:42 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Baker", "Henrietta", ""], ["Hallowell", "Matthew R.", ""], ["Tixier", "Antoine J. -P.", ""]]}, {"id": "1908.05978", "submitter": "Sandra Ortega-Martorell", "authors": "Paulo J. G. Lisboa, Sandra Ortega-Martorell, Sadie Cashman, and Ivan\n  Olier", "title": "The Partial Response Network: a neural network nomogram", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among interpretable machine learning methods, the class of Generalised\nAdditive Neural Networks (GANNs) is referred to as Self-Explaining Neural\nNetworks (SENN) because of the linear dependence on explicit functions of the\ninputs. In binary classification this shows the precise weight that each input\ncontributes towards the logit. The nomogram is a graphical representation of\nthese weights. We show that functions of individual and pairs of variables can\nbe derived from a functional Analysis of Variance (ANOVA) representation,\nenabling an efficient feature selection to be carried by application of the\nlogistic Lasso. This process infers the structure of GANNs which otherwise\nneeds to be predefined. As this method is particularly suited for tabular data,\nit starts by fitting a generic flexible model, in this case a Multi-layer\nPerceptron (MLP) to which the ANOVA decomposition is applied. This has the\nfurther advantage that the resulting GANN can be replicated as a SENN, enabling\nfurther refinement of the univariate and bivariate component functions to take\nplace. The component functions are partial responses hence the SENN is a\npartial response network. The Partial Response Network (PRN) is equally as\ntransparent as a traditional logistic regression model, but capable of\nnon-linear classification with comparable or superior performance to the\noriginal MLP. In other words, the PRN is a fully interpretable representation\nof the MLP, at the level of univariate and bivariate effects. The performance\nof the PRN is shown to be competitive for benchmark data, against\nstate-of-the-art machine learning methods including GBM, SVM and Random\nForests. It is also compared with spline-based Sparse Additive Models (SAM)\nshowing that a semi-parametric representation of the GAM as a neural network\ncan be as effective as the SAM though less constrained by the need to set\nspline nodes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 14:02:19 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 15:52:26 GMT"}, {"version": "v3", "created": "Wed, 16 Jun 2021 08:45:37 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Lisboa", "Paulo J. G.", ""], ["Ortega-Martorell", "Sandra", ""], ["Cashman", "Sadie", ""], ["Olier", "Ivan", ""]]}, {"id": "1908.05982", "submitter": "Tomasz Piotrowski", "authors": "Tomasz Piotrowski and Krzysztof Rykaczewski", "title": "Iterative Neural Networks with Bounded Weights", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent analysis of a model of iterative neural network in Hilbert spaces\nestablished fundamental properties of such networks, such as existence of the\nfixed points sets, convergence analysis, and Lipschitz continuity. Building on\nthese results, we show that under a single mild condition on the weights of the\nnetwork, one is guaranteed to obtain a neural network converging to its unique\nfixed point. We provide a bound on the norm of this fixed point in terms of\nnorms of weights and biases of the network. We also show why this model of a\nfeed-forward neural network is not able to accomodate Hopfield networks under\nour assumption.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 14:16:55 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 13:32:03 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Piotrowski", "Tomasz", ""], ["Rykaczewski", "Krzysztof", ""]]}, {"id": "1908.06008", "submitter": "Soujanya Poria", "authors": "Navonil Majumder, Soujanya Poria, Gangeshwar Krishnamurthy, Niyati\n  Chhaya, Rada Mihalcea, Alexander Gelbukh", "title": "Variational Fusion for Multimodal Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Multimodal fusion is considered a key step in multimodal tasks such as\nsentiment analysis, emotion detection, question answering, and others. Most of\nthe recent work on multimodal fusion does not guarantee the fidelity of the\nmultimodal representation with respect to the unimodal representations. In this\npaper, we propose a variational autoencoder-based approach for modality fusion\nthat minimizes information loss between unimodal and multimodal\nrepresentations. We empirically show that this method outperforms the\nstate-of-the-art methods by a significant margin on several popular datasets.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 13:39:19 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Majumder", "Navonil", ""], ["Poria", "Soujanya", ""], ["Krishnamurthy", "Gangeshwar", ""], ["Chhaya", "Niyati", ""], ["Mihalcea", "Rada", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "1908.06010", "submitter": "Dmitri Kvasov", "authors": "Yaroslav D. Sergeyev (1 and 2), Antonio Candelieri (3), Dmitri E.\n  Kvasov (1 and 2), Riccardo Perego (3) ((1) University of Calabria, Rende,\n  Italy (2) Lobachevsky University, Nizhni Novgorod, Russia (3) University of\n  Milano-Bicocca, Milan, Italy)", "title": "Safe global optimization of expensive noisy black-box functions in the\n  $\\delta$-Lipschitz framework", "comments": "Published paper (37 pages, 44 figures, 4 tables): Yaroslav D.\n  Sergeyev - corresponding author. Soft Computing (2020)", "journal-ref": null, "doi": "10.1007/s00500-020-05030-3", "report-no": null, "categories": "math.OC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of safe global maximization (it should not be\nconfused with robust optimization) of expensive noisy black-box functions\nsatisfying the Lipschitz condition is considered. The notion \"safe\" means that\nthe objective function $f(x)$ during optimization should not violate a \"safety\"\nthreshold, for instance, a certain a priori given value $h$ in a maximization\nproblem. Thus, any new function evaluation (possibly corrupted by noise) must\nbe performed at \"safe points\" only, namely, at points $y$ for which it is known\nthat the objective function $f(y) > h$. The main difficulty here consists in\nthe fact that the used optimization algorithm should ensure that the safety\nconstraint will be satisfied at a point $y$ before evaluation of $f(y)$ will be\nexecuted. Thus, it is required both to determine the safe region $\\Omega$\nwithin the search domain~$D$ and to find the global maximum within $\\Omega$. An\nadditional difficulty consists in the fact that these problems should be solved\nin the presence of the noise. This paper starts with a theoretical study of the\nproblem and it is shown that even though the objective function $f(x)$\nsatisfies the Lipschitz condition, traditional Lipschitz minorants and\nmajorants cannot be used due to the presence of the noise. Then, a\n$\\delta$-Lipschitz framework and two algorithms using it are proposed to solve\nthe safe global maximization problem. The first method determines the safe area\nwithin the search domain and the second one executes the global maximization\nover the found safe region. For both methods a number of theoretical results\nrelated to their functioning and convergence is established. Finally, numerical\nexperiments confirming the reliability of the proposed procedures are\nperformed.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 16:20:55 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 14:31:46 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Sergeyev", "Yaroslav D.", "", "1 and 2"], ["Candelieri", "Antonio", "", "1 and 2"], ["Kvasov", "Dmitri E.", "", "1 and 2"], ["Perego", "Riccardo", ""]]}, {"id": "1908.06012", "submitter": "Zhang-Wei Hong", "authors": "Zhang-Wei Hong, Joni Pajarinen, Jan Peters", "title": "Model-based Lookahead Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based Reinforcement Learning (MBRL) allows data-efficient learning\nwhich is required in real world applications such as robotics. However, despite\nthe impressive data-efficiency, MBRL does not achieve the final performance of\nstate-of-the-art Model-free Reinforcement Learning (MFRL) methods. We leverage\nthe strengths of both realms and propose an approach that obtains high\nperformance with a small amount of data. In particular, we combine MFRL and\nModel Predictive Control (MPC). While MFRL's strength in exploration allows us\nto train a better forward dynamics model for MPC, MPC improves the performance\nof the MFRL policy by sampling-based planning. The experimental results in\nstandard continuous control benchmarks show that our approach can achieve\nMFRL`s level of performance while being as data-efficient as MBRL.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 04:10:13 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Hong", "Zhang-Wei", ""], ["Pajarinen", "Joni", ""], ["Peters", "Jan", ""]]}, {"id": "1908.06013", "submitter": "Maxim Osipov", "authors": "Maxim Osipov", "title": "Towards automated symptoms assessment in mental health", "comments": "This thesis is submitted to the Department of Engineering Science,\n  University of Oxford, in partial fulfilment of the requirements for the\n  degree of Doctor of Philosophy; please find the original submission at\n  https://ora.ox.ac.uk/objects/uuid:42111684-8801-440e-8fbb-00f779d806ee", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.CE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Activity and motion analysis has the potential to be used as a diagnostic\ntool for mental disorders. However, to-date, little work has been performed in\nturning stratification measures of activity into useful symptom markers. The\nresearch presented in this thesis has focused on the identification of\nobjective activity and behaviour metrics that could be useful for the analysis\nof mental health symptoms in the above mentioned dimensions. Particular\nattention is given to the analysis of objective differences between disorders,\nas well as identification of clinical episodes of mania and depression in\nbipolar patients, and deterioration in borderline personality disorder\npatients. A principled framework is proposed for mHealth monitoring of\npsychiatric patients, based on measurable changes in behaviour, represented in\nphysical activity time series, collected via mobile and wearable devices. The\nframework defines methods for direct computational analysis of symptoms in\ndisorganisation and psychomotor dimensions, as well as measures for indirect\nassessment of mood, using patterns of physical activity, sleep and circadian\nrhythms. The approach of computational behaviour analysis, proposed in this\nthesis, has the potential for early identification of clinical deterioration in\nambulatory patients, and allows for the specification of distinct and\nmeasurable behavioural phenotypes, thus enabling better understanding and\ntreatment of mental disorders.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 20:27:51 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Osipov", "Maxim", ""]]}, {"id": "1908.06021", "submitter": "Zhaohong Deng", "authors": "Yingzhong Shi, Zhaohong Deng, Haoran Chen, Kup-Sze Choi, Shitong Wang", "title": "Double-Coupling Learning for Multi-Task Data Stream Classification", "comments": "This work has been accepted conditionally by IEEE Computational\n  Intelligence Magazine in July 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data stream classification methods demonstrate promising performance on a\nsingle data stream by exploring the cohesion in the data stream. However,\nmultiple data streams that involve several correlated data streams are common\nin many practical scenarios, which can be viewed as multi-task data streams.\nInstead of handling them separately, it is beneficial to consider the\ncorrelations among the multi-task data streams for data stream modeling tasks.\nIn this regard, a novel classification method called double-coupling support\nvector machines (DC-SVM), is proposed for classifying them simultaneously.\nDC-SVM considers the external correlations between multiple data streams, while\nhandling the internal relationship within the individual data stream.\nExperimental results on artificial and real-world multi-task data streams\ndemonstrate that the proposed method outperforms traditional data stream\nclassification methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 02:59:56 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Shi", "Yingzhong", ""], ["Deng", "Zhaohong", ""], ["Chen", "Haoran", ""], ["Choi", "Kup-Sze", ""], ["Wang", "Shitong", ""]]}, {"id": "1908.06022", "submitter": "Xiangxiang Chu", "authors": "Xiangxiang Chu, Bo Zhang, Jixiang Li, Qingyuan Li, Ruijun Xu", "title": "SCARLET-NAS: Bridging the gap between Stability and Scalability in\n  Weight-sharing Neural Architecture Search", "comments": "Make one shot nas scalable", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To discover powerful yet compact models is an important goal of neural\narchitecture search. Previous two-stage one-shot approaches are limited by\nsearch space with a fixed depth. It seems handy to include an additional skip\nconnection in the search space to make depths variable. However, it creates a\nlarge range of perturbation during supernet training and it has difficulty\ngiving a confident ranking for subnetworks. In this paper, we discover that\nskip connections bring about significant feature inconsistency compared with\nother operations, which potentially degrades the supernet performance. Based on\nthis observation, we tackle the problem by imposing an equivariant learnable\nstabilizer to homogenize such disparities. Experiments show that our proposed\nstabilizer helps to improve the supernet's convergence as well as ranking\nperformance. With an evolutionary search backend that incorporates the\nstabilized supernet as an evaluator, we derive a family of state-of-the-art\narchitectures, the SCARLET series of several depths, especially SCARLET-A\nobtains 76.9% top-1 accuracy on ImageNet. The models and evaluation code are\nreleased online https://github.com/xiaomi-automl/ScarletNAS.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:31:08 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 10:42:54 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 14:57:13 GMT"}, {"version": "v4", "created": "Thu, 28 Nov 2019 09:04:13 GMT"}, {"version": "v5", "created": "Thu, 2 Apr 2020 03:54:03 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Chu", "Xiangxiang", ""], ["Zhang", "Bo", ""], ["Li", "Jixiang", ""], ["Li", "Qingyuan", ""], ["Xu", "Ruijun", ""]]}, {"id": "1908.06029", "submitter": "Victor Solo", "authors": "Victor Solo", "title": "Pearson Distance is not a Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Pearson distance between a pair of random variables $X,Y$ with\ncorrelation $\\rho_{xy}$, namely, 1-$\\rho_{xy}$, has gained widespread use,\nparticularly for clustering, in areas such as gene expression analysis, brain\nimaging and cyber security. In all these applications it is implicitly\nassumed/required that the distance measures be metrics, thus satisfying the\ntriangle inequality. We show however, that Pearson distance is not a metric. We\ngo on to show that this can be repaired by recalling the result, (well known in\nother literature) that $\\sqrt{1-\\rho_{xy}}$ is a metric. We similarly show that\na related measure of interest, $1-|\\rho_{xy}|$, which is invariant to the sign\nof $\\rho_{xy}$, is not a metric but that $\\sqrt{1-\\rho_{xy}^2}$ is. We also\ngive generalizations of these results.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 06:41:17 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Solo", "Victor", ""]]}, {"id": "1908.06040", "submitter": "Felipe Moreno-Vera", "authors": "Felipe Moreno-Vera", "title": "Performing Deep Recurrent Double Q-Learning for Atari Games", "comments": "Accepted paper on LatinXinAI Workshop co-located with the\n  International Conference on Machine Learning (ICML) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, many applications in Machine Learning are based on define new\nmodels to extract more information about data, In this case Deep Reinforcement\nLearning with the most common application in video games like Atari, Mario, and\nothers causes an impact in how to computers can learning by himself with only\ninformation called rewards obtained from any action. There is a lot of\nalgorithms modeled and implemented based on Deep Recurrent Q-Learning proposed\nby DeepMind used in AlphaZero and Go. In this document, We proposed Deep\nRecurrent Double Q-Learning that is an implementation of Deep Reinforcement\nLearning using Double Q-Learning algorithms and Recurrent Networks like LSTM\nand DRQN.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:56:16 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 21:45:01 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Moreno-Vera", "Felipe", ""]]}, {"id": "1908.06062", "submitter": "Daniel Liu", "authors": "Daniel Liu, Ronald Yu, Hao Su", "title": "Adversarial shape perturbations on 3D point clouds", "comments": "18 pages, accepted to the 2020 ECCV workshop on Adversarial\n  Robustness in the Real World, source code available at this https url:\n  https://github.com/Daniel-Liu-c0deb0t/Adversarial-point-perturbations-on-3D-objects", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CR cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of training robust neural network grows as 3D data is\nincreasingly utilized in deep learning for vision tasks in robotics, drone\ncontrol, and autonomous driving. One commonly used 3D data type is 3D point\nclouds, which describe shape information. We examine the problem of creating\nrobust models from the perspective of the attacker, which is necessary in\nunderstanding how 3D neural networks can be exploited. We explore two\ncategories of attacks: distributional attacks that involve imperceptible\nperturbations to the distribution of points, and shape attacks that involve\ndeforming the shape represented by a point cloud. We explore three possible\nshape attacks for attacking 3D point cloud classification and show that some of\nthem are able to be effective even against preprocessing steps, like the\npreviously proposed point-removal defenses.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:19:34 GMT"}, {"version": "v2", "created": "Mon, 28 Sep 2020 00:04:59 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 04:55:16 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Liu", "Daniel", ""], ["Yu", "Ronald", ""], ["Su", "Hao", ""]]}, {"id": "1908.06065", "submitter": "Mohammed Rayyan Sheriff", "authors": "Mohammed Rayyan Sheriff, Debasish Chatterjee", "title": "On Convex Duality in Linear Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we dwell into the class of so called ill posed Linear Inverse\nProblems (LIP) in machine learning, which has become almost a classic in recent\ntimes. The fundamental task in an LIP is to recover the entire signal / data\nfrom its relatively few random linear measurements. Such problems arise in\nvariety of settings with applications ranging from medical image processing,\nrecommender systems etc. We provide an exposition to the convex duality of the\nlinear inverse problems, and obtain a novel and equivalent convex-concave\nmin-max reformulation that gives rise to simple ascend-descent type algorithms\nto solve an LIP. Moreover, such a reformulation is crucial in developing\nmethods to solve the dictionary learning problem with almost sure recovery\nconstraints.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:25:15 GMT"}, {"version": "v2", "created": "Sat, 19 Oct 2019 19:49:07 GMT"}, {"version": "v3", "created": "Wed, 8 Jan 2020 19:48:26 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Sheriff", "Mohammed Rayyan", ""], ["Chatterjee", "Debasish", ""]]}, {"id": "1908.06075", "submitter": "Xueying Tang", "authors": "Xueying Tang, Zhi Wang, Jingchen Liu, and Zhiliang Ying", "title": "An Exploratory Analysis of the Latent Structure of Process Data via\n  Action Sequence Autoencoder", "comments": "28 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer simulations have become a popular tool of assessing complex skills\nsuch as problem-solving skills. Log files of computer-based items record the\nentire human-computer interactive processes for each respondent. The response\nprocesses are very diverse, noisy, and of nonstandard formats. Few generic\nmethods have been developed for exploiting the information contained in process\ndata. In this article, we propose a method to extract latent variables from\nprocess data. The method utilizes a sequence-to-sequence autoencoder to\ncompress response processes into standard numerical vectors. It does not\nrequire prior knowledge of the specific items and human-computers interaction\npatterns. The proposed method is applied to both simulated and real process\ndata to demonstrate that the resulting latent variables extract useful\ninformation from the response processes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:55:20 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Tang", "Xueying", ""], ["Wang", "Zhi", ""], ["Liu", "Jingchen", ""], ["Ying", "Zhiliang", ""]]}, {"id": "1908.06077", "submitter": "Ali Ramezani-Kebrya", "authors": "Ali Ramezani-Kebrya, Fartash Faghri, Ilya Markov, Vitalii Aksenov, Dan\n  Alistarh, Daniel M. Roy", "title": "NUQSGD: Provably Communication-efficient Data-parallel SGD via\n  Nonuniform Quantization", "comments": "42 pages, 21 figures. To appear in the Journal of Machine Learning\n  Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the size and complexity of models and datasets grow, so does the need for\ncommunication-efficient variants of stochastic gradient descent that can be\ndeployed to perform parallel model training. One popular\ncommunication-compression method for data-parallel SGD is QSGD (Alistarh et\nal., 2017), which quantizes and encodes gradients to reduce communication\ncosts. The baseline variant of QSGD provides strong theoretical guarantees,\nhowever, for practical purposes, the authors proposed a heuristic variant which\nwe call QSGDinf, which demonstrated impressive empirical gains for distributed\ntraining of large neural networks. In this paper, we build on this work to\npropose a new gradient quantization scheme, and show that it has both stronger\ntheoretical guarantees than QSGD, and matches and exceeds the empirical\nperformance of the QSGDinf heuristic and of other compression methods.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:59:01 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 21:39:42 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Ramezani-Kebrya", "Ali", ""], ["Faghri", "Fartash", ""], ["Markov", "Ilya", ""], ["Aksenov", "Vitalii", ""], ["Alistarh", "Dan", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1908.06079", "submitter": "Zhizhong Li", "authors": "Zhizhong Li, Linjie Luo, Sergey Tulyakov, Qieyun Dai, Derek Hoiem", "title": "Task-Assisted Domain Adaptation with Anchor Tasks", "comments": "In WACV 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some tasks, such as surface normals or single-view depth estimation, require\nper-pixel ground truth that is difficult to obtain on real images but easy to\nobtain on synthetic. However, models learned on synthetic images often do not\ngeneralize well to real images due to the domain shift. Our key idea to improve\ndomain adaptation is to introduce a separate anchor task (such as facial\nlandmarks) whose annotations can be obtained at no cost or are already\navailable on both synthetic and real datasets. To further leverage the implicit\nrelationship between the anchor and main tasks, we apply our \\freeze technique\nthat learns the cross-task guidance on the source domain with the final network\nlayers, and use it on the target domain. We evaluate our methods on surface\nnormal estimation on two pairs of datasets (indoor scenes and faces) with two\nkinds of anchor tasks (semantic segmentation and facial landmarks). We show\nthat blindly applying domain adaptation or training the auxiliary task on only\none domain may hurt performance, while using anchor tasks on both domains is\nbetter behaved. Our \\freeze technique outperforms competing approaches,\nreaching performance in facial images on par with a recently popular surface\nnormal estimation method using shape from shading domain knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:59:18 GMT"}, {"version": "v2", "created": "Mon, 6 Jan 2020 18:58:32 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 01:46:18 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Li", "Zhizhong", ""], ["Luo", "Linjie", ""], ["Tulyakov", "Sergey", ""], ["Dai", "Qieyun", ""], ["Hoiem", "Derek", ""]]}, {"id": "1908.06081", "submitter": "Michael Thrun PhD", "authors": "Michael C. Thrun, Tino Gehlert, Alfred Ultsch", "title": "Analyzing the Fine Structure of Distributions", "comments": "66 pages, 81 figures, accepted in PLOS ONE", "journal-ref": null, "doi": "10.1371/journal.pone.0238835", "report-no": "PONE-D-19-19081R4", "categories": "stat.AP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One aim of data mining is the identification of interesting structures in\ndata. For better analytical results, the basic properties of an empirical\ndistribution, such as skewness and eventual clipping, i.e. hard limits in value\nranges, need to be assessed. Of particular interest is the question of whether\nthe data originate from one process or contain subsets related to different\nstates of the data producing process. Data visualization tools should deliver a\nclear picture of the univariate probability density distribution (PDF) for each\nfeature. Visualization tools for PDFs typically use kernel density estimates\nand include both the classical histogram, as well as the modern tools like\nridgeline plots, bean plots and violin plots. If density estimation parameters\nremain in a default setting, conventional methods pose several problems when\nvisualizing the PDF of uniform, multimodal, skewed distributions and\ndistributions with clipped data, For that reason, a new visualization tool\ncalled the mirrored density plot (MD plot), which is specifically designed to\ndiscover interesting structures in continuous features, is proposed. The MD\nplot does not require adjusting any parameters of density estimation, which is\nwhat may make the use of this plot compelling particularly to non-experts. The\nvisualization tools in question are evaluated against statistical tests with\nregard to typical challenges of explorative distribution analysis. The results\nof the evaluation are presented using bimodal Gaussian, skewed distributions\nand several features with already published PDFs. In an exploratory data\nanalysis of 12 features describing quarterly financial statements, when\nstatistical testing poses a great difficulty, only the MD plots can identify\nthe structure of their PDFs. In sum, the MD plot outperforms the above\nmentioned methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 19:24:32 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2020 07:01:09 GMT"}, {"version": "v3", "created": "Sat, 5 Sep 2020 08:59:10 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Thrun", "Michael C.", ""], ["Gehlert", "Tino", ""], ["Ultsch", "Alfred", ""]]}, {"id": "1908.06112", "submitter": "Yisen Wang", "authors": "Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, James Bailey", "title": "Symmetric Cross Entropy for Robust Learning with Noisy Labels", "comments": "ICCV2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training accurate deep neural networks (DNNs) in the presence of noisy labels\nis an important and challenging task. Though a number of approaches have been\nproposed for learning with noisy labels, many open issues remain. In this\npaper, we show that DNN learning with Cross Entropy (CE) exhibits overfitting\nto noisy labels on some classes (\"easy\" classes), but more surprisingly, it\nalso suffers from significant under learning on some other classes (\"hard\"\nclasses). Intuitively, CE requires an extra term to facilitate learning of hard\nclasses, and more importantly, this term should be noise tolerant, so as to\navoid overfitting to noisy labels. Inspired by the symmetric KL-divergence, we\npropose the approach of \\textbf{Symmetric cross entropy Learning} (SL),\nboosting CE symmetrically with a noise robust counterpart Reverse Cross Entropy\n(RCE). Our proposed SL approach simultaneously addresses both the under\nlearning and overfitting problem of CE in the presence of noisy labels. We\nprovide a theoretical analysis of SL and also empirically show, on a range of\nbenchmark and real-world datasets, that SL outperforms state-of-the-art\nmethods. We also show that SL can be easily incorporated into existing methods\nin order to further enhance their performance.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 18:01:32 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Wang", "Yisen", ""], ["Ma", "Xingjun", ""], ["Chen", "Zaiyi", ""], ["Luo", "Yuan", ""], ["Yi", "Jinfeng", ""], ["Bailey", "James", ""]]}, {"id": "1908.06130", "submitter": "Matthew Brennan", "authors": "Matthew Brennan, Guy Bresler", "title": "Average-Case Lower Bounds for Learning Sparse Mixtures, Robust\n  Estimation and Semirandom Adversaries", "comments": "Preliminary version (subsumed by expanded version at\n  arXiv:2005.08099), 65 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.LG math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops several average-case reduction techniques to show new\nhardness results for three central high-dimensional statistics problems,\nimplying a statistical-computational gap induced by robustness, a\ndetection-recovery gap and a universality principle for these gaps. A main\nfeature of our approach is to map to these problems via a common intermediate\nproblem that we introduce, which we call Imbalanced Sparse Gaussian Mixtures.\nWe assume the planted clique conjecture for a version of the planted clique\nproblem where the position of the planted clique is mildly constrained, and\nfrom this obtain the following computational lower bounds: (1) a $k$-to-$k^2$\nstatistical-computational gap for robust sparse mean estimation, providing the\nfirst average-case evidence for a conjecture of Li (2017) and Balakrishnan et\nal. (2017); (2) a tight lower bound for semirandom planted dense subgraph,\nwhich shows that a semirandom adversary shifts the detection threshold in\nplanted dense subgraph to the conjectured recovery threshold; and (3) a\nuniversality principle for $k$-to-$k^2$ gaps in a broad class of sparse mixture\nproblems that includes many natural formulations such as the spiked covariance\nmodel.\n  Our main approach is to introduce several average-case techniques to produce\nstructured and Gaussianized versions of an input graph problem, and then to\nrotate these high-dimensional Gaussians by matrices carefully constructed from\nhyperplanes in $\\mathbb{F}_r^t$. For our universality result, we introduce a\nnew method to perform an algorithmic change of measure tailored to sparse\nmixtures. We also provide evidence that the mild promise in our variant of\nplanted clique does not change the complexity of the problem.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 22:14:09 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 01:20:43 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Brennan", "Matthew", ""], ["Bresler", "Guy", ""]]}, {"id": "1908.06134", "submitter": "Taku Yamagata", "authors": "Taku Yamagata, Ra\\'ul Santos-Rodr\\'iguez, Ryan McConville, Atis Elsts\n  (University of Bristol)", "title": "Online Feature Selection for Activity Recognition using Reinforcement\n  Learning with Multiple Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in both machine learning and Internet-of-Things have\nattracted attention to automatic Activity Recognition, where users wear a\ndevice with sensors and their outputs are mapped to a predefined set of\nactivities. However, few studies have considered the balance between wearable\npower consumption and activity recognition accuracy. This is particularly\nimportant when part of the computational load happens on the wearable device.\nIn this paper, we present a new methodology to perform feature selection on the\ndevice based on Reinforcement Learning (RL) to find the optimum balance between\npower consumption and accuracy. To accelerate the learning speed, we extend the\nRL algorithm to address multiple sources of feedback, and use them to tailor\nthe policy in conjunction with estimating the feedback accuracy. We evaluated\nour system on the SPHERE challenge dataset, a publicly available research\ndataset. The results show that our proposed method achieves a good trade-off\nbetween wearable power consumption and activity recognition accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 19:20:31 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Yamagata", "Taku", "", "University of Bristol"], ["Santos-Rodr\u00edguez", "Ra\u00fal", "", "University of Bristol"], ["McConville", "Ryan", "", "University of Bristol"], ["Elsts", "Atis", "", "University of Bristol"]]}, {"id": "1908.06168", "submitter": "Meenakshi Khosla", "authors": "Meenakshi Khosla, Keith Jamison, Amy Kuceyeski and Mert R. Sabuncu", "title": "Detecting abnormalities in resting-state dynamics: An unsupervised\n  learning approach", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resting-state functional MRI (rs-fMRI) is a rich imaging modality that\ncaptures spontaneous brain activity patterns, revealing clues about the\nconnectomic organization of the human brain. While many rs-fMRI studies have\nfocused on static measures of functional connectivity, there has been a recent\nsurge in examining the temporal patterns in these data. In this paper, we\nexplore two strategies for capturing the normal variability in resting-state\nactivity across a healthy population: (a) an autoencoder approach on the\nrs-fMRI sequence, and (b) a next frame prediction strategy. We show that both\napproaches can learn useful representations of rs-fMRI data and demonstrate\ntheir novel application for abnormality detection in the context of\ndiscriminating autism patients from healthy controls.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:03:08 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Khosla", "Meenakshi", ""], ["Jamison", "Keith", ""], ["Kuceyeski", "Amy", ""], ["Sabuncu", "Mert R.", ""]]}, {"id": "1908.06169", "submitter": "Dimitrios Rafailidis Dr", "authors": "Dimitrios Rafailidis", "title": "Cross-Domain Collaborative Filtering via Translation-based Learning", "comments": "arXiv admin note: text overlap with arXiv:1907.01645", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of social media platforms and e-commerce sites,\nseveral cross-domain collaborative filtering strategies have been recently\nintroduced to transfer the knowledge of user preferences across domains. The\nmain challenge of cross-domain recommendation is to weigh and learn users'\ndifferent behaviors in multiple domains. In this paper, we propose a\nCross-Domain collaborative filtering model following a Translation-based\nstrategy, namely CDT. In our model, we learn the embedding space with\ntranslation vectors and capture high-order feature interactions in users'\nmultiple preferences across domains. In doing so, we efficiently compute the\ntransitivity between feature latent embeddings, that is if feature pairs have\nhigh interaction weights in the latent space, then feature embeddings with no\nobserved interactions across the domains will be closely related as well. We\nformulate our objective function as a ranking problem in factorization machines\nand learn the model's parameters via gradient descent. In addition, to better\ncapture the non-linearity in user preferences across domains we extend the\nproposed CDT model by using a deep learning strategy, namely DeepCDT. Our\nexperiments on six publicly available cross-domain tasks demonstrate the\neffectiveness of the proposed models, outperforming other state-of-the-art\ncross-domain strategies.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 15:23:35 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Rafailidis", "Dimitrios", ""]]}, {"id": "1908.06177", "submitter": "Koustuv Sinha", "authors": "Koustuv Sinha, Shagun Sodhani, Jin Dong, Joelle Pineau, William L.\n  Hamilton", "title": "CLUTRR: A Diagnostic Benchmark for Inductive Reasoning from Text", "comments": "Accepted at EMNLP 2019, 9 page content + Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.LO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent success of natural language understanding (NLU) systems has been\ntroubled by results highlighting the failure of these models to generalize in a\nsystematic and robust way. In this work, we introduce a diagnostic benchmark\nsuite, named CLUTRR, to clarify some key issues related to the robustness and\nsystematicity of NLU systems. Motivated by classic work on inductive logic\nprogramming, CLUTRR requires that an NLU system infer kinship relations between\ncharacters in short stories. Successful performance on this task requires both\nextracting relationships between entities, as well as inferring the logical\nrules governing these relationships. CLUTRR allows us to precisely measure a\nmodel's ability for systematic generalization by evaluating on held-out\ncombinations of logical rules, and it allows us to evaluate a model's\nrobustness by adding curated noise facts. Our empirical results highlight a\nsubstantial performance gap between state-of-the-art NLU models (e.g., BERT and\nMAC) and a graph neural network model that works directly with symbolic\ninputs---with the graph-based model exhibiting both stronger generalization and\ngreater robustness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:12:15 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 00:14:56 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Sinha", "Koustuv", ""], ["Sodhani", "Shagun", ""], ["Dong", "Jin", ""], ["Pineau", "Joelle", ""], ["Hamilton", "William L.", ""]]}, {"id": "1908.06178", "submitter": "Sarthak Dash", "authors": "Sarthak Dash, Alfio Gliozzo", "title": "Distributional Negative Sampling for Knowledge Base Completion", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art approaches for Knowledge Base Completion (KBC) exploit deep\nneural networks trained with both false and true assertions: positive\nassertions are explicitly taken from the knowledge base, whereas negative ones\nare generated by random sampling of entities. In this paper, we argue that\nrandom sampling is not a good training strategy since it is highly likely to\ngenerate a huge number of nonsensical assertions during training, which does\nnot provide relevant training signal to the system. Hence, it slows down the\nlearning process and decreases accuracy. To address this issue, we propose an\nalternative approach called Distributional Negative Sampling that generates\nmeaningful negative examples which are highly likely to be false. Our approach\nachieves a significant improvement in Mean Reciprocal Rank values amongst two\ndifferent KBC algorithms in three standard academic benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:12:37 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Dash", "Sarthak", ""], ["Gliozzo", "Alfio", ""]]}, {"id": "1908.06210", "submitter": "Fuwei Li", "authors": "Fuwei Li, Lifeng Lai, and Shuguang Cui", "title": "On the Adversarial Robustness of Subspace Learning", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2020.2974676", "report-no": null, "categories": "eess.SP cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the adversarial robustness of subspace learning\nproblems. Different from the assumptions made in existing work on robust\nsubspace learning where data samples are contaminated by gross sparse outliers\nor small dense noises, we consider a more powerful adversary who can first\nobserve the data matrix and then intentionally modify the whole data matrix. We\nfirst characterize the optimal rank-one attack strategy that maximizes the\nsubspace distance between the subspace learned from the original data matrix\nand that learned from the modified data matrix. We then generalize the study to\nthe scenario without the rank constraint and characterize the corresponding\noptimal attack strategy. Our analysis shows that the optimal strategies depend\non the singular values of the original data matrix and the adversary's energy\nbudget. Finally, we provide numerical experiments and practical applications to\ndemonstrate the efficiency of the attack strategies.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 00:20:42 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Li", "Fuwei", ""], ["Lai", "Lifeng", ""], ["Cui", "Shuguang", ""]]}, {"id": "1908.06214", "submitter": "Matthew Sotoudeh", "authors": "Matthew Sotoudeh and Aditya V. Thakur", "title": "Computing Linear Restrictions of Neural Networks", "comments": "Conference paper at the Conference on Neural Information Processing\n  Systems (NeurIPS) 2019. Code is available at\n  https://github.com/95616ARG/SyReNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A linear restriction of a function is the same function with its domain\nrestricted to points on a given line. This paper addresses the problem of\ncomputing a succinct representation for a linear restriction of a\npiecewise-linear neural network. This primitive, which we call ExactLine,\nallows us to exactly characterize the result of applying the network to all of\nthe infinitely many points on a line. In particular, ExactLine computes a\npartitioning of the given input line segment such that the network is affine on\neach partition. We present an efficient algorithm for computing ExactLine for\nnetworks that use ReLU, MaxPool, batch normalization, fully-connected,\nconvolutional, and other layers, along with several applications. First, we\nshow how to exactly determine decision boundaries of an ACAS Xu neural network,\nproviding significantly improved confidence in the results compared to prior\nwork that sampled finitely many points in the input space. Next, we demonstrate\nhow to exactly compute integrated gradients, which are commonly used for neural\nnetwork attributions, allowing us to show that the prior heuristic-based\nmethods had relative errors of 25-45% and show that a better sampling method\ncan achieve higher accuracy with less computation. Finally, we use ExactLine to\nempirically falsify the core assumption behind a well-known hypothesis about\nadversarial examples, and in the process identify interesting properties of\nadversarially-trained networks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 00:42:34 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 01:09:15 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Sotoudeh", "Matthew", ""], ["Thakur", "Aditya V.", ""]]}, {"id": "1908.06223", "submitter": "Aditya Thakur", "authors": "Matthew Sotoudeh and Aditya V. Thakur", "title": "A Symbolic Neural Network Representation and its Application to\n  Understanding, Verifying, and Patching Networks", "comments": "Code is available at https://github.com/95616ARG/SyReNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis and manipulation of trained neural networks is a challenging and\nimportant problem. We propose a symbolic representation for piecewise-linear\nneural networks and discuss its efficient computation. With this\nrepresentation, one can translate the problem of analyzing a complex neural\nnetwork into that of analyzing a finite set of affine functions. We demonstrate\nthe use of this representation for three applications. First, we apply the\nsymbolic representation to computing weakest preconditions on network inputs,\nwhich we use to exactly visualize the advisories made by a network meant to\noperate an aircraft collision avoidance system. Second, we use the symbolic\nrepresentation to compute strongest postconditions on the network outputs,\nwhich we use to perform bounded model checking on standard neural network\ncontrollers. Finally, we show how the symbolic representation can be combined\nwith a new form of neural network to perform patching; i.e., correct\nuser-specified behavior of the network.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 01:48:50 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 03:22:57 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Sotoudeh", "Matthew", ""], ["Thakur", "Aditya V.", ""]]}, {"id": "1908.06256", "submitter": "Junwei Pan", "authors": "Yizhi Mao, Miao Chen, Abhinav Wagle, Junwei Pan, Michael Natkovich,\n  Don Matheson", "title": "A Batched Multi-Armed Bandit Approach to News Headline Testing", "comments": "IEEE BigData, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing news headlines is important for publishers and media sites. A\ncompelling headline will increase readership, user engagement and social\nshares. At Yahoo Front Page, headline testing is carried out using a\ntest-rollout strategy: we first allocate equal proportion of the traffic to\neach headline variation for a defined testing period, and then shift all future\ntraffic to the best-performing variation. In this paper, we introduce a\nmulti-armed bandit (MAB) approach with batched Thompson Sampling (bTS) to\ndynamically test headlines for news articles. This method is able to gradually\nallocate traffic towards optimal headlines while testing. We evaluate the bTS\nmethod based on empirical impressions/clicks data and simulated user responses.\nThe result shows that the bTS method is robust, converges accurately and\nquickly to the optimal headline, and outperforms the test-rollout strategy by\n3.69% in terms of clicks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 07:39:19 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 05:34:26 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Mao", "Yizhi", ""], ["Chen", "Miao", ""], ["Wagle", "Abhinav", ""], ["Pan", "Junwei", ""], ["Natkovich", "Michael", ""], ["Matheson", "Don", ""]]}, {"id": "1908.06278", "submitter": "Xiaoyu Zhang", "authors": "Xiaoyu Zhang, Jingqing Zhang, Kai Sun, Xian Yang, Chengliang Dai, Yike\n  Guo", "title": "Integrated Multi-omics Analysis Using Variational Autoencoders:\n  Application to Pan-cancer Classification", "comments": "7 pages, 4 figures", "journal-ref": "2019 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM)", "doi": "10.1109/BIBM47256.2019.8983228", "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different aspects of a clinical sample can be revealed by multiple types of\nomics data. Integrated analysis of multi-omics data provides a comprehensive\nview of patients, which has the potential to facilitate more accurate clinical\ndecision making. However, omics data are normally high dimensional with large\nnumber of molecular features and relatively small number of available samples\nwith clinical labels. The \"dimensionality curse\" makes it challenging to train\na machine learning model using high dimensional omics data like DNA methylation\nand gene expression profiles. Here we propose an end-to-end deep learning model\ncalled OmiVAE to extract low dimensional features and classify samples from\nmulti-omics data. OmiVAE combines the basic structure of variational\nautoencoders with a classification network to achieve task-oriented feature\nextraction and multi-class classification. The training procedure of OmiVAE is\ncomprised of an unsupervised phase without the classifier and a supervised\nphase with the classifier. During the unsupervised phase, a hierarchical\ncluster structure of samples can be automatically formed without the need for\nlabels. And in the supervised phase, OmiVAE achieved an average classification\naccuracy of 97.49% after 10-fold cross-validation among 33 tumour types and\nnormal samples, which shows better performance than other existing methods. The\nOmiVAE model learned from multi-omics data outperformed that using only one\ntype of omics data, which indicates that the complementary information from\ndifferent omics datatypes provides useful insights for biomedical tasks like\ncancer classification.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 09:48:06 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Zhang", "Xiaoyu", ""], ["Zhang", "Jingqing", ""], ["Sun", "Kai", ""], ["Yang", "Xian", ""], ["Dai", "Chengliang", ""], ["Guo", "Yike", ""]]}, {"id": "1908.06281", "submitter": "Jiadong Lin", "authors": "Jiadong Lin, Chuanbiao Song, Kun He, Liwei Wang, John E. Hopcroft", "title": "Nesterov Accelerated Gradient and Scale Invariance for Adversarial\n  Attacks", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are vulnerable to adversarial examples crafted by\napplying human-imperceptible perturbations on benign inputs. However, under the\nblack-box setting, most existing adversaries often have a poor transferability\nto attack other defense models. In this work, from the perspective of regarding\nthe adversarial example generation as an optimization process, we propose two\nnew methods to improve the transferability of adversarial examples, namely\nNesterov Iterative Fast Gradient Sign Method (NI-FGSM) and Scale-Invariant\nattack Method (SIM). NI-FGSM aims to adapt Nesterov accelerated gradient into\nthe iterative attacks so as to effectively look ahead and improve the\ntransferability of adversarial examples. While SIM is based on our discovery on\nthe scale-invariant property of deep learning models, for which we leverage to\noptimize the adversarial perturbations over the scale copies of the input\nimages so as to avoid \"overfitting\" on the white-box model being attacked and\ngenerate more transferable adversarial examples. NI-FGSM and SIM can be\nnaturally integrated to build a robust gradient-based attack to generate more\ntransferable adversarial examples against the defense models. Empirical results\non ImageNet dataset demonstrate that our attack methods exhibit higher\ntransferability and achieve higher attack success rates than state-of-the-art\ngradient-based attacks.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 10:03:05 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 15:28:34 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 09:03:02 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 13:47:15 GMT"}, {"version": "v5", "created": "Mon, 3 Feb 2020 02:58:31 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Lin", "Jiadong", ""], ["Song", "Chuanbiao", ""], ["He", "Kun", ""], ["Wang", "Liwei", ""], ["Hopcroft", "John E.", ""]]}, {"id": "1908.06309", "submitter": "Felix Neutatz", "authors": "Felix Neutatz and Mohammad Mahdavi and Ziawasch Abedjan", "title": "ED2: Two-stage Active Learning for Error Detection -- Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional error detection approaches require user-defined parameters and\nrules. Thus, the user has to know both the error detection system and the data.\nHowever, we can also formulate error detection as a semi-supervised\nclassification problem that only requires domain expertise. The challenges for\nsuch an approach are twofold: (1) to represent the data in a way that enables a\nclassification model to identify various kinds of data errors, and (2) to pick\nthe most promising data values for learning. In this paper, we address these\nchallenges with ED2, our new example-driven error detection method. First, we\npresent a new two-dimensional multi-classifier sampling strategy for active\nlearning. Second, we propose novel multi-column features. The combined\napplication of these techniques provides fast convergence of the classification\ntask with high detection accuracy. On several real-world datasets, ED2\nrequires, on average, less than 1% labels to outperform existing error\ndetection approaches. This report extends the peer-reviewed paper \"ED2: A Case\nfor Active Learning in Error Detection\". All source code related to this\nproject is available on GitHub.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 15:13:12 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Neutatz", "Felix", ""], ["Mahdavi", "Mohammad", ""], ["Abedjan", "Ziawasch", ""]]}, {"id": "1908.06315", "submitter": "Laurent El Ghaoui", "authors": "Laurent El Ghaoui and Fangda Gu and Bertrand Travacca and Armin Askari\n  and Alicia Y. Tsai", "title": "Implicit Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit deep learning prediction rules generalize the recursive rules of\nfeedforward neural networks. Such rules are based on the solution of a\nfixed-point equation involving a single vector of hidden features, which is\nthus only implicitly defined. The implicit framework greatly simplifies the\nnotation of deep learning, and opens up many new possibilities, in terms of\nnovel architectures and algorithms, robustness analysis and design,\ninterpretability, sparsity, and network architecture optimization.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 15:36:37 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 18:55:41 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 17:35:06 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2020 22:10:43 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ghaoui", "Laurent El", ""], ["Gu", "Fangda", ""], ["Travacca", "Bertrand", ""], ["Askari", "Armin", ""], ["Tsai", "Alicia Y.", ""]]}, {"id": "1908.06319", "submitter": "Gagan Sidhu", "authors": "Gagan Sidhu", "title": "Locally Linear Embedding and fMRI feature selection in psychiatric\n  classification", "comments": "Main article is 10 pages. Supplementary Information is 15 pages, and\n  includes figures/results for six additional datasets, w/ performance plots\n  (as a function of dimensionality 'd'), proportion(s) of brain regions defined\n  by the respective atlases, subject ID partitioning for all eleven datasets.\n  Statistical Volumes and GraphVizModel are included in 8_statmaps.rar and\n  9_graphviz_model.rar", "journal-ref": "IEEE Journal of Translational Engineering in Health & Medicine\n  7:10, 2019", "doi": "10.1109/JTEHM.2019.2936348 10.21227/zkkm-es92", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background:\n  Functional magnetic resonance imaging (fMRI) provides non-invasive measures\nof neuronal activity using an endogenous Blood Oxygenation-Level Dependent\n(BOLD) contrast. This article introduces a nonlinear dimensionality reduction\n(Locally Linear Embedding) to extract informative measures of the underlying\nneuronal activity from BOLD time-series. The method is validated using the\nLeave-One-Out-Cross-Validation (LOOCV) accuracy of classifying psychiatric\ndiagnoses using resting-state and task-related fMRI.\n  Methods:\n  Locally Linear Embedding of BOLD time-series (into each voxel's respective\ntensor) was used to optimise feature selection. This uses Gau\\ss' Principle of\nLeast Constraint to conserve quantities over both space and time. This\nconservation was assessed using LOOCV to greedily select time points in an\nincremental fashion on training data that was categorised in terms of\npsychiatric diagnoses.\n  Findings:\n  The embedded fMRI gave highly diagnostic performances (> 80%) on eleven\npublicly-available datasets containing healthy controls and patients with\neither Schizophrenia, Attention-Deficit Hyperactivity Disorder (ADHD), or\nAutism Spectrum Disorder (ASD). Furthermore, unlike the original fMRI data\nbefore or after using Principal Component Analysis (PCA) for artefact\nreduction, the embedded fMRI furnished significantly better than chance\nclassification (defined as the majority class proportion) on ten of eleven\ndatasets\n  Interpretation:\n  Locally Linear Embedding appears to be a useful feature extraction procedure\nthat retains important information about patterns of brain activity\ndistinguishing among psychiatric cohorts.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 17:02:17 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 20:11:25 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 14:45:08 GMT"}, {"version": "v4", "created": "Fri, 23 Aug 2019 14:11:26 GMT"}, {"version": "v5", "created": "Wed, 4 Sep 2019 23:15:36 GMT"}, {"version": "v6", "created": "Fri, 6 Sep 2019 16:47:27 GMT"}, {"version": "v7", "created": "Mon, 23 Sep 2019 18:52:48 GMT"}, {"version": "v8", "created": "Thu, 26 Sep 2019 01:17:34 GMT"}, {"version": "v9", "created": "Thu, 7 Nov 2019 04:06:49 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Sidhu", "Gagan", ""]]}, {"id": "1908.06337", "submitter": "Bilwaj Gaonkar", "authors": "Bilwaj Gaonkar, Joel Beckett, Mark Attiah, Christine Ahn, Matthew\n  Edwards, Bayard Wilson, Azim Laiwalla, Banafsheh Salehi, Bryan Yoo, Alex Bui,\n  Luke Macyszyn", "title": "EigenRank by Committee: A Data Subset Selection and Failure Prediction\n  paradigm for Robust Deep Learning based Medical Image Segmentation", "comments": null, "journal-ref": "Medical Image Analysis, Volume 67, 2021, Medical Image Analysis,\n  Volume 67,2021,101834,ISSN 1361-8415,", "doi": "10.1016/j.media.2020.101834", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Translation of fully automated deep learning based medical image segmentation\ntechnologies to clinical workflows face two main algorithmic challenges. The\nfirst, is the collection and archival of large quantities of manually annotated\nground truth data for both training and validation. The second is the relative\ninability of the majority of deep learning based segmentation techniques to\nalert physicians to a likely segmentation failure. Here we propose a novel\nalgorithm, named `Eigenrank' which addresses both of these challenges.\nEigenrank can select for manual labeling, a subset of medical images from a\nlarge database, such that a U-Net trained on this subset is superior to one\ntrained on a randomly selected subset of the same size. Eigenrank can also be\nused to pick out, cases in a large database, where deep learning segmentation\nwill fail. We present our algorithm, followed by results and a discussion of\nhow Eigenrank exploits the Von Neumann information to perform both data subset\nselection and failure prediction for medical image segmentation using deep\nlearning.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 20:16:07 GMT"}, {"version": "v2", "created": "Mon, 18 Jan 2021 19:40:32 GMT"}], "update_date": "2021-01-20", "authors_parsed": [["Gaonkar", "Bilwaj", ""], ["Beckett", "Joel", ""], ["Attiah", "Mark", ""], ["Ahn", "Christine", ""], ["Edwards", "Matthew", ""], ["Wilson", "Bayard", ""], ["Laiwalla", "Azim", ""], ["Salehi", "Banafsheh", ""], ["Yoo", "Bryan", ""], ["Bui", "Alex", ""], ["Macyszyn", "Luke", ""]]}, {"id": "1908.06349", "submitter": "Creighton Heaukulani", "authors": "Creighton Heaukulani, Daniel M. Roy", "title": "Black-box constructions for exchangeable sequences of random multisets", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop constructions for exchangeable sequences of point processes that\nare rendered conditionally-i.i.d. negative binomial processes by a (possibly\nunknown) random measure called the base measure. Negative binomial processes\nare useful in Bayesian nonparametrics as models for random multisets, and in\napplications we are often interested in cases when the base measure itself is\ndifficult to construct (for example when it has countably infinite support).\nWhile a finitary construction for an important case (corresponding to a beta\nprocess base measure) has appeared in the literature, our constructions\ngeneralize to any random base measure, requiring only an exchangeable sequence\nof Bernoulli processes rendered conditionally-i.i.d. by the same underlying\nrandom base measure. Because finitary constructions for such Bernoulli\nprocesses are known for several different classes of random base\nmeasures--including generalizations of the beta process and hierarchies\nthereof--our results immediately provide constructions for negative binomial\nprocesses with a random base measure from any member of these classes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 23:35:36 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Heaukulani", "Creighton", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1908.06353", "submitter": "Yuh-Shyang Wang", "authors": "Yuh-Shyang Wang, Tsui-Wei Weng, Luca Daniel", "title": "Verification of Neural Network Control Policy Under Persistent\n  Adversarial Perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are known to be fragile to small adversarial\nperturbations. This issue becomes more critical when a neural network is\ninterconnected with a physical system in a closed loop. In this paper, we show\nhow to combine recent works on neural network certification tools (which are\nmainly used in static settings such as image classification) with robust\ncontrol theory to certify a neural network policy in a control loop.\nSpecifically, we give a sufficient condition and an algorithm to ensure that\nthe closed loop state and control constraints are satisfied when the persistent\nadversarial perturbation is l-infinity norm bounded. Our method is based on\nfinding a positively invariant set of the closed loop dynamical system, and\nthus we do not require the differentiability or the continuity of the neural\nnetwork policy. Along with the verification result, we also develop an\neffective attack strategy for neural network control systems that outperforms\nexhaustive Monte-Carlo search significantly. We show that our certification\nalgorithm works well on learned models and achieves 5 times better result than\nthe traditional Lipschitz-based method to certify the robustness of a neural\nnetwork policy on a cart pole control problem.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 00:23:21 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Wang", "Yuh-Shyang", ""], ["Weng", "Tsui-Wei", ""], ["Daniel", "Luca", ""]]}, {"id": "1908.06369", "submitter": "Rodrigo de Lamare", "authors": "Y. Yu, L. Lu, Z. Zheng, W. Wang, Y. Zakharov and R. C. de Lamare", "title": "Robust DCD-Based Recursive Adaptive Algorithms", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dichotomous coordinate descent (DCD) algorithm has been successfully used\nfor significant reduction in the complexity of recursive least squares (RLS)\nalgorithms. In this work, we generalize the application of the DCD algorithm to\nRLS adaptive filtering in impulsive noise scenarios and derive a unified update\nformula. By employing different robust strategies against impulsive noise, we\ndevelop novel computationally efficient DCD-based robust recursive algorithms.\nFurthermore, to equip the proposed algorithms with the ability to track abrupt\nchanges in unknown systems, a simple variable forgetting factor mechanism is\nalso developed. Simulation results for channel identification scenarios in\nimpulsive noise demonstrate the effectiveness of the proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 03:41:25 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Yu", "Y.", ""], ["Lu", "L.", ""], ["Zheng", "Z.", ""], ["Wang", "W.", ""], ["Zakharov", "Y.", ""], ["de Lamare", "R. C.", ""]]}, {"id": "1908.06376", "submitter": "Denys Matthies", "authors": "Shamane Siriwardhana, Rivindu Weerasakera, Denys J.C. Matthies,\n  Suranga Nanayakkara", "title": "VUSFA:Variational Universal Successor Features Approximator to Improve\n  Transfer DRL for Target Driven Visual Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show how novel transfer reinforcement learning techniques\ncan be applied to the complex task of target driven navigation using the\nphotorealistic AI2THOR simulator. Specifically, we build on the concept of\nUniversal Successor Features with an A3C agent. We introduce the novel\narchitectural contribution of a Successor Feature Dependant Policy (SFDP) and\nadopt the concept of Variational Information Bottlenecks to achieve state of\nthe art performance. VUSFA, our final architecture, is a straightforward\napproach that can be implemented using our open source repository. Our approach\nis generalizable, showed greater stability in training, and outperformed recent\napproaches in terms of transfer learning ability.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 04:24:08 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Siriwardhana", "Shamane", ""], ["Weerasakera", "Rivindu", ""], ["Matthies", "Denys J. C.", ""], ["Nanayakkara", "Suranga", ""]]}, {"id": "1908.06395", "submitter": "Hao Jin", "authors": "Hao Jin, Dachao Lin, Zhihua Zhang", "title": "Towards Better Generalization: BP-SVRG in Training Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variance-reduced gradient (SVRG) is a classical optimization\nmethod. Although it is theoretically proved to have better convergence\nperformance than stochastic gradient descent (SGD), the generalization\nperformance of SVRG remains open. In this paper we investigate the effects of\nsome training techniques, mini-batching and learning rate decay, on the\ngeneralization performance of SVRG, and verify the generalization performance\nof Batch-SVRG (B-SVRG). In terms of the relationship between optimization and\ngeneralization, we believe that the average norm of gradients on each training\nsample as well as the norm of average gradient indicate how flat the landscape\nis and how well the model generalizes. Based on empirical observations of such\nmetrics, we perform a sign switch on B-SVRG and derive a practical algorithm,\nBatchPlus-SVRG (BP-SVRG), which is numerically shown to enjoy better\ngeneralization performance than B-SVRG, even SGD in some scenarios of deep\nneural networks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 08:12:03 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Jin", "Hao", ""], ["Lin", "Dachao", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1908.06416", "submitter": "Rohan Ghosh", "authors": "Rohan Ghosh, Anupam K. Gupta, Mehul Motani", "title": "Investigating Convolutional Neural Networks using Spatial Orderness", "comments": "Presented at BMVC 2019: Workshop on Interpretable and Explainable\n  Machine Vision, Cardiff, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNN) have been pivotal to the success of many\nstate-of-the-art classification problems, in a wide variety of domains (for\ne.g. vision, speech, graphs and medical imaging). A commonality within those\ndomains is the presence of hierarchical, spatially agglomerative\nlocal-to-global interactions within the data. For two-dimensional images, such\ninteractions may induce an a priori relationship between the pixel data and the\nunderlying spatial ordering of the pixels. For instance in natural images,\nneighboring pixels are more likely contain similar values than non-neighboring\npixels which are further apart. To that end, we propose a statistical metric\ncalled spatial orderness, which quantifies the extent to which the input data\n(2D) obeys the underlying spatial ordering at various scales. In our\nexperiments, we mainly find that adding convolutional layers to a CNN could be\ncounterproductive for data bereft of spatial order at higher scales. We also\nobserve, quite counter-intuitively, that the spatial orderness of CNN feature\nmaps show a synchronized increase during the intial stages of training, and\nvalidation performance only improves after spatial orderness of feature maps\nstart decreasing. Lastly, we present a theoretical analysis (and empirical\nvalidation) of the spatial orderness of network weights, where we find that\nusing smaller kernel sizes leads to kernels of greater spatial orderness and\nvice-versa.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 10:05:24 GMT"}, {"version": "v2", "created": "Fri, 29 Nov 2019 16:35:10 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Ghosh", "Rohan", ""], ["Gupta", "Anupam K.", ""], ["Motani", "Mehul", ""]]}, {"id": "1908.06438", "submitter": "Angelo Mele", "authors": "Angelo Mele and Lingxin Hao and Joshua Cape and Carey E. Priebe", "title": "Spectral inference for large Stochastic Blockmodels with nodal\n  covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of network analysis, it is important to distinguish\nbetween observed and unobserved factors affecting network structure. To this\nend, we develop spectral estimators for both unobserved blocks and the effect\nof covariates in stochastic blockmodels. On the theoretical side, we establish\nasymptotic normality of our estimators for the subsequent purpose of performing\ninference. On the applied side, we show that computing our estimator is much\nfaster than standard variational expectation--maximization algorithms and\nscales well for large networks. Monte Carlo experiments suggest that the\nestimator performs well under different data generating processes. Our\napplication to Facebook data shows evidence of homophily in gender, role and\ncampus-residence, while allowing us to discover unobserved communities. The\nresults in this paper provide a foundation for spectral estimation of the\neffect of observed covariates as well as unobserved latent community structure\non the probability of link formation in networks.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 13:03:13 GMT"}, {"version": "v2", "created": "Fri, 12 Mar 2021 11:26:08 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Mele", "Angelo", ""], ["Hao", "Lingxin", ""], ["Cape", "Joshua", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1908.06475", "submitter": "John Klein", "authors": "Mahmoud Albardan, John Klein and Olivier Colot", "title": "SPOCC: Scalable POssibilistic Classifier Combination -- toward robust\n  aggregation of classifiers", "comments": null, "journal-ref": null, "doi": "10.1016/j.eswa.2020.113332", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a problem in which each member of a group of learners is\ntrained separately to solve the same classification task. Each learner has\naccess to a training dataset (possibly with overlap across learners) but each\ntrained classifier can be evaluated on a validation dataset. We propose a new\napproach to aggregate the learner predictions in the possibility theory\nframework. For each classifier prediction, we build a possibility distribution\nassessing how likely the classifier prediction is correct using frequentist\nprobabilities estimated on the validation set. The possibility distributions\nare aggregated using an adaptive t-norm that can accommodate dependency and\npoor accuracy of the classifier predictions. We prove that the proposed\napproach possesses a number of desirable classifier combination robustness\nproperties.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 16:48:37 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2020 22:19:29 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Albardan", "Mahmoud", ""], ["Klein", "John", ""], ["Colot", "Olivier", ""]]}, {"id": "1908.06477", "submitter": "Yanzhao Wu", "authors": "Yanzhao Wu, Ling Liu, Juhyun Bae, Ka-Ho Chow, Arun Iyengar, Calton Pu,\n  Wenqi Wei, Lei Yu, Qi Zhang", "title": "Demystifying Learning Rate Policies for High Accuracy Training of Deep\n  Neural Networks", "comments": "To appear on IEEE Big Data 2019. LRBench\n  (https://github.com/git-disl/LRBench)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning Rate (LR) is an important hyper-parameter to tune for effective\ntraining of deep neural networks (DNNs). Even for the baseline of a constant\nlearning rate, it is non-trivial to choose a good constant value for training a\nDNN. Dynamic learning rates involve multi-step tuning of LR values at various\nstages of the training process and offer high accuracy and fast convergence.\nHowever, they are much harder to tune. In this paper, we present a\ncomprehensive study of 13 learning rate functions and their associated LR\npolicies by examining their range parameters, step parameters, and value update\nparameters. We propose a set of metrics for evaluating and selecting LR\npolicies, including the classification confidence, variance, cost, and\nrobustness, and implement them in LRBench, an LR benchmarking system. LRBench\ncan assist end-users and DNN developers to select good LR policies and avoid\nbad LR policies for training their DNNs. We tested LRBench on Caffe, an open\nsource deep learning framework, to showcase the tuning optimization of LR\npolicies. Evaluated through extensive experiments, we attempt to demystify the\ntuning of LR policies by identifying good LR policies with effective LR value\nranges and step sizes for LR update schedules.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 16:58:52 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 20:45:08 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Wu", "Yanzhao", ""], ["Liu", "Ling", ""], ["Bae", "Juhyun", ""], ["Chow", "Ka-Ho", ""], ["Iyengar", "Arun", ""], ["Pu", "Calton", ""], ["Wei", "Wenqi", ""], ["Yu", "Lei", ""], ["Zhang", "Qi", ""]]}, {"id": "1908.06486", "submitter": "Ronak Mehta", "authors": "Ronak Mehta, Jaewon Chung, Cencheng Shen, Ting Xu, Joshua T.\n  Vogelstein", "title": "Independence Testing for Multivariate Time Series", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Complex data structures such as time series are increasingly present in\nmodern data science problems. A fundamental question is whether two such\ntime-series are statistically dependent. Many current approaches make\nparametric assumptions on the random processes, only detect linear association,\nrequire multiple tests, or forfeit power in high-dimensional, nonlinear\nsettings. Estimating the distribution of any test statistic under the null is\nnon-trivial, as the permutation test is invalid. This work juxtaposes distance\ncorrelation (Dcorr) and multiscale graph correlation (MGC) from independence\ntesting literature and block permutation from time series analysis to address\nthese challenges. The proposed nonparametric procedure is valid and consistent,\nbuilding upon prior work by characterizing the geometry of the relationship,\nestimating the time lag at which dependence is maximized, avoiding the need for\nmultiple testing, and exhibiting superior power in high-dimensional, low sample\nsize, nonlinear settings. Neural connectivity is analyzed via fMRI data,\nrevealing linear dependence of signals within the visual network and default\nmode network, and nonlinear relationships in other networks. This work uncovers\na first-resort data analysis tool with open-source code available, directly\nimpacting a wide range of scientific disciplines.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 17:19:16 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 23:29:57 GMT"}, {"version": "v3", "created": "Fri, 15 May 2020 00:50:32 GMT"}], "update_date": "2020-05-18", "authors_parsed": [["Mehta", "Ronak", ""], ["Chung", "Jaewon", ""], ["Shen", "Cencheng", ""], ["Xu", "Ting", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1908.06487", "submitter": "M. Sohel Rahman", "authors": "Md. Adnan Arefeen, Sumaiya Tabassum Nimi, and M Sohel Rahman", "title": "Neural Network Based Undersampling Techniques", "comments": "8 pages in IEEE format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Class imbalance problem is commonly faced while developing machine learning\nmodels for real-life issues. Due to this problem, the fitted model tends to be\nbiased towards the majority class data, which leads to lower precision, recall,\nAUC, F1, G-mean score. Several researches have been done to tackle this\nproblem, most of which employed resampling, i.e. oversampling and undersampling\ntechniques to bring the required balance in the data. In this paper, we propose\nneural network based algorithms for undersampling. Then we resampled several\nclass imbalanced data using our algorithms and also some other popular\nresampling techniques. Afterwards we classified these undersampled data using\nsome common classifier. We found out that our resampling approaches outperform\nmost other resampling techniques in terms of both AUC, F1 and G-mean score.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 17:38:53 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Arefeen", "Md. Adnan", ""], ["Nimi", "Sumaiya Tabassum", ""], ["Rahman", "M Sohel", ""]]}, {"id": "1908.06498", "submitter": "Aliasghar Mortazi", "authors": "Aliasghar Mortazi, Naji Khosravan, Drew A. Torigian, Sila Kurugol,\n  Ulas Bagci", "title": "Weakly Supervised Segmentation by A Deep Geodesic Prior", "comments": "Accepted to Machine Learning in Medical Imaging (MLMI 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of the state-of-the-art image segmentation methods heavily\nrelies on the high-quality annotations, which are not easily affordable,\nparticularly for medical data. To alleviate this limitation, in this study, we\npropose a weakly supervised image segmentation method based on a deep geodesic\nprior. We hypothesize that integration of this prior information can reduce the\nadverse effects of weak labels in segmentation accuracy. Our proposed algorithm\nis based on a prior information, extracted from an auto-encoder, trained to map\nobjects geodesic maps to their corresponding binary maps. The obtained\ninformation is then used as an extra term in the loss function of the\nsegmentor. In order to show efficacy of the proposed strategy, we have\nexperimented segmentation of cardiac substructures with clean and two levels of\nnoisy labels (L1, L2). Our experiments showed that the proposed algorithm\nboosted the performance of baseline deep learning-based segmentation for both\nclean and noisy labels by 4.4%, 4.6%(L1), and 6.3%(L2) in dice score,\nrespectively. We also showed that the proposed method was more robust in the\npresence of high-level noise due to the existence of shape priors.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 18:43:44 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Mortazi", "Aliasghar", ""], ["Khosravan", "Naji", ""], ["Torigian", "Drew A.", ""], ["Kurugol", "Sila", ""], ["Bagci", "Ulas", ""]]}, {"id": "1908.06512", "submitter": "Harvineet Singh", "authors": "Moumita Sinha, Vishwa Vinay, Harvineet Singh", "title": "Modeling Time to Open of Emails with a Latent State for User Engagement\n  Level", "comments": "9 pages, 5 figures, WSDM'18, February 5-9, 2018, Marina Del Rey, CA,\n  USA, https://dl.acm.org/citation.cfm?id=3159683", "journal-ref": "Proceedings of the Eleventh ACM International Conference on Web\n  Search and Data Mining (WSDM 2018). ACM, New York, NY, USA, 531-539", "doi": "10.1145/3159652.3159683", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Email messages have been an important mode of communication, not only for\nwork, but also for social interactions and marketing. When messages have time\nsensitive information, it becomes relevant for the sender to know what is the\nexpected time within which the email will be read by the recipient. In this\npaper we use a survival analysis framework to predict the time to open an email\nonce it has been received. We use the Cox Proportional Hazards (CoxPH) model\nthat offers a way to combine various features that might affect the event of\nopening an email. As an extension, we also apply a mixture model (MM) approach\nto CoxPH that distinguishes between recipients, based on a latent state of how\nprone to opening the messages each individual is. We compare our approach with\nstandard classification and regression models. While the classification model\nprovides predictions on the likelihood of an email being opened, the regression\nmodel provides prediction of the real-valued time to open. The use of survival\nanalysis based methods allows us to jointly model both the open event as well\nas the time-to-open. We experimented on a large real-world dataset of marketing\nemails sent in a 3-month time duration. The mixture model achieves the best\naccuracy on our data where a high proportion of email messages go unopened.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 20:55:27 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Sinha", "Moumita", ""], ["Vinay", "Vishwa", ""], ["Singh", "Harvineet", ""]]}, {"id": "1908.06515", "submitter": "Rahul Mazumder", "authors": "Rahul Mazumder, Stephen Wright, Andrew Zheng", "title": "Computing Estimators of Dantzig Selector type via Column and Constraint\n  Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of linear-programming based estimators in reconstructing\na sparse signal from linear measurements. Specific formulations of the\nreconstruction problem considered here include Dantzig selector, basis pursuit\n(for the case in which the measurements contain no errors), and the fused\nDantzig selector (for the case in which the underlying signal is piecewise\nconstant). In spite of being estimators central to sparse signal processing and\nmachine learning, solving these linear programming problems for large scale\ninstances remains a challenging task, thereby limiting their usage in practice.\nWe show that classic constraint- and column-generation techniques from large\nscale linear programming, when used in conjunction with a commercial\nimplementation of the simplex method, and initialized with the solution from a\nclosely-related Lasso formulation, yields solutions with high efficiency in\nmany settings.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 21:31:52 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Mazumder", "Rahul", ""], ["Wright", "Stephen", ""], ["Zheng", "Andrew", ""]]}, {"id": "1908.06571", "submitter": "Grigorios Chrysos", "authors": "Grigorios Chrysos, Stylianos Moschoglou, Yannis Panagakis, Stefanos\n  Zafeiriou", "title": "PolyGAN: High-Order Polynomial Generators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) have become the gold standard when it\ncomes to learning generative models for high-dimensional distributions. Since\ntheir advent, numerous variations of GANs have been introduced in the\nliterature, primarily focusing on utilization of novel loss functions,\noptimization/regularization strategies and network architectures. In this\npaper, we turn our attention to the generator and investigate the use of\nhigh-order polynomials as an alternative class of universal function\napproximators. Concretely, we propose PolyGAN, where we model the data\ngenerator by means of a high-order polynomial whose unknown parameters are\nnaturally represented by high-order tensors. We introduce two tensor\ndecompositions that significantly reduce the number of parameters and show how\nthey can be efficiently implemented by hierarchical neural networks that only\nemploy linear/convolutional blocks. We exhibit for the first time that by using\nour approach a GAN generator can approximate the data distribution without\nusing any activation functions. Thorough experimental evaluation on both\nsynthetic and real data (images and 3D point clouds) demonstrates the merits of\nPolyGAN against the state of the art.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 03:14:00 GMT"}, {"version": "v2", "created": "Sun, 13 Oct 2019 15:37:29 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Chrysos", "Grigorios", ""], ["Moschoglou", "Stylianos", ""], ["Panagakis", "Yannis", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1908.06597", "submitter": "Yuan Ke", "authors": "Wanjun Liu, Yuan Ke, Jingyuan Liu and Runze Li", "title": "Model-free Feature Screening and FDR Control with Knockoff Features", "comments": null, "journal-ref": null, "doi": "10.1080/01621459.2020.1783274", "report-no": null, "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a model-free and data-adaptive feature screening method\nfor ultra-high dimensional datasets. The proposed method is based on the\nprojection correlation which measures the dependence between two random\nvectors. This projection correlation based method does not require specifying a\nregression model and applies to the data in the presence of heavy-tailed errors\nand multivariate response. It enjoys both sure screening and rank consistency\nproperties under weak assumptions. Further, a two-step approach is proposed to\ncontrol the false discovery rate (FDR) in feature screening with the help of\nknockoff features. It can be shown that the proposed two-step approach enjoys\nboth sure screening and FDR control if the pre-specified FDR level $\\alpha$ is\ngreater or equal to $1/s$, where $s$ is the number of active features. The\nsuperior empirical performance of the proposed methods is justified by various\nnumerical experiments and real data applications.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 05:12:51 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 01:36:15 GMT"}, {"version": "v3", "created": "Sat, 13 Feb 2021 22:43:45 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Liu", "Wanjun", ""], ["Ke", "Yuan", ""], ["Liu", "Jingyuan", ""], ["Li", "Runze", ""]]}, {"id": "1908.06599", "submitter": "Yongli Zhu", "authors": "Yongli Zhu, Chengxi Liu", "title": "Mitigating Multi-Stage Cascading Failure by Reinforcement Learning", "comments": "This paper has been accepted and presented in the IEEE ISGT-Asia\n  conference in 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a cascading failure mitigation strategy based on\nReinforcement Learning (RL) method. Firstly, the principles of RL are\nintroduced. Then, the Multi-Stage Cascading Failure (MSCF) problem is presented\nand its challenges are investigated. The problem is then tackled by the RL\nbased on DC-OPF (Optimal Power Flow). Designs of the key elements of the RL\nframework (rewards, states, etc.) are also discussed in detail. Experiments on\nthe IEEE 118-bus system by both shallow and deep neural networks demonstrate\npromising results in terms of reduced system collapse rates.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 05:41:23 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Zhu", "Yongli", ""], ["Liu", "Chengxi", ""]]}, {"id": "1908.06603", "submitter": "Huaipei Wang", "authors": "Yanshan Xiao, HuaiPei Wang, Bo Liu", "title": "Transfer Learning-Based Label Proportions Method with Data of\n  Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning with label proportions (LLP), which is a learning task that only\nprovides unlabeled data in bags and each bag's label proportion, has widespread\nsuccessful applications in practice. However, most of the existing LLP methods\ndon't consider the knowledge transfer for uncertain data. This paper presents a\ntransfer learning-based approach for the problem of learning with label\nproportions(TL-LLP) to transfer knowledge from source task to target task where\nboth the source and target tasks contain uncertain data. Our approach first\nformulates objective model for the uncertain data and deals with transfer\nlearning at the same time, and then proposes an iterative framework to build an\naccurate classifier for the target task. Extensive experiments have shown that\nthe proposed TL-LLP method can obtain the better accuracies and is less\nsensitive to noise compared with the existing LLP methods.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 05:56:25 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Xiao", "Yanshan", ""], ["Wang", "HuaiPei", ""], ["Liu", "Bo", ""]]}, {"id": "1908.06612", "submitter": "Kyle Young Mr", "authors": "Kyle Young, Gareth Booth, Becks Simpson, Reuben Dutton and Sally\n  Shrapnel", "title": "Deep neural network or dermatologist?", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-33850-3_6", "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have proven high accuracy for identifying melanoma\nin digitised dermoscopic images. A strength is that these methods are not\nconstrained by features that are pre-defined by human semantics. A down-side is\nthat it is difficult to understand the rationale of the model predictions and\nto identify potential failure modes. This is a major barrier to adoption of\ndeep learning in clinical practice. In this paper we ask if two existing local\ninterpretability methods, Grad-CAM and Kernel SHAP, can shed light on\nconvolutional neural networks trained in the context of melanoma detection. Our\ncontributions are (i) we first explore the domain space via a reproducible,\nend-to-end learning framework that creates a suite of 30 models, all trained on\na publicly available data set (HAM10000), (ii) we next explore the reliability\nof GradCAM and Kernel SHAP in this context via some basic sanity check\nexperiments (iii) finally, we investigate a random selection of models from our\nsuite using GradCAM and Kernel SHAP. We show that despite high accuracy, the\nmodels will occasionally assign importance to features that are not relevant to\nthe diagnostic task. We also show that models of similar accuracy will produce\ndifferent explanations as measured by these methods. This work represents first\nsteps in bridging the gap between model accuracy and interpretability in the\ndomain of skin cancer classification.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 06:40:52 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Young", "Kyle", ""], ["Booth", "Gareth", ""], ["Simpson", "Becks", ""], ["Dutton", "Reuben", ""], ["Shrapnel", "Sally", ""]]}, {"id": "1908.06655", "submitter": "Hideyuki Miyahara", "authors": "Hideyuki Miyahara, Kazuyuki Aihara, and Wolfgang Lechner", "title": "Quantum Expectation-Maximization Algorithm", "comments": "10 pages, 9 figures", "journal-ref": "Phys. Rev. A 101, 012326 (2020)", "doi": "10.1103/PhysRevA.101.012326", "report-no": null, "categories": "quant-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering algorithms are a cornerstone of machine learning applications.\nRecently, a quantum algorithm for clustering based on the k-means algorithm has\nbeen proposed by Kerenidis, Landman, Luongo and Prakash. Based on their work,\nwe propose a quantum expectation-maximization (EM) algorithm for Gaussian\nmixture models (GMMs). The robustness and quantum speedup of the algorithm is\ndemonstrated. We also show numerically the advantage of GMM over k-means for\nnon-trivial cluster data.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:19:54 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Miyahara", "Hideyuki", ""], ["Aihara", "Kazuyuki", ""], ["Lechner", "Wolfgang", ""]]}, {"id": "1908.06657", "submitter": "Alessandro Luongo", "authors": "Iordanis Kerenidis, Alessandro Luongo, Anupam Prakash", "title": "Quantum Expectation-Maximization for Gaussian Mixture Models", "comments": "As to appear in ICML2020 conference - with improved algorithms and\n  runtimes", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Expectation-Maximization (EM) algorithm is a fundamental tool in\nunsupervised machine learning. It is often used as an efficient way to solve\nMaximum Likelihood (ML) estimation problems, especially for models with latent\nvariables. It is also the algorithm of choice to fit mixture models: generative\nmodels that represent unlabelled points originating from $k$ different\nprocesses, as samples from $k$ multivariate distributions. In this work we\ndefine and use a quantum version of EM to fit a Gaussian Mixture Model. Given\nquantum access to a dataset of $n$ vectors of dimension $d$, our algorithm has\nconvergence and precision guarantees similar to the classical algorithm, but\nthe runtime is only polylogarithmic in the number of elements in the training\nset, and is polynomial in other parameters - as the dimension of the feature\nspace, and the number of components in the mixture. We generalize further the\nalgorithm in two directions. First, we show how to fit any mixture model of\nprobability distributions in the exponential family. Then, we show how to use\nthis algorithm to compute the Maximum a Posteriori (MAP) estimate of a mixture\nmodel: the Bayesian approach to likelihood estimation problems. We discuss the\nperformance of the algorithm on a dataset that is expected to be classified\nsuccessfully by this algorithm, arguing that on those cases we can give strong\nguarantees on the runtime.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:21:45 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 14:49:27 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Kerenidis", "Iordanis", ""], ["Luongo", "Alessandro", ""], ["Prakash", "Anupam", ""]]}, {"id": "1908.06661", "submitter": "Nils Kriege", "authors": "Nils M. Kriege", "title": "Deep Weisfeiler-Lehman Assignment Kernels via Multiple Kernel Learning", "comments": "ESANN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernels for structured data are commonly obtained by decomposing objects into\ntheir parts and adding up the similarities between all pairs of parts measured\nby a base kernel. Assignment kernels are based on an optimal bijection between\nthe parts and have proven to be an effective alternative to the established\nconvolution kernels. We explore how the base kernel can be learned as part of\nthe classification problem. We build on the theory of valid assignment kernels\nderived from hierarchies defined on the parts. We show that the weights of this\nhierarchy can be optimized via multiple kernel learning. We apply this result\nto learn vertex similarities for the Weisfeiler-Lehman optimal assignment\nkernel for graph classification. We present first experimental results which\ndemonstrate the feasibility and effectiveness of the approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:32:27 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Kriege", "Nils M.", ""]]}, {"id": "1908.06663", "submitter": "Chris Reinke", "authors": "Chris Reinke, Mayalen Etcheverry, Pierre-Yves Oudeyer", "title": "Intrinsically Motivated Discovery of Diverse Patterns in Self-Organizing\n  Systems", "comments": "29 pages, 19 figure, ICLR 2020 conference paper, associated website:\n  https://automated-discovery.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many complex dynamical systems, artificial or natural, one can observe\nself-organization of patterns emerging from local rules. Cellular automata,\nlike the Game of Life (GOL), have been widely used as abstract models enabling\nthe study of various aspects of self-organization and morphogenesis, such as\nthe emergence of spatially localized patterns. However, findings of\nself-organized patterns in such models have so far relied on manual tuning of\nparameters and initial states, and on the human eye to identify interesting\npatterns. In this paper, we formulate the problem of automated discovery of\ndiverse self-organized patterns in such high-dimensional complex dynamical\nsystems, as well as a framework for experimentation and evaluation. Using a\ncontinuous GOL as a testbed, we show that recent intrinsically-motivated\nmachine learning algorithms (POP-IMGEPs), initially developed for learning of\ninverse models in robotics, can be transposed and used in this novel\napplication area. These algorithms combine intrinsically-motivated goal\nexploration and unsupervised learning of goal space representations. Goal space\nrepresentations describe the interesting features of patterns for which diverse\nvariations should be discovered. In particular, we compare various approaches\nto define and learn goal space representations from the perspective of\ndiscovering diverse spatially localized patterns. Moreover, we introduce an\nextension of a state-of-the-art POP-IMGEP algorithm which incrementally learns\na goal representation using a deep auto-encoder, and the use of CPPN primitives\nfor generating initialization parameters. We show that it is more efficient\nthan several baselines and equally efficient as a system pre-trained on a\nhand-made database of patterns identified by human experts.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:32:46 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 16:40:53 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2020 14:43:54 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Reinke", "Chris", ""], ["Etcheverry", "Mayalen", ""], ["Oudeyer", "Pierre-Yves", ""]]}, {"id": "1908.06674", "submitter": "Marius Lindauer", "authors": "Marius Lindauer, Matthias Feurer, Katharina Eggensperger, Andr\\'e\n  Biedenkapp, Frank Hutter", "title": "Towards Assessing the Impact of Bayesian Optimization's Own\n  Hyperparameters", "comments": "Accepted at DSO workshop (as part of IJCAI'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Optimization (BO) is a common approach for hyperparameter\noptimization (HPO) in automated machine learning. Although it is well-accepted\nthat HPO is crucial to obtain well-performing machine learning models, tuning\nBO's own hyperparameters is often neglected. In this paper, we empirically\nstudy the impact of optimizing BO's own hyperparameters and the transferability\nof the found settings using a wide range of benchmarks, including artificial\nfunctions, HPO and HPO combined with neural architecture search. In particular,\nwe show (i) that tuning can improve the any-time performance of different BO\napproaches, that optimized BO settings also perform well (ii) on similar\nproblems and (iii) partially even on problems from other problem families, and\n(iv) which BO hyperparameters are most important.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 09:59:49 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Lindauer", "Marius", ""], ["Feurer", "Matthias", ""], ["Eggensperger", "Katharina", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Hutter", "Frank", ""]]}, {"id": "1908.06698", "submitter": "Dagui Chen", "authors": "Dagui Chen, Junqi Jin, Weinan Zhang, Fei Pan, Lvyin Niu, Chuan Yu, Jun\n  Wang, Han Li, Jian Xu, Kun Gai", "title": "Learning to Advertise for Organic Traffic Maximization in E-Commerce\n  Product Feeds", "comments": "accepted by CIKM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most e-commerce product feeds provide blended results of advertised products\nand recommended products to consumers. The underlying advertising and\nrecommendation platforms share similar if not exactly the same set of candidate\nproducts. Consumers' behaviors on the advertised results constitute part of the\nrecommendation model's training data and therefore can influence the\nrecommended results. We refer to this process as Leverage. Considering this\nmechanism, we propose a novel perspective that advertisers can strategically\nbid through the advertising platform to optimize their recommended organic\ntraffic. By analyzing the real-world data, we first explain the principles of\nLeverage mechanism, i.e., the dynamic models of Leverage. Then we introduce a\nnovel Leverage optimization problem and formulate it with a Markov Decision\nProcess. To deal with the sample complexity challenge in model-free\nreinforcement learning, we propose a novel Hybrid Training Leverage Bidding\n(HTLB) algorithm which combines the real-world samples and the\nemulator-generated samples to boost the learning speed and stability. Our\noffline experiments as well as the results from the online deployment\ndemonstrate the superior performance of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 11:16:33 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Chen", "Dagui", ""], ["Jin", "Junqi", ""], ["Zhang", "Weinan", ""], ["Pan", "Fei", ""], ["Niu", "Lvyin", ""], ["Yu", "Chuan", ""], ["Wang", "Jun", ""], ["Li", "Han", ""], ["Xu", "Jian", ""], ["Gai", "Kun", ""]]}, {"id": "1908.06699", "submitter": "Jinglin Xu", "authors": "Jinglin Xu, Junwei Han, Mingliang Xu, Feiping Nie, Xuelong Li", "title": "Robust and Efficient Fuzzy C-Means Clustering Constrained on Flexible\n  Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is an effective technique in data mining to group a set of objects\nin terms of some attributes. Among various clustering approaches, the family of\nK-Means algorithms gains popularity due to simplicity and efficiency. However,\nmost of existing K-Means based clustering algorithms cannot deal with outliers\nwell and are difficult to efficiently solve the problem embedded the $L_0$-norm\nconstraint. To address the above issues and improve the performance of\nclustering significantly, we propose a novel clustering algorithm, named\nREFCMFS, which develops a $L_{2,1}$-norm robust loss as the data-driven item\nand imposes a $L_0$-norm constraint on the membership matrix to make the model\nmore robust and sparse flexibly. In particular, REFCMFS designs a new way to\nsimplify and solve the $L_0$-norm constraint without any approximate\ntransformation by absorbing $\\|\\cdot\\|_0$ into the objective function through a\nranking function. These improvements not only make REFCMFS efficiently obtain\nmore promising performance but also provide a new tractable and skillful\noptimization method to solve the problem embedded the $L_0$-norm constraint.\nTheoretical analyses and extensive experiments on several public datasets\ndemonstrate the effectiveness and rationality of our proposed REFCMFS method.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 11:17:42 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 02:24:07 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 03:02:13 GMT"}, {"version": "v4", "created": "Thu, 5 Sep 2019 02:51:49 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Xu", "Jinglin", ""], ["Han", "Junwei", ""], ["Xu", "Mingliang", ""], ["Nie", "Feiping", ""], ["Li", "Xuelong", ""]]}, {"id": "1908.06720", "submitter": "D\\'aniel Szil\\'agyi", "authors": "Iordanis Kerenidis, Anupam Prakash, D\\'aniel Szil\\'agyi", "title": "Quantum algorithms for Second-Order Cone Programming and Support Vector\n  Machines", "comments": "final version for Quantum", "journal-ref": "Quantum 5, 427 (2021)", "doi": "10.22331/q-2021-04-08-427", "report-no": null, "categories": "quant-ph cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a quantum interior-point method (IPM) for second-order cone\nprogramming (SOCP) that runs in time $\\widetilde{O} \\left( n\\sqrt{r}\n\\frac{\\zeta \\kappa}{\\delta^2} \\log \\left(1/\\epsilon\\right) \\right)$ where $r$\nis the rank and $n$ the dimension of the SOCP, $\\delta$ bounds the distance of\nintermediate solutions from the cone boundary, $\\zeta$ is a parameter upper\nbounded by $\\sqrt{n}$, and $\\kappa$ is an upper bound on the condition number\nof matrices arising in the classical IPM for SOCP. The algorithm takes as its\ninput a suitable quantum description of an arbitrary SOCP and outputs a\nclassical description of a $\\delta$-approximate $\\epsilon$-optimal solution of\nthe given problem.\n  Furthermore, we perform numerical simulations to determine the values of the\naforementioned parameters when solving the SOCP up to a fixed precision\n$\\epsilon$. We present experimental evidence that in this case our quantum\nalgorithm exhibits a polynomial speedup over the best classical algorithms for\nsolving general SOCPs that run in time $O(n^{\\omega+0.5})$ (here, $\\omega$ is\nthe matrix multiplication exponent, with a value of roughly $2.37$ in theory,\nand up to $3$ in practice). For the case of random SVM (support vector machine)\ninstances of size $O(n)$, the quantum algorithm scales as $O(n^k)$, where the\nexponent $k$ is estimated to be $2.59$ using a least-squares power law. On the\nsame family random instances, the estimated scaling exponent for an external\nSOCP solver is $3.31$ while that for a state-of-the-art SVM solver is $3.11$.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 12:02:13 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 12:49:00 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 10:57:26 GMT"}, {"version": "v4", "created": "Mon, 5 Apr 2021 17:33:22 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Kerenidis", "Iordanis", ""], ["Prakash", "Anupam", ""], ["Szil\u00e1gyi", "D\u00e1niel", ""]]}, {"id": "1908.06729", "submitter": "Hongzhi Wang", "authors": "Xi Chen, Hongzhi Wang, Yanjie Wei, Jianzhong Li and Hong Gao", "title": "Autoregressive-Model-Based Methods for Online Time Series Prediction\n  with Missing Values: an Experimental Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series prediction with missing values is an important problem of time\nseries analysis since complete data is usually hard to obtain in many\nreal-world applications. To model the generation of time series, autoregressive\n(AR) model is a basic and widely used one, which assumes that each observation\nin the time series is a noisy linear combination of some previous observations\nalong with a constant shift. To tackle the problem of prediction with missing\nvalues, a number of methods were proposed based on various data models. For\nreal application scenarios, how do these methods perform over different types\nof time series with different levels of data missing remains to be\ninvestigated. In this paper, we focus on online methods for AR-model-based time\nseries prediction with missing values. We adapted five mainstream methods to\nfit in such a scenario. We make detailed discussion on each of them by\nintroducing their core ideas about how to estimate the AR coefficients and\ntheir different strategies to deal with missing values. We also present\nalgorithmic implementations for better understanding. In order to\ncomprehensively evaluate these methods and do the comparison, we conduct\nexperiments with various configurations of relative parameters over both\nsynthetic and real data. From the experimental results, we derived several\nnoteworthy conclusions and shows that imputation is a simple but reliable\nstrategy to handle missing values in online prediction tasks.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 13:58:54 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 01:59:09 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Chen", "Xi", ""], ["Wang", "Hongzhi", ""], ["Wei", "Yanjie", ""], ["Li", "Jianzhong", ""], ["Gao", "Hong", ""]]}, {"id": "1908.06746", "submitter": "Mohsen Shahhosseini", "authors": "Mohsen Shahhosseini, Rafael A. Martinez-Feria, Guiping Hu, Sotirios V.\n  Archontoulis", "title": "Maize Yield and Nitrate Loss Prediction with Machine Learning Algorithms", "comments": null, "journal-ref": "Environmental Research Letters 14(12) (2019) 124026", "doi": "10.1088/1748-9326/ab5268", "report-no": null, "categories": "q-bio.OT cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-season prediction of crop production outcomes such as grain yields and N\nlosses can provide insights to stakeholders when making decisions. Simulation\nmodels can assist in scenario planning, but their use is limited because of\ndata requirements and long run times. Thus, there is a need for more\ncomputationally expedient approaches to scale up predictions. We evaluated the\npotential of five machine learning (ML) algorithms as meta-models for a\ncropping systems simulator (APSIM) to inform future decision-support tool\ndevelopment. We asked: 1) How well do ML meta-models predict maize yield and N\nlosses using pre-season information? 2) How many data are needed to train ML\nalgorithms to achieve acceptable predictions?; 3) Which input data variables\nare most important for accurate prediction?; and 4) Do ensembles of ML\nmeta-models improve prediction? The simulated dataset included more than 3\nmillion genotype, environment and management scenarios. Random forests most\naccurately predicted maize yield and N loss at planting time, with a RRMSE of\n14% and 55%, respectively. ML meta-models reasonably reproduced simulated maize\nyields but not N loss. They also differed in their sensitivities to the size of\nthe training dataset. Across all ML models, yield prediction error decreased by\n10-40% as the training dataset increased from 0.5 to 1.8 million data points,\nwhereas N loss prediction error showed no consistent pattern. ML models also\ndiffered in their sensitivities to input variables. Averaged across all ML\nmodels, weather conditions, soil properties, management information and initial\nconditions were roughly equally important when predicting yields. Modest\nprediction improvements resulted from ML ensembles. These results can help\naccelerate progress in coupling simulation models and ML toward developing\ndynamic decision support tools for pre-season management.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:43:24 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 18:23:37 GMT"}, {"version": "v3", "created": "Thu, 29 Aug 2019 17:48:56 GMT"}, {"version": "v4", "created": "Thu, 19 Sep 2019 15:12:00 GMT"}, {"version": "v5", "created": "Fri, 6 Nov 2020 18:18:11 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Shahhosseini", "Mohsen", ""], ["Martinez-Feria", "Rafael A.", ""], ["Hu", "Guiping", ""], ["Archontoulis", "Sotirios V.", ""]]}, {"id": "1908.06754", "submitter": "Daniel Rivero", "authors": "Daniel Rivero, Enrique Fernandez-Blanco", "title": "A New Deterministic Technique for Symbolic Regression", "comments": "29 pages. Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new method for Symbolic Regression that allows to find\nmathematical expressions from a dataset. This method has a strong mathematical\nbasis. As opposed to other methods such as Genetic Programming, this method is\ndeterministic, and does not involve the creation of a population of initial\nsolutions. Instead of it, a simple expression is being grown until it fits the\ndata. The experiments performed show that the results are as good as other\nMachine Learning methods, in a very low computational time. Another advantage\nof this technique is that the complexity of the expressions can be limited, so\nthe system can return mathematical expressions that can be easily analysed by\nthe user, in opposition to other techniques like GSGP.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 10:58:11 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 07:57:31 GMT"}, {"version": "v3", "created": "Tue, 1 Oct 2019 11:47:12 GMT"}, {"version": "v4", "created": "Fri, 15 Nov 2019 09:38:36 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Rivero", "Daniel", ""], ["Fernandez-Blanco", "Enrique", ""]]}, {"id": "1908.06756", "submitter": "Marius Lindauer", "authors": "Marius Lindauer, Katharina Eggensperger, Matthias Feurer, Andr\\'e\n  Biedenkapp, Joshua Marben, Philipp M\\\"uller and Frank Hutter", "title": "BOAH: A Tool Suite for Multi-Fidelity Bayesian Optimization & Analysis\n  of Hyperparameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperparameter optimization and neural architecture search can become\nprohibitively expensive for regular black-box Bayesian optimization because the\ntraining and evaluation of a single model can easily take several hours. To\novercome this, we introduce a comprehensive tool suite for effective\nmulti-fidelity Bayesian optimization and the analysis of its runs. The suite,\nwritten in Python, provides a simple way to specify complex design spaces, a\nrobust and efficient combination of Bayesian optimization and HyperBand, and a\ncomprehensive analysis of the optimization process and its outcomes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 10:01:03 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Lindauer", "Marius", ""], ["Eggensperger", "Katharina", ""], ["Feurer", "Matthias", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Marben", "Joshua", ""], ["M\u00fcller", "Philipp", ""], ["Hutter", "Frank", ""]]}, {"id": "1908.06760", "submitter": "Bonggun Shin", "authors": "Bonggun Shin, Sungsoo Park, Keunsoo Kang, Joyce C. Ho", "title": "Self-Attention Based Molecule Representation for Predicting Drug-Target\n  Interaction", "comments": "18 pages, Proceedings of Machine Learning for Healthcare, 2019\n  (MLHC'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting drug-target interactions (DTI) is an essential part of the drug\ndiscovery process, which is an expensive process in terms of time and cost.\nTherefore, reducing DTI cost could lead to reduced healthcare costs for a\npatient. In addition, a precisely learned molecule representation in a DTI\nmodel could contribute to developing personalized medicine, which will help\nmany patient cohorts. In this paper, we propose a new molecule representation\nbased on the self-attention mechanism, and a new DTI model using our molecule\nrepresentation. The experiments show that our DTI model outperforms the state\nof the art by up to 4.9% points in terms of area under the precision-recall\ncurve. Moreover, a study using the DrugBank database proves that our model\neffectively lists all known drugs targeting a specific cancer biomarker in the\ntop-30 candidate list.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 21:39:15 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Shin", "Bonggun", ""], ["Park", "Sungsoo", ""], ["Kang", "Keunsoo", ""], ["Ho", "Joyce C.", ""]]}, {"id": "1908.06802", "submitter": "Binhang Yuan", "authors": "Binhang Yuan and Wenhui Xing", "title": "Diagnosing Cardiac Abnormalities from 12-Lead Electrocardiograms Using\n  Enhanced Deep Convolutional Neural Networks", "comments": "Accepted by MLMECH-MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We train an enhanced deep convolutional neural network in order to identify\neight cardiac abnormalities from the standard 12-lead electrocardiograms (ECGs)\nusing the dataset of 14000 ECGs. Instead of straightforwardly applying an\nend-to-end deep learning approach, we find that deep convolutional neural\nnetworks enhanced with sophisticated hand crafted features show advantages in\nreducing generalization errors. Additionally, data preprocessing and\naugmentation are essential since the distribution of eight cardiac\nabnormalities are highly biased in the given dataset. Our approach achieves\npromising generalization performance in the First China ECG Intelligent\nCompetition; an empirical evaluation is also provided to validate the efficacy\nof our design on the competition ECG dataset.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 15:20:12 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Yuan", "Binhang", ""], ["Xing", "Wenhui", ""]]}, {"id": "1908.06803", "submitter": "Md Tamzeed Islam", "authors": "Md Tamzeed Islam, Shahriar Nirjon", "title": "Wi-Fringe: Leveraging Text Semantics in WiFi CSI-Based Device-Free Named\n  Gesture Recognition", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of adequate training data is one of the major hurdles in WiFi-based\nactivity recognition systems. In this paper, we propose Wi-Fringe, which is a\nWiFi CSI-based device-free human gesture recognition system that recognizes\nnamed gestures, i.e., activities and gestures that have a semantically\nmeaningful name in English language, as opposed to arbitrary free-form\ngestures. Given a list of activities (only their names in English text), along\nwith zero or more training examples (WiFi CSI values) per activity, Wi-Fringe\nis able to detect all activities at runtime. In other words, a subset of\nactivities that Wi-Fringe detects do not require any training examples at all.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 15:42:29 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Islam", "Md Tamzeed", ""], ["Nirjon", "Shahriar", ""]]}, {"id": "1908.06817", "submitter": "Sterling Ramroach", "authors": "Sterling Ramroach, Melford John, and Ajay Joshi", "title": "The efficacy of various machine learning models for multi-class\n  classification of RNA-seq expression data", "comments": "12 pages, 4 figures, 3 tables, conference paper: Computing Conference\n  2019, published at\n  https://link.springer.com/chapter/10.1007/978-3-030-22871-2_65", "journal-ref": null, "doi": "10.1007/978-3-030-22871-2_65", "report-no": null, "categories": "cs.LG q-bio.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Late diagnosis and high costs are key factors that negatively impact the care\nof cancer patients worldwide. Although the availability of biological markers\nfor the diagnosis of cancer type is increasing, costs and reliability of tests\ncurrently present a barrier to the adoption of their routine use. There is a\npressing need for accurate methods that enable early diagnosis and cover a\nbroad range of cancers. The use of machine learning and RNA-seq expression\nanalysis has shown promise in the classification of cancer type. However,\nresearch is inconclusive about which type of machine learning models are\noptimal. The suitability of five algorithms were assessed for the\nclassification of 17 different cancer types. Each algorithm was fine-tuned and\ntrained on the full array of 18,015 genes per sample, for 4,221 samples (75 %\nof the dataset). They were then tested with 1,408 samples (25 % of the dataset)\nfor which cancer types were withheld to determine the accuracy of prediction.\nThe results show that ensemble algorithms achieve 100% accuracy in the\nclassification of 14 out of 17 types of cancer. The clustering and\nclassification models, while faster than the ensembles, performed poorly due to\nthe high level of noise in the dataset. When the features were reduced to a\nlist of 20 genes, the ensemble algorithms maintained an accuracy above 95% as\nopposed to the clustering and classification models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 14:10:44 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Ramroach", "Sterling", ""], ["John", "Melford", ""], ["Joshi", "Ajay", ""]]}, {"id": "1908.06818", "submitter": "Michal Moshkovitz", "authors": "Michal Moshkovitz", "title": "Unexpected Effects of Online no-Substitution k-means Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline k-means clustering was studied extensively, and algorithms with a\nconstant approximation are available. However, online clustering is still\nuncharted. New factors come into play: the ordering of the dataset and whether\nthe number of points, n, is known in advance or not. Their exact effects are\nunknown. In this paper we focus on the online setting where the decisions are\nirreversible: after a point arrives, the algorithm needs to decide whether to\ntake the point as a center or not, and this decision is final. How many centers\nare needed and sufficient to achieve constant approximation in this setting? We\nshow upper and lower bounds for all the different cases. These bounds are\nexactly the same up to a constant, thus achieving optimal bounds. For example,\nfor k-means cost with constant k>1 and random order, Theta(log n) centers are\nenough to achieve a constant approximation, while the mere a priori knowledge\nof n reduces the number of centers to a constant. These bounds hold for any\ndistance function that obeys a triangle-type inequality.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 18:21:00 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 03:13:45 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Moshkovitz", "Michal", ""]]}, {"id": "1908.06830", "submitter": "Nicholas Heller", "authors": "Nicholas Heller, Jack Rickman, Christopher Weight, and Nikolaos\n  Papanikolopoulos", "title": "The Role of Publicly Available Data in MICCAI Papers from 2014 to 2018", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Widely-used public benchmarks are of huge importance to computer vision and\nmachine learning research, especially with the computational resources required\nto reproduce state of the art results quickly becoming untenable. In medical\nimage computing, the wide variety of image modalities and problem formulations\nyields a huge task-space for benchmarks to cover, and thus the widespread\nadoption of standard benchmarks has been slow, and barriers to releasing\nmedical data exacerbate this issue. In this paper, we examine the role that\npublicly available data has played in MICCAI papers from the past five years.\nWe find that more than half of these papers are based on private data alone,\nalthough this proportion seems to be decreasing over time. Additionally, we\nobserved that after controlling for open access publication and the release of\ncode, papers based on public data were cited over 60% more per year than their\nprivate-data counterparts. Further, we found that more than 20% of papers using\npublic data did not provide a citation to the dataset or associated manuscript,\nhighlighting the \"second-rate\" status that data contributions often take\ncompared to theoretical ones. We conclude by making recommendations for MICCAI\npolicies which could help to better incentivise data sharing and move the field\ntoward more efficient and reproducible science.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 16:28:29 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Heller", "Nicholas", ""], ["Rickman", "Jack", ""], ["Weight", "Christopher", ""], ["Papanikolopoulos", "Nikolaos", ""]]}, {"id": "1908.06843", "submitter": "Georgios Exarchakis", "authors": "Georgios Exarchakis, J\\\"org Bornschein, Abdul-Saboor Sheikh, Zhenwen\n  Dai, Marc Henniges, Jakob Drefs, J\\\"org L\\\"ucke", "title": "ProSper -- A Python Library for Probabilistic Sparse Coding with\n  Non-Standard Priors and Superpositions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ProSper is a python library containing probabilistic algorithms to learn\ndictionaries. Given a set of data points, the implemented algorithms seek to\nlearn the elementary components that have generated the data. The library\nwidens the scope of dictionary learning approaches beyond implementations of\nstandard approaches such as ICA, NMF or standard L1 sparse coding. The\nimplemented algorithms are especially well-suited in cases when data consist of\ncomponents that combine non-linearly and/or for data requiring flexible prior\ndistributions. Furthermore, the implemented algorithms go beyond standard\napproaches by inferring prior and noise parameters of the data, and they\nprovide rich a-posteriori approximations for inference. The library is designed\nto be extendable and it currently includes: Binary Sparse Coding (BSC), Ternary\nSparse Coding (TSC), Discrete Sparse Coding (DSC), Maximal Causes Analysis\n(MCA), Maximum Magnitude Causes Analysis (MMCA), and Gaussian Sparse Coding\n(GSC, a recent spike-and-slab sparse coding approach). The algorithms are\nscalable due to a combination of variational approximations and\nparallelization. Implementations of all algorithms allow for parallel execution\non multiple CPUs and multiple machines for medium to large-scale applications.\nTypical large-scale runs of the algorithms can use hundreds of CPUs to learn\nhundreds of dictionary elements from data with tens of millions of\nfloating-point numbers such that models with several hundred thousand\nparameters can be optimized. The library is designed to have minimal\ndependencies and to be easy to use. It targets users of dictionary learning\nalgorithms and Machine Learning researchers.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 14:55:45 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Exarchakis", "Georgios", ""], ["Bornschein", "J\u00f6rg", ""], ["Sheikh", "Abdul-Saboor", ""], ["Dai", "Zhenwen", ""], ["Henniges", "Marc", ""], ["Drefs", "Jakob", ""], ["L\u00fccke", "J\u00f6rg", ""]]}, {"id": "1908.06845", "submitter": "Nir Shlezinger", "authors": "Nir Shlezinger and Yonina C. Eldar", "title": "Deep Task-Based Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantizers play a critical role in digital signal processing systems. Recent\nworks have shown that the performance of quantization systems acquiring\nmultiple analog signals using scalar analog-to-digital converters (ADCs) can be\nsignificantly improved by properly processing the analog signals prior to\nquantization. However, the design of such hybrid quantizers is quite complex,\nand their implementation requires complete knowledge of the statistical model\nof the analog signal, which may not be available in practice. In this work we\ndesign data-driven task-oriented quantization systems with scalar ADCs, which\ndetermine how to map an analog signal into its digital representation using\ndeep learning tools. These representations are designed to facilitate the task\nof recovering underlying information from the quantized signals, which can be a\nset of parameters to estimate, or alternatively, a classification task. By\nutilizing deep learning, we circumvent the need to explicitly recover the\nsystem model and to find the proper quantization rule for it. Our main target\napplication is multiple-input multiple-output (MIMO) communication receivers,\nwhich simultaneously acquire a set of analog signals, and are commonly subject\nto constraints on the number of bits. Our results indicate that, in a MIMO\nchannel estimation setup, the proposed deep task-bask quantizer is capable of\napproaching the optimal performance limits dictated by indirect rate-distortion\ntheory, achievable using vector quantizers and requiring complete knowledge of\nthe underlying statistical model. Furthermore, for a symbol detection scenario,\nit is demonstrated that the proposed approach can realize reliable\nbit-efficient hybrid MIMO receivers capable of setting their quantization rule\nin light of the task, e.g., to minimize the bit error rate.\n", "versions": [{"version": "v1", "created": "Thu, 1 Aug 2019 10:03:42 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Shlezinger", "Nir", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "1908.06847", "submitter": "Solmaz Niknam", "authors": "Solmaz Niknam, Harpreet S. Dhillon, and Jeffery H. Reed", "title": "Federated Learning for Wireless Communications: Motivation,\n  Opportunities and Challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in the wireless communications community to\ncomplement the traditional model-based design approaches with data-driven\nmachine learning (ML)-based solutions. While conventional ML approaches rely on\nthe assumption of having the data and processing heads in a central entity,\nthis is not always feasible in wireless communications applications because of\nthe inaccessibility of private data and large communication overhead required\nto transmit raw data to central ML processors. As a result, decentralized ML\napproaches that keep the data where it is generated are much more appealing.\nOwing to its privacy-preserving nature, federated learning is particularly\nrelevant for many wireless applications, especially in the context of fifth\ngeneration (5G) networks. In this article, we provide an accessible\nintroduction to the general idea of federated learning, discuss several\npossible applications in 5G networks, and describe key technical challenges and\nopen problems for future research on federated learning in the context of\nwireless communications.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 21:30:23 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2019 15:09:48 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 17:33:41 GMT"}, {"version": "v4", "created": "Sun, 3 May 2020 01:05:37 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Niknam", "Solmaz", ""], ["Dhillon", "Harpreet S.", ""], ["Reed", "Jeffery H.", ""]]}, {"id": "1908.06848", "submitter": "Vassilios Dallas", "authors": "Nicolas Boull\\'e, Vassilios Dallas, Yuji Nakatsukasa, D. Samaddar", "title": "Classification of chaotic time series with deep learning", "comments": "15 pages, 13 figures, accepted in Physica D: Nonlinear Phenomena", "journal-ref": null, "doi": "10.1016/j.physd.2019.132261", "report-no": null, "categories": "eess.SP cs.LG math.DS nlin.CD physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use standard deep neural networks to classify univariate time series\ngenerated by discrete and continuous dynamical systems based on their chaotic\nor non-chaotic behaviour. Our approach to circumvent the lack of precise models\nfor some of the most challenging real-life applications is to train different\nneural networks on a data set from a dynamical system with a basic or\nlow-dimensional phase space and then use these networks to classify univariate\ntime series of a dynamical system with more intricate or high-dimensional phase\nspace. We illustrate this generalisation approach using the logistic map, the\nsine-circle map, the Lorenz system, and the Kuramoto--Sivashinsky equation. We\nobserve that a convolutional neural network without batch normalization layers\noutperforms state-of-the-art neural networks for time series classification and\nis able to generalise and classify time series as chaotic or not with high\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 20:54:40 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2019 21:58:04 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 21:28:06 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Boull\u00e9", "Nicolas", ""], ["Dallas", "Vassilios", ""], ["Nakatsukasa", "Yuji", ""], ["Samaddar", "D.", ""]]}, {"id": "1908.06851", "submitter": "Grigorios G. Anagnostopoulos Dr.", "authors": "Grigorios G. Anagnostopoulos, Alexandros Kalousis", "title": "A Reproducible Analysis of RSSI Fingerprinting for Outdoor Localization\n  Using Sigfox: Preprocessing and Hyperparameter Tuning", "comments": "Preprint of a paper to be presented in IPIN2019", "journal-ref": null, "doi": "10.1109/IPIN.2019.8911792", "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fingerprinting techniques, which are a common method for indoor localization,\nhave been recently applied with success into outdoor settings. Particularly,\nthe communication signals of Low Power Wide Area Networks (LPWAN) such as\nSigfox, have been used for localization. In this rather recent field of study,\nnot many publicly available datasets, which would facilitate the consistent\ncomparison of different positioning systems, exist so far. In the current\nstudy, a published dataset of RSSI measurements on a Sigfox network deployed in\nAntwerp, Belgium is used to analyse the appropriate selection of preprocessing\nsteps and to tune the hyperparameters of a kNN fingerprinting method.\nInitially, the tuning of hyperparameter k for a variety of distance metrics,\nand the selection of efficient data transformation schemes, proposed by\nrelevant works, is presented. In addition, accuracy improvements are achieved\nin this study, by a detailed examination of the appropriate adjustment of the\nparameters of the data transformation schemes tested, and of the handling of\nout of range values. With the appropriate tuning of these factors, the achieved\nmean localization error was 298 meters, and the median error was 109 meters. To\nfacilitate the reproducibility of tests and comparability of results, the code\nand train/validation/test split used in this study are available.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 09:16:40 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Anagnostopoulos", "Grigorios G.", ""], ["Kalousis", "Alexandros", ""]]}, {"id": "1908.06852", "submitter": "Clement Benard", "authors": "Cl\\'ement B\\'enard (LPSM (UMR\\_8001)), G\\'erard Biau (LPSM\n  (UMR\\_8001)), S\\'ebastien da Veiga, Erwan Scornet (CMAP)", "title": "SIRUS: Stable and Interpretable RUle Set for Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art learning algorithms, such as random forests or neural\nnetworks, are often qualified as \"black-boxes\" because of the high number and\ncomplexity of operations involved in their prediction mechanism. This lack of\ninterpretability is a strong limitation for applications involving critical\ndecisions, typically the analysis of production processes in the manufacturing\nindustry. In such critical contexts, models have to be interpretable, i.e.,\nsimple, stable, and predictive. To address this issue, we design SIRUS (Stable\nand Interpretable RUle Set), a new classification algorithm based on random\nforests, which takes the form of a short list of rules. While simple models are\nusually unstable with respect to data perturbation, SIRUS achieves a remarkable\nstability improvement over cutting-edge methods. Furthermore, SIRUS inherits a\npredictive accuracy close to random forests, combined with the simplicity of\ndecision trees. These properties are assessed both from a theoretical and\nempirical point of view, through extensive numerical experiments based on our\nR/C++ software implementation sirus available from CRAN.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 14:55:47 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 13:16:57 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 08:09:14 GMT"}, {"version": "v4", "created": "Tue, 29 Sep 2020 12:51:34 GMT"}, {"version": "v5", "created": "Wed, 16 Dec 2020 10:52:20 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["B\u00e9nard", "Cl\u00e9ment", "", "LPSM"], ["Biau", "G\u00e9rard", "", "LPSM"], ["da Veiga", "S\u00e9bastien", "", "CMAP"], ["Scornet", "Erwan", "", "CMAP"]]}, {"id": "1908.06869", "submitter": "Cheng Li", "authors": "Cheng Li, Abdul Dakkak, Jinjun Xiong, Wei Wei, Lingjie Xu, Wen-mei Hwu", "title": "XSP: Across-Stack Profiling and Analysis of Machine Learning Models on\n  GPUs", "comments": null, "journal-ref": null, "doi": "10.1109/IPDPS47924.2020.00042", "report-no": null, "categories": "cs.LG cs.AR cs.PF stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a rapid proliferation of machine learning/deep learning (ML)\nmodels and wide adoption of them in many application domains. This has made\nprofiling and characterization of ML model performance an increasingly pressing\ntask for both hardware designers and system providers, as they would like to\noffer the best possible system to serve ML models with the target latency,\nthroughput, cost, and energy requirements while maximizing resource\nutilization. Such an endeavor is challenging as the characteristics of an ML\nmodel depend on the interplay between the model, framework, system libraries,\nand the hardware (or the HW/SW stack). Existing profiling tools are disjoint,\nhowever, and only focus on profiling within a particular level of the stack,\nwhich limits the thoroughness and usefulness of the profiling results.\n  This paper proposes XSP - an across-stack profiling design that gives a\nholistic and hierarchical view of ML model execution. XSP leverages distributed\ntracing to aggregate and correlates profile data from different sources. XSP\nintroduces a leveled and iterative measurement approach that accurately\ncaptures the latencies at all levels of the HW/SW stack in spite of the\nprofiling overhead. We couple the profiling design with an automated analysis\npipeline to systematically analyze 65 state-of-the-art ML models. We\ndemonstrate that XSP provides insights which would be difficult to discern\notherwise.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:05:29 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2020 16:42:42 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 01:31:35 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Li", "Cheng", ""], ["Dakkak", "Abdul", ""], ["Xiong", "Jinjun", ""], ["Wei", "Wei", ""], ["Xu", "Lingjie", ""], ["Hwu", "Wen-mei", ""]]}, {"id": "1908.06874", "submitter": "Michael Rapp", "authors": "Yannik Klein, Michael Rapp and Eneldo Loza Menc\\'ia", "title": "Efficient Discovery of Expressive Multi-label Rules using Relaxed\n  Pruning", "comments": "Preprint version. To appear in Proceedings of the 22nd International\n  Conference on Discovery Science, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to model correlations between labels is considered crucial in\nmulti-label classification. Rule-based models enable to expose such\ndependencies, e.g., implications, subsumptions, or exclusions, in an\ninterpretable and human-comprehensible manner. Albeit the number of possible\nlabel combinations increases exponentially with the number of available labels,\nit has been shown that rules with multiple labels in their heads, which are a\nnatural form to model local label dependencies, can be induced efficiently by\nexploiting certain properties of rule evaluation measures and pruning the label\nsearch space accordingly. However, experiments have revealed that multi-label\nheads are unlikely to be learned by existing methods due to their\nrestrictiveness. To overcome this limitation, we propose a plug-in approach\nthat relaxes the search space pruning used by existing methods in order to\nintroduce a bias towards larger multi-label heads resulting in more expressive\nrules. We further demonstrate the effectiveness of our approach empirically and\nshow that it does not come with drawbacks in terms of training time or\npredictive performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 15:22:23 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Klein", "Yannik", ""], ["Rapp", "Michael", ""], ["Menc\u00eda", "Eneldo Loza", ""]]}, {"id": "1908.06901", "submitter": "Roi Naveiro", "authors": "Roi Naveiro and David R\\'ios Insua", "title": "Gradient Methods for Solving Stackelberg Games", "comments": "Accepted in ADT Conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stackelberg Games are gaining importance in the last years due to the raise\nof Adversarial Machine Learning (AML). Within this context, a new paradigm must\nbe faced: in classical game theory, intervening agents were humans whose\ndecisions are generally discrete and low dimensional. In AML, decisions are\nmade by algorithms and are usually continuous and high dimensional, e.g.\nchoosing the weights of a neural network. As closed form solutions for\nStackelberg games generally do not exist, it is mandatory to have efficient\nalgorithms to search for numerical solutions. We study two different procedures\nfor solving this type of games using gradient methods. We study time and space\nscalability of both approaches and discuss in which situation it is more\nappropriate to use each of them. Finally, we illustrate their use in an\nadversarial prediction problem.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:00:57 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 13:48:16 GMT"}, {"version": "v3", "created": "Wed, 23 Oct 2019 19:54:12 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Naveiro", "Roi", ""], ["Insua", "David R\u00edos", ""]]}, {"id": "1908.06907", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Probability Estimation with Truncated Inverse Binomial Sampling", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.SY eess.SY stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a general theory of truncated inverse binomial\nsampling. In this theory, the fixed-size sampling and inverse binomial sampling\nare accommodated as special cases. In particular, the classical\nChernoff-Hoeffding bound is an immediate consequence of the theory. Moreover,\nwe propose a rigorous and efficient method for probability estimation, which is\nan adaptive Monte Carlo estimation method based on truncated inverse binomial\nsampling. Our proposed method of probability estimation can be orders of\nmagnitude more efficient as compared to existing methods in literature and\nwidely used software.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:08:50 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "1908.06923", "submitter": "Pritam Anand South Asian University", "authors": "Pritam Anand, Reshma Rastogi (nee Khemchandani) and Suresh Chandra", "title": "A new asymmetric $\\epsilon$-insensitive pinball loss function based\n  support vector quantile regression model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel asymmetric $\\epsilon$-insensitive pinball\nloss function for quantile estimation. There exists some pinball loss functions\nwhich attempt to incorporate the $\\epsilon$-insensitive zone approach in it\nbut, they fail to extend the $\\epsilon$-insensitive approach for quantile\nestimation in true sense. The proposed asymmetric $\\epsilon$-insensitive\npinball loss function can make an asymmetric $\\epsilon$- insensitive zone of\nfixed width around the data and divide it using $\\tau$ value for the estimation\nof the $\\tau$th quantile. The use of the proposed asymmetric\n$\\epsilon$-insensitive pinball loss function in Support Vector Quantile\nRegression (SVQR) model improves its prediction ability significantly. It also\nbrings the sparsity back in SVQR model. Further, the numerical results obtained\nby several experiments carried on artificial and real world datasets\nempirically show the efficacy of the proposed `$\\epsilon$-Support Vector\nQuantile Regression' ($\\epsilon$-SVQR) model over other existing SVQR models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 16:48:54 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Anand", "Pritam", "", "nee Khemchandani"], ["Rastogi", "Reshma", "", "nee Khemchandani"], ["Chandra", "Suresh", ""]]}, {"id": "1908.06940", "submitter": "Makan Arastuie", "authors": "Makan Arastuie, Subhadeep Paul, Kevin S. Xu", "title": "CHIP: A Hawkes Process Model for Continuous-time Networks with Scalable\n  and Consistent Estimation", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada. Source code is available at\n  https://github.com/IdeasLabUT/CHIP-Network-Model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.LG physics.soc-ph stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many application settings involving networks, such as messages between\nusers of an on-line social network or transactions between traders in financial\nmarkets, the observed data consist of timestamped relational events, which form\na continuous-time network. We propose the Community Hawkes Independent Pairs\n(CHIP) generative model for such networks. We show that applying spectral\nclustering to an aggregated adjacency matrix constructed from the CHIP model\nprovides consistent community detection for a growing number of nodes and time\nduration. We also develop consistent and computationally efficient estimators\nfor the model parameters. We demonstrate that our proposed CHIP model and\nestimation procedure scales to large networks with tens of thousands of nodes\nand provides superior fits than existing continuous-time network models on\nseveral real networks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:24:58 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2020 00:37:44 GMT"}, {"version": "v3", "created": "Tue, 10 Nov 2020 06:19:42 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Arastuie", "Makan", ""], ["Paul", "Subhadeep", ""], ["Xu", "Kevin S.", ""]]}, {"id": "1908.06951", "submitter": "Zhiyuan He", "authors": "Zhiyuan He, Danchen Lin, Thomas Lau, and Mike Wu", "title": "Gradient Boosting Machine: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this survey, we discuss several different types of gradient boosting\nalgorithms and illustrate their mathematical frameworks in detail: 1.\nintroduction of gradient boosting leads to 2. objective function optimization,\n3. loss function estimations, and 4. model constructions. 5. application of\nboosting in ranking.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:38:33 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["He", "Zhiyuan", ""], ["Lin", "Danchen", ""], ["Lau", "Thomas", ""], ["Wu", "Mike", ""]]}, {"id": "1908.06966", "submitter": "Yao Li", "authors": "Yao Li", "title": "Improve variational autoEncoder with auxiliary softmax multiclassifier", "comments": "15 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a general-purpose generative model architecture, VAE has been widely used\nin the field of image and natural language processing. VAE maps high\ndimensional sample data into continuous latent variables with unsupervised\nlearning. Sampling in the latent variable space of the feature, VAE can\nconstruct new image or text data. As a general-purpose generation model, the\nvanilla VAE can not fit well with various data sets and neural networks with\ndifferent structures. Because of the need to balance the accuracy of\nreconstruction and the convenience of latent variable sampling in the training\nprocess, VAE often has problems known as \"posterior collapse\". images\nreconstructed by VAE are also often blurred. In this paper, we analyze the main\ncause of these problem, which is the lack of mutual information between the\nsample variable and the latent feature variable during the training process. To\nmaintain mutual information in model training, we propose to use the auxiliary\nsoftmax multi-classification network structure to improve the training effect\nof VAE, named VAE-AS. We use MNIST and Omniglot data sets to test the VAE-AS\nmodel. Based on the test results, It can be show that VAE-AS has obvious\neffects on the mutual information adjusting and solving the posterior collapse\nproblem.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 14:36:13 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 06:59:42 GMT"}, {"version": "v3", "created": "Sun, 3 Nov 2019 07:26:13 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Li", "Yao", ""]]}, {"id": "1908.06971", "submitter": "Cuneyt Gurcan Akcora", "authors": "Nazmiye Ceren Abay, Cuneyt Gurcan Akcora, Yulia R. Gel, Umar D.\n  Islambekov, Murat Kantarcioglu, Yahui Tian, Bhavani Thuraisingham", "title": "ChainNet: Learning on Blockchain Graphs with Topological Features", "comments": "To Appear in the 2019 IEEE International Conference on Data Mining\n  (ICDM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.ST stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With emergence of blockchain technologies and the associated\ncryptocurrencies, such as Bitcoin, understanding network dynamics behind\nBlockchain graphs has become a rapidly evolving research direction. Unlike\nother financial networks, such as stock and currency trading, blockchain based\ncryptocurrencies have the entire transaction graph accessible to the public\n(i.e., all transactions can be downloaded and analyzed). A natural question is\nthen to ask whether the dynamics of the transaction graph impacts the price of\nthe underlying cryptocurrency. We show that standard graph features such as\ndegree distribution of the transaction graph may not be sufficient to capture\nnetwork dynamics and its potential impact on fluctuations of Bitcoin price. In\ncontrast, the new graph associated topological features computed using the\ntools of persistent homology, are found to exhibit a high utility for\npredicting Bitcoin price dynamics. %explain higher order interactions among the\nnodes in Blockchain graphs and can be used to build much more accurate price\nprediction models. Using the proposed persistent homology-based techniques, we\noffer a new elegant, easily extendable and computationally light approach for\ngraph representation learning on Blockchain.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 18:55:16 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Abay", "Nazmiye Ceren", ""], ["Akcora", "Cuneyt Gurcan", ""], ["Gel", "Yulia R.", ""], ["Islambekov", "Umar D.", ""], ["Kantarcioglu", "Murat", ""], ["Tian", "Yahui", ""], ["Thuraisingham", "Bhavani", ""]]}, {"id": "1908.07005", "submitter": "Karol Antczak", "authors": "Karol Antczak", "title": "On Regularization Properties of Artificial Datasets for Deep Learning", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper discusses regularization properties of artificial data for deep\nlearning. Artificial datasets allow to train neural networks in the case of a\nreal data shortage. It is demonstrated that the artificial data generation\nprocess, described as injecting noise to high-level features, bears several\nsimilarities to existing regularization methods for deep neural networks. One\ncan treat this property of artificial data as a kind of \"deep\" regularization.\nIt is thus possible to regularize hidden layers of the network by generating\nthe training data in a certain way.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 18:09:07 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Antczak", "Karol", ""]]}, {"id": "1908.07009", "submitter": "Yi Sun", "authors": "Yi Sun, Ivan Ramirez, Alfredo Cuesta-Infante, Kalyan Veeramachaneni", "title": "Towards Reducing Biases in Combining Multiple Experts Online", "comments": "Accepted to IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real life situations, including job and loan applications,\ngatekeepers must make justified and fair real-time decisions about a person's\nfitness for a particular opportunity. In this paper, we aim to accomplish\napproximate group fairness in an online stochastic decision-making process,\nwhere the fairness metric we consider is equalized odds. Our work follows from\nthe classical learning-from-experts scheme, assuming a finite set of\nclassifiers (human experts, rules, options, etc) that cannot be modified. We\nrun separate instances of the algorithm for each label class as well as\nsensitive groups, where the probability of choosing each instance is optimized\nfor both fairness and regret. Our theoretical results show that approximately\nequalized odds can be achieved without sacrificing much regret. We also\ndemonstrate the performance of the algorithm on real data sets commonly used by\nthe fairness community.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 18:17:51 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 20:02:18 GMT"}, {"version": "v3", "created": "Mon, 14 Sep 2020 18:33:53 GMT"}, {"version": "v4", "created": "Mon, 24 May 2021 22:32:26 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Sun", "Yi", ""], ["Ramirez", "Ivan", ""], ["Cuesta-Infante", "Alfredo", ""], ["Veeramachaneni", "Kalyan", ""]]}, {"id": "1908.07023", "submitter": "Stefan Vlaski", "authors": "Stefan Vlaski, Ali H. Sayed", "title": "Second-Order Guarantees of Stochastic Gradient Descent in Non-Convex\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen increased interest in performance guarantees of\ngradient descent algorithms for non-convex optimization. A number of works have\nuncovered that gradient noise plays a critical role in the ability of gradient\ndescent recursions to efficiently escape saddle-points and reach second-order\nstationary points. Most available works limit the gradient noise component to\nbe bounded with probability one or sub-Gaussian and leverage concentration\ninequalities to arrive at high-probability results. We present an alternate\napproach, relying primarily on mean-square arguments and show that a more\nrelaxed relative bound on the gradient noise variance is sufficient to ensure\nefficient escape from saddle-points without the need to inject additional\nnoise, employ alternating step-sizes or rely on a global dispersive noise\nassumption, as long as a gradient noise component is present in a descent\ndirection for every saddle-point.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 18:56:40 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Vlaski", "Stefan", ""], ["Sayed", "Ali H.", ""]]}, {"id": "1908.07026", "submitter": "Melissa Ailem", "authors": "Melissa Ailem, Bowen Zhang, Fei Sha", "title": "Topic Augmented Generator for Abstractive Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steady progress has been made in abstractive summarization with\nattention-based sequence-to-sequence learning models. In this paper, we propose\na new decoder where the output summary is generated by conditioning on both the\ninput text and the latent topics of the document. The latent topics, identified\nby a topic model such as LDA, reveals more global semantic information that can\nbe used to bias the decoder to generate words. In particular, they enable the\ndecoder to have access to additional word co-occurrence statistics captured at\ndocument corpus level. We empirically validate the advantage of the proposed\napproach on both the CNN/Daily Mail and the WikiHow datasets. Concretely, we\nattain strongly improved ROUGE scores when compared to state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:02:14 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Ailem", "Melissa", ""], ["Zhang", "Bowen", ""], ["Sha", "Fei", ""]]}, {"id": "1908.07031", "submitter": "Weipeng Huang", "authors": "Weipeng Huang, Guangyuan Piao, Raul Moreno, Neil J. Hurley", "title": "Partially Observable Markov Decision Process Modelling for Assessing\n  Hierarchies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering has been shown to be valuable in many scenarios.\nDespite its usefulness to many situations, there is no agreed methodology on\nhow to properly evaluate the hierarchies produced from different techniques,\nparticularly in the case where ground-truth labels are unavailable. This\nmotivates us to propose a framework for assessing the quality of hierarchical\nclustering allocations which covers the case of no ground-truth information.\nThis measurement is useful, e.g., to assess the hierarchical structures used by\nonline retailer websites to display their product catalogues. Our framework is\none of the few attempts for the hierarchy evaluation from a decision-theoretic\nperspective. We model the process as a bot searching stochastically for items\nin the hierarchy and establish a measure representing the degree to which the\nhierarchy supports this search. We employ Partially Observable Markov Decision\nProcesses (POMDP) to model the uncertainty, the decision making, and the\ncognitive return for searchers in such a scenario.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:13:27 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 13:56:23 GMT"}, {"version": "v3", "created": "Mon, 29 Jun 2020 17:20:36 GMT"}, {"version": "v4", "created": "Tue, 30 Jun 2020 01:31:59 GMT"}, {"version": "v5", "created": "Tue, 13 Oct 2020 20:35:41 GMT"}, {"version": "v6", "created": "Wed, 4 Nov 2020 13:28:16 GMT"}, {"version": "v7", "created": "Tue, 8 Dec 2020 09:07:39 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Huang", "Weipeng", ""], ["Piao", "Guangyuan", ""], ["Moreno", "Raul", ""], ["Hurley", "Neil J.", ""]]}, {"id": "1908.07061", "submitter": "Mohsen Farhadloo", "authors": "Mohsen Farhadloo (John Molson School of Business Concordia University)", "title": "Twitter Sentiment on Affordable Care Act using Score Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce score embedding, a neural network based model to\nlearn interpretable vector representations for words. Score embedding is a\nsupervised method that takes advantage of the labeled training data and the\nneural network architecture to learn interpretable representations for words.\nHealth care has been a controversial issue between political parties in the\nUnited States. In this paper we use the discussions on Twitter regarding\ndifferent issues of affordable care act to identify the public opinion about\nthe existing health care plans using the proposed score embedding. Our results\nindicate our approach effectively incorporates the sentiment information and\noutperforms or is at least comparable to the state-of-the-art methods and the\nnegative sentiment towards \"TrumpCare\" was consistently greater than neutral\nand positive sentiment over time.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 20:55:52 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Farhadloo", "Mohsen", "", "John Molson School of Business Concordia University"]]}, {"id": "1908.07063", "submitter": "Xuanlin Liu", "authors": "Xuanlin Liu, Mingzhe Chen, Changchuan Yin, Walid Saad", "title": "Analysis of Memory Capacity for Deep Echo State Networks", "comments": "6 pages, 8 figures, Published in 2018 17th IEEE International\n  Conference on Machine Learning and Applications (ICMLA)", "journal-ref": null, "doi": "10.1109/ICMLA.2018.00072", "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the echo state network (ESN) memory capacity, which represents\nthe amount of input data an ESN can store, is analyzed for a new type of deep\nESNs. In particular, two deep ESN architectures are studied. First, a parallel\ndeep ESN is proposed in which multiple reservoirs are connected in parallel\nallowing them to average outputs of multiple ESNs, thus decreasing the\nprediction error. Then, a series architecture ESN is proposed in which ESN\nreservoirs are placed in cascade that the output of each ESN is the input of\nthe next ESN in the series. This series ESN architecture can capture more\nfeatures between the input sequence and the output sequence thus improving the\noverall prediction accuracy. Fundamental analysis shows that the memory\ncapacity of parallel ESNs is equivalent to that of a traditional shallow ESN,\nwhile the memory capacity of series ESNs is smaller than that of a traditional\nshallow ESN.In terms of normalized root mean square error, simulation results\nshow that the parallel deep ESN achieves 38.5% reduction compared to the\ntraditional shallow ESN while the series deep ESN achieves 16.8% reduction.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 09:16:54 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Liu", "Xuanlin", ""], ["Chen", "Mingzhe", ""], ["Yin", "Changchuan", ""], ["Saad", "Walid", ""]]}, {"id": "1908.07064", "submitter": "Praveen Kumar Bodigutla", "authors": "Praveen Kumar Bodigutla, Longshaokan Wang, Kate Ridgeway, Joshua Levy,\n  Swanand Joshi, Alborz Geramifard, Spyros Matsoukas", "title": "Domain-Independent turn-level Dialogue Quality Evaluation via User\n  Satisfaction Estimation", "comments": "Implications of Deep Learning for Dialog Modeling - Special session\n  at SIGdial 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An automated metric to evaluate dialogue quality is vital for optimizing data\ndriven dialogue management. The common approach of relying on explicit user\nfeedback during a conversation is intrusive and sparse. Current models to\nestimate user satisfaction use limited feature sets and rely on annotation\nschemes with low inter-rater reliability, limiting generalizability to\nconversations spanning multiple domains. To address these gaps, we created a\nnew Response Quality annotation scheme, based on which we developed turn-level\nUser Satisfaction metric. We introduced five new domain-independent feature\nsets and experimented with six machine learning models to estimate the new\nsatisfaction metric.\n  Using Response Quality annotation scheme, across randomly sampled single and\nmulti-turn conversations from 26 domains, we achieved high inter-annotator\nagreement (Spearman's rho 0.94). The Response Quality labels were highly\ncorrelated (0.76) with explicit turn-level user ratings. Gradient boosting\nregression achieved best correlation of ~0.79 between predicted and annotated\nuser satisfaction labels. Multi Layer Perceptron and Gradient Boosting\nregression models generalized to an unseen domain better (linear correlation\n0.67) than other models. Finally, our ablation study verified that our novel\nfeatures significantly improved model performance.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 20:58:24 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Bodigutla", "Praveen Kumar", ""], ["Wang", "Longshaokan", ""], ["Ridgeway", "Kate", ""], ["Levy", "Joshua", ""], ["Joshi", "Swanand", ""], ["Geramifard", "Alborz", ""], ["Matsoukas", "Spyros", ""]]}, {"id": "1908.07078", "submitter": "Arman Hasanzadeh Moghimi", "authors": "Arman Hasanzadeh, Ehsan Hajiramezanali, Nick Duffield, Krishna R.\n  Narayanan, Mingyuan Zhou, Xiaoning Qian", "title": "Semi-Implicit Graph Variational Auto-Encoders", "comments": "Accepted to Advances in Neural Information Processing Systems\n  (NeurIPS 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-implicit graph variational auto-encoder (SIG-VAE) is proposed to expand\nthe flexibility of variational graph auto-encoders (VGAE) to model graph data.\nSIG-VAE employs a hierarchical variational framework to enable neighboring node\nsharing for better generative modeling of graph dependency structure, together\nwith a Bernoulli-Poisson link decoder. Not only does this hierarchical\nconstruction provide a more flexible generative graph model to better capture\nreal-world graph properties, but also does SIG-VAE naturally lead to\nsemi-implicit hierarchical variational inference that allows faithful modeling\nof implicit posteriors of given graph data, which may exhibit heavy tails,\nmultiple modes, skewness, and rich dependency structures. Compared to VGAE, the\nderived graph latent representations by SIG-VAE are more interpretable, due to\nmore expressive generative model and more faithful inference enabled by the\nflexible semi-implicit construction. Extensive experiments with a variety of\ngraph data show that SIG-VAE significantly outperforms state-of-the-art methods\non several different graph analytic tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 21:33:37 GMT"}, {"version": "v2", "created": "Sun, 25 Aug 2019 22:06:14 GMT"}, {"version": "v3", "created": "Sat, 7 Sep 2019 16:55:49 GMT"}, {"version": "v4", "created": "Wed, 22 Apr 2020 06:03:58 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Hasanzadeh", "Arman", ""], ["Hajiramezanali", "Ehsan", ""], ["Duffield", "Nick", ""], ["Narayanan", "Krishna R.", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1908.07100", "submitter": "Benjamin Campbell", "authors": "Benjamin Campbell", "title": "Alliances and Conflict, or Conflict and Alliances? Appraising the Causal\n  Effect of Alliances on Conflict", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The deterrent effect of military alliances is well documented and widely\naccepted. However, such work has typically assumed that alliances are\nexogenous. This is problematic as alliances may simultaneously influence the\nprobability of conflict and be influenced by the probability of conflict.\nFailing to account for such endogeneity produces overly simplistic theories of\nalliance politics and barriers to identifying the causal effect of alliances on\nconflict. In this manuscript, I propose a solution to this theoretical and\nempirical modeling challenge. Synthesizing theories of alliance formation and\nthe alliance-conflict relationship, I innovate an endogenous theory of\nalliances and conflict. I then test this theory using innovative generalized\njoint regression models that allow me to endogenize alliance formation on the\ncausal path to conflict. Once doing so, I ultimately find that alliances\nneither deter nor provoke aggression. This has significant implications for our\nunderstanding of interstate conflict and alliance politics.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 23:03:32 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Campbell", "Benjamin", ""]]}, {"id": "1908.07107", "submitter": "Debanjan Borthakur", "authors": "Debanjan Borthakur, Victoria Grace, Paul Batchelor, Harishchandra\n  Dubey, Kunal Mankodiya", "title": "Fuzzy C-Means Clustering and Sonification of HRV Features", "comments": "5 pages, 5 figures", "journal-ref": "2019 the IEEE/ACM 4th International Conference on Connected\n  Health: Applications, Systems and Engineering Technologies: EdgeDL\n  WorkshopAt: Washington, D.C, sep- 25-27", "doi": null, "report-no": null, "categories": "cs.HC cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear and non-linear measures of heart rate variability (HRV) are widely\ninvestigated as non-invasive indicators of health. Stress has a profound impact\non heart rate, and different meditation techniques have been found to modulate\nheartbeat rhythm. This paper aims to explore the process of identifying\nappropriate metrices from HRV analysis for sonification. Sonification is a type\nof auditory display involving the process of mapping data to acoustic\nparameters. This work explores the use of auditory display in aiding the\nanalysis of HRV leveraged by unsupervised machine learning techniques.\nUnsupervised clustering helps select the appropriate features to improve the\nsonification interpretability. Vocal synthesis sonification techniques are\nemployed to increase comprehension and learnability of the processed data\ndisplayed through sound. These analyses are early steps in building a real-time\nsound-based biofeedback training system.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 23:44:01 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 21:47:27 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Borthakur", "Debanjan", ""], ["Grace", "Victoria", ""], ["Batchelor", "Paul", ""], ["Dubey", "Harishchandra", ""], ["Mankodiya", "Kunal", ""]]}, {"id": "1908.07110", "submitter": "Yichuan Li", "authors": "Kaize Ding, Yichuan Li, Jundong Li, Chenghao Liu and Huan Liu", "title": "Feature Interaction-aware Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the immense success of deep learning, graph neural networks\n(GNNs) are widely used to learn powerful node representations and have\ndemonstrated promising performance on different graph learning tasks. However,\nmost real-world graphs often come with high-dimensional and sparse node\nfeatures, rendering the learned node representations from existing GNN\narchitectures less expressive. In this paper, we propose \\textit{Feature\nInteraction-aware Graph Neural Networks (FI-GNNs)}, a plug-and-play GNN\nframework for learning node representations encoded with informative feature\ninteractions. Specifically, the proposed framework is able to highlight\ninformative feature interactions in a personalized manner and further learn\nhighly expressive node representations on feature-sparse graphs. Extensive\nexperiments on various datasets demonstrate the superior capability of FI-GNNs\nfor graph learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 23:54:28 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 22:13:07 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Ding", "Kaize", ""], ["Li", "Yichuan", ""], ["Li", "Jundong", ""], ["Liu", "Chenghao", ""], ["Liu", "Huan", ""]]}, {"id": "1908.07116", "submitter": "Xiao Wang", "authors": "Xiao Wang, Siyue Wang, Pin-Yu Chen, Yanzhi Wang, Brian Kulis, Xue Lin\n  and Peter Chin", "title": "Protecting Neural Networks with Hierarchical Random Switching: Towards\n  Better Robustness-Accuracy Trade-off for Stochastic Defenses", "comments": "Published as Conference Paper @ IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite achieving remarkable success in various domains, recent studies have\nuncovered the vulnerability of deep neural networks to adversarial\nperturbations, creating concerns on model generalizability and new threats such\nas prediction-evasive misclassification or stealthy reprogramming. Among\ndifferent defense proposals, stochastic network defenses such as random neuron\nactivation pruning or random perturbation to layer inputs are shown to be\npromising for attack mitigation. However, one critical drawback of current\ndefenses is that the robustness enhancement is at the cost of noticeable\nperformance degradation on legitimate data, e.g., large drop in test accuracy.\nThis paper is motivated by pursuing for a better trade-off between adversarial\nrobustness and test accuracy for stochastic network defenses. We propose\nDefense Efficiency Score (DES), a comprehensive metric that measures the gain\nin unsuccessful attack attempts at the cost of drop in test accuracy of any\ndefense. To achieve a better DES, we propose hierarchical random switching\n(HRS), which protects neural networks through a novel randomization scheme. A\nHRS-protected model contains several blocks of randomly switching channels to\nprevent adversaries from exploiting fixed model structures and parameters for\ntheir malicious purposes. Extensive experiments show that HRS is superior in\ndefending against state-of-the-art white-box and adaptive adversarial\nmisclassification attacks. We also demonstrate the effectiveness of HRS in\ndefending adversarial reprogramming, which is the first defense against\nadversarial programs. Moreover, in most settings the average DES of HRS is at\nleast 5X higher than current stochastic network defenses, validating its\nsignificantly improved robustness-accuracy trade-off.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 00:29:23 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Wang", "Xiao", ""], ["Wang", "Siyue", ""], ["Chen", "Pin-Yu", ""], ["Wang", "Yanzhi", ""], ["Kulis", "Brian", ""], ["Lin", "Xue", ""], ["Chin", "Peter", ""]]}, {"id": "1908.07136", "submitter": "Yixiao Li", "authors": "Yixiao Li, Gloria Lin, Thomas Lau, Ruochen Zeng", "title": "A Review of Changepoint Detection Models", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the change-point detection is to discover the abrupt\nproperty changes lying behind the time-series data. In this paper, we firstly\nsummarize the definition and in-depth implication of the changepoint detection.\nThe next stage is to elaborate traditional and some alternative model-based\nchangepoint detection algorithms. Finally, we try to go a bit further in the\ntheory and look into future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 02:58:49 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Li", "Yixiao", ""], ["Lin", "Gloria", ""], ["Lau", "Thomas", ""], ["Zeng", "Ruochen", ""]]}, {"id": "1908.07190", "submitter": "Srikanth Tamilselvam", "authors": "Srikanth G Tamilselvam, Ankush Gupta, Arvind Agarwal", "title": "Compliance Change Tracking in Business Process Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regulatory compliance is an organization's adherence to laws, regulations,\nguidelines and specifications relevant to its business. Compliance officers\nresponsible for maintaining adherence constantly struggle to keep up with the\nlarge amount of changes in regulatory requirements. Keeping up with the changes\nentail two main tasks: fetching the regulatory announcements that actually\ncontain changes of interest, and incorporating those changes in the business\nprocess. In this paper we focus on the first task, and present a Compliance\nChange Tracking System, that gathers regulatory announcements from government\nsites, news sites, email subscriptions; classifies their importance i.e\nActionability through a hierarchical classifier, and business process\napplicability through a multi-class classifier. For these classifiers, we\nexperiment with several approaches such as vanilla classification methods (e.g.\nNaive Bayes, logistic regression etc.), hierarchical classification methods,\nrule based approach, hybrid approach with various preprocessing and feature\nselection methods; and show that despite the richness of other models, a simple\nhierarchical classification with bag-of-words features works the best for\nActionability classifier and multi-class logistic regression works the best for\nApplicability classifier. The system has been deployed in global delivery\ncenters, and has received positive feedback from payroll compliance officers.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 06:49:06 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Tamilselvam", "Srikanth G", ""], ["Gupta", "Ankush", ""], ["Agarwal", "Arvind", ""]]}, {"id": "1908.07193", "submitter": "Nicolo Colombo", "authors": "Nicolo Colombo, Ricardo Silva, Soong M Kang, Arthur Gretton", "title": "Counterfactual Distribution Regression for Structured Inference", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider problems in which a system receives external \\emph{perturbations}\nfrom time to time. For instance, the system can be a train network in which\nparticular lines are repeatedly disrupted without warning, having an effect on\npassenger behavior. The goal is to predict changes in the behavior of the\nsystem at particular points of interest, such as passenger traffic around\nstations at the affected rails. We assume that the data available provides\nrecords of the system functioning at its \"natural regime\" (e.g., the train\nnetwork without disruptions) and data on cases where perturbations took place.\nThe inference problem is how information concerning perturbations, with\nparticular covariates such as location and time, can be generalized to predict\nthe effect of novel perturbations. We approach this problem from the point of\nview of a mapping from the counterfactual distribution of the system behavior\nwithout disruptions to the distribution of the disrupted system. A variant on\n\\emph{distribution regression} is developed for this setup.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 07:13:01 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Colombo", "Nicolo", ""], ["Silva", "Ricardo", ""], ["Kang", "Soong M", ""], ["Gretton", "Arthur", ""]]}, {"id": "1908.07220", "submitter": "Ingvild Margrethe Helg{\\o}y", "authors": "Ingvild M. Helg{\\o}y and Yushu Li", "title": "A Noise-Robust Fast Sparse Bayesian Learning Model", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper utilizes the hierarchical model structure from the Bayesian Lasso\nin the Sparse Bayesian Learning process to develop a new type of probabilistic\nsupervised learning approach. The hierarchical model structure in this Bayesian\nframework is designed such that the priors do not only penalize the unnecessary\ncomplexity of the model but will also be conditioned on the variance of the\nrandom noise in the data. The hyperparameters in the model are estimated by the\nFast Marginal Likelihood Maximization algorithm which can achieve sparsity, low\ncomputational cost and faster learning process. We compare our methodology with\ntwo other popular learning models; the Relevance Vector Machine and the\nBayesian Lasso. We test our model on examples involving both simulated and\nempirical data, and the results show that this approach has several performance\nadvantages, such as being fast, sparse and also robust to the variance in\nrandom noise. In addition, our method can give out a more stable estimation of\nvariance of random error, compared with the other methods in the study.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 08:36:14 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 10:06:26 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Helg\u00f8y", "Ingvild M.", ""], ["Li", "Yushu", ""]]}, {"id": "1908.07235", "submitter": "Tiago Ramalho", "authors": "Tiago Ramalho, Miguel Miranda", "title": "Density estimation in representation space to predict model uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models frequently make incorrect predictions with high\nconfidence when presented with test examples that are not well represented in\ntheir training dataset. We propose a novel and straightforward approach to\nestimate prediction uncertainty in a pre-trained neural network model. Our\nmethod estimates the training data density in representation space for a novel\ninput. A neural network model then uses this information to determine whether\nwe expect the pre-trained model to make a correct prediction. This uncertainty\nmodel is trained by predicting in-distribution errors, but can detect\nout-of-distribution data without having seen any such example. We test our\nmethod for a state-of-the art image classification model in the settings of\nboth in-distribution uncertainty estimation as well as out-of-distribution\ndetection.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 09:21:14 GMT"}, {"version": "v2", "created": "Thu, 3 Oct 2019 06:27:40 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Ramalho", "Tiago", ""], ["Miranda", "Miguel", ""]]}, {"id": "1908.07253", "submitter": "Michel Moukari", "authors": "Michel Moukari, Lo\\\"ic Simon, Sylvaine Picard, Fr\\'ed\\'eric Jurie", "title": "n-MeRCI: A new Metric to Evaluate the Correlation Between Predictive\n  Uncertainty and True Error", "comments": null, "journal-ref": "IEEE/RJS International Conference on Intelligent Robots and\n  Systems (IROS), In press", "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep learning applications are becoming more and more pervasive in\nrobotics, the question of evaluating the reliability of inferences becomes a\ncentral question in the robotics community. This domain, known as predictive\nuncertainty, has come under the scrutiny of research groups developing Bayesian\napproaches adapted to deep learning such as Monte Carlo Dropout. Unfortunately,\nfor the time being, the real goal of predictive uncertainty has been swept\nunder the rug. Indeed, these approaches are solely evaluated in terms of raw\nperformance of the network prediction, while the quality of their estimated\nuncertainty is not assessed. Evaluating such uncertainty prediction quality is\nespecially important in robotics, as actions shall depend on the confidence in\nperceived information. In this context, the main contribution of this article\nis to propose a novel metric that is adapted to the evaluation of relative\nuncertainty assessment and directly applicable to regression with deep neural\nnetworks. To experimentally validate this metric, we evaluate it on a toy\ndataset and then apply it to the task of monocular depth estimation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 09:51:08 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Moukari", "Michel", ""], ["Simon", "Lo\u00efc", ""], ["Picard", "Sylvaine", ""], ["Jurie", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1908.07307", "submitter": "Gang Hu", "authors": "Gang Hu, Lingbo Liu, Dacheng Tao, Jie Song, and K.C.S. Kwok", "title": "Investigation of wind pressures on tall building under interference\n  effects using machine learning techniques", "comments": "15 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interference effects of tall buildings have attracted numerous studies due to\nthe boom of clusters of tall buildings in megacities. To fully understand the\ninterference effects of buildings, it often requires a substantial amount of\nwind tunnel tests. Limited wind tunnel tests that only cover part of\ninterference scenarios are unable to fully reveal the interference effects.\nThis study used machine learning techniques to resolve the conflicting\nrequirement between limited wind tunnel tests that produce unreliable results\nand a completed investigation of the interference effects that is costly and\ntime-consuming. Four machine learning models including decision tree, random\nforest, XGBoost, generative adversarial networks (GANs), were trained based on\n30% of a dataset to predict both mean and fluctuating pressure coefficients on\nthe principal building. The GANs model exhibited the best performance in\npredicting these pressure coefficients. A number of GANs models were then\ntrained based on different portions of the dataset ranging from 10% to 90%. It\nwas found that the GANs model based on 30% of the dataset is capable of\npredicting both mean and fluctuating pressure coefficients under unseen\ninterference conditions accurately. By using this GANs model, 70% of the wind\ntunnel test cases can be saved, largely alleviating the cost of this kind of\nwind tunnel testing study.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 12:46:27 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Hu", "Gang", ""], ["Liu", "Lingbo", ""], ["Tao", "Dacheng", ""], ["Song", "Jie", ""], ["Kwok", "K. C. S.", ""]]}, {"id": "1908.07319", "submitter": "Hassan Ismail Fawaz", "authors": "Hassan Ismail Fawaz, Germain Forestier, Jonathan Weber, Lhassane\n  Idoumghar, Pierre-Alain Muller", "title": "Accurate and interpretable evaluation of surgical skills from kinematic\n  data using fully convolutional neural networks", "comments": "Accepted at IJCARS Special Issue for MICCAI 2018", "journal-ref": null, "doi": "10.1007/s11548-019-02039-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: Manual feedback from senior surgeons observing less experienced\ntrainees is a laborious task that is very expensive, time-consuming and prone\nto subjectivity. With the number of surgical procedures increasing annually,\nthere is an unprecedented need to provide an accurate, objective and automatic\nevaluation of trainees' surgical skills in order to improve surgical practice.\nMethods: In this paper, we designed a convolutional neural network (CNN) to\nclassify surgical skills by extracting latent patterns in the trainees' motions\nperformed during robotic surgery. The method is validated on the JIGSAWS\ndataset for two surgical skills evaluation tasks: classification and\nregression. Results: Our results show that deep neural networks constitute\nrobust machine learning models that are able to reach new competitive\nstate-of-the-art performance on the JIGSAWS dataset. While we leveraged from\nCNNs' efficiency, we were able to minimize its black-box effect using the class\nactivation map technique. Conclusions: This characteristic allowed our method\nto automatically pinpoint which parts of the surgery influenced the skill\nevaluation the most, thus allowing us to explain a surgical skill\nclassification and provide surgeons with a novel personalized feedback\ntechnique. We believe this type of interpretable machine learning model could\nintegrate within \"Operation Room 2.0\" and support novice surgeons in improving\ntheir skills to eventually become experts.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 13:04:05 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Fawaz", "Hassan Ismail", ""], ["Forestier", "Germain", ""], ["Weber", "Jonathan", ""], ["Idoumghar", "Lhassane", ""], ["Muller", "Pierre-Alain", ""]]}, {"id": "1908.07329", "submitter": "Daniel Canedo", "authors": "Daniel Rosa Can\\^edo and Alexandre Ricardo Soares Romariz", "title": "Data Analysis of Wireless Networks Using Classification Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last decade, there has been a great technological advance in the\ninfrastructure of mobile technologies. The increase in the use of wireless\nlocal area networks and the use of satellite services are also noticed. The\nhigh utilization rate of mobile devices for various purposes makes clear the\nneed to track wireless networks to ensure the integrity and confidentiality of\nthe information transmitted. Therefore, it is necessary to quickly and\nefficiently identify the normal and abnormal traffic of such networks, so that\nadministrators can take action. This work aims to analyze classification\ntechniques in relation to data from Wireless Networks, using some classes of\nanomalies pre-established according to some defined criteria of the MAC layer.\nFor data analysis, WEKA Data Mining software (Waikato Environment for Knowledge\nAnalysis) is used. The classification algorithms present a success rate in the\nclassification of viable data, being indicated in the use of intrusion\ndetection systems for wireless networks.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 22:16:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Can\u00eado", "Daniel Rosa", ""], ["Romariz", "Alexandre Ricardo Soares", ""]]}, {"id": "1908.07355", "submitter": "Mauricio Orbes Arteaga", "authors": "Mauricio Orbes-Arteaga and Jorge Cardoso and Lauge S{\\o}rensen and\n  Christian Igel and Sebastien Ourselin and Marc Modat and Mads Nielsen and\n  Akshay Pai", "title": "Knowledge distillation for semi-supervised domain adaptation", "comments": "MLCN MICCAI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the absence of sufficient data variation (e.g., scanner and protocol\nvariability) in annotated data, deep neural networks (DNNs) tend to overfit\nduring training. As a result, their performance is significantly lower on data\nfrom unseen sources compared to the performance on data from the same source as\nthe training data. Semi-supervised domain adaptation methods can alleviate this\nproblem by tuning networks to new target domains without the need for annotated\ndata from these domains. Adversarial domain adaptation (ADA) methods are a\npopular choice that aim to train networks in such a way that the features\ngenerated are domain agnostic. However, these methods require careful\ndataset-specific selection of hyperparameters such as the complexity of the\ndiscriminator in order to achieve a reasonable performance. We propose to use\nknowledge distillation (KD) -- an efficient way of transferring knowledge\nbetween different DNNs -- for semi-supervised domain adaption of DNNs. It does\nnot require dataset-specific hyperparameter tuning, making it generally\napplicable. The proposed method is compared to ADA for segmentation of white\nmatter hyperintensities (WMH) in magnetic resonance imaging (MRI) scans\ngenerated by scanners that are not a part of the training set. Compared with\nboth the baseline DNN (trained on source domain only and without any adaption\nto target domain) and with using ADA for semi-supervised domain adaptation, the\nproposed method achieves significantly higher WMH dice scores.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 11:39:49 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Orbes-Arteaga", "Mauricio", ""], ["Cardoso", "Jorge", ""], ["S\u00f8rensen", "Lauge", ""], ["Igel", "Christian", ""], ["Ourselin", "Sebastien", ""], ["Modat", "Marc", ""], ["Nielsen", "Mads", ""], ["Pai", "Akshay", ""]]}, {"id": "1908.07371", "submitter": "Zitao Liu", "authors": "Zitao Liu, Zhexuan Xu, Yan Yan", "title": "Hierarchical Bayesian Personalized Recommendation: A Case Study and\n  Beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Items in modern recommender systems are often organized in hierarchical\nstructures. These hierarchical structures and the data within them provide\nvaluable information for building personalized recommendation systems. In this\npaper, we propose a general hierarchical Bayesian learning framework, i.e.,\n\\emph{HBayes}, to learn both the structures and associated latent factors.\nFurthermore, we develop a variational inference algorithm that is able to learn\nmodel parameters with fast empirical convergence rate. The proposed HBayes is\nevaluated on two real-world datasets from different domains. The results\ndemonstrate the benefits of our approach on item recommendation tasks, and show\nthat it can outperform the state-of-the-art models in terms of precision,\nrecall, and normalized discounted cumulative gain. To encourage the\nreproducible results, we make our code public on a git repo:\n\\url{https://tinyurl.com/ycruhk4t}.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 14:10:17 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Liu", "Zitao", ""], ["Xu", "Zhexuan", ""], ["Yan", "Yan", ""]]}, {"id": "1908.07377", "submitter": "David Eklund", "authors": "David Eklund, S{\\o}ren Hauberg", "title": "Expected path length on random manifolds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manifold learning seeks a low dimensional representation that faithfully\ncaptures the essence of data. Current methods can successfully learn such\nrepresentations, but do not provide a meaningful set of operations that are\nassociated with the representation. Working towards operational representation\nlearning, we endow the latent space of a large class of generative models with\na random Riemannian metric, which provides us with elementary operators. As\ncomputational tools are unavailable for random Riemannian manifolds, we study\ndeterministic approximations and derive tight error bounds on expected\ndistances.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 14:14:43 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Eklund", "David", ""], ["Hauberg", "S\u00f8ren", ""]]}, {"id": "1908.07380", "submitter": "Omar Rivasplata", "authors": "Omar Rivasplata, Vikram M Tankasali, Csaba Szepesvari", "title": "PAC-Bayes with Backprop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the family of methods \"PAC-Bayes with Backprop\" (PBB) to train\nprobabilistic neural networks by minimizing PAC-Bayes bounds. We present two\ntraining objectives, one derived from a previously known PAC-Bayes bound, and a\nsecond one derived from a novel PAC-Bayes bound. Both training objectives are\nevaluated on MNIST and on various UCI data sets. Our experiments show two\nstriking observations: we obtain competitive test set error estimates (~1.4% on\nMNIST) and at the same time we compute non-vacuous bounds with much tighter\nvalues (~2.3% on MNIST) than previous results. These observations suggest that\nneural nets trained by PBB may lead to self-bounding learning, where the\navailable data can be used to simultaneously learn a predictor and certify its\nrisk, with no need to follow a data-splitting protocol.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 13:27:08 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 10:18:05 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 08:16:40 GMT"}, {"version": "v4", "created": "Mon, 30 Sep 2019 12:32:30 GMT"}, {"version": "v5", "created": "Fri, 4 Oct 2019 17:23:16 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Rivasplata", "Omar", ""], ["Tankasali", "Vikram M", ""], ["Szepesvari", "Csaba", ""]]}, {"id": "1908.07414", "submitter": "Rishabh Misra", "authors": "Rishabh Misra, Prahal Arora", "title": "Sarcasm Detection using Hybrid Neural Network", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.32427.39204", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Sarcasm Detection has enjoyed great interest from the research community,\nhowever the task of predicting sarcasm in a text remains an elusive problem for\nmachines. Past studies mostly make use of twitter datasets collected using\nhashtag based supervision but such datasets are noisy in terms of labels and\nlanguage. To overcome these shortcoming, we introduce a new dataset which\ncontains news headlines from a sarcastic news website and a real news website.\nNext, we propose a hybrid Neural Network architecture with attention mechanism\nwhich provides insights about what actually makes sentences sarcastic. Through\nexperiments, we show that the proposed model improves upon the baseline by ~ 5%\nin terms of classification accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:10:31 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Misra", "Rishabh", ""], ["Arora", "Prahal", ""]]}, {"id": "1908.07420", "submitter": "Antonio Ferrara", "authors": "Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, Antonio Ferrara", "title": "Towards Effective Device-Aware Federated Learning", "comments": "12 pages, AIIA 2019, 18th International Conference of the Italian\n  Association for Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wealth of information produced by social networks, smartphones,\nmedical or financial applications, speculations have been raised about the\nsensitivity of such data in terms of users' personal privacy and data security.\nTo address the above issues, Federated Learning (FL) has been recently proposed\nas a means to leave data and computational resources distributed over a large\nnumber of nodes (clients) where a central coordinating server aggregates only\nlocally computed updates without knowing the original data. In this work, we\nextend the FL framework by pushing forward the state the art in the field on\nseveral dimensions: (i) unlike the original FedAvg approach relying solely on\nsingle criteria (i.e., local dataset size), a suite of domain- and\nclient-specific criteria constitute the basis to compute each local client's\ncontribution, (ii) the multi-criteria contribution of each device is computed\nin a prioritized fashion by leveraging a priority-aware aggregation operator\nused in the field of information retrieval, and (iii) a mechanism is proposed\nfor online-adjustment of the aggregation operator parameters via a local search\nstrategy with backtracking. Extensive experiments on a publicly available\ndataset indicate the merits of the proposed approach compared to standard\nFedAvg baseline.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:12:59 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Ferrara", "Antonio", ""]]}, {"id": "1908.07428", "submitter": "Gautam Kumar", "authors": "Benjamin Plaster and Gautam Kumar", "title": "Data-Driven Predictive Modeling of Neuronal Dynamics using Long\n  Short-Term Memory", "comments": "35 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling brain dynamics to better understand and control complex behaviors\nunderlying various cognitive brain functions are of interests to engineers,\nmathematicians, and physicists from the last several decades. With a motivation\nof developing computationally efficient models of brain dynamics to use in\ndesigning control-theoretic neurostimulation strategies, we have developed a\nnovel data-driven approach in a long short-term memory (LSTM) neural network\narchitecture to predict the temporal dynamics of complex systems over an\nextended long time-horizon in future. In contrast to recent LSTM-based\ndynamical modeling approaches that make use of multi-layer perceptrons or\nlinear combination layers as output layers, our architecture uses a single\nfully connected output layer and reversed-order sequence-to-sequence mapping to\nimprove short time-horizon prediction accuracy and to make multi-timestep\npredictions of dynamical behaviors. We demonstrate the efficacy of our approach\nin reconstructing the regular spiking to bursting dynamics exhibited by an\nexperimentally-validated 9-dimensional Hodgkin-Huxley model of hippocampal CA1\npyramidal neurons. Through simulations, we show that our LSTM neural network\ncan predict the multi-time scale temporal dynamics underlying various spiking\npatterns with reasonable accuracy. Moreover, our results show that the\npredictions improve with increasing predictive time-horizon in the\nmulti-timestep deep LSTM neural network.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 17:36:46 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Plaster", "Benjamin", ""], ["Kumar", "Gautam", ""]]}, {"id": "1908.07442", "submitter": "Sercan Arik", "authors": "Sercan O. Arik and Tomas Pfister", "title": "TabNet: Attentive Interpretable Tabular Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel high-performance and interpretable canonical deep tabular\ndata learning architecture, TabNet. TabNet uses sequential attention to choose\nwhich features to reason from at each decision step, enabling interpretability\nand more efficient learning as the learning capacity is used for the most\nsalient features. We demonstrate that TabNet outperforms other neural network\nand decision tree variants on a wide range of non-performance-saturated tabular\ndatasets and yields interpretable feature attributions plus insights into the\nglobal model behavior. Finally, for the first time to our knowledge, we\ndemonstrate self-supervised learning for tabular data, significantly improving\nperformance with unsupervised representation learning when unlabeled data is\nabundant.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:46:53 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 20:37:43 GMT"}, {"version": "v3", "created": "Thu, 26 Sep 2019 00:59:17 GMT"}, {"version": "v4", "created": "Fri, 14 Feb 2020 18:37:55 GMT"}, {"version": "v5", "created": "Wed, 9 Dec 2020 05:00:33 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Arik", "Sercan O.", ""], ["Pfister", "Tomas", ""]]}, {"id": "1908.07463", "submitter": "Kobi Cohen", "authors": "Tomer Sery and Kobi Cohen", "title": "On Analog Gradient Descent Learning over Multiple Access Fading Channels", "comments": "32 pages, 6 figures", "journal-ref": null, "doi": "10.1109/TSP.2020.2989580", "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed learning problem over multiple access channel (MAC)\nusing a large wireless network. The computation is made by the network edge and\nis based on received data from a large number of distributed nodes which\ntransmit over a noisy fading MAC. The objective function is a sum of the nodes'\nlocal loss functions. This problem has attracted a growing interest in\ndistributed sensing systems, and more recently in federated learning. We\ndevelop a novel Gradient-Based Multiple Access (GBMA) algorithm to solve the\ndistributed learning problem over MAC. Specifically, the nodes transmit an\nanalog function of the local gradient using common shaping waveforms and the\nnetwork edge receives a superposition of the analog transmitted signals used\nfor updating the estimate. GBMA does not require power control or beamforming\nto cancel the fading effect as in other algorithms, and operates directly with\nnoisy distorted gradients. We analyze the performance of GBMA theoretically,\nand prove that it can approach the convergence rate of the centralized gradient\ndescent (GD) algorithm in large networks. Specifically, we establish a\nfinite-sample bound of the error for both convex and strongly convex loss\nfunctions with Lipschitz gradient. Furthermore, we provide energy scaling laws\nfor approaching the centralized convergence rate as the number of nodes\nincreases. Finally, experimental results support the theoretical findings, and\ndemonstrate strong performance of GBMA using synthetic and real data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 16:03:23 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Sery", "Tomer", ""], ["Cohen", "Kobi", ""]]}, {"id": "1908.07465", "submitter": "Sean Yang", "authors": "Sean Yang, Po-shen Lee, Jevin D. West, Bill Howe", "title": "Delineating Knowledge Domains in the Scientific Literature Using Visual\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Figures are an important channel for scientific communication, used to\nexpress complex ideas, models and data in ways that words cannot. However, this\nvisual information is mostly ignored in analyses of the scientific literature.\nIn this paper, we demonstrate the utility of using scientific figures as\nmarkers of knowledge domains in science, which can be used for classification,\nrecommender systems, and studies of scientific information exchange. We encode\nsets of images into a visual signature, then use distances between these\nsignatures to understand how patterns of visual communication compare with\npatterns of jargon and citation structures. We find that figures can be as\neffective for differentiating communities of practice as text or citation\npatterns. We then consider where these metrics disagree to understand how\ndifferent disciplines use visualization to express ideas. Finally, we further\nconsider how specific figure types propagate through the literature, suggesting\na new mechanism for understanding the flow of ideas apart from conventional\nchannels of text and citations. Our ultimate aim is to better leverage these\ninformation-dense objects to improve scientific communication across\ndisciplinary boundaries.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 17:21:48 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Yang", "Sean", ""], ["Lee", "Po-shen", ""], ["West", "Jevin D.", ""], ["Howe", "Bill", ""]]}, {"id": "1908.07483", "submitter": "Cheng Wan", "authors": "Cheng Wan, Andrew W. McHill, Elizabeth Klerman, Akane Sano", "title": "Sensor-Based Estimation of Dim Light Melatonin Onset (DLMO) Using\n  Features of Two Time Scales", "comments": "16 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circadian rhythms influence multiple essential biological activities\nincluding sleep, performance, and mood. The dim light melatonin onset (DLMO) is\nthe gold standard for measuring human circadian phase (i.e., timing). The\ncollection of DLMO is expensive and time-consuming since multiple saliva or\nblood samples are required overnight in special conditions, and the samples\nmust then be assayed for melatonin. Recently, several computational approaches\nhave been designed for estimating DLMO. These methods collect daily sampled\ndata (e.g., sleep onset/offset times) or frequently sampled data (e.g., light\nexposure/skin temperature/physical activity collected every minute) to train\nlearning models for estimating DLMO. One limitation of these studies is that\nthey only leverage one time-scale data. We propose a two-step framework for\nestimating DLMO using data from both time scales. The first step summarizes\ndata from before the current day, while the second step combines this summary\nwith frequently sampled data of the current day. We evaluate three moving\naverage models that input sleep timing data as the first step and use recurrent\nneural network models as the second step. The results using data from 207\nundergraduates show that our two-step model with two time-scale features has\nstatistically significantly lower root-mean-square errors than models that use\neither daily sampled data or frequently sampled data.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 16:39:59 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 22:12:07 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2020 02:25:11 GMT"}, {"version": "v4", "created": "Sun, 7 Feb 2021 03:09:24 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Wan", "Cheng", ""], ["McHill", "Andrew W.", ""], ["Klerman", "Elizabeth", ""], ["Sano", "Akane", ""]]}, {"id": "1908.07498", "submitter": "Rishabh Misra", "authors": "Aditi A. Mavalankar, Ajitesh Gupta, Chetan Gandotra, Rishabh Misra", "title": "Hotel Recommendation System", "comments": "arXiv admin note: text overlap with arXiv:1703.02915 by other authors", "journal-ref": null, "doi": "10.13140/RG.2.2.27394.22728/1", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  One of the first things to do while planning a trip is to book a good place\nto stay. Booking a hotel online can be an overwhelming task with thousands of\nhotels to choose from, for every destination. Motivated by the importance of\nthese situations, we decided to work on the task of recommending hotels to\nusers. We used Expedia's hotel recommendation dataset, which has a variety of\nfeatures that helped us achieve a deep understanding of the process that makes\na user choose certain hotels over others. The aim of this hotel recommendation\ntask is to predict and recommend five hotel clusters to a user that he/she is\nmore likely to book given hundred distinct clusters.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 17:20:41 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 04:05:14 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Mavalankar", "Aditi A.", ""], ["Gupta", "Ajitesh", ""], ["Gandotra", "Chetan", ""], ["Misra", "Rishabh", ""]]}, {"id": "1908.07500", "submitter": "Wei Sun", "authors": "Wei Sun and Tianfu Wu", "title": "Image Synthesis From Reconfigurable Layout and Style", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite remarkable recent progress on both unconditional and conditional\nimage synthesis, it remains a long-standing problem to learn generative models\nthat are capable of synthesizing realistic and sharp images from reconfigurable\nspatial layout (i.e., bounding boxes + class labels in an image lattice) and\nstyle (i.e., structural and appearance variations encoded by latent vectors),\nespecially at high resolution. By reconfigurable, it means that a model can\npreserve the intrinsic one-to-many mapping from a given layout to multiple\nplausible images with different styles, and is adaptive with respect to\nperturbations of a layout and style latent code. In this paper, we present a\nlayout- and style-based architecture for generative adversarial networks\n(termed LostGANs) that can be trained end-to-end to generate images from\nreconfigurable layout and style. Inspired by the vanilla StyleGAN, the proposed\nLostGAN consists of two new components: (i) learning fine-grained mask maps in\na weakly-supervised manner to bridge the gap between layouts and images, and\n(ii) learning object instance-specific layout-aware feature normalization\n(ISLA-Norm) in the generator to realize multi-object style generation. In\nexperiments, the proposed method is tested on the COCO-Stuff dataset and the\nVisual Genome dataset with state-of-the-art performance obtained. The code and\npretrained models are available at \\url{https://github.com/iVMCL/LostGANs}.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 17:22:31 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Sun", "Wei", ""], ["Wu", "Tianfu", ""]]}, {"id": "1908.07558", "submitter": "Xianfeng Tang", "authors": "Xianfeng Tang, Yandong Li, Yiwei Sun, Huaxiu Yao, Prasenjit Mitra,\n  Suhang Wang", "title": "Transferring Robustness for Graph Neural Network Against Poisoning\n  Attacks", "comments": "Accepted by WSDM 2020. Code and data:\n  https://github.com/tangxianfeng/PA-GNN", "journal-ref": null, "doi": "10.1145/3336191.3371851", "report-no": null, "categories": "cs.LG cs.CR cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) are widely used in many applications. However,\ntheir robustness against adversarial attacks is criticized. Prior studies show\nthat using unnoticeable modifications on graph topology or nodal features can\nsignificantly reduce the performances of GNNs. It is very challenging to design\nrobust graph neural networks against poisoning attack and several efforts have\nbeen taken. Existing work aims at reducing the negative impact from adversarial\nedges only with the poisoned graph, which is sub-optimal since they fail to\ndiscriminate adversarial edges from normal ones. On the other hand, clean\ngraphs from similar domains as the target poisoned graph are usually available\nin the real world. By perturbing these clean graphs, we create supervised\nknowledge to train the ability to detect adversarial edges so that the\nrobustness of GNNs is elevated. However, such potential for clean graphs is\nneglected by existing work. To this end, we investigate a novel problem of\nimproving the robustness of GNNs against poisoning attacks by exploring clean\ngraphs. Specifically, we propose PA-GNN, which relies on a penalized\naggregation mechanism that directly restrict the negative impact of adversarial\nedges by assigning them lower attention coefficients. To optimize PA-GNN for a\npoisoned graph, we design a meta-optimization algorithm that trains PA-GNN to\npenalize perturbations using clean graphs and their adversarial counterparts,\nand transfers such ability to improve the robustness of PA-GNN on the poisoned\ngraph. Experimental results on four real-world datasets demonstrate the\nrobustness of PA-GNN against poisoning attacks on graphs. Code and data are\navailable here: https://github.com/tangxianfeng/PA-GNN.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 18:24:32 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 20:33:08 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2020 17:00:28 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Tang", "Xianfeng", ""], ["Li", "Yandong", ""], ["Sun", "Yiwei", ""], ["Yao", "Huaxiu", ""], ["Mitra", "Prasenjit", ""], ["Wang", "Suhang", ""]]}, {"id": "1908.07585", "submitter": "Jun Yang", "authors": "Jun Yang and Shengyang Sun and Daniel M. Roy", "title": "Fast-rate PAC-Bayes Generalization Bounds via Shifted Rademacher\n  Processes", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The developments of Rademacher complexity and PAC-Bayesian theory have been\nlargely independent. One exception is the PAC-Bayes theorem of Kakade,\nSridharan, and Tewari (2008), which is established via Rademacher complexity\ntheory by viewing Gibbs classifiers as linear operators. The goal of this paper\nis to extend this bridge between Rademacher complexity and state-of-the-art\nPAC-Bayesian theory. We first demonstrate that one can match the fast rate of\nCatoni's PAC-Bayes bounds (Catoni, 2007) using shifted Rademacher processes\n(Wegkamp, 2003; Lecu\\'{e} and Mitchell, 2012; Zhivotovskiy and Hanneke, 2018).\nWe then derive a new fast-rate PAC-Bayes bound in terms of the \"flatness\" of\nthe empirical risk surface on which the posterior concentrates. Our analysis\nestablishes a new framework for deriving fast-rate PAC-Bayes bounds and yields\nnew insights on PAC-Bayesian theory.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 19:46:14 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 16:12:50 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Yang", "Jun", ""], ["Sun", "Shengyang", ""], ["Roy", "Daniel M.", ""]]}, {"id": "1908.07587", "submitter": "Songwei Ge", "authors": "Songwei Ge, Austin Dill, Eunsu Kang, Chun-Liang Li, Lingyao Zhang,\n  Manzil Zaheer, Barnabas Poczos", "title": "Developing Creative AI to Generate Sculptural Objects", "comments": "In the Proceedings of International Symposium on Electronic Art (ISEA\n  2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the intersection of human and machine creativity by generating\nsculptural objects through machine learning. This research raises questions\nabout both the technical details of automatic art generation and the\ninteraction between AI and people, as both artists and the audience of art. We\nintroduce two algorithms for generating 3D point clouds and then discuss their\nactualization as sculpture and incorporation into a holistic art installation.\nSpecifically, the Amalgamated DeepDream (ADD) algorithm solves the sparsity\nproblem caused by the naive DeepDream-inspired approach and generates creative\nand printable point clouds. The Partitioned DeepDream (PDD) algorithm further\nallows us to explore more diverse 3D object creation by combining point cloud\nclustering algorithms and ADD.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:00:25 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Ge", "Songwei", ""], ["Dill", "Austin", ""], ["Kang", "Eunsu", ""], ["Li", "Chun-Liang", ""], ["Zhang", "Lingyao", ""], ["Zaheer", "Manzil", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1908.07607", "submitter": "Tomer Lancewicki Ph.D.", "authors": "Tomer Lancewicki, Selcuk Kopru", "title": "Automatic and Simultaneous Adjustment of Learning Rate and Momentum for\n  Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic Gradient Descent (SGD) methods are prominent for training machine\nlearning and deep learning models. The performance of these techniques depends\non their hyperparameter tuning over time and varies for different models and\nproblems. Manual adjustment of hyperparameters is very costly and\ntime-consuming, and even if done correctly, it lacks theoretical justification\nwhich inevitably leads to \"rule of thumb\" settings. In this paper, we propose a\ngeneric approach that utilizes the statistics of an unbiased gradient estimator\nto automatically and simultaneously adjust two paramount hyperparameters: the\nlearning rate and momentum. We deploy the proposed general technique for\nvarious SGD methods to train Convolutional Neural Networks (CNN's). The results\nmatch the performance of the best settings obtained through an exhaustive\nsearch and therefore, removes the need for a tedious manual tuning.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:56:41 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Lancewicki", "Tomer", ""], ["Kopru", "Selcuk", ""]]}, {"id": "1908.07636", "submitter": "Valeriy Avanesov", "authors": "Valeriy Avanesov", "title": "How to gamble with non-stationary $\\mathcal{X}$-armed bandits and have\n  no regrets", "comments": "The algorithm is optimized, the theoretical result is more detailed\n  now", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In $\\mathcal{X}$-armed bandit problem an agent sequentially interacts with\nenvironment which yields a reward based on the vector input the agent provides.\nThe agent's goal is to maximise the sum of these rewards across some number of\ntime steps. The problem and its variations have been a subject of numerous\nstudies, suggesting sub-linear and some times optimal strategies. The given\npaper introduces a novel variation of the problem. We consider an environment,\nwhich can abruptly change its behaviour an unknown number of times. To that end\nwe propose a novel strategy and prove it attains sub-linear cumulative regret.\nMoreover, in case of highly smooth relation between an action and the\ncorresponding reward, the method is nearly optimal. The theoretical result are\nsupported by experimental study.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 22:33:02 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 08:52:27 GMT"}, {"version": "v3", "created": "Sun, 17 Jan 2021 13:04:07 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Avanesov", "Valeriy", ""]]}, {"id": "1908.07643", "submitter": "Venkatadheeraj Pichapati", "authors": "Venkatadheeraj Pichapati and Ananda Theertha Suresh and Felix X. Yu\n  and Sashank J. Reddi and Sanjiv Kumar", "title": "AdaCliP: Adaptive Clipping for Private SGD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy preserving machine learning algorithms are crucial for learning\nmodels over user data to protect sensitive information. Motivated by this,\ndifferentially private stochastic gradient descent (SGD) algorithms for\ntraining machine learning models have been proposed. At each step, these\nalgorithms modify the gradients and add noise proportional to the sensitivity\nof the modified gradients. Under this framework, we propose AdaCliP, a\ntheoretically motivated differentially private SGD algorithm that provably adds\nless noise compared to the previous methods, by using coordinate-wise adaptive\nclipping of the gradient. We empirically demonstrate that AdaCliP reduces the\namount of added noise and produces models with better accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 23:19:21 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 19:02:00 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Pichapati", "Venkatadheeraj", ""], ["Suresh", "Ananda Theertha", ""], ["Yu", "Felix X.", ""], ["Reddi", "Sashank J.", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1908.07644", "submitter": "Gamaleldin Elsayed", "authors": "Gamaleldin F. Elsayed and Simon Kornblith and Quoc V. Le", "title": "Saccader: Improving Accuracy of Hard Attention Models for Vision", "comments": "33rd Conference on Neural Information Processing Systems (NeurIPS\n  2019), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep convolutional neural networks achieve state-of-the-art\nperformance across nearly all image classification tasks, their decisions are\ndifficult to interpret. One approach that offers some level of interpretability\nby design is \\textit{hard attention}, which uses only relevant portions of the\nimage. However, training hard attention models with only class label\nsupervision is challenging, and hard attention has proved difficult to scale to\ncomplex datasets. Here, we propose a novel hard attention model, which we term\nSaccader. Key to Saccader is a pretraining step that requires only class labels\nand provides initial attention locations for policy gradient optimization. Our\nbest models narrow the gap to common ImageNet baselines, achieving $75\\%$ top-1\nand $91\\%$ top-5 while attending to less than one-third of the image.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 23:40:21 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 22:45:26 GMT"}, {"version": "v3", "created": "Sat, 7 Dec 2019 00:34:57 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Elsayed", "Gamaleldin F.", ""], ["Kornblith", "Simon", ""], ["Le", "Quoc V.", ""]]}, {"id": "1908.07653", "submitter": "Hazrat Ali", "authors": "Kashif Sultan, Hazrat Ali, Haris Anwaar, Kabo Poloko Nkabiti, Adeel\n  Ahamd, Zhongshan Zhang", "title": "Understanding and Partitioning Mobile Traffic using Internet Activity\n  Records Data -- A Spatiotemporal Approach", "comments": "2019 28th Wireless and Optical Communications Conference (WOCC)", "journal-ref": null, "doi": "10.1109/WOCC.2019.8770653", "report-no": null, "categories": "cs.NI cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The internet activity records (IARs) of a mobile cellular network posses\nsignificant information which can be exploited to identify the network's\nefficacy and the mobile users' behavior. In this work, we extract useful\ninformation from the IAR data and identify a healthy predictability of\nspatio-temporal pattern within the network traffic. The information extracted\nis helpful for network operators to plan effective network configuration and\nperform management and optimization of network's resources. We report\nexperimentation on spatiotemporal analysis of IAR data of the Telecom Italia.\nBased on this, we present mobile traffic partitioning scheme. Experimental\nresults of the proposed model is helpful in modelling and partitioning of\nnetwork traffic patterns.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 06:29:44 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Sultan", "Kashif", ""], ["Ali", "Hazrat", ""], ["Anwaar", "Haris", ""], ["Nkabiti", "Kabo Poloko", ""], ["Ahamd", "Adeel", ""], ["Zhang", "Zhongshan", ""]]}, {"id": "1908.07656", "submitter": "Alexander Glandon", "authors": "Mahbubul Alam, Manar D. Samad, Lasitha Vidyaratne, Alexander Glandon,\n  and Khan M. Iftekharuddin", "title": "Survey on Deep Neural Networks in Speech and Vision Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE cs.SD eess.AS eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey presents a review of state-of-the-art deep neural network\narchitectures, algorithms, and systems in vision and speech applications.\nRecent advances in deep artificial neural network algorithms and architectures\nhave spurred rapid innovation and development of intelligent vision and speech\nsystems. With availability of vast amounts of sensor data and cloud computing\nfor processing and training of deep neural networks, and with increased\nsophistication in mobile and embedded technology, the next-generation\nintelligent systems are poised to revolutionize personal and commercial\ncomputing. This survey begins by providing background and evolution of some of\nthe most successful deep learning models for intelligent vision and speech\nsystems to date. An overview of large-scale industrial research and development\nefforts is provided to emphasize future trends and prospects of intelligent\nvision and speech systems. Robust and efficient intelligent systems demand\nlow-latency and high fidelity in resource-constrained hardware platforms such\nas mobile devices, robots, and automobiles. Therefore, this survey also\nprovides a summary of key challenges and recent successes in running deep\nneural networks on hardware-restricted platforms, i.e. within limited memory,\nbattery life, and processing capabilities. Finally, emerging applications of\nvision and speech across disciplines such as affective computing, intelligent\ntransportation, and precision medicine are discussed. To our knowledge, this\npaper provides one of the most comprehensive surveys on the latest developments\nin intelligent vision and speech applications from the perspectives of both\nsoftware and hardware systems. Many of these emerging technologies using deep\nneural networks show tremendous promise to revolutionize research and\ndevelopment for future vision and speech systems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 16:40:49 GMT"}, {"version": "v2", "created": "Sun, 1 Dec 2019 03:30:37 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Alam", "Mahbubul", ""], ["Samad", "Manar D.", ""], ["Vidyaratne", "Lasitha", ""], ["Glandon", "Alexander", ""], ["Iftekharuddin", "Khan M.", ""]]}, {"id": "1908.07667", "submitter": "Ka-Ho Chow", "authors": "Ka-Ho Chow, Wenqi Wei, Yanzhao Wu, Ling Liu", "title": "Denoising and Verification Cross-Layer Ensemble Against Black-box\n  Adversarial Attacks", "comments": "To appear in IEEE BigData 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have demonstrated impressive performance on many\nchallenging machine learning tasks. However, DNNs are vulnerable to adversarial\ninputs generated by adding maliciously crafted perturbations to the benign\ninputs. As a growing number of attacks have been reported to generate\nadversarial inputs of varying sophistication, the defense-attack arms race has\nbeen accelerated. In this paper, we present MODEF, a cross-layer model\ndiversity ensemble framework. MODEF intelligently combines unsupervised model\ndenoising ensemble with supervised model verification ensemble by quantifying\nmodel diversity, aiming to boost the robustness of the target model against\nadversarial examples. Evaluated using eleven representative attacks on popular\nbenchmark datasets, we show that MODEF achieves remarkable defense success\nrates, compared with existing defense methods, and provides a superior\ncapability of repairing adversarial inputs and making correct predictions with\nhigh accuracy in the presence of black-box attacks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 01:34:08 GMT"}, {"version": "v2", "created": "Sat, 26 Oct 2019 06:23:58 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Chow", "Ka-Ho", ""], ["Wei", "Wenqi", ""], ["Wu", "Yanzhao", ""], ["Liu", "Ling", ""]]}, {"id": "1908.07725", "submitter": "Kevin Lin", "authors": "Kevin K. Lin and Fei Lu", "title": "Data-driven model reduction, Wiener projections, and the\n  Koopman-Mori-Zwanzig formalism", "comments": "Substantial revisions, including additional references. To appear in\n  Journal of Computational Physics", "journal-ref": "Journal of Computational Physics 424 (2021)", "doi": "10.1016/j.jcp.2020.109864", "report-no": null, "categories": "math.NA cs.NA physics.comp-ph stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model reduction methods aim to describe complex dynamic phenomena using only\nrelevant dynamical variables, decreasing computational cost, and potentially\nhighlighting key dynamical mechanisms. In the absence of special dynamical\nfeatures such as scale separation or symmetries, the time evolution of these\nvariables typically exhibits memory effects. Recent work has found a variety of\ndata-driven model reduction methods to be effective for representing such\nnon-Markovian dynamics, but their scope and dynamical underpinning remain\nincompletely understood. Here, we study data-driven model reduction from a\ndynamical systems perspective. For both chaotic and randomly-forced systems, we\nshow the problem can be naturally formulated within the framework of Koopman\noperators and the Mori-Zwanzig projection operator formalism. We give a\nheuristic derivation of a NARMAX (Nonlinear Auto-Regressive Moving Average with\neXogenous input) model from an underlying dynamical model. The derivation is\nbased on a simple construction we call Wiener projection, which links\nMori-Zwanzig theory to both NARMAX and to classical Wiener filtering. We apply\nthese ideas to the Kuramoto-Sivashinsky model of spatiotemporal chaos and a\nviscous Burgers equation with stochastic forcing.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 07:15:05 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 04:53:27 GMT"}, {"version": "v3", "created": "Sat, 18 Jan 2020 01:10:33 GMT"}, {"version": "v4", "created": "Sun, 20 Sep 2020 16:46:23 GMT"}, {"version": "v5", "created": "Mon, 5 Oct 2020 04:23:50 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Lin", "Kevin K.", ""], ["Lu", "Fei", ""]]}, {"id": "1908.07782", "submitter": "Chenghao Hu", "authors": "Chenghao Hu, Jingyan Jiang, Zhi Wang", "title": "Decentralized Federated Learning: A Segmented Gossip Approach", "comments": "Accepted to the 1st International Workshop on Federated Machine\n  Learning for User Privacy and Data Confidentiality (FML'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging concern about data privacy and security has motivated the\nproposal of federated learning, which allows nodes to only synchronize the\nlocally-trained models instead their own original data. Conventional federated\nlearning architecture, inherited from the parameter server design, relies on\nhighly centralized topologies and the assumption of large nodes-to-server\nbandwidths. However, in real-world federated learning scenarios the network\ncapacities between nodes are highly uniformly distributed and smaller than that\nin a datacenter. It is of great challenges for conventional federated learning\napproaches to efficiently utilize network capacities between nodes. In this\npaper, we propose a model segment level decentralized federated learning to\ntackle this problem. In particular, we propose a segmented gossip approach,\nwhich not only makes full utilization of node-to-node bandwidth, but also has\ngood training convergence. The experimental results show that even the training\ntime can be highly reduced as compared to centralized federated learning.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 10:21:43 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Hu", "Chenghao", ""], ["Jiang", "Jingyan", ""], ["Wang", "Zhi", ""]]}, {"id": "1908.07805", "submitter": "Hanna Meyer", "authors": "Hanna Meyer, Christoph Reudenbach, Stephan W\\\"ollauer, Thomas Nauss", "title": "Importance of spatial predictor variable selection in machine learning\n  applications -- Moving from data reproduction to spatial prediction", "comments": "under review in Ecological Modelling", "journal-ref": "Ecological Modelling, 411, 2019, 108815", "doi": "10.1016/j.ecolmodel.2019.108815", "report-no": null, "categories": "stat.AP cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Machine learning algorithms find frequent application in spatial prediction\nof biotic and abiotic environmental variables. However, the characteristics of\nspatial data, especially spatial autocorrelation, are widely ignored. We\nhypothesize that this is problematic and results in models that can reproduce\ntraining data but are unable to make spatial predictions beyond the locations\nof the training samples. We assume that not only spatial validation strategies\nbut also spatial variable selection is essential for reliable spatial\npredictions. We introduce two case studies that use remote sensing to predict\nland cover and the leaf area index for the \"Marburg Open Forest\", an open\nresearch and education site of Marburg University, Germany. We use the machine\nlearning algorithm Random Forests to train models using non-spatial and spatial\ncross-validation strategies to understand how spatial variable selection\naffects the predictions. Our findings confirm that spatial cross-validation is\nessential in preventing overoptimistic model performance. We further show that\nhighly autocorrelated predictors (such as geolocation variables, e.g. latitude,\nlongitude) can lead to considerable overfitting and result in models that can\nreproduce the training data but fail in making spatial predictions. The problem\nbecomes apparent in the visual assessment of the spatial predictions that show\nclear artefacts that can be traced back to a misinterpretation of the spatially\nautocorrelated predictors by the algorithm. Spatial variable selection could\nautomatically detect and remove such variables that lead to overfitting,\nresulting in reliable spatial prediction patterns and improved statistical\nspatial model performance. We conclude that in addition to spatial validation,\na spatial variable selection must be considered in spatial predictions of\necological data to produce reliable predictions.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 11:47:38 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Meyer", "Hanna", ""], ["Reudenbach", "Christoph", ""], ["W\u00f6llauer", "Stephan", ""], ["Nauss", "Thomas", ""]]}, {"id": "1908.07808", "submitter": "Jules Kruijswijk", "authors": "Jules Kruijswijk, Petri Parvinen, Maurits Kaptein", "title": "Exploring Offline Policy Evaluation for the Continuous-Armed Bandit\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (contextual) multi-armed bandit problem (MAB) provides a formalization of\nsequential decision-making which has many applications. However, validly\nevaluating MAB policies is challenging; we either resort to simulations which\ninherently include debatable assumptions, or we resort to expensive field\ntrials. Recently an offline evaluation method has been suggested that is based\non empirical data, thus relaxing the assumptions, and can be used to evaluate\nmultiple competing policies in parallel. This method is however not directly\nsuited for the continuous armed (CAB) problem; an often encountered version of\nthe MAB problem in which the action set is continuous instead of discrete. We\npropose and evaluate an extension of the existing method such that it can be\nused to evaluate CAB policies. We empirically demonstrate that our method\nprovides a relatively consistent ranking of policies. Furthermore, we detail\nhow our method can be used to select policies in a real-life CAB problem.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 12:11:03 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Kruijswijk", "Jules", ""], ["Parvinen", "Petri", ""], ["Kaptein", "Maurits", ""]]}, {"id": "1908.07832", "submitter": "Ahmed El-Kishky", "authors": "Ahmed El-Kishky, Frank Xu, Aston Zhang, Jiawei Han", "title": "Parsimonious Morpheme Segmentation with an Application to Enriching Word\n  Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, many text-mining tasks treat individual word-tokens as the\nfinest meaningful semantic granularity. However, in many languages and\nspecialized corpora, words are composed by concatenating semantically\nmeaningful subword structures. Word-level analysis cannot leverage the semantic\ninformation present in such subword structures. With regard to word embedding\ntechniques, this leads to not only poor embeddings for infrequent words in\nlong-tailed text corpora but also weak capabilities for handling\nout-of-vocabulary words. In this paper we propose MorphMine for unsupervised\nmorpheme segmentation. MorphMine applies a parsimony criterion to\nhierarchically segment words into the fewest number of morphemes at each level\nof the hierarchy. This leads to longer shared morphemes at each level of\nsegmentation. Experiments show that MorphMine segments words in a variety of\nlanguages into human-verified morphemes. Additionally, we experimentally\ndemonstrate that utilizing MorphMine morphemes to enrich word embeddings\nconsistently improves embedding quality on a variety of of embedding\nevaluations and a downstream language modeling task.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 00:45:16 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 22:18:44 GMT"}], "update_date": "2019-11-15", "authors_parsed": [["El-Kishky", "Ahmed", ""], ["Xu", "Frank", ""], ["Zhang", "Aston", ""], ["Han", "Jiawei", ""]]}, {"id": "1908.07842", "submitter": "Mohammadreza Baharani", "authors": "Mohammadreza Baharani, Shrey Mohan, Hamed Tabkhi", "title": "Real-time Person Re-identification at the Edge: A Mixed Precision\n  Approach", "comments": "This is a pre-print of an article published in International\n  Conference on Image Analysis and Recognition (ICIAR 2019), Lecture Notes in\n  Computer Science. The final authenticated version is available online at\n  https://doi.org/10.1007/978-3-030-27272-2_3", "journal-ref": "International Conference on Image Analysis and Recognition (ICIAR\n  2019), Lecture Notes in Computer Science", "doi": "10.1007/978-3-030-27272-2_3", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A critical part of multi-person multi-camera tracking is person\nre-identification (re-ID) algorithm, which recognizes and retains identities of\nall detected unknown people throughout the video stream. Many re-ID algorithms\ntoday exemplify state of the art results, but not much work has been done to\nexplore the deployment of such algorithms for computation and power constrained\nreal-time scenarios. In this paper, we study the effect of using a light-weight\nmodel, MobileNet-v2 for re-ID and investigate the impact of single (FP32)\nprecision versus half (FP16) precision for training on the server and inference\non the edge nodes. We further compare the results with the baseline model which\nuses ResNet-50 on state of the art benchmarks including CUHK03, Market-1501,\nand Duke-MTMC. The MobileNet-V2 mixed precision training method can improve\nboth inference throughput on the edge node, and training time on server\n$3.25\\times$ reaching to 27.77fps and $1.75\\times$, respectively and decreases\npower consumption on the edge node by $1.45\\times$, while it deteriorates\naccuracy only 5.6\\% in respect to ResNet-50 single precision on the average for\nthree different datasets. The code and pre-trained networks are publicly\navailable at https://github.com/TeCSAR-UNCC/person-reid.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 23:38:53 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Baharani", "Mohammadreza", ""], ["Mohan", "Shrey", ""], ["Tabkhi", "Hamed", ""]]}, {"id": "1908.07844", "submitter": "Benedikt Boenninghoff", "authors": "Benedikt Boenninghoff, Robert M. Nickel, Steffen Zeiler, Dorothea\n  Kolossa", "title": "Similarity Learning for Authorship Verification in Social Media", "comments": "5 pages, 3 figures, 1 table, presented on ICASSP 2019 in Brighton, UK", "journal-ref": null, "doi": "10.1109/ICASSP.2019.8683405", "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Authorship verification tries to answer the question if two documents with\nunknown authors were written by the same author or not. A range of successful\ntechnical approaches has been proposed for this task, many of which are based\non traditional linguistic features such as n-grams. These algorithms achieve\ngood results for certain types of written documents like books and novels.\nForensic authorship verification for social media, however, is a much more\nchallenging task since messages tend to be relatively short, with a large\nvariety of different genres and topics. At this point, traditional methods\nbased on features like n-grams have had limited success. In this work, we\npropose a new neural network topology for similarity learning that\nsignificantly improves the performance on the author verification task with\nsuch challenging data sets.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 04:08:58 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Boenninghoff", "Benedikt", ""], ["Nickel", "Robert M.", ""], ["Zeiler", "Steffen", ""], ["Kolossa", "Dorothea", ""]]}, {"id": "1908.07847", "submitter": "Sterling Ramroach", "authors": "Sterling Ramroach, Andrew Dhanoo, Brian Cockburn, and Ajay Joshi", "title": "CUDA optimized Neural Network predicts blood glucose control from\n  quantified joint mobility and anthropometrics", "comments": "5 pages, 6 figures, conference paper: International Conference on\n  Information System and Data Mining, published at\n  https://dl.acm.org/citation.cfm?id=3325940", "journal-ref": null, "doi": "10.1145/3325917.3325940", "report-no": null, "categories": "cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network training entails heavy computation with obvious bottlenecks.\nThe Compute Unified Device Architecture (CUDA) programming model allows us to\naccelerate computation by passing the processing workload from the CPU to the\ngraphics processing unit (GPU). In this paper, we leveraged the power of Nvidia\nGPUs to parallelize all of the computation involved in training, to accelerate\na backpropagation feed-forward neural network with one hidden layer using CUDA\nand C++. This optimized neural network was tasked with predicting the level of\nglycated hemoglobin (HbA1c) from non-invasive markers. The rate of increase in\nthe prevalence of Diabetes Mellitus has resulted in an urgent need for early\ndetection and accurate diagnosis. However, due to the invasiveness and\nlimitations of conventional tests, alternate means are being considered.\nLimited Joint Mobility (LJM) has been reported as an indicator for poor\nglycemic control. LJM of the fingers is quantified and its link to HbA1c is\ninvestigated along with other potential non-invasive markers of HbA1c. We\ncollected readings of 33 potential markers from 120 participants at a clinic in\nsouth Trinidad. Our neural network achieved 95.65% accuracy on the training and\n86.67% accuracy on the testing set for male participants and 97.73% and 66.67%\naccuracy on the training and testing sets for female participants. Using 960\nCUDA cores from a Nvidia GeForce GTX 660, our parallelized neural network was\ntrained 50 times faster on both subsets, than its corresponding CPU\nimplementation on an Intel Core (TM) i7-3630QM 2.40 GHz CPU.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:39:54 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Ramroach", "Sterling", ""], ["Dhanoo", "Andrew", ""], ["Cockburn", "Brian", ""], ["Joshi", "Ajay", ""]]}, {"id": "1908.07849", "submitter": "Motaz Alfarraj", "authors": "Motaz Alfarraj and Ghassan AlRegib", "title": "Semi-supervised Sequence Modeling for Elastic Impedance Inversion", "comments": "A manuscript in Interpretation. arXiv admin note: text overlap with\n  arXiv:1905.13412", "journal-ref": null, "doi": "10.1190/INT-2018-0250.1", "report-no": null, "categories": "physics.geo-ph cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent applications of machine learning algorithms in the seismic domain have\nshown great potential in different areas such as seismic inversion and\ninterpretation. However, such algorithms rarely enforce geophysical constraints\n- the lack of which might lead to undesirable results. To overcome this issue,\nwe have developed a semi-supervised sequence modeling framework based on\nrecurrent neural networks for elastic impedance inversion from multi-angle\nseismic data. Specifically, seismic traces and elastic impedance (EI) traces\nare modeled as a time series. Then, a neural-network-based inversion model\ncomprising convolutional and recurrent neural layers is used to invert seismic\ndata for EI. The proposed workflow uses well-log data to guide the inversion.\nIn addition, it uses seismic forward modeling to regularize the training and to\nserve as a geophysical constraint for the inversion. The proposed workflow\nachieves an average correlation of 98% between the estimated and target EI\nusing 10 well logs for training on a synthetic data set.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 19:17:10 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Alfarraj", "Motaz", ""], ["AlRegib", "Ghassan", ""]]}, {"id": "1908.07873", "submitter": "Tian Li", "authors": "Tian Li, Anit Kumar Sahu, Ameet Talwalkar, Virginia Smith", "title": "Federated Learning: Challenges, Methods, and Future Directions", "comments": null, "journal-ref": null, "doi": "10.1109/MSP.2020.2975749", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning involves training statistical models over remote devices\nor siloed data centers, such as mobile phones or hospitals, while keeping data\nlocalized. Training in heterogeneous and potentially massive networks\nintroduces novel challenges that require a fundamental departure from standard\napproaches for large-scale machine learning, distributed optimization, and\nprivacy-preserving data analysis. In this article, we discuss the unique\ncharacteristics and challenges of federated learning, provide a broad overview\nof current approaches, and outline several directions of future work that are\nrelevant to a wide range of research communities.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 13:53:23 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Li", "Tian", ""], ["Sahu", "Anit Kumar", ""], ["Talwalkar", "Ameet", ""], ["Smith", "Virginia", ""]]}, {"id": "1908.07882", "submitter": "Shiwan Zhao Mr", "authors": "Bingzhe Wu, Shiwan Zhao, ChaoChao Chen, Haoyang Xu, Li Wang, Xiaolu\n  Zhang, Guangyu Sun, Jun Zhou", "title": "Generalization in Generative Adversarial Networks: A Novel Perspective\n  from Privacy Protection", "comments": "Accepted by NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to understand the generalization properties of\ngenerative adversarial networks (GANs) from a new perspective of privacy\nprotection. Theoretically, we prove that a differentially private learning\nalgorithm used for training the GAN does not overfit to a certain degree, i.e.,\nthe generalization gap can be bounded. Moreover, some recent works, such as the\nBayesian GAN, can be re-interpreted based on our theoretical insight from\nprivacy protection. Quantitatively, to evaluate the information leakage of\nwell-trained GAN models, we perform various membership attacks on these models.\nThe results show that previous Lipschitz regularization techniques are\neffective in not only reducing the generalization gap but also alleviating the\ninformation leakage of the training dataset.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:09:32 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 03:31:06 GMT"}, {"version": "v3", "created": "Wed, 25 Sep 2019 03:40:13 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Wu", "Bingzhe", ""], ["Zhao", "Shiwan", ""], ["Chen", "ChaoChao", ""], ["Xu", "Haoyang", ""], ["Wang", "Li", ""], ["Zhang", "Xiaolu", ""], ["Sun", "Guangyu", ""], ["Zhou", "Jun", ""]]}, {"id": "1908.07885", "submitter": "Qingjie Meng", "authors": "Qingjie Meng and Nick Pawlowski and Daniel Rueckert and Bernhard Kainz", "title": "Representation Disentanglement for Multi-task Learning with application\n  to Fetal Ultrasound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges for deep learning algorithms in medical image\nanalysis is the indiscriminate mixing of image properties, e.g. artifacts and\nanatomy. These entangled image properties lead to a semantically redundant\nfeature encoding for the relevant task and thus lead to poor generalization of\ndeep learning algorithms. In this paper we propose a novel representation\ndisentanglement method to extract semantically meaningful and generalizable\nfeatures for different tasks within a multi-task learning framework. Deep\nneural networks are utilized to ensure that the encoded features are maximally\ninformative with respect to relevant tasks, while an adversarial regularization\nencourages these features to be disentangled and minimally informative about\nirrelevant tasks. We aim to use the disentangled representations to generalize\nthe applicability of deep neural networks. We demonstrate the advantages of the\nproposed method on synthetic data as well as fetal ultrasound images. Our\nexperiments illustrate that our method is capable of learning disentangled\ninternal representations. It outperforms baseline methods in multiple tasks,\nespecially on images with new properties, e.g. previously unseen artifacts in\nfetal ultrasound.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 14:14:44 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Meng", "Qingjie", ""], ["Pawlowski", "Nick", ""], ["Rueckert", "Daniel", ""], ["Kainz", "Bernhard", ""]]}, {"id": "1908.07962", "submitter": "Siavash Haghiri", "authors": "Siavash Haghiri, Felix Wichmann, Ulrike von Luxburg", "title": "Estimation of perceptual scales using ordinal embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of measuring and analysing sensation,\nthe subjective magnitude of one's experience. We do this in the context of the\nmethod of triads: the sensation of the stimulus is evaluated via relative\njudgments of the form: \"Is stimulus S_i more similar to stimulus S_j or to\nstimulus S_k?\". We propose to use ordinal embedding methods from machine\nlearning to estimate the scaling function from the relative judgments. We\nreview two relevant and well-known methods in psychophysics which are partially\napplicable in our setting: non-metric multi-dimensional scaling (NMDS) and the\nmethod of maximum likelihood difference scaling (MLDS). We perform an extensive\nset of simulations, considering various scaling functions, to demonstrate the\nperformance of the ordinal embedding methods. We show that in contrast to\nexisting approaches our ordinal embedding approach allows, first, to obtain\nreasonable scaling function from comparatively few relative judgments, second,\nthe estimation of non-monotonous scaling functions, and, third,\nmulti-dimensional perceptual scales. In addition to the simulations, we analyse\ndata from two real psychophysics experiments using ordinal embedding methods.\nOur results show that in the one-dimensional, monotonically increasing\nperceptual scale our ordinal embedding approach works as well as MLDS, while in\nhigher dimensions, only our ordinal embedding methods can produce a desirable\nscaling function. To make our methods widely accessible, we provide an\nR-implementation and general rules of thumb on how to use ordinal embedding in\nthe context of psychophysics.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 16:12:27 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Haghiri", "Siavash", ""], ["Wichmann", "Felix", ""], ["von Luxburg", "Ulrike", ""]]}, {"id": "1908.07978", "submitter": "G\\'abor Petneh\\'azi", "authors": "G\\'abor Petneh\\'azi", "title": "Quantile Convolutional Neural Networks for Value at Risk Forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.CP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a new method for forecasting Value at Risk.\nConvolutional neural networks can do time series forecasting, since they can\nlearn local patterns in time. A simple modification enables them to forecast\nnot the mean, but arbitrary quantiles of the distribution, and thus allows them\nto be applied to VaR-forecasting. The proposed model can learn from the price\nhistory of different assets, and it seems to produce fairly accurate forecasts.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 16:37:08 GMT"}, {"version": "v2", "created": "Thu, 9 Jan 2020 19:06:18 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 10:40:32 GMT"}, {"version": "v4", "created": "Wed, 30 Sep 2020 14:58:09 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Petneh\u00e1zi", "G\u00e1bor", ""]]}, {"id": "1908.07980", "submitter": "Matthew West", "authors": "Chenchao Shou and Matthew West", "title": "A tree-based radial basis function method for noisy parallel surrogate\n  optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel surrogate optimization algorithms have proven to be efficient\nmethods for solving expensive noisy optimization problems. In this work we\ndevelop a new parallel surrogate optimization algorithm (ProSRS), using a novel\ntree-based \"zoom strategy\" to improve the efficiency of the algorithm. We prove\nthat if ProSRS is run for sufficiently long, with probability converging to one\nthere will be at least one point among all the evaluations that will be\narbitrarily close to the global minimum. We compare our algorithm to several\nstate-of-the-art Bayesian optimization algorithms on a suite of standard\nbenchmark functions and two real machine learning hyperparameter-tuning\nproblems. We find that our algorithm not only achieves significantly faster\noptimization convergence, but is also 1-4 orders of magnitude cheaper in\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 16:43:54 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Shou", "Chenchao", ""], ["West", "Matthew", ""]]}, {"id": "1908.08005", "submitter": "No\\\"elie Cherrier", "authors": "No\\\"elie Cherrier, Jean-Philippe Poli, Maxime Defurne and Franck\n  Sabati\\'e", "title": "Consistent Feature Construction with Constrained Genetic Programming for\n  Experimental Physics", "comments": "Accepted in this version to CEC 2019", "journal-ref": "Proceedings of 2019 IEEE Congress on Evolutionary Computation\n  (CEC), Wellington, New Zealand, 2019, pp. 1650-1658", "doi": "10.1109/CEC.2019.8789937", "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A good feature representation is a determinant factor to achieve high\nperformance for many machine learning algorithms in terms of classification.\nThis is especially true for techniques that do not build complex internal\nrepresentations of data (e.g. decision trees, in contrast to deep neural\nnetworks). To transform the feature space, feature construction techniques\nbuild new high-level features from the original ones. Among these techniques,\nGenetic Programming is a good candidate to provide interpretable features\nrequired for data analysis in high energy physics. Classically, original\nfeatures or higher-level features based on physics first principles are used as\ninputs for training. However, physicists would benefit from an automatic and\ninterpretable feature construction for the classification of particle collision\nevents.\n  Our main contribution consists in combining different aspects of Genetic\nProgramming and applying them to feature construction for experimental physics.\nIn particular, to be applicable to physics, dimensional consistency is enforced\nusing grammars.\n  Results of experiments on three physics datasets show that the constructed\nfeatures can bring a significant gain to the classification accuracy. To the\nbest of our knowledge, it is the first time a method is proposed for\ninterpretable feature construction with units of measurement, and that experts\nin high-energy physics validate the overall approach as well as the\ninterpretability of the built features.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 10:55:15 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Cherrier", "No\u00eblie", ""], ["Poli", "Jean-Philippe", ""], ["Defurne", "Maxime", ""], ["Sabati\u00e9", "Franck", ""]]}, {"id": "1908.08006", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, M. Hadi Amini, and Hamid R. Arabnia", "title": "Evolutionary Computation, Optimization and Learning Algorithms for Data\n  Science", "comments": "40 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large number of engineering, science and computational problems have yet to\nbe solved in a computationally efficient way. One of the emerging challenges is\nhow evolving technologies grow towards autonomy and intelligent decision\nmaking. This leads to collection of large amounts of data from various sensing\nand measurement technologies, e.g., cameras, smart phones, health sensors,\nsmart electricity meters, and environment sensors. Hence, it is imperative to\ndevelop efficient algorithms for generation, analysis, classification, and\nillustration of data. Meanwhile, data is structured purposefully through\ndifferent representations, such as large-scale networks and graphs. We focus on\ndata science as a crucial area, specifically focusing on a curse of\ndimensionality (CoD) which is due to the large amount of\ngenerated/sensed/collected data. This motivates researchers to think about\noptimization and to apply nature-inspired algorithms, such as evolutionary\nalgorithms (EAs) to solve optimization problems. Although these algorithms look\nun-deterministic, they are robust enough to reach an optimal solution.\nResearchers do not adopt evolutionary algorithms unless they face a problem\nwhich is suffering from placement in local optimal solution, rather than global\noptimal solution. In this chapter, we first develop a clear and formal\ndefinition of the CoD problem, next we focus on feature extraction techniques\nand categories, then we provide a general overview of meta-heuristic\nalgorithms, its terminology, and desirable properties of evolutionary\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 17:16:16 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1908.08016", "submitter": "Yi Sun", "authors": "Daniel Kang, Yi Sun, Dan Hendrycks, Tom Brown, Jacob Steinhardt", "title": "Testing Robustness Against Unforeseen Adversaries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing adversarial defenses only measure robustness to L_p adversarial\nattacks. Not only are adversaries unlikely to exclusively create small L_p\nperturbations, adversaries are unlikely to remain fixed. Adversaries adapt and\nevolve their attacks; hence adversarial defenses must be robust to a broad\nrange of unforeseen attacks. We address this discrepancy between research and\nreality by proposing a new evaluation framework called ImageNet-UA. Our\nframework enables the research community to test ImageNet model robustness\nagainst attacks not encountered during training. To create ImageNet-UA's\ndiverse attack suite, we introduce a total of four novel adversarial attacks.\nWe also demonstrate that, in comparison to ImageNet-UA, prevailing L_inf\nrobustness assessments give a narrow account of model robustness. By evaluating\ncurrent defenses with ImageNet-UA, we find they provide little robustness to\nunforeseen attacks. We hope the greater variety and realism of ImageNet-UA\nenables development of more robust defenses which can generalize beyond attacks\nseen during training.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 17:36:48 GMT"}, {"version": "v2", "created": "Tue, 9 Jun 2020 05:17:48 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Kang", "Daniel", ""], ["Sun", "Yi", ""], ["Hendrycks", "Dan", ""], ["Brown", "Tom", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "1908.08021", "submitter": "Xavier Porte", "authors": "Xavier Porte, Louis Andreoli, Maxime Jacquot, Laurent Larger, Daniel\n  Brunner", "title": "Reservoir-size dependent learning in analogue neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The implementation of artificial neural networks in hardware substrates is a\nmajor interdisciplinary enterprise. Well suited candidates for physical\nimplementations must combine nonlinear neurons with dedicated and efficient\nhardware solutions for both connectivity and training. Reservoir computing\naddresses the problems related with the network connectivity and training in an\nelegant and efficient way. However, important questions regarding impact of\nreservoir size and learning routines on the convergence-speed during learning\nremain unaddressed. Here, we study in detail the learning process of a recently\ndemonstrated photonic neural network based on a reservoir. We use a greedy\nalgorithm to train our neural network for the task of chaotic signals\nprediction and analyze the learning-error landscape. Our results unveil\nfundamental properties of the system's optimization hyperspace. Particularly,\nwe determine the convergence speed of learning as a function of reservoir size\nand find exceptional, close to linear scaling. This linear dependence, together\nwith our parallel diffractive coupling, represent optimal scaling conditions\nfor our photonic neural network scheme.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 14:56:03 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Porte", "Xavier", ""], ["Andreoli", "Louis", ""], ["Jacquot", "Maxime", ""], ["Larger", "Laurent", ""], ["Brunner", "Daniel", ""]]}, {"id": "1908.08035", "submitter": "Yunguan Fu", "authors": "Yunguan Fu, Maria R. Robu, Bongjin Koo, Crispin Schneider, Stijn van\n  Laarhoven, Danail Stoyanov, Brian Davidson, Matthew J. Clarkson, Yipeng Hu", "title": "More unlabelled data or label more data? A study on semi-supervised\n  laparoscopic image segmentation", "comments": "Accepted to MICCAI MIL3ID 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improving a semi-supervised image segmentation task has the option of adding\nmore unlabelled images, labelling the unlabelled images or combining both, as\nneither image acquisition nor expert labelling can be considered trivial in\nmost clinical applications. With a laparoscopic liver image segmentation\napplication, we investigate the performance impact by altering the quantities\nof labelled and unlabelled training data, using a semi-supervised segmentation\nalgorithm based on the mean teacher learning paradigm. We first report a\nsignificantly higher segmentation accuracy, compared with supervised learning.\nInterestingly, this comparison reveals that the training strategy adopted in\nthe semi-supervised algorithm is also responsible for this observed\nimprovement, in addition to the added unlabelled data. We then compare\ndifferent combinations of labelled and unlabelled data set sizes for training\nsemi-supervised segmentation networks, to provide a quantitative example of the\npractically useful trade-off between the two data planning strategies in this\nsurgical guidance application.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:54:58 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Fu", "Yunguan", ""], ["Robu", "Maria R.", ""], ["Koo", "Bongjin", ""], ["Schneider", "Crispin", ""], ["van Laarhoven", "Stijn", ""], ["Stoyanov", "Danail", ""], ["Davidson", "Brian", ""], ["Clarkson", "Matthew J.", ""], ["Hu", "Yipeng", ""]]}, {"id": "1908.08037", "submitter": "Shalin Shah", "authors": "Shalin Shah, Venkataramana Kini", "title": "Hebbian Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning has recently been successfully used to create vector\nrepresentations of entities in language learning, recommender systems and in\nsimilarity learning. Graph embeddings exploit the locality structure of a graph\nand generate embeddings for nodes which could be words in a language, products\nof a retail website; and the nodes are connected based on a context window. In\nthis paper, we consider graph embeddings with an error-free associative\nlearning update rule, which models the embedding vector of node as a non-convex\nGaussian mixture of the embeddings of the nodes in its immediate vicinity with\nsome constant variance that is reduced as iterations progress. It is very easy\nto parallelize our algorithm without any form of shared memory, which makes it\npossible to use it on very large graphs with a much higher dimensionality of\nthe embeddings. We study the efficacy of proposed method on several benchmark\ndata sets and favorably compare with state of the art methods. Further,\nproposed method is applied to generate relevant recommendations for a large\nretailer.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 02:45:43 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 20:55:07 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 23:28:36 GMT"}, {"version": "v4", "created": "Thu, 20 Feb 2020 21:25:36 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Shah", "Shalin", ""], ["Kini", "Venkataramana", ""]]}, {"id": "1908.08045", "submitter": "Miles Cranmer", "authors": "Miles D. Cranmer, Richard Galvez, Lauren Anderson, David N. Spergel,\n  Shirley Ho", "title": "Modeling the Gaia Color-Magnitude Diagram with Bayesian Neural Flows to\n  Constrain Distance Estimates", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.GA cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate an algorithm for learning a flexible color-magnitude diagram\nfrom noisy parallax and photometry measurements using a normalizing flow, a\ndeep neural network capable of learning an arbitrary multi-dimensional\nprobability distribution. We present a catalog of 640M photometric distance\nposteriors to nearby stars derived from this data-driven model using Gaia DR2\nphotometry and parallaxes. Dust estimation and dereddening is done iteratively\ninside the model and without prior distance information, using the Bayestar\nmap. The signal-to-noise (precision) of distance measurements improves on\naverage by more than 48% over the raw Gaia data, and we also demonstrate how\nthe accuracy of distances have improved over other models, especially in the\nnoisy-parallax regime. Applications are discussed, including significantly\nimproved Milky Way disk separation and substructure detection. We conclude with\na discussion of future work, which exploits the normalizing flow architecture\nto allow us to exactly marginalize over missing photometry, enabling the\ninclusion of many surveys without losing coverage.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 18:00:00 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Cranmer", "Miles D.", ""], ["Galvez", "Richard", ""], ["Anderson", "Lauren", ""], ["Spergel", "David N.", ""], ["Ho", "Shirley", ""]]}, {"id": "1908.08082", "submitter": "Tim Capes", "authors": "Tim Capes, Vishal Raheja, Mete Kemertas, Iqbal Mohomed", "title": "Dynamic Scheduling of MPI-based Distributed Deep Learning Training Jobs", "comments": null, "journal-ref": "Published at MLSys Workshop @ NeurIPS 2018\n  (https://nips.cc/Conferences/2018/Schedule?showEvent=10919) December 7th,\n  2018", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a general trend towards solving problems suited to deep learning\nwith more complex deep learning architectures trained on larger training sets.\nThis requires longer compute times and greater data parallelization or model\nparallelization. Both data and model parallelism have been historically faster\nin parameter server architectures, but data parallelism is starting to be\nfaster in ring architectures due to algorithmic improvements. In this paper, we\nanalyze the math behind ring architectures and make an informed adaptation of\ndynamic scheduling to ring architectures. To do so, we formulate a non-convex,\nnon-linear, NP-hard integer programming problem and a new efficient doubling\nheuristic for its solution. We build upon Horovod: an open source ring\narchitecture framework over TensorFlow. We show that Horovod jobs have a low\ncost to stop and restart and that stopping and restarting ring architecture\njobs leads to faster completion times. These two facts make dynamic scheduling\nof ring architecture jobs feasible. Lastly, we simulate a scheduler using these\nruns and show a more than halving of average job time on some workload\npatterns.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 18:49:26 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Capes", "Tim", ""], ["Raheja", "Vishal", ""], ["Kemertas", "Mete", ""], ["Mohomed", "Iqbal", ""]]}, {"id": "1908.08098", "submitter": "Waheed Bajwa", "authors": "Zhixiong Yang and Waheed U. Bajwa", "title": "BRIDGE: Byzantine-resilient Decentralized Gradient Descent", "comments": "18 pages, 1 figure, 1 table; preprint of a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.MA eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized optimization techniques are increasingly being used to learn\nmachine learning models from data distributed over multiple locations without\ngathering the data at any one location. Unfortunately, methods that are\ndesigned for faultless networks typically fail in the presence of node\nfailures. In particular, Byzantine failures---corresponding to the scenario in\nwhich faulty/compromised nodes are allowed to arbitrarily deviate from an\nagreed-upon protocol---are the hardest to safeguard against in decentralized\nsettings. This paper introduces a Byzantine-resilient decentralized gradient\ndescent (BRIDGE) method for decentralized learning that, when compared to\nexisting works, is more efficient and scalable in higher-dimensional settings\nand that is deployable in networks having topologies that go beyond the star\ntopology. The main contributions of this work include theoretical analysis of\nBRIDGE for strongly convex learning objectives and numerical experiments\ndemonstrating the efficacy of BRIDGE for both convex and nonconvex learning\ntasks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 19:49:56 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Yang", "Zhixiong", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1908.08118", "submitter": "Yang Li", "authors": "Yang Li, Shihao Ji", "title": "Neural Plasticity Networks", "comments": "Published as a conference paper at IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural plasticity is an important functionality of human brain, in which\nnumber of neurons and synapses can shrink or expand in response to stimuli\nthroughout the span of life. We model this dynamic learning process as an\n$L_0$-norm regularized binary optimization problem, in which each unit of a\nneural network (e.g., weight, neuron or channel, etc.) is attached with a\nstochastic binary gate, whose parameters determine the level of activity of a\nunit in the network. At the beginning, only a small portion of binary gates\n(therefore the corresponding neurons) are activated, while the remaining\nneurons are in a hibernation mode. As the learning proceeds, some neurons might\nbe activated or deactivated if doing so can be justified by the cost-benefit\ntradeoff measured by the $L_0$-norm regularized objective. As the training gets\nmature, the probability of transition between activation and deactivation will\ndiminish until a final hardening stage. We demonstrate that all of these\nlearning dynamics can be modulated by a single parameter $k$ seamlessly. Our\nneural plasticity network (NPN) can prune or expand a network depending on the\ninitial capacity of network provided by the user; it also unifies dropout (when\n$k=0$), traditional training of DNNs (when $k=\\infty$) and interpolates between\nthese two. To the best of our knowledge, this is the first learning framework\nthat unifies network sparsification and network expansion in an end-to-end\ntraining pipeline. Extensive experiments on synthetic dataset and multiple\nimage classification benchmarks demonstrate the superior performance of NPN. We\nshow that both network sparsification and network expansion can yield compact\nmodels of similar architectures, while retaining competitive accuracies of the\noriginal networks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 18:57:30 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 17:45:55 GMT"}, {"version": "v3", "created": "Sun, 2 May 2021 03:23:16 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Li", "Yang", ""], ["Ji", "Shihao", ""]]}, {"id": "1908.08142", "submitter": "Cuong Nguyen", "authors": "Anh T. Tran, Cuong V. Nguyen, Tal Hassner", "title": "Transferability and Hardness of Supervised Classification Tasks", "comments": "This paper is published at the International Conference on Computer\n  Vision (ICCV) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for estimating the difficulty and transferability\nof supervised classification tasks. Unlike previous work, our approach is\nsolution agnostic and does not require or assume trained models. Instead, we\nestimate these values using an information theoretic approach: treating\ntraining labels as random variables and exploring their statistics. When\ntransferring from a source to a target task, we consider the conditional\nentropy between two such variables (i.e., label assignments of the two tasks).\nWe show analytically and empirically that this value is related to the loss of\nthe transferred model. We further show how to use this value to estimate task\nhardness. We test our claims extensively on three large scale data sets --\nCelebA (40 tasks), Animals with Attributes 2 (85 tasks), and Caltech-UCSD Birds\n200 (312 tasks) -- together representing 437 classification tasks. We provide\nresults showing that our hardness and transferability estimates are strongly\ncorrelated with empirical hardness and transferability. As a case study, we\ntransfer a learned face recognition model to CelebA attribute classification\ntasks, showing state of the art accuracy for tasks estimated to be highly\ntransferable.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 23:35:48 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Tran", "Anh T.", ""], ["Nguyen", "Cuong V.", ""], ["Hassner", "Tal", ""]]}, {"id": "1908.08145", "submitter": "Anirvan M. Sengupta", "authors": "Alexander Genkin, Anirvan M. Sengupta and Dmitri Chklovskii", "title": "A Neural Network for Semi-Supervised Learning on Manifolds", "comments": "12 pages, 4 figures, accepted in ICANN 2019", "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2019 (pp.\n  375-386). Springer International Publishing", "doi": "10.1007/978-3-030-30487-4_30", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning algorithms typically construct a weighted graph of\ndata points to represent a manifold. However, an explicit graph representation\nis problematic for neural networks operating in the online setting. Here, we\npropose a feed-forward neural network capable of semi-supervised learning on\nmanifolds without using an explicit graph representation. Our algorithm uses\nchannels that represent localities on the manifold such that correlations\nbetween channels represent manifold structure. The proposed neural network has\ntwo layers. The first layer learns to build a representation of low-dimensional\nmanifolds in the input data as proposed recently in [8]. The second learns to\nclassify data using both occasional supervision and similarity of the manifold\nrepresentation of the data. The channel carrying label information for the\nsecond layer is assumed to be \"silent\" most of the time. Learning in both\nlayers is Hebbian, making our network design biologically plausible. We\nexperimentally demonstrate the effect of semi-supervised learning on\nnon-trivial manifolds.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 23:43:30 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Genkin", "Alexander", ""], ["Sengupta", "Anirvan M.", ""], ["Chklovskii", "Dmitri", ""]]}, {"id": "1908.08169", "submitter": "Yayong Li", "authors": "Yayong Li, Jie Yin, Ling Chen", "title": "SEAL: Semi-supervised Adversarial Active Learning on Attributed Graphs", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.3009682", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active learning (AL) on attributed graphs has received increasing attention\nwith the prevalence of graph-structured data. Although AL has been widely\nstudied for alleviating label sparsity issues with the conventional non-related\ndata, how to make it effective over attributed graphs remains an open research\nquestion. Existing AL algorithms on graphs attempt to reuse the classic AL\nquery strategies designed for non-related data. However, they suffer from two\nmajor limitations. First, different AL query strategies calculated in distinct\nscoring spaces are often naively combined to determine which nodes to be\nlabelled. Second, the AL query engine and the learning of the classifier are\ntreated as two separating processes, resulting in unsatisfactory performance.\nIn this paper, we propose a SEmi-supervised Adversarial active Learning (SEAL)\nframework on attributed graphs, which fully leverages the representation power\nof deep neural networks and devises a novel AL query strategy in an adversarial\nway. Our framework learns two adversarial components: a graph embedding network\nthat encodes both the unlabelled and labelled nodes into a latent space,\nexpecting to trick the discriminator to regard all nodes as already labelled,\nand a semi-supervised discriminator network that distinguishes the unlabelled\nfrom the existing labelled nodes in the latent space. The divergence score,\ngenerated by the discriminator in a unified latent space, serves as the\ninformativeness measure to actively select the most informative node to be\nlabelled by an oracle. The two adversarial components form a closed loop to\nmutually and simultaneously reinforce each other towards enhancing the active\nlearning performance. Extensive experiments on four real-world networks\nvalidate the effectiveness of the SEAL framework with superior performance\nimprovements to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 02:07:32 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 02:38:14 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Li", "Yayong", ""], ["Yin", "Jie", ""], ["Chen", "Ling", ""]]}, {"id": "1908.08200", "submitter": "Prathamesh Mayekar", "authors": "Prathamesh Mayekar and Himanshu Tyagi", "title": "RATQ: A Universal Fixed-Length Quantizer for Stochastic Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Rotated Adaptive Tetra-iterated Quantizer (RATQ), a fixed-length\nquantizer for gradients in first order stochastic optimization. RATQ is easy to\nimplement and involves only a Hadamard transform computation and adaptive\nuniform quantization with appropriately chosen dynamic ranges. For noisy\ngradients with almost surely bounded Euclidean norms, we establish an\ninformation theoretic lower bound for optimization accuracy using finite\nprecision gradients and show that RATQ almost attains this lower bound.\n  For mean square bounded noisy gradients, we use a gain-shape quantizer which\nseparately quantizes the Euclidean norm and uses RATQ to quantize the\nnormalized unit norm vector. We establish lower bounds for performance of any\noptimization procedure and shape quantizer, when used with a uniform gain\nquantizer. Finally, we propose an adaptive quantizer for gain which when used\nwith RATQ for shape quantizer outperforms uniform gain quantization and is, in\nfact, close to optimal.\n  As a by-product, we show that our fixed-length quantizer RATQ has almost the\nsame performance as the optimal variable-length quantizers for distributed mean\nestimation. Also, we obtain an efficient quantizer for Gaussian vectors which\nattains a rate very close to the Gaussian rate-distortion function and is, in\nfact, universal for subgaussian input vectors.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 04:57:22 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 04:56:31 GMT"}, {"version": "v3", "created": "Mon, 16 Dec 2019 16:26:36 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Mayekar", "Prathamesh", ""], ["Tyagi", "Himanshu", ""]]}, {"id": "1908.08204", "submitter": "Yong-Ho Yoo", "authors": "Yong-Ho Yoo, Ue-Hwan Kim, and Jong-Hwan Kim", "title": "Convolutional Recurrent Reconstructive Network for Spatiotemporal\n  Anomaly Detection in Solder Paste Inspection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surface mount technology (SMT) is a process for producing printed circuit\nboards. Solder paste printer (SPP), package mounter, and solder reflow oven are\nused for SMT. The board on which the solder paste is deposited from the SPP is\nmonitored by solder paste inspector (SPI). If SPP malfunctions due to the\nprinter defects, the SPP produces defective products, and then abnormal\npatterns are detected by SPI. In this paper, we propose a convolutional\nrecurrent reconstructive network (CRRN), which decomposes the anomaly patterns\ngenerated by the printer defects, from SPI data. CRRN learns only normal data\nand detects anomaly pattern through reconstruction error. CRRN consists of a\nspatial encoder (S-Encoder), a spatiotemporal encoder and decoder\n(ST-Encoder-Decoder), and a spatial decoder (S-Decoder). The ST-Encoder-Decoder\nconsists of multiple convolutional spatiotemporal memories (CSTMs) with\nST-Attention mechanism. CSTM is developed to extract spatiotemporal patterns\nefficiently. Additionally, a spatiotemporal attention (ST-Attention) mechanism\nis designed to facilitate transmitting information from the ST-Encoder to the\nST-Decoder, which can solve the long-term dependency problem. We demonstrate\nthe proposed CRRN outperforms the other conventional models in anomaly\ndetection. Moreover, we show the discriminative power of the anomaly map\ndecomposed by the proposed CRRN through the printer defect classification.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 05:18:41 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Yoo", "Yong-Ho", ""], ["Kim", "Ue-Hwan", ""], ["Kim", "Jong-Hwan", ""]]}, {"id": "1908.08223", "submitter": "Junghoon Seo", "authors": "Yooseung Wang, Junghoon Seo, and Taegyun Jeon", "title": "NL-LinkNet: Toward Lighter but More Accurate Road Extraction with\n  Non-Local Operations", "comments": "IEEE Geoscience and Remote Sensing Letters (2020, to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road extraction from very high resolution satellite (VHR) images is one of\nthe most important topics in the field of remote sensing. In this paper, we\npropose an efficient Non-Local LinkNet with non-local blocks that can grasp\nrelations between global features. This enables each spatial feature point to\nrefer to all other contextual information and results in more accurate road\nsegmentation. In detail, our single model without any post-processing like CRF\nrefinement, performed better than any other published state-of-the-art ensemble\nmodel in the official DeepGlobe Challenge. Moreover, our NL-LinkNet beat the\nD-LinkNet, the winner of the DeepGlobe challenge, with 43 \\% less parameters,\nless giga floating-point operations per seconds (GFLOPs) and shorter training\nconvergence time. We also present empirical analyses on the proper usages of\nnon-local blocks for the baseline model.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 06:56:57 GMT"}, {"version": "v2", "created": "Fri, 23 Oct 2020 06:29:12 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 10:25:37 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Wang", "Yooseung", ""], ["Seo", "Junghoon", ""], ["Jeon", "Taegyun", ""]]}, {"id": "1908.08258", "submitter": "Favour Mandanji Nyikosa", "authors": "Favour M. Nyikosa, Michael A. Osborne, Stephen J. Roberts", "title": "Adaptive Configuration Oracle for Online Portfolio Selection Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial markets are complex environments that produce enormous amounts of\nnoisy and non-stationary data. One fundamental problem is online portfolio\nselection, the goal of which is to exploit this data to sequentially select\nportfolios of assets to achieve positive investment outcomes while managing\nrisks. Various algorithms have been proposed for solving this problem in fields\nsuch as finance, statistics and machine learning, among others. Most of the\nmethods have parameters that are estimated from backtests for good performance.\nSince these algorithms operate on non-stationary data that reflects the\ncomplexity of financial markets, we posit that adaptively tuning these\nparameters in an intelligent manner is a remedy for dealing with this\ncomplexity. In this paper, we model the mapping between the parameter space and\nthe space of performance metrics using a Gaussian process prior. We then\npropose an oracle based on adaptive Bayesian optimization for automatically and\nadaptively configuring online portfolio selection methods. We test the efficacy\nof our solution on algorithms operating on equity and index data from various\nmarkets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 08:46:55 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Nyikosa", "Favour M.", ""], ["Osborne", "Michael A.", ""], ["Roberts", "Stephen J.", ""]]}, {"id": "1908.08281", "submitter": "Georgios Karantaidis", "authors": "Georgios Karantaidis, Ioannis Sarridis, Constantine Kotropoulos", "title": "Block Randomized Optimization for Adaptive Hypergraph Learning", "comments": "5 pages, 1 figure, International Conference on Image Processing\n  (ICIP) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The high-order relations between the content in social media sharing\nplatforms are frequently modeled by a hypergraph. Either hypergraph Laplacian\nmatrix or the adjacency matrix is a big matrix. Randomized algorithms are used\nfor low-rank factorizations in order to approximately decompose and eventually\ninvert such big matrices fast. Here, block randomized Singular Value\nDecomposition (SVD) via subspace iteration is integrated within adaptive\nhypergraph weight estimation for image tagging, as a first approach.\nSpecifically, creating low-rank submatrices along the main diagonal by\ntessellation permits fast matrix inversions via randomized SVD. Moreover, a\nsecond approach is proposed for solving the linear system in the optimization\nproblem of hypergraph learning by employing the conjugate gradient method. Both\nproposed approaches achieve high accuracy in image tagging measured by F1 score\nand succeed to reduce the computational requirements of adaptive hypergraph\nweight estimation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 09:41:04 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Karantaidis", "Georgios", ""], ["Sarridis", "Ioannis", ""], ["Kotropoulos", "Constantine", ""]]}, {"id": "1908.08286", "submitter": "Hao Ni", "authors": "Shujian Liao, Terry Lyons, Weixin Yang, and Hao Ni", "title": "Learning stochastic differential equations using RNN with log signature\n  features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes to the challenge of learning a function on streamed\nmultimodal data through evaluation. The core of the result of our paper is the\ncombination of two quite different approaches to this problem. One comes from\nthe mathematically principled technology of signatures and log-signatures as\nrepresentations for streamed data, while the other draws on the techniques of\nrecurrent neural networks (RNN). The ability of the former to manage high\nsample rate streams and the latter to manage large scale nonlinear interactions\nallows hybrid algorithms that are easy to code, quicker to train, and of lower\ncomplexity for a given accuracy.\n  We illustrate the approach by approximating the unknown functional as a\ncontrolled differential equation. Linear functionals on solutions of controlled\ndifferential equations are the natural universal class of functions on data\nstreams. Following this approach, we propose a hybrid Logsig-RNN algorithm that\nlearns functionals on streamed data. By testing on various datasets, i.e.\nsynthetic data, NTU RGB+D 120 skeletal action data, and Chalearn2013 gesture\ndata, our algorithm achieves the outstanding accuracy with superior efficiency\nand robustness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 09:58:58 GMT"}, {"version": "v2", "created": "Sun, 22 Sep 2019 18:10:13 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Liao", "Shujian", ""], ["Lyons", "Terry", ""], ["Yang", "Weixin", ""], ["Ni", "Hao", ""]]}, {"id": "1908.08314", "submitter": "Benjamin Donnot", "authors": "Benjamin Donnot (TAU), Balthazar Donon (TAU), Isabelle Guyon (TAU),\n  Zhengying Liu (TAU), Antoine Marot, Patrick Panciatici, Marc Schoenauer (TAU)", "title": "LEAP nets for power grid perturbations", "comments": null, "journal-ref": "ESANN, Apr 2019, Bruges, Belgium", "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural network embedding approach to model power\ntransmission grids, in which high voltage lines are disconnected and\nreconnected with one-another from time to time, either accidentally or\nwillfully. We call our architeture LEAP net, for Latent Encoding of Atypical\nPerturbation. Our method implements a form of transfer learning, permitting to\ntrain on a few source domains, then generalize to new target domains, without\nlearning on any example of that domain. We evaluate the viability of this\ntechnique to rapidly assess cu-rative actions that human operators take in\nemergency situations, using real historical data, from the French high voltage\npower grid.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 11:16:32 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Donnot", "Benjamin", "", "TAU"], ["Donon", "Balthazar", "", "TAU"], ["Guyon", "Isabelle", "", "TAU"], ["Liu", "Zhengying", "", "TAU"], ["Marot", "Antoine", "", "TAU"], ["Panciatici", "Patrick", "", "TAU"], ["Schoenauer", "Marc", "", "TAU"]]}, {"id": "1908.08339", "submitter": "Wei Lu", "authors": "Guoliang Feng, Wei Lu, Witold Pedrycz, Jianhua Yang, and Xiaodong Liu", "title": "The Learning of Fuzzy Cognitive Maps With Noisy Data: A Rapid and Robust\n  Learning Method With Maximum Entropy", "comments": "The manuscript has been published on IEEE Transactions on Cybernetics", "journal-ref": null, "doi": "10.1109/TCYB.2019.2933438", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous learning methods for fuzzy cognitive maps (FCMs), such as the\nHebbian-based and the population-based learning methods, have been developed\nfor modeling and simulating dynamic systems. However, these methods are faced\nwith several obvious limitations. Most of these models are extremely time\nconsuming when learning the large-scale FCMs with hundreds of nodes.\nFurthermore, the FCMs learned by those algorithms lack robustness when the\nexperimental data contain noise. In addition, reasonable distribution of the\nweights is rarely considered in these algorithms, which could result in the\nreduction of the performance of the resulting FCM. In this article, a\nstraightforward, rapid, and robust learning method is proposed to learn FCMs\nfrom noisy data, especially, to learn large-scale FCMs. The crux of the\nproposed algorithm is to equivalently transform the learning problem of FCMs to\na classic-constrained convex optimization problem in which the least-squares\nterm ensures the robustness of the well-learned FCM and the maximum entropy\nterm regularizes the distribution of the weights of the well-learned FCM. A\nseries of experiments covering two frequently used activation functions (the\nsigmoid and hyperbolic tangent functions) are performed on both synthetic\ndatasets with noise and real-world datasets. The experimental results show that\nthe proposed method is rapid and robust against data containing noise and that\nthe well-learned weights have better distribution. In addition, the FCMs\nlearned by the proposed method also exhibit superior performance in comparison\nwith the existing methods. Index Terms-Fuzzy cognitive maps (FCMs), maximum\nentropy, noisy data, rapid and robust learning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:39:37 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Feng", "Guoliang", ""], ["Lu", "Wei", ""], ["Pedrycz", "Witold", ""], ["Yang", "Jianhua", ""], ["Liu", "Xiaodong", ""]]}, {"id": "1908.08340", "submitter": "Hongyu Li", "authors": "Hongyu Li and Tianqi Han", "title": "An End-to-End Encrypted Neural Network for Gradient Updates Transmission\n  in Federated Learning", "comments": "8 pages, 3 figures", "journal-ref": "This paper is an extended version of a summary published in the\n  Proc. of 2019 Data Compression Conference (DCC). The 1-page summary in the\n  DCC proceedings can be found at: https://ieeexplore.ieee.org/document/8712695", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning is a distributed learning method to train a shared model\nby aggregating the locally-computed gradient updates. In federated learning,\nbandwidth and privacy are two main concerns of gradient updates transmission.\nThis paper proposes an end-to-end encrypted neural network for gradient updates\ntransmission. This network first encodes the input gradient updates to a\nlower-dimension space in each client, which significantly mitigates the\npressure of data communication in federated learning. The encoded gradient\nupdates are directly recovered as a whole, i.e. the aggregated gradient updates\nof the trained model, in the decoding layers of the network on the server. In\nthis way, gradient updates encrypted in each client are not only prevented from\ninterception during communication, but also unknown to the server. Based on the\nencrypted neural network, a novel federated learning framework is designed in\nreal applications. Experimental results show that the proposed network can\neffectively achieve two goals, privacy protection and data compression, under a\nlittle sacrifice of the model accuracy in federated learning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 12:41:32 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Li", "Hongyu", ""], ["Han", "Tianqi", ""]]}, {"id": "1908.08346", "submitter": "Saptarshi Bej", "authors": "Saptarshi Bej, Narek Davtyan, Markus Wolfien, Mariam Nassar, Olaf\n  Wolkenhauer", "title": "LoRAS: An oversampling approach for imbalanced datasets", "comments": "2 figures, Supplementary data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Synthetic Minority Oversampling TEchnique (SMOTE) is widely-used for the\nanalysis of imbalanced datasets. It is known that SMOTE frequently\nover-generalizes the minority class, leading to misclassifications for the\nmajority class, and effecting the overall balance of the model.\n  In this article, we present an approach that overcomes this limitation of\nSMOTE, employing Localized Random Affine Shadowsampling (LoRAS) to oversample\nfrom an approximated data manifold of the minority class.\n  We benchmarked our algorithm with 14 publicly available imbalanced datasets\nusing three different Machine Learning (ML) algorithms and compared the\nperformance of LoRAS, SMOTE and several SMOTE extensions that share the concept\nof using convex combinations of minority class data points for oversampling\nwith LoRAS. We observed that LoRAS, on average generates better ML models in\nterms of F1-Score and Balanced accuracy. Another key observation is that while\nmost of the extensions of SMOTE we have tested, improve the F1-Score with\nrespect to SMOTE on an average, they compromise on the Balanced accuracy of a\nclassification model. LoRAS on the contrary, improves both F1 Score and the\nBalanced accuracy thus produces better classification models.\n  Moreover, to explain the success of the algorithm, we have constructed a\nmathematical framework to prove that LoRAS oversampling technique provides a\nbetter estimate for the mean of the underlying local data distribution of the\nminority class data space.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:00:35 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 08:46:37 GMT"}, {"version": "v3", "created": "Thu, 19 Dec 2019 18:09:26 GMT"}, {"version": "v4", "created": "Sat, 15 Aug 2020 11:26:03 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Bej", "Saptarshi", ""], ["Davtyan", "Narek", ""], ["Wolfien", "Markus", ""], ["Nassar", "Mariam", ""], ["Wolkenhauer", "Olaf", ""]]}, {"id": "1908.08351", "submitter": "Dieuwke Hupkes", "authors": "Dieuwke Hupkes, Verna Dankers, Mathijs Mul, Elia Bruni", "title": "Compositionality decomposed: how do neural networks generalise?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite a multitude of empirical studies, little consensus exists on whether\nneural networks are able to generalise compositionally, a controversy that, in\npart, stems from a lack of agreement about what it means for a neural model to\nbe compositional. As a response to this controversy, we present a set of tests\nthat provide a bridge between, on the one hand, the vast amount of linguistic\nand philosophical theory about compositionality of language and, on the other,\nthe successful neural models of language. We collect different interpretations\nof compositionality and translate them into five theoretically grounded tests\nfor models that are formulated on a task-independent level. In particular, we\nprovide tests to investigate (i) if models systematically recombine known parts\nand rules (ii) if models can extend their predictions beyond the length they\nhave seen in the training data (iii) if models' composition operations are\nlocal or global (iv) if models' predictions are robust to synonym substitutions\nand (v) if models favour rules or exceptions during training. To demonstrate\nthe usefulness of this evaluation paradigm, we instantiate these five tests on\na highly compositional data set which we dub PCFG SET and apply the resulting\ntests to three popular sequence-to-sequence models: a recurrent, a\nconvolution-based and a transformer model. We provide an in-depth analysis of\nthe results, which uncover the strengths and weaknesses of these three\narchitectures and point to potential areas of improvement.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:08:26 GMT"}, {"version": "v2", "created": "Sun, 23 Feb 2020 15:42:10 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Hupkes", "Dieuwke", ""], ["Dankers", "Verna", ""], ["Mul", "Mathijs", ""], ["Bruni", "Elia", ""]]}, {"id": "1908.08368", "submitter": "Hongzhi Wang", "authors": "Hongzhi Wang, Yijie Yang and Yang Song", "title": "A General Data Renewal Model for Prediction Algorithms in Industrial\n  Data Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In industrial data analytics, one of the fundamental problems is to utilize\nthe temporal correlation of the industrial data to make timely predictions in\nthe production process, such as fault prediction and yield prediction. However,\nthe traditional prediction models are fixed while the conditions of the\nmachines change over time, thus making the errors of predictions increase with\nthe lapse of time. In this paper, we propose a general data renewal model to\ndeal with it. Combined with the similarity function and the loss function, it\nestimates the time of updating the existing prediction model, then updates it\naccording to the evaluation function iteratively and adaptively. We have\napplied the data renewal model to two prediction algorithms. The experiments\ndemonstrate that the data renewal model can effectively identify the changes of\ndata, update and optimize the prediction model so as to improve the accuracy of\nprediction.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:38:22 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Wang", "Hongzhi", ""], ["Yang", "Yijie", ""], ["Song", "Yang", ""]]}, {"id": "1908.08379", "submitter": "Joel Oren", "authors": "Dotan Di Castro, Joel Oren, Shie Mannor", "title": "Practical Risk Measures in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practical application of Reinforcement Learning (RL) often involves risk\nconsiderations. We study a generalized approximation scheme for risk measures,\nbased on Monte-Carlo simulations, where the risk measures need not necessarily\nbe \\emph{coherent}. We demonstrate that, even in simple problems, measures such\nas the variance of the reward-to-go do not capture the risk in a satisfactory\nmanner. In addition, we show how a risk measure can be derived from model's\nrealizations. We propose a neural architecture for estimating the risk and\nsuggest the risk critic architecture that can be use to optimize a policy under\ngeneral risk measures. We conclude our work with experiments that demonstrate\nthe efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:50:31 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Di Castro", "Dotan", ""], ["Oren", "Joel", ""], ["Mannor", "Shie", ""]]}, {"id": "1908.08380", "submitter": "Zachariah Carmichael", "authors": "Zachariah Carmichael, Humza Syed, Dhireesha Kudithipudi", "title": "Analysis of Wide and Deep Echo State Networks for Multiscale\n  Spatiotemporal Time Series Forecasting", "comments": "10 pages, 10 figures, Proceedings of the Neuro-inspired Computational\n  Elements Workshop (NICE '19), March 26-28, 2019, Albany, NY, USA", "journal-ref": null, "doi": "10.1145/3320288.3320303", "report-no": null, "categories": "eess.SP cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo state networks are computationally lightweight reservoir models inspired\nby the random projections observed in cortical circuitry. As interest in\nreservoir computing has grown, networks have become deeper and more intricate.\nWhile these networks are increasingly applied to nontrivial forecasting tasks,\nthere is a need for comprehensive performance analysis of deep reservoirs. In\nthis work, we study the influence of partitioning neurons given a budget and\nthe effect of parallel reservoir pathways across different datasets exhibiting\nmulti-scale and nonlinear dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:39:08 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Carmichael", "Zachariah", ""], ["Syed", "Humza", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1908.08389", "submitter": "Shujaat Khan Engr", "authors": "Alishba Sadiq, Muhammad Sohail Ibrahim, Muhammad Usman, Muhammad\n  Zubair and Shujaat Khan", "title": "Chaotic Time Series Prediction using Spatio-Temporal RBF Neural Networks", "comments": "Published in: 2018 3rd International Conference on Emerging Trends in\n  Engineering, Sciences and Technology (ICEEST). arXiv admin note: substantial\n  text overlap with arXiv:1908.01321", "journal-ref": null, "doi": "10.1109/ICEEST.2018.8643321", "report-no": null, "categories": "stat.ML cs.LG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the dynamic nature, chaotic time series are difficult predict. In\nconventional signal processing approaches signals are treated either in time or\nin space domain only. Spatio-temporal analysis of signal provides more\nadvantages over conventional uni-dimensional approaches by harnessing the\ninformation from both the temporal and spatial domains. Herein, we propose an\nspatio-temporal extension of RBF neural networks for the prediction of chaotic\ntime series. The proposed algorithm utilizes the concept of time-space\northogonality and separately deals with the temporal dynamics and spatial\nnon-linearity(complexity) of the chaotic series. The proposed RBF architecture\nis explored for the prediction of Mackey-Glass time series and results are\ncompared with the standard RBF. The spatio-temporal RBF is shown to out perform\nthe standard RBFNN by achieving significantly reduced estimation error.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 08:49:42 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Sadiq", "Alishba", ""], ["Ibrahim", "Muhammad Sohail", ""], ["Usman", "Muhammad", ""], ["Zubair", "Muhammad", ""], ["Khan", "Shujaat", ""]]}, {"id": "1908.08394", "submitter": "Guangzeng Xie", "authors": "Guangzeng Xie, Luo Luo, Zhihua Zhang", "title": "A General Analysis Framework of Lower Complexity Bounds for Finite-Sum\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the lower bound complexity for the optimization problem\nwhose objective function is the average of $n$ individual smooth convex\nfunctions. We consider the algorithm which gets access to gradient and proximal\noracle for each individual component. For the strongly-convex case, we prove\nsuch an algorithm can not reach an $\\varepsilon$-suboptimal point in fewer than\n$\\Omega((n+\\sqrt{\\kappa n})\\log(1/\\varepsilon))$ iterations, where $\\kappa$ is\nthe condition number of the objective function. This lower bound is tighter\nthan previous results and perfectly matches the upper bound of the existing\nproximal incremental first-order oracle algorithm Point-SAGA. We develop a\nnovel construction to show the above result, which partitions the tridiagonal\nmatrix of classical examples into $n$ groups. This construction is friendly to\nthe analysis of proximal oracle and also could be used to general convex and\naverage smooth cases naturally.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 14:02:46 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Xie", "Guangzeng", ""], ["Luo", "Luo", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1908.08401", "submitter": "Chen Zhong", "authors": "Chen Zhong, Ziyang Lu, M. Cenk Gursoy, and Senem Velipasalar", "title": "A Deep Actor-Critic Reinforcement Learning Framework for Dynamic\n  Multichannel Access", "comments": "14 figures. arXiv admin note: text overlap with arXiv:1810.03695", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make efficient use of limited spectral resources, we in this work propose\na deep actor-critic reinforcement learning based framework for dynamic\nmultichannel access. We consider both a single-user case and a scenario in\nwhich multiple users attempt to access channels simultaneously. We employ the\nproposed framework as a single agent in the single-user case, and extend it to\na decentralized multi-agent framework in the multi-user scenario. In both\ncases, we develop algorithms for the actor-critic deep reinforcement learning\nand evaluate the proposed learning policies via experiments and numerical\nresults. In the single-user model, in order to evaluate the performance of the\nproposed channel access policy and the framework's tolerance against\nuncertainty, we explore different channel switching patterns and different\nswitching probabilities. In the case of multiple users, we analyze the\nprobabilities of each user accessing channels with favorable channel conditions\nand the probability of collision. We also address a time-varying environment to\nidentify the adaptive ability of the proposed framework. Additionally, we\nprovide comparisons (in terms of both the average reward and time efficiency)\nbetween the proposed actor-critic deep reinforcement learning framework, Deep-Q\nnetwork (DQN) based approach, random access, and the optimal policy when the\nchannel dynamics are known.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 20:19:35 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Zhong", "Chen", ""], ["Lu", "Ziyang", ""], ["Gursoy", "M. Cenk", ""], ["Velipasalar", "Senem", ""]]}, {"id": "1908.08450", "submitter": "Mantas Luko\\v{s}evi\\v{c}ius", "authors": "Mantas Luko\\v{s}evi\\v{c}ius (1) and Arnas Uselis (1) ((1) Kaunas\n  University of Technology)", "title": "Efficient Cross-Validation of Echo State Networks", "comments": "Accepted in ICANN'19 Workshop on Reservoir Computing", "journal-ref": "Artificial Neural Networks and Machine Learning - ICANN 2019:\n  Workshop and Special Sessions. ICANN 2019., pp. 121-133", "doi": "10.1007/978-3-030-30493-5_12", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Echo State Networks (ESNs) are known for their fast and precise one-shot\nlearning of time series. But they often need good hyper-parameter tuning for\nbest performance. For this good validation is key, but usually, a single\nvalidation split is used. In this rather practical contribution we suggest\nseveral schemes for cross-validating ESNs and introduce an efficient algorithm\nfor implementing them. The component that dominates the time complexity of the\nalready quite fast ESN training remains constant (does not scale up with $k$)\nin our proposed method of doing $k$-fold cross-validation. The component that\ndoes scale linearly with $k$ starts dominating only in some not very common\nsituations. Thus in many situations $k$-fold cross-validation of ESNs can be\ndone for virtually the same time complexity as a simple single split\nvalidation. Space complexity can also remain the same. We also discuss when the\nproposed validation schemes for ESNs could be beneficial and empirically\ninvestigate them on several different real-world datasets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 15:26:04 GMT"}], "update_date": "2020-07-13", "authors_parsed": [["Luko\u0161evi\u010dius", "Mantas", ""], ["Uselis", "Arnas", ""]]}, {"id": "1908.08452", "submitter": "Swathi Mula", "authors": "Swathi M. Mula, Gerardo Veltri", "title": "A new measure of modularity density for community detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using an intuitive concept of what constitutes a meaningful community, a\nnovel metric is formulated for detecting non-overlapping communities in\nundirected, weighted heterogeneous networks. This metric, modularity density,\nis shown to be superior to the versions of modularity density in present\nliterature. Compared to the previous versions of modularity density,\nmaximization of our metric is proven to be free from bias and better detect\nweakly-separated communities particularly in heterogeneous networks. In\naddition to these characteristics, the computational running time of our\nmodularity density is found to be on par or faster than that of the previous\nvariants. Our findings further reveal that community detection by maximization\nof our metric is mathematically related to partitioning a network by\nminimization of the normalized cut criterion.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 15:27:37 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Mula", "Swathi M.", ""], ["Veltri", "Gerardo", ""]]}, {"id": "1908.08469", "submitter": "Hyunsik Jeon", "authors": "Hyunsik Jeon, Bonhun Koo, U Kang", "title": "Data Context Adaptation for Accurate Recommendation with Additional\n  Information", "comments": "10 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a sparse rating matrix and an auxiliary matrix of users or items, how\ncan we accurately predict missing ratings considering different data contexts\nof entities? Many previous studies proved that utilizing the additional\ninformation with rating data is helpful to improve the performance. However,\nexisting methods are limited in that 1) they ignore the fact that data contexts\nof rating and auxiliary matrices are different, 2) they have restricted\ncapability of expressing independence information of users or items, and 3)\nthey assume the relation between a user and an item is linear. We propose\nDaConA, a neural network based method for recommendation with a rating matrix\nand an auxiliary matrix. DaConA is designed with the following three main\nideas. First, we propose a data context adaptation layer to extract pertinent\nfeatures for different data contexts. Second, DaConA represents each entity\nwith latent interaction vector and latent independence vector. Unlike previous\nmethods, both of the two vectors are not limited in size. Lastly, while\nprevious matrix factorization based methods predict missing values through the\ninner-product of latent vectors, DaConA learns a non-linear function of them\nvia a neural network. We show that DaConA is a generalized algorithm including\nthe standard matrix factorization and the collective matrix factorization as\nspecial cases. Through comprehensive experiments on real-world datasets, we\nshow that DaConA provides the state-of-the-art accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 16:02:17 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Jeon", "Hyunsik", ""], ["Koo", "Bonhun", ""], ["Kang", "U", ""]]}, {"id": "1908.08479", "submitter": "Anna Ma", "authors": "Rachel Grotheer, Shuang Li, Anna Ma, Deanna Needell, Jing Qin", "title": "Iterative Hard Thresholding for Low CP-rank Tensor Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recovery of low-rank matrices from a small number of linear measurements is\nnow well-known to be possible under various model assumptions on the\nmeasurements. Such results demonstrate robustness and are backed with provable\ntheoretical guarantees. However, extensions to tensor recovery have only\nrecently began to be studied and developed, despite an abundance of practical\ntensor applications. Recently, a tensor variant of the Iterative Hard\nThresholding method was proposed and theoretical results were obtained that\nguarantee exact recovery of tensors with low Tucker rank. In this paper, we\nutilize the same tensor version of the Restricted Isometry Property (RIP) to\nextend these results for tensors with low CANDECOMP/PARAFAC (CP) rank. In doing\nso, we leverage recent results on efficient approximations of CP decompositions\nthat remove the need for challenging assumptions in prior works. We complement\nour theoretical findings with empirical results that showcase the potential of\nthe approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 16:20:38 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Grotheer", "Rachel", ""], ["Li", "Shuang", ""], ["Ma", "Anna", ""], ["Needell", "Deanna", ""], ["Qin", "Jing", ""]]}, {"id": "1908.08484", "submitter": "Teemu Roos", "authors": "Peter Gr\\\"unwald and Teemu Roos", "title": "Minimum Description Length Revisited", "comments": "to appear in International Journal of Mathematics for Industry", "journal-ref": null, "doi": "10.1142/S2661335219300018", "report-no": null, "categories": "stat.ME cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an up-to-date introduction to and overview of the Minimum Description\nLength (MDL) Principle, a theory of inductive inference that can be applied to\ngeneral problems in statistics, machine learning and pattern recognition. While\nMDL was originally based on data compression ideas, this introduction can be\nread without any knowledge thereof. It takes into account all major\ndevelopments since 2007, the last time an extensive overview was written. These\ninclude new methods for model selection and averaging and hypothesis testing,\nas well as the first completely general definition of {\\em MDL estimators}.\nIncorporating these developments, MDL can be seen as a powerful extension of\nboth penalized likelihood and Bayesian approaches, in which penalization\nfunctions and prior distributions are replaced by more general luckiness\nfunctions, average-case methodology is replaced by a more robust worst-case\napproach, and in which methods classically viewed as highly distinct, such as\nAIC vs BIC and cross-validation vs Bayes can, to a large extent, be viewed from\na unified perspective.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 11:42:56 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2019 13:54:57 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Gr\u00fcnwald", "Peter", ""], ["Roos", "Teemu", ""]]}, {"id": "1908.08489", "submitter": "Sasan Barak Dr", "authors": "Sasan Barak, Mahdi Nasiri, Mehrdad Rostamzadeh", "title": "Time series model selection with a meta-learning approach; evidence from\n  a pool of forecasting algorithms", "comments": "30 pages, 10 tables, and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  One of the challenging questions in time series forecasting is how to find\nthe best algorithm. In recent years, a recommender system scheme has been\ndeveloped for time series analysis using a meta-learning approach. This system\nselects the best forecasting method with consideration of the time series\ncharacteristics. In this paper, we propose a novel approach to focusing on some\nof the unanswered questions resulting from the use of meta-learning in time\nseries forecasting. Therefore, three main gaps in previous works are addressed\nincluding, analyzing various subsets of top forecasters as inputs for\nmeta-learners; evaluating the effect of forecasting error measures; and\nassessing the role of the dimensionality of the feature space on the\nforecasting errors of meta-learners. All of these objectives are achieved with\nthe help of a diverse state-of-the-art pool of forecasters and meta-learners.\nFor this purpose, first, a pool of forecasting algorithms is implemented on the\nNN5 competition dataset and ranked based on the two error measures. Then, six\nmachine-learning classifiers known as meta-learners, are trained on the\nextracted features of the time series in order to assign the most suitable\nforecasting method for the various subsets of the pool of forecasters.\nFurthermore, two-dimensionality reduction methods are implemented in order to\ninvestigate the role of feature space dimension on the performance of\nmeta-learners. In general, it was found that meta-learners were able to defeat\nall of the individual benchmark forecasters; this performance was improved even\nafter applying the feature selection method.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 16:49:30 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Barak", "Sasan", ""], ["Nasiri", "Mahdi", ""], ["Rostamzadeh", "Mehrdad", ""]]}, {"id": "1908.08497", "submitter": "Yuyang Gao", "authors": "Yuyang Gao, Lingfei Wu, Houman Homayoun, Liang Zhao", "title": "DynGraph2Seq: Dynamic-Graph-to-Sequence Interpretable Learning for\n  Health Stage Prediction in Online Health Forums", "comments": "6 pages. Accepted as ICDM 2019 Short Paper. Final Version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online health communities such as the online breast cancer forum enable\npatients (i.e., users) to interact and help each other within various\nsubforums, which are subsections of the main forum devoted to specific health\ntopics. The changing nature of the users' activities in different subforums can\nbe strong indicators of their health status changes. This additional\ninformation could allow health-care organizations to respond promptly and\nprovide additional help for the patient. However, modeling complex transitions\nof an individual user's activities among different subforums over time and\nlearning how these correspond to his/her health stage are extremely\nchallenging. In this paper, we first formulate the transition of user\nactivities as a dynamic graph with multi-attributed nodes, then formalize the\nhealth stage inference task as a dynamic graph-to-sequence learning problem,\nand hence propose a novel dynamic graph-to-sequence neural networks\narchitecture (DynGraph2Seq) to address all the challenges. Our proposed\nDynGraph2Seq model consists of a novel dynamic graph encoder and an\ninterpretable sequence decoder that learn the mapping between a sequence of\ntime-evolving user activity graphs and a sequence of target health stages. We\ngo on to propose dynamic graph hierarchical attention mechanisms to facilitate\nthe necessary multi-level interpretability. A comprehensive experimental\nanalysis of its use for a health stage prediction task demonstrates both the\neffectiveness and the interpretability of the proposed models.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:06:59 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Gao", "Yuyang", ""], ["Wu", "Lingfei", ""], ["Homayoun", "Houman", ""], ["Zhao", "Liang", ""]]}, {"id": "1908.08507", "submitter": "Ningyu Zhang", "authors": "Ningyu Zhang, Shumin Deng, Zhanlin Sun, Jiaoyan Chen, Wei Zhang,\n  Huajun Chen", "title": "Transfer Learning for Relation Extraction via Relation-Gated Adversarial\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction aims to extract relational facts from sentences. Previous\nmodels mainly rely on manually labeled datasets, seed instances or\nhuman-crafted patterns, and distant supervision. However, the human annotation\nis expensive, while human-crafted patterns suffer from semantic drift and\ndistant supervision samples are usually noisy. Domain adaptation methods enable\nleveraging labeled data from a different but related domain. However, different\ndomains usually have various textual relation descriptions and different label\nspace (the source label space is usually a superset of the target label space).\nTo solve these problems, we propose a novel model of relation-gated adversarial\nlearning for relation extraction, which extends the adversarial based domain\nadaptation. Experimental results have shown that the proposed approach\noutperforms previous domain adaptation methods regarding partial domain\nadaptation and can improve the accuracy of distance supervised relation\nextraction through fine-tuning.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:27:54 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Zhang", "Ningyu", ""], ["Deng", "Shumin", ""], ["Sun", "Zhanlin", ""], ["Chen", "Jiaoyan", ""], ["Zhang", "Wei", ""], ["Chen", "Huajun", ""]]}, {"id": "1908.08526", "submitter": "Nathan Kallus", "authors": "Nathan Kallus, Masatoshi Uehara", "title": "Double Reinforcement Learning for Efficient Off-Policy Evaluation in\n  Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation (OPE) in reinforcement learning allows one to evaluate\nnovel decision policies without needing to conduct exploration, which is often\ncostly or otherwise infeasible. We consider for the first time the\nsemiparametric efficiency limits of OPE in Markov decision processes (MDPs),\nwhere actions, rewards, and states are memoryless. We show existing OPE\nestimators may fail to be efficient in this setting. We develop a new estimator\nbased on cross-fold estimation of $q$-functions and marginalized density\nratios, which we term double reinforcement learning (DRL). We show that DRL is\nefficient when both components are estimated at fourth-root rates and is also\ndoubly robust when only one component is consistent. We investigate these\nproperties empirically and demonstrate the performance benefits due to\nharnessing memorylessness.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:57:19 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 07:59:07 GMT"}, {"version": "v3", "created": "Fri, 5 Jun 2020 09:58:10 GMT"}], "update_date": "2020-06-08", "authors_parsed": [["Kallus", "Nathan", ""], ["Uehara", "Masatoshi", ""]]}, {"id": "1908.08529", "submitter": "Jyoti Aneja", "authors": "Jyoti Aneja, Harsh Agrawal, Dhruv Batra, Alexander Schwing", "title": "Sequential Latent Spaces for Modeling the Intention During Diverse Image\n  Captioning", "comments": "Accepted to ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse and accurate vision+language modeling is an important goal to retain\ncreative freedom and maintain user engagement. However, adequately capturing\nthe intricacies of diversity in language models is challenging. Recent works\ncommonly resort to latent variable models augmented with more or less\nsupervision from object detectors or part-of-speech tags. Common to all those\nmethods is the fact that the latent variable either only initializes the\nsentence generation process or is identical across the steps of generation.\nBoth methods offer no fine-grained control. To address this concern, we propose\nSeq-CVAE which learns a latent space for every word position. We encourage this\ntemporal latent space to capture the 'intention' about how to complete the\nsentence by mimicking a representation which summarizes the future. We\nillustrate the efficacy of the proposed approach to anticipate the sentence\ncontinuation on the challenging MSCOCO dataset, significantly improving\ndiversity metrics compared to baselines while performing on par w.r.t sentence\nquality.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:59:08 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Aneja", "Jyoti", ""], ["Agrawal", "Harsh", ""], ["Batra", "Dhruv", ""], ["Schwing", "Alexander", ""]]}, {"id": "1908.08563", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, M. Hadi Amini, and Hamid R. Arabnia", "title": "Applications of Nature-Inspired Algorithms for Dimension Reduction:\n  Enabling Efficient Data Analytics", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In [1], we have explored the theoretical aspects of feature selection and\nevolutionary algorithms. In this chapter, we focus on optimization algorithms\nfor enhancing data analytic process, i.e., we propose to explore applications\nof nature-inspired algorithms in data science. Feature selection optimization\nis a hybrid approach leveraging feature selection techniques and evolutionary\nalgorithms process to optimize the selected features. Prior works solve this\nproblem iteratively to converge to an optimal feature subset. Feature selection\noptimization is a non-specific domain approach. Data scientists mainly attempt\nto find an advanced way to analyze data n with high computational efficiency\nand low time complexity, leading to efficient data analytics. Thus, by\nincreasing generated/measured/sensed data from various sources, analysis,\nmanipulation and illustration of data grow exponentially. Due to the large\nscale data sets, Curse of dimensionality (CoD) is one of the NP-hard problems\nin data science. Hence, several efforts have been focused on leveraging\nevolutionary algorithms (EAs) to address the complex issues in large scale data\nanalytics problems. Dimension reduction, together with EAs, lends itself to\nsolve CoD and solve complex problems, in terms of time complexity, efficiently.\nIn this chapter, we first provide a brief overview of previous studies that\nfocused on solving CoD using feature extraction optimization process. We then\ndiscuss practical examples of research studies are successfully tackled some\napplication domains, such as image processing, sentiment analysis, network\ntraffics / anomalies analysis, credit score analysis and other benchmark\nfunctions/data sets analysis.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:01:09 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1908.08574", "submitter": "Anil Kag", "authors": "Anil Kag, Ziming Zhang, Venkatesh Saligrama", "title": "RNNs Evolving on an Equilibrium Manifold: A Panacea for Vanishing and\n  Exploding Gradients?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) are particularly well-suited for modeling\nlong-term dependencies in sequential data, but are notoriously hard to train\nbecause the error backpropagated in time either vanishes or explodes at an\nexponential rate. While a number of works attempt to mitigate this effect\nthrough gated recurrent units, well-chosen parametric constraints, and\nskip-connections, we develop a novel perspective that seeks to evolve the\nhidden state on the equilibrium manifold of an ordinary differential equation\n(ODE). We propose a family of novel RNNs, namely {\\em Equilibriated Recurrent\nNeural Networks} (ERNNs) that overcome the gradient decay or explosion effect\nand lead to recurrent models that evolve on the equilibrium manifold. We show\nthat equilibrium points are stable, leading to fast convergence of the\ndiscretized ODE to fixed points. Furthermore, ERNNs account for long-term\ndependencies, and can efficiently recall informative aspects of data from the\ndistant past. We show that ERNNs achieve state-of-the-art accuracy on many\nchallenging data sets with 3-10x speedups, 1.5-3x model size reduction, and\nwith similar prediction cost relative to vanilla RNNs.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:35:13 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 21:20:39 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Kag", "Anil", ""], ["Zhang", "Ziming", ""], ["Saligrama", "Venkatesh", ""]]}, {"id": "1908.08576", "submitter": "Yu Ye", "authors": "Yu Ye, Ming Xiao, Mikael Skoglund", "title": "Mobility-aware Content Preference Learning in Decentralized Caching\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the drastic increase of mobile traffic, wireless caching is proposed\nto serve repeated requests for content download. To determine the caching\nscheme for decentralized caching networks, the content preference learning\nproblem based on mobility prediction is studied. We first formulate preference\nprediction as a decentralized regularized multi-task learning (DRMTL) problem\nwithout considering the mobility of mobile terminals (MTs). The problem is\nsolved by a hybrid Jacobian and Gauss-Seidel proximal multi-block alternating\ndirection method (ADMM) based algorithm, which is proven to conditionally\nconverge to the optimal solution with a rate $O(1/k)$. Then we use the tool of\n\\textit{Markov renewal process} to predict the moving path and sojourn time for\nMTs, and integrate the mobility pattern with the DRMTL model by reweighting the\ntraining samples and introducing a transfer penalty in the objective. We solve\nthe problem and prove that the developed algorithm has the same convergence\nproperty but with different conditions. Through simulation we show the\nconvergence analysis on proposed algorithms. Our real trace driven experiments\nillustrate that the mobility-aware DRMTL model can provide a more accurate\nprediction on geography preference than DRMTL model. Besides, the hit ratio\nachieved by most popular proactive caching (MPC) policy with preference\npredicted by mobility-aware DRMTL outperforms the MPC with preference from\nDRMTL and random caching (RC) schemes.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:52:17 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Ye", "Yu", ""], ["Xiao", "Ming", ""], ["Skoglund", "Mikael", ""]]}, {"id": "1908.08578", "submitter": "Tao Li", "authors": "Tao Li and Quanyan Zhu", "title": "On Convergence Rate of Adaptive Multiscale Value Function Approximation\n  For Reinforcement Learning", "comments": "submitted to 2019 IEEE International Workshop MLSP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a generic framework for devising an adaptive\napproximation scheme for value function approximation in reinforcement\nlearning, which introduces multiscale approximation. The two basic ingredients\nare multiresolution analysis as well as tree approximation. Starting from\nsimple refinable functions, multiresolution analysis enables us to construct a\nwavelet system from which the basis functions are selected adaptively,\nresulting in a tree structure. Furthermore, we present the convergence rate of\nour multiscale approximation which does not depend on the regularity of basis\nfunctions.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 19:56:26 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Li", "Tao", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1908.08584", "submitter": "Beinan Wang", "authors": "Beinan Wang, John Glossner, Daniel Iancu, Georgi N. Gaydadjiev", "title": "Feedbackward Decoding for Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach for semantic segmentation that uses an encoder in\nthe reverse direction to decode. Many semantic segmentation networks adopt a\nfeedforward encoder-decoder architecture. Typically, an input is first\ndownsampled by the encoder to extract high-level semantic features and\ncontinues to be fed forward through the decoder module to recover low-level\nspatial clues. Our method works in an alternative direction that lets\ninformation flow backward from the last layer of the encoder towards the first.\nThe encoder performs encoding in the forward pass and the same network performs\ndecoding in the backward pass. Therefore, the encoder itself is also the\ndecoder. Compared to conventional encoder-decoder architectures, ours doesn't\nrequire additional layers for decoding and further reuses the encoder weights\nthereby reducing the total number of parameters required for processing. We\nshow by using only the 13 convolutional layers from VGG-16 plus one tiny\nclassification layer, our model significantly outperforms other frequently\ncited models that are also adapted from VGG-16. On the Cityscapes semantic\nsegmentation benchmark, our model uses 50.0% less parameters than SegNet and\nachieves an 18.1% higher \"IoU class\" score; it uses 28.3% less parameters than\nDeepLab LargeFOV and the achieved \"IoU class\" score is 3.9% higher; it uses\n89.1% fewer parameters than FCN-8s and the achieved \"IoU class\" score is 3.1%\nhigher. Our code will be publicly available on Github later.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 20:29:05 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Wang", "Beinan", ""], ["Glossner", "John", ""], ["Iancu", "Daniel", ""], ["Gaydadjiev", "Georgi N.", ""]]}, {"id": "1908.08593", "submitter": "Olga Kovaleva", "authors": "Olga Kovaleva, Alexey Romanov, Anna Rogers, Anna Rumshisky", "title": "Revealing the Dark Secrets of BERT", "comments": "Accepted to EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BERT-based architectures currently give state-of-the-art performance on many\nNLP tasks, but little is known about the exact mechanisms that contribute to\nits success. In the current work, we focus on the interpretation of\nself-attention, which is one of the fundamental underlying components of BERT.\nUsing a subset of GLUE tasks and a set of handcrafted features-of-interest, we\npropose the methodology and carry out a qualitative and quantitative analysis\nof the information encoded by the individual BERT's heads. Our findings suggest\nthat there is a limited set of attention patterns that are repeated across\ndifferent heads, indicating the overall model overparametrization. While\ndifferent heads consistently use the same attention patterns, they have varying\nimpact on performance across different tasks. We show that manually disabling\nattention in certain heads leads to a performance improvement over the regular\nfine-tuned BERT models.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 04:27:38 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:26:37 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Kovaleva", "Olga", ""], ["Romanov", "Alexey", ""], ["Rogers", "Anna", ""], ["Rumshisky", "Anna", ""]]}, {"id": "1908.08600", "submitter": "Caio Waisman", "authors": "Caio Waisman, Harikesh S. Nair, Carlos Carrion, Nan Xu", "title": "Online Causal Inference for Advertising in Real-Time Bidding Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.GT econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time bidding (RTB) systems, which leverage auctions to programmatically\nallocate user impressions to multiple competing advertisers, continue to enjoy\nwidespread success in digital advertising. Assessing the effectiveness of such\nadvertising remains a lingering challenge in research and practice. This paper\npresents a new experimental design to perform causal inference on advertising\nbought through such mechanisms. Our method leverages the economic structure of\nfirst- and second-price auctions, which are ubiquitous in RTB systems, embedded\nwithin a multi-armed bandit (MAB) setup for online adaptive experimentation. We\nimplement it via a modified Thompson sampling (TS) algorithm that estimates\ncausal effects of advertising while minimizing the costs of experimentation to\nthe advertiser by simultaneously learning the optimal bidding policy that\nmaximizes her expected payoffs from auction participation. Simulations show\nthat not only the proposed method successfully accomplishes the advertiser's\ngoals, but also does so at a much lower cost than more conventional\nexperimentation policies aimed at performing causal inference.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 21:13:03 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 21:14:43 GMT"}], "update_date": "2021-03-08", "authors_parsed": [["Waisman", "Caio", ""], ["Nair", "Harikesh S.", ""], ["Carrion", "Carlos", ""], ["Xu", "Nan", ""]]}, {"id": "1908.08609", "submitter": "Kai Middlebrook", "authors": "Kai Middlebrook, Kian Sheik", "title": "Song Hit Prediction: Predicting Billboard Hits Using Spotify Data", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we attempt to solve the Hit Song Science problem, which aims to\npredict which songs will become chart-topping hits. We constructed a dataset\nwith approximately 1.8 million hit and non-hit songs and extracted their audio\nfeatures using the Spotify Web API. We test four models on our dataset. Our\nbest model was random forest, which was able to predict Billboard song success\nwith 88% accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 22:10:08 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 18:39:45 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Middlebrook", "Kai", ""], ["Sheik", "Kian", ""]]}, {"id": "1908.08610", "submitter": "Muhammad Maaz", "authors": "Muhammad Maaz (Faculty of Health Sciences, McMaster University)", "title": "Viability of machine learning to reduce workload in systematic review\n  screenings in the health sciences: a working paper", "comments": "10 pages, 2 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic reviews, which summarize and synthesize all the current research\nin a specific topic, are a crucial component to academia. They are especially\nimportant in the biomedical and health sciences, where they synthesize the\nstate of medical evidence and conclude the best course of action for various\ndiseases, pathologies, and treatments. Due to the immense amount of literature\nthat exists, as well as the output rate of research, reviewing abstracts can be\na laborious process. Automation may be able to significantly reduce this\nworkload. Of course, such classifications are not easily automated due to the\npeculiar nature of written language. Machine learning may be able to help. This\npaper explored the viability and effectiveness of using machine learning\nmodelling to classify abstracts according to specific exclusion/inclusion\ncriteria, as would be done in the first stage of a systematic review. The\nspecific task was performing the classification of deciding whether an abstract\nis a randomized control trial (RCT) or not, a very common classification made\nin systematic reviews in the healthcare field. Random training/testing splits\nof an n=2042 dataset of labelled abstracts were repeatedly created (1000 times\nin total), with a model trained and tested on each of these instances. A Bayes\nclassifier as well as an SVM classifier were used, and compared to non-machine\nlearning, simplistic approaches to textual classification. An SVM classifier\nwas seen to be highly effective, yielding a 90% accuracy, as well as an F1\nscore of 0.84, and yielded a potential workload reduction of 70%. This shows\nthat machine learning has the potential to significantly revolutionize the\nabstract screening process in healthcare systematic reviews.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 22:13:32 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Maaz", "Muhammad", "", "Faculty of Health Sciences, McMaster University"]]}, {"id": "1908.08612", "submitter": "Daniel T Chang", "authors": "Daniel T. Chang", "title": "Tiered Graph Autoencoders with PyTorch Geometric for Molecular Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tiered latent representations and latent spaces for molecular graphs provide\na simple but effective way to explicitly represent and utilize groups (e.g.,\nfunctional groups), which consist of the atom (node) tier, the group tier and\nthe molecule (graph) tier. They can be learned using the tiered graph\nautoencoder architecture. In this paper we discuss adapting tiered graph\nautoencoders for use with PyTorch Geometric, for both the deterministic tiered\ngraph autoencoder model and the probabilistic tiered variational graph\nautoencoder model. We also discuss molecular structure information sources that\ncan be accessed to extract training data for molecular graphs. To support\ntransfer learning, a critical consideration is that the information must\nutilize standard unique molecule and constituent atom identifiers. As a result\nof using tiered graph autoencoders for deep learning, each molecular graph\npossesses tiered latent representations. At each tier, the latent\nrepresentation consists of: node features, edge indices, edge features,\nmembership matrix, and node embeddings. This enables the utilization and\nexploration of tiered molecular latent spaces, either individually (the node\ntier, the group tier, or the graph tier) or jointly, as well as navigation\nacross the tiers.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 22:23:24 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Chang", "Daniel T.", ""]]}, {"id": "1908.08616", "submitter": "Ahmad Mousavi", "authors": "Ahmad Mousavi, Zheming Gao, Lanshan Han, and Alvin Lim", "title": "Quadratic Surface Support Vector Machine with L1 Norm Regularization", "comments": null, "journal-ref": null, "doi": "10.3934/jimo.2021046", "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose $\\ell_1$ norm regularized quadratic surface support vector machine\nmodels for binary classification in supervised learning. We establish their\ndesired theoretical properties, including the existence and uniqueness of the\noptimal solution, reduction to the standard SVMs over (almost) linearly\nseparable data sets, and detection of true sparsity pattern over (almost)\nquadratically separable data sets if the penalty parameter of $\\ell_1$ norm is\nlarge enough. We also demonstrate their promising practical efficiency by\nconducting various numerical experiments on both synthetic and publicly\navailable benchmark data sets.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 23:00:28 GMT"}, {"version": "v2", "created": "Sat, 30 Jan 2021 21:58:16 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Mousavi", "Ahmad", ""], ["Gao", "Zheming", ""], ["Han", "Lanshan", ""], ["Lim", "Alvin", ""]]}, {"id": "1908.08619", "submitter": "Ruoxi Jia", "authors": "Ruoxi Jia, David Dao, Boxin Wang, Frances Ann Hubis, Nezihe Merve\n  Gurel, Bo Li, Ce Zhang, Costas J. Spanos, Dawn Song", "title": "Efficient Task-Specific Data Valuation for Nearest Neighbor Algorithms", "comments": null, "journal-ref": "PVLDB, 12(11): 1610-1623, 2019", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a data set $\\mathcal{D}$ containing millions of data points and a data\nconsumer who is willing to pay for \\$$X$ to train a machine learning (ML) model\nover $\\mathcal{D}$, how should we distribute this \\$$X$ to each data point to\nreflect its \"value\"? In this paper, we define the \"relative value of data\" via\nthe Shapley value, as it uniquely possesses properties with appealing\nreal-world interpretations, such as fairness, rationality and\ndecentralizability. For general, bounded utility functions, the Shapley value\nis known to be challenging to compute: to get Shapley values for all $N$ data\npoints, it requires $O(2^N)$ model evaluations for exact computation and\n$O(N\\log N)$ for $(\\epsilon, \\delta)$-approximation. In this paper, we focus on\none popular family of ML models relying on $K$-nearest neighbors ($K$NN). The\nmost surprising result is that for unweighted $K$NN classifiers and regressors,\nthe Shapley value of all $N$ data points can be computed, exactly, in $O(N\\log\nN)$ time -- an exponential improvement on computational complexity! Moreover,\nfor $(\\epsilon, \\delta)$-approximation, we are able to develop an algorithm\nbased on Locality Sensitive Hashing (LSH) with only sublinear complexity\n$O(N^{h(\\epsilon,K)}\\log N)$ when $\\epsilon$ is not too small and $K$ is not\ntoo large. We empirically evaluate our algorithms on up to $10$ million data\npoints and even our exact algorithm is up to three orders of magnitude faster\nthan the baseline approximation algorithm. The LSH-based approximation\nalgorithm can accelerate the value calculation process even further. We then\nextend our algorithms to other scenarios such as (1) weighed $K$NN classifiers,\n(2) different data points are clustered by different data curators, and (3)\nthere are data analysts providing computation who also requires proper\nvaluation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 23:09:27 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 02:45:43 GMT"}, {"version": "v3", "created": "Wed, 11 Sep 2019 04:46:57 GMT"}, {"version": "v4", "created": "Sun, 29 Mar 2020 06:05:56 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Jia", "Ruoxi", ""], ["Dao", "David", ""], ["Wang", "Boxin", ""], ["Hubis", "Frances Ann", ""], ["Gurel", "Nezihe Merve", ""], ["Li", "Bo", ""], ["Zhang", "Ce", ""], ["Spanos", "Costas J.", ""], ["Song", "Dawn", ""]]}, {"id": "1908.08642", "submitter": "Artemy Kolchinsky", "authors": "Artemy Kolchinsky", "title": "A novel approach to multivariate redundancy and synergy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a situation in which a set of $n$ \"source\" random variables\n$X_{1},\\dots,X_{n}$ have information about some \"target\" random variable $Y$.\nFor example, in neuroscience $Y$ might represent the state of an external\nstimulus and $X_{1},\\dots,X_{n}$ the activity of $n$ different brain regions.\nRecent work in information theory has considered how to decompose the\ninformation that the sources $X_{1},\\dots,X_{n}$ provide about the target $Y$\ninto separate terms such as (1) the \"redundant information\" that is shared\namong all of sources, (2) the \"unique information\" that is provided only by a\nsingle source, (3) the \"synergistic information\" that is provided by all\nsources only when considered jointly, and (4) the \"union information\" that is\nprovided by at least one source. We propose a novel framework deriving such a\ndecomposition that can be applied to any number of sources. Our measures are\nmotivated in three distinct ways: via a formal analogy to intersection and\nunion operators in set theory, via a decision-theoretic operationalization\nbased on Blackwell's theorem, and via an axiomatic derivation. A key aspect of\nour approach is that we relax the assumption that measures of redundancy and\nunion information should be related by the inclusion-exclusion principle. We\ndiscuss relations to previous proposals as well as possible generalizations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 02:33:27 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 01:37:06 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 20:25:58 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kolchinsky", "Artemy", ""]]}, {"id": "1908.08649", "submitter": "Waheed Bajwa", "authors": "Zhixiong Yang, Arpita Gang, and Waheed U. Bajwa", "title": "Adversary-resilient Distributed and Decentralized Statistical Inference\n  and Machine Learning: An Overview of Recent Advances Under the Byzantine\n  Threat Model", "comments": "24 pages, 6 figures, 2 tables; Published in IEEE Signal Processing\n  Magazine, May 2020 (Special Issue on \"Machine Learning From Distributed,\n  Streaming Data\")", "journal-ref": "IEEE Signal Processing Mag., vol. 37, no. 3, pp. 146-159, May 2020", "doi": "10.1109/MSP.2020.2973345", "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the last few decades have witnessed a huge body of work devoted to\ninference and learning in distributed and decentralized setups, much of this\nwork assumes a non-adversarial setting in which individual nodes---apart from\noccasional statistical failures---operate as intended within the algorithmic\nframework. In recent years, however, cybersecurity threats from malicious\nnon-state actors and rogue entities have forced practitioners and researchers\nto rethink the robustness of distributed and decentralized algorithms against\nadversarial attacks. As a result, we now have a plethora of algorithmic\napproaches that guarantee robustness of distributed and/or decentralized\ninference and learning under different adversarial threat models. Driven in\npart by the world's growing appetite for data-driven decision making, however,\nsecuring of distributed/decentralized frameworks for inference and learning\nagainst adversarial threats remains a rapidly evolving research area. In this\narticle, we provide an overview of some of the most recent developments in this\narea under the threat model of Byzantine attacks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 03:23:49 GMT"}, {"version": "v2", "created": "Sat, 8 Feb 2020 17:39:59 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 02:21:10 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Yang", "Zhixiong", ""], ["Gang", "Arpita", ""], ["Bajwa", "Waheed U.", ""]]}, {"id": "1908.08652", "submitter": "Suraj Tripathi", "authors": "Abhay Kumar, Nishant Jain, Suraj Tripathi, Chirag Singh, Kamal Krishna", "title": "MTCNET: Multi-task Learning Paradigm for Crowd Count Estimation", "comments": "5 pages, 3 figures, Accepted in IEEE AVSS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Multi-Task Learning (MTL) paradigm based deep neural network\narchitecture, called MTCNet (Multi-Task Crowd Network) for crowd density and\ncount estimation. Crowd count estimation is challenging due to the non-uniform\nscale variations and the arbitrary perspective of an individual image. The\nproposed model has two related tasks, with Crowd Density Estimation as the main\ntask and Crowd-Count Group Classification as the auxiliary task. The auxiliary\ntask helps in capturing the relevant scale-related information to improve the\nperformance of the main task. The main task model comprises two blocks: VGG-16\nfront-end for feature extraction and a dilated Convolutional Neural Network for\ndensity map generation. The auxiliary task model shares the same front-end as\nthe main task, followed by a CNN classifier. Our proposed network achieves 5.8%\nand 14.9% lower Mean Absolute Error (MAE) than the state-of-the-art methods on\nShanghaiTech dataset without using any data augmentation. Our model also\noutperforms with 10.5% lower MAE on UCF_CC_50 dataset.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 03:30:53 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Kumar", "Abhay", ""], ["Jain", "Nishant", ""], ["Tripathi", "Suraj", ""], ["Singh", "Chirag", ""], ["Krishna", "Kamal", ""]]}, {"id": "1908.08681", "submitter": "Diganta Misra", "authors": "Diganta Misra", "title": "Mish: A Self Regularized Non-Monotonic Activation Function", "comments": "Accepted to BMVC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose $\\textit{Mish}$, a novel self-regularized non-monotonic activation\nfunction which can be mathematically defined as: $f(x)=x\\tanh(softplus(x))$. As\nactivation functions play a crucial role in the performance and training\ndynamics in neural networks, we validated experimentally on several well-known\nbenchmarks against the best combinations of architectures and activation\nfunctions. We also observe that data augmentation techniques have a favorable\neffect on benchmarks like ImageNet-1k and MS-COCO across multiple\narchitectures. For example, Mish outperformed Leaky ReLU on YOLOv4 with a\nCSP-DarkNet-53 backbone on average precision ($AP_{50}^{val}$) by 2.1$\\%$ in\nMS-COCO object detection and ReLU on ResNet-50 on ImageNet-1k in Top-1 accuracy\nby $\\approx$1$\\%$ while keeping all other network parameters and\nhyperparameters constant. Furthermore, we explore the mathematical formulation\nof Mish in relation with the Swish family of functions and propose an intuitive\nunderstanding on how the first derivative behavior may be acting as a\nregularizer helping the optimization of deep neural networks. Code is publicly\navailable at https://github.com/digantamisra98/Mish.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 06:22:06 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 16:59:14 GMT"}, {"version": "v3", "created": "Thu, 13 Aug 2020 05:42:12 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Misra", "Diganta", ""]]}, {"id": "1908.08713", "submitter": "Valentin Emiya", "authors": "Luc Giffon, Valentin Emiya, Liva Ralaivola, Hachem Kadri", "title": "QuicK-means: Acceleration of K-means by learning a fast transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-means -- and the celebrated Lloyd algorithm -- is more than the clustering\nmethod it was originally designed to be. It has indeed proven pivotal to help\nincrease the speed of many machine learning and data analysis techniques such\nas indexing, nearest-neighbor search and prediction, data compression; its\nbeneficial use has been shown to carry over to the acceleration of kernel\nmachines (when using the Nystr\\\"om method). Here, we propose a fast extension\nof K-means, dubbed QuicK-means, that rests on the idea of expressing the matrix\nof the $K$ centroids as a product of sparse matrices, a feat made possible by\nrecent results devoted to find approximations of matrices as a product of\nsparse factors. Using such a decomposition squashes the complexity of the\nmatrix-vector product between the factorized $K \\times D$ centroid matrix\n$\\mathbf{U}$ and any vector from $\\mathcal{O}(K D)$ to $\\mathcal{O}(A \\log\nA+B)$, with $A=\\min (K, D)$ and $B=\\max (K, D)$, where $D$ is the dimension of\nthe training data. This drastic computational saving has a direct impact in the\nassignment process of a point to a cluster, meaning that it is not only\ntangible at prediction time, but also at training time, provided the\nfactorization procedure is performed during Lloyd's algorithm. We precisely\nshow that resorting to a factorization step at each iteration does not impair\nthe convergence of the optimization scheme and that, depending on the context,\nit may entail a reduction of the training time. Finally, we provide discussions\nand numerical simulations that show the versatility of our\ncomputationally-efficient QuicK-means algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 08:20:53 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Giffon", "Luc", ""], ["Emiya", "Valentin", ""], ["Ralaivola", "Liva", ""], ["Kadri", "Hachem", ""]]}, {"id": "1908.08729", "submitter": "Viet Anh Nguyen", "authors": "Daniel Kuhn, Peyman Mohajerin Esfahani, Viet Anh Nguyen, Soroosh\n  Shafieezadeh-Abadeh", "title": "Wasserstein Distributionally Robust Optimization: Theory and\n  Applications in Machine Learning", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many decision problems in science, engineering and economics are affected by\nuncertain parameters whose distribution is only indirectly observable through\nsamples. The goal of data-driven decision-making is to learn a decision from\nfinitely many training samples that will perform well on unseen test samples.\nThis learning task is difficult even if all training and test samples are drawn\nfrom the same distribution---especially if the dimension of the uncertainty is\nlarge relative to the training sample size. Wasserstein distributionally robust\noptimization seeks data-driven decisions that perform well under the most\nadverse distribution within a certain Wasserstein distance from a nominal\ndistribution constructed from the training samples. In this tutorial we will\nargue that this approach has many conceptual and computational benefits. Most\nprominently, the optimal decisions can often be computed by solving tractable\nconvex optimization problems, and they enjoy rigorous out-of-sample and\nasymptotic consistency guarantees. We will also show that Wasserstein\ndistributionally robust optimization has interesting ramifications for\nstatistical learning and motivates new approaches for fundamental learning\ntasks such as classification, regression, maximum likelihood estimation or\nminimum mean square error estimation, among others.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 09:28:21 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Kuhn", "Daniel", ""], ["Esfahani", "Peyman Mohajerin", ""], ["Nguyen", "Viet Anh", ""], ["Shafieezadeh-Abadeh", "Soroosh", ""]]}, {"id": "1908.08733", "submitter": "Fei Wang", "authors": "Fei Wang, Qi Liu, Enhong Chen, Zhenya Huang, Yuying Chen, Yu Yin, Zai\n  Huang, Shijin Wang", "title": "Neural Cognitive Diagnosis for Intelligent Education Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive diagnosis is a fundamental issue in intelligent education, which\naims to discover the proficiency level of students on specific knowledge\nconcepts. Existing approaches usually mine linear interactions of student\nexercising process by manual-designed function (e.g., logistic function), which\nis not sufficient for capturing complex relations between students and\nexercises. In this paper, we propose a general Neural Cognitive Diagnosis\n(NeuralCD) framework, which incorporates neural networks to learn the complex\nexercising interactions, for getting both accurate and interpretable diagnosis\nresults. Specifically, we project students and exercises to factor vectors and\nleverage multi neural layers for modeling their interactions, where the\nmonotonicity assumption is applied to ensure the interpretability of both\nfactors. Furthermore, we propose two implementations of NeuralCD by\nspecializing the required concepts of each exercise, i.e., the NeuralCDM with\ntraditional Q-matrix and the improved NeuralCDM+ exploring the rich text\ncontent. Extensive experimental results on real-world datasets show the\neffectiveness of NeuralCD framework with both accuracy and interpretability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 09:38:13 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 13:36:38 GMT"}, {"version": "v3", "created": "Tue, 3 Mar 2020 15:27:57 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Wang", "Fei", ""], ["Liu", "Qi", ""], ["Chen", "Enhong", ""], ["Huang", "Zhenya", ""], ["Chen", "Yuying", ""], ["Yin", "Yu", ""], ["Huang", "Zai", ""], ["Wang", "Shijin", ""]]}, {"id": "1908.08734", "submitter": "Christoph Schran", "authors": "Christoph Schran, J\\\"org Behler, Dominik Marx", "title": "Automated Fitting of Neural Network Potentials at Coupled Cluster\n  Accuracy: Protonated Water Clusters as Testing Ground", "comments": null, "journal-ref": null, "doi": "10.1021/acs.jctc.9b00805", "report-no": null, "categories": "physics.chem-ph cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly accurate potential energy surfaces are of key interest for the\ndetailed understanding and predictive modeling of chemical systems. In recent\nyears, several new types of force fields, which are based on machine learning\nalgorithms and fitted to ab initio reference calculations, have been introduced\nto meet this requirement. Here we show how high-dimensional neural network\npotentials can be employed to automatically generate the potential energy\nsurface of finite sized clusters at coupled cluster accuracy, namely\nCCSD(T*)-F12a/aug-cc-pVTZ. The developed automated procedure utilizes the\nestablished intrinsic properties of the model such that the configurations for\nthe training set are selected in an unbiased and efficient way to minimize the\ncomputational effort of expensive reference calculations. These ideas are\napplied to protonated water clusters from the hydronium cation, H$_3$O$^+$, up\nto the tetramer, H$_9$O$_{4}^{+}$, and lead to a single potential energy\nsurface that describes all these systems at essentially converged coupled\ncluster accuracy with a fitting error of 0.06 kJ/mol per atom. The fit is\nvalidated in detail for all clusters up to the tetramer and yields reliable\nresults not only for stationary points, but also for reaction pathways,\nintermediate configurations, as well as different sampling techniques. Per\ndesign the NNPs constructed in this fashion can handle very different\nconditions including the quantum nature of the nuclei and enhanced sampling\ntechniques covering very low as well as high temperatures. This enables fast\nand exhaustive exploration of the targeted protonated water clusters with\nessentially converged interactions. In addition, the automated process will\nallow one to tackle finite systems much beyond the present case.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 09:38:29 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 13:41:42 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Schran", "Christoph", ""], ["Behler", "J\u00f6rg", ""], ["Marx", "Dominik", ""]]}, {"id": "1908.08750", "submitter": "Alexej Klushyn", "authors": "Alexej Klushyn, Nutan Chen, Botond Cseke, Justin Bayer, Patrick van\n  der Smagt", "title": "Increasing the Generalisation Capacity of Conditional VAEs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of one-to-many mappings in supervised learning, where\na single instance has many different solutions of possibly equal cost. The\nframework of conditional variational autoencoders describes a class of methods\nto tackle such structured-prediction tasks by means of latent variables. We\npropose to incentivise informative latent representations for increasing the\ngeneralisation capacity of conditional variational autoencoders. To this end,\nwe modify the latent variable model by defining the likelihood as a function of\nthe latent variable only and introduce an expressive multimodal prior to enable\nthe model for capturing semantically meaningful features of the data. To\nvalidate our approach, we train our model on the Cornell Robot Grasping\ndataset, and modified versions of MNIST and Fashion-MNIST obtaining results\nthat show a significantly higher generalisation capability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 10:28:59 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 07:37:06 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Klushyn", "Alexej", ""], ["Chen", "Nutan", ""], ["Cseke", "Botond", ""], ["Bayer", "Justin", ""], ["van der Smagt", "Patrick", ""]]}, {"id": "1908.08769", "submitter": "Dittaya Wanvarie", "authors": "Kawisorn Kamtue, Kasina Euchukanonchai, Dittaya Wanvarie and Naruemon\n  Pratanwanich", "title": "Lukthung Classification Using Neural Networks on Lyrics and Audios", "comments": "ICSEC 2019 (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music genre classification is a widely researched topic in music information\nretrieval (MIR). Being able to automatically tag genres will benefit music\nstreaming service providers such as JOOX, Apple Music, and Spotify for their\ncontent-based recommendation. However, most studies on music classification\nhave been done on western songs which differ from Thai songs. Lukthung, a\ndistinctive and long-established type of Thai music, is one of the most popular\nmusic genres in Thailand and has a specific group of listeners. In this paper,\nwe develop neural networks to classify such Lukthung genre from others using\nboth lyrics and audios. Words used in Lukthung songs are particularly poetical,\nand their musical styles are uniquely composed of traditional Thai instruments.\nWe leverage these two main characteristics by building a lyrics model based on\nbag-of-words (BoW), and an audio model using a convolutional neural network\n(CNN) architecture. We then aggregate the intermediate features learned from\nboth models to build a final classifier. Our results show that the proposed\nthree models outperform all of the standard classifiers where the combined\nmodel yields the best $F_1$ score of 0.86, allowing Lukthung classification to\nbe applicable to personalized recommendation for Thai audience.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 11:55:13 GMT"}, {"version": "v2", "created": "Wed, 23 Oct 2019 09:43:51 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Kamtue", "Kawisorn", ""], ["Euchukanonchai", "Kasina", ""], ["Wanvarie", "Dittaya", ""], ["Pratanwanich", "Naruemon", ""]]}, {"id": "1908.08771", "submitter": "Sakira Hassan", "authors": "Syeda Sakira Hassan, Heikki Huttunen, Jari Niemi and Jussi Tohka", "title": "Bayesian Receiver Operating Characteristic Metric for Linear Classifiers", "comments": "Accepted in Pattern Recognition Letters", "journal-ref": null, "doi": "10.1016/j.patrec.2019.07.016", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel classifier accuracy metric: the Bayesian Area Under the\nReceiver Operating Characteristic Curve (CBAUC). The method estimates the area\nunder the ROC curve and is related to the recently proposed Bayesian Error\nEstimator. The metric can assess the quality of a classifier using only the\ntraining dataset without the need for computationally expensive\ncross-validation. We derive a closed-form solution of the proposed accuracy\nmetric for any linear binary classifier under the Gaussianity assumption, and\nstudy the accuracy of the proposed estimator using simulated and real-world\ndata. These experiments confirm that the closed-form CBAUC is both faster and\nmore accurate than conventional AUC estimators.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 11:58:42 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Hassan", "Syeda Sakira", ""], ["Huttunen", "Heikki", ""], ["Niemi", "Jari", ""], ["Tohka", "Jussi", ""]]}, {"id": "1908.08773", "submitter": "Victor Gallego", "authors": "Victor Gallego, Roi Naveiro, David Rios Insua, David Gomez-Ullate\n  Oteiza", "title": "Opponent Aware Reinforcement Learning", "comments": "Substantially extends the previous work:\n  https://www.aaai.org/ojs/index.php/AAAI/article/view/5106. This article draws\n  heavily from arXiv arXiv:1809.01560", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Threatened Markov Decision Processes (TMDPs) as an extension of\nthe classical Markov Decision Process framework for Reinforcement Learning\n(RL). TMDPs allow suporting a decision maker against potential opponents in a\nRL context. We also propose a level-k thinking scheme resulting in a novel\nlearning approach to deal with TMDPs. After introducing our framework and\nderiving theoretical results, relevant empirical evidence is given via\nextensive experiments, showing the benefits of accounting for adversaries in RL\nwhile the agent learns\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 04:19:12 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 14:20:44 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Gallego", "Victor", ""], ["Naveiro", "Roi", ""], ["Insua", "David Rios", ""], ["Oteiza", "David Gomez-Ullate", ""]]}, {"id": "1908.08783", "submitter": "Shantanu Mandal", "authors": "Shantanu Mandal, Todd A. Anderson, Javier S. Turek, Justin\n  Gottschlich, Shengtian Zhou, Abdullah Muzahid", "title": "Learning Fitness Functions for Machine Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of automatic software generation is known as Machine Programming.\nIn this work, we propose a framework based on genetic algorithms to solve this\nproblem. Although genetic algorithms have been used successfully for many\nproblems, one criticism is that hand-crafting its fitness function, the test\nthat aims to effectively guide its evolution, can be notably challenging. Our\nframework presents a novel approach to learn the fitness function using neural\nnetworks to predict values of ideal fitness functions. We also augment the\nevolutionary process with a minimally intrusive search heuristic. This\nheuristic improves the framework's ability to discover correct programs from\nones that are approximately correct and does so with negligible computational\noverhead. We compare our approach with several state-of-the-art program\nsynthesis methods and demonstrate that it finds more correct programs with\nfewer candidate program generations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 17:47:34 GMT"}, {"version": "v2", "created": "Tue, 10 Sep 2019 09:24:21 GMT"}, {"version": "v3", "created": "Mon, 24 Feb 2020 17:11:08 GMT"}, {"version": "v4", "created": "Thu, 17 Dec 2020 00:03:58 GMT"}, {"version": "v5", "created": "Sat, 23 Jan 2021 21:48:02 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Mandal", "Shantanu", ""], ["Anderson", "Todd A.", ""], ["Turek", "Javier S.", ""], ["Gottschlich", "Justin", ""], ["Zhou", "Shengtian", ""], ["Muzahid", "Abdullah", ""]]}, {"id": "1908.08807", "submitter": "Badong Chen", "authors": "Hao Wu, Ziyu Zhu, Jiayi Wang, Nanning Zheng, Badong Chen", "title": "An encoding framework with brain inner state for natural image\n  identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural encoding and decoding, which aim to characterize the relationship\nbetween stimuli and brain activities, have emerged as an important area in\ncognitive neuroscience. Traditional encoding models, which focus on feature\nextraction and mapping, consider the brain as an input-output mapper without\ninner states. In this work, inspired by the fact that human brain acts like a\nstate machine, we proposed a novel encoding framework that combines information\nfrom both the external world and the inner state to predict brain activity. The\nframework comprises two parts: forward encoding model that deals with visual\nstimuli and inner state model that captures influence from intrinsic\nconnections in the brain. The forward model can be any traditional encoding\nmodel, making the framework flexible. The inner state model is a linear model\nto utilize information in the prediction residuals of the forward model. The\nproposed encoding framework can achieve much better performance on natural\nimage identification from fMRI response than forwardonly models. The\nidentification accuracy will decrease slightly with the dataset size\nincreasing, but remain relatively stable with different identification methods.\nThe results confirm that the new encoding framework is effective and robust\nwhen used for brain decoding.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:41:49 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Wu", "Hao", ""], ["Zhu", "Ziyu", ""], ["Wang", "Jiayi", ""], ["Zheng", "Nanning", ""], ["Chen", "Badong", ""]]}, {"id": "1908.08810", "submitter": "Jannik Fischbach", "authors": "Jannik Fischbach, Maximilian Junker, Andreas Vogelsang, Dietmar\n  Freudenstein", "title": "Automated Generation of Test Models from Semi-Structured Requirements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  [Context:] Model-based testing is an instrument for automated generation of\ntest cases. It requires identifying requirements in documents, understanding\nthem syntactically and semantically, and then translating them into a test\nmodel. One light-weight language for these test models are Cause-Effect-Graphs\n(CEG) that can be used to derive test cases. [Problem:] The creation of test\nmodels is laborious and we lack an automated solution that covers the entire\nprocess from requirement detection to test model creation. In addition, the\nmajority of requirements is expressed in natural language (NL), which is hard\nto translate to test models automatically. [Principal Idea:] We build on the\nfact that not all NL requirements are equally unstructured. We found that 14 %\nof the lines in requirements documents of our industry partner contain\n\"pseudo-code\"-like descriptions of business rules. We apply Machine Learning to\nidentify such semi-structured requirements descriptions and propose a\nrule-based approach for their translation into CEGs. [Contribution:] We make\nthree contributions: (1) an algorithm for the automatic detection of\nsemi-structured requirements descriptions in documents, (2) an algorithm for\nthe automatic translation of the identified requirements into a CEG and (3) a\nstudy demonstrating that our proposed solution leads to 86 % time savings for\ntest model creation without loss of quality.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:02:20 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Fischbach", "Jannik", ""], ["Junker", "Maximilian", ""], ["Vogelsang", "Andreas", ""], ["Freudenstein", "Dietmar", ""]]}, {"id": "1908.08815", "submitter": "\\'Angel F. Garc\\'ia-Fern\\'andez", "authors": "\\'Angel F. Garc\\'ia-Fern\\'andez, Lennart Svensson", "title": "Spooky effect in optimal OSPA estimation and how GOSPA solves it", "comments": "This paper received the third best paper award at the 22nd\n  International Conference on Information Fusion, Ottawa, Canada, 2019. Matlab\n  code of the GOSPA metric can be found in https://github.com/abusajana/GOSPA .\n  Additional information on MTT can be found in the online course\n  https://www.youtube.com/channel/UCa2-fpj6AV8T6JK1uTRuFpw", "journal-ref": "Proceedings of the 22nd International Conference on Information\n  Fusion, 2019", "doi": null, "report-no": null, "categories": "eess.SP cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show the spooky effect at a distance that arises in optimal\nestimation of multiple targets with the optimal sub-pattern assignment (OSPA)\nmetric. This effect refers to the fact that if we have several independent\npotential targets at distant locations, a change in the probability of\nexistence of one of them can completely change the optimal estimation of the\nrest of the potential targets. As opposed to OSPA, the generalised OSPA (GOSPA)\nmetric ($\\alpha=2$) penalises localisation errors for properly detected\ntargets, false targets and missed targets. As a consequence, optimal GOSPA\nestimation aims to lower the number of false and missed targets, as well as the\nlocalisation error for properly detected targets, and avoids the spooky effect.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 13:21:42 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Garc\u00eda-Fern\u00e1ndez", "\u00c1ngel F.", ""], ["Svensson", "Lennart", ""]]}, {"id": "1908.08843", "submitter": "Mengnan Du", "authors": "Mengnan Du, Fan Yang, Na Zou, Xia Hu", "title": "Fairness in Deep Learning: A Computational Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is increasingly being used in high-stake decision making\napplications that affect individual lives. However, deep learning models might\nexhibit algorithmic discrimination behaviors with respect to protected groups,\npotentially posing negative impacts on individuals and society. Therefore,\nfairness in deep learning has attracted tremendous attention recently. We\nprovide a review covering recent progresses to tackle algorithmic fairness\nproblems of deep learning from the computational perspective. Specifically, we\nshow that interpretability can serve as a useful ingredient to diagnose the\nreasons that lead to algorithmic discrimination. We also discuss fairness\nmitigation approaches categorized according to three stages of deep learning\nlife-cycle, aiming to push forward the area of fairness in deep learning and\nbuild genuinely fair and reliable deep learning systems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 14:38:07 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 02:33:17 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Du", "Mengnan", ""], ["Yang", "Fan", ""], ["Zou", "Na", ""], ["Hu", "Xia", ""]]}, {"id": "1908.08847", "submitter": "G\\\"okhan Yildirim", "authors": "G\\\"okhan Yildirim, Nikolay Jetchev, Roland Vollgraf, Urs Bergmann", "title": "Generating High-Resolution Fashion Model Images Wearing Custom Outfits", "comments": "Accepted to the International Conference on Computer Vision, ICCV\n  2019, Workshop on Computer Vision for Fashion, Art and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visualizing an outfit is an essential part of shopping for clothes. Due to\nthe combinatorial aspect of combining fashion articles, the available images\nare limited to a pre-determined set of outfits. In this paper, we broaden these\nvisualizations by generating high-resolution images of fashion models wearing a\ncustom outfit under an input body pose. We show that our approach can not only\ntransfer the style and the pose of one generated outfit to another, but also\ncreate realistic images of human bodies and garments.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 14:46:41 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Yildirim", "G\u00f6khan", ""], ["Jetchev", "Nikolay", ""], ["Vollgraf", "Roland", ""], ["Bergmann", "Urs", ""]]}, {"id": "1908.08906", "submitter": "Dong Liu", "authors": "Dong Liu, Nima N. Moghadam, Lars K. Rasmussen, Jinliang Huang, Saikat\n  Chatterjee", "title": "$\\alpha$ Belief Propagation as Fully Factorized Approximation", "comments": "GlobalSIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Belief propagation (BP) can do exact inference in loop-free graphs, but its\nperformance could be poor in graphs with loops, and the understanding of its\nsolution is limited. This work gives an interpretable belief propagation rule\nthat is actually minimization of a localized $\\alpha$-divergence. We term this\nalgorithm as $\\alpha$ belief propagation ($\\alpha$-BP). The performance of\n$\\alpha$-BP is tested in MAP (maximum a posterior) inference problems, where\n$\\alpha$-BP can outperform (loopy) BP by a significant margin even in\nfully-connected graphs.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 17:18:29 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Liu", "Dong", ""], ["Moghadam", "Nima N.", ""], ["Rasmussen", "Lars K.", ""], ["Huang", "Jinliang", ""], ["Chatterjee", "Saikat", ""]]}, {"id": "1908.08919", "submitter": "Vandad Davoodnia", "authors": "Vandad Davoodnia, Saeed Ghorbani, Ali Etemad", "title": "In-bed Pressure-based Pose Estimation using Image Space Representation\n  Learning", "comments": "\\c{opyright}2021 IEEE. Personal use of this material is permitted.\n  Permission from IEEE must be obtained for all other uses, in any current or\n  future media, including reprinting/republishing this material for advertising\n  or promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "2021 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP) (pp. 3965-3969). IEEE", "doi": "10.1109/ICASSP39728.2021.9413516", "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep pose estimation models have proven to be effective in\na wide range of applications such as health monitoring, sports, animations, and\nrobotics. However, pose estimation models fail to generalize when facing images\nacquired from in-bed pressure sensing systems. In this paper, we address this\nchallenge by presenting a novel end-to-end framework capable of accurately\nlocating body parts from vague pressure data. Our method exploits the idea of\nequipping an off-the-shelf pose estimator with a deep trainable neural network,\nwhich pre-processes and prepares the pressure data for subsequent pose\nestimation. Our model transforms the ambiguous pressure maps to images\ncontaining shapes and structures similar to the common input domain of the\npre-existing pose estimation methods. As a result, we show that our model is\nable to reconstruct unclear body parts, which in turn enables pose estimators\nto accurately and robustly estimate the pose. We train and test our method on a\nmanually annotated public pressure map dataset using a combination of loss\nfunctions. Results confirm the effectiveness of our method by the high visual\nquality in the generated images and the high pose estimation rates achieved.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 01:52:54 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 03:41:41 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 19:15:25 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Davoodnia", "Vandad", ""], ["Ghorbani", "Saeed", ""], ["Etemad", "Ali", ""]]}, {"id": "1908.08936", "submitter": "Daisuke Moriwaki", "authors": "Daisuke Moriwaki, Komei Fujita, Shota Yasui, Takahiro Hoshino", "title": "Fatigue-Aware Ad Creative Selection", "comments": "The previous version was uploaded under the title of \"A Contextual\n  Bandit for Ad Creative Selection under Ad Fatigue\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In online display advertising, selecting the most effective ad creative (ad\nimage) for each impression is a crucial task for DSPs (Demand-Side Platforms)\nto fulfill their goals (click-through rate, number of conversions, revenue, and\nbrand improvement). As widely recognized in the marketing literature, the\neffect of ad creative changes with the number of repetitive ad exposures. In\nthis study, we propose an efficient and easy-to-implement ad creative selection\nalgorithm that explicitly considers user's psychological status when selecting\nad creatives. The proposed system was deployed in a real-world production\nenvironment and tested against the baseline algorithms. The results show\nsuperiority of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 03:56:49 GMT"}, {"version": "v2", "created": "Tue, 14 Jan 2020 08:56:23 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Moriwaki", "Daisuke", ""], ["Fujita", "Komei", ""], ["Yasui", "Shota", ""], ["Hoshino", "Takahiro", ""]]}, {"id": "1908.08937", "submitter": "Stephan Sloth Lorenzen", "authors": "Stephan Lorenzen and Niklas Hjuler and Stephen Alstrup", "title": "Tracking Behavioral Patterns among Students in an Online Educational\n  System", "comments": null, "journal-ref": "In Proceedings of the 11'th International Conference on\n  Educational Data Mining (EDM), p. 280-285. 2018", "doi": null, "report-no": null, "categories": "cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of log data generated by online educational systems is an essential\ntask to better the educational systems and increase our understanding of how\nstudents learn. In this study we investigate previously unseen data from Clio\nOnline, the largest provider of digital learning content for primary schools in\nDenmark. We consider data for 14,810 students with 3 million sessions in the\nperiod 2015-2017. We analyze student activity in periods of one week. By using\nnon-negative matrix factorization techniques, we obtain soft clusterings,\nrevealing dependencies among time of day, subject, activity type, activity\ncomplexity (measured by Bloom's taxonomy), and performance. Furthermore, our\nmethod allows for tracking behavioral changes of individual students over time,\nas well as general behavioral changes in the educational system. Based on the\nresults, we give suggestions for behavioral changes, in order to optimize the\nlearning experience and improve performance.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 13:36:26 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Lorenzen", "Stephan", ""], ["Hjuler", "Niklas", ""], ["Alstrup", "Stephen", ""]]}, {"id": "1908.08961", "submitter": "Max Tegmark", "authors": "Max Tegmark (MIT), Tailin Wu (MIT)", "title": "Pareto-optimal data compression for binary classification tasks", "comments": "Replaced to match version published in Entropy. 17 pages, 9 figs;\n  improved discussion, comparison with Blahut-Arimoto method", "journal-ref": "Entropy (2020), 22, 7", "doi": "10.3390/e22010007", "report-no": null, "categories": "cs.LG cs.CV cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of lossy data compression is to reduce the storage cost of a data\nset $X$ while retaining as much information as possible about something ($Y$)\nthat you care about. For example, what aspects of an image $X$ contain the most\ninformation about whether it depicts a cat? Mathematically, this corresponds to\nfinding a mapping $X\\to Z\\equiv f(X)$ that maximizes the mutual information\n$I(Z,Y)$ while the entropy $H(Z)$ is kept below some fixed threshold. We\npresent a method for mapping out the Pareto frontier for classification tasks,\nreflecting the tradeoff between retained entropy and class information. We\nfirst show how a random variable $X$ (an image, say) drawn from a class\n$Y\\in\\{1,...,n\\}$ can be distilled into a vector $W=f(X)\\in \\mathbb{R}^{n-1}$\nlosslessly, so that $I(W,Y)=I(X,Y)$; for example, for a binary classification\ntask of cats and dogs, each image $X$ is mapped into a single real number $W$\nretaining all information that helps distinguish cats from dogs. For the $n=2$\ncase of binary classification, we then show how $W$ can be further compressed\ninto a discrete variable $Z=g_\\beta(W)\\in\\{1,...,m_\\beta\\}$ by binning $W$ into\n$m_\\beta$ bins, in such a way that varying the parameter $\\beta$ sweeps out the\nfull Pareto frontier, solving a generalization of the Discrete Information\nBottleneck (DIB) problem. We argue that the most interesting points on this\nfrontier are \"corners\" maximizing $I(Z,Y)$ for a fixed number of bins\n$m=2,3...$ which can be conveniently be found without multiobjective\noptimization. We apply this method to the CIFAR-10, MNIST and Fashion-MNIST\ndatasets, illustrating how it can be interpreted as an\ninformation-theoretically optimal image clustering algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 18:00:40 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 18:43:57 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Tegmark", "Max", "", "MIT"], ["Wu", "Tailin", "", "MIT"]]}, {"id": "1908.08972", "submitter": "Juan Maro\\~nas", "authors": "Juan Maro\\~nas and Roberto Paredes and Daniel Ramos", "title": "Calibration of Deep Probabilistic Models with Decoupled Bayesian Neural\n  Networks", "comments": "Submit to Neurocomputing", "journal-ref": null, "doi": "10.1016/j.neucom.2020.04.103", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Deep Neural Networks (DNNs) have achieved state-of-the-art accuracy\nperformance in many tasks. However, recent works have pointed out that the\noutputs provided by these models are not well-calibrated, seriously limiting\ntheir use in critical decision scenarios. In this work, we propose to use a\ndecoupled Bayesian stage, implemented with a Bayesian Neural Network (BNN), to\nmap the uncalibrated probabilities provided by a DNN to calibrated ones,\nconsistently improving calibration. Our results evidence that incorporating\nuncertainty provides more reliable probabilistic models, a critical condition\nfor achieving good calibration. We report a generous collection of experimental\nresults using high-accuracy DNNs in standardized image classification\nbenchmarks, showing the good performance, flexibility and robust behavior of\nour approach with respect to several state-of-the-art calibration methods. Code\nfor reproducibility is provided.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 18:35:48 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 13:18:52 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 15:18:08 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Maro\u00f1as", "Juan", ""], ["Paredes", "Roberto", ""], ["Ramos", "Daniel", ""]]}, {"id": "1908.08979", "submitter": "Mimansa Jaiswal", "authors": "Mimansa Jaiswal, Zakaria Aldeneh, Emily Mower Provost", "title": "Controlling for Confounders in Multimodal Emotion Classification via\n  Adversarial Learning", "comments": "10 pages, ICMI 2019", "journal-ref": null, "doi": "10.1145/3340555.3353731", "report-no": null, "categories": "cs.LG cs.CL cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various psychological factors affect how individuals express emotions. Yet,\nwhen we collect data intended for use in building emotion recognition systems,\nwe often try to do so by creating paradigms that are designed just with a focus\non eliciting emotional behavior. Algorithms trained with these types of data\nare unlikely to function outside of controlled environments because our\nemotions naturally change as a function of these other factors. In this work,\nwe study how the multimodal expressions of emotion change when an individual is\nunder varying levels of stress. We hypothesize that stress produces modulations\nthat can hide the true underlying emotions of individuals and that we can make\nemotion recognition algorithms more generalizable by controlling for variations\nin stress. To this end, we use adversarial networks to decorrelate stress\nmodulations from emotion representations. We study how stress alters acoustic\nand lexical emotional predictions, paying special attention to how modulations\ndue to stress affect the transferability of learned emotion recognition models\nacross domains. Our results show that stress is indeed encoded in trained\nemotion classifiers and that this encoding varies across levels of emotions and\nacross the lexical and acoustic modalities. Our results also show that emotion\nrecognition models that control for stress during training have better\ngeneralizability when applied to new domains, compared to models that do not\ncontrol for stress during training. We conclude that is is necessary to\nconsider the effect of extraneous psychological factors when building and\ntesting emotion recognition models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 19:00:18 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Jaiswal", "Mimansa", ""], ["Aldeneh", "Zakaria", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1908.08984", "submitter": "Venkatesh Umaashankar Mr", "authors": "Venkatesh Umaashankar, Girish Shanmugam S and Aditi Prakash", "title": "Atlas: A Dataset and Benchmark for E-commerce Clothing Product\n  Categorization", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In E-commerce, it is a common practice to organize the product catalog using\nproduct taxonomy. This enables the buyer to easily locate the item they are\nlooking for and also to explore various items available under a category.\nProduct taxonomy is a tree structure with 3 or more levels of depth and several\nleaf nodes. Product categorization is a large scale classification task that\nassigns a category path to a particular product. Research in this area is\nrestricted by the unavailability of good real-world datasets and the variations\nin taxonomy due to the absence of a standard across the different e-commerce\nstores. In this paper, we introduce a high-quality product taxonomy dataset\nfocusing on clothing products which contain 186,150 images under clothing\ncategory with 3 levels and 52 leaf nodes in the taxonomy. We explain the\nmethodology used to collect and label this dataset. Further, we establish the\nbenchmark by comparing image classification and Attention based Sequence models\nfor predicting the category path. Our benchmark model reaches a micro f-score\nof 0.92 on the test set. The dataset, code and pre-trained models are publicly\navailable at \\url{https://github.com/vumaasha/atlas}. We invite the community\nto improve upon these baselines.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 16:46:00 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Umaashankar", "Venkatesh", ""], ["S", "Girish Shanmugam", ""], ["Prakash", "Aditi", ""]]}, {"id": "1908.08986", "submitter": "Elad Hoffer", "authors": "Elad Hoffer, Berry Weinstein, Itay Hubara, Tal Ben-Nun, Torsten\n  Hoefler, Daniel Soudry", "title": "Mix & Match: training convnets with mixed image sizes for improved\n  accuracy, speed and scale resiliency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) are commonly trained using a fixed\nspatial image size predetermined for a given model. Although trained on images\nof aspecific size, it is well established that CNNs can be used to evaluate a\nwide range of image sizes at test time, by adjusting the size of intermediate\nfeature maps. In this work, we describe and evaluate a novel mixed-size\ntraining regime that mixes several image sizes at training time. We demonstrate\nthat models trained using our method are more resilient to image size changes\nand generalize well even on small images. This allows faster inference by using\nsmaller images attest time. For instance, we receive a 76.43% top-1 accuracy\nusing ResNet50 with an image size of 160, which matches the accuracy of the\nbaseline model with 2x fewer computations. Furthermore, for a given image size\nused at test time, we show this method can be exploited either to accelerate\ntraining or the final test accuracy. For example, we are able to reach a 79.27%\naccuracy with a model evaluated at a 288 spatial size for a relative\nimprovement of 14% over the baseline.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 08:27:49 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hoffer", "Elad", ""], ["Weinstein", "Berry", ""], ["Hubara", "Itay", ""], ["Ben-Nun", "Tal", ""], ["Hoefler", "Torsten", ""], ["Soudry", "Daniel", ""]]}, {"id": "1908.08988", "submitter": "Xiang Li", "authors": "Xiang Li, Shihao Ji", "title": "Neural Image Compression and Explanation", "comments": "Published as a journal paper at IEEE Access 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining the prediction of deep neural networks (DNNs) and semantic image\ncompression are two active research areas of deep learning with a numerous of\napplications in decision-critical systems, such as surveillance cameras, drones\nand self-driving cars, where interpretable decision is critical and\nstorage/network bandwidth is limited. In this paper, we propose a novel\nend-to-end Neural Image Compression and Explanation (NICE) framework that\nlearns to (1) explain the predictions of convolutional neural networks (CNNs),\nand (2) subsequently compress the input images for efficient storage or\ntransmission. Specifically, NICE generates a sparse mask over an input image by\nattaching a stochastic binary gate to each pixel of the image, whose parameters\nare learned through the interaction with the CNN classifier to be explained.\nThe generated mask is able to capture the saliency of each pixel measured by\nits influence to the final prediction of CNN; it can also be used to produce a\nmixed-resolution image, where important pixels maintain their original high\nresolution and insignificant background pixels are subsampled to a low\nresolution. The produced images achieve a high compression rate (e.g., about\n0.6x of original image file size), while retaining a similar classification\naccuracy. Extensive experiments across multiple image classification benchmarks\ndemonstrate the superior performance of NICE compared to the state-of-the-art\nmethods in terms of explanation quality and semantic image compression rate.\nOur code is available at: https://github.com/lxuniverse/NICE.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 15:39:20 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2020 03:01:50 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Li", "Xiang", ""], ["Ji", "Shihao", ""]]}, {"id": "1908.08989", "submitter": "Maren Awiszus", "authors": "Maren Awiszus, Hanno Ackermann and Bodo Rosenhahn", "title": "Learning Disentangled Representations via Independent Subspaces", "comments": "Accepted at ICCV 2019 Workshop on Robust Subspace Learning and\n  Applications in Computer Vision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image generating neural networks are mostly viewed as black boxes, where any\nchange in the input can have a number of globally effective changes on the\noutput. In this work, we propose a method for learning disentangled\nrepresentations to allow for localized image manipulations. We use face images\nas our example of choice. Depending on the image region, identity and other\nfacial attributes can be modified. The proposed network can transfer parts of a\nface such as shape and color of eyes, hair, mouth, etc.~directly between\npersons while all other parts of the face remain unchanged. The network allows\nto generate modified images which appear like realistic images. Our model\nlearns disentangled representations by weak supervision. We propose a localized\nresnet autoencoder optimized using several loss functions including a loss\nbased on the semantic segmentation, which we interpret as masks, and a loss\nwhich enforces disentanglement by decomposition of the latent space into\nstatistically independent subspaces. We evaluate the proposed solution w.r.t.\ndisentanglement and generated image quality. Convincing results are\ndemonstrated using the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 09:08:12 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Awiszus", "Maren", ""], ["Ackermann", "Hanno", ""], ["Rosenhahn", "Bodo", ""]]}, {"id": "1908.08990", "submitter": "Sebastian Agethen", "authors": "Sebastian Agethen, Winston H. Hsu", "title": "Deep Multi-Kernel Convolutional LSTM Networks and an Attention-Based\n  Mechanism for Videos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Action recognition greatly benefits motion understanding in video analysis.\nRecurrent networks such as long short-term memory (LSTM) networks are a popular\nchoice for motion-aware sequence learning tasks. Recently, a convolutional\nextension of LSTM was proposed, in which input-to-hidden and hidden-to-hidden\ntransitions are modeled through convolution with a single kernel. This implies\nan unavoidable trade-off between effectiveness and efficiency. Herein, we\npropose a new enhancement to convolutional LSTM networks that supports\naccommodation of multiple convolutional kernels and layers. This resembles a\nNetwork-in-LSTM approach, which improves upon the aforementioned concern. In\naddition, we propose an attention-based mechanism that is specifically designed\nfor our multi-kernel extension. We evaluated our proposed extensions in a\nsupervised classification setting on the UCF-101 and Sports-1M datasets, with\nthe findings showing that our enhancements improve accuracy. We also undertook\nqualitative analysis to reveal the characteristics of our system and the\nconvolutional LSTM baseline.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 05:51:20 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Agethen", "Sebastian", ""], ["Hsu", "Winston H.", ""]]}, {"id": "1908.08992", "submitter": "Anjana Wijekoon", "authors": "Anjana Wijekoon, Nirmalie Wiratunga, Kay Cooper", "title": "MEx: Multi-modal Exercises Dataset for Human Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MEx: Multi-modal Exercises Dataset is a multi-sensor, multi-modal dataset,\nimplemented to benchmark Human Activity Recognition(HAR) and Multi-modal Fusion\nalgorithms. Collection of this dataset was inspired by the need for recognising\nand evaluating quality of exercise performance to support patients with\nMusculoskeletal Disorders(MSD). We select 7 exercises regularly recommended for\nMSD patients by physiotherapists and collected data with four sensors a\npressure mat, a depth camera and two accelerometers. The dataset contains three\ndata modalities; numerical time-series data, video data and pressure sensor\ndata posing interesting research challenges when reasoning for HAR and Exercise\nQuality Assessment. This paper presents our evaluation of the dataset on number\nof standard classification algorithms for the HAR task by comparing different\nfeature representation algorithms for each sensor. These results set a\nreference performance for each individual sensor that expose their strengths\nand weaknesses for the future tasks. In addition we visualise pressure mat data\nto explore the potential of the sensor to capture exercise performance quality.\nWith the recent advancement in multi-modal fusion, we also believe MEx is a\nsuitable dataset to benchmark not only HAR algorithms, but also fusion\nalgorithms of heterogeneous data types in multiple application domains.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 16:09:53 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wijekoon", "Anjana", ""], ["Wiratunga", "Nirmalie", ""], ["Cooper", "Kay", ""]]}, {"id": "1908.08993", "submitter": "Dmitry Krotov", "authors": "Leopold Grinberg, John Hopfield, Dmitry Krotov", "title": "Local Unsupervised Learning for Image Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Hebbian learning is believed to be inferior in performance to\nend-to-end training using a backpropagation algorithm. We question this popular\nbelief by designing a local algorithm that can learn convolutional filters at\nscale on large image datasets. These filters combined with patch normalization\nand very steep non-linearities result in a good classification accuracy for\nshallow networks trained locally, as opposed to end-to-end. The filters learned\nby our algorithm contain both orientation selective units and unoriented color\nunits, resembling the responses of pyramidal neurons located in the cytochrome\noxidase 'interblob' and 'blob' regions in the primary visual cortex of\nprimates. It is shown that convolutional networks with patch normalization\nsignificantly outperform standard convolutional networks on the task of\nrecovering the original classes when shadows are superimposed on top of\nstandard CIFAR-10 images. Patch normalization approximates the retinal\nadaptation to the mean light intensity, important for human vision. We also\ndemonstrate a successful transfer of learned representations between CIFAR-10\nand ImageNet 32x32 datasets. All these results taken together hint at the\npossibility that local unsupervised training might be a powerful tool for\nlearning general representations (without specifying the task) directly from\nunlabeled data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:42:11 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Grinberg", "Leopold", ""], ["Hopfield", "John", ""], ["Krotov", "Dmitry", ""]]}, {"id": "1908.08997", "submitter": "Thomas Hartley", "authors": "Thomas Hartley, Kirill Sidorov, Christopher Willis and David Marshall", "title": "Gradient Weighted Superpixels for Interpretability in CNNs", "comments": "Presented at BMVC 2019: Workshop on Interpretable and Explainable\n  Machine Vision, Cardiff, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Convolutional Neural Networks embed themselves into our everyday lives,\nthe need for them to be interpretable increases. However, there is often a\ntrade-off between methods that are efficient to compute but produce an\nexplanation that is difficult to interpret, and those that are slow to compute\nbut provide a more interpretable result. This is particularly challenging in\nproblem spaces that require a large input volume, especially video which\ncombines both spatial and temporal dimensions. In this work we introduce the\nidea of scoring superpixels through the use of gradient based pixel scoring\ntechniques. We show qualitatively and quantitatively that this is able to\napproximate LIME, in a fraction of the time. We investigate our techniques\nusing both image classification, and action recognition networks on large scale\ndatasets (ImageNet and Kinetics-400 respectively).\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 12:02:25 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hartley", "Thomas", ""], ["Sidorov", "Kirill", ""], ["Willis", "Christopher", ""], ["Marshall", "David", ""]]}, {"id": "1908.09002", "submitter": "Chris Xiaoxuan Lu", "authors": "Chris Xiaoxuan Lu, Xuan Kan, Bowen Du, Changhao Chen, Hongkai Wen,\n  Andrew Markham, Niki Trigoni and John Stankovic", "title": "Autonomous Learning for Face Recognition in the Wild via Ambient\n  Wireless Cues", "comments": "11 pages, accepted in the Web Conference (WWW'2019)", "journal-ref": null, "doi": "10.1145/3308558.3313398", "report-no": null, "categories": "cs.CV cs.LG cs.NI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Facial recognition is a key enabling component for emerging Internet of\nThings (IoT) services such as smart homes or responsive offices. Through the\nuse of deep neural networks, facial recognition has achieved excellent\nperformance. However, this is only possibly when trained with hundreds of\nimages of each user in different viewing and lighting conditions. Clearly, this\nlevel of effort in enrolment and labelling is impossible for wide-spread\ndeployment and adoption. Inspired by the fact that most people carry smart\nwireless devices with them, e.g. smartphones, we propose to use this wireless\nidentifier as a supervisory label. This allows us to curate a dataset of facial\nimages that are unique to a certain domain e.g. a set of people in a particular\noffice. This custom corpus can then be used to finetune existing pre-trained\nmodels e.g. FaceNet. However, due to the vagaries of wireless propagation in\nbuildings, the supervisory labels are noisy and weak.We propose a novel\ntechnique, AutoTune, which learns and refines the association between a face\nand wireless identifier over time, by increasing the inter-cluster separation\nand minimizing the intra-cluster distance. Through extensive experiments with\nmultiple users on two sites, we demonstrate the ability of AutoTune to design\nan environment-specific, continually evolving facial recognition system with\nentirely no user effort.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 18:39:09 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Lu", "Chris Xiaoxuan", ""], ["Kan", "Xuan", ""], ["Du", "Bowen", ""], ["Chen", "Changhao", ""], ["Wen", "Hongkai", ""], ["Markham", "Andrew", ""], ["Trigoni", "Niki", ""], ["Stankovic", "John", ""]]}, {"id": "1908.09006", "submitter": "Siddharth Samsi", "authors": "Jeffrey Liu, David Strohschein, Siddharth Samsi, Andrew Weinert", "title": "Large Scale Organization and Inference of an Imagery Dataset for Public\n  Safety", "comments": "Accepted for publication IEEE HPEC 2019", "journal-ref": null, "doi": "10.1109/HPEC.2019.8916437", "report-no": null, "categories": "cs.CV cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video applications and analytics are routinely projected as a stressing and\nsignificant service of the Nationwide Public Safety Broadband Network. As part\nof a NIST PSCR funded effort, the New Jersey Office of Homeland Security and\nPreparedness and MIT Lincoln Laboratory have been developing a computer vision\ndataset of operational and representative public safety scenarios. The scale\nand scope of this dataset necessitates a hierarchical organization approach for\nefficient compute and storage. We overview architectural considerations using\nthe Lincoln Laboratory Supercomputing Cluster as a test architecture. We then\ndescribe how we intelligently organized the dataset across LLSC and evaluated\nit with large scale imagery inference across terabytes of data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 18:20:01 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Liu", "Jeffrey", ""], ["Strohschein", "David", ""], ["Samsi", "Siddharth", ""], ["Weinert", "Andrew", ""]]}, {"id": "1908.09008", "submitter": "Apratim Bhattacharyya", "authors": "Apratim Bhattacharyya, Michael Hanselmann, Mario Fritz, Bernt Schiele,\n  Christoph-Nikolas Straehle", "title": "Conditional Flow Variational Autoencoders for Structured Sequence\n  Prediction", "comments": "To appear at Bayesian Deep Learning and Machine Learning for\n  Autonomous Driving @NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of future states of the environment and interacting agents is a\nkey competence required for autonomous agents to operate successfully in the\nreal world. Prior work for structured sequence prediction based on latent\nvariable models imposes a uni-modal standard Gaussian prior on the latent\nvariables. This induces a strong model bias which makes it challenging to fully\ncapture the multi-modality of the distribution of the future states. In this\nwork, we introduce Conditional Flow Variational Autoencoders (CF-VAE) using our\nnovel conditional normalizing flow based prior to capture complex multi-modal\nconditional distributions for effective structured sequence prediction.\nMoreover, we propose two novel regularization schemes which stabilizes training\nand deals with posterior collapse for stable training and better fit to the\ntarget data distribution. Our experiments on three multi-modal structured\nsequence prediction datasets -- MNIST Sequences, Stanford Drone and HighD --\nshow that the proposed method obtains state of art results across different\nevaluation metrics.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 08:02:34 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 10:44:50 GMT"}, {"version": "v3", "created": "Tue, 18 Aug 2020 09:55:31 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Bhattacharyya", "Apratim", ""], ["Hanselmann", "Michael", ""], ["Fritz", "Mario", ""], ["Schiele", "Bernt", ""], ["Straehle", "Christoph-Nikolas", ""]]}, {"id": "1908.09021", "submitter": "Sizhong Lan", "authors": "Sizhong Lan", "title": "Geometrical Regret Matching", "comments": "11 pages, 22 figures; https://github.com/lansiz/eqpt with code and\n  hands-on demos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the existing regret matchings for Nash equilibrium\napproximation conduct \"jumpy\" strategy updating when the probabilities of\nfuture plays are set to be proportional to positive regret measures. We propose\na geometrical regret matching which features \"smooth\" strategy updating. Our\napproach is simple, intuitive and natural. The analytical and numerical results\nshow that, continuously and \"smoothly\" suppressing \"unprofitable\" pure\nstrategies is sufficient for the game to evolve towards Nash equilibrium,\nsuggesting that in reality the tendency for equilibrium could be pervasive and\nirresistible. Technically, iterative regret matching gives rise to a sequence\nof adjusted mixed strategies for our study its approximation to the true\nequilibrium point. The sequence can be studied in metric space and visualized\nnicely as a clear path towards an equilibrium point. Our theory has limitations\nin optimizing the approximation accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 18 Aug 2019 10:34:36 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 13:09:40 GMT"}, {"version": "v3", "created": "Fri, 30 Aug 2019 07:26:43 GMT"}, {"version": "v4", "created": "Mon, 9 Sep 2019 15:17:48 GMT"}, {"version": "v5", "created": "Mon, 23 Sep 2019 12:56:01 GMT"}, {"version": "v6", "created": "Mon, 14 Oct 2019 17:39:49 GMT"}, {"version": "v7", "created": "Tue, 31 Dec 2019 04:26:20 GMT"}, {"version": "v8", "created": "Thu, 23 Jan 2020 05:31:43 GMT"}], "update_date": "2020-01-24", "authors_parsed": [["Lan", "Sizhong", ""]]}, {"id": "1908.09031", "submitter": "Jiachen Li", "authors": "Jiachen Li and Wei Zhan and Yeping Hu and Masayoshi Tomizuka", "title": "Generic Tracking and Probabilistic Prediction Framework and Its\n  Application in Autonomous Driving", "comments": "IEEE Transactions on Intelligent Transportation Systems", "journal-ref": null, "doi": "10.1109/TITS.2019.2930310", "report-no": null, "categories": "cs.RO cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately tracking and predicting behaviors of surrounding objects are key\nprerequisites for intelligent systems such as autonomous vehicles to achieve\nsafe and high-quality decision making and motion planning. However, there still\nremain challenges for multi-target tracking due to object number fluctuation\nand occlusion. To overcome these challenges, we propose a constrained mixture\nsequential Monte Carlo (CMSMC) method in which a mixture representation is\nincorporated in the estimated posterior distribution to maintain\nmulti-modality. Multiple targets can be tracked simultaneously within a unified\nframework without explicit data association between observations and tracking\ntargets. The framework can incorporate an arbitrary prediction model as the\nimplicit proposal distribution of the CMSMC method. An example in this paper is\na learning-based model for hierarchical time-series prediction, which consists\nof a behavior recognition module and a state evolution module. Both modules in\nthe proposed model are generic and flexible so as to be applied to a class of\ntime-series prediction problems where behaviors can be separated into different\nlevels. Finally, the proposed framework is applied to a numerical case study as\nwell as a task of on-road vehicle tracking, behavior recognition, and\nprediction in highway scenarios. Instead of only focusing on forecasting\ntrajectory of a single entity, we jointly predict continuous motions for\ninteractive entities simultaneously. The proposed approaches are evaluated from\nmultiple aspects, which demonstrate great potential for intelligent vehicular\nsystems and traffic surveillance systems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 20:34:53 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Li", "Jiachen", ""], ["Zhan", "Wei", ""], ["Hu", "Yeping", ""], ["Tomizuka", "Masayoshi", ""]]}, {"id": "1908.09038", "submitter": "Tom Velez PhD", "authors": "Tom Velez, Tony Wang, Ioannis Koutroulis, James Chamberlain, Amit\n  Uppal, Seife Yohannes, Tim Tschampel, Emilia Apostolova", "title": "Identification of Pediatric Sepsis Subphenotypes for Enhanced Machine\n  Learning Predictive Performance: A Latent Profile Analysis", "comments": "Keywords: Pediatric Sepsis, Mortality, Latent Profile Analysis,\n  Machine Learning, Subphenotypes 15 pages including Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: While machine learning (ML) models are rapidly emerging as\npromising screening tools in critical care medicine, the identification of\nhomogeneous subphenotypes within populations with heterogeneous conditions such\nas pediatric sepsis may facilitate attainment of high-predictive performance of\nthese prognostic algorithms. This study is aimed to identify subphenotypes of\npediatric sepsis and demonstrate the potential value of partitioned\ndata/subtyping-based training. Methods: This was a retrospective study of\nclinical data extracted from medical records of 6,446 pediatric patients that\nwere admitted at a major hospital system in the DC area. Vitals and labs\nassociated with patients meeting the diagnostic criteria for sepsis were used\nto perform latent profile analysis. Modern ML algorithms were used to explore\nthe predictive performance benefits of reduced training data heterogeneity via\nlabel profiling. Results: In total 134 (2.1%) patients met the diagnostic\ncriteria for sepsis in this cohort and latent profile analysis identified four\nprofiles/subphenotypes of pediatric sepsis. Profiles 1 and 3 had the lowest\nmortality and included pediatric patients from different age groups. Profile 2\nwere characterized by respiratory dysfunction; profile 4 by neurological\ndysfunction and highest mortality rate (22.2%). Machine learning experiments\ncomparing the predictive performance of models derived without training data\nprofiling against profile targeted models suggest statistically significant\nimproved performance of prediction can be obtained. For example, area under ROC\ncurve (AUC) obtained to predict profile 4 with 24-hour data (AUC = .998, p <\n.0001) compared favorably with the AUC obtained from the model considering all\nprofiles as a single homogeneous group (AUC = .918) with 24-hour data.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 20:59:42 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Velez", "Tom", ""], ["Wang", "Tony", ""], ["Koutroulis", "Ioannis", ""], ["Chamberlain", "James", ""], ["Uppal", "Amit", ""], ["Yohannes", "Seife", ""], ["Tschampel", "Tim", ""], ["Apostolova", "Emilia", ""]]}, {"id": "1908.09041", "submitter": "Neil Lutz", "authors": "Christopher Jung, Sampath Kannan, Neil Lutz", "title": "A Center in Your Neighborhood: Fairness in Facility Location", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When selecting locations for a set of facilities, standard clustering\nalgorithms may place unfair burden on some individuals and neighborhoods. We\nformulate a fairness concept that takes local population densities into\naccount. In particular, given $k$ facilities to locate and a population of size\n$n$, we define the \"neighborhood radius\" of an individual $i$ as the minimum\nradius of a ball centered at $i$ that contains at least $n/k$ individuals. Our\nobjective is to ensure that each individual has a facility within at most a\nsmall constant factor of her neighborhood radius. We present several\ntheoretical results:\n  We show that optimizing this factor is NP-hard; we give an approximation\nalgorithm that guarantees a factor of at most 2 in all metric spaces; and we\nprove matching lower bounds in some metric spaces. We apply a variant of this\nalgorithm to real-world address data, showing that it is quite different from\nstandard clustering algorithms and outperforms them on our objective function\nand balances the load between facilities more evenly.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 22:04:57 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 15:42:36 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Jung", "Christopher", ""], ["Kannan", "Sampath", ""], ["Lutz", "Neil", ""]]}, {"id": "1908.09048", "submitter": "Subramaniam Venkatraman Krishnan", "authors": "Liqun Shao, Yiwen Zhu, Abhiram Eswaran, Kristin Lieber, Janhavi\n  Mahajan, Minsoo Thigpen, Sudhir Darbha, Siqi Liu, Subru Krishnan, Soundar\n  Srinivasan, Carlo Curino and Konstantinos Karanasos", "title": "Griffon: Reasoning about Job Anomalies with Unlabeled Data in\n  Cloud-based Platforms", "comments": null, "journal-ref": null, "doi": "10.1145/3357223.3362716", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Microsoft's internal big data analytics platform is comprised of hundreds of\nthousands of machines, serving over half a million jobs daily, from thousands\nof users. The majority of these jobs are recurring and are crucial for the\ncompany's operation. Although administrators spend significant effort tuning\nsystem performance, some jobs inevitably experience slowdowns, i.e., their\nexecution time degrades over previous runs. Currently, the investigation of\nsuch slowdowns is a labor-intensive and error-prone process, which costs\nMicrosoft significant human and machine resources, and negatively impacts\nseveral lines of businesses. In this work, we present Griffin, a system we\nbuilt and have deployed in production last year to automatically discover the\nroot cause of job slowdowns. Existing solutions either rely on labeled data\n(i.e., resolved incidents with labeled reasons for job slowdowns), which is in\nmost cases non-existent or non-trivial to acquire, or on time-series analysis\nof individual metrics that do not target specific jobs holistically. In\ncontrast, in Griffin we cast the problem to a corresponding regression one that\npredicts the runtime of a job, and show how the relative contributions of the\nfeatures used to train our interpretable model can be exploited to rank the\npotential causes of job slowdowns. Evaluated over historical incidents, we show\nthat Griffin discovers slowdown causes that are consistent with the ones\nvalidated by domain-expert engineers, in a fraction of the time required by\nthem.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 22:57:50 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Shao", "Liqun", ""], ["Zhu", "Yiwen", ""], ["Eswaran", "Abhiram", ""], ["Lieber", "Kristin", ""], ["Mahajan", "Janhavi", ""], ["Thigpen", "Minsoo", ""], ["Darbha", "Sudhir", ""], ["Liu", "Siqi", ""], ["Krishnan", "Subru", ""], ["Srinivasan", "Soundar", ""], ["Curino", "Carlo", ""], ["Karanasos", "Konstantinos", ""]]}, {"id": "1908.09057", "submitter": "Oluwasanmi Koyejo", "authors": "Xiaoyan Wang, Ran Li, Bowei Yan, Oluwasanmi Koyejo", "title": "Consistent Classification with Generalized Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for constructing and analyzing multiclass and\nmultioutput classification metrics, i.e., involving multiple, possibly\ncorrelated multiclass labels. Our analysis reveals novel insights on the\ngeometry of feasible confusion tensors -- including necessary and sufficient\nconditions for the equivalence between optimizing an arbitrary non-decomposable\nmetric and learning a weighted classifier. Further, we analyze averaging\nmethodologies commonly used to compute multioutput metrics and characterize the\ncorresponding Bayes optimal classifiers. We show that the plug-in estimator\nbased on this characterization is consistent and is easily implemented as a\npost-processing rule. Empirical results on synthetic and benchmark datasets\nsupport the theoretical findings.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 00:31:15 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Wang", "Xiaoyan", ""], ["Li", "Ran", ""], ["Yan", "Bowei", ""], ["Koyejo", "Oluwasanmi", ""]]}, {"id": "1908.09078", "submitter": "Shujun Bi", "authors": "Shujun Bi, Ting Tao and Shaohua Pan", "title": "KL property of exponent $1/2$ of $\\ell_{2,0}$-norm and DC regularized\n  factorizations for low-rank matrix recovery", "comments": "29 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with the factorization form of the rank regularized\nloss minimization problem. To cater for the scenario in which only a coarse\nestimation is available for the rank of the true matrix, an $\\ell_{2,0}$-norm\nregularized term is added to the factored loss function to reduce the rank\nadaptively; and account for the ambiguities in the factorization, a balanced\nterm is then introduced. For the least squares loss, under a restricted\ncondition number assumption on the sampling operator, we establish the KL\nproperty of exponent $1/2$ of the nonsmooth factored composite function and its\nequivalent DC reformulations in the set of their global minimizers. We also\nconfirm the theoretical findings by applying a proximal linearized alternating\nminimization method to the regularized factorizations.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 02:56:17 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Bi", "Shujun", ""], ["Tao", "Ting", ""], ["Pan", "Shaohua", ""]]}, {"id": "1908.09092", "submitter": "Dylan Slack", "authors": "Dylan Slack, Sorelle Friedler, Emile Givental", "title": "Fairness Warnings and Fair-MAML: Learning Fairly with Minimal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by concerns surrounding the fairness effects of sharing and\ntransferring fair machine learning tools, we propose two algorithms: Fairness\nWarnings and Fair-MAML. The first is a model-agnostic algorithm that provides\ninterpretable boundary conditions for when a fairly trained model may not\nbehave fairly on similar but slightly different tasks within a given domain.\nThe second is a fair meta-learning approach to train models that can be quickly\nfine-tuned to specific tasks from only a few number of sample instances while\nbalancing fairness and accuracy. We demonstrate experimentally the individual\nutility of each model using relevant baselines and provide the first experiment\nto our knowledge of K-shot fairness, i.e. training a fair model on a new task\nwith only K data points. Then, we illustrate the usefulness of both algorithms\nas a combined method for training models from a few data points on new tasks\nwhile using Fairness Warnings as interpretable boundary conditions under which\nthe newly trained model may not be fair.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 05:15:41 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 05:51:42 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Slack", "Dylan", ""], ["Friedler", "Sorelle", ""], ["Givental", "Emile", ""]]}, {"id": "1908.09094", "submitter": "Sandeep Juneja", "authors": "Shubhada Agrawal, Sandeep Juneja and Peter Glynn", "title": "Optimal $\\delta$-Correct Best-Arm Selection for General Distributions", "comments": "49 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.PR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a finite set of unknown distributions, or arms, that can be sampled, we\nconsider the problem of identifying the one with the largest mean using a\ndelta-correct algorithm (an adaptive, sequential algorithm that restricts the\nprobability of error to a specified delta) that has minimum sample complexity.\nLower bounds for delta-correct algorithms are well known. Delta-correct\nalgorithms that match the lower bound asymptotically as delta reduces to zero\nhave been previously developed when arm distributions are restricted to a\nsingle parameter exponential family. In this paper, we first observe a negative\nresult that some restrictions are essential, as otherwise under a delta-correct\nalgorithm, distributions with unbounded support would require an infinite\nnumber of samples in expectation. We then propose a delta-correct algorithm\nthat matches the lower bound as delta reduces to zero under the mild\nrestriction that a known bound on the expectation of a non-negative,\ncontinuous, increasing convex function (for example, the squared moment) of the\nunderlying random variables, exists. We also propose batch processing and\nidentify near-optimal batch sizes to substantially speed up the proposed\nalgorithm. The best-arm problem has many learning applications, including\nrecommendation systems and product selection. It is also a well studied classic\nproblem in the simulation community.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 05:31:49 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2019 07:13:06 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Agrawal", "Shubhada", ""], ["Juneja", "Sandeep", ""], ["Glynn", "Peter", ""]]}, {"id": "1908.09127", "submitter": "Ehsan Montahaei", "authors": "Ehsan Montahaei, Danial Alihosseini, Mahdieh Soleymani Baghshah", "title": "DGSAN: Discrete Generative Self-Adversarial Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although GAN-based methods have received many achievements in the last few\nyears, they have not been entirelysuccessful in generating discrete data. The\nmost crucial challenge of these methods is the difficulty of passing the\ngradientfrom the discriminator to the generator when the generator outputs are\ndiscrete. Despite the fact that several attemptshave been made to alleviate\nthis problem, none of the existing GAN-based methods have improved the\nperformance oftext generation compared with the maximum likelihood approach in\nterms of both the quality and the diversity. In thispaper, we proposed a new\nframework for generating discrete data by an adversarial approach in which\nthere is no need topass the gradient to the generator. The proposed method has\nan iterative manner in which each new generator is definedbased on the last\ndiscriminator. It leverages the discreteness of data and the last discriminator\nto model the real datadistribution implicitly. Moreover, the method is\nsupported with theoretical guarantees, and experimental results generallyshow\nthe superiority of the proposed DGSAN method compared to the other popular or\nrecent methods in generatingdiscrete sequential data.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 11:39:50 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 10:25:10 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["Montahaei", "Ehsan", ""], ["Alihosseini", "Danial", ""], ["Baghshah", "Mahdieh Soleymani", ""]]}, {"id": "1908.09148", "submitter": "Szymon P{\\l}otka", "authors": "Tomasz W{\\l}odarczyk, Szymon P{\\l}otka, Tomasz Trzci\\'nski,\n  Przemys{\\l}aw Rokita, Nicole Sochacki-W\\'ojcicka, Micha{\\l} Lipa, Jakub\n  W\\'ojcicki", "title": "Estimation of preterm birth markers with U-Net segmentation network", "comments": "Accepted at MICCAI Workshop on Perinatal, Preterm and Paediatric\n  Image analysis (PIPPI) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preterm birth is the most common cause of neonatal death. Current diagnostic\nmethods that assess the risk of preterm birth involve the collection of\nmaternal characteristics and transvaginal ultrasound imaging conducted in the\nfirst and second trimester of pregnancy. Analysis of the ultrasound data is\nbased on visual inspection of images by gynaecologist, sometimes supported by\nhand-designed image features such as cervical length. Due to the complexity of\nthis process and its subjective component, approximately 30% of spontaneous\npreterm deliveries are not correctly predicted. Moreover, 10% of the predicted\npreterm deliveries are false-positives. In this paper, we address the problem\nof predicting spontaneous preterm delivery using machine learning. To achieve\nthis goal, we propose to first use a deep neural network architecture for\nsegmenting prenatal ultrasound images and then automatically extract two\nbiophysical ultrasound markers, cervical length (CL) and anterior cervical\nangle (ACA), from the resulting images. Our method allows to estimate\nultrasound markers without human oversight. Furthermore, we show that CL and\nACA markers, when combined, allow us to decrease false-negative ratio from 30%\nto 18%. Finally, contrary to the current approaches to diagnostics methods that\nrely only on gynaecologist's expertise, our method introduce objectively\nobtained results.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 15:14:11 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["W\u0142odarczyk", "Tomasz", ""], ["P\u0142otka", "Szymon", ""], ["Trzci\u0144ski", "Tomasz", ""], ["Rokita", "Przemys\u0142aw", ""], ["Sochacki-W\u00f3jcicka", "Nicole", ""], ["Lipa", "Micha\u0142", ""], ["W\u00f3jcicki", "Jakub", ""]]}, {"id": "1908.09157", "submitter": "Pawe{\\l} Czy\\.z", "authors": "Albert Ziegler and Pawe{\\l} Czy\\.z", "title": "Unsupervised Recalibration", "comments": "26 pages, added comparison with standard quantification algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised recalibration (URC) is a general way to improve the accuracy of\nan already trained probabilistic classification or regression model upon\nencountering new data while deployed in the field. URC does not require any\nground truth associated with the new field data. URC merely observes the\nmodel's predictions and recognizes when the training set is not representative\nof field data, and then corrects to remove any introduced bias.\n  URC can be particularly useful when applied separately to different\nsubpopulations observed in the field that were not considered as features when\ntraining the machine learning model. This makes it possible to exploit\nsubpopulation information without retraining the model or even having ground\ntruth for some or all subpopulations available.\n  Additionally, if these subpopulations are the object of study, URC serves to\ndetermine the correct ground truth distributions for them, where naive\naggregation methods, like averaging the model's predictions, systematically\nunderestimate their differences.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 15:54:00 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 11:31:32 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2020 13:01:13 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Ziegler", "Albert", ""], ["Czy\u017c", "Pawe\u0142", ""]]}, {"id": "1908.09173", "submitter": "Vira Semenova", "authors": "Victor Chernozhukov, Whitney Newey, Vira Semenova", "title": "Inference on weighted average value function in high-dimensional state\n  space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives a consistent, asymptotically normal estimator of the\nexpected value function when the state space is high-dimensional and the\nfirst-stage nuisance functions are estimated by modern machine learning tools.\nFirst, we show that value function is orthogonal to the conditional choice\nprobability, therefore, this nuisance function needs to be estimated only at\n$n^{-1/4}$ rate. Second, we give a correction term for the transition density\nof the state variable. The resulting orthogonal moment is robust to\nmisspecification of the transition density and does not require this nuisance\nfunction to be consistently estimated. Third, we generalize this result by\nconsidering the weighted expected value. In this case, the orthogonal moment is\ndoubly robust in the transition density and additional second-stage nuisance\nfunctions entering the correction term. We complete the asymptotic theory by\nproviding bounds on second-order asymptotic terms.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 17:34:40 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Newey", "Whitney", ""], ["Semenova", "Vira", ""]]}, {"id": "1908.09174", "submitter": "Najibesadat Sadati Jafarkalaei", "authors": "Najibesadat Sadati, Milad Zafar Nezhad, Ratna Babu Chinnam, Dongxiao\n  Zhu", "title": "Representation Learning with Autoencoders for Electronic Health Records:\n  A Comparative Study", "comments": "Reason: This submission is the extension of our other research which\n  has already submitted in arXiv (arXiv:1801.02961), therefore we decided\n  update that version and withdraw this submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing volume of Electronic Health Records (EHR) in recent years provides\ngreat opportunities for data scientists to collaborate on different aspects of\nhealthcare research by applying advanced analytics to these EHR clinical data.\nA key requirement however is obtaining meaningful insights from high\ndimensional, sparse and complex clinical data. Data science approaches\ntypically address this challenge by performing feature learning in order to\nbuild more reliable and informative feature representations from clinical data\nfollowed by supervised learning. In this paper, we propose a predictive\nmodeling approach based on deep learning based feature representations and word\nembedding techniques. Our method uses different deep architectures (stacked\nsparse autoencoders, deep belief network, adversarial autoencoders and\nvariational autoencoders) for feature representation in higher-level\nabstraction to obtain effective and robust features from EHRs, and then build\nprediction models on top of them. Our approach is particularly useful when the\nunlabeled data is abundant whereas labeled data is scarce. We investigate the\nperformance of representation learning through a supervised learning approach.\nOur focus is to present a comparative study to evaluate the performance of\ndifferent deep architectures through supervised learning and provide insights\nin the choice of deep feature representation techniques. Our experiments\ndemonstrate that for small data sets, stacked sparse autoencoder demonstrates a\nsuperior generality performance in prediction due to sparsity regularization\nwhereas variational autoencoders outperform the competing approaches for large\ndata sets due to its capability of learning the representation distribution\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 17:38:30 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 02:17:16 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Sadati", "Najibesadat", ""], ["Nezhad", "Milad Zafar", ""], ["Chinnam", "Ratna Babu", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1908.09183", "submitter": "Caroline Clark", "authors": "Josiah I. Clark, Caroline A. Clark", "title": "Deriving a Quantitative Relationship Between Resolution and Human\n  Classification Error", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For machine learning perception problems, human-level classification\nperformance is used as an estimate of top algorithm performance. Thus, it is\nimportant to understand as precisely as possible the factors that impact\nhuman-level performance. Knowing this 1) provides a benchmark for model\nperformance, 2) tells a project manager what type of data to obtain for human\nlabelers in order to get accurate labels, and 3) enables ground-truth\nanalysis--largely conducted by humans--to be carried out smoothly. In this\nempirical study, we explored the relationship between resolution and human\nclassification performance using the MNIST data set down-sampled to various\nresolutions. The quantitative heuristic we derived could prove useful for\npredicting machine model performance, predicting data storage requirements, and\nsaving valuable resources in the deployment of machine learning projects. It\nalso has the potential to be used in a wide variety of fields such as remote\nsensing, medical imaging, scientific imaging, and astronomy.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 18:34:13 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Clark", "Josiah I.", ""], ["Clark", "Caroline A.", ""]]}, {"id": "1908.09195", "submitter": "Samuel I. Berchuck", "authors": "Samuel I. Berchuck, Felipe A. Medeiros and Sayan Mukherjee", "title": "Scalable Modeling of Spatiotemporal Data using the Variational\n  Autoencoder: an Application in Glaucoma", "comments": "This is a preprint of an article submitted for publication in the\n  Annals of Applied Statistics. The article contains 26 pages and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As big spatial data becomes increasingly prevalent, classical spatiotemporal\n(ST) methods often do not scale well. While methods have been developed to\naccount for high-dimensional spatial objects, the setting where there are\nexceedingly large samples of spatial observations has had less attention. The\nvariational autoencoder (VAE), an unsupervised generative model based on deep\nlearning and approximate Bayesian inference, fills this void using a latent\nvariable specification that is inferred jointly across the large number of\nsamples. In this manuscript, we compare the performance of the VAE with a more\nclassical ST method when analyzing longitudinal visual fields from a large\ncohort of patients in a prospective glaucoma study. Through simulation and a\ncase study, we demonstrate that the VAE is a scalable method for analyzing ST\ndata, when the goal is to obtain accurate predictions. R code to implement the\nVAE can be found on GitHub: https://github.com/berchuck/vaeST.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 20:02:41 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Berchuck", "Samuel I.", ""], ["Medeiros", "Felipe A.", ""], ["Mukherjee", "Sayan", ""]]}, {"id": "1908.09207", "submitter": "Qinzhe Wu", "authors": "Snehil Verma, Qinzhe Wu, Bagus Hanindhito, Gunjan Jha, Eugene B. John,\n  Ramesh Radhakrishnan, and Lizy K. John", "title": "Demystifying the MLPerf Benchmark Suite", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  MLPerf, an emerging machine learning benchmark suite strives to cover a broad\nrange of applications of machine learning. We present a study on its\ncharacteristics and how the MLPerf benchmarks differ from some of the previous\ndeep learning benchmarks like DAWNBench and DeepBench. We find that application\nbenchmarks such as MLPerf (although rich in kernels) exhibit different features\ncompared to kernel benchmarks such as DeepBench. MLPerf benchmark suite\ncontains a diverse set of models which allows unveiling various bottlenecks in\nthe system. Based on our findings, dedicated low latency interconnect between\nGPUs in multi-GPU systems is required for optimal distributed deep learning\ntraining. We also observe variation in scaling efficiency across the MLPerf\nmodels. The variation exhibited by the different models highlight the\nimportance of smart scheduling strategies for multi-GPU training. Another\nobservation is that CPU utilization increases with increase in number of GPUs\nused for training. Corroborating prior work we also observe and quantify\nimprovements possible by compiler optimizations, mixed-precision training and\nuse of Tensor Cores.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 20:55:10 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Verma", "Snehil", ""], ["Wu", "Qinzhe", ""], ["Hanindhito", "Bagus", ""], ["Jha", "Gunjan", ""], ["John", "Eugene B.", ""], ["Radhakrishnan", "Ramesh", ""], ["John", "Lizy K.", ""]]}, {"id": "1908.09213", "submitter": "Alicja Gosiewska", "authors": "Alicja Gosiewska and Mateusz Bakala and Katarzyna Woznica and Maciej\n  Zwolinski and Przemyslaw Biecek", "title": "EPP: interpretable score of model predictive power", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most important part of model selection and hyperparameter tuning is the\nevaluation of model performance. The most popular measures, such as AUC, F1,\nACC for binary classification, or RMSE, MAD for regression, or cross-entropy\nfor multilabel classification share two common weaknesses. First is, that they\nare not on an interval scale. It means that the difference in performance for\nthe two models has no direct interpretation. It makes no sense to compare such\ndifferences between datasets. Second is, that for k-fold cross-validation, the\nmodel performance is in most cases calculated as an average performance from\nparticular folds, which neglects the information how stable is the performance\nfor different folds.\n  In this talk, we introduce a new EPP rating system for predictive models. We\nalso demonstrate numerous advantages for this system, First, differences in EPP\nscores have probabilistic interpretation. Based on it we can assess the\nprobability that one model will achieve better performance than another.\nSecond, EPP scores can be directly compared between datasets. Third, they can\nbe used for navigated hyperparameter tuning and model selection. Forth, we can\ncreate embeddings for datasets based on EPP scores.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 21:24:15 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Gosiewska", "Alicja", ""], ["Bakala", "Mateusz", ""], ["Woznica", "Katarzyna", ""], ["Zwolinski", "Maciej", ""], ["Biecek", "Przemyslaw", ""]]}, {"id": "1908.09219", "submitter": "Andre Nguyen", "authors": "Andre T. Nguyen and Edward Raff", "title": "Heterogeneous Relational Kernel Learning", "comments": "MileTS '19: 5th KDD Workshop on Mining and Learning from Time Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has developed Bayesian methods for the automatic statistical\nanalysis and description of single time series as well as of homogeneous sets\nof time series data. We extend prior work to create an interpretable kernel\nembedding for heterogeneous time series. Our method adds practically no\ncomputational cost compared to prior results by leveraging previously discarded\nintermediate results. We show the practical utility of our method by leveraging\nthe learned embeddings for clustering, pattern discovery, and anomaly\ndetection. These applications are beyond the ability of prior relational kernel\nlearning approaches.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 22:00:39 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Nguyen", "Andre T.", ""], ["Raff", "Edward", ""]]}, {"id": "1908.09222", "submitter": "Vishwali Mhasawade", "authors": "Vishwali Mhasawade, Nabeel Abdur Rehman, Rumi Chunara", "title": "Population-aware Hierarchical Bayesian Domain Adaptation via\n  Multiple-component Invariant Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3368555.3384451", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While machine learning is rapidly being developed and deployed in health\nsettings such as influenza prediction, there are critical challenges in using\ndata from one environment in another due to variability in features; even\nwithin disease labels there can be differences (e.g. \"fever\" may mean something\ndifferent reported in a doctor's office versus in an online app). Moreover,\nmodels are often built on passive, observational data which contain different\ndistributions of population subgroups (e.g. men or women). Thus, there are two\nforms of instability between environments in this observational transport\nproblem. We first harness knowledge from health to conceptualize the underlying\ncausal structure of this problem in a health outcome prediction task. Based on\nsources of stability in the model, we posit that for human-sourced data and\nhealth prediction tasks we can combine environment and population information\nin a novel population-aware hierarchical Bayesian domain adaptation framework\nthat harnesses multiple invariant components through population attributes when\nneeded. We study the conditions under which invariant learning fails, leading\nto reliance on the environment-specific attributes. Experimental results for an\ninfluenza prediction task on four datasets gathered from different contexts\nshow the model can improve prediction in the case of largely unlabelled target\ndata from a new environment and different constituent population, by harnessing\nboth environment and population invariant information. This work represents a\nnovel, principled way to address a critical challenge by blending domain\n(health) knowledge and algorithmic innovation. The proposed approach will have\na significant impact in many social settings wherein who and where the data\ncomes from matters.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 22:14:11 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 14:04:58 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 16:40:18 GMT"}, {"version": "v4", "created": "Fri, 13 Sep 2019 13:07:43 GMT"}, {"version": "v5", "created": "Mon, 9 Mar 2020 15:55:16 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Mhasawade", "Vishwali", ""], ["Rehman", "Nabeel Abdur", ""], ["Chunara", "Rumi", ""]]}, {"id": "1908.09237", "submitter": "Fallaw Sowell", "authors": "Nandana Sengupta and Fallaw Sowell", "title": "The Ridge Path Estimator for Linear Instrumental Variables", "comments": "33 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the asymptotic behavior of a linear instrumental\nvariables (IV) estimator that uses a ridge regression penalty. The\nregularization tuning parameter is selected empirically by splitting the\nobserved data into training and test samples. Conditional on the tuning\nparameter, the training sample creates a path from the IV estimator to a prior.\nThe optimal tuning parameter is the value along this path that minimizes the IV\nobjective function for the test sample.\n  The empirically selected regularization tuning parameter becomes an estimated\nparameter that jointly converges with the parameters of interest. The\nasymptotic distribution of the tuning parameter is a nonstandard mixture\ndistribution. Monte Carlo simulations show the asymptotic distribution captures\nthe characteristics of the sampling distributions and when this ridge estimator\nperforms better than two-stage least squares.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 00:09:10 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Sengupta", "Nandana", ""], ["Sowell", "Fallaw", ""]]}, {"id": "1908.09238", "submitter": "Weizhong Yan", "authors": "Weizhong Yan and Lijie Yu", "title": "On Accurate and Reliable Anomaly Detection for Gas Turbine Combustors: A\n  Deep Learning Approach", "comments": "8 pages", "journal-ref": "PHM 2015 Conference", "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring gas turbine combustors health, in particular, early detecting\nabnormal behaviors and incipient faults, is critical in ensuring gas turbines\noperating efficiently and in preventing costly unplanned maintenance. One\npopular means of detecting combustor abnormalities is through continuously\nmonitoring exhaust gas temperature profiles. Over the years many anomaly\ndetection technologies have been explored for detecting combustor faults,\nhowever, the performance (detection rate) of anomaly detection solutions\nfielded is still inadequate. Advanced technologies that can improve detection\nperformance are in great need. Aiming for improving anomaly detection\nperformance, in this paper we introduce recently-developed deep learning (DL)\nin machine learning into the combustors anomaly detection application.\nSpecifically, we use deep learning to hierarchically learn features from the\nsensor measurements of exhaust gas temperatures. And we then use the learned\nfeatures as the input to a neural network classifier for performing combustor\nanomaly detection. Since such deep learned features potentially better capture\ncomplex relations among all sensor measurements and the underlying combustor\nbehavior than handcrafted features do, we expect the learned features can lead\nto a more accurate and robust anomaly detection. Using the data collected from\na real-world gas turbine combustion system, we demonstrated that the proposed\ndeep learning based anomaly detection significantly indeed improved combustor\nanomaly detection performance.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 00:11:34 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Yan", "Weizhong", ""], ["Yu", "Lijie", ""]]}, {"id": "1908.09251", "submitter": "Robert Gniadecki", "authors": "Sepideh Emam, Amy X. Du, Philip Surmanowicz, Simon F. Thomsen, Russ\n  Greiner, Robert Gniadecki", "title": "Predicting the Long-Term Outcomes of Biologics in Psoriasis Patients\n  Using Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. Real-world data show that approximately 50% of psoriasis patients\ntreated with a biologic agent will discontinue the drug because of loss of\nefficacy. History of previous therapy with another biologic, female sex and\nobesity were identified as predictors of drug discontinuations, but their\nindividual predictive value is low. Objectives. To determine whether machine\nlearning algorithms can produce models that can accurately predict outcomes of\nbiologic therapy in psoriasis on individual patient level. Results. All tested\nmachine learning algorithms could accurately predict the risk of drug\ndiscontinuation and its cause (e.g. lack of efficacy vs adverse event). The\nlearned generalized linear model achieved diagnostic accuracy of 82%, requiring\nunder 2 seconds per patient using the psoriasis patients dataset. Input\noptimization analysis established a profile of a patient who has best chances\nof long-term treatment success: biologic-naive patient under 49 years,\nearly-onset plaque psoriasis without psoriatic arthritis, weight < 100 kg, and\nmoderate-to-severe psoriasis activity (DLQI $\\geq$ 16; PASI $\\geq$ 10).\nMoreover, a different generalized linear model is used to predict the length of\ntreatment for each patient with mean absolute error (MAE) of 4.5 months.\nHowever Pearson Correlation Coefficient indicates 0.935 linear dependencies\nbetween the actual treatment lengths and predicted ones. Conclusions. Machine\nlearning algorithms predict the risk of drug discontinuation and treatment\nduration with accuracy exceeding 80%, based on a small set of predictive\nvariables. This approach can be used as a decision-making tool, communicating\nexpected outcomes to the patient, and development of evidence-based guidelines.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 05:07:49 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Emam", "Sepideh", ""], ["Du", "Amy X.", ""], ["Surmanowicz", "Philip", ""], ["Thomsen", "Simon F.", ""], ["Greiner", "Russ", ""], ["Gniadecki", "Robert", ""]]}, {"id": "1908.09257", "submitter": "Ivan Kobyzev", "authors": "Ivan Kobyzev and Simon J.D. Prince and Marcus A. Brubaker", "title": "Normalizing Flows: An Introduction and Review of Current Methods", "comments": "This paper appears in: IEEE Transactions on Pattern Analysis and\n  Machine Intelligence On page(s): 1-16 Print ISSN: 0162-8828 Online ISSN:\n  0162-8828", "journal-ref": null, "doi": "10.1109/TPAMI.2020.2992934", "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normalizing Flows are generative models which produce tractable distributions\nwhere both sampling and density evaluation can be efficient and exact. The goal\nof this survey article is to give a coherent and comprehensive review of the\nliterature around the construction and use of Normalizing Flows for\ndistribution learning. We aim to provide context and explanation of the models,\nreview current state-of-the-art literature, and identify open questions and\npromising future directions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 06:14:08 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2019 05:49:57 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 01:45:47 GMT"}, {"version": "v4", "created": "Sat, 6 Jun 2020 00:24:11 GMT"}], "update_date": "2020-06-09", "authors_parsed": [["Kobyzev", "Ivan", ""], ["Prince", "Simon J. D.", ""], ["Brubaker", "Marcus A.", ""]]}, {"id": "1908.09258", "submitter": "Bahareh Tolooshams", "authors": "Thomas Chang, Bahareh Tolooshams, Demba Ba", "title": "RandNet: deep learning with compressed measurements of images", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis, dictionary learning, and auto-encoders are all\nunsupervised methods for learning representations from a large amount of\ntraining data. In all these methods, the higher the dimensions of the input\ndata, the longer it takes to learn. We introduce a class of neural networks,\ntermed RandNet, for learning representations using compressed random\nmeasurements of data of interest, such as images. RandNet extends the\nconvolutional recurrent sparse auto-encoder architecture to dense networks and,\nmore importantly, to the case when the input data are compressed random\nmeasurements of the original data. Compressing the input data makes it possible\nto fit a larger number of batches in memory during training. Moreover, in the\ncase of sparse measurements,training is more efficient computationally. We\ndemonstrate that, in unsupervised settings, RandNet performs dictionary\nlearning using compressed data. In supervised settings, we show that RandNet\ncan classify MNIST images with minimal loss in accuracy, despite being trained\nwith random projections of the images that result in a 50% reduction in size.\nOverall, our results provide a general principled framework for training neural\nnetworks using compressed data.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 06:19:15 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Chang", "Thomas", ""], ["Tolooshams", "Bahareh", ""], ["Ba", "Demba", ""]]}, {"id": "1908.09260", "submitter": "Lucas Bechberger", "authors": "Lucas Bechberger and Kai-Uwe K\\\"uhnberger", "title": "Generalizing Psychological Similarity Spaces to Unseen Stimuli", "comments": "Submitted to the edited volume \"Concepts in Action: Representation,\n  Learning, and Application\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cognitive framework of conceptual spaces proposes to represent concepts\nas regions in psychological similarity spaces. These similarity spaces are\ntypically obtained through multidimensional scaling (MDS), which converts human\ndissimilarity ratings for a fixed set of stimuli into a spatial representation.\nOne can distinguish metric MDS (which assumes that the dissimilarity ratings\nare interval or ratio scaled) from nonmetric MDS (which only assumes an ordinal\nscale). In our first study, we show that despite its additional assumptions,\nmetric MDS does not necessarily yield better solutions than nonmetric MDS. In\nthis chapter, we furthermore propose to learn a mapping from raw stimuli into\nthe similarity space using artificial neural networks (ANNs) in order to\ngeneralize the similarity space to unseen inputs. In our second study, we show\nthat a linear regression from the activation vectors of a convolutional ANN to\nsimilarity spaces obtained by MDS can be successful and that the results are\nsensitive to the number of dimensions of the similarity space.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 06:49:52 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2020 12:49:29 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Bechberger", "Lucas", ""], ["K\u00fchnberger", "Kai-Uwe", ""]]}, {"id": "1908.09287", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Principal Component Analysis Using Structural Similarity Index for\n  Images", "comments": "Paper for the methods named \"Image Structural Component Analysis\n  (ISCA)\" and \"Kernel Image Structural Component Analysis (Kernel ISCA)\"", "journal-ref": "International Conference on Image Analysis and Recognition,\n  Springer, pp. 77-88, 2019", "doi": "10.1007/978-3-030-27202-9_7", "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advances of deep learning in specific tasks using images, the\nprincipled assessment of image fidelity and similarity is still a critical\nability to develop. As it has been shown that Mean Squared Error (MSE) is\ninsufficient for this task, other measures have been developed with one of the\nmost effective being Structural Similarity Index (SSIM). Such measures can be\nused for subspace learning but existing methods in machine learning, such as\nPrincipal Component Analysis (PCA), are based on Euclidean distance or MSE and\nthus cannot properly capture the structural features of images. In this paper,\nwe define an image structure subspace which discriminates different types of\nimage distortions. We propose Image Structural Component Analysis (ISCA) and\nalso kernel ISCA by using SSIM, rather than Euclidean distance, in the\nformulation of PCA. This paper provides a bridge between image quality\nassessment and manifold learning opening a broad new area for future research.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 09:18:03 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1908.09288", "submitter": "Benyamin Ghojogh", "authors": "Benyamin Ghojogh, Fakhri Karray, Mark Crowley", "title": "Locally Linear Image Structural Embedding for Image Structure Manifold\n  Learning", "comments": "This is the paper for the methods named \"Locally Linear Image\n  Structural Embedding (LLISE)\" and \"Kernel Locally Linear Image Structural\n  Embedding (Kernel LLISE)\"", "journal-ref": "International Conference on Image Analysis and Recognition,\n  Springer, pp. 126-138, 2019", "doi": "10.1007/978-3-030-27202-9_11", "report-no": null, "categories": "stat.ML cs.CV cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of existing manifold learning methods rely on Mean Squared Error (MSE)\nor $\\ell_2$ norm. However, for the problem of image quality assessment, these\nare not promising measure. In this paper, we introduce the concept of an image\nstructure manifold which captures image structure features and discriminates\nimage distortions. We propose a new manifold learning method, Locally Linear\nImage Structural Embedding (LLISE), and kernel LLISE for learning this\nmanifold. The LLISE is inspired by Locally Linear Embedding (LLE) but uses SSIM\nrather than MSE. This paper builds a bridge between manifold learning and image\nfidelity assessment and it can open a new area for future investigations.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 09:32:45 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Ghojogh", "Benyamin", ""], ["Karray", "Fakhri", ""], ["Crowley", "Mark", ""]]}, {"id": "1908.09296", "submitter": "Sun-Yu Gordon Chi", "authors": "Sun-Yu Gordon Chi", "title": "Exploring the Performance of Deep Residual Networks in Crazyhouse Chess", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crazyhouse is a chess variant that incorporates all of the classical chess\nrules, but allows users to drop pieces captured from the opponent as a normal\nmove. Until 2018, all competitive computer engines for this board game made use\nof an alpha-beta pruning algorithm with a hand-crafted evaluation function for\neach position. Previous machine learning-based algorithms for just regular\nchess, such as NeuroChess and Giraffe, took hand-crafted evaluation features as\ninput rather than a raw board representation. More recent projects, such as\nAlphaZero, reached massive success but required massive computational resources\nin order to reach its final strength.\n  This paper describes the development of SixtyFour, an engine designed to\ncompete in the chess variant of Crazyhouse with limited hardware. This specific\nvariant poses a multitude of significant challenges due to its large branching\nfactor, state-space complexity, and the multiple move types a player can make.\nWe propose the novel creation of a neural network-based evaluation function for\nCrazyhouse. More importantly, we evaluate the effectiveness of an ensemble\nmodel, which allows the training time and datasets to be easily distributed on\nregular CPU hardware commodity. Early versions of the network have attained a\nplaying level comparable to a strong amateur on online servers.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 10:18:02 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Chi", "Sun-Yu Gordon", ""]]}, {"id": "1908.09341", "submitter": "Artem Artemov", "authors": "Artem Artemov, Boris Alekseev", "title": "A Method for Estimating the Proximity of Vector Representation Groups in\n  Multidimensional Space. On the Example of the Paraphrase Task", "comments": "8 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The following paper presents a method of comparing two sets of vectors. The\nmethod can be applied in all tasks, where it is necessary to measure the\ncloseness of two objects presented as sets of vectors. It may be applicable\nwhen we compare the meanings of two sentences as part of the problem of\nparaphrasing. This is the problem of measuring semantic similarity of two\nsentences (group of words). The existing methods are not sensible for the word\norder or syntactic connections in the considered sentences. The method appears\nto be advantageous because it neither presents a group of words as one scalar\nvalue, nor does it try to show the closeness through an aggregation vector,\nwhich is mean for the set of vectors. Instead of that we measure the cosine of\nthe angle as the mean for the first group vectors projections (the context) on\none side and each vector of the second group on the other side. The similarity\nof two sentences defined by these means does not lose any semantic\ncharacteristics and takes account of the words traits. The method was verified\non the comparison of sentence pairs in Russian.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 14:54:49 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 13:22:14 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Artemov", "Artem", ""], ["Alekseev", "Boris", ""]]}, {"id": "1908.09345", "submitter": "Bingcong Li", "authors": "Bingcong Li, Lingda Wang, Georgios B. Giannakis", "title": "Almost Tune-Free Variance Reduction", "comments": null, "journal-ref": "ICML 2020", "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variance reduction class of algorithms including the representative ones,\nSVRG and SARAH, have well documented merits for empirical risk minimization\nproblems. However, they require grid search to tune parameters (step size and\nthe number of iterations per inner loop) for optimal performance. This work\nintroduces `almost tune-free' SVRG and SARAH schemes equipped with i)\nBarzilai-Borwein (BB) step sizes; ii) averaging; and, iii) the inner loop\nlength adjusted to the BB step sizes. In particular, SVRG, SARAH, and their BB\nvariants are first reexamined through an `estimate sequence' lens to enable new\naveraging methods that tighten their convergence rates theoretically, and\nimprove their performance empirically when the step size or the inner loop\nlength is chosen large. Then a simple yet effective means to adjust the number\nof iterations per inner loop is developed to enhance the merits of the proposed\naveraging schemes and BB step sizes. Numerical tests corroborate the proposed\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 15:24:04 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 12:14:42 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Li", "Bingcong", ""], ["Wang", "Lingda", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1908.09354", "submitter": "Kun Cao", "authors": "Kun Cao, James Fairbanks", "title": "Unsupervised Construction of Knowledge Graphs From Text and Code", "comments": "25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining,\n  15th International Workshop On Mining and Learning with Graphs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scientific literature is a rich source of information for data mining\nwith conceptual knowledge graphs; the open science movement has enriched this\nliterature with complementary source code that implements scientific models. To\nexploit this new resource, we construct a knowledge graph using unsupervised\nlearning methods to identify conceptual entities. We associate source code\nentities to these natural language concepts using word embedding and clustering\ntechniques. Practical naming conventions for methods and functions tend to\nreflect the concept(s) they implement. We take advantage of this specificity by\npresenting a novel process for joint clustering text concepts that combines\nword-embeddings, nonlinear dimensionality reduction, and clustering techniques\nto assist in understanding, organizing, and comparing software in the open\nscience ecosystem. With our pipeline, we aim to assist scientists in building\non existing models in their discipline when making novel models for new\nphenomena. By combining source code and conceptual information, our knowledge\ngraph enhances corpus-wide understanding of scientific literature.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 16:10:31 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Cao", "Kun", ""], ["Fairbanks", "James", ""]]}, {"id": "1908.09357", "submitter": "William Whitney", "authors": "William Whitney, Rajat Agarwal, Kyunghyun Cho, and Abhinav Gupta", "title": "Dynamics-aware Embeddings", "comments": "Published at ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider self-supervised representation learning to improve\nsample efficiency in reinforcement learning (RL). We propose a forward\nprediction objective for simultaneously learning embeddings of states and\naction sequences. These embeddings capture the structure of the environment's\ndynamics, enabling efficient policy learning. We demonstrate that our action\nembeddings alone improve the sample efficiency and peak performance of\nmodel-free RL on control from low-dimensional states. By combining state and\naction embeddings, we achieve efficient learning of high-quality policies on\ngoal-conditioned continuous control from pixel observations in only 1-2 million\nenvironment steps.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 16:22:04 GMT"}, {"version": "v2", "created": "Sun, 1 Sep 2019 13:08:05 GMT"}, {"version": "v3", "created": "Tue, 14 Jan 2020 14:50:13 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Whitney", "William", ""], ["Agarwal", "Rajat", ""], ["Cho", "Kyunghyun", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1908.09364", "submitter": "Benjamin Paassen", "authors": "Benjamin Paa{\\ss}en", "title": "Adversarial Edit Attacks for Tree Data", "comments": "accepted at the 20th International Conference on Intelligent Data\n  Engineering and Automated Learning (IDEAL)", "journal-ref": "Proc. IDEAL 20 (2019) 359-366", "doi": "10.1007/978-3-030-33607-3_39", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning models can be attacked with adversarial examples, i.e.\ninputs close to correctly classified examples that are classified incorrectly.\nHowever, most research on adversarial attacks to date is limited to vectorial\ndata, in particular image data. In this contribution, we extend the field by\nintroducing adversarial edit attacks for tree-structured data with potential\napplications in medicine and automated program analysis. Our approach solely\nrelies on the tree edit distance and a logarithmic number of black-box queries\nto the attacked classifier without any need for gradient information. We\nevaluate our approach on two programming and two biomedical data sets and show\nthat many established tree classifiers, like tree-kernel-SVMs and recursive\nneural networks, can be attacked effectively.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 17:20:15 GMT"}, {"version": "v2", "created": "Tue, 27 Aug 2019 07:53:03 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Paa\u00dfen", "Benjamin", ""]]}, {"id": "1908.09375", "submitter": "Qianli Liao", "authors": "Tomaso Poggio, Andrzej Banburski, Qianli Liao", "title": "Theoretical Issues in Deep Networks: Approximation, Optimization and\n  Generalization", "comments": "arXiv admin note: text overlap with arXiv:1611.00740", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning is successful in a number of applications, it is not yet\nwell understood theoretically. A satisfactory theoretical characterization of\ndeep learning however, is beginning to emerge. It covers the following\nquestions: 1) representation power of deep networks 2) optimization of the\nempirical risk 3) generalization properties of gradient descent techniques ---\nwhy the expected error does not suffer, despite the absence of explicit\nregularization, when the networks are overparametrized? In this review we\ndiscuss recent advances in the three areas. In approximation theory both\nshallow and deep networks have been shown to approximate any continuous\nfunctions on a bounded domain at the expense of an exponential number of\nparameters (exponential in the dimensionality of the function). However, for a\nsubset of compositional functions, deep networks of the convolutional type can\nhave a linear dependence on dimensionality, unlike shallow networks. In\noptimization we discuss the loss landscape for the exponential loss function\nand show that stochastic gradient descent will find with high probability the\nglobal minima. To address the question of generalization for classification\ntasks, we use classical uniform convergence results to justify minimizing a\nsurrogate exponential-type loss function under a unit norm constraint on the\nweight matrix at each layer -- since the interesting variables for\nclassification are the weight directions rather than the weights. Our approach,\nwhich is supported by several independent new results, offers a solution to the\npuzzle about generalization performance of deep overparametrized ReLU networks,\nuncovering the origin of the underlying hidden complexity control.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 19:12:56 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Poggio", "Tomaso", ""], ["Banburski", "Andrzej", ""], ["Liao", "Qianli", ""]]}, {"id": "1908.09381", "submitter": "Xudong Sun", "authors": "Xudong Sun and Bernd Bischl", "title": "Tutorial and Survey on Probabilistic Graphical Model and Variational\n  Inference in Deep Reinforcement Learning", "comments": "2019 IEEE Symposium on Computational Intelligence, Symposium on\n  Adaptive Dynamic Programming and Reinforcement Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Aiming at a comprehensive and concise tutorial survey, recap of variational\ninference and reinforcement learning with Probabilistic Graphical Models are\ngiven with detailed derivations. Reviews and comparisons on recent advances in\ndeep reinforcement learning are made from various aspects. We offer detailed\nderivations to a taxonomy of Probabilistic Graphical Model and Variational\nInference methods in deep reinforcement learning, which serves as a\ncomplementary material on top of the original contributions.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 19:36:36 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 20:10:41 GMT"}, {"version": "v3", "created": "Thu, 10 Oct 2019 21:33:38 GMT"}, {"version": "v4", "created": "Mon, 28 Oct 2019 23:28:17 GMT"}, {"version": "v5", "created": "Sun, 8 Dec 2019 11:44:35 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Sun", "Xudong", ""], ["Bischl", "Bernd", ""]]}, {"id": "1908.09393", "submitter": "Jonathan Strahl", "authors": "Jonathan Strahl and Jaakko Peltonen and Hiroshi Mamitsuka and Samuel\n  Kaski", "title": "Scalable Probabilistic Matrix Factorization with Graph-Based Priors", "comments": "Under review", "journal-ref": "AAAI 2020", "doi": "10.1609/aaai.v34i04.6043", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In matrix factorization, available graph side-information may not be well\nsuited for the matrix completion problem, having edges that disagree with the\nlatent-feature relations learnt from the incomplete data matrix. We show that\nremoving these $\\textit{contested}$ edges improves prediction accuracy and\nscalability. We identify the contested edges through a highly-efficient\ngraphical lasso approximation. The identification and removal of contested\nedges adds no computational complexity to state-of-the-art graph-regularized\nmatrix factorization, remaining linear with respect to the number of non-zeros.\nComputational load even decreases proportional to the number of edges removed.\nFormulating a probabilistic generative model and using expectation maximization\nto extend graph-regularised alternating least squares (GRALS) guarantees\nconvergence. Rich simulated experiments illustrate the desired properties of\nthe resulting algorithm. On real data experiments we demonstrate improved\nprediction accuracy with fewer graph edges (empirical evidence that graph\nside-information is often inaccurate). A 300 thousand dimensional graph with\nthree million edges (Yahoo music side-information) can be analyzed in under ten\nminutes on a standard laptop computer demonstrating the efficiency of our graph\nupdate.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 21:21:18 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 12:26:43 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Strahl", "Jonathan", ""], ["Peltonen", "Jaakko", ""], ["Mamitsuka", "Hiroshi", ""], ["Kaski", "Samuel", ""]]}, {"id": "1908.09419", "submitter": "Junghoon Seo", "authors": "Junghoon Seo, Jamyoung Koo, Taegyun Jeon", "title": "Deep Closed-Form Subspace Clustering", "comments": "Accepted at the 2019 ICCV Workshop on Robust Subspace Learning and\n  Applications in Computer Vision (RSL-CV 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Deep Closed-Form Subspace Clustering (DCFSC), a new embarrassingly\nsimple model for subspace clustering with learning non-linear mapping. Compared\nwith the previous deep subspace clustering (DSC) techniques, our DCFSC does not\nhave any parameters at all for the self-expressive layer. Instead, DCFSC\nutilizes the implicit data-driven self-expressive layer derived from\nclosed-form shallow auto-encoder. Moreover, DCFSC also has no complicated\noptimization scheme, unlike the other subspace clustering methods. With its\nextreme simplicity, DCFSC has significant memory-related benefits over the\nexisting DSC method, especially on the large dataset. Several experiments\nshowed that our DCFSC model had enough potential to be a new reference model\nfor subspace clustering on large-scale high-dimensional dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 00:52:04 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Seo", "Junghoon", ""], ["Koo", "Jamyoung", ""], ["Jeon", "Taegyun", ""]]}, {"id": "1908.09451", "submitter": "Huanru Henry Mao", "authors": "Huanru Henry Mao, Bodhisattwa Prasad Majumder, Julian McAuley,\n  Garrison W. Cottrell", "title": "Improving Neural Story Generation by Targeted Common Sense Grounding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stories generated with neural language models have shown promise in\ngrammatical and stylistic consistency. However, the generated stories are still\nlacking in common sense reasoning, e.g., they often contain sentences deprived\nof world knowledge. We propose a simple multi-task learning scheme to achieve\nquantitatively better common sense reasoning in language models by leveraging\nauxiliary training signals from datasets designed to provide common sense\ngrounding. When combined with our two-stage fine-tuning pipeline, our method\nachieves improved common sense reasoning and state-of-the-art perplexity on the\nWriting Prompts (Fan et al., 2018) story generation dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 03:29:21 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 04:55:09 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Mao", "Huanru Henry", ""], ["Majumder", "Bodhisattwa Prasad", ""], ["McAuley", "Julian", ""], ["Cottrell", "Garrison W.", ""]]}, {"id": "1908.09482", "submitter": "Nadja Klein Prof. Dr.", "authors": "Nadja Klein, David J. Nott and Michael Stanley Smith", "title": "Marginally-calibrated deep distributional regression", "comments": null, "journal-ref": "Journal of Computational and Graphical Statistics (2020)", "doi": "10.1080/10618600.2020.1807996", "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) regression models are widely used in applications\nrequiring state-of-the-art predictive accuracy. However, until recently there\nhas been little work on accurate uncertainty quantification for predictions\nfrom such models. We add to this literature by outlining an approach to\nconstructing predictive distributions that are `marginally calibrated'. This is\nwhere the long run average of the predictive distributions of the response\nvariable matches the observed empirical margin. Our approach considers a DNN\nregression with a conditionally Gaussian prior for the final layer weights,\nfrom which an implicit copula process on the feature space is extracted. This\ncopula process is combined with a non-parametrically estimated marginal\ndistribution for the response. The end result is a scalable distributional DNN\nregression method with marginally calibrated predictions, and our work\ncomplements existing methods for probability calibration. The approach is first\nillustrated using two applications of dense layer feed-forward neural networks.\nHowever, our main motivating applications are in likelihood-free inference,\nwhere distributional deep regression is used to estimate marginal posterior\ndistributions. In two complex ecological time series examples we employ the\nimplicit copulas of convolutional networks, and show that marginal calibration\nresults in improved uncertainty quantification. Our approach also avoids the\nneed for manual specification of summary statistics, a requirement that is\nburdensome for users and typical of competing likelihood-free inference\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 05:47:34 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 09:29:21 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 19:33:06 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Klein", "Nadja", ""], ["Nott", "David J.", ""], ["Smith", "Michael Stanley", ""]]}, {"id": "1908.09493", "submitter": "Tobias Kuhn", "authors": "Tobias Kuhn, Steven Bourke, Levin Brinkmann, Tobias Buchwald, Conor\n  Digan, Hendrik Hache, Sebastian Jaeger, Patrick Lehmann, Oskar Maier, Stefan\n  Matting, Yura Okulovsky", "title": "Supporting stylists by recommending fashion style", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outfittery is an online personalized styling service targeted at men. We have\nhundreds of stylists who create thousands of bespoke outfits for our customers\nevery day. A critical challenge faced by our stylists when creating these\noutfits is selecting an appropriate item of clothing that makes sense in the\ncontext of the outfit being created, otherwise known as style fit. Another\nsignificant challenge is knowing if the item is relevant to the customer based\non their tastes, physical attributes and price sensitivity. At Outfittery we\nleverage machine learning extensively and combine it with human domain\nexpertise to tackle these challenges. We do this by surfacing relevant items of\nclothing during the outfit building process based on what our stylist is doing\nand what the preferences of our customer are. In this paper we describe one way\nin which we help our stylists to tackle style fit for a particular item of\nclothing and its relevance to an outfit. A thorough qualitative and\nquantitative evaluation highlights the method's ability to recommend fashion\nitems by style fit.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 06:34:05 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Kuhn", "Tobias", ""], ["Bourke", "Steven", ""], ["Brinkmann", "Levin", ""], ["Buchwald", "Tobias", ""], ["Digan", "Conor", ""], ["Hache", "Hendrik", ""], ["Jaeger", "Sebastian", ""], ["Lehmann", "Patrick", ""], ["Maier", "Oskar", ""], ["Matting", "Stefan", ""], ["Okulovsky", "Yura", ""]]}, {"id": "1908.09574", "submitter": "Alexander Mey", "authors": "Alexander Mey and Marco Loog", "title": "Improvability Through Semi-Supervised Learning: A Survey of Theoretical\n  Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised learning is a setting in which one has labeled and unlabeled\ndata available. In this survey we explore different types of theoretical\nresults when one uses unlabeled data in classification and regression tasks.\nMost methods that use unlabeled data rely on certain assumptions about the data\ndistribution. When those assumptions are not met in reality, including\nunlabeled data may actually decrease performance. Studying such methods, it\ntherefore is particularly important to have an understanding of the underlying\ntheory. In this review we gather results about the possible gains one can\nachieve when using semi-supervised learning as well as results about the limits\nof such methods. More precisely, this review collects the answers to the\nfollowing questions: What are, in terms of improving supervised methods, the\nlimits of semi-supervised learning? What are the assumptions of different\nmethods? What can we achieve if the assumptions are true? Finally, we also\ndiscuss the biggest bottleneck of semi-supervised learning, namely the\nassumptions they make.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 10:03:15 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 13:14:46 GMT"}, {"version": "v3", "created": "Thu, 30 Jul 2020 14:48:55 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Mey", "Alexander", ""], ["Loog", "Marco", ""]]}, {"id": "1908.09625", "submitter": "Martin Mundt", "authors": "Martin Mundt, Iuliia Pliushch, Sagnik Majumder, Visvanathan Ramesh", "title": "Open Set Recognition Through Deep Neural Network Uncertainty: Does\n  Out-of-Distribution Detection Require Generative Classifiers?", "comments": "Accepted at the first workshop on Statistical Deep Learning for\n  Computer Vision (SDL-CV) at ICCV 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analysis of predictive uncertainty based out-of-distribution\ndetection for different approaches to estimate various models' epistemic\nuncertainty and contrast it with extreme value theory based open set\nrecognition. While the former alone does not seem to be enough to overcome this\nchallenge, we demonstrate that uncertainty goes hand in hand with the latter\nmethod. This seems to be particularly reflected in a generative model approach,\nwhere we show that posterior based open set recognition outperforms\ndiscriminative models and predictive uncertainty based outlier rejection,\nraising the question of whether classifiers need to be generative in order to\nknow what they have not seen.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 12:19:53 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Mundt", "Martin", ""], ["Pliushch", "Iuliia", ""], ["Majumder", "Sagnik", ""], ["Ramesh", "Visvanathan", ""]]}, {"id": "1908.09653", "submitter": "Yipeng Song", "authors": "Yipeng Song", "title": "Fusing heterogeneous data sets", "comments": "PhD thesis, 173 pages, 60 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In systems biology, it is common to measure biochemical entities at different\nlevels of the same biological system. One of the central problems for the data\nfusion of such data sets is the heterogeneity of the data. This thesis\ndiscusses two types of heterogeneity. The first one is the type of data, such\nas metabolomics, proteomics and RNAseq data in genomics. These different omics\ndata reflect the properties of the studied biological system from different\nperspectives. The second one is the type of scale, which indicates the\nmeasurements obtained at different scales, such as binary, ordinal, interval\nand ratio-scaled variables. In this thesis, we developed several statistical\nmethods capable to fuse data sets of these two types of heterogeneity. The\nadvantages of the proposed methods in comparison with other approaches are\nassessed using comprehensive simulations as well as the analysis of real\nbiological data sets.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 12:20:04 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Song", "Yipeng", ""]]}, {"id": "1908.09710", "submitter": "Ehsan Hajiramezanali", "authors": "Ehsan Hajiramezanali, Arman Hasanzadeh, Nick Duffield, Krishna R\n  Narayanan, Mingyuan Zhou, Xiaoning Qian", "title": "Variational Graph Recurrent Neural Networks", "comments": "Accepted to Neural Information Processing Systems (NeurIPS2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representation learning over graph structured data has been mostly studied in\nstatic graph settings while efforts for modeling dynamic graphs are still\nscant. In this paper, we develop a novel hierarchical variational model that\nintroduces additional latent random variables to jointly model the hidden\nstates of a graph recurrent neural network (GRNN) to capture both topology and\nnode attribute changes in dynamic graphs. We argue that the use of high-level\nlatent random variables in this variational GRNN (VGRNN) can better capture\npotential variability observed in dynamic graphs as well as the uncertainty of\nnode latent representation. With semi-implicit variational inference developed\nfor this new VGRNN architecture (SI-VGRNN), we show that flexible non-Gaussian\nlatent representations can further help dynamic graph analytic tasks. Our\nexperiments with multiple real-world dynamic graph datasets demonstrate that\nSI-VGRNN and VGRNN consistently outperform the existing baseline and\nstate-of-the-art methods by a significant margin in dynamic link prediction.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 14:44:47 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 19:46:08 GMT"}, {"version": "v3", "created": "Thu, 23 Apr 2020 03:03:40 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Hajiramezanali", "Ehsan", ""], ["Hasanzadeh", "Arman", ""], ["Duffield", "Nick", ""], ["Narayanan", "Krishna R", ""], ["Zhou", "Mingyuan", ""], ["Qian", "Xiaoning", ""]]}, {"id": "1908.09712", "submitter": "Louis Falissard", "authors": "Louis Falissard, Claire Morgand, Sylvie Roussel, Claire Imbaud, Walid\n  Ghosn, Karim Bounebache, Gr\\'egoire Rey", "title": "A deep artificial neural network based model for underlying cause of\n  death prediction from death certificates", "comments": "25 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Underlying cause of death coding from death certificates is a process that is\nnowadays undertaken mostly by humans with a potential assistance from expert\nsystems such as the Iris software. It is as a consequence an expensive process\nthat can in addition suffer from geospatial discrepancies, thus severely\nimpairing the comparability of death statistics at the international level. The\nrecent advances in artificial intelligence, specifically the raise of deep\nlearning methods, has enabled computers to make efficient decisions on a number\nof complex problem that were typically considered as out of reach without human\nassistance. They however require a considerable amount of data to learn from,\nwhich is typically their main limiting factor. However, the C\\'epiDc stores an\nexhaustive database of death certificate at the French national scale,\namounting to several millions training example available for the machine\nlearning practitioner. This article presents a deep learning based tool for\nautomated coding of the underlying cause of death from the data contained in\ndeath certificates with 97.8% accuracy, a substantial achievement compared to\nthe Iris software and its 75% accuracy assessed on the same test examples. Such\nan improvement opens a whole field of new applications, from nosologist-level\nbatch automated coding to international and temporal harmonization of cause of\ndeath statistics.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 14:46:36 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Falissard", "Louis", ""], ["Morgand", "Claire", ""], ["Roussel", "Sylvie", ""], ["Imbaud", "Claire", ""], ["Ghosn", "Walid", ""], ["Bounebache", "Karim", ""], ["Rey", "Gr\u00e9goire", ""]]}, {"id": "1908.09736", "submitter": "Yicheng Cheng", "authors": "Yicheng Cheng, Bartek Rajwa, Murat Dundar", "title": "Bayesian Nonparametrics for Non-exhaustive Learning", "comments": "Published in BNP NIPS workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-exhaustive learning (NEL) is an emerging machine-learning paradigm\ndesigned to confront the challenge of non-stationary environments characterized\nby anon-exhaustive training sets lacking full information about the available\nclasses.Unlike traditional supervised learning that relies on fixed models, NEL\nutilizes self-adjusting machine learning to better accommodate the\nnon-stationary nature of the real-world problem, which is at the root of many\nrecently discovered limitations of deep learning. Some of these hurdles led to\na surge of interest in several research areas relevant to NEL such as open set\nclassification or zero-shot learning. The presented study which has been\nmotivated by two important applications proposes a NEL algorithm built on a\nhighly flexible, doubly non-parametric Bayesian Gaussian mixture model that can\ngrow arbitrarily large in terms of the number of classes and their components.\nWe report several experiments that demonstrate the promising performance of the\nintroduced model for NEL.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:31:06 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Cheng", "Yicheng", ""], ["Rajwa", "Bartek", ""], ["Dundar", "Murat", ""]]}, {"id": "1908.09744", "submitter": "Victor Gallego", "authors": "Victor Gallego and David Rios Insua", "title": "Variationally Inferred Sampling Through a Refined Bound for\n  Probabilistic Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework to boost the efficiency of Bayesian inference in probabilistic\nprograms is introduced by embedding a sampler inside a variational posterior\napproximation. We call it the refined variational approximation. Its strength\nlies both in ease of implementation and automatically tuning of the sampler\nparameters to speed up mixing time using automatic differentiation. Several\nstrategies to approximate \\emph{evidence lower bound} (ELBO) computation are\nintroduced.\n  Experimental evidence of its efficient performance is shown solving an\ninfluence diagram in a high-dimensional space using a conditional variational\nautoencoder (cVAE) as a deep Bayes classifier; an unconditional VAE on density\nestimation tasks; and state-space models for time-series data.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:38:30 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 13:47:08 GMT"}, {"version": "v3", "created": "Mon, 21 Oct 2019 14:07:28 GMT"}, {"version": "v4", "created": "Sat, 22 Feb 2020 13:26:21 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Gallego", "Victor", ""], ["Insua", "David Rios", ""]]}, {"id": "1908.09756", "submitter": "Ting Chen", "authors": "Ting Chen and Lala Li and Yizhou Sun", "title": "Differentiable Product Quantization for End-to-End Embedding Compression", "comments": "ICML'2020. Code at\n  https://github.com/chentingpc/dpq_embedding_compression", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding layers are commonly used to map discrete symbols into continuous\nembedding vectors that reflect their semantic meanings. Despite their\neffectiveness, the number of parameters in an embedding layer increases\nlinearly with the number of symbols and poses a critical challenge on memory\nand storage constraints. In this work, we propose a generic and end-to-end\nlearnable compression framework termed differentiable product quantization\n(DPQ). We present two instantiations of DPQ that leverage different\napproximation techniques to enable differentiability in end-to-end learning.\nOur method can readily serve as a drop-in alternative for any existing\nembedding layer. Empirically, DPQ offers significant compression ratios\n(14-238$\\times$) at negligible or no performance cost on 10 datasets across\nthree different language tasks.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 15:56:10 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2020 03:23:48 GMT"}, {"version": "v3", "created": "Thu, 25 Jun 2020 23:36:28 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Chen", "Ting", ""], ["Li", "Lala", ""], ["Sun", "Yizhou", ""]]}, {"id": "1908.09772", "submitter": "Xinjie Lan", "authors": "Xinjie Lan, Kenneth E. Barner", "title": "A Probabilistic Representation of Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we introduce a novel probabilistic representation of deep\nlearning, which provides an explicit explanation for the Deep Neural Networks\n(DNNs) in three aspects: (i) neurons define the energy of a Gibbs distribution;\n(ii) the hidden layers of DNNs formulate Gibbs distributions; and (iii) the\nwhole architecture of DNNs can be interpreted as a Bayesian neural network.\nBased on the proposed probabilistic representation, we investigate two\nfundamental properties of deep learning: hierarchy and generalization. First,\nwe explicitly formulate the hierarchy property from the Bayesian perspective,\nnamely that some hidden layers formulate a prior distribution and the remaining\nlayers formulate a likelihood distribution. Second, we demonstrate that DNNs\nhave an explicit regularization by learning a prior distribution and the\nlearning algorithm is one reason for decreasing the generalization ability of\nDNNs. Moreover, we clarify two empirical phenomena of DNNs that cannot be\nexplained by traditional theories of generalization. Simulation results\nvalidate the proposed probabilistic representation and the insights into these\nproperties of deep learning based on a synthetic dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:18:22 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Lan", "Xinjie", ""], ["Barner", "Kenneth E.", ""]]}, {"id": "1908.09788", "submitter": "Farid Ghareh Mohammadi", "authors": "Farid Ghareh Mohammadi, M. Hadi Amini, and Hamid R. Arabnia", "title": "An Introduction to Advanced Machine Learning : Meta Learning Algorithms,\n  Applications and Promises", "comments": "17 pages, 9 figures. arXiv admin note: text overlap with\n  arXiv:1902.08438 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In [1, 2], we have explored the theoretical aspects of feature extraction\noptimization processes for solving largescale problems and overcoming machine\nlearning limitations. Majority of optimization algorithms that have been\nintroduced in [1, 2] guarantee the optimal performance of supervised learning,\ngiven offline and discrete data, to deal with curse of dimensionality (CoD)\nproblem. These algorithms, however, are not tailored for solving emerging\nlearning problems. One of the important issues caused by online data is lack of\nsufficient samples per class. Further, traditional machine learning algorithms\ncannot achieve accurate training based on limited distributed data, as data has\nproliferated and dispersed significantly. Machine learning employs a strict\nmodel or embedded engine to train and predict which still fails to learn unseen\nclasses and sufficiently use online data. In this chapter, we introduce these\nchallenges elaborately. We further investigate Meta-Learning (MTL) algorithm,\nand their application and promises to solve the emerging problems by answering\nhow autonomous agents can learn to learn?.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:42:33 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Mohammadi", "Farid Ghareh", ""], ["Amini", "M. Hadi", ""], ["Arabnia", "Hamid R.", ""]]}, {"id": "1908.09791", "submitter": "Han Cai", "authors": "Han Cai, Chuang Gan, Tianzhe Wang, Zhekai Zhang, Song Han", "title": "Once-for-All: Train One Network and Specialize it for Efficient\n  Deployment", "comments": "ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the challenging problem of efficient inference across many devices\nand resource constraints, especially on edge devices. Conventional approaches\neither manually design or use neural architecture search (NAS) to find a\nspecialized neural network and train it from scratch for each case, which is\ncomputationally prohibitive (causing $CO_2$ emission as much as 5 cars'\nlifetime) thus unscalable. In this work, we propose to train a once-for-all\n(OFA) network that supports diverse architectural settings by decoupling\ntraining and search, to reduce the cost. We can quickly get a specialized\nsub-network by selecting from the OFA network without additional training. To\nefficiently train OFA networks, we also propose a novel progressive shrinking\nalgorithm, a generalized pruning method that reduces the model size across many\nmore dimensions than pruning (depth, width, kernel size, and resolution). It\ncan obtain a surprisingly large number of sub-networks ($> 10^{19}$) that can\nfit different hardware platforms and latency constraints while maintaining the\nsame level of accuracy as training independently. On diverse edge devices, OFA\nconsistently outperforms state-of-the-art (SOTA) NAS methods (up to 4.0%\nImageNet top1 accuracy improvement over MobileNetV3, or same accuracy but 1.5x\nfaster than MobileNetV3, 2.6x faster than EfficientNet w.r.t measured latency)\nwhile reducing many orders of magnitude GPU hours and $CO_2$ emission. In\nparticular, OFA achieves a new SOTA 80.0% ImageNet top-1 accuracy under the\nmobile setting ($<$600M MACs). OFA is the winning solution for the 3rd Low\nPower Computer Vision Challenge (LPCVC), DSP classification track and the 4th\nLPCVC, both classification track and detection track. Code and 50 pre-trained\nmodels (for many devices & many latency constraints) are released at\nhttps://github.com/mit-han-lab/once-for-all.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:46:23 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 20:26:58 GMT"}, {"version": "v3", "created": "Sun, 8 Mar 2020 18:18:22 GMT"}, {"version": "v4", "created": "Sun, 26 Apr 2020 23:02:50 GMT"}, {"version": "v5", "created": "Wed, 29 Apr 2020 20:49:05 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Cai", "Han", ""], ["Gan", "Chuang", ""], ["Wang", "Tianzhe", ""], ["Zhang", "Zhekai", ""], ["Han", "Song", ""]]}, {"id": "1908.09853", "submitter": "Maximilian Pichler", "authors": "Maximilian Pichler, Virginie Boreux, Alexandra-Maria Klein, Matthias\n  Schleuning, Florian Hartig", "title": "Machine learning algorithms to infer trait-matching and predict species\n  interactions in ecological networks", "comments": "48 pages, 5 figures", "journal-ref": null, "doi": "10.1111/2041-210X.13329", "report-no": null, "categories": "q-bio.PE cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ecologists have long suspected that species are more likely to interact if\ntheir traits match in a particular way. For example, a pollination interaction\nmay be more likely if the proportions of a bee's tongue fit a plant's flower\nshape. Empirical estimates of the importance of trait-matching for determining\nspecies interactions, however, vary significantly among different types of\necological networks. Here, we show that ambiguity among empirical\ntrait-matching studies may have arisen at least in parts from using overly\nsimple statistical models. Using simulated and real data, we contrast\nconventional generalized linear models (GLM) with more flexible Machine\nLearning (ML) models (Random Forest, Boosted Regression Trees, Deep Neural\nNetworks, Convolutional Neural Networks, Support Vector Machines, naive Bayes,\nand k-Nearest-Neighbor), testing their ability to predict species interactions\nbased on traits, and infer trait combinations causally responsible for species\ninteractions. We find that the best ML models can successfully predict species\ninteractions in plant-pollinator networks, outperforming GLMs by a substantial\nmargin. Our results also demonstrate that ML models can better identify the\ncausally responsible trait-matching combinations than GLMs. In two case\nstudies, the best ML models successfully predicted species interactions in a\nglobal plant-pollinator database and inferred ecologically plausible\ntrait-matching rules for a plant-hummingbird network, without any prior\nassumptions. We conclude that flexible ML models offer many advantages over\ntraditional regression models for understanding interaction networks. We\nanticipate that these results extrapolate to other ecological network types.\nMore generally, our results highlight the potential of machine learning and\nartificial intelligence for inference in ecology, beyond standard tasks such as\nimage or pattern recognition.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 18:00:09 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 18:58:36 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Pichler", "Maximilian", ""], ["Boreux", "Virginie", ""], ["Klein", "Alexandra-Maria", ""], ["Schleuning", "Matthias", ""], ["Hartig", "Florian", ""]]}, {"id": "1908.09874", "submitter": "Vitor Baisi Hadad", "authors": "Jonathan Johannemann, Vitor Hadad, Susan Athey, Stefan Wager", "title": "Sufficient Representations for Categorical Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many learning algorithms require categorical data to be transformed into real\nvectors before it can be used as input. Often, categorical variables are\nencoded as one-hot (or dummy) vectors. However, this mode of representation can\nbe wasteful since it adds many low-signal regressors, especially when the\nnumber of unique categories is large. In this paper, we investigate simple\nalternative solutions for universally consistent estimators that rely on\nlower-dimensional real-valued representations of categorical variables that are\n\"sufficient\" in the sense that no predictive information is lost. We then\ncompare preexisting and proposed methods on simulated and observational\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 18:41:29 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 20:28:32 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Johannemann", "Jonathan", ""], ["Hadad", "Vitor", ""], ["Athey", "Susan", ""], ["Wager", "Stefan", ""]]}, {"id": "1908.09880", "submitter": "Hrushikesh Mhaskar", "authors": "Hrushikesh N. Mhaskar", "title": "Dimension independent bounds for general shallow networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proves an abstract theorem addressing in a unified manner two\nimportant problems in function approximation: avoiding curse of dimensionality\nand estimating the degree of approximation for out-of-sample extension in\nmanifold learning. We consider an abstract (shallow) network that includes, for\nexample, neural networks, radial basis function networks, and kernels on data\ndefined manifolds used for function approximation in various settings. A deep\nnetwork is obtained by a composition of the shallow networks according to a\ndirected acyclic graph, representing the architecture of the deep network.\n  In this paper, we prove dimension independent bounds for approximation by\nshallow networks in the very general setting of what we have called\n$G$-networks on a compact metric measure space, where the notion of dimension\nis defined in terms of the cardinality of maximal distinguishable sets,\ngeneralizing the notion of dimension of a cube or a manifold. Our techniques\ngive bounds that improve without saturation with the smoothness of the kernel\ninvolved in an integral representation of the target function. In the context\nof manifold learning, our bounds provide estimates on the degree of\napproximation for an out-of-sample extension of the target function to the\nambient space.\n  One consequence of our theorem is that without the requirement of robust\nparameter selection, deep networks using a non-smooth activation function such\nas the ReLU, do not provide any significant advantage over shallow networks in\nterms of the degree of approximation alone.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:03:19 GMT"}, {"version": "v2", "created": "Mon, 4 Nov 2019 17:56:05 GMT"}], "update_date": "2019-11-05", "authors_parsed": [["Mhaskar", "Hrushikesh N.", ""]]}, {"id": "1908.09888", "submitter": "Jing Ma", "authors": "Jing Ma, Qiuchen Zhang, Jian Lou, Joyce C. Ho, Li Xiong, Xiaoqian\n  Jiang", "title": "Privacy-Preserving Tensor Factorization for Collaborative Health Data\n  Analysis", "comments": null, "journal-ref": null, "doi": "10.1145/3357384.3357878", "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor factorization has been demonstrated as an efficient approach for\ncomputational phenotyping, where massive electronic health records (EHRs) are\nconverted to concise and meaningful clinical concepts. While distributing the\ntensor factorization tasks to local sites can avoid direct data sharing, it\nstill requires the exchange of intermediary results which could reveal\nsensitive patient information. Therefore, the challenge is how to jointly\ndecompose the tensor under rigorous and principled privacy constraints, while\nstill support the model's interpretability. We propose DPFact, a\nprivacy-preserving collaborative tensor factorization method for computational\nphenotyping using EHR. It embeds advanced privacy-preserving mechanisms with\ncollaborative learning. Hospitals can keep their EHR database private but also\ncollaboratively learn meaningful clinical concepts by sharing differentially\nprivate intermediary results. Moreover, DPFact solves the heterogeneous patient\npopulation using a structured sparsity term. In our framework, each hospital\ndecomposes its local tensors, and sends the updated intermediary results with\noutput perturbation every several iterations to a semi-trusted server which\ngenerates the phenotypes. The evaluation on both real-world and synthetic\ndatasets demonstrated that under strict privacy constraints, our method is more\naccurate and communication-efficient than state-of-the-art baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 19:31:54 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 15:50:54 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ma", "Jing", ""], ["Zhang", "Qiuchen", ""], ["Lou", "Jian", ""], ["Ho", "Joyce C.", ""], ["Xiong", "Li", ""], ["Jiang", "Xiaoqian", ""]]}, {"id": "1908.09899", "submitter": "Jeremy Charlier", "authors": "Jeremy Charlier, Aman Singh, Gaston Ormazabal, Radu State, Henning\n  Schulzrinne", "title": "SynGAN: Towards Generating Synthetic Network Attacks using GANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid digital transformation without security considerations has resulted\nin the rise of global-scale cyberattacks. The first line of defense against\nthese attacks are Network Intrusion Detection Systems (NIDS). Once deployed,\nhowever, these systems work as blackboxes with a high rate of false positives\nwith no measurable effectiveness. There is a need to continuously test and\nimprove these systems by emulating real-world network attack mutations. We\npresent SynGAN, a framework that generates adversarial network attacks using\nthe Generative Adversial Networks (GAN). SynGAN generates malicious packet flow\nmutations using real attack traffic, which can improve NIDS attack detection\nrates. As a first step, we compare two public datasets, NSL-KDD and CICIDS2017,\nfor generating synthetic Distributed Denial of Service (DDoS) network attacks.\nWe evaluate the attack quality (real vs. synthetic) using a gradient boosting\nclassifier.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 20:06:31 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Charlier", "Jeremy", ""], ["Singh", "Aman", ""], ["Ormazabal", "Gaston", ""], ["State", "Radu", ""], ["Schulzrinne", "Henning", ""]]}, {"id": "1908.09915", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani and Justin Romberg", "title": "Convex Programming for Estimation in Nonlinear Recurrent Models", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formulation for nonlinear recurrent models that includes simple\nparametric models of recurrent neural networks as a special case. The proposed\nformulation leads to a natural estimator in the form of a convex program. We\nprovide a sample complexity for this estimator in the case of stable dynamics,\nwhere the nonlinear recursion has a certain contraction property, and under\ncertain regularity conditions on the input distribution. We evaluate the\nperformance of the estimator by simulation on synthetic data. These numerical\nexperiments also suggest the extent at which the imposed theoretical\nassumptions may be relaxed.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 20:50:26 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Bahmani", "Sohail", ""], ["Romberg", "Justin", ""]]}, {"id": "1908.09919", "submitter": "Erhan Sezerer", "authors": "Erhan Sezerer, Ozan Polatbilek, Selma Tekir", "title": "Gender Prediction from Tweets: Improving Neural Representations with\n  Hand-Crafted Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Author profiling is the characterization of an author through some key\nattributes such as gender, age, and language. In this paper, a RNN model with\nAttention (RNNwA) is proposed to predict the gender of a twitter user using\ntheir tweets. Both word level and tweet level attentions are utilized to learn\n'where to look'. This model\n(https://github.com/Darg-Iztech/gender-prediction-from-tweets) is improved by\nconcatenating LSA-reduced n-gram features with the learned neural\nrepresentation of a user. Both models are tested on three languages: English,\nSpanish, Arabic. The improved version of the proposed model (RNNwA + n-gram)\nachieves state-of-the-art performance on English and has competitive results on\nSpanish and Arabic.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 07:36:48 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 10:27:36 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Sezerer", "Erhan", ""], ["Polatbilek", "Ozan", ""], ["Tekir", "Selma", ""]]}, {"id": "1908.09928", "submitter": "Mansi Ranjit Mane", "authors": "Mansi Ranjit Mane, Stephen Guo, Kannan Achan", "title": "Complementary-Similarity Learning using Quadruplet Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel learning framework to answer questions such as \"if a user\nis purchasing a shirt, what other items will (s)he need with the shirt?\" Our\nframework learns distributed representations for items from available textual\ndata, with the learned representations representing items in a latent space\nexpressing functional complementarity as well similarity. In particular, our\nframework places functionally similar items close together in the latent space,\nwhile also placing complementary items closer than non-complementary items, but\nfarther away than similar items. In this study, we introduce a new dataset of\nsimilar, complementary, and negative items derived from the Amazon co-purchase\ndataset. For evaluation purposes, we focus our approach on clothing and fashion\nverticals. As per our knowledge, this is the first attempt to learn similar and\ncomplementary relationships simultaneously through just textual title metadata.\nOur framework is applicable across a broad set of items in the product catalog\nand can generate quality complementary item recommendations at scale.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 21:29:19 GMT"}, {"version": "v2", "created": "Sat, 14 Sep 2019 21:42:27 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Mane", "Mansi Ranjit", ""], ["Guo", "Stephen", ""], ["Achan", "Kannan", ""]]}, {"id": "1908.09931", "submitter": "Xiaojie Guo", "authors": "Xiaojie Guo, Amir Alipour-Fanid, Lingfei Wu, Hemant Purohit, Xiang\n  Chen, Kai Zeng, Liang Zhao", "title": "Multi-stage Deep Classifier Cascades for Open World Recognition", "comments": "This paper has been accepted by CIKM 2019", "journal-ref": "In Proceedings of the 28th ACM International Conference on\n  Information and Knowledge Management (pp. 179-188), 2019", "doi": "10.1145/3357384.3357981", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, object recognition studies are mostly conducted in a closed lab\nsetting with classes in test phase typically in training phase. However,\nreal-world problem is far more challenging because: i) new classes unseen in\nthe training phase can appear when predicting; ii) discriminative features need\nto evolve when new classes emerge in real time; and iii) instances in new\nclasses may not follow the \"independent and identically distributed\" (iid)\nassumption. Most existing work only aims to detect the unknown classes and is\nincapable of continuing to learn newer classes. Although a few methods consider\nboth detecting and including new classes, all are based on the predefined\nhandcrafted features that cannot evolve and are out-of-date for characterizing\nemerging classes. Thus, to address the above challenges, we propose a novel\ngeneric end-to-end framework consisting of a dynamic cascade of classifiers\nthat incrementally learn their dynamic and inherent features. The proposed\nmethod injects dynamic elements into the system by detecting instances from\nunknown classes, while at the same time incrementally updating the model to\ninclude the new classes. The resulting cascade tree grows by adding a new leaf\nnode classifier once a new class is detected, and the discriminative features\nare updated via an end-to-end learning strategy. Experiments on two real-world\ndatasets demonstrate that our proposed method outperforms existing\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 21:31:20 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Guo", "Xiaojie", ""], ["Alipour-Fanid", "Amir", ""], ["Wu", "Lingfei", ""], ["Purohit", "Hemant", ""], ["Chen", "Xiang", ""], ["Zeng", "Kai", ""], ["Zhao", "Liang", ""]]}, {"id": "1908.09936", "submitter": "Adrian De Wynter", "authors": "Adrian de Wynter and Lambert Mathias", "title": "Leveraging External Knowledge for Out-Of-Vocabulary Entity Labeling", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with previously unseen slots is a challenging problem in a real-world\nmulti-domain dialogue state tracking task. Other approaches rely on predefined\nmappings to generate candidate slot keys, as well as their associated values.\nThis, however, may fail when the key, the value, or both, are not seen during\ntraining. To address this problem we introduce a neural network that leverages\nexternal knowledge bases (KBs) to better classify out-of-vocabulary slot keys\nand values. This network projects the slot into an attribute space derived from\nthe KB, and, by leveraging similarities in this space, we propose candidate\nslot keys and values to the dialogue state tracker. We provide extensive\nexperiments that demonstrate that our stratagem can improve upon a previous\napproach, which relies on predefined candidate mappings. In particular, we\nevaluate this approach by training a state-of-the-art model with candidates\ngenerated from our network, and obtained relative increases of 57.7% and 82.7%\nin F1 score and accuracy, respectively, for the aforementioned model, when\ncompared to the current candidate generation strategy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:08:55 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["de Wynter", "Adrian", ""], ["Mathias", "Lambert", ""]]}, {"id": "1908.09941", "submitter": "Yan Yan", "authors": "Yan Yan, Yi Xu, Lijun Zhang, Xiaoyu Wang, Tianbao Yang", "title": "Stochastic Optimization for Non-convex Inf-Projection Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study a family of non-convex and possibly non-smooth\ninf-projection minimization problems, where the target objective function is\nequal to minimization of a joint function over another variable. This problem\ninclude difference of convex (DC) functions and a family of bi-convex functions\nas special cases. We develop stochastic algorithms and establish their\nfirst-order convergence for finding a (nearly) stationary solution of the\ntarget non-convex function under different conditions of the component\nfunctions. To the best of our knowledge, this is the first work that\ncomprehensively studies stochastic optimization of non-convex inf-projection\nminimization problems with provable convergence guarantee. Our algorithms\nenable efficient stochastic optimization of a family of non-decomposable DC\nfunctions and a family of bi-convex functions. To demonstrate the power of the\nproposed algorithms we consider an important application in variance-based\nregularization. Experiments verify the effectiveness of our inf-projection\nbased formulation and the proposed stochastic algorithm in comparison with\nprevious stochastic algorithms based on the min-max formulation for achieving\nthe same effect.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:28:53 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 20:16:48 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Yan", "Yan", ""], ["Xu", "Yi", ""], ["Zhang", "Lijun", ""], ["Wang", "Xiaoyu", ""], ["Yang", "Tianbao", ""]]}, {"id": "1908.09942", "submitter": "Adrian De Wynter", "authors": "Adrian de Wynter", "title": "On the Bounds of Function Approximations", "comments": "Accepted as a full paper at ICANN 2019. The final, authenticated\n  publication will be available at https://doi.org/10.1007/978-3-030-30487-4_32", "journal-ref": "In: Tetko, I. V. et al. (eds.) ICANN 2019. LNCS, vol 11727.\n  Springer, Heidelberg, pp. 401-417", "doi": "10.1007/978-3-030-30487-4_32", "report-no": null, "categories": "cs.LG cs.CC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within machine learning, the subfield of Neural Architecture Search (NAS) has\nrecently garnered research attention due to its ability to improve upon\nhuman-designed models. However, the computational requirements for finding an\nexact solution to this problem are often intractable, and the design of the\nsearch space still requires manual intervention. In this paper we attempt to\nestablish a formalized framework from which we can better understand the\ncomputational bounds of NAS in relation to its search space. For this, we first\nreformulate the function approximation problem in terms of sequences of\nfunctions, and we call it the Function Approximation (FA) problem; then we show\nthat it is computationally infeasible to devise a procedure that solves FA for\nall functions to zero error, regardless of the search space. We show also that\nsuch error will be minimal if a specific class of functions is present in the\nsearch space. Subsequently, we show that machine learning as a mathematical\nproblem is a solution strategy for FA, albeit not an effective one, and further\ndescribe a stronger version of this approach: the Approximate Architectural\nSearch Problem (a-ASP), which is the mathematical equivalent of NAS. We\nleverage the framework from this paper and results from the literature to\ndescribe the conditions under which a-ASP can potentially solve FA as well as\nan exhaustive search, but in polynomial time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:32:33 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["de Wynter", "Adrian", ""]]}, {"id": "1908.09943", "submitter": "Furkan K{\\i}nl{\\i}", "authors": "Furkan K{\\i}nl{\\i} and Bar{\\i}\\c{s} \\\"Ozcan and Furkan K{\\i}ra\\c{c}", "title": "Fashion Image Retrieval with Capsule Networks", "comments": "Accepted to the International Conference on Computer Vision, ICCV\n  2019, Workshop on Computer Vision for Fashion, Art and Design", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we investigate in-shop clothing retrieval performance of\ndensely-connected Capsule Networks with dynamic routing. To achieve this, we\npropose Triplet-based design of Capsule Network architecture with two different\nfeature extraction methods. In our design, Stacked-convolutional (SC) and\nResidual-connected (RC) blocks are used to form the input of capsule layers.\nExperimental results show that both of our designs outperform all variants of\nthe baseline study, namely FashionNet, without relying on the landmark\ninformation. Moreover, when compared to the SOTA architectures on clothing\nretrieval, our proposed Triplet Capsule Networks achieve comparable recall\nrates only with half of parameters used in the SOTA architectures.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:33:14 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["K\u0131nl\u0131", "Furkan", ""], ["\u00d6zcan", "Bar\u0131\u015f", ""], ["K\u0131ra\u00e7", "Furkan", ""]]}, {"id": "1908.09946", "submitter": "Avgoustinos Vouros", "authors": "Avgoustinos Vouros (1), Stephen Langdell (2), Mike Croucher (2), Eleni\n  Vasilaki (1) ((1) Department of Computer Science, University of Sheffield,\n  (2) Numerical Algorithms Group (NAG))", "title": "An empirical comparison between stochastic and deterministic centroid\n  initialisation for K-Means variations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-Means is one of the most used algorithms for data clustering and the usual\nclustering method for benchmarking. Despite its wide application it is\nwell-known that it suffers from a series of disadvantages; it is only able to\nfind local minima and the positions of the initial clustering centres\n(centroids) can greatly affect the clustering solution. Over the years many\nK-Means variations and initialisation techniques have been proposed with\ndifferent degrees of complexity. In this study we focus on common K-Means\nvariations along with a range of deterministic and stochastic initialisation\ntechniques. We show that, on average, more sophisticated initialisation\ntechniques alleviate the need for complex clustering methods. Furthermore,\ndeterministic methods perform better than stochastic methods. However, there is\na trade-off: less sophisticated stochastic methods, executed multiple times,\ncan result in better clustering. Factoring in execution time, deterministic\nmethods can be competitive and result in a good clustering solution. These\nconclusions are obtained through extensive benchmarking using a range of\nsynthetic model generators and real-world data sets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:37:57 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 21:33:34 GMT"}, {"version": "v3", "created": "Thu, 3 Oct 2019 09:55:30 GMT"}, {"version": "v4", "created": "Wed, 9 Oct 2019 10:21:24 GMT"}, {"version": "v5", "created": "Thu, 16 Jul 2020 06:36:38 GMT"}, {"version": "v6", "created": "Sat, 27 Feb 2021 22:11:05 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Vouros", "Avgoustinos", ""], ["Langdell", "Stephen", ""], ["Croucher", "Mike", ""], ["Vasilaki", "Eleni", ""]]}, {"id": "1908.09948", "submitter": "Hossein Sadeghi Esfahani", "authors": "Hossein Sadeghi, Evgeny Andriyash, Walter Vinci, Lorenzo Buffoni,\n  Mohammad H. Amin", "title": "PixelVAE++: Improved PixelVAE with Discrete Prior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constructing powerful generative models for natural images is a challenging\ntask. PixelCNN models capture details and local information in images very well\nbut have limited receptive field. Variational autoencoders with a factorial\ndecoder can capture global information easily, but they often fail to\nreconstruct details faithfully. PixelVAE combines the best features of the two\nmodels and constructs a generative model that is able to learn local and global\nstructures. Here we introduce PixelVAE++, a VAE with three types of latent\nvariables and a PixelCNN++ for the decoder. We introduce a novel architecture\nthat reuses a part of the decoder as an encoder. We achieve the state of the\nart performance on binary data sets such as MNIST and Omniglot and achieve the\nstate of the art performance on CIFAR-10 among latent variable models while\nkeeping the latent variables informative.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:40:55 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Sadeghi", "Hossein", ""], ["Andriyash", "Evgeny", ""], ["Vinci", "Walter", ""], ["Buffoni", "Lorenzo", ""], ["Amin", "Mohammad H.", ""]]}, {"id": "1908.09961", "submitter": "Kien Do", "authors": "Kien Do and Truyen Tran", "title": "Theory and Evaluation Metrics for Learning Disentangled Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make two theoretical contributions to disentanglement learning by (a)\ndefining precise semantics of disentangled representations, and (b)\nestablishing robust metrics for evaluation. First, we characterize the concept\n\"disentangled representations\" used in supervised and unsupervised methods\nalong three dimensions-informativeness, separability and interpretability -\nwhich can be expressed and quantified explicitly using information-theoretic\nconstructs. This helps explain the behaviors of several well-known\ndisentanglement learning models. We then propose robust metrics for measuring\ninformativeness, separability and interpretability. Through a comprehensive\nsuite of experiments, we show that our metrics correctly characterize the\nrepresentations learned by different methods and are consistent with\nqualitative (visual) results. Thus, the metrics allow disentanglement learning\nmethods to be compared on a fair ground. We also empirically uncovered new\ninteresting properties of VAE-based methods and interpreted them with our\nformulation. These findings are promising and hopefully will encourage the\ndesign of more theoretically driven models for learning disentangled\nrepresentations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 23:55:11 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 21:08:15 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 22:59:04 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Do", "Kien", ""], ["Tran", "Truyen", ""]]}, {"id": "1908.09967", "submitter": "Timothy Coleman", "authors": "Tim Coleman, Kimberly Kaufeld, Mary Frances Dorn, Lucas Mentch", "title": "Locally Optimized Random Forests", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard supervised learning procedures are validated against a test set that\nis assumed to have come from the same distribution as the training data.\nHowever, in many problems, the test data may have come from a different\ndistribution. We consider the case of having many labeled observations from one\ndistribution, $P_1$, and making predictions at unlabeled points that come from\n$P_2$. We combine the high predictive accuracy of random forests (Breiman,\n2001) with an importance sampling scheme, where the splits and predictions of\nthe base-trees are done in a weighted manner, which we call Locally Optimized\nRandom Forests. These weights correspond to a non-parametric estimate of the\nlikelihood ratio between the training and test distributions. To estimate these\nratios with an unlabeled test set, we make the covariate shift assumption,\nwhere the differences in distribution are only a function of the training\ndistributions (Shimodaira, 2000.) This methodology is motivated by the problem\nof forecasting power outages during hurricanes. The extreme nature of the most\ndevastating hurricanes means that typical validation set ups will overly favor\nless extreme storms. Our method provides a data-driven means of adapting a\nmachine learning method to deal with extreme events.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 00:42:56 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Coleman", "Tim", ""], ["Kaufeld", "Kimberly", ""], ["Dorn", "Mary Frances", ""], ["Mentch", "Lucas", ""]]}, {"id": "1908.09970", "submitter": "Raef Bassily", "authors": "Raef Bassily, Vitaly Feldman, Kunal Talwar, Abhradeep Thakurta", "title": "Private Stochastic Convex Optimization with Optimal Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study differentially private (DP) algorithms for stochastic convex\noptimization (SCO). In this problem the goal is to approximately minimize the\npopulation loss given i.i.d. samples from a distribution over convex and\nLipschitz loss functions. A long line of existing work on private convex\noptimization focuses on the empirical loss and derives asymptotically tight\nbounds on the excess empirical loss. However a significant gap exists in the\nknown bounds for the population loss. We show that, up to logarithmic factors,\nthe optimal excess population loss for DP algorithms is equal to the larger of\nthe optimal non-private excess population loss, and the optimal excess\nempirical loss of DP algorithms. This implies that, contrary to intuition based\non private ERM, private SCO has asymptotically the same rate of $1/\\sqrt{n}$ as\nnon-private SCO in the parameter regime most common in practice. The best\nprevious result in this setting gives rate of $1/n^{1/4}$. Our approach builds\non existing differentially private algorithms and relies on the analysis of\nalgorithmic stability to ensure generalization.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 00:50:27 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Bassily", "Raef", ""], ["Feldman", "Vitaly", ""], ["Talwar", "Kunal", ""], ["Thakurta", "Abhradeep", ""]]}, {"id": "1908.09979", "submitter": "Huanrui Yang", "authors": "Huanrui Yang, Wei Wen, Hai Li", "title": "DeepHoyer: Learning Sparser Neural Network with Differentiable\n  Scale-Invariant Sparsity Measures", "comments": "To be appeared in ICLR 2020 (poster presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In seeking for sparse and efficient neural network models, many previous\nworks investigated on enforcing L1 or L0 regularizers to encourage weight\nsparsity during training. The L0 regularizer measures the parameter sparsity\ndirectly and is invariant to the scaling of parameter values, but it cannot\nprovide useful gradients, and therefore requires complex optimization\ntechniques. The L1 regularizer is almost everywhere differentiable and can be\neasily optimized with gradient descent. Yet it is not scale-invariant, causing\nthe same shrinking rate to all parameters, which is inefficient in increasing\nsparsity. Inspired by the Hoyer measure (the ratio between L1 and L2 norms)\nused in traditional compressed sensing problems, we present DeepHoyer, a set of\nsparsity-inducing regularizers that are both differentiable almost everywhere\nand scale-invariant. Our experiments show that enforcing DeepHoyer regularizers\ncan produce even sparser neural network models than previous works, under the\nsame accuracy level. We also show that DeepHoyer can be applied to both\nelement-wise and structural pruning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 01:34:25 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 18:04:11 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Yang", "Huanrui", ""], ["Wen", "Wei", ""], ["Li", "Hai", ""]]}, {"id": "1908.09980", "submitter": "Chang Liu", "authors": "Eddie S.J. Du, Chang Liu, David H. Wayne", "title": "Automated Fashion Size Normalization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to accurately predict the fit of fashion items and recommend the\ncorrect size is key to reducing merchandise returns in e-commerce. A critical\nprerequisite of fit prediction is size normalization, the mapping of product\nsizes across brands to a common space in which sizes can be compared. At\npresent, size normalization is usually a time-consuming manual process. We\npropose a method to automate size normalization through the use of salesdata.\nThe size mappings generated from our automated approaches are comparable to\nhuman-generated mappings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 01:43:43 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Du", "Eddie S. J.", ""], ["Liu", "Chang", ""], ["Wayne", "David H.", ""]]}, {"id": "1908.10001", "submitter": "Bai Li", "authors": "Bai Li, Nanyi Jiang, Joey Sham, Henry Shi, Hussein Fazal", "title": "Real-world Conversational AI for Hotel Bookings", "comments": "Accepted to IEEE AI4I 2019 (International Conference on Artificial\n  Intelligence for Industries)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a real-world conversational AI system to search for\nand book hotels through text messaging. Our architecture consists of a\nframe-based dialogue management system, which calls machine learning models for\nintent classification, named entity recognition, and information retrieval\nsubtasks. Our chatbot has been deployed on a commercial scale, handling tens of\nthousands of hotel searches every day. We describe the various opportunities\nand challenges of developing a chatbot in the travel industry.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 03:13:53 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Li", "Bai", ""], ["Jiang", "Nanyi", ""], ["Sham", "Joey", ""], ["Shi", "Henry", ""], ["Fazal", "Hussein", ""]]}, {"id": "1908.10030", "submitter": "Joe Antognini", "authors": "Joseph M. Antognini", "title": "Finite size corrections for neural network Gaussian processes", "comments": "Presented at the 2019 ICML Workshop on Theoretical Physics for Deep\n  Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent surge of interest in modeling neural networks (NNs)\nas Gaussian processes. In the limit of a NN of infinite width the NN becomes\nequivalent to a Gaussian process. Here we demonstrate that for an ensemble of\nlarge, finite, fully connected networks with a single hidden layer the\ndistribution of outputs at initialization is well described by a Gaussian\nperturbed by the fourth Hermite polynomial for weights drawn from a symmetric\ndistribution. We show that the scale of the perturbation is inversely\nproportional to the number of units in the NN and that higher order terms decay\nmore rapidly, thereby recovering the Edgeworth expansion. We conclude by\nobserving that understanding how this perturbation changes under training would\nreveal the regimes in which the Gaussian process framework is valid to model NN\nbehavior.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 04:49:23 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Antognini", "Joseph M.", ""]]}, {"id": "1908.10037", "submitter": "Shengyu Zhu", "authors": "Shengyu Zhu, Biao Chen, Zhitang Chen, Pengfei Yang", "title": "Asymptotically Optimal One- and Two-Sample Testing with Kernels", "comments": "Accepted to IEEE Transactions on Information Theory. This version may\n  be further modified", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the asymptotic performance of nonparametric one- and\ntwo-sample testing. The exponential decay rate or error exponent of the type-II\nerror probability is used as the asymptotic performance metric, and an optimal\ntest achieves the maximum rate subject to a constant level constraint on the\ntype-I error probability. With Sanov's theorem, we derive a sufficient\ncondition for one-sample tests to achieve the optimal error exponent in the\nuniversal setting, i.e., for any distribution defining the alternative\nhypothesis. We then show that two classes of Maximum Mean Discrepancy (MMD)\nbased tests attain the optimal type-II error exponent on $\\mathbb R^d$, while\nthe quadratic-time Kernel Stein Discrepancy (KSD) based tests achieve this\noptimality with an asymptotic level constraint. For general two-sample testing,\nhowever, Sanov's theorem is insufficient to obtain a similar sufficient\ncondition. We proceed to establish an extended version of Sanov's theorem and\nderive an exact error exponent for the quadratic-time MMD based two-sample\ntests. The obtained error exponent is further shown to be optimal among all\ntwo-sample tests satisfying a given level constraint. Our work hence provides\nan achievability result for optimal nonparametric one- and two-sample testing\nin the universal setting. Application to off-line change detection and related\nissues are also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 05:39:36 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 10:05:22 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zhu", "Shengyu", ""], ["Chen", "Biao", ""], ["Chen", "Zhitang", ""], ["Yang", "Pengfei", ""]]}, {"id": "1908.10088", "submitter": "Yang Liu", "authors": "Yang Liu, Runnan He, Kuanquan Wang, Qince Li, Qiang Sun, Na Zhao and\n  Henggui Zhang", "title": "Automatic Detection of ECG Abnormalities by using an Ensemble of Deep\n  Residual Networks with Attention", "comments": "8 pages, 2 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heart disease is one of the most common diseases causing morbidity and\nmortality. Electrocardiogram (ECG) has been widely used for diagnosing heart\ndiseases for its simplicity and non-invasive property. Automatic ECG analyzing\ntechnologies are expected to reduce human working load and increase diagnostic\nefficacy. However, there are still some challenges to be addressed for\nachieving this goal. In this study, we develop an algorithm to identify\nmultiple abnormalities from 12-lead ECG recordings. In the algorithm pipeline,\nseveral preprocessing methods are firstly applied on the ECG data for\ndenoising, augmentation and balancing recording numbers of variant classes. In\nconsideration of efficiency and consistency of data length, the recordings are\npadded or truncated into a medium length, where the padding/truncating time\nwindows are selected randomly to sup-press overfitting. Then, the ECGs are used\nto train deep neural network (DNN) models with a novel structure that combines\na deep residual network with an attention mechanism. Finally, an ensemble model\nis built based on these trained models to make predictions on the test data\nset. Our method is evaluated based on the test set of the First China ECG\nIntelligent Competition dataset by using the F1 metric that is regarded as the\nharmonic mean between the precision and recall. The resultant overall F1 score\nof the algorithm is 0.875, showing a promising performance and potential for\npractical use.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 08:57:55 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Liu", "Yang", ""], ["He", "Runnan", ""], ["Wang", "Kuanquan", ""], ["Li", "Qince", ""], ["Sun", "Qiang", ""], ["Zhao", "Na", ""], ["Zhang", "Henggui", ""]]}, {"id": "1908.10133", "submitter": "Andres Perez-Lopez", "authors": "Andres Perez-Lopez, Eduardo Fonseca, Xavier Serra", "title": "A hybrid parametric-deep learning approach for sound event localization\n  and detection", "comments": "5 pages, 5 figures, submitted to DCASE2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work describes and discusses an algorithm submitted to the Sound Event\nLocalization and Detection Task of DCASE2019 Challenge. The proposed\nmethodology relies on parametric spatial audio analysis for source localization\nand detection, combined with a deep learning-based monophonic event classifier.\nThe evaluation of the proposed algorithm yields overall results comparable to\nthe baseline system. The main highlight is a reduction of the localization\nerror on the evaluation dataset by a factor of 2.6, compared with the baseline\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 11:20:57 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Perez-Lopez", "Andres", ""], ["Fonseca", "Eduardo", ""], ["Serra", "Xavier", ""]]}, {"id": "1908.10149", "submitter": "Michael Barz", "authors": "Michael Barz and Daniel Sonntag", "title": "Incremental Improvement of a Question Answering System by Re-ranking\n  Answer Candidates using Machine Learning", "comments": "Accepted for oral presentation at tenth International Workshop on\n  Spoken Dialogue Systems Technology (IWSDS) 2019", "journal-ref": null, "doi": "10.1007/978-981-15-9323-9_34", "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a method for re-ranking top-10 results of a state-of-the-art\nquestion answering (QA) system. The goal of our re-ranking approach is to\nimprove the answer selection given the user question and the top-10 candidates.\nWe focus on improving deployed QA systems that do not allow re-training or\nre-training comes at a high cost. Our re-ranking approach learns a similarity\nfunction using n-gram based features using the query, the answer and the\ninitial system confidence as input. Our contributions are: (1) we generate a QA\ntraining corpus starting from 877 answers from the customer care domain of\nT-Mobile Austria, (2) we implement a state-of-the-art QA pipeline using neural\nsentence embeddings that encode queries in the same space than the answer\nindex, and (3) we evaluate the QA pipeline and our re-ranking approach using a\nseparately provided test set. The test set can be considered to be available\nafter deployment of the system, e.g., based on feedback of users. Our results\nshow that the system performance, in terms of top-n accuracy and the mean\nreciprocal rank, benefits from re-ranking using gradient boosted regression\ntrees. On average, the mean reciprocal rank improves by 9.15%.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 11:54:23 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Barz", "Michael", ""], ["Sonntag", "Daniel", ""]]}, {"id": "1908.10166", "submitter": "Casimiro Adays Curbelo Monta\\~nez", "authors": "Casimiro Aday Curbelo Monta\\~nez, Paul Fergus, Carl Chalmers, Nurul\n  Ahamed Hassain Malim, Basma Abdulaimma, Denis Reilly, and Francesco Falciani", "title": "SAERMA: Stacked Autoencoder Rule Mining Algorithm for the Interpretation\n  of Epistatic Interactions in GWAS for Extreme Obesity", "comments": "12 pages, 6 figures, 12 tables, 9 equations, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important challenges in the analysis of high-throughput\ngenetic data is the development of efficient computational methods to identify\nstatistically significant Single Nucleotide Polymorphisms (SNPs). Genome-wide\nassociation studies (GWAS) use single-locus analysis where each SNP is\nindependently tested for association with phenotypes. The limitation with this\napproach, however, is its inability to explain genetic variation in complex\ndiseases. Alternative approaches are required to model the intricate\nrelationships between SNPs. Our proposed approach extends GWAS by combining\ndeep learning stacked autoencoders (SAEs) and association rule mining (ARM) to\nidentify epistatic interactions between SNPs. Following traditional GWAS\nquality control and association analysis, the most significant SNPs are\nselected and used in the subsequent analysis to investigate epistasis. SAERMA\ncontrols the classification results produced in the final fully connected\nmulti-layer feedforward artificial neural network (MLP) by manipulating the\ninterestingness measures, support and confidence, in the rule generation\nprocess. The best classification results were achieved with 204 SNPs compressed\nto 100 units (77% AUC, 77% SE, 68% SP, 53% Gini, logloss=0.58, and MSE=0.20),\nalthough it was possible to achieve 73% AUC (77% SE, 63% SP, 45% Gini,\nlogloss=0.62, and MSE=0.21) with 50 hidden units - both supported by close\nmodel interpretation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 12:49:05 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Monta\u00f1ez", "Casimiro Aday Curbelo", ""], ["Fergus", "Paul", ""], ["Chalmers", "Carl", ""], ["Malim", "Nurul Ahamed Hassain", ""], ["Abdulaimma", "Basma", ""], ["Reilly", "Denis", ""], ["Falciani", "Francesco", ""]]}, {"id": "1908.10172", "submitter": "Mert B\\\"ulent Sar{\\i}y{\\i}ld{\\i}z", "authors": "Mert B\\\"ulent Sar{\\i}y{\\i}ld{\\i}z, Ramazan G\\\"okberk Cinbi\\c{s}, Erman\n  Ayday", "title": "Key Protected Classification for Collaborative Learning", "comments": "Accepted to Pattern Recognition", "journal-ref": null, "doi": "10.1016/j.patcog.2020.107327", "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale datasets play a fundamental role in training deep learning\nmodels. However, dataset collection is difficult in domains that involve\nsensitive information. Collaborative learning techniques provide a\nprivacy-preserving solution, by enabling training over a number of private\ndatasets that are not shared by their owners. However, recently, it has been\nshown that the existing collaborative learning frameworks are vulnerable to an\nactive adversary that runs a generative adversarial network (GAN) attack. In\nthis work, we propose a novel classification model that is resilient against\nsuch attacks by design. More specifically, we introduce a key-based\nclassification model and a principled training scheme that protects class\nscores by using class-specific private keys, which effectively hide the\ninformation necessary for a GAN attack. We additionally show how to utilize\nhigh dimensional keys to improve the robustness against attacks without\nincreasing the model complexity. Our detailed experiments demonstrate the\neffectiveness of the proposed technique. Source code is available at\nhttps://github.com/mbsariyildiz/key-protected-classification.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 13:00:30 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2020 09:31:45 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Sar\u0131y\u0131ld\u0131z", "Mert B\u00fclent", ""], ["Cinbi\u015f", "Ramazan G\u00f6kberk", ""], ["Ayday", "Erman", ""]]}, {"id": "1908.10187", "submitter": "M. Ricardo Carlos", "authors": "M. Ricardo Carlos", "title": "A Machine Learning Approach for Smartphone-based Sensing of Roads and\n  Driving Style", "comments": "Doctoral Dissertation. Dissertation Advisors: Luis Carlos Gonz\\'alez\n  Gurrola and Fernando Mart\\'inez", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road transportation is of critical importance for a nation, having profound\neffects in the economy, the health and life style of its people. With the\ngrowth of cities and populations come bigger demands for mobility and safety,\ncreating new problems and magnifying those of the past. New tools are needed to\nface the challenge, to keep roads in good conditions, their users safe, and\nminimize the impact on the environment.\n  This dissertation is concerned with road quality assessment and aggressive\ndriving, two important problems in road transportation, approached in the\ncontext of Intelligent Transportation Systems by using Machine Learning\ntechniques to analyze acceleration time series acquired with smartphone-based\nopportunistic sensing to automatically detect, classify, and characterize\nevents of interest.\n  Two aspects of road quality assessment are addressed: the detection and the\ncharacterization of road anomalies. For the first, the most widely cited works\nin the literature are compared and proposals capable of equal or better\nperformance are presented, removing the reliance on threshold values and\nreducing the computational cost and dimensionality of previous proposals. For\nthe second, new approaches for the estimation of pothole depth and the\nfunctional condition of speed reducers are showed. The new problem of pothole\ndepth ranking is introduced, using a learning-to-rank approach to sort\nacceleration signals by the depth of the potholes that they reflect.\n  The classification of aggressive driving maneuvers is done with automatic\nfeature extraction, finding characteristically shaped subsequences in the\nsignals as more effective discriminants than conventional descriptors\ncalculated over time windows.\n  Finally, all the previously mentioned tasks are combined to produce a robust\nroad transport evaluation platform.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 00:16:10 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Carlos", "M. Ricardo", ""]]}, {"id": "1908.10206", "submitter": "Raul Vicente", "authors": "Raul Vicente", "title": "The many faces of deep learning", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has sparked a network of mutual interactions between different\ndisciplines and AI. Naturally, each discipline focuses and interprets the\nworkings of deep learning in different ways. This diversity of perspectives on\ndeep learning, from neuroscience to statistical physics, is a rich source of\ninspiration that fuels novel developments in the theory and applications of\nmachine learning. In this perspective, we collect and synthesize different\nintuitions scattered across several communities as for how deep learning works.\nIn particular, we will briefly discuss the different perspectives that\ndisciplines across mathematics, physics, computation, and neuroscience take on\nhow deep learning does its tricks. Our discussion on each perspective is\nnecessarily shallow due to the multiple views that had to be covered. The\ndeepness in this case should come from putting all these faces of deep learning\ntogether in the reader's mind, so that one can look at the same problem from\ndifferent angles.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 12:04:49 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Vicente", "Raul", ""]]}, {"id": "1908.10208", "submitter": "Yucheng Liu", "authors": "Yucheng Liu, Naji Khosravan, Yulin Liu, Joseph Stember, Jonathan\n  Shoag, Christopher E. Barbieri, Ulas Bagci, and Sachin Jambawalikar", "title": "Cross-modality Knowledge Transfer for Prostate Segmentation from CT\n  Scans", "comments": "9 pages, 3 figures, 2019 MICCAI-DART workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG physics.med-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating large scale high-quality annotations is a known challenge in medical\nimaging. In this work, based on the CycleGAN algorithm, we propose leveraging\nannotations from one modality to be useful in other modalities. More\nspecifically, the proposed algorithm creates highly realistic synthetic CT\nimages (SynCT) from prostate MR images using unpaired data sets. By using SynCT\nimages (without segmentation labels) and MR images (with segmentation labels\navailable), we have trained a deep segmentation network for precise delineation\nof prostate from real CT scans. For the generator in our CycleGAN, the cycle\nconsistency term is used to guarantee that SynCT shares the identical\nmanually-drawn, high-quality masks originally delineated on MR images. Further,\nwe introduce a cost function based on structural similarity index (SSIM) to\nimprove the anatomical similarity between real and synthetic images. For\nsegmentation followed by the SynCT generation from CycleGAN, automatic\ndelineation is achieved through a 2.5D Residual U-Net. Quantitative evaluation\ndemonstrates comparable segmentation results between our SynCT and radiologist\ndrawn masks for real CT images, solving an important problem in medical image\nsegmentation field when ground truth annotations are not available for the\nmodality of interest.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 00:39:50 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 16:43:03 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Liu", "Yucheng", ""], ["Khosravan", "Naji", ""], ["Liu", "Yulin", ""], ["Stember", "Joseph", ""], ["Shoag", "Jonathan", ""], ["Barbieri", "Christopher E.", ""], ["Bagci", "Ulas", ""], ["Jambawalikar", "Sachin", ""]]}, {"id": "1908.10209", "submitter": "Sameera Ramasinghe Mr.", "authors": "Sameera Ramasinghe, Salman Khan, Nick Barnes, Stephen Gould", "title": "Blended Convolution and Synthesis for Efficient Discrimination of 3D\n  Shapes", "comments": "10 pages: corrected typos and added affiliations. The IEEE Winter\n  Conference on Applications of Computer Vision. 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing networks directly learn feature representations on 3D point clouds\nfor shape analysis. We argue that 3D point clouds are highly redundant and hold\nirregular (permutation-invariant) structure, which makes it difficult to\nachieve inter-class discrimination efficiently. In this paper, we propose a\ntwo-faceted solution to this problem that is seamlessly integrated in a single\n`Blended Convolution and Synthesis' layer. This fully differentiable layer\nperforms two critical tasks in succession. In the first step, it projects the\ninput 3D point clouds into a latent 3D space to synthesize a highly compact and\nmore inter-class discriminative point cloud representation. Since, 3D point\nclouds do not follow a Euclidean topology, standard 2/3D Convolutional Neural\nNetworks offer limited representation capability. Therefore, in the second\nstep, it uses a novel 3D convolution operator functioning inside the unit ball\n($\\mathbb{B}^3$) to extract useful volumetric features. We extensively derive\nformulae to achieve both translation and rotation of our novel convolution\nkernels. Finally, using the proposed techniques we present an extremely\nlight-weight, end-to-end architecture that achieves compelling results on 3D\nshape recognition and retrieval.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 08:18:33 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 09:29:28 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Ramasinghe", "Sameera", ""], ["Khan", "Salman", ""], ["Barnes", "Nick", ""], ["Gould", "Stephen", ""]]}, {"id": "1908.10218", "submitter": "Peng Xie", "authors": "Peng Xie, Tianrui Li, Jia Liu, Shengdong Du, Xin Yang, Junbo Zhang", "title": "Urban flows prediction from spatial-temporal data using machine\n  learning: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Urban spatial-temporal flows prediction is of great importance to traffic\nmanagement, land use, public safety, etc. Urban flows are affected by several\ncomplex and dynamic factors, such as patterns of human activities, weather,\nevents and holidays. Datasets evaluated the flows come from various sources in\ndifferent domains, e.g. mobile phone data, taxi trajectories data, metro/bus\nswiping data, bike-sharing data and so on. To summarize these methodologies of\nurban flows prediction, in this paper, we first introduce four main factors\naffecting urban flows. Second, in order to further analysis urban flows, a\npreparation process of multi-sources spatial-temporal data related with urban\nflows is partitioned into three groups. Third, we choose the spatial-temporal\ndynamic data as a case study for the urban flows prediction task. Fourth, we\nanalyze and compare some well-known and state-of-the-art flows prediction\nmethods in detail, classifying them into five categories: statistics-based,\ntraditional machine learning-based, deep learning-based, reinforcement\nlearning-based and transfer learning-based methods. Finally, we give open\nchallenges of urban flows prediction and an outlook in the future of this\nfield. This paper will facilitate researchers find suitable methods and open\ndatasets for addressing urban spatial-temporal flows forecast problems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 13:50:37 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Xie", "Peng", ""], ["Li", "Tianrui", ""], ["Liu", "Jia", ""], ["Du", "Shengdong", ""], ["Yang", "Xin", ""], ["Zhang", "Junbo", ""]]}, {"id": "1908.10219", "submitter": "Bo Li", "authors": "Bo Li, Marius de Groot, Meike Vernooij, Arfan Ikram, Wiro Niessen,\n  Esther Bron", "title": "Reproducible White Matter Tract Segmentation Using 3D U-Net on a\n  Large-scale DTI Dataset", "comments": "Machine Learning in Medical Imaging (MLMI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tract-specific diffusion measures, as derived from brain diffusion MRI, have\nbeen linked to white matter tract structural integrity and neurodegeneration.\nAs a consequence, there is a large interest in the automatic segmentation of\nwhite matter tract in diffusion tensor MRI data. Methods based on the\ntractography are popular for white matter tract segmentation. However, because\nof the limited consistency and long processing time, such methods may not be\nsuitable for clinical practice. We therefore developed a novel convolutional\nneural network based method to directly segment white matter tract trained on a\nlow-resolution dataset of 9149 DTI images. The method is optimized on input,\nloss function and network architecture selections. We evaluated both\nsegmentation accuracy and reproducibility, and reproducibility of determining\ntract-specific diffusion measures. The reproducibility of the method is higher\nthan that of the reference standard and the determined diffusion measures are\nconsistent. Therefore, we expect our method to be applicable in clinical\npractice and in longitudinal analysis of white matter microstructure.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 11:06:14 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Li", "Bo", ""], ["de Groot", "Marius", ""], ["Vernooij", "Meike", ""], ["Ikram", "Arfan", ""], ["Niessen", "Wiro", ""], ["Bron", "Esther", ""]]}, {"id": "1908.10221", "submitter": "Bo Li", "authors": "Bo Li, Wiro Niessen, Stefan Klein, Marius de Groot, Arfan Ikram, Meike\n  Vernooij, Esther Bron", "title": "A hybrid deep learning framework for integrated segmentation and\n  registration: evaluation on longitudinal white matter tract changes", "comments": "MICCAI 2019 (oral presentation)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accurately analyze changes of anatomical structures in longitudinal\nimaging studies, consistent segmentation across multiple time-points is\nrequired. Existing solutions often involve independent registration and\nsegmentation components. Registration between time-points is used either as a\nprior for segmentation in a subsequent time point or to perform segmentation in\na common space. In this work, we propose a novel hybrid convolutional neural\nnetwork (CNN) that integrates segmentation and registration into a single\nprocedure. We hypothesize that the joint optimization leads to increased\nperformance on both tasks. The hybrid CNN is trained by minimizing an\nintegrated loss function composed of four different terms, measuring\nsegmentation accuracy, similarity between registered images, deformation field\nsmoothness, and segmentation consistency. We applied this method to the\nsegmentation of white matter tracts, describing functionally grouped axonal\nfibers, using N=8045 longitudinal brain MRI data of 3249 individuals. The\nproposed method was compared with two multistage pipelines using two existing\nsegmentation methods combined with a conventional deformable registration\nalgorithm. In addition, we assessed the added value of the joint optimization\nfor segmentation and registration separately. The hybrid CNN yielded\nsignificantly higher accuracy, consistency and reproducibility of segmentation\nthan the multistage pipelines, and was orders of magnitude faster. Therefore,\nwe expect it can serve as a novel tool to support clinical and epidemiological\nanalyses on understanding microstructural brain changes over time.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 10:39:30 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Li", "Bo", ""], ["Niessen", "Wiro", ""], ["Klein", "Stefan", ""], ["de Groot", "Marius", ""], ["Ikram", "Arfan", ""], ["Vernooij", "Meike", ""], ["Bron", "Esther", ""]]}, {"id": "1908.10223", "submitter": "Canyu Le", "authors": "Canyu Le, Xihan Wei, Biao Wang, Lei Zhang, Zhonggui Chen", "title": "Learning Continually from Low-shot Data Stream", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has achieved remarkable results on various applications,\nit is usually data hungry and struggles to learn over non-stationary data\nstream. To solve these two limits, the deep learning model should not only be\nable to learn from a few of data, but also incrementally learn new concepts\nfrom data stream over time without forgetting the previous knowledge. Limited\nliterature simultaneously address both problems. In this work, we propose a\nnovel approach, MetaCL, which enables neural networks to effectively learn meta\nknowledge from low-shot data stream without catastrophic forgetting. MetaCL\ntrains a model to exploit the intrinsic feature of data (i.e. meta knowledge)\nand dynamically penalize the important model parameters change to preserve\nlearned knowledge. In this way, the deep learning model can efficiently obtain\nnew knowledge from small volume of data and still keep high performance on\nprevious tasks. MetaCL is conceptually simple, easy to implement and\nmodel-agnostic. We implement our method on three recent regularization-based\nmethods. Extensive experiments show that our approach leads to state-of-the-art\nperformance on image classification benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:16:31 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 12:58:51 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Le", "Canyu", ""], ["Wei", "Xihan", ""], ["Wang", "Biao", ""], ["Zhang", "Lei", ""], ["Chen", "Zhonggui", ""]]}, {"id": "1908.10226", "submitter": "I\\~nigo Urteaga", "authors": "I\\~nigo Urteaga, Tristan Bertin, Theresa M. Hardy, David J. Albers,\n  No\\'emie Elhadad", "title": "Multi-Task Gaussian Processes and Dilated Convolutional Networks for\n  Reconstruction of Reproductive Hormonal Dynamics", "comments": "Accepted and presented in Machine Learning for Healthcare 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an end-to-end statistical framework for personalized, accurate,\nand minimally invasive modeling of female reproductive hormonal patterns.\nReconstructing and forecasting the evolution of hormonal dynamics is a\nchallenging task, but a critical one to improve general understanding of the\nmenstrual cycle and personalized detection of potential health issues. Our goal\nis to infer and forecast individual hormone daily levels over time, while\naccommodating pragmatic and minimally invasive measurement settings. To that\nend, our approach combines the power of probabilistic generative models (i.e.,\nmulti-task Gaussian processes) with the flexibility of neural networks (i.e., a\ndilated convolutional architecture) to learn complex temporal mappings. To\nattain accurate hormone level reconstruction with as little data as possible,\nwe propose a sampling mechanism for optimal reconstruction accuracy with\nlimited sampling budget. Our results show the validity of our proposed hormonal\ndynamic modeling framework, as it provides accurate predictive performance\nacross different realistic sampling budgets and outperforms baselines methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:21:31 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Urteaga", "I\u00f1igo", ""], ["Bertin", "Tristan", ""], ["Hardy", "Theresa M.", ""], ["Albers", "David J.", ""], ["Elhadad", "No\u00e9mie", ""]]}, {"id": "1908.10243", "submitter": "Robert O'Shea", "authors": "Robert O'Shea", "title": "Model Selection With Graphical Neighbour Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate model selection is a fundamental requirement for statistical\nanalysis. In many real-world applications of graphical modelling, correct model\nstructure identification is the ultimate objective. Standard model validation\nprocedures such as information theoretic scores and cross validation have\ndemonstrated poor performance in the high dimensional setting. Specialised\nmethods such as EBIC, StARS and RIC have been developed for the explicit\npurpose of high-dimensional Gaussian graphical model selection. We present a\nnovel model score criterion, Graphical Neighbour Information. This method\ndemonstrates oracle performance in high-dimensional model selection,\noutperforming the current state-of-the-art in our simulations. The Graphical\nNeighbour Information criterion has the additional advantage of efficient,\nclosed-form computability, sparing the costly inference of multiple models on\ndata subsamples. We provide a theoretical analysis of the method and benchmark\nsimulations versus the current state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:47:53 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["O'Shea", "Robert", ""]]}, {"id": "1908.10247", "submitter": "Hamza Jaffali", "authors": "Hamza Jaffali, Luke Oeding", "title": "Learning Algebraic Models of Quantum Entanglement", "comments": "22 pages. comments welcome", "journal-ref": "Quantum Inf Process 19, 279 (2020)", "doi": "10.1007/s11128-020-02785-4", "report-no": null, "categories": "cs.LG cs.ET math.AG quant-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review supervised learning and deep neural network design for learning\nmembership on algebraic varieties. We demonstrate that these trained artificial\nneural networks can predict the entanglement type for quantum states. We give\nexamples for detecting degenerate states, as well as border rank classification\nfor up to 5 binary qubits and 3 qutrits (ternary qubits).\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:54:34 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 12:46:52 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Jaffali", "Hamza", ""], ["Oeding", "Luke", ""]]}, {"id": "1908.10266", "submitter": "Santi Puch", "authors": "Santi Puch, Irina S\\'anchez, Matt Rowe", "title": "Few-shot Learning with Deep Triplet Networks for Brain Imaging Modality\n  Recognition", "comments": "Medical Image Learning with Less Labels and Imperfect Data, MICCAI\n  2019 workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Image modality recognition is essential for efficient imaging workflows in\ncurrent clinical environments, where multiple imaging modalities are used to\nbetter comprehend complex diseases. Emerging biomarkers from novel, rare\nmodalities are being developed to aid in such understanding, however the\navailability of these images is often limited. This scenario raises the\nnecessity of recognising new imaging modalities without them being collected\nand annotated in large amounts. In this work, we present a few-shot learning\nmodel for limited training examples based on Deep Triplet Networks. We show\nthat the proposed model is more accurate in distinguishing different modalities\nthan a traditional Convolutional Neural Network classifier when limited samples\nare available. Furthermore, we evaluate the performance of both classifiers\nwhen presented with noisy samples and provide an initial inspection of how the\nproposed model can incorporate measures of uncertainty to be more robust\nagainst out-of-sample examples.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:19:24 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Puch", "Santi", ""], ["S\u00e1nchez", "Irina", ""], ["Rowe", "Matt", ""]]}, {"id": "1908.10281", "submitter": "Santi Puch", "authors": "Santi Puch, Irina S\\'anchez, Aura Hern\\'andez, Gemma Piella, Vesna\n  Prchkovska", "title": "Global Planar Convolutions for improved context aggregation in Brain\n  Tumor Segmentation", "comments": "Brainlesion: Glioma, Multiple Sclerosis, Stroke and Traumatic Brain\n  Injuries. BrainLes 2018", "journal-ref": null, "doi": "10.1007/978-3-030-11726-9_35", "report-no": null, "categories": "eess.IV cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we introduce the Global Planar Convolution module as a\nbuilding-block for fully-convolutional networks that aggregates global\ninformation and, therefore, enhances the context perception capabilities of\nsegmentation networks in the context of brain tumor segmentation. We implement\ntwo baseline architectures (3D UNet and a residual version of 3D UNet, ResUNet)\nand present a novel architecture based on these two architectures, ContextNet,\nthat includes the proposed Global Planar Convolution module. We show that the\naddition of such module eliminates the need of building networks with several\nrepresentation levels, which tend to be over-parametrized and to showcase slow\nrates of convergence. Furthermore, we provide a visual demonstration of the\nbehavior of GPC modules via visualization of intermediate representations. We\nfinally participate in the 2018 edition of the BraTS challenge with our best\nperforming models, that are based on ContextNet, and report the evaluation\nscores on the validation and the test sets of the challenge.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:38:50 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Puch", "Santi", ""], ["S\u00e1nchez", "Irina", ""], ["Hern\u00e1ndez", "Aura", ""], ["Piella", "Gemma", ""], ["Prchkovska", "Vesna", ""]]}, {"id": "1908.10283", "submitter": "Marc Ru{\\ss}wurm", "authors": "Marc Ru{\\ss}wurm, Romain Tavenard, S\\'ebastien Lef\\`evre, Marco\n  K\\\"orner", "title": "Early Classification for Agricultural Monitoring from Satellite Time\n  Series", "comments": "Appeared at the International Conference on Machine Learning AI for\n  Social Good Workshop, Long Beach, United States, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work, we introduce a recently developed early classification\nmechanism to satellite-based agricultural monitoring. It augments existing\nclassification models by an additional stopping probability based on the\npreviously seen information. This mechanism is end-to-end trainable and derives\nits stopping decision solely from the observed satellite data. We show results\non field parcels in central Europe where sufficient ground truth data is\navailable for an empiric evaluation of the results with local phenological\ninformation obtained from authorities. We observe that the recurrent neural\nnetwork outfitted with this early classification mechanism was able to\ndistinguish the many of the crop types before the end of the vegetative period.\nFurther, we associated these stopping times with evaluated ground truth\ninformation and saw that the times of classification were related to\ncharacteristic events of the observed plants' phenology.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:43:04 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Ru\u00dfwurm", "Marc", ""], ["Tavenard", "Romain", ""], ["Lef\u00e8vre", "S\u00e9bastien", ""], ["K\u00f6rner", "Marco", ""]]}, {"id": "1908.10284", "submitter": "Daniele Calandriello", "authors": "Daniele Calandriello, Lorenzo Rosasco", "title": "Statistical and Computational Trade-Offs in Kernel K-Means", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, pp. 9357-9367.\n  2018", "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the efficiency of k-means in terms of both statistical and\ncomputational requirements. More precisely, we study a Nystr\\\"om approach to\nkernel k-means. We analyze the statistical properties of the proposed method\nand show that it achieves the same accuracy of exact kernel k-means with only a\nfraction of computations. Indeed, we prove under basic assumptions that\nsampling $\\sqrt{n}$ Nystr\\\"om landmarks allows to greatly reduce computational\ncosts without incurring in any loss of accuracy. To the best of our knowledge\nthis is the first result of this kind for unsupervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 15:43:49 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Calandriello", "Daniele", ""], ["Rosasco", "Lorenzo", ""]]}, {"id": "1908.10292", "submitter": "Alexander Rakhlin", "authors": "Tengyuan Liang and Alexander Rakhlin and Xiyu Zhai", "title": "On the Multiple Descent of Minimum-Norm Interpolants and Restricted\n  Lower Isometry of Kernels", "comments": null, "journal-ref": "Proceedings of the 33rd Conference on Learning Theory 125 (2020)\n  2683-2711", "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the risk of minimum-norm interpolants of data in Reproducing Kernel\nHilbert Spaces. Our upper bounds on the risk are of a multiple-descent shape\nfor the various scalings of $d = n^{\\alpha}$, $\\alpha\\in(0,1)$, for the input\ndimension $d$ and sample size $n$. Empirical evidence supports our finding that\nminimum-norm interpolants in RKHS can exhibit this unusual non-monotonicity in\nsample size; furthermore, locations of the peaks in our experiments match our\ntheoretical predictions. Since gradient flow on appropriately initialized wide\nneural networks converges to a minimum-norm interpolant with respect to a\ncertain kernel, our analysis also yields novel estimation and generalization\nguarantees for these over-parametrized models.\n  At the heart of our analysis is a study of spectral properties of the random\nkernel matrix restricted to a filtration of eigen-spaces of the population\ncovariance operator, and may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:05:50 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 15:22:45 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Liang", "Tengyuan", ""], ["Rakhlin", "Alexander", ""], ["Zhai", "Xiyu", ""]]}, {"id": "1908.10324", "submitter": "Tengyuan Liang", "authors": "Tengyuan Liang", "title": "On the Minimax Optimality of Estimating the Wasserstein Metric", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the minimax optimal rate for estimating the Wasserstein-$1$ metric\nbetween two unknown probability measures based on $n$ i.i.d. empirical samples\nfrom them. We show that estimating the Wasserstein metric itself between\nprobability measures, is not significantly easier than estimating the\nprobability measures under the Wasserstein metric. We prove that the minimax\noptimal rates for these two problems are multiplicatively equivalent, up to a\n$\\log \\log (n)/\\log (n)$ factor.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:56:35 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Liang", "Tengyuan", ""]]}, {"id": "1908.10336", "submitter": "William Schoenberg", "authors": "William Schoenberg", "title": "Feedback System Neural Networks for Inferring Causality in Directed\n  Cyclic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new causal network learning algorithm (FSNN, Feedback\nSystem Neural Network) based on the construction and analysis of a non-linear\nsystem of Ordinary Differential Equations (ODEs). The constructed system\nprovides insight into the mechanisms responsible for generating the past and\npotential future behavior of dynamic systems. It is also interpretable in terms\nof real system variables, providing a wholistic, causally accurate, and\nsystemic understanding of the real-life interactions governing observed\nphenomena. This paper demonstrates the generation of an n-dimensional ordinary\ndifferential equation model that can be parameterized to fit measured data\nusing standard numerical optimization techniques. The model makes use of feed\nforward artificial neural nets to capture nonlinearity, but is a parsimonious\nand interpretable representation of the network of causal relationships in\ncomplex systems. The generated model can easily and rapidly be experimented\nwith and analyzed to determine the origins of behavior using the loops that\nmatter method (Schoenberg et. al 2019). A demonstration of the utility and\napplicability of the method is given, showing that it produces an accurate, and\ncausally correct model for a three state, non-linear, complex dynamic system of\nknown origin. Generalization to other dynamic systems with other data sources\nis then discussed.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:15:42 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 22:23:28 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Schoenberg", "William", ""]]}, {"id": "1908.10341", "submitter": "Marco Broccardo", "authors": "Ziqi Wang, Marco Broccardo", "title": "A novel active learning-based Gaussian process metamodelling strategy\n  for estimating the full probability distribution in forward UQ analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an active learning-based Gaussian process (AL-GP)\nmetamodelling method to estimate the cumulative as well as complementary\ncumulative distribution function (CDF/CCDF) for forward uncertainty\nquantification (UQ) problems. Within the field of UQ, previous studies focused\non developing AL-GP approaches for reliability (rare event probability)\nanalysis of expensive black-box solvers. A naive iteration of these algorithms\nwith respect to different CDF/CCDF threshold values would yield a discretized\nCDF/CCDF. However, this approach inevitably leads to a trade-off between\naccuracy and computational efficiency since both depend (in opposite way) on\nthe selected discretization. In this study, a specialized error measure and a\nlearning function are developed such that the resulting AL-GP method is able to\nefficiently estimate the CDF/CCDF for a specified range of interest without an\nexplicit dependency on discretization. Particularly, the proposed AL-GP method\nis able to simultaneously provide accurate CDF and CCDF estimation in their\nmedian-low probability regions. Three numerical examples are introduced to test\nand verify the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:25:01 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Wang", "Ziqi", ""], ["Broccardo", "Marco", ""]]}, {"id": "1908.10356", "submitter": "Navid Alemi Koohbanani", "authors": "Navid Alemi Koohbanani, Mostafa Jahanifar, Ali Gooya, Nasir Rajpoot", "title": "Nuclear Instance Segmentation using a Proposal-Free Spatially Aware Deep\n  Learning Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV q-bio.TO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nuclear segmentation in histology images is a challenging task due to\nsignificant variations in the shape and appearance of nuclei. One of the main\nhurdles in nuclear instance segmentation is overlapping nuclei where a smart\nalgorithm is needed to separate each nucleus. In this paper, we introduce a\nproposal-free deep learning based framework to address these challenges. To\nthis end, we propose a spatially-aware network (SpaNet) to capture spatial\ninformation in a multi-scale manner. A dual-head variation of the SpaNet is\nfirst utilized to predict the pixel-wise segmentation and centroid detection\nmaps of nuclei. Based on these outputs, a single-head SpaNet predicts the\npositional information related to each nucleus instance. Spectral clustering\nmethod is applied on the output of the last SpaNet, which utilizes the nuclear\nmask and the Gaussian-like detection map for determining the connected\ncomponents and associated cluster identifiers, respectively. The output of the\nclustering method is the final nuclear instance segmentation mask. We applied\nour method on a publicly available multi-organ data set and achieved\nstate-of-the-art performance for nuclear segmentation.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 17:53:39 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Koohbanani", "Navid Alemi", ""], ["Jahanifar", "Mostafa", ""], ["Gooya", "Ali", ""], ["Rajpoot", "Nasir", ""]]}, {"id": "1908.10382", "submitter": "Rishit Sheth", "authors": "Rishit Sheth, Nicolo Fusi", "title": "Feature Gradients: Scalable Feature Selection via Discrete Relaxation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce Feature Gradients, a gradient-based search\nalgorithm for feature selection. Our approach extends a recent result on the\nestimation of learnability in the sublinear data regime by showing that the\ncalculation can be performed iteratively (i.e., in mini-batches) and in linear\ntime and space with respect to both the number of features D and the sample\nsize N . This, along with a discrete-to-continuous relaxation of the search\ndomain, allows for an efficient, gradient-based search algorithm among feature\nsubsets for very large datasets. Crucially, our algorithm is capable of finding\nhigher-order correlations between features and targets for both the N > D and N\n< D regimes, as opposed to approaches that do not consider such interactions\nand/or only consider one regime. We provide experimental demonstration of the\nalgorithm in small and large sample-and feature-size settings.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:02:11 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Sheth", "Rishit", ""], ["Fusi", "Nicolo", ""]]}, {"id": "1908.10396", "submitter": "Ruiqi Guo", "authors": "Ruiqi Guo, Philip Sun, Erik Lindgren, Quan Geng, David Simcha, Felix\n  Chern, Sanjiv Kumar", "title": "Accelerating Large-Scale Inference with Anisotropic Vector Quantization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantization based techniques are the current state-of-the-art for scaling\nmaximum inner product search to massive databases. Traditional approaches to\nquantization aim to minimize the reconstruction error of the database points.\nBased on the observation that for a given query, the database points that have\nthe largest inner products are more relevant, we develop a family of\nanisotropic quantization loss functions. Under natural statistical assumptions,\nwe show that quantization with these loss functions leads to a new variant of\nvector quantization that more greatly penalizes the parallel component of a\ndatapoint's residual relative to its orthogonal component. The proposed\napproach achieves state-of-the-art results on the public benchmarks available\nat \\url{ann-benchmarks.com}.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:27:17 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 20:41:46 GMT"}, {"version": "v3", "created": "Tue, 12 May 2020 20:17:08 GMT"}, {"version": "v4", "created": "Fri, 17 Jul 2020 22:24:16 GMT"}, {"version": "v5", "created": "Fri, 4 Dec 2020 21:29:31 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Guo", "Ruiqi", ""], ["Sun", "Philip", ""], ["Lindgren", "Erik", ""], ["Geng", "Quan", ""], ["Simcha", "David", ""], ["Chern", "Felix", ""], ["Kumar", "Sanjiv", ""]]}, {"id": "1908.10400", "submitter": "Alireza Fallah", "authors": "Alireza Fallah, Aryan Mokhtari, Asuman Ozdaglar", "title": "On the Convergence Theory of Gradient-Based Model-Agnostic Meta-Learning\n  Algorithms", "comments": "To appear in the proceedings of the $23^{rd}$ International\n  Conference on Artificial Intelligence and Statistics (AISTATS) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the convergence of a class of gradient-based Model-Agnostic\nMeta-Learning (MAML) methods and characterize their overall complexity as well\nas their best achievable accuracy in terms of gradient norm for nonconvex loss\nfunctions. We start with the MAML method and its first-order approximation\n(FO-MAML) and highlight the challenges that emerge in their analysis. By\novercoming these challenges not only we provide the first theoretical\nguarantees for MAML and FO-MAML in nonconvex settings, but also we answer some\nof the unanswered questions for the implementation of these algorithms\nincluding how to choose their learning rate and the batch size for both tasks\nand datasets corresponding to tasks. In particular, we show that MAML can find\nan $\\epsilon$-first-order stationary point ($\\epsilon$-FOSP) for any positive\n$\\epsilon$ after at most $\\mathcal{O}(1/\\epsilon^2)$ iterations at the expense\nof requiring second-order information. We also show that FO-MAML which ignores\nthe second-order information required in the update of MAML cannot achieve any\nsmall desired level of accuracy, i.e., FO-MAML cannot find an $\\epsilon$-FOSP\nfor any $\\epsilon>0$. We further propose a new variant of the MAML algorithm\ncalled Hessian-free MAML which preserves all theoretical guarantees of MAML,\nwithout requiring access to second-order information.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:36:10 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 03:21:03 GMT"}, {"version": "v3", "created": "Fri, 13 Mar 2020 00:38:45 GMT"}, {"version": "v4", "created": "Sat, 16 May 2020 01:46:37 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Fallah", "Alireza", ""], ["Mokhtari", "Aryan", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "1908.10402", "submitter": "Huozhi Zhou", "authors": "Huozhi Zhou, Lingda Wang, Lav R. Varshney, Ee-Peng Lim", "title": "A Near-Optimal Change-Detection Based Algorithm for Piecewise-Stationary\n  Combinatorial Semi-Bandits", "comments": "Accepted by AAAI 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the piecewise-stationary combinatorial semi-bandit problem.\nCompared to the original combinatorial semi-bandit problem, our setting assumes\nthe reward distributions of base arms may change in a piecewise-stationary\nmanner at unknown time steps. We propose an algorithm, \\texttt{GLR-CUCB}, which\nincorporates an efficient combinatorial semi-bandit algorithm, \\texttt{CUCB},\nwith an almost parameter-free change-point detector, the \\emph{Generalized\nLikelihood Ratio Test} (GLRT). Our analysis shows that the regret of\n\\texttt{GLR-CUCB} is upper bounded by $\\mathcal{O}(\\sqrt{NKT\\log{T}})$, where\n$N$ is the number of piecewise-stationary segments, $K$ is the number of base\narms, and $T$ is the number of time steps. As a complement, we also derive a\nnearly matching regret lower bound on the order of $\\Omega(\\sqrt{NKT}$), for\nboth piecewise-stationary multi-armed bandits and combinatorial semi-bandits,\nusing information-theoretic techniques and judiciously constructed\npiecewise-stationary bandit instances. Our lower bound is tighter than the best\navailable regret lower bound, which is $\\Omega(\\sqrt{T})$. Numerical\nexperiments on both synthetic and real-world datasets demonstrate the\nsuperiority of \\texttt{GLR-CUCB} compared to other state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:37:16 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 02:18:16 GMT"}, {"version": "v3", "created": "Fri, 15 Nov 2019 15:55:02 GMT"}, {"version": "v4", "created": "Fri, 21 Feb 2020 17:45:27 GMT"}], "update_date": "2020-02-24", "authors_parsed": [["Zhou", "Huozhi", ""], ["Wang", "Lingda", ""], ["Varshney", "Lav R.", ""], ["Lim", "Ee-Peng", ""]]}, {"id": "1908.10407", "submitter": "Cosmin Anitescu", "authors": "Esteban Samaniego, Cosmin Anitescu, Somdatta Goswami, Vien Minh\n  Nguyen-Thanh, Hongwei Guo, Khader Hamdia, Timon Rabczuk, Xiaoying Zhuang", "title": "An Energy Approach to the Solution of Partial Differential Equations in\n  Computational Mechanics via Machine Learning: Concepts, Implementation and\n  Applications", "comments": null, "journal-ref": null, "doi": "10.1016/j.cma.2019.112790", "report-no": null, "categories": "stat.ML cs.LG math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial Differential Equations (PDE) are fundamental to model different\nphenomena in science and engineering mathematically. Solving them is a crucial\nstep towards a precise knowledge of the behaviour of natural and engineered\nsystems. In general, in order to solve PDEs that represent real systems to an\nacceptable degree, analytical methods are usually not enough. One has to resort\nto discretization methods. For engineering problems, probably the best known\noption is the finite element method (FEM). However, powerful alternatives such\nas mesh-free methods and Isogeometric Analysis (IGA) are also available. The\nfundamental idea is to approximate the solution of the PDE by means of\nfunctions specifically built to have some desirable properties. In this\ncontribution, we explore Deep Neural Networks (DNNs) as an option for\napproximation. They have shown impressive results in areas such as visual\nrecognition. DNNs are regarded here as function approximation machines. There\nis great flexibility to define their structure and important advances in the\narchitecture and the efficiency of the algorithms to implement them make DNNs a\nvery interesting alternative to approximate the solution of a PDE. We\nconcentrate in applications that have an interest for Computational Mechanics.\nMost contributions that have decided to explore this possibility have adopted a\ncollocation strategy. In this contribution, we concentrate in mechanical\nproblems and analyze the energetic format of the PDE. The energy of a\nmechanical system seems to be the natural loss function for a machine learning\nmethod to approach a mechanical problem. As proofs of concept, we deal with\nseveral problems and explore the capabilities of the method for applications in\nengineering.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:50:50 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 10:43:50 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Samaniego", "Esteban", ""], ["Anitescu", "Cosmin", ""], ["Goswami", "Somdatta", ""], ["Nguyen-Thanh", "Vien Minh", ""], ["Guo", "Hongwei", ""], ["Hamdia", "Khader", ""], ["Rabczuk", "Timon", ""], ["Zhuang", "Xiaoying", ""]]}, {"id": "1908.10408", "submitter": "Vikas Garg", "authors": "Vikas K. Garg and Inderjit S. Dhillon and Hsiang-Fu Yu", "title": "Multiresolution Transformer Networks: Recurrence is Not Essential for\n  Modeling Hierarchical Structure", "comments": "Initial version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The architecture of Transformer is based entirely on self-attention, and has\nbeen shown to outperform models that employ recurrence on sequence transduction\ntasks such as machine translation. The superior performance of Transformer has\nbeen attributed to propagating signals over shorter distances, between\npositions in the input and the output, compared to the recurrent architectures.\nWe establish connections between the dynamics in Transformer and recurrent\nnetworks to argue that several factors including gradient flow along an\nensemble of multiple weakly dependent paths play a paramount role in the\nsuccess of Transformer. We then leverage the dynamics to introduce {\\em\nMultiresolution Transformer Networks} as the first architecture that exploits\nhierarchical structure in data via self-attention. Our models significantly\noutperform state-of-the-art recurrent and hierarchical recurrent models on two\nreal-world datasets for query suggestion, namely, \\aol and \\amazon. In\nparticular, on AOL data, our model registers at least 20\\% improvement on each\nprecision score, and over 25\\% improvement on the BLEU score with respect to\nthe best performing recurrent model. We thus provide strong evidence that\nrecurrence is not essential for modeling hierarchical structure.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 18:51:50 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Garg", "Vikas K.", ""], ["Dhillon", "Inderjit S.", ""], ["Yu", "Hsiang-Fu", ""]]}, {"id": "1908.10417", "submitter": "Corneliu Arsene Dr", "authors": "Corneliu Arsene", "title": "Complex Deep Learning Models for Denoising of Human Heart ECG signals", "comments": "51 pages, 23 figures", "journal-ref": "EUSIPCO.2019 (Pages 11- 18)", "doi": "10.5281/zenodo.3904247", "report-no": null, "categories": "cs.LG cs.CV eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Effective and powerful methods for denoising real electrocardiogram (ECG)\nsignals are important for wearable sensors and devices. Deep Learning (DL)\nmodels have been used extensively in image processing and other domains with\ngreat success but only very recently have been used in processing ECG signals.\nThis paper presents several DL models namely Convolutional Neural Networks\n(CNNs), Long Short-Term Memory (LSTM), Restricted Boltzmann Machine (RBM)\ntogether with the more conventional filtering methods (low pass filtering, high\npass filtering, Notch filtering) and the standard wavelet-based technique for\ndenoising EEG signals. These methods are trained, tested and evaluated on\ndifferent synthetic and real ECG datasets taken from the MIT PhysioNet database\nand for different simulation conditions (i.e. various lengths of the ECG\nsignals, single or multiple records). The results show the CNN model is a\nperformant model that can be used for off-line denoising ECG applications where\nit is satisfactory to train on a clean part of an ECG signal from an ECG\nrecord, and then to test on the same ECG signal, which would have some high\nlevel of noise added to it. However, for real-time applications or near-real\ntime applications, this task becomes more cumbersome, as the clean part of an\nECG signal is very probable to be very limited in size. Therefore the solution\nput forth in this work is to train a CNN model on 1 second ECG noisy artificial\nmultiple heartbeat data (i.e. ECG at effort), which was generated in a first\ninstance based on few sequences of real signal heartbeat ECG data (i.e. ECG at\nrest). Afterwards it would be possible to use the trained CNN model in real\nlife situations to denoise the ECG signal.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 19:14:32 GMT"}, {"version": "v2", "created": "Thu, 12 Sep 2019 13:44:56 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 10:14:02 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Arsene", "Corneliu", ""]]}, {"id": "1908.10449", "submitter": "Eric Yuan", "authors": "Xingdi Yuan, Jie Fu, Marc-Alexandre Cote, Yi Tay, Christopher Pal,\n  Adam Trischler", "title": "Interactive Machine Comprehension with Information Seeking Agents", "comments": "ACL2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing machine reading comprehension (MRC) models do not scale effectively\nto real-world applications like web-level information retrieval and question\nanswering (QA). We argue that this stems from the nature of MRC datasets: most\nof these are static environments wherein the supporting documents and all\nnecessary information are fully observed. In this paper, we propose a simple\nmethod that reframes existing MRC datasets as interactive, partially observable\nenvironments. Specifically, we \"occlude\" the majority of a document's text and\nadd context-sensitive commands that reveal \"glimpses\" of the hidden text to a\nmodel. We repurpose SQuAD and NewsQA as an initial case study, and then show\nhow the interactive corpora can be used to train a model that seeks relevant\ninformation through sequential decision making. We believe that this setting\ncan contribute in scaling models to web-level QA scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 20:11:54 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 17:51:00 GMT"}, {"version": "v3", "created": "Thu, 16 Apr 2020 17:23:30 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Yuan", "Xingdi", ""], ["Fu", "Jie", ""], ["Cote", "Marc-Alexandre", ""], ["Tay", "Yi", ""], ["Pal", "Christopher", ""], ["Trischler", "Adam", ""]]}, {"id": "1908.10479", "submitter": "Nevena Lazic", "authors": "Yasin Abbasi-Yadkori, Nevena Lazic, Csaba Szepesvari, Gellert Weisz", "title": "Exploration-Enhanced POLITEX", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study algorithms for average-cost reinforcement learning problems with\nvalue function approximation. Our starting point is the recently proposed\nPOLITEX algorithm, a version of policy iteration where the policy produced in\neach iteration is near-optimal in hindsight for the sum of all past value\nfunction estimates. POLITEX has sublinear regret guarantees in uniformly-mixing\nMDPs when the value estimation error can be controlled, which can be satisfied\nif all policies sufficiently explore the environment. Unfortunately, this\nassumption is often unrealistic. Motivated by the rapid growth of interest in\ndeveloping policies that learn to explore their environment in the lack of\nrewards (also known as no-reward learning), we replace the previous assumption\nthat all policies explore the environment with that a single, sufficiently\nexploring policy is available beforehand. The main contribution of the paper is\nthe modification of POLITEX to incorporate such an exploration policy in a way\nthat allows us to obtain a regret guarantee similar to the previous one but\nwithout requiring that all policies explore environment. In addition to the\nnovel theoretical guarantees, we demonstrate the benefits of our scheme on\nenvironments which are difficult to explore using simple schemes like\ndithering. While the solution we obtain may not achieve the best possible\nregret, it is the first result that shows how to control the regret in the\npresence of function approximation errors on problems where exploration is\nnontrivial. Our approach can also be seen as a way of reducing the problem of\nminimizing the regret to learning a good exploration policy. We believe that\nmodular approaches like ours can be highly beneficial in tackling harder\ncontrol problems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 21:53:42 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Abbasi-Yadkori", "Yasin", ""], ["Lazic", "Nevena", ""], ["Szepesvari", "Csaba", ""], ["Weisz", "Gellert", ""]]}, {"id": "1908.10493", "submitter": "Zhongkui Ma", "authors": "Zhongkui Ma", "title": "The Function Representation of Artificial Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.FA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper expresses the structure of artificial neural network (ANN) as a\nfunctional form, using the activation integral concept derived from the\nactivation function. In this way, the structure of ANN can be represented by a\nsimple function, and it is possible to find the mathematical solutions of ANN.\nThus, it can be recognized that the current ANN can be placed in a more\nreasonable framework. Perhaps all questions about ANN will be eliminated.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 23:20:34 GMT"}, {"version": "v2", "created": "Tue, 3 Sep 2019 00:29:01 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Ma", "Zhongkui", ""]]}, {"id": "1908.10498", "submitter": "George Kesidis", "authors": "Zhen Xiang, David J. Miller, George Kesidis", "title": "Detection of Backdoors in Trained Classifiers Without Access to the\n  Training Set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a special type of data poisoning (DP) attack targeting Deep Neural\nNetwork (DNN) classifiers, known as a backdoor, was proposed. These attacks do\nnot seek to degrade classification accuracy, but rather to have the classifier\nlearn to classify to a target class whenever the backdoor pattern is present in\na test example. Launching backdoor attacks does not require knowledge of the\nclassifier or its training process - it only needs the ability to poison the\ntraining set with (a sufficient number of) exemplars containing a sufficiently\nstrong backdoor pattern (labeled with the target class). Here we address\npost-training detection of backdoor attacks in DNN image classifiers, seldom\nconsidered in existing works, wherein the defender does not have access to the\npoisoned training set, but only to the trained classifier itself, as well as to\nclean examples from the classification domain. This is an important scenario\nbecause a trained classifier may be the basis of e.g. a phone app that will be\nshared with many users. Detecting backdoors post-training may thus reveal a\nwidespread attack. We propose a purely unsupervised anomaly detection (AD)\ndefense against imperceptible backdoor attacks that: i) detects whether the\ntrained DNN has been backdoor-attacked; ii) infers the source and target\nclasses involved in a detected attack; iii) we even demonstrate it is possible\nto accurately estimate the backdoor pattern. We test our AD approach, in\ncomparison with alternative defenses, for several backdoor patterns, data sets,\nand attack settings and demonstrate its favorability. Our defense essentially\nrequires setting a single hyperparameter (the detection threshold), which can\ne.g. be chosen to fix the system's false positive rate.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 23:51:43 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 23:57:04 GMT"}, {"version": "v3", "created": "Wed, 19 Aug 2020 15:52:35 GMT"}], "update_date": "2020-08-20", "authors_parsed": [["Xiang", "Zhen", ""], ["Miller", "David J.", ""], ["Kesidis", "George", ""]]}, {"id": "1908.10506", "submitter": "Donghui Yan", "authors": "Donghui Yan, Songxiang Gu, Ying Xu and Zhiwei Qin", "title": "Similarity Kernel and Clustering via Random Projection Forests", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity plays a fundamental role in many areas, including data mining,\nmachine learning, statistics and various applied domains. Inspired by the\nsuccess of ensemble methods and the flexibility of trees, we propose to learn a\nsimilarity kernel called rpf-kernel through random projection forests\n(rpForests). Our theoretical analysis reveals a highly desirable property of\nrpf-kernel: far-away (dissimilar) points have a low similarity value while\nnearby (similar) points would have a high similarity}, and the similarities\nhave a native interpretation as the probability of points remaining in the same\nleaf nodes during the growth of rpForests. The learned rpf-kernel leads to an\neffective clustering algorithm--rpfCluster. On a wide variety of real and\nbenchmark datasets, rpfCluster compares favorably to K-means clustering,\nspectral clustering and a state-of-the-art clustering ensemble\nalgorithm--Cluster Forests. Our approach is simple to implement and readily\nadapt to the geometry of the underlying data. Given its desirable theoretical\nproperty and competitive empirical performance when applied to clustering, we\nexpect rpf-kernel to be applicable to many problems of an unsupervised nature\nor as a regularizer in some supervised or weakly supervised settings.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 00:38:53 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yan", "Donghui", ""], ["Gu", "Songxiang", ""], ["Xu", "Ying", ""], ["Qin", "Zhiwei", ""]]}, {"id": "1908.10508", "submitter": "Alex Gaudio", "authors": "Asim Smailagic, Pedro Costa, Alex Gaudio, Kartik Khandelwal, Mostafa\n  Mirshekari, Jonathon Fagert, Devesh Walawalkar, Susu Xu, Adrian Galdran, Pei\n  Zhang, Aur\\'elio Campilho, Hae Young Noh", "title": "O-MedAL: Online Active Deep Learning for Medical Image Analysis", "comments": "Code: https://github.com/adgaudio/o-medal ; Accepted and published by\n  Wiley Journal of Pattern Recognition and Knowledge Discovery ; Journal URL:\n  https://doi.org/10.1002/widm.1353", "journal-ref": "Wiley Interdisciplinary Reviews: Data Mining and Knowledge\n  Discovery 10.4 (2020): e1353", "doi": "10.1002/widm.1353", "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active Learning methods create an optimized labeled training set from\nunlabeled data. We introduce a novel Online Active Deep Learning method for\nMedical Image Analysis. We extend our MedAL active learning framework to\npresent new results in this paper. Our novel sampling method queries the\nunlabeled examples that maximize the average distance to all training set\nexamples. Our online method enhances performance of its underlying baseline\ndeep network. These novelties contribute significant performance improvements,\nincluding improving the model's underlying deep network accuracy by 6.30%,\nusing only 25% of the labeled dataset to achieve baseline accuracy, reducing\nbackpropagated images during training by as much as 67%, and demonstrating\nrobustness to class imbalance in binary and multi-class tasks.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 00:48:12 GMT"}, {"version": "v2", "created": "Mon, 27 Jul 2020 20:53:28 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Smailagic", "Asim", ""], ["Costa", "Pedro", ""], ["Gaudio", "Alex", ""], ["Khandelwal", "Kartik", ""], ["Mirshekari", "Mostafa", ""], ["Fagert", "Jonathon", ""], ["Walawalkar", "Devesh", ""], ["Xu", "Susu", ""], ["Galdran", "Adrian", ""], ["Zhang", "Pei", ""], ["Campilho", "Aur\u00e9lio", ""], ["Noh", "Hae Young", ""]]}, {"id": "1908.10525", "submitter": "Yuege Xie", "authors": "Yuege Xie, Xiaoxia Wu, Rachel Ward", "title": "Linear Convergence of Adaptive Stochastic Gradient Descent", "comments": null, "journal-ref": "Proceedings of the Twenty Third International Conference on\n  Artificial Intelligence and Statistics, in PMLR 108:1475-1485 (2020)", "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that the norm version of the adaptive stochastic gradient method\n(AdaGrad-Norm) achieves a linear convergence rate for a subset of either\nstrongly convex functions or non-convex functions that satisfy the Polyak\nLojasiewicz (PL) inequality. The paper introduces the notion of Restricted\nUniform Inequality of Gradients (RUIG)---which is a measure of the\nbalanced-ness of the stochastic gradient norms---to depict the landscape of a\nfunction. RUIG plays a key role in proving the robustness of AdaGrad-Norm to\nits hyper-parameter tuning in the stochastic setting. On top of RUIG, we\ndevelop a two-stage framework to prove the linear convergence of AdaGrad-Norm\nwithout knowing the parameters of the objective functions. This framework can\nlikely be extended to other adaptive stepsize algorithms. The numerical\nexperiments validate the theory and suggest future directions for improvement.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 02:42:50 GMT"}, {"version": "v2", "created": "Fri, 6 Mar 2020 05:05:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Xie", "Yuege", ""], ["Wu", "Xiaoxia", ""], ["Ward", "Rachel", ""]]}, {"id": "1908.10530", "submitter": "Kunal Talwar", "authors": "Ilya Mironov and Kunal Talwar and Li Zhang", "title": "R\\'enyi Differential Privacy of the Sampled Gaussian Mechanism", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sampled Gaussian Mechanism (SGM)---a composition of subsampling and the\nadditive Gaussian noise---has been successfully used in a number of machine\nlearning applications. The mechanism's unexpected power is derived from privacy\namplification by sampling where the privacy cost of a single evaluation\ndiminishes quadratically, rather than linearly, with the sampling rate.\nCharacterizing the precise privacy properties of SGM motivated development of\nseveral relaxations of the notion of differential privacy.\n  This work unifies and fills in gaps in published results on SGM. We describe\na numerically stable procedure for precise computation of SGM's R\\'enyi\nDifferential Privacy and prove a nearly tight (within a small constant factor)\nclosed-form bound.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 03:03:25 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Mironov", "Ilya", ""], ["Talwar", "Kunal", ""], ["Zhang", "Li", ""]]}, {"id": "1908.10552", "submitter": "Yuan Yao", "authors": "Yuan Yao, Yu Zhang, Xutao Li, Yunming Ye", "title": "Heterogeneous Domain Adaptation via Soft Transfer Network", "comments": "Accepted by ACM Multimedia (ACM MM) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous domain adaptation (HDA) aims to facilitate the learning task in\na target domain by borrowing knowledge from a heterogeneous source domain. In\nthis paper, we propose a Soft Transfer Network (STN), which jointly learns a\ndomain-shared classifier and a domain-invariant subspace in an end-to-end\nmanner, for addressing the HDA problem. The proposed STN not only aligns the\ndiscriminative directions of domains but also matches both the marginal and\nconditional distributions across domains. To circumvent negative transfer, STN\naligns the conditional distributions by using the soft-label strategy of\nunlabeled target data, which prevents the hard assignment of each unlabeled\ntarget data to only one category that may be incorrect. Further, STN introduces\nan adaptive coefficient to gradually increase the importance of the soft-labels\nsince they will become more and more accurate as the number of iterations\nincreases. We perform experiments on the transfer tasks of image-to-image,\ntext-to-image, and text-to-text. Experimental results testify that the STN\nsignificantly outperforms several state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 05:25:12 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yao", "Yuan", ""], ["Zhang", "Yu", ""], ["Li", "Xutao", ""], ["Ye", "Yunming", ""]]}, {"id": "1908.10572", "submitter": "Toru Imai", "authors": "Toru Imai", "title": "On the overestimation of widely applicable Bayesian information\n  criterion", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A widely applicable Bayesian information criterion (Watanabe, 2013) is\napplicable for both regular and singular models in the model selection problem.\nThis criterion tends to overestimate the log marginal likelihood. We identify\nan overestimating term of a widely applicable Bayesian information criterion.\nAdjustment of the term gives an asymptotically unbiased estimator of the\nleading two terms of asymptotic expansion of the log marginal likelihood. In\nnumerical experiments on regular and singular models, the adjustment resulted\nin smaller bias than the original criterion.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 07:04:39 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Imai", "Toru", ""]]}, {"id": "1908.10611", "submitter": "Yuting Ye", "authors": "Yuting Ye, Xuwu Wang, Jiangchao Yao, Kunyang Jia, Jingren Zhou,\n  Yanghua Xiao, and Hongxia Yang", "title": "Bayes EMbedding (BEM): Refining Representation by Integrating Knowledge\n  Graphs and Behavior-specific Networks", "comments": "25 pages, 5 figures, 10 tables. CIKM 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-dimensional embeddings of knowledge graphs and behavior graphs have\nproved remarkably powerful in varieties of tasks, from predicting unobserved\nedges between entities to content recommendation. The two types of graphs can\ncontain distinct and complementary information for the same entities/nodes.\nHowever, previous works focus either on knowledge graph embedding or behavior\ngraph embedding while few works consider both in a unified way. Here we present\nBEM , a Bayesian framework that incorporates the information from knowledge\ngraphs and behavior graphs. To be more specific, BEM takes as prior the\npre-trained embeddings from the knowledge graph, and integrates them with the\npre-trained embeddings from the behavior graphs via a Bayesian generative\nmodel. BEM is able to mutually refine the embeddings from both sides while\npreserving their own topological structures. To show the superiority of our\nmethod, we conduct a range of experiments on three benchmark datasets: node\nclassification, link prediction, triplet classification on two small datasets\nrelated to Freebase, and item recommendation on a large-scale e-commerce\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 09:49:15 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Ye", "Yuting", ""], ["Wang", "Xuwu", ""], ["Yao", "Jiangchao", ""], ["Jia", "Kunyang", ""], ["Zhou", "Jingren", ""], ["Xiao", "Yanghua", ""], ["Yang", "Hongxia", ""]]}, {"id": "1908.10623", "submitter": "Fasih Haider Dr", "authors": "Fasih Haider, Senja Pollak, Pierre Albert, Saturnino Luz", "title": "Emotion Recognition in Low-Resource Settings: An Evaluation of Automatic\n  Feature Selection Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in automatic affect recognition has seldom addressed the issue of\ncomputational resource utilization. With the advent of ambient intelligence\ntechnology which employs a variety of low-power, resource-constrained devices,\nthis issue is increasingly gaining interest. This is especially the case in the\ncontext of health and elderly care technologies, where interventions may rely\non monitoring of emotional status to provide support or alert carers as\nappropriate. This paper focuses on emotion recognition from speech data, in\nsettings where it is desirable to minimize memory and computational\nrequirements. Reducing the number of features for inductive inference is a\nroute towards this goal. In this study, we evaluate three different\nstate-of-the-art feature selection methods: Infinite Latent Feature Selection\n(ILFS), ReliefF and Fisher (generalized Fisher score), and compare them to our\nrecently proposed feature selection method named `Active Feature Selection'\n(AFS). The evaluation is performed on three emotion recognition data sets\n(EmoDB, SAVEE and EMOVO) using two standard acoustic paralinguistic feature\nsets (i.e. eGeMAPs and emobase). The results show that similar or better\naccuracy can be achieved using subsets of features substantially smaller than\nthe entire feature set. A machine learning model trained on a smaller feature\nset will reduce the memory and computational resources of an emotion\nrecognition system which can result in lowering the barriers for use of health\nmonitoring technology.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 10:14:20 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 14:39:09 GMT"}], "update_date": "2020-06-01", "authors_parsed": [["Haider", "Fasih", ""], ["Pollak", "Senja", ""], ["Albert", "Pierre", ""], ["Luz", "Saturnino", ""]]}, {"id": "1908.10661", "submitter": "Waleed Yousef", "authors": "Waleed A. Yousef, Ahmed A. Abouelkahire, Deyaaeldeen Almahallawi, Omar\n  S.Marzouk, Sameh K. Mohamed, Waleed A. Mustafa, Omar M. Osama, Ali A. Saleh,\n  Naglaa M. Abdelrazek", "title": "Method and System for Image Analysis to Detect Cancer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Breast cancer is the most common cancer and is the leading cause of cancer\ndeath among women worldwide. Detection of breast cancer, while it is still\nsmall and confined to the breast, provides the best chance of effective\ntreatment. Computer Aided Detection (CAD) systems that detect cancer from\nmammograms will help in reducing the human errors that lead to missing breast\ncarcinoma. Literature is rich of scientific papers for methods of CAD design,\nyet with no complete system architecture to deploy those methods. On the other\nhand, commercial CADs are developed and deployed only to vendors' mammography\nmachines with no availability to public access. This paper presents a complete\nCAD; it is complete since it combines, on a hand, the rigor of algorithm design\nand assessment (method), and, on the other hand, the implementation and\ndeployment of a system architecture for public accessibility (system). (1) We\ndevelop a novel algorithm for image enhancement so that mammograms acquired\nfrom any digital mammography machine look qualitatively of the same clarity to\nradiologists' inspection; and is quantitatively standardized for the detection\nalgorithms. (2) We develop novel algorithms for masses and microcalcifications\ndetection with accuracy superior to both literature results and the majority of\napproved commercial systems. (3) We design, implement, and deploy a system\narchitecture that is computationally effective to allow for deploying these\nalgorithms to cloud for public access.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 22:28:47 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Yousef", "Waleed A.", ""], ["Abouelkahire", "Ahmed A.", ""], ["Almahallawi", "Deyaaeldeen", ""], ["Marzouk", "Omar S.", ""], ["Mohamed", "Sameh K.", ""], ["Mustafa", "Waleed A.", ""], ["Osama", "Omar M.", ""], ["Saleh", "Ali A.", ""], ["Abdelrazek", "Naglaa M.", ""]]}, {"id": "1908.10705", "submitter": "\\'Italo Gomes Santana", "authors": "\\'Italo Gomes Santana", "title": "Improving a State-of-the-Art Heuristic for the Minimum Latency Problem\n  with Data Mining", "comments": "This document is a dissertation file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, hybrid metaheuristics have become a trend in operations research. A\nsuccessful example combines the Greedy Randomized Adaptive Search Procedures\n(GRASP) and data mining techniques, where frequent patterns found in\nhigh-quality solutions can lead to an efficient exploration of the search\nspace, along with a significant reduction of computational time. In this work,\na GRASP-based state-of-the-art heuristic for the Minimum Latency Problem (MLP)\nis improved by means of data mining techniques for two MLP variants.\nComputational experiments showed that the approaches with data mining were able\nto match or improve the solution quality for a large number of instances,\ntogether with a substantial reduction of running time. In addition, 88 new cost\nvalues of solutions are introduced into the literature. To support our results,\ntests of statistical significance, impact of using mined patterns, equal time\ncomparisons and time-to-target plots are provided.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:12:30 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Santana", "\u00cdtalo Gomes", ""]]}, {"id": "1908.10711", "submitter": "Md Rafiqul Islam Rabin", "authors": "Md Rafiqul Islam Rabin, Ke Wang, Mohammad Amin Alipour", "title": "Testing Neural Program Analyzers", "comments": "ASE 2019 Late Breaking Results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.PL cs.SE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have been increasingly used in software engineering and\nprogram analysis tasks. They usually take a program and make some predictions\nabout it, e.g., bug prediction. We call these models neural program analyzers.\nThe reliability of neural programs can impact the reliability of the\nencompassing analyses. In this paper, we describe our ongoing efforts to\ndevelop effective techniques for testing neural programs. We discuss the\nchallenges involved in developing such tools and our future plans. In our\npreliminary experiment on a neural model recently proposed in the literature,\nwe found that the model is very brittle, and simple perturbations in the input\ncan cause the model to make mistakes in its prediction.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 04:55:22 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 22:27:27 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Rabin", "Md Rafiqul Islam", ""], ["Wang", "Ke", ""], ["Alipour", "Mohammad Amin", ""]]}, {"id": "1908.10714", "submitter": "Steven Abreu", "authors": "Steven Abreu", "title": "Automated Architecture Design for Deep Neural Networks", "comments": "Undergraduate Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Machine learning has made tremendous progress in recent years and received\nlarge amounts of public attention. Though we are still far from designing a\nfull artificially intelligent agent, machine learning has brought us many\napplications in which computers solve human learning tasks remarkably well.\nMuch of this progress comes from a recent trend within machine learning, called\ndeep learning. Deep learning models are responsible for many state-of-the-art\napplications of machine learning. Despite their success, deep learning models\nare hard to train, very difficult to understand, and often times so complex\nthat training is only possible on very large GPU clusters. Lots of work has\nbeen done on enabling neural networks to learn efficiently. However, the design\nand architecture of such neural networks is often done manually through trial\nand error and expert knowledge. This thesis inspects different approaches,\nexisting and novel, to automate the design of deep feedforward neural networks\nin an attempt to create less complex models with good performance that take\naway the burden of deciding on an architecture and make it more efficient to\ndesign and train such deep networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 00:57:45 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Abreu", "Steven", ""]]}, {"id": "1908.10722", "submitter": "Junya Ikemoto", "authors": "Junya Ikemoto and Toshimitsu Ushio", "title": "Networked Control of Nonlinear Systems under Partial Observation Using\n  Continuous Deep Q-Learning", "comments": "6 pages, 9 figures, Accepted for presentation in the IEEE Conference\n  on Decision and Control (CDC) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a design of a model-free networked controller for a\nnonlinear plant whose mathematical model is unknown. In a networked control\nsystem, the controller and plant are located away from each other and exchange\ndata over a network, which causes network delays that may fluctuate randomly\ndue to network routing. So, in this paper, we assume that the current network\ndelay is not known but the maximum value of fluctuating network delays is known\nbeforehand. Moreover, we also assume that the sensor cannot observe all state\nvariables of the plant. Under these assumption, we apply continuous deep\nQ-learning to the design of the networked controller. Then, we introduce an\nextended state consisting of a sequence of past control inputs and outputs as\ninputs to the deep neural network. By simulation, it is shown that, using the\nextended state, the controller can learn a control policy robust to the\nfluctuation of the network delays under the partial observation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:51:08 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 03:24:18 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Ikemoto", "Junya", ""], ["Ushio", "Toshimitsu", ""]]}, {"id": "1908.10742", "submitter": "Zhengling Qi", "authors": "Zhengling Qi, Ying Cui, Yufeng Liu, Jong-Shi Pang", "title": "Estimation of Individualized Decision Rules Based on an Optimized\n  Covariate-Dependent Equivalent of Random Outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent exploration of optimal individualized decision rules (IDRs) for\npatients in precision medicine has attracted a lot of attention due to the\nheterogeneous responses of patients to different treatments. In the existing\nliterature of precision medicine, an optimal IDR is defined as a decision\nfunction mapping from the patients' covariate space into the treatment space\nthat maximizes the expected outcome of each individual. Motivated by the\nconcept of Optimized Certainty Equivalent (OCE) introduced originally in\n\\cite{ben1986expected} that includes the popular conditional-value-of risk\n(CVaR) \\cite{rockafellar2000optimization}, we propose a decision-rule based\noptimized covariates dependent equivalent (CDE) for individualized decision\nmaking problems. Our proposed IDR-CDE broadens the existing expected-mean\noutcome framework in precision medicine and enriches the previous concept of\nthe OCE. Numerical experiments demonstrate that our overall approach\noutperforms existing methods in estimating optimal IDRs under heavy-tail\ndistributions of the data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 14:54:46 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Qi", "Zhengling", ""], ["Cui", "Ying", ""], ["Liu", "Yufeng", ""], ["Pang", "Jong-Shi", ""]]}, {"id": "1908.10744", "submitter": "Jonathan Scarlett", "authors": "Zhaoqiang Liu and Jonathan Scarlett", "title": "Information-Theoretic Lower Bounds for Compressive Sensing with\n  Generative Models", "comments": "To appear in IEEE Journal on Selected Areas in Information Theory. In\n  this version, Theorem 7 was updated to allow for general depth/width scalings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.LG eess.SP math.IT math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been shown that for compressive sensing, significantly fewer\nmeasurements may be required if the sparsity assumption is replaced by the\nassumption the unknown vector lies near the range of a suitably-chosen\ngenerative model. In particular, in (Bora {\\em et al.}, 2017) it was shown\nroughly $O(k\\log L)$ random Gaussian measurements suffice for accurate recovery\nwhen the generative model is an $L$-Lipschitz function with bounded\n$k$-dimensional inputs, and $O(kd \\log w)$ measurements suffice when the\ngenerative model is a $k$-input ReLU network with depth $d$ and width $w$. In\nthis paper, we establish corresponding algorithm-independent lower bounds on\nthe sample complexity using tools from minimax statistical analysis. In\naccordance with the above upper bounds, our results are summarized as follows:\n(i) We construct an $L$-Lipschitz generative model capable of generating\ngroup-sparse signals, and show that the resulting necessary number of\nmeasurements is $\\Omega(k \\log L)$; (ii) Using similar ideas, we construct ReLU\nnetworks with high depth and/or high depth for which the necessary number of\nmeasurements scales as $\\Omega\\big( kd \\frac{\\log w}{\\log n}\\big)$ (with output\ndimension $n$), and in some cases $\\Omega(kd \\log w)$. As a result, we\nestablish that the scaling laws derived in (Bora {\\em et al.}, 2017) are\noptimal or near-optimal in the absence of further assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 14:24:03 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 06:15:58 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Liu", "Zhaoqiang", ""], ["Scarlett", "Jonathan", ""]]}, {"id": "1908.10761", "submitter": "Matthieu Lerasle", "authors": "Matthieu Lerasle", "title": "Lecture Notes: Selected topics on robust statistical learning theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These notes gather recent results on robust statistical learning theory. The\ngoal is to stress the main principles underlying the construction and\ntheoretical analysis of these estimators rather than provide an exhaustive\naccount on this rapidly growing field. The notes are the basis of lectures\ngiven at the conference StatMathAppli 2019.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:00:51 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Lerasle", "Matthieu", ""]]}, {"id": "1908.10776", "submitter": "Qing Qu", "authors": "Qing Qu, Xiao Li, Zhihui Zhu", "title": "A Nonconvex Approach for Exact and Efficient Multichannel Sparse Blind\n  Deconvolution", "comments": "62 pages, 6 figures; short version accepted as a spotlight paper at\n  NeurIPS'19\n  (https://papers.nips.cc/paper/8656-a-nonconvex-approach-for-exact-and-efficient-multichannel-sparse-blind-deconvolution)\n  ; A long journal version is under revision at SIIMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-channel sparse blind deconvolution (MCS-BD) problem, whose\ntask is to simultaneously recover a kernel $\\mathbf a$ and multiple sparse\ninputs $\\{\\mathbf x_i\\}_{i=1}^p$ from their circulant convolution $\\mathbf y_i\n= \\mathbf a \\circledast \\mathbf x_i $ ($i=1,\\cdots,p$). We formulate the task\nas a nonconvex optimization problem over the sphere. Under mild statistical\nassumptions of the data, we prove that the vanilla Riemannian gradient descent\n(RGD) method, with random initializations, provably recovers both the kernel\n$\\mathbf a$ and the signals $\\{\\mathbf x_i\\}_{i=1}^p$ up to a signed shift\nambiguity. In comparison with state-of-the-art results, our work shows\nsignificant improvements in terms of sample complexity and computational\nefficiency. Our theoretical results are corroborated by numerical experiments,\nwhich demonstrate superior performance of the proposed approach over the\nprevious methods on both synthetic and real datasets.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:25:54 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 14:38:53 GMT"}, {"version": "v3", "created": "Sun, 1 Mar 2020 02:57:22 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Qu", "Qing", ""], ["Li", "Xiao", ""], ["Zhu", "Zhihui", ""]]}, {"id": "1908.10796", "submitter": "Florian Pfisterer", "authors": "Florian Pfisterer, Stefan Coors, Janek Thomas, Bernd Bischl", "title": "Multi-Objective Automatic Machine Learning with AutoxgboostMC", "comments": "Accepted at Ecmlpkdd Workshop on Automating Data Science 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AutoML systems are currently rising in popularity, as they can build powerful\nmodels without human oversight. They often combine techniques from many\ndifferent sub-fields of machine learning in order to find a model or set of\nmodels that optimize a user-supplied criterion, such as predictive performance.\nThe ultimate goal of such systems is to reduce the amount of time spent on\nmenial tasks, or tasks that can be solved better by algorithms while leaving\ndecisions that require human intelligence to the end-user. In recent years, the\nimportance of other criteria, such as fairness and interpretability, and many\nothers have become more and more apparent. Current AutoML frameworks either do\nnot allow to optimize such secondary criteria or only do so by limiting the\nsystem's choice of models and preprocessing steps. We propose to optimize\nadditional criteria defined by the user directly to guide the search towards an\noptimal machine learning pipeline. In order to demonstrate the need and\nusefulness of our approach, we provide a simple multi-criteria AutoML system\nand showcase an exemplary application.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:52:57 GMT"}, {"version": "v2", "created": "Fri, 30 Apr 2021 07:01:15 GMT"}], "update_date": "2021-05-03", "authors_parsed": [["Pfisterer", "Florian", ""], ["Coors", "Stefan", ""], ["Thomas", "Janek", ""], ["Bischl", "Bernd", ""]]}, {"id": "1908.10831", "submitter": "Mingrui Liu", "authors": "Mingrui Liu, Zhuoning Yuan, Yiming Ying, Tianbao Yang", "title": "Stochastic AUC Maximization with Deep Neural Networks", "comments": "Accepted by ICLR 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic AUC maximization has garnered an increasing interest due to better\nfit to imbalanced data classification. However, existing works are limited to\nstochastic AUC maximization with a linear predictive model, which restricts its\npredictive power when dealing with extremely complex data. In this paper, we\nconsider stochastic AUC maximization problem with a deep neural network as the\npredictive model. Building on the saddle point reformulation of a surrogated\nloss of AUC, the problem can be cast into a {\\it non-convex concave} min-max\nproblem. The main contribution made in this paper is to make stochastic AUC\nmaximization more practical for deep neural networks and big data with\ntheoretical insights as well. In particular, we propose to explore\nPolyak-\\L{}ojasiewicz (PL) condition that has been proved and observed in deep\nlearning, which enables us to develop new stochastic algorithms with even\nfaster convergence rate and more practical step size scheme. An AdaGrad-style\nalgorithm is also analyzed under the PL condition with adaptive convergence\nrate. Our experimental results demonstrate the effectiveness of the proposed\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:02:49 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 19:28:38 GMT"}, {"version": "v3", "created": "Thu, 26 Dec 2019 21:45:03 GMT"}, {"version": "v4", "created": "Sun, 17 May 2020 21:35:03 GMT"}, {"version": "v5", "created": "Tue, 30 Jun 2020 03:25:14 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Liu", "Mingrui", ""], ["Yuan", "Zhuoning", ""], ["Ying", "Yiming", ""], ["Yang", "Tianbao", ""]]}, {"id": "1908.10833", "submitter": "Dan Simovici", "authors": "Dan Simovici and Kaixun Hua", "title": "Data ultrametricity and clusterability", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/1334/1/012002", "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing needs of clustering massive datasets and the high cost of\nrunning clustering algorithms poses difficult problems for users. In this\ncontext it is important to determine if a data set is clusterable, that is, it\nmay be partitioned efficiently into well-differentiated groups containing\nsimilar objects. We approach data clusterability from an ultrametric-based\nperspective. A novel approach to determine the ultrametricity of a dataset is\nproposed via a special type of matrix product, which allows us to evaluate the\nclusterability of the dataset. Furthermore, we show that by applying our\ntechnique to a dissimilarity space will generate the sub-dominant ultrametric\nof the dissimilarity.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:04:32 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Simovici", "Dan", ""], ["Hua", "Kaixun", ""]]}, {"id": "1908.10859", "submitter": "Wenlong Mou", "authors": "Wenlong Mou, Yi-An Ma, Martin J. Wainwright, Peter L. Bartlett,\n  Michael I. Jordan", "title": "High-Order Langevin Diffusion Yields an Accelerated MCMC Algorithm", "comments": "Changes from v1: improved algorithm with $O (d^{1/4} /\n  \\varepsilon^{1/2})$ mixing time", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Markov chain Monte Carlo (MCMC) algorithm based on third-order\nLangevin dynamics for sampling from distributions with log-concave and smooth\ndensities. The higher-order dynamics allow for more flexible discretization\nschemes, and we develop a specific method that combines splitting with more\naccurate integration. For a broad class of $d$-dimensional distributions\narising from generalized linear models, we prove that the resulting third-order\nalgorithm produces samples from a distribution that is at most $\\varepsilon >\n0$ in Wasserstein distance from the target distribution in\n$O\\left(\\frac{d^{1/4}}{ \\varepsilon^{1/2}} \\right)$ steps. This result requires\nonly Lipschitz conditions on the gradient. For general strongly convex\npotentials with $\\alpha$-th order smoothness, we prove that the mixing time\nscales as $O \\left(\\frac{d^{1/4}}{\\varepsilon^{1/2}} +\n\\frac{d^{1/2}}{\\varepsilon^{1/(\\alpha - 1)}} \\right)$.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:59:29 GMT"}, {"version": "v2", "created": "Tue, 26 May 2020 15:10:59 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Mou", "Wenlong", ""], ["Ma", "Yi-An", ""], ["Wainwright", "Martin J.", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1908.10920", "submitter": "Guan-Horng Liu", "authors": "Guan-Horng Liu, Evangelos A. Theodorou", "title": "Deep Learning Theory Review: An Optimal Control and Dynamical Systems\n  Perspective", "comments": "Under Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attempts from different disciplines to provide a fundamental understanding of\ndeep learning have advanced rapidly in recent years, yet a unified framework\nremains relatively limited. In this article, we provide one possible way to\nalign existing branches of deep learning theory through the lens of dynamical\nsystem and optimal control. By viewing deep neural networks as discrete-time\nnonlinear dynamical systems, we can analyze how information propagates through\nlayers using mean field theory. When optimization algorithms are further recast\nas controllers, the ultimate goal of training processes can be formulated as an\noptimal control problem. In addition, we can reveal convergence and\ngeneralization properties by studying the stochastic dynamics of optimization\nalgorithms. This viewpoint features a wide range of theoretical study from\ninformation bottleneck to statistical physics. It also provides a principled\nway for hyper-parameter tuning when optimal control theory is introduced. Our\nframework fits nicely with supervised learning and can be extended to other\nlearning problems, such as Bayesian learning, adversarial training, and\nspecific forms of meta learning, without efforts. The review aims to shed\nlights on the importance of dynamics and optimal control when developing deep\nlearning theory.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 19:36:23 GMT"}, {"version": "v2", "created": "Sat, 28 Sep 2019 20:40:02 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Liu", "Guan-Horng", ""], ["Theodorou", "Evangelos A.", ""]]}, {"id": "1908.10935", "submitter": "Yihong Wu", "authors": "Yihong Wu and Harrison H. Zhou", "title": "Randomly initialized EM algorithm for two-component Gaussian mixture\n  achieves near optimality in $O(\\sqrt{n})$ iterations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.IT math.IT stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the classical EM algorithm for parameter estimation in the\nsymmetric two-component Gaussian mixtures in $d$ dimensions. We show that, even\nin the absence of any separation between components, provided that the sample\nsize satisfies $n=\\Omega(d \\log^3 d)$, the randomly initialized EM algorithm\nconverges to an estimate in at most $O(\\sqrt{n})$ iterations with high\nprobability, which is at most $O((\\frac{d \\log^3 n}{n})^{1/4})$ in Euclidean\ndistance from the true parameter and within logarithmic factors of the minimax\nrate of $(\\frac{d}{n})^{1/4}$. Both the nonparametric statistical rate and the\nsublinear convergence rate are direct consequences of the zero Fisher\ninformation in the worst case. Refined pointwise guarantees beyond worst-case\nanalysis and convergence to the MLE are also shown under mild conditions.\n  This improves the previous result of Balakrishnan et al \\cite{BWY17} which\nrequires strong conditions on both the separation of the components and the\nquality of the initialization, and that of Daskalakis et al \\cite{DTZ17} which\nrequires sample splitting and restarting the EM iteration.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 20:44:19 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Wu", "Yihong", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1908.10947", "submitter": "Juliane Mueller", "authors": "Juliane Mueller, Jangho Park, Reetik Sahu, Charuleka Varadharajan,\n  Bhavna Arora, Boris Faybishenko, Deborah Agarwal", "title": "Surrogate Optimization of Deep Neural Networks for Groundwater\n  Predictions", "comments": "submitted to Journal of Global Optimization; main paper: 25 pages, 19\n  figures, 1 table; online supplement: 11 pages, 18 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": "LBNL-2001234", "categories": "stat.ML cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sustainable management of groundwater resources under changing climatic\nconditions require an application of reliable and accurate predictions of\ngroundwater levels. Mechanistic multi-scale, multi-physics simulation models\nare often too hard to use for this purpose, especially for groundwater managers\nwho do not have access to the complex compute resources and data. Therefore, we\nanalyzed the applicability and performance of four modern deep learning\ncomputational models for predictions of groundwater levels. We compare three\nmethods for optimizing the models' hyperparameters, including two surrogate\nmodel-based algorithms and a random sampling method. The models were tested\nusing predictions of the groundwater level in Butte County, California, USA,\ntaking into account the temporal variability of streamflow, precipitation, and\nambient temperature. Our numerical study shows that the optimization of the\nhyperparameters can lead to reasonably accurate performance of all models (root\nmean squared errors of groundwater predictions of 2 meters or less), but the\n''simplest'' network, namely a multilayer perceptron (MLP) performs overall\nbetter for learning and predicting groundwater data than the more advanced long\nshort-term memory or convolutional neural networks in terms of prediction\naccuracy and time-to-solution, making the MLP a suitable candidate for\ngroundwater prediction.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 21:18:35 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 17:22:23 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 20:47:58 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Mueller", "Juliane", ""], ["Park", "Jangho", ""], ["Sahu", "Reetik", ""], ["Varadharajan", "Charuleka", ""], ["Arora", "Bhavna", ""], ["Faybishenko", "Boris", ""], ["Agarwal", "Deborah", ""]]}, {"id": "1908.10959", "submitter": "Qing Qu", "authors": "Yenson Lau, Qing Qu, Han-Wen Kuo, Pengcheng Zhou, Yuqian Zhang, John\n  Wright", "title": "Short-and-Sparse Deconvolution -- A Geometric Approach", "comments": "*YL and QQ contributed equally to this work; 30 figures, 45 pages;\n  This version: added an experiment comparing with other methods, corrected\n  typos and added references", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG eess.IV math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-and-sparse deconvolution (SaSD) is the problem of extracting localized,\nrecurring motifs in signals with spatial or temporal structure. Variants of\nthis problem arise in applications such as image deblurring, microscopy, neural\nspike sorting, and more. The problem is challenging in both theory and\npractice, as natural optimization formulations are nonconvex. Moreover,\npractical deconvolution problems involve smooth motifs (kernels) whose spectra\ndecay rapidly, resulting in poor conditioning and numerical challenges. This\npaper is motivated by recent theoretical advances, which characterize the\noptimization landscape of a particular nonconvex formulation of SaSD. This is\nused to derive a $provable$ algorithm which exactly solves certain\nnon-practical instances of the SaSD problem. We leverage the key ideas from\nthis theory (sphere constraints, data-driven initialization) to develop a\n$practical$ algorithm, which performs well on data arising from a range of\napplication areas. We highlight key additional challenges posed by the\nill-conditioning of real SaSD problems, and suggest heuristics (acceleration,\ncontinuation, reweighting) to mitigate them. Experiments demonstrate both the\nperformance and generality of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 21:52:28 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 05:25:59 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Lau", "Yenson", ""], ["Qu", "Qing", ""], ["Kuo", "Han-Wen", ""], ["Zhou", "Pengcheng", ""], ["Zhang", "Yuqian", ""], ["Wright", "John", ""]]}, {"id": "1908.10962", "submitter": "Ashok Makkuva", "authors": "Ashok Vardhan Makkuva, Amirhossein Taghvaei, Sewoong Oh, Jason D. Lee", "title": "Optimal transport mapping via input convex neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present a novel and principled approach to learn the\noptimal transport between two distributions, from samples. Guided by the\noptimal transport theory, we learn the optimal Kantorovich potential which\ninduces the optimal transport map. This involves learning two convex functions,\nby solving a novel minimax optimization. Building upon recent advances in the\nfield of input convex neural networks, we propose a new framework where the\ngradient of one convex function represents the optimal transport mapping.\nNumerical experiments confirm that we learn the optimal transport mapping. This\napproach ensures that the transport mapping we find is optimal independent of\nhow we initialize the neural networks. Further, target distributions from a\ndiscontinuous support can be easily captured, as gradient of a convex function\nnaturally models a {\\em discontinuous} transport mapping.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 21:59:58 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 19:44:15 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Makkuva", "Ashok Vardhan", ""], ["Taghvaei", "Amirhossein", ""], ["Oh", "Sewoong", ""], ["Lee", "Jason D.", ""]]}, {"id": "1908.10964", "submitter": "Siddharth Samsi", "authors": "Siddharth Samsi, Christopher J. Mattioli, Mark S. Veillette", "title": "Distributed Deep Learning for Precipitation Nowcasting", "comments": "IEEE HPEC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective training of Deep Neural Networks requires massive amounts of data\nand compute. As a result, longer times are needed to train complex models\nrequiring large datasets, which can severely limit research on model\ndevelopment and the exploitation of all available data. In this paper, this\nproblem is investigated in the context of precipitation nowcasting, a term used\nto describe highly detailed short-term forecasts of precipitation and other\nhazardous weather. Convolutional Neural Networks (CNNs) are a powerful class of\nmodels that are well-suited for this task; however, the high resolution input\nweather imagery combined with model complexity required to process this data\nmakes training CNNs to solve this task time consuming. To address this issue, a\ndata-parallel model is implemented where a CNN is replicated across multiple\ncompute nodes and the training batches are distributed across multiple nodes.\nBy leveraging multiple GPUs, we show that the training time for a given\nnowcasting model architecture can be reduced from 59 hours to just over 1 hour.\nThis will allow for faster iterations for improving CNN architectures and will\nfacilitate future advancement in the area of nowcasting.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 22:06:42 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Samsi", "Siddharth", ""], ["Mattioli", "Christopher J.", ""], ["Veillette", "Mark S.", ""]]}, {"id": "1908.10999", "submitter": "Kanglin Liu", "authors": "Kanglin Liu and Wenming Tang and Fei Zhou and Guoping Qiu", "title": "Spectral Regularization for Combating Mode Collapse in GANs", "comments": "24 pages, 33 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite excellent progress in recent years, mode collapse remains a major\nunsolved problem in generative adversarial networks (GANs).In this paper, we\npresent spectral regularization for GANs (SR-GANs), a new and robust method for\ncombating the mode collapse problem in GANs. Theoretical analysis shows that\nthe optimal solution to the discriminator has a strong relationship to the\nspectral distributions of the weight matrix.Therefore, we monitor the spectral\ndistribution in the discriminator of spectral normalized GANs (SN-GANs), and\ndiscover a phenomenon which we refer to as spectral collapse, where a large\nnumber of singular values of the weight matrices drop dramatically when mode\ncollapse occurs. We show that there are strong evidence linking mode collapse\nto spectral collapse; and based on this link, we set out to tackle spectral\ncollapse as a surrogate of mode collapse. We have developed a spectral\nregularization method where we compensate the spectral distributions of the\nweight matrices to prevent them from collapsing, which in turn successfully\nprevents mode collapse in GANs. We provide theoretical explanations for why\nSR-GANs are more stable and can provide better performances than SN-GANs. We\nalso present extensive experimental results and analysis to show that SR-GANs\nnot only always outperform SN-GANs but also always succeed in combating mode\ncollapse where SN-GANs fail. The code is available at\nhttps://github.com/max-liu-112/SRGANs-Spectral-Regularization-GANs-.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 00:56:47 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 05:21:37 GMT"}, {"version": "v3", "created": "Sat, 12 Oct 2019 07:43:51 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Liu", "Kanglin", ""], ["Tang", "Wenming", ""], ["Zhou", "Fei", ""], ["Qiu", "Guoping", ""]]}, {"id": "1908.11033", "submitter": "Jinlong Chai", "authors": "Jinlong Chai, Jiangeng Chang, Yakun Zhao, Honggang Liu", "title": "An Auto-ML Framework Based on GBDT for Lifelong Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic Machine Learning (Auto-ML) has attracted more and more attention in\nrecent years, our work is to solve the problem of data drift, which means that\nthe distribution of data will gradually change with the acquisition process,\nresulting in a worse performance of the auto-ML model. We construct our model\nbased on GBDT, Incremental learning and full learning are used to handle with\ndrift problem. Experiments show that our method performs well on the five data\nsets. Which shows that our method can effectively solve the problem of data\ndrift and has robust performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 03:30:11 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Chai", "Jinlong", ""], ["Chang", "Jiangeng", ""], ["Zhao", "Yakun", ""], ["Liu", "Honggang", ""]]}, {"id": "1908.11051", "submitter": "Wei Cui Dr.", "authors": "Wei Cui, Teng Ma, Lin Zhao, Yaojun Ge", "title": "Data-based wind disaster climate identification algorithm and extreme\n  wind speed prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An extreme wind speed estimation method that considers wind hazard climate\ntypes is critical for design wind load calculation for building structures\naffected by mixed climates. However, it is very difficult to obtain wind hazard\nclimate types from meteorological data records, because they restrict the\napplication of extreme wind speed estimation in mixed climates. This paper\nfirst proposes a wind hazard type identification algorithm based on a numerical\npattern recognition method that utilizes feature extraction and generalization.\nNext, it compares six commonly used machine learning models using K-fold\ncross-validation. Finally, it takes meteorological data from three locations\nnear the southeast coast of China as examples to examine the algorithm\nperformance. Based on classification results, the extreme wind speeds\ncalculated based on mixed wind hazard types is compared with those obtained\nfrom conventional methods, and the effects on structural design for different\nreturn periods are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 04:58:19 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Cui", "Wei", ""], ["Ma", "Teng", ""], ["Zhao", "Lin", ""], ["Ge", "Yaojun", ""]]}, {"id": "1908.11056", "submitter": "Tao Wen", "authors": "Guanjie Zheng, Mengqi Liu, Tao Wen, Hongjian Wang, Huaxiu Yao, Susan\n  L. Brantley, Zhenhui Li", "title": "Targeted Source Detection for Environmental Data", "comments": "8 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the face of growing needs for water and energy, a fundamental\nunderstanding of the environmental impacts of human activities becomes critical\nfor managing water and energy resources, remedying water pollution, and making\nregulatory policy wisely. Among activities that impact the environment, oil and\ngas production, wastewater transport, and urbanization are included. In\naddition to the occurrence of anthropogenic contamination, the presence of some\ncontaminants (e.g., methane, salt, and sulfate) of natural origin is not\nuncommon. Therefore, scientists sometimes find it difficult to identify the\nsources of contaminants in the coupled natural and human systems. In this\npaper, we propose a technique to simultaneously conduct source detection and\nprediction, which outperforms other approaches in the interdisciplinary case\nstudy of the identification of potential groundwater contamination within a\nregion of high-density shale gas development.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 05:15:53 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Zheng", "Guanjie", ""], ["Liu", "Mengqi", ""], ["Wen", "Tao", ""], ["Wang", "Hongjian", ""], ["Yao", "Huaxiu", ""], ["Brantley", "Susan L.", ""], ["Li", "Zhenhui", ""]]}, {"id": "1908.11071", "submitter": "Lin Yang", "authors": "Aaron Sidford, Mengdi Wang, Lin F. Yang, Yinyu Ye", "title": "Solving Discounted Stochastic Two-Player Games with Near-Optimal Time\n  and Sample Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we settle the sampling complexity of solving discounted\ntwo-player turn-based zero-sum stochastic games up to polylogarithmic factors.\nGiven a stochastic game with discount factor $\\gamma\\in(0,1)$ we provide an\nalgorithm that computes an $\\epsilon$-optimal strategy with high-probability\ngiven $\\tilde{O}((1 - \\gamma)^{-3} \\epsilon^{-2})$ samples from the transition\nfunction for each state-action-pair. Our algorithm runs in time nearly linear\nin the number of samples and uses space nearly linear in the number of\nstate-action pairs. As stochastic games generalize Markov decision processes\n(MDPs) our runtime and sample complexities are optimal due to Azar et al\n(2013). We achieve our results by showing how to generalize a near-optimal\nQ-learning based algorithms for MDP, in particular Sidford et al (2018), to\ntwo-player strategy computation algorithms. This overcomes limitations of\nstandard Q-learning and strategy iteration or alternating minimization based\napproaches and we hope will pave the way for future reinforcement learning\nresults by facilitating the extension of MDP results to multi-agent settings\nwith little loss.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 07:04:25 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Sidford", "Aaron", ""], ["Wang", "Mengdi", ""], ["Yang", "Lin F.", ""], ["Ye", "Yinyu", ""]]}, {"id": "1908.11091", "submitter": "Wenqi Wei", "authors": "Ling Liu, Wenqi Wei, Ka-Ho Chow, Margaret Loper, Emre Gursoy, Stacey\n  Truex, Yanzhao Wu", "title": "Deep Neural Network Ensembles against Deception: Ensemble Diversity,\n  Accuracy and Robustness", "comments": "To appear in IEEE MASS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensemble learning is a methodology that integrates multiple DNN learners for\nimproving prediction performance of individual learners. Diversity is greater\nwhen the errors of the ensemble prediction is more uniformly distributed.\nGreater diversity is highly correlated with the increase in ensemble accuracy.\nAnother attractive property of diversity optimized ensemble learning is its\nrobustness against deception: an adversarial perturbation attack can mislead\none DNN model to misclassify but may not fool other ensemble DNN members\nconsistently. In this paper we first give an overview of the concept of\nensemble diversity and examine the three types of ensemble diversity in the\ncontext of DNN classifiers. We then describe a set of ensemble diversity\nmeasures, a suite of algorithms for creating diversity ensembles and for\nperforming ensemble consensus (voted or learned) for generating high accuracy\nensemble output by strategically combining outputs of individual members. This\npaper concludes with a discussion on a set of open issues in quantifying\nensemble diversity for robust deep learning.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 08:22:05 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Liu", "Ling", ""], ["Wei", "Wenqi", ""], ["Chow", "Ka-Ho", ""], ["Loper", "Margaret", ""], ["Gursoy", "Emre", ""], ["Truex", "Stacey", ""], ["Wu", "Yanzhao", ""]]}, {"id": "1908.11133", "submitter": "Sophie Langer", "authors": "Michael Kohler and Sophie Langer", "title": "On the rate of convergence of fully connected very deep neural network\n  regression estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent results in nonparametric regression show that deep learning, i.e.,\nneural network estimates with many hidden layers, are able to circumvent the\nso-called curse of dimensionality in case that suitable restrictions on the\nstructure of the regression function hold. One key feature of the neural\nnetworks used in these results is that their network architecture has a further\nconstraint, namely the network sparsity. In this paper we show that we can get\nsimilar results also for least squares estimates based on simple fully\nconnected neural networks with ReLU activation functions. Here either the\nnumber of neurons per hidden layer is fixed and the number of hidden layers\ntends to infinity suitably fast for sample size tending to infinity, or the\nnumber of hidden layers is bounded by some logarithmic factor in the sample\nsize and the number of neurons per hidden layer tends to infinity suitably fast\nfor sample size tending to infinity. The proof is based on new approximation\nresults concerning deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 10:01:20 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 09:25:19 GMT"}, {"version": "v3", "created": "Tue, 23 Jun 2020 08:40:19 GMT"}, {"version": "v4", "created": "Thu, 20 Aug 2020 12:45:47 GMT"}, {"version": "v5", "created": "Tue, 29 Sep 2020 15:22:58 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Kohler", "Michael", ""], ["Langer", "Sophie", ""]]}, {"id": "1908.11140", "submitter": "Sophie Langer", "authors": "Michael Kohler, Adam Krzyzak and Sophie Langer", "title": "Estimation of a function of low local dimensionality by deep neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) achieve impressive results for complicated tasks\nlike object detection on images and speech recognition. Motivated by this\npractical success, there is now a strong interest in showing good theoretical\nproperties of DNNs. To describe for which tasks DNNs perform well and when they\nfail, it is a key challenge to understand their performance. The aim of this\npaper is to contribute to the current statistical theory of DNNs. We apply DNNs\non high dimensional data and we show that the least squares regression\nestimates using DNNs are able to achieve dimensionality reduction in case that\nthe regression function has locally low dimensionality. Consequently, the rate\nof convergence of the estimate does not depend on its input dimension $d$, but\non its local dimension $d^*$ and the DNNs are able to circumvent the curse of\ndimensionality in case that $d^*$ is much smaller than $d$. In our simulation\nstudy we provide numerical experiments to support our theoretical result and we\ncompare our estimate with other conventional nonparametric regression\nestimates. The performance of our estimates is also validated in experiments\nwith real data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 10:24:10 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 18:11:26 GMT"}, {"version": "v3", "created": "Mon, 15 Jun 2020 12:10:43 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kohler", "Michael", ""], ["Krzyzak", "Adam", ""], ["Langer", "Sophie", ""]]}, {"id": "1908.11161", "submitter": "Rafael Caba\\~nas", "authors": "Javier C\\'ozar, Rafael Caba\\~nas, Antonio Salmer\\'on, Andr\\'es R.\n  Masegosa", "title": "InferPy: Probabilistic Modeling with Deep Neural Networks Made Easy", "comments": "5 pages limit (paper submitted to an original software publication\n  track). This paper briefly describes a scientific software", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  InferPy is a Python package for probabilistic modeling with deep neural\nnetworks. It defines a user-friendly API that trades-off model complexity with\nease of use, unlike other libraries whose focus is on dealing with very general\nprobabilistic models at the cost of having a more complex API. In particular,\nthis package allows to define, learn and evaluate general hierarchical\nprobabilistic models containing deep neural networks in a compact and simple\nway. InferPy is built on top of Tensorflow Probability and Keras.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 11:44:59 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 09:22:59 GMT"}, {"version": "v3", "created": "Wed, 4 Sep 2019 11:22:12 GMT"}, {"version": "v4", "created": "Wed, 12 Feb 2020 13:37:54 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["C\u00f3zar", "Javier", ""], ["Caba\u00f1as", "Rafael", ""], ["Salmer\u00f3n", "Antonio", ""], ["Masegosa", "Andr\u00e9s R.", ""]]}, {"id": "1908.11199", "submitter": "Theerawit Wilaiprasitporn", "authors": "Theerasarn Pianpanit, Sermkiat Lolak, Phattarapong Sawangjai, Thapanun\n  Sudhawiyangkul and Theerawit Wilaiprasitporn", "title": "Parkinson's Disease Recognition Using SPECT Image and Interpretable AI:\n  A Tutorial", "comments": null, "journal-ref": "IEEE Sensors Journal, 2021", "doi": "10.1109/JSEN.2021.3077949", "report-no": null, "categories": "eess.IV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the past few years, there are several researches on Parkinson's disease\n(PD) recognition using single-photon emission computed tomography (SPECT)\nimages with deep learning (DL) approach. However, the DL model's complexity\nusually results in difficult model interpretation when used in clinical. Even\nthough there are multiple interpretation methods available for the DL model,\nthere is no evidence of which method is suitable for PD recognition\napplication. This tutorial aims to demonstrate the procedure to choose a\nsuitable interpretation method for the PD recognition model. We exhibit four\nDCNN architectures as an example and introduce six well-known interpretation\nmethods. Finally, we propose an evaluation method to measure the interpretation\nperformance and a method to use the interpreted feedback for assisting in model\nselection. The evaluation demonstrates that the guided backpropagation and SHAP\ninterpretation methods are suitable for PD recognition methods in different\naspects. Guided backpropagation has the best ability to show fine-grained\nimportance, which is proven by the highest Dice coefficient and lowest mean\nsquare error. On the other hand, SHAP can generate a better quality heatmap at\nthe uptake depletion location, which outperforms other methods in\ndiscriminating the difference between PD and NC subjects. Shortly, the\nintroduced interpretation methods can contribute to not only the PD recognition\napplication but also to sensor data processing in an AI Era (interpretable-AI)\nas feedback in constructing well-suited deep learning architectures for\nspecific applications.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 11:23:47 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 07:38:07 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2020 07:44:50 GMT"}, {"version": "v4", "created": "Fri, 19 Feb 2021 17:02:48 GMT"}, {"version": "v5", "created": "Fri, 9 Apr 2021 16:25:00 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Pianpanit", "Theerasarn", ""], ["Lolak", "Sermkiat", ""], ["Sawangjai", "Phattarapong", ""], ["Sudhawiyangkul", "Thapanun", ""], ["Wilaiprasitporn", "Theerawit", ""]]}, {"id": "1908.11212", "submitter": "Kerda Varaku", "authors": "Kerda Varaku", "title": "Stock Price Forecasting and Hypothesis Testing Using Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.LG econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we use Recurrent Neural Networks and Multilayer Perceptrons to\npredict NYSE, NASDAQ and AMEX stock prices from historical data. We experiment\nwith different architectures and compare data normalization techniques. Then,\nwe leverage those findings to question the efficient-market hypothesis through\na formal statistical test.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 03:10:30 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Varaku", "Kerda", ""]]}, {"id": "1908.11219", "submitter": "Jivitesh Sharma", "authors": "Jivitesh Sharma, Ole-Christoffer Granmo and Morten Goodwin", "title": "Environment Sound Classification using Multiple Feature Channels and\n  Attention based Deep Convolutional Neural Network", "comments": "Re-checking results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a model for the Environment Sound Classification\nTask (ESC) that consists of multiple feature channels given as input to a Deep\nConvolutional Neural Network (CNN) with Attention mechanism. The novelty of the\npaper lies in using multiple feature channels consisting of Mel-Frequency\nCepstral Coefficients (MFCC), Gammatone Frequency Cepstral Coefficients (GFCC),\nthe Constant Q-transform (CQT) and Chromagram. Such multiple features have\nnever been used before for signal or audio processing. And, we employ a deeper\nCNN (DCNN) compared to previous models, consisting of spatially separable\nconvolutions working on time and feature domain separately. Alongside, we use\nattention modules that perform channel and spatial attention together. We use\nsome data augmentation techniques to further boost performance. Our model is\nable to achieve state-of-the-art performance on all three benchmark environment\nsound classification datasets, i.e. the UrbanSound8K (97.52%), ESC-10 (95.75%)\nand ESC-50 (88.50%). To the best of our knowledge, this is the first time that\na single environment sound classification model is able to achieve\nstate-of-the-art results on all three datasets. For ESC-10 and ESC-50 datasets,\nthe accuracy achieved by the proposed model is beyond human accuracy of 95.7%\nand 81.3% respectively.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 17:02:19 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 09:31:16 GMT"}, {"version": "v3", "created": "Fri, 13 Sep 2019 06:48:47 GMT"}, {"version": "v4", "created": "Wed, 25 Sep 2019 13:52:40 GMT"}, {"version": "v5", "created": "Wed, 4 Dec 2019 13:56:44 GMT"}, {"version": "v6", "created": "Thu, 27 Feb 2020 13:46:20 GMT"}, {"version": "v7", "created": "Thu, 2 Apr 2020 08:45:48 GMT"}, {"version": "v8", "created": "Mon, 16 Nov 2020 10:05:53 GMT"}, {"version": "v9", "created": "Tue, 8 Dec 2020 12:55:29 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Sharma", "Jivitesh", ""], ["Granmo", "Ole-Christoffer", ""], ["Goodwin", "Morten", ""]]}, {"id": "1908.11221", "submitter": "Chengqing Li", "authors": "Siwang Zhou, Yan He, Yonghe Liu, Chengqing Li", "title": "Multi-Channel Deep Networks for Block-Based Image Compressive Sensing", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating deep neural networks in image compressive sensing (CS) receives\nintensive attentions recently. As deep network approaches learn the inverse\nmapping directly from the CS measurements, a number of models have to be\ntrained, each of which corresponds to a sampling rate. This may potentially\ndegrade the performance of image CS, especially when multiple sampling rates\nare assigned to different blocks within an image. In this paper, we develop a\nmulti-channel deep network for block-based image CS with performance\nsignificantly exceeding the current state-of-the-art methods. The significant\nperformance improvement of the model is attributed to block-based sampling\nrates allocation and model-level removal of blocking artifacts. Specifically,\nthe image blocks with a variety of sampling rates can be reconstructed in a\nsingle model by exploiting inter-block correlation. At the same time, the\ninitially reconstructed blocks are reassembled into a full image to remove\nblocking artifacts within the network by unrolling a hand-designed block-based\nCS algorithm. Experimental results demonstrate that the proposed method\noutperforms the state-of-the-art CS methods by a large margin in terms of\nobjective metrics, PSNR, SSIM, and subjective visual quality.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 13:49:28 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Zhou", "Siwang", ""], ["He", "Yan", ""], ["Liu", "Yonghe", ""], ["Li", "Chengqing", ""]]}, {"id": "1908.11229", "submitter": "Alexandre Sablayrolles", "authors": "Alexandre Sablayrolles, Matthijs Douze, Yann Ollivier, Cordelia\n  Schmid, Herv\\'e J\\'egou", "title": "White-box vs Black-box: Bayes Optimal Strategies for Membership\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Membership inference determines, given a sample and trained parameters of a\nmachine learning model, whether the sample was part of the training set. In\nthis paper, we derive the optimal strategy for membership inference with a few\nassumptions on the distribution of the parameters. We show that optimal attacks\nonly depend on the loss function, and thus black-box attacks are as good as\nwhite-box attacks. As the optimal strategy is not tractable, we provide\napproximations of it leading to several inference methods, and show that\nexisting membership inference methods are coarser approximations of this\noptimal strategy. Our membership attacks outperform the state of the art in\nvarious settings, ranging from a simple logistic regression to more complex\narchitectures and datasets, such as ResNet-101 and Imagenet.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 13:53:49 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Sablayrolles", "Alexandre", ""], ["Douze", "Matthijs", ""], ["Ollivier", "Yann", ""], ["Schmid", "Cordelia", ""], ["J\u00e9gou", "Herv\u00e9", ""]]}, {"id": "1908.11250", "submitter": "Suraj Tripathi", "authors": "Mayank Sharma, Suraj Tripathi, Abhimanyu Dubey, Jayadeva, Sai Guruju,\n  Nihal Goalla", "title": "Smaller Models, Better Generalization", "comments": "10 pages, 3 figures, In Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing network complexity has been a major research focus in recent years\nwith the advent of mobile technology. Convolutional Neural Networks that\nperform various vision tasks without memory overhaul is the need of the hour.\nThis paper focuses on qualitative and quantitative analysis of reducing the\nnetwork complexity using an upper bound on the Vapnik-Chervonenkis dimension,\npruning, and quantization. We observe a general trend in improvement of\naccuracies as we quantize the models. We propose a novel loss function that\nhelps in achieving considerable sparsity at comparable accuracies to that of\ndense models. We compare various regularizations prevalent in the literature\nand show the superiority of our method in achieving sparser models that\ngeneralize well.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 14:17:41 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Sharma", "Mayank", ""], ["Tripathi", "Suraj", ""], ["Dubey", "Abhimanyu", ""], ["Jayadeva", "", ""], ["Guruju", "Sai", ""], ["Goalla", "Nihal", ""]]}, {"id": "1908.11272", "submitter": "David Gaudrie", "authors": "David Gaudrie, Rodolphe Le Riche, Victor Picheny, Benoit Enaux,\n  Vincent Herbert", "title": "Modeling and Optimization with Gaussian Processes in Reduced Eigenbases\n  -- Extended Version", "comments": null, "journal-ref": "Structural and Multidisciplinary Optimization, 2020, 61,\n  pp.2343-2361", "doi": "10.1007/s00158-019-02458-6", "report-no": null, "categories": "stat.ML cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Parametric shape optimization aims at minimizing an objective function f(x)\nwhere x are CAD parameters. This task is difficult when f is the output of an\nexpensive-to-evaluate numerical simulator and the number of CAD parameters is\nlarge. Most often, the set of all considered CAD shapes resides in a manifold\nof lower effective dimension in which it is preferable to build the surrogate\nmodel and perform the optimization. In this work, we uncover the manifold\nthrough a high-dimensional shape mapping and build a new coordinate system made\nof eigenshapes. The surrogate model is learned in the space of eigenshapes: a\nregularized likelihood maximization provides the most relevant dimensions for\nthe output. The final surrogate model is detailed (anisotropic) with respect to\nthe most sensitive eigenshapes and rough (isotropic) in the remaining\ndimensions. Last, the optimization is carried out with a focus on the critical\ndimensions, the remaining ones being coarsely optimized through a random\nembedding and the manifold being accounted for through a replication strategy.\nAt low budgets, the methodology leads to a more accurate model and a faster\noptimization than the classical approach of directly working with the CAD\nparameters.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 14:58:20 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 06:48:22 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Gaudrie", "David", ""], ["Riche", "Rodolphe Le", ""], ["Picheny", "Victor", ""], ["Enaux", "Benoit", ""], ["Herbert", "Vincent", ""]]}, {"id": "1908.11307", "submitter": "Yoshiaki Bando", "authors": "Yoshiaki Bando, Yoko Sasaki, Kazuyoshi Yoshii", "title": "Deep Bayesian Unsupervised Source Separation Based on a Complex Gaussian\n  Mixture Model", "comments": "6 pages, 2 figures, accepted for publication in 2019 IEEE\n  International Workshop on Machine Learning for Signal Processing (MLSP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an unsupervised method that trains neural source\nseparation by using only multichannel mixture signals. Conventional neural\nseparation methods require a lot of supervised data to achieve excellent\nperformance. Although multichannel methods based on spatial information can\nwork without such training data, they are often sensitive to parameter\ninitialization and degraded with the sources located close to each other. The\nproposed method uses a cost function based on a spatial model called a complex\nGaussian mixture model (cGMM). This model has the time-frequency (TF) masks and\ndirection of arrivals (DoAs) of sources as latent variables and is used for\ntraining separation and localization networks that respectively estimate these\nvariables. This joint training solves the frequency permutation ambiguity of\nthe spatial model in a unified deep Bayesian framework. In addition, the\npre-trained network can be used not only for conducting monaural separation but\nalso for efficiently initializing a multichannel separation algorithm.\nExperimental results with simulated speech mixtures showed that our method\noutperformed a conventional initialization method.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 15:45:20 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Bando", "Yoshiaki", ""], ["Sasaki", "Yoko", ""], ["Yoshii", "Kazuyoshi", ""]]}, {"id": "1908.11319", "submitter": "Mi Yan", "authors": "Mi Yan, Jonathan C. MacDonald, Chris T. Reaume, Wesley Cobb, Tamas\n  Toth, Sarah S. Karthigan", "title": "Machine Learning and the Internet of Things Enable Steam Flood\n  Optimization for Improved Oil Production", "comments": "Accepted by the 1st International Workshop on Artificial Intelligence\n  of Things at KDD 2019", "journal-ref": "The 1st International Workshop on Artificial Intelligence of\n  Things at KDD 2019", "doi": null, "report-no": null, "categories": "stat.ML cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently developed machine learning techniques, in association with the\nInternet of Things (IoT) allow for the implementation of a method of increasing\noil production from heavy-oil wells. Steam flood injection, a widely used\nenhanced oil recovery technique, uses thermal and gravitational potential to\nmobilize and dilute heavy oil in situ to increase oil production. In contrast\nto traditional steam flood simulations based on principles of classic physics,\nwe introduce here an approach using cutting-edge machine learning techniques\nthat have the potential to provide a better way to describe the performance of\nsteam flood. We propose a workflow to address a category of time-series data\nthat can be analyzed with supervised machine learning algorithms and IoT. We\ndemonstrate the effectiveness of the technique for forecasting oil production\nin steam flood scenarios. Moreover, we build an optimization system that\nrecommends an optimal steam allocation plan, and show that it leads to a 3%\nimprovement in oil production. We develop a minimum viable product on a cloud\nplatform that can implement real-time data collection, transfer, and storage,\nas well as the training and implementation of a cloud-based machine learning\nmodel. This workflow also offers an applicable solution to other problems with\nsimilar time-series data structures, like predictive maintenance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:04:38 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 01:08:54 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yan", "Mi", ""], ["MacDonald", "Jonathan C.", ""], ["Reaume", "Chris T.", ""], ["Cobb", "Wesley", ""], ["Toth", "Tamas", ""], ["Karthigan", "Sarah S.", ""]]}, {"id": "1908.11332", "submitter": "Junde Wu", "authors": "Junde Wu", "title": "Generating adversarial examples in the harsh conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks have been found vulnerable re-cently. A kind of\nwell-designed inputs, which called adver-sarial examples, can lead the networks\nto make incorrectpredictions. Depending on the different scenarios, goalsand\ncapabilities, the difficulties of the attacks are different.For example, a\ntargeted attack is more difficult than a non-targeted attack, a universal\nattack is more difficult than anon-universal attack, a transferable attack is\nmore difficultthan a nontransferable one. The question is: Is there existan\nattack that can meet all these requirements? In this pa-per, we answer this\nquestion by producing a kind of attacksunder these conditions. We learn a\nuniversal mapping tomap the sources to the adversarial examples. These\nexam-ples can fool classification networks to classify all of theminto one\ntargeted class, and also have strong transferability.Our code is released at:\nxxxxx.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:27:24 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 15:17:55 GMT"}, {"version": "v3", "created": "Wed, 16 Dec 2020 21:25:14 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Wu", "Junde", ""]]}, {"id": "1908.11335", "submitter": "Ilias Diakonikolas", "authors": "Ilias Diakonikolas and Daniel M. Kane and Pasin Manurangsi", "title": "Nearly Tight Bounds for Robust Proper Learning of Halfspaces with a\n  Margin", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of {\\em properly} learning large margin halfspaces in\nthe agnostic PAC model. In more detail, we study the complexity of properly\nlearning $d$-dimensional halfspaces on the unit ball within misclassification\nerror $\\alpha \\cdot \\mathrm{OPT}_{\\gamma} + \\epsilon$, where\n$\\mathrm{OPT}_{\\gamma}$ is the optimal $\\gamma$-margin error rate and $\\alpha\n\\geq 1$ is the approximation ratio. We give learning algorithms and\ncomputational hardness results for this problem, for all values of the\napproximation ratio $\\alpha \\geq 1$, that are nearly-matching for a range of\nparameters. Specifically, for the natural setting that $\\alpha$ is any constant\nbigger than one, we provide an essentially tight complexity characterization.\nOn the positive side, we give an $\\alpha = 1.01$-approximate proper learner\nthat uses $O(1/(\\epsilon^2\\gamma^2))$ samples (which is optimal) and runs in\ntime $\\mathrm{poly}(d/\\epsilon) \\cdot 2^{\\tilde{O}(1/\\gamma^2)}$. On the\nnegative side, we show that {\\em any} constant factor approximate proper\nlearner has runtime $\\mathrm{poly}(d/\\epsilon) \\cdot 2^{(1/\\gamma)^{2-o(1)}}$,\nassuming the Exponential Time Hypothesis.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 16:34:25 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Diakonikolas", "Ilias", ""], ["Kane", "Daniel M.", ""], ["Manurangsi", "Pasin", ""]]}, {"id": "1908.11358", "submitter": "Noah Golowich", "authors": "Badih Ghazi, Noah Golowich, Ravi Kumar, Rasmus Pagh, Ameya Velingker", "title": "On the Power of Multiple Anonymous Messages", "comments": "70 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An exciting new development in differential privacy is the shuffled model, in\nwhich an anonymous channel enables non-interactive, differentially private\nprotocols with error much smaller than what is possible in the local model,\nwhile relying on weaker trust assumptions than in the central model. In this\npaper, we study basic counting problems in the shuffled model and establish\nseparations between the error that can be achieved in the single-message\nshuffled model and in the shuffled model with multiple messages per user.\n  For the problem of frequency estimation for $n$ users and a domain of size\n$B$, we obtain:\n  - A nearly tight lower bound of $\\tilde{\\Omega}( \\min(\\sqrt[4]{n},\n\\sqrt{B}))$ on the error in the single-message shuffled model. This implies\nthat the protocols obtained from the amplification via shuffling work of\nErlingsson et al. (SODA 2019) and Balle et al. (Crypto 2019) are essentially\noptimal for single-message protocols. A key ingredient in the proof is a lower\nbound on the error of locally-private frequency estimation in the low-privacy\n(aka high $\\epsilon$) regime.\n  - Protocols in the multi-message shuffled model with $poly(\\log{B}, \\log{n})$\nbits of communication per user and $poly\\log{B}$ error, which provide an\nexponential improvement on the error compared to what is possible with\nsingle-message algorithms.\n  For the related selection problem on a domain of size $B$, we prove:\n  - A nearly tight lower bound of $\\Omega(B)$ on the number of users in the\nsingle-message shuffled model. This significantly improves on the\n$\\Omega(B^{1/17})$ lower bound obtained by Cheu et al. (Eurocrypt 2019), and\nwhen combined with their $\\tilde{O}(\\sqrt{B})$-error multi-message protocol,\nimplies the first separation between single-message and multi-message protocols\nfor this problem.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 17:26:23 GMT"}, {"version": "v2", "created": "Wed, 16 Oct 2019 16:40:51 GMT"}, {"version": "v3", "created": "Sun, 1 Dec 2019 20:42:51 GMT"}, {"version": "v4", "created": "Tue, 19 May 2020 05:53:03 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Ghazi", "Badih", ""], ["Golowich", "Noah", ""], ["Kumar", "Ravi", ""], ["Pagh", "Rasmus", ""], ["Velingker", "Ameya", ""]]}, {"id": "1908.11399", "submitter": "Andrey Kormilitzin", "authors": "Andrey Kormilitzin, Xinyu Yang, William H. Stone, Caroline Woffindale,\n  Francesca Nicholls, Elena Ribe, Alejo Nevado-Holgado, Noel Buckley", "title": "Deep Learning for Estimating Synaptic Health of Primary Neuronal Cell\n  Culture", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the morphological changes of primary neuronal cells induced by\nchemical compounds is essential for drug discovery. Using the data from a\nsingle high-throughput imaging assay, a classification model for predicting the\nbiological activity of candidate compounds was introduced. The image\nrecognition model which is based on deep convolutional neural network (CNN)\narchitecture with residual connections achieved accuracy of 99.6$\\%$ on a\nbinary classification task of distinguishing untreated and treated rodent\nprimary neuronal cells with Amyloid-$\\beta_{(25-35)}$.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:03:07 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Kormilitzin", "Andrey", ""], ["Yang", "Xinyu", ""], ["Stone", "William H.", ""], ["Woffindale", "Caroline", ""], ["Nicholls", "Francesca", ""], ["Ribe", "Elena", ""], ["Nevado-Holgado", "Alejo", ""], ["Buckley", "Noel", ""]]}, {"id": "1908.11404", "submitter": "Xi Chen", "authors": "Xi C. Chen, Adithya Sagar, Justine T. Kao, Tony Y. Li, Christopher\n  Klein, Stephen Pulman, Ashish Garg, Jason D. Williams", "title": "Active Learning for Domain Classification in a Commercial Spoken\n  Personal Assistant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a method for selecting relevant new training data for the\nLSTM-based domain selection component of our personal assistant system. Adding\nmore annotated training data for any ML system typically improves accuracy, but\nonly if it provides examples not already adequately covered in the existing\ndata. However, obtaining, selecting, and labeling relevant data is expensive.\nThis work presents a simple technique that automatically identifies new helpful\nexamples suitable for human annotation. Our experimental results show that the\nproposed method, compared with random-selection and entropy-based methods,\nleads to higher accuracy improvements given a fixed annotation budget. Although\ndeveloped and tested in the setting of a commercial intelligent assistant, the\ntechnique is of wider applicability.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:14:46 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Chen", "Xi C.", ""], ["Sagar", "Adithya", ""], ["Kao", "Justine T.", ""], ["Li", "Tony Y.", ""], ["Klein", "Christopher", ""], ["Pulman", "Stephen", ""], ["Garg", "Ashish", ""], ["Williams", "Jason D.", ""]]}, {"id": "1908.11415", "submitter": "Zelun Wang", "authors": "Zelun Wang, Jyh-Charn Liu", "title": "Translating Math Formula Images to LaTeX Sequences Using Deep Neural\n  Networks with Sequence-level Training", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a deep neural network model with an encoder-decoder\narchitecture that translates images of math formulas into their LaTeX markup\nsequences. The encoder is a convolutional neural network (CNN) that transforms\nimages into a group of feature maps. To better capture the spatial\nrelationships of math symbols, the feature maps are augmented with 2D\npositional encoding before being unfolded into a vector. The decoder is a\nstacked bidirectional long short-term memory (LSTM) model integrated with the\nsoft attention mechanism, which works as a language model to translate the\nencoder output into a sequence of LaTeX tokens. The neural network is trained\nin two steps. The first step is token-level training using the\nMaximum-Likelihood Estimation (MLE) as the objective function. At completion of\nthe token-level training, the sequence-level training objective function is\nemployed to optimize the overall model based on the policy gradient algorithm\nfrom reinforcement learning. Our design also overcomes the exposure bias\nproblem by closing the feedback loop in the decoder during sequence-level\ntraining, i.e., feeding in the predicted token instead of the ground truth\ntoken at every time step. The model is trained and evaluated on the\nIM2LATEX-100K dataset and shows state-of-the-art performance on both\nsequence-based and image-based evaluation metrics.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 18:33:21 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 19:09:42 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Wang", "Zelun", ""], ["Liu", "Jyh-Charn", ""]]}, {"id": "1908.11450", "submitter": "Siqi Wang", "authors": "Siqi Wang, Anuj Pathania, Tulika Mitra", "title": "Neural Network Inference on Mobile SoCs", "comments": "Accepted to IEEE Design & Test", "journal-ref": "in IEEE Design & Test, vol. 37, no. 5, pp. 50-57, Oct. 2020", "doi": "10.1109/MDAT.2020.2968258", "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing demand from mobile Machine Learning (ML) applications\ncalls for evermore powerful on-chip computing resources. Mobile devices are\nempowered with heterogeneous multi-processor Systems-on-Chips (SoCs) to process\nML workloads such as Convolutional Neural Network (CNN) inference. Mobile SoCs\nhouse several different types of ML capable components on-die, such as CPU,\nGPU, and accelerators. These different components are capable of independently\nperforming inference but with very different power-performance characteristics.\nIn this article, we provide a quantitative evaluation of the inference\ncapabilities of the different components on mobile SoCs. We also present\ninsights behind their respective power-performance behavior. Finally, we\nexplore the performance limit of the mobile SoCs by synergistically engaging\nall the components concurrently. We observe that a mobile SoC provides up to 2x\nimprovement with parallel inference when all its components are engaged, as\nopposed to engaging only one component.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 07:13:57 GMT"}, {"version": "v2", "created": "Wed, 22 Jan 2020 16:03:15 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Wang", "Siqi", ""], ["Pathania", "Anuj", ""], ["Mitra", "Tulika", ""]]}, {"id": "1908.11462", "submitter": "Liu Yang", "authors": "Liu Yang and George Em Karniadakis", "title": "Potential Flow Generator with $L_2$ Optimal Transport Regularity for\n  Generative Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a potential flow generator with $L_2$ optimal transport\nregularity, which can be easily integrated into a wide range of generative\nmodels including different versions of GANs and flow-based models. We show the\ncorrectness and robustness of the potential flow generator in several 2D\nproblems, and illustrate the concept of \"proximity\" due to the $L_2$ optimal\ntransport regularity. Subsequently, we demonstrate the effectiveness of the\npotential flow generator in image translation tasks with unpaired training data\nfrom the MNIST dataset and the CelebA dataset.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 22:00:49 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yang", "Liu", ""], ["Karniadakis", "George Em", ""]]}, {"id": "1908.11468", "submitter": "Lin Xiao", "authors": "Junyu Zhang and Lin Xiao", "title": "Multi-Level Composite Stochastic Optimization via Nested Variance\n  Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider multi-level composite optimization problems where each mapping in\nthe composition is the expectation over a family of random smooth mappings or\nthe sum of some finite number of smooth mappings. We present a normalized\nproximal approximate gradient (NPAG) method where the approximate gradients are\nobtained via nested stochastic variance reduction. In order to find an\napproximate stationary point where the expected norm of its gradient mapping is\nless than $\\epsilon$, the total sample complexity of our method is\n$O(\\epsilon^{-3})$ in the expectation case, and $O(N+\\sqrt{N}\\epsilon^{-2})$ in\nthe finite-sum case where $N$ is the total number of functions across all\ncomposition levels. In addition, the dependence of our total sample complexity\non the number of composition levels is polynomial, rather than exponential as\nin previous work.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 22:22:06 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 22:58:57 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zhang", "Junyu", ""], ["Xiao", "Lin", ""]]}, {"id": "1908.11479", "submitter": "Hamidreza Tavafoghi", "authors": "Hamidreza Tavafoghi, Kameshwar Poolla, and Pravin Varaiya", "title": "A Queuing Approach to Parking: Modeling, Verification, and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SY eess.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a queuing model of parking dynamics and a model-based prediction\nmethod to provide real-time probabilistic forecasts of future parking\noccupancy. The queuing model has a non-homogeneous arrival rate and\ntime-varying service time distribution. All statistical assumptions of the\nmodel are verified using data from 29 truck parking locations, each with\nbetween 55 and 299 parking spots. For each location and each spot the data\nspecifies the arrival and departure times of a truck, for 16 months of\noperation. The modeling framework presented in this paper provides empirical\nsupport for queuing models adopted in many theoretical studies and policy\ndesigns. We discuss how our framework can be used to study parking problems in\ndifferent environments. Based on the queuing model, we propose two prediction\nmethods, a microscopic method and a macroscopic method, that provide a\nreal-time probabilistic forecast of parking occupancy for an arbitrary forecast\nhorizon. These model-based methods convert a probabilistic forecast problem\ninto a parameter estimation problem that can be tackled using classical\nestimation methods such as regressions or pure machine learning algorithms. We\ncharacterize a lower bound for an arbitrary real-time prediction algorithm. We\nevaluate the performance of these methods using the truck data comparing the\noutcomes of their implementations with other model-based and model-free methods\nproposed in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 23:29:44 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Tavafoghi", "Hamidreza", ""], ["Poolla", "Kameshwar", ""], ["Varaiya", "Pravin", ""]]}, {"id": "1908.11503", "submitter": "Chenrui Zhang", "authors": "Chenrui Zhang, Xiaoqing Lyu, Zhi Tang", "title": "TGG: Transferable Graph Generation for Zero-shot and Few-shot Learning", "comments": "ACM Multimedia 2019 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Zero-shot and few-shot learning aim to improve generalization to unseen\nconcepts, which are promising in many realistic scenarios. Due to the lack of\ndata in unseen domain, relation modeling between seen and unseen domains is\nvital for knowledge transfer in these tasks. Most existing methods capture\nseen-unseen relation implicitly via semantic embedding or feature generation,\nresulting in inadequate use of relation and some issues remain (e.g. domain\nshift). To tackle these challenges, we propose a Transferable Graph Generation\n(TGG) approach, in which the relation is modeled and utilized explicitly via\ngraph generation. Specifically, our proposed TGG contains two main components:\n(1) Graph generation for relation modeling. An attention-based aggregate\nnetwork and a relation kernel are proposed, which generate instance-level graph\nbased on a class-level prototype graph and visual features. Proximity\ninformation aggregating is guided by a multi-head graph attention mechanism,\nwhere seen and unseen features synthesized by GAN are revised as node\nembeddings. The relation kernel further generates edges with GCN and graph\nkernel method, to capture instance-level topological structure while tackling\ndata imbalance and noise. (2) Relation propagation for relation utilization. A\ndual relation propagation approach is proposed, where relations captured by the\ngenerated graph are separately propagated from the seen and unseen subgraphs.\nThe two propagations learn from each other in a dual learning fashion, which\nperforms as an adaptation way for mitigating domain shift. All components are\njointly optimized with a meta-learning strategy, and our TGG acts as an\nend-to-end framework unifying conventional zero-shot, generalized zero-shot and\nfew-shot learning. Extensive experiments demonstrate that it consistently\nsurpasses existing methods of the above three fields by a significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 01:47:24 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zhang", "Chenrui", ""], ["Lyu", "Xiaoqing", ""], ["Tang", "Zhi", ""]]}, {"id": "1908.11514", "submitter": "Quanyu Dai", "authors": "Quanyu Dai, Xiao Shen, Liang Zhang, Qiang Li and Dan Wang", "title": "Adversarial Training Methods for Network Embedding", "comments": "The World Wide Web Conference 2019, WWW'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Embedding is the task of learning continuous node representations for\nnetworks, which has been shown effective in a variety of tasks such as link\nprediction and node classification. Most of existing works aim to preserve\ndifferent network structures and properties in low-dimensional embedding\nvectors, while neglecting the existence of noisy information in many real-world\nnetworks and the overfitting issue in the embedding learning process. Most\nrecently, generative adversarial networks (GANs) based regularization methods\nare exploited to regularize embedding learning process, which can encourage a\nglobal smoothness of embedding vectors. These methods have very complicated\narchitecture and suffer from the well-recognized non-convergence problem of\nGANs. In this paper, we aim to introduce a more succinct and effective local\nregularization method, namely adversarial training, to network embedding so as\nto achieve model robustness and better generalization performance. Firstly, the\nadversarial training method is applied by defining adversarial perturbations in\nthe embedding space with an adaptive $L_2$ norm constraint that depends on the\nconnectivity pattern of node pairs. Though effective as a regularizer, it\nsuffers from the interpretability issue which may hinder its application in\ncertain real-world scenarios. To improve this strategy, we further propose an\ninterpretable adversarial training method by enforcing the reconstruction of\nthe adversarial examples in the discrete graph domain. These two regularization\nmethods can be applied to many existing embedding models, and we take DeepWalk\nas the base model for illustration in the paper. Empirical evaluations in both\nlink prediction and node classification demonstrate the effectiveness of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 02:48:52 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Dai", "Quanyu", ""], ["Shen", "Xiao", ""], ["Zhang", "Liang", ""], ["Li", "Qiang", ""], ["Wang", "Dan", ""]]}, {"id": "1908.11523", "submitter": "Niccol\\`o Dalmasso", "authors": "Niccol\\`o Dalmasso and Taylor Pospisil and Ann B. Lee and Rafael\n  Izbicki and Peter E. Freeman and Alex I. Malz", "title": "Conditional Density Estimation Tools in Python and R with Applications\n  to Photometric Redshifts and Likelihood-Free Cosmological Inference", "comments": "27 pages, 7 figures, 4 tables", "journal-ref": null, "doi": "10.1016/j.ascom.2019.100362", "report-no": null, "categories": "astro-ph.IM stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known in astronomy that propagating non-Gaussian prediction\nuncertainty in photometric redshift estimates is key to reducing bias in\ndownstream cosmological analyses. Similarly, likelihood-free inference\napproaches, which are beginning to emerge as a tool for cosmological analysis,\nrequire a characterization of the full uncertainty landscape of the parameters\nof interest given observed data. However, most machine learning (ML) or\ntraining-based methods with open-source software target point prediction or\nclassification, and hence fall short in quantifying uncertainty in complex\nregression and parameter inference settings. As an alternative to methods that\nfocus on predicting the response (or parameters) $\\mathbf{y}$ from features\n$\\mathbf{x}$, we provide nonparametric conditional density estimation (CDE)\ntools for approximating and validating the entire probability density function\n(PDF) $\\mathrm{p}(\\mathbf{y}|\\mathbf{x})$ of $\\mathbf{y}$ given (i.e.,\nconditional on) $\\mathbf{x}$. As there is no one-size-fits-all CDE method, the\ngoal of this work is to provide a comprehensive range of statistical tools and\nopen-source software for nonparametric CDE and method assessment which can\naccommodate different types of settings and be easily fit to the problem at\nhand. Specifically, we introduce four CDE software packages in\n$\\texttt{Python}$ and $\\texttt{R}$ based on ML prediction methods adapted and\noptimized for CDE: $\\texttt{NNKCDE}$, $\\texttt{RFCDE}$, $\\texttt{FlexCode}$,\nand $\\texttt{DeepCDE}$. Furthermore, we present the $\\texttt{cdetools}$\npackage, which includes functions for computing a CDE loss function for tuning\nand assessing the quality of individual PDFs, along with diagnostic functions.\nWe provide sample code in $\\texttt{Python}$ and $\\texttt{R}$ as well as\nexamples of applications to photometric redshift estimation and likelihood-free\ncosmological inference via CDE.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 03:56:17 GMT"}, {"version": "v2", "created": "Sat, 21 Dec 2019 02:49:21 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Dalmasso", "Niccol\u00f2", ""], ["Pospisil", "Taylor", ""], ["Lee", "Ann B.", ""], ["Izbicki", "Rafael", ""], ["Freeman", "Peter E.", ""], ["Malz", "Alex I.", ""]]}, {"id": "1908.11527", "submitter": "Le Fang", "authors": "Le Fang, Chunyuan Li, Jianfeng Gao, Wen Dong and Changyou Chen", "title": "Implicit Deep Latent Variable Models for Text Generation", "comments": "13 pages, 8 Tables, 1 Figure, Accepted at 2019 Conference on\n  Empirical Methods in Natural Language Processing (EMNLP 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep latent variable models (LVM) such as variational auto-encoder (VAE) have\nrecently played an important role in text generation. One key factor is the\nexploitation of smooth latent structures to guide the generation. However, the\nrepresentation power of VAEs is limited due to two reasons: (1) the Gaussian\nassumption is often made on the variational posteriors; and meanwhile (2) a\nnotorious \"posterior collapse\" issue occurs. In this paper, we advocate\nsample-based representations of variational distributions for natural language,\nleading to implicit latent features, which can provide flexible representation\npower compared with Gaussian-based posteriors. We further develop an LVM to\ndirectly match the aggregated posterior to the prior. It can be viewed as a\nnatural extension of VAEs with a regularization of maximizing mutual\ninformation, mitigating the \"posterior collapse\" issue. We demonstrate the\neffectiveness and versatility of our models in various text generation\nscenarios, including language modeling, unaligned style transfer, and dialog\nresponse generation. The source code to reproduce our experimental results is\navailable on GitHub.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 04:12:08 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 05:48:05 GMT"}, {"version": "v3", "created": "Wed, 27 Nov 2019 19:53:57 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Fang", "Le", ""], ["Li", "Chunyuan", ""], ["Gao", "Jianfeng", ""], ["Dong", "Wen", ""], ["Chen", "Changyou", ""]]}, {"id": "1908.11535", "submitter": "Yusuke Yasuda", "authors": "Yusuke Yasuda, Xin Wang, Junichi Yamagishi", "title": "Initial investigation of an encoder-decoder end-to-end TTS framework\n  using marginalization of monotonic hard latent alignments", "comments": "To be appeared at SSW10", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.CL cs.SD stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end text-to-speech (TTS) synthesis is a method that directly converts\ninput text to output acoustic features using a single network. A recent advance\nof end-to-end TTS is due to a key technique called attention mechanisms, and\nall successful methods proposed so far have been based on soft attention\nmechanisms. However, although network structures are becoming increasingly\ncomplex, end-to-end TTS systems with soft attention mechanisms may still fail\nto learn and to predict accurate alignment between the input and output. This\nmay be because the soft attention mechanisms are too flexible. Therefore, we\npropose an approach that has more explicit but natural constraints suitable for\nspeech signals to make alignment learning and prediction of end-to-end TTS\nsystems more robust. The proposed system, with the constrained alignment scheme\nborrowed from segment-to-segment neural transduction (SSNT), directly\ncalculates the joint probability of acoustic features and alignment given an\ninput text. The alignment is designed to be hard and monotonically increase by\nconsidering the speech nature, and it is treated as a latent variable and\nmarginalized during training. During prediction, both the alignment and\nacoustic features can be generated from the probabilistic distributions. The\nadvantages of our approach are that we can simplify many modules for the soft\nattention and that we can train the end-to-end TTS model using a single\nlikelihood function. As far as we know, our approach is the first end-to-end\nTTS without a soft attention mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 05:00:06 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Yasuda", "Yusuke", ""], ["Wang", "Xin", ""], ["Yamagishi", "Junichi", ""]]}, {"id": "1908.11550", "submitter": "Junyi Zou", "authors": "Junyi Zou, Jinliang Zhang, Ludi Wang", "title": "Handwritten Chinese Character Recognition by Convolutional Neural\n  Network and Similarity Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Convolution Neural Networks (CNN) have recently achieved state-of-the art\nperformance on handwritten Chinese character recognition (HCCR). However, most\nof CNN models employ the SoftMax activation function and minimize cross entropy\nloss, which may cause loss of inter-class information. To cope with this\nproblem, we propose to combine cross entropy with similarity ranking function\nand use it as loss function. The experiments results show that the combination\nloss functions produce higher accuracy in HCCR. This report briefly reviews\ncross entropy loss function, a typical similarity ranking function: Euclidean\ndistance, and also propose a new similarity ranking function: Average variance\nsimilarity. Experiments are done to compare the performances of a CNN model\nwith three different loss functions. In the end, SoftMax cross entropy with\nAverage variance similarity produce the highest accuracy on handwritten Chinese\ncharacters recognition.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 06:21:52 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zou", "Junyi", ""], ["Zhang", "Jinliang", ""], ["Wang", "Ludi", ""]]}, {"id": "1908.11553", "submitter": "Junyi Zou", "authors": "Junyi Zou, Jinliang Zhang, Ping Jiang", "title": "Credit Card Fraud Detection Using Autoencoder Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Imbalanced data classification problem has always been a popular topic in the\nfield of machine learning research. In order to balance the samples between\nmajority and minority class. Oversampling algorithm is used to synthesize new\nminority class samples, but it could bring in noise. Pointing to the noise\nproblems, this paper proposed a denoising autoencoder neural network (DAE)\nalgorithm which can not only oversample minority class sample through\nmisclassification cost, but it can denoise and classify the sampled dataset.\nThrough experiments, compared with the denoising autoencoder neural network\n(DAE) with oversampling process and traditional fully connected neural\nnetworks, the results showed the proposed algorithm improves the classification\naccuracy of minority class of imbalanced datasets.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 06:25:26 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Zou", "Junyi", ""], ["Zhang", "Jinliang", ""], ["Jiang", "Ping", ""]]}, {"id": "1908.11567", "submitter": "Tobias Skovgaard Jepsen", "authors": "Tobias Skovgaard Jepsen, Christian S. Jensen, Thomas Dyhre Nielsen", "title": "Graph Convolutional Networks for Road Networks", "comments": "Ten-page pre-print version of a four-page ACM SIGSPATIAL 2019 poster\n  paper", "journal-ref": null, "doi": "10.1145/3347146.3359094", "report-no": null, "categories": "cs.LG cs.DB stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques for road networks hold the potential to\nfacilitate many important transportation applications. Graph Convolutional\nNetworks (GCNs) are neural networks that are capable of leveraging the\nstructure of a road network by utilizing information of, e.g., adjacent road\nsegments. While state-of-the-art GCNs target node classification tasks in\nsocial, citation, and biological networks, machine learning tasks in road\nnetworks differ substantially from such tasks. In road networks, prediction\ntasks concern edges representing road segments, and many tasks involve\nregression. In addition, road networks differ substantially from the networks\nassumed in the GCN literature in terms of the attribute information available\nand the network characteristics. Many implicit assumptions of GCNs do therefore\nnot apply. We introduce the notion of Relational Fusion Network (RFN), a novel\ntype of GCN designed specifically for machine learning on road networks. In\nparticular, we propose methods that outperform state-of-the-art GCNs on both a\nroad segment regression task and a road segment classification task by 32-40%\nand 21-24%, respectively. In addition, we provide experimental evidence of the\nshort-comings of state-of-the-art GCNs in the context of road networks: unlike\nour method, they cannot effectively leverage the road network structure for\nroad segment classification and fail to outperform a regular multi-layer\nperceptron.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 07:08:51 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 09:44:40 GMT"}, {"version": "v3", "created": "Wed, 22 Jul 2020 14:50:54 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Jepsen", "Tobias Skovgaard", ""], ["Jensen", "Christian S.", ""], ["Nielsen", "Thomas Dyhre", ""]]}, {"id": "1908.11598", "submitter": "Adam Richardson", "authors": "Adam Richardson, Aris Filos-Ratsikas, Boi Faltings", "title": "Rewarding High-Quality Data via Influence Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a crowdsourcing data acquisition scenario, such as federated\nlearning, where a Center collects data points from a set of rational Agents,\nwith the aim of training a model. For linear regression models, we show how a\npayment structure can be designed to incentivize the agents to provide\nhigh-quality data as early as possible, based on a characterization of the\ninfluence that data points have on the loss function of the model. Our\ncontributions can be summarized as follows: (a) we prove theoretically that\nthis scheme ensures truthful data reporting as a game-theoretic equilibrium and\nfurther demonstrate its robustness against mixtures of truthful and heuristic\ndata reports, (b) we design a procedure according to which the influence\ncomputation can be efficiently approximated and processed sequentially in\nbatches over time, (c) we develop a theory that allows correcting the\ndifference between the influence and the overall change in loss and (d) we\nevaluate our approach on real datasets, confirming our theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 08:57:18 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Richardson", "Adam", ""], ["Filos-Ratsikas", "Aris", ""], ["Faltings", "Boi", ""]]}, {"id": "1908.11658", "submitter": "Florian Schmidt", "authors": "Florian Schmidt, Stephan Mandt, Thomas Hofmann", "title": "Autoregressive Text Generation Beyond Feedback Loops", "comments": "emnlp camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoregressive state transitions, where predictions are conditioned on past\npredictions, are the predominant choice for both deterministic and stochastic\nsequential models. However, autoregressive feedback exposes the evolution of\nthe hidden state trajectory to potential biases from well-known train-test\ndiscrepancies. In this paper, we combine a latent state space model with a CRF\nobservation model. We argue that such autoregressive observation models form an\ninteresting middle ground that expresses local correlations on the word level\nbut keeps the state evolution non-autoregressive. On unconditional sentence\ngeneration we show performance improvements compared to RNN and GAN baselines\nwhile avoiding some prototypical failure modes of autoregressive models.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 11:31:07 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Schmidt", "Florian", ""], ["Mandt", "Stephan", ""], ["Hofmann", "Thomas", ""]]}, {"id": "1908.11682", "submitter": "Panagiotis Mandros", "authors": "Panagiotis Mandros, Mario Boley, Jilles Vreeken", "title": "Discovering Reliable Correlations in Categorical Data", "comments": "Accepted to the IEEE International Conference on Data Mining 2019\n  (ICDM'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IT math.IT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In many scientific tasks we are interested in discovering whether there exist\nany correlations in our data. This raises many questions, such as how to\nreliably and interpretably measure correlation between a multivariate set of\nattributes, how to do so without having to make assumptions on distribution of\nthe data or the type of correlation, and, how to efficiently discover the\ntop-most reliably correlated attribute sets from data. In this paper we answer\nthese questions for discovery tasks in categorical data.\n  In particular, we propose a corrected-for-chance, consistent, and efficient\nestimator for normalized total correlation, by which we obtain a reliable,\nnaturally interpretable, non-parametric measure for correlation over\nmultivariate sets. For the discovery of the top-k correlated sets, we derive an\neffective algorithmic framework based on a tight bounding function. This\nframework offers exact, approximate, and heuristic search. Empirical evaluation\nshows that already for small sample sizes the estimator leads to low-regret\noptimization outcomes, while the algorithms are shown to be highly effective\nfor both large and high-dimensional data. Through two case studies we confirm\nthat our discovery framework identifies interesting and meaningful\ncorrelations.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 12:18:29 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Mandros", "Panagiotis", ""], ["Boley", "Mario", ""], ["Vreeken", "Jilles", ""]]}, {"id": "1908.11694", "submitter": "Adam Pantanowitz", "authors": "Adam Pantanowitz, Emmanuel Cohen, Philippe Gradidge, Nigel Crowther,\n  Vered Aharonson, Benjamin Rosman, David M Rubin", "title": "Estimation of Body Mass Index from Photographs using Deep Convolutional\n  Neural Networks", "comments": "7 pages, 4 figures, preprint journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obesity is an important concern in public health, and Body Mass Index is one\nof the useful (and proliferant) measures. We use Convolutional Neural Networks\nto determine Body Mass Index from photographs in a study with 161 participants.\nLow data, a common problem in medicine, is addressed by reducing the\ninformation in the photographs by generating silhouette images. Results present\nwith high correlation when tested on unseen data.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 10:33:26 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Pantanowitz", "Adam", ""], ["Cohen", "Emmanuel", ""], ["Gradidge", "Philippe", ""], ["Crowther", "Nigel", ""], ["Aharonson", "Vered", ""], ["Rosman", "Benjamin", ""], ["Rubin", "David M", ""]]}, {"id": "1908.11708", "submitter": "Loc Tran H", "authors": "Loc Tran, Tuan Tran, Linh Tran, An Mai", "title": "Solve fraud detection problem by using graph based learning methods", "comments": "9 pages. arXiv admin note: substantial text overlap with\n  arXiv:1811.02986", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The credit cards' fraud transactions detection is the important problem in\nmachine learning field. To detect the credit cards's fraud transactions help\nreduce the significant loss of the credit cards' holders and the banks. To\ndetect the credit cards' fraud transactions, data scientists normally employ\nthe unsupervised learning techniques and supervised learning techniques. In\nthis paper, we employ the graph p-Laplacian based semi-supervised learning\nmethods combined with the undersampling techniques such as Cluster Centroids to\nsolve the credit cards' fraud transactions detection problem. Experimental\nresults show that the graph p-Laplacian semi-supervised learning methods\noutperform the current state of the art graph Laplacian based semi-supervised\nlearning method (p=2).\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 04:04:56 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Tran", "Loc", ""], ["Tran", "Tuan", ""], ["Tran", "Linh", ""], ["Mai", "An", ""]]}, {"id": "1908.11775", "submitter": "Yao-Hung Tsai", "authors": "Yao-Hung Hubert Tsai and Shaojie Bai and Makoto Yamada and\n  Louis-Philippe Morency and Ruslan Salakhutdinov", "title": "Transformer Dissection: A Unified Understanding of Transformer's\n  Attention via the Lens of Kernel", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer is a powerful architecture that achieves superior performance on\nvarious sequence learning tasks, including neural machine translation, language\nunderstanding, and sequence prediction. At the core of the Transformer is the\nattention mechanism, which concurrently processes all inputs in the streams. In\nthis paper, we present a new formulation of attention via the lens of the\nkernel. To be more precise, we realize that the attention can be seen as\napplying kernel smoother over the inputs with the kernel scores being the\nsimilarities between inputs. This new formulation gives us a better way to\nunderstand individual components of the Transformer's attention, such as the\nbetter way to integrate the positional embedding. Another important advantage\nof our kernel-based formulation is that it paves the way to a larger space of\ncomposing Transformer's attention. As an example, we propose a new variant of\nTransformer's attention which models the input as a product of symmetric\nkernels. This approach achieves competitive performance to the current state of\nthe art model with less computation. In our experiments, we empirically study\ndifferent kernel construction strategies on two widely used tasks: neural\nmachine translation and sequence prediction.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 15:05:02 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 21:16:58 GMT"}, {"version": "v3", "created": "Mon, 4 Nov 2019 16:40:11 GMT"}, {"version": "v4", "created": "Mon, 11 Nov 2019 21:51:11 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Tsai", "Yao-Hung Hubert", ""], ["Bai", "Shaojie", ""], ["Yamada", "Makoto", ""], ["Morency", "Louis-Philippe", ""], ["Salakhutdinov", "Ruslan", ""]]}, {"id": "1908.11823", "submitter": "Alexander Mey", "authors": "Alexander Mey and Marco Loog", "title": "Consistency and Finite Sample Behavior of Binary Class Probability\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we investigate to which extent one can recover class\nprobabilities within the empirical risk minimization (ERM) paradigm. The main\naim of our paper is to extend existing results and emphasize the tight\nrelations between empirical risk minimization and class probability estimation.\nBased on existing literature on excess risk bounds and proper scoring rules, we\nderive a class probability estimator based on empirical risk minimization. We\nthen derive fairly general conditions under which this estimator will converge,\nin the L1-norm and in probability, to the true class probabilities. Our main\ncontribution is to present a way to derive finite sample L1-convergence rates\nof this estimator for different surrogate loss functions. We also study in\ndetail which commonly used loss functions are suitable for this estimation\nproblem and finally discuss the setting of model-misspecification as well as a\npossible extension to asymmetric loss functions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 16:22:19 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 11:29:35 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 07:55:05 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Mey", "Alexander", ""], ["Loog", "Marco", ""]]}, {"id": "1908.11833", "submitter": "Avinash Barnwal", "authors": "Avinash Barnwal", "title": "Network Elastic Net for Identifying Smoking specific gene expression for\n  lung cancer", "comments": "Published on Proceedings of IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Survival month for non-small lung cancer patients depend upon which stage of\nlung cancer is present. Our aim is to identify smoking specific gene expression\nbiomarkers in the prognosis of lung cancer patients. In this paper, we\nintroduce the network elastic net, a generalization of network lasso that\nallows for simultaneous clustering and regression on graphs. In Network elastic\nnet, we consider similar patients based on smoking cigarettes per year to form\nthe network. We then further find the suitable cluster among patients based on\ncoefficients of genes having different survival month structures and showed the\nefficacy of the clusters using stage enrichment. This can be used to identify\nthe stage of cancer using gene expression and smoking behavior of patients\nwithout doing any tests.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 16:46:35 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Barnwal", "Avinash", ""]]}, {"id": "1908.11843", "submitter": "Tiffany Vlaar", "authors": "Benedict Leimkuhler, Charles Matthews and Tiffany Vlaar", "title": "Partitioned integrators for thermodynamic parameterization of neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, neural networks are parameterized using optimization\nprocedures such as stochastic gradient descent, RMSProp and ADAM. These\nprocedures tend to drive the parameters of the network toward a local minimum.\nIn this article, we employ alternative \"sampling\" algorithms (referred to here\nas \"thermodynamic parameterization methods\") which rely on discretized\nstochastic differential equations for a defined target distribution on\nparameter space. We show that the thermodynamic perspective already improves\nneural network training. Moreover, by partitioning the parameters based on\nnatural layer structure we obtain schemes with very rapid convergence for data\nsets with complicated loss landscapes.\n  We describe easy-to-implement hybrid partitioned numerical algorithms, based\non discretized stochastic differential equations, which are adapted to\nfeed-forward neural networks, including a multi-layer Langevin algorithm,\nAdLaLa (combining the adaptive Langevin and Langevin algorithms) and LOL\n(combining Langevin and Overdamped Langevin); we examine the convergence of\nthese methods using numerical studies and compare their performance among\nthemselves and in relation to standard alternatives such as stochastic gradient\ndescent and ADAM. We present evidence that thermodynamic parameterization\nmethods can be (i) faster, (ii) more accurate, and (iii) more robust than\nstandard algorithms used within machine learning frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:12:56 GMT"}, {"version": "v2", "created": "Sun, 5 Jan 2020 21:15:43 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Leimkuhler", "Benedict", ""], ["Matthews", "Charles", ""], ["Vlaar", "Tiffany", ""]]}, {"id": "1908.11848", "submitter": "Bao Xin Chen", "authors": "Xing Zhao and Aijun An and Junfeng Liu and Bao Xin Chen", "title": "Dynamic Stale Synchronous Parallel Distributed Training for Deep\n  Learning", "comments": null, "journal-ref": "2019 IEEE 39th International Conference on Distributed Computing\n  Systems (ICDCS)", "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is a popular machine learning technique and has been applied to\nmany real-world problems. However, training a deep neural network is very\ntime-consuming, especially on big data. It has become difficult for a single\nmachine to train a large model over large datasets. A popular solution is to\ndistribute and parallelize the training process across multiple machines using\nthe parameter server framework. In this paper, we present a distributed\nparadigm on the parameter server framework called Dynamic Stale Synchronous\nParallel (DSSP) which improves the state-of-the-art Stale Synchronous Parallel\n(SSP) paradigm by dynamically determining the staleness threshold at the run\ntime. Conventionally to run distributed training in SSP, the user needs to\nspecify a particular staleness threshold as a hyper-parameter. However, a user\ndoes not usually know how to set the threshold and thus often finds a threshold\nvalue through trial and error, which is time-consuming. Based on workers'\nrecent processing time, our approach DSSP adaptively adjusts the threshold per\niteration at running time to reduce the waiting time of faster workers for\nsynchronization of the globally shared parameters, and consequently increases\nthe frequency of parameters updates (increases iteration throughput), which\nspeedups the convergence rate. We compare DSSP with other paradigms such as\nBulk Synchronous Parallel (BSP), Asynchronous Parallel (ASP), and SSP by\nrunning deep neural networks (DNN) models over GPU clusters in both homogeneous\nand heterogeneous environments. The results show that in a heterogeneous\nenvironment where the cluster consists of mixed models of GPUs, DSSP converges\nto a higher accuracy much earlier than SSP and BSP and performs similarly to\nASP. In a homogeneous distributed cluster, DSSP has more stable and slightly\nbetter performance than SSP and ASP, and converges much faster than BSP.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 23:03:45 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Zhao", "Xing", ""], ["An", "Aijun", ""], ["Liu", "Junfeng", ""], ["Chen", "Bao Xin", ""]]}, {"id": "1908.11853", "submitter": "Evgenii Egorov", "authors": "Anna Kuzina, Evgenii Egorov, Evgeny Burnaev", "title": "BooVAE: Boosting Approach for Continual Learning of VAE", "comments": "14 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoder (VAE) is a deep generative model for unsupervised\nlearning, allowing to encode observations into the meaningful latent space. VAE\nis prone to catastrophic forgetting when tasks arrive sequentially, and only\nthe data for the current one is available. We address this problem of continual\nlearning for VAEs. It is known that the choice of the prior distribution over\nthe latent space is crucial for VAE in the non-continual setting. We argue that\nit can also be helpful to avoid catastrophic forgetting. We learn the\napproximation of the aggregated posterior as a prior for each task. This\napproximation is parametrised as an additive mixture of distributions induced\nby encoder evaluated at trainable pseudo-inputs. We use a greedy boosting-like\napproach with entropy regularisation to learn the components. This method\nencourages components diversity, which is essential as we aim at memorising the\ncurrent task with the fewest components possible. Based on the learnable prior,\nwe introduce an end-to-end approach for continual learning of VAEs and provide\nempirical studies on commonly used benchmarks (MNIST, Fashion MNIST, NotMNIST)\nand CelebA datasets. For each dataset, the proposed method avoids catastrophic\nforgetting in a fully automatic way.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:26:03 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 19:26:50 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kuzina", "Anna", ""], ["Egorov", "Evgenii", ""], ["Burnaev", "Evgeny", ""]]}, {"id": "1908.11863", "submitter": "Rohan Akut Mr", "authors": "Rohan Akut, Sumukh Marathe, Rucha Apte, Ishan Joshi, Siddhivinayak\n  Kulkarni", "title": "Systematic Analysis of Image Generation using GANs", "comments": "Accepted in IEEE ICMLDS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks have been crucial in the developments made in\nunsupervised learning in recent times. Exemplars of image synthesis from text\nor other images, these networks have shown remarkable improvements over\nconventional methods in terms of performance. Trained on the adversarial\ntraining philosophy, these networks aim to estimate the potential distribution\nfrom the real data and then use this as input to generate the synthetic data.\nBased on this fundamental principle, several frameworks can be generated that\nare paragon implementations in several real-life applications such as art\nsynthesis, generation of high resolution outputs and synthesis of images from\nhuman drawn sketches, to name a few. While theoretically GANs present better\nresults and prove to be an improvement over conventional methods in many\nfactors, the implementation of these frameworks for dedicated applications\nremains a challenge. This study explores and presents a taxonomy of these\nframeworks and their use in various image to image synthesis and text to image\nsynthesis applications. The basic GANs, as well as a variety of different niche\nframeworks, are critically analyzed. The advantages of GANs for image\ngeneration over conventional methods as well their disadvantages amongst other\nframeworks are presented. The future applications of GANs in industries such as\nhealthcare, art and entertainment are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:48:05 GMT"}], "update_date": "2019-09-02", "authors_parsed": [["Akut", "Rohan", ""], ["Marathe", "Sumukh", ""], ["Apte", "Rucha", ""], ["Joshi", "Ishan", ""], ["Kulkarni", "Siddhivinayak", ""]]}]