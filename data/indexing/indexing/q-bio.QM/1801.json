[{"id": "1801.00030", "submitter": "Hossein Babashah", "authors": "Ehsan Maleki, Hossein Babashah, Somayyeh Koohi, Zahra Kavehvash", "title": "High Speed All-optical extended DV-Curve-based DNA sequence alignment\n  utilizing wavelength and polarization modulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel optical processing approach for exploring genome\nsequences built upon optical correlator for global alignment and extended\nDV-curve method for local alignment. To overcome the problem of traditional\nDV-curve method for presenting an accurate and simplified output, we propose\nHAWPOD, built upon DV- curve method, to analyze genome sequences in five steps:\nDNA coding, alignment, noise cancellation, simplification, and modification.\nMoreover, all-optical implementation of the HAWPOD method is developed, while\nits accuracy is validated through numerical simulations in LUMERICAL FDTD. The\nresults express the proposed method is much faster than its electrical\ncounterparts, such as Basic Local Alignment Search Tools.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 01:19:25 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Maleki", "Ehsan", ""], ["Babashah", "Hossein", ""], ["Koohi", "Somayyeh", ""], ["Kavehvash", "Zahra", ""]]}, {"id": "1801.00065", "submitter": "Alvaro Ulloa Cerna", "authors": "Alvaro Ulloa, Anna Basile, Gregory J. Wehner, Linyuan Jing, Marylyn D.\n  Ritchie, Brett Beaulieu-Jones, Christopher M. Haggerty, Brandon K. Fornwalt", "title": "An Unsupervised Homogenization Pipeline for Clustering Similar Patients\n  using Electronic Health Record Data", "comments": "conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic health records (EHR) contain a large variety of information on the\nclinical history of patients such as vital signs, demographics, diagnostic\ncodes and imaging data. The enormous potential for discovery in this rich\ndataset is hampered by its complexity and heterogeneity.\n  We present the first study to assess unsupervised homogenization pipelines\ndesigned for EHR clustering. To identify the optimal pipeline, we tested\naccuracy on simulated data with varying amounts of redundancy, heterogeneity,\nand missingness. We identified two optimal pipelines: 1) Multiple Imputation by\nChained Equations (MICE) combined with Local Linear Embedding; and 2) MICE,\nZ-scoring, and Deep Autoencoders.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 01:06:14 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 14:46:41 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Ulloa", "Alvaro", ""], ["Basile", "Anna", ""], ["Wehner", "Gregory J.", ""], ["Jing", "Linyuan", ""], ["Ritchie", "Marylyn D.", ""], ["Beaulieu-Jones", "Brett", ""], ["Haggerty", "Christopher M.", ""], ["Fornwalt", "Brandon K.", ""]]}, {"id": "1801.00257", "submitter": "Martin Frasch", "authors": "Martin G. Frasch, Silvia Lobmaier, Tamara Stampalija, Paula Desplats,\n  Mar\\'ia Eugenia Pallar\\'es, Ver\\'onica Pastor, Marcela Brocco, Hau-tieng Wu,\n  Jay Schulkin, Christophe Herry, Andrew Seely, Gerlinde A.S. Metz, Yoram\n  Louzoun, Marta Antonelli", "title": "Non-invasive biomarkers of fetal brain development reflecting prenatal\n  stress: an integrative multi-scale multi-species perspective on data\n  collection and analysis", "comments": "Focused review, 13 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.neubiorev.2018.05.026", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Prenatal stress (PS) impacts early postnatal behavioural and cognitive\ndevelopment. This process of 'fetal programming' is mediated by the effects of\nthe prenatal experience on the developing hypothalamic-pituitary-adrenal (HPA)\naxis and autonomic nervous system (ANS). The HPA axis is a dynamic system\nregulating homeostasis, especially the stress response, and is highly sensitive\nto adverse early life experiences. We review the evidence for the effects of PS\non fetal programming of the HPA axis and the ANS. We derive a multi-scale\nmulti-species approach to devising preclinical and clinical studies to identify\nearly non-invasively available pre- and postnatal biomarkers of these\nprogramming effects. Such approach would identify adverse postnatal brain\ndevelopmental trajectories, a prerequisite for designing therapeutic\ninterventions. The multiple scales include the biomarkers reflecting changes in\nthe brain epigenome, metabolome, microbiome and the ANS activity gauged via an\narray of advanced non-invasively obtainable properties of fetal heart rate\nfluctuations. The proposed framework has the potential to reveal mechanistic\nlinks between maternal stress during pregnancy and changes across these\nphysiological scales. Such biomarkers may hence be useful as early and\nnon-invasive predictors of neurodevelopmental trajectories influenced by the\nPS. We conclude that studies into PS effects must be conducted on multiple\nscales derived from concerted observations in multiple animal models and human\ncohorts performed in an interactive and iterative manner and deploying machine\nlearning for data synthesis, identification and validation of the best\nnon-invasive biomarkers.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 09:20:09 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Frasch", "Martin G.", ""], ["Lobmaier", "Silvia", ""], ["Stampalija", "Tamara", ""], ["Desplats", "Paula", ""], ["Pallar\u00e9s", "Mar\u00eda Eugenia", ""], ["Pastor", "Ver\u00f3nica", ""], ["Brocco", "Marcela", ""], ["Wu", "Hau-tieng", ""], ["Schulkin", "Jay", ""], ["Herry", "Christophe", ""], ["Seely", "Andrew", ""], ["Metz", "Gerlinde A. S.", ""], ["Louzoun", "Yoram", ""], ["Antonelli", "Marta", ""]]}, {"id": "1801.00567", "submitter": "Paul M\\\"uller", "authors": "Paul M\\\"uller, Mirjam Sch\\\"urmann, Chii J. Chan, and Jochen Guck", "title": "Single-cell diffraction tomography with optofluidic rotation about a\n  tilted axis", "comments": "7 pages, 3 figures", "journal-ref": "SPIE Proceedings Volume 9548, 95480U (2015)", "doi": "10.1117/12.2191501", "report-no": null, "categories": "q-bio.QM physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical diffraction tomography (ODT) is a tomographic technique that can be\nused to measure the three-dimensional (3D) refractive index distribution within\nliving cells without the requirement of any marker. In principle, ODT can be\nregarded as a generalization of optical projection tomography which is\nequivalent to computerized tomography (CT). Both optical tomographic techniques\nrequire projection-phase images of cells measured at multiple angles. However,\nthe reconstruction of the 3D refractive index distribution post-measurement\ndiffers for the two techniques. It is known that ODT yields better results than\nprojection tomography, because it takes into account diffraction of the imaging\nlight due to the refractive index structure of the sample. Here, we apply ODT\nto biological cells in a microfluidic chip which combines optical trapping and\nmicrofluidic flow to achieve an optofluidic single-cell rotation. In\nparticular, we address the problem that arises when the trapped cell is not\nrotating about an axis perpendicular to the imaging plane, but instead about an\narbitrarily tilted axis. In this paper we show that the 3D reconstruction can\nbe improved by taking into account such a tilted rotational axis in the\nreconstruction process.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 07:44:19 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["M\u00fcller", "Paul", ""], ["Sch\u00fcrmann", "Mirjam", ""], ["Chan", "Chii J.", ""], ["Guck", "Jochen", ""]]}, {"id": "1801.01019", "submitter": "Nghia (Andy) Nguyen", "authors": "Christine A. Liang, Lei Chen, Amer Wahed, Andy N.D. Nguyen", "title": "Proteomics Analysis of FLT3-ITD Mutation in Acute Myeloid Leukemia Using\n  Deep Learning Neural Network", "comments": "12 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning can significantly benefit cancer proteomics and genomics. In\nthis study, we attempt to determine a set of critical proteins that are\nassociated with the FLT3-ITD mutation in newly-diagnosed acute myeloid leukemia\npatients. A Deep Learning network consisting of autoencoders forming a\nhierarchical model from which high-level features are extracted without labeled\ntraining data. Dimensional reduction reduced the number of critical proteins\nfrom 231 to 20. Deep Learning found an excellent correlation between FLT3-ITD\nmutation with the levels of these 20 critical proteins (accuracy 97%,\nsensitivity 90%, specificity 100%). Our Deep Learning network could hone in on\n20 proteins with the strongest association with FLT3-ITD. The results of this\nstudy allow a novel approach to determine critical protein pathways in the\nFLT3-ITD mutation, and provide proof-of-concept for an accurate approach to\nmodel big data in cancer proteomics and genomics.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 13:05:30 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Liang", "Christine A.", ""], ["Chen", "Lei", ""], ["Wahed", "Amer", ""], ["Nguyen", "Andy N. D.", ""]]}, {"id": "1801.01539", "submitter": "Fatema Zohora", "authors": "Fatema Tuz Zohora, Ngoc Hieu Tran, Xianglilan Zhang, Lei Xin, Baozhen\n  Shan, and Ming Li", "title": "DeepIso: A Deep Learning Model for Peptide Feature Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.NE physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Liquid chromatography with tandem mass spectrometry (LC-MS/MS) based\nproteomics is a well-established research field with major applications such as\nidentification of disease biomarkers, drug discovery, drug design and\ndevelopment. In proteomics, protein identification and quantification is a\nfundamental task, which is done by first enzymatically digesting it into\npeptides, and then analyzing peptides by LC-MS/MS instruments. The peptide\nfeature detection and quantification from an LC-MS map is the first step in\ntypical analysis workflows. In this paper we propose a novel deep learning\nbased model, DeepIso, that uses Convolutional Neural Networks (CNNs) to scan an\nLC-MS map to detect peptide features and estimate their abundance. Existing\ntools are often designed with limited engineered features based on domain\nknowledge, and depend on pretrained parameters which are hardly updated despite\nhuge amount of new coming proteomic data. Our proposed model, on the other\nhand, is capable of learning multiple levels of representation of high\ndimensional data through its many layers of neurons and continuously evolving\nwith newly acquired data. To evaluate our proposed model, we use an antibody\ndataset including a heavy and a light chain, each digested by Asp-N,\nChymotrypsin, Trypsin, thus giving six LC-MS maps for the experiment. Our model\nachieves 93.21% sensitivity with specificity of 99.44% on this dataset. Our\nresults demonstrate that novel deep learning tools are desirable to advance the\nstate-of-the-art in protein identification and quantification.\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 04:55:39 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Zohora", "Fatema Tuz", ""], ["Tran", "Ngoc Hieu", ""], ["Zhang", "Xianglilan", ""], ["Xin", "Lei", ""], ["Shan", "Baozhen", ""], ["Li", "Ming", ""]]}, {"id": "1801.01558", "submitter": "Kedi Wu", "authors": "Kedi Wu, Zhixiong Zhao, Renxiao Wang, Guo-Wei Wei", "title": "TopP-S: Persistent homology based multi-task deep neural networks for\n  simultaneous predictions of partition coefficient and aqueous solubility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aqueous solubility and partition coefficient are important physical\nproperties of small molecules. Accurate theoretical prediction of aqueous\nsolubility and partition coefficient plays an important role in drug design and\ndiscovery. The prediction accuracy depends crucially on molecular descriptors\nwhich are typically derived from theoretical understanding of the chemistry and\nphysics of small molecules. The present work introduces an algebraic topology\nbased method, called element specific persistent homology (ESPH), as a new\nrepresentation of small molecules that is entirely different from conventional\nchemical and/or physical representations. ESPH describes molecular properties\nin terms of multiscale and multicomponent topological invariants. Such\ntopological representation is systematical, comprehensive, and scalable with\nrespect to molecular size and composition variations. However, it cannot be\nliterally translated into a physical interpretation. Fortunately, it is readily\nsuitable for machine learning methods, rendering topological learning\nalgorithms. Due to the inherent correlation between solubility and partition\ncoefficient, a uniform ESPH representation is developed for both properties,\nwhich facilitates multi-task deep neural networks for their simultaneous\npredictions. This strategy leads to more accurate prediction of relatively\nsmall data sets. A total of six data sets is considered in the present work to\nvalidate the proposed topological and multi-task deep learning approaches. It\nis demonstrate that the proposed approaches achieve some of the most accurate\npredictions of aqueous solubility and partition coefficient. Our software is\navailable online at {\\url{http://weilab.math.msu.edu/TopP-S/}}\n", "versions": [{"version": "v1", "created": "Sat, 9 Dec 2017 22:03:53 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Wu", "Kedi", ""], ["Zhao", "Zhixiong", ""], ["Wang", "Renxiao", ""], ["Wei", "Guo-Wei", ""]]}, {"id": "1801.01841", "submitter": "Rachel Jeitziner", "authors": "Rachel Jeitziner and Mathieu Carri\\`ere and Jacques Rougemont and\n  Steve Oudot and Kathryn Hess and Cathrin Brisken", "title": "Two-Tier Mapper: a user-independent clustering method for global gene\n  expression analysis based on topology", "comments": "Article 11 pages, supplementary material 29 pages (total of 40\n  pages), 4 figures, 4 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN math.AT q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing need for unbiased clustering methods, ideally automated.\nWe have developed a topology-based analysis tool called Two-Tier Mapper (TTMap)\nto detect subgroups in global gene expression datasets and identify their\ndistinguishing features. First, TTMap discerns and adjusts for highly variable\nfeatures in the control group and identifies outliers. Second, the deviation of\neach test sample from the control group in a high-dimensional space is computed\nand the test samples are clustered in a global and local network using a new\ntopological algorithm based on Mapper. Validation of TTMap on both synthetic\nand biological datasets shows that it outperforms current clustering methods in\nsensitivity and stability; clustering is not affected by removal of samples\nfrom the control group, choice of normalization nor subselection of data. There\nis no user induced bias because all parameters are data-driven. Datasets can\nreadily be combined into one analysis. TTMap reveals hitherto undetected gene\nexpression changes in mouse mammary glands related to hormonal changes during\nthe estrous cycle. This illustrates the ability to extract information from\nhighly variable biological samples and its potential for personalized medicine.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 16:08:56 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Jeitziner", "Rachel", ""], ["Carri\u00e8re", "Mathieu", ""], ["Rougemont", "Jacques", ""], ["Oudot", "Steve", ""], ["Hess", "Kathryn", ""], ["Brisken", "Cathrin", ""]]}, {"id": "1801.01861", "submitter": "Adriano Barra Dr.", "authors": "Elena Agliari, Adriano Barra, Giulio Landolfi, Sara Murciano, Sarah\n  Perrone", "title": "Complex Reaction Kinetics in Chemistry: A unified picture suggested by\n  Mechanics in Physics", "comments": null, "journal-ref": "Complexity 2018", "doi": null, "report-no": "Roma01.Math", "categories": "q-bio.QM cond-mat.dis-nn physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex biochemical pathways or regulatory enzyme kinetics can be reduced to\nchains of elementary reactions, which can be described in terms of chemical\nkinetics. This discipline provides a set of tools for quantifying and\nunderstanding the dialogue between reactants, whose framing into a solid and\nconsistent mathematical description is of pivotal importance in the growing\nfield of biotechnology. Among the elementary reactions so far extensively\ninvestigated, we recall the socalled Michaelis-Menten scheme and the Hill\npositive-cooperative kinetics, which apply to molecular binding and are\ncharacterized by the absence and the presence, respectively, of cooperative\ninteractions between binding sites, giving rise to qualitative different\nphenomenologies. However, there is evidence of reactions displaying a more\ncomplex, and by far less understood, pattern: these follow the\npositive-cooperative scenario at small substrate concentration, yet\nnegative-cooperative effects emerge and get stronger as the substrate\nconcentration is increased. In this paper we analyze the structural analogy\nbetween the mathematical backbone of (classical) reaction kinetics in Chemistry\nand that of (classical) mechanics in Physics: techniques and results from the\nlatter shall be used to infer properties on the former.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 18:19:35 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Agliari", "Elena", ""], ["Barra", "Adriano", ""], ["Landolfi", "Giulio", ""], ["Murciano", "Sara", ""], ["Perrone", "Sarah", ""]]}, {"id": "1801.01876", "submitter": "Yi Sun", "authors": "Yi Sun", "title": "Root Mean Square Minimum Distance as a Quality Metric for Localization\n  Nanoscopy Images", "comments": "11 pages, 5 figures", "journal-ref": "Y. Sun, \"Root mean square minimum distance as a quality metric for\n  stochastic optical localization nanoscopy images,\" Scientific Reports, 8(1),\n  Nov. 21, 2018", "doi": "10.1038/s41598-018-35053-8", "report-no": null, "categories": "q-bio.QM eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A localization algorithm in stochastic optical localization nanoscopy plays\nan important role in obtaining a high-quality image. A universal and objective\nmetric is crucial and necessary to evaluate qualities of nanoscopy images and\nperformances of localization algorithms. In this paper, we propose root mean\nsquare minimum distance (RMSMD) as a quality metric for localization nanoscopy\nimages. RMSMD measures an average, local, and mutual fitness between two sets\nof points. Its properties common to a distance metric as well as unique to\nitself are presented. The ambiguity, discontinuity, and inappropriateness of\nthe metrics of accuracy, precision, recall, and Jaccard index, which are\ncurrently used in the literature, are analyzed. A numerical example\ndemonstrates the advantages of RMSMD over the four existing metrics that fail\nto distinguish qualities of different nanoscopy images in certain conditions.\nThe unbiased Gaussian estimator that achieves the Fisher information and\nCramer-Rao lower bound (CRLB) of a single data frame is proposed to benchmark\nthe quality of localization nanoscopy images and the performance of\nlocalization algorithms. The information-achieving estimator is simulated in an\nexample and the result demonstrates the superior sensitivity of RMSMD over the\nother four metrics. As a universal and objective metric, RMSMD can be broadly\nemployed in various applications to measure the mutual fitness of two sets of\npoints.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 13:34:51 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 18:04:04 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 17:58:02 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Sun", "Yi", ""]]}, {"id": "1801.02068", "submitter": "Mircea Andrecut Dr", "authors": "M. Andrecut", "title": "On the inherent competition between valid and spurious inductive\n  inferences in Boolean data", "comments": "12 pages, 2 figures, Int. J. Mod. Phys. C, 2017", "journal-ref": null, "doi": "10.1142/S0129183117501467", "report-no": null, "categories": "physics.data-an cs.AI cs.LO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inductive inference is the process of extracting general rules from specific\nobservations. This problem also arises in the analysis of biological networks,\nsuch as genetic regulatory networks, where the interactions are complex and the\nobservations are incomplete. A typical task in these problems is to extract\ngeneral interaction rules as combinations of Boolean covariates, that explain a\nmeasured response variable. The inductive inference process can be considered\nas an incompletely specified Boolean function synthesis problem. This\nincompleteness of the problem will also generate spurious inferences, which are\na serious threat to valid inductive inference rules. Using random Boolean data\nas a null model, here we attempt to measure the competition between valid and\nspurious inductive inference rules from a given data set. We formulate two\ngreedy search algorithms, which synthesize a given Boolean response variable in\na sparse disjunct normal form, and respectively a sparse generalized algebraic\nnormal form of the variables from the observation data, and we evaluate\nnumerically their performance.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jan 2018 19:06:15 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Andrecut", "M.", ""]]}, {"id": "1801.02430", "submitter": "Mukhtiar Ali Unar Unar", "authors": "Shahram Najam Syed, Aamir Zeb Shaikh, Shabbar Naqvi", "title": "A Novel Hybrid Biometric Electronic Voting System: Integrating Finger\n  Print and Face Recognition", "comments": null, "journal-ref": "Mehran University Research Journal of Engineering and Technology,\n  Mehran University Research Journal of Engineering and Technology, 2018, 37\n  (1), pp.59-68.\n  http://publications.muet.edu.pk/index.php/muetrj/article/view/100/50", "doi": null, "report-no": null, "categories": "cs.CR cs.CY q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel hybrid design based electronic voting system is proposed, implemented\nand analyzed. The proposed system uses two voter verification techniques to\ngive better results in comparison to single identification based systems.\nFinger print and facial recognition based methods are used for voter\nidentification. Cross verification of a voter during an election process\nprovides better accuracy than single parameter identification method. The\nfacial recognition system uses Viola-Jones algorithm along with rectangular\nHaar feature selection method for detection and extraction of features to\ndevelop a biometric template and for feature extraction during the voting\nprocess. Cascaded machine learning based classifiers are used for comparing the\nfeatures for identity verification using GPCA (Generalized Principle Component\nAnalysis) and K-NN (K-Nearest Neighbor). It is accomplished through comparing\nthe Eigen-vectors of the extracted features with the biometric template\npre-stored in the election regulatory body database. The results of the\nproposed system show that the proposed cascaded design based system performs\nbetter than the systems using other classifiers or separate schemes i.e. facial\nor finger print based schemes. The proposed system will be highly useful for\nreal time applications due to the reason that it has 91% accuracy under nominal\nlight in terms of facial recognition. with bags of paper votes. The central\nstation compiles and publishes the names of winners and losers through\ntelevision and radio stations. This method is useful only if the whole process\nis completed in a transparent way. However, there are some drawbacks to this\nsystem. These include higher expenses, longer time to complete the voting\nprocess, fraudulent practices by the authorities administering elections as\nwell as malpractices by the voters [1]. These challenges result in manipulated\nelection results.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 07:57:29 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Syed", "Shahram Najam", ""], ["Shaikh", "Aamir Zeb", ""], ["Naqvi", "Shabbar", ""]]}, {"id": "1801.02591", "submitter": "Mojtaba Sedigh Fazli", "authors": "Mojtaba S. Fazli, Stephen A.Vella, Silvia N.J. Moreno and Shannon\n  Quinn", "title": "Unsupervised Discovery of Toxoplasma gondii Motility Phenotypes", "comments": "4 pages, Accepted to 2018 IEEE International Symposium on Biomedical\n  Imaging", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Toxoplasma gondii is a parasitic protozoan that causes dis- seminated\ntoxoplasmosis, a disease that afflicts roughly a third of the worlds\npopulation. Its virulence is predicated on its motility and ability to enter\nand exit nucleated cells; therefore, studies elucidating its mechanism of\nmotility and in particular, its motility patterns in the context of its lytic\ncycle, are critical to the eventual development of therapeutic strate- gies.\nHere, we present an end-to-end computational pipeline for identifying T. gondii\nmotility phenotypes in a completely unsupervised, data-driven way. We track the\nparasites before and after addition of extracellular Ca2+ to study its effects\non the parasite motility patterns and use this information to parameterize the\nmotion and group it according to similarity of spatiotemporal dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 18:04:00 GMT"}, {"version": "v2", "created": "Thu, 11 Jan 2018 19:04:18 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Fazli", "Mojtaba S.", ""], ["Vella", "Stephen A.", ""], ["Moreno", "Silvia N. J.", ""], ["Quinn", "Shannon", ""]]}, {"id": "1801.02665", "submitter": "Wenpo Yao", "authors": "Wenpo Yao Wenli Yao and Jun Wang", "title": "Symbolic relative entropy in quantifying nonlinear dynamics of\n  equalities-involved heartbeats", "comments": "The theory underlying the symbolic relative entropy on nonlinear\n  dynamics in our manuscript might lead somewhat misleading and is needed\n  further analysis and discussions", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Symbolic relative entropy, an efficient nonlinear complexity parameter\nmeasuring probabilistic divergences of symbolic sequences, is proposed in our\nnonlinear dynamics analysis of heart rates considering equal states. Equalities\nare not rare in discrete heartbeats because of the limits of resolution of\nsignals collection, and more importantly equal states contain underlying\nimportant cardiac regulation information which is neglected by some chaotic\ndeterministic parameters and temporal asymmetric measurements. The relative\nentropy of symbolization associated with equal states has satisfied nonlinear\ndynamics complexity detections in heartbeats and shows advantages to some\nnonlinear dynamics parameters without considering equalities. Researches on\ncardiac activities suggest the highest probabilistic divergence of the healthy\nyoung heart rates and highlight the facts that heart diseases and aging reduce\nthe nonlinear dynamical complexity of heart rates.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 12:26:45 GMT"}, {"version": "v2", "created": "Sun, 21 Jan 2018 02:52:22 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 04:32:18 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Yao", "Wenpo Yao Wenli", ""], ["Wang", "Jun", ""]]}, {"id": "1801.02736", "submitter": "Brenden Petersen", "authors": "Brenden K. Petersen, Michael B. Mayhew, Kalvin O. E. Ogbuefi, John D.\n  Greene, Vincent X. Liu, Priyadip Ray", "title": "Modeling sepsis progression using hidden Markov models", "comments": "Accepted to NIPS ML4H 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing a patient's progression through stages of sepsis is critical\nfor enabling risk stratification and adaptive, personalized treatment. However,\ncommonly used sepsis diagnostic criteria fail to account for significant\nunderlying heterogeneity, both between patients as well as over time in a\nsingle patient. We introduce a hidden Markov model of sepsis progression that\nexplicitly accounts for patient heterogeneity. Benchmarked against two sepsis\ndiagnostic criteria, the model provides a useful tool to uncover a patient's\nlatent sepsis trajectory and to identify high-risk patients in whom more\naggressive therapy may be indicated.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 01:02:32 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Petersen", "Brenden K.", ""], ["Mayhew", "Michael B.", ""], ["Ogbuefi", "Kalvin O. E.", ""], ["Greene", "John D.", ""], ["Liu", "Vincent X.", ""], ["Ray", "Priyadip", ""]]}, {"id": "1801.03230", "submitter": "Sarfaraz Hussein", "authors": "Sarfaraz Hussein, Pujan Kandel, Candice W. Bolan, Michael B. Wallace,\n  and Ulas Bagci", "title": "Lung and Pancreatic Tumor Characterization in the Deep Learning Era:\n  Novel Supervised and Unsupervised Learning Approaches", "comments": "Accepted for publication in IEEE Transactions on Medical Imaging 2019", "journal-ref": null, "doi": "10.1109/TMI.2019.2894349", "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk stratification (characterization) of tumors from radiology images can be\nmore accurate and faster with computer-aided diagnosis (CAD) tools. Tumor\ncharacterization through such tools can also enable non-invasive cancer\nstaging, prognosis, and foster personalized treatment planning as a part of\nprecision medicine. In this study, we propose both supervised and unsupervised\nmachine learning strategies to improve tumor characterization. Our first\napproach is based on supervised learning for which we demonstrate significant\ngains with deep learning algorithms, particularly by utilizing a 3D\nConvolutional Neural Network and Transfer Learning. Motivated by the\nradiologists' interpretations of the scans, we then show how to incorporate\ntask dependent feature representations into a CAD system via a\ngraph-regularized sparse Multi-Task Learning (MTL) framework. In the second\napproach, we explore an unsupervised learning algorithm to address the limited\navailability of labeled training data, a common problem in medical imaging\napplications. Inspired by learning from label proportion (LLP) approaches in\ncomputer vision, we propose to use proportion-SVM for characterizing tumors. We\nalso seek the answer to the fundamental question about the goodness of \"deep\nfeatures\" for unsupervised tumor classification. We evaluate our proposed\nsupervised and unsupervised learning algorithms on two different tumor\ndiagnosis challenges: lung and pancreas with 1018 CT and 171 MRI scans,\nrespectively, and obtain the state-of-the-art sensitivity and specificity\nresults in both problems.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 03:47:07 GMT"}, {"version": "v2", "created": "Sun, 29 Jul 2018 05:30:33 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 13:25:51 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Hussein", "Sarfaraz", ""], ["Kandel", "Pujan", ""], ["Bolan", "Candice W.", ""], ["Wallace", "Michael B.", ""], ["Bagci", "Ulas", ""]]}, {"id": "1801.03681", "submitter": "Tsvi Tlusty", "authors": "Sandipan Dutta, Jean-Pierre Eckmann, Albert Libchaber, Tsvi Tlusty", "title": "Green function of correlated genes in a minimal mechanical model of\n  protein evolution", "comments": "published in PNAS", "journal-ref": "PNAS April 30, 2018. 201716215; published ahead of print April 30,\n  2018", "doi": "10.1073/pnas.1716215115", "report-no": null, "categories": "q-bio.QM physics.bio-ph q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The function of proteins arises from cooperative interactions and\nrearrangements of their amino acids, which exhibit large-scale dynamical modes.\nLong-range correlations have also been revealed in protein sequences, and this\nhas motivated the search for physical links between the observed genetic and\ndynamic cooperativity. We outline here a simplified theory of protein, which\nrelates sequence correlations to physical interactions and to the emergence of\nmechanical function. Our protein is modeled as a strongly-coupled amino acid\nnetwork whose interactions and motions are captured by the mechanical\npropagator, the Green function. The propagator describes how the gene\ndetermines the connectivity of the amino acids, and thereby the transmission of\nforces. Mutations introduce localized perturbations to the propagator which\nscatter the force field. The emergence of function is manifested by a\ntopological transition when a band of such perturbations divides the protein\ninto subdomains. We find that epistasis -- the interaction among mutations in\nthe gene -- is related to the nonlinearity of the Green function, which can be\ninterpreted as a sum over multiple scattering paths. We apply this mechanical\nframework to simulations of protein evolution, and observe long-range epistasis\nwhich facilitates collective functional modes.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 09:17:54 GMT"}, {"version": "v2", "created": "Tue, 1 May 2018 14:47:08 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Dutta", "Sandipan", ""], ["Eckmann", "Jean-Pierre", ""], ["Libchaber", "Albert", ""], ["Tlusty", "Tsvi", ""]]}, {"id": "1801.03721", "submitter": "Ushasi Roy", "authors": "C. S. Renadheer, Ushasi Roy, Manoj Gopalakrishnan", "title": "A path-integral formulation of the run and tumble motion and chemotaxis\n  in Escherichia coli", "comments": "22 pages, major reorganization of sections, additional figure added,\n  few errors corrected", "journal-ref": null, "doi": "10.1088/1751-8121/ab5425", "report-no": null, "categories": "q-bio.QM physics.bio-ph q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bacteria such as Escherichia coli move about in a series of runs and tumbles:\nwhile a run state (straight motion) entails all the flagellar motors spinning\nin counterclockwise mode, a tumble is caused by a shift in the state of one or\nmore motors to clockwise spinning mode. In the presence of an attractant\ngradient in the environment, runs in the favourable direction are extended, and\nthis results in a net drift of the organism in the direction of the gradient.\nThe underlying signal transduction mechanism produces directed motion through a\nbi-lobed response function which relates the clockwise bias of the flagellar\nmotor to temporal changes in the attractant concentration. The two lobes\n(positive and negative) of the response function are separated by a time\ninterval of $\\sim 1$s, such that the bacterium effectively compares the\nconcentration at two different positions in space and responds accordingly. We\npresent here a novel path-integral method which allows us to address this\nproblem in the most general way possible, including multi-step CW-CCW\ntransitions, directional persistence and power-law waiting time distributions.\nThe method allows us to calculate quantities such as the effective diffusion\ncoefficient and drift velocity, in a power series expansion in the attractant\ngradient. Explicit results in the lowest order in the expansion are presented\nfor specific models, which, wherever applicable, agree with the known results.\nNew results for gamma-distributed run interval distributions are also\npresented.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 11:36:37 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 10:33:40 GMT"}, {"version": "v3", "created": "Fri, 23 Feb 2018 09:07:38 GMT"}], "update_date": "2020-01-08", "authors_parsed": [["Renadheer", "C. S.", ""], ["Roy", "Ushasi", ""], ["Gopalakrishnan", "Manoj", ""]]}, {"id": "1801.03921", "submitter": "Hanrong Chen", "authors": "Hanrong Chen, Arup K. Chakraborty, Mehran Kardar", "title": "How nonuniform contact profiles of T cell receptors modulate thymic\n  selection outcomes", "comments": "10 pages, 4 figures, submitted to Phys. Rev. E", "journal-ref": "Phys. Rev. E 97, 032413 (2018)", "doi": "10.1103/PhysRevE.97.032413", "report-no": null, "categories": "q-bio.PE cond-mat.stat-mech physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  T cell receptors (TCRs) bind foreign or self-peptides attached to major\nhistocompatibility complex (MHC) molecules, and the strength of this\ninteraction determines T cell activation. Optimizing the ability of T cells to\nrecognize a diversity of foreign peptides yet be tolerant of self-peptides is\ncrucial for the adaptive immune system to properly function. This is achieved\nby selection of T cells in the thymus, where immature T cells expressing\nunique, stochastically generated TCRs interact with a large number of\nself-peptide-MHC; if a TCR does not bind strongly enough to any\nself-peptide-MHC, or too strongly with at least one self-peptide-MHC, the T\ncell dies. Past theoretical work cast thymic selection as an extreme value\nproblem, and characterized the statistical enrichment or depletion of amino\nacids in the post-selection TCR repertoire, showing how T cells are selected to\nbe able to specifically recognize peptides derived from diverse pathogens, yet\nhave limited self-reactivity. Here, we investigate how the degree of enrichment\nis modified by nonuniform contacts that a TCR makes with peptide-MHC.\nSpecifically, we were motivated by recent experiments showing that amino acids\nat certain positions of a TCR sequence have large effects on thymic selection\noutcomes, and crystal structure data that reveal a nonuniform contact profile\nbetween a TCR and its peptide-MHC ligand. Using a representative TCR contact\nprofile as an illustration, we show via simulations that the degree of\nenrichment now varies by position according to the contact profile, and,\nimportantly, it depends on the implementation of nonuniform contacts during\nthymic selection. We explain these nontrivial results analytically. Our study\nhas implications for understanding the selection forces that shape the\nfunctionality of the post-selection TCR repertoire.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 18:49:23 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Chen", "Hanrong", ""], ["Chakraborty", "Arup K.", ""], ["Kardar", "Mehran", ""]]}, {"id": "1801.04008", "submitter": "Eslam Abbas", "authors": "Eslam Abbas", "title": "Comorbid CAD and Ventricular Hypertrophy Compromise The Perfusion of\n  Myocardial Tissue at Subcritical Stenosis of Epicardial Coronaries", "comments": "10 pages and 2 figures", "journal-ref": null, "doi": "10.1186/s43044-019-0003-5", "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BACKGROUND: Most studies of CAD revascularization have been based on and\nreported according to angiographic criteria which don't consider the relation\nbetween the resulting effective flow distal to the stenosis and the demand of a\nhypertrophied myocardial tissue.\n  MODEL: Mathematical model of the myocardial perfusion in comorbid CAD and\nventricular hypertrophy using Poiseuille's law. The analysis yields that the\ncurve, which represents the relation between the perfusion and the severity of\nCAD depending on angiographic and/or angiophysiologic criteria, is shifted to\nthe right by the effect of myocardial tissue hypertrophy. The right shift of\nsaid curve, which is directly proportional to the degree of ventricular\nhypertrophy, indicates that the perfusion of the corresponding myocardial\ntissue is compromised at angiographically and/or angiophysiologically\nsubsignificant stenosis of the supplying epicardial vessel.\n  RESULTS: Patients with comorbid CAD and left ventricular hypertrophy are more\nsensitive to CAD-related hemodynamic changes. They are more prone to develop\nischemic complications, than their peers with isolated CAD regarding the same\ndegree of coronary stenosis.\n  CONCLUSION: Patients with comorbid CAD and ventricular hypertrophy suffer\nfrom myocardial hypoperfusion at angiographically and/or angiophysiologically\nsubcritical epicardial stenosis. Accordingly; the comorbidity of both diseases\nshould be considered upon designing of the treatment regime.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 22:46:55 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Abbas", "Eslam", ""]]}, {"id": "1801.04087", "submitter": "V\\^an Anh Huynh-Thu", "authors": "V\\^an Anh Huynh-Thu and Guido Sanguinetti", "title": "Gene regulatory network inference: an introductory survey", "comments": "This chapter appears in the book \"Gene Regulatory Networks: Methods\n  and Protocols\", published by Springer Nature", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gene regulatory networks are powerful abstractions of biological systems.\nSince the advent of high-throughput measurement technologies in biology in the\nlate 90s, reconstructing the structure of such networks has been a central\ncomputational problem in systems biology. While the problem is certainly not\nsolved in its entirety, considerable progress has been made in the last two\ndecades, with mature tools now available. This chapter aims to provide an\nintroduction to the basic concepts underpinning network inference tools,\nattempting a categorisation which highlights commonalities and relative\nstrengths. While the chapter is meant to be self-contained, the material\npresented should provide a useful background to the later, more specialised\nchapters of this book.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 08:37:36 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 09:27:25 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Huynh-Thu", "V\u00e2n Anh", ""], ["Sanguinetti", "Guido", ""]]}, {"id": "1801.04184", "submitter": "Pierre Barrat-Charlaix", "authors": "Matteo Figliuzzi, Pierre Barrat-Charlaix and Martin Weigt", "title": "How pairwise coevolutionary models capture the collective residue\n  variability in proteins", "comments": "17 pages, 3 figures and one table", "journal-ref": "Molecular Biology and Evolution 35, 1018 (2018)", "doi": "10.1093/molbev/msy007", "report-no": null, "categories": "q-bio.QM cond-mat.stat-mech q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global coevolutionary models of homologous protein families, as constructed\nby direct coupling analysis (DCA), have recently gained popularity in\nparticular due to their capacity to accurately predict residue-residue contacts\nfrom sequence information alone, and thereby to facilitate tertiary and\nquaternary protein structure prediction. More recently, they have also been\nused to predict fitness effects of amino-acid substitutions in proteins, and to\npredict evolutionary conserved protein-protein interactions. These models are\nbased on two currently unjustified hypotheses: (a) correlations in the\namino-acid usage of different positions are resulting collectively from\nnetworks of direct couplings; and (b) pairwise couplings are sufficient to\ncapture the amino-acid variability. Here we propose a highly precise inference\nscheme based on Boltzmann-machine learning, which allows us to systematically\naddress these hypotheses. We show how correlations are built up in a highly\ncollective way by a large number of coupling paths, which are based on the\nprotein's three-dimensional structure. We further find that pairwise\ncoevolutionary models capture the collective residue variability across\nhomologous proteins even for quantities which are not imposed by the inference\nprocedure, like three-residue correlations, the clustered structure of protein\nfamilies in sequence space or the sequence distances between homologs. These\nfindings strongly suggest that pairwise coevolutionary models are actually\nsufficient to accurately capture the residue variability in homologous protein\nfamilies.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 14:52:10 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Figliuzzi", "Matteo", ""], ["Barrat-Charlaix", "Pierre", ""], ["Weigt", "Martin", ""]]}, {"id": "1801.04498", "submitter": "Louxin Zhang", "authors": "Andreas D. M. Gunawan, Bingxin Lu, Louxin Zhang", "title": "Fast Methods for Solving the Cluster Containment Problem for\n  Phylogenetic Networks", "comments": "8 figure, 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic and comparative genomic studies indicate that extant genomes are more\nproperly considered to be a fusion product of random mutations over generations\nand genomic material transfers between individuals of different lineages. This\nhas motivated researchers to adopt phylogenetic networks and other general\nmodels to study genome evolution. One important problem arising from\nreconstruction and verification of phylogenetic networks is the cluster\ncontainment problem, namely determining whether or not a cluster of taxa is\ndisplayed in a phylogenetic network. In this work, a new upper bound for this\nNP-complete problem is established through an efficient reduction to the SAT\nproblem. Two efficient (albeit exponential time) methods are also implemented.\nIt is developed on the basis of generalization of the so-called\nreticulation-visible property of phylogenetic networks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 02:11:23 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Gunawan", "Andreas D. M.", ""], ["Lu", "Bingxin", ""], ["Zhang", "Louxin", ""]]}, {"id": "1801.04600", "submitter": "Zi Wang", "authors": "Zi Wang, Dali Wang, Chengcheng Li, Yichi Xu, Husheng Li, Zhirong Bao", "title": "Deep Reinforcement Learning of Cell Movement in the Early Stage of C.\n  elegans Embryogenesis", "comments": "We revised the manuscript to make it clearer to follow. Please notice\n  that the Abstract shown in this page is slightly different than that in the\n  manuscript due to the limitation of 1920 characters in arxiv.org", "journal-ref": "Bioinformatics, 2018", "doi": "10.1093/bioinformatics/bty323", "report-no": "bty323", "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell movement in the early phase of C. elegans development is regulated by a\nhighly complex process in which a set of rules and connections are formulated\nat distinct scales. Previous efforts have shown that agent-based, multi-scale\nmodeling systems can integrate physical and biological rules and provide new\navenues to study developmental systems. However, the application of these\nsystems to model cell movement is still challenging and requires a\ncomprehensive understanding of regulation networks at the right scales. Recent\ndevelopments in deep learning and reinforcement learning provide an\nunprecedented opportunity to explore cell movement using 3D time-lapse images.\nWe present a deep reinforcement learning approach within an ABM system to\ncharacterize cell movement in C. elegans embryogenesis. Our modeling system\ncaptures the complexity of cell movement patterns in the embryo and overcomes\nthe local optimization problem encountered by traditional rule-based, ABM that\nuses greedy algorithms. We tested our model with two real developmental\nprocesses: the anterior movement of the Cpaaa cell via intercalation and the\nrearrangement of the left-right asymmetry. In the first case, model results\nshowed that Cpaaa's intercalation is an active directional cell movement caused\nby the continuous effects from a longer distance, as opposed to a passive\nmovement caused by neighbor cell movements. This is because the learning-based\nsimulation found that a passive movement model could not lead Cpaaa to the\npredefined destination. In the second case, a leader-follower mechanism well\nexplained the collective cell movement pattern. These results showed that our\napproach to introduce deep reinforcement learning into ABM can test regulatory\nmechanisms by exploring cell migration paths in a reverse engineering\nperspective. This model opens new doors to explore large datasets generated by\nlive imaging.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 19:33:48 GMT"}, {"version": "v2", "created": "Fri, 2 Mar 2018 19:16:18 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Wang", "Zi", ""], ["Wang", "Dali", ""], ["Li", "Chengcheng", ""], ["Xu", "Yichi", ""], ["Li", "Husheng", ""], ["Bao", "Zhirong", ""]]}, {"id": "1801.04901", "submitter": "Grace Brannigan", "authors": "Reza Salari and Thomas Joseph and Ruchi Lohia and Jerome Henin and\n  Grace Brannigan", "title": "A streamlined, general approach for computing ligand binding free\n  energies and its application to GPCR-bound cholesterol", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cond-mat.soft cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theory of receptor-ligand binding equilibria has long been\nwell-established in biochemistry, and was primarily constructed to describe\ndilute aqueous solutions. Accordingly, few computational approaches have been\ndeveloped for making quantitative predictions of binding probabilities in\nenvironments other than dilute isotropic solution. Existing techniques, ranging\nfrom simple automated docking procedures to sophisticated thermodynamics-based\nmethods, have been developed with soluble proteins in mind. Biologically and\npharmacologically relevant protein-ligand interactions often occur in complex\nenvironments, including lamellar phases like membranes and crowded, non-dilute\nsolutions. Here we revisit the theoretical bases of ligand binding equilibria,\navoiding overly specific assumptions that are nearly always made when\ndescribing receptor-ligand binding. Building on this formalism, we extend the\nasymptotically exact Alchemical Free Energy Perturbation technique to\nquantifying occupancies of sites on proteins in a complex bulk, including\nphase-separated, anisotropic, or non-dilute solutions, using a\nthermodynamically consistent and easily generalized approach that resolves\nseveral ambiguities of current frameworks. To incorporate the complex bulk\nwithout overcomplicating the overall thermodynamic cycle, we simplify the\ncommon approach for ligand restraints by using a single\ndistance-from-bound-configuration (DBC) ligand restraint during AFEP decoupling\nfrom protein. DBC restraints should be generalizable to binding modes of most\nsmall molecules, even those with strong orientational dependence. We apply this\napproach to compute the likelihood that membrane cholesterol binds to known\ncrystallographic sites on 3 GPCRs at a range of concentrations. Non-ideality of\ncholesterol in a binary cholesterol:POPC bilayer is characterized and\nconsistently incorporated into the interpretation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 18:18:35 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 21:45:49 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2018 18:27:08 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Salari", "Reza", ""], ["Joseph", "Thomas", ""], ["Lohia", "Ruchi", ""], ["Henin", "Jerome", ""], ["Brannigan", "Grace", ""]]}, {"id": "1801.04909", "submitter": "C. Anthony Hunt", "authors": "C. Anthony Hunt, Ahmet Erdemir, Feilim Mac Gabhann, William W. Lytton,\n  Edward A. Sander, Mark K. Transtrum, and Lealem Mulugeta", "title": "The Spectrum of Mechanism-oriented Models for Explanations of Biological\n  Phenomena", "comments": "29 pages, 6 figures, 47 references, and 7 suggestions for further\n  reading", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Within the diverse interdisciplinary life sciences domains, semantic,\nworkflow, and methodological ambiguities can prevent the appreciation of\nexplanations of phenomena, handicap the use of computational models, and hamper\ncommunication among scientists, engineers, and the public. Members of the life\nsciences community commonly, and too often loosely, draw on \"mechanistic model\"\nand similar phrases when referring to the processes of discovering and\nestablishing causal explanations of biological phenomena. Ambiguities in\nmodeling and simulation terminology and methods diminish clarity, credibility,\nand the perceived significance of research findings. To encourage improved\nsemantic and methodological clarity, we describe the spectrum of\nMechanism-oriented Models being used to develop explanations of biological\nphenomena. We cluster them into three broad groups. We then expand the three\ngroups into a total of seven workflow-related model types having clearly\ndistinguishable features. We name each type and illustrate with diverse\nexamples drawn from the literature. These model types are intended to\ncontribute to the foundation of an ontology of mechanism-based simulation\nresearch in the life sciences. We show that it is within the model-development\nworkflows that the different model types manifest and exert their scientific\nusefulness by enhancing and extending different forms and degrees of\nexplanation. The process starts with knowledge about the phenomenon and\ncontinues with explanatory and mathematical descriptions. Those descriptions\nare transformed into software and used to perform experimental explorations by\nrunning and examining simulation output. The credibility of inferences is thus\nlinked to having easy access to the scientific and technical provenance from\neach workflow stage.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 18:55:23 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Hunt", "C. Anthony", ""], ["Erdemir", "Ahmet", ""], ["Mac Gabhann", "Feilim", ""], ["Lytton", "William W.", ""], ["Sander", "Edward A.", ""], ["Transtrum", "Mark K.", ""], ["Mulugeta", "Lealem", ""]]}, {"id": "1801.05042", "submitter": "Valentin Danchev", "authors": "Valentin Danchev, Andrey Rzhetsky, James A. Evans", "title": "Centralized \"big science\" communities more likely generate\n  non-replicable results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI nlin.AO physics.data-an q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing concern that most published results, including those widely agreed\nupon, may be false are rarely examined against rapidly expanding research\nproduction. Replications have only occurred on small scales due to prohibitive\nexpense and limited professional incentive. We introduce a novel,\nhigh-throughput replication strategy aligning 51,292 published claims about\ndrug-gene interactions with high-throughput experiments performed through the\nNIH LINCS L1000 program. We show (1) that unique claims replicate 19% more\nfrequently than at random, while those widely agreed upon replicate 45% more\nfrequently, manifesting collective correction mechanisms in science; but (2)\ncentralized scientific communities perpetuate claims that are less likely to\nreplicate even if widely agreed upon, demonstrating how centralized,\noverlapping collaborations weaken collective understanding. Decentralized\nresearch communities involve more independent teams and use more diverse\nmethodologies, generating the most robust, replicable results. Our findings\nhighlight the importance of science policies that foster decentralized\ncollaboration to promote robust scientific advance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 21:50:28 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Danchev", "Valentin", ""], ["Rzhetsky", "Andrey", ""], ["Evans", "James A.", ""]]}, {"id": "1801.05767", "submitter": "Denis Michel", "authors": "Denis Michel and Philippe Ruelle", "title": "Polylogarithmic equilibrium treatment of molecular aggregation and\n  critical concentrations", "comments": "14 pages, 2 figures", "journal-ref": "Phys. Chem. Chem. Phys. 2017 Feb 15;19(7):5273-5284", "doi": "10.1039/C6CP08369B", "report-no": null, "categories": "q-bio.QM cond-mat.soft", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A full equilibrium treatment of molecular aggregation is presented for\nprototypes of 1D and 3D aggregates, with and without nucleation. By skipping\ncomplex kinetic parameters like aggregate size-dependent diffusion, the\nequilibrium treatment allows to predict directly time-independent quantities\nsuch as critical concentrations. The relationships between the macroscopic\nequilibrium constants for the different paths are first established by\nstatistical corrections and so as to comply with the detailed balance\nconstraints imposed by nucleation, and the composition of the mixture resulting\nfrom homogeneous aggregation is then analyzed using the polylogarithm function.\nSeveral critical concentrations are distinguished: the residual monomer\nconcentation in equilibrium (RMC) and the critical nucleation concentration\n(CNC), that is the threshold concentration of total subunits necessary for\ninitiating aggregation. When increasing the concentration of total subunits,\nthe RMC converges more strongly to its asymptotic value, the equilibrium\nconstant of depolymerization, for 3D aggregates and in case of nucleation. The\nCNC moderately depends on the number of subunits in the nucleus, but sharply\nincreases with the difference between the equilibrium constants of\npolymerization and nucleation. As the RMC and CNC can be numerically but not\nanalytically determined, ansatz equations connecting them to thermodynamic\nparameters are proposed.\n", "versions": [{"version": "v1", "created": "Sun, 24 Dec 2017 08:21:13 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Michel", "Denis", ""], ["Ruelle", "Philippe", ""]]}, {"id": "1801.05803", "submitter": "Jose Casadiego", "authors": "Jose Casadiego, Mor Nitzan, Sarah Hallerberg, Marc Timme", "title": "Model-free inference of direct network interactions from nonlinear\n  collective dynamics", "comments": "10 pages, 7 figures", "journal-ref": "Nature Communications 8, Article number: 2192 (2017)", "doi": "10.1038/s41467-017-02288-4", "report-no": null, "categories": "physics.soc-ph nlin.CD physics.comp-ph physics.data-an q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The topology of interactions in network dynamical systems fundamentally\nunderlies their function. Accelerating technological progress creates massively\navailable data about collective nonlinear dynamics in physical, biological, and\ntechnological systems. Detecting direct interaction patterns from those\ndynamics still constitutes a major open problem. In particular, current\nnonlinear dynamics approaches mostly require to know a priori a model of the\n(often high dimensional) system dynamics. Here we develop a model-independent\nframework for inferring direct interactions solely from recording the nonlinear\ncollective dynamics generated. Introducing an explicit dependency matrix in\ncombination with a block-orthogonal regression algorithm, the approach works\nreliably across many dynamical regimes, including transient dynamics toward\nsteady states, periodic and non-periodic dynamics, and chaos. Together with its\ncapabilities to reveal network (two point) as well as hypernetwork (e.g., three\npoint) interactions, this framework may thus open up nonlinear dynamics options\nof inferring direct interaction patterns across systems where no model is\nknown.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 09:28:47 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Casadiego", "Jose", ""], ["Nitzan", "Mor", ""], ["Hallerberg", "Sarah", ""], ["Timme", "Marc", ""]]}, {"id": "1801.06227", "submitter": "Chloe Pasin", "authors": "Chlo\\'e Pasin, Fran\\c{c}ois Dufour, Laura Villain, Huilong Zhang,\n  Rodolphe Thi\\'ebaut", "title": "Controlling IL-7 injections in HIV-infected patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Immune interventions consisting in repeated injection are broadly used as\nthey are thought to improve the quantity and the quality of the immune\nresponse. However, they also raised several questions that remains unanswered,\nin particular the number of injections to make or the delay to respect between\ndifferent injections to acheive this goal. Practical and financial\nconsiderations add constraints to these questions, especially in the framework\nof human studies. We specifically focus here on the use of interleukine-7\n(IL-7) injections in HIV-infected patients under antiretroviral treatment, but\nstill unable to restore normal levels of CD4+ T lymphocytes. Clinical trials\nhave already shown that repeated cycles of injections of IL-7 could help\nmaintaining CD4+ T lymphocytes levels over the limit of 500 cells per microL,\nby affecting proliferation and survival of CD4+ T cells. We then aim at\nanswering the question : how to maintain a patient's level of CD4+ T\nlymphocytes by using a minimum number of injections (ie optimizing the strategy\nof injections) ? Based on mechanistic models that were previously developed for\nthe dynamics of CD4+ T lymphocytes in this context, we model the process by a\npiecewise deterministic Markov model. We then address the question by using\nsome recently established theory on impulse control problem in order to develop\na numerical tool determining the optimal strategy. Results are obtained on a\nreduced model, as a proof of concept : the method allows to defined an optimal\nstrategy for a given patient. This method could applied to optimize injections\nschedules in clinical trials.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 20:30:20 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Pasin", "Chlo\u00e9", ""], ["Dufour", "Fran\u00e7ois", ""], ["Villain", "Laura", ""], ["Zhang", "Huilong", ""], ["Thi\u00e9baut", "Rodolphe", ""]]}, {"id": "1801.06752", "submitter": "David Nguyen", "authors": "David H. Nguyen", "title": "Translating the Architectural Complexity of the Colon or Polyp into a\n  Sinusoid Wave for Classification via the Fast Fourier Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.TO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There is no method to quantify the spatial complexity within colon polyps.\nThis paper describes a spatial transformation that translates the tissue\narchitecture within a polyp, or a normal colon lining, into a complex sinusoid\nwave composed of discrete points. This sinusoid wave can then undergo the Fast\nFourier Transform to obtain a spectrum of frequencies that represents the\nsinusoid wave. This spectrum can then serve as a signature of the spatial\ncomplexity [an index] within the polyp. By overlaying vertical lines that\nradiate from the bottom middle [like a fold-out fan] of an image of a polyp\nstained by hematoxylin and eosin, the image is segmented into sectors. Each\nvertical line also forms an angle with the horizontal axis of the image,\nranging from 0 degrees to 180 degrees rising counter clockwise. Each vertical\nline will intersect with various features of the polyp [border of lumens,\nborder of epithelial lining]. Each of these intersections is a point that can\nbe characterized by its distance from the origin [this distance is also a\nmagnitude of that point]. Thus, each intersection between radial line and polyp\nfeature can be mapped by polar coordinates [radius length, angle measure]. By\nsumming the distance of all points along the same radial line, each radial line\nthat divides the image becomes one value. Plotting these values [y variable]\nagainst the angle of each radial line from the horizontal axis [x variable]\nresults in a sinusoid wave consisting of discrete points. This method is\nreferred to as the Linearized Compressed Polar Coordinates [LCPC] Transform.\nThe LCPC transform, in conjunction with the Fast Fourier Transform, can reduce\nthe complexity of visually hidden histological grades in colon polyps into\ncategories of similar wave frequencies [each histological grade has a signature\nconsisting of a handful of frequencies].\n", "versions": [{"version": "v1", "created": "Sun, 21 Jan 2018 02:18:51 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Nguyen", "David H.", ""]]}, {"id": "1801.07113", "submitter": "Shantia  Yarahmadian", "authors": "Amin Oroji, Shantia Yarahmadian, Sarkhosh Seddighi and Mohd Omar", "title": "A Mathematical Model for Tumor Cell Population Dynamics Based on Target\n  Theory and Tumor Lifespan", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiation Therapy (XRT) is one of the most common cancer treatment methods.\nIn this paper, a new mathematical model is proposed for the population dynamics\nof heterogeneous tumor cells following external beam radiation treatment.\nAccording to the Target Theory, the tumor population is divided into m\ndifferent subpopulations based on the diverse effects of ionizing radiation on\nhuman cells. A hybrid model con- sists of a system of differential equations\nwith random variable coefficients representing the transition rates between\nsubpopulations is proposed. This model is utilized to sim- ulate the dynamics\nof cell subpopulations within a tumor. The model also describes the cell damage\nheterogeneity and the repair mechanism between two consecutive dose fractions.\nAs such, a new definition of tumor lifespan based on population size is intro-\nduced. Finally, the stability of the system is studied by using the Gershgorin\ntheorem. It is proven that the probability of target inactivity post radiation\nplays the most important role in the stability of the system.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 19:25:42 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Oroji", "Amin", ""], ["Yarahmadian", "Shantia", ""], ["Seddighi", "Sarkhosh", ""], ["Omar", "Mohd", ""]]}, {"id": "1801.07130", "submitter": "Yifei Qi", "authors": "Jingxue Wang, Huali Cao, and John Z.H. Zhang, and Yifei Qi", "title": "Computational Protein Design with Deep Learning Neural Networks", "comments": "16 pages, 5 figures, 3 tables", "journal-ref": "Scientific Reports 8: 6349 (2018)", "doi": "10.1038/s41598-018-24760-x", "report-no": null, "categories": "q-bio.QM q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational protein design has a wide variety of applications. Despite its\nremarkable success, designing a protein for a given structure and function is\nstill a challenging task. On the other hand, the number of solved protein\nstructures is rapidly increasing while the number of unique protein folds has\nreached a steady number, suggesting more structural information is being\naccumulated on each fold. Deep learning neural network is a powerful method to\nlearn such big data set and has shown superior performance in many machine\nlearning fields. In this study, we applied the deep learning neural network\napproach to computational protein design for predicting the probability of 20\nnatural amino acids on each residue in a protein. A large set of protein\nstructures was collected and a multi-layer neural network was constructed. A\nnumber of structural properties were extracted as input features and the best\nnetwork achieved an accuracy of 38.3%. Using the network output as residue type\nrestraints was able to improve the average sequence identity in designing three\nnatural proteins using Rosetta. Moreover, the predictions from our network show\n~3% higher sequence identity than a previous method. Results from this study\nmay benefit further development of computational protein design methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 14:59:18 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 03:15:40 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Wang", "Jingxue", ""], ["Cao", "Huali", ""], ["Zhang", "John Z. H.", ""], ["Qi", "Yifei", ""]]}, {"id": "1801.07299", "submitter": "Yibo Li", "authors": "Yibo Li, Liangren Zhang, Zhenming Liu", "title": "Multi-Objective De Novo Drug Design with Conditional Graph Generative\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep generative models have revealed itself as a promising way of\nperforming de novo molecule design. However, previous research has focused\nmainly on generating SMILES strings instead of molecular graphs. Although\ncurrent graph generative models are available, they are often too general and\ncomputationally expensive, which restricts their application to molecules with\nsmall sizes. In this work, a new de novo molecular design framework is proposed\nbased on a type sequential graph generators that do not use atom level\nrecurrent units. Compared with previous graph generative models, the proposed\nmethod is much more tuned for molecule generation and have been scaled up to\ncover significantly larger molecules in the ChEMBL database. It is shown that\nthe graph-based model outperforms SMILES based models in a variety of metrics,\nespecially in the rate of valid outputs. For the application of drug design\ntasks, conditional graph generative model is employed. This method offers\nhigher flexibility compared to previous fine-tuning based approach and is\nsuitable for generation based on multiple objectives. This approach is applied\nto solve several drug design problems, including the generation of compounds\ncontaining a given scaffold, generation of compounds with specific\ndrug-likeness and synthetic accessibility requirements, as well as generating\ndual inhibitors against JNK3 and GSK3$\\beta$. Results show high enrichment\nrates for outputs satisfying the given requirements.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 13:54:55 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 03:50:40 GMT"}, {"version": "v3", "created": "Sat, 21 Apr 2018 15:36:33 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Li", "Yibo", ""], ["Zhang", "Liangren", ""], ["Liu", "Zhenming", ""]]}, {"id": "1801.07318", "submitter": "Lorin Crawford", "authors": "Lorin Crawford, Seth R. Flaxman, Daniel E. Runcie, Mike West", "title": "Variable Prioritization in Nonlinear Black Box Methods: A Genetic\n  Association Case Study", "comments": "28 pages, 5 figures, 1 tables; Supplementary Material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.QM stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The central aim in this paper is to address variable selection questions in\nnonlinear and nonparametric regression. Motivated by statistical genetics,\nwhere nonlinear interactions are of particular interest, we introduce a novel\nand interpretable way to summarize the relative importance of predictor\nvariables. Methodologically, we develop the \"RelATive cEntrality\" (RATE)\nmeasure to prioritize candidate genetic variants that are not just marginally\nimportant, but whose associations also stem from significant covarying\nrelationships with other variants in the data. We illustrate RATE through\nBayesian Gaussian process regression, but the methodological innovations apply\nto other \"black box\" methods. It is known that nonlinear models often exhibit\ngreater predictive accuracy than linear models, particularly for phenotypes\ngenerated by complex genetic architectures. With detailed simulations and two\nreal data association mapping studies, we show that applying RATE enables an\nexplanation for this improved performance.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 20:57:39 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 23:32:04 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 00:36:45 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Crawford", "Lorin", ""], ["Flaxman", "Seth R.", ""], ["Runcie", "Daniel E.", ""], ["West", "Mike", ""]]}, {"id": "1801.07330", "submitter": "Hao Zhang", "authors": "Hao Zhang (1), Xinlin Xie (1), Chunyu Fang (1), Yicong Yang (1), Di\n  Jin (2) and Peng Fei (1 and 3) ((1) School of Optical and Electronic\n  Informaiton, Huazhong University of Science and Technology, Wuhan, China, (2)\n  Computer Science and Artificial Intelligence Laboratory, Massachusetts\n  Institute of Technology, Cambridge, U.S.A., (3) Britton Chance Center for\n  Biomedical Photonics, Wuhan National Laboratory for Optoelectronics, Huazhong\n  University of Science and Technology, Wuhan, China)", "title": "High-throughput, high-resolution registration-free generated adversarial\n  network microscopy", "comments": "21 pages, 9 figures and 1 table. Peng Fe and Di Jin conceived the\n  ides, initiated the investigation. Hao Zhang, Di Jin and Peng Fei prepared\n  the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG eess.SP physics.optics q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We combine generative adversarial network (GAN) with light microscopy to\nachieve deep learning super-resolution under a large field of view (FOV). By\nappropriately adopting prior microscopy data in an adversarial training, the\nneural network can recover a high-resolution, accurate image of new specimen\nfrom its single low-resolution measurement. Its capacity has been broadly\ndemonstrated via imaging various types of samples, such as USAF resolution\ntarget, human pathological slides, fluorescence-labelled fibroblast cells, and\ndeep tissues in transgenic mouse brain, by both wide-field and light-sheet\nmicroscopes. The gigapixel, multi-color reconstruction of these samples\nverifies a successful GAN-based single image super-resolution procedure. We\nalso propose an image degrading model to generate low resolution images for\ntraining, making our approach free from the complex image registration during\ntraining dataset preparation. After a welltrained network being created, this\ndeep learning-based imaging approach is capable of recovering a large FOV (~95\nmm2), high-resolution (~1.7 {\\mu}m) image at high speed (within 1 second),\nwhile not necessarily introducing any changes to the setup of existing\nmicroscopes.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 09:47:48 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 07:39:45 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Zhang", "Hao", "", "1 and 3"], ["Xie", "Xinlin", "", "1 and 3"], ["Fang", "Chunyu", "", "1 and 3"], ["Yang", "Yicong", "", "1 and 3"], ["Jin", "Di", "", "1 and 3"], ["Fei", "Peng", "", "1 and 3"]]}, {"id": "1801.07660", "submitter": "Hesam Montazeri", "authors": "Hesam Montazeri, Susan Little, Niko Beerenwinkel, Victor DeGruttola", "title": "Bayesian reconstruction of HIV transmission trees from viral sequences\n  and uncertain infection times", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic sequence data of pathogens are increasingly used to investigate\ntransmission dynamics in both endemic diseases and disease outbreaks; such\nresearch can aid in development of appropriate interventions and in design of\nstudies to evaluate them. Several methods have been proposed to infer\ntransmission chains from sequence data; however, existing methods do not\ngenerally reliably reconstruct transmission trees because genetic sequence data\nor inferred phylogenetic trees from such data are insufficient for accurate\ninference regarding transmission chains. In this paper, we demonstrate the lack\nof a one-to-one relationship between phylogenies and transmission trees, and\nalso show that information regarding infection times together with genetic\nsequences permit accurate reconstruction of transmission trees. We propose a\nBayesian inference method for this purpose and demonstrate that precision of\ninference regarding these transmission trees depends on precision of the\nestimated times of infection. We also illustrate the use of these methods to\nstudy features of epidemic dynamics, such as the relationship between\ncharacteristics of nodes and average number of outbound edges or inbound\nedges-- signifying possible transmission events from and to nodes. We study the\nperformance of the proposed method in simulation experiments and demonstrate\nits superiority in comparison to an alternative method. We apply them to a\ntransmission cluster in San Diego and investigate the impact of biological,\nbehavioral, and demographic factors.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 17:02:20 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Montazeri", "Hesam", ""], ["Little", "Susan", ""], ["Beerenwinkel", "Niko", ""], ["DeGruttola", "Victor", ""]]}, {"id": "1801.08085", "submitter": "Meysam Golmohammadi", "authors": "Vinit Shah, Eva von Weltin, Silvia Lopez, James Riley McHugh, Lily\n  Veloso, Meysam Golmohammadi, Iyad Obeid and Joseph Picone", "title": "The Temple University Hospital Seizure Detection Corpus", "comments": "Under review in Frontiers in Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM eess.SP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the TUH EEG Seizure Corpus (TUSZ), which is the largest open\nsource corpus of its type, and represents an accurate characterization of\nclinical conditions. In this paper, we describe the techniques used to develop\nTUSZ, evaluate their effectiveness, and present some descriptive statistics on\nthe resulting corpus.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 01:16:26 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Shah", "Vinit", ""], ["von Weltin", "Eva", ""], ["Lopez", "Silvia", ""], ["McHugh", "James Riley", ""], ["Veloso", "Lily", ""], ["Golmohammadi", "Meysam", ""], ["Obeid", "Iyad", ""], ["Picone", "Joseph", ""]]}, {"id": "1801.08216", "submitter": "Edward D Lee", "authors": "Edward D. Lee, Bryan C Daniels", "title": "Convenient Interface to Inverse Ising (ConIII): A Python 3 Package for\n  Solving Ising-Type Maximum Entropy Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cond-mat.stat-mech physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ConIII (pronounced CON-ee) is an open-source Python project providing a\nsimple interface to solving the pairwise and higher order Ising model and a\nbase for extension to other maximum entropy models. We describe the maximum\nentropy problem and give an overview of the algorithms that are implemented as\npart of ConIII (https://github.com/eltrompetero/coniii) including Monte Carlo\nhistogram, pseudolikelihood, minimum probability flow, a regularized mean field\nmethod, and a cluster expansion method. Our goal is to make a variety of\nmaximum entropy techniques accessible to those unfamiliar with the techniques\nand accelerate workflow for users.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 22:10:43 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2019 01:42:19 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Lee", "Edward D.", ""], ["Daniels", "Bryan C", ""]]}, {"id": "1801.08447", "submitter": "Michael Altenbuchinger", "authors": "Franziska G\\\"ortler, Stefan Solbrig, Tilo Wettig, Peter J. Oefner,\n  Rainer Spang, Michael Altenbuchinger", "title": "Loss-function learning for digital tissue deconvolution", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": "10.1007/978-3-319-89929-9_5", "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gene expression profile of a tissue averages the expression profiles of\nall cells in this tissue. Digital tissue deconvolution (DTD) addresses the\nfollowing inverse problem: Given the expression profile $y$ of a tissue, what\nis the cellular composition $c$ of that tissue? If $X$ is a matrix whose\ncolumns are reference profiles of individual cell types, the composition $c$\ncan be computed by minimizing $\\mathcal L(y-Xc)$ for a given loss function\n$\\mathcal L$. Current methods use predefined all-purpose loss functions. They\nsuccessfully quantify the dominating cells of a tissue, while often falling\nshort in detecting small cell populations.\n  Here we learn the loss function $\\mathcal L$ along with the composition $c$.\nThis allows us to adapt to application-specific requirements such as focusing\non small cell populations or distinguishing phenotypically similar cell\npopulations. Our method quantifies large cell fractions as accurately as\nexisting methods and significantly improves the detection of small cell\npopulations and the distinction of similar cell types.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 15:17:31 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["G\u00f6rtler", "Franziska", ""], ["Solbrig", "Stefan", ""], ["Wettig", "Tilo", ""], ["Oefner", "Peter J.", ""], ["Spang", "Rainer", ""], ["Altenbuchinger", "Michael", ""]]}, {"id": "1801.08522", "submitter": "Isaac Rosenthal", "authors": "Isaac S. Rosenthal (Department of Biology, University of Massachusetts\n  Boston), Jarrett E.K. Byrnes (Department of Biology, University of\n  Massachusetts Boston), Kyle C. Cavanaugh (Department of Geography, University\n  of California), Tom W. Bell (Department of Geography, University of\n  California), Briana Harder, Alison J. Haupt (School of Natural Sciences,\n  California State University Monterey Bay), Andrew T.W. Rassweiler (Department\n  of Biological Science, Florida State University), Alejandro P\\'erez-Matus\n  (Estaci\\'on Costera de Investigaciones Marina, Pontificia Universidad\n  Cat\\'olica de Chile), Jorge Assis (Center of Marine Sciences, CCMAR- CIMAR,\n  University of Algarve), Ali Swanson (The Zooniverse), Amy Boyer (The\n  Zooniverse, Adler Planetarium, Chicago, IL 60605), Adam McMaster (The\n  Zooniverse, Adler Planetarium), Laura Trouille (The Zooniverse, Adler\n  Planetarium)", "title": "Floating Forests: Quantitative Validation of Citizen Science Data\n  Generated From Consensus Classifications", "comments": "14 pages, 5 figures, 2 tables, 1 supplemental figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale research endeavors can be hindered by logistical constraints\nlimiting the amount of available data. For example, global ecological questions\nrequire a global dataset, and traditional sampling protocols are often too\ninefficient for a small research team to collect an adequate amount of data.\nCitizen science offers an alternative by crowdsourcing data collection. Despite\ngrowing popularity, the community has been slow to embrace it largely due to\nconcerns about quality of data collected by citizen scientists. Using the\ncitizen science project Floating Forests (http://floatingforests.org), we show\nthat consensus classifications made by citizen scientists produce data that is\nof comparable quality to expert generated classifications. Floating Forests is\na web-based project in which citizen scientists view satellite photographs of\ncoastlines and trace the borders of kelp patches. Since launch in 2014, over\n7,000 citizen scientists have classified over 750,000 images of kelp forests\nlargely in California and Tasmania. Images are classified by 15 users. We\ngenerated consensus classifications by overlaying all citizen classifications\nand assessed accuracy by comparing to expert classifications. Matthews\ncorrelation coefficient (MCC) was calculated for each threshold (1-15), and the\nthreshold with the highest MCC was considered optimal. We showed that optimal\nuser threshold was 4.2 with an MCC of 0.400 (0.023 SE) for Landsats 5 and 7,\nand a MCC of 0.639 (0.246 SE) for Landsat 8. These results suggest that citizen\nscience data derived from consensus classifications are of comparable accuracy\nto expert classifications. Citizen science projects should implement methods\nsuch as consensus classification in conjunction with a quantitative comparison\nto expert generated classifications to avoid concerns about data quality.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 18:42:32 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Rosenthal", "Isaac S.", "", "Department of Biology, University of Massachusetts\n  Boston"], ["Byrnes", "Jarrett E. K.", "", "Department of Biology, University of\n  Massachusetts Boston"], ["Cavanaugh", "Kyle C.", "", "Department of Geography, University\n  of California"], ["Bell", "Tom W.", "", "Department of Geography, University of\n  California"], ["Harder", "Briana", "", "School of Natural Sciences,\n  California State University Monterey Bay"], ["Haupt", "Alison J.", "", "School of Natural Sciences,\n  California State University Monterey Bay"], ["Rassweiler", "Andrew T. W.", "", "Department\n  of Biological Science, Florida State University"], ["P\u00e9rez-Matus", "Alejandro", "", "Estaci\u00f3n Costera de Investigaciones Marina, Pontificia Universidad\n  Cat\u00f3lica de Chile"], ["Assis", "Jorge", "", "Center of Marine Sciences, CCMAR- CIMAR,\n  University of Algarve"], ["Swanson", "Ali", "", "The Zooniverse"], ["Boyer", "Amy", "", "The\n  Zooniverse, Adler Planetarium, Chicago, IL 60605"], ["McMaster", "Adam", "", "The\n  Zooniverse, Adler Planetarium"], ["Trouille", "Laura", "", "The Zooniverse, Adler\n  Planetarium"]]}, {"id": "1801.08570", "submitter": "Alexandr A. Kalinin", "authors": "Alexandr A. Kalinin, Gerald A. Higgins, Narathip Reamaroon, S.M. Reza\n  Soroushmehr, Ari Allyn-Feuer, Ivo D. Dinov, Kayvan Najarian, Brian D. Athey", "title": "Deep Learning in Pharmacogenomics: From Gene Regulation to Patient\n  Stratification", "comments": "Alexandr A. Kalinin and Gerald A. Higgins contributed equally to this\n  work. Corresponding author: Brian D. Athey, <bleu@umich.edu>", "journal-ref": null, "doi": "10.2217/pgs-2018-0008", "report-no": null, "categories": "q-bio.QM cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Perspective provides examples of current and future applications of deep\nlearning in pharmacogenomics, including: (1) identification of novel regulatory\nvariants located in noncoding domains and their function as applied to\npharmacoepigenomics; (2) patient stratification from medical records; and (3)\nprediction of drugs, targets, and their interactions. Deep learning\nencapsulates a family of machine learning algorithms that over the last decade\nhas transformed many important subfields of artificial intelligence (AI) and\nhas demonstrated breakthrough performance improvements on a wide range of tasks\nin biomedicine. We anticipate that in the future deep learning will be widely\nused to predict personalized drug response and optimize medication selection\nand dosing, using knowledge extracted from large and complex molecular,\nepidemiological, clinical, and demographic datasets.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 19:21:15 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 00:25:37 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Kalinin", "Alexandr A.", ""], ["Higgins", "Gerald A.", ""], ["Reamaroon", "Narathip", ""], ["Soroushmehr", "S. M. Reza", ""], ["Allyn-Feuer", "Ari", ""], ["Dinov", "Ivo D.", ""], ["Najarian", "Kayvan", ""], ["Athey", "Brian D.", ""]]}, {"id": "1801.08626", "submitter": "Yunda Huang", "authors": "Lily Zhang, Peter B. Gilbert, Edmund Capparelli, Yunda Huang", "title": "Pharmacokinetics Simulations for Studying Correlates of Prevention\n  Efficacy of Passive HIV-1 Antibody Prophylaxis in the Antibody Mediated\n  Prevention (AMP) Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key objective in two phase 2b AMP clinical trials of VRC01 is to evaluate\nwhether drug concentration over time, as estimated by non-linear mixed effects\npharmacokinetics (PK) models, is associated with HIV infection rate. We\nconducted a simulation study of marker sampling designs, and evaluated the\neffect of study adherence and sub-cohort sample size on PK model estimates in\nmultiple-dose studies. With m=120, even under low adherence (about half of\nstudy visits missing per participant), reasonably unbiased and consistent\nestimates of most fixed and random effect terms were obtained. Coarsened marker\nsampling schedules were also studied.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 22:43:57 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Zhang", "Lily", ""], ["Gilbert", "Peter B.", ""], ["Capparelli", "Edmund", ""], ["Huang", "Yunda", ""]]}, {"id": "1801.08668", "submitter": "Vibhu Agarwal", "authors": "Vibhu Agarwal, Matthew Smuck, Nigam H Shah", "title": "Monitoring physical function in patients with knee osteoarthritis using\n  data from wearable activity monitors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently used clinical assessments for physical function do not objectively\nquantify daily activities in routine living. Wearable activity monitors enable\nobjective measurement of routine daily activities, but do not map to clinically\nmeasured physical performance measures. We represent physical function as a\ndaily activity profile derived from minute-level activity data obtained via a\nwearable activity monitor. We construct daily activity profiles representing\naverage time spent in a set of activity classes over consecutive days using the\nOsteoarthritis Initiative (OAI) data. Using the daily activity profile as\ninput, we trained statistical models that classify subjects into quartiles of\nobjective measurements of physical function as measured via the 400m walk test,\nthe 20m walk test and 5 times sit stand test. We evaluated model performance on\nheld out data from the same calendar year as that used to train the models as\nwell as on activity data two years into the future. The daily activity profile\npredicts physical performance as measured via clinical assessments. Using held\nout data, the AUC obtained in classifying performance values in the 1st\nquartile was 0.79, 0.78 and 0.72, for the 400m walk, the 20m walk and 5 times\nsit stand tests. For classifying performance values in the 4th quartile, the\nAUC obtained was 0.77, 0.66 and 0.73 respectively. Evaluated on data from two\nyears into the future, for the 20m pace test and the 5 times sit stand tests,\nthe highest AUC obtained was 0.77 and 0.68 for the 1st quartile and 0.75 and\n0.70 for the 4th quartile respectively. We can construct activity profiles\nrepresenting actual physical function as demonstrated by the relationship\nbetween the activity profiles and the clinically measured physical performance\nmeasures. Measurement of physical performance via the activity profile as\ndescribed can enable remote functional monitoring of patients.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 04:08:21 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Agarwal", "Vibhu", ""], ["Smuck", "Matthew", ""], ["Shah", "Nigam H", ""]]}, {"id": "1801.08929", "submitter": "Matthew Levine", "authors": "Matthew E. Levine, David J. Albers, George Hripcsak", "title": "Methodological variations in lagged regression for detecting physiologic\n  drug effects in EHR data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We studied how lagged linear regression can be used to detect the physiologic\neffects of drugs from data in the electronic health record (EHR). We\nsystematically examined the effect of methodological variations ((i) time\nseries construction, (ii) temporal parameterization, (iii) intra-subject\nnormalization, (iv) differencing (lagged rates of change achieved by taking\ndifferences between consecutive measurements), (v) explanatory variables, and\n(vi) regression models) on performance of lagged linear methods in this\ncontext. We generated two gold standards (one knowledge-base derived, one\nexpert-curated) for expected pairwise relationships between 7 drugs and 4 labs,\nand evaluated how the 64 unique combinations of methodological perturbations\nreproduce gold standards. Our 28 cohorts included patients in Columbia\nUniversity Medical Center/NewYork-Presbyterian Hospital clinical database. The\nmost accurate methods achieved AUROC of 0.794 for knowledge-base derived gold\nstandard (95%CI [0.741, 0.847]) and 0.705 for expert-curated gold standard (95%\nCI [0.629, 0.781]). We observed a 0.633 mean AUROC (95%CI [0.610, 0.657],\nexpert-curated gold standard) across all methods that re-parameterize time\naccording to sequence and use either a joint autoregressive model with\ndifferencing or an independent lag model without differencing. The complement\nof this set of methods achieved a mean AUROC close to 0.5, indicating the\nimportance of these choices. We conclude that time- series analysis of EHR data\nwill likely rely on some of the beneficial pre-processing and modeling\nmethodologies identified, and will certainly benefit from continued careful\nanalysis of methodological perturbations. This study found that methodological\nvariations, such as pre-processing and representations, significantly affect\nresults, exposing the importance of evaluating these components when comparing\nmachine-learning methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 18:43:32 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Levine", "Matthew E.", ""], ["Albers", "David J.", ""], ["Hripcsak", "George", ""]]}, {"id": "1801.09231", "submitter": "Saptarshi Das", "authors": "Suparna Dutta Sinha, Saptarshi Das, Sujata Tarafdar, and Tapati Dutta", "title": "Monitoring of Wild Pseudomonas Biofilm Strain Conditions Using\n  Statistical Characterisation of Scanning Electron Microscopy Images", "comments": "34 pages, 14 figures", "journal-ref": "Industrial & Engineering Chemistry Research, volume 56, no. 34,\n  pages 9496-9512, 2017", "doi": "10.1021/acs.iecr.7b01106", "report-no": null, "categories": "physics.bio-ph cond-mat.soft q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper proposes a novel method of quantification of the variation\nin biofilm architecture, in correlation with the alteration of growth\nconditions that include, variations of substrate and conditioning layer. The\npolymeric biomaterial serving as substrates are widely used in implants and\nindwelling medical devices, while the plasma proteins serve as the conditioning\nlayer. The present method uses descriptive statistics of FESEM images of\nbiofilms obtained during a variety of growth conditions. We aim to explore here\nthe texture and fractal analysis techniques, to identify the most\ndiscriminatory features which are capable of predicting the difference in\nbiofilm growth conditions. We initially extract some statistical features of\nbiofilm images on bare polymer surfaces, followed by those on the same\nsubstrates adsorbed with two different types of plasma proteins, viz. Bovine\nserum albumin (BSA) and Fibronectin (FN), for two different adsorption times.\nThe present analysis has the potential to act as a futuristic technology for\ndeveloping a computerized monitoring system in hospitals with automated image\nanalysis and feature extraction, which may be used to predict the growth\nprofile of an emerging biofilm on surgical implants or similar medical\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 13:55:15 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Sinha", "Suparna Dutta", ""], ["Das", "Saptarshi", ""], ["Tarafdar", "Sujata", ""], ["Dutta", "Tapati", ""]]}, {"id": "1801.09257", "submitter": "Hyekyoung Lee", "authors": "Hyekyoung Lee, Eunkyung Kim, Hyejin Kang, Youngmin Huh, Youngjo Lee,\n  Seonhee Lim, Dong Soo Lee", "title": "Volume entropy and information flow in a brain graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy is a classical measure to quantify the amount of information or\ncomplexity of a system. Various entropy-based measures such as functional and\nspectral entropies have been proposed in brain network analysis. However, they\nare less widely used than traditional graph theoretic measures such as global\nand local efficiencies because either they are not well-defined on a graph or\ndifficult to interpret its biological meaning. In this paper, we propose a new\nentropy-based graph invariant, called volume entropy. It measures the\nexponential growth rate of the number of paths in a graph, which is a relevant\nmeasure if information flows through the graph forever. We model the\ninformation propagation on a graph by the generalized Markov system associated\nto the weighted edge-transition matrix. We estimate the volume entropy using\nthe stationary equation of the generalized Markov system. A prominent advantage\nof using the stationary equation is that it assigns certain distribution of\nweights on the edges of the brain graph, which we call the stationary\ndistribution. The stationary distribution shows the information capacity of\nedges and the direction of information flow on a brain graph. The simulation\nresults show that the volume entropy distinguishes the underlying graph\ntopology and geometry better than the existing graph measures. In brain imaging\ndata application, the volume entropy of brain graphs was significantly related\nto healthy normal aging from 20s to 60s. In addition, the stationary\ndistribution of information propagation gives a new insight into the\ninformation flow of functional brain graph.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 17:51:43 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 05:16:50 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Lee", "Hyekyoung", ""], ["Kim", "Eunkyung", ""], ["Kang", "Hyejin", ""], ["Huh", "Youngmin", ""], ["Lee", "Youngjo", ""], ["Lim", "Seonhee", ""], ["Lee", "Dong Soo", ""]]}, {"id": "1801.09372", "submitter": "Tzvetomir Tzvetanov", "authors": "Christian Beste and Daniel Kaping and Tzvetomir Tzvetanov", "title": "Extension of the non-parametric cluster-based time-frequency statistics\n  to the full time windows and to single condition tests", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oscillatory processes are central for the understanding of the neural bases\nof cognition and behaviour. To analyse these processes, time-frequency (TF)\ndecomposition methods are applied and non-parametric cluster-based statistical\nprocedure are used for comparing two or more conditions. While this combination\nis a powerful method, it has two drawbacks. One the unreliable estimation of\nsignals outside the cone-of-influence and the second relates to the length of\nthe time frequency window used for the analysis. Both impose constrains on the\nnon-parametric statistical procedure for inferring an effect in the TF domain.\nHere we extend the method to reliably infer oscillatory differences within the\nfull TF map and to test single conditions. We show that it can be applied in\nsmall time windows irrespective of the cone-of-influence and we further develop\nits application to single-condition case for testing the hypothesis of the\npresence or not of time-varying signals. We present tests of this new method on\nreal EEG and behavioural data and show that its sensitivity to single-condition\ntests is at least as good as classic Fourier analysis. Statistical inference in\nthe full TF map is available and efficient in detecting differences between\nconditions as well as the presence of time-varying signal in single condition.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 06:27:08 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Beste", "Christian", ""], ["Kaping", "Daniel", ""], ["Tzvetanov", "Tzvetomir", ""]]}, {"id": "1801.09831", "submitter": "Sanjana Gupta", "authors": "Sanjana Gupta, Liam Hainsworth, Justin S. Hogg, Robin E. C. Lee, and\n  James R. Faeder", "title": "Evaluation of Parallel Tempering to Accelerate Bayesian Parameter\n  Estimation in Systems Biology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models of biological systems often have many unknown parameters that must be\ndetermined in order for model behavior to match experimental observations.\nCommonly-used methods for parameter estimation that return point estimates of\nthe best-fit parameters are insufficient when models are high dimensional and\nunder-constrained. As a result, Bayesian methods, which treat model parameters\nas random variables and attempt to estimate their probability distributions\ngiven data, have become popular in systems biology. Bayesian parameter\nestimation often relies on Markov Chain Monte Carlo (MCMC) methods to sample\nmodel parameter distributions, but the slow convergence of MCMC sampling can be\na major bottleneck. One approach to improving performance is parallel tempering\n(PT), a physics-based method that uses swapping between multiple Markov chains\nrun in parallel at different temperatures to accelerate sampling. The\ntemperature of a Markov chain determines the probability of accepting an\nunfavorable move, so swapping with higher temperatures chains enables the\nsampling chain to escape from local minima. In this work we compared the MCMC\nperformance of PT and the commonly-used Metropolis-Hastings (MH) algorithm on\nsix biological models of varying complexity. We found that for simpler models\nPT accelerated convergence and sampling, and that for more complex models, PT\noften converged in cases MH became trapped in non-optimal local minima. We also\ndeveloped a freely-available MATLAB package for Bayesian parameter estimation\ncalled PTempEst (http://github.com/RuleWorld/ptempest), which is closely\nintegrated with the popular BioNetGen software for rule-based modeling of\nbiological systems.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 02:45:59 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Gupta", "Sanjana", ""], ["Hainsworth", "Liam", ""], ["Hogg", "Justin S.", ""], ["Lee", "Robin E. C.", ""], ["Faeder", "James R.", ""]]}, {"id": "1801.10189", "submitter": "Jason Swedlow", "authors": "Jan Ellenberg, Jason R Swedlow, Mary Barlow, Charles E Cook, Ardan\n  Patwardhan, Alvis Brazma, and Ewan Birney", "title": "Public archives for biological image data", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": "10.1038/s41592-018-0195-8", "report-no": null, "categories": "q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Public data archives are the backbone of modern biological and biomedical\nresearch. While archives for biological molecules and structures are\nwell-established, resources for imaging data do not yet cover the full range of\nspatial and temporal scales or application domains used by the scientific\ncommunity. In the last few years, the technical barriers to building such\nresources have been solved and the first examples of scientific outputs from\npublic image data resources, often through linkage to existing molecular\nresources, have been published. Using the successes of existing biomolecular\nresources as a guide, we present the rationale and principles for the\nconstruction of image data archives and databases that will be the foundation\nof the next revolution in biological and biomedical informatics and discovery.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 19:44:57 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Ellenberg", "Jan", ""], ["Swedlow", "Jason R", ""], ["Barlow", "Mary", ""], ["Cook", "Charles E", ""], ["Patwardhan", "Ardan", ""], ["Brazma", "Alvis", ""], ["Birney", "Ewan", ""]]}, {"id": "1801.10195", "submitter": "Gianrocco Lazzari", "authors": "Gianrocco Lazzari, Yannis Jaquet, Djilani Kebaili, Laura Symul, Marcel\n  Salath\\'e", "title": "FoodRepo: An Open Food Repository of Barcoded Food Products", "comments": "13 pages, 3 figures", "journal-ref": "Frontiers in Nutrition 5 (2018): 57", "doi": "10.3389/fnut.2018.00057", "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, digital technologies have started to profoundly influence\nhealthcare systems. Digital self-tracking has facilitated more precise\nepidemiological studies, and in the field of nutritional epidemiology, mobile\napps have the potential to alleviate a significant part of the journaling\nburden by, for example, allowing users to record their food intake via a simple\nscan of packaged products barcodes. Such studies thus rely on databases of\ncommercialized products, their barcodes, ingredients, and nutritional values,\nwhich are not yet openly available with sufficient geographical and product\ncoverage. In this paper, we present FoodRepo (https://www.foodrepo.org), an\nopen food repository of barcoded food items, whose database is programmatically\naccessible through an application programming interface (API). Furthermore, an\nopen source license gives the appropriate rights to anyone to share and reuse\nFoodRepo data, including for commercial purposes. With currently more than\n21,000 items available on the Swiss market, our database represents a solid\nstarting point for large-scale studies in the field of digital nutrition, with\nthe aim to lead to a better understanding of the intricate connections between\ndiets and health in general, and metabolic disorders in particular.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 16:22:33 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Lazzari", "Gianrocco", ""], ["Jaquet", "Yannis", ""], ["Kebaili", "Djilani", ""], ["Symul", "Laura", ""], ["Salath\u00e9", "Marcel", ""]]}, {"id": "1801.10227", "submitter": "Song Feng", "authors": "Ryan Suderman, Eshan D. Mitra, Yen Ting Lin, Keesha E. Erickson, Song\n  Feng, William S. Hlavacek", "title": "Generalizing Gillespie's direct method to enable network-free\n  simulations", "comments": "27 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.MN q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gillespie's direct method for stochastic simulation of chemical kinetics is a\nstaple of computational systems biology research. However, the algorithm\nrequires explicit enumeration of all reactions and all chemical species that\nmay arise in the system. In many cases, this is not feasible due to the\ncombinatorial explosion of reactions and species in biological networks.\nRule-based modeling frameworks provide a way to exactly represent networks\ncontaining such combinatorial complexity, and generalizations of Gillespie's\ndirect method have been developed as simulation engines for rule-based modeling\nlanguages. Here, we provide both a high-level description of the algorithms\nunderlying the simulation engines, termed network-free simulation algorithms,\nand how they have been applied in systems biology research. We also define a\ngeneric rule-based modeling framework and describe a number of technical\ndetails required for adapting Gillespie's direct method for network-free\nsimulation. Finally, we briefly discuss potential avenues for advancing\nnetwork-free simulation and the role they continue to play in modeling\ndynamical systems in biology.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 21:13:04 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Suderman", "Ryan", ""], ["Mitra", "Eshan D.", ""], ["Lin", "Yen Ting", ""], ["Erickson", "Keesha E.", ""], ["Feng", "Song", ""], ["Hlavacek", "William S.", ""]]}, {"id": "1801.10562", "submitter": "Min Xu", "authors": "Bo Zhou, Qiang Guo, Xiangrui Zeng, Min Xu", "title": "Feature Decomposition Based Saliency Detection in Electron\n  Cryo-Tomograms", "comments": "14 pages", "journal-ref": "IEEE International Conference on Bioinformatics & Biomedicine,\n  Workshop on Machine Learning in High Resolution Microscopy (BIBM-MLHRM 2018)", "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electron Cryo-Tomography (ECT) allows 3D visualization of subcellular\nstructures at the submolecular resolution in close to the native state.\nHowever, due to the high degree of structural complexity and imaging limits,\nthe automatic segmentation of cellular components from ECT images is very\ndifficult. To complement and speed up existing segmentation methods, it is\ndesirable to develop a generic cell component segmentation method that is 1)\nnot specific to particular types of cellular components, 2) able to segment\nunknown cellular components, 3) fully unsupervised and does not rely on the\navailability of training data. As an important step towards this goal, in this\npaper, we propose a saliency detection method that computes the likelihood that\na subregion in a tomogram stands out from the background. Our method consists\nof four steps: supervoxel over-segmentation, feature extraction, feature matrix\ndecomposition, and computation of saliency. The method produces a distribution\nmap that represents the regions' saliency in tomograms. Our experiments show\nthat our method can successfully label most salient regions detected by a human\nobserver, and able to filter out regions not containing cellular components.\nTherefore, our method can remove the majority of the background region, and\nsignificantly speed up the subsequent processing of segmentation and\nrecognition of cellular components captured by ECT.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 17:25:14 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Zhou", "Bo", ""], ["Guo", "Qiang", ""], ["Zeng", "Xiangrui", ""], ["Xu", "Min", ""]]}, {"id": "1801.10597", "submitter": "Min Xu", "authors": "Jialiang Guo, Bo Zhou, Xiangrui Zeng, Zachary Freyberg, Min Xu", "title": "Model compression for faster structural separation of macromolecules\n  captured by Cellular Electron Cryo-Tomography", "comments": "8 pages", "journal-ref": "International Conference on Image Analysis and Recognition (ICIAR)\n  2018", "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electron Cryo-Tomography (ECT) enables 3D visualization of macromolecule\nstructure inside single cells. Macromolecule classification approaches based on\nconvolutional neural networks (CNN) were developed to separate millions of\nmacromolecules captured from ECT systematically. However, given the fast\naccumulation of ECT data, it will soon become necessary to use CNN models to\nefficiently and accurately separate substantially more macromolecules at the\nprediction stage, which requires additional computational costs. To speed up\nthe prediction, we compress classification models into compact neural networks\nwith little in accuracy for deployment. Specifically, we propose to perform\nmodel compression through knowledge distillation. Firstly, a complex teacher\nnetwork is trained to generate soft labels with better classification\nfeasibility followed by training of customized student networks with simple\narchitectures using the soft label to compress model complexity. Our tests\ndemonstrate that our compressed models significantly reduce the number of\nparameters and time cost while maintaining similar classification accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 18:39:41 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Guo", "Jialiang", ""], ["Zhou", "Bo", ""], ["Zeng", "Xiangrui", ""], ["Freyberg", "Zachary", ""], ["Xu", "Min", ""]]}]