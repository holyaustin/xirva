[{"id": "1705.00004", "submitter": "Daniel Wilson", "authors": "Daniel Wilson and Helen Byrne and Maria Bruna", "title": "Reactions, Diffusion and Volume Exclusion in a Heterogeneous System of\n  Interacting Particles", "comments": "13 pages, 4 figures", "journal-ref": "Phys. Rev. E 97, 062137 (2018)", "doi": "10.1103/PhysRevE.97.062137", "report-no": null, "categories": "cond-mat.stat-mech physics.chem-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex biological and physical transport processes are often described\nthrough systems of interacting particles. Excluded-volume effects on these\ntransport processes are well studied, however the interplay between volume\nexclusion and reactions between heterogenous particles is less well known. In\nthis paper we develop a novel framework for modeling reaction-diffusion\nprocesses which directly incorporates volume exclusion. From an off-lattice\nmicroscopic individual based model we use the Fokker--Planck equation and the\nmethod of matched asymptotic expansions to derive a low-dimensional macroscopic\nsystem of nonlinear partial differential equations describing the evolution of\nthe particles. A biologically motivated, hybrid model of chemotaxis with volume\nexclusion is explored, where reactions occur at rates dependent upon the\nchemotactic environment. Further, we show that for reactions due to contact\ninteractions the appropriate reaction term in the macroscopic model is of lower\norder in the asymptotic expansion than the nonlinear diffusion term. However,\nwe find that the next reaction term in the expansion is needed to ensure good\nagreement with simulations of the microscopic model. Our macroscopic model\nallows for more direct parameterization to experimental data than the models\navailable to date.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 11:49:53 GMT"}, {"version": "v2", "created": "Wed, 10 May 2017 09:06:10 GMT"}, {"version": "v3", "created": "Mon, 2 Apr 2018 11:29:53 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Wilson", "Daniel", ""], ["Byrne", "Helen", ""], ["Bruna", "Maria", ""]]}, {"id": "1705.00121", "submitter": "G Ambika", "authors": "Snehal M. Shekatkar, Yamini Kotriwar, K.P. Harikrishnan and G. Ambika", "title": "Detecting abnormality in heart dynamics from multifractal analysis of\n  ECG signals", "comments": "6 pages, 13b figures, submitted to PNAS", "journal-ref": "Scientific Reports 7: 15127 2017", "doi": "10.1038/s41598-017-15498-z", "report-no": null, "categories": "q-bio.TO nlin.CD q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characterization of heart dynamics with a view to distinguish abnormal\nfrom normal behavior is an interesting topic in clinical sciences. Here we\npresent an analysis of the Electro-cardiogram (ECG) signals obtained under\ncontrolled conditions from several healthy and unhealthy subjects using the\nframework of multifractal analysis. Our analysis differs from the conventional\nnonlinear analysis in that the information contained in the amplitude\nvariations of the signal is being extracted and quantified. The results thus\nobtained reveal that the attractor underlying the dynamics of the heart has\nmultifractal structure and the resultant multifractal spectra can clearly\nseparate healthy subjects from unhealthy ones. We use supervised machine\nlearning approach to build a model that predicts the group label of a new\nsubject with very high accuracy on the basis of the multifractal parameters. By\ncomparing the range of scaling indices in the multifractal spectra with that of\nbeat replicated data from the same ECG, we show how each ECG can be checked for\nabnormality for variations within itself.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 03:15:13 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Shekatkar", "Snehal M.", ""], ["Kotriwar", "Yamini", ""], ["Harikrishnan", "K. P.", ""], ["Ambika", "G.", ""]]}, {"id": "1705.00400", "submitter": "Francesca Parise", "authors": "Francesca Parise, Maria Elena Valcher and John Lygeros", "title": "Computing the projected reachable set of switched affine systems: an\n  application to systems biology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY math.OC q-bio.MN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental question in systems biology is what combinations of mean and\nvariance of the species present in a stochastic biochemical reaction network\nare attainable by perturbing the system with an external signal. To address\nthis question, we show that the moments evolution in any generic network can be\neither approximated or, under suitable assumptions, computed exactly as the\nsolution of a switched affine system. Motivated by this application, we propose\na new method to approximate the reachable set of switched affine systems. A\nremarkable feature of our approach is that it allows one to easily compute\nprojections of the reachable set for pairs of moments of interest, without\nrequiring the computation of the full reachable set, which can be prohibitive\nfor large networks. As a second contribution, we also show how to select the\nexternal signal in order to maximize the probability of reaching a target set.\nTo illustrate the method we study a renown model of controlled gene expression\nand we derive estimates of the reachable set, for the protein mean and\nvariance, that are more accurate than those available in the literature and\nconsistent with experimental data.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 02:11:24 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Parise", "Francesca", ""], ["Valcher", "Maria Elena", ""], ["Lygeros", "John", ""]]}, {"id": "1705.00708", "submitter": "Alexandra Koulouri", "authors": "Alexandra Koulouri", "title": "Overcoming the ill-posedness through discretization in vector\n  tomography: Reconstruction of irrotational vector fields", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector tomography methods intend to reconstruct and visualize vector fields\nin restricted domains by measuring line integrals of projections of these\nvector fields. Here, we deal with the reconstruction of irrotational vector\nfunctions from boundary measurements. As the majority of inverse problems,\nvector field recovery is an ill posed in the continuous domain and therefore\nfurther assumptions, measurements and constraints should be imposed for the\nfull vector field estimation. The reconstruction idea in the discrete domain\nrelies on solving a numerical system of linear equations which derives from the\napproximation of the line integrals along lines which trace the bounded domain.\nThis work presents an extensive description of a vector field recovery, the\nfundamental assumptions and the ill conditioning of this inverse problem. More\nimportantly we show that this inverse problem is regularized via the domain\ndiscretization, i.e. we show that the recovery of an irrotational vector field\nwithin a discrete grid employing a finite set of longitudinal line integrals,\nleads to a consistent linear system which has bounded solution errors. We\nelaborate on the estimation of the solution's error and we prove that this\nrelative error is finite and therefore a stable vector field reconstruction is\nensured. Such theoretical aspects are critical for future implementations of\nvector tomography in practical applications like the inverse bioelectric field\nproblem. We validate our theoretical results by performing simulations that\nreconstruct smooth irrotational fields based solely on a finite number of\nboundary measurements and without the need of any additional or prior\ninformation (e.g. transversal line integrals or source free assumption).\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 20:00:36 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Koulouri", "Alexandra", ""]]}, {"id": "1705.01135", "submitter": "Eben Kenah", "authors": "Yushuf Sharker and Eben Kenah", "title": "Estimating and interpreting secondary attack risk: Binomial considered\n  harmful", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The household secondary attack risk (SAR), often called the secondary attack\nrate or secondary infection risk, is the probability of infectious contact from\nan infectious household member A to a given household member B, where we define\ninfectious contact to be a contact sufficient to infect B if he or she is\nsusceptible. Estimation of the SAR is an important part of understanding and\ncontrolling the transmission of infectious diseases. In practice, it is most\noften estimated using binomial models such as logistic regression, which\nimplicitly attribute all secondary infections in a household to the primary\ncase. In the simplest case, the number of secondary infections in a household\nwith m susceptibles and a single primary case is modeled as a binomial(m, p)\nrandom variable where p is the SAR. Although it has long been understood that\ntransmission within households is not binomial, it is thought that multiple\ngenerations of transmission can be safely neglected when p is small. We use\nprobability generating functions and simulations to show that this is a\nmistake. The proportion of susceptible household members infected can be\nsubstantially larger than the SAR even when p is small. As a result, binomial\nestimates of the SAR are biased upward and their confidence intervals have poor\ncoverage probabilities even if adjusted for clustering. Accurate point and\ninterval estimates of the SAR can be obtained using longitudinal chain binomial\nmodels or pairwise survival analysis, which account for multiple generations of\ntransmission within households, the ongoing risk of infection from outside the\nhousehold, and incomplete follow-up. We illustrate the practical implications\nof these results in an analysis of household surveillance data collected by the\nLos Angeles County Department of Public Health during the 2009 influenza A\n(H1N1) pandemic.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 18:37:44 GMT"}, {"version": "v2", "created": "Fri, 17 Jul 2020 05:15:31 GMT"}], "update_date": "2020-07-20", "authors_parsed": [["Sharker", "Yushuf", ""], ["Kenah", "Eben", ""]]}, {"id": "1705.01213", "submitter": "Emanuele Crosato", "authors": "Emanuele Crosato, Li Jiang, Valentin Lecheval, Joseph T. Lizier, X.\n  Rosalind Wang, Pierre Tichit, Guy Theraulaz, Mikhail Prokopenko", "title": "Informative and misinformative interactions in a school of fish", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.IT math.IT nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally accepted that, when moving in groups, animals process\ninformation to coordinate their motion. Recent studies have begun to apply\nrigorous methods based on Information Theory to quantify such distributed\ncomputation. Following this perspective, we use transfer entropy to quantify\ndynamic information flows locally in space and time across a school of fish\nduring directional changes around a circular tank, i.e. U-turns. This analysis\nreveals peaks in information flows during collective U-turns and identifies two\ndifferent flows: an informative flow (positive transfer entropy) based on fish\nthat have already turned about fish that are turning, and a misinformative flow\n(negative transfer entropy) based on fish that have not turned yet about fish\nthat are turning. We also reveal that the information flows are related to\nrelative position and alignment between fish, and identify spatial patterns of\ninformation and misinformation cascades. This study offers several\nmethodological contributions and we expect further application of these\nmethodologies to reveal intricacies of self-organisation in other animal groups\nand active matter in general.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 01:03:23 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Crosato", "Emanuele", ""], ["Jiang", "Li", ""], ["Lecheval", "Valentin", ""], ["Lizier", "Joseph T.", ""], ["Wang", "X. Rosalind", ""], ["Tichit", "Pierre", ""], ["Theraulaz", "Guy", ""], ["Prokopenko", "Mikhail", ""]]}, {"id": "1705.01620", "submitter": "Vladimir Boza", "authors": "Vladim\\'ir Bo\\v{z}a, Bro\\v{n}a Brejov\\'a, Tom\\'a\\v{s} Vina\\v{r}", "title": "Improving Nanopore Reads Raw Signal Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate usage of dynamic time warping (DTW) algorithm for aligning raw\nsignal data from MinION sequencer. DTW is mostly using for fast alignment for\nselective sequencing to quickly determine whether a read comes from sequence of\ninterest.\n  We show that standard usage of DTW has low discriminative power mainly due to\nproblem with accurate estimation of scaling parameters. We propose a simple\nvariation of DTW algorithm, which does not suffer from scaling problems and has\nmuch higher discriminative power.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 20:58:54 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Bo\u017ea", "Vladim\u00edr", ""], ["Brejov\u00e1", "Bro\u0148a", ""], ["Vina\u0159", "Tom\u00e1\u0161", ""]]}, {"id": "1705.01643", "submitter": "Haley Clark", "authors": "Haley D. Clark, Stefan A. Reinsberg, Vitali Moiseenko, Jonn Wu, and\n  Steven D. Thomas", "title": "Prefer Nested Segmentation to Compound Segmentation", "comments": "7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM physics.med-ph q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction: Intra-organ radiation dose sensitivity is becoming increasingly\nrelevant in clinical radiotherapy. One method for assessment involves\npartitioning delineated regions of interest and comparing the relative\ncontributions or importance to clinical outcomes. We show that an intuitive\nmethod for dividing organ contours, compound (sub-)segmentation, can\nunintentionally lead to sub-segments with inconsistent volumes, which will bias\nrelative importance assessment. An improved technique, nested segmentation, is\nintroduced and compared. Methods: Clinical radiotherapy planning parotid\ncontours from 510 patients were segmented. Counts of radiotherapy dose matrix\nvoxels interior to sub-segments were used to determine the equivalency of\nsub-segment volumes. The distribution of voxel counts within sub-segments were\ncompared using Kolmogorov-Smirnov tests and characterized by their dispersion.\nAnalytical solutions for 2D/3D analogues were derived and sub-segment\narea/volume were compared directly. Results: Both parotid and 2D/3D region of\ninterest analogue segmentation confirmed compound segmentation intrinsically\nproduces sub-segments with volumes that depend on the region of interest shape\nand selection location. Significant volume differences were observed when\nsub-segmenting parotid contours into 18ths, and vanishingly small sub-segments\nwere observed when sub-segmenting into 96ths. Central sub-segments were\nconsiderably smaller than sub-segments on the periphery. Nested segmentation\ndid not exhibit these shortcomings and produced sub-segments with equivalent\nvolumes when dose grid and contour collinearity was addressed, even when\ndividing the parotid into 96ths. Nested segmentation was always faster or\nequivalent in runtime to compound segmentation. Conclusions: Nested\nsegmentation is more suited than compound segmentation for analyses requiring\nequal weighting of sub-segments.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 22:38:11 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Clark", "Haley D.", ""], ["Reinsberg", "Stefan A.", ""], ["Moiseenko", "Vitali", ""], ["Wu", "Jonn", ""], ["Thomas", "Steven D.", ""]]}, {"id": "1705.01667", "submitter": "Masahito Ohue", "authors": "Masahito Ohue, Takuro Yamazaki, Tomohiro Ban, and Yutaka Akiyama", "title": "Link Mining for Kernel-based Compound-Protein Interaction Predictions\n  Using a Chemogenomics Approach", "comments": null, "journal-ref": "In the Thirteenth International Conference on Intelligent\n  Computing (ICIC2017), Lecture Notes in Computer Science, 10362: 549-558, 2017", "doi": "10.1007/978-3-319-63312-1_48", "report-no": null, "categories": "q-bio.QM cs.CE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual screening (VS) is widely used during computational drug discovery to\nreduce costs. Chemogenomics-based virtual screening (CGBVS) can be used to\npredict new compound-protein interactions (CPIs) from known CPI network data\nusing several methods, including machine learning and data mining. Although\nCGBVS facilitates highly efficient and accurate CPI prediction, it has poor\nperformance for prediction of new compounds for which CPIs are unknown. The\npairwise kernel method (PKM) is a state-of-the-art CGBVS method and shows high\naccuracy for prediction of new compounds. In this study, on the basis of link\nmining, we improved the PKM by combining link indicator kernel (LIK) and\nchemical similarity and evaluated the accuracy of these methods. The proposed\nmethod obtained an average area under the precision-recall curve (AUPR) value\nof 0.562, which was higher than that achieved by the conventional Gaussian\ninteraction profile (GIP) method (0.425), and the calculation time was only\nincreased by a few percent.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 01:29:19 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 03:46:09 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ohue", "Masahito", ""], ["Yamazaki", "Takuro", ""], ["Ban", "Tomohiro", ""], ["Akiyama", "Yutaka", ""]]}, {"id": "1705.02026", "submitter": "Carlos Martinez Mr.", "authors": "Carlos A. Mart\\'inez, Kshitij Khare, Syed Rahman, Mauricio A. Elzo", "title": "Inferring the Partial Correlation Structure of Allelic Effects and\n  Incorporating it in Genome-wide Prediction", "comments": "25 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we addressed the problem of genome-wide prediction accounting\nfor partial correlation of marker effects when the partial correlation\nstructure, or equivalently, the pattern of zeros of the precision matrix is\nunknown. This problem requires estimating the partial correlation structure of\nmarker effects, that is, learning the pattern of zeros of the corresponding\nprecision matrix, estimating its non-null entries, and incorporating the\ninferred concentration matrix in the prediction of marker allelic effects. To\nthis end, we developed a set of statistical methods based on Gaussian\nconcentration graph models (GCGM) and Gaussian directed acyclic graph models\n(GDAGM) that adapt the existing theory to perform covariance model selection\n(GCGM) or DAG selection (GDAGM) to genome-wide prediction. Bayesian and\nfrequentist approaches were formulated. Our frequentist formulations combined\nsome existing methods with the EM algorithm and were termed Glasso-EM,\nCONCORD-EM and CSCS-EM, whereas our Bayesian formulations corresponded to\nhierarchical models termed Bayes G-Sel and Bayes DAG-Sel. Results from a\nsimulation study showed that our methods can accurately recover the partial\ncorrelation structure and estimate the precision matrix. Methods CONCORD-EM and\nBayes G-Sel had an outstanding performance in estimating the partial\ncorrelation structure and a method based on CONCORD-EM yielded the most\naccurate estimates of the precision matrix. Our methods can be used as\npredictive machines and as tools to learn about the covariation of effects of\npairs of loci on a given phenotype conditioned on the effects of all the other\nloci considered in the model. Therefore, they are useful tools to learn about\nthe underlying biology of a given trait because they help to understand\nrelationships between different regions of the genome in terms of the partial\ncorrelations of their effects on that trait.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 21:25:54 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Mart\u00ednez", "Carlos A.", ""], ["Khare", "Kshitij", ""], ["Rahman", "Syed", ""], ["Elzo", "Mauricio A.", ""]]}, {"id": "1705.02168", "submitter": "Victor Maltsev", "authors": "Alexander V. Maltsev, Sean P. Parsons, Mary S. Kim, Kenta Tsutsui,\n  Michael D. Stern, Edward G Lakatta, Victor A. Maltsev, Oliver Monfredi", "title": "Computer Algorithms for Automated Detection and Analysis of Local Ca2+\n  Releases in Spontaneously Beating Cardiac Pacemaker Cells", "comments": "43 pages, 7 figures, 2 tables, 5 videos (with web links)", "journal-ref": null, "doi": "10.1371/journal.pone.0179419", "report-no": null, "categories": "q-bio.SC q-bio.QM", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Local Ca Releases (LCRs) are crucial events involved in cardiac pacemaker\ncell function. However, specific algorithms for automatic LCR detection and\nanalysis have not been developed in live, spontaneously beating pacemaker\ncells. Here we measured LCRs using a high-speed 2D-camera in spontaneously\ncontracting sinoatrial (SA) node cells isolated from rabbit and guinea pig and\ndeveloped a new algorithm capable of detecting and analyzing the LCRs spatially\nin two-dimensions, and in time. Our algorithm tracks points along the midline\nof the contracting cell. It uses these points as a coordinate system for affine\ntransform, producing a transformed image series where the cell does not\ncontract. Action potential-induced Ca transients and LCRs were thereafter\nisolated from recording noise by applying a series of spatial filters. The LCR\nbirth and death events were detected by a differential (frame-to-frame)\nsensitivity algorithm. An LCR was detected when its signal changes sufficiently\nquickly within a sufficiently large area. The LCR is considered to have died\nwhen its amplitude decays substantially, or when it merges into the rising\nwhole cell Ca transient. Our algorithm provides major LCR parameters such as\nperiod, signal mass, duration, and path area. As LCRs propagate within cells,\nthe algorithm identifies splitting and merging behaviors, indicating the\nimportance of Ca-induced-Ca-release for the fate of LCRs and for generating a\npowerful ensemble Ca signal. Thus, our new computer algorithms eliminate motion\nartifacts and detect 2D local spatiotemporal Ca release events from recording\nnoise and global signals. While the algorithms detect LCRs in sinoatrial nodal\ncells, they have the potential to be used in other applications in biophysics\nand cell physiology, for example, to detect Ca wavelets (abortive waves),\nsparks and embers in muscle cells and Ca puffs and syntillas in neurons.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 10:57:32 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Maltsev", "Alexander V.", ""], ["Parsons", "Sean P.", ""], ["Kim", "Mary S.", ""], ["Tsutsui", "Kenta", ""], ["Stern", "Michael D.", ""], ["Lakatta", "Edward G", ""], ["Maltsev", "Victor A.", ""], ["Monfredi", "Oliver", ""]]}, {"id": "1705.02344", "submitter": "Jakob Knollm\\\"uller", "authors": "Jakob Knollm\\\"uller, Torsten A. En{\\ss}lin", "title": "Noisy independent component analysis of auto-correlated components", "comments": null, "journal-ref": "Phys. Rev. E 96, 042114 (2017)", "doi": "10.1103/PhysRevE.96.042114", "report-no": null, "categories": "stat.ME astro-ph.IM physics.data-an q-bio.QM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new method for the separation of superimposed, independent,\nauto-correlated components from noisy multi-channel measurement. The presented\nmethod simultaneously reconstructs and separates the components, taking all\nchannels into account and thereby increases the effective signal-to-noise ratio\nconsiderably, allowing separations even in the high noise regime.\nCharacteristics of the measurement instruments can be included, allowing for\napplication in complex measurement situations. Independent posterior samples\ncan be provided, permitting error estimates on all desired quantities. Using\nthe concept of information field theory, the algorithm is not restricted to any\ndimensionality of the underlying space or discretization scheme thereof.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 18:00:04 GMT"}, {"version": "v2", "created": "Fri, 4 Aug 2017 10:17:59 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Knollm\u00fcller", "Jakob", ""], ["En\u00dflin", "Torsten A.", ""]]}, {"id": "1705.02612", "submitter": "Joachim Draeger", "authors": "Joachim Draeger", "title": "Some Remarks about the Complexity of Epidemics Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph q-bio.PE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent outbreaks of Ebola, H1N1 and other infectious diseases have shown that\nthe assumptions underlying the established theory of epidemics management are\ntoo idealistic. For an improvement of procedures and organizations involved in\nfighting epidemics, extended models of epidemics management are required. The\nnecessary extensions consist in a representation of the management loop and the\npotential frictions influencing the loop. The effects of the non-deterministic\nfrictions can be taken into account by including the measures of robustness and\nrisk in the assessment of management options. Thus, besides of the increased\nstructural complexity resulting from the model extensions, the computational\ncomplexity of the task of epidemics management - interpreted as an optimization\nproblem - is increased as well. This is a serious obstacle for analyzing the\nmodel and may require an additional pre-processing enabling a simplification of\nthe analysis process. The paper closes with an outlook discussing some\nforthcoming problems.\n", "versions": [{"version": "v1", "created": "Sun, 7 May 2017 12:55:21 GMT"}, {"version": "v2", "created": "Sun, 18 Jun 2017 11:58:36 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Draeger", "Joachim", ""]]}, {"id": "1705.02867", "submitter": "Alberto Sorrentino", "authors": "Alberto Sorrentino and Michele Piana", "title": "Inverse Modeling for MEG/EEG data", "comments": "15 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an overview of the state-of-the-art for mathematical methods that\nare used to reconstruct brain activity from neurophysiological data. After a\nbrief introduction on the mathematics of the forward problem, we discuss\nstandard and recently proposed regularization methods, as well as Monte Carlo\ntechniques for Bayesian inference. We classify the inverse methods based on the\nunderlying source model, and discuss advantages and disadvantages. Finally we\ndescribe an application to the pre-surgical evaluation of epileptic patients.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 13:37:23 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Sorrentino", "Alberto", ""], ["Piana", "Michele", ""]]}, {"id": "1705.03094", "submitter": "Xueyang Feng", "authors": "Weihua Guo, You Xu, and Xueyang Feng", "title": "DeepMetabolism: A Deep Learning System to Predict Phenotype from Genome\n  Sequencing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN q-bio.QM", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Life science is entering a new era of petabyte-level sequencing data.\nConverting such big data to biological insights represents a huge challenge for\ncomputational analysis. To this end, we developed DeepMetabolism, a\nbiology-guided deep learning system to predict cell phenotypes from\ntranscriptomics data. By integrating unsupervised pre-training with supervised\ntraining, DeepMetabolism is able to predict phenotypes with high accuracy\n(PCC>0.92), high speed (<30 min for >100 GB data using a single GPU), and high\nrobustness (tolerate up to 75% noise). We envision DeepMetabolism to bridge the\ngap between genotype and phenotype and to serve as a springboard for\napplications in synthetic biology and precision medicine.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 21:26:07 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Guo", "Weihua", ""], ["Xu", "You", ""], ["Feng", "Xueyang", ""]]}, {"id": "1705.03318", "submitter": "Luiz Gustavo de Andrade  Alves", "authors": "Luiz G. A. Alves, Peter B. Winter, Leonardo N. Ferreira, Ren\\'ee M.\n  Brielmann, Richard I. Morimoto, Lu\\'is A. N. Amaral", "title": "Long-range correlations and fractal dynamics in C. elegans: changes with\n  aging and stress", "comments": "Accepted for publication in Physical Review E", "journal-ref": "Phys. Rev. E 96, 022417 (2017)", "doi": "10.1103/PhysRevE.96.022417", "report-no": null, "categories": "q-bio.QM physics.bio-ph physics.med-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduced motor control is one of the most frequent features associated with\naging and disease. Nonlinear and fractal analyses have proved to be useful in\ninvestigating human physiological alterations with age and disease. Similar\nfindings have not been established for any of the model organisms typically\nstudied by biologists, though. If the physiology of a simpler model organism\ndisplays the same characteristics, this fact would open a new research window\non the control mechanisms that organisms use to regulate physiological\nprocesses during aging and stress. Here, we use a recently introduced animal\ntracking technology to simultaneously follow tens of Caenorhabdits elegans for\nseveral hours and use tools from fractal physiology to quantitatively evaluate\nthe effects of aging and temperature stress on nematode motility. Similarly to\nhuman physiological signals, scaling analysis reveals long-range correlations\nin numerous motility variables, fractal properties in behavioral shifts, and\nfluctuation dynamics over a wide range of timescales. These properties change\nas a result of a superposition of age and stress-related adaptive mechanisms\nthat regulate motility.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 16:57:52 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 01:48:53 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Alves", "Luiz G. A.", ""], ["Winter", "Peter B.", ""], ["Ferreira", "Leonardo N.", ""], ["Brielmann", "Ren\u00e9e M.", ""], ["Morimoto", "Richard I.", ""], ["Amaral", "Lu\u00eds A. N.", ""]]}, {"id": "1705.03321", "submitter": "Hamid Reza Hassanzadeh", "authors": "Hamid Reza Hassanzadeh, Pushkar Kolhe, Charles L. Isbell, May D. Wang", "title": "MotifMark: Finding Regulatory Motifs in DNA Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interaction between proteins and DNA is a key driving force in a\nsignificant number of biological processes such as transcriptional regulation,\nrepair, recombination, splicing, and DNA modification. The identification of\nDNA-binding sites and the specificity of target proteins in binding to these\nregions are two important steps in understanding the mechanisms of these\nbiological activities. A number of high-throughput technologies have recently\nemerged that try to quantify the affinity between proteins and DNA motifs.\nDespite their success, these technologies have their own limitations and fall\nshort in precise characterization of motifs, and as a result, require further\ndownstream analysis to extract useful and interpretable information from a\nhaystack of noisy and inaccurate data. Here we propose MotifMark, a new\nalgorithm based on graph theory and machine learning, that can find binding\nsites on candidate probes and rank their specificity in regard to the\nunderlying transcription factor. We developed a pipeline to analyze\nexperimental data derived from compact universal protein binding microarrays\nand benchmarked it against two of the most accurate motif search methods. Our\nresults indicate that MotifMark can be a viable alternative technique for\nprediction of motif from protein binding microarrays and possibly other related\nhigh-throughput techniques.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 14:50:12 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Hassanzadeh", "Hamid Reza", ""], ["Kolhe", "Pushkar", ""], ["Isbell", "Charles L.", ""], ["Wang", "May D.", ""]]}, {"id": "1705.03457", "submitter": "Omer Faruk Gulban", "authors": "Omer Faruk Gulban", "title": "The relation between color spaces and compositional data analysis\n  demonstrated with magnetic resonance image processing applications", "comments": "13 pages, 3 figures, short paper, submitted to Austrian Journal of\n  Statistics compositional data analysis special issue, first revision, fix\n  rendering error in fig2", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel application of compositional data analysis\nmethods in the context of color image processing. A vector decomposition method\nis proposed to reveal compositional components of any vector with positive\ncomponents followed by compositional data analysis to demonstrate the relation\nbetween color space concepts such as hue and saturation to their compositional\ncounterparts. The proposed methods are applied to a magnetic resonance imaging\ndataset acquired from a living human brain and a digital color photograph to\nperform image fusion. Potential future applications in magnetic resonance\nimaging are mentioned and the benefits/disadvantages of the proposed methods\nare discussed in terms of color image processing.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 07:14:26 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 17:50:56 GMT"}, {"version": "v3", "created": "Tue, 27 Mar 2018 16:35:10 GMT"}, {"version": "v4", "created": "Mon, 11 Jun 2018 10:19:36 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Gulban", "Omer Faruk", ""]]}, {"id": "1705.03868", "submitter": "Abhirup Ghosh", "authors": "Abhirup Ghosh, Samit Bhattacharyya, Somdatta Sinha, Amit Apte", "title": "Parameter Estimation in Models with Complex Dynamics", "comments": "25 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CD q-bio.PE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical models of real life phenomena are highly nonlinear involving\nmultiple parameters and often exhibiting complex dynamics. Experimental data\nsets are typically small and noisy, rendering estimation of parameters from\nsuch data unreliable and difficult. This paper presents a study of the Bayesian\nposterior distribution for unknown parameters of two chaotic discrete dynamical\nsystems conditioned on observations of the system. The study shows how the\nqualitative properties of the posterior are affected by the intrinsic noise\npresent in the data, the representation of this noise in the parameter\nestimation process, and the length of the data-set. The results indicate that\nincreasing length of dataset does not significantly increase the precision of\nthe estimate, and this is true for both periodic and chaotic data. On the other\nhand, increasing precision of the measurements leads to significant increase in\nprecision of the estimated parameter in case of periodic data, but not in the\ncase of chaotic data. These results are highly useful in designing laboratory\nand field-based studies in biology in general, and ecology and conservation in\nparticular.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 17:34:59 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Ghosh", "Abhirup", ""], ["Bhattacharyya", "Samit", ""], ["Sinha", "Somdatta", ""], ["Apte", "Amit", ""]]}, {"id": "1705.03998", "submitter": "Jiahui Liu", "authors": "YaoGong Zhang, YingJie Xu, Xin Fan, YuXiang Hong, Jiahui Liu, ZhiCheng\n  He, YaLou Huang and MaoQiang Xie", "title": "Mining Functional Modules by Multiview-NMF of Phenome-Genome Association", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Mining gene modules from genomic data is an important step to\ndetect gene members of pathways or other relations such as protein-protein\ninteractions. In this work, we explore the plausibility of detecting gene\nmodules by factorizing gene-phenotype associations from a phenotype ontology\nrather than the conventionally used gene expression data. In particular, the\nhierarchical structure of ontology has not been sufficiently utilized in\nclustering genes while functionally related genes are consistently associated\nwith phenotypes on the same path in the phenotype ontology. Results: We propose\na hierarchal Nonnegative Matrix Factorization (NMF)-based method, called\nConsistent Multiple Nonnegative Matrix Factorization (CMNMF), to factorize\ngenome-phenome association matrix at two levels of the hierarchical structure\nin phenotype ontology for mining gene functional modules. CMNMF constrains the\ngene clusters from the association matrices at two consecutive levels to be\nconsistent since the genes are annotated with both the child phenotype and the\nparent phenotype in the consecutive levels. CMNMF also restricts the identified\nphenotype clusters to be densely connected in the phenotype ontology hierarchy.\nIn the experiments on mining functionally related genes from mouse phenotype\nontology and human phenotype ontology, CMNMF effectively improved clustering\nperformance over the baseline methods. Gene ontology enrichment analysis was\nalso conducted to reveal interesting gene modules. Conclusions: Utilizing the\ninformation in the hierarchical structure of phenotype ontology, CMNMF can\nidentify functional gene modules with more biological significance than the\nconventional methods. CMNMF could also be a better tool for predicting members\nof gene pathways and protein-protein interactions. Availability:\nhttps://github.com/nkiip/CMNMF\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 03:33:26 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Zhang", "YaoGong", ""], ["Xu", "YingJie", ""], ["Fan", "Xin", ""], ["Hong", "YuXiang", ""], ["Liu", "Jiahui", ""], ["He", "ZhiCheng", ""], ["Huang", "YaLou", ""], ["Xie", "MaoQiang", ""]]}, {"id": "1705.04182", "submitter": "Edgardo Brigatti", "authors": "E. Brigatti and A. Hern\\'andez", "title": "Exploring the onset of collective motion in self-organised trails of\n  social organisms", "comments": "11 pages, 5 figures", "journal-ref": "Physica A 496 (2018) 474-480", "doi": "10.1016/j.physa.2017.12.147", "report-no": null, "categories": "nlin.AO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the emergence of self-organised trails between two specific\ntarget areas in collective motion of social organisms by means of an\nagent-based model. We present numerical evidences that an increase in the\nefficiency of navigation in dependence of the colony size, exists. Moreover,\nthe shift, from the diffusive to the directed motion can be quantitatively\ncharacterised, identifying and measuring a well defined crossover point. This\npoint corresponds to the minimal number of individuals necessary for the onset\nof collective cooperation. Finally, by means of a finite-size scaling analysis,\nwe describe its scaling behavior as a function of the environment size. This\nlast result can be of particular interest for interpreting empirical\nobservations or for the design of artificial swarms.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 13:45:12 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 11:23:07 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Brigatti", "E.", ""], ["Hern\u00e1ndez", "A.", ""]]}, {"id": "1705.04312", "submitter": "Alexej Gossmann", "authors": "Alexej Gossmann, Pascal Zille, Vince Calhoun, and Yu-Ping Wang", "title": "FDR-Corrected Sparse Canonical Correlation Analysis with Applications to\n  Imaging Genomics", "comments": "- Clarification of the definition of FDR for CCA in Section III;\n  results unchanged. - Corrected typos. - Added IEEE copyright notice for the\n  accepted article", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reducing the number of false discoveries is presently one of the most\npressing issues in the life sciences. It is of especially great importance for\nmany applications in neuroimaging and genomics, where datasets are typically\nhigh-dimensional, which means that the number of explanatory variables exceeds\nthe sample size. The false discovery rate (FDR) is a criterion that can be\nemployed to address that issue. Thus it has gained great popularity as a tool\nfor testing multiple hypotheses. Canonical correlation analysis (CCA) is a\nstatistical technique that is used to make sense of the cross-correlation of\ntwo sets of measurements collected on the same set of samples (e.g., brain\nimaging and genomic data for the same mental illness patients), and sparse CCA\nextends the classical method to high-dimensional settings. Here we propose a\nway of applying the FDR concept to sparse CCA, and a method to control the FDR.\nThe proposed FDR correction directly influences the sparsity of the solution,\nadapting it to the unknown true sparsity level. Theoretical derivation as well\nas simulation studies show that our procedure indeed keeps the FDR of the\ncanonical vectors below a user-specified target level. We apply the proposed\nmethod to an imaging genomics dataset from the Philadelphia Neurodevelopmental\nCohort. Our results link the brain connectivity profiles derived from brain\nactivity during an emotion identification task, as measured by functional\nmagnetic resonance imaging (fMRI), to the corresponding subjects' genomic data.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 17:57:40 GMT"}, {"version": "v2", "created": "Fri, 12 May 2017 01:28:42 GMT"}, {"version": "v3", "created": "Tue, 12 Dec 2017 00:12:42 GMT"}, {"version": "v4", "created": "Sat, 23 Jun 2018 04:45:44 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Gossmann", "Alexej", ""], ["Zille", "Pascal", ""], ["Calhoun", "Vince", ""], ["Wang", "Yu-Ping", ""]]}, {"id": "1705.04405", "submitter": "Luigi Acerbi", "authors": "Luigi Acerbi, Wei Ji Ma", "title": "Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive\n  Direct Search", "comments": "To appear in Advances in Neural Information Processing Systems 30\n  (NIPS 2017). 21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models in fields such as computational neuroscience are often\nevaluated via stochastic simulation or numerical approximation. Fitting these\nmodels implies a difficult optimization problem over complex, possibly noisy\nparameter landscapes. Bayesian optimization (BO) has been successfully applied\nto solving expensive black-box problems in engineering and machine learning.\nHere we explore whether BO can be applied as a general tool for model fitting.\nFirst, we present a novel hybrid BO algorithm, Bayesian adaptive direct search\n(BADS), that achieves competitive performance with an affordable computational\noverhead for the running time of typical models. We then perform an extensive\nbenchmark of BADS vs. many common and state-of-the-art nonconvex,\nderivative-free optimizers, on a set of model-fitting problems with real data\nand models from six studies in behavioral, cognitive, and computational\nneuroscience. With default settings, BADS consistently finds comparable or\nbetter solutions than other methods, including `vanilla' BO, showing great\npromise for advanced BO techniques, and BADS in particular, as a general\nmodel-fitting tool.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 23:53:13 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 13:45:54 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Acerbi", "Luigi", ""], ["Ma", "Wei Ji", ""]]}, {"id": "1705.04600", "submitter": "Songbai Ji", "authors": "Yunliang Cai, Shaoju Wu, Wei Zhao, Zhigang Li, Songbai Ji", "title": "Concussion classification via deep learning using whole-brain white\n  matter fiber strains", "comments": "18 pages, 7 figures, and 4 tables", "journal-ref": null, "doi": "10.1371/journal.pone.0197992", "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing an accurate and reliable injury predictor is central to the\nbiomechanical studies of traumatic brain injury. State-of-the-art efforts\ncontinue to rely on empirical, scalar metrics based on kinematics or\nmodel-estimated tissue responses explicitly pre-defined in a specific brain\nregion of interest. They could suffer from loss of information. A single\ntraining dataset has also been used to evaluate performance but without\ncross-validation. In this study, we developed a deep learning approach for\nconcussion classification using implicit features of the entire voxel-wise\nwhite matter fiber strains. Using reconstructed American National Football\nLeague (NFL) injury cases, leave-one-out cross-validation was employed to\nobjectively compare injury prediction performances against two baseline machine\nlearning classifiers (support vector machine (SVM) and random forest (RF)) and\nfour scalar metrics via univariate logistic regression (Brain Injury Criterion\n(BrIC), cumulative strain damage measure of the whole brain (CSDM-WB) and the\ncorpus callosum (CSDM-CC), and peak fiber strain in the CC). Feature-based deep\nlearning and machine learning classifiers consistently outperformed all scalar\ninjury metrics across all performance categories in cross-validation (e.g.,\naverage accuracy of 0.844 vs. 0.746, and average area under the receiver\noperating curve (AUC) of 0.873 vs. 0.769, respectively, based on the testing\ndataset). Nevertheless, deep learning achieved the best cross-validation\naccuracy, sensitivity, and AUC (e.g., accuracy of 0.862 vs. 0.828 and 0.842 for\nSVM and RF, respectively). These findings demonstrate the superior performances\nof deep learning in concussion prediction, and suggest its promise for future\napplications in biomechanical investigations of traumatic brain injury.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 14:40:59 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 18:09:48 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Cai", "Yunliang", ""], ["Wu", "Shaoju", ""], ["Zhao", "Wei", ""], ["Li", "Zhigang", ""], ["Ji", "Songbai", ""]]}, {"id": "1705.04603", "submitter": "Mara Scussolini", "authors": "Mara Scussolini, Sara Garbarino, Gianmario Sambuceti, Giacomo Caviglia\n  and Michele Piana", "title": "Parametric Imaging of FDG-PET Data Using Physiology and Iterative\n  Regularization: Application to the Hepatic and Renal Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:1702.06067", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.TO math.NA q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper proposes a novel computational method for parametric\nimaging of nuclear medicine data. The mathematical procedure is general enough\nto work for compartmental models of diverse complexity and is effective in the\ndetermination of the parametric maps of all kinetic parameters governing tracer\nflow. We consider applications to [18F]-fluorodeoxyglucose Positron Emission\nTomography (FDG-PET) data and analyze the two-compartment catenary model\ndescribing the standard FDG metabolization by an homogeneous tissue, e.g. the\nliver, and the three-compartment non-catenary model representing the renal\nphysiology. The proposed imaging method starts from the reconstructed FDG-PET\nimages of tracer concentration and preliminarily applies image processing\nalgorithms for noise reduction and image segmentation processes for selecting\nthe region enclosing the organ of physiologic interest. The optimization scheme\nsolves pixelwise the non-linear inverse problem of determining the kinetic\nparameters from dynamic concentration data through a Gauss-Newton iterative\nalgorithm with a penalty term accounting for the ill-posedness of the problem.\nWe tested our imaging approach on FDG-PET data of murine models obtained by\nmeans of a dedicated microPET system, and we analyzed different PET slices\ncontaining axial sections of the liver and axial sections of the kidneys. The\nreconstructed parametric images proved to be reliable and qualitatively\neffective in the description of the local FDG metabolism with respect to the\ndifferent physiologies.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 15:51:47 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Scussolini", "Mara", ""], ["Garbarino", "Sara", ""], ["Sambuceti", "Gianmario", ""], ["Caviglia", "Giacomo", ""], ["Piana", "Michele", ""]]}, {"id": "1705.04678", "submitter": "Nikhil Galagali", "authors": "Nikhil Galagali and Youssef M. Marzouk", "title": "Exploiting network topology for large-scale inference of nonlinear\n  reaction models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.QM stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of chemical reaction models aids understanding and prediction\nin areas ranging from biology to electrochemistry and combustion. A systematic\napproach to building reaction network models uses observational data not only\nto estimate unknown parameters, but also to learn model structure. Bayesian\ninference provides a natural approach to this data-driven construction of\nmodels. Yet traditional Bayesian model inference methodologies that numerically\nevaluate the evidence for each model are often infeasible for nonlinear\nreaction network inference, as the number of plausible models can be\ncombinatorially large. Alternative approaches based on model-space sampling can\nenable large-scale network inference, but their realization presents many\nchallenges. In this paper, we present new computational methods that make\nlarge-scale nonlinear network inference tractable. First, we exploit the\ntopology of networks describing potential interactions among chemical species\nto design improved \"between-model\" proposals for reversible-jump Markov chain\nMonte Carlo. Second, we introduce a sensitivity-based determination of move\ntypes which, when combined with network-aware proposals, yields significant\nadditional gains in sampling performance. These algorithms are demonstrated on\ninference problems drawn from systems biology, with nonlinear differential\nequation models of species interactions.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 17:55:44 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 18:35:07 GMT"}, {"version": "v3", "created": "Sun, 14 Oct 2018 16:11:46 GMT"}, {"version": "v4", "created": "Tue, 16 Oct 2018 01:26:55 GMT"}, {"version": "v5", "created": "Sat, 19 Jan 2019 03:43:48 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Galagali", "Nikhil", ""], ["Marzouk", "Youssef M.", ""]]}, {"id": "1705.04802", "submitter": "Ahmet Sureyya Rifaioglu", "authors": "Ahmet Sureyya Rifaioglu, Tunca Do\\u{g}an, Maria Jesus Martin, Rengul\n  Cetin-Atalay, Mehmet Volkan Atalay", "title": "Multi-task Deep Neural Networks in Automated Protein Function Prediction", "comments": "19 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep learning algorithms have outperformed the state-of-the\nart methods in several areas thanks to the efficient methods for training and\nfor preventing overfitting, advancement in computer hardware, the availability\nof vast amount data. The high performance of multi-task deep neural networks in\ndrug discovery has attracted the attention to deep learning algorithms in\nbioinformatics area. Here, we proposed a hierarchical multi-task deep neural\nnetwork architecture based on Gene Ontology (GO) terms as a solution to protein\nfunction prediction problem and investigated various aspects of the proposed\narchitecture by performing several experiments. First, we showed that there is\na positive correlation between performance of the system and the size of\ntraining datasets. Second, we investigated whether the level of GO terms on GO\nhierarchy related to their performance. We showed that there is no relation\nbetween the depth of GO terms on GO hierarchy and their performance. In\naddition, we included all annotations to the training of a set of GO terms to\ninvestigate whether including noisy data to the training datasets change the\nperformance of the system. The results showed that including less reliable\nannotations in training of deep neural networks increased the performance of\nthe low performed GO terms, significantly. We evaluated the performance of the\nsystem using hierarchical evaluation method. Mathews correlation coefficient\nwas calculated as 0.75, 0.49 and 0.63 for molecular function, biological\nprocess and cellular component categories, respectively. We showed that deep\nlearning algorithms have a great potential in protein function prediction area.\nWe plan to further improve the DEEPred by including other types of annotations\nfrom various biological data sources. We plan to construct DEEPred as an open\naccess online tool.\n", "versions": [{"version": "v1", "created": "Sat, 13 May 2017 09:05:03 GMT"}, {"version": "v2", "created": "Sun, 28 May 2017 09:46:33 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Rifaioglu", "Ahmet Sureyya", ""], ["Do\u011fan", "Tunca", ""], ["Martin", "Maria Jesus", ""], ["Cetin-Atalay", "Rengul", ""], ["Atalay", "Mehmet Volkan", ""]]}, {"id": "1705.04942", "submitter": "Adam Mahdi", "authors": "Adam Mahdi, Dragana Nikolic, Anthony A. Birch, Mette S. Olufsen,\n  Ronney B. Panerai, David M. Simpson, Stephen J. Payne", "title": "Increased blood pressure variability upon standing up improves\n  reproducibility of cerebral autoregulation indices", "comments": "4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic cerebral autoregulation, that is the transient response of cerebral\nblood flow to changes in arterial blood pressure, is currently assessed using a\nvariety of different time series methods and data collection protocols. In the\ncontinuing absence of a gold standard for the study of cerebral autoregulation\nit is unclear to what extent does the assessment depend on the choice of a\ncomputational method and protocol. We use continuous measurements of blood\npressure and cerebral blood flow velocity in the middle cerebral artery from\nthe cohorts of 18 normotensive subjects performing sit-to-stand manoeuvre. We\nestimate cerebral autoregulation using a wide variety of black-box approaches\n(ARI, Mx, Sx, Dx, FIR and ARX) and compare them in the context of\nreproducibility and variability. For all autoregulation indices, considered\nhere, the ICC was greater during the standing protocol, however, it was\nsignificantly greater (Fisher's Z-test) for Mx (p < 0.03), Sx (p<0.003)$ and Dx\n(p<0.03). In the specific case of the sit-to-stand manoeuvre, measurements\ntaken immediately after standing up greatly improve the reproducibility of the\nautoregulation coefficients. This is generally coupled with an increase of the\nwithin-group spread of the estimates.\n", "versions": [{"version": "v1", "created": "Sun, 14 May 2017 09:57:04 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Mahdi", "Adam", ""], ["Nikolic", "Dragana", ""], ["Birch", "Anthony A.", ""], ["Olufsen", "Mette S.", ""], ["Panerai", "Ronney B.", ""], ["Simpson", "David M.", ""], ["Payne", "Stephen J.", ""]]}, {"id": "1705.05191", "submitter": "Philippe Terrier PhD", "authors": "Fabienne Reynard and Philippe Terrier", "title": "Determinants of gait stability while walking on a treadmill: a machine\n  learning approach", "comments": "This is the author's version of a manuscript published in the Journal\n  of Biomechanics", "journal-ref": "Journnal of Biomechanics Volume 65, 8 December 2017, Pages 212-215", "doi": "10.1016/j.jbiomech.2017.10.020", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dynamic balance in human locomotion can be assessed through the local dynamic\nstability (LDS) method. Whereas gait LDS has been used successfully in many\nsettings and applications, little is known about its sensitivity to individual\ncharacteristics of healthy adults. Therefore, we reanalyzed a large dataset of\naccelerometric data measured for 100 healthy adults from 20 to 70 years of age\nperforming 10 min. treadmill walking. We sought to assess the extent to which\nthe variations of age, body mass and height, sex, and preferred walking speed\n(PWS) could influence gait LDS. The random forest (RF) and multiple adaptive\nregression splines (MARS) algorithms were selected for their good bias-variance\ntradeoff and their capabilities to handle nonlinear associations. First,\nthrough variable importance measure (VIM), we used RF to evaluate which\nindividual characteristics had the highest influence on gait LDS. Second, we\nused MARS to detect potential interactions among individual characteristics\nthat may influence LDS. The VIM and MARS results indicated that PWS and age\ncorrelated with LDS, whereas no associations were found for sex, body height,\nand body mass. Further, the MARS model detected an age by PWS interaction: on\none hand, at high PWS, gait stability is constant across age while, on the\nother hand, at low PWS, gait instability increases substantially with age. We\nconclude that it is advisable to consider the participants' age as well as\ntheir PWS to avoid potential biases in evaluating dynamic balance through LDS.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 12:47:46 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 12:43:14 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Reynard", "Fabienne", ""], ["Terrier", "Philippe", ""]]}, {"id": "1705.05368", "submitter": "Chunwei Ma", "authors": "Chunwei Ma, Zhiyong Zhu, Jun Ye, Jiarui Yang, Jianguo Pei, Shaohang\n  Xu, Ruo Zhou, Chang Yu, Fan Mo, Bo Wen, Siqi Liu", "title": "DeepRT: deep learning for peptide retention time prediction in\n  proteomics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate predictions of peptide retention times (RT) in liquid chromatography\nhave many applications in mass spectrometry-based proteomics. Herein, we\npresent DeepRT, a deep learning based software for peptide retention time\nprediction. DeepRT automatically learns features directly from the peptide\nsequences using the deep convolutional Neural Network (CNN) and Recurrent\nNeural Network (RNN) model, which eliminates the need to use hand-crafted\nfeatures or rules. After the feature learning, principal component analysis\n(PCA) was used for dimensionality reduction, then three conventional machine\nlearning methods were utilized to perform modeling. Two published datasets were\nused to evaluate the performance of DeepRT and we demonstrate that DeepRT\ngreatly outperforms previous state-of-the-art approaches ELUDE and GPTime.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 10:13:36 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Ma", "Chunwei", ""], ["Zhu", "Zhiyong", ""], ["Ye", "Jun", ""], ["Yang", "Jiarui", ""], ["Pei", "Jianguo", ""], ["Xu", "Shaohang", ""], ["Zhou", "Ruo", ""], ["Yu", "Chang", ""], ["Mo", "Fan", ""], ["Wen", "Bo", ""], ["Liu", "Siqi", ""]]}, {"id": "1705.05805", "submitter": "Michael Stefferson", "authors": "Michael W. Stefferson, Samantha A. Norris, Franck J. Vernerey,\n  Meredith D. Betterton, and Loren E. Hough", "title": "Effects of soft interactions and bound mobility on diffusion in crowded\n  environments: a model of sticky and slippery obstacles", "comments": "Submitted to Biophysical Journal", "journal-ref": null, "doi": "10.1088/1478-3975/aa7869", "report-no": null, "categories": "physics.bio-ph cond-mat.soft q-bio.QM q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crowded environments modify the diffusion of macromolecules, generally\nslowing their movement and inducing transient anomalous subdiffusion. The\npresence of obstacles also modifies the kinetics and equilibrium behavior of\ntracers. While previous theoretical studies of particle diffusion have\ntypically assumed either impenetrable obstacles or binding interactions that\nimmobilize the particle, in many cellular contexts bound particles remain\nmobile. Examples include membrane proteins or lipids with some entry and\ndiffusion within lipid domains and proteins that can enter into membraneless\norganelles or compartments such as the nucleolus. Using a lattice model, we\nstudied the diffusive movement of tracer particles which bind to soft\nobstacles, allowing tracers and obstacles to occupy the same lattice site. For\nsticky obstacles, bound tracer particles are immobile, while for slippery\nobstacles, bound tracers can hop without penalty to adjacent obstacles. In both\nmodels, binding significantly alters tracer motion. The type and degree of\nmotion while bound is a key determinant of the tracer mobility: slippery\nobstacles can allow nearly unhindered diffusion, even at high obstacle filling\nfraction. To mimic compartmentalization in a cell, we examined how obstacle\nsize and a range of bound diffusion coefficients affect tracer dynamics. The\nbehavior of the model is similar in two and three spatial dimensions. Our work\nhas implications for protein movement and interactions within cells.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 17:14:48 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 14:19:17 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Stefferson", "Michael W.", ""], ["Norris", "Samantha A.", ""], ["Vernerey", "Franck J.", ""], ["Betterton", "Meredith D.", ""], ["Hough", "Loren E.", ""]]}, {"id": "1705.05919", "submitter": "Maxat Kulmanov", "authors": "Maxat Kulmanov, Mohammed Asif Khan and Robert Hoehndorf", "title": "DeepGO: Predicting protein functions from sequence and interactions\n  using a deep ontology-aware classifier", "comments": null, "journal-ref": null, "doi": "10.1093/bioinformatics/btx624", "report-no": null, "categories": "q-bio.GN cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large number of protein sequences are becoming available through the\napplication of novel high-throughput sequencing technologies. Experimental\nfunctional characterization of these proteins is time-consuming and expensive,\nand is often only done rigorously for few selected model organisms.\nComputational function prediction approaches have been suggested to fill this\ngap. The functions of proteins are classified using the Gene Ontology (GO),\nwhich contains over 40,000 classes. Additionally, proteins have multiple\nfunctions, making function prediction a large-scale, multi-class, multi-label\nproblem.\n  We have developed a novel method to predict protein function from sequence.\nWe use deep learning to learn features from protein sequences as well as a\ncross-species protein-protein interaction network. Our approach specifically\noutputs information in the structure of the GO and utilizes the dependencies\nbetween GO classes as background information to construct a deep learning\nmodel. We evaluate our method using the standards established by the\nComputational Assessment of Function Annotation (CAFA) and demonstrate a\nsignificant improvement over baseline methods such as BLAST, with significant\nimprovement for predicting cellular locations.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 06:04:08 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Kulmanov", "Maxat", ""], ["Khan", "Mohammed Asif", ""], ["Hoehndorf", "Robert", ""]]}, {"id": "1705.06147", "submitter": "Roberto Cavoretto", "authors": "Roberto Cavoretto, Alessandra De Rossi, Roberta Freda, Hanli Qiao,\n  Ezio Venturino", "title": "Numerical Methods for Pulmonary Image Registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.NA physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to complexity and invisibility of human organs, diagnosticians need to\nanalyze medical images to determine where the lesion region is, and which kind\nof disease is, in order to make precise diagnoses. For satisfying clinical\npurposes through analyzing medical images, registration plays an essential\nrole. For instance, in Image-Guided Interventions (IGI) and computer-aided\nsurgeries, patient anatomy is registered to preoperative images to guide\nsurgeons complete procedures. Medical image registration is also very useful in\nsurgical planning, monitoring disease progression and for atlas construction.\nDue to the significance, the theories, methods, and implementation method of\nimage registration constitute fundamental knowledge in educational training for\nmedical specialists. In this chapter, we focus on image registration of a\nspecific human organ, i.e. the lung, which is prone to be lesioned. For\npulmonary image registration, the improvement of the accuracy and how to obtain\nit in order to achieve clinical purposes represents an important problem which\nshould seriously be addressed. In this chapter, we provide a survey which\nfocuses on the role of image registration in educational training together with\nthe state-of-the-art of pulmonary image registration. In the first part, we\ndescribe clinical applications of image registration introducing artificial\norgans in Simulation-based Education. In the second part, we summarize the\ncommon methods used in pulmonary image registration and analyze popular papers\nto obtain a survey of pulmonary image registration.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 06:42:08 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Cavoretto", "Roberto", ""], ["De Rossi", "Alessandra", ""], ["Freda", "Roberta", ""], ["Qiao", "Hanli", ""], ["Venturino", "Ezio", ""]]}, {"id": "1705.06384", "submitter": "Junghyo Jo", "authors": "Danh-Tai Hoang, Juyong Song, Vipul Periwal, Junghyo Jo", "title": "Causality inference in stochastic systems from neurons to currencies:\n  Profiting from small sample size", "comments": "6 pages, 5 figures", "journal-ref": "Phys. Rev. E 99, 023311 (2019)", "doi": "10.1103/PhysRevE.99.023311", "report-no": null, "categories": "physics.data-an q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Success in modeling complex phenomena such as human perception hinges\ncritically on the availability of data and computational power. Significant\nprogress has been made in modeling such phenomena using probabilistic methods,\nparticularly in image analysis and speech recognition. Maximum Likelihood\nEstimation (MLE) combined with Bayesian model selection is the basis of much of\nthis progress, as MLE converges to the true model with copious data. In the\nsciences, large enough datasets are rarae aves, so alternatives to MLE must be\ndeveloped for small sample size. We introduce a data-driven statistical physics\napproach to model inference based on minimizing a free energy of data and show\nsuperior model recovery for small sample sizes. We demonstrate coupling\nstrength inference in non-equilibrium kinetic Ising models, including in the\ndifficult large coupling variability regime, and show scaling to systems of\narbitrary size. As applications, we infer a functional connectivity network in\nthe salamander retina and a currency exchange rate network from time-series\ndata of neuronal spiking and currency exchange rates, respectively. Accurate\nsmall sample size inference is critical for devising a profitable currency\nhedging strategy.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 01:23:27 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 05:08:21 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Hoang", "Danh-Tai", ""], ["Song", "Juyong", ""], ["Periwal", "Vipul", ""], ["Jo", "Junghyo", ""]]}, {"id": "1705.06817", "submitter": "Varun Ojha", "authors": "Varun Kumar Ojha, Konrad Jackowski, Ajith Abraham, V\\'aclav\n  Sn\\'a\\v{s}el", "title": "Dimensionality reduction, and function approximation of\n  poly(lactic-co-glycolic acid) micro- and nanoparticle dissolution rate", "comments": null, "journal-ref": "International Journal of Nanomedicine 2015,10", "doi": "10.2147/IJN.S71847", "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of poly(lactic co glycolic acid) (PLGA) micro- and nanoparticles'\ndissolution rates plays a significant role in pharmaceutical and medical\nindustries. The prediction of PLGA dissolution rate is crucial for drug\nmanufacturing. Therefore, a model that predicts the PLGA dissolution rate could\nbe beneficial. PLGA dissolution is influenced by numerous factors (features),\nand counting the known features leads to a dataset with 300 features. This\nlarge number of features and high redundancy within the dataset makes the\nprediction task very difficult and inaccurate. In this study, dimensionality\nreduction techniques were applied in order to simplify the task and eliminate\nirrelevant and redundant features. A heterogeneous pool of several regression\nalgorithms were independently tested and evaluated. In addition, several\nensemble methods were tested in order to improve the accuracy of prediction.\nThe empirical results revealed that the proposed evolutionary weighted ensemble\nmethod offered the lowest margin of error and significantly outperformed the\nindividual algorithms and the other ensemble techniques.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 07:36:47 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Ojha", "Varun Kumar", ""], ["Jackowski", "Konrad", ""], ["Abraham", "Ajith", ""], ["Sn\u00e1\u0161el", "V\u00e1clav", ""]]}, {"id": "1705.06823", "submitter": "Andrew Chen", "authors": "Andrew X. Chen, Ra\\'ul Rabad\\'an", "title": "Fast and Accurate Semi-Automatic Segmentation Tool for Brain Tumor MRIs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Segmentation, the process of delineating tumor apart from healthy tissue, is\na vital part of both the clinical assessment and the quantitative analysis of\nbrain cancers. Here, we provide an open-source algorithm (MITKats), built on\nthe Medical Imaging Interaction Toolkit, to provide user-friendly and expedient\ntools for semi-automatic segmentation. To evaluate its performance against\ncompeting algorithms, we applied MITKats to 38 high-grade glioma cases from\npublicly available benchmarks. The similarity of the segmentations to\nexpert-delineated ground truths approached the discrepancies among different\nmanual raters, the theoretically maximal precision. The average time spent on\neach segmentation was 5 minutes, making MITKats between 4 and 11 times faster\nthan competing semi-automatic algorithms, while retaining similar accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 22:48:46 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Chen", "Andrew X.", ""], ["Rabad\u00e1n", "Ra\u00fal", ""]]}, {"id": "1705.06911", "submitter": "Taikai Takeda", "authors": "Taikai Takeda, Michiaki Hamada", "title": "Beyond similarity assessment: Selecting the optimal model for sequence\n  alignment via the Factorized Asymptotic Bayesian algorithm", "comments": "This article has been accepted for publication in Bioinformatics\n  Published by Oxford University Press", "journal-ref": "Bioinformatics, 2017, btx643", "doi": "10.1093/bioinformatics/btx643", "report-no": null, "categories": "q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pair Hidden Markov Models (PHMMs) are probabilistic models used for pairwise\nsequence alignment, a quintessential problem in bioinformatics. PHMMs include\nthree types of hidden states: match, insertion and deletion. Most previous\nstudies have used one or two hidden states for each PHMM state type. However,\nfew studies have examined the number of states suitable for representing\nsequence data or improving alignment accuracy.We developed a novel method to\nselect superior models (including the number of hidden states) for PHMM. Our\nmethod selects models with the highest posterior probability using Factorized\nInformation Criteria (FIC), which is widely utilised in model selection for\nprobabilistic models with hidden variables. Our simulations indicated this\nmethod has excellent model selection capabilities with slightly improved\nalignment accuracy. We applied our method to DNA datasets from 5 and 28\nspecies, ultimately selecting more complex models than those used in previous\nstudies.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 09:49:59 GMT"}, {"version": "v2", "created": "Sun, 15 Oct 2017 06:52:17 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Takeda", "Taikai", ""], ["Hamada", "Michiaki", ""]]}, {"id": "1705.07099", "submitter": "Balazs Kegl", "authors": "Laetitia Le, Camille Marini, Alexandre Gramfort, David Nguyen, Mehdi\n  Cherti, Sana Tfaili, Ali Tfayli, Arlette Baillet-Guffroy, Patrice Prognon,\n  Pierre Chaminade, Eric Caudron, Bal\\'azs K\\'egl", "title": "Machine learning for classification and quantification of monoclonal\n  antibody preparations for cancer therapy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monoclonal antibodies constitute one of the most important strategies to\ntreat patients suffering from cancers such as hematological malignancies and\nsolid tumors. In order to guarantee the quality of those preparations prepared\nat hospital, quality control has to be developed. The aim of this study was to\nexplore a noninvasive, nondestructive, and rapid analytical method to ensure\nthe quality of the final preparation without causing any delay in the process.\nWe analyzed four mAbs (Inlfiximab, Bevacizumab, Ramucirumab and Rituximab)\ndiluted at therapeutic concentration in chloride sodium 0.9% using Raman\nspectroscopy. To reduce the prediction errors obtained with traditional\nchemometric data analysis, we explored a data-driven approach using statistical\nmachine learning methods where preprocessing and predictive models are jointly\noptimized. We prepared a data analytics workflow and submitted the problem to a\ncollaborative data challenge platform called Rapid Analytics and Model\nPrototyping (RAMP). This allowed to use solutions from about 300 data\nscientists during five days of collaborative work. The prediction of the four\nmAbs samples was considerably improved with a misclassification rate and the\nmean error rate of 0.8% and 4%, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 17:23:38 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 12:42:21 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Le", "Laetitia", ""], ["Marini", "Camille", ""], ["Gramfort", "Alexandre", ""], ["Nguyen", "David", ""], ["Cherti", "Mehdi", ""], ["Tfaili", "Sana", ""], ["Tfayli", "Ali", ""], ["Baillet-Guffroy", "Arlette", ""], ["Prognon", "Patrice", ""], ["Chaminade", "Pierre", ""], ["Caudron", "Eric", ""], ["K\u00e9gl", "Bal\u00e1zs", ""]]}, {"id": "1705.08228", "submitter": "Peter Gawthrop", "authors": "Peter J. Gawthrop", "title": "Sensitivity Properties of Intermittent Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sensitivity properties of intermittent control are analysed and the\nconditions for a limit cycle derived theoretically and verified by simulation.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 14:01:43 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Gawthrop", "Peter J.", ""]]}, {"id": "1705.08246", "submitter": "Thierry Mora", "authors": "Quentin Marcou, Thierry Mora, Aleksandra M Walczak", "title": "IGoR: a tool for high-throughput immune repertoire analysis", "comments": null, "journal-ref": "Nature Communications 9, 561 (2018)", "doi": "10.1038/s41467-018-02832-w", "report-no": null, "categories": "q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High throughput immune repertoire sequencing is promising to lead to new\nstatistical diagnostic tools for medicine and biology. Successful\nimplementations of these methods require a correct characterization, analysis\nand interpretation of these datasets. We present IGoR -- a new comprehensive\ntool that takes B or T-cell receptors sequence reads and quantitatively\ncharacterizes the statistics of receptor generation from both cDNA and gDNA. It\nprobabilistically annotates sequences and its modular structure can investigate\nmodels of increasing biological complexity for different organisms. For B-cells\nIGoR returns the hypermutation statistics, which we use to reveal\nco-localization of hypermutations along the sequence. We demonstrate that IGoR\noutperforms existing tools in accuracy and estimate the sample sizes needed for\nreliable repertoire characterization.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 13:37:19 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Marcou", "Quentin", ""], ["Mora", "Thierry", ""], ["Walczak", "Aleksandra M", ""]]}, {"id": "1705.08324", "submitter": "Helen Liedtke", "authors": "H.Liedtke, A.T. McBride, S. Sivarasu, S. Roche", "title": "Computational simulation of bone remodelling post reverse total shoulder\n  arthroplasty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.TO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bone is a living material. It adapts, in an optimal sense, to loading by\nchanging its density and trabeculae architecture - a process termed\nremodelling. Implanted orthopaedic devices can significantly alter the loading\non the surrounding bone, which can have a detrimental impact on bone ingrowth\nthat is critical to ensure secure implant fixation. In this contribution, a\ncomputational model that accounts for bone remodelling is developed to\nelucidate the response of bone following a reverse shoulder procedure for\nrotator cuff deficient patients. The physical process of remodelling is\nmodelled using continuum scale, open system thermodynamics whereby the density\nof bone evolves isotropically in response to the loading it experiences. The\nfully-nonlinear continuum theory is solved approximately using the finite\nelement method. The code developed to model the reverse shoulder procedure is\nvalidated using a series of benchmark problems.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 09:38:15 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Liedtke", "H.", ""], ["McBride", "A. T.", ""], ["Sivarasu", "S.", ""], ["Roche", "S.", ""]]}, {"id": "1705.08369", "submitter": "Talha Qaiser", "authors": "Talha Qaiser, Abhik Mukherjee, Chaitanya Reddy Pb, Sai Dileep\n  Munugoti, Vamsi Tallam, Tomi Pitk\\\"aaho, Taina Lehtim\\\"aki, Thomas Naughton,\n  Matt Berseth, An\\'ibal Pedraza, Ramakrishnan Mukundan, Matthew Smith, Abhir\n  Bhalerao, Erik Rodner, Marcel Simon, Joachim Denzler, Chao-Hui Huang, Gloria\n  Bueno, David Snead, Ian Ellis, Mohammad Ilyas, Nasir Rajpoot", "title": "Her2 Challenge Contest: A Detailed Assessment of Automated Her2 Scoring\n  Algorithms in Whole Slide Images of Breast Cancer Tissues", "comments": null, "journal-ref": null, "doi": "10.1111/his.13333", "report-no": null, "categories": "cs.CV cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluating expression of the Human epidermal growth factor receptor 2 (Her2)\nby visual examination of immunohistochemistry (IHC) on invasive breast cancer\n(BCa) is a key part of the diagnostic assessment of BCa due to its recognised\nimportance as a predictive and prognostic marker in clinical practice. However,\nvisual scoring of Her2 is subjective and consequently prone to inter-observer\nvariability. Given the prognostic and therapeutic implications of Her2 scoring,\na more objective method is required. In this paper, we report on a recent\nautomated Her2 scoring contest, held in conjunction with the annual PathSoc\nmeeting held in Nottingham in June 2016, aimed at systematically comparing and\nadvancing the state-of-the-art Artificial Intelligence (AI) based automated\nmethods for Her2 scoring. The contest dataset comprised of digitised whole\nslide images (WSI) of sections from 86 cases of invasive breast carcinoma\nstained with both Haematoxylin & Eosin (H&E) and IHC for Her2. The contesting\nalgorithms automatically predicted scores of the IHC slides for an unseen\nsubset of the dataset and the predicted scores were compared with the 'ground\ntruth' (a consensus score from at least two experts). We also report on a\nsimple Man vs Machine contest for the scoring of Her2 and show that the\nautomated methods could beat the pathology experts on this contest dataset.\nThis paper presents a benchmark for comparing the performance of automated\nalgorithms for scoring of Her2. It also demonstrates the enormous potential of\nautomated algorithms in assisting the pathologist with objective IHC scoring.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 15:36:04 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 08:47:33 GMT"}, {"version": "v3", "created": "Mon, 24 Jul 2017 21:39:53 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Qaiser", "Talha", ""], ["Mukherjee", "Abhik", ""], ["Pb", "Chaitanya Reddy", ""], ["Munugoti", "Sai Dileep", ""], ["Tallam", "Vamsi", ""], ["Pitk\u00e4aho", "Tomi", ""], ["Lehtim\u00e4ki", "Taina", ""], ["Naughton", "Thomas", ""], ["Berseth", "Matt", ""], ["Pedraza", "An\u00edbal", ""], ["Mukundan", "Ramakrishnan", ""], ["Smith", "Matthew", ""], ["Bhalerao", "Abhir", ""], ["Rodner", "Erik", ""], ["Simon", "Marcel", ""], ["Denzler", "Joachim", ""], ["Huang", "Chao-Hui", ""], ["Bueno", "Gloria", ""], ["Snead", "David", ""], ["Ellis", "Ian", ""], ["Ilyas", "Mohammad", ""], ["Rajpoot", "Nasir", ""]]}, {"id": "1705.09242", "submitter": "David Coomes Prof", "authors": "Tommaso Jucker, Gregory P. Asner, Michele Dalponte, Philip Brodrick,\n  Christopher D. Philipson, Nick Vaughn, Craig Brelsford, David F.R.P. Burslem,\n  Nicholas J. Deere, Robert M. Ewers, Jakub Kvasnica, Simon L. Lewis, Yadvinder\n  Malhi, Sol Milne, Reuben Nilus, Marion Pfeifer, Oliver Phillips, Lan Qie,\n  Nathan Renneboog, Glen Reynolds, Terhi Riutta, Matthew J. Struebig, Martin\n  Sv\\'atek, Yit Arn Teh, Edgar C. Turner and David A. Coomes", "title": "A regional model for estimating the aboveground carbon density of\n  Borneo's tropical forests from airborne laser scanning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Borneo contains some of the world's most biodiverse and carbon dense tropical\nforest, but this 750,000-km2 island has lost 62% of its old-growth forests\nwithin the last 40 years. Efforts to protect and restore the remaining forests\nof Borneo hinge on recognising the ecosystem services they provide, including\ntheir ability to store and sequester carbon. Airborne Laser Scanning (ALS) is a\nremote sensing technology that allows forest structural properties to be\ncaptured in great detail across vast geographic areas. In recent years ALS has\nbeen integrated into state-wide assessment of forest carbon in Neotropical and\nAfrican regions, but not yet in Asia. For this to happen new regional models\nneed to be developed for estimating carbon stocks from ALS in tropical Asia, as\nthe forests of this region are structurally and compositionally distinct from\nthose found elsewhere in the tropics. By combining ALS imagery with data from\n173 permanent forest plots spanning the lowland rain forests of Sabah, on the\nisland of Borneo, we develop a simple-yet-general model for estimating forest\ncarbon stocks using ALS-derived canopy height and canopy cover as input\nmetrics. An advanced feature of this new model is the propagation of\nuncertainty in both ALS- and ground-based data, allowing uncertainty in\nhectare-scale estimates of carbon stocks to be quantified robustly. We show\nthat the model effectively captures variation in aboveground carbons stocks\nacross extreme disturbance gradients spanning tall dipterocarp forests and\nheavily logged regions, and clearly outperforms existing ALS-based models\ncalibrated for the tropics, as well as currently available satellite-derived\nproducts. Our model provides a simple, generalised and effective approach for\nmapping forest carbon stocks in Borneo, providing a key tool to support the\nprotection and restoration of its tropical forests.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 16:01:15 GMT"}], "update_date": "2017-05-26", "authors_parsed": [["Jucker", "Tommaso", ""], ["Asner", "Gregory P.", ""], ["Dalponte", "Michele", ""], ["Brodrick", "Philip", ""], ["Philipson", "Christopher D.", ""], ["Vaughn", "Nick", ""], ["Brelsford", "Craig", ""], ["Burslem", "David F. R. P.", ""], ["Deere", "Nicholas J.", ""], ["Ewers", "Robert M.", ""], ["Kvasnica", "Jakub", ""], ["Lewis", "Simon L.", ""], ["Malhi", "Yadvinder", ""], ["Milne", "Sol", ""], ["Nilus", "Reuben", ""], ["Pfeifer", "Marion", ""], ["Phillips", "Oliver", ""], ["Qie", "Lan", ""], ["Renneboog", "Nathan", ""], ["Reynolds", "Glen", ""], ["Riutta", "Terhi", ""], ["Struebig", "Matthew J.", ""], ["Sv\u00e1tek", "Martin", ""], ["Teh", "Yit Arn", ""], ["Turner", "Edgar C.", ""], ["Coomes", "David A.", ""]]}, {"id": "1705.09509", "submitter": "Boris Barbour", "authors": "Boris Barbour", "title": "Inverse sensitivity of plasmonic nanosensors at the single-molecule\n  limit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM physics.chem-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work using plasmonic nanosensors in a clinically relevant detection\nassay reports extreme sensitivity based upon a mechanism termed 'inverse\nsensitivity', whereby reduction of substrate concentration increases reaction\nrate, even at the single-molecule limit. This near-homoeopathic mechanism\ncontradicts the law of mass action. The assay involves deposition of silver\natoms upon gold nanostars, changing their absorption spectrum. Multiple\nadditional aspects of the assay appear to be incompatible with settled chemical\nknowledge, in particular the detection of tiny numbers of silver atoms on a\nbackground of the classic 'silver mirror reaction'. Finally, it is estimated\nhere that the reported spectral changes require some 2.5E11 times more silver\natoms than are likely to be produced. It is suggested that alternative\nexplanations must be sought for the original observations.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 10:06:10 GMT"}, {"version": "v2", "created": "Thu, 1 Jun 2017 19:59:07 GMT"}], "update_date": "2017-06-05", "authors_parsed": [["Barbour", "Boris", ""]]}, {"id": "1705.09718", "submitter": "Christian Yates", "authors": "Christian A Yates, Matthew J Ford and Richard L Mort", "title": "A multi-stage representation of cell proliferation as a Markov process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stochastic simulation algorithm commonly known as Gillespie's algorithm\nis now used ubiquitously in the modelling of biological processes in which\nstochastic effects play an important role. In well-mixed scenarios at the\nsub-cellular level it is often reasonable to assume that times between\nsuccessive reaction/interaction events are exponentially distributed and can be\nappropriately modelled as a Markov process and hence simulated by the Gillespie\nalgorithm. However, Gillespie's algorithm is routinely applied to model\nbiological systems for which it was never intended. In particular, processes in\nwhich cell proliferation is important should not be simulated naively using the\nGillespie algorithm since the history-dependent nature of the cell cycle breaks\nthe Markov process. The variance in experimentally measured cell cycle times is\nfar less than in an exponential cell cycle time distribution with the same\nmean.\n  Here we suggest a method of modelling the cell cycle that restores the\nmemoryless property to the system and is therefore consistent with simulation\nvia the Gillespie algorithm. By breaking the cell cycle into a number of\nindependent exponentially distributed stages we can restore the Markov property\nat the same time as more accurately approximating the appropriate cell cycle\ntime distributions. The consequences of our revised mathematical model are\nexplored analytically. We demonstrate the importance of employing the correct\ncell cycle time distribution by considering two models incorporating cellular\nproliferation (one spatial and one non-spatial) and demonstrating that changing\nthe cell cycle time distribution makes quantitative and qualitative differences\nto their outcomes. Our adaptation will allow modellers and experimentalists\nalike to appropriately represent cellular proliferation, whilst still being\nable to take advantage of the Gillespie algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 20:57:10 GMT"}, {"version": "v2", "created": "Mon, 14 Aug 2017 21:24:29 GMT"}, {"version": "v3", "created": "Mon, 22 Jul 2019 16:19:50 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Yates", "Christian A", ""], ["Ford", "Matthew J", ""], ["Mort", "Richard L", ""]]}, {"id": "1705.10371", "submitter": "Madhusudhan Venkadesan", "authors": "Madhusudhan Venkadesan and Marcelo A. Dias and Dhiraj K. Singh and\n  Mahesh M. Bandi and Shreyas Mandre", "title": "Stiffness of the human foot and evolution of the transverse arch", "comments": "22 pages, 7 figures, 4 tables", "journal-ref": "Nature 579, 97-100 (2020)", "doi": "10.1038/s41586-020-2053-y", "report-no": null, "categories": "physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foot stiffness underlies its mechanical function, and is central to the\nevolution of human bipedal locomotion. The stiff and propulsive human foot has\ntwo distinct arches, the longitudinal and transverse. By contrast, the feet of\nnon-human primates are flat and softer. Current understanding of foot stiffness\nis based on studies that focus solely on the longitudinal arch, and little is\nknown about the mechanical function of the transverse arch. However, common\nexperience suggests that transverse curvature dominates the stiffness; a\ndrooping dollar bill stiffens significantly upon curling it along the\ntransverse direction, not the longitudinal. We derive a normalized curvature\nparameter that encapsulates the geometric principle underlying the transverse\ncurvature-induced stiffness. We show that the transverse arch accounts for\nalmost all the difference in stiffness between human and monkey feet (vervet\nmonkeys and pig-tailed macaques) by comparing transverse curvature-based\npredictions against published data on foot stiffness. Using this functional\ninterpretation of the transverse arch, we trace the evolution of hominin feet\nand show that a human-like stiff foot likely predates Homo by $\\sim 1.5$\nmillion years, and appears in the $\\sim 3.4$ million year old fossil from\nBurtele. A distinctly human-like transverse arch is also present in early\nmembers of Homo, including Homo naledi, Homo habilis, and Homo erectus.\nHowever, the $\\sim 3.2$ million year old Australopithecus afarensis is\nestimated to have possessed a transitional foot, softer than humans and stiffer\nthan other extant primates. A foot with human-like stiffness probably evolved\naround the same time as other lower limb adaptations for regular bipedality,\nand well before the emergence of Homo, the longitudinal arch, and other\nadaptations for endurance running.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 19:36:12 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Venkadesan", "Madhusudhan", ""], ["Dias", "Marcelo A.", ""], ["Singh", "Dhiraj K.", ""], ["Bandi", "Mahesh M.", ""], ["Mandre", "Shreyas", ""]]}, {"id": "1705.10435", "submitter": "Christopher Kovach", "authors": "Christopher K. Kovach, Hiroyuki Oya and Hiroto Kawasaki", "title": "The Bispectrum and Its Relationship to Phase-Amplitude Coupling", "comments": null, "journal-ref": "NeuroImage 173, 2018, 518 - 539", "doi": "10.1016/j.neuroimage.2018.02.033", "report-no": null, "categories": "stat.ME q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most biological signals are non-Gaussian, reflecting their origins in highly\nnonlinear physiological systems. A versatile set of techniques for studying\nnon-Gaussian signals relies on the spectral representations of higher moments,\nknown as polyspectra, which describe forms of cross-frequency dependence that\ndo not arise in time-invariant Gaussian signals. The most commonly used of\nthese employ the bispectrum. Recently, other measures of cross-frequency\ndependence have drawn interest in EEG literature, in particular those which\naddress phase-amplitude coupling (PAC). Here we demonstrate a close\nrelationship between the bispectrum and popular measures of PAC, which we\nrelate to smoothings of the signal bispectrum, making them fundamentally\nbispectral estimators. Viewed this way, however, conventional PAC measures\nexhibit some unfavorable qualities, including poor bias properties, lack of\ncorrect symmetry and artificial constraints on the spectral range and\nresolution of the estimate. Moreover, information obscured by smoothing in\nmeasures of PAC, but preserved in standard bispectral estimators, may be\ncritical for distinguishing nested oscillations from transient signal features\nand other non-oscillatory causes of \"spurious\" PAC. We propose guidelines for\ngauging the nature and origin of cross-frequency coupling with bispectral\nstatistics. Beyond clarifying the relationship between PAC and the bispectrum,\nthe present work lays out a general framework for the interpretation of the\nbispectrum, which extends to other higher-order spectra. In particular, this\nframework holds promise for the detailed identification of signal features\nrelated to both nested oscillations and transient phenomena. We conclude with a\ndiscussion of some broader theoretical implications of this framework and\nhighlight promising directions for future development.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 02:36:54 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 19:18:39 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Kovach", "Christopher K.", ""], ["Oya", "Hiroyuki", ""], ["Kawasaki", "Hiroto", ""]]}, {"id": "1705.10441", "submitter": "Sherry Towers", "authors": "Sherry Towers, Jun Chen, Carlos Cruz, Steven Madler, Juan Melendez,\n  Jennifer Rodriguez, Armando Salinas, Fan Yu, Yun Kang", "title": "Quantifying the relative effects of environmental and direct\n  transmission of norovirus", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Norovirus is a common cause of outbreaks of acute gastroenteritis\nin health- and child-care settings, with serial outbreaks also frequently\nobserved aboard cruise ships. The relative contributions of environmental and\ndirect person-to-person transmission of norovirus has hitherto not been\nquantified. Objective: We employ a novel mathematical model of norovirus\ntransmission, and fit the model to daily incidence data from a major norovirus\noutbreak on a cruise ship, and examine the relative efficacy of potential\ncontrol strategies aimed at reducing environmental and/or direct transmission.\nResults: The reproduction number for environmental and direct transmission\ncombined is Rtot = 11.0 [9.4,15.6], and of environmental transmission alone is\nRenviron = 0.85 [0.18,2.04]. Direct transmission is overwhelmingly due to 0\npassenger-to-passenger contacts, but crew can act as a reservoir of infection\nfrom cruise-to-cruise. Implications: This is the first quantification of the\nrelative roles of environmental and direct transmission of norovirus. While\nenvironmental transmission has the potential to maintain a sustained series of\noutbreaks aboard a cruise ship in the absence of strict sanitation practices,\ndirect transmission dominates. Quarantine of ill passengers and cleaning are\nlikely to have little impact on final outbreak size, but intensive promotion of\ngood hand washing practices can prevent outbreaks.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 03:02:11 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Towers", "Sherry", ""], ["Chen", "Jun", ""], ["Cruz", "Carlos", ""], ["Madler", "Steven", ""], ["Melendez", "Juan", ""], ["Rodriguez", "Jennifer", ""], ["Salinas", "Armando", ""], ["Yu", "Fan", ""], ["Kang", "Yun", ""]]}, {"id": "1705.10697", "submitter": "Enrico Carlon", "authors": "B. Lannoo, E. Carlon, M. Lefranc", "title": "The heterodimer auto-repression loop: a robust and flexible\n  pulse-generating genetic module", "comments": "5 pages, 5 figures and SI (6 pages)", "journal-ref": "Phys. Rev. Lett. 117, 018102 (2016)", "doi": "10.1103/PhysRevLett.117.018102", "report-no": null, "categories": "q-bio.MN physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the dynamics of the heterodimer autorepression loop (HAL), a\nsmall genetic module in which a protein A acts as an auto-repressor and binds\nto a second protein B to form a AB dimer. For suitable values of the rate\nconstants the HAL produces pulses of A alternating with pulses of B. By means\nof analytical and numerical calculations, we show that the duration of A-pulses\nis extremely robust against variation of the rate constants while the duration\nof the B-pulses can be flexibly adjusted. The HAL is thus a minimal genetic\nmodule generating robust pulses with tunable duration an interesting property\nfor cellular signalling.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 15:17:36 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Lannoo", "B.", ""], ["Carlon", "E.", ""], ["Lefranc", "M.", ""]]}, {"id": "1705.10862", "submitter": "Gianluca Ascolani", "authors": "Gianluca Ascolani and Pietro Li\\'o", "title": "Modelling the order of driver mutations and metabolic mutations as\n  structures in cancer dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.CB q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have stressed the important role that random mutations have in\nthe development of cancer phenotype. We challenge this current view by means of\nbioinformatic data analysis and computational modelling approaches. Not all the\nmutations are equally important for the development of metastasis. The survival\nof cancer cells from the primary tumour site to the secondary seeding sites\ndepends on the occurrence of very few driver mutations promoting oncogenic cell\nbehaviours and on the order with which these mutations occur. We introduce a\nmodel in the framework of Cellular Automata to investigate the effects of\nmetabolic mutations and mutation order on cancer stemness and tumour cell\nmigration in bone metastasised breast cancers. The metabolism of the cancer\ncell is a key factor in its proliferation rate. Bioinformatics analysis on a\ncancer mutation database shows that metabolism-modifying alterations constitute\nan important class of key cancer mutations. Our approach models three types of\nmutations: drivers, the order of which is relevant for the dynamics, metabolic\nwhich support cancer growth and are estimated from existing databases, and\nnon--driver mutations. Our results provide a quantitative basis of how the\norder of driver mutations and the metabolic mutations in different cancer\nclones could impact proliferation of therapy-resistant clonal populations and\npatient survival. Further mathematical modelling of the order of mutations is\npresented in terms of operators. We believe our work is novel because it\nquantifies two important factors in cancer spreading models: the order of\ndriver mutations and the effects of metabolic mutations.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 20:41:12 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 19:38:25 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Ascolani", "Gianluca", ""], ["Li\u00f3", "Pietro", ""]]}, {"id": "1705.10922", "submitter": "Sahil Shah", "authors": "Sahil D. Shah and Rosemary Braun", "title": "Network-based identification of disease genes in expression data: the\n  GeneSurrounder method", "comments": "We have extended the application and evaluation of our GeneSurrounder\n  method to a second disease (gene expression data from bladder cancer) and\n  added additional analyses of GeneSurrounder's ability to identify known\n  cancer-associated genes", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.GN q-bio.MN stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of high--throughput transcription profiling technologies has\nenabled identification of genes and pathways associated with disease, providing\nnew avenues for precision medicine. A key challenge is to analyze this data in\nthe context of the regulatory networks and pathways that control cellular\nprocesses, while still obtaining insights that can be used to design new\ndiagnostic and therapeutic interventions. While classical differential\nexpression analysis provides specific and hence targetable gene-level insights,\nit does not include any systems-level information. On the other hand, pathway\nanalyses integrate systems-level information with expression data, but are\noften limited in their ability to indicate specific molecular targets. We\nintroduce GeneSurrounder, an analysis method that takes into account the\ncomplex structure of interaction networks to identify specific genes that\ndisrupt pathway activity in a disease-specific manner. GeneSurrounder\nintegrates transcriptomic data and pathway network information in a novel\ntwo-step procedure to detect genes that (i) appear to influence the expression\nof other genes local to it in the network and (ii) are part of a subnetwork of\ndifferentially expressed genes. Combined, this evidence can be used to pinpoint\nspecific genes that have a mechanistic role in the phenotype of interest.\nApplying GeneSurrounder to three distinct ovarian cancer studies using a global\nKEGG network, we show that our method is able to identify biologically relevant\ngenes and genes missed by single-gene association tests, integrate pathway and\nexpression data, and yield more consistent results across multiple studies of\nthe same phenotype than competing methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 02:40:18 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 23:08:36 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Shah", "Sahil D.", ""], ["Braun", "Rosemary", ""]]}]