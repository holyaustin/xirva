[{"id": "1604.00268", "submitter": "David Schwab", "authors": "DJ Strouse, David J Schwab", "title": "The deterministic information bottleneck", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech cs.IT math.IT q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lossy compression and clustering fundamentally involve a decision about what\nfeatures are relevant and which are not. The information bottleneck method (IB)\nby Tishby, Pereira, and Bialek formalized this notion as an\ninformation-theoretic optimization problem and proposed an optimal tradeoff\nbetween throwing away as many bits as possible, and selectively keeping those\nthat are most important. In the IB, compression is measure my mutual\ninformation. Here, we introduce an alternative formulation that replaces mutual\ninformation with entropy, which we call the deterministic information\nbottleneck (DIB), that we argue better captures this notion of compression. As\nsuggested by its name, the solution to the DIB problem turns out to be a\ndeterministic encoder, or hard clustering, as opposed to the stochastic\nencoder, or soft clustering, that is optimal under the IB. We compare the IB\nand DIB on synthetic data, showing that the IB and DIB perform similarly in\nterms of the IB cost function, but that the DIB significantly outperforms the\nIB in terms of the DIB cost function. We also empirically find that the DIB\noffers a considerable gain in computational efficiency over the IB, over a\nrange of convergence parameters. Our derivation of the DIB also suggests a\nmethod for continuously interpolating between the soft clustering of the IB and\nthe hard clustering of the DIB.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 14:48:31 GMT"}, {"version": "v2", "created": "Mon, 19 Dec 2016 05:26:11 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Strouse", "DJ", ""], ["Schwab", "David J", ""]]}, {"id": "1604.00385", "submitter": "Stephen Plaza", "authors": "Stephen M. Plaza and Stuart E. Berg", "title": "Large-Scale Electron Microscopy Image Segmentation in Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging field of connectomics aims to unlock the mysteries of the brain\nby understanding the connectivity between neurons. To map this connectivity, we\nacquire thousands of electron microscopy (EM) images with nanometer-scale\nresolution. After aligning these images, the resulting dataset has the\npotential to reveal the shapes of neurons and the synaptic connections between\nthem. However, imaging the brain of even a tiny organism like the fruit fly\nyields terabytes of data. It can take years of manual effort to examine such\nimage volumes and trace their neuronal connections. One solution is to apply\nimage segmentation algorithms to help automate the tracing tasks. In this\npaper, we propose a novel strategy to apply such segmentation on very large\ndatasets that exceed the capacity of a single machine. Our solution is robust\nto potential segmentation errors which could otherwise severely compromise the\nquality of the overall segmentation, for example those due to poor classifier\ngeneralizability or anomalies in the image dataset. We implement our algorithms\nin a Spark application which minimizes disk I/O, and apply them to a few large\nEM datasets, revealing both their effectiveness and scalability. We hope this\nwork will encourage external contributions to EM segmentation by providing 1) a\nflexible plugin architecture that deploys easily on different cluster\nenvironments and 2) an in-memory representation of segmentation that could be\nconducive to new advances.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 19:53:30 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Plaza", "Stephen M.", ""], ["Berg", "Stuart E.", ""]]}, {"id": "1604.01674", "submitter": "Sean Robinson", "authors": "C. Brandon Ogbunugafor and Sean P. Robinson", "title": "OFFl models: novel schema for dynamical modeling of biological systems", "comments": "23 pages, 6 figures. Revised to match published version in PLoS ONE", "journal-ref": "PLoS ONE 11(6): e0156844 (2016)", "doi": "10.1371/journal.pone.0156844", "report-no": null, "categories": "q-bio.QM q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow diagrams are a common tool used to help build and interpret models of\ndynamical systems, often in biological contexts such as consumer-resource\nmodels and similar compartmental models. Typically, their usage is intuitive\nand informal. Here, we present a formalized version of flow diagrams as a kind\nof weighted directed graph which follow a strict grammar, which translate into\na system of ordinary differential equations (ODEs) by a single unambiguous\nrule, and which have an equivalent representation as a relational database. (We\nabbreviate this schema of \"ODEs and formalized flow diagrams\" as OFFl.) Drawing\na diagram within this strict grammar encourages a mental discipline on the part\nof the modeler in which all dynamical processes of a system are thought of as\ninteractions between dynamical species that draw parcels from one or more\nsource species and deposit them into target species according to a set of\ntransformation rules. From these rules, the net rate of change for each species\ncan be derived. The modeling schema can therefore be understood as both an\nepistemic and practical heuristic for modeling, serving both as an\norganizational framework for the model building process and as a mechanism for\nderiving ODEs. All steps of the schema beyond the initial scientific\n(intuitive, creative) abstraction of natural observations into model variables\nare algorithmic and easily carried out by a computer, thus enabling the future\ndevelopment of a dedicated software implementation. Such tools would empower\nthe modeler to consider significantly more complex models than practical\nlimitations might have otherwise proscribed, since the modeling framework\nitself manages that complexity on the modeler's behalf. In this report, we\ndescribe the chief motivations for OFFl, outline its implementation, and\nutilize a range of classic examples from ecology and epidemiology to showcase\nits features.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 16:04:03 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 20:09:27 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Ogbunugafor", "C. Brandon", ""], ["Robinson", "Sean P.", ""]]}, {"id": "1604.02099", "submitter": "Yoo Ah Kim", "authors": "Yoo-Ah Kim, Sanna Madan, and Teresa M. Przytycka", "title": "WeSME: Uncovering Mutual Exclusivity of Cancer Drivers and Beyond", "comments": "Paper accepted at RECOMB-CCB 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mutual exclusivity is a widely recognized property of many cancer drivers.\nKnowledge about these relationships can provide important insights into cancer\ndrivers, cancer-driving pathways, and cancer subtypes. It can also be used to\npredict new functional interactions between cancer driving genes and uncover\nnovel cancer drivers. Currently, most of mutual exclusivity analyses are\npreformed focusing on a limited set of genes in part due to the computational\ncost required to rigorously compute p-values. To reduce the computing cost and\nperform less restricted mutual exclusivity analysis, we developed an efficient\nmethod to estimate p-values while controlling the mutation rates of individual\npatients and genes similar to the permutation test. A comprehensive mutual\nexclusivity analysis allowed us to uncover mutually exclusive pairs, some of\nwhich may have relatively low mutation rates. These pairs often included likely\ncancer drivers that have been missed in previous analyses. More importantly,\nour results demonstrated that mutual exclusivity can also provide information\nthat goes beyond the interactions between cancer drivers and can, for example,\nelucidate different mutagenic processes in different cancer groups. In\nparticular, including frequently mutated, long genes such as TTN in our\nanalysis allowed us to observe interesting patterns of APOBEC activity in\nbreast cancer and identify a set of related driver genes that are highly\npredictive of patient survival. In addition, we utilized our mutual exclusivity\nanalysis in support of a previously proposed model where APOBEC activity is the\nunderlying process that causes TP53 mutations in a subset of breast cancer\ncases.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 18:18:21 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Kim", "Yoo-Ah", ""], ["Madan", "Sanna", ""], ["Przytycka", "Teresa M.", ""]]}, {"id": "1604.02270", "submitter": "Mikhail Kolmogorov", "authors": "Mikhail Kolmogorov, Eamonn Kennedy, Zhuxin Dong, Gregory Timp and\n  Pavel Pevzner", "title": "Single-Molecule Protein Identification by Sub-Nanopore Sensors", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1005356", "report-no": null, "categories": "q-bio.QM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in top-down mass spectrometry enabled identification of\nintact proteins, but this technology still faces challenges. For example,\ntop-down mass spectrometry suffers from a lack of sensitivity since the ion\ncounts for a single fragmentation event are often low. In contrast, nanopore\ntechnology is exquisitely sensitive to single intact molecules, but it has only\nbeen successfully applied to DNA sequencing, so far. Here, we explore the\npotential of sub-nanopores for single-molecule protein identification (SMPI)\nand describe an algorithm for identification of the electrical current blockade\nsignal (nanospectrum) resulting from the translocation of a denaturated,\nlinearly charged protein through a sub-nanopore. The analysis of identification\np-values suggests that the current technology is already sufficient for\nmatching nanospectra against small protein databases, e.g., protein\nidentification in bacterial proteomes.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 08:16:41 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 23:24:59 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Kolmogorov", "Mikhail", ""], ["Kennedy", "Eamonn", ""], ["Dong", "Zhuxin", ""], ["Timp", "Gregory", ""], ["Pevzner", "Pavel", ""]]}, {"id": "1604.02467", "submitter": "Fabio Vandin", "authors": "Tommy Hansen, Fabio Vandin", "title": "Finding Mutated Subnetworks Associated with Survival in Cancer", "comments": "This paper was selected for oral presentation at RECOMB 2016 and an\n  abstract is published in the conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-generation sequencing technologies allow the measurement of somatic\nmutations in a large number of patients from the same cancer type. One of the\nmain goals in analyzing these mutations is the identification of mutations\nassociated with clinical parameters, such as survival time. This goal is\nhindered by the genetic heterogeneity of mutations in cancer, due to the fact\nthat genes and mutations act in the context of pathways. To identify mutations\nassociated with survival time it is therefore crucial to study mutations in the\ncontext of interaction networks.\n  In this work we study the problem of identifying subnetworks of a large\ngene-gene interaction network that have mutations associated with survival. We\nformally define the associated computational problem by using a score for\nsubnetworks based on the test statistic of the log-rank test, a widely used\nstatistical test for comparing the survival of two populations. We show that\nthe computational problem is NP-hard and we propose a novel algorithm, called\nNetwork of Mutations Associated with Survival (NoMAS), to solve it. NoMAS is\nbased on the color-coding technique, that has been previously used in other\napplications to find the highest scoring subnetwork with high probability when\nthe subnetwork score is additive. In our case the score is not additive;\nnonetheless, we prove that under a reasonable model for mutations in cancer\nNoMAS does identify the optimal solution with high probability. We test NoMAS\non simulated and cancer data, comparing it to approaches based on single gene\ntests and to various greedy approaches. We show that our method does indeed\nfind the optimal solution and performs better than the other approaches.\nMoreover, on two cancer datasets our method identifies subnetworks with\nsignificant association to survival when none of the genes has significant\nassociation with survival when considered in isolation.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 20:09:07 GMT"}, {"version": "v2", "created": "Sat, 10 Sep 2016 11:25:43 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Hansen", "Tommy", ""], ["Vandin", "Fabio", ""]]}, {"id": "1604.02605", "submitter": "Mohammed El-Kebir", "authors": "Mohammed El-Kebir and Gryte Satas and Layla Oesper and Benjamin J.\n  Raphael", "title": "Multi-State Perfect Phylogeny Mixture Deconvolution and Applications to\n  Cancer Sequencing", "comments": "RECOMB 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconstruction of phylogenetic trees from mixed populations has become\nimportant in the study of cancer evolution, as sequencing is often performed on\nbulk tumor tissue containing mixed populations of cells. Recent work has shown\nhow to reconstruct a perfect phylogeny tree from samples that contain mixtures\nof two-state characters, where each character/locus is either mutated or not.\nHowever, most cancers contain more complex mutations, such as copy-number\naberrations, that exhibit more than two states. We formulate the Multi-State\nPerfect Phylogeny Mixture Deconvolution Problem of reconstructing a multi-state\nperfect phylogeny tree given mixtures of the leaves of the tree. We\ncharacterize the solutions of this problem as a restricted class of spanning\ntrees in a graph constructed from the input data, and prove that the problem is\nNP-complete. We derive an algorithm to enumerate such trees in the important\nspecial case of cladisitic characters, where the ordering of the states of each\ncharacter is given. We apply our algorithm to simulated data and to two cancer\ndatasets. On simulated data, we find that for a small number of samples, the\nMulti-State Perfect Phylogeny Mixture Deconvolution Problem often has many\nsolutions, but that this ambiguity declines quickly as the number of samples\nincreases. On real data, we recover copy-neutral loss of heterozygosity,\nsingle-copy amplification and single-copy deletion events, as well as their\ninteractions with single-nucleotide variants.\n", "versions": [{"version": "v1", "created": "Sat, 9 Apr 2016 20:00:07 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["El-Kebir", "Mohammed", ""], ["Satas", "Gryte", ""], ["Oesper", "Layla", ""], ["Raphael", "Benjamin J.", ""]]}, {"id": "1604.02699", "submitter": "Yunan Luo", "authors": "Yunan Luo, Jianyang Zeng, Bonnie Berger, Jian Peng", "title": "Low-density locality-sensitive hashing boosts metagenomic binning", "comments": "RECOMB 2016. Due to the limitation \"The abstract field cannot be\n  longer than 1,920 characters\", the abstract appearing here is slightly\n  shorter than the one in the PDF file", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metagenomic binning is an essential task in analyzing metagenomic sequence\ndatasets. To analyze structure or function of microbial communities from\nenvironmental samples, metagenomic sequence fragments are assigned to their\ntaxonomic origins. Although sequence alignment algorithms can readily be used\nand usually provide high-resolution alignments and accurate binning results,\nthe computational cost of such alignment-based methods becomes prohibitive as\nmetagenomic datasets continue to grow. Alternative compositional-based methods,\nwhich exploit sequence composition by profiling local short k-mers in\nfragments, are often faster but less accurate than alignment-based methods.\nInspired by the success of linear error correcting codes in noisy channel\ncommunication, we introduce Opal, a fast and accurate novel compositional-based\nbinning method. It incorporates ideas from Gallager's low-density parity-check\ncode to design a family of compact and discriminative locality-sensitive\nhashing functions that encode long-range compositional dependencies in long\nfragments. By incorporating the Gallager LSH functions as features in a simple\nlinear SVM, Opal provides fast, accurate and robust binning for datasets\nconsisting of a large number of species, even with mutations and sequencing\nerrors. Opal not only performs up to two orders of magnitude faster than BWA,\nan alignment-based binning method, but also achieves improved binning accuracy\nand robustness to sequencing errors. Opal also outperforms models built on\ntraditional k-mer profiles in terms of robustness and accuracy. Finally, we\ndemonstrate that we can effectively use Opal in the \"coarse search\" stage of a\ncompressive genomics pipeline to identify a much smaller candidate set of\ntaxonomic origins for a subsequent alignment-based method to analyze, thus\nproviding metagenomic binning with high scalability, high accuracy and high\nresolution.\n", "versions": [{"version": "v1", "created": "Sun, 10 Apr 2016 14:57:58 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Luo", "Yunan", ""], ["Zeng", "Jianyang", ""], ["Berger", "Bonnie", ""], ["Peng", "Jian", ""]]}, {"id": "1604.02909", "submitter": "Benjamin Schott M.Sc.", "authors": "Benjamin Schott, Johannes Stegmaier, Alexandre Arbaud, Markus Reischl,\n  Ralf Mikut, Francis L\\'evi", "title": "Robust Individual Circadian Parameter Estimation for Biosignal-based\n  Personalisation of Cancer Chronotherapy", "comments": "Conference Biosig 2016, Berlin", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cancer treatment, chemotherapy is administered according a constant\nschedule. The chronotherapy approach, considering chronobiological drug\ndelivery, adapts the chemotherapy profile to the circadian rhythms of the human\norganism. This reduces toxicity effects and at the same time enhances\nefficiency of chemotherapy. To personalize cancer treatment, chemotherapy\nprofiles have to be further adapted to individual patients. Therefore, we\npresent a new model to represent cycle phenomena in circadian rhythms. The\nmodel enables a more precise modelling of the underlying circadian rhythms. In\ncomparison with the standard model, our model delivers better results in all\ndefined quality indices. The new model can be used to adapt the chemotherapy\nprofile efficiently to individual patients. The adaption to individual patients\ncontributes to the aim of personalizing cancer therapy.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 12:14:07 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Schott", "Benjamin", ""], ["Stegmaier", "Johannes", ""], ["Arbaud", "Alexandre", ""], ["Reischl", "Markus", ""], ["Mikut", "Ralf", ""], ["L\u00e9vi", "Francis", ""]]}, {"id": "1604.03052", "submitter": "Sabrina Rashid", "authors": "Shashank Singh, Sabrina Rashid, Zhicheng Long, Saket Navlakha, Hanna\n  Salman, Zoltan N. Oltvai, Ziv Bar-Joseph", "title": "Distributed Gradient Descent in Bacterial Food Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication and coordination play a major role in the ability of bacterial\ncells to adapt to ever changing environments and conditions. Recent work has\nshown that such coordination underlies several aspects of bacterial responses\nincluding their ability to develop antibiotic resistance. Here we develop a new\ndistributed gradient descent method that helps explain how bacterial cells\ncollectively search for food in harsh environments using extremely limited\ncommunication and computational complexity. This method can also be used for\ncomputational tasks when agents are facing similarly restricted conditions. We\nformalize the communication and computation assumptions required for successful\ncoordination and prove that the method we propose leads to convergence even\nwhen using a dynamically changing interaction network. The proposed method\nimproves upon prior models suggested for bacterial foraging despite making\nfewer assumptions. Simulation studies and analysis of experimental data\nillustrate the ability of the method to explain and further predict several\naspects of bacterial swarm food search.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 18:19:33 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Singh", "Shashank", ""], ["Rashid", "Sabrina", ""], ["Long", "Zhicheng", ""], ["Navlakha", "Saket", ""], ["Salman", "Hanna", ""], ["Oltvai", "Zoltan N.", ""], ["Bar-Joseph", "Ziv", ""]]}, {"id": "1604.03071", "submitter": "Anton Korobeynikov", "authors": "Sergey Nurk, Dmitry Meleshko, Anton Korobeynikov and Pavel Pevzner", "title": "metaSPAdes: a new versatile de novo metagenomics assembler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While metagenomics has emerged as a technology of choice for analyzing\nbacterial populations, assembly of metagenomic data remains difficult thus\nstifling biological discoveries. metaSPAdes is a new assembler that addresses\nthe challenge of metagenome analysis and capitalizes on computational ideas\nthat proved to be useful in assemblies of single cells and highly polymorphic\ndiploid genomes. We benchmark metaSPAdes against other state-of-the-art\nmetagenome assemblers across diverse da-tasets and demonstrate that it results\nin high-quality assemblies.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 19:09:22 GMT"}, {"version": "v2", "created": "Mon, 1 Aug 2016 15:32:16 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Nurk", "Sergey", ""], ["Meleshko", "Dmitry", ""], ["Korobeynikov", "Anton", ""], ["Pevzner", "Pavel", ""]]}, {"id": "1604.03081", "submitter": "Jan Hoinka", "authors": "Phuong Dao, Jan Hoinka, Yijie Wang, Mayumi Takahashi, Jiehua Zhou,\n  Fabrizio Costa, John Rossi, John Burnett, Rolf Backofen, Teresa M. Przytycka", "title": "AptaTRACE: Elucidating Sequence-Structure Binding Motifs by Uncovering\n  Selection Trends in HT-SELEX Experiments", "comments": "This paper was selected for oral presentation at RECOMB 2016 and an\n  abstract is published in the conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aptamers, short synthetic RNA/DNA molecules binding specific targets with\nhigh affinity and specificity, are utilized in an increasing spectrum of\nbio-medical applications. Aptamers are identified in vitro via the Systematic\nEvolution of Ligands by Exponential Enrichment (SELEX) protocol. SELEX selects\nbinders through an iterative process that, starting from a pool of random\nssDNA/RNA sequences, amplifies target-affine species through a series of\nselection cycles. HT-SELEX, which combines SELEX with high throughput\nsequencing, has recently transformed aptamer development and has opened the\nfield to even more applications. HT-SELEX is capable of generating over half a\nbillion data points, challenging computational scientists with the task of\nidentifying aptamer properties such as sequence structure motifs that determine\nbinding. While currently available motif finding approaches suggest partial\nsolutions to this question, none possess the generality or scalability required\nfor HT-SELEX data, and they do not take advantage of important properties of\nthe experimental procedure.\n  We present AptaTRACE, a novel approach for the identification of\nsequence-structure binding motifs in HT-SELEX derived aptamers. Our approach\nleverages the experimental design of the SELEX protocol and identifies\nsequence-structure motifs that show a signature of selection. Because of its\nunique approach, AptaTRACE can uncover motifs even when these are present in\nonly a minuscule fraction of the pool. Due to these features, our method can\nhelp to reduce the number of selection cycles required to produce aptamers with\nthe desired properties, thus reducing cost and time of this rather expensive\nprocedure. The performance of the method on simulated and real data indicates\nthat AptaTRACE can detect sequence-structure motifs even in highly challenging\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 18:47:52 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Dao", "Phuong", ""], ["Hoinka", "Jan", ""], ["Wang", "Yijie", ""], ["Takahashi", "Mayumi", ""], ["Zhou", "Jiehua", ""], ["Costa", "Fabrizio", ""], ["Rossi", "John", ""], ["Burnett", "John", ""], ["Backofen", "Rolf", ""], ["Przytycka", "Teresa M.", ""]]}, {"id": "1604.03199", "submitter": "William Gray Roncal", "authors": "William Gray Roncal, Eva L Dyer, Doga G\\\"ursoy, Konrad Kording,\n  Narayanan Kasthuri", "title": "From sample to knowledge: Towards an integrated approach for\n  neuroscience discovery", "comments": "first two authors contributed equally. 8 pages, 2 figures. v2: added\n  acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging methods used in modern neuroscience experiments are quickly producing\nlarge amounts of data capable of providing increasing amounts of knowledge\nabout neuroanatomy and function. A great deal of information in these datasets\nis relatively unexplored and untapped. One of the bottlenecks in knowledge\nextraction is that often there is no feedback loop between the knowledge\nproduced (e.g., graph, density estimate, or other statistic) and the earlier\nstages of the pipeline (e.g., acquisition). We thus advocate for the\ndevelopment of sample-to-knowledge discovery pipelines that one can use to\noptimize acquisition and processing steps with a particular end goal (i.e.,\npiece of knowledge) in mind. We therefore propose that optimization takes place\nnot just within each processing stage but also between adjacent (and\nnon-adjacent) steps of the pipeline. Furthermore, we explore the existing\ncategories of knowledge representation and models to motivate the types of\nexperiments and analysis needed to achieve the ultimate goal. To illustrate\nthis approach, we provide an experimental paradigm to answer questions about\nlarge-scale synaptic distributions through a multimodal approach combining\nX-ray microtomography and electron microscopy.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 01:41:48 GMT"}, {"version": "v2", "created": "Mon, 23 Jan 2017 19:30:41 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Roncal", "William Gray", ""], ["Dyer", "Eva L", ""], ["G\u00fcrsoy", "Doga", ""], ["Kording", "Konrad", ""], ["Kasthuri", "Narayanan", ""]]}, {"id": "1604.03388", "submitter": "Daniele Cappelletti", "authors": "David F. Anderson, Daniele Cappelletti and Thomas G. Kurtz", "title": "Finite time distributions of stochastically modeled chemical systems\n  with absolute concentration robustness", "comments": null, "journal-ref": null, "doi": "10.1137/16M1070773", "report-no": null, "categories": "math.PR q-bio.MN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in both the experimental and mathematical communities has\nfocused on biochemical interaction systems that satisfy an \"absolute\nconcentration robustness\" (ACR) property. The ACR property was first discovered\nexperimentally when, in a number of different systems, the concentrations of\nkey system components at equilibrium were observed to be robust to the total\nconcentration levels of the system. Followup mathematical work focused on\ndeterministic models of biochemical systems and demonstrated how chemical\nreaction network theory can be utilized to explain this robustness. Later\nmathematical work focused on the behavior of this same class of reaction\nnetworks, though under the assumption that the dynamics were stochastic. Under\nthe stochastic assumption, it was proven that the system will undergo an\nextinction event with a probability of one so long as the system is\nconservative, showing starkly different long-time behavior than in the\ndeterministic setting. Here we consider a general class of stochastic models\nthat intersects with the class of ACR systems studied previously. We consider a\nspecific system scaling over compact time intervals and prove that in a limit\nof this scaling the distribution of the abundances of the ACR species converges\nto a certain product-form Poisson distribution whose mean is the ACR value of\nthe deterministic model. This result is in agreement with recent conjectures\npertaining to the behavior of ACR networks endowed with stochastic kinetics,\nand helps to resolve the conflicting theoretical results pertaining to\ndeterministic and stochastic models in this setting.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 13:07:40 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2016 14:08:22 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Anderson", "David F.", ""], ["Cappelletti", "Daniele", ""], ["Kurtz", "Thomas G.", ""]]}, {"id": "1604.03629", "submitter": "William Gray Roncal", "authors": "Eva L. Dyer, William Gray Roncal, Hugo L. Fernandes, Doga G\\\"ursoy,\n  Vincent De Andrade, Rafael Vescovi, Kamel Fezzaa, Xianghui Xiao, Joshua T.\n  Vogelstein, Chris Jacobsen, Konrad P. K\\\"ording and Narayanan Kasthuri", "title": "Quantifying mesoscale neuroanatomy using X-ray microtomography", "comments": "28 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for resolving the 3D microstructure of the brain typically start by\nthinly slicing and staining the brain, and then imaging each individual section\nwith visible light photons or electrons. In contrast, X-rays can be used to\nimage thick samples, providing a rapid approach for producing large 3D brain\nmaps without sectioning. Here we demonstrate the use of synchrotron X-ray\nmicrotomography ($\\mu$CT) for producing mesoscale $(1~\\mu m^3)$ resolution\nbrain maps from millimeter-scale volumes of mouse brain. We introduce a\npipeline for $\\mu$CT-based brain mapping that combines methods for sample\npreparation, imaging, automated segmentation of image volumes into cells and\nblood vessels, and statistical analysis of the resulting brain structures. Our\nresults demonstrate that X-ray tomography promises rapid quantification of\nlarge brain volumes, complementing other brain mapping and connectomics\nefforts.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 01:46:54 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 19:56:59 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Dyer", "Eva L.", ""], ["Roncal", "William Gray", ""], ["Fernandes", "Hugo L.", ""], ["G\u00fcrsoy", "Doga", ""], ["De Andrade", "Vincent", ""], ["Vescovi", "Rafael", ""], ["Fezzaa", "Kamel", ""], ["Xiao", "Xianghui", ""], ["Vogelstein", "Joshua T.", ""], ["Jacobsen", "Chris", ""], ["K\u00f6rding", "Konrad P.", ""], ["Kasthuri", "Narayanan", ""]]}, {"id": "1604.03834", "submitter": "Yaneer Bar-Yam", "authors": "Dan Evans, Fred Nijhout, Raphael Parens, Alfredo J. Morales and Yaneer\n  Bar-Yam", "title": "A Possible Link Between Pyriproxyfen and Microcephaly", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": "New England Complex Systems Institute Report 2016-04-02", "categories": "q-bio.QM q-bio.BM q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Zika virus is the primary suspect in the large increase in microcephaly\ncases in 2015-6 in Brazil, however its role is unconfirmed despite individual\ncases of viral infections found in neural tissue. Here we consider the\nalternative that the insecticide pyriproxyfen, used in Brazilian drinking water\nfor mosquito control, may actually be the cause. Pyriproxifen is an analog of\njuvenile hormone, which corresponds in mammals to regulatory molecules\nincluding retinoic acid, a vitamin A metabolite, with which it has\ncross-reactivity and whose application during development causes microcephaly.\nMethoprene, another juvenile hormone analog approved as an insecticide has\nmetabolites that bind to the retinoid X receptor, and causes developmental\ndisorders in mammals. Isotretinoin is another example of a retinoid causing\nmicrocephaly in human babies via activation of the retinoid X receptor.\nMoreover, tests of pyriproxyfen by the manufacturer, Sumitomo, widely quoted as\ngiving no evidence for developmental toxicity, actually found some evidence for\nsuch an effect, including low brain mass and arhinencephaly--incomplete\nformation of the anterior cerebral hemispheres--in rat pups. Finally, the\npyriproxyfen use in Brazil is unprecedented--it has never before been applied\nto a water supply on such a scale. Claims that it is not being used in Recife,\nthe epicenter of microcephaly cases, do not distinguish the metropolitan area\nof Recife, where it is widely used, and the municipality, where it is not.\nGiven this combination of information we strongly recommend that the use of\npyriproxyfen in Brazil be suspended pending further investigation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 15:35:21 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Evans", "Dan", ""], ["Nijhout", "Fred", ""], ["Parens", "Raphael", ""], ["Morales", "Alfredo J.", ""], ["Bar-Yam", "Yaneer", ""]]}, {"id": "1604.04484", "submitter": "Sean Simmons", "authors": "Sean Simmons, Cenk Sahinalp, and Bonnie Berger", "title": "Enabling Privacy-Preserving GWAS in Heterogeneous Human Populations", "comments": "To be presented at RECOMB 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The projected increase of genotyping in the clinic and the rise of large\ngenomic databases has led to the possibility of using patient medical data to\nperform genomewide association studies (GWAS) on a larger scale and at a lower\ncost than ever before. Due to privacy concerns, however, access to this data is\nlimited to a few trusted individuals, greatly reducing its impact on biomedical\nresearch. Privacy preserving methods have been suggested as a way of allowing\nmore people access to this precious data while protecting patients. In\nparticular, there has been growing interest in applying the concept of\ndifferential privacy to GWAS results. Unfortunately, previous approaches for\nperforming differentially private GWAS are based on rather simple statistics\nthat have some major limitations. In particular, they do not correct for\npopulation stratification, a major issue when dealing with the genetically\ndiverse populations present in modern GWAS. To address this concern we\nintroduce a novel computational framework for performing GWAS that tailors\nideas from differential privacy to protect private phenotype information, while\nat the same time correcting for population stratification. This framework\nallows us to produce privacy preserving GWAS results based on two of the most\ncommonly used GWAS statistics: EIGENSTRAT and linear mixed model (LMM) based\nstatistics. We test our differentially private statistics, PrivSTRAT and\nPrivLMM, on both simulated and real GWAS datasets and find that they are able\nto protect privacy while returning meaningful GWAS results.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 13:06:47 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Simmons", "Sean", ""], ["Sahinalp", "Cenk", ""], ["Berger", "Bonnie", ""]]}, {"id": "1604.04539", "submitter": "Youdong Mao", "authors": "Jiayi Wu, Yong-Bei Ma, Charles Congdon, Bevin Brett, Shuobing Chen, Qi\n  Ouyang, Youdong Mao", "title": "Unsupervised single-particle deep clustering via statistical manifold\n  learning", "comments": "29 pages, 5 figures", "journal-ref": "PLoS ONE 12, e0182130 (2017)", "doi": "10.1371/journal.pone.0182130", "report-no": null, "categories": "physics.data-an cs.CV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Structural heterogeneity in single-particle cryo-electron\nmicroscopy (cryo-EM) data represents a major challenge for high-resolution\nstructure determination. Unsupervised classification may serve as the first\nstep in the assessment of structural heterogeneity. Traditional algorithms for\nunsupervised classification, such as K-means clustering and maximum likelihood\noptimization, may classify images into wrong classes with decreasing\nsignal-to-noise-ratio (SNR) in the image data, yet demand increased cost in\ncomputation. Overcoming these limitations requires further development on\nclustering algorithms for high-performance cryo-EM data analysis. Results: Here\nwe introduce a statistical manifold learning algorithm for unsupervised\nsingle-particle deep clustering. We show that statistical manifold learning\nimproves classification accuracy by about 40% in the absence of input\nreferences for lower SNR data. Applications to several experimental datasets\nsuggest that our deep clustering approach can detect subtle structural\ndifference among classes. Through code optimization over the Intel\nhigh-performance computing (HPC) processors, our software implementation can\ngenerate thousands of reference-free class averages within several hours from\nhundreds of thousands of single-particle cryo-EM images, which allows\nsignificant improvement in ab initio 3D reconstruction resolution and quality.\nOur approach has been successfully applied in several structural determination\nprojects. We expect that it provides a powerful computational tool in analyzing\nhighly heterogeneous structural data and assisting in computational\npurification of single-particle datasets for high-resolution reconstruction.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 15:28:39 GMT"}, {"version": "v2", "created": "Sat, 31 Dec 2016 07:43:07 GMT"}], "update_date": "2017-11-01", "authors_parsed": [["Wu", "Jiayi", ""], ["Ma", "Yong-Bei", ""], ["Congdon", "Charles", ""], ["Brett", "Bevin", ""], ["Chen", "Shuobing", ""], ["Ouyang", "Qi", ""], ["Mao", "Youdong", ""]]}, {"id": "1604.04683", "submitter": "John Medaglia", "authors": "John D. Medaglia, Fabio Pasqualetti, Roy H. Hamilton, Sharon L.\n  Thompson-Schill, and Danielle S. Bassett", "title": "Brain and Cognitive Reserve: Translation via Network Control Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional approaches to understanding the brain's resilience to\nneuropathology have identified neurophysiological variables, often described as\nbrain or cognitive 'reserve,' associated with better outcomes. However,\nmechanisms of function and resilience in large-scale brain networks remain\npoorly understood. Dynamic network theory may provide a basis for substantive\nadvances in understanding functional resilience in the human brain. In this\nperspective, we describe recent theoretical approaches from network control\ntheory as a framework for investigating network level mechanisms underlying\ncognitive function and the dynamics of neuroplasticity in the human brain. We\ndescribe the theoretical opportunities offered by the application of network\ncontrol theory at the level of the human connectome to understand cognitive\nresilience and inform translational intervention.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 02:50:00 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2017 13:56:10 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Medaglia", "John D.", ""], ["Pasqualetti", "Fabio", ""], ["Hamilton", "Roy H.", ""], ["Thompson-Schill", "Sharon L.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1604.04878", "submitter": "Antonio Fiore", "authors": "Antonio Fiore, Jitao Zhang, Peng Shao, Seok Hyun Yun and Giuliano\n  Scarcelli", "title": "High-extinction VIPA-based Brillouin spectroscopy of turbid biological\n  media", "comments": null, "journal-ref": null, "doi": "10.1063/1.4948353", "report-no": null, "categories": "physics.bio-ph physics.optics q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brillouin microscopy has recently emerged as powerful technique to\ncharacterize the mechanical properties of biological tissue, cell and\nbiomaterials. However, the potential of Brillouin microscopy is currently\nlimited to transparent samples, because Brillouin spectrometers do not have\nsufficient spectral extinction to reject the predominant non-Brillouin\nscattered light of turbid media. To overcome this issue, we developed a\nspectrometer composed of a two VIPA stages and a multi-pass Fabry-Perot\ninterferometer. The Fabry-Perot etalon acts as an ultra-narrow band-pass filter\nfor Brillouin light with high spectral extinction and low loss. We report\nbackground-free Brillouin spectra from Intralipid solutions and up to 100\nmicrons deep within chicken muscle tissue.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2016 14:59:58 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Fiore", "Antonio", ""], ["Zhang", "Jitao", ""], ["Shao", "Peng", ""], ["Yun", "Seok Hyun", ""], ["Scarcelli", "Giuliano", ""]]}, {"id": "1604.04903", "submitter": "Thorsten Pr\\\"ustel", "authors": "Thorsten Pr\\\"ustel and Martin Meier-Schellersheim", "title": "Path integral approach to theories of diffusion-influenced reactions", "comments": "13 pages", "journal-ref": null, "doi": "10.1103/PhysRevE.96.022151", "report-no": null, "categories": "q-bio.QM cond-mat.stat-mech", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The path decomposition expansion represents the propagator of the\nirreversible reaction as a convolution of the first-passage, last-passage and\nrebinding time probability densities. Using path integral technique, we give an\nelementary, yet rigorous, proof of the path decomposition expansion of the\nGreen's functions describing the non-reactive case and the irreversible\nreaction of an isolated pair of molecules. To this end, we exploit the\nconnection between boundary value problems and interaction potential problems\nwith $\\delta$- and $\\delta'$-function perturbation. In particular, we employ a\nknown exact summation of a perturbation series to derive exact relations\nbetween the Green's functions of the perturbed and unperturbed problem. Along\nthe way, we are able to derive a number of additional exact identities that\nrelate the propagators describing the free-space, the non-reactive as well as\nthe completely and partially reactive case.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2016 18:05:02 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Pr\u00fcstel", "Thorsten", ""], ["Meier-Schellersheim", "Martin", ""]]}, {"id": "1604.04906", "submitter": "Johannes Stegmaier", "authors": "Johannes Stegmaier, Julian Arz, Benjamin Schott, Jens C. Otte, Andrei\n  Kobitski, G. Ulrich Nienhaus, Uwe Str\\\"ahle, Peter Sanders, Ralf Mikut", "title": "Generating Semi-Synthetic Validation Benchmarks for Embryomics", "comments": "Accepted publication at IEEE International Symposium on Biomedical\n  Imaging: From Nano to Macro (ISBI), 2016", "journal-ref": null, "doi": "10.1109/ISBI.2016.7493359", "report-no": null, "categories": "cs.CV q-bio.CB q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systematic validation is an essential part of algorithm development. The\nenormous dataset sizes and the complexity observed in many recent time-resolved\n3D fluorescence microscopy imaging experiments, however, prohibit a\ncomprehensive manual ground truth generation. Moreover, existing simulated\nbenchmarks in this field are often too simple or too specialized to\nsufficiently validate the observed image analysis problems. We present a new\nsemi-synthetic approach to generate realistic 3D+t benchmarks that combines\nchallenging cellular movement dynamics of real embryos with simulated\nfluorescent nuclei and artificial image distortions including various\nparametrizable options like cell numbers, acquisition deficiencies or multiview\nsimulations. We successfully applied the approach to simulate the development\nof a zebrafish embryo with thousands of cells over 14 hours of its early\nexistence.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2016 18:29:48 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Stegmaier", "Johannes", ""], ["Arz", "Julian", ""], ["Schott", "Benjamin", ""], ["Otte", "Jens C.", ""], ["Kobitski", "Andrei", ""], ["Nienhaus", "G. Ulrich", ""], ["Str\u00e4hle", "Uwe", ""], ["Sanders", "Peter", ""], ["Mikut", "Ralf", ""]]}, {"id": "1604.05102", "submitter": "Ruth Baker", "authors": "Daniel Wilson and Ruth E. Baker", "title": "Multi-level methods and approximating distribution functions", "comments": "22 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biochemical reaction networks are often modelled using discrete-state,\ncontinuous-time Markov chains. System statistics of these Markov chains usually\ncannot be calculated analytically and therefore estimates must be generated via\nsimulation techniques. There is a well documented class of simulation\ntechniques known as exact stochastic simulation algorithms, an example of which\nis Gillespie's direct method. These algorithms often come with high\ncomputational costs, therefore approximate stochastic simulation algorithms\nsuch as the tau-leap method are used. However, in order to minimise the bias in\nthe estimates generated using them, a relatively small value of tau is needed,\nrendering the computational costs comparable to Gillespie's direct method.\n  The multi-level Monte Carlo method (Anderson and Higham, Multiscale Model.\nSimul. 10:146-179, 2012) provides a reduction in computational costs whilst\nminimising or even eliminating the bias in the estimates of system statistics.\nThis is achieved by first crudely approximating required statistics with many\nsample paths of low accuracy. Then correction terms are added until a required\nlevel of accuracy is reached. Recent literature has primarily focussed on\nimplementing the multi-level method efficiently to estimate a single system\nstatistic. However, it is clearly also of interest to be able to approximate\nentire probability distributions of species counts. We present two novel\nmethods that combine known techniques for distribution reconstruction with the\nmulti-level method. We demonstrate the potential of our methods using a number\nof examples.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 11:49:05 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Wilson", "Daniel", ""], ["Baker", "Ruth E.", ""]]}, {"id": "1604.05189", "submitter": "Aaron Golden", "authors": "David Rhee, Kevin Shieh, Julie Sullivan, Gos Micklem, Kami Kim, Aaron\n  Golden", "title": "Understanding the Systems Biology of Pathogen Virulence Using Semantic\n  Methodologies", "comments": "To appear in the Proceedings of the 2016 IEEE Tenth International\n  Conference on Semantic Computing (ICSC 2016)", "journal-ref": null, "doi": "10.1109/ICSC.2016.33", "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems biology approaches to the integrative study of cells, organs and\norganisms offer the best means of understanding in a holistic manner the\ndiversity of molecular assays that can be now be implemented in a high\nthroughput manner. Such assays can sample the genome, epigenome, proteome,\nmetabolome and microbiome contemporaneously, allowing us for the first time to\nperform a complete analysis of physiological activity. The central problem\nremains empowering the scientific community to actually implement such an\nintegration, across seemingly diverse data types and measurements. One\npromising solution is to apply semantic techniques on a self-consistent and\nimplicitly correct ontological representation of these data types. In this\npaper we describe how we have applied one such solution, based around the\nInterMine data warehouse platform which uses as its basis the Sequence\nOntology, to facilitate a systems biology analysis of virulence in the\napicomplexan pathogen $Toxoplasma~gondii$, a common parasite that infects up to\nhalf the worlds population, with acute pathogenic risks for immuno-compromised\nindividuals or pregnant mothers. Our solution, which we named `toxoMine', has\nprovided both a platform for our collaborators to perform such integrative\nanalyses and also opportunities for such cyberinfrastructure to be further\ndeveloped, particularly to take advantage of possible semantic similarities of\nvalue to knowledge discovery in the Omics enterprise. We discuss these\nopportunities in the context of further enhancing the capabilities of this\npowerful integrative platform.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 14:56:35 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Rhee", "David", ""], ["Shieh", "Kevin", ""], ["Sullivan", "Julie", ""], ["Micklem", "Gos", ""], ["Kim", "Kami", ""], ["Golden", "Aaron", ""]]}, {"id": "1604.06089", "submitter": "Richard Mann", "authors": "Richard P. Mann", "title": "Towards a fully predictive model of flight paths in pigeons navigating\n  in the familiar area: prediction across differing individuals", "comments": "8 pages, 2 figures, Royal Institute of Navigation Conference on\n  Animal Navigation 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper will detail the basis of our previously developed predictive model\nfor pigeon flight paths based on observations of the specific individual being\npredicted. We will then describe how this model can be adapted to predict the\nflight of a new, unobserved bird, based on observations of other individuals\nfrom the same release site. We will test the accuracy of these predictions\nrelative to naive models with no previous flight information and those trained\non the focal bird's own previous flights, and discuss the implications of these\nresults for the nature of navigational cue use in the familiar area. Finally we\nwill discuss how visual cues may be explicitly encoded in the model in future\nwork.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 18:58:13 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Mann", "Richard P.", ""]]}, {"id": "1604.06660", "submitter": "Lina Meinecke", "authors": "Lina Meinecke and Markus Eriksson", "title": "Excluded volume effects in on- and off-lattice reaction-diffusion models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical models are important tools to study the excluded volume effects\non reaction-diffusion systems, which are known to play an important role inside\nliving cells. Detailed microscopic simulations with off-lattice Brownian\ndynamics become computationally expensive in crowded environments. In this\npaper we therefore investigate to which extent on-lattice approximations, so\ncalled Cellular Automata models, can be used to simulate reactions and\ndiffusion in the presence of crowding molecules. We show that the diffusion is\nmost severely slowed down in the off-lattice model, since randomly distributed\nobstacles effectively exclude more volume than those ordered on an artificial\ngrid. Crowded reaction rates can be both increased and decreased by the grid\nstructure and it proves important to model the molecules with realistic sizes\nwhen excluded volume is taken into account. The grid artifacts increase with\nincreasing crowder density and we conclude that the computationally more\nefficient on-lattice simulations are accurate approximations only for low\ncrowder densities.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 14:00:20 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Meinecke", "Lina", ""], ["Eriksson", "Markus", ""]]}, {"id": "1604.06783", "submitter": "Marieke Kuijjer", "authors": "David G.P. van IJzendoorn, Kimberly Glass, John Quackenbush, Marieke\n  L. Kuijjer", "title": "PyPanda: a Python Package for Gene Regulatory Network Reconstruction", "comments": "3 pages, 1 figure; version after Bioinformatics proofs", "journal-ref": null, "doi": "10.1093/bioinformatics/btw422", "report-no": null, "categories": "q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  PANDA (Passing Attributes between Networks for Data Assimilation) is a gene\nregulatory network inference method that uses message-passing to integrate\nmultiple sources of 'omics data. PANDA was originally coded in C++. In this\napplication note we describe PyPanda, the Python version of PANDA. PyPanda runs\nconsiderably faster than the C++ version and includes additional features for\nnetwork analysis. Availability: The open source PyPanda Python package is\nfreely available at https://github.com/davidvi/pypanda. Contact: d.g.p.van\nijzendoorn@lumc.nl\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 19:17:43 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2016 20:19:00 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["van IJzendoorn", "David G. P.", ""], ["Glass", "Kimberly", ""], ["Quackenbush", "John", ""], ["Kuijjer", "Marieke L.", ""]]}, {"id": "1604.06796", "submitter": "YongKeun Park", "authors": "JaeHwang Jung, Lucas E. Matemba, KyeoReh Lee, Paul E. Kazyoba, Jonghee\n  Yoon, Julius J. Massaga, Kyoohyun Kim, Dong-Jin Kim, and YongKeun Park", "title": "Optical characterization of red blood cells from individuals with sickle\n  cell trait and disease in Tanzania using quantitative phase imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph physics.optics q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sickle cell disease (SCD) is common across Sub-Saharan Africa. However, the\ninvestigation of SCD in this area has been significantly limited mainly due to\nthe lack of research facilities and skilled personnel. Here, we present optical\nmeasurements of individual red blood cells (RBCs) from healthy individuals and\nindividuals with SCD and sickle cell trait in Tanzania using the quantitative\nphase imaging technique. By employing a quantitative phase imaging unit (QPIU),\nan existing microscope in a clinic is transformed into a powerful quantitative\nphase microscope providing measurements on the morphological, biochemical, and\nbiomechanical properties of individual cells. The present approach will open up\nnew opportunities for cost-effective investigation and diagnosis of several\ndiseases in low resource environments.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 10:51:13 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Jung", "JaeHwang", ""], ["Matemba", "Lucas E.", ""], ["Lee", "KyeoReh", ""], ["Kazyoba", "Paul E.", ""], ["Yoon", "Jonghee", ""], ["Massaga", "Julius J.", ""], ["Kim", "Kyoohyun", ""], ["Kim", "Dong-Jin", ""], ["Park", "YongKeun", ""]]}, {"id": "1604.07176", "submitter": "Zhen Li", "authors": "Zhen Li and Yizhou Yu", "title": "Protein Secondary Structure Prediction Using Cascaded Convolutional and\n  Recurrent Neural Networks", "comments": "8 pages, 3 figures, Accepted by International Joint Conferences on\n  Artificial Intelligence (IJCAI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI cs.LG cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein secondary structure prediction is an important problem in\nbioinformatics. Inspired by the recent successes of deep neural networks, in\nthis paper, we propose an end-to-end deep network that predicts protein\nsecondary structures from integrated local and global contextual features. Our\ndeep architecture leverages convolutional neural networks with different kernel\nsizes to extract multiscale local contextual features. In addition, considering\nlong-range dependencies existing in amino acid sequences, we set up a\nbidirectional neural network consisting of gated recurrent unit to capture\nglobal contextual features. Furthermore, multi-task learning is utilized to\npredict secondary structure labels and amino-acid solvent accessibility\nsimultaneously. Our proposed deep network demonstrates its effectiveness by\nachieving state-of-the-art performance, i.e., 69.7% Q8 accuracy on the public\nbenchmark CB513, 76.9% Q8 accuracy on CASP10 and 73.1% Q8 accuracy on CASP11.\nOur model and results are publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 09:17:18 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Li", "Zhen", ""], ["Yu", "Yizhou", ""]]}, {"id": "1604.08314", "submitter": "Jonathan Harrison", "authors": "Jonathan U. Harrison, Christian A. Yates", "title": "A hybrid algorithm for coupling PDE and compartment-based dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic simulation methods can be applied successfully to model exact\nspatio-temporally resolved reaction-diffusion systems. However, in many cases,\nthese methods can quickly become extremely computationally intensive with\nincreasing particle numbers. An alternative description of many of these\nsystems can be derived in the diffusive limit as a deterministic, continuum\nsystem of partial differential equations. Although the numerical solution of\nsuch partial differential equations is, in general, much more efficient than\nthe full stochastic simulation, the deterministic continuum description is\ngenerally not valid when copy numbers are low and stochastic effects dominate.\nTherefore, to take advantage of the benefits of both of these types of models,\neach of which may be appropriate in different parts of a spatial domain, we\nhave developed an algorithm that can be used to couple these two types of model\ntogether. This hybrid coupling algorithm uses an overlap region between the two\nmodelling regimes. By coupling fluxes at one end of the interface and using a\nconcentration-matching condition at the other end, we ensure that mass is\nappropriately transferred between PDE- and compartment-based regimes. Our\nmethodology gives notable reductions in simulation time in comparison with\nusing a fully stochastic model, whilst maintaining the important stochastic\nfeatures of the system and providing detail in appropriate areas of the domain.\nWe test our hybrid methodology robustly by applying it to several biologically\nmotivated problems including diffusion and morphogen gradient formation. Our\nanalysis shows that the resulting error is small, unbiased and does not grow\nover time.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 05:55:22 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Harrison", "Jonathan U.", ""], ["Yates", "Christian A.", ""]]}, {"id": "1604.08544", "submitter": "Mauricio J. Del Razo Sarmina", "authors": "Mauricio J. Del Razo and Randall J. LeVeque", "title": "Numerical methods for interface coupling of compressible and almost\n  incompressible media", "comments": null, "journal-ref": "SIAM Journal on Scientific Computing, 39.3: B486-B507 (2017)", "doi": "10.1137/16M1067834", "report-no": null, "categories": "math.NA physics.flu-dyn q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many experiments in biomedical applications and other disciplines use a shock\ntube. These experiments often involve placing an experimental sample within a\nfluid-filled container, which is then placed inside the shock tube. The shock\ntube produces an initial shock that propagates through gas before hitting the\ncontainer with the sample. In order to gain insight into the shock dynamics\nthat is hard to obtain by experimental means, computational simulations of the\nshock wave passing from gas into a thin elastic solid and into a nearly\nincompressible fluid are developed. It is shown that if the solid interface is\nvery thin, it can be neglected, simplifying the model. The model uses Euler\nequations for compressible fluids coupled with a Tammann equation of state\n(EOS) to model both compressible gas and almost incompressible materials. A\nthree-dimensional (2D axisymmetric) model of these equations is solved using\nhigh-resolution shock-capturing methods, with newly developed Riemann solvers\nand limiters. The methods are extended to work on a mapped grid to allow more\ncomplicated interface geometry, and they are adapted to work with adaptive mesh\nrefinement (AMR) for higher resolution and faster computations. The Clawpack\nsoftware is used to implement the method. These methods were initially inspired\nby shock tube experiments to study the injury mechanisms of traumatic brain\ninjury (TBI).\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 18:22:20 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Del Razo", "Mauricio J.", ""], ["LeVeque", "Randall J.", ""]]}, {"id": "1604.08743", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze and Willie Yu", "title": "Factor Models for Cancer Signatures", "comments": "70 pages, 21 figures; a few trivial typos corrected", "journal-ref": "Physica A 462 (2016) 527-559", "doi": "10.1016/j.physa.2016.06.089", "report-no": null, "categories": "q-bio.GN q-bio.QM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for extracting cancer signatures by applying\nstatistical risk models (http://ssrn.com/abstract=2732453) from quantitative\nfinance to cancer genome data. Using 1389 whole genome sequenced samples from\n14 cancers, we identify an \"overall\" mode of somatic mutational noise. We give\na prescription for factoring out this noise and source code for fixing the\nnumber of signatures. We apply nonnegative matrix factorization (NMF) to genome\ndata aggregated by cancer subtype and filtered using our method. The resultant\nsignatures have substantially lower variability than those from unfiltered\ndata. Also, the computational cost of signature extraction is cut by about a\nfactor of 10. We find 3 novel cancer signatures, including a liver cancer\ndominant signature (96% contribution) and a renal cell carcinoma signature (70%\ncontribution). Our method accelerates finding new cancer signatures and\nimproves their overall stability. Reciprocally, the methods for extracting\ncancer signatures could have interesting applications in quantitative finance.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 09:11:34 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 00:16:35 GMT"}, {"version": "v3", "created": "Wed, 29 Jun 2016 16:42:31 GMT"}, {"version": "v4", "created": "Mon, 23 Jan 2017 04:47:59 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Kakushadze", "Zura", ""], ["Yu", "Willie", ""]]}, {"id": "1604.08908", "submitter": "Bence M\\'elyk\\'uti", "authors": "Felix Beck, Bence M\\'elyk\\'uti", "title": "Parameter estimation in a subcritical percolation model with colouring", "comments": "32 pages, 7 figures. Proof of uniform law of large numbers and\n  numerical evidence of identifiability added. Numerical testing redone. Code\n  available at https://github.com/Melykuti/Parameterestimation_MSM", "journal-ref": "Stochastics, 91(5), 657-694, 2019 (open access)", "doi": "10.1080/17442508.2018.1539089", "report-no": null, "categories": "math.ST math.PR q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the bond percolation model on a lattice, we colour vertices with $n_c$\ncolours independently at random according to Bernoulli distributions. A vertex\ncan receive multiple colours and each of these colours is individually\nobservable. The colours colour the entire component into which they fall. Our\ngoal is to estimate the $n_c +1$ parameters of the model: the probabilities of\ncolouring of single vertices and the probability with which an edge is open.\nThe input data is the configuration of colours once the complete components\nhave been coloured, without the information which vertices were originally\ncoloured or which edges are open.\n  We use a Monte Carlo method, the method of simulated moments to achieve this\ngoal. We prove that this method is a strongly consistent estimator by proving a\nuniform strong law of large numbers for the vertices' weakly dependent colour\nvalues. We evaluate the method in computer tests. The motivating application is\ncross-contamination rate estimation for digital PCR in lab-on-a-chip\nmicrofluidic devices.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 16:54:40 GMT"}, {"version": "v2", "created": "Fri, 22 Jul 2016 12:06:09 GMT"}, {"version": "v3", "created": "Fri, 10 Mar 2017 16:46:29 GMT"}], "update_date": "2019-06-14", "authors_parsed": [["Beck", "Felix", ""], ["M\u00e9lyk\u00fati", "Bence", ""]]}]