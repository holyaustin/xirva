[{"id": "1101.0305", "submitter": "David R. Bickel", "authors": "David R. Bickel", "title": "Measuring support for a hypothesis about a random parameter without\n  estimating its unknown prior", "comments": "Errors in the first version were corrected, and the methodology is\n  now applied to more interesting data", "journal-ref": "D. R. Bickel, Minimax-optimal strength of statistical evidence for\n  a composite alternative hypothesis, International Statistical Review 81,\n  188-206 (2013)", "doi": "10.1111/insr.12008", "report-no": null, "categories": "math.ST cs.IT math.IT q-bio.QM stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For frequentist settings in which parameter randomness represents variability\nrather than uncertainty, the ideal measure of the support for one hypothesis\nover another is the difference in the posterior and prior log odds. For\nsituations in which the prior distribution cannot be accurately estimated, that\nideal support may be replaced by another measure of support, which may be any\npredictor of the ideal support that, on a per-observation basis, is\nasymptotically unbiased. Two qualifying measures of support are defined. The\nfirst is minimax optimal with respect to the population and is equivalent to a\nparticular Bayes factor. The second is worst-sample minimax optimal and is\nequivalent to the normalized maximum likelihood. It has been extended by\nlikelihood weights for compatibility with more general models.\n  One such model is that of two independent normal samples, the standard\nsetting for gene expression microarray data analysis. Applying that model to\nproteomics data indicates that support computed from data for a single protein\ncan closely approximate the estimated difference in posterior and prior odds\nthat would be available with the data for 20 proteins. This suggests the\napplicability of random-parameter models to other situations in which the\nparameter distribution cannot be reliably estimated.\n", "versions": [{"version": "v1", "created": "Fri, 31 Dec 2010 22:32:51 GMT"}, {"version": "v2", "created": "Sat, 2 Apr 2011 20:29:05 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Bickel", "David R.", ""]]}, {"id": "1101.0344", "submitter": "Robin Genuer", "authors": "Robin Genuer (LM-Orsay, INRIA Saclay - Ile de France), Isabelle\n  Morlais, Wilson Toussile (LM-Orsay)", "title": "Gametocytes infectiousness to mosquitoes: variable selection using\n  random forests, and zero inflated models", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-7497", "categories": "math.ST q-bio.PE q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malaria control strategies aiming at reducing disease transmission intensity\nmay impact both oocyst intensity and infection prevalence in the mosquito\nvector. Thus far, mathematical models failed to identify a clear relationship\nbetween Plasmodium falciparum gametocytes and their infectiousness to\nmosquitoes. Natural isolates of gametocytes are genetically diverse and\nbiologically complex. Infectiousness to mosquitoes relies on multiple\nparameters such as density, sex-ratio, maturity, parasite genotypes and host\nimmune factors. In this article, we investigated how density and genetic\ndiversity of gametocytes impact on the success of transmission in the mosquito\nvector. We analyzed data for which the number of covariates plus attendant\ninteractions is at least of order of the sample size, precluding usage of\nclassical models such as general linear models. We then considered the variable\nimportance from random forests to address the problem of selecting the most\ninfluent variables. The selected covariates were assessed in the zero inflated\nnegative binomial model which accommodates both over-dispersion and the sources\nof non infected mosquitoes. We found that the most important covariates related\nto infection prevalence and parasite intensity are gametocyte density and\nmultiplicity of infection.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jan 2011 15:02:14 GMT"}, {"version": "v2", "created": "Tue, 4 Jan 2011 15:27:42 GMT"}, {"version": "v3", "created": "Tue, 22 Feb 2011 07:23:13 GMT"}], "update_date": "2011-02-24", "authors_parsed": [["Genuer", "Robin", "", "LM-Orsay, INRIA Saclay - Ile de France"], ["Morlais", "Isabelle", "", "LM-Orsay"], ["Toussile", "Wilson", "", "LM-Orsay"]]}, {"id": "1101.0484", "submitter": "Marc Joyeux", "authors": "Marc Joyeux, Olivier Vincent, Philippe Marmottant", "title": "Mechanical model of the ultra-fast underwater trap of Utricularia", "comments": "Accepted for publication in Physical Review E", "journal-ref": "Physical Review E 83 (2011) 021911", "doi": "10.1103/PhysRevE.83.021911", "report-no": null, "categories": "physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The underwater traps of the carnivorous plants of the Utricularia species\ncatch their preys through the repetition of an \"active slow deflation / passive\nfast suction\" sequence. In this paper, we propose a mechanical model that\ndescribes both phases and strongly supports the hypothesis that the trap door\nacts as a flexible valve that buckles under the combined effects of pressure\nforces and the mechanical stimulation of trigger hairs, and not as a panel\narticulated on hinges. This model combines two different approaches, namely (i)\nthe description of thin membranes as triangle meshes with strain and curvature\nenergy, and (ii) the molecular dynamics approach, which consists in computing\nthe time evolution of the position of each vertex of the mesh according to\nLangevin equations. The only free parameter in the expression of the elastic\nenergy is the Young's modulus E of the membranes. The values for this parameter\nare unequivocally obtained by requiring that the trap model fires, like real\ntraps, when the pressure difference between the outside and the inside of the\ntrap reaches about 15 kPa. Among other results, our simulations show that, for\na pressure difference slightly larger than the critical one, the door buckles,\nslides on the threshold and finally swings wide open, in excellent agreement\nwith the sequence observed in high-speed videos.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jan 2011 10:37:30 GMT"}], "update_date": "2011-02-22", "authors_parsed": [["Joyeux", "Marc", ""], ["Vincent", "Olivier", ""], ["Marmottant", "Philippe", ""]]}, {"id": "1101.0632", "submitter": "Doug Speed", "authors": "Doug Speed, Simon Tavar\\'e", "title": "Sparse Partitioning: Nonlinear regression with binary or tertiary\n  predictors, with application to association studies", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS411 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2A, 873-893", "doi": "10.1214/10-AOAS411", "report-no": "IMS-AOAS-AOAS411", "categories": "q-bio.QM stat.AP stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Sparse Partitioning, a Bayesian method for identifying\npredictors that either individually or in combination with others affect a\nresponse variable. The method is designed for regression problems involving\nbinary or tertiary predictors and allows the number of predictors to exceed the\nsize of the sample, two properties which make it well suited for association\nstudies. Sparse Partitioning differs from other regression methods by placing\nno restrictions on how the predictors may influence the response. To compensate\nfor this generality, Sparse Partitioning implements a novel way of exploring\nthe model space. It searches for high posterior probability partitions of the\npredictor set, where each partition defines groups of predictors that jointly\ninfluence the response. The result is a robust method that requires no prior\nknowledge of the true predictor--response relationship. Testing on simulated\ndata suggests Sparse Partitioning will typically match the performance of an\nexisting method on a data set which obeys the existing method's model\nassumptions. When these assumptions are violated, Sparse Partitioning will\ngenerally offer superior performance.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 00:43:09 GMT"}, {"version": "v2", "created": "Tue, 30 Aug 2011 06:11:26 GMT"}], "update_date": "2011-08-31", "authors_parsed": [["Speed", "Doug", ""], ["Tavar\u00e9", "Simon", ""]]}, {"id": "1101.0687", "submitter": "Martin Berglund", "authors": "Martin Berglund, Mikael Sunn{\\aa}ker, Martin Adiels, Mats Jirstrand,\n  Bernt Wennberg", "title": "Investigations of a compartmental model for leucine kinetics using\n  nonlinear mixed effects models with ordinary and stochastic differential\n  equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear mixed effects models represent a powerful tool to simultaneously\nanalyze data from several individuals. In this study a compartmental model of\nleucine kinetics is examined and extended with a stochastic differential\nequation to model non-steady state concentrations of free leucine in the\nplasma. Data obtained from tracer/tracee experiments for a group of healthy\ncontrol individuals and a group of individuals suffering from diabetes mellitus\ntype 2 are analyzed. We find that the interindividual variation of the model\nparameters is much smaller for the nonlinear mixed effects models, compared to\ntraditional estimates obtained from each individual separately. Using the mixed\neffects approach, the population parameters are estimated well also when only\nhalf of the data are used for each individual. For a typical individual the\namount of free leucine is predicted to vary with a standard deviation of 8.9%\naround a mean value during the experiment. Moreover, leucine degradation and\nprotein uptake of leucine is smaller, proteolysis larger, and the amount of\nfree leucine in the body is much larger for the diabetic individuals than the\ncontrol individuals. In conclusion nonlinear mixed effects models offers\nimproved estimates for model parameters in complex models based on\ntracer/tracee data and may be a suitable tool to reduce data sampling in\nclinical studies.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 09:58:26 GMT"}], "update_date": "2011-01-05", "authors_parsed": [["Berglund", "Martin", ""], ["Sunn\u00e5ker", "Mikael", ""], ["Adiels", "Martin", ""], ["Jirstrand", "Mats", ""], ["Wennberg", "Bernt", ""]]}, {"id": "1101.0723", "submitter": "Jongmin Kim", "authors": "Pakpoom Subsoontorn, Jongmin Kim, Erik Winfree", "title": "Bistability of an In Vitro Synthetic Autoregulatory Switch", "comments": "21 pages, 9 figures, journal version in preparation", "journal-ref": "ACS Synthetic Biology 2012", "doi": "10.1021/sb300018h", "report-no": null, "categories": "q-bio.MN q-bio.BM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The construction of synthetic biochemical circuits is an essential step for\ndeveloping quantitative understanding of information processing in natural\norganisms. Here, we report construction and analysis of an in vitro circuit\nwith positive autoregulation that consists of just four synthetic DNA strands\nand three enzymes, bacteriophage T7 RNA polymerase, Escherichia coli\nribonuclease (RNase) H, and RNase R. The modularity of the DNA switch template\nallowed a rational design of a synthetic DNA switch regulated by its RNA output\nacting as a transcription activator. We verified that the thermodynamic and\nkinetic constraints dictated by the sequence design criteria were enough to\nexperimentally achieve the intended dynamics: a transcription activator\nconfigured to regulate its own production. Although only RNase H is necessary\nto achieve bistability of switch states, RNase R is necessary to maintain\nstable RNA signal levels and to control incomplete degradation products. A\nsimple mathematical model was used to fit ensemble parameters for the training\nset of experimental results and was then directly applied to predict\ntime-courses of switch dynamics and sensitivity to parameter variations with\nreasonable agreement. The positive autoregulation switches can be used to\nprovide constant input signals and store outputs of biochemical networks and\nare potentially useful for chemical control applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 14:23:40 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Subsoontorn", "Pakpoom", ""], ["Kim", "Jongmin", ""], ["Winfree", "Erik", ""]]}, {"id": "1101.1154", "submitter": "Alan R. Dabney", "authors": "Yuliya V. Karpievitch, Ashoka D. Polpitiya, Gordon A. Anderson,\n  Richard D. Smith, Alan R. Dabney", "title": "Liquid chromatography mass spectrometry-based proteomics: Biological and\n  technological aspects", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS341 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 1797-1823", "doi": "10.1214/10-AOAS341", "report-no": "IMS-AOAS-AOAS341", "categories": "stat.AP q-bio.BM q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass spectrometry-based proteomics has become the tool of choice for\nidentifying and quantifying the proteome of an organism. Though recent years\nhave seen a tremendous improvement in instrument performance and the\ncomputational tools used, significant challenges remain, and there are many\nopportunities for statisticians to make important contributions. In the most\nwidely used \"bottom-up\" approach to proteomics, complex mixtures of proteins\nare first subjected to enzymatic cleavage, the resulting peptide products are\nseparated based on chemical or physical properties and analyzed using a mass\nspectrometer. The two fundamental challenges in the analysis of bottom-up\nMS-based proteomics are as follows: (1) Identifying the proteins that are\npresent in a sample, and (2) Quantifying the abundance levels of the identified\nproteins. Both of these challenges require knowledge of the biological and\ntechnological context that gives rise to observed data, as well as the\napplication of sound statistical principles for estimation and inference. We\npresent an overview of bottom-up proteomics and outline the key statistical\nissues that arise in protein identification and quantification.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jan 2011 07:40:25 GMT"}], "update_date": "2011-01-07", "authors_parsed": [["Karpievitch", "Yuliya V.", ""], ["Polpitiya", "Ashoka D.", ""], ["Anderson", "Gordon A.", ""], ["Smith", "Richard D.", ""], ["Dabney", "Alan R.", ""]]}, {"id": "1101.1438", "submitter": "Rebecca Killick", "authors": "R. Killick, P. Fearnhead and I. A. Eckley", "title": "Optimal detection of changepoints with a linear computational cost", "comments": "25 pages, 4 figures, To appear in Journal of the American Statistical\n  Association", "journal-ref": "Journal of the American Statistical Association 107(500), pp.\n  1590-1598 (2012)", "doi": "10.1080/01621459.2012.737745", "report-no": null, "categories": "stat.ME q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of detecting multiple changepoints in large data\nsets. Our focus is on applications where the number of changepoints will\nincrease as we collect more data: for example in genetics as we analyse larger\nregions of the genome, or in finance as we observe time-series over longer\nperiods. We consider the common approach of detecting changepoints through\nminimising a cost function over possible numbers and locations of changepoints.\nThis includes several established procedures for detecting changing points,\nsuch as penalised likelihood and minimum description length. We introduce a new\nmethod for finding the minimum of such cost functions and hence the optimal\nnumber and location of changepoints that has a computational cost which, under\nmild conditions, is linear in the number of observations. This compares\nfavourably with existing methods for the same problem whose computational cost\ncan be quadratic or even cubic. In simulation studies we show that our new\nmethod can be orders of magnitude faster than these alternative exact methods.\nWe also compare with the Binary Segmentation algorithm for identifying\nchangepoints, showing that the exactness of our approach can lead to\nsubstantial improvements in the accuracy of the inferred segmentation of the\ndata.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 14:13:12 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2011 11:10:53 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2012 08:47:31 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Killick", "R.", ""], ["Fearnhead", "P.", ""], ["Eckley", "I. A.", ""]]}, {"id": "1101.1556", "submitter": "Simon DeDeo", "authors": "Simon DeDeo, David C. Krakauer, Jessica C. Flack", "title": "Evidence of strategic periodicities in collective conflict dynamics", "comments": "22 pages, 7 figures, 1 table. Accepted for publication in Journal of\n  the Royal Society Interface", "journal-ref": "J. R. Soc. Interface (2011) vol. 8, no. 62, 1260-1273", "doi": "10.1098/rsif.2010.0687", "report-no": "SFI Working Paper #11-01-002", "categories": "q-bio.PE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the timescales of conflict decision-making in a primate society.\nWe present evidence for multiple, periodic timescales associated with social\ndecision-making and behavioral patterns. We demonstrate the existence of\nperiodicities that are not directly coupled to environmental cycles or known\nultraridian mechanisms. Among specific biological and socially-defined\ndemographic classes, periodicities span timescales between hours and days, and\nmany are not driven by exogenous or internal regularities. Our results indicate\nthat they are instead driven by strategic responses to social interaction\npatterns. Analyses also reveal that a class of individuals, playing a critical\nfunctional role, policing, have a signature timescale on the order of one hour.\nWe propose a classification of behavioral timescales analogous to those of the\nnervous system, with high-frequency, or $\\alpha$-scale, behavior occurring on\nhour-long scales, through to multi-hour, or $\\beta$-scale, behavior, and,\nfinally $\\gamma$ periodicities observed on a timescale of days.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jan 2011 23:39:54 GMT"}], "update_date": "2011-09-21", "authors_parsed": [["DeDeo", "Simon", ""], ["Krakauer", "David C.", ""], ["Flack", "Jessica C.", ""]]}, {"id": "1101.1651", "submitter": "Giuseppe Tronci", "authors": "Giuseppe Tronci", "title": "Synthesis, characterization, and biological evaluation of gelatin-based\n  scaffolds", "comments": "PhD thesis, University of Potsdam, Germany, December 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft cond-mat.mtrl-sci physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis presents the development of entropy-elastic gelatin based\nnetworks in the form of films or scaffolds. The materials have good prospects\nfor biomedical applications, especially in the context of bone regeneration.\nEntropy-elastic gelatin based hydrogel films with varying crosslinking\ndensities were prepared with tailored mechanical properties. Gelatin was\ncovalently crosslinked in water above its sol gel transition, which suppressed\nthe gelatin chain helicity. Amorphous films were prepared with tailorable\ndegrees of swelling and wet state Young's modulus. The knowledge gained with\nthis bulk material was transferred to the integrated process of foaming and\ncrosslinking to obtain porous gelatin-based scaffolds. A gelatin solution was\nfoamed in the presence of saponin and the resulting foam was fixed by chemical\ncrosslinking with a diisocyanate. The scaffolds were analyzed in the dry state\nby micro computed tomography (\\mu CT, porosity: 65\\pm 11-73\\pm 14 vol.-%), and\nscanning electron microscopy (SEM, pore size: 117\\pm 28-166 \\pm 32 \\mu m).\nAfter equilibration with water, the scaffolds were form-stable and displayed\nshape recovery after removal of mechanical loads. The composition dependent\ncompression moduli (Ec: 10 50 kPa) were comparable to the bulk micromechanical\nYoung's moduli, which were measured by atomic force microscopy (AFM). The\nhydrolytic degradation profile could be adjusted, and a controlled decrease of\nmechanical properties was observed. The scaffold cytotoxicity and immunologic\nresponses were analyzed in vitro. Indirect eluate tests were carried out with\nL929 cells so that fully cytocompatible scaffolds were obtained. Furthermore,\nthe material immune response was investigated in vitro. Minimal material\nendotoxin contamination was successfully achieved (<0.5 EU/mL) by using\nlow-endotoxin gelatin and performing all synthetic steps in cleanroom.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jan 2011 16:27:23 GMT"}, {"version": "v2", "created": "Tue, 11 Jan 2011 10:00:45 GMT"}], "update_date": "2011-01-12", "authors_parsed": [["Tronci", "Giuseppe", ""]]}, {"id": "1101.1796", "submitter": "Christos Skiadas H", "authors": "Christos H Skiadas, Charilaos Skiadas", "title": "Properties of a Stochastic Model for Life Table Data: Exploring Life\n  Expectancy Limits", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CD nlin.AO q-bio.PE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explore the life expectancy limits by based on the\nstochastic modeling of mortality and applying the first exit or hitting time\ntheory of a stochastic process. The main assumption is that the health state or\nthe \"vitality\", according to Strehler and Mildvan, of an individual is a\nstochastic variable and thus it was introduced and applied a first exit time\ndensity function to mortality data. The model is used to estimate the\ndevelopment of mortality rates in the late stages of the human life span, to\nmake better fitting to population mortality data including the infant\nmortality, to compare it with the classical Gompertz curve, and to make\ncomparisons between the Carey med-fly data and the population mortality data\nestimating the health state or \"vitality\" functions. Furthermore, we apply the\nmodel to the life table data of Italy, France, USA, Canada, Sweden, Norway and\nJapan, and we analyze the characteristic parameters of the model and make\nforecasts.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jan 2011 12:56:47 GMT"}], "update_date": "2011-01-11", "authors_parsed": [["Skiadas", "Christos H", ""], ["Skiadas", "Charilaos", ""]]}, {"id": "1101.1836", "submitter": "Ahmad Khoureich Ka", "authors": "Ahmad Khoureich Ka (IRMAR)", "title": "ECG beats classification using waveform similarity and RR interval", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper present an electrocardiogram (ECG) beat classification method\nbased on waveform similarity and RR interval. The purpose of the method is to\nclassify six types of heart beats (normal beat, atrial premature beat, paced\nbeat, premature ventricular beat, left bundle branch block beat and right\nbundle branch block beat). The electrocardiogram signal is first denoised using\nwavelet transform based techniques. Heart beats of 128 samples data centered on\nthe R peak are extracted from the ECG signal and thence reduced to 16 samples\ndata to constitute a feature. RR intervals surrounding the beat are also\nexploited as feature. A database of annotated beats is built for the classifier\nfor waveform comparison to unknown beats. Tested on 46 records in the MIT/BIH\narrhythmia database, the method shows classification rate of 97.52%.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jan 2011 15:03:05 GMT"}], "update_date": "2011-01-11", "authors_parsed": [["Ka", "Ahmad Khoureich", "", "IRMAR"]]}, {"id": "1101.2103", "submitter": "Tim Spencer", "authors": "T. J. Spencer, I. Halliday, C. M. Care, S. H. Cartmell and L. A.\n  Hidalgo-Bastida", "title": "Numerical Solution of a Complete Formulation of Flow in a Perfusion\n  Bone-Tissue Bioreactor Using Lattice Boltzmann Equation Method", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report the key findings from numerical solutions of a model of transport\nwithin an established perfusion bioreactor design. The model includes a\ncomplete formulation of transport with fully coupled convection-diffusion and\nscaffold cell attachment. It also includes the experimentally determined\ninternal (Poly-L-Lactic Acid (PLLA)) scaffold boundary, together with the\nexternal vessel and flow-port boundaries. Our findings, obtained using parallel\nlattice Boltzmann equation method, relate to (i) whole-device, steady-state\nflow and species distribution and (ii) the properties of the scaffold. In\nparticular the results identify which elements of the problem may be addressed\nby coarse grained methods such as the Darcy approximation and those which\nrequire a more complete description. The work demonstrates that appropriate\nnumerical modelling will make a key contribution to the design and development\nof large scale bioreactors.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jan 2011 11:49:03 GMT"}], "update_date": "2011-01-12", "authors_parsed": [["Spencer", "T. J.", ""], ["Halliday", "I.", ""], ["Care", "C. M.", ""], ["Cartmell", "S. H.", ""], ["Hidalgo-Bastida", "L. A.", ""]]}, {"id": "1101.2592", "submitter": "Sean Simpson", "authors": "Sean L. Simpson, Malaak N. Moussa, Paul J. Laurienti", "title": "An exponential random graph modeling approach to creating group-based\n  representative whole-brain connectivity networks", "comments": null, "journal-ref": "NeuroImage 2012: 60, 1117-1126", "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Group-based brain connectivity networks have great appeal for researchers\ninterested in gaining further insight into complex brain function and how it\nchanges across different mental states and disease conditions. Accurately\nconstructing these networks presents a daunting challenge given the\ndifficulties associated with accounting for inter-subject topological\nvariability. Viable approaches to this task must engender networks that capture\nthe constitutive topological properties of the group of subjects' networks that\nit is aiming to represent. The conventional approach has been to use a mean or\nmedian correlation network (Achard et al., 2006; Song et al., 2009) to embody a\ngroup of networks. However, the degree to which their topological properties\nconform with those of the groups that they are purported to represent has yet\nto be explored. Here we investigate the performance of these mean and median\ncorrelation networks. We also propose an alternative approach based on an\nexponential random graph modeling framework and compare its performance to that\nof the aforementioned conventional approach. Simpson et al. (2010) illustrated\nthe utility of exponential random graph models (ERGMs) for creating brain\nnetworks that capture the topological characteristics of a single subject's\nbrain network. However, their advantageousness in the context of producing a\nbrain network that \"represents\" a group of brain networks has yet to be\nexamined. Here we show that our proposed ERGM approach outperforms the\nconventional mean and median correlation based approaches and provides an\naccurate and flexible method for constructing group-based representative brain\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jan 2011 15:48:05 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2011 21:17:26 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Simpson", "Sean L.", ""], ["Moussa", "Malaak N.", ""], ["Laurienti", "Paul J.", ""]]}, {"id": "1101.2597", "submitter": "Nayyar Mehmood", "authors": "Nayyar Mehmood", "title": "Modelling the Transmission Dynamics of Hepatitis B & Optimal control", "comments": "This paper has been withdrawn by the author due to a crucial error in\n  one of equation in (3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has been withdrawn by the author due to a crucial error in one of\nequation in (3).\n", "versions": [{"version": "v1", "created": "Thu, 13 Jan 2011 15:59:19 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2011 05:21:05 GMT"}], "update_date": "2011-10-21", "authors_parsed": [["Mehmood", "Nayyar", ""]]}, {"id": "1101.2851", "submitter": "Thierry Gobron", "authors": "Thierry Gobron (LPTM), Mario Santoro, Livio Triolo", "title": "Competing HIV Strains and Immune System Response", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a simple deterministic model which describes an asymmetric\ncompetition between an immune system with a specific and powerful response, and\na virus with a broad toxicity and fast mutations. Interest in this model relies\non the fact that in spite of it simplicity, it reproduces some of the features\nof the asymptomatic phase of the infection by HIV-1. In particular, there is a\ndomain of parameters in which the dynamics is characterized by the apparition\nof \\blips\", associated here to an instability which develops at high virus\nreproduction rate. Various possible extensions of this simple model are\ndiscussed, in particular in view of its applications in the context of HAART\ntherapy.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jan 2011 16:14:44 GMT"}], "update_date": "2011-01-17", "authors_parsed": [["Gobron", "Thierry", "", "LPTM"], ["Santoro", "Mario", ""], ["Triolo", "Livio", ""]]}, {"id": "1101.3391", "submitter": "Thorsten Riess", "authors": "Thorsten Riess, Christian Dietz, Martin Tomas, Elisa Ferrando-May and\n  Dorit Merhof", "title": "Automated Image Processing for the Analysis of DNA Repair Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficient repair of cellular DNA is essential for the maintenance and\ninheritance of genomic information. In order to cope with the high frequency of\nspontaneous and induced DNA damage, a multitude of repair mechanisms have\nevolved. These are enabled by a wide range of protein factors specifically\nrecognizing different types of lesions and finally restoring the normal DNA\nsequence. This work focuses on the repair factor XPC (xeroderma pigmentosum\ncomplementation group C), which identifies bulky DNA lesions and initiates\ntheir removal via the nucleotide excision repair pathway. The binding of XPC to\ndamaged DNA can be visualized in living cells by following the accumulation of\na fluorescent XPC fusion at lesions induced by laser microirradiation in a\nfluorescence microscope. In this work, an automated image processing pipeline\nis presented which allows to identify and quantify the accumulation reaction\nwithout any user interaction. The image processing pipeline comprises a\npreprocessing stage where the image stack data is filtered and the nucleus of\ninterest is segmented. Afterwards, the images are registered to each other in\norder to account for movements of the cell, and then a bounding box enclosing\nthe XPC-specific signal is automatically determined. Finally, the\ntime-dependent relocation of XPC is evaluated by analyzing the intensity change\nwithin this box. Comparison of the automated processing results with the manual\nevaluation yields qualitatively similar results. However, the automated\nanalysis provides more accurate, reproducible data with smaller standard\nerrors. The image processing pipeline presented in this work allows for an\nefficient analysis of large amounts of experimental data with no user\ninteraction required.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jan 2011 06:48:35 GMT"}], "update_date": "2011-01-19", "authors_parsed": [["Riess", "Thorsten", ""], ["Dietz", "Christian", ""], ["Tomas", "Martin", ""], ["Ferrando-May", "Elisa", ""], ["Merhof", "Dorit", ""]]}, {"id": "1101.3457", "submitter": "F\\'elix Balado", "authors": "F\\'elix Balado", "title": "Capacity of DNA Data Embedding Under Substitution Mutations", "comments": "22 pages, 13 figures; preliminary versions of this work were\n  presented at the SPIE Media Forensics and Security XII conference (January\n  2010) and at the IEEE ICASSP conference (March 2010)", "journal-ref": null, "doi": "10.1109/TIT.2012.2219495", "report-no": null, "categories": "cs.IT math.IT q-bio.PE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of methods have been proposed over the last decade for encoding\ninformation using deoxyribonucleic acid (DNA), giving rise to the emerging area\nof DNA data embedding. Since a DNA sequence is conceptually equivalent to a\nsequence of quaternary symbols (bases), DNA data embedding (diversely called\nDNA watermarking or DNA steganography) can be seen as a digital communications\nproblem where channel errors are tantamount to mutations of DNA bases.\nDepending on the use of coding or noncoding DNA hosts, which, respectively,\ndenote DNA segments that can or cannot be translated into proteins, DNA data\nembedding is essentially a problem of communications with or without side\ninformation at the encoder. In this paper the Shannon capacity of DNA data\nembedding is obtained for the case in which DNA sequences are subject to\nsubstitution mutations modelled using the Kimura model from molecular evolution\nstudies. Inferences are also drawn with respect to the biological implications\nof some of the results presented.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jan 2011 13:52:29 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Balado", "F\u00e9lix", ""]]}, {"id": "1101.3493", "submitter": "Marine Jeanmougin", "authors": "Marine Jeanmougin, Mickael Guedj, Christophe Ambroise", "title": "Defining a robust biological prior from Pathway Analysis to drive\n  Network Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.MN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring genetic networks from gene expression data is one of the most\nchallenging work in the post-genomic era, partly due to the vast space of\npossible networks and the relatively small amount of data available. In this\nfield, Gaussian Graphical Model (GGM) provides a convenient framework for the\ndiscovery of biological networks. In this paper, we propose an original\napproach for inferring gene regulation networks using a robust biological prior\non their structure in order to limit the set of candidate networks.\n  Pathways, that represent biological knowledge on the regulatory networks,\nwill be used as an informative prior knowledge to drive Network Inference. This\napproach is based on the selection of a relevant set of genes, called the\n\"molecular signature\", associated with a condition of interest (for instance,\nthe genes involved in disease development). In this context, differential\nexpression analysis is a well established strategy. However outcome signatures\nare often not consistent and show little overlap between studies. Thus, we will\ndedicate the first part of our work to the improvement of the standard process\nof biomarker identification to guarantee the robustness and reproducibility of\nthe molecular signature.\n  Our approach enables to compare the networks inferred between two conditions\nof interest (for instance case and control networks) and help along the\nbiological interpretation of results. Thus it allows to identify differential\nregulations that occur in these conditions. We illustrate the proposed approach\nby applying our method to a study of breast cancer's response to treatment.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jan 2011 16:29:49 GMT"}, {"version": "v2", "created": "Tue, 17 May 2011 09:59:38 GMT"}], "update_date": "2011-05-18", "authors_parsed": [["Jeanmougin", "Marine", ""], ["Guedj", "Mickael", ""], ["Ambroise", "Christophe", ""]]}, {"id": "1101.3722", "submitter": "Giovanni Feverati", "authors": "Giovanni Feverati", "title": "Quantum integrable systems. Quantitative methods in biology", "comments": "This is the thesis I presented to the University of Savoie on\n  December, the 13, 2010, to obtain the \"habilitation \\`a diriger les\n  recherches\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.MP q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum integrable systems have very strong mathematical properties that\nallow an exact description of their energetic spectrum. From the Bethe\nequations, I formulate the Baxter \"T-Q\" relation, that is the starting point of\ntwo complementary approaches based on nonlinear integral equations. The first\none is known as thermodynamic Bethe ansatz, the second one as\nKl\\\"umper-Batchelor-Pearce-Destri- de Vega. I show the steps toward the\nderivation of the equations for some of the models concerned. I study the\ninfrared and ultraviolet limits and discuss the numerical approach. Higher rank\nintegrals of motion can be obtained, so gaining some control on the\neigenvectors. After, I discuss the Hubbard model in relation to the N = 4\nsupersymmetric gauge theory. The Hubbard model describes hopping electrons on a\nlattice.\n  In the second part, I present an evolutionary model based on Turing machines.\nThe goal is to describe aspects of the real biological evolution, or Darwinism,\nby letting evolve populations of algorithms. Particularly, with this model one\ncan study the mutual transformation of coding/non coding parts in a genome or\nthe presence of an error threshold. The assembly of oligomeric proteins is an\nimportant phenomenon which interests the majority of proteins in a cell. I\nparticipated to the creation of the project \"Gemini\" which has for purpose the\ninvestigation of the structural data of the interfaces of such proteins. The\nobjective is to differentiate the role of amino acids and determine the\npresence of patterns characterizing certain geometries.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jan 2011 16:16:09 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Feverati", "Giovanni", ""]]}, {"id": "1101.3983", "submitter": "Lipi Acharya", "authors": "Lipi Acharya, Thair Judeh, Zhansheng Duan, Michael Rabbat and Dongxiao\n  Zhu", "title": "GSGS: A Computational Framework to Reconstruct Signaling Pathways from\n  Gene Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel two-stage Gene Set Gibbs Sampling (GSGS) framework, to\nreverse engineer signaling pathways from gene sets inferred from molecular\nprofiling data. We hypothesize that signaling pathways are structurally an\nensemble of overlapping linear signal transduction events which we encode as\nInformation Flow Gene Sets (IFGS's). We infer pathways from gene sets\ncorresponding to these events subjected to a random permutation of genes within\neach set. In Stage I, we use a source separation algorithm to derive unordered\nand overlapping IFGS's from molecular profiling data, allowing cross talk among\nIFGS's. In Stage II, we develop a Gibbs sampling like algorithm, Gene Set Gibbs\nSampler, to reconstruct signaling pathways from the latent IFGS's derived in\nStage I. The novelty of this framework lies in the seamless integration of the\ntwo stages and the hypothesis of IFGS's as the basic building blocks for signal\npathways. In the proof-of-concept studies, our approach is shown to outperform\nthe existing Bayesian network approaches using both continuous and discrete\ndata generated from benchmark networks in the DREAM initiative. We perform a\ncomprehensive sensitivity analysis to assess the robustness of the approach.\nFinally, we implement the GSGS framework to reconstruct signaling pathways in\nbreast cancer cells.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jan 2011 18:08:48 GMT"}, {"version": "v2", "created": "Sun, 23 Jan 2011 07:22:58 GMT"}, {"version": "v3", "created": "Thu, 13 Oct 2011 21:53:19 GMT"}], "update_date": "2011-10-17", "authors_parsed": [["Acharya", "Lipi", ""], ["Judeh", "Thair", ""], ["Duan", "Zhansheng", ""], ["Rabbat", "Michael", ""], ["Zhu", "Dongxiao", ""]]}, {"id": "1101.4154", "submitter": "Maria Deijfen", "authors": "Maria Deijfen", "title": "Epidemics and vaccination on weighted graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Reed-Frost epidemic with inhomogeneous infection probabilities on a graph\nwith prescribed degree distribution is studied. Each edge $(u,v)$ in the graph\nis equipped with two weights $W_{(u,v)}$ and $W_{(v,u)}$ that represent the\n(subjective) strength of the connection and determine the probability that $u$\ninfects $v$ in case $u$ is infected and vice versa. Expressions for the\nepidemic threshold are derived for i.i.d.\\ weights and for weights that are\nfunctions of the degrees. For i.i.d.\\ weights, a variation of the so called\nacquaintance vaccination strategy is analyzed where vertices are chosen\nrandomly and neighbors of these vertices with large edge weights are\nvaccinated. This strategy is shown to outperform the strategy where the\nneighbors are chosen randomly in the sense that the basic reproduction number\nis smaller for a given vaccination coverage.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jan 2011 15:07:44 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Deijfen", "Maria", ""]]}, {"id": "1101.4242", "submitter": "Jarad Niemi", "authors": "Jarad Niemi and Matthew Wheeler", "title": "Efficient Bayesian inference in stochastic chemical kinetic models using\n  graphical processing units", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A goal of systems biology is to understand the dynamics of intracellular\nsystems. Stochastic chemical kinetic models are often utilized to accurately\ncapture the stochastic nature of these systems due to low numbers of molecules.\nCollecting system data allows for estimation of stochastic chemical kinetic\nrate parameters. We describe a well-known, but typically impractical data\naugmentation Markov chain Monte Carlo algorithm for estimating these\nparameters. The impracticality is due to the use of rejection sampling for\nlatent trajectories with fixed initial and final endpoints which can have\ndiminutive acceptance probability. We show how graphical processing units can\nbe efficiently utilized for parameter estimation in systems that hitherto were\ninestimable. For more complex systems, we show the efficiency gain over\ntraditional CPU computing is on the order of 200. Finally, we show a Bayesian\nanalysis of a system based on Michaelis-Menton kinetics.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jan 2011 22:57:52 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Niemi", "Jarad", ""], ["Wheeler", "Matthew", ""]]}, {"id": "1101.4265", "submitter": "Kevin E. Cahill", "authors": "Kevin Cahill", "title": "Models of Membrane Electrostatics", "comments": "Minor changes, 12 pages, 8 figures", "journal-ref": "Physical Review E 85(5), 051921 (2012)", "doi": "10.1103/PhysRevE.85.051921", "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I derive formulas for the electrostatic potential of a charge in or near a\nmembrane modeled as one or more dielectric slabs lying between two\nsemi-infinite dielectrics. One can use these formulas in Monte Carlo codes to\ncompute the distribution of ions near cell membranes more accurately than by\nusing Poisson-Boltzmann theory or its linearized version. Here I use them to\ndiscuss the electric field of a uniformly charged membrane, the image charges\nof an ion, the distribution of salt ions near a charged membrane, the energy of\na zwitterion near a lipid slab, and the effect of including the phosphate head\ngroups as thin layers of high electric permittivity.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jan 2011 06:30:58 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2011 04:56:35 GMT"}, {"version": "v3", "created": "Tue, 18 Oct 2011 13:50:54 GMT"}, {"version": "v4", "created": "Wed, 19 Oct 2011 02:33:27 GMT"}, {"version": "v5", "created": "Mon, 2 Jan 2012 06:28:49 GMT"}, {"version": "v6", "created": "Tue, 15 May 2012 06:57:43 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Cahill", "Kevin", ""]]}, {"id": "1101.4577", "submitter": "Meili Baragatti", "authors": "Meili Baragatti (IML)", "title": "Bayesian Variable Selection for Probit Mixed Models Applied to Gene\n  Selection", "comments": null, "journal-ref": "Bayesian Analysis 6, 2 (2011) 209-230", "doi": "10.1214/11-BA607", "report-no": null, "categories": "stat.ME q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computational biology, gene expression datasets are characterized by very\nfew individual samples compared to a large number of measurements per sample.\nThus, it is appealing to merge these datasets in order to increase the number\nof observations and diversify the data, allowing a more reliable selection of\ngenes relevant to the biological problem. Besides, the increased size of a\nmerged dataset facilitates its re-splitting into training and validation sets.\nThis necessitates the introduction of the dataset as a random effect. In this\ncontext, extending a work of Lee et al. (2003), a method is proposed to select\nrelevant variables among tens of thousands in a probit mixed regression model,\nconsidered as part of a larger hierarchical Bayesian model. Latent variables\nare used to identify subsets of selected variables and the grouping (or\nblocking) technique of Liu (1994) is combined with a Metropolis-within-Gibbs\nalgorithm (Robert and Casella 2004). The method is applied to a merged dataset\nmade of three individual gene expression datasets, in which tens of thousands\nof measurements are available for each of several hundred human breast cancer\nsamples. Even for this large dataset comprised of around 20000 predictors, the\nmethod is shown to be efficient and feasible. As an illustration, it is used to\nselect the most important genes that characterize the estrogen receptor status\nof patients with breast cancer.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jan 2011 16:08:54 GMT"}, {"version": "v2", "created": "Wed, 23 Feb 2011 06:12:55 GMT"}], "update_date": "2011-08-18", "authors_parsed": [["Baragatti", "Meili", "", "IML"]]}, {"id": "1101.4636", "submitter": "David Koslicki", "authors": "David Koslicki", "title": "Topological Entropy of DNA Sequences", "comments": "16 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological entropy has been one of the most difficult to implement of all\nthe entropy-theoretic notions. This is primarily due to finite sample effects\nand high-dimensionality problems. In particular, topological entropy has been\nimplemented in previous literature to conclude that entropy of exons is higher\nthan of introns, thus implying that exons are more \"random\" than introns. We\ndefine a new approximation to topological entropy free from the aforementioned\ndifficulties. We compute its expected value and apply this definition to the\nintron and exon regions of the human genome to observe that as expected, the\nentropy of introns are significantly higher than that of exons. Though we\nsurprisingly find that introns are less random than expected: their entropy is\nlower than the computed expected value. We observe the perplexing phenomena\nthat chromosome Y has atypically low and bi-modal entropy, possibly\ncorresponding to random sequences (high entropy) and sequences that posses\nhidden structure or function (low entropy).\n", "versions": [{"version": "v1", "created": "Mon, 24 Jan 2011 20:09:10 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Koslicki", "David", ""]]}, {"id": "1101.5008", "submitter": "Anne-Claire Haury", "authors": "Anne-Claire Haury (CBIO), Pierre Gestraud, Jean-Philippe Vert (CBIO)", "title": "The influence of feature selection methods on accuracy, stability and\n  interpretability of molecular signatures", "comments": null, "journal-ref": "PLoS ONE (2011) 6(12): e28210", "doi": "10.1371/journal.pone.0028210", "report-no": null, "categories": "q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Biomarker discovery from high-dimensional data is a crucial\nproblem with enormous applications in biology and medicine. It is also\nextremely challenging from a statistical viewpoint, but surprisingly few\nstudies have investigated the relative strengths and weaknesses of the plethora\nof existing feature selection methods. Methods: We compare 32 feature selection\nmethods on 4 public gene expression datasets for breast cancer prognosis, in\nterms of predictive performance, stability and functional interpretability of\nthe signatures they produce. Results: We observe that the feature selection\nmethod has a significant influence on the accuracy, stability and\ninterpretability of signatures. Simple filter methods generally outperform more\ncomplex embedded or wrapper methods, and ensemble feature selection has\ngenerally no positive effect. Overall a simple Student's t-test seems to\nprovide the best results. Availability: Code and data are publicly available at\nhttp://cbio.ensmp.fr/~ahaury/.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jan 2011 09:04:05 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2011 07:17:10 GMT"}], "update_date": "2012-09-17", "authors_parsed": [["Haury", "Anne-Claire", "", "CBIO"], ["Gestraud", "Pierre", "", "CBIO"], ["Vert", "Jean-Philippe", "", "CBIO"]]}, {"id": "1101.5087", "submitter": "Arnd Pralle", "authors": "Heng Huang and Arnd Pralle", "title": "Continuous monitoring of membrane protein micro-domain association\n  during cell signaling", "comments": "13 pages, 5 figures, currently being reviewed by journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph cond-mat.soft q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central to understanding membrane bound cell signaling is to quantify how the\nmembrane ultra-structure consisting of transient spatial domains modulates\nsignaling and how the signaling influences this ultra-structure. Yet, measuring\nthe association of membrane proteins with domains in living, intact cells poses\nconsiderable challenges. Here, we describe a non-destructive method to quantify\nprotein-lipid domain and protein cytoskeleton interactions in single, intact\ncells enabling continuous monitoring of the protein domains interaction over\ntime during signaling.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jan 2011 15:39:04 GMT"}], "update_date": "2011-01-27", "authors_parsed": [["Huang", "Heng", ""], ["Pralle", "Arnd", ""]]}, {"id": "1101.5091", "submitter": "Christian P. Robert", "authors": "Christian Robert (Universite Paris Dauphine), Jean-Michel Marin\n  (Universite de Montpellier 2) and Natesh S. Pillai (Harvard University)", "title": "Why approximate Bayesian computational (ABC) methods cannot handle model\n  choice problems", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian computation (ABC), also known as likelihood-free\nmethods, have become a favourite tool for the analysis of complex stochastic\nmodels, primarily in population genetics but also in financial analyses. We\nadvocated in Grelaud et al. (2009) the use of ABC for Bayesian model choice in\nthe specific case of Gibbs random fields (GRF), relying on a sufficiency\nproperty mainly enjoyed by GRFs to show that the approach was legitimate.\nDespite having previously suggested the use of ABC for model choice in a wider\nrange of models in the DIY ABC software (Cornuet et al., 2008), we present\ntheoretical evidence that the general use of ABC for model choice is fraught\nwith danger in the sense that no amount of computation, however large, can\nguarantee a proper approximation of the posterior probabilities of the models\nunder comparison.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jan 2011 15:51:55 GMT"}, {"version": "v2", "created": "Thu, 27 Jan 2011 06:32:36 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Robert", "Christian", "", "Universite Paris Dauphine"], ["Marin", "Jean-Michel", "", "Universite de Montpellier 2"], ["Pillai", "Natesh S.", "", "Harvard University"]]}, {"id": "1101.5244", "submitter": "Gerald Teschl", "authors": "Helin Koc, Julian King, Gerald Teschl, Karl Unterkofler, Susanne\n  Teschl, Pawel Mochalski, Hartmann Hinterhuber, and Anton Amann", "title": "The role of mathematical modeling in VOC analysis using isoprene as a\n  prototypic example", "comments": "17 pages", "journal-ref": "J. Breath Res. 5 (2011) 037102", "doi": "10.1088/1752-7155/5/3/037102", "report-no": null, "categories": "q-bio.QM physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isoprene is one of the most abundant endogenous volatile organic compounds\n(VOCs) contained in human breath and is considered to be a potentially useful\nbiomarker for diagnostic and monitoring purposes. However, neither the exact\nbiochemical origin of isoprene nor its physiological role are understood in\nsufficient depth, thus hindering the validation of breath isoprene tests in\nclinical routine.\n  Exhaled isoprene concentrations are reported to change under different\nclinical and physiological conditions, especially in response to enhanced\ncardiovascular and respiratory activity. Investigating isoprene exhalation\nkinetics under dynamical exercise helps to gather the relevant experimental\ninformation for understanding the gas exchange phenomena associated with this\nimportant VOC.\n  A first model for isoprene in exhaled breath has been developed by our\nresearch group. In the present paper, we aim at giving a concise overview of\nthis model and describe its role in providing supportive evidence for a\nperipheral (extrahepatic) source of isoprene. In this sense, the results\npresented here may enable a new perspective on the biochemical processes\ngoverning isoprene formation in the human body.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jan 2011 10:11:40 GMT"}, {"version": "v2", "created": "Mon, 28 Mar 2011 19:59:19 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Koc", "Helin", ""], ["King", "Julian", ""], ["Teschl", "Gerald", ""], ["Unterkofler", "Karl", ""], ["Teschl", "Susanne", ""], ["Mochalski", "Pawel", ""], ["Hinterhuber", "Hartmann", ""], ["Amann", "Anton", ""]]}, {"id": "1101.5376", "submitter": "Chris Thachuk", "authors": "Chris Thachuk", "title": "Succincter Text Indexing with Wildcards", "comments": "10 pages, 3 additional pages for supporting proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of indexing text with wildcard positions, motivated by\nthe challenge of aligning sequencing data to large genomes that contain\nmillions of single nucleotide polymorphisms (SNPs)---positions known to differ\nbetween individuals. SNPs modeled as wildcards can lead to more informed and\nbiologically relevant alignments. We improve the space complexity of previous\napproaches by giving a succinct index requiring $(2 + o(1))n \\log \\sigma + O(n)\n+ O(d \\log n) + O(k \\log k)$ bits for a text of length $n$ over an alphabet of\nsize $\\sigma$ containing $d$ groups of $k$ wildcards. A key to the space\nreduction is a result we give showing how any compressed suffix array can be\nsupplemented with auxiliary data structures occupying $O(n) + O(d \\log\n\\frac{n}{d})$ bits to also support efficient dictionary matching queries. The\nquery algorithm for our wildcard index is faster than previous approaches using\nreasonable working space. More importantly our new algorithm greatly reduces\nthe query working space to $O(d m + m \\log n)$ bits. We note that compared to\nprevious results this reduces the working space by two orders of magnitude when\naligning short read data to the Human genome.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jan 2011 20:09:34 GMT"}], "update_date": "2011-01-28", "authors_parsed": [["Thachuk", "Chris", ""]]}, {"id": "1101.5814", "submitter": "Jacopo Grilli", "authors": "Jacopo Grilli, Bruno Bassetti, Sergei Maslov and Marco Cosentino\n  Lagomarsino", "title": "Joint scaling laws in functional and evolutionary categories in\n  prokaryotic genomes", "comments": "39 pages, 21 figures", "journal-ref": "Nucleic Acids Research (2012) 40 (2): 530-540", "doi": "10.1093/nar/gkr711", "report-no": null, "categories": "q-bio.GN q-bio.MN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study a class-expansion/innovation/loss model of genome\nevolution taking into account biological roles of genes and their constituent\ndomains. In our model numbers of genes in different functional categories are\ncoupled to each other. For example, an increase in the number of metabolic\nenzymes in a genome is usually accompanied by addition of new transcription\nfactors regulating these enzymes. Such coupling can be thought of as a\nproportional \"recipe\" for genome composition of the type \"a spoonful of sugar\nfor each egg yolk\". The model jointly reproduces two known empirical laws: the\ndistribution of family sizes and the nonlinear scaling of the number of genes\nin certain functional categories (e.g. transcription factors) with genome size.\nIn addition, it allows us to derive a novel relation between the exponents\ncharacterising these two scaling laws, establishing a direct quantitative\nconnection between evolutionary and functional categories. It predicts that\nfunctional categories that grow faster-than-linearly with genome size to be\ncharacterised by flatter-than-average family size distributions. This relation\nis confirmed by our bioinformatics analysis of prokaryotic genomes. This proves\nthat the joint quantitative trends of functional and evolutionary classes can\nbe understood in terms of evolutionary growth with proportional recipes.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jan 2011 20:23:10 GMT"}, {"version": "v2", "created": "Tue, 8 Mar 2011 10:35:36 GMT"}, {"version": "v3", "created": "Tue, 9 Aug 2011 19:11:58 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Grilli", "Jacopo", ""], ["Bassetti", "Bruno", ""], ["Maslov", "Sergei", ""], ["Lagomarsino", "Marco Cosentino", ""]]}, {"id": "1101.6022", "submitter": "Anthony Coolen", "authors": "E.S. Roberts, A.C.C. Coolen, and T. Schlitt", "title": "Tailored graph ensembles as proxies or null models for real networks II:\n  results on directed graphs", "comments": "21 pages, 1 figure, submitted to J. Phys. A", "journal-ref": null, "doi": "10.1088/1751-8113/44/27/275002", "report-no": null, "categories": "q-bio.QM cond-mat.dis-nn cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generate new mathematical tools with which to quantify the macroscopic\ntopological structure of large directed networks. This is achieved via a\nstatistical mechanical analysis of constrained maximum entropy ensembles of\ndirected random graphs with prescribed joint distributions for in- and\noutdegrees and prescribed degree-degree correlation functions. We calculate\nexact and explicit formulae for the leading orders in the system size of the\nShannon entropies and complexities of these ensembles, and for\ninformation-theoretic distances. The results are applied to data on gene\nregulation networks.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jan 2011 17:03:18 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Roberts", "E. S.", ""], ["Coolen", "A. C. C.", ""], ["Schlitt", "T.", ""]]}]