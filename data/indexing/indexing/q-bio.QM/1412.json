[{"id": "1412.0207", "submitter": "Surojit Biswas", "authors": "Surojit Biswas, Meredith McDonald, Derek S. Lundberg, Jeffery L.\n  Dangl, Vladimir Jojic", "title": "Learning microbial interaction networks from metagenomic count data", "comments": "Submitted to RECOMB 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many microbes associate with higher eukaryotes and impact their vitality. In\norder to engineer microbiomes for host benefit, we must understand the rules of\ncommunity assembly and maintenence, which in large part, demands an\nunderstanding of the direct interactions between community members. Toward this\nend, we've developed a Poisson-multivariate normal hierarchical model to learn\ndirect interactions from the count-based output of standard metagenomics\nsequencing experiments. Our model controls for confounding predictors at the\nPoisson layer, and captures direct taxon-taxon interactions at the multivariate\nnormal layer using an $\\ell_1$ penalized precision matrix. We show in a\nsynthetic experiment that our method handily outperforms state-of-the-art\nmethods such as SparCC and the graphical lasso (glasso). In a real, in planta\nperturbation experiment of a nine member bacterial community, we show our\nmodel, but not SparCC or glasso, correctly resolves a direct interaction\nstructure among three community members that associate with Arabidopsis\nthaliana roots. We conclude that our method provides a structured, accurate,\nand distributionally reasonable way of modeling correlated count based random\nvariables and capturing direct interactions among them.\n", "versions": [{"version": "v1", "created": "Sun, 30 Nov 2014 11:19:59 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Biswas", "Surojit", ""], ["McDonald", "Meredith", ""], ["Lundberg", "Derek S.", ""], ["Dangl", "Jeffery L.", ""], ["Jojic", "Vladimir", ""]]}, {"id": "1412.0346", "submitter": "Tyas Fiantoro", "authors": "Tyas Pandu Fiantoro, Lussya Eveline", "title": "Single Channel Cutaneous Electrogastrography Parameters from Local White\n  Rabbit (Oryctolagus cuniculus)", "comments": "7 pages, 3 figures, typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EGG recordings performed on 13 local white rabbits (O. cuniculus) which\ndivided into 3 groups; acetosal 35 mg/kgBM receiver, reserpine 37.5 mg/kgBM\nreceiver, and control group. A total of 72 EGG recordings obtained from them,\nwhich divided furthermore into 9 datasets based on prepandrial state,\npostpandrial state, and post 1 hour drug administration state. EGG parameters\nsuch as the number of cycle per minute ($cpm$), average voltage of action\npotential segment ($\\bar{V_a}$), root mean square voltage of action potential\nsegment ($A_{rms}$), root mean square voltage of all EGG segment ($V_{rms}$),\naverage period of action potential segment ($\\bar{T_a}$), average period of\nresting plateau ($\\bar{T_i}$), average period difference among action potential\nsegment and resting plateau ($\\bar{T_a - T_i}$), and dominant frequency ($f_d$)\nare obtained. Insignificant difference of $f_d$ ($P$ = 0.9112993) and cpm ($P$\n= 0.9382463) among 9 EGG datasets were found. These findings contrasted the\ncommon practice of EGG assessment, which $f_d$ and $cpm$ are the main\nparameters for diagnosis base. In other hand, significant difference between 9\nEGG datasets found for $\\bar{V_a}$, $A_{rms}$, and $V_{rms}$ parameter with $P$\n= 0.0007346, 0.0039191, and 0.0000559 respectively. In conclusion, EGG\nparameterization should not be limited to $f_d$ and $cpm$ only.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 04:46:41 GMT"}, {"version": "v2", "created": "Fri, 5 Dec 2014 15:19:41 GMT"}, {"version": "v3", "created": "Mon, 8 Dec 2014 18:22:53 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Fiantoro", "Tyas Pandu", ""], ["Eveline", "Lussya", ""]]}, {"id": "1412.0488", "submitter": "Pavel Tomancak", "authors": "Tobias Pietzsch and Stephan Saalfeld and Stephan Preibisch and Pavel\n  Tomancak", "title": "BigDataViewer: Interactive Visualization and Image Processing for\n  Terabyte Data Sets", "comments": "38 pages, 1 main figure, 27 supplementary figures, under review at\n  Nature Methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasingly popular light sheet microscopy techniques generate very\nlarge 3D time-lapse recordings of living biological specimen. The necessity to\nmake large volumetric datasets available for interactive visualization and\nanalysis has been widely recognized. However, existing solutions build on\ndedicated servers to generate virtual slices that are transferred to the client\napplications, practically leading to insufficient frame rates (less than 10\nframes per second) for truly interactive experience. An easily accessible open\nsource solution for interactive arbitrary virtual re-slicing of very large\nvolumes and time series of volumes has yet been missing. We fill this gap with\nBigDataViewer, a Fiji plugin to interactively navigate and visualize large\nimage sequences from both local and remote data sources.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 14:24:44 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Pietzsch", "Tobias", ""], ["Saalfeld", "Stephan", ""], ["Preibisch", "Stephan", ""], ["Tomancak", "Pavel", ""]]}, {"id": "1412.0744", "submitter": "Artemy Kolchinsky", "authors": "Artemy Kolchinsky, An\\'alia Louren\\c{c}o, Heng-Yi Wu, Lang Li, Luis M.\n  Rocha", "title": "Extraction of Pharmacokinetic Evidence of Drug-drug Interactions from\n  the Literature", "comments": "PLOS One (2015)", "journal-ref": null, "doi": "10.1371/journal.pone.0122199", "report-no": null, "categories": "stat.ML cs.IR q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drug-drug interaction (DDI) is a major cause of morbidity and mortality and a\nsubject of intense scientific interest. Biomedical literature mining can aid\nDDI research by extracting evidence for large numbers of potential interactions\nfrom published literature and clinical databases. Though DDI is investigated in\ndomains ranging in scale from intracellular biochemistry to human populations,\nliterature mining has not been used to extract specific types of experimental\nevidence, which are reported differently for distinct experimental goals. We\nfocus on pharmacokinetic evidence for DDI, essential for identifying causal\nmechanisms of putative interactions and as input for further pharmacological\nand pharmaco-epidemiology investigations. We used manually curated corpora of\nPubMed abstracts and annotated sentences to evaluate the efficacy of literature\nmining on two tasks: first, identifying PubMed abstracts containing\npharmacokinetic evidence of DDIs; second, extracting sentences containing such\nevidence from abstracts. We implemented a text mining pipeline and evaluated it\nusing several linear classifiers and a variety of feature transforms. The most\nimportant textual features in the abstract and sentence classification tasks\nwere analyzed. We also investigated the performance benefits of using features\nderived from PubMed metadata fields, various publicly available named entity\nrecognizers, and pharmacokinetic dictionaries. Several classifiers performed\nvery well in distinguishing relevant and irrelevant abstracts (reaching\nF1~=0.93, MCC~=0.74, iAUC~=0.99) and sentences (F1~=0.76, MCC~=0.65,\niAUC~=0.83). We found that word bigram features were important for achieving\noptimal classifier performance and that features derived from Medical Subject\nHeadings (MeSH) terms significantly improved abstract classification. ...\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 00:01:39 GMT"}, {"version": "v2", "created": "Mon, 18 May 2015 16:45:42 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Kolchinsky", "Artemy", ""], ["Louren\u00e7o", "An\u00e1lia", ""], ["Wu", "Heng-Yi", ""], ["Li", "Lang", ""], ["Rocha", "Luis M.", ""]]}, {"id": "1412.1138", "submitter": "Ben Fulcher", "authors": "B. D. Fulcher, A. E. Georgieva, C. W. G. Redman, Nick S. Jones", "title": "Highly comparative fetal heart rate analysis", "comments": "7 pages, 4 figures", "journal-ref": "Fulcher, B. D., Georgieva, A., Redman, C. W., & Jones, N. S.\n  (2012). Highly comparative fetal heart rate analysis (pp. 3135-3138).\n  Presented at the 34th Annual International Conference of the IEEE EMBS, San\n  Diego, CA, USA", "doi": "10.1109/EMBC.2012.6346629", "report-no": null, "categories": "cs.LG cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A database of fetal heart rate (FHR) time series measured from 7221 patients\nduring labor is analyzed with the aim of learning the types of features of\nthese recordings that are informative of low cord pH. Our 'highly comparative'\nanalysis involves extracting over 9000 time-series analysis features from each\nFHR time series, including measures of autocorrelation, entropy, distribution,\nand various model fits. This diverse collection of features was developed in\nprevious work, and is publicly available. We describe five features that most\naccurately classify a balanced training set of 59 'low pH' and 59 'normal pH'\nFHR recordings. We then describe five of the features with the strongest linear\ncorrelation to cord pH across the full dataset of FHR time series. The features\nidentified in this work may be used as part of a system for guiding\nintervention during labor in future. This work successfully demonstrates the\nutility of comparing across a large, interdisciplinary literature on\ntime-series analysis to automatically contribute new scientific results for\nspecific biomedical signal processing challenges.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 00:00:42 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Fulcher", "B. D.", ""], ["Georgieva", "A. E.", ""], ["Redman", "C. W. G.", ""], ["Jones", "Nick S.", ""]]}, {"id": "1412.1390", "submitter": "Rosalind J Allen", "authors": "Philip Greulich, Matthew Scott, Martin R. Evans and Rosalind J. Allen", "title": "Growth-dependent bacterial susceptibility to ribosome-targeting\n  antibiotics", "comments": "26 pages, 7 figures", "journal-ref": "Molecular Systems Biology 11:796 (2015)", "doi": null, "report-no": null, "categories": "q-bio.CB q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bacterial growth environment strongly influences the efficacy of antibiotic\ntreatment, with slow growth often being associated with decreased\nsusceptibility. Yet in many cases the connection between antibiotic\nsusceptibility and pathogen physiology remains unclear. We show that for\nribosome-targeting antibiotics acting on Escherichia coli, a complex interplay\nexists between physiology and antibiotic action; for some antibiotics within\nthis class faster growth indeed increases susceptibility, but for other\nantibiotics the opposite is true. Remarkably, these observations can be\nexplained by a simple mathematical model that combines drug transport and\nbinding with physiological constraints. Our model reveals that growth-dependent\nsusceptibility is controlled by a single parameter characterizing the\n`reversibility' of antibiotic transport and binding. This parameter provides a\nspectrum-classification of antibiotic growth-dependent efficacy that appears to\ncorrespond at its extremes to existing binary classification schemes. In these\nlimits the model predicts universal, parameter-free limiting forms for growth\ninhibition curves. The model also leads to non-trivial predictions for the drug\nsusceptibility of a translation-mutant strain of E. coli, which we verify\nexperimentally. Drug action and bacterial metabolism are mechanistically\ncomplex; nevertheless this study illustrates how coarse-grained models can be\nused to integrate pathogen physiology into drug design and treatment\nstrategies.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 12:26:13 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Greulich", "Philip", ""], ["Scott", "Matthew", ""], ["Evans", "Martin R.", ""], ["Allen", "Rosalind J.", ""]]}, {"id": "1412.1449", "submitter": "Bernard Ycart", "authors": "Agn\\`es Hamon (LJK), Marie Tosolini (CRCT), Bernard Ycart (LJK), Pont\n  Fr\\'ed\\'eric (CRCT), Jean-Jacques Fourni\\'e (CRCT)", "title": "Simultaneous growth of two cancer cell lines evidences variability in\n  growth rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cancer cells co-cultured in vitro reveal unexpected differential growth rates\nthat classical exponential growth models cannot account for. Two\nnon-interacting cell lines were grown in the same culture, and counts of each\nspecies were recorded at periodic times. The relative growth of population\nratios was found to depend on the initial proportion, in contradiction with the\ntraditional exponential growth model. The proposed explanation is the\nvariability of growth rates for clones inside the same cell line. This leads to\na log-quadratic growth model that provides both a theoretical explanation to\nthe phenomenon that was observed, and a better fit to our growth data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2014 05:50:54 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Hamon", "Agn\u00e8s", "", "LJK"], ["Tosolini", "Marie", "", "CRCT"], ["Ycart", "Bernard", "", "LJK"], ["Fr\u00e9d\u00e9ric", "Pont", "", "CRCT"], ["Fourni\u00e9", "Jean-Jacques", "", "CRCT"]]}, {"id": "1412.1597", "submitter": "Iain Johnston", "authors": "Iain G. Johnston, Benjamin C. Rickett, Nick S. Jones", "title": "Explicit tracking of uncertainty increases the power of quantitative\n  rule-of-thumb reasoning in cell biology", "comments": "8 pages, 3 figures", "journal-ref": "Biophys. J. 107 2612 (2014)", "doi": "10.1016/j.bpj.2014.08.040", "report-no": null, "categories": "q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Back-of-the-envelope\" or \"rule-of-thumb\" calculations involving rough\nestimates of quantities play a central scientific role in developing intuition\nabout the structure and behaviour of physical systems, for example in so-called\n`Fermi problems' in the physical sciences. Such calculations can be used to\npowerfully and quantitatively reason about biological systems, particularly at\nthe interface between physics and biology. However, substantial uncertainties\nare often associated with values in cell biology, and performing calculations\nwithout taking this uncertainty into account may limit the extent to which\nresults can be interpreted for a given problem. We present a means to\nfacilitate such calculations where uncertainties are explicitly tracked through\nthe line of reasoning, and introduce a `probabilistic calculator' called\nCaladis, a web tool freely available at www.caladis.org, designed to perform\nthis tracking. This approach allows users to perform more statistically robust\ncalculations in cell biology despite having uncertain values, and to identify\nwhich quantities need to be measured more precisely in order to make confident\nstatements, facilitating efficient experimental design. We illustrate the use\nof our tool for tracking uncertainty in several example biological\ncalculations, showing that the results yield powerful and interpretable\nstatistics on the quantities of interest. We also demonstrate that the outcomes\nof calculations may differ from point estimates when uncertainty is accurately\ntracked. An integral link between Caladis and the Bionumbers repository of\nbiological quantities further facilitates the straightforward location,\nselection, and use of a wealth of experimental data in cell biological\ncalculations.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 09:29:48 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Johnston", "Iain G.", ""], ["Rickett", "Benjamin C.", ""], ["Jones", "Nick S.", ""]]}, {"id": "1412.1746", "submitter": "Momiao Xiong", "authors": "Lerong Li, Momiao Xiong", "title": "Dynamic Model for RNA-seq Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The newly developed deep-sequencing technologies make it possible to acquire\nboth quantitative and qualitative information regarding transcript biology. By\nmeasuring messenger RNA levels for all genes in a sample, RNA-seq provides an\nattractive option to characterize the global changes in transcription. RNA-seq\nis becoming the widely used platform for gene expression profiling. However,\nreal transcription signals in the RNA-seq data are confounded with measurement\nand sequencing errors, and other random biological/technical variation. How to\nappropriately take the variability due to errors and sequencing technology\nvariation into account is essential issue in the RNA-seq data analysis. To\nextract biologically useful transcription process from the RNA-seq data, we\npropose to use the second ODE for modeling the RNA-seq data. We use\ndifferential principal analysis to develop statistical methods for estimation\nof location-varying coefficients of the ODE. We validate the accuracy of the\nODE model to fit the RNA-seq data by prediction analysis and 5 fold cross\nvalidation. We find the accuracy of the second ODE model to predict the gene\nexpression level across the gene is very high and the second ODE model to fit\nthe RNA-seq data very well. To further evaluate the performance of the ODE\nmodel for RNA-seq data analysis, we used the location-varying coefficients of\nthe second ODE as features to classify the normal and tumor cells. We\ndemonstrate that even using the ODE model for single gene we can achieve high\nclassification accuracy. We also conduct response analysis to investigate how\nthe transcription process respond to the perturbation of the external signals\nand identify dozens of genes that are related to cancer.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 17:58:00 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Li", "Lerong", ""], ["Xiong", "Momiao", ""]]}, {"id": "1412.1759", "submitter": "Paulo Matias", "authors": "Paulo Matias, Jan Frans Willem Slaets, Reynaldo Daniel Pinto", "title": "Individual discrimination of freely swimming pulse-type electric fish\n  from electrode array recordings", "comments": "Preprint submitted to Elsevier", "journal-ref": null, "doi": "10.1016/j.neucom.2014.11.037", "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pulse-type weakly electric fishes communicate through electrical discharges\nwith a stereotyped waveform, varying solely the interval between pulses\naccording to the information being transmitted. This simple codification\nmechanism is similar to the one found in various known neuronal circuits, which\nrenders these animals as good models for the study of natural communication\nsystems, allowing experiments involving behavioral and neuroethological\naspects. Performing analysis of data collected from more than one freely\nswimming fish is a challenge since the detected electric organ discharge (EOD)\npatterns are dependent on each animal's position and orientation relative to\nthe electrodes. However, since each fish emits a characteristic EOD waveform,\ncomputational tools can be employed to match each EOD to the respective fish.\nIn this paper we describe a computational method able to recognize fish EODs\nfrom dyads using normalized feature vectors obtained by applying Fourier and\ndual-tree complex wavelet packet transforms. We employ support vector machines\nas classifiers, and a continuity constraint algorithm allows us to solve issues\ncaused by overlapping EODs and signal saturation. Extensive validation\nprocedures with Gymnotus sp. showed that EODs can be assigned correctly to each\nfish with only two errors per million discharges.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 18:41:23 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Matias", "Paulo", ""], ["Slaets", "Jan Frans Willem", ""], ["Pinto", "Reynaldo Daniel", ""]]}, {"id": "1412.1770", "submitter": "Kinshuk Mitra", "authors": "Kinshuk Mitra, Brett C. Geiger, Preethi Chidambaram, Aaron P. Maharry,\n  Ronald X. Xu, Michael F. Tweedle", "title": "Non-constrictive bead immobilization leading to decreased and uniform\n  shear stress in microfluidic bead-based ELISA", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph physics.flu-dyn q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microfluidic biosensors have been utilized for sensing a wide range of\nantigens using numerous configurations. Bead based microfluidic sensors have\nbeen a popular modality due to the plug and play nature of analyte choice and\nthe favorable geometry of spherical sensor scaffolds. While constriction of\nbeads against fluid flow remains a popular method to immobilize the sensor, it\nresults in poor fluidic regimes and shear conditions around sensor beads that\ncan affect sensor performance. We present an alternative means of sensor bead\nimmobilization using poly-carbonate membrane. This system results in several\norders of magnitude lower variance of flow radially around the sensor bead.\nShear stress experienced by our non-constrictive immobilized bead was three\norders of magnitude lower. We demonstrate ability to quantitatively sense EpCAM\nprotein, a marker for cancer stem cells and operation under both far-red and\ngreen wavelengths with no auto-fluorescence.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 17:30:35 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Mitra", "Kinshuk", ""], ["Geiger", "Brett C.", ""], ["Chidambaram", "Preethi", ""], ["Maharry", "Aaron P.", ""], ["Xu", "Ronald X.", ""], ["Tweedle", "Michael F.", ""]]}, {"id": "1412.1929", "submitter": "Sebastian B\\\"ocker", "authors": "Kai D\\\"uhrkop and Sebastian B\\\"ocker", "title": "Fragmentation trees reloaded", "comments": "different dataset", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metabolites, small molecules that are involved in cellular reactions, provide\na direct functional signature of cellular state. Untargeted metabolomics\nexperiments usually relies on tandem mass spectrometry to identify the\nthousands of compounds in a biological sample. Today, the vast majority of\nmetabolites remain unknown. Fragmentation trees have become a powerful tool for\nthe interpretation of tandem mass spectrometry data of small molecules. These\ntrees are found by combinatorial optimization, and aim at explaining the\nexperimental data via fragmentation cascades. To obtain biochemically\nmeaningful results requires an elaborate optimization function. We present a\nnew scoring for computing fragmentation trees, transforming the combinatorial\noptimization into a maximum a posteriori estimator. We demonstrate the\nsuperiority of the new scoring for two tasks: Both for the de novo\nidentification of molecular formulas of unknown compounds, and for searching a\ndatabase for structurally similar compounds, our methods performs significantly\nbetter than the previous scoring, as well as other methods for this task. Our\nmethod can expedite the workflow for untargeted metabolomics, allowing\nresearchers to investigate unknowns using automated computational methods.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 09:20:07 GMT"}, {"version": "v2", "created": "Mon, 15 Dec 2014 15:04:23 GMT"}, {"version": "v3", "created": "Wed, 28 Jan 2015 14:35:36 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["D\u00fchrkop", "Kai", ""], ["B\u00f6cker", "Sebastian", ""]]}, {"id": "1412.2153", "submitter": "Yannis Pantazis", "authors": "Georgios Arampatzis and Markos A. Katsoulakis and Yannis Pantazis", "title": "Accelerated Sensitivity Analysis in High-Dimensional Stochastic Reaction\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0130825", "report-no": null, "categories": "q-bio.MN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a two-step strategy for parametric sensitivity analysis for\nsuch systems is proposed, exploiting advantages and synergies between two\nrecently proposed sensitivity analysis methodologies for stochastic dynamics.\nThe first method performs sensitivity analysis of the stochastic dynamics by\nmeans of the Fisher Information Matrix on the underlying distribution of the\ntrajectories; the second method is a reduced-variance, finite-difference,\ngradient-type sensitivity approach relying on stochastic coupling techniques\nfor variance reduction. Here we demonstrate that these two methods can be\ncombined and deployed together by means of a new sensitivity bound which\nincorporates the variance of the quantity of interest as well as the Fisher\nInformation Matrix estimated from the first method. The first step of the\nproposed strategy labels sensitivities using the bound and screens out the\ninsensitive parameters in a controlled manner based also on the new sensitivity\nbound. In the second step of the proposed strategy, the finite-difference\nmethod is applied only for the sensitivity estimation of the (potentially)\nsensitive parameters that have not been screened out in the first step. Results\non an epidermal growth factor network with fifty parameters and on a protein\nhomeostasis with eighty parameters demonstrate that the proposed strategy is\nable to quickly discover and discard the insensitive parameters and in the\nremaining potentially sensitive parameters it accurately estimates the\nsensitivities. The new sensitivity strategy can be several times faster than\ncurrent state-of-the-art approaches that test all parameters, especially in\n\"sloppy\" systems. In particular, the computational acceleration is quantified\nby the ratio between the total number of parameters over the number of the\nsensitive parameters.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 15:40:06 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Arampatzis", "Georgios", ""], ["Katsoulakis", "Markos A.", ""], ["Pantazis", "Yannis", ""]]}, {"id": "1412.2587", "submitter": "Laurent Noe", "authors": "Laurent No\\'e (LIFL, INRIA Lille - Nord Europe), Donald E. K. Martin", "title": "A Coverage Criterion for Spaced Seeds and its Applications to Support\n  Vector Machine String Kernels and k-Mer Distances", "comments": "http://online.liebertpub.com/doi/abs/10.1089/cmb.2014.0173", "journal-ref": "Journal of Computational Biology, Mary Ann Liebert, 2014, 21 (12),\n  pp.28", "doi": "10.1089/cmb.2014.0173", "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spaced seeds have been recently shown to not only detect more alignments, but\nalso to give a more accurate measure of phylogenetic distances (Boden et al.,\n2013, Horwege et al., 2014, Leimeister et al., 2014), and to provide a lower\nmisclassification rate when used with Support Vector Machines (SVMs) (On-odera\nand Shibuya, 2013), We confirm by independent experiments these two results,\nand propose in this article to use a coverage criterion (Benson and Mak, 2008,\nMartin, 2013, Martin and No{\\'e}, 2014), to measure the seed efficiency in both\ncases in order to design better seed patterns. We show first how this coverage\ncriterion can be directly measured by a full automaton-based approach. We then\nillustrate how this criterion performs when compared with two other criteria\nfrequently used, namely the single-hit and multiple-hit criteria, through\ncorrelation coefficients with the correct classification/the true distance. At\nthe end, for alignment-free distances, we propose an extension by adopting the\ncoverage criterion, show how it performs, and indicate how it can be\nefficiently computed.\n", "versions": [{"version": "v1", "created": "Mon, 8 Dec 2014 14:43:56 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["No\u00e9", "Laurent", "", "LIFL, INRIA Lille - Nord Europe"], ["Martin", "Donald E. K.", ""]]}, {"id": "1412.2678", "submitter": "Tyas Fiantoro", "authors": "Tyas Pandu Fiantoro, Akhmad Kharis Nugroho", "title": "In-vitro iontophoresis of pinneal Sus scrofa skin and its transport flux\n  modelling as influenced by time and current density", "comments": "4 pages, 4 figures, infant version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study was to enhance the existing time dependent flux\nmodel for the transdermal iontophoretic transport of drugs. This study\nevaluated the flux data as influenced by time and current density. In vitro\niontophoresis performed on the piglet (Sus scrofa) necropsy-taken medial scapha\npinneal skin that mounted in the U shaped sink chamber. Iontophoresis of\natenolol with a constant dose of 1000 ppm was implemented for 3 hours with\nacceptor phase sampling every 30 minutes. Data were analised based on\nexponential fitting of each current density value to produce a current density\ndependent flux model. This model then combined with the time differential model\nof flux to produce a flux model that takes account of both current density and\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 8 Dec 2014 17:47:01 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Fiantoro", "Tyas Pandu", ""], ["Nugroho", "Akhmad Kharis", ""]]}, {"id": "1412.2788", "submitter": "Brian Williams Dr", "authors": "Brian G. Williams", "title": "Fitting and projecting HIV epidemics: Data, structure and parsimony", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding historical trends in the epidemic of HIV is important for\nassessing current and projecting future trends in prevalence, incidence and\nmortality and for evaluating the impact and cost-effectiveness of control\nmeasures. In generalized epidemics the available data are of variable quality\namong countries and limited mainly to trends in the prevalence of HIV among\nwomen attending ante-natal clinics. In concentrated epidemics one needs, at the\nvery least, time trends in the prevalence of HIV among different risk groups,\nincluding intravenous drug users, men-who-have-sex-with-men, and commercial sex\nworkers as well as the size of each group and the degree of overlap between\nthem. Here we focus on the comparatively straight forward problems presented by\ngeneralized epidemics. We fit data from Kenya to a susceptible-infected model\nand then successively add structure to the model, drawing on our knowledge of\nthe natural history of HIV, to explore the effect that different structural\naspects of the model have on the fits and the projections.\n  Both heterogeneity in risk and changes in behaviour over time are important\nbut easily confounded. Using a Weibull rather than exponential survival\nfunction for people infected with HIV, in the absence of treatment, makes a\nsignificant difference to the estimated trends in incidence and mortality and\nto the projected trends. Allowing for population growth has a small effect on\nthe fits and the projections but is easy to include. Including details of the\ndemography adds substantially to the complexity of the model, increases the run\ntime by several orders of magnitude, but changes the fits and projections only\nslightly and to an extent that is less than the uncertainty inherent in the\ndata. We make specific recommendations for the kind of model that would be\nsuitable for understanding and managing HIV epidemics in east and southern\nAfrica.\n", "versions": [{"version": "v1", "created": "Sat, 22 Nov 2014 20:55:59 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Williams", "Brian G.", ""]]}, {"id": "1412.3050", "submitter": "Panagiotis Papastamoulis", "authors": "Panagiotis Papastamoulis and Magnus Rattray", "title": "A Bayesian model selection approach for identifying differentially\n  expressed transcripts from RNA-Seq data", "comments": "Revised version of arXiv:1412.3050v3", "journal-ref": "Journal of the Royal Statistical Society: Series C (Applied\n  Statistics), 2017", "doi": "10.1111/rssc.12213", "report-no": null, "categories": "stat.ME q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in molecular biology allow the quantification of the\ntranscriptome and scoring transcripts as differentially or equally expressed\nbetween two biological conditions. Although these two tasks are closely linked,\nthe available inference methods treat them separately: a primary model is used\nto estimate expression and its output is post-processed using a differential\nexpression model. In this paper, both issues are simultaneously addressed by\nproposing the joint estimation of expression levels and differential\nexpression: the unknown relative abundance of each transcript can either be\nequal or not between two conditions. A hierarchical Bayesian model builds upon\nthe BitSeq framework and the posterior distribution of transcript expression\nand differential expression is inferred using Markov Chain Monte Carlo (MCMC).\nIt is shown that the proposed model enjoys conjugacy for fixed dimension\nvariables, thus the full conditional distributions are analytically derived.\nTwo samplers are constructed, a reversible jump MCMC sampler and a collapsed\nGibbs sampler, and the latter is found to perform best. A cluster\nrepresentation of the aligned reads to the transcriptome is introduced,\nallowing parallel estimation of the marginal posterior distribution of subsets\nof transcripts under reasonable computing time. The proposed algorithm is\nbenchmarked against alternative methods using synthetic datasets and applied to\nreal RNA-sequencing data. Source code is available online\n(https://github.com/mqbssppe/cjBitSeq).\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 18:42:22 GMT"}, {"version": "v2", "created": "Fri, 12 Jun 2015 07:10:28 GMT"}, {"version": "v3", "created": "Sat, 17 Oct 2015 08:07:21 GMT"}, {"version": "v4", "created": "Mon, 26 Sep 2016 10:32:45 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Papastamoulis", "Panagiotis", ""], ["Rattray", "Magnus", ""]]}, {"id": "1412.3051", "submitter": "Edward Meeds", "authors": "Edward Meeds and Michael Chiang and Mary Lee and Olivier Cinquin and\n  John Lowengrub and Max Welling", "title": "POPE: Post Optimization Posterior Evaluation of Likelihood Free Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many domains, scientists build complex simulators of natural phenomena\nthat encode their hypotheses about the underlying processes. These simulators\ncan be deterministic or stochastic, fast or slow, constrained or unconstrained,\nand so on. Optimizing the simulators with respect to a set of parameter values\nis common practice, resulting in a single parameter setting that minimizes an\nobjective subject to constraints. We propose a post optimization posterior\nanalysis that computes and visualizes all the models that can generate equally\ngood or better simulation results, subject to constraints. These optimization\nposteriors are desirable for a number of reasons among which easy\ninterpretability, automatic parameter sensitivity and correlation analysis and\nposterior predictive analysis. We develop a new sampling framework based on\napproximate Bayesian computation (ABC) with one-sided kernels. In collaboration\nwith two groups of scientists we applied POPE to two important biological\nsimulators: a fast and stochastic simulator of stem-cell cycling and a slow and\ndeterministic simulator of tumor growth patterns.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 18:51:07 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Meeds", "Edward", ""], ["Chiang", "Michael", ""], ["Lee", "Mary", ""], ["Cinquin", "Olivier", ""], ["Lowengrub", "John", ""], ["Welling", "Max", ""]]}, {"id": "1412.3800", "submitter": "Lior Pachter", "authors": "Akshay Tambe, Jennifer Doudna and Lior Pachter", "title": "Identifying RNA contacts from SHAPE-MaP by partial correlation analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper Siegfried et al. published a new sequence-based structural\nRNA assay that utilizes mutational profiling to detect base pairing (MaP).\nOutput from MaP provides information about both pairing (via reactivities) and\ncontact (via correlations). Reactivities can be coupled to partition function\nfolding models for structural inference, while correlations can reveal pairs of\nsites that may be in structural proximity. The possibility for inference of 3D\ncontacts via MaP suggests a novel approach to structural prediction for RNA\nanalogous to covariance structural prediction for proteins. We explore this\napproach and show that partial correlation analysis outperforms na\\\"ive\ncorrelation analysis. Our results should be applicable to a wide range of\nhigh-throughput sequencing based RNA structural assays that are under\ndevelopment.\n", "versions": [{"version": "v1", "created": "Mon, 8 Dec 2014 19:04:51 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Tambe", "Akshay", ""], ["Doudna", "Jennifer", ""], ["Pachter", "Lior", ""]]}, {"id": "1412.4069", "submitter": "Christopher Lester", "authors": "Christopher Lester, Ruth E. Baker, Michael B. Giles, Christian A.\n  Yates", "title": "Extending the multi-level method for the simulation of stochastic\n  biological systems", "comments": "38 pages", "journal-ref": null, "doi": "10.1007/s11538-016-0178-9", "report-no": null, "categories": "q-bio.QM q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multi-level method for discrete state systems, first introduced by\nAnderson and Higham [Multiscale Model. Simul. 10:146--179, 2012], is a highly\nefficient simulation technique that can be used to elucidate statistical\ncharacteristics of biochemical reaction networks. A single point estimator is\nproduced in a cost-effective manner by combining a number of estimators of\ndiffering accuracy in a telescoping sum, and, as such, the method has the\npotential to revolutionise the field of stochastic simulation. The first term\nin the sum is calculated using an approximate simulation algorithm, and can be\ncalculated quickly but is of significant bias. Subsequent terms successively\ncorrect this bias by combining estimators from approximate stochastic\nsimulations algorithms of increasing accuracy, until a desired level of\naccuracy is reached.\n  In this paper we present several refinements of the multi-level method which\nrender it easier to understand and implement, and also more efficient. Given\nthe substantial and complex nature of the multi-level method, the first part of\nthis work (Sections 2 - 5) is written as a tutorial, with the aim of providing\na practical guide to its use. The second part (Sections 6 - 8) takes on a form\nakin to a research article, thereby providing the means for a deft\nimplementation of the technique, and concludes with a discussion of a number of\nopen problems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 17:54:10 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2015 18:13:55 GMT"}, {"version": "v3", "created": "Thu, 19 May 2016 19:25:54 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Lester", "Christopher", ""], ["Baker", "Ruth E.", ""], ["Giles", "Michael B.", ""], ["Yates", "Christian A.", ""]]}, {"id": "1412.4416", "submitter": "Amir Toor", "authors": "Amir A. Toor, Roy T. Sabo, Catherine H. Roberts, Bonny L. Moore,\n  Salman R. Salman, Allison F. Scalora, May T. Aziz, Ali S. Shubar Ali, Charles\n  E. Hall, Jeremy Meier, Radhika M. Thorn, Elaine Wang, Shiyu Song, Kristin\n  Miller, Kathryn Rizzo, William B. Clark, John M. McCarty, Harold M. Chung,\n  Masoud H. Manjili and Michael C. Neale", "title": "Dynamical System Modeling Of Immune Reconstitution Following Allogeneic\n  Stem Cell Transplantation Identifies Patients At Risk For Adverse Outcomes", "comments": "17 pages, 4 tables, 4 Figures, 4 Supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems that evolve over time and follow mathematical laws as they do so, are\ncalled dynamical systems. Lymphocyte recovery and clinical outcomes in 41\nallograft recipients conditioned using anti-thymocyte globulin (ATG) and 4.5\nGray total-body-irradiation were studied to determine if immune reconstitution\ncould be described as a dynamical system. Survival, relapse, and graft vs. host\ndisease (GVHD) were not significantly different in two cohorts of patients\nreceiving different doses of ATG. However, donor-derived CD3+ (ddCD3) cell\nreconstitution was superior in the lower ATG dose cohort, and there were fewer\ninstances of donor lymphocyte infusion (DLI). Lymphoid recovery was plotted in\neach individual over time and demonstrated one of three sigmoid growth\npatterns; Pattern A (n=15), had rapid growth with high lymphocyte counts,\npattern B (n=14), slower growth with intermediate recovery and pattern C, poor\nlymphocyte reconstitution (n=10). There was a significant association between\nlymphocyte recovery patterns and both the rate of change of ddCD3 at day 30\npost-SCT and the clinical outcomes. GVHD was observed more frequently with\npattern A; relapse and DLI more so with pattern C, with a consequent survival\nadvantage in patients with patterns A and B. We conclude that evaluating immune\nreconstitution following SCT as a dynamical system may differentiate patients\nat risk of adverse outcomes and allow early intervention to modulate that risk.\n", "versions": [{"version": "v1", "created": "Sun, 14 Dec 2014 21:57:21 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Toor", "Amir A.", ""], ["Sabo", "Roy T.", ""], ["Roberts", "Catherine H.", ""], ["Moore", "Bonny L.", ""], ["Salman", "Salman R.", ""], ["Scalora", "Allison F.", ""], ["Aziz", "May T.", ""], ["Ali", "Ali S. Shubar", ""], ["Hall", "Charles E.", ""], ["Meier", "Jeremy", ""], ["Thorn", "Radhika M.", ""], ["Wang", "Elaine", ""], ["Song", "Shiyu", ""], ["Miller", "Kristin", ""], ["Rizzo", "Kathryn", ""], ["Clark", "William B.", ""], ["McCarty", "John M.", ""], ["Chung", "Harold M.", ""], ["Manjili", "Masoud H.", ""], ["Neale", "Michael C.", ""]]}, {"id": "1412.5454", "submitter": "Md Shamsuzzoha Bayzid", "authors": "Md. Shamsuzzoha Bayzid, Siavash Mirarab, Bastien Boussau, Tandy Warnow", "title": "Weighted Statistical Binning: enabling statistically consistent\n  genome-scale phylogenetic analyses", "comments": "(1) In Press, PLoS ONE", "journal-ref": null, "doi": "10.1371/journal.pone.0129183", "report-no": null, "categories": "q-bio.QM q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because biological processes can make different loci have different\nevolutionary histories, species tree estimation requires multiple loci from\nacross the genome. While many processes can result in discord between gene\ntrees and species trees, incomplete lineage sorting (ILS), modeled by the\nmulti-species coalescent, is considered to be a dominant cause for gene tree\nheterogeneity. Coalescent-based methods have been developed to estimate species\ntrees, many of which operate by combining estimated gene trees, and so are\ncalled summary methods. Because summary methods are generally fast, they have\nbecome very popular techniques for estimating species trees from multiple loci.\nHowever, recent studies have established that summary methods can have reduced\naccuracy in the presence of gene tree estimation error, and also that many\nbiological datasets have substantial gene tree estimation error, so that\nsummary methods may not be highly accurate on biologically realistic\nconditions. Mirarab et al. (Science 2014) presented the statistical binning\ntechnique to improve gene tree estimation in multi-locus analyses, and showed\nthat it improved the accuracy of MP-EST, one of the most popular\ncoalescent-based summary methods. Statistical binning, which uses a simple\nstatistical test for combinability and then uses the larger sets of genes to\nre-calculate gene trees, has good empirical performance, but using statistical\nbinning within a phylogenomics pipeline does not have the desirable property of\nbeing statistically consistent. We show that weighting the recalculated gene\ntrees by the bin sizes makes statistical binning statistically consistent under\nthe multispecies coalescent, and maintains the good empirical performance.\nThus, \"weighted statistical binning\" enables highly accurate genome-scale\nspecies tree estimation, and is also statistical consistent under the\nmulti-species coalescent model.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 16:02:17 GMT"}, {"version": "v2", "created": "Fri, 9 Jan 2015 14:45:22 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2015 21:10:06 GMT"}, {"version": "v4", "created": "Wed, 3 Jun 2015 19:36:03 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Bayzid", "Md. Shamsuzzoha", ""], ["Mirarab", "Siavash", ""], ["Boussau", "Bastien", ""], ["Warnow", "Tandy", ""]]}, {"id": "1412.5459", "submitter": "Mariam Kiran Dr.", "authors": "Mariam Kiran and Wei Liu", "title": "Converting a Systems Dynamic Model to an Agent-based model for studying\n  the Bicoid morphogen gradient in Drosophila embryo", "comments": "21 pages, 13 figures, technical report, exploratory study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CE q-bio.QM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The concentration gradient of the Bicoid morphogen, which is established\nduring the early stages of a Drosophila melanogaster embryonic development,\ndetermines the differential spatial patterns of gene expression and subsequent\ncell fate determination. This is mainly achieved by diffusion elicited by the\ndifferent concentrations of the Bicoid protein in the embryo. Such chemical\ndynamic progress can be simulated by stochastic models, particularly the\nGillespie alogrithm. However, as with various modelling approaches in biology,\neach technique involves drawing assumptions and reducing the model complexity\nsometimes limiting the model capability. This is mainly due to the complexity\nof the software modelling approaches to construct these models. Agent-based\nmodelling is a technique which is becoming increasingly popular for modelling\nthe behaviour of individual molecules or cells in computational biology.\n  This paper attempts to compare these two popular modelling techniques of\nstochastic and agent-based modelling to show how the model can be studied in\ndetail using the different approaches. This paper presents how to use these\ntechniques with the advantages and disadvantages of using either of these.\nThrough various comparisons, such as computation complexity and results\nobtained, we show that although the same model is implemented, both approaches\ncan give varying results. The results of the paper show that the stochastic\nmodel is able to give smoother results compared to the agent-based model which\nmay need further analysis at a later stage. We discuss the reasons for these\nresults and how these could be rectified in systems biology research.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 16:14:55 GMT"}], "update_date": "2014-12-18", "authors_parsed": [["Kiran", "Mariam", ""], ["Liu", "Wei", ""]]}, {"id": "1412.5627", "submitter": "Fabricio Martins Lopes", "authors": "Bruno Mendes Moro Conque and Andr\\'e Yoshiaki Kashiwabara and\n  Fabr\\'icio Martins Lopes", "title": "Feature extraction from complex networks: A case of study in genomic\n  sequences classification", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new approach for classification of genomic sequences\nfrom measurements of complex networks and information theory. For this, it is\nconsidered the nucleotides, dinucleotides and trinucleotides of a genomic\nsequence. For each of them, the entropy, sum entropy and maximum entropy values\nare calculated.For each of them is also generated a network, in which the nodes\nare the nucleotides, dinucleotides or trinucleotides and its edges are\nestimated by observing the respective adjacency among them in the genomic\nsequence. In this way, it is generated three networks, for which measures of\ncomplex networks are extracted.These measures together with measures of\ninformation theory comprise a feature vector representing a genomic sequence.\nThus, the feature vector is used for classification by methods such as SVM,\nMultiLayer Perceptron, J48, IBK, Naive Bayes and Random Forest in order to\nevaluate the proposed approach.It was adopted coding sequences, intergenic\nsequences and TSS (Transcriptional Starter Sites) as datasets, for which the\nbetter results were obtained by the Random Forest with 91.2%, followed by J48\nwith 89.1% and SVM with 84.8% of accuracy. These results indicate that the new\napproach of feature extraction has its value, reaching good levels of\nclassification even considering only the genomic sequences, i.e., no other a\npriori knowledge about them is considered.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 21:31:51 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Conque", "Bruno Mendes Moro", ""], ["Kashiwabara", "Andr\u00e9 Yoshiaki", ""], ["Lopes", "Fabr\u00edcio Martins", ""]]}, {"id": "1412.5693", "submitter": "Yougan Cheng", "authors": "Daniela Calvetti, Yougan Cheng, Erkki Somersalo", "title": "Energy Demand and Metabolite Partitioning in Spatially Lumped and\n  Distributed Models of Neuron-Astrocyte Complex", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.DS q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The degrees of freedom of multi-compartment mathematical models for energy\nmetabolism of a neuron-astrocyte complex may offer a key to understand the\ndifferent ways in which the energetic needs of the brain are met. In this paper\nwe address the problem within a steady state framework and we use the\ntechniques of linear algebra to identify the degrees of freedom first in a\nlumped model, then in its extension to a spatially distributed case. The\ninterpretation of the degrees of freedom in metabolic terms, more specifically\nin terms of glucose and oxygen partitioning, is then leveraged to derive\nconstraints on the free parameters needed to guarantee that the model is\nenergetically feasible. We also demonstrate how the model can be used to\nestimate the stoichiometric energy needs of the cells as well as the household\nenergy based on observed oxidative cerebral metabolic rate (CMR) of glucose,\nand the glutamate cycling. Moreover, our analysis shows that in the lumped\nmodel the direction of lactate dehydrogenase (LDH) in the cells can be deduced\nfrom the glucose partitioning between the compartments. The extension of the\nlumped model into a spatially distributed multi-compartment setting that\nincludes diffusion fluxes from capillary to tissue increases the number of\ndegrees of freedom, requiring the use of statistical sampling techniques. The\nanalysis of distributed model reveals that some of the conclusions, e.g.,\nconcerning the LDH activity and glucose partitioning, based on a spatially\nlumped model may no longer hold.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 01:04:39 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Calvetti", "Daniela", ""], ["Cheng", "Yougan", ""], ["Somersalo", "Erkki", ""]]}, {"id": "1412.5755", "submitter": "Simon Cotter", "authors": "Simon Cotter and Radek Erban", "title": "Error Analysis of Diffusion Approximation Methods for Multiscale Systems\n  in Reaction Kinetics", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA physics.chem-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several different methods exist for efficient approximation of paths in\nmultiscale stochastic chemical systems. Another approach is to use bursts of\nstochastic simulation to estimate the parameters of a stochastic differential\nequation approximation of the paths. In this paper, multiscale methods for\napproximating paths are used to formulate different strategies for estimating\nthe dynamics by diffusion processes. We then analyse how efficient and accurate\nthese methods are in a range of different scenarios, and compare their\nrespective advantages and disadvantages to other methods proposed to analyse\nmultiscale chemical networks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 08:37:18 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Cotter", "Simon", ""], ["Erban", "Radek", ""]]}, {"id": "1412.5932", "submitter": "Guillaume Rizk", "authors": "Ga\\\"etan Benoit, Claire Lemaitre, Dominique Lavenier and Guillaume\n  Rizk", "title": "Compression of high throughput sequencing data with probabilistic de\n  Bruijn graph", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Data volumes generated by next-generation sequencing technolo-\ngies is now a major concern, both for storage and transmission. This triggered\nthe need for more efficient methods than general purpose compression tools,\nsuch as the widely used gzip. Most reference-free tools developed for NGS data\ncompression still use general text compression methods and fail to benefit from\nalgorithms already designed specifically for the analysis of NGS data. The goal\nof our new method Leon is to achieve compression of DNA sequences of high\nthroughput sequencing data, without the need of a reference genome, with\ntechniques derived from existing assembly principles, that possibly better\nexploit NGS data redundancy. Results: We propose a novel method, implemented in\nthe software Leon, for compression of DNA sequences issued from high throughput\nsequencing technologies. This is a lossless method that does not need a\nreference genome. Instead, a reference is built de novo from the set of reads\nas a probabilistic de Bruijn Graph, stored in a Bloom filter. Each read is\nencoded as a path in this graph, storing only an anchoring kmer and a list of\nbifurcations indicating which path to follow in the graph. This new method will\nallow to have compressed read files that also already contain its underlying de\nBruijn Graph, thus directly re-usable by many tools relying on this structure.\nLeon achieved encoding of a C. elegans reads set with 0.7 bits/base,\noutperforming state of the art reference-free methods. Availability: Open\nsource, under GNU affero GPL License, available for download at\nhttp://gatb.inria.fr/software/leon/\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 16:37:12 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Benoit", "Ga\u00ebtan", ""], ["Lemaitre", "Claire", ""], ["Lavenier", "Dominique", ""], ["Rizk", "Guillaume", ""]]}, {"id": "1412.5995", "submitter": "Panagiotis Papastamoulis", "authors": "James Hensman, Panagiotis Papastamoulis, Peter Glaus, Antti Honkela\n  and Magnus Rattray", "title": "Fast and accurate approximate inference of transcript expression from\n  RNA-seq data", "comments": "Main changes: (a) shuffling of reads simulated from spanki and repeat\n  the analysis for sailfish and eXpress. Now both methods yield better point\n  estimates. (b) including the Markov chain Monte Carlo sampler of rsem\n  (RSEM-PME). (c) including the Kallisto method (d) adding alternative measures\n  of transcript expression (TPM) and filtering out low expressed transcripts\n  (supplementary material). arXiv admin note: substantial text overlap with\n  arXiv:1308.5953", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Assigning RNA-seq reads to their transcript of origin is a\nfundamental task in transcript expression estimation. Where ambiguities in\nassignments exist due to transcripts sharing sequence, e.g. alternative\nisoforms or alleles, the problem can be solved through probabilistic inference.\nBayesian methods have been shown to provide accurate transcript abundance\nestimates compared to competing methods. However, exact Bayesian inference is\nintractable and approximate methods such as Markov chain Monte Carlo (MCMC) and\nVariational Bayes (VB) are typically used. While providing a high degree of\naccuracy and modelling flexibility, standard implementations can be\nprohibitively slow for large datasets and complex transcriptome annotations.\n  Results: We propose a novel approximate inference scheme based on VB and\napply it to an existing model of transcript expression inference from RNA-seq\ndata. Recent advances in VB algorithmics are used to improve the convergence of\nthe algorithm beyond the standard Variational Bayes Expectation Maximisation\n(VBEM) algorithm. We apply our algorithm to simulated and biological datasets,\ndemonstrating a significant increase in speed with only very small loss in\naccuracy of expression level estimation. We carry out a comparative study\nagainst seven popular alternative methods and demonstrate that our new\nalgorithm provides excellent accuracy and inter-replicate consistency while\nremaining competitive in computation time.\n  Availability: The methods were implemented in R and C++, and are available as\npart of the BitSeq project at \\url{https://github.com/BitSeq}. The method is\nalso available through the BitSeq Bioconductor package. The source code to\nreproduce all simulation results can be accessed via\n\\url{https://github.com/BitSeq/BitSeqVB_benchmarking}.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 18:48:48 GMT"}, {"version": "v2", "created": "Tue, 27 Jan 2015 09:55:43 GMT"}, {"version": "v3", "created": "Tue, 30 Jun 2015 13:13:09 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Hensman", "James", ""], ["Papastamoulis", "Panagiotis", ""], ["Glaus", "Peter", ""], ["Honkela", "Antti", ""], ["Rattray", "Magnus", ""]]}, {"id": "1412.6068", "submitter": "Christina Schenk", "authors": "Alfio Borz\\`i, Juri Merger, Jonas M\\\"uller, Achim Rosch, Christina\n  Schenk, Dominik Schmidt, Stephan Schmidt, Volker Schulz, Kai Velten,\n  Christian von Wallbrunn and Michael Z\\\"anglein", "title": "Novel model for wine fermentation including the yeast dying phase", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel model for wine fermentation including a death\nphase for yeast and the influence of oxygen on the process. A model for the\ninclusion of the yeast dying phase is derived and compared to a model taken\nfrom the literature. The modeling ability of the several models is analyzed by\ncomparing their simulation results.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 15:58:24 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Borz\u00ec", "Alfio", ""], ["Merger", "Juri", ""], ["M\u00fcller", "Jonas", ""], ["Rosch", "Achim", ""], ["Schenk", "Christina", ""], ["Schmidt", "Dominik", ""], ["Schmidt", "Stephan", ""], ["Schulz", "Volker", ""], ["Velten", "Kai", ""], ["von Wallbrunn", "Christian", ""], ["Z\u00e4nglein", "Michael", ""]]}, {"id": "1412.6399", "submitter": "Pierre de Buyl", "authors": "Jamie A. Dean, Liam C. Welsh, Kevin J. Harrington, Christopher M.\n  Nutting, Sarah L. Gulliford", "title": "Predictive Modelling of Toxicity Resulting from Radiotherapy Treatments\n  of Head and Neck Cancer", "comments": "Part of the Proceedings of the 7th European Conference on Python in\n  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)", "journal-ref": null, "doi": null, "report-no": "euroscipy-proceedings2014-09", "categories": "physics.med-ph cs.CE q-bio.QM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In radiotherapy for head and neck cancer, the radiation dose delivered to the\npharyngeal mucosa (mucosal lining of the throat) is thought to be a major\ncontributing factor to dysphagia (swallowing dysfunction), the most commonly\nreported severe toxicity. There is a variation in the severity of dysphagia\nexperienced by patients. Understanding the role of the dose distribution in\ndysphagia would allow improvements in the radiotherapy technique to be\nexplored. The 3D dose distributions delivered to the pharyngeal mucosa of 249\npatients treated as part of clinical trials were reconstructed. Pydicom was\nused to extract DICOM (digital imaging and communications in medicine) data\n(the standard file formats for medical imaging and radiotherapy data). NumPy\nand SciPy were used to manipulate the data to generate 3D maps of the dose\ndistribution delivered to the pharyngeal mucosa and calculate metrics\ndescribing the dose distribution. Multivariate predictive modelling of severe\ndysphagia, including descriptions of the dose distribution and relevant\nclinical factors, was performed using Pandas and SciKit-Learn. Matplotlib and\nMayavi were used for 2D and 3D data visualisation. A support vector\nclassification model, with feature selection using randomised logistic\nregression, to predict radiation-induced severe dysphagia, was trained. When\nthis model was independently validated, the area under the receiver operating\ncharacteristic curve was 0.54. The model has poor predictive power and work is\nongoing to improve the model through alternative feature engineering and\nstatistical modelling approaches.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 15:54:51 GMT"}], "update_date": "2014-12-22", "authors_parsed": [["Dean", "Jamie A.", ""], ["Welsh", "Liam C.", ""], ["Harrington", "Kevin J.", ""], ["Nutting", "Christopher M.", ""], ["Gulliford", "Sarah L.", ""]]}, {"id": "1412.6430", "submitter": "Chad M. Topaz", "authors": "Chad M. Topaz, Lori Ziegelmeier, Tom Halverson", "title": "Topological Data Analysis of Biological Aggregation Models", "comments": "25 pages, 12 figures; second version contains typo corrections, minor\n  textual additions, and a brief discussion of computational complexity; third\n  version fixes one typo and adds small paragraph about topological stability", "journal-ref": null, "doi": "10.1371/journal.pone.0126383", "report-no": null, "categories": "q-bio.QM math.AT nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply tools from topological data analysis to two mathematical models\ninspired by biological aggregations such as bird flocks, fish schools, and\ninsect swarms. Our data consists of numerical simulation output from the models\nof Vicsek and D'Orsogna. These models are dynamical systems describing the\nmovement of agents who interact via alignment, attraction, and/or repulsion.\nEach simulation time frame is a point cloud in position-velocity space. We\nanalyze the topological structure of these point clouds, interpreting the\npersistent homology by calculating the first few Betti numbers. These Betti\nnumbers count connected components, topological circles, and trapped volumes\npresent in the data. To interpret our results, we introduce a visualization\nthat displays Betti numbers over simulation time and topological persistence\nscale. We compare our topological results to order parameters typically used to\nquantify the global behavior of aggregations, such as polarization and angular\nmomentum. The topological calculations reveal events and structure not captured\nby the order parameters.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 16:44:03 GMT"}, {"version": "v2", "created": "Fri, 13 Feb 2015 19:29:09 GMT"}, {"version": "v3", "created": "Wed, 11 Mar 2015 16:54:37 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Topaz", "Chad M.", ""], ["Ziegelmeier", "Lori", ""], ["Halverson", "Tom", ""]]}, {"id": "1412.6566", "submitter": "James Moore", "authors": "James R. Moore and Fred Adler", "title": "Mathematical modeling of type 1 diabetes in the NOD mouse: separating\n  incidence and age of onset", "comments": "29 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.TO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Type 1 diabetes (T1D) is an autoimmune disease of the beta cells of the\npancreas. The nonobese diabetic (NOD) mouse is a commonly used animal model,\nwith roughly an 80% incidence rate of T1D among females. In 100% of NOD mice,\nmacrophages and T-cells invade the islets in a process called insulitis. It can\nbe several weeks between insulitis and T1D, and some mice do not progress at\nall. It is thought that this delay is mediated by regulatory T-cells (Tregs)\nand that a gradual loss of effectiveness in this population leads to T1D.\nHowever, this does not explain why some mice progress and others do not. We\npropose a simple mathematical model of the interaction between beta cells and\nthe immune populations, including regulatory T-cells. We find that individual\nmice may enter one of two stable steady states: a `mild' insulitis state that\ndoes not progress to T1D and a `severe' insulitis state that does. We then run\na sensitivity analysis to identify which parameters affect incidence of T1D\nversus those that affect age of onset. We also test the model by simulating\nseveral experimental manipulations found in the literature that modify\ninsulitis severity and/or Treg activity. Notably, we are able to match a\nreproduce a large number of phenomena using a relatively small number of\nequations. We finish by proposing experiments that could help validate or\nrefine the model.\n", "versions": [{"version": "v1", "created": "Sat, 20 Dec 2014 00:57:07 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Moore", "James R.", ""], ["Adler", "Fred", ""]]}, {"id": "1412.7384", "submitter": "Peng Yang", "authors": "Peng Yang, Xiaoquan Su, Le Ou-Yang, Hon-Nian Chua, Xiao-Li Li, Kang\n  Ning", "title": "Microbial community pattern detection in human body habitats via\n  ensemble clustering framework", "comments": "BMC Systems Biology 2014", "journal-ref": "BMC Systems Biology 2014, 8(Suppl 4):S7", "doi": "10.1186/1752-0509-8-S4-S7", "report-no": null, "categories": "q-bio.QM cs.CE cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human habitat is a host where microbial species evolve, function, and\ncontinue to evolve. Elucidating how microbial communities respond to human\nhabitats is a fundamental and critical task, as establishing baselines of human\nmicrobiome is essential in understanding its role in human disease and health.\nHowever, current studies usually overlook a complex and interconnected\nlandscape of human microbiome and limit the ability in particular body habitats\nwith learning models of specific criterion. Therefore, these methods could not\ncapture the real-world underlying microbial patterns effectively. To obtain a\ncomprehensive view, we propose a novel ensemble clustering framework to mine\nthe structure of microbial community pattern on large-scale metagenomic data.\nParticularly, we first build a microbial similarity network via integrating\n1920 metagenomic samples from three body habitats of healthy adults. Then a\nnovel symmetric Nonnegative Matrix Factorization (NMF) based ensemble model is\nproposed and applied onto the network to detect clustering pattern. Extensive\nexperiments are conducted to evaluate the effectiveness of our model on\nderiving microbial community with respect to body habitat and host gender. From\nclustering results, we observed that body habitat exhibits a strong bound but\nnon-unique microbial structural patterns. Meanwhile, human microbiome reveals\ndifferent degree of structural variations over body habitat and host gender. In\nsummary, our ensemble clustering framework could efficiently explore integrated\nclustering results to accurately identify microbial communities, and provide a\ncomprehensive view for a set of microbial communities. Such trends depict an\nintegrated biography of microbial communities, which offer a new insight\ntowards uncovering pathogenic model of human microbiome.\n", "versions": [{"version": "v1", "created": "Sun, 21 Dec 2014 12:52:45 GMT"}, {"version": "v2", "created": "Wed, 24 Dec 2014 02:03:08 GMT"}, {"version": "v3", "created": "Sun, 4 Jan 2015 05:37:42 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Yang", "Peng", ""], ["Su", "Xiaoquan", ""], ["Ou-Yang", "Le", ""], ["Chua", "Hon-Nian", ""], ["Li", "Xiao-Li", ""], ["Ning", "Kang", ""]]}, {"id": "1412.7519", "submitter": "Helene Montanie", "authors": "H\\'el\\`ene Montani\\'e (LIENSs), Pascaline Ory (LIENSs), Francis\n  Orvain, Daniel Delmas, Christine Dupuy (LIENSs)", "title": "Microbial interactions in marine water amended by eroded benthic\n  biofilm: A case study from an intertidal mudflat", "comments": null, "journal-ref": "Journal of Sea Research, Elsevier, 2014, 92, pp.74 - 85", "doi": "10.1016/j.seares.2013.11.011", "report-no": null, "categories": "q-bio.QM q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In shallow macrotidal ecosystems with large intertidal mudflats, the\nsediment-water coupling plays a crucial role in structuring the pelagic\nmicrobial food web functioning, since inorganic and organic matter and\nmicrobial components (viruses and microbes) of the microphytobenthic biofilm\ncan be suspended toward the water column. Two experimental bioassays were\nconducted in March and July 2008 to investigate the importance of biofilm input\nfor the pelagic Microbial and Viral Loops. Pelagic inocula (<0.6$\\mu$ and\n<10$\\mu$ filtrates) were diluted either with \\textless{}30kDa-ultrafiltered\nseawater or with this ultrafiltrate enriched with the respective\nsize-fractionated benthic biofilm or with \\textless{}30kDa-benthic compounds\n(BC). The kinetics of heterotrophic nanoflagellates (HNF), bacteria and viruses\nwere assessed together with bacterial and viral genomic fingerprints, bacterial\nenzymatic activities and viral life strategies. The experimental design allowed\nus to evaluate the effect of BC modulated by those of benthic size-fractionated\nmicroorganisms (virus+bacteria, +HNF). BC presented (1) in March, a positive\neffect on viruses and bacteria weakened by pelagic HNF. Benthic microorganisms\nconsolidated this negative effect and sustained the viral production together\nwith a relatively diverse and uneven bacterial assemblage structure; (2) in\nJuly, no direct impact on viruses but a positive effect on bacteria modulated\nby HNF, which indirectly enhanced viral multiplication. Both effects were\nintensified by benthic microorganisms and bacterial assemblage structure became\nmore even. HNF indirectly profited from BC more in March than in July. The\nMicrobial Loop would be stimulated by biofilm during periods of high resources\n(March) and the Viral Loop during periods of depleted resources (July).\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 20:50:46 GMT"}], "update_date": "2014-12-24", "authors_parsed": [["Montani\u00e9", "H\u00e9l\u00e8ne", "", "LIENSs"], ["Ory", "Pascaline", "", "LIENSs"], ["Orvain", "Francis", "", "LIENSs"], ["Delmas", "Daniel", "", "LIENSs"], ["Dupuy", "Christine", "", "LIENSs"]]}, {"id": "1412.7560", "submitter": "Franck Jabot", "authors": "Franck Jabot, Guillaume Lagarrigues, Beno\\^it Courbaud, Nicolas\n  Dumoulin", "title": "A comparison of emulation methods for Approximate Bayesian Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.PE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian Computation (ABC) is a family of statistical inference\ntechniques, which is increasingly used in biology and other scientific fields.\nIts main benefit is to be applicable to models for which the computation of the\nmodel likelihood is intractable. The basic idea of ABC is to empirically\napproximate the model likelihood by using intensive realizations of model runs.\nDue to computing time limitations, ABC has thus been mainly applied to models\nthat are relatively quick to simulate. We here aim at briefly introducing the\nfield of statistical emulation of computer code outputs and to demonstrate its\npotential for ABC applications. Emulation consists in replacing the costly to\nsimulate model by another (quick to simulate) statistical model called emulator\nor meta-model. This emulator is fitted to a small number of outputs of the\noriginal model, and is subsequently used as a surrogate during the inference\nprocedure. In this contribution, we first detail the principles of model\nemulation, with a special reference to the ABC context in which the description\nof the stochasticity of model realizations is as important as the description\nof the trends linking model parameters and outputs. We then compare several\nemulation strategies in an ABC context, using as case study a stochastic\necological model of community dynamics. We finally describe a novel\nemulation-based sequential ABC algorithm which is shown to decrease computing\ntime by a factor of two on the studied example, compared to previous sequential\nABC algorithms. Routines to perform emulation-based ABC were made available\nwithin the R package EasyABC.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 08:18:48 GMT"}], "update_date": "2014-12-25", "authors_parsed": [["Jabot", "Franck", ""], ["Lagarrigues", "Guillaume", ""], ["Courbaud", "Beno\u00eet", ""], ["Dumoulin", "Nicolas", ""]]}, {"id": "1412.7828", "submitter": "S{\\o}ren S{\\o}nderby", "authors": "S{\\o}ren Kaae S{\\o}nderby and Ole Winther", "title": "Protein Secondary Structure Prediction with Long Short Term Memory\n  Networks", "comments": "v2: adds larger network with slightly better results, update author\n  affiliations", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prediction of protein secondary structure from the amino acid sequence is a\nclassical bioinformatics problem. Common methods use feed forward neural\nnetworks or SVMs combined with a sliding window, as these models does not\nnaturally handle sequential data. Recurrent neural networks are an\ngeneralization of the feed forward neural network that naturally handle\nsequential data. We use a bidirectional recurrent neural network with long\nshort term memory cells for prediction of secondary structure and evaluate\nusing the CB513 dataset. On the secondary structure 8-class problem we report\nbetter performance (0.674) than state of the art (0.664). Our model includes\nfeed forward networks between the long short term memory cells, a path that can\nbe further explored.\n", "versions": [{"version": "v1", "created": "Thu, 25 Dec 2014 14:27:42 GMT"}, {"version": "v2", "created": "Sun, 4 Jan 2015 19:44:17 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["S\u00f8nderby", "S\u00f8ren Kaae", ""], ["Winther", "Ole", ""]]}, {"id": "1412.8081", "submitter": "Carl Boettiger", "authors": "Carl Boettiger, Marc Mangel, Stephan Munch", "title": "Avoiding tipping points in fisheries management through Gaussian Process\n  Dynamic Programming", "comments": "2015 Proceedings of the Royal Society B: Biological Sciences", "journal-ref": null, "doi": "10.1098/rspb-2014-1631", "report-no": null, "categories": "q-bio.QM q-bio.PE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Model uncertainty and limited data are fundamental challenges to robust\nmanagement of human intervention in a natural system. These challenges are\nacutely highlighted by concerns that many ecological systems may contain\ntipping points, such as Allee population sizes. Before a collapse, we do not\nknow where the tipping points lie, if they exist at all. Hence, we know neither\na complete model of the system dynamics nor do we have access to data in some\nlarge region of state-space where such a tipping point might exist. We\nillustrate how a Bayesian Non-Parametric (BNP) approach using a Gaussian\nProcess (GP) prior provides a flexible representation of this inherent\nuncertainty. We embed GPs in a Stochastic Dynamic Programming (SDP) framework\nin order to make robust management predictions with both model uncertainty and\nlimited data. We use simulations to evaluate this approach as compared with the\nstandard approach of using model selection to choose from a set of candidate\nmodels. We find that model selection erroneously favors models without tipping\npoints -- leading to harvest policies that guarantee extinction. The GPDP\nperforms nearly as well as the true model and significantly outperforms\nstandard approaches. We illustrate this using examples of simulated\nsingle-species dynamics, where the standard model selection approach should be\nmost effective, and find that it still fails to account for uncertainty\nappropriately and leads to population crashes, while management based on the\nGPDP does not, since it does not underestimate the uncertainty outside of the\nobserved data.\n", "versions": [{"version": "v1", "created": "Sat, 27 Dec 2014 21:08:13 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Boettiger", "Carl", ""], ["Mangel", "Marc", ""], ["Munch", "Stephan", ""]]}, {"id": "1412.8752", "submitter": "William Bialek", "authors": "Ga\\v{s}per Tka\\v{c}ik and William Bialek", "title": "Information processing in living systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cond-mat.stat-mech physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Life depends as much on the flow of information as on the flow of energy.\nHere we review the many efforts to make this intuition precise. Starting with\nthe building blocks of information theory, we explore examples where it has\nbeen possible to measure, directly, the flow of information in biological\nnetworks, or more generally where information theoretic ideas have been used to\nguide the analysis of experiments. Systems of interest range from single\nmolecules (the sequence diversity in families of proteins) to groups of\norganisms (the distribution of velocities in flocks of birds), and all scales\nin between. Many of these analyses are motivated by the idea that biological\nsystems may have evolved to optimize the gathering and representation of\ninformation, and we review the experimental evidence for this optimization,\nagain across a wide range of scales.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 20:15:08 GMT"}], "update_date": "2014-12-31", "authors_parsed": [["Tka\u010dik", "Ga\u0161per", ""], ["Bialek", "William", ""]]}]