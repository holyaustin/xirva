[{"id": "1708.00062", "submitter": "Volodymyr Perederiy", "authors": "Volodymyr Perederiy", "title": "Sparse Structural Approach for Rating Transitions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In banking practice, rating transition matrices have become the standard\napproach of deriving multi-year probabilities of default (PDs) from one-year\nPDs, the latter normally being available from Basel ratings. Rating transition\nmatrices have gained in importance with the newly adopted IFRS 9 accounting\nstandard. Here, the multi-year PDs can be used to calculate the so-called\nexpected credit losses (ECL) over the entire lifetime of relevant credit\nassets. A typical approach for estimating the rating transition matrices relies\non calculating empirical rating migration counts and frequencies from rating\nhistory data. For small portfolios, however, this approach often leads to zero\ncounts and high count volatility, which makes the estimations unreliable and\nunstable, and can also produce counter-intuitive prediction patterns such as\nnon-parallel/crossing forward PD patterns. This paper proposes a structural\nmodel which overcomes these problems. We make a plausible assumption of an\nunderlying autoregressive mean-reverting ability-to-pay process. With only\nthree parameters, this sparse process can well describe an entire typical\nrating transition matrix, provided the one-year PDs of the rating classes are\nspecified. The transition probabilities produced by the structural approach are\nwell-behaved by design. The approach significantly reduces the statistical\ndegrees of freedom of the estimated transition probabilities, which makes the\nrating transition matrix more reliable for small portfolios. The approach can\nbe applied to data with as few as 50 observed rating transitions. Moreover, the\napproach can be efficiently applied to data consisting of continuous PDs (prior\nto rating discretization). In the IFRS 9 context, the approach offers an\nadditional merit: it can easily account for the macroeconomic adjustments,\nwhich are required by the IFRS 9 accounting standard.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 20:34:25 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 03:38:44 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Perederiy", "Volodymyr", ""]]}, {"id": "1708.01324", "submitter": "Simge Kucukyavuz University of Washington", "authors": "Merve Merakli, Simge Kucukyavuz", "title": "Vector-Valued Multivariate Conditional Value-at-Risk", "comments": null, "journal-ref": "Operations Research Letters, 46(3), 300-305, 2018", "doi": "10.1016/j.orl.2018.02.006", "report-no": null, "categories": "math.OC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we propose a new definition of multivariate conditional\nvalue-at-risk (MCVaR) as a set of vectors for discrete probability spaces. We\nexplore the properties of the vector-valued MCVaR (VMCVaR) and show the\nadvantages of VMCVaR over the existing definitions given for continuous random\nvariables when adapted to the discrete case.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 22:35:34 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Merakli", "Merve", ""], ["Kucukyavuz", "Simge", ""]]}, {"id": "1708.01489", "submitter": "Alexander McNeil", "authors": "Michael B. Gordy and Alexander J. McNeil", "title": "Spectral backtests of forecast distributions with application to risk\n  management", "comments": "41 pages, 3 figures, supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of backtests for forecast distributions in which the test\nstatistic depends on a spectral transformation that weights exceedance events\nby a function of the modeled probability level. The weighting scheme is\nspecified by a kernel measure which makes explicit the user's priorities for\nmodel performance. The class of spectral backtests includes tests of\nunconditional coverage and tests of conditional coverage. We show how the class\nembeds a wide variety of backtests in the existing literature, and further\npropose novel variants which are easily implemented, well-sized and have good\npower. In an empirical application, we backtest forecast distributions for the\novernight P&L of ten bank trading portfolios. For some portfolios, test results\ndepend materially on the choice of kernel.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 13:31:25 GMT"}, {"version": "v2", "created": "Fri, 9 Mar 2018 15:03:49 GMT"}, {"version": "v3", "created": "Mon, 6 Aug 2018 12:10:32 GMT"}, {"version": "v4", "created": "Fri, 29 Mar 2019 09:07:29 GMT"}, {"version": "v5", "created": "Mon, 8 Apr 2019 14:40:20 GMT"}, {"version": "v6", "created": "Mon, 29 Jul 2019 12:13:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Gordy", "Michael B.", ""], ["McNeil", "Alexander J.", ""]]}, {"id": "1708.01561", "submitter": "Zachary Feinstein", "authors": "Zachary Feinstein, Weijie Pang, Birgit Rudloff, Eric Schaanning,\n  Stephan Sturm, Mackenzie Wildman", "title": "Sensitivity of the Eisenberg-Noe clearing vector to individual interbank\n  liabilities", "comments": "37 pages", "journal-ref": "SIAM J. Finan. Math. 9:4 (2018), 1286-1325", "doi": "10.1137/18M1171060", "report-no": null, "categories": "q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We quantify the sensitivity of the Eisenberg-Noe clearing vector to\nestimation errors in the bilateral liabilities of a financial system in a\nstylized setting. The interbank liabilities matrix is a crucial input to the\ncomputation of the clearing vector. However, in practice central bankers and\nregulators must often estimate this matrix because complete information on\nbilateral liabilities is rarely available. As a result, the clearing vector may\nsuffer from estimation errors in the liabilities matrix. We quantify the\nclearing vector's sensitivity to such estimation errors and show that its\ndirectional derivatives are, like the clearing vector itself, solutions of\nfixed point equations. We describe estimation errors utilizing a basis for the\nspace of matrices representing permissible perturbations and derive analytical\nsolutions to the maximal deviations of the Eisenberg-Noe clearing vector. This\nallows us to compute upper bounds for the worst case perturbations of the\nclearing vector in our simple setting. Moreover, we quantify the probability of\nobserving clearing vector deviations of a certain magnitude, for uniformly or\nnormally distributed errors in the relative liability matrix.\n  Applying our methodology to a dataset of European banks, we find that\nperturbations to the relative liabilities can result in economically sizeable\ndifferences that could lead to an underestimation of the risk of contagion. Our\nresults are a first step towards allowing regulators to quantify errors in\ntheir simulations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 15:45:01 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 20:13:55 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2018 16:20:10 GMT"}, {"version": "v4", "created": "Sat, 6 Oct 2018 06:59:44 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Feinstein", "Zachary", ""], ["Pang", "Weijie", ""], ["Rudloff", "Birgit", ""], ["Schaanning", "Eric", ""], ["Sturm", "Stephan", ""], ["Wildman", "Mackenzie", ""]]}, {"id": "1708.02180", "submitter": "Jian-Jun Shu", "authors": "Qi-Wen Wang, Jian-Jun Shu", "title": "Financial option insurance", "comments": null, "journal-ref": "Risk Management-Journal of Risk Crisis and Disaster, Vol. 19, No.\n  1, pp. 72-101, 2017", "doi": "10.1057/s41283-016-0013-5", "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The option is a financial derivative, which is regularly employed in reducing\nthe risk of its underlying securities. However, investing in option is still\nrisky. Such risk becomes much severer for speculators who utilize option as a\nmeans of leverage to increase their potential returns. In order to mitigate\nrisk on their positions, the rudimentary concept of financial option insurance\nis introduced into practice. Two starkly-dissimilar concepts of insurance and\nfinancial option are integrated into the formation of financial option\ninsurance. The proposed financial product insures investors option premiums\nwhen misfortune befalls on them. As a trade-off, they are likely to sacrifice a\nlimited portion of their potential profits. The loopholes of prevailing\nfinancial market are addressed and the void is filled by introducing a stable\nthree-entity framework. Moreover, a specifically designed mathematical model is\nproposed. It consists of two portions: the business strategy of matching and a\nverification-and-modification process. The proposed model enables the option\ninvestors with calls and puts of different moneyness to be protected by the\nissued option insurance. Meanwhile, it minimizes the exposure of option\ninsurers position to any potential losses.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 16:02:12 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Wang", "Qi-Wen", ""], ["Shu", "Jian-Jun", ""]]}, {"id": "1708.02984", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze and Willie Yu", "title": "Decoding Stock Market with Quant Alphas", "comments": "20 pages; to appear in Journal of Asset Management", "journal-ref": "Journal of Asset Management 19(1) (2018) 38-48", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an explicit algorithm and source code for extracting expected returns\nfor stocks from expected returns for alphas. Our algorithm altogether bypasses\ncombining alphas with weights into \"alpha combos\". Simply put, we have\ndeveloped a new method for trading alphas which does not involve combining\nthem. This yields substantial cost savings as alpha combos cost hedge funds\naround 3% of the P&L, while alphas themselves cost around 10%. Also, the extra\nlayer of alpha combos, which our new method avoids, adds noise and\nsuboptimality. We also arrive at our algorithm independently by explicitly\nconstructing alpha risk models based on position data.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 19:53:47 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Kakushadze", "Zura", ""], ["Yu", "Willie", ""]]}, {"id": "1708.05319", "submitter": "Damiano  Brigo", "authors": "Damiano Brigo, Marco Francischello, Andrea Pallavicini", "title": "An indifference approach to the cost of capital constraints: KVA and\n  beyond", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The strengthening of capital requirements has induced banks and traders to\nconsider charging a so called capital valuation adjustment (KVA) to the clients\nin OTC transactions. This roughly corresponds to charge the clients ex-ante the\nprofit requirement that is asked to the trading desk. In the following we try\nto delineate a possible way to assess the impact of capital constraints in the\nvaluation of a deal. We resort to an optimisation stemming from an indifference\npricing approach, and we study both the linear problem from the point of view\nof the whole bank and the non-linear problem given by the viewpoint of\nshareholders. We also consider the case where one optimises the median rather\nthan the mean statistics of the profit and loss distribution.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 14:54:26 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Brigo", "Damiano", ""], ["Francischello", "Marco", ""], ["Pallavicini", "Andrea", ""]]}, {"id": "1708.05713", "submitter": "Amir Ahmadi Javid", "authors": "Amir Ahmadi-Javid and Malihe Fallah-Tafti", "title": "Portfolio Optimization with Entropic Value-at-Risk", "comments": null, "journal-ref": "European Journal of Operational Research, 279(1), 225-241", "doi": "10.1016/j.ejor.2019.02.007", "report-no": null, "categories": "q-fin.PM math.OC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The entropic value-at-risk (EVaR) is a new coherent risk measure, which is an\nupper bound for both the value-at-risk (VaR) and conditional value-at-risk\n(CVaR). As important properties, the EVaR is strongly monotone over its domain\nand strictly monotone over a broad sub-domain including all continuous\ndistributions, while well-known monotone risk measures, such as VaR and CVaR\nlack these properties. A key feature for a risk measure, besides its financial\nproperties, is its applicability in large-scale sample-based portfolio\noptimization. If the negative return of an investment portfolio is a\ndifferentiable convex function, the portfolio optimization with the EVaR\nresults in a differentiable convex program whose number of variables and\nconstraints is independent of the sample size, which is not the case for the\nVaR and CVaR. This enables us to design an efficient algorithm using\ndifferentiable convex optimization. Our extensive numerical study shows the\nhigh efficiency of the algorithm in large scales, compared to the existing\nconvex optimization software packages. The computational efficiency of the EVaR\nportfolio optimization approach is also compared with that of CVaR-based\nportfolio optimization. This comparison shows that the EVaR approach generally\nperforms similarly, and it outperforms as the sample size increases. Moreover,\nthe comparison of the portfolios obtained for a real case by the EVaR and CVaR\napproaches shows that the EVaR approach can find portfolios with better\nexpectations and VaR values at high confidence levels.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 15:38:56 GMT"}], "update_date": "2020-04-17", "authors_parsed": [["Ahmadi-Javid", "Amir", ""], ["Fallah-Tafti", "Malihe", ""]]}, {"id": "1708.06886", "submitter": "Anne MacKay", "authors": "Michael A. Kouritzin and Anne MacKay", "title": "VIX-linked fees for GMWBs via Explicit Solution Simulation Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a market with stochastic volatility and jumps, we consider a VIX-linked\nfee structure for variable annuity contracts with guaranteed minimum withdrawal\nbenefits (GMWB). Our goal is to assess the effectiveness of the VIX-linked fee\nstructure in decreasing the sensitivity of the insurer's liability to\nvolatility risk. Since the GMWB payoff is highly path-dependent, it is\nparticularly sensitive to volatility risk, and can also be challenging to\nprice, especially in the presence of the VIX-linked fee. In this paper, we\npresent an explicit weak solution for the value of the VA account and use it in\nMonte Carlo simulations to value the GMWB guarantee. Numerical examples are\nprovided to analyze the impact of the VIX-linked fee on the sensitivity of the\nliability to changes in market volatility.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 05:06:06 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 19:40:02 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Kouritzin", "Michael A.", ""], ["MacKay", "Anne", ""]]}, {"id": "1708.07585", "submitter": "Wujiang Lou", "authors": "Wujiang Lou", "title": "Haircutting Non-cash Collateral", "comments": "26 pages, 4 figures, 7 tables; published in Risk, September 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Haircutting non-cash collateral has become a key element of the post-crisis\nreform of the shadow banking system and OTC derivatives markets. This article\ndevelops a parametric haircut model by expanding haircut definitions beyond the\ntraditional value-at-risk measure and employing a double-exponential\njump-diffusion model for collateral market risk. Haircuts are solved to target\ncredit risk measurements, including probability of default, expected loss or\nunexpected loss criteria. Comparing to data-driven approach typically run on\nproxy data series, the model enables sensitivity analysis and stress test,\ncaptures market liquidity risk, allows idiosyncratic risk adjustments, and\nincorporates relevant market information. Computational results for main\nequities, securitization, and corporate bonds show potential for uses in\ncollateral agreements, e.g. CSAs, and for regulatory capital calculations.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 00:42:07 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Lou", "Wujiang", ""]]}, {"id": "1708.07587", "submitter": "Wilson Ye Chen", "authors": "Wilson Ye Chen, Richard H. Gerlach", "title": "Semiparametric GARCH via Bayesian model averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the dynamic structure of the financial markets is subject to dramatic\nchanges, a model capable of providing consistently accurate volatility\nestimates must not make strong assumptions on how prices change over time. Most\nvolatility models impose a particular parametric functional form that relates\nan observed price change to a volatility forecast (news impact function). We\npropose a new class of functional coefficient semiparametric volatility models\nwhere the news impact function is allowed to be any smooth function, and study\nits ability to estimate volatilities compared to the well known parametric\nproposals, in both a simulation study and an empirical study with real\nfinancial data. We estimate the news impact function using a Bayesian model\naveraging approach, implemented via a carefully developed Markov chain Monte\nCarlo (MCMC) sampling algorithm. Using simulations we show that our flexible\nsemiparametric model is able to learn the shape of the news impact function\nfrom the observed data. When applied to real financial time series, our new\nmodel suggests that the news impact functions are significantly different in\nshapes for different asset types, but are similar for the assets of the same\ntype.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 00:56:20 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Chen", "Wilson Ye", ""], ["Gerlach", "Richard H.", ""]]}, {"id": "1708.08411", "submitter": "Hai Ha Pham", "authors": "Jiro Akahori and Hai Ha Pham", "title": "Default Contagion with Domino Effect , A First Passage Time Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper introduces a structural framework to model dependent\ndefaults, with a particular interest in their contagion.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 16:46:29 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Akahori", "Jiro", ""], ["Pham", "Hai Ha", ""]]}, {"id": "1708.08622", "submitter": "Jozef Barunik", "authors": "Frantisek Cech, and Jozef Barunik", "title": "Measurement of Common Risk Factors: A Panel Quantile Regression Model\n  for Returns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how to measure common market risk factors using newly\nproposed Panel Quantile Regression Model for Returns. By exploring the fact\nthat volatility crosses all quantiles of the return distribution and using\npenalized fixed effects estimator we are able to control for otherwise\nunobserved heterogeneity among financial assets. Direct benefits of the\nproposed approach are revealed in the portfolio Value-at-Risk forecasting\napplication, where our modeling strategy performs significantly better than\nseveral benchmark models according to both statistical and economic comparison.\nIn particular Panel Quantile Regression Model for Returns consistently\noutperforms all the competitors in the 5\\% and 10\\% quantiles. Sound\nstatistical performance translates directly into economic gains which is\ndemonstrated in the Global Minimum Value-at-Risk Portfolio and Markowitz-like\ncomparison. Overall results of our research are important for correct\nidentification of the sources of systemic risk, and are particularly attractive\nfor high dimensional applications.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 07:54:01 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Cech", "Frantisek", ""], ["Barunik", "Jozef", ""]]}, {"id": "1708.09343", "submitter": "Stavros Stavroyiannis", "authors": "Stavros Stavroyiannis", "title": "Value-at-Risk and Expected Shortfall for the major digital currencies", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital currencies and cryptocurrencies have hesitantly started to penetrate\nthe investors, and the next step will be the regulatory risk management\nframework. We examine the Value-at-Risk and Expected Shortfall properties for\nthe major digital currencies, Bitcoin, Ethereum, Litecoin, and Ripple. The\nmethodology used is GARCH modelling followed by Filtered Historical Simulation.\nWe find that digital currencies are subject to a higher risk, therefore, to\nhigher sufficient buffer and risk capital to cover potential losses.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 16:18:10 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Stavroyiannis", "Stavros", ""]]}, {"id": "1708.09810", "submitter": "Enrico Moretto", "authors": "Alessandra Mainini, Enrico Moretto", "title": "Extending Yagil exchange ratio determination model to the case of\n  stochastic dividends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article extends, in a stochastic environment, the Yagil (1987) model\nwhich establishes, in a deterministic dividend discount model, a range for the\nexchange ratio in a stock-for-stock merger agreement. Here, we generalize\nYagil's work letting both pre- and post-merger dividends grow randomly over\ntime. If Yagil focuses only on changes in stock prices before and after the\nmerger, our stochastic environment allows to keep in account both shares'\nexpected values and variance, letting us to identify a more complex bargaining\nregion whose shape depends on mean and standard deviation of the dividends'\ngrowth rate.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 16:42:03 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Mainini", "Alessandra", ""], ["Moretto", "Enrico", ""]]}]