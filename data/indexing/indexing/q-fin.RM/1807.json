[{"id": "1807.01977", "submitter": "Marcelo Righi", "authors": "Marcelo Brutti Righi", "title": "A theory for combinations of risk measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study combinations of risk measures under no restrictive assumption on the\nset of alternatives. We develop and discuss results regarding the preservation\nof properties and acceptance sets for the combinations of risk measures. One of\nthe main results is the representation for resulting risk measures from the\nproperties of both alternative functionals and combination functions. To that,\nwe build on the development of a representation for arbitrary mixture of convex\nrisk measures. In this case, we obtain a penalty that recalls the notion of\ninf-convolution under theoretical measure integration. As an application, we\naddress the context of probability-based risk measurements for functionals on\nthe set of distribution functions. We develop results related to this specific\ncontext. We also explore features of individual interest generated by our\nframework, such as the preservation of continuity properties, the\nrepresentation of worst-case risk measures, stochastic dominance and\nelicitability. We also address model uncertainty measurement under our\nframework and propose a new class of measures for this task.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 12:57:47 GMT"}, {"version": "v2", "created": "Mon, 20 Aug 2018 19:05:17 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 19:02:40 GMT"}, {"version": "v4", "created": "Mon, 18 Mar 2019 18:39:10 GMT"}, {"version": "v5", "created": "Mon, 27 Jan 2020 22:05:05 GMT"}, {"version": "v6", "created": "Fri, 14 Aug 2020 13:04:25 GMT"}], "update_date": "2020-08-17", "authors_parsed": [["Righi", "Marcelo Brutti", ""]]}, {"id": "1807.02422", "submitter": "Chao Wang Dr", "authors": "Chao Wang, Richard Gerlach, Qian Chen", "title": "A Semi-parametric Realized Joint Value-at-Risk and Expected Shortfall\n  Regression Framework", "comments": "45 pages, 4 figures. arXiv admin note: substantial text overlap with\n  arXiv:1805.08653, arXiv:1612.08488, arXiv:1707.03715", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A new realized conditional autoregressive Value-at-Risk (VaR) framework is\nproposed, through incorporating a measurement equation into the original\nquantile regression model. The framework is further extended by employing\nvarious Expected Shortfall (ES) components, to jointly estimate and forecast\nVaR and ES. The measurement equation models the contemporaneous dependence\nbetween the realized measure (i.e., Realized Variance and Realized Range) and\nthe latent conditional ES. An adaptive Bayesian Markov Chain Monte Carlo method\nis employed for estimation and forecasting, the properties of which are\nassessed and compared with maximum likelihood through a simulation study. In a\ncomprehensive forecasting study on 1% and 2.5 % quantile levels, the proposed\nmodels are compared to a range of parametric, non-parametric and\nsemi-parametric models, based on 7 market indices and 7 individual assets.\nOne-day-ahead VaR and ES forecasting results favor the proposed models,\nespecially when incorporating the sub-sampled Realized Variance and the\nsub-sampled Realized Range in the model.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 05:47:05 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2021 05:39:30 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Wang", "Chao", ""], ["Gerlach", "Richard", ""], ["Chen", "Qian", ""]]}, {"id": "1807.02711", "submitter": "Zachary Feinstein", "authors": "Zachary Feinstein", "title": "Capital Regulation under Price Impacts and Dynamic Financial Contagion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a continuous time model for price-mediated contagion\nprecipitated by a common exogenous stress to the banking book of all firms in\nthe financial system. In this setting, firms are constrained so as to satisfy a\nrisk-weight based capital ratio requirement. We use this model to find\nanalytical bounds on the risk-weights for assets as a function of the market\nliquidity. Under these appropriate risk-weights, we find existence and\nuniqueness for the joint system of firm behavior and the asset prices. We\nfurther consider an analytical bound on the firm liquidations, which allows us\nto construct exact formulas for stress testing the financial system with\ndeterministic or random stresses. Numerical case studies are provided to\ndemonstrate various implications of this model and analytical bounds.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 19:11:29 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 02:10:16 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 21:05:58 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Feinstein", "Zachary", ""]]}, {"id": "1807.02923", "submitter": "Sitabhra Sinha", "authors": "Chandrashekar Kuyyamudi, Anindya S. Chakrabarti and Sitabhra Sinha", "title": "Emergence of frustration signals systemic risk", "comments": "6 pages, 4 figures", "journal-ref": "Phys. Rev. E 99, 052306 (2019)", "doi": "10.1103/PhysRevE.99.052306", "report-no": null, "categories": "physics.soc-ph q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the emergence of systemic risk in complex systems can be\nunderstood from the evolution of functional networks representing interactions\ninferred from fluctuation correlations between macroscopic observables.\nSpecifically, we analyze the long-term collective dynamics of the New York\nStock Exchange between 1926-2016, showing that periods marked by systemic\ncrisis, viz., around the Great Depression of 1929-33 and the Great Recession of\n2007-09, are associated with emergence of frustration indicated by the loss of\nstructural balance in the interaction networks. During these periods the\ndominant eigenmodes characterizing the collective behavior exhibit\ndelocalization leading to increased coherence in the dynamics. The topological\nstructure of the networks exhibits a slowly evolving trend marked by the\nemergence of a prominent core-periphery organization around both of the crisis\nperiods.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 03:09:20 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Kuyyamudi", "Chandrashekar", ""], ["Chakrabarti", "Anindya S.", ""], ["Sinha", "Sitabhra", ""]]}, {"id": "1807.06892", "submitter": "Chuancun Yin", "authors": "Yuxia Huang, Chuancun Yin", "title": "A unifying approach to constrained and unconstrained optimal reinsurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study two classes of optimal reinsurance models from\nperspectives of both insurers and reinsurers by minimizing their convex\ncombination where the risk is measured by a distortion risk measure and the\npremium is given by a distortion premium principle. Firstly, we show that how\noptimal reinsurance models for the unconstrained optimization problem and\nconstrained optimization problems can be formulated in a unified way. Secondly,\nwe propose a geometric approach to solve optimal reinsurance problems directly.\nThis paper considers a class of increasing convex ceded loss functions and\nderives the explicit solutions of the optimal reinsurance which can be in forms\nof quota-share, stop-loss, change-loss, the combination of quota-share and\nchange-loss or the combination of change-loss and change-loss with different\nretentions. Finally, we consider two specific cases: Value at Risk (VaR) and\nTail Value at Risk (TVaR).\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 12:32:44 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Huang", "Yuxia", ""], ["Yin", "Chuancun", ""]]}, {"id": "1807.09864", "submitter": "Eric Benhamou", "authors": "Eric Benhamou and Beatrice Guez", "title": "Incremental Sharpe and other performance ratios", "comments": "18 pages", "journal-ref": "Journal of Statistical and Econometric Methods, vol.7, no.4, 2018,\n  19-37", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM q-fin.ST stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new methodology of computing incremental contribution for\nperformance ratios for portfolio like Sharpe, Treynor, Calmar or Sterling\nratios. Using Euler's homogeneous function theorem, we are able to decompose\nthese performance ratios as a linear combination of individual modified\nperformance ratios. This allows understanding the drivers of these performance\nratios as well as deriving a condition for a new asset to provide incremental\nperformance for the portfolio. We provide various numerical examples of this\nperformance ratio decomposition.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 16:30:47 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 01:12:25 GMT"}, {"version": "v3", "created": "Tue, 4 Sep 2018 05:47:16 GMT"}, {"version": "v4", "created": "Sun, 16 Sep 2018 10:52:25 GMT"}, {"version": "v5", "created": "Mon, 17 Dec 2018 07:19:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Benhamou", "Eric", ""], ["Guez", "Beatrice", ""]]}, {"id": "1807.09919", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze and Willie Yu", "title": "Betas, Benchmarks and Beating the Market", "comments": "36 pages; to appear in The Journal of Trading", "journal-ref": "The Journal of Trading 13(3) (2018) 44-66", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an explicit formulaic algorithm and source code for building\nlong-only benchmark portfolios and then using these benchmarks in long-only\nmarket outperformance strategies. The benchmarks (or the corresponding betas)\ndo not involve any principal components, nor do they require iterations.\nInstead, we use a multifactor risk model (which utilizes multilevel industry\nclassification or clustering) specifically tailored to long-only benchmark\nportfolios to compute their weights, which are explicitly positive in our\nconstruction.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 01:58:39 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Kakushadze", "Zura", ""], ["Yu", "Willie", ""]]}, {"id": "1807.10694", "submitter": "Zachary Feinstein", "authors": "Zachary Feinstein, Birgit Rudloff", "title": "Scalar multivariate risk measures with a single eligible asset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present results on scalar risk measures in markets with\ntransaction costs. Such risk measures are defined as the minimal capital\nrequirements in the cash asset. First, some results are provided on the dual\nrepresentation of such risk measures, with particular emphasis given on the\nspace of dual variables as (equivalent) martingale measures and prices\nconsistent with the market model. Then, these dual representations are used to\nobtain the main results of this paper on time consistency for scalar risk\nmeasures in markets with frictions. It is well known from the superhedging risk\nmeasure in markets with transaction costs, as in Jouini and Kallal (1995), Roux\nand Zastawniak (2016), and Loehne and Rudloff (2014), that the usual scalar\nconcept of time consistency is too strong and not satisfied. We will show that\na weaker notion of time consistency can be defined, which corresponds to the\nusual scalar time consistency but under any fixed consistent pricing process.\nWe will prove the equivalence of this weaker notion of time consistency and a\ncertain type of backward recursion with respect to the underlying risk measure\nwith a fixed consistent pricing process. Several examples are given, with\nspecial emphasis on the superhedging risk measure.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 15:45:55 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 03:53:06 GMT"}, {"version": "v3", "created": "Wed, 3 Jun 2020 09:49:15 GMT"}, {"version": "v4", "created": "Fri, 27 Nov 2020 14:20:25 GMT"}, {"version": "v5", "created": "Thu, 4 Feb 2021 14:31:43 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Feinstein", "Zachary", ""], ["Rudloff", "Birgit", ""]]}, {"id": "1807.11381", "submitter": "Natalie Packham", "authors": "Natalie Packham and Fabian Woebbeking", "title": "A factor-model approach for correlation scenarios and correlation\n  stress-testing", "comments": null, "journal-ref": "Journal of Banking and Finance, 101 (2019), 92-103", "doi": "10.1016/j.jbankfin.2019.01.020", "report-no": null, "categories": "q-fin.RM q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2012, JPMorgan accumulated a USD~6.2 billion loss on a credit derivatives\nportfolio, the so-called `London Whale', partly as a consequence of\nde-correlations of non-perfectly correlated positions that were supposed to\nhedge each other. Motivated by this case, we devise a factor model for\ncorrelations that allows for scenario-based stress testing of correlations. We\nderive a number of analytical results related to a portfolio of homogeneous\nassets. Using the concept of Mahalanobis distance, we show how to identify\nadverse scenarios of correlation risk. In addition, we demonstrate how\ncorrelation and volatility stress tests can be combined. As an example, we\napply the factor-model approach to the \"London Whale\" portfolio and determine\nthe value-at-risk impact from correlation changes. Since our findings are\nparticularly relevant for large portfolios, where even small correlation\nchanges can have a large impact, a further application would be to stress test\nportfolios of central counterparties, which are of systemically relevant size.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 14:55:36 GMT"}, {"version": "v2", "created": "Tue, 27 Nov 2018 08:53:05 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 19:03:19 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Packham", "Natalie", ""], ["Woebbeking", "Fabian", ""]]}, {"id": "1807.11703", "submitter": "Yuri Kifer I", "authors": "Yuri Kifer", "title": "Shortfall Minimization for Game Options in Discrete Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove existence of a self-financing strategy which minimizes shortfall for\ngame options in discrete time\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 08:51:20 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Kifer", "Yuri", ""]]}, {"id": "1807.11823", "submitter": "Jozef Barunik", "authors": "Franti\\v{s}ek \\v{C}ech and Jozef Barun\\'ik", "title": "Panel quantile regressions for estimating and predicting the\n  Value--at--Risk of commodities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how realized and option implied volatilities are\nrelated to the future quantiles of commodity returns. Whereas realized\nvolatility measures ex-post uncertainty, volatility implied by option prices\nreveals the market's expectation and is often used as an ex-ante measure of the\ninvestor sentiment. Using a flexible panel quantile regression framework, we\nshow how the future conditional quantiles of commodities returns depend on both\nex-post and ex-ante uncertainty measures. Empirical analysis of the most liquid\ncommodities covering main sectors including energy, food, agricultural,\nprecious and industrial metals reveal several important stylized facts about\nthe data. We document common patterns of the dependence between future quantile\nreturns and ex-post as well as ex-ante volatilities. We further show that\nconditional returns distribution is platykurtic and time-invariant. The\napproach can serve as a useful risk management tools for investors interested\nin commodity future contracts.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 14:03:23 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["\u010cech", "Franti\u0161ek", ""], ["Barun\u00edk", "Jozef", ""]]}]