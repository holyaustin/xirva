[{"id": "1812.00501", "submitter": "Soham Phade", "authors": "Soham R. Phade and Venkat Anantharam", "title": "Optimal Resource Allocation over Networks via Lottery-Based Mechanisms", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-16989-3_4", "report-no": null, "categories": "econ.TH cs.GT cs.NI math.OC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that, in a resource allocation problem, the ex ante aggregate utility\nof players with cumulative-prospect-theoretic preferences can be increased over\ndeterministic allocations by implementing lotteries. We formulate an\noptimization problem, called the system problem, to find the optimal lottery\nallocation. The system problem exhibits a two-layer structure comprised of a\npermutation profile and optimal allocations given the permutation profile. For\nany fixed permutation profile, we provide a market-based mechanism to find the\noptimal allocations and prove the existence of equilibrium prices. We show that\nthe system problem has a duality gap, in general, and that the primal problem\nis NP-hard. We then consider a relaxation of the system problem and derive some\nqualitative features of the optimal lottery structure.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2018 01:04:36 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Phade", "Soham R.", ""], ["Anantharam", "Venkat", ""]]}, {"id": "1812.01341", "submitter": "Xuan Lu Dr.", "authors": "Xuan Lu, Li Huang, Kangjuan Lyu", "title": "Modelling China's Credit System with Complex Network Theory for\n  Systematic Credit Risk Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The insufficient understanding of the credit network structure was recognized\nas a key factor for regulators' underestimation of the destructive systematic\nrisk during the financial crisis that started in 2007. The existing credit\nnetwork research either took a macro perspective to clarify the topological\nproperties of financial systems at a descriptive level or analyzed the risk\ntransmission path and characteristics of individual entities with much\npre-assumptions of the network. Here, we used the theory of complex network to\nmodel China's credit system from 2000 to 2014 based on actual financial data. A\nbipartite financial institution-firm network and its projected sub-networks\nwere constructed for an integrated analysis from both macro and micro\nperspectives, and the relationship between typological properties and\nsystematic credit risk control was also explored. The typological analysis of\nthe networks suggested that the financial institutions and firms were highly\nbut asymmetrically connected, and the credit network structure made local\nidiosyncratic shocks possible to proliferate through the whole economy. In\naddition, the Chinese credit market was still dominated by state-owned\nfinancial institutions with firms competing fiercely for financial resources in\nthe past fifteen years. Furthermore, the credit risk score (CRS) was introduced\nby simulation to identify the systematically important vertices in terms of\nsystematic risk control. The results indicated that the vertices with more\naccess to the credit market or less likelihood to be a bridge in the network\nwere the ones with higher systematically importance. The empirical results from\nthis study would provide specific policy suggestions to financial regulators on\nsupervisory approaches and optimizing the allocation of regulatory resources to\nenhance the robustness of credit systems in China and in other countries.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2018 11:16:54 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Lu", "Xuan", ""], ["Huang", "Li", ""], ["Lyu", "Kangjuan", ""]]}, {"id": "1812.04354", "submitter": "Andreas Hamel H", "authors": "Andreas H Hamel", "title": "Monetary Measures of Risk", "comments": "55 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This survey gives an introduction to monetary measures of risk as monotone\nand cash additive functions on spaces of univariate random variables. Primal\nand dual representation results as well as several examples are discussed.\nPrincipal ways to construct risk measures are given and extensions to more\ngeneral situations indicated.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 12:28:36 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Hamel", "Andreas H", ""]]}, {"id": "1812.04827", "submitter": "Ruodu Wang", "authors": "Ruodu Wang, Ricardas Zitikis", "title": "Weak comonotonicity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical notion of comonotonicity has played a pivotal role when solving\ndiverse problems in economics, finance, and insurance. In various practical\nproblems, however, this notion of extreme positive dependence structure is\noverly restrictive and sometimes unrealistic. In the present paper, we put\nforward a notion of weak comonotonicity, which contains the classical notion of\ncomonotonicity as a special case, and gives rise to necessary and sufficient\nconditions for a number of optimization problems, such as those arising in\nportfolio diversification, risk aggregation, and premium calculation. In\nparticular, we show that a combination of weak comonotonicity and weak\nantimonotonicity with respect to some choices of measures is sufficient for the\nmaximization of Value-at-Risk aggregation, and weak comonotonicity is necessary\nand sufficient for the Expected Shortfall aggregation. Finally, with the help\nof weak comonotonicity acting as an intermediate notion of dependence between\nthe extreme cases of no dependence and strong comonotonicity, we give a natural\nsolution to a risk-sharing problem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Dec 2018 06:49:08 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2019 20:57:08 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Wang", "Ruodu", ""], ["Zitikis", "Ricardas", ""]]}, {"id": "1812.05893", "submitter": "Erwan Koch", "authors": "Erwan Koch and Christian Y. Robert", "title": "Stochastic derivative estimation for max-stable random fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider expected performances based on max-stable random fields and we\nare interested in their derivatives with respect to the spatial dependence\nparameters of those fields. Max-stable fields, such as the Brown--Resnick and\nSmith fields, are very popular in spatial extremes. We focus on the two most\npopular unbiased stochastic derivative estimation approaches: the likelihood\nratio method (LRM) and the infinitesimal perturbation analysis (IPA). LRM\nrequires the multivariate density of the max-stable field to be explicit, and\nIPA necessitates the computation of the derivative with respect to the\nparameters for each simulated value. We propose convenient and tractable\nconditions ensuring the validity of LRM and IPA in the cases of the\nBrown--Resnick and Smith field, respectively. Obtaining such conditions is\nintricate owing to the very structure of max-stable fields. Then we focus on\nrisk and dependence measures, which constitute one of the several frameworks\nwhere our theoretical results can be useful. We perform a simulation study\nwhich shows that both LRM and IPA perform well in various configurations, and\nprovide a real case study that is valuable for the insurance industry.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 12:49:29 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 05:58:21 GMT"}, {"version": "v3", "created": "Tue, 3 Nov 2020 14:13:34 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Koch", "Erwan", ""], ["Robert", "Christian Y.", ""]]}, {"id": "1812.06166", "submitter": "Hamzeh Torabi", "authors": "Hossein Nadeb, Hamzeh Torabi, Ali Dolati", "title": "Ordering the smallest claim amounts from two sets of interdependent\n  heterogeneous portfolios", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $ X_{\\lambda_1},\\ldots,X_{\\lambda_n}$ be a set of dependent and\nnon-negative random variables share a survival copula and let $Y_i=\nI_{p_i}X_{\\lambda_i}$, $i=1,\\ldots,n$, where $I_{p_1},\\ldots,I_{p_n}$ be\nindependent Bernoulli random variables independent of $X_{\\lambda_i}$'s, with\n${\\rm E}[I_{p_i}]=p_i$, $i=1,\\ldots,n$. In actuarial sciences, $Y_i$\ncorresponds to the claim amount in a portfolio of risks. This paper considers\ncomparing the smallest claim amounts from two sets of interdependent\nportfolios, in the sense of usual and likelihood ratio orders, when the\nvariables in one set have the parameters $\\lambda_1,\\ldots,\\lambda_n$ and\n$p_1,\\ldots,p_n$ and the variables in the other set have the parameters\n$\\lambda^{*}_1,\\ldots,\\lambda^{*}_n$ and $p^*_1,\\ldots,p^*_n$. Also, we present\nsome bounds for survival function of the smallest claim amount in a portfolio.\nTo illustrate validity of the results, we serve some applicable models.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 21:08:17 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Nadeb", "Hossein", ""], ["Torabi", "Hamzeh", ""], ["Dolati", "Ali", ""]]}, {"id": "1812.06175", "submitter": "Yaodong Yang Mr.", "authors": "Yaodong Yang, Alisa Kolesnikova, Stefan Lessmann, Tiejun Ma,\n  Ming-Chien Sung, Johnnie E.V. Johnson", "title": "Can Deep Learning Predict Risky Retail Investors? A Case Study in\n  Financial Risk Behavior Forecasting", "comments": "Within the \"equal\" contribution, Yaodong Yang contributed the core\n  deep learning algorithm along with its experimental results, and the first\n  draft of the manuscript (including Figure 1,2,3,4,7,8,9,11, and Table 3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper examines the potential of deep learning to support decisions in\nfinancial risk management. We develop a deep learning model for predicting\nwhether individual spread traders secure profits from future trades. This task\nembodies typical modeling challenges faced in risk and behavior forecasting.\nConventional machine learning requires data that is representative of the\nfeature-target relationship and relies on the often costly development,\nmaintenance, and revision of handcrafted features. Consequently, modeling\nhighly variable, heterogeneous patterns such as trader behavior is challenging.\nDeep learning promises a remedy. Learning hierarchical distributed\nrepresentations of the data in an automatic manner (e.g. risk taking behavior),\nit uncovers generative features that determine the target (e.g., trader's\nprofitability), avoids manual feature engineering, and is more robust toward\nchange (e.g. dynamic market conditions). The results of employing a deep\nnetwork for operational risk forecasting confirm the feature learning\ncapability of deep learning, provide guidance on designing a suitable network\narchitecture and demonstrate the superiority of deep learning over machine\nlearning and rule-based benchmarks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 21:31:41 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 16:31:04 GMT"}, {"version": "v3", "created": "Sun, 17 Nov 2019 22:59:23 GMT"}], "update_date": "2019-11-19", "authors_parsed": [["Yang", "Yaodong", ""], ["Kolesnikova", "Alisa", ""], ["Lessmann", "Stefan", ""], ["Ma", "Tiejun", ""], ["Sung", "Ming-Chien", ""], ["Johnson", "Johnnie E. V.", ""]]}, {"id": "1812.06185", "submitter": "Fei Sun", "authors": "Fei Sun, Yijun Hu", "title": "Systemic risk measures with markets volatility", "comments": "arXiv admin note: text overlap with arXiv:1806.01166,\n  arXiv:1806.08701", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As systemic risk has become a hot topic in the financial markets, how to\nmeasure, allocate and regulate the systemic risk are becoming especially\nimportant. However, the financial markets are becoming more and more\ncomplicate, which makes the usual study of systemic risk to be restricted. In\nthis paper, we will study the systemic risk measures on a special space\n$L^{p(\\cdot)}$ where the variable exponent $p(\\cdot)$ is no longer a given real\nnumber like the space $L^{p}$, but a random variable, which reflects the\npossible volatility of the financial markets. Finally, the dual representation\nfor this new systemic risk measures will be studied. Our results show that\nevery this new systemic risk measure can be decomposed into a convex certain\nfunction and a simple-systemic risk measure, which provides a new ideas for\ndealing with the systemic risk.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 07:30:19 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 07:46:44 GMT"}, {"version": "v3", "created": "Mon, 24 Jun 2019 23:44:21 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Sun", "Fei", ""], ["Hu", "Yijun", ""]]}, {"id": "1812.06973", "submitter": "Lorella Fatone", "authors": "Lorella Fatone and Francesca Mariani", "title": "Systemic risk governance in a dynamical model of a banking system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of governing systemic risk in a banking system model.\nThe banking system model consists in an initial value problem for a system of\nstochastic differential equations whose dependent variables are the\nlog-monetary reserves of the banks as functions of time. The banking system\nmodel considered generalizes previous models studied in [5], [4], [7] and\ndescribes an homogeneous population of banks. Two distinct mechanisms are used\nto model the cooperation among banks and the cooperation between banks and\nmonetary authority. These mechanisms are regulated respectively by the\nparameters $\\alpha$ and $\\gamma$. A bank fails when its log-monetary reserves\ngo below an assigned default level. We call systemic risk or systemic event in\na bounded time interval the fact that in that time interval at least a given\nfraction of the banks fails. The probability of systemic risk in a bounded time\ninterval is evaluated using statistical simulation. A method to govern the\nprobability of systemic risk in a bounded time interval is presented. The goal\nof the governance is to keep the probability of systemic risk in a bounded time\ninterval between two given thresholds. The governance is based on the choice of\nthe log-monetary reserves of a kind of \"ideal bank\" as a function of time and\non the solution of an optimal control problem for the mean field approximation\nof the banking system model. The solution of the optimal control problem\ndetermines the parameters $\\alpha$ and $\\gamma$ as functions of time, that is\ndefines the rules of the borrowing and lending activity among banks and between\nbanks and monetary authority. Some numerical examples are discussed. The\nsystemic risk governance is tested in absence and in presence of positive and\nnegative shocks acting on the banking system.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2018 16:10:37 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Fatone", "Lorella", ""], ["Mariani", "Francesca", ""]]}, {"id": "1812.07635", "submitter": "Omid Mohaddesi", "authors": "Mostafa Zandieh, Seyed Omid Mohaddesi", "title": "Portfolio Rebalancing under Uncertainty Using Meta-heuristic Algorithm", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we solve portfolio rebalancing problem when security returns\nare represented by uncertain variables considering transaction costs. The\nperformance of the proposed model is studied using constant-proportion\nportfolio insurance (CPPI) as rebalancing strategy. Numerical results showed\nthat uncertain parameters and different belief degrees will produce different\nefficient frontiers, and affect the performance of the proposed model.\nMoreover, CPPI strategy performs as an insurance mechanism and limits downside\nrisk in bear markets while it allows potential benefit in bull markets.\nFinally, using a globally optimization solver and genetic algorithm (GA) for\nsolving the model, we concluded that the problem size is an important factor in\nsolving portfolio rebalancing problem with uncertain parameters and to gain\nbetter results, it is recommended to use a meta-heuristic algorithm rather than\na global solver.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 20:44:43 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Zandieh", "Mostafa", ""], ["Mohaddesi", "Seyed Omid", ""]]}, {"id": "1812.07645", "submitter": "Konstantinos Spiliopoulos", "authors": "Konstantinos Spiliopoulos and Jia Yang", "title": "Network effects in default clustering for large systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a large collection of dynamically interacting components defined\non a weighted directed graph determining the impact of default of one component\nto another one. We prove a law of large numbers for the empirical measure\ncapturing the evolution of the different components in the pool and from this\nwe extract important information for quantities such as the loss rate in the\noverall pool as well as the mean impact on a given component from system wide\ndefaults. A singular value decomposition of the adjacency matrix of the graph\nallows to coarse-grain the system by focusing on the highest eigenvalues which\nalso correspond to the components with the highest contagion impact on the\npool. Numerical simulations demonstrate the theoretical findings.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2018 21:17:14 GMT"}, {"version": "v2", "created": "Thu, 30 May 2019 21:03:21 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 20:05:49 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Spiliopoulos", "Konstantinos", ""], ["Yang", "Jia", ""]]}, {"id": "1812.08343", "submitter": "Hamzeh Torabi", "authors": "Hossein Nadeb, Hamzeh Torabi, Ali Dolati", "title": "Stochastic comparisons of the largest claim amounts from two sets of\n  interdependent heterogeneous portfolios", "comments": "arXiv admin note: text overlap with arXiv:1812.06078 and\n  arXiv:1812.06166", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $ X_{\\lambda_1},\\ldots,X_{\\lambda_n}$ be dependent non-negative random\nvariables and $Y_i=I_{p_i} X_{\\lambda_i}$, $i=1,\\ldots,n$, where\n$I_{p_1},\\ldots,I_{p_n}$ are independent Bernoulli random variables independent\nof $X_{\\lambda_i}$'s, with ${\\rm E}[I_{p_i}]=p_i$, $i=1,\\ldots,n$. In actuarial\nsciences, $Y_i$ corresponds to the claim amount in a portfolio of risks. In\nthis paper, we compare the largest claim amounts of two sets of interdependent\nportfolios, in the sense of usual stochastic order, when the variables in one\nset have the parameters $\\lambda_1,\\ldots,\\lambda_n$ and $p_1,\\ldots,p_n$ and\nthe variables in the other set have the parameters\n$\\lambda^{*}_1,\\ldots,\\lambda^{*}_n$ and $p^*_1,\\ldots,p^*_n$. For\nillustration, we apply the results to some important models in actuary.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2018 19:31:38 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Nadeb", "Hossein", ""], ["Torabi", "Hamzeh", ""], ["Dolati", "Ali", ""]]}, {"id": "1812.08435", "submitter": "Guusje Delsing", "authors": "G.A. Delsing, M.R.H. Mandjes, P.J.C. Spreij, E.M.M. Winands", "title": "An optimization approach to adaptive multi-dimensional capital\n  management", "comments": null, "journal-ref": null, "doi": "10.1016/j.insmatheco.2018.10.001", "report-no": null, "categories": "q-fin.RM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Firms should keep capital to offer sufficient protection against the risks\nthey are facing. In the insurance context methods have been developed to\ndetermine the minimum capital level required, but less so in the context of\nfirms with multiple business lines including allocation. The individual capital\nreserve of each line can be represented by means of classical models, such as\nthe conventional Cram\\'{e}r-Lundberg model, but the challenge lies in soundly\nmodelling the correlations between the business lines. We propose a simple yet\nversatile approach that allows for dependence by introducing a common\nenvironmental factor. We present a novel Bayesian approach to calibrate the\nlatent environmental state distribution based on observations concerning the\nclaim processes. The calibration approach is adjusted for an environmental\nfactor that changes over time. The convergence of the calibration procedure\ntowards the true environmental state is deduced. We then point out how to\ndetermine the optimal initial capital of the different business lines under\nspecific constraints on the ruin probability of subsets of business lines. Upon\ncombining the above findings, we have developed an easy-to-implement approach\nto capital risk management in a multi-dimensional insurance risk model.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2018 09:31:34 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Delsing", "G. A.", ""], ["Mandjes", "M. R. H.", ""], ["Spreij", "P. J. C.", ""], ["Winands", "E. M. M.", ""]]}, {"id": "1812.09407", "submitter": "Lucia Cipolina Kun", "authors": "Lucia Cipolina-Kun, Ignacio Ruiz, Mariano Zero-Medina Laris", "title": "An Enhanced Initial Margin Methodology to Manage Warehoused Credit Risk", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.14536.37124", "report-no": null, "categories": "q-fin.RM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The use of CVA to cover credit risk is widely spread, but has its\nlimitations. Namely, dealers face the problem of the illiquidity of instruments\nused for hedging it, hence forced to warehouse credit risk. As a result,\ndealers tend to offer a limited OTC derivatives market to highly risky\ncounterparties. Consequently, those highly risky entities rarely have access to\nhedging services precisely when they need them most. In this paper we propose a\nmethod to overcome this limitation. We propose to extend the CVA risk-neutral\nframework to compute an initial margin (IM) specific to each counterparty,\nwhich depends on the credit quality of the entity at stake, transforming the\neffective credit rating of a given netting set to AAA, regardless of the credit\nrating of the counterparty. By transforming CVA requirement into IM ones, as\nproposed in this paper, an institution could rely on the existing mechanisms\nfor posting and calling of IM, hence ensuring the operational viability of this\nnew form of managing warehoused risk. The main difference with the currently\nstandard framework is the creation of a Specific Initial Margin, that depends\nin the credit rating of the counterparty and the characteristics of the netting\nset in question. In this paper we propose a methodology for such transformation\nin a sound manner, and hence this method overcomes some of the limitations of\nthe CVA framework.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 23:14:24 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Cipolina-Kun", "Lucia", ""], ["Ruiz", "Ignacio", ""], ["Laris", "Mariano Zero-Medina", ""]]}, {"id": "1812.10479", "submitter": "Marcelo Sardelich", "authors": "Marcelo Sardelich and Suresh Manandhar", "title": "Multimodal deep learning for short-term stock volatility prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CL cs.LG q-fin.RM stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Stock market volatility forecasting is a task relevant to assessing market\nrisk. We investigate the interaction between news and prices for the\none-day-ahead volatility prediction using state-of-the-art deep learning\napproaches. The proposed models are trained either end-to-end or using sentence\nencoders transfered from other tasks. We evaluate a broad range of stock market\nsectors, namely Consumer Staples, Energy, Utilities, Heathcare, and Financials.\nOur experimental results show that adding news improves the volatility\nforecasting as compared to the mainstream models that rely only on price data.\nIn particular, our model outperforms the widely-recognized GARCH(1,1) model for\nall sectors in terms of coefficient of determination $R^2$, $MSE$ and $MAE$,\nachieving the best performance when training from both news and price data.\n", "versions": [{"version": "v1", "created": "Tue, 25 Dec 2018 14:35:08 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Sardelich", "Marcelo", ""], ["Manandhar", "Suresh", ""]]}]