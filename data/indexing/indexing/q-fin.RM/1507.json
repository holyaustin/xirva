[{"id": "1507.00244", "submitter": "Johanna F. Ziegel", "authors": "Tobias Fissler, Johanna F. Ziegel, Tilmann Gneiting", "title": "Expected Shortfall is jointly elicitable with Value at Risk -\n  Implications for backtesting", "comments": null, "journal-ref": "Risk, January 2016, 58-61", "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we comment on the relevance of elicitability for backtesting\nrisk measure estimates. In particular, we propose the use of Diebold-Mariano\ntests, and show how they can be implemented for Expected Shortfall (ES), based\non the recent result of Fissler and Ziegel (2015) that ES is jointly elicitable\nwith Value at Risk.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 14:24:36 GMT"}, {"version": "v2", "created": "Sun, 12 Jul 2015 10:24:23 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Fissler", "Tobias", ""], ["Ziegel", "Johanna F.", ""], ["Gneiting", "Tilmann", ""]]}, {"id": "1507.00250", "submitter": "Giovanni Bonaccolto", "authors": "Giovanni Bonaccolto, Massimiliano Caporin and Sandra Paterlini", "title": "Asset Allocation Strategies Based on Penalized Quantile Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that quantile regression model minimizes the portfolio\nextreme risk, whenever the attention is placed on the estimation of the\nresponse variable left quantiles. We show that, by considering the entire\nconditional distribution of the dependent variable, it is possible to optimize\ndifferent risk and performance indicators. In particular, we introduce a\nrisk-adjusted profitability measure, useful in evaluating financial portfolios\nunder a pessimistic perspective, since the reward contribution is net of the\nmost favorable outcomes. Moreover, as we consider large portfolios, we also\ncope with the dimensionality issue by introducing an l1-norm penalty on the\nassets weights.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 14:52:57 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Bonaccolto", "Giovanni", ""], ["Caporin", "Massimiliano", ""], ["Paterlini", "Sandra", ""]]}, {"id": "1507.01175", "submitter": "Khalil Said", "authors": "V\\'eronique Maume-Deschamps (ICJ), Didier Rulli\\`ere (SAF), Khalil\n  Said (SAF)", "title": "Impact of dependence on some multivariate risk indicators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimization of some multivariate risk indicators may be used as an\nallocation method, as proposed in C\\'enac et al. [6]. The aim of capital\nallocation is to choose a point in a simplex, according to a given criterion.\nIn a previous paper [17] we proved that the proposed allocation technique\nsatisfies a set of coherence axioms. In the present one, we study the\nproperties and asymptotic behavior of the allocation for some distribution\nmodels. We analyze also the impact of the dependence structure on the\nallocation using some copulas.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 08:08:53 GMT"}], "update_date": "2015-07-07", "authors_parsed": [["Maume-Deschamps", "V\u00e9ronique", "", "ICJ"], ["Rulli\u00e8re", "Didier", "", "SAF"], ["Said", "Khalil", "", "SAF"]]}, {"id": "1507.01847", "submitter": "Zachary Feinstein", "authors": "Zachary Feinstein and Fatena El-Masri", "title": "The Effects of Leverage Requirements and Fire Sales on Financial\n  Contagion via Asset Liquidation Strategies in Financial Networks", "comments": "38 pages, 23 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a framework for modeling the financial system with\nmultiple illiquid assets when liquidation of illiquid assets is caused by\nfailure to meet a leverage requirement. This extends the network model of\nCifuentes, Shin & Ferrucci (2005) which incorporates a single asset with fire\nsales and capital adequacy ratio. This also extends the network model of\nFeinstein (2015) which incorporates multiple illiquid assets with fire sales\nand no leverage ratios. We prove existence of equilibrium clearing payments and\nliquidation prices for a known liquidation strategy when leverage requirements\nare required. We also prove sufficient conditions for the existence of an\nequilibrium liquidation strategy with corresponding clearing payments and\nliquidation prices. Finally we calibrate network models to asset and liability\ndata for 50 banks in the United States from 2007-2014 in order to draw\nconclusions on systemic risk as a function of leverage requirements.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2015 15:39:12 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2016 20:51:42 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Feinstein", "Zachary", ""], ["El-Masri", "Fatena", ""]]}, {"id": "1507.02025", "submitter": "Ola Mahmoud", "authors": "Enrico G. De Giorgi and Ola Mahmoud", "title": "Diversification Preferences in the Theory of Choice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC q-fin.MF q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diversification represents the idea of choosing variety over uniformity.\nWithin the theory of choice, desirability of diversification is axiomatized as\npreference for a convex combination of choices that are equivalently ranked.\nThis corresponds to the notion of risk aversion when one assumes the\nvon-Neumann-Morgenstern expected utility model, but the equivalence fails to\nhold in other models. This paper studies axiomatizations of the concept of\ndiversification and their relationship to the related notions of risk aversion\nand convex preferences within different choice theoretic models. Implications\nof these notions on portfolio choice are discussed. We cover model-independent\ndiversification preferences, preferences within models of choice under risk,\nincluding expected utility theory and the more general rank-dependent expected\nutility theory, as well as models of choice under uncertainty axiomatized via\nChoquet expected utility theory. Remarks on interpretations of diversification\npreferences within models of behavioral choice are given in the conclusion.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2015 04:54:08 GMT"}, {"version": "v2", "created": "Fri, 29 Apr 2016 11:02:28 GMT"}, {"version": "v3", "created": "Thu, 6 Oct 2016 07:54:47 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["De Giorgi", "Enrico G.", ""], ["Mahmoud", "Ola", ""]]}, {"id": "1507.04136", "submitter": "Fabio Caccioli", "authors": "Christoph Aymanns, Fabio Caccioli, J. Doyne Farmer, Vincent W.C. Tan", "title": "Taming the Basel Leverage Cycle", "comments": "41 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC q-fin.GN q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective risk control must make a tradeoff between the microprudential risk\nof exogenous shocks to individual institutions and the macroprudential risks\ncaused by their systemic interactions. We investigate a simple dynamical model\nfor understanding this tradeoff, consisting of a bank with a leverage target\nand an unleveraged fundamental investor subject to exogenous noise with\nclustered volatility. The parameter space has three regions: (i) a stable\nregion, where the system always reaches a fixed point equilibrium; (ii) a\nlocally unstable region, characterized by cycles and chaotic behavior; and\n(iii) a globally unstable region. A crude calibration of parameters to data\nputs the model in region (ii). In this region there is a slowly building price\nbubble, resembling a \"Great Moderation\", followed by a crash, with a period of\napproximately 10-15 years, which we dub the \"Basel leverage cycle\". We propose\na criterion for rating macroprudential policies based on their ability to\nminimize risk for a given average leverage. We construct a one parameter family\nof leverage policies that allows us to vary from the procyclical policies of\nBasel II or III, in which leverage decreases when volatility increases, to\ncountercyclical policies in which leverage increases when volatility increases.\nWe find the best policy depends critically on three parameters: The average\nleverage used by the bank; the relative size of the bank and the\nfundamentalist, and the amplitude of the exogenous noise. Basel II is optimal\nwhen the exogenous noise is high, the bank is small and leverage is low; in the\nopposite limit where the bank is large or leverage is high the optimal policy\nis closer to constant leverage. We also find that systemic risk can be\ndramatically decreased by lowering the leverage target adjustment speed of the\nbanks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2015 09:14:10 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Aymanns", "Christoph", ""], ["Caccioli", "Fabio", ""], ["Farmer", "J. Doyne", ""], ["Tan", "Vincent W. C.", ""]]}, {"id": "1507.04655", "submitter": "Alexander Adamou", "authors": "Ole Peters and Alexander Adamou", "title": "Insurance makes wealth grow faster", "comments": "27 pages, 3 figures, 3 tables, 1 glossary", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voluntary insurance contracts constitute a puzzle because they increase the\nexpectation value of one party's wealth, whereas both parties must sign for\nsuch contracts to exist. Classically, the puzzle is resolved by introducing\nnon-linear utility functions, which encode asymmetric risk preferences; or by\nassuming the parties have asymmetric information. Here we show the puzzle goes\naway if contracts are evaluated by their effect on the time-average growth rate\nof wealth. Our solution assumes only knowledge of wealth dynamics. Time\naverages and expectation values differ because wealth changes are non-ergodic.\nOur reasoning is generalisable: business happens when both parties grow faster.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2015 17:06:40 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 16:17:20 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Peters", "Ole", ""], ["Adamou", "Alexander", ""]]}, {"id": "1507.04767", "submitter": "Ilnaz Asadzadeh", "authors": "Antony Ware, Ilnaz Asadzadeh", "title": "Semi-parametric time series modelling with autocopulas", "comments": "10 pages, AMMCS-CAIMS 2015 Congress", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present an application of the use of autocopulas for\nmodelling financial time series showing serial dependencies that are not\nnecessarily linear. The approach presented here is semi-parametric in that it\nis characterized by a non-parametric autocopula and parametric marginals. One\nadvantage of using autocopulas is that they provide a general representation of\nthe auto-dependency of the time series, in particular making it possible to\nstudy the interdependence of values of the series at different extremes\nseparately. The specific time series that is studied here comes from daily cash\nflows involving the product of daily natural gas price and daily temperature\ndeviations from normal levels. Seasonality is captured by using a time\ndependent normal inverse Gaussian (NIG) distribution fitted to the raw values.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2015 20:45:22 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Ware", "Antony", ""], ["Asadzadeh", "Ilnaz", ""]]}, {"id": "1507.05351", "submitter": "Samuel Drapeau", "authors": "Yannick Armenti, Stephane Crepey, Samuel Drapeau, Antonis\n  Papapantoleon", "title": "Multivariate Shortfall Risk Allocation and Systemic Risk", "comments": "Code, results and figures can also be consulted at\n  https://github.com/yarmenti/MSRA", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ongoing concern about systemic risk since the outburst of the global\nfinancial crisis has highlighted the need for risk measures at the level of\nsets of interconnected financial components, such as portfolios, institutions\nor members of clearing houses. The two main issues in systemic risk measurement\nare the computation of an overall reserve level and its allocation to the\ndifferent components according to their systemic relevance. We develop here a\npragmatic approach to systemic risk measurement and allocation based on\nmultivariate shortfall risk measures, where acceptable allocations are first\ncomputed and then aggregated so as to minimize costs. We analyze the\nsensitivity of the risk allocations to various factors and highlight its\nrelevance as an indicator of systemic risk. In particular, we study the\ninterplay between the loss function and the dependence structure of the\ncomponents. Moreover, we address the computational aspects of risk allocation.\nFinally, we apply this methodology to the allocation of the default fund of a\nCCP on real data.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2015 22:45:22 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 14:53:34 GMT"}, {"version": "v3", "created": "Tue, 26 Jul 2016 16:28:21 GMT"}, {"version": "v4", "created": "Thu, 23 Mar 2017 05:11:55 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Armenti", "Yannick", ""], ["Crepey", "Stephane", ""], ["Drapeau", "Samuel", ""], ["Papapantoleon", "Antonis", ""]]}, {"id": "1507.05415", "submitter": "Volodymyr Perederiy", "authors": "Volodymyr Perederiy", "title": "Endogenous Derivation and Forecast of Lifetime PDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.EC q-fin.PR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a simple technical approach for the analytical derivation\nof Point-in-Time PD (probability of default) forecasts, with minimal data\nrequirements. The inputs required are the current and future Through-the-Cycle\nPDs of the obligors, their last known default rates, and a measurement of the\nsystematic dependence of the obligors. Technically, the forecasts are made from\nwithin a classical asset-based credit portfolio model, with the additional\nassumption of a simple (first/second order) autoregressive process for the\nsystematic factor. This paper elaborates in detail on the practical issues of\nimplementation, especially on the parametrization alternatives. We also show\nhow the approach can be naturally extended to low-default portfolios with\nvolatile default rates, using Bayesian methodology. Furthermore, expert\njudgments on the current macroeconomic state, although not necessary for the\nforecasts, can be embedded into the model using the Bayesian technique. The\nresulting PD forecasts can be used for the derivation of expected lifetime\ncredit losses as required by the newly adopted accounting standard IFRS 9. In\ndoing so, the presented approach is endogenous, as it does not require any\nexogenous macroeconomic forecasts, which are notoriously unreliable and often\nsubjective. Also, it does not require any dependency modeling between PDs and\nmacroeconomic variables, which often proves to be cumbersome and unstable.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2015 08:36:34 GMT"}, {"version": "v2", "created": "Mon, 28 Dec 2020 03:32:45 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Perederiy", "Volodymyr", ""]]}, {"id": "1507.06015", "submitter": "Helin Zhu", "authors": "Helin Zhu, Tianyi Liu and Enlu Zhou", "title": "Risk Quantification in Stochastic Simulation under Input Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When simulating a complex stochastic system, the behavior of output response\ndepends on input parameters estimated from finite real-world data, and the\nfiniteness of data brings input uncertainty into the system. The quantification\nof the impact of input uncertainty on output response has been extensively\nstudied. Most of the existing literature focuses on providing inferences on the\nmean response at the true but unknown input parameter, including point\nestimation and confidence interval construction. Risk quantification of mean\nresponse under input uncertainty often plays an important role in system\nevaluation and control, because it provides inferences on extreme scenarios of\nmean response in all possible input models. To the best of our knowledge, it\nhas rarely been systematically studied in the literature. In this paper, first\nwe introduce risk measures of mean response under input uncertainty, and\npropose a nested Monte Carlo simulation approach to estimate them. Then we\ndevelop asymptotical properties such as consistency and asymptotic normality\nfor the proposed nested risk estimators. We further study the associated budget\nallocation problem for efficient nested risk simulation, and finally use a\nsharing economy example to illustrate the importance of accessing and\ncontrolling risk due to input uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 23:59:56 GMT"}, {"version": "v2", "created": "Sun, 31 Jul 2016 19:47:07 GMT"}, {"version": "v3", "created": "Mon, 18 Dec 2017 22:30:03 GMT"}], "update_date": "2017-12-20", "authors_parsed": [["Zhu", "Helin", ""], ["Liu", "Tianyi", ""], ["Zhou", "Enlu", ""]]}, {"id": "1507.07162", "submitter": "Pavel Shevchenko V", "authors": "Pavel V. Shevchenko, Jonas Hirz and Uwe Schmock", "title": "Forecasting Leading Death Causes in Australia using Extended\n  CreditRisk$+$", "comments": "arXiv admin note: text overlap with arXiv:1505.04757", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we developed a new framework in Hirz et al (2015) to model\nstochastic mortality using extended CreditRisk$^+$ methodology which is very\ndifferent from traditional time series methods used for mortality modelling\npreviously. In this framework, deaths are driven by common latent stochastic\nrisk factors which may be interpreted as death causes like neoplasms,\ncirculatory diseases or idiosyncratic components. These common factors\nintroduce dependence between policyholders in annuity portfolios or between\ndeath events in population. This framework can be used to construct life tables\nbased on mortality rate forecast. Moreover this framework allows stress testing\nand, therefore, offers insight into how certain health scenarios influence\nannuity payments of an insurer. Such scenarios may include improvement in\nhealth treatments or better medication. In this paper, using publicly available\ndata for Australia, we estimate the model using Markov chain Monte Carlo method\nto identify leading death causes across all age groups including long term\nforecast for 2031 and 2051. On top of general reduced mortality, the proportion\nof deaths for certain certain causes has changed massively over the period 1987\nto 2011. Our model forecasts suggest that if these trends persist, then the\nfuture gives a whole new picture of mortality for people aged above 40 years.\nNeoplasms will become the overall number-one death cause. Moreover, deaths due\nto mental and behavioural disorders are very likely to surge whilst deaths due\nto circulatory diseases will tend to decrease. This potential increase in\ndeaths due to mental and behavioural disorders for older ages will have a\nmassive impact on social systems as, typically, such patients need long-term\ngeriatric care.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2015 02:51:54 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Shevchenko", "Pavel V.", ""], ["Hirz", "Jonas", ""], ["Schmock", "Uwe", ""]]}, {"id": "1507.07216", "submitter": "Andrei Soklakov N", "authors": "Andrei N. Soklakov", "title": "Model Risk Analysis via Investment Structuring", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"What are the origins of risks?\" and \"How material are they?\" -- these are\nthe two most fundamental questions of any risk analysis. Quantitative\nStructuring -- a technology for building financial products -- provides\neconomically meaningful answers for both of these questions. It does so by\nconsidering risk as an investment opportunity. The structure of the investment\nreveals the precise sources of risk and its expected performance measures\nmateriality. We demonstrate these capabilities of Quantitative Structuring\nusing a concrete practical example -- model risk in options on vol-targeted\nindices.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jul 2015 16:19:17 GMT"}, {"version": "v2", "created": "Tue, 28 Jul 2015 17:58:31 GMT"}], "update_date": "2015-07-29", "authors_parsed": [["Soklakov", "Andrei N.", ""]]}, {"id": "1507.07870", "submitter": "Samuel R\\\"onnqvist", "authors": "Samuel R\\\"onnqvist and Peter Sarlin", "title": "Detect & Describe: Deep learning of bank stress in the news", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.AI cs.LG cs.NE q-fin.RM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  News is a pertinent source of information on financial risks and stress\nfactors, which nevertheless is challenging to harness due to the sparse and\nunstructured nature of natural text. We propose an approach based on\ndistributional semantics and deep learning with neural networks to model and\nlink text to a scarce set of bank distress events. Through unsupervised\ntraining, we learn semantic vector representations of news articles as\npredictors of distress events. The predictive model that we learn can signal\ncoinciding stress with an aggregated index at bank or European level, while\ncrucially allowing for automatic extraction of text descriptions of the events,\nbased on passages with high stress levels. The method offers insight that\nmodels based on other types of data cannot provide, while offering a general\nmeans for interpreting this type of semantic-predictive model. We model bank\ndistress with data on 243 events and 6.6M news articles for 101 large European\nbanks.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2015 18:47:09 GMT"}], "update_date": "2015-07-29", "authors_parsed": [["R\u00f6nnqvist", "Samuel", ""], ["Sarlin", "Peter", ""]]}]