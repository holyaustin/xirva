[{"id": "1508.00090", "submitter": "Man Chung Fung", "authors": "Man Chung Fung, Katja Ignatieva, Michael Sherris", "title": "Managing Systematic Mortality Risk in Life Annuities: An Application of\n  Longevity Derivatives", "comments": "23 pages; under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper assesses the hedge effectiveness of an index-based longevity swap\nand a longevity cap. Although swaps are a natural instrument for hedging\nlongevity risk, derivatives with non-linear pay-offs, such as longevity caps,\nalso provide downside protection. A tractable stochastic mortality model with\nage dependent drift and volatility is developed and analytical formulae for\nprices of these longevity derivatives are derived. Hedge effectiveness is\nconsidered for a hypothetical life annuity portfolio. The hedging of the life\nannuity portfolio is comprehensively assessed for a range of assumptions for\nthe market price of longevity risk, the term to maturity of the hedging\ninstruments, as well as the size of the underlying annuity portfolio. The model\nis calibrated using Australian mortality data. The results provide a\ncomprehensive analysis of longevity hedging, highlighting the risk management\nbenefits and costs of linear and nonlinear payoff structures.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2015 06:58:37 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Fung", "Man Chung", ""], ["Ignatieva", "Katja", ""], ["Sherris", "Michael", ""]]}, {"id": "1508.01914", "submitter": "Bahman Angoshtari", "authors": "Bahman Angoshtari, Erhan Bayraktar, Virginia R. Young", "title": "Minimizing the Expected Lifetime Spent in Drawdown under Proportional\n  Consumption", "comments": "This paper is to appear in Finance Research Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the optimal amount to invest in a Black-Scholes financial market\nfor an individual who consumes at a rate equal to a constant proportion of her\nwealth and who wishes to minimize the expected time that her wealth spends in\ndrawdown during her lifetime. Drawdown occurs when wealth is less than some\nfixed proportion of maximum wealth. We compare the optimal investment strategy\nwith those for three related goal-seeking problems and learn that the\nindividual is myopic in her investing behavior, as expected from other\ngoal-seeking research.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2015 15:04:37 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2015 15:58:15 GMT"}, {"version": "v3", "created": "Sun, 23 Aug 2015 20:30:51 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Angoshtari", "Bahman", ""], ["Bayraktar", "Erhan", ""], ["Young", "Virginia R.", ""]]}, {"id": "1508.02367", "submitter": "Zachary Feinstein", "authors": "Zachary Feinstein and Birgit Rudloff", "title": "A recursive algorithm for multivariate risk measures and a set-valued\n  Bellman's principle", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": "10.1007/s10898-016-0459-8", "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method for calculating multi-portfolio time consistent multivariate risk\nmeasures in discrete time is presented. Market models for $d$ assets with\ntransaction costs or illiquidity and possible trading constraints are\nconsidered on a finite probability space. The set of capital requirements at\neach time and state is calculated recursively backwards in time along the event\ntree. We motivate why the proposed procedure can be seen as a set-valued\nBellman's principle, that might be of independent interest within the growing\nfield of set optimization. We give conditions under which the backwards\ncalculation of the sets reduces to solving a sequence of linear, respectively\nconvex vector optimization problems. Numerical examples are given and include\nsuperhedging under illiquidity, the set-valued entropic risk measure, and the\nmulti-portfolio time consistent version of the relaxed worst case risk measure\nand of the set-valued average value at risk.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 19:28:35 GMT"}, {"version": "v2", "created": "Mon, 4 Jul 2016 16:22:06 GMT"}], "update_date": "2017-01-27", "authors_parsed": [["Feinstein", "Zachary", ""], ["Rudloff", "Birgit", ""]]}, {"id": "1508.02749", "submitter": "Georg Mainik", "authors": "Georg Mainik", "title": "Risk aggregation with empirical margins: Latin hypercubes, empirical\n  copulas, and convergence of sum distributions", "comments": "Manuscript accepted in the Journal of Multivariate Analysis", "journal-ref": null, "doi": "10.1016/j.jmva.2015.07.008", "report-no": null, "categories": "q-fin.RM stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies convergence properties of multivariate distributions\nconstructed by endowing empirical margins with a copula. This setting includes\nLatin Hypercube Sampling with dependence, also known as the Iman--Conover\nmethod. The primary question addressed here is the convergence of the component\nsum, which is relevant to risk aggregation in insurance and finance.\n  This paper shows that a CLT for the aggregated risk distribution is not\navailable, so that the underlying mathematical problem goes beyond classic\nfunctional CLTs for empirical copulas. This issue is relevant to Monte-Carlo\nbased risk aggregation in all multivariate models generated by plugging\nempirical margins into a copula.\n  Instead of a functional CLT, this paper establishes strong uniform\nconsistency of the estimated sum distribution function and provides a\nsufficient criterion for the convergence rate $O(n^{-1/2})$ in probability.\nThese convergence results hold for all copulas with bounded densities. Examples\nwith unbounded densities include bivariate Clayton and Gauss copulas. The\nconvergence results are not specific to the component sum and hold also for any\nother componentwise non-decreasing aggregation function. On the other hand,\nconvergence of estimates for the joint distribution is much easier to prove,\nincluding CLTs.\n  Beyond Iman--Conover estimates, the results of this paper apply to\nmultivariate distributions obtained by plugging empirical margins into an exact\ncopula or by plugging exact margins into an empirical copula.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 21:14:49 GMT"}], "update_date": "2015-08-13", "authors_parsed": [["Mainik", "Georg", ""]]}, {"id": "1508.02824", "submitter": "Paul Larsen", "authors": "Paul Larsen", "title": "Asyptotic Normality for Maximum Likelihood Estimation and Operational\n  Risk", "comments": "Split previous arXiv submission into two parts for journal\n  submission. A slightly modified version of this paper will appear in the\n  Journal of Operational Risk. The second part on stability of OpVar will be\n  posted separately", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operational risk models commonly employ maximum likelihood estimation (MLE)\nto fit loss data to heavy-tailed distributions. Yet several desirable\nproperties of MLE (e.g. asymptotic normality) are generally valid only for\nlarge sample-sizes, a situation rarely encountered in operational risk. In this\npaper, we study how asymptotic normality does--or does not--hold for common\nseverity distributions in operational risk models. We then apply these results\nto evaluate errors caused by failure of asymptotic normality in constructing\nconfidence intervals around the MLE fitted parameters.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 06:36:15 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2015 17:46:26 GMT"}, {"version": "v3", "created": "Thu, 25 Aug 2016 16:03:56 GMT"}], "update_date": "2016-08-26", "authors_parsed": [["Larsen", "Paul", ""]]}, {"id": "1508.02919", "submitter": "Gaurab Aryal", "authors": "Gaurab Aryal, Isabelle Perrigne and Quang Vuong", "title": "Identification of Insurance Models with Multidimensional Screening", "comments": "55 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.EC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the identification of insurance models with\nmultidimensional screening where insurees have private information about their\nrisk and risk aversion. The model includes a random damage and the possibility\nof several claims. Screening of insurees relies on their certainty equivalence.\nThe paper then investigates how data availability on the number of offered\ncoverages and reported claims affects the identification of the model\nprimitives under four different scenarios. We show that the model structure is\nidentified despite bunching due to multidimensional screening and/or a finite\nnumber of offered coverages. The observed number of claims plays a key role in\nthe identification of the joint distribution of risk and risk aversion. In\naddition, the paper derives all the restrictions imposed by the model on\nobservables. Our results are constructive with explicit equations for\nestimation and model testing.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 13:58:06 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2016 03:27:51 GMT"}], "update_date": "2016-01-18", "authors_parsed": [["Aryal", "Gaurab", ""], ["Perrigne", "Isabelle", ""], ["Vuong", "Quang", ""]]}, {"id": "1508.04883", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze", "title": "Heterotic Risk Models", "comments": "41 pages; a trivial typo corrected", "journal-ref": "Wilmott Magazine 2015(80) (2015) 40-55", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a complete algorithm and source code for constructing what we refer\nto as heterotic risk models (for equities), which combine: i) granularity of an\nindustry classification; ii) diagonality of the principal component factor\ncovariance matrix for any sub-cluster of stocks; and iii) dramatic reduction of\nthe factor covariance matrix size in the Russian-doll risk model construction.\nThis appears to prove a powerful approach for constructing out-of-sample stable\nshort-lookback risk models. Thus, for intraday mean-reversion alphas based on\novernight returns, Sharpe ratio optimization using our heterotic risk models\nsizably improves the performance characteristics compared to weighted\nregressions based on principal components or industry classification. We also\ngive source code for: a) building statistical risk models; and ii) Sharpe ratio\noptimization with homogeneous linear constraints and position bounds.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 05:41:26 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2015 20:43:38 GMT"}, {"version": "v3", "created": "Mon, 4 Jan 2016 22:13:25 GMT"}, {"version": "v4", "created": "Sat, 23 Jan 2016 04:13:12 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Kakushadze", "Zura", ""]]}, {"id": "1508.05460", "submitter": "Marcin Pitera", "authors": "Marcin Pitera and {\\L}ukasz Stettner", "title": "Long run risk sensitive portfolio with general factors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC q-fin.MF q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper portfolio optimization over long run risk sensitive criterion is\nconsidered. It is assumed that economic factors which stimulate asset prices\nare ergodic but non necessarily uniformly ergodic. Solution to suitable Bellman\nequation using local span contraction with weighted norms is shown. The form of\noptimal strategy is presented and examples of market models satisfying imposed\nassumptions are shown.\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2015 03:09:05 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Pitera", "Marcin", ""], ["Stettner", "\u0141ukasz", ""]]}, {"id": "1508.05837", "submitter": "Simone Farinelli", "authors": "Simone Farinelli and Luisa Tibiletti", "title": "Hydroassets Portfolio Management for Intraday Electricity Trading from a\n  Discrete Time Stochastic Optimization Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hydro storage system optimization is becoming one of the most challenging\ntasks in Energy Finance. While currently the state-of-the-art of the commercial\nsoftware in the industry implements mainly linear models, we would like to\nintroduce risk aversion and a generic utility function. At the same time, we\naim to develop and implement a computational efficient algorithm, which is not\naffected by the curse of dimensionality and does not utilize subjective\nheuristics to prevent it. For the short term power market we propose a\nsimultaneous solution for both dispatch and bidding problems.\n  Following the Blomvall and Lindberg (2002) interior point model, we set up a\nstochastic multiperiod optimization procedure by means of a \"bushy\" recombining\ntree that provides fast computational results. Inequality constraints are\npacked into the objective function by the logarithmic barrier approach and the\nutility function is approximated by its second order Taylor polynomial. The\noptimal solution for the original problem is obtained as a diagonal sequence\nwhere the first diagonal dimension is the parameter controlling the logarithmic\npenalty and the second is the parameter for the Newton step in the construction\nof the approximated solution. Optimal intraday electricity trading and water\nvalues for hydro assets as shadow prices are computed. The algorithm is\nimplemented in Mathematica.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 07:38:30 GMT"}, {"version": "v2", "created": "Thu, 12 May 2016 13:49:16 GMT"}, {"version": "v3", "created": "Tue, 19 Jul 2016 15:41:31 GMT"}, {"version": "v4", "created": "Tue, 25 Apr 2017 21:53:43 GMT"}, {"version": "v5", "created": "Thu, 24 Aug 2017 21:13:31 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Farinelli", "Simone", ""], ["Tibiletti", "Luisa", ""]]}, {"id": "1508.07505", "submitter": "Zhi-Qiang Jiang", "authors": "Zhi-Qiang Jiang (ECUST, BU), Askery A. Canabarro (UFAL, BU), Boris\n  Podobnik (UR), H. Eugene Stanley (BU), and Wei-Xing Zhou (ECUST)", "title": "Early warning of large volatilities based on recurrence interval\n  analysis in Chinese stock markets", "comments": "13 pages and 7 figures", "journal-ref": "Quantitative Finance 16 (11), 1713-1724 (2016)", "doi": "10.1080/14697688.2016.1175656", "report-no": null, "categories": "q-fin.ST q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to forcast extreme volatility is a central issue in financial risk\nmanagement. We present a large volatility predicting method based on the\ndistribution of recurrence intervals between volatilities exceeding a certain\nthreshold $Q$ for a fixed expected recurrence time $\\tau_Q$. We find that the\nrecurrence intervals are well approximated by the $q$-exponential distribution\nfor all stocks and all $\\tau_Q$ values. Thus a analytical formula for\ndetermining the hazard probability $W(\\Delta t |t)$ that a volatility above $Q$\nwill occur within a short interval $\\Delta t$ if the last volatility exceeding\n$Q$ happened $t$ periods ago can be directly derived from the $q$-exponential\ndistribution, which is found to be in good agreement with the empirical hazard\nprobability from real stock data. Using these results, we adopt a\ndecision-making algorithm for triggering the alarm of the occurrence of the\nnext volatility above $Q$ based on the hazard probability. Using a \"receiver\noperator characteristic\" (ROC) analysis, we find that this predicting method\nefficiently forecasts the occurrance of large volatility events in real stock\ndata. Our analysis may help us better understand reoccurring large volatilities\nand more accurately quantify financial risks in stock markets.\n", "versions": [{"version": "v1", "created": "Sat, 29 Aug 2015 21:16:53 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Jiang", "Zhi-Qiang", "", "ECUST, BU"], ["Canabarro", "Askery A.", "", "UFAL, BU"], ["Podobnik", "Boris", "", "UR"], ["Stanley", "H. Eugene", "", "BU"], ["Zhou", "Wei-Xing", "", "ECUST"]]}]