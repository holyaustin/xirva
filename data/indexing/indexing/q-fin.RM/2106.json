[{"id": "2106.00288", "submitter": "Chao Wang Dr", "authors": "Chao Wang, Richard Gerlach", "title": "A Bayesian realized threshold measurement GARCH framework for financial\n  tail risk forecasting", "comments": "29 pages, 5 Tables, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, an innovative threshold measurement equation is proposed to be\nemployed in a Realized-GARCH framework. The proposed framework employs a\nnonlinear threshold regression specification to consider the leverage effect\nand model the contemporaneous dependence between the observed realized measures\nand hidden volatility. A Bayesian Markov Chain Monte Carlo method is adapted\nand employed for the model estimation and forecasting, with its validity\nassessed via a simulation study. The usefulness of the proposed measurement\nequation in a Realized-GARCH model has been evaluated via a comprehensive\nempirical study, by forecasting the 1% and 2.5% Value-at-Risk and Expected\nShortfall on six market indices. The proposed framework is shown to be capable\nof producing competitive tail risk forecasting results, compared to the\noriginal Realized-GARCH. Especially, the proposed model is favoured during the\nhigh volatility 2008 Global Financial Crisis period.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 07:41:07 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wang", "Chao", ""], ["Gerlach", "Richard", ""]]}, {"id": "2106.00839", "submitter": "Agni Orfanoudaki", "authors": "Dimitris Bertsimas, Agni Orfanoudaki", "title": "Pricing Algorithmic Insurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-fin.RM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As machine learning algorithms start to get integrated into the\ndecision-making process of companies and organizations, insurance products will\nbe developed to protect their owners from risk. We introduce the concept of\nalgorithmic insurance and present a quantitative framework to enable the\npricing of the derived insurance contracts. We propose an optimization\nformulation to estimate the risk exposure and price for a binary classification\nmodel. Our approach outlines how properties of the model, such as accuracy,\ninterpretability and generalizability, can influence the insurance contract\nevaluation. To showcase a practical implementation of the proposed framework,\nwe present a case study of medical malpractice in the context of breast cancer\ndetection. Our analysis focuses on measuring the effect of the model parameters\non the expected financial loss and identifying the aspects of algorithmic\nperformance that predominantly affect the price of the contract.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jun 2021 22:32:02 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Bertsimas", "Dimitris", ""], ["Orfanoudaki", "Agni", ""]]}, {"id": "2106.01281", "submitter": "Felix-Benedikt Liebrich", "authors": "Felix-Benedikt Liebrich and Cosimo Munari", "title": "Law-invariant functionals that collapse to the mean: Beyond convexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF math.PR q-fin.RM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We establish general \"collapse to the mean\" principles that provide\nconditions under which a law-invariant functional reduces to an expectation. In\nthe convex setting, we retrieve and sharpen known results from the literature.\nHowever, our results also apply beyond the convex setting. We illustrate this\nby providing a complete account of the \"collapse to the mean\" for quasiconvex\nfunctionals. In the special cases of consistent risk measures and Choquet\nintegrals, we can even dispense with quasiconvexity. In addition, we relate the\n\"collapse to the mean\" to the study of solutions of a broad class of\noptimisation problems with law-invariant objectives that appear in mathematical\nfinance, insurance, and economics. We show that the corresponding quantile\nformulations studied in the literature are sometimes illegitimate and require\nfurther analysis.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jun 2021 16:42:52 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 06:39:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Liebrich", "Felix-Benedikt", ""], ["Munari", "Cosimo", ""]]}, {"id": "2106.03560", "submitter": "Roger Laeven", "authors": "Raviar Karim, Roger J. A. Laeven, Michel Mandjes", "title": "Exact and Asymptotic Analysis of General Multivariate Hawkes Processes\n  and Induced Population Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers population processes in which general, not necessarily\nMarkovian, multivariate Hawkes processes dictate the stochastic arrivals. We\nestablish results to determine the corresponding time-dependent joint\nprobability distribution, allowing for general intensity decay functions,\ngeneral intensity jumps, and general sojourn times. We obtain an exact, full\ncharacterization of the time-dependent joint transform of the multivariate\npopulation process and its underlying intensity process in terms of a\nfixed-point representation and corresponding convergence results. We also\nderive the asymptotic tail behavior of the population process and its\nunderlying intensity process in the setting of heavy-tailed intensity jumps. By\nexploiting the results we establish, arbitrary joint spatial-temporal moments\nand other distributional properties can now be readily evaluated using standard\ntransform differentiation and inversion techniques, and we illustrate this in a\nfew examples.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jun 2021 12:41:01 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Karim", "Raviar", ""], ["Laeven", "Roger J. A.", ""], ["Mandjes", "Michel", ""]]}, {"id": "2106.05797", "submitter": "Mike Li", "authors": "Paul Glasserman, Mike Li", "title": "Linear Classifiers Under Infinite Imbalance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-fin.RM stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the behavior of linear discriminant functions for binary\nclassification in the infinite-imbalance limit, where the sample size of one\nclass grows without bound while the sample size of the other remains fixed. The\ncoefficients of the classifier minimize an expected loss specified through a\nweight function. We show that for a broad class of weight functions, the\nintercept diverges but the rest of the coefficient vector has a finite limit\nunder infinite imbalance, extending prior work on logistic regression. The\nlimit depends on the left tail of the weight function, for which we distinguish\nthree cases: bounded, asymptotically polynomial, and asymptotically\nexponential. The limiting coefficient vectors reflect robustness or\nconservatism properties in the sense that they optimize against certain\nworst-case alternatives. In the bounded and polynomial cases, the limit is\nequivalent to an implicit choice of upsampling distribution for the minority\nclass. We apply these ideas in a credit risk setting, with particular emphasis\non performance in the high-sensitivity and high-specificity regions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 15:01:54 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Glasserman", "Paul", ""], ["Li", "Mike", ""]]}, {"id": "2106.06028", "submitter": "Runhuan Feng", "authors": "Runhuan Feng and Peng Li", "title": "Sample Recycling Method -- A New Approach to Efficient Nested Monte\n  Carlo Simulations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.RM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nested stochastic modeling has been on the rise in many fields of the\nfinancial industry. Such modeling arises whenever certain components of a\nstochastic model are stochastically determined by other models. There are at\nleast two main areas of applications, including (1) portfolio risk management\nin the banking sector and (2) principle-based reserving and capital\nrequirements in the insurance sector. As financial instrument values often\nchange with economic fundamentals, the risk management of a portfolio (outer\nloop) often requires the assessment of financial positions subject to changes\nin risk factors in the immediate future. The valuation of financial position\n(inner loop) is based on projections of cashflows and risk factors into the\ndistant future. The nesting of such stochastic modeling can be computationally\nchallenging.\n  Most of existing techniques to speed up nested simulations are based on curve\nfitting. The main idea is to establish a functional relationship between inner\nloop estimator and risk factors by running a limited set of economic scenarios,\nand, instead of running inner loop simulations, inner loop estimations are made\nby feeding other scenarios into the fitted curve. This paper presents a\nnon-conventional approach based on the concept of sample recycling. Its essence\nis to run inner loop estimation for a small set of outer loop scenarios and to\nfind inner loop estimates under other outer loop scenarios by recycling those\nknown inner loop paths. This new approach can be much more efficient when\ntraditional techniques are difficult to implement in practice.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jun 2021 20:13:00 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Feng", "Runhuan", ""], ["Li", "Peng", ""]]}, {"id": "2106.06518", "submitter": "Luca Merlo", "authors": "Luca Merlo, Lea Petrella, Valentina Raponi", "title": "Forecasting VaR and ES using a joint quantile regression and\n  implications in portfolio allocation", "comments": null, "journal-ref": "Journal of Banking & Finance (2021), 106248", "doi": "10.1016/j.jbankfin.2021.106248", "report-no": null, "categories": "q-fin.RM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we propose a multivariate quantile regression framework to\nforecast Value at Risk (VaR) and Expected Shortfall (ES) of multiple financial\nassets simultaneously, extending Taylor (2019). We generalize the Multivariate\nAsymmetric Laplace (MAL) joint quantile regression of Petrella and Raponi\n(2019) to a time-varying setting, which allows us to specify a dynamic process\nfor the evolution of both VaR and ES of each asset. The proposed methodology\naccounts for the dependence structure among asset returns. By exploiting the\nproperties of the MAL distribution, we then propose a new portfolio\noptimization method that minimizes the portfolio risk and controls for\nwell-known characteristics of financial data. We evaluate the advantages of the\nproposed approach on both simulated and real data, using weekly returns on\nthree major stock market indices. We show that our method outperforms other\nexisting models and provides more accurate risk measure forecasts compared to\nunivariate ones.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jun 2021 17:24:40 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Merlo", "Luca", ""], ["Petrella", "Lea", ""], ["Raponi", "Valentina", ""]]}, {"id": "2106.08778", "submitter": "Fabio Caccioli", "authors": "Isobel Seabrook, Fabio Caccioli, Tomaso Aste", "title": "An Information Filtering approach to stress testing: an application to\n  FTSE markets", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel methodology to quantify the \"impact\" of and \"response\" to\nmarket shocks. We apply shocks to a group of stocks in a part of the market,\nand we quantify the effects in terms of average losses on another part of the\nmarket using a sparse probabilistic elliptical model for the multivariate\nreturn distribution of the whole market. Sparsity is introduced with an\n$L_0$-norm regularization, which forces to zero some elements of the inverse\ncovariance according to a dependency structure inferred from an information\nfiltering network. Our study concerns the FTSE 100 and 250 markets and analyzes\nimpact and response to shocks both applied to and received from individual\nstocks and group of stocks. We observe that the shock pattern is related to the\nstructure of the network associated with the sparse structure of the inverse\ncovariance of stock returns. Central sectors appear more likely to be affected\nby shocks, and stocks with a large level of underlying diversification have a\nlarger impact on the rest of the market when experiencing shocks. By analyzing\nthe system during times of crisis and comparative market calmness, we observe\nchanges in the shock patterns with a convergent behavior in times of crisis.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 13:38:35 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Seabrook", "Isobel", ""], ["Caccioli", "Fabio", ""], ["Aste", "Tomaso", ""]]}, {"id": "2106.10024", "submitter": "Thorsten Schmidt", "authors": "Eva L\\\"utkebohmert, Thorsten Schmidt, Julian Sester", "title": "Robust deep hedging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR q-fin.CP q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study pricing and hedging under parameter uncertainty for a class of\nMarkov processes which we call generalized affine processes and which includes\nthe Black-Scholes model as well as the constant elasticity of variance (CEV)\nmodel as special cases. Based on a general dynamic programming principle, we\nare able to link the associated nonlinear expectation to a variational form of\nthe Kolmogorov equation which opens the door for fast numerical pricing in the\nrobust framework.\n  The main novelty of the paper is that we propose a deep hedging approach\nwhich efficiently solves the hedging problem under parameter uncertainty. We\nnumerically evaluate this method on simulated and real data and show that the\nrobust deep hedging outperforms existing hedging approaches, in particular in\nhighly volatile periods.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 09:54:31 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["L\u00fctkebohmert", "Eva", ""], ["Schmidt", "Thorsten", ""], ["Sester", "Julian", ""]]}, {"id": "2106.10030", "submitter": "Alex Garivaltis", "authors": "Alex Garivaltis", "title": "Universal Risk Budgeting", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM econ.TH q-fin.CP q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I juxtapose Cover's vaunted universal portfolio selection algorithm (Cover\n1991) with the modern representation (Qian 2016; Roncalli 2013) of a portfolio\nas a certain allocation of risk among the available assets, rather than a mere\nallocation of capital. Thus, I define a Universal Risk Budgeting scheme that\nweights each risk budget (instead of each capital budget) by its historical\nperformance record (a la Cover). I prove that my scheme is mathematically\nequivalent to a novel type of Cover and Ordentlich 1996 universal portfolio\nthat uses a new family of prior densities that have hitherto not appeared in\nthe literature on universal portfolio theory. I argue that my universal risk\nbudget, so-defined, is a potentially more perspicuous and flexible type of\nuniversal portfolio; it allows the algorithmic trader to incorporate, with\nadvantage, his prior knowledge (or beliefs) about the particular covariance\nstructure of instantaneous asset returns. Say, if there is some dispersion in\nthe volatilities of the available assets, then the uniform (or Dirichlet)\npriors that are standard in the literature will generate a dangerously lopsided\nprior distribution over the possible risk budgets. In the author's opinion, the\nproposed \"Garivaltis prior\" makes for a nice improvement on Cover's timeless\nexpert system (Cover 1991), that is properly agnostic and open (from the very\nget-go) to different risk budgets. Inspired by Jamshidian 1992, the universal\nrisk budget is formulated as a new kind of exotic option in the continuous time\nBlack and Scholes 1973 market, with all the pleasure, elegance, and convenience\nthat that entails.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jun 2021 10:06:02 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Garivaltis", "Alex", ""]]}, {"id": "2106.10236", "submitter": "Anand Deo", "authors": "Anand Deo, Karthyek Murthy", "title": "Efficient Black-Box Importance Sampling for VaR and CVaR Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.LG math.PR stat.AP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers Importance Sampling (IS) for the estimation of tail\nrisks of a loss defined in terms of a sophisticated object such as a machine\nlearning feature map or a mixed integer linear optimisation formulation.\nAssuming only black-box access to the loss and the distribution of the\nunderlying random vector, the paper presents an efficient IS algorithm for\nestimating the Value at Risk and Conditional Value at Risk. The key challenge\nin any IS procedure, namely, identifying an appropriate change-of-measure, is\nautomated with a self-structuring IS transformation that learns and replicates\nthe concentration properties of the conditional excess from less rare samples.\nThe resulting estimators enjoy asymptotically optimal variance reduction when\nviewed in the logarithmic scale. Simulation experiments highlight the efficacy\nand practicality of the proposed scheme\n", "versions": [{"version": "v1", "created": "Wed, 16 Jun 2021 01:29:11 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Deo", "Anand", ""], ["Murthy", "Karthyek", ""]]}, {"id": "2106.12431", "submitter": "Stefano Scoleri", "authors": "Andrea Maran, Andrea Pallavicini and Stefano Scoleri", "title": "Chebyshev Greeks: Smoothing Gamma without Bias", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP q-fin.MF q-fin.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of Greeks is a fundamental task for risk managing of\nfinancial instruments. The standard approach to their numerical evaluation is\nvia finite differences. Most exotic derivatives are priced via Monte Carlo\nsimulation: in these cases, it is hard to find a fast and accurate\napproximation of Greeks, mainly because of the need of a tradeoff between bias\nand variance. Recent improvements in Greeks computation, such as Adjoint\nAlgorithmic Differentiation, are unfortunately uneffective on second order\nGreeks (such as Gamma), which are plagued by the most significant\ninstabilities, so that a viable alternative to standard finite differences is\nstill lacking. We apply Chebyshev interpolation techniques to the computation\nof spot Greeks, showing how to improve the stability of finite difference\nGreeks of arbitrary order, in a simple and general way. The increased\nperformance of the proposed technique is analyzed for a number of real payoffs\ncommonly traded by financial institutions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 14:35:48 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Maran", "Andrea", ""], ["Pallavicini", "Andrea", ""], ["Scoleri", "Stefano", ""]]}, {"id": "2106.14168", "submitter": "Hai-Chuan Xu", "authors": "William A. Barnett, Xue Wang, Hai-Chuan Xu and Wei-Xing Zhou", "title": "Hierarchical contagions in the interdependent financial network", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We model hierarchical cascades of failures among banks linked through an\ninterdependent network. The interaction among banks include not only direct\ncross-holding, but also indirect dependency by holding mutual assets outside\nthe banking system. Using data extracted from the European Banking Authority,\nwe present the interdependency network composed of 48 banks and 21 asset\nclasses. Since interbank exposures are not public, we first reconstruct the\nasset/liability cross-holding network using the aggregated claims. For the\nrobustness, we employ three reconstruction methods, called $\\textit{Anan}$,\n$\\textit{Ha\\l{}a}$ and $\\textit{Maxe}$. Then we combine the external portfolio\nholdings of each bank to compute the interdependency matrix. The\ninterdependency network is much denser than the direct cross-holding network,\nshowing the complex latent interaction among banks. Finally, we perform\nmacroprudential stress tests for the European banking system, using the adverse\nscenario in EBA stress test as the initial shock. For different reconstructed\nnetworks, we illustrate the hierarchical cascades and show that the failure\nhierarchies are roughly the same except for a few banks, reflecting the\noverlapping portfolio holding accounts for the majority of defaults.\nUnderstanding the interdependency network and the hierarchy of the cascades\nshould help to improve policy intervention and implement rescue strategy.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jun 2021 08:25:11 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Barnett", "William A.", ""], ["Wang", "Xue", ""], ["Xu", "Hai-Chuan", ""], ["Zhou", "Wei-Xing", ""]]}, {"id": "2106.14404", "submitter": "Andreas Aigner", "authors": "Andreas A. Aigner and Gurvinder Dhaliwal", "title": "UNISWAP: Impermanent Loss and Risk Profile of a Liquidity Provider", "comments": "16 pages, 8 Figures, 1 Table", "journal-ref": null, "doi": "10.13140/RG.2.2.32419.58400/6", "report-no": null, "categories": "q-fin.TR q-fin.CP q-fin.GN q-fin.PM q-fin.RM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Uniswap is a decentralized exchange (DEX) and was first launched on November\n2, 2018 on the Ethereum mainnet [1] and is part of an Ecosystem of products in\nDecentralized Finance (DeFi). It replaces a traditional order book type of\ntrading common on centralized exchanges (CEX) with a deterministic model that\nswaps currencies (or tokens/assets) along a fixed price function determined by\nthe amount of currencies supplied by the liquidity providers. Liquidity\nproviders can be regarded as investors in the decentralized exchange and earn\nfixed commissions per trade. They lock up funds in liquidity pools for distinct\npairs of currencies allowing market participants to swap them using the fixed\nprice function. Liquidity providers take on market risk as a liquidity provider\nin exchange for earning commissions on each trade. Here we analyze the risk\nprofile of a liquidity provider and the so called impermanent (unrealized) loss\nin particular. We provide an improved version of the commonly denoted\nimpermanent loss function for Uniswap v2 on the semi-infinite domain. The\ndifferences between Uniswap v2 and v3 are also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 05:38:51 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Aigner", "Andreas A.", ""], ["Dhaliwal", "Gurvinder", ""]]}, {"id": "2106.14824", "submitter": "Akif Ince", "authors": "Akif Ince, Ilaria Peri, Silvana Pesenti", "title": "Risk contributions of lambda quantiles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Risk contributions of portfolios form an indispensable part of risk adjusted\nperformance measurement. The risk contribution of a portfolio, e.g., in the\nEuler or Aumann-Shapley framework, is given by the partial derivatives of a\nrisk measure applied to the portfolio return in direction of the asset weights.\nFor risk measures that are not positively homogeneous of degree 1, however,\nknown capital allocation principles do not apply. We study the class of lambda\nquantile risk measures, that includes the well-known Value-at-Risk as a special\ncase, but for which no known allocation rule is applicable. We prove\ndifferentiability and derive explicit formulae of the derivatives of lambda\nquantiles with respect to their portfolio composition, that is their risk\ncontribution. For this purpose, we define lambda quantiles on the space of\nportfolio compositions and consider generic (also non-linear) portfolio\noperators.\n  We further derive the Euler decomposition of lambda quantiles for generic\nportfolios and show that lambda quantiles are homogeneous in the space of\nportfolio compositions, with a homogeneity degree that depends on the portfolio\ncomposition and the lambda function. This result is in stark contrast to the\npositive homogeneity properties of risk measures defined on the space of random\nvariables which admit a constant homogeneity degree. We introduce a generalised\nversion of Euler contributions and Euler allocation rule, which are compatible\nwith risk measures of any homogeneity degree and non-linear portfolios. We\nfurther provide financial interpretations of the homogeneity degree of lambda\nquantiles and introduce the notion of event-specific homogeneity of portfolio\noperators.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jun 2021 16:01:38 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Ince", "Akif", ""], ["Peri", "Ilaria", ""], ["Pesenti", "Silvana", ""]]}, {"id": "2106.15466", "submitter": "\\\"Ozge Sahin", "authors": "\\\"Ozge Sahin, Karoline Bax, Sandra Paterlini, Claudia Czado", "title": "ESGM: ESG scores and the Missing pillar", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environmental, social, and governance (ESG) scores measure companies'\nactivities concerning sustainability and societal impact and are organized on\nthree pillars: Environmental (E-), Social (S-), and Governance (G-). Different\napproaches have been proposed to compute ESG scores for companies, which\ntypically rely on the aggregation of many and different sources of information.\nThese complementary non-financial ESG scores should provide information about\nthe ESG performance and risks of different companies. However, the extent of\nmissing information makes the reliability of ESG scores questionable. To\naccount for the missing information in the underlying ESG pillars, we introduce\na new pillar, the so-called Missing (M-) pillar, and propose an optimization\napproach to compute new ESG (ESGM) scores, which should also be related to the\ncompany riskiness. As a result, the ESGM scores allow for incorporating the\nextent of missing information and establishing some meaningful relationship\nwith respect to the riskiness of the companies under consideration. Interesting\ninsights into the current limitations of ESG scoring methodology are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 14:52:51 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Sahin", "\u00d6zge", ""], ["Bax", "Karoline", ""], ["Paterlini", "Sandra", ""], ["Czado", "Claudia", ""]]}]