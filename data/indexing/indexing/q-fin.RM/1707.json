[{"id": "1707.00757", "submitter": "Jinglun Yao", "authors": "Jinglun Yao, Maxime Levy-Chapira, Mamikon Margaryan", "title": "Checking account activity and credit default risk of enterprises: An\n  application of statistical learning methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.RM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The existence of asymmetric information has always been a major concern for\nfinancial institutions. Financial intermediaries such as commercial banks need\nto study the quality of potential borrowers in order to make their decision on\ncorporate loans. Classical methods model the default probability by financial\nratios using the logistic regression. As one of the major commercial banks in\nFrance, we have access to the the account activities of corporate clients. We\nshow that this transactional data outperforms classical financial ratios in\npredicting the default event. As the new data reflects the real time status of\ncash flow, this result confirms our intuition that liquidity plays an important\nrole in the phenomenon of default. Moreover, the two data sets are\nsupplementary to each other to a certain extent: the merged data has a better\nprediction power than each individual data. We have adopted some advanced\nmachine learning methods and analyzed their characteristics. The correct use of\nthese methods helps us to acquire a deeper understanding of the role of central\nfactors in the phenomenon of default, such as credit line violations and cash\ninflows.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 21:03:41 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Yao", "Jinglun", ""], ["Levy-Chapira", "Maxime", ""], ["Margaryan", "Mamikon", ""]]}, {"id": "1707.00917", "submitter": "Olena Ragulina", "authors": "Olena Ragulina", "title": "Bonus--malus systems with different claim types and varying deductibles", "comments": "Published at http://dx.doi.org/10.15559/17-VMSTA80 in the Modern\n  Stochastics: Theory and Applications (https://www.i-journals.org/vtxpp/VMSTA)\n  by VTeX (http://www.vtex.lt/)", "journal-ref": "Modern Stochastics: Theory and Applications 2017, Vol. 4, No. 2,\n  141-159", "doi": "10.15559/17-VMSTA80", "report-no": "VTeX-VMSTA-VMSTA80", "categories": "q-fin.RM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper deals with bonus-malus systems with different claim types and\nvarying deductibles. The premium relativities are softened for the\npolicyholders who are in the malus zone and these policyholders are subject to\nper claim deductibles depending on their levels in the bonus-malus scale and\nthe types of the reported claims. We introduce such bonus-malus systems and\nstudy their basic properties. In particular, we investigate when it is possible\nto introduce varying deductibles, what restrictions we have and how we can do\nthis. Moreover, we deal with the special case where varying deductibles are\napplied to the claims reported by policyholders occupying the highest level in\nthe bonus-malus scale and consider two allocation principles for the\ndeductibles. Finally, numerical illustrations are presented.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 11:25:54 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Ragulina", "Olena", ""]]}, {"id": "1707.01370", "submitter": "Nassim Nicholas Taleb", "authors": "Andrea Fontanari, Nassim Nicholas Taleb, Pasquale Cirillo", "title": "Gini estimation under infinite variance", "comments": null, "journal-ref": "Physica A: Statistical Mechanics and its Applications 502,\n  256-269, 2018", "doi": "10.1016/j.physa.2018.02.102", "report-no": null, "categories": "stat.ME q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problems related to the estimation of the Gini index in presence\nof a fat-tailed data generating process, i.e. one in the stable distribution\nclass with finite mean but infinite variance (i.e. with tail index\n$\\alpha\\in(1,2)$). We show that, in such a case, the Gini coefficient cannot be\nreliably estimated using conventional nonparametric methods, because of a\ndownward bias that emerges under fat tails. This has important implications for\nthe ongoing discussion about economic inequality.\n  We start by discussing how the nonparametric estimator of the Gini index\nundergoes a phase transition in the symmetry structure of its asymptotic\ndistribution, as the data distribution shifts from the domain of attraction of\na light-tailed distribution to that of a fat-tailed one, especially in the case\nof infinite variance. We also show how the nonparametric Gini bias increases\nwith lower values of $\\alpha$. We then prove that maximum likelihood estimation\noutperforms nonparametric methods, requiring a much smaller sample size to\nreach efficiency.\n  Finally, for fat-tailed data, we provide a simple correction mechanism to the\nsmall sample bias of the nonparametric estimator based on the distance between\nthe mode and the mean of its asymptotic distribution.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 12:46:35 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 11:40:38 GMT"}, {"version": "v3", "created": "Mon, 17 Jul 2017 21:38:37 GMT"}, {"version": "v4", "created": "Sun, 17 Dec 2017 23:17:47 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Fontanari", "Andrea", ""], ["Taleb", "Nassim Nicholas", ""], ["Cirillo", "Pasquale", ""]]}, {"id": "1707.02087", "submitter": "Mikhail E Semenov", "authors": "Margarita E. Fatyanova, Mikhail E. Semenov", "title": "Model for Constructing an Options Portfolio with a Certain Payoff\n  Function", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The portfolio optimization problem is a basic problem of financial analysis.\nIn the study, an optimization model for constructing an options portfolio with\na certain payoff function has been proposed. The model is formulated as an\ninteger linear programming problem and includes an objective payoff function\nand a system of constraints. In order to demonstrate the performance of the\nproposed model, we have constructed the portfolio on the European call and put\noptions of Taiwan Futures Exchange. The optimum solution was obtained using the\nMATLAB software. Our approach is quite general and has the potential to design\noptions portfolios on financial markets.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 09:12:06 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Fatyanova", "Margarita E.", ""], ["Semenov", "Mikhail E.", ""]]}, {"id": "1707.02587", "submitter": "Wilson Ye Chen", "authors": "Wilson Ye Chen, Gareth W. Peters, Richard H. Gerlach, Scott A. Sisson", "title": "Dynamic Quantile Function Models", "comments": "MATLAB code: https://github.com/wilson-ye-chen/aqua", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the need for effectively summarising, modelling, and forecasting\nthe distributional characteristics of intra-daily returns, as well as the\nrecent work on forecasting histogram-valued time-series in the area of symbolic\ndata analysis, we develop a time-series model for forecasting\nquantile-function-valued (QF-valued) daily summaries for intra-daily returns.\nWe call this model the dynamic quantile function (DQF) model. Instead of a\nhistogram, we propose to use a $g$-and-$h$ quantile function to summarise the\ndistribution of intra-daily returns. We work with a Bayesian formulation of the\nDQF model in order to make statistical inference while accounting for parameter\nuncertainty; an efficient MCMC algorithm is developed for sampling-based\nposterior inference. Using ten international market indices and approximately\n2,000 days of out-of-sample data from each market, the performance of the DQF\nmodel compares favourably, in terms of forecasting VaR of intra-daily returns,\nagainst the interval-valued and histogram-valued time-series models.\nAdditionally, we demonstrate that the QF-valued forecasts can be used to\nforecast VaR measures at the daily timescale via a simple quantile regression\nmodel on daily returns (QR-DQF). In certain markets, the resulting QR-DQF model\nis able to provide competitive VaR forecasts for daily returns.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 14:31:09 GMT"}, {"version": "v2", "created": "Mon, 4 Sep 2017 07:19:26 GMT"}, {"version": "v3", "created": "Tue, 5 Sep 2017 05:59:04 GMT"}, {"version": "v4", "created": "Fri, 22 Nov 2019 03:49:30 GMT"}, {"version": "v5", "created": "Tue, 4 May 2021 15:24:03 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Chen", "Wilson Ye", ""], ["Peters", "Gareth W.", ""], ["Gerlach", "Richard H.", ""], ["Sisson", "Scott A.", ""]]}, {"id": "1707.03391", "submitter": "William Guevara-Alarc\\'on", "authors": "William Guevara-Alarc\\'on, Luz Mery Gonz\\'alez and Armando Antonio\n  Zarruk", "title": "The partial damage loss cover ratemaking of the automobile insurance\n  using generalized linear models", "comments": "in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is illustrated a methodology to compute the pure premium for the\nautomobile insurance (claim frequency and severity) using generalized linear\nmodels. It is obtained the pure premium for the partial damage loss cover (PPD)\nusing a set of automobile insurance policies with an exposition of a year. It\nis found that the most influential variables in the claim frequency are the car\nproduction year, the insured's age, and the region's subscription policy and\nthe most influential variables in the claim severity are the car's value, type\nand make and the insured's gender.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 08:11:41 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Guevara-Alarc\u00f3n", "William", ""], ["Gonz\u00e1lez", "Luz Mery", ""], ["Zarruk", "Armando Antonio", ""]]}, {"id": "1707.03500", "submitter": "Delfim F. M. Torres", "authors": "Olena Kostylenko, Helena Sofia Rodrigues, Delfim F. M. Torres", "title": "Banking risk as an epidemiological model: an optimal control approach", "comments": "This is a preprint of a paper whose final and definite form is in\n  'Operational Research', Springer Proceedings in Mathematics & Statistics,\n  available at [http://www.springer.com/series/10533]. Paper Submitted\n  23/March/17; Revised 29/May/17; Accepted 11/July/2017", "journal-ref": "Springer Proc. Math. Stat. 223 (2018), 165--176", "doi": "10.1007/978-3-319-71583-4_12", "report-no": null, "categories": "math.OC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of contagiousness spread modelling is well-known in epidemiology.\nHowever, the application of spread modelling to banking market is quite recent.\nIn this work, we present a system of ordinary differential equations,\nsimulating data from the largest European banks. Then, an optimal control\nproblem is formulated in order to study the impact of a possible measure of the\nCentral Bank in the economy. The proposed approach enables qualitative\nspecifications of contagion in banking obtainment and an adequate analysis and\nprognosis within the financial sector development and macroeconomic as a whole.\nWe show that our model describes well the reality of the largest European\nbanks. Simulations were done using MATLAB and BOCOP optimal control solver, and\nthe main results are taken for three distinct scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 23:54:32 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Kostylenko", "Olena", ""], ["Rodrigues", "Helena Sofia", ""], ["Torres", "Delfim F. M.", ""]]}, {"id": "1707.03516", "submitter": "Mikhail E Semenov", "authors": "Mikhail Semenov, Daulet Smagulov", "title": "Portfolio Risk Assessment using Copula Models", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we use and investigate copulas models to represent multivariate\ndependence in financial time series. We propose the algorithm of risk measure\ncomputation using copula models. Using the optimal mean-$CVaR$ portfolio we\ncompute portfolio's Profit and Loss series and corresponded risk measures\ncurves. Value-at-risk and Conditional-Value-at-risk curves were simulated by\nthree copula models: full Gaussian, Student's $t$ and regular vine copula.\nThese risk curves are lower than historical values of the risk measures curve.\nAll three models have superior prediction ability than a usual empirical\nmethod. Further directions of research are described.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 02:05:27 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Semenov", "Mikhail", ""], ["Smagulov", "Daulet", ""]]}, {"id": "1707.03542", "submitter": "Andrey Sarantsev Mr", "authors": "Aditya Maheshwari, Andrey Sarantsev", "title": "Modeling Financial System with Interbank Flows, Borrowing, and Investing", "comments": "27 pages, 29 figures. Keywords: systemic risk, stochastic control,\n  principal-agent problem, stationary distribution, stochastic stability,\n  Lyapunov function", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our model, private actors with interbank cash flows similar to, but nore\ngeneral than (Carmona, Fouque, Sun, 2013) borrow from the outside economy at a\ncertain interest rate, controlled by the central bank, and invest in risky\nassets. Each private actor aims to maximize its expected terminal logarithmic\nutility. The central bank, in turn, aims to control the overall economy by\nmeans of an exponential utility function. We solve all stochastic optimal\ncontrol problems explicitly. We are able to recreate occasions such as\nliquidity trap. We study distribution of the number of defaults (net worth of a\nprivate actor going below a certain threshold).\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 05:06:37 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 21:42:12 GMT"}, {"version": "v3", "created": "Tue, 20 Feb 2018 20:55:26 GMT"}, {"version": "v4", "created": "Fri, 5 Oct 2018 21:50:19 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Maheshwari", "Aditya", ""], ["Sarantsev", "Andrey", ""]]}, {"id": "1707.03715", "submitter": "Chao Wang Dr", "authors": "Chao Wang (1), Qian Chen (2), Richard Gerlach (1) ((1) Discipline of\n  Business Analytics, The University of Sydney, (2) HSBC Business School,\n  Peking University)", "title": "Bayesian Realized-GARCH Models for Financial Tail Risk Forecasting\n  Incorporating Two-sided Weibull Distribution", "comments": "33 pages, 5 figures, 8 tables. arXiv admin note: substantial text\n  overlap with arXiv:1612.08488", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The realized GARCH framework is extended to incorporate the two-sided Weibull\ndistribution, for the purpose of volatility and tail risk forecasting in a\nfinancial time series. Further, the realized range, as a competitor for\nrealized variance or daily returns, is employed in the realized GARCH\nframework. Further, sub-sampling and scaling methods are applied to both the\nrealized range and realized variance, to help deal with inherent\nmicro-structure noise and inefficiency. An adaptive Bayesian Markov Chain Monte\nCarlo method is developed and employed for estimation and forecasting, whose\nproperties are assessed and compared with maximum likelihood, via a simulation\nstudy. Compared to a range of well-known parametric GARCH, GARCH with two-sided\nWeibull distribution and realized GARCH models, tail risk forecasting results\nacross 7 market index return series and 2 individual assets clearly favor the\nrealized GARCH models incorporating two-sided Weibull distribution, especially\nmodels employing the sub-sampled realized variance and sub-sampled realized\nrange, over a six year period that includes the global financial crisis.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 07:25:10 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Wang", "Chao", ""], ["Chen", "Qian", ""], ["Gerlach", "Richard", ""]]}, {"id": "1707.04831", "submitter": "Xiaojiao Yu", "authors": "Xiaojiao Yu", "title": "Machine learning application in online lending risk prediction", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Online leading has disrupted the traditional consumer banking sector with\nmore effective loan processing. Risk prediction and monitoring is critical for\nthe success of the business model. Traditional credit score models fall short\nin applying big data technology in building risk model. In this manuscript,\ndata with various format and size were collected from public website,\nthird-parties and assembled with client's loan application information data.\nEnsemble machine learning models, random forest model and XGBoost model, were\nbuilt and trained with the historical transaction data and subsequently tested\nwith separate data. XGBoost model shows higher K-S value, suggesting better\nclassification capability in this task. Top 10 important features from the two\nmodels suggest external data such as zhimaScore, multi-platform stacking loans\ninformation, and social network information are important factors in predicting\nloan default probability.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 06:56:28 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Yu", "Xiaojiao", ""]]}, {"id": "1707.05108", "submitter": "Johanna F. Ziegel", "authors": "Andrew J. Patton and Johanna F. Ziegel and Rui Chen", "title": "Dynamic Semiparametric Models for Expected Shortfall (and Value-at-Risk)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expected Shortfall (ES) is the average return on a risky asset conditional on\nthe return being below some quantile of its distribution, namely its\nValue-at-Risk (VaR). The Basel III Accord, which will be implemented in the\nyears leading up to 2019, places new attention on ES, but unlike VaR, there is\nlittle existing work on modeling ES. We use recent results from statistical\ndecision theory to overcome the problem of \"elicitability\" for ES by jointly\nmodelling ES and VaR, and propose new dynamic models for these risk measures.\nWe provide estimation and inference methods for the proposed models, and\nconfirm via simulation studies that the methods have good finite-sample\nproperties. We apply these models to daily returns on four international equity\nindices, and find the proposed new ES-VaR models outperform forecasts based on\nGARCH or rolling window models.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 11:37:54 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Patton", "Andrew J.", ""], ["Ziegel", "Johanna F.", ""], ["Chen", "Rui", ""]]}, {"id": "1707.05596", "submitter": "Xianhua Peng", "authors": "Xue Dong He, Xianhua Peng", "title": "Surplus-Invariant, Law-Invariant, and Conic Acceptance Sets Must be the\n  Sets Induced by Value-at-Risk", "comments": "20 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.GN q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The regulator is interested in proposing a capital adequacy test by\nspecifying an acceptance set for firms' capital positions at the end of a given\nperiod. This set needs to be surplus-invariant, i.e., not to depend on the\nsurplus of firms' shareholders, because the test means to protect firms'\nliability holders. We prove that any surplus-invariant, law-invariant, and\nconic acceptance set must be the set of capital positions whose value-at-risk\nat a given level is less than zero. The result still holds if we replace\nconicity with numeraire-invariance, a property stipulating that whether a firm\npasses the test should not depend on the currency used to denominate its\nassets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 13:07:01 GMT"}, {"version": "v2", "created": "Tue, 23 Jan 2018 09:20:15 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["He", "Xue Dong", ""], ["Peng", "Xianhua", ""]]}, {"id": "1707.07322", "submitter": "Mohammed Berkhouch", "authors": "Mohammed Berkhouch, Ghizlane Lakhnati, Marcelo Brutti Righi", "title": "Extended Gini-type measures of risk and variability", "comments": "This is a working paper consisting of 20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to introduce a risk measure that extends the\nGini-type measures of risk and variability, the Extended Gini Shortfall, by\ntaking risk aversion into consideration. Our risk measure is coherent and\ncatches variability, an important concept for risk management. The analysis is\nmade under the Choquet integral representations framework. We expose results\nfor analytic computation under well-known distribution functions. Furthermore,\nwe provide a practical application.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jul 2017 17:06:58 GMT"}, {"version": "v2", "created": "Tue, 20 Mar 2018 14:52:32 GMT"}], "update_date": "2018-03-21", "authors_parsed": [["Berkhouch", "Mohammed", ""], ["Lakhnati", "Ghizlane", ""], ["Righi", "Marcelo Brutti", ""]]}, {"id": "1707.09037", "submitter": "Thomas Sch\\\"urmann", "authors": "Thomas Sch\\\"urmann and Ingo Hoffmann", "title": "On Biased Correlation Estimation", "comments": "5 pages, 6 figures, working paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST math.ST physics.data-an q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, underestimation of risk is something which should be avoided as\nfar as possible. Especially in financial asset management, equity risk is\ntypically characterized by the measure of portfolio variance, or indirectly by\nquantities which are derived from it. Since there is a linear dependency of the\nvariance and the empirical correlation between asset classes, one is compelled\nto control or to avoid the possibility of underestimating correlation\ncoefficients. In the present approach, we formalize common practice and\nclassify these approaches by computing their probability of underestimation. In\naddition, we introduce a new estimator which is characterized by having the\nadvantage of a constant and controllable probability of underestimation. We\nprove that the new estimator is statistically consistent.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 18:18:42 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Sch\u00fcrmann", "Thomas", ""], ["Hoffmann", "Ingo", ""]]}, {"id": "1707.09829", "submitter": "Marcelo Righi", "authors": "Marcelo Brutti Righi, Fernanda Maria M\\\"uller and Marlon Ruoso Moresco", "title": "On a robust risk measurement approach for capital determination errors\n  minimization", "comments": null, "journal-ref": "Insurance: Mathematics and Economics 95, 199-211 (2020)", "doi": "10.1016/j.insmatheco.2020.10.007", "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a robust risk measurement approach that minimizes the expectation\nof overestimation plus underestimation costs. We consider uncertainty by taking\nthe supremum over a collection of probability measures, relating our approach\nto dual sets in the representation of coherent risk measures. We provide\nresults that guarantee the existence of a solution and explore the properties\nof minimizer and minimum as risk and deviation measures, respectively. An\nempirical illustration is carried out to demonstrate the use of our approach in\ncapital determination.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 12:59:01 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 13:38:13 GMT"}, {"version": "v3", "created": "Wed, 2 Oct 2019 00:06:23 GMT"}, {"version": "v4", "created": "Mon, 26 Oct 2020 12:36:38 GMT"}], "update_date": "2020-10-27", "authors_parsed": [["Righi", "Marcelo Brutti", ""], ["M\u00fcller", "Fernanda Maria", ""], ["Moresco", "Marlon Ruoso", ""]]}]