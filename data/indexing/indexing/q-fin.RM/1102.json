[{"id": "1102.0938", "submitter": "Ola Mahmoud", "authors": "Lisa R. Goldberg, Michael Y. Hayes, Ola Mahmoud", "title": "Minimizing Shortfall", "comments": null, "journal-ref": "Quantitative Finance, iFirst, 1-13, 2012", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an empirical study of shortfall optimization with Barra\nExtreme Risk. We compare minimum shortfall to minimum variance portfolios in\nthe US, UK, and Japanese equity markets using Barra Style Factors (Value,\nGrowth, Momentum, etc.). We show that minimizing shortfall generally improves\nperformance over minimizing variance, especially during down-markets, over the\nperiod 1985-2010. The outperformance of shortfall is due to intuitive tilts\ntowards protective factors like Value, and away from aggressive factors like\nGrowth and Momentum. The outperformance is largest for the shortfall that\nmeasures overall asymmetry rather than the extreme losses.\n", "versions": [{"version": "v1", "created": "Fri, 4 Feb 2011 15:24:01 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2013 18:41:56 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Goldberg", "Lisa R.", ""], ["Hayes", "Michael Y.", ""], ["Mahmoud", "Ola", ""]]}, {"id": "1102.3150", "submitter": "Rudi Schaefer", "authors": "Rudi Sch\\\"afer and Alexander F. R. Koivusalo", "title": "Dependence of defaults and recoveries in structural credit risk models", "comments": "19 pages, 11 figures", "journal-ref": "Economic Modelling 30 (2013) 1-9", "doi": "10.1016/j.econmod.2012.08.033", "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current research on credit risk is primarily focused on modeling default\nprobabilities. Recovery rates are often treated as an afterthought; they are\nmodeled independently, in many cases they are even assumed constant. This is\ndespite of their pronounced effect on the tail of the loss distribution. Here,\nwe take a step back, historically, and start again from the Merton model, where\ndefaults and recoveries are both determined by an underlying process. Hence,\nthey are intrinsically connected. For the diffusion process, we can derive the\nfunctional relation between expected recovery rate and default probability.\nThis relation depends on a single parameter only. In Monte Carlo simulations we\nfind that the same functional dependence also holds for jump-diffusion and\nGARCH processes. We discuss how to incorporate this structural recovery rate\ninto reduced form models, in order to restore essential structural information\nwhich is usually neglected in the reduced-form approach.\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 18:30:47 GMT"}, {"version": "v2", "created": "Wed, 30 Mar 2011 09:23:34 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Sch\u00e4fer", "Rudi", ""], ["Koivusalo", "Alexander F. R.", ""]]}, {"id": "1102.3534", "submitter": "Alberto Elices", "authors": "Alberto Elices and Eduard Gim\\'enez", "title": "Applying hedging strategies to estimate model risk and provision\n  calculation", "comments": "32 pages, 9 figures, accepted for publication in Quantitative Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a relative model risk measure of a product priced with\na given model, with respect to another reference model for which the market is\nassumed to be driven. This measure allows comparing products valued with\ndifferent models (pricing hypothesis) under a homogeneous framework which\nallows concluding which model is the closest to the reference. The relative\nmodel risk measure is defined as the expected shortfall of the hedging strategy\nat a given time horizon for a chosen significance level. The reference model\nhas been chosen to be Heston calibrated to market for a given time horizon\n(this reference model should be chosen to be a market proxy). The method is\napplied to estimate and compare this relative model risk measure under\nvolga-vanna and Black-Scholes models for double-no-touch options and a\nportfolio of forward fader options.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 09:30:33 GMT"}, {"version": "v2", "created": "Fri, 12 Oct 2012 23:26:54 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Elices", "Alberto", ""], ["Gim\u00e9nez", "Eduard", ""]]}, {"id": "1102.3582", "submitter": "Gareth Peters Dr", "authors": "Gareth W. Peters, Pavel Shevchenko, Mark Young, Wendy Yip", "title": "Analytic Loss Distributional Approach Model for Operational Risk from\n  the alpha-Stable Doubly Stochastic Compound Processes and Implications for\n  Capital Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the Basel II standards, the Operational Risk (OpRisk) advanced\nmeasurement approach is not prescriptive regarding the class of statistical\nmodel utilised to undertake capital estimation. It has however become well\naccepted to utlise a Loss Distributional Approach (LDA) paradigm to model the\nindividual OpRisk loss process corresponding to the Basel II Business\nline/event type. In this paper we derive a novel class of doubly stochastic\nalpha-stable family LDA models. These models provide the ability to capture the\nheavy tailed loss process typical of OpRisk whilst also providing analytic\nexpressions for the compound process annual loss density and distributions as\nwell as the aggregated compound process annual loss models. In particular we\ndevelop models of the annual loss process in two scenarios. The first scenario\nconsiders the loss process with a stochastic intensity parameter, resulting in\nan inhomogeneous compound Poisson processes annually. The resulting arrival\nprocess of losses under such a model will have independent counts over\nincrements within the year. The second scenario considers discretization of the\nannual loss process into monthly increments with dependent time increments as\ncaptured by a Binomial process with a stochastic probability of success\nchanging annually. Each of these models will be coupled under an LDA framework\nwith heavy-tailed severity models comprised of $\\alpha$-stable severities for\nthe loss amounts per loss event. In this paper we will derive analytic results\nfor the annual loss distribution density and distribution under each of these\nmodels and study their properties.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 13:38:56 GMT"}], "update_date": "2011-02-18", "authors_parsed": [["Peters", "Gareth W.", ""], ["Shevchenko", "Pavel", ""], ["Young", "Mark", ""], ["Yip", "Wendy", ""]]}, {"id": "1102.3857", "submitter": "Hu Zhang", "authors": "Tzahi Yavin, Hu Zhang, Eugene Wang and Michael A. Clayton", "title": "Transition Probability Matrix Methodology for Incremental Risk Charge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As part of Basel II's incremental risk charge (IRC) methodology, this paper\nsummarizes our extensive investigations of constructing transition probability\nmatrices (TPMs) for unsecuritized credit products in the trading book. The\nobjective is to create monthly or quarterly TPMs with predefined sectors and\nratings that are consistent with the bank's Basel PDs. Constructing a TPM is\nnot a unique process. We highlight various aspects of three types of\nuncertainties embedded in different construction methods: 1) the available\nhistorical data and the bank's rating philosophy; 2) the merger of one-year\nBasel PD and the chosen Moody's TPMs; and 3) deriving a monthly or quarterly\nTPM when the generator matrix does not exist. Given the fact that TPMs and\nspecifically their PDs are the most important parameters in IRC, it is our view\nthat banks may need to make discretionary choices regarding their methodology,\nwith uncertainties well understood and managed.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 15:39:38 GMT"}], "update_date": "2011-02-21", "authors_parsed": [["Yavin", "Tzahi", ""], ["Zhang", "Hu", ""], ["Wang", "Eugene", ""], ["Clayton", "Michael A.", ""]]}, {"id": "1102.3900", "submitter": "Michael Christopher M\\\"unnix", "authors": "Michael C. M\\\"unnix, Rudi Sch\\\"afer, Thomas Guhr", "title": "A Random Matrix Approach to Credit Risk", "comments": "Fully revised version; 15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We estimate generic statistical properties of a structural credit risk model\nby considering an ensemble of correlation matrices. This ensemble is set up by\nRandom Matrix Theory. We demonstrate analytically that the presence of\ncorrelations severely limits the effect of diversification in a credit\nportfolio if the correlations are not identically zero. The existence of\ncorrelations alters the tails of the loss distribution considerably, even if\ntheir average is zero. Under the assumption of randomly fluctuating\ncorrelations, a lower bound for the estimation of the loss distribution is\nprovided.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 20:12:24 GMT"}, {"version": "v2", "created": "Tue, 22 Feb 2011 13:07:31 GMT"}, {"version": "v3", "created": "Wed, 23 Mar 2011 23:00:48 GMT"}, {"version": "v4", "created": "Thu, 31 Mar 2011 23:26:58 GMT"}, {"version": "v5", "created": "Thu, 14 Apr 2011 12:53:12 GMT"}, {"version": "v6", "created": "Wed, 18 May 2011 17:24:39 GMT"}, {"version": "v7", "created": "Tue, 28 Jun 2011 13:33:22 GMT"}], "update_date": "2011-06-29", "authors_parsed": [["M\u00fcnnix", "Michael C.", ""], ["Sch\u00e4fer", "Rudi", ""], ["Guhr", "Thomas", ""]]}, {"id": "1102.3928", "submitter": "Michal Barski dr", "authors": "Micha{\\l} Barski", "title": "Integral representations of risk functions for basket derivatives", "comments": "25 pages", "journal-ref": "Applicationes Mathematicae, 2012, 39, 489-514", "doi": null, "report-no": null, "categories": "math.OC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The risk minimizing problem\n$\\mathbf{E}[l((H-X_T^{x,\\pi})^{+})]\\overset{\\pi}{\\longrightarrow}\\min$ in the\nmultidimensional Black-Scholes framework is studied. Specific formulas for the\nminimal risk function and the cost reduction function for basket derivatives\nare shown. Explicit integral representations for the risk functions for\n$l(x)=x$ and $l(x)=x^p$, with $p>1$ for digital, quantos, outperformance and\nspread options are derived.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 22:04:24 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 22:33:19 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Barski", "Micha\u0142", ""]]}, {"id": "1102.3956", "submitter": "Philippe Barbe", "authors": "Ph. Barbe (CNRS), W.P. McCormick (UGA)", "title": "Ruin probabilities in tough times - Part 2 - Heavy-traffic approximation\n  for fractionally differentiated random walks in the domain of attraction of a\n  nonGaussian stable distribution", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by applications to insurance mathematics, we prove some\nheavy-traffic limit theorems for processes which encompass the fractionally\ndifferentiated random walk as well as some FARIMA processes, when the\ninnovations are in the domain of attraction of a nonGaussian stable\ndistribution.\n", "versions": [{"version": "v1", "created": "Sat, 19 Feb 2011 03:38:54 GMT"}], "update_date": "2011-02-22", "authors_parsed": [["Barbe", "Ph.", "", "CNRS"], ["McCormick", "W. P.", "", "UGA"]]}, {"id": "1102.4055", "submitter": "Ronnie Loeffen", "authors": "Ronnie Loeffen, Irmina Czarna, Zbigniew Palmowski", "title": "Parisian ruin probability for spectrally negative L\\'{e}vy processes", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ404 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 2, 599-609", "doi": "10.3150/11-BEJ404", "report-no": "IMS-BEJ-BEJ404", "categories": "math.PR math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we give, for a spectrally negative Levy process, a compact\nformula for the Parisian ruin probability, which is defined by the probability\nthat the process exhibits an excursion below zero, with a length that exceeds a\ncertain fixed period r. The formula involves only the scale function of the\nspectrally negative Levy process and the distribution of the process at time r.\n", "versions": [{"version": "v1", "created": "Sun, 20 Feb 2011 09:33:00 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2013 06:36:31 GMT"}], "update_date": "2013-03-22", "authors_parsed": [["Loeffen", "Ronnie", ""], ["Czarna", "Irmina", ""], ["Palmowski", "Zbigniew", ""]]}, {"id": "1102.4132", "submitter": "Jinxia  Zhu", "authors": "Jinxia Zhu", "title": "Optimal dividend control for a generalized risk model with investment\n  incomes and debit interest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.SY q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates dividend optimization of an insurance corporation\nunder a more realistic model which takes into consideration refinancing or\ncapital injections. The model follows the compound Poisson framework with\ncredit interest for positive reserve, and debit interest for negative reserve.\nRuin occurs when the reserve drops below the critical value. The company\ncontrols the dividend pay-out dynamically with the objective to maximize the\nexpected total discounted dividends until ruin. We show that that the optimal\nstrategy is a band strategy and it is optimal to pay no dividends when the\nreserve is negative.\n", "versions": [{"version": "v1", "created": "Mon, 21 Feb 2011 05:00:59 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2011 03:37:33 GMT"}, {"version": "v3", "created": "Mon, 16 May 2011 00:56:06 GMT"}, {"version": "v4", "created": "Thu, 26 May 2011 06:28:28 GMT"}, {"version": "v5", "created": "Thu, 2 Jun 2011 06:07:19 GMT"}, {"version": "v6", "created": "Tue, 18 Sep 2012 02:59:31 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Zhu", "Jinxia", ""]]}, {"id": "1102.4489", "submitter": "Carmine De Franco", "authors": "Carmine De Franco and Peter Tankov", "title": "Portfolio Insurance under a risk-measure constraint", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of portfolio insurance from the point of view of a fund\nmanager, who guarantees to the investor that the portfolio value at maturity\nwill be above a fixed threshold. If, at maturity, the portfolio value is below\nthe guaranteed level, a third party will refund the investor up to the\nguarantee. In exchange for this protection, the third party imposes a limit on\nthe risk exposure of the fund manager, in the form of a convex monetary risk\nmeasure. The fund manager therefore tries to maximize the investor's utility\nfunction subject to the risk measure constraint.We give a full solution to this\nnonconvex optimization problem in the complete market setting and show in\nparticular that the choice of the risk measure is crucial for the optimal\nportfolio to exist. Explicit results are provided for the entropic risk measure\n(for which the optimal portfolio always exists) and for the class of spectral\nrisk measures (for which the optimal portfolio may fail to exist in some\ncases).\n", "versions": [{"version": "v1", "created": "Tue, 22 Feb 2011 12:43:24 GMT"}], "update_date": "2011-02-23", "authors_parsed": [["De Franco", "Carmine", ""], ["Tankov", "Peter", ""]]}, {"id": "1102.4864", "submitter": "Rudi Schaefer", "authors": "Alexander F. R. Koivusalo and Rudi Sch\\\"afer", "title": "Calibration of structural and reduced-form recovery models", "comments": "15 pages", "journal-ref": "Journal of Credit Risk 8(4), 31-51 (2012)", "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years research on credit risk modelling has mainly focused on\ndefault probabilities. Recovery rates are usually modelled independently, quite\noften they are even assumed constant. Then, however, the structural connection\nbetween recovery rates and default probabilities is lost and the tails of the\nloss distribution can be underestimated considerably. The problem of\nunderestimating tail losses becomes even more severe, when calibration issues\nare taken into account. To demonstrate this we choose a Merton-type structural\nmodel as our reference system. Diffusion and jump-diffusion are considered as\nunderlying processes. We run Monte Carlo simulations of this model and\ncalibrate different recovery models to the simulation data. For simplicity, we\ntake the default probabilities directly from the simulation data. We compare a\nreduced-form model for recoveries with a constant recovery approach. In\naddition, we consider a functional dependence between recovery rates and\ndefault probabilities. This dependence can be derived analytically for the\ndiffusion case. We find that the constant recovery approach drastically and\nsystematically underestimates the tail of the loss distribution. The\nreduced-form recovery model shows better results, when all simulation data is\nused for calibration. However, if we restrict the simulation data used for\ncalibration, the results for the reduced-form model deteriorate. We find the\nmost reliable and stable results, when we make use of the functional dependence\nbetween recovery rates and default probabilities.\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 22:19:17 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Koivusalo", "Alexander F. R.", ""], ["Sch\u00e4fer", "Rudi", ""]]}, {"id": "1102.5665", "submitter": "William Shaw", "authors": "William T. Shaw", "title": "Risk, VaR, CVaR and their associated Portfolio Optimizations when Asset\n  Returns have a Multivariate Student T Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM math.OC q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to reduce the problem of computing VaR and CVaR with Student T\nreturn distributions to evaluation of analytical functions of the moments. This\nallows an analysis of the risk properties of systems to be carefully attributed\nbetween choices of risk function (e.g. VaR vs CVaR); choice of return\ndistribution (power law tail vs Gaussian) and choice of event frequency, for\nrisk assessment. We exploit this to provide a simple method for portfolio\noptimization when the asset returns follow a standard multivariate T\ndistribution. This may be used as a semi-analytical verification tool for more\ngeneral optimizers, and for practical assessment of the impact of fat tails on\nasset allocation for shorter time horizons.\n", "versions": [{"version": "v1", "created": "Mon, 28 Feb 2011 14:10:35 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Shaw", "William T.", ""]]}]