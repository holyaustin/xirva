[{"id": "1510.00616", "submitter": "Oliver Kley", "authors": "Oliver Kley and Claudia Kl\\\"uppelberg and Gesine Reinert", "title": "Conditional risk measures in a bipartite market structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the effect of network structure between agents and\nobjects on measures for systemic risk. We model the influence of sharing large\nexogeneous losses to the financial or (re)insuance market by a bipartite graph.\nUsing Pareto-tailed losses and multivariate regular variation we obtain\nasymptotic results for systemic conditional risk measures based on the\nValue-at-Risk and the Conditional Tail Expectation. These results allow us to\nassess the influence of an individual institution on the systemic or market\nrisk and vice versa through a collection of conditional systemic risk measures.\nFor large markets Poisson approximations of the relevant constants are provided\nin the example of an insurance market. The example of an underlying homogeneous\nrandom graph is analysed in detail, and the results are illustrated through\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 2 Oct 2015 14:51:53 GMT"}], "update_date": "2015-10-05", "authors_parsed": [["Kley", "Oliver", ""], ["Kl\u00fcppelberg", "Claudia", ""], ["Reinert", "Gesine", ""]]}, {"id": "1510.01593", "submitter": "Halis Sak", "authors": "Halis Sak and \\.Ismail Ba\\c{s}o\\u{g}lu", "title": "Efficient Randomized Quasi-Monte Carlo Methods For Portfolio Market Risk", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": "10.1016/j.insmatheco.2017.07.001", "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of simulating loss probabilities and conditional\nexcesses for linear asset portfolios under the t-copula model. Although in the\nliterature on market risk management there are papers proposing efficient\nvariance reduction methods for Monte Carlo simulation of portfolio market risk,\nthere is no paper discussing combining the randomized quasi-Monte Carlo method\nwith variance reduction techniques. In this paper, we combine the randomized\nquasi-Monte Carlo method with importance sampling and stratified importance\nsampling. Numerical results for realistic portfolio examples suggest that\nreplacing pseudorandom numbers (Monte Carlo) with quasi-random sequences\n(quasi-Monte Carlo) in the simulations increases the robustness of the\nestimates once we reduce the effective dimension and the non-smoothness of the\nintegrands.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 14:35:30 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Sak", "Halis", ""], ["Ba\u015fo\u011flu", "\u0130smail", ""]]}, {"id": "1510.01675", "submitter": "Nikolaus Schweizer", "authors": "Thomas Kruse, Judith C. Schneider, Nikolaus Schweizer", "title": "What's in a ball? Constructing and characterizing uncertainty sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.OC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the presence of model risk, it is well-established to replace classical\nexpected values by worst-case expectations over all models within a fixed\nradius from a given reference model. This is the \"robustness\" approach. We show\nthat previous methods for measuring this radius, e.g. relative entropy or\npolynomial divergences, are inadequate for reference models which are\nmoderately heavy-tailed such as lognormal models. Worst cases are either\ninfinitely pessimistic, or they rule out the possibility of fat-tailed \"power\nlaw\" models as plausible alternatives. We introduce a new family of divergence\nmeasures which captures intermediate levels of pessimism.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2015 17:38:22 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Kruse", "Thomas", ""], ["Schneider", "Judith C.", ""], ["Schweizer", "Nikolaus", ""]]}, {"id": "1510.03920", "submitter": "Lingjiong Zhu", "authors": "Lingjiong Zhu", "title": "A State-Dependent Dual Risk Model", "comments": "20 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a dual risk model, the premiums are considered as the costs and the claims\nare regarded as the profits. The surplus can be interpreted as the wealth of a\nventure capital, whose profits depend on research and development. In most of\nthe existing literature of dual risk models, the profits follow the compound\nPoisson model and the cost is constant. In this paper, we develop a\nstate-dependent dual risk model, in which the arrival rate of the profits and\nthe costs depend on the current state of the wealth process. Ruin probabilities\nare obtained in closed-forms. Further properties and results will also be\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2015 22:51:14 GMT"}], "update_date": "2015-10-15", "authors_parsed": [["Zhu", "Lingjiong", ""]]}, {"id": "1510.04924", "submitter": "Lingjiong Zhu", "authors": "Arash Fahim, Lingjiong Zhu", "title": "Optimal Investment in a Dual Risk Model", "comments": "32 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual risk models are popular for modeling a venture capital or high tech\ncompany, for which the running cost is deterministic and the profits arrive\nstochastically over time. Most of the existing literature on dual risk models\nconcentrated on the optimal dividend strategies. In this paper, we propose to\nstudy the optimal investment strategy on research and development for the dual\nrisk models to minimize the ruin probability of the underlying company. We will\nalso study the optimization problem when in addition the investment in a risky\nasset is allowed.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 16:01:46 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Fahim", "Arash", ""], ["Zhu", "Lingjiong", ""]]}, {"id": "1510.04943", "submitter": "Fabio Caccioli", "authors": "Fabio Caccioli, Imre Kondor, G\\'abor Papp", "title": "Portfolio Optimization under Expected Shortfall: Contour Maps of\n  Estimation Error", "comments": "47 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contour maps of the error of historical resp. parametric estimates for\nlarge random portfolios optimized under the risk measure Expected Shortfall\n(ES) are constructed. Similar maps for the sensitivity of the portfolio weights\nto small changes in the returns as well as the VaR of the ES-optimized\nportfolio are also presented, along with results for the distribution of\nportfolio weights over the random samples and for the out-of-sample and\nin-the-sample estimates for ES. The contour maps allow one to quantitatively\ndetermine the sample size (the length of the time series) required by the\noptimization for a given number of different assets in the portfolio, at a\ngiven confidence level and a given level of relative estimation error. The\nnecessary sample sizes invariably turn out to be unrealistically large for any\nreasonable choice of the number of assets and the confidence level. These\nresults are obtained via analytical calculations based on methods borrowed from\nthe statistical physics of random systems, supported by numerical simulations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2015 16:57:13 GMT"}], "update_date": "2015-10-19", "authors_parsed": [["Caccioli", "Fabio", ""], ["Kondor", "Imre", ""], ["Papp", "G\u00e1bor", ""]]}, {"id": "1510.05561", "submitter": "Zachary Feinstein", "authors": "Zachary Feinstein, Birgit Rudloff", "title": "A Supermartingale Relation for Multivariate Risk Measures", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The equivalence between multiportfolio time consistency of a dynamic\nmultivariate risk measure and a supermartingale property is proven.\nFurthermore, the dual variables under which this set-valued supermartingale is\na martingale are characterized as the worst-case dual variables in the dual\nrepresentation of the risk measure. Examples of multivariate risk measures\nsatisfying the supermartingale property are given. Crucial for obtaining the\nresults are dual representations of scalarizations of set-valued dynamic risk\nmeasures, which are of independent interest in the fast growing literature on\nmultivariate risks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2015 16:14:06 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 19:03:03 GMT"}, {"version": "v3", "created": "Tue, 15 Nov 2016 17:33:36 GMT"}, {"version": "v4", "created": "Wed, 31 Jan 2018 21:09:26 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Feinstein", "Zachary", ""], ["Rudloff", "Birgit", ""]]}, {"id": "1510.07030", "submitter": "Daniel Lacker", "authors": "Daniel Lacker", "title": "Law invariant risk measures and information divergences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A one-to-one correspondence is drawn between law invariant risk measures and\ndivergences, which we define as functionals of pairs of probability measures on\narbitrary standard Borel spaces satisfying a few natural properties.\nDivergences include many classical information divergence measures, such as\nrelative entropy and $f$-divergences. Several properties of divergence and\ntheir duality with law invariant risk measures are developed, most notably\nrelating their chain rules or additivity properties with certain notions of\ntime consistency for dynamic law invariant risk measures known as acceptance\nand rejection consistency. These properties are linked also to a peculiar\nproperty of the acceptance sets on the level of distributions, analogous to\nresults of Weber on weak acceptance and rejection consistency. Finally, the\nexamples of shortfall risk measures and optimized certainty equivalents are\ndiscussed in some detail, and it is shown that the relative entropy is\nessentially the only divergence satisfying the chain rule.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2015 19:52:33 GMT"}, {"version": "v2", "created": "Sat, 4 Jun 2016 22:24:41 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Lacker", "Daniel", ""]]}, {"id": "1510.07033", "submitter": "Daniel Lacker", "authors": "Daniel Lacker", "title": "Liquidity, risk measures, and concentration of measure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expanding on techniques of concentration of measure, we develop a\nquantitative framework for modeling liquidity risk using convex risk measures.\nThe fundamental objects of study are curves of the form $(\\rho(\\lambda\nX))_{\\lambda \\ge 0}$, where $\\rho$ is a convex risk measure and $X$ a random\nvariable, and we call such a curve a \\emph{liquidity risk profile}. The shape\nof a liquidity risk profile is intimately linked with the tail behavior of the\nunderlying $X$ for some notable classes of risk measures, namely shortfall risk\nmeasures. We exploit this link to systematically bound liquidity risk profiles\nfrom above by other real functions $\\gamma$, deriving tractable necessary and\nsufficient conditions for \\emph{concentration inequalities} of the form\n$\\rho(\\lambda X) \\le \\gamma(\\lambda)$, for all $\\lambda \\ge 0$. These\nconcentration inequalities admit useful dual representations related to\ntransport inequalities, and this leads to efficient uniform bounds for\nliquidity risk profiles for large classes of $X$. On the other hand, some\nmodest new mathematical results emerge from this analysis, including a new\ncharacterization of some classical transport-entropy inequalities. Lastly, the\nanalysis is deepened by means of a surprising connection between time\nconsistency properties of law invariant risk measures and the tensorization of\nconcentration inequalities.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2015 19:58:27 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2015 14:55:09 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Lacker", "Daniel", ""]]}, {"id": "1510.07608", "submitter": "Alexander Lipton", "authors": "Alexander Lipton", "title": "Modern Monetary Circuit Theory, Stability of Interconnected Banking\n  Network, and Balance Sheet Optimization for Individual Banks", "comments": "67 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC q-fin.CP q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modern version of Monetary Circuit Theory with a particular emphasis on\nstochastic underpinning mechanisms is developed. It is explained how money is\ncreated by the banking system as a whole and by individual banks. The role of\ncentral banks as system stabilizers and liquidity providers is elucidated. It\nis shown how in the process of money creation banks become naturally\ninterconnected. A novel Extended Structural Default Model describing the\nstability of the Interconnected Banking Network is proposed. The purpose of\nbanks' capital and liquidity is explained. Multi-period constrained\noptimization problem for banks's balance sheet is formulated and solved in a\nsimple case. Both theoretical and practical aspects are covered.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2015 19:38:59 GMT"}], "update_date": "2015-10-27", "authors_parsed": [["Lipton", "Alexander", ""]]}]