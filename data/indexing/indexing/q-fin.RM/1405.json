[{"id": "1405.0508", "submitter": "Chris Kenyon", "authors": "Andrew Green and Chris Kenyon", "title": "MVA: Initial Margin Valuation Adjustment by Replication and Regression", "comments": "15 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.GN q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initial margin requirements are becoming an increasingly common feature of\nderivative markets. However, while the valuation of derivatives under\ncollateralisation (Piterbarg 2010, Piterbarg2012), under counterparty risk with\nunsecured funding costs (FVA) (Burgard2011, Burgard2011, Burgard2013) and in\nthe presence of regulatory capital (KVA) (Green2014) are established through\nvaluation adjustments, hitherto initial margin has not been considered. This\npaper further extends the semi-replication framework of (Burgard2013a), itself\nlater extended by (Green2014), to cover the cost of initial margin, leading to\nMargin Valuation Adjustment (MVA). Initial margin requirements are typically\ngenerated through the use of VAR or CVAR models. Given the form of MVA as an\nintegral over the expected initial margin profile this would lead to excessive\ncomputational costs if a brute force calculation were to be used. Hence we also\npropose a computationally efficient approach to the calculation of MVA through\nthe use of regression techniques, Longstaff-Schwartz Augmented Compression\n(LSAC).\n", "versions": [{"version": "v1", "created": "Fri, 2 May 2014 20:49:38 GMT"}, {"version": "v2", "created": "Mon, 12 Jan 2015 18:27:52 GMT"}], "update_date": "2015-01-13", "authors_parsed": [["Green", "Andrew", ""], ["Kenyon", "Chris", ""]]}, {"id": "1405.0732", "submitter": "Przemyslaw Klusik", "authors": "Klusik Przemyslaw", "title": "Hedging of equity-linked with maximal success factor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an equity-linked contract whose payoff depends on the lifetime of\npolicy holder and the stock price. We assume the limited capital for hedging\nand we provide with the best strategy for an insurance company in the meaning\nof so called succes factor $\\IE^\\IP\\left[{\\mathbf 1}_{\\{V_T \\geq D)}+{\\mathbf\n1}_{\\{V_T < D\\}}\\frac{V_T}{D}\\right ]$, where $V_T$ denotes the end value of\nstrategy and $D$ is the payoff of the contract. The work is a genaralisation of\nthe work of F\\\"{o}llmer and Schied \\cite{FS2004} and Klusik and Palmowski\n\\cite{KluPal}, but it considers much more general \"incompletness\" of the\nmarket, among others midterm nonmarket information signals and infitite\nnonmarket scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 4 May 2014 18:55:09 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Przemyslaw", "Klusik", ""]]}, {"id": "1405.1212", "submitter": "Przemyslaw Klusik", "authors": "Przemys{\\l}aw Klusik", "title": "Market risk modelling in Solvency II regime and hedging options not\n  using underlying", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we develop mathematical tools of quantile hedging in incomplete\nmarket. Those could be used for two significant applications:\n  o calculating the \\textbf{optimal capital requirement imposed by Solvency II}\n(Directive 2009/138/EC of the European Parliament and of the Council) when the\nmarket and non-market risk is present in insurance company. We show hot to find\nthe minimal capital $V_0$ to provide with the one-year hedging strategy for\ninsurance company satisfying $E\\left[{\\mathbf 1}_{\\{V_1 \\geq\nD\\}}\\right]=0.995$, where $V_1$ denotes the value of insurance company in one\nyear time and $D$ is the payoff of the contract.\n  o finding a hedging strategy for derivative not using underlying but an asset\nwith dynamics correlated or in some other way dependent (no deterministically)\non underlying. The work is a generalisation of the work of Klusik and Palmowski\n\\cite{KluPal}.\n  Keywords: quantile hedging, solvency II, capital modelling, hedging options\non nontradable asset.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 10:08:33 GMT"}], "update_date": "2016-03-27", "authors_parsed": [["Klusik", "Przemys\u0142aw", ""]]}, {"id": "1405.1309", "submitter": "Luciana Dalla Valle PhD", "authors": "Luciana Dalla Valle, Maria Elena De Giuli, Claudia Tarantola, Claudio\n  Manelli", "title": "Default Probability Estimation via Pair Copula Constructions", "comments": "40 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel approach for firm default probability\nestimation. The methodology is based on multivariate contingent claim analysis\nand pair copula constructions. For each considered firm, balance sheet data are\nused to assess the asset value, and to compute its default probability. The\nasset pricing function is expressed via a pair copula construction, and it is\napproximated via Monte Carlo simulations. The methodology is illustrated\nthrough an application to the analysis of both operative and defaulted firms.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 15:19:46 GMT"}, {"version": "v2", "created": "Thu, 13 Nov 2014 10:21:30 GMT"}, {"version": "v3", "created": "Fri, 21 Aug 2015 18:15:32 GMT"}], "update_date": "2015-08-24", "authors_parsed": [["Valle", "Luciana Dalla", ""], ["De Giuli", "Maria Elena", ""], ["Tarantola", "Claudia", ""], ["Manelli", "Claudio", ""]]}, {"id": "1405.1326", "submitter": "Jianxi Su", "authors": "Edward Furman, Jianxi Su, and Ri\\v{c}ardas Zitikis", "title": "Paths and indices of maximal tail dependence", "comments": "ASTIN Bulletin: The Journal of the International Actuarial\n  Association, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-fin.RM q-fin.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate both analytically and numerically that the existing methods\nfor measuring tail dependence in copulas may sometimes underestimate the extent\nof extreme co-movements of dependent risks and, therefore, may not always\ncomply with the new paradigm of prudent risk management. This phenomenon holds\nin the context of both symmetric and asymmetric copulas with and without\nsingularities. As a remedy, we introduce a notion of paths of maximal (tail)\ndependence and utilize it to propose several new indices of tail dependence.\nThe suggested new indices are conservative, conform with the basic concepts of\nmodern quantitative risk management, and are able to distinguish between\ndistinct risky positions in situations when the existing indices fail to do so.\n", "versions": [{"version": "v1", "created": "Tue, 6 May 2014 15:42:31 GMT"}, {"version": "v2", "created": "Sat, 7 Feb 2015 20:38:44 GMT"}, {"version": "v3", "created": "Sat, 16 Jul 2016 13:03:47 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Furman", "Edward", ""], ["Su", "Jianxi", ""], ["Zitikis", "Ri\u010dardas", ""]]}, {"id": "1405.1791", "submitter": "Nassim Nicholas Taleb", "authors": "Nassim N Taleb, Raphael Douady", "title": "On the Super-Additivity and Estimation Biases of Quantile Contributions", "comments": null, "journal-ref": "Physica A: Statistical Mechanics and its Applications 429,\n  252-260, 2015", "doi": "10.1016/j.physa.2015.02.038", "report-no": null, "categories": "stat.AP q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample measures of top centile contributions to the total (concentration) are\ndownward biased, unstable estimators, extremely sensitive to sample size and\nconcave in accounting for large deviations. It makes them particularly unfit in\ndomains with power law tails, especially for low values of the exponent. These\nestimators can vary over time and increase with the population size, as shown\nin this article, thus providing the illusion of structural changes in\nconcentration. They are also inconsistent under aggregation and mixing\ndistributions, as the weighted average of concentration measures for A and B\nwill tend to be lower than that from A U B. In addition, it can be shown that\nunder such fat tails, increases in the total sum need to be accompanied by\nincreased sample size of the concentration measurement. We examine the\nestimation superadditivity and bias under homogeneous and mixed distributions.\n", "versions": [{"version": "v1", "created": "Thu, 8 May 2014 01:53:03 GMT"}, {"version": "v2", "created": "Sun, 11 May 2014 22:44:14 GMT"}, {"version": "v3", "created": "Wed, 12 Nov 2014 18:46:14 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Taleb", "Nassim N", ""], ["Douady", "Raphael", ""]]}, {"id": "1405.3769", "submitter": "Johanna F. Ziegel", "authors": "Ruodu Wang and Johanna F. Ziegel", "title": "Distortion Risk Measures and Elicitability", "comments": "The paper has been withdrawn by the authors because it is not\n  properly written to be cited by the research community", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss equivalent axiomatic characterizations of distortion risk\nmeasures, and give a novel and concise proof of the characterization of\nelicitable distortion risk measures. Elicitability has recently been discussed\nas a desirable criterion for risk measures, motivated by statistical\nconsiderations of forecasting. We reveal the mathematical conflict between the\nrequirements of elicitability and comonotonic additivity which intuitively\nexplains why only Value-at-Risk and the mean are elicitable distortion risk\nmeasures in a general sense.\n", "versions": [{"version": "v1", "created": "Thu, 15 May 2014 08:49:57 GMT"}, {"version": "v2", "created": "Sat, 24 May 2014 11:53:59 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Wang", "Ruodu", ""], ["Ziegel", "Johanna F.", ""]]}, {"id": "1405.4716", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze", "title": "Combining Alpha Streams with Costs", "comments": "21 pages; minor misprints corrected; to appear in The Journal of Risk", "journal-ref": "The Journal of Risk 17(3) (2015) 57-78", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss investment allocation to multiple alpha streams traded on the same\nexecution platform with internal crossing of trades and point out differences\nwith allocating investment when alpha streams are traded on separate execution\nplatforms with no crossing. First, in the latter case allocation weights are\nnon-negative, while in the former case they can be negative. Second, the\neffects of both linear and nonlinear (impact) costs are different in these two\ncases due to turnover reduction when the trades are crossed. Third, the\nturnover reduction depends on the universe of traded alpha streams, so if some\nalpha streams have zero allocations, turnover reduction needs to be recomputed,\nhence an iterative procedure. We discuss an algorithm for finding allocation\nweights with crossing and linear costs. We also discuss a simple approximation\nwhen nonlinear costs are added, making the allocation problem tractable while\nstill capturing nonlinear portfolio capacity bound effects. We also define\n\"regression with costs\" as a limit of optimization with costs, useful in\noften-occurring cases with singular alpha covariance matrix.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 13:24:22 GMT"}, {"version": "v2", "created": "Fri, 11 Jul 2014 00:11:02 GMT"}, {"version": "v3", "created": "Fri, 16 Jan 2015 18:05:09 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Kakushadze", "Zura", ""]]}, {"id": "1405.4905", "submitter": "Birgit Rudloff", "authors": "\\c{C}a\\u{g}{\\i}n Ararat, Andreas H. Hamel, Birgit Rudloff", "title": "Set-valued shortfall and divergence risk measures", "comments": null, "journal-ref": "International Journal of Theoretical and Applied Finance 20 (5)\n  1750026 (2017)", "doi": "10.1142/S0219024917500261", "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Risk measures for multivariate financial positions are studied in a\nutility-based framework. Under a certain incomplete preference relation,\nshortfall and divergence risk measures are defined as the optimal values of\nspecific set minimization problems. The dual relationship between these two\nclasses of multivariate risk measures is constructed via a recent Lagrange\nduality for set optimization. In particular, it is shown that a shortfall risk\nmeasure can be written as an intersection over a family of divergence risk\nmeasures indexed by a scalarization parameter. Examples include set-valued\nversions of the entropic risk measure and the average value at risk. As a\nsecond step, the minimization of these risk measures subject to trading\nopportunities is studied in a general convex market in discrete time. The\noptimal value of the minimization problem, called the market risk measure, is\nalso a set-valued risk measure. A dual representation for the market risk\nmeasure that decomposes the effects of the original risk measure and the\nfrictions of the market is proved.\n", "versions": [{"version": "v1", "created": "Mon, 19 May 2014 22:10:52 GMT"}, {"version": "v2", "created": "Sun, 10 Sep 2017 15:19:09 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Ararat", "\u00c7a\u011f\u0131n", ""], ["Hamel", "Andreas H.", ""], ["Rudloff", "Birgit", ""]]}, {"id": "1405.6677", "submitter": "Tatiana Labopin-Richard", "authors": "Tatiana Labopin-Richard (IMT), Fabrice Gamboa (IMT), Aur\\'elien\n  Garivier (IMT), Bertrand Iooss (GdR MASCOT-NUM)", "title": "Bregman superquantiles. Estimation methods and applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-fin.RM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we extend some quantities introduced in \"Optimization of\nconditional value-at-risk\" of R.T Rockafellar and S. Uryasev to the case where\nthe proximity between real numbers is measured by using a Bregman divergence.\nThis leads to the definition of the Bregman superquantile. Axioms of a coherent\nmeasure of risk discussed in \"Coherent approches to risk in optimization under\nuncertainty\" of R.T Rockafellar are studied in the case of Bregman\nsuperquantile. Furthermore, we deal with asymptotic properties of a Monte Carlo\nestimator of the Bregman superquantile.\n", "versions": [{"version": "v1", "created": "Mon, 26 May 2014 18:45:49 GMT"}, {"version": "v2", "created": "Fri, 22 May 2015 08:38:31 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2015 18:16:47 GMT"}, {"version": "v4", "created": "Wed, 6 Jan 2016 12:30:33 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Labopin-Richard", "Tatiana", "", "IMT"], ["Gamboa", "Fabrice", "", "IMT"], ["Garivier", "Aur\u00e9lien", "", "IMT"], ["Iooss", "Bertrand", "", "GdR MASCOT-NUM"]]}, {"id": "1405.7611", "submitter": "Chris Kenyon", "authors": "Chris Kenyon and Andrew Green", "title": "VAR and ES/CVAR Dependence on data cleaning and Data Models: Analysis\n  and Resolution", "comments": "22 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Historical (Stressed-) Value-at-Risk ((S)VAR), and Expected Shortfall (ES),\nare widely used risk measures in regulatory capital and Initial Margin, i.e.\nfunding, computations. However, whilst the definitions of VAR and ES are\nunambiguous, they depend on input distributions that are data-cleaning- and\nData-Model-dependent. We quantify the scale of these effects from USD CDS\n(2004--2014), and from USD interest rates (1989--2014, single-curve setup\nbefore 2004, multi-curve setup after 2004), and make two standardisation\nproposals: for data; and for Data-Models. VAR and ES are required for lifetime\nportfolio calculations, i.e. collateral calls, which cover a wide range of\nmarket states. Hence we need standard, i.e. clean, complete, and common (i.e.\nidentical for all banks), market data also covering this wide range of market\nstates. This data is historically incomplete and not clean hence data\nstandardization is required. Stressed VAR and ES require moving market\nmovements during a past (usually not recent) window to current, and future,\nmarket states. All choices (e.g. absolute difference, relative, relative scaled\nby some function of market states) implicitly define a Data Model for\ntransformation of extreme market moves (recall that 99th percentiles are\ntypical, and the behaviour of the rest is irrelevant). Hence we propose\nstandard Data Models. These are necessary because different banks have\ndifferent stress windows. Where there is no data, or a requirement for\nsimplicity, we propose standard lookup tables (one per window, etc.). Without\nthis standardization of data and Data Models we demonstrate that VAR and ES are\ncomplex derivatives of subjective choices.\n", "versions": [{"version": "v1", "created": "Thu, 29 May 2014 16:51:49 GMT"}], "update_date": "2014-05-30", "authors_parsed": [["Kenyon", "Chris", ""], ["Green", "Andrew", ""]]}]