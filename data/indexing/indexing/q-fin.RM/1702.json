[{"id": "1702.01936", "submitter": "Cosimo Munari", "authors": "Michel Baes, Pablo Koch-Medina, Cosimo Munari", "title": "Existence, uniqueness and stability of optimal portfolios of eligible\n  assets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a capital adequacy framework, risk measures are used to determine the\nminimal amount of capital that a financial institution has to raise and invest\nin a portfolio of pre-specified eligible assets in order to pass a given\ncapital adequacy test. From a capital efficiency perspective, it is important\nto identify the set of portfolios of eligible assets that allow to pass the\ntest by raising the least amount of capital. We study the existence and\nuniqueness of such optimal portfolios as well as their sensitivity to changes\nin the underlying capital position. This naturally leads to investigating the\ncontinuity properties of the set-valued map associating to each capital\nposition the corresponding set of optimal portfolios. We pay special attention\nto lower semicontinuity, which is the key continuity property from a financial\nperspective. This \"stability\" property is always satisfied if the test is based\non a polyhedral risk measure but it generally fails once we depart from\npolyhedrality even when the reference risk measure is convex. However, lower\nsemicontinuity can be often achieved if one if one is willing to focuses on\nportfolios that are close to being optimal. Besides capital adequacy, our\nresults have a variety of natural applications to pricing, hedging, and capital\nallocation problems.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 09:27:52 GMT"}, {"version": "v2", "created": "Sat, 30 Dec 2017 08:22:18 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Baes", "Michel", ""], ["Koch-Medina", "Pablo", ""], ["Munari", "Cosimo", ""]]}, {"id": "1702.03098", "submitter": "Takaaki Koike", "authors": "Takaaki Koike, Mihoko Minami", "title": "Estimation of Risk Contributions with MCMC", "comments": "31 pages, 1 table, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.ST q-fin.CP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining risk contributions of unit exposures to portfolio-wide economic\ncapital is an important task in financial risk management. Computing risk\ncontributions involves difficulties caused by rare-event simulations. In this\nstudy, we address the problem of estimating risk contributions when the total\nrisk is measured by value-at-risk (VaR). Our proposed estimator of VaR\ncontributions is based on the Metropolis-Hasting (MH) algorithm, which is one\nof the most prevalent Markov chain Monte Carlo (MCMC) methods. Unlike existing\nestimators, our MH-based estimator consists of samples from conditional loss\ndistribution given a rare event of interest. This feature enhances sample\nefficiency compared with the crude Monte Carlo method. Moreover, our method has\nthe consistency and asymptotic normality, and is widely applicable to various\nrisk models having joint loss density. Our numerical experiments based on\nsimulation and real-world data demonstrate that in various risk models, even\nthose having high-dimensional (approximately 500) inhomogeneous margins, our MH\nestimator has smaller bias and mean squared error compared with existing\nestimators.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 08:49:04 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2019 04:58:34 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Koike", "Takaaki", ""], ["Minami", "Mihoko", ""]]}, {"id": "1702.04287", "submitter": "Carsten Chong", "authors": "Carsten Chong and Claudia Kl\\\"uppelberg", "title": "Contagion in financial systems: A Bayesian network approach", "comments": null, "journal-ref": "SIAM J. Financial Math., 9(1):28-53, 2018", "doi": "10.1137/17M1116659", "report-no": null, "categories": "q-fin.RM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a structural default model for interconnected financial\ninstitutions in a probabilistic framework. For all possible network structures\nwe characterize the joint default distribution of the system using Bayesian\nnetwork methodologies. Particular emphasis is given to the treatment and\nconsequences of cyclic financial linkages. We further demonstrate how Bayesian\nnetwork theory can be applied to detect contagion channels within the financial\nnetwork, to measure the systemic importance of selected entities on others, and\nto compute conditional or unconditional probabilities of default for single or\nmultiple institutions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 16:54:47 GMT"}, {"version": "v2", "created": "Sun, 16 Jul 2017 16:02:21 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Chong", "Carsten", ""], ["Kl\u00fcppelberg", "Claudia", ""]]}, {"id": "1702.07936", "submitter": "Zachary Feinstein", "authors": "Zachary Feinstein", "title": "Obligations with Physical Delivery in a Multi-Layered Financial Network", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a general framework for modeling financial contagion in a\nsystem with obligations in multiple illiquid assets (e.g., currencies). In so\ndoing, we develop a multi-layered financial network that extends the single\nnetwork of Eisenberg and Noe (2001). In particular, we develop a financial\ncontagion model with fire sales that allows institutions to both buy and sell\nassets to cover their liabilities in the different assets and act as utility\nmaximizers.\n  We prove that, under standard assumptions and without market impacts,\nequilibrium portfolio holdings exist and are unique. However, with market\nimpacts, we prove that equilibrium portfolio holdings and market prices exist\nwhich clear the multi-layered financial system. In general, though, these\nclearing solutions are not unique. We extend this result by considering the\nt\\^atonnement process to find the unique attained equilibrium. The attained\nequilibrium need not be continuous with respect to the initial shock; these\npoints of discontinuity match those stresses in which a financial crisis\nbecomes a systemic crisis. We further provide mathematical formulations for\npayment rules and utility functions satisfying the necessary conditions for\nthese existence and uniqueness results.\n  We demonstrate the value of our model through illustrative numerical case\nstudies. In particular, we study a counterfactual scenario on the event that\nGreece re-instituted the drachma on a dataset from the European Banking\nAuthority.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 18:59:15 GMT"}, {"version": "v2", "created": "Tue, 8 Aug 2017 16:19:07 GMT"}, {"version": "v3", "created": "Fri, 15 Jun 2018 21:48:17 GMT"}, {"version": "v4", "created": "Thu, 23 May 2019 12:55:01 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Feinstein", "Zachary", ""]]}, {"id": "1702.08744", "submitter": "Daniel Grigat", "authors": "Daniel Grigat, Fabio Caccioli", "title": "Reverse stress testing interbank networks", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reverse engineer dynamics of financial contagion to find the scenario of\nsmallest exogenous shock that, should it occur, would lead to a given final\nsystemic loss. This reverse stress test can be used to identify the potential\ntriggers of systemic events, and it removes the arbitrariness in the selection\nof shock scenarios in stress testing. We consider in particular the case of\ndistress propagation in an interbank market, and we study a network of 44\nEuropean banks, which we reconstruct using data collected from Bloomberg. By\nlooking at the distribution across banks of the size of smallest exogenous\nshocks we rank banks in terms of their systemic importance, and we show the\neffectiveness of a policy with capital requirements based on this ranking. We\nalso study the properties of smallest exogenous shocks as a function of the\nlargest eigenvalue $\\lambda_{\\rm max}$ of the matrix of interbank leverages,\nwhich determines the endogenous amplification of shocks. We find that the size\nof smallest exogenous shocks reduces and that the distribution across banks\nbecomes more localized as $\\lambda_{\\rm max}$ increases.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 11:12:59 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 12:53:28 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Grigat", "Daniel", ""], ["Caccioli", "Fabio", ""]]}, {"id": "1702.08774", "submitter": "Yuri Biondi", "authors": "Yuri Biondi, Feng Zhou", "title": "Interbank Credit and the Money Manufacturing Process. A Systemic\n  Perspective on Financial Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN econ.GN physics.soc-ph q-fin.EC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interbank lending and borrowing occur when financial institutions seek to\nsettle and refinance their mutual positions over time and circumstances. This\ninteractive process involves money creation at the aggregate level.\nCoordination mismatch on interbank credit may trigger systemic crises. This\nhappened when, since summer 2007, interbank credit coordination did not longer\nwork smoothly across financial institutions, eventually requiring exceptional\nmonetary policies by central banks, and guarantee and bailout interventions by\ngovernments. Our article develops an interacting heterogeneous agents-based\nmodel of interbank credit coordination under minimal institutions. First, we\nexplore the link between interbank credit coordination and the money generation\nprocess. Contrary to received understanding, interbank credit has the capacity\nto make the monetary system unbound. Second, we develop simulation analysis on\nimperfect interbank credit coordination, studying impact of interbank dynamics\non financial stability and resilience at individual and aggregate levels.\nSystemically destabilizing forces prove to be related to the working of the\nbanking system over time, especially interbank coordination conditions and\ncircumstances.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 13:05:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Biondi", "Yuri", ""], ["Zhou", "Feng", ""]]}, {"id": "1702.08867", "submitter": "Gon\\c{c}alo dos Reis Dr.", "authors": "Greig Smith and Goncalo dos Reis", "title": "Robust and Consistent Estimation of Generators in Credit Risk", "comments": "29 pages, 7 Figures, 9 tables", "journal-ref": null, "doi": "10.1080/14697688.2017.1383627", "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bond rating Transition Probability Matrices (TPMs) are built over a one-year\ntime-frame and for many practical purposes, like the assessment of risk in\nportfolios or the computation of banking Capital Requirements (e.g. the new\nIFRS 9 regulation), one needs to compute the TPM and probabilities of default\nover a smaller time interval. In the context of continuous time Markov chains\n(CTMC) several deterministic and statistical algorithms have been proposed to\nestimate the generator matrix. We focus on the Expectation-Maximization (EM)\nalgorithm by Bladt and Sorensen (2005) for a CTMC with an absorbing state for\nsuch estimation.\n  This work's contribution is threefold. Firstly, we provide directly\ncomputable closed-form expressions for quantities appearing in the EM algorithm\nand associated information matrix, allowing to easily approximate confidence\nintervals. Previously, these quantities had to be estimated numerically and\nconsiderable computational speedups have been gained. Secondly, we prove\nconvergence to a single set of parameters under very weak conditions (for the\nTPM problem). Finally, we provide a numerical benchmark of our results against\nother known algorithms, in particular, on several problems related to credit\nrisk. The EM algorithm we propose, padded with the new formulas (and error\ncriteria), outperforms other known algorithms in several metrics, in\nparticular, with much less overestimation of probabilities of default in higher\nratings than other statistical algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 17:07:03 GMT"}, {"version": "v2", "created": "Sun, 15 Oct 2017 12:17:02 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Smith", "Greig", ""], ["Reis", "Goncalo dos", ""]]}, {"id": "1702.08901", "submitter": "Stefan Weber", "authors": "Stefan Weber", "title": "Solvency II, or How to Sweep the Downside Risk Under the Carpet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under Solvency II the computation of capital requirements is based on value\nat risk (V@R). V@R is a quantile-based risk measure and neglects extreme risks\nin the tail. V@R belongs to the family of distortion risk measures. A serious\ndeficiency of V@R is that firms can hide their total downside risk in corporate\nnetworks, unless a consolidated solvency balance sheet is required for each\neconomic scenario. In this case, they can largely reduce their total capital\nrequirements via appropriate transfer agreements within a network structure\nconsisting of sufficiently many entities and thereby circumvent capital\nregulation. We prove several versions of such a result for general distortion\nrisk measures of V@R-type, explicitly construct suitable allocations of the\nnetwork portfolio, and finally demonstrate how these findings can be extended\nbeyond distortion risk measures. We also discuss why consolidation requirements\ncannot completely eliminate this problem. Capital regulation should thus be\nbased on coherent or convex risk measures like average value at risk or\nexpectiles.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 18:39:56 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 18:20:43 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Weber", "Stefan", ""]]}]