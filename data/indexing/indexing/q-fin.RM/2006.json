[{"id": "2006.00717", "submitter": "Benjamin Avanzi", "authors": "Benjamin Avanzi and Hayden Lau and Bernard Wong", "title": "On the optimality of joint periodic and extraordinary dividend\n  strategies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we model the cash surplus (or equity) of a risky business with\na Brownian motion. Owners can take cash out of the surplus in the form of\n\"dividends\", subject to transaction costs. However, if the surplus hits 0 then\nruin occurs and the business cannot operate any more.\n  We consider two types of dividend distributions: (i) periodic, regular ones\n(that is, dividends can be paid only at countable many points in time,\naccording to a specific arrival process); and (ii) extraordinary dividend\npayments that can be made immediately at any time (that is, the dividend\ndecision time space is continuous and matches that of the surplus process).\nBoth types of dividends attract proportional transaction costs, and\nextraordinary distributions also attracts fixed transaction costs, a realistic\nfeature. A dividend strategy that involves both types of distributions\n(periodic and extraordinary) is qualified as \"hybrid\".\n  We determine which strategies (either periodic, immediate, or hybrid) are\noptimal, that is, we show which are the strategies that maximise the expected\npresent value of dividends paid until ruin, net of transaction costs.\nSometimes, a liquidation strategy (which pays out all monies and stops the\nprocess) is optimal. Which strategy is optimal depends on the profitability of\nthe business, and the level of (proportional and fixed) transaction costs.\nResults are illustrated.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 04:52:08 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 04:41:50 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Avanzi", "Benjamin", ""], ["Lau", "Hayden", ""], ["Wong", "Bernard", ""]]}, {"id": "2006.01037", "submitter": "Zachary Feinstein", "authors": "Zachary Feinstein and T. R. Hurd", "title": "Contingent Convertible Obligations and Financial Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates whether a financial system can be made more stable if\nfinancial institutions share risk by exchanging contingent convertible (CoCo)\ndebt obligations. The question is framed in a financial network model of debt\nand equity interlinkages with the addition of a variant of the CoCo that\nconverts continuously when a bank's equity-debt ratio drops to a trigger level.\nThe main theoretical result is a complete characterization of the clearing\nproblem for the interbank debt and equity at the maturity of the obligations.\nWe then introduce stylized networks to study when introducing contingent\nconvertible bonds improves financial stability, as well as specific networks\nfor which contingent convertible bonds do not provide uniformly improved system\nperformance. To return to the main question, we examine the EU financial\nnetwork at the time of the 2011 EBA stress test to do comparative statics to\nstudy the implications of CoCo debt on financial stability. It is found that by\nreplacing all unsecured interbank debt by standardized CoCo interbank debt\nsecurities, systemic risk in the EU will decrease and bank shareholder value\nwill increase.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2020 16:04:25 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 14:57:51 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Feinstein", "Zachary", ""], ["Hurd", "T. R.", ""]]}, {"id": "2006.01802", "submitter": "Roger Laeven", "authors": "Roger J. A. Laeven, John G. M. Schoenmakers, Nikolaus F. F. Schweizer,\n  Mitja Stadje", "title": "Robust Multiple Stopping -- A Pathwise Duality Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a solution method for general optimal stopping\nproblems. Our general setting allows for multiple exercise rights, i.e.,\noptimal multiple stopping, for a robust evaluation that accounts for model\nuncertainty, and for general reward processes driven by multi-dimensional\njump-diffusions. Our approach relies on first establishing robust martingale\ndual representation results for the multiple stopping problem which satisfy\nappealing pathwise optimality (almost sure) properties. Next, we exploit these\ntheoretical results to develop upper and lower bounds which, as we formally\nshow, not only converge to the true solution asymptotically, but also\nconstitute genuine upper and lower bounds. We illustrate the applicability of\nour general approach in a few examples and analyze the impact of model\nuncertainty on optimal multiple stopping strategies.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2020 17:37:02 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Laeven", "Roger J. A.", ""], ["Schoenmakers", "John G. M.", ""], ["Schweizer", "Nikolaus F. F.", ""], ["Stadje", "Mitja", ""]]}, {"id": "2006.03014", "submitter": "Ioannis Anagnostou", "authors": "Ioannis Anagnostou, Tiziano Squartini, Drona Kandhai, Diego\n  Garlaschelli", "title": "Uncovering the mesoscale structure of the credit default swap market to\n  improve portfolio risk modelling", "comments": "Quantitative Finance (2021)", "journal-ref": null, "doi": "10.1080/14697688.2021.1890807", "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging aspects in the analysis and modelling of\nfinancial markets, including Credit Default Swap (CDS) markets, is the presence\nof an emergent, intermediate level of structure standing in between the\nmicroscopic dynamics of individual financial entities and the macroscopic\ndynamics of the market as a whole. This elusive, mesoscopic level of\norganisation is often sought for via factor models that ultimately decompose\nthe market according to geographic regions and economic industries. However, at\na more general level the presence of mesoscopic structure might be revealed in\nan entirely data-driven approach, looking for a modular and possibly\nhierarchical organisation of the empirical correlation matrix between financial\ntime series. The crucial ingredient in such an approach is the definition of an\nappropriate null model for the correlation matrix. Recent research showed that\ncommunity detection techniques developed for networks become intrinsically\nbiased when applied to correlation matrices. For this reason, a method based on\nRandom Matrix Theory has been developed, which identifies the optimal\nhierarchical decomposition of the system into internally correlated and\nmutually anti-correlated communities. Building upon this technique, here we\nresolve the mesoscopic structure of the CDS market and identify groups of\nissuers that cannot be traced back to standard industry/region taxonomies,\nthereby being inaccessible to standard factor models. We use this decomposition\nto introduce a novel default risk model that is shown to outperform more\ntraditional alternatives.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2020 17:02:52 GMT"}, {"version": "v2", "created": "Fri, 9 Apr 2021 12:18:05 GMT"}], "update_date": "2021-04-12", "authors_parsed": [["Anagnostou", "Ioannis", ""], ["Squartini", "Tiziano", ""], ["Kandhai", "Drona", ""], ["Garlaschelli", "Diego", ""]]}, {"id": "2006.04639", "submitter": "Jozef Barunik", "authors": "Jozef Barunik and Michael Ellington", "title": "Dynamic Network Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines the pricing of short-term and long-term dynamic network\nrisk in the cross-section of stock returns. Stocks with high sensitivities to\ndynamic network risk earn lower returns. We rationalize our finding with\neconomic theory that allows the stochastic discount factor to load on network\nrisk through the precautionary savings channel. A one-standard deviation\nincrease in long-term (short-term) network risk loadings associate with a 7.66%\n(6.71%) drop in annualized expected returns.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 14:37:04 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2020 10:23:53 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Barunik", "Jozef", ""], ["Ellington", "Michael", ""]]}, {"id": "2006.05632", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze", "title": "Quant Bust 2020", "comments": "29 pages; to appear in the Apr-Jun 2020 issue of The World Economics\n  Journal", "journal-ref": "World Economics 21(2) (2020) 183-217", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explain in a nontechnical fashion why dollar-neutral quant trading\nstrategies, such as equities Statistical Arbitrage, suffered substantial losses\n(drawdowns) during the COVID-19 market selloff. We discuss: (i) why these\nstrategies work during \"normal\" times; (ii) the market regimes when they work\nbest; and (iii) their limitations and the reasons for why they \"break\" during\nextreme market events. An accompanying appendix (with a link to freely\naccessible source code) includes backtests for various strategies, which put\nflesh on and illustrate the discussion in the main text.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 03:17:26 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Kakushadze", "Zura", ""]]}, {"id": "2006.05750", "submitter": "Christoph Berninger", "authors": "Christoph Berninger, Almond St\\\"ocker, David R\\\"ugamer", "title": "A Bayesian Time-Varying Autoregressive Model for Improved Short- and\n  Long-Term Prediction", "comments": "Revised Introduction, results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the application to German interest rates, we propose a\ntimevarying autoregressive model for short and long term prediction of time\nseries that exhibit a temporary non-stationary behavior but are assumed to mean\nrevert in the long run. We use a Bayesian formulation to incorporate prior\nassumptions on the mean reverting process in the model and thereby regularize\npredictions in the far future. We use MCMC-based inference by deriving relevant\nfull conditional distributions and employ a Metropolis-Hastings within Gibbs\nSampler approach to sample from the posterior (predictive) distribution. In\ncombining data-driven short term predictions with long term distribution\nassumptions our model is competitive to the existing methods in the short\nhorizon while yielding reasonable predictions in the long run. We apply our\nmodel to interest rate data and contrast the forecasting performance to the one\nof a 2-Additive-Factor Gaussian model as well as to the predictions of a\ndynamic Nelson-Siegel model.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 09:39:07 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 18:24:11 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Berninger", "Christoph", ""], ["St\u00f6cker", "Almond", ""], ["R\u00fcgamer", "David", ""]]}, {"id": "2006.06076", "submitter": "Richard Martin", "authors": "Richard J. Martin and Aldous Birchall", "title": "Black to Negative: Embedded optionalities in commodities markets", "comments": "Extended section on Levy models and given explicit formulae and\n  numerical example. Corrected typo in put/call formulae (eq.5,6 in this vsn)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the modelling of commodities that are supposed to have positive\nprice but, on account of a possible failure in the physical delivery mechanism,\nmay turn out not to. This is done by explicitly incorporating a `delivery\nliability' option into the contract. As such it is a simple generalisation of\nthe established Black model.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2020 21:37:50 GMT"}, {"version": "v2", "created": "Thu, 29 Oct 2020 15:57:41 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Martin", "Richard J.", ""], ["Birchall", "Aldous", ""]]}, {"id": "2006.08110", "submitter": "Nils Detering", "authors": "Nils Detering, Thilo Meyer-Brandis, Konstantinos Panagiotou, Daniel\n  Ritter", "title": "Suffocating Fire Sales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fire sales are among the major drivers of market instability in modern\nfinancial systems. Due to iterated distressed selling and the associated price\nimpact, initial shocks to some institutions can be amplified dramatically\nthrough the network induced by portfolio overlaps. In this paper we develop a\nmathematical framework that allow us to investigate central characteristics\nthat drive or hinder the propagation of distress. We investigate single systems\nas well as ensembles of systems that are alike, where similarity is measured in\nterms of the empirical distribution of all defining properties of a system.\nThis asymptotic approach ensures a great deal of robustness to statistical\nuncertainty and temporal fluctuations. A characterization of those systems that\nare resilient to small shocks emerges, and we provide explicit criteria that\nregulators may exploit in order to assess the stability of any system.\n  We illustrate the application of these criteria for some exemplary\nconfigurations in the context of capital requirements and test the\napplicability of our results for systems of moderate size by Monte Carlo\nsimulations.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2020 03:33:29 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 05:13:29 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Detering", "Nils", ""], ["Meyer-Brandis", "Thilo", ""], ["Panagiotou", "Konstantinos", ""], ["Ritter", "Daniel", ""]]}, {"id": "2006.09542", "submitter": "Zhibin Niu", "authors": "Zhibin Niu, Runlin Li, Junqi Wu, Dawei Cheng, Jiawan Zhang", "title": "iConViz: Interactive Visual Exploration of the Default Contagion Risk of\n  Networked-Guarantee Loans", "comments": "2020 IEEE Conference on Visual Analytics Science and Technology\n  (VAST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Groups of enterprises can serve as guarantees for one another and form\ncomplex networks when obtaining loans from commercial banks. During economic\nslowdowns, corporate default may spread like a virus and lead to large-scale\ndefaults or even systemic financial crises. To help financial regulatory\nauthorities and banks manage the risk associated with networked loans, we\nidentified the default contagion risk, a pivotal issue in developing preventive\nmeasures, and established iConVis, an interactive visual analysis tool that\nfacilitates the closed-loop analysis process. A novel financial metric, the\ncontagion effect, was formulated to quantify the infectious consequences of\nguarantee chains in this type of network. Based on this metric, we designed and\nimplement a series of novel and coordinated views that address the analysis of\nfinancial problems. Experts evaluated the system using real-world financial\ndata. The proposed approach grants practitioners the ability to avoid previous\nad hoc analysis methodologies and extend coverage of the conventional Capital\nAccord to the banking industry.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2020 22:17:56 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 19:25:34 GMT"}, {"version": "v3", "created": "Sat, 29 Aug 2020 20:51:57 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Niu", "Zhibin", ""], ["Li", "Runlin", ""], ["Wu", "Junqi", ""], ["Cheng", "Dawei", ""], ["Zhang", "Jiawan", ""]]}, {"id": "2006.09955", "submitter": "Giacomo Bormetti", "authors": "Pietro Rossi, Flavio Cocco, and Giacomo Bormetti", "title": "Deep learning Profit & Loss", "comments": "19 pages, 3 figures, and 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building the future profit and loss (P&L) distribution of a portfolio\nholding, among other assets, highly non-linear and path-dependent derivatives\nis a challenging task. We provide a simple machinery where more and more assets\ncould be accounted for in a simple and semi-automatic fashion. We resort to a\nvariation of the Least Square Monte Carlo algorithm where interpolation of the\ncontinuation value of the portfolio is done with a feed forward neural network.\nThis approach has several appealing features not all of them will be fully\ndiscussed in the paper. Neural networks are extremely flexible regressors. We\ndo not need to worry about the fact that for multi assets payoff, the exercise\nsurface could be non connected. Neither we have to search for smart regressors.\nThe idea is to use, regardless of the complexity of the payoff, only the\nunderlying processes. Neural networks with many outputs can interpolate every\nsingle assets in the portfolio generated by a single Monte Carlo simulation.\nThis is an essential feature to account for the P&L distribution of the whole\nportfolio when the dependence structure between the different assets is very\nstrong like the case where one has contingent claims written on the same\nunderlying.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2020 16:07:03 GMT"}, {"version": "v2", "created": "Thu, 27 Aug 2020 08:56:02 GMT"}], "update_date": "2020-08-28", "authors_parsed": [["Rossi", "Pietro", ""], ["Cocco", "Flavio", ""], ["Bormetti", "Giacomo", ""]]}, {"id": "2006.11146", "submitter": "Richard Martin", "authors": "Richard J. Martin", "title": "Credit migration: Generating generators", "comments": "Minor corrections from V1", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.CP q-fin.MF q-fin.PR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Markovian credit migration models are a reasonably standard tool nowadays,\nbut there are fundamental difficulties with calibrating them. We show how these\nare resolved using a simplified form of matrix generator and explain why\nrisk-neutral calibration cannot be done without volatility information. We also\nshow how to use elementary ideas from differential geometry to make general\ninferences about calibration stability. This the longer version of an article\npublished by RISK (Feb 2021).\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2020 14:12:13 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 14:34:01 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Martin", "Richard J.", ""]]}, {"id": "2006.12686", "submitter": "Nelson Vadori", "authors": "Nelson Vadori and Sumitra Ganesh and Prashant Reddy and Manuela Veloso", "title": "Risk-Sensitive Reinforcement Learning: a Martingale Approach to Reward\n  Uncertainty", "comments": "Published at ICAIF 2020: ACM International Conference on AI in\n  Finance", "journal-ref": null, "doi": "10.1145/3383455.3422519", "report-no": null, "categories": "cs.LG q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel framework to account for sensitivity to rewards\nuncertainty in sequential decision-making problems. While risk-sensitive\nformulations for Markov decision processes studied so far focus on the\ndistribution of the cumulative reward as a whole, we aim at learning policies\nsensitive to the uncertain/stochastic nature of the rewards, which has the\nadvantage of being conceptually more meaningful in some cases. To this end, we\npresent a new decomposition of the randomness contained in the cumulative\nreward based on the Doob decomposition of a stochastic process, and introduce a\nnew conceptual tool - the \\textit{chaotic variation} - which can rigorously be\ninterpreted as the risk measure of the martingale component associated to the\ncumulative reward process. We innovate on the reinforcement learning side by\nincorporating this new risk-sensitive approach into model-free algorithms, both\npolicy gradient and value function based, and illustrate its relevance on grid\nworld and portfolio optimization problems.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2020 01:20:00 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2020 13:50:26 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Vadori", "Nelson", ""], ["Ganesh", "Sumitra", ""], ["Reddy", "Prashant", ""], ["Veloso", "Manuela", ""]]}, {"id": "2006.13921", "submitter": "Revathi Bhuvaneswari", "authors": "Revathi Bhuvaneswari, Antonio Segalini", "title": "Determining Secondary Attributes for Credit Evaluation in P2P Lending", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.GN cs.LG q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been an increased need for secondary means of credit evaluation by\nboth traditional banking organizations as well as peer-to-peer lending\nentities. This is especially important in the present technological era where\nsticking with strict primary credit histories doesn't help distinguish between\na 'good' and a 'bad' borrower, and ends up hurting both the individual borrower\nas well as the investor as a whole. We utilized machine learning classification\nand clustering algorithms to accurately predict a borrower's creditworthiness\nwhile identifying specific secondary attributes that contribute to this score.\nWhile extensive research has been done in predicting when a loan would be fully\npaid, the area of feature selection for lending is relatively new. We achieved\n65% F1 and 73% AUC on the LendingClub data while identifying key secondary\nattributes.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2020 16:12:00 GMT"}], "update_date": "2020-06-25", "authors_parsed": [["Bhuvaneswari", "Revathi", ""], ["Segalini", "Antonio", ""]]}, {"id": "2006.14272", "submitter": "Max Nendel", "authors": "Max Nendel, Frank Riedel, Maren Diane Schmeck", "title": "A decomposition of general premium principles into risk and deviation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide an axiomatic approach to general premium principles in a\nprobability-free setting that allows for Knightian uncertainty. Every premium\nprinciple is the sum of a risk measure, as a generalization of the expected\nvalue, and a deviation measure, as a generalization of the variance. One can\nuniquely identify a maximal risk measure and a minimal deviation measure in\nsuch decompositions. We show how previous axiomatizations of premium principles\ncan be embedded into our more general framework. We discuss dual\nrepresentations of convex premium principles, and study the consistency of\npremium principles with a financial market in which insurance contracts are\ntraded.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2020 09:32:14 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2020 23:29:12 GMT"}, {"version": "v3", "created": "Fri, 18 Dec 2020 16:15:42 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Nendel", "Max", ""], ["Riedel", "Frank", ""], ["Schmeck", "Maren Diane", ""]]}, {"id": "2006.15491", "submitter": "Wei Wang", "authors": "Wei Wang, Huifu Xu and Tiejun Ma", "title": "Quantitative Statistical Robustness for Tail-Dependent Law Invariant\n  Risk Measures", "comments": "28 pages; 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM econ.EM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When estimating the risk of a financial position with empirical data or Monte\nCarlo simulations via a tail-dependent law invariant risk measure such as the\nConditional Value-at-Risk (CVaR), it is important to ensure the robustness of\nthe statistical estimator particularly when the data contain noise. Kr\u007fatscher\net al. [1] propose a new framework to examine the qualitative robustness of\nestimators for tail-dependent law invariant risk measures on Orlicz spaces,\nwhich is a step further from earlier work for studying the robustness of risk\nmeasurement procedures by Cont et al. [2]. In this paper, we follow the stream\nof research to propose a quantitative approach for verifying the statistical\nrobustness of tail-dependent law invariant risk measures. A distinct feature of\nour approach is that we use the Fortet-Mourier metric to quantify the variation\nof the true underlying probability measure in the analysis of the discrepancy\nbetween the laws of the plug-in estimators of law invariant risk measure based\non the true data and perturbed data, which enables us to derive an explicit\nerror bound for the discrepancy when the risk functional is Lipschitz\ncontinuous with respect to a class of admissible laws. Moreover, the newly\nintroduced notion of Lipschitz continuity allows us to examine the degree of\nrobustness for tail-dependent risk measures. Finally, we apply our quantitative\napproach to some well-known risk measures to illustrate our theory.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jun 2020 02:52:32 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Wang", "Wei", ""], ["Xu", "Huifu", ""], ["Ma", "Tiejun", ""]]}, {"id": "2006.16383", "submitter": "Eduardo Ramos", "authors": "E. Ramos-P\\'erez, P.J. Alonso-Gonz\\'alez, J.J. N\\'u\\~nez-Vel\\'azquez", "title": "Forecasting volatility with a stacked model based on a hybridized\n  Artificial Neural Network", "comments": "22 pages, 7 tables, 1 Figure. Published in Expert Systems with\n  Applications, Volume 129, 1 September 2019, Pages 1-9", "journal-ref": "Expert Systems with Applications, Volume 129, 1 September 2019,\n  Pages 1-9", "doi": "10.1016/j.eswa.2019.03.046", "report-no": null, "categories": "q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An appropriate calibration and forecasting of volatility and market risk are\nsome of the main challenges faced by companies that have to manage the\nuncertainty inherent to their investments or funding operations such as banks,\npension funds or insurance companies. This has become even more evident after\nthe 2007-2008 Financial Crisis, when the forecasting models assessing the\nmarket risk and volatility failed. Since then, a significant number of\ntheoretical developments and methodologies have appeared to improve the\naccuracy of the volatility forecasts and market risk assessments. Following\nthis line of thinking, this paper introduces a model based on using a set of\nMachine Learning techniques, such as Gradient Descent Boosting, Random Forest,\nSupport Vector Machine and Artificial Neural Network, where those algorithms\nare stacked to predict S&P500 volatility. The results suggest that our\nconstruction outperforms other habitual models on the ability to forecast the\nlevel of volatility, leading to a more accurate assessment of the market risk.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 21:01:24 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 18:28:29 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Ramos-P\u00e9rez", "E.", ""], ["Alonso-Gonz\u00e1lez", "P. J.", ""], ["N\u00fa\u00f1ez-Vel\u00e1zquez", "J. J.", ""]]}]