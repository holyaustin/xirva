[{"id": "1610.00256", "submitter": "Chris Kenyon", "authors": "Andrew Green and Chris Kenyon", "title": "XVA at the Exercise Boundary", "comments": "15 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.CP q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  XVA is a material component of a trade valuation and hence it must impact the\ndecision to exercise options within a given netting set. This is true for both\nunsecured trades and secured / cleared trades where KVA and MVA play a material\nrole even if CVA and FVA do not. However, this effect has frequently been\nignored in XVA models and indeed in exercise decisions made by option owners.\nThis paper describes how XVA impacts the exercise decision and how this can be\nreadily evaluated using regression techniques (Longstaff and Schwartz 2001).\nThe paper then assesses the materiality of the impact of XVA at the exercise\nboundary on swaption examples.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 10:25:56 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Green", "Andrew", ""], ["Kenyon", "Chris", ""]]}, {"id": "1610.00795", "submitter": "Daniele Petrone", "authors": "Daniele Petrone and Vito Latora", "title": "A dynamic approach merging network theory and credit risk techniques to\n  assess systemic risk in financial networks", "comments": "8 pages, 5 figures, 1 table", "journal-ref": "Scientific Reports 8 (2018) 5561", "doi": "10.1038/s41598-018-23689-5", "report-no": null, "categories": "q-fin.CP q-fin.RM q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interconnectedness of financial institutions affects instability and\ncredit crises. To quantify systemic risk we introduce here the PD model, a\ndynamic model that combines credit risk techniques with a contagion mechanism\non the network of exposures among banks. A potential loss distribution is\nobtained through a multi-period Monte Carlo simulation that considers the\nprobability of default (PD) of the banks and their tendency of defaulting in\nthe same time interval. A contagion process increases the PD of banks exposed\ntoward distressed counterparties. The systemic risk is measured by statistics\nof the loss distribution, while the contribution of each node is quantified by\nthe new measures PDRank and PDImpact. We illustrate how the model works on the\nnetwork of the European Global Systemically Important Banks. For a certain\nrange of the banks' capital and of their assets volatility, our results reveal\nthe emergence of a strong contagion regime where lower default correlation\nbetween banks corresponds to higher losses. This is the opposite of the\ndiversification benefits postulated by standard credit risk models used by\nbanks and regulators who could therefore underestimate the capital needed to\novercome a period of crisis, thereby contributing to the financial system\ninstability.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 23:40:44 GMT"}, {"version": "v2", "created": "Sun, 8 Apr 2018 12:34:28 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Petrone", "Daniele", ""], ["Latora", "Vito", ""]]}, {"id": "1610.02126", "submitter": "Jianxi Su", "authors": "Jianxi Su and Edward Furman", "title": "Multiple risk factor dependence structures: Copulas and related\n  properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Copulas have become an important tool in the modern best practice Enterprise\nRisk Management, often supplanting other approaches to modelling stochastic\ndependence. However, choosing the `right' copula is not an easy task, and the\ntemptation to prefer a tractable rather than a meaningful candidate from the\nencompassing copulas toolbox is strong. The ubiquitous applications of the\nGaussian copula is just one illuminating example.\n  Speaking generally, a `good' copula should conform to the problem at hand,\nallow for asymmetry in the domain of definition and exhibit some extent of tail\ndependence. In this paper we introduce and study a new class of Multiple Risk\nFactor (MRF) copula functions, which we show are exactly such. Namely, the MRF\ncopulas (1) arise from a number of meaningful default risk specification with\nstochastic default barriers, (2) are in general non-exchangeable and (3)\npossess a variety of tail dependences. That being said, the MRF copulas turn\nout to be surprisingly tractable analytically.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 02:19:46 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Su", "Jianxi", ""], ["Furman", "Edward", ""]]}, {"id": "1610.03259", "submitter": "Giulio Cimini", "authors": "Giuseppe Brandi, Riccardo Di Clemente, Giulio Cimini", "title": "Epidemics of Liquidity Shortages in Interbank Markets", "comments": null, "journal-ref": "Physica A: Statistical Mechanics and its Applications 507, pp\n  255-267, (2018)", "doi": "10.1016/j.physa.2018.05.104", "report-no": null, "categories": "q-fin.RM physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Financial contagion from liquidity shocks has being recently ascribed as a\nprominent driver of systemic risk in interbank lending markets. Building on\nstandard compartment models used in epidemics, in this work we develop an EDB\n(Exposed-Distressed-Bankrupted) model for the dynamics of liquidity shocks\nreverberation between banks, and validate it on electronic market for interbank\ndeposits data. We show that the interbank network was highly susceptible to\nliquidity contagion at the beginning of the 2007/2008 global financial crisis,\nand that the subsequent micro-prudential and liquidity hoarding policies\nadopted by banks increased the network resilience to systemic risk---yet with\nthe undesired side effect of drying out liquidity from the market. We finally\nshow that the individual riskiness of a bank is better captured by its network\ncentrality than by its participation to the market, along with the currently\ndebated concept of \"too interconnected to fail\".\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 10:01:05 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 09:11:11 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Brandi", "Giuseppe", ""], ["Di Clemente", "Riccardo", ""], ["Cimini", "Giulio", ""]]}, {"id": "1610.03718", "submitter": "J.D. Opdyke", "authors": "J.D. Opdyke", "title": "Fast, Accurate, Straightforward Extreme Quantiles of Compound Loss\n  Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an easily implemented, fast, and accurate method for approximating\nextreme quantiles of compound loss distributions (frequency+severity) as are\ncommonly used in insurance and operational risk capital models. The\nInterpolated Single Loss Approximation (ISLA) of Opdyke (2014) is based on the\nwidely used Single Loss Approximation (SLA) of Degen (2010) and maintains two\nimportant advantages over its competitors: first, ISLA correctly accounts for a\ndiscontinuity in SLA that otherwise can systematically and notably bias the\nquantile (capital) approximation under conditions of both finite and infinite\nmean. Secondly, because it is based on a closed-form approximation, ISLA\nmaintains the notable speed advantages of SLA over other methods requiring\nalgorithmic looping (e.g. fast Fourier transform or Panjer recursion). Speed is\nimportant when simulating many quantile (capital) estimates, as is so often\nrequired in practice, and essential when simulations of simulations are needed\n(e.g. some power studies). The modified ISLA (MISLA) presented herein increases\nthe range of application across the severity distributions most commonly used\nin these settings, and it is tested against extensive Monte Carlo simulation\n(one billion years' worth of losses) and the best competing method (the\nperturbative expansion (PE2) of Hernandez et al., 2014) using twelve\nheavy-tailed severity distributions, some of which are truncated. MISLA is\nshown to be comparable to PE2 in terms of both speed and accuracy, and it is\narguably more straightforward to implement for the majority of Advanced\nMeasurement Approaches (AMA) banks that are already using SLA (and failing to\ntake into account its biasing discontinuity).\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 14:04:45 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2016 12:10:11 GMT"}, {"version": "v3", "created": "Thu, 5 Jan 2017 20:03:11 GMT"}, {"version": "v4", "created": "Mon, 23 Jan 2017 15:40:09 GMT"}, {"version": "v5", "created": "Sat, 28 Jan 2017 23:23:02 GMT"}, {"version": "v6", "created": "Mon, 17 Apr 2017 20:18:44 GMT"}, {"version": "v7", "created": "Tue, 18 Jul 2017 21:00:54 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Opdyke", "J. D.", ""]]}, {"id": "1610.03769", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze", "title": "On Origins of Bubbles", "comments": "26 pages; a trivial typo corrected, no other changes", "journal-ref": "Journal of Risk & Control 4(1) (2017) 1-30", "doi": null, "report-no": null, "categories": "q-fin.RM hep-th q-fin.MF quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss - in what is intended to be a pedagogical fashion - a criterion,\nwhich is a lower bound on a certain ratio, for when a stock (or a similar\ninstrument) is not a good investment in the long term, which can happen even if\nthe expected return is positive. The root cause is that prices are positive and\nhave skewed, long-tailed distributions, which coupled with volatility results\nin a long-run asymmetry. This relates to bubbles in stock prices, which we\ndiscuss using a simple binomial tree model, without resorting to the stochastic\ncalculus machinery. We illustrate empirical properties of the aforesaid ratio.\nLog of market cap and sectors appear to be relevant explanatory variables for\nthis ratio, while price-to-book ratio (or its log) is not. We also discuss a\nshort-term effect of volatility, to wit, the analog of Heisenberg's uncertainty\nprinciple in finance and a simple derivation thereof using a binary tree.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 16:12:53 GMT"}, {"version": "v2", "created": "Sun, 30 Jul 2017 18:31:15 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Kakushadze", "Zura", ""]]}, {"id": "1610.07131", "submitter": "Pingjin Deng", "authors": "Pingjin Deng", "title": "Asymptotic of Non-Crossings probability of Additive Wiener Fields", "comments": "12 pages. arXiv admin note: text overlap with arXiv:1402.2620 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $W_i=\\{W_i(t_i), t_i\\in \\R_+\\}, i=1,2,\\ldots,d$ are independent Wiener\nprocesses. $W=\\{W(\\mathbf{t}),t\\in \\R_+^d\\}$ be the additive Wiener field\ndefine as the sum of $W_i$. For any trend $f$ in $\\kHC$ (the reproducing kernel\nHilbert Space of $W$), we derive upper and lower bounds for the boundary\nnon-crossing probability $$P_f=P\\{\\sum_{i=1}^{d}W_i(t_i) +f(\\mathbf{t})\\leq\nu(\\mathbf{t}), \\mathbf{t}\\in\\R_+^d\\},$$ where $u: \\R_+^d\\rightarrow \\R_+$ is a\nmeasurable function. Furthermore, for large trend functions $\\gamma f>0$, we\nshow that the asymptotically relation $\\ln P_{\\gamma f}\\sim \\ln P_{\\gamma\n\\underline{f}}$ as $\\gamma \\to \\IF$, where $\\underline{f}$ is the projection of\n$f$ on some closed convex subset of $\\kHC$.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 08:35:28 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Deng", "Pingjin", ""]]}, {"id": "1610.08143", "submitter": "Zheng Wang", "authors": "Tim Leung and Zheng Wang", "title": "Optimal Risk-Averse Timing of an Asset Sale: Trending vs Mean-Reverting\n  Price Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.RM q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the optimal risk-averse timing to sell a risky asset. The\ninvestor's risk preference is described by the exponential, power, or log\nutility. Two stochastic models are considered for the asset price -- the\ngeometric Brownian motion and exponential Ornstein-Uhlenbeck models -- to\naccount for, respectively, the trending and mean-reverting price dynamics. In\nall cases, we derive the optimal thresholds and certainty equivalents to sell\nthe asset, and compare them across models and utilities, with emphasis on their\ndependence on asset price, risk aversion, and quantity. We find that the timing\noption may render the investor's value function and certainty equivalent\nnon-concave in price. Numerical results are provided to illustrate the\ninvestor's strategies and the premium associated with optimally timing to sell.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 01:55:13 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Leung", "Tim", ""], ["Wang", "Zheng", ""]]}, {"id": "1610.08230", "submitter": "Zhi-Qiang Jiang", "authors": "Zhi-Qiang Jiang (ECUST, BU), Gang-Jin Wang (HNU, BU), Askery Canabarro\n  (BU, UFA), Boris Podobnik (ZSEM), Chi Xie (HNU), H. Eugene Stanley (BU),\n  Wei-Xing Zhou (ECUST)", "title": "Short term prediction of extreme returns based on the recurrence\n  interval analysis", "comments": "18 pages, 5 figues, 3 tables", "journal-ref": "Quantitative Finance 18 (3), 353-370 (2018)", "doi": "10.1080/14697688.2017.1373843", "report-no": null, "categories": "q-fin.ST q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being able to predict the occurrence of extreme returns is important in\nfinancial risk management. Using the distribution of recurrence intervals---the\nwaiting time between consecutive extremes---we show that these extreme returns\nare predictable on the short term. Examining a range of different types of\nreturns and thresholds we find that recurrence intervals follow a\n$q$-exponential distribution, which we then use to theoretically derive the\nhazard probability $W(\\Delta t |t)$. Maximizing the usefulness of extreme\nforecasts to define an optimized hazard threshold, we indicates a financial\nextreme occurring within the next day when the hazard probability is greater\nthan the optimized threshold. Both in-sample tests and out-of-sample\npredictions indicate that these forecasts are more accurate than a benchmark\nthat ignores the predictive signals. This recurrence interval finding deepens\nour understanding of reoccurring extreme returns and can be applied to forecast\nextremes in risk management.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 08:49:33 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Jiang", "Zhi-Qiang", "", "ECUST, BU"], ["Wang", "Gang-Jin", "", "HNU, BU"], ["Canabarro", "Askery", "", "BU, UFA"], ["Podobnik", "Boris", "", "ZSEM"], ["Xie", "Chi", "", "HNU"], ["Stanley", "H. Eugene", "", "BU"], ["Zhou", "Wei-Xing", "", "ECUST"]]}, {"id": "1610.08782", "submitter": "Alexander Smirnow", "authors": "W. Farkas, A. Smirnow", "title": "Intrinsic risk measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monetary risk measures are usually interpreted as the smallest amount of\nexternal capital that must be added to a financial position to make it\nacceptable. We propose a new concept: intrinsic risk measures and argue that\nthis approach provides a direct path from unacceptable positions towards the\nacceptance set. Intrinsic risk measures use only internal resources and return\nthe smallest percentage of the currently held financial position which has to\nbe sold and reinvested into an eligible asset such that the resulting position\nbecomes acceptable. While avoiding the problem of infinite values, intrinsic\nrisk measures allow a free choice of the eligible asset and they preserve\ndesired properties such as monotonicity and quasi-convexity. A dual\nrepresentation on convex acceptance sets is derived and the link of intrinsic\nrisk measures to their monetary counterparts on cones is detailed.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 13:57:57 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Farkas", "W.", ""], ["Smirnow", "A.", ""]]}, {"id": "1610.09542", "submitter": "Nils Detering", "authors": "Nils Detering, Thilo Meyer-Brandis, Konstantinos Panagiotou and Daniel\n  Ritter", "title": "Managing Default Contagion in Inhomogeneous Financial Networks", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to quantify and manage systemic risk caused by\ndefault contagion in the interbank market. We model the market as a random\ndirected network, where the vertices represent financial institutions and the\nweighted edges monetary exposures between them. Our model captures the strong\ndegree of heterogeneity observed in empirical data and the parameters can\neasily be fitted to real data sets. One of our main results allows us to\ndetermine the impact of local shocks, where initially some banks default, to\nthe entire system and the wider economy. Here the impact is measured by some\nindex of total systemic importance of all eventually defaulted institutions. As\na central application, we characterize resilient and non-resilient cases. In\nparticular, for the prominent case where the network has a degree sequence\nwithout second moment, we show that a small number of initially defaulted banks\ncan trigger a substantial default cascade. Our results complement and extend\nsignificantly earlier findings derived in the configuration model where the\nexistence of a second moment of the degree distribution is assumed. As a second\nmain contribution, paralleling regulatory discussions, we determine minimal\ncapital requirements for financial institutions sufficient to make the network\nresilient to small shocks. An appealing feature of these capital requirements\nis that they can be determined locally by each institution without knowing the\ncomplete network structure as they basically only depend on the institution's\nexposures to its counterparties.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 17:09:22 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 14:23:30 GMT"}, {"version": "v3", "created": "Wed, 8 Nov 2017 18:34:07 GMT"}, {"version": "v4", "created": "Fri, 21 Sep 2018 07:31:46 GMT"}, {"version": "v5", "created": "Sat, 22 Dec 2018 16:02:49 GMT"}, {"version": "v6", "created": "Tue, 12 Jan 2021 17:23:58 GMT"}, {"version": "v7", "created": "Thu, 14 Jan 2021 21:29:46 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Detering", "Nils", ""], ["Meyer-Brandis", "Thilo", ""], ["Panagiotou", "Konstantinos", ""], ["Ritter", "Daniel", ""]]}, {"id": "1610.09734", "submitter": "Antonis Papapantoleon", "authors": "Thibaut Lux, Antonis Papapantoleon", "title": "Model-free bounds on Value-at-Risk using extreme value information and\n  statistical distances", "comments": "22 pages, revised version with new title", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive bounds on the distribution function, therefore also on the\nValue-at-Risk, of $\\varphi(\\mathbf X)$ where $\\varphi$ is an aggregation\nfunction and $\\mathbf X = (X_1,\\dots,X_d)$ is a random vector with known\nmarginal distributions and partially known dependence structure. More\nspecifically, we analyze three types of available information on the dependence\nstructure: First, we consider the case where extreme value information, such as\nthe distributions of partial minima and maxima of $\\mathbf X$, is available. In\norder to include this information in the computation of Value-at-Risk bounds,\nwe utilize a reduction principle that relates this problem to an optimization\nproblem over a standard Fr\\'echet class, which can then be solved by means of\nthe rearrangement algorithm or using analytical results. Second, we assume that\nthe copula of $\\mathbf X$ is known on a subset of its domain, and finally we\nconsider the case where the copula of $\\mathbf X$ lies in the vicinity of a\nreference copula as measured by a statistical distance. In order to derive\nValue-at-Risk bounds in the latter situations, we first improve the\nFr\\'echet--Hoeffding bounds on copulas so as to include this additional\ninformation on the dependence structure. Then, we translate the improved\nFr\\'echet--Hoeffding bounds to bounds on the Value-at-Risk using the so-called\nimproved standard bounds. In numerical examples we illustrate that the\nadditional information typically leads to a significant improvement of the\nbounds compared to the marginals-only case.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 00:00:09 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2016 22:02:39 GMT"}, {"version": "v3", "created": "Thu, 15 Jun 2017 23:08:26 GMT"}, {"version": "v4", "created": "Sat, 17 Nov 2018 17:40:44 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Lux", "Thibaut", ""], ["Papapantoleon", "Antonis", ""]]}]