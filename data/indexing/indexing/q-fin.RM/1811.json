[{"id": "1811.00304", "submitter": "Stephan Eckstein", "authors": "Stephan Eckstein, Michael Kupper, Mathias Pohl", "title": "Robust risk aggregation with neural networks", "comments": "Revised version. Accepted for publication in \"Mathematical Finance\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF math.OC q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider settings in which the distribution of a multivariate random\nvariable is partly ambiguous. We assume the ambiguity lies on the level of the\ndependence structure, and that the marginal distributions are known.\nFurthermore, a current best guess for the distribution, called reference\nmeasure, is available. We work with the set of distributions that are both\nclose to the given reference measure in a transportation distance (e.g. the\nWasserstein distance), and additionally have the correct marginal structure.\nThe goal is to find upper and lower bounds for integrals of interest with\nrespect to distributions in this set. The described problem appears naturally\nin the context of risk aggregation. When aggregating different risks, the\nmarginal distributions of these risks are known and the task is to quantify\ntheir joint effect on a given system. This is typically done by applying a\nmeaningful risk measure to the sum of the individual risks. For this purpose,\nthe stochastic interdependencies between the risks need to be specified. In\npractice the models of this dependence structure are however subject to\nrelatively high model ambiguity. The contribution of this paper is twofold:\nFirstly, we derive a dual representation of the considered problem and prove\nthat strong duality holds. Secondly, we propose a generally applicable and\ncomputationally feasible method, which relies on neural networks, in order to\nnumerically solve the derived dual problem. The latter method is tested on a\nnumber of toy examples, before it is finally applied to perform robust risk\naggregation in a real world instance.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 10:32:03 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 12:53:15 GMT"}, {"version": "v3", "created": "Tue, 26 May 2020 09:15:51 GMT"}], "update_date": "2020-05-27", "authors_parsed": [["Eckstein", "Stephan", ""], ["Kupper", "Michael", ""], ["Pohl", "Mathias", ""]]}, {"id": "1811.00952", "submitter": "Marcus Christiansen", "authors": "Marcus C. Christiansen", "title": "A martingale concept for non-monotone information in a jump process\n  framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information dynamics in finance and insurance applications is usually\nmodeled by a filtration. This paper looks at situations where information\nrestrictions apply such that the information dynamics may become non-monotone.\nA fundamental tool for calculating and managing risks in finance and insurance\nare martingale representations. We present a general theory that extends\nclassical martingale representations to non-monotone information generated by\nmarked point processes. The central idea is to focus only on those properties\nthat martingales and compensators show on infinitesimally short intervals.\nWhile classical martingale representations describe innovations only, our\nrepresentations have an additional symmetric counterpart that quantifies the\neffect of information loss. We exemplify the results with examples from life\ninsurance and credit risk.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:01:41 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 15:24:11 GMT"}, {"version": "v3", "created": "Fri, 28 Feb 2020 10:10:02 GMT"}, {"version": "v4", "created": "Fri, 8 Jan 2021 15:35:21 GMT"}], "update_date": "2021-01-11", "authors_parsed": [["Christiansen", "Marcus C.", ""]]}, {"id": "1811.02530", "submitter": "Delia Coculescu", "authors": "Delia Coculescu and Freddy Delbaen", "title": "Surplus sharing with coherent utility functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the theory of coherent measures to look at the problem of surplus\nsharing in an insurance business. The surplus share of an insured is calculated\nby the surplus premium in the contract. The theory of coherent risk measures\nand the resulting capital allocation gives a way to divide the surplus between\nthe insured and the capital providers, i.e. the shareholders.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2018 11:51:24 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Coculescu", "Delia", ""], ["Delbaen", "Freddy", ""]]}, {"id": "1811.04223", "submitter": "Nadine Walters Ms", "authors": "Nadine M Walters, Conrad Beyers, Gusti van Zyl, Rolf van den Heever", "title": "A framework for simulating systemic risk and its application to the\n  South African banking sector", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a network-based framework for simulating systemic risk that\nconsiders shock propagation in banking systems. In particular, the framework\nallows the modeller to reflect a top-down framework where a shock to one bank\nin the system affects the solvency and liquidity position of other banks,\nthrough systemic market risks and consequential liquidity strains. We\nillustrate the framework with an application using South African bank balance\nsheet data. Spikes in simulated assessments of systemic risk agree closely with\nspikes in documented subjective assessments of this risk. This indicates that\nnetwork models can be useful for monitoring systemic risk levels. The model\nresults are sensitive to liquidity risk and market sentiment and therefore the\nrelated parameters are important considerations when using a network approach\nto systemic risk modelling.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 09:36:18 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Walters", "Nadine M", ""], ["Beyers", "Conrad", ""], ["van Zyl", "Gusti", ""], ["Heever", "Rolf van den", ""]]}, {"id": "1811.05270", "submitter": "Rastin Matin", "authors": "Rastin Matin, Casper Hansen, Christian Hansen and Pia M{\\o}lgaard", "title": "Predicting Distresses using Deep Learning of Text Segments in Annual\n  Reports", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-fin.CP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Corporate distress models typically only employ the numerical financial\nvariables in the firms' annual reports. We develop a model that employs the\nunstructured textual data in the reports as well, namely the auditors' reports\nand managements' statements. Our model consists of a convolutional recurrent\nneural network which, when concatenated with the numerical financial variables,\nlearns a descriptive representation of the text that is suited for corporate\ndistress prediction. We find that the unstructured data provides a\nstatistically significant enhancement of the distress prediction performance,\nin particular for large firms where accurate predictions are of the utmost\nimportance. Furthermore, we find that auditors' reports are more informative\nthan managements' statements and that a joint model including both managements'\nstatements and auditors' reports displays no enhancement relative to a model\nincluding only auditors' reports. Our model demonstrates a direct improvement\nover existing state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 13:09:58 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Matin", "Rastin", ""], ["Hansen", "Casper", ""], ["Hansen", "Christian", ""], ["M\u00f8lgaard", "Pia", ""]]}, {"id": "1811.06361", "submitter": "Matyas Barczy", "authors": "Matyas Barczy, Adam Dudas, Jozsef Gall", "title": "On approximations of Value at Risk and Expected Shortfall involving\n  kurtosis", "comments": "30 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive new approximations for the Value at Risk and the Expected Shortfall\nat high levels of loss distributions with positive skewness and excess\nkurtosis, and we describe their precisions for notable ones such as for\nexponential, Pareto type I, lognormal and compound (Poisson) distributions. Our\napproximations are motivated by that kind of extensions of the so-called Normal\nPower Approximation, used for approximating the cumulative distribution\nfunction of a random variable, which incorporate not only the skewness but the\nkurtosis of the random variable in question as well. We show the performance of\nour approximations in numerical examples and we also give comparisons with some\nknown ones in the literature.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 14:11:16 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 14:50:45 GMT"}, {"version": "v3", "created": "Wed, 23 Dec 2020 12:49:38 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Barczy", "Matyas", ""], ["Dudas", "Adam", ""], ["Gall", "Jozsef", ""]]}, {"id": "1811.07860", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze", "title": "Cryptoasset Factor Models", "comments": "45 pages; 2 trivial typos corrected, no other changes; to appear in\n  Algorithmic Finance", "journal-ref": "Algorithmic Finance 7(3-4) (2018) 87-104", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose factor models for the cross-section of daily cryptoasset returns\nand provide source code for data downloads, computing risk factors and\nbacktesting them out-of-sample. In \"cryptoassets\" we include all\ncryptocurrencies and a host of various other digital assets (coins and tokens)\nfor which exchange market data is available. Based on our empirical analysis,\nwe identify the leading factor that appears to strongly contribute into daily\ncryptoasset returns. Our results suggest that cross-sectional statistical\narbitrage trading may be possible for cryptoassets subject to efficient\nexecutions and shorting.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 18:24:40 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 17:02:24 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Kakushadze", "Zura", ""]]}, {"id": "1811.08038", "submitter": "Zhongmin Luo", "authors": "Raymond Brummelhuis and Zhongmin Luo", "title": "Arbitrage Opportunities in CDS Term Structure: Theory and Implications\n  for OTC Derivatives", "comments": "37 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Absence-of-Arbitrage (AoA) is the basic assumption underpinning derivatives\npricing theory. As part of the OTC derivatives market, the CDS market not only\nprovides a vehicle for participants to hedge and speculate on the default risks\nof corporate and sovereign entities, it also reveals important market-implied\ndefault-risk information concerning the counterparties with which financial\ninstitutions trade, and for which these financial institutions have to\ncalculate various valuation adjustments (collectively referred to as XVA) as\npart of their pricing and risk management of OTC derivatives, to account for\ncounterparty default risks. In this study, we derive No-arbitrage conditions\nfor CDS term structures, first in a positive interest rate environment and then\nin an arbitrary one. Using an extensive CDS dataset which covers the 2007-09\nfinancial crisis, we present a catalogue of 2,416 pairs of anomalous CDS\ncontracts which violate the above conditions. Finally, we show in an example\nthat such anomalies in the CDS term structure can lead to persistent arbitrage\nprofits and to nonsensical default probabilities. The paper is a first\nsystematic study on CDS-term-structure arbitrage providing model-free AoA\nconditions supported by ample empirical evidence.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 00:41:36 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 09:03:33 GMT"}, {"version": "v3", "created": "Sun, 16 Dec 2018 18:03:18 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Brummelhuis", "Raymond", ""], ["Luo", "Zhongmin", ""]]}, {"id": "1811.08365", "submitter": "Aurelio Fernandez Bariviera", "authors": "Nektarios Aslanidis, Aurelio F. Bariviera, Oscar Martinez-Iba\\~nez", "title": "An analysis of cryptocurrencies conditional cross correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter explores the behavior of conditional correlations among main\ncryptocurrencies, stock and bond indices, and gold, using a generalized DCC\nclass model. From a portfolio management point of view, asset correlation is a\nkey metric in order to construct efficient portfolios. We find that: (i)\ncorrelations among cryptocurrencies are positive, albeit varying across time;\n(ii) correlations with Monero are more stable across time; (iii) correlations\nbetween cryptocurrencies and traditional financial assets are negligible.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 16:58:22 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 22:19:45 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Aslanidis", "Nektarios", ""], ["Bariviera", "Aurelio F.", ""], ["Martinez-Iba\u00f1ez", "Oscar", ""]]}, {"id": "1811.08604", "submitter": "Florian Ziel", "authors": "Christopher Kath, Florian Ziel", "title": "The value of forecasts: Quantifying the economic gains of accurate\n  quarter-hourly electricity price forecasts", "comments": null, "journal-ref": "Energy Economics, 76 (2018) 411-423", "doi": "10.1016/j.eneco.2018.10.005", "report-no": null, "categories": "q-fin.ST econ.EM q-fin.PM q-fin.RM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a multivariate elastic net regression forecast model for German\nquarter-hourly electricity spot markets. While the literature is diverse on\nday-ahead prediction approaches, both the intraday continuous and intraday\ncall-auction prices have not been studied intensively with a clear focus on\npredictive power. Besides electricity price forecasting, we check for the\nimpact of early day-ahead (DA) EXAA prices on intraday forecasts. Another\nnovelty of this paper is the complementary discussion of economic benefits. A\nprecise estimation is worthless if it cannot be utilized. We elaborate possible\ntrading decisions based upon our forecasting scheme and analyze their monetary\neffects. We find that even simple electricity trading strategies can lead to\nsubstantial economic impact if combined with a decent forecasting technique.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 06:05:38 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Kath", "Christopher", ""], ["Ziel", "Florian", ""]]}, {"id": "1811.08706", "submitter": "Cyril Benezet", "authors": "Cyril B\\'en\\'ezet, J\\'er\\'emie Bonnefoy, Jean-Fran\\c{c}ois\n  Chassagneux, Shuoqing Deng, Camilo Garcia Trillos, Lionel Len\\^otre", "title": "A sparse grid approach to balance sheet risk measurement", "comments": "27 pages, 7 figures. CEMRACS 2017", "journal-ref": "ESAIM: PROCEEDINGS AND SURVEYS, February 2019, Vol. 65, p. 236-265", "doi": "10.1051/proc/201965236", "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present a numerical method based on a sparse grid\napproximation to compute the loss distribution of the balance sheet of a\nfinancial or an insurance company. We first describe, in a stylised way, the\nassets and liabilities dynamics that are used for the numerical estimation of\nthe balance sheet distribution. For the pricing and hedging model, we chose a\nclassical Black & Scholes model with a stochastic interest rate following a\nHull & White model. The risk management model describing the evolution of the\nparameters of the pricing and hedging model is a Gaussian model. The new\nnumerical method is compared with the traditional nested simulation approach.\nWe review the convergence of both methods to estimate the risk indicators under\nconsideration. Finally, we provide numerical results showing that the sparse\ngrid approach is extremely competitive for models with moderate dimension.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 12:15:43 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["B\u00e9n\u00e9zet", "Cyril", ""], ["Bonnefoy", "J\u00e9r\u00e9mie", ""], ["Chassagneux", "Jean-Fran\u00e7ois", ""], ["Deng", "Shuoqing", ""], ["Trillos", "Camilo Garcia", ""], ["Len\u00f4tre", "Lionel", ""]]}, {"id": "1811.08773", "submitter": "Michael Harre", "authors": "Michael S. Harre", "title": "Entropy and Transfer Entropy: The Dow Jones and the build up to the 1997\n  Asian Crisis", "comments": "11 pages, 5 figures. econophysics conference", "journal-ref": "Proceedings of the International Conference on Social Modeling and\n  Simulation, plus Econophysics Colloquium, 2014, pages 15-25", "doi": "10.1007/978-3-319-20591-5_2", "report-no": null, "categories": "q-fin.ST q-fin.CP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy measures in their various incarnations play an important role in the\nstudy of stochastic time series providing important insights into both the\ncorrelative and the causative structure of the stochastic relationships between\nthe individual components of a system. Recent applications of entropic\ntechniques and their linear progenitors such as Pearson correlations and\nGranger causality have have included both normal as well as critical periods in\na system's dynamical evolution. Here I measure the entropy, Pearson correlation\nand transfer entropy of the intra-day price changes of the Dow Jones Industrial\nAverage in the period immediately leading up to and including the Asian\nfinancial crisis and subsequent mini-crash of the DJIA on the 27th October\n1997. I use a novel variation of transfer entropy that dynamically adjusts to\nthe arrival rate of individual prices and does not require the binning of data\nto show that quite different relationships emerge from those given by the\nconventional Pearson correlations between equities. These preliminary results\nillustrate how this modified form of the TE compares to results using Pearson\ncorrelation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 03:39:53 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Harre", "Michael S.", ""]]}, {"id": "1811.08808", "submitter": "Nikolaos Kolliopoulos", "authors": "Ben Hambly and Nikolaos Kolliopoulos", "title": "Fast mean-reversion asymptotics for large portfolios of stochastic\n  volatility models", "comments": "37 pages", "journal-ref": null, "doi": "10.1007/s00780-020-00422-7", "report-no": null, "categories": "math.PR q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an SPDE description of a large portfolio limit model where the\nunderlying asset prices evolve according to certain stochastic volatility\nmodels with default upon hitting a lower barrier. The asset prices and their\nvolatilities are correlated via systemic Brownian motions, and the resulting\nSPDE is defined on the positive half-space with Dirichlet boundary conditions.\nWe study the convergence of the loss from the system, a function of the total\nmass of a solution to this stochastic initial-boundary value problem under fast\nmean reversion of the volatility. We consider two cases. In the first case the\nvolatility converges to a limiting distribution and the convergence of the\nsystem is in the sense of weak convergence. On the other hand, when only the\nmean reversion of the volatility goes to infinity we see a stronger form of\nconvergence of the system to its limit. Our results show that in a fast\nmean-reverting volatility environment we can accurately estimate the\ndistribution of the loss from a large portfolio by using an approximate\nconstant volatility model which is easier to handle.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 16:17:19 GMT"}, {"version": "v2", "created": "Thu, 13 Feb 2020 13:10:46 GMT"}], "update_date": "2020-05-11", "authors_parsed": [["Hambly", "Ben", ""], ["Kolliopoulos", "Nikolaos", ""]]}, {"id": "1811.09615", "submitter": "Mitja Stadje", "authors": "Mitja Stadje", "title": "Representation Results for Law Invariant Recursive Dynamic Deviation\n  Measures and Risk Sharing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze a dynamic recursive extension of the (static) notion\nof a deviation measure and its properties. We study distribution invariant\ndeviation measures and show that the only dynamic deviation measure which is\nlaw invariant and recursive is the variance. We also solve the problem of\noptimal risk-sharing generalizing classical risk-sharing results for variance\nthrough a dynamic inf-convolution problem involving a transformation of the\noriginal dynamic deviation measures.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 10:52:08 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 14:15:17 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Stadje", "Mitja", ""]]}, {"id": "1811.11079", "submitter": "Suproteem Sarkar", "authors": "Suproteem K. Sarkar, Kojin Oshiba, Daniel Giebisch, Yaron Singer", "title": "Robust Classification of Financial Risk", "comments": "NIPS 2018 Workshop on Challenges and Opportunities for AI in\n  Financial Services", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CR cs.LG q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms are increasingly common components of high-impact decision-making,\nand a growing body of literature on adversarial examples in laboratory settings\nindicates that standard machine learning models are not robust. This suggests\nthat real-world systems are also susceptible to manipulation or\nmisclassification, which especially poses a challenge to machine learning\nmodels used in financial services. We use the loan grade classification problem\nto explore how machine learning models are sensitive to small changes in\nuser-reported data, using adversarial attacks documented in the literature and\nan original, domain-specific attack. Our work shows that a robust optimization\nalgorithm can build models for financial services that are resistant to\nmisclassification on perturbations. To the best of our knowledge, this is the\nfirst study of adversarial attacks and defenses for deep learning in financial\nservices.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 16:28:32 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Sarkar", "Suproteem K.", ""], ["Oshiba", "Kojin", ""], ["Giebisch", "Daniel", ""], ["Singer", "Yaron", ""]]}, {"id": "1811.11301", "submitter": "Matthew Norton", "authors": "Matthew Norton, Valentyn Khokhlov, Stan Uryasev", "title": "Calculating CVaR and bPOE for Common Probability Distributions With\n  Application to Portfolio Optimization and Density Estimation", "comments": "Fixed typo in Proposition 5 (changed - to +) and added reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.OC math.PR stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional Value-at-Risk (CVaR) and Value-at-Risk (VaR), also called the\nsuperquantile and quantile, are frequently used to characterize the tails of\nprobability distribution's and are popular measures of risk. Buffered\nProbability of Exceedance (bPOE) is a recently introduced characterization of\nthe tail which is the inverse of CVaR, much like the CDF is the inverse of the\nquantile. These quantities can prove very useful as the basis for a variety of\nrisk-averse parametric engineering approaches. Their use, however, is often\nmade difficult by the lack of well-known closed-form equations for calculating\nthese quantities for commonly used probability distribution's. In this paper,\nwe derive formulas for the superquantile and bPOE for a variety of common\nunivariate probability distribution's. Besides providing a useful collection\nwithin a single reference, we use these formulas to incorporate the\nsuperquantile and bPOE into parametric procedures. In particular, we consider\ntwo: portfolio optimization and density estimation. First, when portfolio\nreturns are assumed to follow particular distribution families, we show that\nfinding the optimal portfolio via minimization of bPOE has advantages over\nsuperquantile minimization. We show that, given a fixed threshold, a single\nportfolio is the minimal bPOE portfolio for an entire class of distribution's\nsimultaneously. Second, we apply our formulas to parametric density estimation\nand propose the method of superquantile's (MOS), a simple variation of the\nmethod of moment's (MM) where moment's are replaced by superquantile's at\ndifferent confidence levels. With the freedom to select various combinations of\nconfidence levels, MOS allows the user to focus the fitting procedure on\ndifferent portions of the distribution, such as the tail when fitting\nheavy-tailed asymmetric data.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 23:00:06 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2019 18:44:33 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Norton", "Matthew", ""], ["Khokhlov", "Valentyn", ""], ["Uryasev", "Stan", ""]]}, {"id": "1811.11326", "submitter": "Moshe Milevsky", "authors": "Moshe A. Milevsky", "title": "Swimming with Wealthy Sharks: Longevity, Volatility and the Value of\n  Risk Pooling", "comments": "57 pages, 8 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Who {\\em values} life annuities more? Is it the healthy retiree who expects\nto live long and might become a centenarian, or is the unhealthy retiree with a\nshort life expectancy more likely to appreciate the pooling of longevity risk?\nWhat if the unhealthy retiree is pooled with someone who is much healthier and\nthus forced to pay an implicit loading? To answer these and related questions\nthis paper examines the empirical conditions under which retirees benefit (or\nmay not) from longevity risk pooling by linking the {\\em economics} of annuity\nequivalent wealth (AEW) to {\\em actuarially} models of aging. I focus attention\non the {\\em Compensation Law of Mortality} which implies that individuals with\nhigher relative mortality (e.g. lower income) age more slowly and experience\ngreater longevity uncertainty. Ergo, they place higher utility value on the\nannuity. The impetus for this research today is the increasing evidence on the\ngrowing disparity in longevity expectations between rich and poor.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 00:42:04 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Milevsky", "Moshe A.", ""]]}]