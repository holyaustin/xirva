[{"id": "1409.1071", "submitter": "Andrei Leonidov", "authors": "A.V. Leonidov, E.L. Rumyantsev", "title": "Default contagion risks in Russian interbank market", "comments": "Final version, to appear in Physica A", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systemic risks of default contagion in the Russian interbank market are\ninvestigated. The analysis is based on considering the bow-tie structure of the\nweighted oriented graph describing the structure of the interbank loans. A\nprobabilistic model of interbank contagion explicitly taking into account the\nempirical bow-tie structure reflecting functionality of the corresponding nodes\n(borrowers, lenders, borrowers and lenders simultaneously), degree\ndistributions and disassortativity of the interbank network under consideration\nbased on empirical data is developed. The characteristics of contagion-related\nsystemic risk calculated with this model are shown to be in agreement with\nthose of explicit stress tests.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2014 13:09:45 GMT"}, {"version": "v2", "created": "Thu, 4 Sep 2014 08:40:08 GMT"}, {"version": "v3", "created": "Sun, 3 Jan 2016 09:33:42 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Leonidov", "A. V.", ""], ["Rumyantsev", "E. L.", ""]]}, {"id": "1409.1451", "submitter": "Gareth Peters Dr", "authors": "Gareth W. Peters, Ariane Chapelle, Efstathios Panayi", "title": "Opening discussion on banking sector risk exposures and vulnerabilities\n  from virtual currencies: An operational risk perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.CR q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the first basic Operational Risk perspective on key risk\nmanagement issues associated with the development of new forms of electronic\ncurrency in the real economy. In particular, we focus on understanding the\ndevelopment of new risks types and the evolution of current risk types as new\ncomponents of financial institutions arise to cater for an increasing demand\nfor electronic money, micro-payment systems, Virtual money and cryptographic\n(Crypto) currencies. In particular, this paper proposes a framework of risk\nidentification and assessment applied to Virtual and Crypto currencies from a\nbanking regulation perspective. In doing so, it addresses the topical issues of\nunderstanding important key Operational Risk vulnerabilities and exposure risk\ndrivers under the framework of the Basel II/III banking regulation,\nspecifically associated with Virtual and Crypto currencies. This is critical to\nconsider should such alternative currencies continue to grow in utilisation to\nthe point that they enter into the banking sector, through commercial banks and\nfinancial institutions who are beginning to contemplate their recognition in\nterms of deposits, transactions and exchangeability for fiat currencies.\n  We highlight how some of the features of Virtual and Crypto currencies are\nimportant drivers of Operational Risk, posing both management and regulatory\nchallenges that must start to be considered and addressed both by regulators,\ncentral banks and security exchanges. In this paper we focus purely on the\nOperational Risk perspective of banks operating in an environment where such\nelectronic Virtual currencies are available. Some aspects of this discussion\nare directly relevant now, whilst others can be understood as discussions to\nraise awareness of issues in Operational Risk that will arise as Virtual\ncurrency start to interact more widely in the real economy.\n", "versions": [{"version": "v1", "created": "Thu, 4 Sep 2014 14:22:25 GMT"}], "update_date": "2014-09-05", "authors_parsed": [["Peters", "Gareth W.", ""], ["Chapelle", "Ariane", ""], ["Panayi", "Efstathios", ""]]}, {"id": "1409.2575", "submitter": "Zurab Kakushadze", "authors": "Zura Kakushadze and Jim Kyung-Soo Liew", "title": "Custom v. Standardized Risk Models", "comments": "30 pages; minor improvements, more source code added; to appear in\n  Risks", "journal-ref": "Risks 3(2) (2015) 112-138", "doi": null, "report-no": null, "categories": "q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss when and why custom multi-factor risk models are warranted and\ngive source code for computing some risk factors. Pension/mutual funds do not\nrequire customization but standardization. However, using standardized risk\nmodels in quant trading with much shorter holding horizons is suboptimal: 1)\nlonger horizon risk factors (value, growth, etc.) increase noise trades and\ntrading costs; 2) arbitrary risk factors can neutralize alpha; 3)\n\"standardized\" industries are artificial and insufficiently granular; 4)\nnormalization of style risk factors is lost for the trading universe; 5)\ndiversifying risk models lowers P&L correlations, reduces turnover and market\nimpact, and increases capacity. We discuss various aspects of custom risk model\nbuilding.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 02:36:32 GMT"}, {"version": "v2", "created": "Mon, 5 Jan 2015 20:21:28 GMT"}, {"version": "v3", "created": "Fri, 15 May 2015 21:38:39 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Kakushadze", "Zura", ""], ["Liew", "Jim Kyung-Soo", ""]]}, {"id": "1409.2625", "submitter": "Pierre Paga", "authors": "Pierre Paga and Reimer K\\\"uhn", "title": "Contagion in an interacting economy", "comments": "21 pages, 6 figures", "journal-ref": "J. Stat. Mech. (2015) P03008", "doi": "10.1088/1742-5468/2015/03/P03008", "report-no": null, "categories": "physics.soc-ph q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the credit risk model defined in Hatchett & K\\\"{u}hn under\nmore general assumptions, in particular using a general degree distribution for\nsparse graphs. Expanding upon earlier results, we show that the model is\nexactly solvable in the $N\\rightarrow \\infty$ limit and demonstrate that the\nexact solution is described by the message-passing approach outlined by Karrer\nand Newman, generalized to include heterogeneous agents and couplings. We\nprovide comparisons with simulations of graph ensembles with power-law degree\ndistributions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 07:51:39 GMT"}, {"version": "v2", "created": "Fri, 27 Mar 2015 12:12:45 GMT"}], "update_date": "2015-03-30", "authors_parsed": [["Paga", "Pierre", ""], ["K\u00fchn", "Reimer", ""]]}, {"id": "1409.2661", "submitter": "Pedro Lencastre", "authors": "P. Lencastre, F. Raischel, P.G. Lind", "title": "The effect of the number of states on the validity of credit ratings", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/574/1/012151", "report-no": null, "categories": "q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explicitly test if the reliability of credit ratings depends on the total\nnumber of admissible states. We analyse open access credit rating data and show\nthat the effect of the number of states in the dynamical properties of ratings\nchange with time, thus giving supportive evidence that the ideal number of\nadmissible states changes with time. We use matrix estimation methods that\nexplicitly assume the hypothesis needed for the process to be a valid rating\nprocess. By comparing with the likelihood maximization method of matrix\nestimation, we quantify the \"likelihood-loss\" of assuming that the process is a\nwell grounded rating process.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 10:19:25 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Lencastre", "P.", ""], ["Raischel", "F.", ""], ["Lind", "P. G.", ""]]}, {"id": "1409.4894", "submitter": "Matteo Formenti", "authors": "Matteo Formenti", "title": "The Credibility Theory applied to backtesting Counterparty Credit Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Credibility theory provides tools to obtain better estimates by combining\nindividual data with sample information. We apply the Credibility theory to a\nUniform distribution that is used in testing the reliability of forecasting an\ninterest rate for long term horizons. Such empirical exercise is asked by\nRegulators (CRR, 2013) in validating an Internal Model Method for Counterparty\nCredit Risk. The main results is that risk managers consider more reliable the\noutput of a test with limited sample size when the Credibility is applied to\ndefine a confidence interval.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 08:06:12 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Formenti", "Matteo", ""]]}, {"id": "1409.4896", "submitter": "Matteo Formenti", "authors": "Matteo Formenti", "title": "Mean of Ratios or Ratio of Means: statistical uncertainty applied to\n  estimate Multiperiod Probability of Defaul", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimate of a Multiperiod probability of default applied to residential\nmortgages can be obtained using the mean of the observed default, so called the\nMean of ratios estimator, or aggregating the default and the issued mortgages\nand computing the ratio of their sum, that is the Ratio of means. This work\nstudies the statistical properties of the two estimators with the result that\nthe Ratio of means has a lower statistical uncertainty. The application on a\nprivate residential mortgage portfolio leads to a lower probability of default\non the overall portfolio by eleven basis points.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 08:13:20 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Formenti", "Matteo", ""]]}, {"id": "1409.7028", "submitter": "Igor Cialenco", "authors": "Tomasz R. Bielecki and Igor Cialenco and Marcin Pitera", "title": "A unified approach to time consistency of dynamic risk measures and\n  dynamic performance measures in discrete time", "comments": null, "journal-ref": null, "doi": "10.1287/moor.2017.0858", "report-no": null, "categories": "math.PR q-fin.MF q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide a flexible framework allowing for a unified study of\ntime consistency of risk measures and performance measures (also known as\nacceptability indices). The proposed framework not only integrates existing\nforms of time consistency, but also provides a comprehensive toolbox for\nanalysis and synthesis of the concept of time consistency in decision making.\nIn particular, it allows for in depth comparative analysis of (most of) the\nexisting types of time consistency -- a feat that has not be possible before\nand which is done in the companion paper [BCP2016] to this one. In our approach\nthe time consistency is studied for a large class of maps that are postulated\nto satisfy only two properties -- monotonicity and locality. The time\nconsistency is defined in terms of an update rule. The form of the update rule\nintroduced here is novel, and is perfectly suited for developing the unifying\nframework that is worked out in this paper. As an illustration of the\napplicability of our approach, we show how to recover almost all concepts of\nweak time consistency by means of constructing appropriate update rules.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 17:42:18 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2015 23:08:02 GMT"}, {"version": "v3", "created": "Thu, 7 Sep 2017 02:50:28 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Bielecki", "Tomasz R.", ""], ["Cialenco", "Igor", ""], ["Pitera", "Marcin", ""]]}, {"id": "1409.7933", "submitter": "Lorenzo Mercuri", "authors": "Lorenzo Mercuri, Edit Rroji", "title": "Parametric Risk Parity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM q-fin.PM stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any optimization algorithm based on the risk parity approach requires the\nformulation of portfolio total risk in terms of marginal contributions. In this\npaper we use the independence of the underlying factors in the market to derive\nthe centered moments required in the risk decomposition process when the\nmodified versions of Value at Risk and Expected Shortfall are considered.\n  The choice of the Mixed Tempered Stable distribution seems adequate for\nfitting skewed and heavy tailed distributions. The ensuing detailed description\nof the optimization procedure is due to the existence of analytical higher\norder moments. Better results are achieved in terms of out of sample\nperformance and greater diversification.\n", "versions": [{"version": "v1", "created": "Sun, 28 Sep 2014 17:10:20 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Mercuri", "Lorenzo", ""], ["Rroji", "Edit", ""]]}]