[{"id": "0907.1100", "submitter": "Siu Chin", "authors": "Mark Girolami, Ben Calderhead and Siu A. Chin", "title": "Riemannian Manifold Hamiltonian Monte Carlo", "comments": "This paper has been withdrawn by the posting author because he is no\n  longer a co-author of this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.NA math.NA math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a Riemannian Manifold Hamiltonian Monte Carlo sampler to\nresolve the shortcomings of existing Monte Carlo algorithms when sampling from\ntarget densities that may be high dimensional and exhibit strong correlations.\nThe method provides a fully automated adaptation mechanism that circumvents the\ncostly pilot runs required to tune proposal densities for Metropolis-Hastings\nor indeed Hybrid Monte Carlo and Metropolis Adjusted Langevin Algorithms. This\nallows for highly efficient sampling even in very high dimensions where\ndifferent scalings may be required for the transient and stationary phases of\nthe Markov chain. The proposed method exploits the Riemannian structure of the\nparameter space of statistical models and thus automatically adapts to the\nlocal manifold structure at each step based on the metric tensor. A\nsemi-explicit second order symplectic integrator for non-separable Hamiltonians\nis derived for simulating paths across this manifold which provides highly\nefficient convergence and exploration of the target density. The performance of\nthe Riemannian Manifold Hamiltonian Monte Carlo method is assessed by\nperforming posterior inference on logistic regression models, log-Gaussian Cox\npoint processes, stochastic volatility models, and Bayesian estimation of\nparameter posteriors of dynamical systems described by nonlinear differential\nequations. Substantial improvements in the time normalised Effective Sample\nSize are reported when compared to alternative sampling approaches. Matlab code\nat \\url{http://www.dcs.gla.ac.uk/inference/rmhmc} allows replication of all\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2009 20:45:31 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2013 19:40:08 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 08:20:13 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Girolami", "Mark", ""], ["Calderhead", "Ben", ""], ["Chin", "Siu A.", ""]]}, {"id": "0907.1254", "submitter": "Jean-Michel Marin", "authors": "Jean-Marie Cornuet (CBGP, INRA, Montpellier), Jean-Michel Marin (I3M,\n  Montpellier), Antonietta Mira (University of Lugano) and Christian P. Robert\n  (Universite Paris Dauphine)", "title": "Adaptive Multiple Importance Sampling", "comments": "20 pages, 3 figures, revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Adaptive Multiple Importance Sampling (AMIS) algorithm is aimed at an\noptimal recycling of past simulations in an iterated importance sampling\nscheme. The difference with earlier adaptive importance sampling\nimplementations like Population Monte Carlo is that the importance weights of\nall simulated values, past as well as present, are recomputed at each\niteration, following the technique of the deterministic multiple mixture\nestimator of Owen and Zhou (2000). Although the convergence properties of the\nalgorithm cannot be fully investigated, we demonstrate through a challenging\nbanana shape target distribution and a population genetics example that the\nimprovement brought by this technique is substantial.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2009 16:29:47 GMT"}, {"version": "v2", "created": "Thu, 16 Dec 2010 13:17:24 GMT"}, {"version": "v3", "created": "Mon, 20 Dec 2010 11:02:21 GMT"}, {"version": "v4", "created": "Wed, 4 May 2011 15:30:58 GMT"}, {"version": "v5", "created": "Mon, 3 Oct 2011 09:48:09 GMT"}], "update_date": "2011-10-04", "authors_parsed": [["Cornuet", "Jean-Marie", "", "CBGP, INRA, Montpellier"], ["Marin", "Jean-Michel", "", "I3M,\n  Montpellier"], ["Mira", "Antonietta", "", "University of Lugano"], ["Robert", "Christian P.", "", "Universite Paris Dauphine"]]}, {"id": "0907.1823", "submitter": "Andrey Pepelyshev", "authors": "Andrey Pepelyshev", "title": "Improvement of random LHD for high dimensions", "comments": "6 pages, Proceedings of the 6th St. Petersburg Workshop on\n  Simulation, 1091-1096", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designs of experiments for multivariate case are reviewed. Fast algorithm of\nconstruction of good Latin hypercube designs is developed.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2009 13:46:00 GMT"}], "update_date": "2009-07-13", "authors_parsed": [["Pepelyshev", "Andrey", ""]]}, {"id": "0907.1835", "submitter": "C T J Dodson", "authors": "C.T.J. Dodson", "title": "Information geometry for testing pseudorandom number generators", "comments": "4 pages,", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The information geometry of the 2-manifold of gamma probability density\nfunctions provides a framework in which pseudorandom number generators may be\nevaluated using a neighbourhood of the curve of exponential density functions.\nThe process is illustrated using the pseudorandom number generator in\nMathematica. This methodology may be useful to add to the current family of\ntest procedures in real applications to finite sampling data.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2009 14:37:58 GMT"}], "update_date": "2009-07-13", "authors_parsed": [["Dodson", "C. T. J.", ""]]}, {"id": "0907.1997", "submitter": "Leonid (Aryeh) Kontorovich", "authors": "Leonid (Aryeh) Kontorovich", "title": "Statistical estimation requires unbounded memory", "comments": "this is an old version, with a mistake in the proof of Thm. 6.1.\n  Please see my homepage for an updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the existence of bounded-memory consistent estimators of\nvarious statistical functionals. This question is resolved in the negative in a\nrather strong sense. We propose various bounded-memory approximations, using\ntechniques from automata theory and stochastic processes. Some questions of\npotential interest are raised for future work.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2009 13:20:32 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2011 11:53:22 GMT"}], "update_date": "2011-10-28", "authors_parsed": [["Leonid", "", "", "Aryeh"], ["Kontorovich", "", ""]]}, {"id": "0907.2079", "submitter": "Yong Zhang", "authors": "Zhaosong Lu and Yong Zhang", "title": "An Augmented Lagrangian Approach for Sparse Principal Component Analysis", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.ST stat.AP stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a widely used technique for data\nanalysis and dimension reduction with numerous applications in science and\nengineering. However, the standard PCA suffers from the fact that the principal\ncomponents (PCs) are usually linear combinations of all the original variables,\nand it is thus often difficult to interpret the PCs. To alleviate this\ndrawback, various sparse PCA approaches were proposed in literature [15, 6, 17,\n28, 8, 25, 18, 7, 16]. Despite success in achieving sparsity, some important\nproperties enjoyed by the standard PCA are lost in these methods such as\nuncorrelation of PCs and orthogonality of loading vectors. Also, the total\nexplained variance that they attempt to maximize can be too optimistic. In this\npaper we propose a new formulation for sparse PCA, aiming at finding sparse and\nnearly uncorrelated PCs with orthogonal loading vectors while explaining as\nmuch of the total variance as possible. We also develop a novel augmented\nLagrangian method for solving a class of nonsmooth constrained optimization\nproblems, which is well suited for our formulation of sparse PCA. We show that\nit converges to a feasible point, and moreover under some regularity\nassumptions, it converges to a stationary point. Additionally, we propose two\nnonmonotone gradient methods for solving the augmented Lagrangian subproblems,\nand establish their global and local convergence. Finally, we compare our\nsparse PCA approach with several existing methods on synthetic, random, and\nreal data, respectively. The computational results demonstrate that the sparse\nPCs produced by our approach substantially outperform those by other methods in\nterms of total explained variance, correlation of PCs, and orthogonality of\nloading vectors.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2009 00:45:51 GMT"}], "update_date": "2009-07-14", "authors_parsed": [["Lu", "Zhaosong", ""], ["Zhang", "Yong", ""]]}, {"id": "0907.3521", "submitter": "Aleksey Polunchenko", "authors": "George V. Moustakides, Aleksey S. Polunchenko, Alexander G.\n  Tartakovsky", "title": "A Numerical Approach to Performance Analysis of Quickest Change-Point\n  Detection Procedures", "comments": "32 pages, to appear in Statistica Sinica", "journal-ref": "Statistica Sinica, vol. 21, no. 2, pp. 571--596, 2011", "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the most popular sequential change detection rules such as CUSUM, EWMA,\nand the Shiryaev-Roberts test, we develop integral equations and a concise\nnumerical method to compute a number of performance metrics, including average\ndetection delay and average time to false alarm. We pay special attention to\nthe Shiryaev-Roberts procedure and evaluate its performance for various\ninitialization strategies. Regarding the randomized initialization variant\nproposed by Pollak, known to be asymptotically optimal of order-3, we offer a\nmeans for numerically computing the quasi-stationary distribution of the\nShiryaev-Roberts statistic that is the distribution of the initializing random\nvariable, thus making this test applicable in practice. A significant\nside-product of our computational technique is the observation that\ndeterministic initializations of the Shiryaev-Roberts procedure can also enjoy\nthe same order-3 optimality property as Pollak's randomized test and, after\ncareful selection, even uniformly outperform it.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2009 00:48:06 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2009 21:20:59 GMT"}], "update_date": "2011-09-15", "authors_parsed": [["Moustakides", "George V.", ""], ["Polunchenko", "Aleksey S.", ""], ["Tartakovsky", "Alexander G.", ""]]}, {"id": "0907.3574", "submitter": "Andrea Montanari", "authors": "David L. Donoho and Arian Maleki and Andrea Montanari", "title": "Message Passing Algorithms for Compressed Sensing", "comments": "6 pages paper + 9 pages supplementary information, 13 eps figure.\n  Submitted to Proc. Natl. Acad. Sci. USA", "journal-ref": null, "doi": "10.1073/pnas.0909892106", "report-no": null, "categories": "cs.IT cond-mat.dis-nn math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing aims to undersample certain high-dimensional signals, yet\naccurately reconstruct them by exploiting signal characteristics. Accurate\nreconstruction is possible when the object to be recovered is sufficiently\nsparse in a known basis. Currently, the best known sparsity-undersampling\ntradeoff is achieved when reconstructing by convex optimization -- which is\nexpensive in important large-scale applications. Fast iterative thresholding\nalgorithms have been intensively studied as alternatives to convex optimization\nfor large-scale problems. Unfortunately known fast algorithms offer\nsubstantially worse sparsity-undersampling tradeoffs than convex optimization.\n  We introduce a simple costless modification to iterative thresholding making\nthe sparsity-undersampling tradeoff of the new algorithms equivalent to that of\nthe corresponding convex optimization procedures. The new\niterative-thresholding algorithms are inspired by belief propagation in\ngraphical models. Our empirical measurements of the sparsity-undersampling\ntradeoff for the new algorithms agree with theoretical calculations. We show\nthat a state evolution formalism correctly derives the true\nsparsity-undersampling tradeoff. There is a surprising agreement between\nearlier calculations based on random convex polytopes and this new, apparently\nvery different theoretical formalism.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2009 14:47:47 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Donoho", "David L.", ""], ["Maleki", "Arian", ""], ["Montanari", "Andrea", ""]]}, {"id": "0907.3837", "submitter": "Michael A. Newton", "authors": "Michael A. Newton, Lisa M. Chung", "title": "Gamma-based clustering via ordered means with application to\n  gene-expression analysis", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS805 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 6, 3217-3244", "doi": "10.1214/10-AOS805", "report-no": "IMS-AOS-AOS805", "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete mixture models provide a well-known basis for effective clustering\nalgorithms, although technical challenges have limited their scope. In the\ncontext of gene-expression data analysis, a model is presented that mixes over\na finite catalog of structures, each one representing equality and inequality\nconstraints among latent expected values. Computations depend on the\nprobability that independent gamma-distributed variables attain each of their\npossible orderings. Each ordering event is equivalent to an event in\nindependent negative-binomial random variables, and this finding guides a\ndynamic-programming calculation. The structuring of mixture-model components\naccording to constraints among latent means leads to strict concavity of the\nmixture log likelihood. In addition to its beneficial numerical properties, the\nclustering method shows promising results in an empirical study.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2009 19:01:48 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2009 17:05:14 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2010 20:05:00 GMT"}, {"version": "v4", "created": "Fri, 9 Nov 2012 11:12:41 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Newton", "Michael A.", ""], ["Chung", "Lisa M.", ""]]}, {"id": "0907.4010", "submitter": "Christian P. Robert", "authors": "Christian P. Robert", "title": "Simulation of truncated normal variables", "comments": "This 1992 paper appeared in 1995 in Statistics and Computing and the\n  gist of it is contained in Monte Carlo Statistical Methods (2004), but I\n  receive weekly requests for reprints so here it is!", "journal-ref": "Statistics and Computing, 1995, 5, 121-125", "doi": "10.1007/BF00143942", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide in this paper simulation algorithms for one-sided and two-sided\ntruncated normal distributions. These algorithms are then used to simulate\nmultivariate normal variables with restricted parameter space for any\ncovariance structure.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2009 09:07:22 GMT"}], "update_date": "2009-07-24", "authors_parsed": [["Robert", "Christian P.", ""]]}, {"id": "0907.4018", "submitter": "Krzysztof Latuszynski", "authors": "Krzysztof Latuszynski, Ioannis Kosmidis, Omiros Papaspiliopoulos,\n  Gareth O. Roberts", "title": "Simulating Events of Unknown Probabilities via Reverse Time Martingales", "comments": "referees suggestions incorporated", "journal-ref": null, "doi": null, "report-no": "University of Warwick CRiSM research report No. 09-30", "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume that one aims to simulate an event of unknown probability $s\\in (0,1)$\nwhich is uniquely determined, however only its approximations can be obtained\nusing a finite computational effort. Such settings are often encountered in\nstatistical simulations. We consider two specific examples. First, the exact\nsimulation of non-linear diffusions, second, the celebrated Bernoulli factory\nproblem of generating an $f(p)-$coin given a sequence $X_1,X_2,...$ of\nindependent tosses of a $p-$coin (with known $f$ and unknown $p$). We describe\na general framework and provide algorithms where this kind of problems can be\nfitted and solved. The algorithms are straightforward to implement and thus\nallow for effective simulation of desired events of probability $s.$ In the\ncase of diffusions, we obtain the algorithm of \\cite{BeskosRobertsEA1} as a\nspecific instance of the generic framework developed here. In the case of the\nBernoulli factory, our work offers a statistical understanding of the\nNacu-Peres algorithm for $f(p) = \\min\\{2p, 1-2\\varepsilon\\}$ (which is central\nto the general question) and allows for its immediate implementation that\navoids algorithmic difficulties of the original version.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2009 09:40:40 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2009 01:09:01 GMT"}], "update_date": "2009-11-22", "authors_parsed": [["Latuszynski", "Krzysztof", ""], ["Kosmidis", "Ioannis", ""], ["Papaspiliopoulos", "Omiros", ""], ["Roberts", "Gareth O.", ""]]}, {"id": "0907.4160", "submitter": "Ioannis Kontoyiannis", "authors": "Ioannis Kontoyiannis, Petros Dellaportas", "title": "Notes on Using Control Variates for Estimation with Reversible MCMC\n  Samplers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general methodology is presented for the construction and effective use of\ncontrol variates for reversible MCMC samplers. The values of the coefficients\nof the optimal linear combination of the control variates are computed, and\nadaptive, consistent MCMC estimators are derived for these optimal\ncoefficients. All methodological and asymptotic arguments are rigorously\njustified. Numerous MCMC simulation examples from Bayesian inference\napplications demonstrate that the resulting variance reduction can be quite\ndramatic.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2009 18:02:47 GMT"}, {"version": "v2", "created": "Tue, 4 May 2010 16:21:21 GMT"}], "update_date": "2010-05-05", "authors_parsed": [["Kontoyiannis", "Ioannis", ""], ["Dellaportas", "Petros", ""]]}, {"id": "0907.4383", "submitter": "Jiangang Hao", "authors": "Jiangang Hao, Benjamin P. Koester, Timothy A. Mckay, Eli S. Rykoff,\n  Eduardo Rozo, August Evrard, James Annis, Matthew Becker, Michael Busha,\n  David Gerdes, David E. Johnston, Erin Sheldon, Risa H. Wechsler", "title": "Precision Measurements of the Cluster Red Sequence using an Error\n  Corrected Gaussian Mixture Model", "comments": "33 pages, 14 Figures; A typo in Eq.A11 is fixed. The C++/Python codes\n  for ECGMM can be downloaded from:\n  https://sites.google.com/site/jiangangecgmm/", "journal-ref": "Astrophys.J.702:745-758,2009", "doi": "10.1088/0004-637X/702/1/745", "report-no": "FERMILAB-PUB-09-339-A", "categories": "astro-ph.CO astro-ph.GA stat.CO", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The red sequence is an important feature of galaxy clusters and plays a\ncrucial role in optical cluster detection. Measurement of the slope and scatter\nof the red sequence are affected both by selection of red sequence galaxies and\nmeasurement errors. In this paper, we describe a new error corrected Gaussian\nMixture Model for red sequence galaxy identification. Using this technique, we\ncan remove the effects of measurement error and extract unbiased information\nabout the intrinsic properties of the red sequence. We use this method to\nselect red sequence galaxies in each of the 13,823 clusters in the maxBCG\ncatalog, and measure the red sequence ridgeline location and scatter of each.\nThese measurements provide precise constraints on the variation of the average\nred galaxy populations in the observed frame with redshift. We find that the\nscatter of the red sequence ridgeline increases mildly with redshift, and that\nthe slope decreases with redshift. We also observe that the slope does not\nstrongly depend on cluster richness. Using similar methods, we show that this\nbehavior is mirrored in a spectroscopic sample of field galaxies, further\nemphasizing that ridgeline properties are independent of environment.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2009 22:40:48 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2009 20:33:55 GMT"}, {"version": "v3", "created": "Thu, 28 Oct 2010 16:31:19 GMT"}], "update_date": "2010-10-29", "authors_parsed": [["Hao", "Jiangang", ""], ["Koester", "Benjamin P.", ""], ["Mckay", "Timothy A.", ""], ["Rykoff", "Eli S.", ""], ["Rozo", "Eduardo", ""], ["Evrard", "August", ""], ["Annis", "James", ""], ["Becker", "Matthew", ""], ["Busha", "Michael", ""], ["Gerdes", "David", ""], ["Johnston", "David E.", ""], ["Sheldon", "Erin", ""], ["Wechsler", "Risa H.", ""]]}, {"id": "0907.4698", "submitter": "Yilun Chen", "authors": "Yilun Chen, Ami Wiesel, Yonina C. Eldar, Alfred O. Hero III", "title": "Shrinkage Algorithms for MMSE Covariance Estimation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2010.2053029", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address covariance estimation in the sense of minimum mean-squared error\n(MMSE) for Gaussian samples. Specifically, we consider shrinkage methods which\nare suitable for high dimensional problems with a small number of samples\n(large p small n). First, we improve on the Ledoit-Wolf (LW) method by\nconditioning on a sufficient statistic. By the Rao-Blackwell theorem, this\nyields a new estimator called RBLW, whose mean-squared error dominates that of\nLW for Gaussian variables. Second, to further reduce the estimation error, we\npropose an iterative approach which approximates the clairvoyant shrinkage\nestimator. Convergence of this iterative method is established and a closed\nform expression for the limit is determined, which is referred to as the oracle\napproximating shrinkage (OAS) estimator. Both RBLW and OAS estimators have\nsimple expressions and are easily implemented. Although the two methods are\ndeveloped from different persepctives, their structure is identical up to\nspecified constants. The RBLW estimator provably dominates the LW method.\nNumerical simulations demonstrate that the OAS approach can perform even better\nthan RBLW, especially when n is much less than p. We also demonstrate the\nperformance of these techniques in the context of adaptive beamforming.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2009 16:42:53 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Chen", "Yilun", ""], ["Wiesel", "Ami", ""], ["Eldar", "Yonina C.", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "0907.4716", "submitter": "Krzysztof Latuszynski", "authors": "Krzysztof Latuszynski", "title": "Regeneration and Fixed-Width Analysis of Markov Chain Monte Carlo\n  Algorithms", "comments": "PhD thesis, University of Warsaw, supervisor - Wojciech Niemiro", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the thesis we take the split chain approach to analyzing Markov chains and\nuse it to establish fixed-width results for estimators obtained via Markov\nchain Monte Carlo procedures (MCMC). Theoretical results include necessary and\nsufficient conditions in terms of regeneration for central limit theorems for\nergodic Markov chains and a regenerative proof of a CLT version for uniformly\nergodic Markov chains with $E_{\\pi}f^2< \\infty.$ To obtain asymptotic\nconfidence intervals for MCMC estimators, strongly consistent estimators of the\nasymptotic variance are essential. We relax assumptions required to obtain such\nestimators. Moreover, under a drift condition, nonasymptotic fixed-width\nresults for MCMC estimators for a general state space setting (not necessarily\ncompact) and not necessarily bounded target function $f$ are obtained. The last\nchapter is devoted to the idea of adaptive Monte Carlo simulation and provides\nconvergence results and law of large numbers for adaptive procedures under\npath-stability condition for transition kernels.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2009 17:46:24 GMT"}], "update_date": "2009-07-28", "authors_parsed": [["Latuszynski", "Krzysztof", ""]]}, {"id": "0907.4915", "submitter": "Krzysztof Latuszynski", "authors": "Krzysztof Latuszynski, Blazej Miasojedow, Wojciech Niemiro", "title": "Nonasymptotic bounds on the estimation error for regenerative MCMC\n  algorithms", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "CRiSM research paper 09-23", "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MCMC methods are used in Bayesian statistics not only to sample from\nposterior distributions but also to estimate expectations. Underlying functions\nare most often defined on a continuous state space and can be unbounded. We\nconsider a regenerative setting and Monte Carlo estimators based on i.i.d.\nblocks of a Markov chain trajectory. The main result is an inequality for the\nmean square error. We also consider confidence bounds. We first derive the\nresults in terms of the asymptotic variance and then bound the asymptotic\nvariance for both uniformly ergodic and geometrically ergodic Markov chains.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2009 13:37:55 GMT"}], "update_date": "2009-07-29", "authors_parsed": [["Latuszynski", "Krzysztof", ""], ["Miasojedow", "Blazej", ""], ["Niemiro", "Wojciech", ""]]}, {"id": "0907.5123", "submitter": "Christian P. Robert", "authors": "Christian P. Robert and Darren Wraith", "title": "Computational methods for Bayesian model choice", "comments": "12 pages, 4 figures, submitted to the proceedings of MaxEnt 2009,\n  July 05-10, 2009, to be published by the American Institute of Physics", "journal-ref": null, "doi": "10.1063/1.3275622", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we shortly survey some recent approaches on the approximation\nof the Bayes factor used in Bayesian hypothesis testing and in Bayesian model\nchoice. In particular, we reassess importance sampling, harmonic mean sampling,\nand nested sampling from a unified perspective.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2009 13:33:51 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Robert", "Christian P.", ""], ["Wraith", "Darren", ""]]}, {"id": "0907.5448", "submitter": "Iosif Pinelis", "authors": "Raymond Molzon and Iosif Pinelis", "title": "Monotonicity properties of the asymptotic relative efficiency between\n  common correlation statistics in the bivariate normal model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pearson's is the most common correlation statistic, used mainly in parametric\nsettings. Most common among nonparametric correlation statistics are Spearman's\nand Kendall's. We show that for bivariate normal i.i.d. samples the pairwise\nasymptotic relative efficiency between these three statistics depends\nmonotonically on the population correlation coefficient. This monotonicity is a\ncorollary to a stronger result. The proofs rely on the use of l'Hospital-type\nrules for monotonicity patterns.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2009 00:09:40 GMT"}], "update_date": "2009-08-03", "authors_parsed": [["Molzon", "Raymond", ""], ["Pinelis", "Iosif", ""]]}]