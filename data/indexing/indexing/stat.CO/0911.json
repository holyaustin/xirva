[{"id": "0911.0047", "submitter": "Ethan Anderes", "authors": "Ethan Anderes and Michael Stein", "title": "Local likelihood estimation of local parameters for nonstationary random\n  fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a weighted local likelihood estimate for the parameters that\ngovern the local spatial dependency of a locally stationary random field. The\nadvantage of this local likelihood estimate is that it smoothly downweights the\ninfluence of far away observations, works for irregular sampling locations, and\nwhen designed appropriately, can trade bias and variance for reducing\nestimation error. This paper starts with an exposition of our technique on the\nproblem of estimating an unknown positive function when multiplied by a\nstationary random field. This example gives concrete evidence of the benefits\nof our local likelihood as compared to na\\\"ive local likelihoods where the\nstationary model is assumed throughout a neighborhood. We then discuss the\ndifficult problem of estimating a bandwidth parameter that controls the amount\nof influence from distant observations. Finally we present a simulation\nexperiment for estimating the local smoothness of a local Mat\\'ern random field\nwhen observing the field at random sampling locations in $[0,1]^2$.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2009 00:57:51 GMT"}], "update_date": "2009-11-03", "authors_parsed": [["Anderes", "Ethan", ""], ["Stein", "Michael", ""]]}, {"id": "0911.0108", "submitter": "Yaming Yu", "authors": "Yaming Yu", "title": "D-optimal designs via a cocktail algorithm", "comments": "A number of changes after accounting for the referees' comments\n  including new examples in Section 4 and more detailed explanations throughout", "journal-ref": "Statistics and Computing 21 (2011) 475-481", "doi": "10.1007/s11222-010-9183-2", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fast new algorithm is proposed for numerical computation of (approximate)\nD-optimal designs. This \"cocktail algorithm\" extends the well-known vertex\ndirection method (VDM; Fedorov 1972) and the multiplicative algorithm (Silvey,\nTitterington and Torsney, 1978), and shares their simplicity and monotonic\nconvergence properties. Numerical examples show that the cocktail algorithm can\nlead to dramatically improved speed, sometimes by orders of magnitude, relative\nto either the multiplicative algorithm or the vertex exchange method (a variant\nof VDM). Key to the improved speed is a new nearest neighbor exchange strategy,\nwhich acts locally and complements the global effect of the multiplicative\nalgorithm. Possible extensions to related problems such as nonparametric\nmaximum likelihood estimation are mentioned.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2009 20:32:12 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2009 22:40:35 GMT"}, {"version": "v3", "created": "Wed, 19 May 2010 16:29:00 GMT"}], "update_date": "2011-08-15", "authors_parsed": [["Yu", "Yaming", ""]]}, {"id": "0911.0221", "submitter": "Yves Atchade F", "authors": "Yves F. Atchade and Gersende Fort", "title": "Limit theorems for some adaptive MCMC algorithms with subgeometric\n  kernels: Part II", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove a central limit theorem for a general class of adaptive Markov Chain\nMonte Carlo algorithms driven by sub-geometrically ergodic Markov kernels. We\ndiscuss in detail the special case of stochastic approximation. We use the\nresult to analyze the asymptotic behavior of an adaptive version of the\nMetropolis Adjusted Langevin algorithm with a heavy tailed target density.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2009 01:10:38 GMT"}], "update_date": "2009-11-03", "authors_parsed": [["Atchade", "Yves F.", ""], ["Fort", "Gersende", ""]]}, {"id": "0911.0230", "submitter": "Robert Kohn", "authors": "Ralph Silva, Paolo Giordani, Robert Kohn and Mike Pitt", "title": "Particle filtering within adaptive Metropolis Hastings sampling", "comments": "37 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that it is feasible to carry out exact Bayesian inference for\nnon-Gaussian state space models using an adaptive Metropolis Hastings sampling\nscheme with the likelihood approximated by the particle filter. Furthermore, an\nadapyive independent Metropolis Hastings sampler based on a mixture of normals\nproposal is computationally much more efficient than an adaptive random walk\nproposal because the cost of constructing a good adaptive proposal is\nnegligible compared to the cost of approximating the likelihood. Independent\nMetropolis Hastings proposals are also attractive because they are easy to run\nin parallel on multiple processors. We also show that when the particle filter\nis used, the marginal likelihood of any model is obtained in an efficient and\nunbiased manner, making model comparison straightforward.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2009 13:43:29 GMT"}], "update_date": "2009-11-03", "authors_parsed": [["Silva", "Ralph", ""], ["Giordani", "Paolo", ""], ["Kohn", "Robert", ""], ["Pitt", "Mike", ""]]}, {"id": "0911.0412", "submitter": "Enrico Carlini", "authors": "Enrico Carlini and Fabio Rapallo", "title": "Probability matrices, non-negative rank, and parameterizations of\n  mixture models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we parameterize non-negative matrices of sum one and rank at\nmost two. More precisely, we give a family of parameterizations using the least\npossible number of parameters. We also show how these parameterizations relate\nto a class of statistical models, known in Probability and Statistics as\nmixture models for contingency tables.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2009 21:33:22 GMT"}, {"version": "v2", "created": "Mon, 9 Nov 2009 22:41:21 GMT"}], "update_date": "2009-11-10", "authors_parsed": [["Carlini", "Enrico", ""], ["Rapallo", "Fabio", ""]]}, {"id": "0911.0522", "submitter": "Matti Vihola", "authors": "Matti Vihola", "title": "Can the Adaptive Metropolis Algorithm Collapse Without the Covariance\n  Lower Bound?", "comments": "31 pages, 1 figure", "journal-ref": "Electronic Journal of Probability, Vol 16, pp. 45-75, 2011", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Adaptive Metropolis (AM) algorithm is based on the symmetric random-walk\nMetropolis algorithm. The proposal distribution has the following\ntime-dependent covariance matrix at step $n+1$ \\[\n  S_n = Cov(X_1,...,X_n) + \\epsilon I, \\] that is, the sample covariance matrix\nof the history of the chain plus a (small) constant $\\epsilon>0$ multiple of\nthe identity matrix $I$. The lower bound on the eigenvalues of $S_n$ induced by\nthe factor $\\epsilon I$ is theoretically convenient, but practically\ncumbersome, as a good value for the parameter $\\epsilon$ may not always be easy\nto choose. This article considers variants of the AM algorithm that do not\nexplicitly bound the eigenvalues of $S_n$ away from zero. The behaviour of\n$S_n$ is studied in detail, indicating that the eigenvalues of $S_n$ do not\ntend to collapse to zero in general.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2009 09:10:55 GMT"}], "update_date": "2011-02-09", "authors_parsed": [["Vihola", "Matti", ""]]}, {"id": "0911.0985", "submitter": "Christian P. Robert", "authors": "Pierre Jacob, Nicolas Chopin, Christian P. Robert and Havard Rue", "title": "Comments on \"Particle Markov chain Monte Carlo\" by C. Andrieu, A.\n  Doucet, and R. Hollenstein", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the compilation of our comments submitted to the Journal of the Royal\nStatistical Society, Series B, to be published within the discussion of the\nRead Paper of Andrieu, Doucet and Hollenstein.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2009 07:10:03 GMT"}], "update_date": "2009-11-06", "authors_parsed": [["Jacob", "Pierre", ""], ["Chopin", "Nicolas", ""], ["Robert", "Christian P.", ""], ["Rue", "Havard", ""]]}, {"id": "0911.1164", "submitter": "Yves F. Atchad\\'{e}", "authors": "Yves F. Atchad\\'e", "title": "Kernel estimators of asymptotic variance for adaptive Markov chain Monte\n  Carlo", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS828 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 2, 990-1011", "doi": "10.1214/10-AOS828", "report-no": "IMS-AOS-AOS828", "categories": "math.PR math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic behavior of kernel estimators of asymptotic variances\n(or long-run variances) for a class of adaptive Markov chains. The convergence\nis studied both in $L^p$ and almost surely. The results also apply to Markov\nchains and improve on the existing literature by imposing weaker conditions. We\nillustrate the results with applications to the $\\operatorname {GARCH}(1,1)$\nMarkov model and to an adaptive MCMC algorithm for Bayesian logistic\nregression.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2009 02:02:04 GMT"}, {"version": "v2", "created": "Mon, 16 May 2011 08:44:09 GMT"}], "update_date": "2011-05-17", "authors_parsed": [["Atchad\u00e9", "Yves F.", ""]]}, {"id": "0911.1189", "submitter": "Bertrand Iooss", "authors": "Amandine Marrel (IFP), Bertrand Iooss (M\\'ethodes d'Analyse\n  Stochastique des Codes et Traitements Num\\'eriques), Michel Jullien, Beatrice\n  Laurent (IMT), Elena Volkova", "title": "Global sensitivity analysis for models with spatially dependent outputs", "comments": null, "journal-ref": "Environmentrics 22 (2011) 383-397", "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global sensitivity analysis of a complex numerical model often calls for\nthe estimation of variance-based importance measures, named Sobol' indices.\nMetamodel-based techniques have been developed in order to replace the cpu\ntime-expensive computer code with an inexpensive mathematical function, which\npredicts the computer code output. The common metamodel-based sensitivity\nanalysis methods are well-suited for computer codes with scalar outputs.\nHowever, in the environmental domain, as in many areas of application, the\nnumerical model outputs are often spatial maps, which may also vary with time.\nIn this paper, we introduce an innovative method to obtain a spatial map of\nSobol' indices with a minimal number of numerical model computations. It is\nbased upon the functional decomposition of the spatial output onto a wavelet\nbasis and the metamodeling of the wavelet coefficients by the Gaussian process.\nAn analytical example is presented to clarify the various steps of our\nmethodology. This technique is then applied to a real hydrogeological case: for\neach model input variable, a spatial map of Sobol' indices is thus obtained.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2009 07:33:31 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2010 08:12:40 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2010 16:25:22 GMT"}, {"version": "v4", "created": "Thu, 23 Sep 2010 11:58:53 GMT"}], "update_date": "2011-04-22", "authors_parsed": [["Marrel", "Amandine", "", "IFP"], ["Iooss", "Bertrand", "", "M\u00e9thodes d'Analyse\n  Stochastique des Codes et Traitements Num\u00e9riques"], ["Jullien", "Michel", "", "IMT"], ["Laurent", "Beatrice", "", "IMT"], ["Volkova", "Elena", ""]]}, {"id": "0911.1705", "submitter": "Tina Toni", "authors": "Tina Toni and Michael P. H. Stumpf", "title": "Simulation-based model selection for dynamical systems in systems and\n  population biology", "comments": "This article is in press in Bioinformatics, 2009. Advance Access is\n  available on Bioinformatics webpage", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer simulations have become an important tool across the biomedical\nsciences and beyond. For many important problems several different models or\nhypotheses exist and choosing which one best describes reality or observed data\nis not straightforward. We therefore require suitable statistical tools that\nallow us to choose rationally between different mechanistic models of e.g.\nsignal transduction or gene regulation networks. This is particularly\nchallenging in systems biology where only a small number of molecular species\ncan be assayed at any given time and all measurements are subject to\nmeasurement uncertainty. Here we develop such a model selection framework based\non approximate Bayesian computation and employing sequential Monte Carlo\nsampling. We show that our approach can be applied across a wide range of\nbiological scenarios, and we illustrate its use on real data describing\ninfluenza dynamics and the JAK-STAT signalling pathway. Bayesian model\nselection strikes a balance between the complexity of the simulation models and\ntheir ability to describe observed data. The present approach enables us to\nemploy the whole formal apparatus to any system that can be (efficiently)\nsimulated, even when exact likelihoods are computationally intractable.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2009 15:45:41 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2010 10:29:36 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2010 15:30:10 GMT"}], "update_date": "2010-01-20", "authors_parsed": [["Toni", "Tina", ""], ["Stumpf", "Michael P. H.", ""]]}, {"id": "0911.1894", "submitter": "Yanan Fan Dr", "authors": "Y. Fan, J.-L Dortet-Bernadet, S. A. Sisson", "title": "On Bayesian Curve Fitting Via Auxiliary Variables", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we revisit the auxiliary variable method introduced in Smith\nand kohn (1996) for the fitting of P-th order spline regression models with an\nunknown number of knot points. We introduce modifications which allow the\nlocation of knot points to be random, and we further consider an extension of\nthe method to handle models with non-Gaussian errors. We provide a new\nalgorithm for the MCMC sampling of such models. Simulated data examples are\nused to compare the performance of our method with existing ones. Finally, we\nmake a connection with some change-point problems, and show how they can be\nre-parameterised to the variable selection setting.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2009 12:18:06 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2009 16:25:32 GMT"}], "update_date": "2009-11-11", "authors_parsed": [["Fan", "Y.", ""], ["Dortet-Bernadet", "J. -L", ""], ["Sisson", "S. A.", ""]]}, {"id": "0911.1928", "submitter": "Andrew Smith", "authors": "Arne Kovac and Andrew D.A.C. Smith", "title": "Regression on a Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The `Signal plus Noise' model for nonparametric regression can be extended to\nthe case of observations taken at the vertices of a graph. This model includes\nmany familiar regression problems. This article discusses the use of the edges\nof a graph to measure roughness in penalized regression. Distance between\nestimate and observation is measured at every vertex in the $L_2$ norm, and\nroughness is penalized on every edge in the $L_1$ norm. Thus the ideas of\ntotal-variation penalization can be extended to a graph. The resulting\nminimization problem presents special computational challenges, so we describe\na new, fast algorithm and demonstrate its use with examples.\n  Further examples include a graphical approach that gives an improved estimate\nof the baseline in spectroscopic analysis, and a simulation applicable to\ndiscrete spatial variation. In our example, penalized regression outperforms\nkernel smoothing in terms of identifying local extreme values. In all examples\nwe use fully automatic procedures for setting the smoothing parameters.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2009 15:29:49 GMT"}], "update_date": "2009-11-11", "authors_parsed": [["Kovac", "Arne", ""], ["Smith", "Andrew D. A. C.", ""]]}, {"id": "0911.2634", "submitter": "Giorgio Vittadini Mr", "authors": "Salvatore Ingrassia, Simona C. Minotti, Giorgio Vittadini", "title": "Local statistical modeling by cluster-weighted", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate statistical properties of Cluster-Weighted Modeling, which is\na framework for supervised learning originally developed in order to recreate a\ndigital violin with traditional inputs and realistic sound. The analysis is\ncarried out in comparison with Finite Mixtures of Regression models. Based on\nsome geometrical arguments, we highlight that Cluster-WeightedModeling provides\na quite general framework for local statistical modeling. Theoretical results\nare illustrated on the ground of some numerical simulations.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2009 15:20:29 GMT"}, {"version": "v2", "created": "Mon, 13 Sep 2010 09:35:36 GMT"}, {"version": "v3", "created": "Wed, 15 Jun 2011 09:47:06 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Ingrassia", "Salvatore", ""], ["Minotti", "Simona C.", ""], ["Vittadini", "Giorgio", ""]]}, {"id": "0911.3866", "submitter": "Julien Cornebise", "authors": "Julien Cornebise and Gareth W. Peters", "title": "Comments on \"Particle Markov Chain Monte Carlo\" by C. Andrieu, A. Doucet\n  and R. Hollenstein", "comments": "This merged extended version of our two comments to be published in\n  the discussion of Andrieu, C., A. Doucet, and R. Holenstein (2010), Particle\n  Markov chain Monte Carlo methods. J. R. Statis. Soc. B 72 (2), 1-33. is\n  available as a technical report of Statistical and Applied Mathematical\n  Sciences Institute (SAMSI), see http://www.samsi.info/TR/tr2009-07.pdf", "journal-ref": null, "doi": null, "report-no": "2009-07", "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We merge in this note our two discussions about the Read Paper \"Particle\nMarkov chain Monte Carlo\" (Andrieu, Doucet, and Holenstein, 2010) presented on\nOctober 16th 2009 at the Royal Statistical Society, appearing in the Journal of\nthe Royal Statistical Society Series B. We also present a more detailed version\nof the ABC extension.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2009 20:47:13 GMT"}], "update_date": "2009-11-20", "authors_parsed": [["Cornebise", "Julien", ""], ["Peters", "Gareth W.", ""]]}, {"id": "0911.4546", "submitter": "James P. Hobert", "authors": "James P. Hobert, Vivekananda Roy, Christian P. Robert", "title": "Improving the Convergence Properties of the Data Augmentation Algorithm\n  with an Application to Bayesian Mixture Modeling", "comments": "Published in at http://dx.doi.org/10.1214/11-STS365 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2011, Vol. 26, No. 3, 332-351", "doi": "10.1214/11-STS365", "report-no": "IMS-STS-STS365", "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reversible Markov chains that drive the data augmentation (DA) and\nsandwich algorithms define self-adjoint operators whose spectra encode the\nconvergence properties of the algorithms. When the target distribution has\nuncountable support, as is nearly always the case in practice, it is generally\nquite difficult to get a handle on these spectra. We show that, if the\naugmentation space is finite, then (under regularity conditions) the operators\ndefined by the DA and sandwich chains are compact, and the spectra are finite\nsubsets of $[0,1)$. Moreover, we prove that the spectrum of the sandwich\noperator dominates the spectrum of the DA operator in the sense that the\nordered elements of the former are all less than or equal to the corresponding\nelements of the latter. As a concrete example, we study a widely used DA\nalgorithm for the exploration of posterior densities associated with Bayesian\nmixture models [J. Roy. Statist. Soc. Ser. B 56 (1994) 363--375]. In\nparticular, we compare this mixture DA algorithm with an alternative algorithm\nproposed by Fr\\\"{u}hwirth-Schnatter [J. Amer. Statist. Assoc. 96 (2001)\n194--209] that is based on random label switching.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2009 05:32:19 GMT"}, {"version": "v2", "created": "Sat, 4 Jun 2011 11:44:11 GMT"}, {"version": "v3", "created": "Fri, 3 Feb 2012 14:29:05 GMT"}], "update_date": "2012-02-06", "authors_parsed": [["Hobert", "James P.", ""], ["Roy", "Vivekananda", ""], ["Robert", "Christian P.", ""]]}]