[{"id": "1506.00043", "submitter": "Matthias Morzfeld", "authors": "Alexandre J. Chorin, Fei Lu, Robert N. Miller, Matthias Morzfeld,\n  Xuemin Tu", "title": "Sampling, feasibility, and priors in Bayesian estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance sampling algorithms are discussed in detail, with an emphasis on\nimplicit sampling, and applied to data assimilation via particle filters.\nImplicit sampling makes it possible to use the data to find high-probability\nsamples at relatively low cost, making the assimilation more efficient. A new\nanalysis of the feasibility of data assimilation is presented, showing in\ndetail why feasibility depends on the Frobenius norm of the covariance matrix\nof the noise and not on the number of variables. A discussion of the\nconvergence of particular particle filters follows. A major open problem in\nnumerical data assimilation is the determination of appropriate priors, a\nprogress report on recent work on this problem is given. The analysis\nhighlights the need for a careful attention both to the data and to the physics\nin data assimilation problems.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 22:23:18 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Chorin", "Alexandre J.", ""], ["Lu", "Fei", ""], ["Miller", "Robert N.", ""], ["Morzfeld", "Matthias", ""], ["Tu", "Xuemin", ""]]}, {"id": "1506.00053", "submitter": "Panagiotis Tsilifis", "authors": "Panagiotis Tsilifis, Roger G. Ghanem and Paris Hajali", "title": "Efficient Bayesian experimentation using an expected information gain\n  lower bound", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML physics.geo-ph stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental design is crucial for inference where limitations in the data\ncollection procedure are present due to cost or other restrictions. Optimal\nexperimental designs determine parameters that in some appropriate sense make\nthe data the most informative possible. In a Bayesian setting this is\ntranslated to updating to the best possible posterior. Information theoretic\narguments have led to the formation of the expected information gain as a\ndesign criterion. This can be evaluated mainly by Monte Carlo sampling and\nmaximized by using stochastic approximation methods, both known for being\ncomputationally expensive tasks. We propose a framework where a lower bound of\nthe expected information gain is used as an alternative design criterion. In\naddition to alleviating the computational burden, this also addresses issues\nconcerning estimation bias. The problem of permeability inference in a large\ncontaminated area is used to demonstrate the validity of our approach where we\nemploy the massively parallel version of the multiphase multicomponent\nsimulator TOUGH2 to simulate contaminant transport and a Polynomial Chaos\napproximation of the forward model that further accelerates the objective\nfunction evaluations. The proposed methodology is demonstrated to a setting\nwhere field measurements are available.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2015 01:17:38 GMT"}, {"version": "v2", "created": "Thu, 10 Mar 2016 18:34:41 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["Tsilifis", "Panagiotis", ""], ["Ghanem", "Roger G.", ""], ["Hajali", "Paris", ""]]}, {"id": "1506.00138", "submitter": "Joseph Guinness", "authors": "Joseph Guinness and Ilse C. F. Ipsen", "title": "Efficient Computation of Gaussian Likelihoods for Stationary Markov\n  Random Field Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rue and Held (2005) proposed a method for efficiently computing the Gaussian\nlikelihood for stationary Markov random field models, when the data locations\nfall on a complete regular grid, and the model has no additive error term. The\ncalculations rely on the availability of the covariances. We prove a theorem\ngiving the rate of convergence of a spectral method of computing the\ncovariances, establishing that the error decays faster than any polynomial in\nthe size of the computing grid. We extend the exact likelihood calculations to\nthe case of non-rectangular domains and missing values on the interior of the\ngrid and to the case when an additive uncorrelated error term (nugget) is\npresent in the model. We also give an alternative formulation of the likelihood\nthat has a smaller memory burden, parts of which can be computed in parallel.\nWe show in simulations that using the exact likelihood can give far better\nparameter estimates than using standard Markov random field approximations.\nHaving access to the exact likelihood allows for model comparisons via\nlikelihood ratios on large datasets, so as an application of the methods, we\ncompare several state-of-the-art methods for large spatial datasets on an\naerosol optical thickness dataset. We find that simple block independent\nlikelihood and composite likelihood methods outperform stochastic partial\ndifferential equation approximations in terms of computation time and returning\nparameter estimates that nearly maximize the likelihood.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2015 16:17:38 GMT"}, {"version": "v2", "created": "Thu, 12 Dec 2019 21:23:38 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Guinness", "Joseph", ""], ["Ipsen", "Ilse C. F.", ""]]}, {"id": "1506.00343", "submitter": "Alireza Doostan", "authors": "Ji Peng and Jerrad Hampton and Alireza Doostan", "title": "On Polynomial Chaos Expansion via Gradient-enhanced\n  $\\ell_1$-minimization", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2015.12.049", "report-no": null, "categories": "stat.CO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gradient-enhanced Uncertainty Quantification (UQ) has received recent\nattention, in which the derivatives of a Quantity of Interest (QoI) with\nrespect to the uncertain parameters are utilized to improve the surrogate\napproximation. Polynomial chaos expansions (PCEs) are often employed in UQ, and\nwhen the QoI can be represented by a sparse PCE, $\\ell_1$-minimization can\nidentify the PCE coefficients with a relatively small number of samples. In\nthis work, we investigate a gradient-enhanced $\\ell_1$-minimization, where\nderivative information is computed to accelerate the identification of the PCE\ncoefficients. For this approach, stability and convergence analysis are\nlacking, and thus we address these here with a probabilistic result. In\nparticular, with an appropriate normalization, we show the inclusion of\nderivative information will almost-surely lead to improved conditions, e.g.\nrelated to the null-space and coherence of the measurement matrix, for a\nsuccessful solution recovery. Further, we demonstrate our analysis empirically\nvia three numerical examples: a manufactured PCE, an elliptic partial\ndifferential equation with random inputs, and a plane Poiseuille flow with\nrandom boundaries. These examples all suggest that including derivative\ninformation admits solution recovery at reduced computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 04:08:56 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Peng", "Ji", ""], ["Hampton", "Jerrad", ""], ["Doostan", "Alireza", ""]]}, {"id": "1506.00552", "submitter": "Julie Nutini", "authors": "Julie Nutini, Mark Schmidt, Issam H. Laradji, Michael Friedlander,\n  Hoyt Koepke", "title": "Coordinate Descent Converges Faster with the Gauss-Southwell Rule Than\n  Random Selection", "comments": "ICML 2015. v2: Updated the Gauss-Southwell-q result in Section 8 and\n  Appendix H, to remove the part depending on mu_1 (the proof had an error).\n  Added Section 8.1, which discusses conditions under which a rate depending on\n  mu_1 does hold", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been significant recent work on the theory and application of\nrandomized coordinate descent algorithms, beginning with the work of Nesterov\n[SIAM J. Optim., 22(2), 2012], who showed that a random-coordinate selection\nrule achieves the same convergence rate as the Gauss-Southwell selection rule.\nThis result suggests that we should never use the Gauss-Southwell rule, as it\nis typically much more expensive than random selection. However, the empirical\nbehaviours of these algorithms contradict this theoretical result: in\napplications where the computational costs of the selection rules are\ncomparable, the Gauss-Southwell selection rule tends to perform substantially\nbetter than random coordinate selection. We give a simple analysis of the\nGauss-Southwell rule showing that---except in extreme cases---its convergence\nrate is faster than choosing random coordinates. Further, in this work we (i)\nshow that exact coordinate optimization improves the convergence rate for\ncertain sparse problems, (ii) propose a Gauss-Southwell-Lipschitz rule that\ngives an even faster convergence rate given knowledge of the Lipschitz\nconstants of the partial derivatives, (iii) analyze the effect of approximate\nGauss-Southwell rules, and (iv) analyze proximal-gradient variants of the\nGauss-Southwell rule.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 16:04:37 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2018 17:11:00 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Nutini", "Julie", ""], ["Schmidt", "Mark", ""], ["Laradji", "Issam H.", ""], ["Friedlander", "Michael", ""], ["Koepke", "Hoyt", ""]]}, {"id": "1506.00570", "submitter": "Nicolas Chopin", "authors": "Nicolas Chopin, James Ridgway, Mathieu Gerber, Omiros Papaspiliopoulos", "title": "Towards automatic calibration of the number of state particles within\n  the SMC$^2$ algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SMC$^2$ is an efficient algorithm for sequential estimation and state\ninference of state-space models. It generates $N_{\\theta}$ parameter particles\n$\\theta^{m}$, and, for each $\\theta^{m}$, it runs a particle filter of size\n$N_{x}$ (i.e. at each time step, $N_{x}$ particles are generated in the state\nspace $\\mathcal{X}$). We discuss how to automatically calibrate $N_{x}$ in the\ncourse of the algorithm. Our approach relies on conditional Sequential Monte\nCarlo updates, monitoring the state of the pseudo random number generator and\non an estimator of the variance of the unbiased estimate of the likelihood that\nis produced by the particle filters, which is obtained using nonparametric\nregression techniques. We observe that our approach is both less CPU intensive\nand with smaller Monte Carlo errors than the initial version of SMC$^2$.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 17:01:56 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Chopin", "Nicolas", ""], ["Ridgway", "James", ""], ["Gerber", "Mathieu", ""], ["Papaspiliopoulos", "Omiros", ""]]}, {"id": "1506.00575", "submitter": "Nicolas Boumal", "authors": "Nicolas Boumal", "title": "A Riemannian low-rank method for optimization over semidefinite matrices\n  with block-diagonal constraints", "comments": "37 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm to solve optimization problems of the form $\\min\nf(X)$ for a smooth function $f$ under the constraints that $X$ is positive\nsemidefinite and the diagonal blocks of $X$ are small identity matrices. Such\nproblems often arise as the result of relaxing a rank constraint (lifting). In\nparticular, many estimation tasks involving phases, rotations, orthonormal\nbases or permutations fit in this framework, and so do certain relaxations of\ncombinatorial problems such as Max-Cut. The proposed algorithm exploits the\nfacts that (1) such formulations admit low-rank solutions, and (2) their\nrank-restricted versions are smooth optimization problems on a Riemannian\nmanifold. Combining insights from both the Riemannian and the convex geometries\nof the problem, we characterize when second-order critical points of the smooth\nproblem reveal KKT points of the semidefinite problem. We compare against state\nof the art, mature software and find that, on certain interesting problem\ninstances, what we call the staircase method is orders of magnitude faster, is\nmore accurate and scales better. Code is available.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 17:17:49 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 15:01:39 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Boumal", "Nicolas", ""]]}, {"id": "1506.00774", "submitter": "Jiangjiang Zhang", "authors": "Jiangjiang Zhang", "title": "Inverse iterative simulation: An efficient approach for contaminant\n  source identification", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In groundwater contaminant remediation and risk assessment, it is important\nto identify parameters of the contaminant source and hydraulic conductivity\nfield by solving an inverse problem. However, if the dimensionality of the\ninverse problem is high, it is usually computationally expensive to obtain\naccurate estimation and uncertainty assessment of these parameters. This is\nparticularly the case when Markov Chain Monte Carlo (MCMC) sampling is used. In\nthis paper, an efficient approach entitled inverse iterative simulation (iIS)\nis proposed to efficiently identify the contaminant source characteristics,\ntogether with the hydraulic conductivity field. The iIS algorithm utilizes a\nsimple approach borrowed from Ensemble Smother (ES) to update model parameters\nand an inverse Gaussian process (iGP) approach to improve the accuracy of\nparameter updating. Two numerical experiments are tested. For the low\ndimensional case (with 11 parameters), the iIS algorithm can obtain parameter\nestimation very close to that of MCMC method. For the high dimensional case\n(with 108 parameters), the iIS algorithm can obtain accurate parameter\nestimation with very low computational cost.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 06:59:56 GMT"}, {"version": "v2", "created": "Tue, 16 Jun 2015 06:16:28 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Zhang", "Jiangjiang", ""]]}, {"id": "1506.00821", "submitter": "Hung Hoang", "authors": "Hung Gia Hoang and Ba-Tuong Vo and Ba-Ngu Vo", "title": "A Generalized Labeled Multi-Bernoulli Filter Implementation using Gibbs\n  Sampling", "comments": "11 pages, 8 figures. Part of the paper has been accepted for\n  presentation at the 18th international conference on Information Fusion\n  (FUSION 15)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an efficient implementation of the generalized labeled\nmulti-Bernoulli (GLMB) filter by combining the prediction and update into a\nsingle step. In contrast to the original approach which involves separate\ntruncations in the prediction and update steps, the proposed implementation\nrequires only one single truncation for each iteration, which can be performed\nusing a standard ranked optimal assignment algorithm. Furthermore, we propose a\nnew truncation technique based on Markov Chain Monte Carlo methods such as\nGibbs sampling, which drastically reduces the complexity of the filter. The\nsuperior performance of the proposed approach is demonstrated through extensive\nnumerical studies.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 09:59:34 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2015 11:18:15 GMT"}, {"version": "v3", "created": "Fri, 3 Jul 2015 06:17:28 GMT"}], "update_date": "2015-07-06", "authors_parsed": [["Hoang", "Hung Gia", ""], ["Vo", "Ba-Tuong", ""], ["Vo", "Ba-Ngu", ""]]}, {"id": "1506.01117", "submitter": "Rohan Shah", "authors": "Rohan Shah and Dirk P. Kroese", "title": "Estimating Residual Connectivity for Random Graphs", "comments": "29 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation of the probability that a random graph is connected is a\nchallenging problem, so it is natural to turn to approximations such as Monte\nCarlo methods. We describe sequential importance resampling and splitting\nalgorithms for the estimation of these probabilities. The importance sampling\nsteps of these algorithms involve identifying vertices that must be present in\norder for the random graph to be connected, and conditioning on the\ncorresponding events. We provide numerical results demonstrating the\neffectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 04:28:39 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Shah", "Rohan", ""], ["Kroese", "Dirk P.", ""]]}, {"id": "1506.01326", "submitter": "Philipp Hennig PhD", "authors": "Philipp Hennig and Michael A Osborne and Mark Girolami", "title": "Probabilistic Numerics and Uncertainty in Computations", "comments": "Author Generated Postprint. 17 pages, 4 Figures, 1 Table", "journal-ref": null, "doi": "10.1098/rspa.2015.0142", "report-no": null, "categories": "math.NA cs.AI cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deliver a call to arms for probabilistic numerical methods: algorithms for\nnumerical tasks, including linear algebra, integration, optimization and\nsolving differential equations, that return uncertainties in their\ncalculations. Such uncertainties, arising from the loss of precision induced by\nnumerical calculation with limited time or hardware, are important for much\ncontemporary science and industry. Within applications such as climate science\nand astrophysics, the need to make decisions on the basis of computations with\nlarge and complex data has led to a renewed focus on the management of\nnumerical uncertainty. We describe how several seminal classic numerical\nmethods can be interpreted naturally as probabilistic inference. We then show\nthat the probabilistic view suggests new algorithms that can flexibly be\nadapted to suit application specifics, while delivering improved empirical\nperformance. We provide concrete illustrations of the benefits of probabilistic\nnumeric algorithms on real scientific problems from astrometry and astronomical\nimaging, while highlighting open problems with these new algorithms. Finally,\nwe describe how probabilistic numerical methods provide a coherent framework\nfor identifying the uncertainty in calculations performed with a combination of\nnumerical algorithms (e.g. both numerical optimisers and differential equation\nsolvers), potentially allowing the diagnosis (and control) of error sources in\ncomputations.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 17:45:01 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Hennig", "Philipp", ""], ["Osborne", "Michael A", ""], ["Girolami", "Mark", ""]]}, {"id": "1506.02267", "submitter": "Andreas Svensson", "authors": "Andreas Svensson, Arno Solin, Simo S\\\"arkk\\\"a, Thomas B. Sch\\\"on", "title": "Computationally Efficient Bayesian Learning of Gaussian Process State\n  Space Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes allow for flexible specification of prior assumptions of\nunknown dynamics in state space models. We present a procedure for efficient\nBayesian learning in Gaussian process state space models, where the\nrepresentation is formed by projecting the problem onto a set of approximate\neigenfunctions derived from the prior covariance structure. Learning under this\nfamily of models can be conducted using a carefully crafted particle MCMC\nalgorithm. This scheme is computationally efficient and yet allows for a fully\nBayesian treatment of the problem. Compared to conventional system\nidentification tools or existing learning methods, we show competitive\nperformance and reliable quantification of uncertainties in the model.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 13:57:51 GMT"}, {"version": "v2", "created": "Fri, 15 Apr 2016 07:39:12 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Svensson", "Andreas", ""], ["Solin", "Arno", ""], ["S\u00e4rkk\u00e4", "Simo", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1506.02557", "submitter": "Diederik P Kingma M.Sc.", "authors": "Diederik P. Kingma, Tim Salimans, Max Welling", "title": "Variational Dropout and the Local Reparameterization Trick", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a local reparameterizaton technique for greatly reducing the\nvariance of stochastic gradients for variational Bayesian inference (SGVB) of a\nposterior over model parameters, while retaining parallelizability. This local\nreparameterization translates uncertainty about global parameters into local\nnoise that is independent across datapoints in the minibatch. Such\nparameterizations can be trivially parallelized and have variance that is\ninversely proportional to the minibatch size, generally leading to much faster\nconvergence. Additionally, we explore a connection with dropout: Gaussian\ndropout objectives correspond to SGVB with local reparameterization, a\nscale-invariant prior and proportionally fixed posterior variance. Our method\nallows inference of more flexibly parameterized posteriors; specifically, we\npropose variational dropout, a generalization of Gaussian dropout where the\ndropout rates are learned, often leading to better models. The method is\ndemonstrated through several experiments.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 15:37:56 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2015 16:07:38 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Kingma", "Diederik P.", ""], ["Salimans", "Tim", ""], ["Welling", "Max", ""]]}, {"id": "1506.02691", "submitter": "Evangelos Evangelou", "authors": "Evangelos Evangelou and Vasileios Maroulas", "title": "Sequential Empirical Bayes method for filtering dynamic spatiotemporal\n  processes", "comments": null, "journal-ref": "Spatial Statistics 21PA, pp. 114-129 (2017)", "doi": "10.1016/j.spasta.2017.06.006", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider online prediction of a latent dynamic spatiotemporal process and\nestimation of the associated model parameters based on noisy data. The problem\nis motivated by the analysis of spatial data arriving in real-time and the\ncurrent parameter estimates and predictions are updated using the new data at a\nfixed computational cost. Estimation and prediction is performed within an\nempirical Bayes framework with the aid of Markov chain Monte Carlo samples.\nSamples for the latent spatial field are generated using a sampling importance\nresampling algorithm with a skewed-normal proposal and for the temporal\nparameters using Gibbs sampling with their full conditionals written in terms\nof sufficient quantities which are updated online. The spatial range parameter\nis estimated by a novel online implementation of an empirical Bayes method,\ncalled herein sequential empirical Bayes method. A simulation study shows that\nour method gives similar results as an offline Bayesian method. We also find\nthat the skewed-normal proposal improves over the traditional Gaussian\nproposal. The application of our method is demonstrated for online monitoring\nof radiation after the Fukushima nuclear accident.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 20:42:52 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2015 18:10:07 GMT"}, {"version": "v3", "created": "Tue, 26 Apr 2016 21:22:26 GMT"}, {"version": "v4", "created": "Sat, 21 Jan 2017 19:24:01 GMT"}, {"version": "v5", "created": "Tue, 27 Jun 2017 08:45:25 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Evangelou", "Evangelos", ""], ["Maroulas", "Vasileios", ""]]}, {"id": "1506.03074", "submitter": "Maxim Rabinovich", "authors": "Maxim Rabinovich, Elaine Angelino, Michael I. Jordan", "title": "Variational consensus Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Practitioners of Bayesian statistics have long depended on Markov chain Monte\nCarlo (MCMC) to obtain samples from intractable posterior distributions.\nUnfortunately, MCMC algorithms are typically serial, and do not scale to the\nlarge datasets typical of modern machine learning. The recently proposed\nconsensus Monte Carlo algorithm removes this limitation by partitioning the\ndata and drawing samples conditional on each partition in parallel (Scott et\nal, 2013). A fixed aggregation function then combines these samples, yielding\napproximate posterior samples. We introduce variational consensus Monte Carlo\n(VCMC), a variational Bayes algorithm that optimizes over aggregation functions\nto obtain samples from a distribution that better approximates the target. The\nresulting objective contains an intractable entropy term; we therefore derive a\nrelaxation of the objective and show that the relaxed problem is blockwise\nconcave under mild conditions. We illustrate the advantages of our algorithm on\nthree inference tasks from the literature, demonstrating both the superior\nquality of the posterior approximation and the moderate overhead of the\noptimization step. Our algorithm achieves a relative error reduction (measured\nagainst serial MCMC) of up to 39% compared to consensus Monte Carlo on the task\nof estimating 300-dimensional probit regression parameter expectations;\nsimilarly, it achieves an error reduction of 92% on the task of estimating\ncluster comembership probabilities in a Gaussian mixture model with 8\ncomponents in 8 dimensions. Furthermore, these gains come at moderate cost\ncompared to the runtime of serial MCMC, achieving near-ideal speedup in some\ninstances.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 20:00:48 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Rabinovich", "Maxim", ""], ["Angelino", "Elaine", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1506.03101", "submitter": "Bo Dai", "authors": "Bo Dai, Niao He, Hanjun Dai, Le Song", "title": "Provable Bayesian Inference via Particle Mirror Descent", "comments": "38 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian methods are appealing in their flexibility in modeling complex data\nand ability in capturing uncertainty in parameters. However, when Bayes' rule\ndoes not result in tractable closed-form, most approximate inference algorithms\nlack either scalability or rigorous guarantees. To tackle this challenge, we\npropose a simple yet provable algorithm, \\emph{Particle Mirror Descent} (PMD),\nto iteratively approximate the posterior density. PMD is inspired by stochastic\nfunctional mirror descent where one descends in the density space using a small\nbatch of data points at each iteration, and by particle filtering where one\nuses samples to approximate a function. We prove result of the first kind that,\nwith $m$ particles, PMD provides a posterior density estimator that converges\nin terms of $KL$-divergence to the true posterior in rate $O(1/\\sqrt{m})$. We\ndemonstrate competitive empirical performances of PMD compared to several\napproximate inference algorithms in mixture models, logistic regression, sparse\nGaussian processes and latent Dirichlet allocation on large scale datasets.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 20:57:37 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 19:06:18 GMT"}, {"version": "v3", "created": "Thu, 5 May 2016 22:56:13 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Dai", "Bo", ""], ["He", "Niao", ""], ["Dai", "Hanjun", ""], ["Song", "Le", ""]]}, {"id": "1506.03159", "submitter": "Dustin Tran", "authors": "Dustin Tran, David M. Blei, Edoardo M. Airoldi", "title": "Copula variational inference", "comments": "Appears in Neural Information Processing Systems, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general variational inference method that preserves dependency\namong the latent variables. Our method uses copulas to augment the families of\ndistributions used in mean-field and structured approximations. Copulas model\nthe dependency that is not captured by the original variational distribution,\nand thus the augmented variational family guarantees better approximations to\nthe posterior. With stochastic optimization, inference on the augmented\ndistribution is scalable. Furthermore, our strategy is generic: it can be\napplied to any inference procedure that currently uses the mean-field or\nstructured approach. Copula variational inference has many advantages: it\nreduces bias; it is less sensitive to local optima; it is less sensitive to\nhyperparameters; and it helps characterize and interpret the dependency among\nthe latent variables.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 04:14:22 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2015 06:52:07 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Tran", "Dustin", ""], ["Blei", "David M.", ""], ["Airoldi", "Edoardo M.", ""]]}, {"id": "1506.03571", "submitter": "Enea Giuseppe Bongiorno", "authors": "Enea G. Bongiorno and Aldo Goia", "title": "Classification methods for Hilbert data based on surrogate density", "comments": "33 pages, 11 figures, 6 tables", "journal-ref": "Computational Statistics & Data Analysis, 99 (2016) pp. 204-222", "doi": "10.1016/j.csda.2016.01.019", "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unsupervised and a supervised classification approaches for Hilbert random\ncurves are studied. Both rest on the use of a surrogate of the probability\ndensity which is defined, in a distribution-free mixture context, from an\nasymptotic factorization of the small-ball probability. That surrogate density\nis estimated by a kernel approach from the principal components of the data.\nThe focus is on the illustration of the classification algorithms and the\ncomputational implications, with particular attention to the tuning of the\nparameters involved. Some asymptotic results are sketched. Applications on\nsimulated and real datasets show how the proposed methods work.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 07:31:45 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2016 08:57:16 GMT"}], "update_date": "2016-03-30", "authors_parsed": [["Bongiorno", "Enea G.", ""], ["Goia", "Aldo", ""]]}, {"id": "1506.03670", "submitter": "David  Bolin", "authors": "David Bolin and Jonas Wallin", "title": "Spatially adaptive covariance tapering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covariance tapering is a popular approach for reducing the computational cost\nof spatial prediction and parameter estimation for Gaussian process models.\nHowever, tapering can have poor performance when the process is sampled at\nspatially irregular locations or when non-stationary covariance models are\nused. This work introduces an adaptive tapering method in order to improve the\nperformance of tapering in these problematic cases. This is achieved by\nintroducing a computationally convenient class of compactly supported\nnon-stationary covariance functions, combined with a new method for choosing\nspatially varying taper ranges. Numerical experiments are used to show that the\nperformance of both kriging prediction and parameter estimation can be improved\nby allowing for spatially varying taper ranges. However, although adaptive\ntapering outperforms regular tapering, simply dividing the data into blocks and\nignoring the dependence between the blocks is often a better method for\nparameter estimation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 13:49:02 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2016 15:29:43 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Bolin", "David", ""], ["Wallin", "Jonas", ""]]}, {"id": "1506.03736", "submitter": "Joseph  Salmon", "authors": "Eugene Ndiaye, Olivier Fercoq, Alexandre Gramfort, Joseph Salmon", "title": "GAP Safe screening rules for sparse multi-task and multi-class models", "comments": "in Proceedings of the 29-th Conference on Neural Information\n  Processing Systems (NIPS), 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High dimensional regression benefits from sparsity promoting regularizations.\nScreening rules leverage the known sparsity of the solution by ignoring some\nvariables in the optimization, hence speeding up solvers. When the procedure is\nproven not to discard features wrongly the rules are said to be \\emph{safe}. In\nthis paper we derive new safe rules for generalized linear models regularized\nwith $\\ell_1$ and $\\ell_1/\\ell_2$ norms. The rules are based on duality gap\ncomputations and spherical safe regions whose diameters converge to zero. This\nallows to discard safely more variables, in particular for low regularization\nparameters. The GAP Safe rule can cope with any iterative solver and we\nillustrate its performance on coordinate descent for multi-task Lasso, binary\nand multinomial logistic regression, demonstrating significant speed ups on all\ntested datasets with respect to previous safe rules.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2015 16:25:36 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 10:07:20 GMT"}], "update_date": "2015-11-19", "authors_parsed": [["Ndiaye", "Eugene", ""], ["Fercoq", "Olivier", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "1506.04131", "submitter": "Igor Korkin", "authors": "Igor Korkin", "title": "Two Challenges of Stealthy Hypervisors Detection: Time Cheating and Data\n  Fluctuations", "comments": "25 pages, 7 figures, 8 tables. Paper presented at the Proceedings of\n  the 10th Annual Conference on Digital Forensics, Security and Law (CDFSL),\n  33-57, Daytona Beach, Florida, USA (2015, May 18-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR stat.AP stat.CO stat.OT", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Hardware virtualization technologies play a significant role in cyber\nsecurity. On the one hand these technologies enhance security levels, by\ndesigning a trusted operating system. On the other hand these technologies can\nbe taken up into modern malware which is rather hard to detect. None of the\nexisting methods is able to efficiently detect a hypervisor in the face of\ncountermeasures such as time cheating, temporary self uninstalling, memory\nhiding etc. New hypervisor detection methods which will be described in this\npaper can detect a hypervisor under these countermeasures and even count\nseveral nested ones. These novel approaches rely on the new statistical\nanalysis of time discrepancies by examination of a set of instructions, which\nare unconditionally intercepted by a hypervisor. Reliability was achieved\nthrough the comprehensive analysis of the collected data despite its\nfluctuation. These offered methods were comprehensively assessed in both Intel\nand AMD CPUs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 19:50:33 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Korkin", "Igor", ""]]}, {"id": "1506.04137", "submitter": "Utkarsh Dang", "authors": "Utkarsh J. Dang, Ryan P. Browne, and Paul D. McNicholas", "title": "Mixtures of Multivariate Power Exponential Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An expanded family of mixtures of multivariate power exponential\ndistributions is introduced. While fitting heavy-tails and skewness has\nreceived much attention in the model-based clustering literature recently, we\ninvestigate the use of a distribution that can deal with both varying\ntail-weight and peakedness of data. A family of parsimonious models is proposed\nusing an eigen-decomposition of the scale matrix. A generalized\nexpectation-maximization algorithm is presented that combines convex\noptimization via a minorization-maximization approach and optimization based on\naccelerated line search algorithms on the Stiefel manifold. Lastly, the utility\nof this family of models is illustrated using both toy and benchmark data.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 19:59:14 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Dang", "Utkarsh J.", ""], ["Browne", "Ryan P.", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1506.04209", "submitter": "Kejun Huang", "authors": "Kejun Huang, Nicholas D. Sidiropoulos, Athanasios P. Liavas", "title": "A Flexible and Efficient Algorithmic Framework for Constrained Matrix\n  and Tensor Factorization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2016.2576427", "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general algorithmic framework for constrained matrix and tensor\nfactorization, which is widely used in signal processing and machine learning.\nThe new framework is a hybrid between alternating optimization (AO) and the\nalternating direction method of multipliers (ADMM): each matrix factor is\nupdated in turn, using ADMM, hence the name AO-ADMM. This combination can\nnaturally accommodate a great variety of constraints on the factor matrices,\nand almost all possible loss measures for the fitting. Computation caching and\nwarm start strategies are used to ensure that each update is evaluated\nefficiently, while the outer AO framework exploits recent developments in block\ncoordinate descent (BCD)-type methods which help ensure that every limit point\nis a stationary point, as well as faster and more robust convergence in\npractice. Three special cases are studied in detail: non-negative matrix/tensor\nfactorization, constrained matrix/tensor completion, and dictionary learning.\nExtensive simulations and experiments with real data are used to showcase the\neffectiveness and broad applicability of the proposed framework.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2015 01:42:05 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2015 16:24:52 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Huang", "Kejun", ""], ["Sidiropoulos", "Nicholas D.", ""], ["Liavas", "Athanasios P.", ""]]}, {"id": "1506.04493", "submitter": "Julien Bect", "authors": "H\\'elo\\\"ise Dutrieux (EDF R\\&D, L2EP), Ivana Aleksovska (L2S), Julien\n  Bect (L2S,(M\\'ethodes d'Analyse Stochastique des Codes et Traitements\n  Num\\'eriques)), Emmanuel Vazquez (L2S,(M\\'ethodes d'Analyse Stochastique des\n  Codes et Traitements Num\\'eriques)), Delille Gauthier (EDF R\\&D), Bruno\n  Fran\\c{c}ois (L2EP)", "title": "The Informational Approach to Global Optimization in presence of very\n  noisy evaluation results. Application to the optimization of renewable energy\n  integration strategies", "comments": null, "journal-ref": "47\\`emes Journ\\'ees de Statistique de la SFdS (JdS 2015), Jun\n  2015, Lille, France", "doi": null, "report-no": null, "categories": "stat.CO math.OC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of global optimization of a function f from very\nnoisy evaluations. We adopt a Bayesian sequential approach: evaluation points\nare chosen so as to reduce the uncertainty about the position of the global\noptimum of f, as measured by the entropy of the corresponding random variable\n(Informational Approach to Global Optimization, Villemonteix et al., 2009).\nWhen evaluations are very noisy, the error coming from the estimation of the\nentropy using conditional simulations becomes non negligible compared to its\nvariations on the input domain. We propose a solution to this problem by\nchoosing evaluation points as if several evaluations were going to be made at\nthese points. The method is applied to the optimization of a strategy for the\nintegration of renewable energies into an electrical distribution network.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 07:25:16 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Dutrieux", "H\u00e9lo\u00efse", "", "EDF R\\&D, L2EP"], ["Aleksovska", "Ivana", "", "L2S"], ["Bect", "Julien", "", "L2S,"], ["Vazquez", "Emmanuel", "", "L2S,"], ["Gauthier", "Delille", "", "EDF R\\&D"], ["Fran\u00e7ois", "Bruno", "", "L2EP"]]}, {"id": "1506.04778", "submitter": "Antik Chakraborty", "authors": "Anirban Bhattacharya, Antik Chakraborty, Bani K. Mallick", "title": "Fast sampling with Gaussian scale-mixture priors in high-dimensional\n  regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient way to sample from a class of structured multivariate\nGaussian distributions which routinely arise as conditional posteriors of model\nparameters that are assigned a conditionally Gaussian prior. The proposed\nalgorithm only requires matrix operations in the form of matrix multiplications\nand linear system solutions. We exhibit that the computational complexity of\nthe proposed algorithm grows linearly with the dimension unlike existing\nalgorithms relying on Cholesky factorizations with cubic orders of complexity.\nThe algorithm should be broadly applicable in settings where Gaussian scale\nmixture priors are used on high dimensional model parameters. We provide an\nillustration through posterior sampling in a high dimensional regression\nsetting with a horseshoe prior on the vector of regression coefficients.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 21:28:31 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2015 17:34:08 GMT"}, {"version": "v3", "created": "Mon, 27 Jun 2016 06:26:42 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Bhattacharya", "Anirban", ""], ["Chakraborty", "Antik", ""], ["Mallick", "Bani K.", ""]]}, {"id": "1506.05435", "submitter": "George Karabatsos Ph.D.", "authors": "George Karabatsos", "title": "A Menu-Driven Software Package of Bayesian Nonparametric (and\n  Parametric) Mixed Models for Regression Analysis and Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of applied statistics involves regression analysis of data. This paper\npresents a stand-alone and menu-driven software package, Bayesian Regression:\nNonparametric and Parametric Models. Currently, this package gives the user a\nchoice from 83 Bayesian models for data analysis. They include 47 Bayesian\nnonparametric (BNP) infinite-mixture regression models; 5 BNP infinite-mixture\nmodels for density estimation; and 31 normal random effects models (HLMs),\nincluding normal linear models. Each of the 78 regression models handles either\na continuous, binary, or ordinal dependent variable, and can handle multi-level\n(grouped) data. All 83 Bayesian models can handle the analysis of weighted\nobservations (e.g., for meta-analysis), and the analysis of left-censored,\nright-censored, and/or interval-censored data. Each BNP infinite-mixture model\nhas a mixture distribution assigned one of various BNP prior distributions,\nincluding priors defined by either the Dirichlet process, Pitman-Yor process\n(including the normalized stable process), beta (two-parameter) process,\nnormalized inverse-Gaussian process, geometric weights prior, dependent\nDirichlet process, or the dependent infinite-probits prior. The software user\ncan mouse-click to select a Bayesian model and perform data analysis via Markov\nchain Monte Carlo (MCMC) sampling. After the sampling completes, the software\nautomatically opens text output that reports MCMC-based estimates of the\nmodel's posterior distribution and model predictive fit to the data. Additional\ntext and/or graphical output can be generated by mouse-clicking other menu\noptions. This includes output of MCMC convergence analyses, and estimates of\nthe model's posterior predictive distribution, for selected functionals and\nvalues of covariates. The software, constructed from MATLAB Compiler, is\nillustrated through the BNP regression analysis of real data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 19:18:45 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2015 01:58:40 GMT"}, {"version": "v3", "created": "Fri, 19 Jun 2015 01:37:29 GMT"}, {"version": "v4", "created": "Tue, 14 Jul 2015 19:11:34 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Karabatsos", "George", ""]]}, {"id": "1506.05555", "submitter": "Cheng Zhang", "authors": "Cheng Zhang, Babak Shahbaba and Hongkai Zhao", "title": "Hamiltonian Monte Carlo Acceleration Using Surrogate Functions with\n  Random Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For big data analysis, high computational cost for Bayesian methods often\nlimits their applications in practice. In recent years, there have been many\nattempts to improve computational efficiency of Bayesian inference. Here we\npropose an efficient and scalable computational technique for a\nstate-of-the-art Markov Chain Monte Carlo (MCMC) methods, namely, Hamiltonian\nMonte Carlo (HMC). The key idea is to explore and exploit the structure and\nregularity in parameter space for the underlying probabilistic model to\nconstruct an effective approximation of its geometric properties. To this end,\nwe build a surrogate function to approximate the target distribution using\nproperly chosen random bases and an efficient optimization process. The\nresulting method provides a flexible, scalable, and efficient sampling\nalgorithm, which converges to the correct target distribution. We show that by\nchoosing the basis functions and optimization process differently, our method\ncan be related to other approaches for the construction of surrogate functions\nsuch as generalized additive models or Gaussian process models. Experiments\nbased on simulated and real data show that our approach leads to substantially\nmore efficient sampling algorithms compared to existing state-of-the art\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 06:25:59 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 17:36:39 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2015 22:17:16 GMT"}, {"version": "v4", "created": "Wed, 4 May 2016 23:23:16 GMT"}, {"version": "v5", "created": "Mon, 17 Apr 2017 22:05:56 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Zhang", "Cheng", ""], ["Shahbaba", "Babak", ""], ["Zhao", "Hongkai", ""]]}, {"id": "1506.05741", "submitter": "Kody Law", "authors": "Yuxin Chen, David Keyes, Kody J.H. Law, and Hatem Ltaief", "title": "Accelerated dimension-independent adaptive Metropolis", "comments": null, "journal-ref": "SIAM J. Sci. Comput., 38(5), S539--S565, (2016)", "doi": "10.1137/15M1026432", "report-no": null, "categories": "stat.CO math.PR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers black-box Bayesian inference over high-dimensional\nparameter spaces. The well-known adaptive Metropolis (AM) algorithm of (Haario\netal. 2001) is extended herein to scale asymptotically uniformly with respect\nto the underlying parameter dimension for Gaussian targets, by respecting the\nvariance of the target. The resulting algorithm, referred to as the\ndimension-independent adaptive Metropolis (DIAM) algorithm, also shows improved\nperformance with respect to adaptive Metropolis on non-Gaussian targets. This\nalgorithm is further improved, and the possibility of probing high-dimensional\ntargets is enabled, via GPU-accelerated numerical libraries and periodically\nsynchronized concurrent chains (justified a posteriori). Asymptotically in\ndimension, this GPU implementation exhibits a factor of four improvement versus\na competitive CPU-based Intel MKL parallel version alone. Strong scaling to\nconcurrent chains is exhibited, through a combination of longer time per sample\nbatch (weak scaling) and yet fewer necessary samples to convergence. The\nalgorithm performance is illustrated on several Gaussian and non-Gaussian\ntarget examples, in which the dimension may be in excess of one thousand.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 16:30:55 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Chen", "Yuxin", ""], ["Keyes", "David", ""], ["Law", "Kody J. H.", ""], ["Ltaief", "Hatem", ""]]}, {"id": "1506.05860", "submitter": "Shaobo Han", "authors": "Shaobo Han, Xuejun Liao, David B. Dunson, Lawrence Carin", "title": "Variational Gaussian Copula Inference", "comments": "Appearing in Proceedings of the 19th International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2016, Cadiz, Spain. JMLR:\n  W&CP volume 51", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We utilize copulas to constitute a unified framework for constructing and\noptimizing variational proposals in hierarchical Bayesian models. For models\nwith continuous and non-Gaussian hidden variables, we propose a semiparametric\nand automated variational Gaussian copula approach, in which the parametric\nGaussian copula family is able to preserve multivariate posterior dependence,\nand the nonparametric transformations based on Bernstein polynomials provide\nample flexibility in characterizing the univariate marginal posteriors.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 01:49:46 GMT"}, {"version": "v2", "created": "Wed, 16 Mar 2016 01:26:51 GMT"}, {"version": "v3", "created": "Wed, 18 May 2016 15:16:28 GMT"}], "update_date": "2016-05-19", "authors_parsed": [["Han", "Shaobo", ""], ["Liao", "Xuejun", ""], ["Dunson", "David B.", ""], ["Carin", "Lawrence", ""]]}, {"id": "1506.05934", "submitter": "Thibaut Lienart", "authors": "Thibaut Lienart, Yee Whye Teh and Arnaud Doucet", "title": "Expectation Particle Belief Propagation", "comments": "submitted to NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an original particle-based implementation of the Loopy Belief\nPropagation (LPB) algorithm for pairwise Markov Random Fields (MRF) on a\ncontinuous state space. The algorithm constructs adaptively efficient proposal\ndistributions approximating the local beliefs at each note of the MRF. This is\nachieved by considering proposal distributions in the exponential family whose\nparameters are updated iterately in an Expectation Propagation (EP) framework.\nThe proposed particle scheme provides consistent estimation of the LBP\nmarginals as the number of particles increases. We demonstrate that it provides\nmore accurate results than the Particle Belief Propagation (PBP) algorithm of\nIhler and McAllester (2009) at a fraction of the computational cost and is\nadditionally more robust empirically. The computational complexity of our\nalgorithm at each iteration is quadratic in the number of particles. We also\npropose an accelerated implementation with sub-quadratic computational\ncomplexity which still provides consistent estimates of the loopy BP marginal\ndistributions and performs almost as well as the original procedure.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 09:34:21 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Lienart", "Thibaut", ""], ["Teh", "Yee Whye", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1506.05936", "submitter": "Shiwei Lan", "authors": "Shiwei Lan and Babak Shahbaba", "title": "Sampling constrained probability distributions using Spherical\n  Augmentation", "comments": "41 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical models with constrained probability distributions are abundant in\nmachine learning. Some examples include regression models with norm constraints\n(e.g., Lasso), probit, many copula models, and latent Dirichlet allocation\n(LDA). Bayesian inference involving probability distributions confined to\nconstrained domains could be quite challenging for commonly used sampling\nalgorithms. In this paper, we propose a novel augmentation technique that\nhandles a wide range of constraints by mapping the constrained domain to a\nsphere in the augmented space. By moving freely on the surface of this sphere,\nsampling algorithms handle constraints implicitly and generate proposals that\nremain within boundaries when mapped back to the original space. Our proposed\nmethod, called {Spherical Augmentation}, provides a mathematically natural and\ncomputationally efficient framework for sampling from constrained probability\ndistributions. We show the advantages of our method over state-of-the-art\nsampling algorithms, such as exact Hamiltonian Monte Carlo, using several\nexamples including truncated Gaussian distributions, Bayesian Lasso, Bayesian\nbridge regression, reconstruction of quantized stationary Gaussian process, and\nLDA for topic modeling.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 09:44:53 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Lan", "Shiwei", ""], ["Shahbaba", "Babak", ""]]}, {"id": "1506.06117", "submitter": "Mathieu Gerber", "authors": "Mathieu Gerber and Nicolas Chopin", "title": "Convergence of Sequential Quasi-Monte Carlo Smoothing Algorithms", "comments": "37 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gerber and Chopin (2015) recently introduced Sequential quasi-Monte Carlo\n(SQMC) algorithms as an efficient way to perform filtering in state-space\nmodels. The basic idea is to replace random variables with low-discrepancy\npoint sets, so as to obtain faster convergence than with standard particle\nfiltering. Gerber and Chopin (2015) describe briefly several ways to extend\nSQMC to smoothing, but do not provide supporting theory for this extension. We\ndiscuss more thoroughly how smoothing may be performed within SQMC, and derive\nconvergence results for the so-obtained smoothing algorithms. We consider in\nparticular SQMC equivalents of forward smoothing and forward filtering backward\nsampling, which are the most well-known smoothing techniques. As a preliminary\nstep, we provide a generalization of the classical result of Hlawka and M\\\"uck\n(1972) on the transformation of QMC point sets into low discrepancy point sets\nwith respect to non uniform distributions. As a corollary of the latter, we\nnote that we can slightly weaken the assumptions to prove the consistency of\nSQMC.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 19:20:01 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Gerber", "Mathieu", ""], ["Chopin", "Nicolas", ""]]}, {"id": "1506.06285", "submitter": "\\'Oli Geirsson", "authors": "\\'Oli P\\'all Geirsson, Birgir Hrafnkelsson, Daniel Simpson, Helgi\n  Sigur{\\dh}arson", "title": "The MCMC split sampler: A block Gibbs sampling scheme for latent\n  Gaussian models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel computationally efficient Markov chain Monte Carlo (MCMC) scheme for\nlatent Gaussian models (LGMs) is proposed in this paper. The sampling scheme is\na two block Gibbs sampling scheme designed to exploit the model structure of\nLGMs. We refer to the proposed sampling scheme as the MCMC split sampler. The\nprinciple idea behind the MCMC split sampler is to split the latent Gaussian\nparameters into two vectors. The former vector consists of latent parameters\nwhich appear in the data density function, while the latter vector consists of\nlatent parameters which do not appear in it. The former vector is placed in the\nfirst block of the proposed sampling scheme and the latter vector is placed in\nthe second block along with any potential hyperparameters. The resulting\nconditional posterior density functions within the blocks allow the MCMC split\nsampler to handle, by design, LGMs with latent models imposed on more than just\nthe mean structure of the data density function. The MCMC split sampler is also\ndesigned to be applicable for any choice of a parametric data density function.\nMoreover, it scales well in terms of computational efficiency when the\ndimension of the latent model increase.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2015 19:25:14 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Geirsson", "\u00d3li P\u00e1ll", ""], ["Hrafnkelsson", "Birgir", ""], ["Simpson", "Daniel", ""], ["Sigur\u00f0arson", "Helgi", ""]]}, {"id": "1506.06322", "submitter": "Mohammad Jafari Jozani", "authors": "Saeid Amiri, Mohammad Jafari Jozani, Reza Modarres", "title": "Exponentially Titled Empirical Distribution Function for Ranked Set\n  Samples", "comments": "18 pages, 3 Figuers, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonparametric estimation of the distribution function (DF) of a\ncontinuous random variable based on a ranked set sampling design using the\nexponentially tilted (ET) empirical likelihood method. We propose ET estimators\nof the DF and use them to construct new resampling algorithms for unbalanced\nranked set samples. We explore the properties of the proposed algorithms. For a\nhypothesis testing problem about the underlying population mean, we show that\nthe bootstrap tests based on the ET estimators of the DF are asymptotically\nnormal and exhibit a small bias of order $O(n^{-1})$. We illustrate the methods\nand evaluate the finite sample performance of the algorithms under both perfect\nand imperfect ranking schemes using a real data set and several Monte Carlo\nsimulation studies. We compare the performance of the test statistics based on\nthe ET estimators with those based on the empirical likelihood estimators.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2015 05:11:06 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Amiri", "Saeid", ""], ["Jozani", "Mohammad Jafari", ""], ["Modarres", "Reza", ""]]}, {"id": "1506.06629", "submitter": "Willem Van Den Boom", "authors": "Willem van den Boom, Galen Reeves, David B. Dunson", "title": "Scalable Approximations of Marginal Posteriors in Variable Selection", "comments": "10 pages, 4 figures, PDFLaTeX, submitted to the Twenty-ninth Annual\n  Conference on Neural Information Processing Systems (NIPS 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many contexts, there is interest in selecting the most important variables\nfrom a very large collection, commonly referred to as support recovery or\nvariable, feature or subset selection. There is an enormous literature\nproposing a rich variety of algorithms. In scientific applications, it is of\ncrucial importance to quantify uncertainty in variable selection, providing\nmeasures of statistical significance for each variable. The overwhelming\nmajority of algorithms fail to produce such measures. This has led to a focus\nin the scientific literature on independent screening methods, which examine\neach variable in isolation, obtaining p-values measuring the significance of\nmarginal associations. Bayesian methods provide an alternative, with marginal\ninclusion probabilities used in place of p-values. Bayesian variable selection\nhas advantages, but is impractical computationally beyond small problems. In\nthis article, we show that approximate message passing (AMP) and Bayesian\ncompressed regression (BCR) can be used to rapidly obtain accurate\napproximations to marginal inclusion probabilities in high-dimensional variable\nselection. Theoretical support is provided, simulation studies are conducted to\nassess performance, and the method is applied to a study relating brain\nnetworks to creative reasoning.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 14:37:07 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Boom", "Willem van den", ""], ["Reeves", "Galen", ""], ["Dunson", "David B.", ""]]}, {"id": "1506.06722", "submitter": "Masaaki Imaizumi", "authors": "Masaaki Imaizumi", "title": "Approximation method for discrete Markov decision models with a large\n  state space", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve discrete Markov decision models with a large number of dimensions is\nalways difficult (and at times, impossible), because size of state space and\ncomputation cost increases exponentially with the number of dimensions. This\nphenomenon is called \"The Curse of Dimensionality,\" and it prevents us from\nusing models with many state variables. To overcome this problem, we propose a\nnew approximation method, named statistical least square temporal difference\n(SLSTD) method, that can solve discrete Markov decision models with large state\nspace. SLSTD method approximate the value function on the whole state space at\nonce, and obtain optimal approximation weight by minimizing temporal residuals\nof the Bellman equation. Furthermore, a stochastic approximation method enables\nus to optimize the problem with low computational cost. SLSTD method can solve\nDMD models with large state space more easily than other existing methods, and\nin some cases, reduces the computation time by over 99 percent. We also show\nthe parameter estimated by SLSTD is consistent and asymptotically normally\ndistributed.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 19:18:47 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 17:57:45 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Imaizumi", "Masaaki", ""]]}, {"id": "1506.06975", "submitter": "Johan Dahlin", "authors": "Johan Dahlin, Mattias Villani and Thomas B. Sch\\\"on", "title": "Bayesian optimisation for fast approximate inference in state-space\n  models with intractable likelihoods", "comments": "24 pages, 7 figures. Submitted to journal for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-fin.RM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of approximate Bayesian parameter inference in\nnon-linear state-space models with intractable likelihoods. Sequential Monte\nCarlo with approximate Bayesian computations (SMC-ABC) is one approach to\napproximate the likelihood in this type of models. However, such approximations\ncan be noisy and computationally costly which hinders efficient implementations\nusing standard methods based on optimisation and Monte Carlo methods. We\npropose a computationally efficient novel method based on the combination of\nGaussian process optimisation and SMC-ABC to create a Laplace approximation of\nthe intractable posterior. We exemplify the proposed algorithm for inference in\nstochastic volatility models with both synthetic and real-world data as well as\nfor estimating the Value-at-Risk for two portfolios using a copula model. We\ndocument speed-ups of between one and two orders of magnitude compared to\nstate-of-the-art algorithms for posterior inference.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 13:04:03 GMT"}, {"version": "v2", "created": "Tue, 20 Dec 2016 07:54:19 GMT"}, {"version": "v3", "created": "Tue, 13 Jun 2017 13:20:12 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Dahlin", "Johan", ""], ["Villani", "Mattias", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1506.06998", "submitter": "Paul Jenkins", "authors": "Paul A. Jenkins and Dario Spano", "title": "Exact simulation of the Wright-Fisher diffusion", "comments": "36 pages, 2 figure, 2 tables. This version corrects an error in the\n  proof of Lemma 6.1", "journal-ref": "Annals of Applied Probability 27(3):1478-1509 (2017)", "doi": "10.1214/16-AAP1236", "report-no": "CRiSM Working Paper 14-27", "categories": "stat.ME math.PR q-bio.PE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wright-Fisher family of diffusion processes is a widely used class of\nevolutionary models. However, simulation is difficult because there is no known\nclosed-form formula for its transition function. In this article we demonstrate\nthat it is in fact possible to simulate exactly from a broad class of\nWright-Fisher diffusion processes and their bridges. For those diffusions\ncorresponding to reversible, neutral evolution, our key idea is to exploit an\neigenfunction expansion of the transition function; this approach even applies\nto its infinite-dimensional analogue, the Fleming-Viot process. We then develop\nan exact rejection algorithm for processes with more general drift functions,\nincluding those modelling natural selection, using ideas from retrospective\nsimulation. Our approach also yields methods for exact simulation of the moment\ndual of the Wright-Fisher diffusion, the ancestral process of an infinite-leaf\nKingman coalescent tree. We believe our new perspective on diffusion simulation\nholds promise for other models admitting a transition eigenfunction expansion.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 13:47:42 GMT"}, {"version": "v2", "created": "Fri, 22 Jul 2016 15:04:56 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 13:32:15 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Jenkins", "Paul A.", ""], ["Spano", "Dario", ""]]}, {"id": "1506.07044", "submitter": "Mehdi Molkaraie", "authors": "Mehdi Molkaraie, Vicenc Gomez", "title": "Monte Carlo Methods for the Ferromagnetic Potts Model Using Factor Graph\n  Duality", "comments": null, "journal-ref": "IEEE Trans. on Information Theory, Volume 64, Dec. 2018, pp.\n  7449-7464", "doi": null, "report-no": null, "categories": "stat.CO physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normal factor graph duality offers new possibilities for Monte Carlo\nalgorithms in graphical models. Specifically, we consider the problem of\nestimating the partition function of the ferromagnetic Ising and Potts models\nby Monte Carlo methods, which are known to work well at high temperatures, but\nto fail at low temperatures. We propose Monte Carlo methods (uniform sampling\nand importance sampling) in the dual normal factor graph, and demonstrate that\nthey behave differently: they work particularly well at low temperatures. By\ncomparing the relative error in estimating the partition function, we show that\nthe proposed importance sampling algorithm significantly outperforms the\nstate-of-the-art deterministic and Monte Carlo methods. For the ferromagnetic\nIsing model in an external field, we show the equivalence between the valid\nconfigurations in the dual normal factor graph and the terms that appear in the\nhigh-temperature series expansion of the partition function. Following this\nresult, we discuss connections with Jerrum-Sinclair's polynomial randomized\napproximation scheme (the subgraphs-world process) for evaluating the partition\nfunction of ferromagnetic\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 15:12:11 GMT"}, {"version": "v2", "created": "Mon, 20 Jul 2015 10:53:10 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2015 13:57:16 GMT"}, {"version": "v4", "created": "Fri, 23 Nov 2018 01:22:35 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Molkaraie", "Mehdi", ""], ["Gomez", "Vicenc", ""]]}, {"id": "1506.07564", "submitter": "Bruno Sudret", "authors": "Joseph B. Nagel and Bruno Sudret", "title": "Spectral likelihood expansions for Bayesian inference", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2015.12.047", "report-no": "RSUQ-2015-004", "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A spectral approach to Bayesian inference is presented. It pursues the\nemulation of the posterior probability density. The starting point is a series\nexpansion of the likelihood function in terms of orthogonal polynomials. From\nthis spectral likelihood expansion all statistical quantities of interest can\nbe calculated semi-analytically. The posterior is formally represented as the\nproduct of a reference density and a linear combination of polynomial basis\nfunctions. Both the model evidence and the posterior moments are related to the\nexpansion coefficients. This formulation avoids Markov chain Monte Carlo\nsimulation and allows one to make use of linear least squares instead. The pros\nand cons of spectral Bayesian inference are discussed and demonstrated on the\nbasis of simple applications from classical statistics and inverse modeling.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 21:11:48 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 09:03:00 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Nagel", "Joseph B.", ""], ["Sudret", "Bruno", ""]]}, {"id": "1506.07925", "submitter": "Alexander Volfovsky", "authors": "Daniel L. Sussman, Alexander Volfovsky, Edoardo M. Airoldi", "title": "Analyzing statistical and computational tradeoffs of estimation\n  procedures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent explosion in the amount and dimensionality of data has exacerbated\nthe need of trading off computational and statistical efficiency carefully, so\nthat inference is both tractable and meaningful. We propose a framework that\nprovides an explicit opportunity for practitioners to specify how much\nstatistical risk they are willing to accept for a given computational cost, and\nleads to a theoretical risk-computation frontier for any given inference\nproblem. We illustrate the tradeoff between risk and computation and illustrate\nthe frontier in three distinct settings. First, we derive analytic forms for\nthe risk of estimating parameters in the classical setting of estimating the\nmean and variance for normally distributed data and for the more general\nsetting of parameters of an exponential family. The second example concentrates\non computationally constrained Hodges-Lehmann estimators. We conclude with an\nevaluation of risk associated with early termination of iterative matrix\ninversion algorithms in the context of linear regression.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 23:57:34 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Sussman", "Daniel L.", ""], ["Volfovsky", "Alexander", ""], ["Airoldi", "Edoardo M.", ""]]}, {"id": "1506.08010", "submitter": "Alfredo Garbuno-Inigo", "authors": "A. Garbuno-Inigo, F.A. DiazDelaO, K.M. Zuev", "title": "Gaussian process hyper-parameter estimation using parallel\n  asymptotically independent Markov sampling", "comments": "Computational Statistics \\& Data Analysis, Volume 103, November 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process emulators of computationally expensive computer codes\nprovide fast statistical approximations to model physical processes. The\ntraining of these surrogates depends on the set of design points chosen to run\nthe simulator. Due to computational cost, such training set is bound to be\nlimited and quantifying the resulting uncertainty in the hyper-parameters of\nthe emulator by uni-modal distributions is likely to induce bias. In order to\nquantify this uncertainty, this paper proposes a computationally efficient\nsampler based on an extension of Asymptotically Independent Markov Sampling, a\nrecently developed algorithm for Bayesian inference. Structural uncertainty of\nthe emulator is obtained as a by-product of the Bayesian treatment of the\nhyper-parameters. Additionally, the user can choose to perform stochastic\noptimisation to sample from a neighbourhood of the Maximum a Posteriori\nestimate, even in the presence of multimodality. Model uncertainty is also\nacknowledged through numerical stabilisation measures by including a nugget\nterm in the formulation of the probability model. The efficiency of the\nproposed sampler is illustrated in examples where multi-modal distributions are\nencountered. For the purpose of reproducibility, further development, and use\nin other applications the code used to generate the examples is freely\navailable for download at https://github.com/agarbuno/paims_codes\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 09:46:04 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2015 08:58:26 GMT"}, {"version": "v3", "created": "Thu, 31 Mar 2016 14:15:28 GMT"}, {"version": "v4", "created": "Mon, 15 Aug 2016 10:18:09 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Garbuno-Inigo", "A.", ""], ["DiazDelaO", "F. A.", ""], ["Zuev", "K. M.", ""]]}, {"id": "1506.08170", "submitter": "Zhuang Ma", "authors": "Zhuang Ma, Yichao Lu, Dean Foster", "title": "Finding Linear Structure in Large Datasets with Scalable Canonical\n  Correlation Analysis", "comments": "Appearing in International Conference on Machine Learning (ICML) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canonical Correlation Analysis (CCA) is a widely used spectral technique for\nfinding correlation structures in multi-view datasets. In this paper, we tackle\nthe problem of large scale CCA, where classical algorithms, usually requiring\ncomputing the product of two huge matrices and huge matrix decomposition, are\ncomputationally and storage expensive. We recast CCA from a novel perspective\nand propose a scalable and memory efficient Augmented Approximate Gradient\n(AppGrad) scheme for finding top $k$ dimensional canonical subspace which only\ninvolves large matrix multiplying a thin matrix of width $k$ and small matrix\ndecomposition of dimension $k\\times k$. Further, AppGrad achieves optimal\nstorage complexity $O(k(p_1+p_2))$, compared with classical algorithms which\nusually require $O(p_1^2+p_2^2)$ space to store two dense whitening matrices.\nThe proposed scheme naturally generalizes to stochastic optimization regime,\nespecially efficient for huge datasets where batch algorithms are prohibitive.\nThe online property of stochastic AppGrad is also well suited to the streaming\nscenario, where data comes sequentially. To the best of our knowledge, it is\nthe first stochastic algorithm for CCA. Experiments on four real data sets are\nprovided to show the effectiveness of the proposed methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 17:51:57 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Ma", "Zhuang", ""], ["Lu", "Yichao", ""], ["Foster", "Dean", ""]]}, {"id": "1506.08180", "submitter": "Amar Shah", "authors": "Amar Shah and David A. Knowles and Zoubin Ghahramani", "title": "An Empirical Study of Stochastic Variational Algorithms for the Beta\n  Bernoulli Process", "comments": "ICML, 12 pages. Volume 37: Proceedings of The 32nd International\n  Conference on Machine Learning, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference (SVI) is emerging as the most promising\ncandidate for scaling inference in Bayesian probabilistic models to large\ndatasets. However, the performance of these methods has been assessed primarily\nin the context of Bayesian topic models, particularly latent Dirichlet\nallocation (LDA). Deriving several new algorithms, and using synthetic, image\nand genomic datasets, we investigate whether the understanding gleaned from LDA\napplies in the setting of sparse latent factor models, specifically beta\nprocess factor analysis (BPFA). We demonstrate that the big picture is\nconsistent: using Gibbs sampling within SVI to maintain certain posterior\ndependencies is extremely effective. However, we find that different posterior\ndependencies are important in BPFA relative to LDA. Particularly,\napproximations able to model intra-local variable dependence perform best.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 18:55:11 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Shah", "Amar", ""], ["Knowles", "David A.", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1506.08237", "submitter": "Peter Hoff", "authors": "Peter D. Hoff", "title": "Dyadic data analysis with amen", "comments": "This is a vignette for the R package \"amen\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dyadic data on pairs of objects, such as relational or social network data,\noften exhibit strong statistical dependencies. Certain types of second-order\ndependencies, such as degree heterogeneity and reciprocity, can be\nwell-represented with additive random effects models. Higher-order\ndependencies, such as transitivity and stochastic equivalence, can often be\nrepresented with multiplicative effects. The \"amen\" package for the R\nstatistical computing environment provides estimation and inference for a class\nof additive and multiplicative random effects models for ordinal, continuous,\nbinary and other types of dyadic data. The package also provides methods for\nmissing, censored and fixed-rank nomination data, as well as longitudinal\ndyadic data. This tutorial illustrates the \"amen\" package via example\nstatistical analyses of several of these different data types.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 23:48:01 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Hoff", "Peter D.", ""]]}, {"id": "1506.08640", "submitter": "James Ridgway", "authors": "Nicolas Chopin and James Ridgway", "title": "Leave Pima Indians alone: binary regression as a benchmark for Bayesian\n  computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract. Whenever a new approach to perform Bayesian computation is\nintroduced, a common practice is to showcase this approach on a binary\nregression model and datasets of moderate size. This paper discusses to which\nextent this practice is sound. It also reviews the current state of the art of\nBayesian computation, using binary regression as a running example. Both\nsampling-based algorithms (importance sampling, MCMC and SMC) and fast\napproximations (Laplace and EP) are covered. Extensive numerical results are\nprovided, some of which might go against conventional wisdom regarding the\neffectiveness of certain algorithms. Implications for other problems (variable\nselection) and other models are also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 14:14:38 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Chopin", "Nicolas", ""], ["Ridgway", "James", ""]]}, {"id": "1506.08852", "submitter": "Espen Bernton", "authors": "Espen Bernton, Shihao Yang, Yang Chen, Neil Shephard, Jun S. Liu", "title": "Locally weighted Markov chain Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a weighting scheme for the proposals within Markov chain Monte\nCarlo algorithms and show how this can improve statistical efficiency at no\nextra computational cost. These methods are most powerful when combined with\nmulti-proposal MCMC algorithms such as multiple-try Metropolis, which can\nefficiently exploit modern computer architectures with large numbers of cores.\nThe locally weighted Markov chain Monte Carlo method also improves upon a\npartial parallelization of the Metropolis-Hastings algorithm via\nRao-Blackwellization. We derive the effective sample size of the output of our\nalgorithm and show how to estimate this in practice. Illustrations and examples\nof the method are given and the algorithm is compared in theory and\napplications with existing methods.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 20:28:05 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Bernton", "Espen", ""], ["Yang", "Shihao", ""], ["Chen", "Yang", ""], ["Shephard", "Neil", ""], ["Liu", "Jun S.", ""]]}, {"id": "1506.09035", "submitter": "Niamh Russell", "authors": "Niamh Russell and Thomas Brendan Murphy and Adrian E Raftery", "title": "Bayesian model averaging in model-based clustering and density\n  estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Bayesian model averaging (BMA) as a method for postprocessing the\nresults of model-based clustering. Given a number of competing models,\nappropriate model summaries are averaged, using the posterior model\nprobabilities, instead of being taken from a single \"best\" model. We\ndemonstrate the use of BMA in model-based clustering for a number of datasets.\nWe show that BMA provides a useful summary of the clustering of observations\nwhile taking model uncertainty into account. Further, we show that BMA in\nconjunction with model-based clustering gives a competitive method for density\nestimation in a multivariate setting. Applying BMA in the model-based context\nis fast and can give enhanced modeling performance.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 11:17:40 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Russell", "Niamh", ""], ["Murphy", "Thomas Brendan", ""], ["Raftery", "Adrian E", ""]]}]