[{"id": "0806.0129", "submitter": "Elvira Di Nardo Ph.D.", "authors": "E. Di Nardo, G. Guarino, D. Senato", "title": "Symbolic computation of moments of sampling distributions", "comments": "21 pages, 7 tables", "journal-ref": "Computational Statistics and Data Analysis (2008)", "doi": null, "report-no": null, "categories": "stat.CO math.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By means of the notion of umbrae indexed by multisets, a general method to\nexpress estimators and their products in terms of power sums is derived. A\nconnection between the notion of multiset and integer partition leads\nimmediately to a way to speed up the procedures. Comparisons of computational\ntimes with known procedures show how this approach turns out to be more\nefficient in eliminating much unnecessary computation.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jun 2008 07:33:27 GMT"}], "update_date": "2008-06-03", "authors_parsed": [["Di Nardo", "E.", ""], ["Guarino", "G.", ""], ["Senato", "D.", ""]]}, {"id": "0806.0539", "submitter": "Jan Christoph Neddermeyer", "authors": "Jan C. Neddermeyer", "title": "Nonparametric Partial Importance Sampling for Financial Derivative\n  Pricing", "comments": "26 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance sampling is a promising variance reduction technique for Monte\nCarlo simulation based derivative pricing. Existing importance sampling methods\nare based on a parametric choice of the proposal. This article proposes an\nalgorithm that estimates the optimal proposal nonparametrically using a\nmultivariate frequency polygon estimator. In contrast to parametric methods,\nnonparametric estimation allows for close approximation of the optimal\nproposal. Standard nonparametric importance sampling is inefficient for\nhigh-dimensional problems. We solve this issue by applying the procedure to a\nlow-dimensional subspace, which is identified through principal component\nanalysis and the concept of the effective dimension. The mean square error\nproperties of the algorithm are investigated and its asymptotic optimality is\nshown. Quasi-Monte Carlo is used for further improvement of the method. It is\neasy to implement, particularly it does not require any analytical computation,\nand it is computationally very efficient. We demonstrate through path-dependent\nand multi-asset option pricing problems that the algorithm leads to significant\nefficiency gains compared to other algorithms in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jun 2008 13:39:45 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2009 08:57:26 GMT"}], "update_date": "2009-04-14", "authors_parsed": [["Neddermeyer", "Jan C.", ""]]}, {"id": "0806.2424", "submitter": "Kostas Alexandridis", "authors": "Kostas Alexandridis, Bryan C. Pijanowski", "title": "Developing Bayesian Information Entropy-based Techniques for Spatially\n  Explicit Model Assessment", "comments": "13 pages, 10 figures, 3 tables, 25 equations Submitted to IEEE Trans\n  Inf Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to explore and develop advanced spatial Bayesian\nassessment methods and techniques for land use modeling. The paper provides a\ncomprehensive guide for assessing additional informational entropy value of\nmodel predictions at the spatially explicit domain of knowledge, and proposes a\nfew alternative metrics and indicators for extracting higher-order information\ndynamics from simulation tournaments. A seven-county study area in\nSouth-Eastern Wisconsin (SEWI) has been used to simulate and assess the\naccuracy of historical land use changes (1963-1990) using artificial neural\nnetwork simulations of the Land Transformation Model (LTM). The use of the\nanalysis and the performance of the metrics helps: (a) understand and learn how\nwell the model runs fits to different combinations of presence and absence of\ntransitions in a landscape, not simply how well the model fits our given data;\n(b) derive (estimate) a theoretical accuracy that we would expect a model to\nassess under the presence of incomplete information and measurement; (c)\nunderstand the spatially explicit role and patterns of uncertainty in\nsimulations and model estimations, by comparing results across simulation runs;\n(d) compare the significance or estimation contribution of transitional\npresence and absence (change versus no change) to model performance, and the\ncontribution of the spatial drivers and variables to the explanatory value of\nour model; and (e) compare measurements of informational uncertainty at\ndifferent scales of spatial resolution.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jun 2008 07:38:03 GMT"}], "update_date": "2008-06-17", "authors_parsed": [["Alexandridis", "Kostas", ""], ["Pijanowski", "Bryan C.", ""]]}, {"id": "0806.3301", "submitter": "Ryan Tibshirani", "authors": "Ryan J. Tibshirani", "title": "Fast computation of the median by successive binning", "comments": "14 pages, 1 Postscript figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DS stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new median algorithm and a median approximation\nalgorithm. The former has O(n) average running time and the latter has O(n)\nworst-case running time. These algorithms are highly competitive with the\nstandard algorithm when computing the median of a single data set, but are\nsignificantly faster in updating the median when more data is added.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2008 00:44:53 GMT"}, {"version": "v2", "created": "Tue, 12 May 2009 04:46:56 GMT"}], "update_date": "2009-05-12", "authors_parsed": [["Tibshirani", "Ryan J.", ""]]}, {"id": "0806.3474", "submitter": "Torsten Ensslin", "authors": "Torsten A. Ensslin, Mona Frommert, Francisco S. Kitaura", "title": "Information field theory for cosmological perturbation reconstruction\n  and non-linear signal analysis", "comments": "38 pages, 6 figures, LaTeX; version accepted by PRD", "journal-ref": null, "doi": "10.1103/PhysRevD.80.105005", "report-no": "J-MPA2270e", "categories": "astro-ph cs.IT hep-th math.IT physics.data-an stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop information field theory (IFT) as a means of Bayesian inference on\nspatially distributed signals, the information fields. A didactical approach is\nattempted. Starting from general considerations on the nature of measurements,\nsignals, noise, and their relation to a physical reality, we derive the\ninformation Hamiltonian, the source field, propagator, and interaction terms.\nFree IFT reproduces the well known Wiener-filter theory. Interacting IFT can be\ndiagrammatically expanded, for which we provide the Feynman rules in position-,\nFourier-, and spherical harmonics space, and the Boltzmann-Shannon information\nmeasure. The theory should be applicable in many fields. However, here, two\ncosmological signal recovery problems are discussed in their IFT-formulation.\n1) Reconstruction of the cosmic large-scale structure matter distribution from\ndiscrete galaxy counts in incomplete galaxy surveys within a simple model of\ngalaxy formation. We show that a Gaussian signal, which should resemble the\ninitial density perturbations of the Universe, observed with a strongly\nnon-linear, incomplete and Poissonian-noise affected response, as the processes\nof structure and galaxy formation and observations provide, can be\nreconstructed thanks to the virtue of a response-renormalization flow equation.\n2) We design a filter to detect local non-linearities in the cosmic microwave\nbackground, which are predicted from some Early-Universe inflationary\nscenarios, and expected due to measurement imperfections. This filter is the\noptimal Bayes' estimator up to linear order in the non-linearity parameter and\ncan be used even to construct sky maps of non-linearities in the data.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jun 2008 21:24:25 GMT"}, {"version": "v2", "created": "Wed, 6 May 2009 18:30:53 GMT"}, {"version": "v3", "created": "Tue, 29 Sep 2009 07:57:21 GMT"}], "update_date": "2013-05-29", "authors_parsed": [["Ensslin", "Torsten A.", ""], ["Frommert", "Mona", ""], ["Kitaura", "Francisco S.", ""]]}]