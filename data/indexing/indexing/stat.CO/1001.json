[{"id": "1001.0175", "submitter": "Iain Murray", "authors": "Iain Murray, Ryan Prescott Adams, David J.C. MacKay", "title": "Elliptical slice sampling", "comments": "8 pages, 6 figures, appearing in AISTATS 2010 (JMLR: W&CP volume 6).\n  Differences from first submission: some minor edits in response to feedback.", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many probabilistic models introduce strong dependencies between variables\nusing a latent multivariate Gaussian distribution or a Gaussian process. We\npresent a new Markov chain Monte Carlo algorithm for performing inference in\nmodels with multivariate Gaussian priors. Its key properties are: 1) it has\nsimple, generic code applicable to many models, 2) it has no free parameters,\n3) it works well for a variety of Gaussian process based models. These\nproperties make our method ideal for use while model building, removing the\nneed to spend time deriving and tuning updates for more complex algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2009 19:41:31 GMT"}, {"version": "v2", "created": "Fri, 19 Mar 2010 13:05:31 GMT"}], "update_date": "2010-03-22", "authors_parsed": [["Murray", "Iain", ""], ["Adams", "Ryan Prescott", ""], ["MacKay", "David J. C.", ""]]}, {"id": "1001.1049", "submitter": "Bertrand Iooss", "authors": "Bertrand Iooss (M\\'ethodes d'Analyse Stochastique des Codes et\n  Traitements Num\\'eriques), Lo\\\"ic Boussouf, Vincent Feuillard, Amandine\n  Marrel (IFP)", "title": "Numerical studies of the metamodel fitting and validation processes", "comments": null, "journal-ref": "International Journal of Advances in Systems and Measurements 3\n  (2010) 11-21", "doi": null, "report-no": null, "categories": "math.NA math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex computer codes, for instance simulating physical phenomena, are often\ntoo time expensive to be directly used to perform uncertainty, sensitivity,\noptimization and robustness analyses. A widely accepted method to circumvent\nthis problem consists in replacing cpu time expensive computer models by cpu\ninexpensive mathematical functions, called metamodels. In this paper, we focus\non the Gaussian process metamodel and two essential steps of its definition\nphase. First, the initial design of the computer code input variables (which\nallows to fit the metamodel) has to honor adequate space filling properties. We\nadopt a numerical approach to compare the performance of different types of\nspace filling designs, in the class of the optimal Latin hypercube samples, in\nterms of the predictivity of the subsequent fitted metamodel. We conclude that\nsuch samples with minimal wrap-around discrepancy are particularly well-suited\nfor the Gaussian process metamodel fitting. Second, the metamodel validation\nprocess consists in evaluating the metamodel predictivity with respect to the\ninitial computer code. We propose and test an algorithm which optimizes the\ndistance between the validation points and the metamodel learning points in\norder to estimate the true metamodel predictivity with a minimum number of\nvalidation points. Comparisons with classical validation algorithms and\napplication to a nuclear safety computer code show the relevance of this new\nsequential validation design.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2010 10:43:51 GMT"}, {"version": "v2", "created": "Thu, 23 Sep 2010 11:51:41 GMT"}], "update_date": "2011-04-22", "authors_parsed": [["Iooss", "Bertrand", "", "M\u00e9thodes d'Analyse Stochastique des Codes et\n  Traitements Num\u00e9riques"], ["Boussouf", "Lo\u00efc", "", "IFP"], ["Feuillard", "Vincent", "", "IFP"], ["Marrel", "Amandine", "", "IFP"]]}, {"id": "1001.1297", "submitter": "Karel Klouda", "authors": "Karel Klouda", "title": "BSA - exact algorithm computing LTS estimate", "comments": "18 pages, 1 figure", "journal-ref": "Computational Statistics & Data Analysis, 84 (2015), 27-40", "doi": "10.1016/j.csda.2014.11.001", "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main result of this paper is a new exact algorithm computing the estimate\ngiven by the Least Trimmed Squares (LTS). The algorithm works under very weak\nassumptions. To prove that, we study the respective objective function using\nbasic techniques of analysis and linear algebra.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2010 15:05:01 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Klouda", "Karel", ""]]}, {"id": "1001.2136", "submitter": "Serena Arima", "authors": "Serena Arima and Luca Tardella", "title": "An alternative marginal likelihood estimator for phylogenetic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-bio.QM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian phylogenetic methods are generating noticeable enthusiasm in the\nfield of molecular systematics. Many phylogenetic models are often at stake and\ndifferent approaches are used to compare them within a Bayesian framework. The\nBayes factor, defined as the ratio of the marginal likelihoods of two competing\nmodels, plays a key role in Bayesian model selection. We focus on an\nalternative estimator of the marginal likelihood whose computation is still a\nchallenging problem. Several computational solutions have been proposed none of\nwhich can be considered outperforming the others simultaneously in terms of\nsimplicity of implementation, computational burden and precision of the\nestimates. Practitioners and researchers, often led by available software, have\nprivileged so far the simplicity of the harmonic mean estimator (HM) and the\narithmetic mean estimator (AM). However it is known that the resulting\nestimates of the Bayesian evidence in favor of one model are biased and often\ninaccurate up to having an infinite variance so that the reliability of the\ncorresponding conclusions is doubtful. Our new implementation of the\ngeneralized harmonic mean (GHM) idea recycles MCMC simulations from the\nposterior, shares the computational simplicity of the original HM estimator,\nbut, unlike it, overcomes the infinite variance issue. The alternative\nestimator is applied to simulated phylogenetic data and produces fully\nsatisfactory results outperforming those simple estimators currently provided\nby most of the publicly available software.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 12:06:44 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2010 13:18:50 GMT"}], "update_date": "2010-06-22", "authors_parsed": [["Arima", "Serena", ""], ["Tardella", "Luca", ""]]}, {"id": "1001.2166", "submitter": "Mehrdad Ghaemi", "authors": "Mehrdad Ghaemi, Zahra Zabihinpour, Yazdan Asgari", "title": "Computer Simulation Study of the Levy Flight Process", "comments": "14 pages, 7 figures", "journal-ref": "Physica A 388 (2009) 1509-1514", "doi": "10.1016/j.physa.2008.12.071", "report-no": null, "categories": "nlin.CD cond-mat.stat-mech stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walk simulation of the Levy flight shows a linear relation between the\nmean square displacement <r2> and time. We have analyzed different aspects of\nthis linearity. It is shown that the restriction of jump length to a maximum\nvalue (lm) affects the diffusion coefficient, even though it remains constant\nfor lm greater than 1464. So, this factor has no effect on the linearity. In\naddition, it is shown that the number of samples does not affect the results.\nWe have demonstrated that the relation between the mean square displacement and\ntime remains linear in a continuous space, while continuous variables just\nreduce the diffusion coefficient. The results are also implied that the\nmovement of a levy flight particle is similar to the case the particle moves in\neach time step with an average length of jumping <l>. Finally, it is shown that\nthe non-linear relation of the Levy flight will be satisfied if we use time\naverage instead of ensemble average. The difference between time average and\nensemble average results points that the Levy distribution may be a non-ergodic\ndistribution.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 13:57:00 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Ghaemi", "Mehrdad", ""], ["Zabihinpour", "Zahra", ""], ["Asgari", "Yazdan", ""]]}, {"id": "1001.2797", "submitter": "Krzysztof Latuszynski", "authors": "Krzysztof Latuszynski and Jeffrey S. Rosenthal", "title": "Adaptive Gibbs samplers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider various versions of adaptive Gibbs and Metropolis within-Gibbs\nsamplers, which update their selection probabilities (and perhaps also their\nproposal distributions) on the fly during a run, by learning as they go in an\nattempt to optimise the algorithm. We present a cautionary example of how even\na simple-seeming adaptive Gibbs sampler may fail to converge. We then present\nvarious positive results guaranteeing convergence of adaptive Gibbs samplers\nunder certain conditions.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2010 00:55:16 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Latuszynski", "Krzysztof", ""], ["Rosenthal", "Jeffrey S.", ""]]}, {"id": "1001.2906", "submitter": "Christian P. Robert", "authors": "Christian P. Robert and George Casella", "title": "Introducing Monte Carlo Methods with R Solutions to Odd-Numbered\n  Exercises", "comments": "87 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the solution manual to the odd-numbered exercises in our book\n\"Introducing Monte Carlo Methods with R\", published by Springer Verlag on\nDecember 10, 2009, and made freely available to everyone.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2010 17:43:52 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Robert", "Christian P.", ""], ["Casella", "George", ""]]}, {"id": "1001.3355", "submitter": "Charles Sutton", "authors": "Charles Sutton, Michael I. Jordan", "title": "Bayesian inference for queueing networks and modeling of internet\n  services", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS392 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 1, 254-282", "doi": "10.1214/10-AOAS392", "report-no": "IMS-AOAS-AOAS392", "categories": "stat.ML cs.NI cs.PF stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern Internet services, such as those at Google, Yahoo!, and Amazon, handle\nbillions of requests per day on clusters of thousands of computers. Because\nthese services operate under strict performance requirements, a statistical\nunderstanding of their performance is of great practical interest. Such\nservices are modeled by networks of queues, where each queue models one of the\ncomputers in the system. A key challenge is that the data are incomplete,\nbecause recording detailed information about every request to a heavily used\nsystem can require unacceptable overhead. In this paper we develop a Bayesian\nperspective on queueing models in which the arrival and departure times that\nare not observed are treated as latent variables. Underlying this viewpoint is\nthe observation that a queueing model defines a deterministic transformation\nbetween the data and a set of independent variables called the service times.\nWith this viewpoint in hand, we sample from the posterior distribution over\nmissing data and model parameters using Markov chain Monte Carlo. We evaluate\nour framework on data from a benchmark Web application. We also present a\nsimple technique for selection among nested queueing models. We are unaware of\nany previous work that considers inference in networks of queues in the\npresence of missing data.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 16:27:13 GMT"}, {"version": "v2", "created": "Wed, 4 Aug 2010 15:34:17 GMT"}, {"version": "v3", "created": "Fri, 15 Apr 2011 06:03:52 GMT"}], "update_date": "2011-04-18", "authors_parsed": [["Sutton", "Charles", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1001.3859", "submitter": "Yaming Yu", "authors": "Yaming Yu", "title": "Strict Monotonicity and Convergence Rate of Titterington's Algorithm for\n  Computing D-optimal Designs", "comments": null, "journal-ref": "Computational Statistics and Data Analysis 54 (2010) 1419--1425.", "doi": "10.1016/j.csda.2010.01.026", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of multiplicative algorithms introduced by Silvey et al.\n(1978) for computing D-optimal designs. Strict monotonicity is established for\na variant considered by Titterington (1978). A formula for the rate of\nconvergence is also derived. This is used to explain why modifications\nconsidered by Titterington (1978) and Dette et al. (2008) usually converge\nfaster.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2010 17:58:19 GMT"}], "update_date": "2010-02-26", "authors_parsed": [["Yu", "Yaming", ""]]}, {"id": "1001.3907", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin, James V. Burke, Gianluigi Pillonetto", "title": "Robust and Trend-following Kalman Smoothers using Student's t", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose two nonlinear Kalman smoothers that rely on Student's t\ndistributions. The T-Robust smoother finds the maximum a posteriori likelihood\n(MAP) solution for Gaussian process noise and Student's t observation noise,\nand is extremely robust against outliers, outperforming the recently proposed\nl1-Laplace smoother in extreme situations (e.g. 50% or more outliers). The\nsecond estimator, which we call the T-Trend smoother, is able to follow sudden\nchanges in the process model, and is derived as a MAP solver for a model with\nStudent's t-process noise and Gaussian observation noise. We design specialized\nmethods to solve both problems which exploit the special structure of the\nStudent's t-distribution, and provide a convergence theory. Both smoothers can\nbe implemented with only minor modifications to an existing L2 smoother\nimplementation. Numerical results for linear and nonlinear models illustrating\nboth robust and fast tracking applications are presented.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2010 02:48:12 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2010 08:56:39 GMT"}, {"version": "v3", "created": "Fri, 11 Nov 2011 12:43:55 GMT"}], "update_date": "2011-11-14", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1001.4208", "submitter": "Abel Rodriguez", "authors": "Abel Rodriguez, Alex Lenkoski and Adrian Dobra", "title": "Sparse covariance estimation in heterogeneous samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard Gaussian graphical models (GGMs) implicitly assume that the\nconditional independence among variables is common to all observations in the\nsample. However, in practice, observations are usually collected form\nheterogeneous populations where such assumption is not satisfied, leading in\nturn to nonlinear relationships among variables. To tackle these problems we\nexplore mixtures of GGMs; in particular, we consider both infinite mixture\nmodels of GGMs and infinite hidden Markov models with GGM emission\ndistributions. Such models allow us to divide a heterogeneous population into\nhomogenous groups, with each cluster having its own conditional independence\nstructure. The main advantage of considering infinite mixtures is that they\nallow us easily to estimate the number of number of subpopulations in the\nsample. As an illustration, we study the trends in exchange rate fluctuations\nin the pre-Euro era. This example demonstrates that the models are very\nflexible while providing extremely interesting interesting insights into\nreal-life applications.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2010 21:49:00 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Rodriguez", "Abel", ""], ["Lenkoski", "Alex", ""], ["Dobra", "Adrian", ""]]}, {"id": "1001.4776", "submitter": "Robert Strawderman", "authors": "Elizabeth D. Schifano, Robert L. Strawderman, Martin T. Wells", "title": "MM Algorithms for Minimizing Nonsmoothly Penalized Objective Functions", "comments": "A revised version of this paper has been published in the Electronic\n  Journal of Statistics", "journal-ref": "Electronic Journal of Statistics, Volume 4 (2010), pages 1258-1299", "doi": "10.1214/10-EJS582", "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a general class of algorithms for optimizing an\nextensive variety of nonsmoothly penalized objective functions that satisfy\ncertain regularity conditions. The proposed framework utilizes the\nmajorization-minimization (MM) algorithm as its core optimization engine. The\nresulting algorithms rely on iterated soft-thresholding, implemented\ncomponentwise, allowing for fast, stable updating that avoids the need for any\nhigh-dimensional matrix inversion. We establish a local convergence theory for\nthis class of algorithms under weaker assumptions than previously considered in\nthe statistical literature. We also demonstrate the exceptional effectiveness\nof new acceleration methods, originally proposed for the EM algorithm, in this\nclass of problems. Simulation results and a microarray data example are\nprovided to demonstrate the algorithm's capabilities and versatility.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2010 20:47:20 GMT"}, {"version": "v2", "created": "Fri, 21 Jan 2011 19:05:53 GMT"}], "update_date": "2011-01-24", "authors_parsed": [["Schifano", "Elizabeth D.", ""], ["Strawderman", "Robert L.", ""], ["Wells", "Martin T.", ""]]}]