[{"id": "1806.00093", "submitter": "Yousef El-Laham", "authors": "Yousef El-Laham, Victor Elvira, Monica F. Bugallo", "title": "Robust Covariance Adaptation in Adaptive Importance Sampling", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2018.2841641", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance sampling (IS) is a Monte Carlo methodology that allows for\napproximation of a target distribution using weighted samples generated from\nanother proposal distribution. Adaptive importance sampling (AIS) implements an\niterative version of IS which adapts the parameters of the proposal\ndistribution in order to improve estimation of the target. While the adaptation\nof the location (mean) of the proposals has been largely studied, an important\nchallenge of AIS relates to the difficulty of adapting the scale parameter\n(covariance matrix). In the case of weight degeneracy, adapting the covariance\nmatrix using the empirical covariance results in a singular matrix, which leads\nto poor performance in subsequent iterations of the algorithm. In this paper,\nwe propose a novel scheme which exploits recent advances in the IS literature\nto prevent the so-called weight degeneracy. The method efficiently adapts the\ncovariance matrix of a population of proposal distributions and achieves a\nsignificant performance improvement in high-dimensional scenarios. We validate\nthe new method through computer simulations.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 20:37:40 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["El-Laham", "Yousef", ""], ["Elvira", "Victor", ""], ["Bugallo", "Monica F.", ""]]}, {"id": "1806.00225", "submitter": "Mirko Signorelli", "authors": "Mirko Signorelli, Ernst Wit", "title": "Model-based clustering for populations of networks", "comments": "The final (published) version of the article can be downloaded for\n  free (Open Access) from the editor's website (click on the DOI link below)", "journal-ref": "Statistical Modelling, 2020, 20 (1), 9-29", "doi": "10.1177/1471082X19871128", "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Until recently obtaining data on populations of networks was typically rare.\nHowever, with the advancement of automatic monitoring devices and the growing\nsocial and scientific interest in networks, such data has become more widely\navailable. From sociological experiments involving cognitive social structures\nto fMRI scans revealing large-scale brain networks of groups of patients, there\nis a growing awareness that we urgently need tools to analyse populations of\nnetworks and particularly to model the variation between networks due to\ncovariates. We propose a model-based clustering method based on mixtures of\ngeneralized linear (mixed) models that can be employed to describe the joint\ndistribution of a populations of networks in a parsimonious manner and to\nidentify subpopulations of networks that share certain topological properties\nof interest (degree distribution, community structure, effect of covariates on\nthe presence of an edge, etc.). Maximum likelihood estimation for the proposed\nmodel can be efficiently carried out with an implementation of the EM\nalgorithm. We assess the performance of this method on simulated data and\nconclude with an example application on advice networks in a small business.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2018 07:48:28 GMT"}, {"version": "v2", "created": "Tue, 5 Mar 2019 13:23:55 GMT"}, {"version": "v3", "created": "Tue, 5 Nov 2019 10:13:21 GMT"}, {"version": "v4", "created": "Mon, 20 Jan 2020 12:00:43 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Signorelli", "Mirko", ""], ["Wit", "Ernst", ""]]}, {"id": "1806.00671", "submitter": "Michael Grabchak", "authors": "Michael Grabchak", "title": "Rejection Sampling for Tempered Levy Processes", "comments": null, "journal-ref": "Statistics and Computing, volume 29, pages 549-558 (2019)", "doi": "10.1007/s11222-018-9822-6", "report-no": null, "categories": "math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the idea of tempering stable Levy processes to tempering more\ngeneral classes of Levy processes. We show that the original process can be\ndecomposed into the sum of the tempered process and an independent point\nprocess of large jumps. We then use this to set up a rejection sampling\nalgorithm for sampling from the tempered process. A small scale simulation\nstudy is given to help understand the performance of this algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 17:04:56 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Grabchak", "Michael", ""]]}, {"id": "1806.00690", "submitter": "David Hofmeyr", "authors": "David P. Hofmeyr", "title": "Fast Exact Univariate Kernel Density Estimation", "comments": "A vastly extended paper has been accepted to IEEE Transactions on\n  Pattern Analysis and Machine Intelligence", "journal-ref": null, "doi": "10.1109/TPAMI.2019.2930501", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents new methodology for computationally efficient kernel\ndensity estimation. It is shown that a large class of kernels allows for exact\nevaluation of the density estimates using simple recursions. The same\nmethodology can be used to compute density derivative estimates exactly. Given\nan ordered sample the computational complexity is linear in the sample size.\nCombining the proposed methodology with existing approximation methods results\nin extremely fast density estimation. Extensive experimentation documents the\neffectiveness and efficiency of this approach compared with the existing\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 19:09:03 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 12:52:13 GMT"}, {"version": "v3", "created": "Sat, 9 Nov 2019 12:33:43 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Hofmeyr", "David P.", ""]]}, {"id": "1806.00989", "submitter": "Fran\\c{c}ois Portier", "authors": "Bernard Delyon and Fran\\c{c}ois Portier", "title": "Asymptotic optimality of adaptive importance sampling", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive importance sampling (AIS) uses past samples to update the\n\\textit{sampling policy} $q_t$ at each stage $t$. Each stage $t$ is formed with\ntwo steps : (i) to explore the space with $n_t$ points according to $q_t$ and\n(ii) to exploit the current amount of information to update the sampling\npolicy. The very fundamental question raised in this paper concerns the\nbehavior of empirical sums based on AIS. Without making any assumption on the\nallocation policy $n_t$, the theory developed involves no restriction on the\nsplit of computational resources between the explore (i) and the exploit (ii)\nstep. It is shown that AIS is asymptotically optimal : the asymptotic behavior\nof AIS is the same as some \"oracle\" strategy that knows the targeted sampling\npolicy from the beginning. From a practical perspective, weighted AIS is\nintroduced, a new method that allows to forget poor samples from early stages.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 07:20:07 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 08:02:54 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Delyon", "Bernard", ""], ["Portier", "Fran\u00e7ois", ""]]}, {"id": "1806.01042", "submitter": "Andreas Bender", "authors": "Andreas Bender and Fabian Scheipl", "title": "pammtools: Piece-wise exponential Additive Mixed Modeling tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces the pammtools package, which facilitates data\ntransformation, estimation and interpretation of Piece-wise exponential\nAdditive Mixed Models. A special focus is on time-varying effects and\ncumulative effects of time-dependent covariates, where multiple past\nobservations of a covariate can cumulatively affect the hazard, possibly\nweighted by a non-linear function. The package provides functions for\nconvenient simulation and visualization of such effects as well as a robust and\nversatile function to transform time-to-event data from standard formats to a\nformat suitable for their estimation. The models can be represented as\nGeneralized Additive Mixed Models and estimated using the R package mgcv. Many\nexamples on real and simulated data as well as the respective R code are\nprovided throughout the article.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 10:55:43 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Bender", "Andreas", ""], ["Scheipl", "Fabian", ""]]}, {"id": "1806.01270", "submitter": "Kai Rothauge", "authors": "Alex Gittens, Kai Rothauge, Shusen Wang, Michael W. Mahoney, Jey\n  Kottalam, Lisa Gerhardt, Prabhat, Michael Ringenburg, Kristyn Maschhoff", "title": "Alchemist: An Apache Spark <=> MPI Interface", "comments": "Accepted for publication in Concurrency and Computation: Practice and\n  Experience, Special Issue on the Cray User Group 2018. arXiv admin note: text\n  overlap with arXiv:1805.11800", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB physics.data-an stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Apache Spark framework for distributed computation is popular in the data\nanalytics community due to its ease of use, but its MapReduce-style programming\nmodel can incur significant overheads when performing computations that do not\nmap directly onto this model. One way to mitigate these costs is to off-load\ncomputations onto MPI codes. In recent work, we introduced Alchemist, a system\nfor the analysis of large-scale data sets. Alchemist calls MPI-based libraries\nfrom within Spark applications, and it has minimal coding, communication, and\nmemory overheads. In particular, Alchemist allows users to retain the\nproductivity benefits of working within the Spark software ecosystem without\nsacrificing performance efficiency in linear algebra, machine learning, and\nother related computations.\n  In this paper, we discuss the motivation behind the development of Alchemist,\nand we provide a detailed overview its design and usage. We also demonstrate\nthe efficiency of our approach on medium-to-large data sets, using some\nstandard linear algebra operations, namely matrix multiplication and the\ntruncated singular value decomposition of a dense matrix, and we compare the\nperformance of Spark with that of Spark+Alchemist. These computations are run\non the NERSC supercomputer Cori Phase 1, a Cray XC40.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jun 2018 23:25:29 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Gittens", "Alex", ""], ["Rothauge", "Kai", ""], ["Wang", "Shusen", ""], ["Mahoney", "Michael W.", ""], ["Kottalam", "Jey", ""], ["Gerhardt", "Lisa", ""], ["Prabhat", "", ""], ["Ringenburg", "Michael", ""], ["Maschhoff", "Kristyn", ""]]}, {"id": "1806.01412", "submitter": "Peter Carbonetto", "authors": "Youngseok Kim, Peter Carbonetto, Matthew Stephens, Mihai Anitescu", "title": "A fast algorithm for maximum likelihood estimation of mixture\n  proportions using sequential quadratic programming", "comments": "28 pages, 6 figures", "journal-ref": "Journal of Computational and Graphical Statistics 29 (2020),\n  261-273", "doi": "10.1080/10618600.2019.1689985", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum likelihood estimation of mixture proportions has a long history, and\ncontinues to play an important role in modern statistics, including in\ndevelopment of nonparametric empirical Bayes methods. Maximum likelihood of\nmixture proportions has traditionally been solved using the expectation\nmaximization (EM) algorithm, but recent work by Koenker & Mizera shows that\nmodern convex optimization techniques -- in particular, interior point methods\n-- are substantially faster and more accurate than EM. Here, we develop a new\nsolution based on sequential quadratic programming (SQP). It is substantially\nfaster than the interior point method, and just as accurate. Our approach\ncombines several ideas: first, it solves a reformulation of the original\nproblem; second, it uses an SQP approach to make the best use of the expensive\ngradient and Hessian computations; third, the SQP iterations are implemented\nusing an active set method to exploit the sparse nature of the quadratic\nsubproblems; fourth, it uses accurate low-rank approximations for more\nefficient gradient and Hessian computations. We illustrate the benefits of our\napproach in experiments on synthetic data sets as well as a large genetic\nassociation data set. In large data sets (n = 1,000,000 observations, m = 1,000\nmixture components), our implementation achieves at least 100-fold reduction in\nruntime compared with a state-of-the-art interior point solver. Our methods are\nimplemented in Julia, and in an R package available on CRAN (see\nhttps://CRAN.R-project.org/package=mixsqp).\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 22:11:11 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 20:51:05 GMT"}, {"version": "v3", "created": "Mon, 1 Apr 2019 18:30:21 GMT"}, {"version": "v4", "created": "Fri, 8 Nov 2019 16:34:27 GMT"}, {"version": "v5", "created": "Wed, 9 Dec 2020 18:49:37 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Kim", "Youngseok", ""], ["Carbonetto", "Peter", ""], ["Stephens", "Matthew", ""], ["Anitescu", "Mihai", ""]]}, {"id": "1806.01416", "submitter": "Arno Siri-J\\'egousse", "authors": "Asger Hobolth and Arno Siri-J\\'egousse and Mogens Bladt", "title": "Phase-type distributions in population genetics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE q-bio.QM stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probability modelling for DNA sequence evolution is well established and\nprovides a rich framework for understanding genetic variation between samples\nof individuals from one or more populations. We show that both classical and\nmore recent models for coalescence (with or without recombination) can be\ndescribed in terms of the so-called phase-type theory, where complicated and\ntedious calculations are circumvented by the use of matrices. The application\nof phase-type theory consists of describing the stochastic model as a Markov\nmodel by appropriately setting up a state space and calculating the\ncorresponding intensity and reward matrices. Formulae of interest are then\nexpressed in terms of these aforementioned matrices. We illustrate this by a\nfew examples calculating the mean, variance and even higher order moments of\nthe site frequency spectrum in the multiple merger coalescent models, and by\nanalysing the mean and variance for the number of segregating sites for\nmultiple samples in the two-locus ancestral recombination graph. We believe\nthat phase-type theory has great potential as a tool for analysing probability\nmodels in population genetics. The compact matrix notation is useful for\nclarification of current models, in particular their formal manipulation\n(calculation), but also for further development or extensions.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 22:22:10 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Hobolth", "Asger", ""], ["Siri-J\u00e9gousse", "Arno", ""], ["Bladt", "Mogens", ""]]}, {"id": "1806.01615", "submitter": "Michael Crowther", "authors": "Michael J. Crowther", "title": "merlin - a unified modelling framework for data analysis and methods\n  development in Stata", "comments": "Submitted to the Stata Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  merlin can do a lot of things. From simple stuff, like fitting a linear\nregression or a Weibull survival model, to a three-level logistic mixed effects\nmodel, or a multivariate joint model of multiple longitudinal outcomes (of\ndifferent types) and a recurrent event and survival with non-linear\neffects...the list is rather endless. merlin can do things I haven't even\nthought of yet. I'll take a single dataset, and attempt to show you the full\nrange of capabilities of merlin, and discuss some future directions for the\nimplementation in Stata.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 11:37:53 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Crowther", "Michael J.", ""]]}, {"id": "1806.01870", "submitter": "Jorge Ignacio Gonz\\'alez C\\'azares", "authors": "Jorge Ignacio Gonz\\'alez C\\'azares, Aleksandar Mijatovi\\'c, and\n  Ger\\'onimo Uribe Bravo", "title": "Exact Simulation of the Extrema of Stable Processes", "comments": "26 pages, 3 figures, Julia implementation of the exact simulation\n  algorithm is in the GitHub repository:\n  https://github.com/jorgeignaciogc/StableSupremum.jl", "journal-ref": "Adv. in Appl. Probab. 51 (2019), no. 4, 967-993", "doi": "10.1017/apr.2019.39", "report-no": null, "categories": "math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exhibit an exact simulation algorithm for the supremum of a stable process\nover a finite time interval using dominated coupling from the past (DCFTP). We\nestablish a novel perpetuity equation for the supremum (via the representation\nof the concave majorants of L\\'evy processes) and apply it to construct a\nMarkov chain in the DCFTP algorithm. We prove that the number of steps taken\nbackwards in time before the coalescence is detected is finite. We analyse\nnumerically the performance of the algorithm (the code, written in Julia 1.0,\nis available on GitHub).\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 18:07:05 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 13:16:37 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["C\u00e1zares", "Jorge Ignacio Gonz\u00e1lez", ""], ["Mijatovi\u0107", "Aleksandar", ""], ["Bravo", "Ger\u00f3nimo Uribe", ""]]}, {"id": "1806.01916", "submitter": "Patrick Heas", "authors": "Patrick H\\'eas", "title": "Selecting Reduced Models in the Cross-Entropy Method", "comments": "to appear", "journal-ref": "SIAM / ASA Journal on Uncertainty Quantification (JUQ), 2020", "doi": null, "report-no": null, "categories": "stat.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the estimation of rare event probabilities using\nimportance sampling (IS), where an optimal proposal distribution is computed\nwith the cross-entropy (CE) method. Although, IS optimized with the CE method\nleads to an efficient reduction of the estimator variance, this approach\nremains unaffordable for problems where the repeated evaluation of the score\nfunction represents a too intensive computational effort. This is often the\ncase for score functions related to the solution of a partial differential\nequation (PDE) with random inputs. This work proposes to alleviate computation\nby the parsimonious use of a hierarchy of score function approximations in the\nCE optimization process. The score function approximation is obtained by\nselecting the surrogate of lowest dimensionality, whose accuracy guarantees to\npass the current CE optimization stage. The selection relies on certified upper\nbounds on the error norm. An asymptotic analysis provides some theoretical\nguarantees on the efficiency and convergence of the proposed algorithm.\nNumerical results demonstrate the gain brought by the method in the context of\npollution alerts and a system modeled by a PDE.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 20:00:44 GMT"}, {"version": "v2", "created": "Tue, 19 Mar 2019 16:53:16 GMT"}, {"version": "v3", "created": "Tue, 4 Feb 2020 13:14:03 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["H\u00e9as", "Patrick", ""]]}, {"id": "1806.01981", "submitter": "Zdravko Botev", "authors": "Y.-L. Chen and Z. I. Botev", "title": "Regenerative Simulation for the Bayesian Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gibbs sampler of Park and Casella is one of the most popular MCMC methods\nfor sampling from the posterior density of the Bayesian Lasso regression. As\nwith many Markov chain samplers, their Gibbs sampler lacks a theoretically\nsound method of output analysis --- a method for estimating the variance of a\ngiven ergodic average and estimating how closely the chain is sampling from the\nstationary distribution, that is, the burn-in.\n  In this paper, we address this shortcoming by identifying regenerative\nstructure in the sampler of Park and Casella, thus providing a theoretically\nsound method of assessing its performance. The regenerative structure provides\nboth a strongly consistent variance estimator, and an estimator of (an upper\nbound on) the total variation distance from the target posterior density. The\nresult is a simple and theoretically sound way to assess the stationarity of\nthe Park and Casella and, more generally, other MCMC samplers, for which\nregenerative simulation is possible.\n  We perform a numerical study in which we validate the standard errors\ncalculated by our regenerative method by comparing it with the standard errors\ncalculated by an AR(1) heuristic approximation. Thus, we show that for the\nBayesian Lasso model, the regenerative method is a viable and theoretically\njustified alternative to the existing ad-hoc MCMC convergence diagnostics.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 02:24:59 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Chen", "Y. -L.", ""], ["Botev", "Z. I.", ""]]}, {"id": "1806.02068", "submitter": "Tore Selland Kleppe", "authors": "Tore Selland Kleppe", "title": "Dynamically rescaled Hamiltonian Monte Carlo for Bayesian Hierarchical\n  Models", "comments": "Includes supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamically rescaled Hamiltonian Monte Carlo (DRHMC) is introduced as a\ncomputationally fast and easily implemented method for performing full Bayesian\nanalysis in hierarchical statistical models. The method relies on introducing a\nmodified parameterisation so that the re-parameterised target distribution has\nclose to constant scaling properties, and thus is easily sampled using standard\n(Euclidian metric) Hamiltonian Monte Carlo. Provided that the parameterisations\nof the conditional distributions specifying the hierarchical model are\n\"constant information parameterisations\" (CIP), the relation between the\nmodified- and original parameterisation is bijective, explicitly computed and\nadmit exploitation of sparsity in the numerical linear algebra involved. CIPs\nfor a large catalogue of statistical models are presented, and from the\ncatalogue, it is clear that many CIPs are currently routinely used in\nstatistical computing. A relation between the proposed methodology and a class\nof explicitly integrated Riemann manifold Hamiltonian Monte Carlo methods is\ndiscussed. The methodology is illustrated on several example models, including\na model for inflation rates with multiple levels of non-linearly dependent\nlatent variables.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 08:52:57 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 12:35:56 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Kleppe", "Tore Selland", ""]]}, {"id": "1806.02107", "submitter": "Fran\\c{c}ois Portier", "authors": "Patrice Bertail and Fran\\c{c}ois Portier", "title": "Rademacher complexity for Markov chains : Applications to kernel\n  smoothing and Metropolis-Hasting", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the seminal approach by Talagrand, the concept of Rademacher\ncomplexity for independent sequences of random variables is extended to Markov\nchains. The proposed notion of \"block Rademacher complexity\" (of a class of\nfunctions) follows from renewal theory and allows to control the expected\nvalues of suprema (over the class of functions) of empirical processes based on\nHarris Markov chains as well as the excess probability. For classes of\nVapnik-Chervonenkis type, bounds on the \"block Rademacher complexity\" are\nestablished. These bounds depend essentially on the sample size and the\nprobability tails of the regeneration times. The proposed approach is employed\nto obtain convergence rates for the kernel density estimator of the stationary\nmeasure and to derive concentration inequalities for the Metropolis-Hasting\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 10:40:18 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 07:11:49 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Bertail", "Patrice", ""], ["Portier", "Fran\u00e7ois", ""]]}, {"id": "1806.02429", "submitter": "Susanne Pieschner", "authors": "Susanne Pieschner, Christiane Fuchs", "title": "Bayesian Inference for Diffusion Processes: Using Higher-Order\n  Approximations for Transition Densities", "comments": "33 pages, 15 figures", "journal-ref": null, "doi": "10.1098/rsos.200270", "report-no": null, "categories": "stat.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Modelling random dynamical systems in continuous time, diffusion processes\nare a powerful tool in many areas of science. Model parameters can be estimated\nfrom time-discretely observed processes using Markov chain Monte Carlo (MCMC)\nmethods that introduce auxiliary data. These methods typically approximate the\ntransition densities of the process numerically, both for calculating the\nposterior densities and proposing auxiliary data. Here, the Euler-Maruyama\nscheme is the standard approximation technique. However, the MCMC method is\ncomputationally expensive. Using higher-order approximations may accelerate it,\nbut the specific implementation and benefit remain unclear. Hence, we\ninvestigate the utilisation and usefulness of higher-order approximations in\nthe example of the Milstein scheme. Our study demonstrates that the MCMC\nmethods based on the Milstein approximation yield good estimation results.\nHowever, they are computationally more expensive and can be applied to\nmultidimensional processes only with impractical restrictions. Moreover, the\ncombination of the Milstein approximation and the well-known modified bridge\nproposal introduces additional numerical challenges.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 21:11:31 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 06:57:02 GMT"}, {"version": "v3", "created": "Tue, 15 Sep 2020 08:14:13 GMT"}], "update_date": "2020-10-12", "authors_parsed": [["Pieschner", "Susanne", ""], ["Fuchs", "Christiane", ""]]}, {"id": "1806.02458", "submitter": "Theodore  Kypraios", "authors": "Iker Perez, Lax Chan, Mercedes Torres Torres, James Goulding, Theodore\n  Kypraios", "title": "On Bayesian inferential tasks with infinite-state jump processes:\n  efficient data augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in sampling schemes for Markov jump processes have recently enabled\nmultiple inferential tasks. However, in statistical and machine learning\napplications, we often require that these continuous-time models find support\non structured and infinite state spaces. In these cases, exact sampling may\nonly be achieved by often inefficient particle filtering procedures, and\nrapidly augmenting observed datasets remains a significant challenge. Here, we\nbuild on the principles of uniformization and present a tractable framework to\naddress this problem, which greatly improves the efficiency of existing\nstate-of-the-art methods commonly used in small finite-state systems, and\nfurther scales their use to infinite-state scenarios. We capitalize on the\nmarginal role of variable subsets in a model hierarchy during the process\njumps, and describe an algorithm that relies on measurable mappings between\npairs of states and carefully designed sets of synthetic jump observations. The\nproposed method enables the efficient integration of slice sampling techniques\nand it can overcome the existing computational bottleneck. We offer evidence by\nmeans of experiments addressing inference and clustering tasks on both\nsimulated and real data sets.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2018 23:27:39 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Perez", "Iker", ""], ["Chan", "Lax", ""], ["Torres", "Mercedes Torres", ""], ["Goulding", "James", ""], ["Kypraios", "Theodore", ""]]}, {"id": "1806.02670", "submitter": "Yang Ni", "authors": "Yang Ni and Peter M\\\"uller and Maurice Diesendruck and Sinead\n  Williamson and Yitan Zhu and Yuan Ji", "title": "Scalable Bayesian Nonparametric Clustering and Classification", "comments": "29 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a scalable multi-step Monte Carlo algorithm for inference under a\nlarge class of nonparametric Bayesian models for clustering and classification.\nEach step is \"embarrassingly parallel\" and can be implemented using the same\nMarkov chain Monte Carlo sampler. The simplicity and generality of our approach\nmakes inference for a wide range of Bayesian nonparametric mixture models\napplicable to large datasets. Specifically, we apply the approach to inference\nunder a product partition model with regression on covariates. We show results\nfor inference with two motivating data sets: a large set of electronic health\nrecords (EHR) and a bank telemarketing dataset. We find interesting clusters\nand favorable classification performance relative to other widely used\ncompeting classifiers.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2018 13:30:36 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Ni", "Yang", ""], ["M\u00fcller", "Peter", ""], ["Diesendruck", "Maurice", ""], ["Williamson", "Sinead", ""], ["Zhu", "Yitan", ""], ["Ji", "Yuan", ""]]}, {"id": "1806.03756", "submitter": "Weijun Xie", "authors": "Weijun Xie and Xinwei Deng", "title": "Scalable Algorithms for the Sparse Ridge Regression", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse regression and variable selection for large-scale data have been\nrapidly developed in the past decades. This work focuses on sparse ridge\nregression, which enforces the sparsity by use of the L0 norm. We first prove\nthat the continuous relaxation of the mixed integer second order conic (MISOC)\nreformulation using perspective formulation is equivalent to that of the convex\ninteger formulation proposed in recent work. We also show that the convex hull\nof the constraint system of MISOC formulation is equal to its continuous\nrelaxation. Based upon these two formulations (i.e., the MISOC formulation and\nconvex integer formulation), we analyze two scalable algorithms, the greedy and\nrandomized algorithms, for sparse ridge regression with desirable theoretical\nproperties. The proposed algorithms are proved to yield near-optimal solutions\nunder mild conditions. We further propose to integrate the greedy algorithm\nwith the randomized algorithm, which can greedily search the features from the\nnonzero subset identified by the continuous relaxation of the MISOC\nformulation. The merits of the proposed methods are illustrated through\nnumerical examples in comparison with several existing ones.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 01:07:47 GMT"}, {"version": "v2", "created": "Sun, 19 Jan 2020 04:25:43 GMT"}, {"version": "v3", "created": "Sun, 28 Jun 2020 21:49:49 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Xie", "Weijun", ""], ["Deng", "Xinwei", ""]]}, {"id": "1806.03791", "submitter": "Lingjiao Chen", "authors": "Lingjiao Chen and Hongyi Wang and Jinman Zhao and Dimitris\n  Papailiopoulos and Paraschos Koutris", "title": "The Effect of Network Width on the Performance of Large-batch Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed implementations of mini-batch stochastic gradient descent (SGD)\nsuffer from communication overheads, attributed to the high frequency of\ngradient updates inherent in small-batch training. Training with large batches\ncan reduce these overheads; however, large batches can affect the convergence\nproperties and generalization performance of SGD. In this work, we take a first\nstep towards analyzing how the structure (width and depth) of a neural network\naffects the performance of large-batch training. We present new theoretical\nresults which suggest that--for a fixed number of parameters--wider networks\nare more amenable to fast large-batch training compared to deeper ones. We\nprovide extensive experiments on residual and fully-connected neural networks\nwhich suggest that wider networks can be trained using larger batches without\nincurring a convergence slow-down, unlike their deeper variants.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 03:29:17 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Chen", "Lingjiao", ""], ["Wang", "Hongyi", ""], ["Zhao", "Jinman", ""], ["Papailiopoulos", "Dimitris", ""], ["Koutris", "Paraschos", ""]]}, {"id": "1806.03948", "submitter": "Abbas Alhakim", "authors": "Abbas Alhakim", "title": "Hadamard Matrices, Quaternions, and the Pearson Chi-square Statistic", "comments": "19 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a symbolic decomposition of the Pearson chi-square statistic with\nunequal cell probabilities, by presenting Hadamard-type matrices whose columns\nare eigenvectors of the variance-covariance matrix of the cell counts. All of\nthe eigenvectors have non-zero values so each component test uses all cell\nprobabilities in a way that makes it intuitively interpretable. When all cell\nprobabilities are distinct and unrelated we establish that such decomposition\nis only possible when the number of multinomial cells is a small power of 2.\nFor higher powers of 2, we show, using the theory of orthogonal designs, that\nthe targeted decomposition is possible when appropriate relations are imposed\non the cell probabilities, the simplest of which is when the probabilities are\nequal and the decomposition is reduced to the one obtained by Hadamard\nmatrices. Simulations are given to illustrate the sensitivity of various\ncomponents to changes in location, scale skewness and tail probability, as well\nas to illustrate the potential improvement in power when the cell probabilities\nare changed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2018 10:09:29 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Alhakim", "Abbas", ""]]}, {"id": "1806.04059", "submitter": "Chaoran Hu", "authors": "Chaoran Hu and Vladimir Pozdnyakov and Jun Yan", "title": "Density and Distribution Evaluation for Convolution of Independent Gamma\n  Variables", "comments": null, "journal-ref": "Computational Statistics 35 (2020) 327-342", "doi": "10.1007/s00180-019-00924-9", "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several numerical evaluations of the density and distribution of convolution\nof independent gamma variables are compared in their accuracy and speed. In\napplication to renewal processes, an efficient formula is derived for the\nprobability mass function of the event count.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2018 15:37:11 GMT"}], "update_date": "2020-08-25", "authors_parsed": [["Hu", "Chaoran", ""], ["Pozdnyakov", "Vladimir", ""], ["Yan", "Jun", ""]]}, {"id": "1806.04632", "submitter": "Giorgio Matteo Vitetta Prof.", "authors": "Giorgio M. Vitetta, Pasquale Di Viesti, Emilio Sirignano and Francesco\n  Montorsi", "title": "Parallel Concatenation of Bayesian Filters: Turbo Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript a method for developing novel filtering algorithms through\nthe parallel concatenation of two Bayesian filters is illustrated. Our\ndescription of this method, called turbo filtering, is based on a new graphical\nmodel; this allows us to efficiently describe both the processing accomplished\ninside each of the constituent filter and the interactions between them. This\nmodel is exploited to develop two new filtering algorithms for conditionally\nlinear Gaussian systems. Numerical results for a specific dynamic system\nevidence that such filters can achieve a better complexity-accuracy tradeoff\nthan marginalized particle filtering.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2018 16:28:58 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 08:15:42 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Vitetta", "Giorgio M.", ""], ["Di Viesti", "Pasquale", ""], ["Sirignano", "Emilio", ""], ["Montorsi", "Francesco", ""]]}, {"id": "1806.04854", "submitter": "Mohammad Emtiyaz Khan", "authors": "Mohammad Emtiyaz Khan, Didrik Nielsen, Voot Tangkaratt, Wu Lin, Yarin\n  Gal, Akash Srivastava", "title": "Fast and Scalable Bayesian Deep Learning by Weight-Perturbation in Adam", "comments": "Camera ready version", "journal-ref": "Thirty-fifth International Conference on Machine Learning, 2018", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty computation in deep learning is essential to design robust and\nreliable systems. Variational inference (VI) is a promising approach for such\ncomputation, but requires more effort to implement and execute compared to\nmaximum-likelihood methods. In this paper, we propose new natural-gradient\nalgorithms to reduce such efforts for Gaussian mean-field VI. Our algorithms\ncan be implemented within the Adam optimizer by perturbing the network weights\nduring gradient evaluations, and uncertainty estimates can be cheaply obtained\nby using the vector that adapts the learning rate. This requires lower memory,\ncomputation, and implementation effort than existing VI methods, while\nobtaining uncertainty estimates of comparable quality. Our empirical results\nconfirm this and further suggest that the weight-perturbation in our algorithm\ncould be useful for exploration in reinforcement learning and stochastic\noptimization.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 05:45:22 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 12:19:00 GMT"}, {"version": "v3", "created": "Thu, 2 Aug 2018 08:21:25 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Khan", "Mohammad Emtiyaz", ""], ["Nielsen", "Didrik", ""], ["Tangkaratt", "Voot", ""], ["Lin", "Wu", ""], ["Gal", "Yarin", ""], ["Srivastava", "Akash", ""]]}, {"id": "1806.05035", "submitter": "Bruno Sudret", "authors": "S. J. Peter, A. Siviglia, J. Nagel, S. Marelli, R. M. Boes, D. Vetsch\n  and B. Sudret", "title": "Development of probabilistic dam breach model using Bayesian inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO physics.geo-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dam breach models are commonly used to predict outflow hydrographs of\npotentially failing dams and are key ingredients for evaluating flood risk. In\nthis paper a new dam breach modeling framework is introduced that shall improve\nthe reliability of hydrograph predictions of homogeneous earthen embankment\ndams. Striving for a small number of parameters, the simplified physics-based\nmodel describes the processes of failing embankment dams by breach enlargement,\ndriven by progressive surface erosion. Therein the erosion rate of dam material\nis modeled by empirical sediment transport formulations. Embedding the model\ninto a Bayesian multilevel framework allows for quantitative analysis of\ndifferent categories of uncertainties. To this end, data available in\nliterature of observed peak discharge and final breach width of historical dam\nfailures was used to perform model inversion by applying Markov Chain Monte\nCarlo simulation. Prior knowledge is mainly based on non-informative\ndistribution functions. The resulting posterior distribution shows that the\nmain source of uncertainty is a correlated subset of parameters, consisting of\nthe residual error term and the epistemic term quantifying the breach erosion\nrate. The prediction intervals of peak discharge and final breach width are\ncongruent with values known from literature. To finally predict the outflow\nhydrograph for real case applications, an alternative residual model was\nformulated that assumes perfect data and a perfect model. The fully\nprobabilistic fashion of hydrograph prediction has the potential to improve the\nadequate risk management of downstream flooding.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2018 13:48:19 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Peter", "S. J.", ""], ["Siviglia", "A.", ""], ["Nagel", "J.", ""], ["Marelli", "S.", ""], ["Boes", "R. M.", ""], ["Vetsch", "D.", ""], ["Sudret", "B.", ""]]}, {"id": "1806.05424", "submitter": "Andrew Golightly", "authors": "Yingying Lai, Andrew Golightly, Richard Boys", "title": "Sequential Bayesian inference for spatio-temporal models of temperature\n  and humidity data", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a spatio-temporal model to forecast sensor output at five\nlocations in North East England. The signal is described using coupled dynamic\nlinear models, with spatial effects specified by a Gaussian process. Data\nstreams are analysed using a stochastic algorithm which sequentially\napproximates the parameter posterior through a series of reweighting and\nresampling steps. An iterated batch importance sampling scheme is used to\ncircumvent particle degeneracy through a resample-move step. The algorithm is\nmodified to make it more efficient and parallisable. The model is shown to give\na good description of the underlying process and provide reasonable forecast\naccuracy.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 09:15:27 GMT"}], "update_date": "2018-06-15", "authors_parsed": [["Lai", "Yingying", ""], ["Golightly", "Andrew", ""], ["Boys", "Richard", ""]]}, {"id": "1806.05738", "submitter": "Jingyu He", "authors": "P. Richard Hahn, Jingyu He, Hedibert Lopes", "title": "Efficient sampling for Gaussian linear regression with arbitrary priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a slice sampler for Bayesian linear regression models\nwith arbitrary priors. The new sampler has two advantages over current\napproaches. One, it is faster than many custom implementations that rely on\nauxiliary latent variables, if the number of regressors is large. Two, it can\nbe used with any prior with a density function that can be evaluated up to a\nnormalizing constant, making it ideal for investigating the properties of new\nshrinkage priors without having to develop custom sampling algorithms. The new\nsampler takes advantage of the special structure of the linear regression\nlikelihood, allowing it to produce better effective sample size per second than\ncommon alternative approaches.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2018 20:39:06 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Hahn", "P. Richard", ""], ["He", "Jingyu", ""], ["Lopes", "Hedibert", ""]]}, {"id": "1806.05852", "submitter": "Anthony Lee", "authors": "Anthony Lee, Sumeetpal S. Singh and Matti Vihola", "title": "Coupled conditional backward sampling particle filter", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conditional particle filter (CPF) is a promising algorithm for general\nhidden Markov model smoothing. Empirical evidence suggests that the variant of\nCPF with backward sampling (CBPF) performs well even with long time series.\nPrevious theoretical results have not been able to demonstrate the improvement\nbrought by backward sampling, whereas we provide rates showing that CBPF can\nremain effective with a fixed number of particles independent of the time\nhorizon. Our result is based on analysis of a new coupling of two CBPFs, the\ncoupled conditional backward sampling particle filter (CCBPF). We show that\nCCBPF has good stability properties in the sense that with fixed number of\nparticles, the coupling time in terms of iterations increases only linearly\nwith respect to the time horizon under a general (strong mixing) condition. The\nCCBPF is useful not only as a theoretical tool, but also as a practical method\nthat allows for unbiased estimation of smoothing expectations, following the\nrecent developments by Jacob et al. (to appear). Unbiased estimation has many\nadvantages, such as enabling the construction of asymptotically exact\nconfidence intervals and straightforward parallelisation.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 08:31:04 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 15:54:30 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2019 14:56:43 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Lee", "Anthony", ""], ["Singh", "Sumeetpal S.", ""], ["Vihola", "Matti", ""]]}, {"id": "1806.05924", "submitter": "Daniel Andrade", "authors": "Daniel Andrade, Akiko Takeda, Kenji Fukumizu", "title": "Robust Bayesian Model Selection for Variable Clustering with the\n  Gaussian Graphical Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable clustering is important for explanatory analysis. However, only few\ndedicated methods for variable clustering with the Gaussian graphical model\nhave been proposed. Even more severe, small insignificant partial correlations\ndue to noise can dramatically change the clustering result when evaluating for\nexample with the Bayesian Information Criteria (BIC). In this work, we try to\naddress this issue by proposing a Bayesian model that accounts for negligible\nsmall, but not necessarily zero, partial correlations. Based on our model, we\npropose to evaluate a variable clustering result using the marginal likelihood.\nTo address the intractable calculation of the marginal likelihood, we propose\ntwo solutions: one based on a variational approximation, and another based on\nMCMC. Experiments on simulated data shows that the proposed method is similarly\naccurate as BIC in the no noise setting, but considerably more accurate when\nthere are noisy partial correlations. Furthermore, on real data the proposed\nmethod provides clustering results that are intuitively sensible, which is not\nalways the case when using BIC or its extensions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 12:06:03 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Andrade", "Daniel", ""], ["Takeda", "Akiko", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "1806.05982", "submitter": "Samuel Wiqvist", "authors": "Samuel Wiqvist, Umberto Picchini, Julie Lyng Forman, Kresten\n  Lindorff-Larsen, Wouter Boomsma", "title": "Accelerating delayed-acceptance Markov chain Monte Carlo algorithms", "comments": "40 pages, 21 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Delayed-acceptance Markov chain Monte Carlo (DA-MCMC) samples from a\nprobability distribution via a two-stages version of the Metropolis-Hastings\nalgorithm, by combining the target distribution with a \"surrogate\" (i.e. an\napproximate and computationally cheaper version) of said distribution. DA-MCMC\naccelerates MCMC sampling in complex applications, while still targeting the\nexact distribution. We design a computationally faster, albeit approximate,\nDA-MCMC algorithm. We consider parameter inference in a Bayesian setting where\na surrogate likelihood function is introduced in the delayed-acceptance scheme.\nWhen the evaluation of the likelihood function is computationally intensive,\nour scheme produces a 2-4 times speed-up, compared to standard DA-MCMC.\nHowever, the acceleration is highly problem dependent. Inference results for\nthe standard delayed-acceptance algorithm and our approximated version are\nsimilar, indicating that our algorithm can return reliable Bayesian inference.\nAs a computationally intensive case study, we introduce a novel stochastic\ndifferential equation model for protein folding data.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2018 13:59:16 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 13:35:05 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Wiqvist", "Samuel", ""], ["Picchini", "Umberto", ""], ["Forman", "Julie Lyng", ""], ["Lindorff-Larsen", "Kresten", ""], ["Boomsma", "Wouter", ""]]}, {"id": "1806.06428", "submitter": "Michail Vlysidis", "authors": "Michail Vlysidis, Andrew C. Schiek and Yiannis N. Kaznessis", "title": "ZICS: an application for calculating the stationary probability\n  distribution of stochastic reaction networks", "comments": "21 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic formalisms are necessary to describe the behavior of many\nbiological systems. However, there remains a lack of numerical methods\navailable to calculate the stationary probability distributions of stochastic\nreaction networks. We have previously development a numerical approach to\ncalculate stationary probability distributions of stochastic networks, named ZI\nclosure scheme. In this work, we present a free applications based on\nZI-closure scheme, called ZICS.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2018 18:55:33 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Vlysidis", "Michail", ""], ["Schiek", "Andrew C.", ""], ["Kaznessis", "Yiannis N.", ""]]}, {"id": "1806.06520", "submitter": "Sumeetpal S Singh", "authors": "Bernd Kuhlenschmidt and Sumeetpal S. Singh", "title": "Stability of Conditional Sequential Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The particle Gibbs (PG) sampler is a Markov Chain Monte Carlo (MCMC)\nalgorithm, which uses an interacting particle system to perform the Gibbs\nsteps. Each Gibbs step consists of simulating a particle system conditioned on\none particle path. It relies on a conditional Sequential Monte Carlo (cSMC)\nmethod to create the particle system. We propose a novel interpretation of the\ncSMC algorithm as a perturbed Sequential Monte Carlo (SMC) method and apply\ntelescopic decompositions developed for the analysis of SMC algorithms\n\\cite{delmoral2004} to derive a bound for the distance between the expected\nsampled path from cSMC and the target distribution of the MCMC algorithm. This\ncan be used to get a uniform ergodicity result. In particular, we can show that\nthe mixing rate of cSMC can be kept constant by increasing the number of\nparticles linearly with the number of observations. Based on our decomposition,\nwe also prove a central limit theorem for the cSMC Algorithm, which cannot be\ndone using the approaches in \\cite{Andrieu2013} and \\cite{Lindsten2014}.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 07:10:27 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Kuhlenschmidt", "Bernd", ""], ["Singh", "Sumeetpal S.", ""]]}, {"id": "1806.06761", "submitter": "HaiYing Wang", "authors": "Mingyao Ai, Jun Yu, Huiming Zhang and HaiYing Wang", "title": "Optimal Subsampling Algorithms for Big Data Regressions", "comments": null, "journal-ref": "Statist Sinica, 2021, 31(2), 749-772", "doi": "10.5705/ss.202018.0439", "report-no": "http://www3.stat.sinica.edu.tw/statistica/J31N2/j31n208/j31n208.html", "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To fast approximate maximum likelihood estimators with massive data, this\npaper studies the Optimal Subsampling Method under the A-optimality Criterion\n(OSMAC) for generalized linear models. The consistency and asymptotic normality\nof the estimator from a general subsampling algorithm are established, and\noptimal subsampling probabilities under the A- and L-optimality criteria are\nderived. Furthermore, using Frobenius norm matrix concentration inequalities,\nfinite sample properties of the subsample estimator based on optimal\nsubsampling probabilities are also derived. Since the optimal subsampling\nprobabilities depend on the full data estimate, an adaptive two-step algorithm\nis developed. Asymptotic normality and optimality of the estimator from this\nadaptive algorithm are established. The proposed methods are illustrated and\nevaluated through numerical experiments on simulated and real datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 15:15:41 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 09:05:27 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Ai", "Mingyao", ""], ["Yu", "Jun", ""], ["Zhang", "Huiming", ""], ["Wang", "HaiYing", ""]]}, {"id": "1806.06777", "submitter": "Li Ma", "authors": "Shai Gorsky and Li Ma", "title": "Multiscale Fisher's Independence Test for Multivariate Dependence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying dependency in multivariate data is a common inference task that\narises in numerous applications. However, existing nonparametric independence\ntests typically require computation that scales at least quadratically with the\nsample size, making it difficult to apply them to massive data. Moreover,\nresampling is usually necessary to evaluate the statistical significance of the\nresulting test statistics at finite sample sizes, further worsening the\ncomputational burden. We introduce a scalable, resampling-free approach to\ntesting the independence between two random vectors by breaking down the task\ninto simple univariate tests of independence on a collection of 2x2 contingency\ntables constructed through sequential coarse-to-fine discretization of the\nsample space, transforming the inference task into a multiple testing problem\nthat can be completed with almost linear complexity with respect to the sample\nsize. To address increasing dimensionality, we introduce a coarse-to-fine\nsequential adaptive procedure that exploits the spatial features of dependency\nstructures to more effectively examine the sample space. We derive a\nfinite-sample theory that guarantees the inferential validity of our adaptive\nprocedure at any given sample size. In particular, we show that our approach\ncan achieve strong control of the family-wise error rate without resampling or\nlarge-sample approximation. We demonstrate the substantial computational\nadvantage of the procedure in comparison to existing approaches as well as its\ndecent statistical power under various dependency scenarios through an\nextensive simulation study, and illustrate how the divide-and-conquer nature of\nthe procedure can be exploited to not just test independence but to learn the\nnature of the underlying dependency. Finally, we demonstrate the use of our\nmethod through analyzing a large data set from a flow cytometry experiment.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 15:38:54 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 19:02:19 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 13:48:05 GMT"}, {"version": "v4", "created": "Wed, 5 Jun 2019 14:13:48 GMT"}, {"version": "v5", "created": "Fri, 10 Jan 2020 17:21:40 GMT"}, {"version": "v6", "created": "Tue, 14 Jan 2020 19:09:36 GMT"}, {"version": "v7", "created": "Wed, 7 Jul 2021 11:37:00 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Gorsky", "Shai", ""], ["Ma", "Li", ""]]}, {"id": "1806.06784", "submitter": "Cheng Ju", "authors": "Cheng Ju and David Benkeser and Mark J. van der Laan", "title": "Robust inference on the average treatment effect using the outcome\n  highly adaptive lasso", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many estimators of the average effect of a treatment on an outcome require\nestimation of the propensity score, the outcome regression, or both. It is\noften beneficial to utilize flexible techniques such as semiparametric\nregression or machine learning to estimate these quantities. However, optimal\nestimation of these regressions does not necessarily lead to optimal estimation\nof the average treatment effect, particularly in settings with strong\ninstrumental variables. A recent proposal addressed these issues via the\noutcome-adaptive lasso, a penalized regression technique for estimating the\npropensity score that seeks to minimize the impact of instrumental variables on\ntreatment effect estimators. However, a notable limitation of this approach is\nthat its application is restricted to parametric models. We propose a more\nflexible alternative that we call the outcome highly adaptive lasso. We discuss\nlarge sample theory for this estimator and propose closed form confidence\nintervals based on the proposed estimator. We show via simulation that our\nmethod offers benefits over several popular approaches.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2018 15:47:37 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 18:01:26 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 00:04:41 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Ju", "Cheng", ""], ["Benkeser", "David", ""], ["van der Laan", "Mark J.", ""]]}, {"id": "1806.07048", "submitter": "Parfair Munezero", "authors": "Parfait Munezero", "title": "Efficient Particle Smoothing for Bayesian Inference in Dynamic Survival\n  Models", "comments": "The title of the paper has been changed to reflect the content. The\n  new version adds on the existing version the following 1) A particle\n  smoothing inference methodology. 2) A simulation study of assessing the\n  efficiency of the proposed inference methodology. 3) A comparison of the\n  proposed methodology with a state-of-the-art MCMC inference methodology", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article proposes an efficient Bayesian inference for piecewise\nexponential hazard (PEH) models, which allow the effect of a covariate on the\nsurvival time to vary over time. The proposed inference methodology is based on\na particle smoothing (PS) algorithm that depends on three particle filters.\nEfficient proposal (importance) distributions for the particle filters tailored\nto the nature of survival data and PEH models are developed using the Laplace\napproximation of the posterior distribution and linear Bayes theory. The\nalgorithm is applied to both simulated and real data, and the results show that\nit generates an effective sample size that is more than two orders of magnitude\nlarger than a state-of-the-art MCMC sampler for the same computing time, and\nscales well in high-dimensional and relatively large data.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 05:23:21 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 08:48:10 GMT"}, {"version": "v3", "created": "Tue, 31 Mar 2020 13:44:33 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Munezero", "Parfait", ""]]}, {"id": "1806.07137", "submitter": "Jack Baker", "authors": "Jack Baker, Paul Fearnhead, Emily B Fox, Christopher Nemeth", "title": "Large-Scale Stochastic Sampling from the Probability Simplex", "comments": "Accepted to Advances in Neural Information Processing Systems (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic gradient Markov chain Monte Carlo (SGMCMC) has become a popular\nmethod for scalable Bayesian inference. These methods are based on sampling a\ndiscrete-time approximation to a continuous time process, such as the Langevin\ndiffusion. When applied to distributions defined on a constrained space the\ntime-discretization error can dominate when we are near the boundary of the\nspace. We demonstrate that because of this, current SGMCMC methods for the\nsimplex struggle with sparse simplex spaces; when many of the components are\nclose to zero. Unfortunately, many popular large-scale Bayesian models, such as\nnetwork or topic models, require inference on sparse simplex spaces. To avoid\nthe biases caused by this discretization error, we propose the stochastic\nCox-Ingersoll-Ross process (SCIR), which removes all discretization error and\nwe prove that samples from the SCIR process are asymptotically unbiased. We\ndiscuss how this idea can be extended to target other constrained spaces. Use\nof the SCIR process within a SGMCMC algorithm is shown to give substantially\nbetter performance for a topic model and a Dirichlet process mixture model than\nexisting SGMCMC approaches.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 10:08:37 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 16:06:24 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Baker", "Jack", ""], ["Fearnhead", "Paul", ""], ["Fox", "Emily B", ""], ["Nemeth", "Christopher", ""]]}, {"id": "1806.07274", "submitter": "Vincent Chin", "authors": "Vincent Chin, David Gunawan, Denzil G. Fiebig, Robert Kohn, Scott A.\n  Sisson", "title": "Efficient data augmentation for multivariate probit models with panel\n  data: An application to general practitioner decision-making about\n  contraceptives", "comments": null, "journal-ref": null, "doi": "10.1111/rssc.12393", "report-no": null, "categories": "stat.CO stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article considers the problem of estimating a multivariate probit model\nin a panel data setting with emphasis on sampling a high-dimensional\ncorrelation matrix and improving the overall efficiency of the data\naugmentation approach. We reparameterise the correlation matrix in a principled\nway and then carry out efficient Bayesian inference using Hamiltonian Monte\nCarlo. We also propose a novel antithetic variable method to generate samples\nfrom the posterior distribution of the random effects and regression\ncoefficients, resulting in significant gains in efficiency. We apply the\nmethodology by analysing stated preference data obtained from Australian\ngeneral practitioners evaluating alternative contraceptive products. Our\nanalysis suggests that the joint probability of discussing combinations of\ncontraceptive products with a patient shows medical practice variation among\nthe general practitioners, which indicates some resistance to even discuss\nthese products, let alone recommend them.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 14:22:29 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 09:06:02 GMT"}], "update_date": "2020-05-07", "authors_parsed": [["Chin", "Vincent", ""], ["Gunawan", "David", ""], ["Fiebig", "Denzil G.", ""], ["Kohn", "Robert", ""], ["Sisson", "Scott A.", ""]]}, {"id": "1806.07307", "submitter": "Sohail Bahmani", "authors": "Sohail Bahmani", "title": "Estimation from Non-Linear Observations via Convex Programming with\n  Application to Bilinear Regression", "comments": "Some elaboration on the algorithm and theoretical results are added.\n  Minor errors and typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a computationally efficient estimator, formulated as a convex\nprogram, for a broad class of non-linear regression problems that involve\ndifference of convex (DC) non-linearities. The proposed method can be viewed as\na significant extension of the \"anchored regression\" method formulated and\nanalyzed in [10] for regression with convex non-linearities. Our main\nassumption, in addition to other mild statistical and computational\nassumptions, is availability of a certain approximation oracle for the average\nof the gradients of the observation functions at a ground truth. Under this\nassumption and using a PAC-Bayesian analysis we show that the proposed\nestimator produces an accurate estimate with high probability. As a concrete\nexample, we study the proposed framework in the bilinear regression problem\nwith Gaussian factors and quantify a sufficient sample complexity for exact\nrecovery. Furthermore, we describe a computationally tractable scheme that\nprovably produces the required approximation oracle in the considered bilinear\nregression problem.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 15:28:46 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 18:43:46 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Bahmani", "Sohail", ""]]}, {"id": "1806.07533", "submitter": "Sanvesh Srivastava", "authors": "Sanvesh Srivastava, Glen DePalma, and Chuanhai Liu", "title": "An Asynchronous Distributed Expectation Maximization Algorithm For\n  Massive Data: The DEM Algorithm", "comments": "34 pages, 5 figures, 5 tables. Accepted for publication in JCGS", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The family of Expectation-Maximization (EM) algorithms provides a general\napproach to fitting flexible models for large and complex data. The expectation\n(E) step of EM-type algorithms is time-consuming in massive data applications\nbecause it requires multiple passes through the full data. We address this\nproblem by proposing an asynchronous and distributed generalization of the EM\ncalled the Distributed EM (DEM). Using DEM, existing EM-type algorithms are\neasily extended to massive data settings by exploiting the divide-and-conquer\ntechnique and widely available computing power, such as grid computing. The DEM\nalgorithm reserves two groups of computing processes called \\emph{workers} and\n\\emph{managers} for performing the E step and the maximization step (M step),\nrespectively. The samples are randomly partitioned into a large number of\ndisjoint subsets and are stored on the worker processes. The E step of DEM\nalgorithm is performed in parallel on all the workers, and every worker\ncommunicates its results to the managers at the end of local E step. The\nmanagers perform the M step after they have received results from a\n$\\gamma$-fraction of the workers, where $\\gamma$ is a fixed constant in $(0,\n1]$. The sequence of parameter estimates generated by the DEM algorithm retains\nthe attractive properties of EM: convergence of the sequence of parameter\nestimates to a local mode and linear global rate of convergence. Across diverse\nsimulations focused on linear mixed-effects models, the DEM algorithm is\nsignificantly faster than competing EM-type algorithms while having a similar\naccuracy. The DEM algorithm maintains its superior empirical performance on a\nmovie ratings database consisting of 10 million ratings.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 03:20:04 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Srivastava", "Sanvesh", ""], ["DePalma", "Glen", ""], ["Liu", "Chuanhai", ""]]}, {"id": "1806.07934", "submitter": "Jaewoo Park", "authors": "Jaewoo Park and Murali Haran", "title": "A Function Emulation Approach for Doubly Intractable Distributions", "comments": "32 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Doubly intractable distributions arise in many settings, for example in\nMarkov models for point processes and exponential random graph models for\nnetworks. Bayesian inference for these models is challenging because they\ninvolve intractable normalising \"constants\" that are actually functions of the\nparameters of interest. Although several clever computational methods have been\ndeveloped for these models, each method suffers from computational issues that\nmakes it computationally burdensome or even infeasible for many problems. We\npropose a novel algorithm that provides computational gains over existing\nmethods by replacing Monte Carlo approximations to the normalising function\nwith a Gaussian process-based approximation. We provide theoretical\njustification for this method. We also develop a closely related algorithm that\nis applicable more broadly to any likelihood function that is expensive to\nevaluate. We illustrate the application of our methods to a variety of\nchallenging simulated and real data examples, including an exponential random\ngraph model, a Markov point process, and a model for infectious disease\ndynamics. The algorithm shows significant gains in computational efficiency\nover existing methods, and has the potential for greater gains for more\nchallenging problems. For a random graph model example, we show how this gain\nin efficiency allows us to carry out accurate Bayesian inference when other\nalgorithms are computationally impractical.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 19:25:26 GMT"}, {"version": "v2", "created": "Sat, 14 Jul 2018 21:01:32 GMT"}, {"version": "v3", "created": "Sun, 22 Jul 2018 15:59:55 GMT"}, {"version": "v4", "created": "Tue, 2 Apr 2019 17:55:46 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Park", "Jaewoo", ""], ["Haran", "Murali", ""]]}, {"id": "1806.08320", "submitter": "Athanasios Kousathanas", "authors": "Athanasios Kousathanas, Pablo Duchen and Daniel Wegmann", "title": "A Guide to General-Purpose Approximate Bayesian Computation Software", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This Chapter, \"A Guide to General-Purpose ABC Software\", is to appear in the\nforthcoming Handbook of Approximate Bayesian Computation (2018). We present\ngeneral-purpose software to perform Approximate Bayesian Computation (ABC) as\nimplemented in the R-packages abc and EasyABC and the c++ program ABCtoolbox.\nWith simple toy models we demonstrate how to perform parameter inference, model\nselection, validation and optimal choice of summary statistics. We demonstrate\nhow to combine ABC with Markov Chain Monte Carlo and describe a realistic\npopulation genetics application.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2018 17:01:51 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Kousathanas", "Athanasios", ""], ["Duchen", "Pablo", ""], ["Wegmann", "Daniel", ""]]}, {"id": "1806.08813", "submitter": "Shijia Wang", "authors": "Liangliang Wang, Shijia Wang, Alexandre Bouchard-C\\^ot\\'e", "title": "An Annealed Sequential Monte Carlo Method for Bayesian Phylogenetics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an \"embarrassingly parallel\" method for Bayesian phylogenetic\ninference, annealed Sequential Monte Carlo, based on recent advances in the\nSequential Monte Carlo literature such as adaptive determination of annealing\nparameters. The algorithm provides an approximate posterior distribution over\ntrees and evolutionary parameters as well as an unbiased estimator for the\nmarginal likelihood. This unbiasedness property can be used for the purpose of\ntesting the correctness of posterior simulation software. We evaluate the\nperformance of phylogenetic annealed Sequential Monte Carlo by reviewing and\ncomparing with other computational Bayesian phylogenetic methods, in\nparticular, different marginal likelihood estimation methods. Unlike previous\nSequential Monte Carlo methods in phylogenetics, our annealed method can\nutilize standard Markov chain Monte Carlo tree moves and hence benefit from the\nlarge inventory of such moves available in the literature. Consequently, the\nannealed Sequential Monte Carlo method should be relatively easy to incorporate\ninto existing phylogenetic software packages based on Markov chain Monte Carlo\nalgorithms. We illustrate our method using simulation studies and real data\nanalysis.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2018 18:33:05 GMT"}, {"version": "v2", "created": "Sat, 19 Jan 2019 23:01:20 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 19:10:41 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Wang", "Liangliang", ""], ["Wang", "Shijia", ""], ["Bouchard-C\u00f4t\u00e9", "Alexandre", ""]]}, {"id": "1806.09048", "submitter": "Alexis Derumigny", "authors": "Alexis Derumigny and Jean-David Fermanian", "title": "A classification point-of-view about conditional Kendall's tau", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how the problem of estimating conditional Kendall's tau can be\nrewritten as a classification task. Conditional Kendall's tau is a conditional\ndependence parameter that is a characteristic of a given pair of random\nvariables. The goal is to predict whether the pair is concordant (value of $1$)\nor discordant (value of $-1$) conditionally on some covariates. We prove the\nconsistency and the asymptotic normality of a family of penalized approximate\nmaximum likelihood estimators, including the equivalent of the logit and probit\nregressions in our framework. Then, we detail specific algorithms adapting\nusual machine learning techniques, including nearest neighbors, decision trees,\nrandom forests and neural networks, to the setting of the estimation of\nconditional Kendall's tau. Finite sample properties of these estimators and\ntheir sensitivities to each component of the data-generating process are\nassessed in a simulation study. Finally, we apply all these estimators to a\ndataset of European stock indices.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2018 22:03:10 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 15:10:28 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 10:35:28 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Derumigny", "Alexis", ""], ["Fermanian", "Jean-David", ""]]}, {"id": "1806.09341", "submitter": "Anna Nikishova", "authors": "Anna Nikishova and Alfons G. Hoekstra", "title": "Semi-intrusive uncertainty propagation for multiscale models", "comments": null, "journal-ref": null, "doi": "10.1016/j.jocs.2019.06.007", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A family of semi-intrusive uncertainty propagation (UP) methods for\nmultiscale models is introduced. The methods are semi-intrusive in the sense\nthat inspection of the model is limited up to the level of the single scale\nsystems, and viewing these single scale components as black-boxes. The goal is\nto estimate uncertainty in the result of multiscale models at a reduced amount\nof time as compared to black-box Monte Carlo (MC). In the resulting\nsemi-intrusive MC method, the required number of samples of an expensive single\nscale model is minimized in order to reduce the execution time for the overall\nUP. In the metamodeling approach, the expensive model component is replaced\ncompletely by a computationally much cheaper surrogate model. These\nsemi-intrusive algorithms have been tested on two case studies based on\nreaction-diffusion dynamics. The results demonstrate that the proposed\nsemi-intrusive methods can result in a significant reduction of the\ncomputational time for multiscale UP, while still computing accurately the\nestimates of uncertainties. The semi-intrusive methods can, therefore, be a\nvalid alternative, when uncertainties of a multiscale model cannot be estimated\nby the black-box MC methods in a feasible amount of time.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 09:18:08 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 12:45:33 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 10:13:26 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Nikishova", "Anna", ""], ["Hoekstra", "Alfons G.", ""]]}, {"id": "1806.09362", "submitter": "Virgilio Gomez-Rubio", "authors": "Elena L\\'azaro and Carmen Armero and Virgilio G\\'omez-Rubio", "title": "Approximate Bayesian inference for mixture cure models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cure models in survival analysis deal with populations in which a part of the\nindividuals cannot experience the event of interest. Mixture cure models\nconsider the target population as a mixture of susceptible and non-susceptible\nindividuals. The statistical analysis of these models focuses on examining the\nprobability of cure (incidence model) and inferring on the time-to-event in the\nsusceptible subpopulation (latency model).\n  Bayesian inference on mixture cure models has typically relied upon Markov\nchain Monte Carlo (MCMC) methods. The integrated nested Laplace approximation\n(INLA) is a recent and attractive approach for doing Bayesian inference. INLA\nin its natural definition cannot fit mixture models but recent research has new\nproposals that combine INLA and MCMC methods to extend its applicability to\nthem (Bivand et al., 2014, G\\'omez-Rubio et al., 2017, G\\'omez-Rubio and Rue,\n2018}.\n  This paper focuses on the implementation of INLA in mixture cure models. A\ngeneral mixture cure survival model with covariate information for the latency\nand the incidence model within a general scenario with censored and\nnon-censored information is discussed. The fact that non-censored individuals\nundoubtedly belong to the uncured population is a valuable information that was\nincorporated in the inferential process.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 10:20:51 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["L\u00e1zaro", "Elena", ""], ["Armero", "Carmen", ""], ["G\u00f3mez-Rubio", "Virgilio", ""]]}, {"id": "1806.09548", "submitter": "Andreas Lindholm", "authors": "Andreas Lindholm and Fredrik Lindsten", "title": "Learning dynamical systems with particle stochastic approximation EM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.CE eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the particle stochastic approximation EM (PSAEM) algorithm for\nlearning of dynamical systems. The method builds on the EM algorithm, an\niterative procedure for maximum likelihood inference in latent variable models.\nBy combining stochastic approximation EM and particle Gibbs with ancestor\nsampling (PGAS), PSAEM obtains superior computational performance and\nconvergence properties compared to plain particle-smoothing-based\napproximations of the EM algorithm. PSAEM can be used for plain maximum\nlikelihood inference as well as for empirical Bayes learning of\nhyperparameters. Specifically, the latter point means that existing PGAS\nimplementations easily can be extended with PSAEM to estimate hyperparameters\nat almost no extra computational cost. We discuss the convergence properties of\nthe algorithm, and demonstrate it on several signal processing applications.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 16:12:35 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 10:38:50 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Lindholm", "Andreas", ""], ["Lindsten", "Fredrik", ""]]}, {"id": "1806.09550", "submitter": "Tom Rainforth", "authors": "Tom Rainforth, Yuan Zhou, Xiaoyu Lu, Yee Whye Teh, Frank Wood,\n  Hongseok Yang, Jan-Willem van de Meent", "title": "Inference Trees: Adaptive Inference with Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce inference trees (ITs), a new class of inference methods that\nbuild on ideas from Monte Carlo tree search to perform adaptive sampling in a\nmanner that balances exploration with exploitation, ensures consistency, and\nalleviates pathologies in existing adaptive methods. ITs adaptively sample from\nhierarchical partitions of the parameter space, while simultaneously learning\nthese partitions in an online manner. This enables ITs to not only identify\nregions of high posterior mass, but also maintain uncertainty estimates to\ntrack regions where significant posterior mass may have been missed. ITs can be\nbased on any inference method that provides a consistent estimate of the\nmarginal likelihood. They are particularly effective when combined with\nsequential Monte Carlo, where they capture long-range dependencies and yield\nimprovements beyond proposal adaptation alone.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 16:13:23 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Rainforth", "Tom", ""], ["Zhou", "Yuan", ""], ["Lu", "Xiaoyu", ""], ["Teh", "Yee Whye", ""], ["Wood", "Frank", ""], ["Yang", "Hongseok", ""], ["van de Meent", "Jan-Willem", ""]]}, {"id": "1806.09780", "submitter": "Johan Dahlin PhD", "authors": "Johan Dahlin, Adrian Wills, Brett Ninness", "title": "Correlated pseudo-marginal Metropolis-Hastings using quasi-Newton\n  proposals", "comments": "45 pages and 11 figures. Submitted to journal. Fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pseudo-marginal Metropolis-Hastings (pmMH) is a versatile algorithm for\nsampling from target distributions which are not easy to evaluate point-wise.\nHowever, pmMH requires good proposal distributions to sample efficiently from\nthe target, which can be problematic to construct in practice. This is\nespecially a problem for high-dimensional targets when the standard random-walk\nproposal is inefficient. We extend pmMH to allow for constructing the proposal\nbased on information from multiple past iterations. As a consequence,\nquasi-Newton (qN) methods can be employed to form proposals which utilize\ngradient information to guide the Markov chain to areas of high probability and\nto construct approximations of the local curvature to scale step sizes. The\nproposed method is demonstrated on several problems which indicate that qN\nproposals can perform better than other common Hessian-based proposals.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 03:17:45 GMT"}, {"version": "v2", "created": "Fri, 27 Jul 2018 01:21:24 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Dahlin", "Johan", ""], ["Wills", "Adrian", ""], ["Ninness", "Brett", ""]]}, {"id": "1806.10009", "submitter": "Yong Luo", "authors": "Luo Yong", "title": "Item Parameter Recovery for the Two-Parameter Testlet Model with\n  Different Estimation Methods", "comments": "36 pages, 6 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The testlet model is a popular statistical approach widely used by\nresearchers and practitioners to address local item dependence (LID), a\nviolation of the local independence assumption in item response theory (IRT)\nwhich can cause various deleterious psychometric consequences. Same as other\npsychometric models, the utility of the testlet model relies heavily on\naccurate estimation of its model parameters. The two-parameter logistic (2PL)\ntestlet model has only been systematically investigated in the psychometric\nliterature regarding its model parameter recovery with one full information\nestimation methods, namely Markov chain Monte Carlo (MCMC) method, although\nthere are other estimation methods available such as marginal maximum\nlikelihood estimation (MMLE) and limited information estimation methods.\n  In the current study, a comprehensive simulation study was conducted to\ninvestigate how MCMC, MMLE, and one limited information estimation method\n(WLSMV), all implemented in Mplus, recovered the item parameters and the\ntestlet variance parameter of the 2PL testlet model. The manipulated factors\nwere sample size and testlet effect magnitude, and parameter recovery were\nevaluated with bias, standard error, and root mean square error. We found that\nthere were no statistically significant differences regarding parameter\nrecovery between the three methods. When both sample size and magnitude of\ntestlet variance were small, both WLSMV and MCMC had convergence issues, which\ndid not occur to MCMC regardless of sample size and testlet variance. A real\ndataset from a high-stakes test was used to demonstrate the estimation of the\n2PL testlet model with the three estimation methods.\n  Keywords: IRT, testlet model, estimation, full-information,\nlimited-information.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 14:07:36 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Yong", "Luo", ""]]}, {"id": "1806.10060", "submitter": "Sebastian Schmon", "authors": "Sebastian M. Schmon, George Deligiannidis, Arnaud Doucet, Michael K.\n  Pitt", "title": "Large Sample Asymptotics of the Pseudo-Marginal Method", "comments": "76 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pseudo-marginal algorithm is a variant of the Metropolis--Hastings\nalgorithm which samples asymptotically from a probability distribution when it\nis only possible to estimate unbiasedly an unnormalized version of its density.\nPractically, one has to trade-off the computational resources used to obtain\nthis estimator against the asymptotic variances of the ergodic averages\nobtained by the pseudo-marginal algorithm. Recent works optimizing this\ntrade-off rely on some strong assumptions which can cast doubts over their\npractical relevance. In particular, they all assume that the distribution of\nthe difference between the log-density and its estimate is independent of the\nparameter value at which it is evaluated. Under regularity conditions we show\nhere that, as the number of data points tends to infinity, a space-rescaled\nversion of the pseudo-marginal chain converges weakly towards another\npseudo-marginal chain for which this assumption indeed holds. A study of this\nlimiting chain allows us to provide parameter dimension-dependent guidelines on\nhow to optimally scale a normal random walk proposal and the number of Monte\nCarlo samples for the pseudo-marginal method in the large-sample regime. This\ncomplements and validates currently available results.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 15:22:03 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2019 21:20:46 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Schmon", "Sebastian M.", ""], ["Deligiannidis", "George", ""], ["Doucet", "Arnaud", ""], ["Pitt", "Michael K.", ""]]}, {"id": "1806.10234", "submitter": "Jonathan Huggins", "authors": "Jonathan H. Huggins, Trevor Campbell, Miko{\\l}aj Kasprzak, Tamara\n  Broderick", "title": "Scalable Gaussian Process Inference with Finite-data Mean and Variance\n  Guarantees", "comments": "20 pages, 7 figures, 1 table, including Appendix. Code available at\n  https://github.com/trevorcampbell/fishergp", "journal-ref": "Proceedings of the 22nd International Conference on Artificial\n  Intelligence and Statistics (AISTATS) 2019, Naha, Okinawa, Japan. PMLR:\n  Volume 89", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) offer a flexible class of priors for nonparametric\nBayesian regression, but popular GP posterior inference methods are typically\nprohibitively slow or lack desirable finite-data guarantees on quality. We\ndevelop an approach to scalable approximate GP regression with finite-data\nguarantees on the accuracy of pointwise posterior mean and variance estimates.\nOur main contribution is a novel objective for approximate inference in the\nnonparametric setting: the preconditioned Fisher (pF) divergence. We show that\nunlike the Kullback--Leibler divergence (used in variational inference), the pF\ndivergence bounds the 2-Wasserstein distance, which in turn provides tight\nbounds the pointwise difference of the mean and variance functions. We\ndemonstrate that, for sparse GP likelihood approximations, we can minimize the\npF divergence efficiently. Our experiments show that optimizing the pF\ndivergence has the same computational requirements as variational sparse GPs\nwhile providing comparable empirical performance--in addition to our novel\nfinite-data quality guarantees.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2018 22:42:15 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 16:49:53 GMT"}, {"version": "v3", "created": "Sat, 2 Mar 2019 21:24:19 GMT"}, {"version": "v4", "created": "Wed, 27 Mar 2019 13:50:14 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Huggins", "Jonathan H.", ""], ["Campbell", "Trevor", ""], ["Kasprzak", "Miko\u0142aj", ""], ["Broderick", "Tamara", ""]]}, {"id": "1806.10404", "submitter": "Matthias Troffaes", "authors": "Matthias C. M. Troffaes", "title": "Imprecise Monte Carlo simulation and iterative importance sampling for\n  the estimation of lower previsions", "comments": "24 pages, 5 tables", "journal-ref": "International Journal of Approximate Reasoning 101 (2018) 31-48", "doi": "10.1016/j.ijar.2018.06.009", "report-no": null, "categories": "stat.CO math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a theoretical framework for studying numerical estimation of lower\nprevisions, generally applicable to two-level Monte Carlo methods, importance\nsampling methods, and a wide range of other sampling methods one might devise.\nWe link consistency of these estimators to Glivenko-Cantelli classes, and for\nthe sub-Gaussian case we show how the correlation structure of this process can\nbe used to bound the bias and prove consistency. We also propose a new upper\nestimator, which can be used along with the standard lower estimator, in order\nto provide a simple confidence interval. As a case study of this framework, we\nthen discuss how importance sampling can be exploited to provide accurate\nnumerical estimates of lower previsions. We propose an iterative importance\nsampling method to drastically improve the performance of imprecise importance\nsampling. We demonstrate our results on the imprecise Dirichlet model.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 10:46:52 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Troffaes", "Matthias C. M.", ""]]}, {"id": "1806.10423", "submitter": "Zhentao Shi", "authors": "Zhan Gao, Zhentao Shi", "title": "Implementing Convex Optimization in R: Two Econometric Examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO econ.EM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Economists specify high-dimensional models to address heterogeneity in\nempirical studies with complex big data. Estimation of these models calls for\noptimization techniques to handle a large number of parameters. Convex problems\ncan be effectively executed in modern statistical programming languages. We\ncomplement Koenker and Mizera (2014)'s work on numerical implementation of\nconvex optimization, with focus on high-dimensional econometric estimators.\nCombining R and the convex solver MOSEK achieves faster speed and equivalent\naccuracy, demonstrated by examples from Su, Shi, and Phillips (2016) and Shi\n(2016). Robust performance of convex optimization is witnessed cross platforms.\nThe convenience and reliability of convex optimization in R make it easy to\nturn new ideas into prototypes.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2018 11:50:26 GMT"}, {"version": "v2", "created": "Sat, 3 Aug 2019 16:35:22 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Gao", "Zhan", ""], ["Shi", "Zhentao", ""]]}, {"id": "1806.10761", "submitter": "Benjamin Peherstorfer", "authors": "Benjamin Peherstorfer, Karen Willcox, Max Gunzburger", "title": "Survey of multifidelity methods in uncertainty propagation, inference,\n  and optimization", "comments": "will appear in SIAM Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.NA stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many situations across computational science and engineering, multiple\ncomputational models are available that describe a system of interest. These\ndifferent models have varying evaluation costs and varying fidelities.\nTypically, a computationally expensive high-fidelity model describes the system\nwith the accuracy required by the current application at hand, while\nlower-fidelity models are less accurate but computationally cheaper than the\nhigh-fidelity model. Outer-loop applications, such as optimization, inference,\nand uncertainty quantification, require multiple model evaluations at many\ndifferent inputs, which often leads to computational demands that exceed\navailable resources if only the high-fidelity model is used. This work surveys\nmultifidelity methods that accelerate the solution of outer-loop applications\nby combining high-fidelity and low-fidelity model evaluations, where the\nlow-fidelity evaluations arise from an explicit low-fidelity model (e.g., a\nsimplified physics approximation, a reduced model, a data-fit surrogate, etc.)\nthat approximates the same output quantity as the high-fidelity model. The\noverall premise of these multifidelity methods is that low-fidelity models are\nleveraged for speedup while the high-fidelity model is kept in the loop to\nestablish accuracy and/or convergence guarantees. We categorize multifidelity\nmethods according to three classes of strategies: adaptation, fusion, and\nfiltering. The paper reviews multifidelity methods in the outer-loop contexts\nof uncertainty propagation, inference, and optimization.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 04:06:17 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Peherstorfer", "Benjamin", ""], ["Willcox", "Karen", ""], ["Gunzburger", "Max", ""]]}, {"id": "1806.11021", "submitter": "Xiaofei Wang", "authors": "Xiaofei Wang and Michael John Kane", "title": "fc: A Package for Generalized Function Composition Using Standard\n  Evaluation", "comments": "To be submitted to RJournal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a new R package fc that provides a streamlined,\nstandard evaluation-based approach to function composition. Using fc, a\nsequence of functions can be composed together such that returned objects from\ncomposed functions are used as intermediate values directly passed to the next\nfunction. Unlike with magrittr and purrr, no intermediate values need to be\nstored. When benchmarked, functions composed using fc achieve favorable\nruntimes in comparison to other implementations.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 14:59:16 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["Wang", "Xiaofei", ""], ["Kane", "Michael John", ""]]}, {"id": "1806.11032", "submitter": "Antonio El\\'ias Fern\\'andez", "authors": "Antonio El\\'ias and Ra\\'ul Jim\\'enez", "title": "A depth-based method for functional time series forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An approach is presented for making predictions about functional time series.\nThe method is applied to data coming from periodically correlated processes and\nelectricity demand, obtaining accurate point forecasts and narrow prediction\nbands that cover high proportions of the forecasted functional datum, for a\ngiven confidence level. The method is computationally efficient and\nsubstantially different to other functional time series methods, offering a new\ninsight for the analysis of these data structures.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 15:22:43 GMT"}], "update_date": "2018-06-29", "authors_parsed": [["El\u00edas", "Antonio", ""], ["Jim\u00e9nez", "Ra\u00fal", ""]]}, {"id": "1806.11220", "submitter": "Sixing Chen", "authors": "Sixing Chen, Jukka-Pekka Onnela", "title": "A Bootstrap Method for Goodness of Fit and Model Selection with a Single\n  Observed Network", "comments": "21 pages, 6 figures, presented at Netsci 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network models are applied in numerous domains where data can be represented\nas a system of interactions among pairs of actors. While both statistical and\nmechanistic network models are increasingly capable of capturing various\ndependencies amongst these actors, these dependencies imply the lack of\nindependence. This poses statistical challenges for analyzing such data,\nespecially when there is only a single observed network, and often leads to\nintractable likelihoods regardless of the modeling paradigm, which limit the\napplication of existing statistical methods for networks. We explore a\nsubsampling bootstrap procedure to serve as the basis for goodness of fit and\nmodel selection with a single observed network that circumvents the\nintractability of such likelihoods. Our approach is based on flexible\nresampling distributions formed from the single observed network, allowing for\nfiner and higher dimensional comparisons than simply point estimates of\nquantities of interest. We include worked examples for model selection, with\nsimulation, and assessment of goodness of fit, with duplication-divergence\nmodel fits for yeast (S.cerevisiae) protein-protein interaction data from the\nliterature. The proposed procedure produces a flexible resampling distribution\nthat can be based on any statistics of one's choosing and can be employed\nregardless of choice of model.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 22:24:42 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Chen", "Sixing", ""], ["Onnela", "Jukka-Pekka", ""]]}, {"id": "1806.11276", "submitter": "Caitlin Gray", "authors": "Caitlin Gray, Lewis Mitchell, Matthew Roughan", "title": "Generating Connected Random Graphs", "comments": "Added references, Expanded Implementation - same conclusions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DS stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling random graphs is essential in many applications, and often\nalgorithms use Markov chain Monte Carlo methods to sample uniformly from the\nspace of graphs. However, often there is a need to sample graphs with some\nproperty that we are unable, or it is too inefficient, to sample using standard\napproaches. In this paper, we are interested in sampling graphs from a\nconditional ensemble of the underlying graph model. We present an algorithm to\ngenerate samples from an ensemble of connected random graphs using a\nMetropolis-Hastings framework. The algorithm extends to a general framework for\nsampling from a known distribution of graphs, conditioned on a desired\nproperty. We demonstrate the method to generate connected spatially embedded\nrandom graphs, specifically the well known Waxman network, and illustrate the\nconvergence and practicalities of the algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 06:03:20 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 00:54:04 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Gray", "Caitlin", ""], ["Mitchell", "Lewis", ""], ["Roughan", "Matthew", ""]]}, {"id": "1806.11388", "submitter": "Matthew Edwards", "authors": "Matthew Edwards, Stefano Castruccio and Dorit Hammerling", "title": "Marginally Parametrized Spatio-Temporal Models and Stepwise Maximum\n  Likelihood Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to learn the complex features of large spatio-temporal data, models\nwith large parameter sets are often required. However, estimating a large\nnumber of parameters is often infeasible due to the computational and memory\ncosts of maximum likelihood estimation (MLE). We introduce the class of\nmarginally parametrized (MP) models, where inference can be performed\nefficiently with a sequence of marginal (estimated) likelihood functions via\nstepwise maximum likelihood estimation (SMLE). We provide the conditions under\nwhich the stepwise estimators are consistent, and we prove that this class of\nmodels includes the diagonal vector autoregressive moving average model. We\ndemonstrate that the parameters of this model can be obtained at least three\norders of magnitude faster using SMLE compared to MLE, with only a small loss\nin statistical efficiency. We apply an MP model to a spatio-temporal global\nclimate data set (in order to learn complex features of interest to climate\nscientists) consisting of over five million data points, and we demonstrate how\nestimation can be performed in less than an hour on a laptop.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 12:56:02 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Edwards", "Matthew", ""], ["Castruccio", "Stefano", ""], ["Hammerling", "Dorit", ""]]}]