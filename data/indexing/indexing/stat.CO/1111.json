[{"id": "1111.0433", "submitter": "Jouni Kerman", "authors": "Jouni Kerman", "title": "A closed-form approximation for the median of the beta distribution", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A simple closed-form approximation for the median of the beta distribution\nBeta(a, b) is introduced: (a-1/3)/(a+b-2/3) for (a,b) both larger than 1 has a\nrelative error of less than 4%, rapidly decreasing to zero as both shape\nparameters increase.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 09:28:16 GMT"}], "update_date": "2011-11-03", "authors_parsed": [["Kerman", "Jouni", ""]]}, {"id": "1111.0522", "submitter": "Charles Soussen", "authors": "Charles Soussen, R\\'emi Gribonval, J\\'er\\^ome Idier, and C\\'edric\n  Herzet", "title": "Joint k-step analysis of Orthogonal Matching Pursuit and Orthogonal\n  Least Squares", "comments": "39 pages", "journal-ref": "IEEE Transactions on Information Theory, vol. 59, no. 5, May 2013,\n  pp. 3158-3174", "doi": "10.1109/TIT.2013.2238606", "report-no": null, "categories": "stat.CO physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tropp's analysis of Orthogonal Matching Pursuit (OMP) using the Exact\nRecovery Condition (ERC) is extended to a first exact recovery analysis of\nOrthogonal Least Squares (OLS). We show that when the ERC is met, OLS is\nguaranteed to exactly recover the unknown support in at most k iterations.\nMoreover, we provide a closer look at the analysis of both OMP and OLS when the\nERC is not fulfilled. The existence of dictionaries for which some subsets are\nnever recovered by OMP is proved. This phenomenon also appears with basis\npursuit where support recovery depends on the sign patterns, but it does not\noccur for OLS. Finally, numerical experiments show that none of the considered\nalgorithms is uniformly better than the other but for correlated dictionaries,\nguaranteed exact recovery may be obtained after fewer iterations for OLS than\nfor OMP.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 15:02:11 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2012 18:57:48 GMT"}], "update_date": "2013-04-25", "authors_parsed": [["Soussen", "Charles", ""], ["Gribonval", "R\u00e9mi", ""], ["Idier", "J\u00e9r\u00f4me", ""], ["Herzet", "C\u00e9dric", ""]]}, {"id": "1111.0574", "submitter": "Christian Sch\\\"afer", "authors": "Christian Sch\\\"afer", "title": "Particle algorithms for optimization on binary spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a unified approach to stochastic optimization of pseudo-Boolean\nobjective functions based on particle methods, including the cross-entropy\nmethod and simulated annealing as special cases. We point out the need for\nauxiliary sampling distributions, that is parametric families on binary spaces,\nwhich are able to reproduce complex dependency structures, and illustrate their\nusefulness in our numerical experiments. We provide numerical evidence that\nparticle-driven optimization algorithms based on parametric families yield\nsuperior results on strongly multi-modal optimization problems while local\nsearch heuristics outperform them on easier problems.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 17:32:23 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2012 16:42:56 GMT"}], "update_date": "2012-04-09", "authors_parsed": [["Sch\u00e4fer", "Christian", ""]]}, {"id": "1111.0576", "submitter": "Christian Sch\\\"afer", "authors": "Christian Sch\\\"afer", "title": "On parametric families for sampling binary data with specified mean and\n  correlation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a class of binary parametric families with conditional\nprobabilities taking the form of generalized linear models and show that this\napproach allows to model high-dimensional random binary vectors with arbitrary\nmean and correlation. We derive the special case of logistic conditionals as an\napproximation to the Ising-type exponential distribution and provide empirical\nevidence that this parametric family indeed outperforms competing approaches in\nterms of feasible correlations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2011 17:36:27 GMT"}, {"version": "v2", "created": "Mon, 14 Nov 2011 18:14:46 GMT"}, {"version": "v3", "created": "Wed, 25 Jan 2012 16:58:40 GMT"}, {"version": "v4", "created": "Fri, 6 Apr 2012 16:33:28 GMT"}], "update_date": "2012-04-09", "authors_parsed": [["Sch\u00e4fer", "Christian", ""]]}, {"id": "1111.0641", "submitter": "Daniel Simpson", "authors": "Daniel Simpson, Janine Illian, Finn Lindgren, Sigrunn S{\\o}rbye and\n  H{\\aa}vard Rue", "title": "Going off grid: Computationally efficient inference for log-Gaussian Cox\n  processes", "comments": "22 Pages, 8 figures", "journal-ref": null, "doi": null, "report-no": "NTNU Department of Mathematics Statistics Technical Report 9/2011", "categories": "stat.CO math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new method for performing computational inference on\nlog-Gaussian Cox processes. The likelihood is approximated directly by making\nnovel use of a continuously specified Gaussian random field. We show that for\nsufficiently smooth Gaussian random field prior distributions, the\napproximation can converge with arbitrarily high order, while an approximation\nbased on a counting process on a partition of the domain only achieves\nfirst-order convergence. The given results improve on the general theory of\nconvergence of the stochastic partial differential equation models, introduced\nby Lindgren et al. (2011). The new method is demonstrated on a standard point\npattern data set and two interesting extensions to the classical log-Gaussian\nCox process framework are discussed. The first extension considers variable\nsampling effort throughout the observation window and implements the method of\nChakraborty et al. (2011). The second extension constructs a log-Gaussian Cox\nprocess on the world's oceans. The analysis is performed using integrated\nnested Laplace approximation for fast approximate inference.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2011 17:56:10 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2013 08:53:15 GMT"}, {"version": "v3", "created": "Fri, 30 Oct 2015 18:46:25 GMT"}], "update_date": "2015-11-02", "authors_parsed": [["Simpson", "Daniel", ""], ["Illian", "Janine", ""], ["Lindgren", "Finn", ""], ["S\u00f8rbye", "Sigrunn", ""], ["Rue", "H\u00e5vard", ""]]}, {"id": "1111.1308", "submitter": "Maxime Lenormand", "authors": "Maxime Lenormand (UR LISC), Franck Jabot (UR LISC), Guillaume Deffuant\n  (UR LISC)", "title": "Adaptive approximate Bayesian computation for complex models", "comments": "14 pages, 5 figures", "journal-ref": "Computational Statistics 28, 2777-2796 (2013)", "doi": "10.1007/s00180-013-0428-3", "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian computation (ABC) is a family of computational\ntechniques in Bayesian statistics. These techniques allow to fi t a model to\ndata without relying on the computation of the model likelihood. They instead\nrequire to simulate a large number of times the model to be fi tted. A number\nof re finements to the original rejection-based ABC scheme have been proposed,\nincluding the sequential improvement of posterior distributions. This technique\nallows to de- crease the number of model simulations required, but it still\npresents several shortcomings which are particu- larly problematic for costly\nto simulate complex models. We here provide a new algorithm to perform adaptive\napproximate Bayesian computation, which is shown to perform better on both a\ntoy example and a complex social model.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2011 13:50:53 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2012 21:09:39 GMT"}, {"version": "v3", "created": "Tue, 31 Jul 2012 06:46:11 GMT"}, {"version": "v4", "created": "Thu, 7 May 2015 13:09:44 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Lenormand", "Maxime", "", "UR LISC"], ["Jabot", "Franck", "", "UR LISC"], ["Deffuant", "Guillaume", "", "UR LISC"]]}, {"id": "1111.1400", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin, Michael Styer, Zachary Moratto, Ara Nefian,\n  Michael Broxton", "title": "Student's T Robust Bundle Adjustment Algorithm", "comments": "8 pages. Originally written in November 2009. Describes\n  implementation of Robust Bundle Adjustment in NASA's VisionWorkbench package,\n  available at https://github.com/visionworkbench/visionworkbench", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.GR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bundle adjustment (BA) is the problem of refining a visual reconstruction to\nproduce better structure and viewing parameter estimates. This problem is often\nformulated as a nonlinear least squares problem, where data arises from\ninterest point matching. Mismatched interest points cause serious problems in\nthis approach, as a single mismatch will affect the entire reconstruction. In\nthis paper, we propose a novel robust Student's t BA algorithm (RST-BA). We\nmodel reprojection errors using the heavy tailed Student's t-distribution, and\nuse an implicit trust region method to compute the maximum a posteriori (MAP)\nestimate of the camera and viewing parameters in this model. The resulting\nalgorithm exploits the sparse structure essential for reconstructing\nmulti-image scenarios, has the same time complexity as standard L2 bundle\nadjustment (L2-BA), and can be implemented with minimal changes to the standard\nleast squares framework. We show that the RST-BA is more accurate than either\nL2-BA or L2-BA with a sigma-edit rule for outlier removal for a range of\nsimulated error generation scenarios. The new method has also been used to\nreconstruct lunar topography using data from the NASA Apollo 15 orbiter, and we\npresent visual and quantitative comparisons of RST-BA and L2-BA methods for\nthis application. In particular, using the RST-BA algorithm we were able to\nreconstruct a DEM from unprocessed data with many outliers and no ground\ncontrol points, which was not possible with the L2-BA method.\n", "versions": [{"version": "v1", "created": "Sun, 6 Nov 2011 10:56:13 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Styer", "Michael", ""], ["Moratto", "Zachary", ""], ["Nefian", "Ara", ""], ["Broxton", "Michael", ""]]}, {"id": "1111.1687", "submitter": "Noah Simon", "authors": "Noah Simon and Rob Tibshirani", "title": "Discriminant Analysis with Adaptively Pooled Covariance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear and Quadratic Discriminant analysis (LDA/QDA) are common tools for\nclassification problems. For these methods we assume observations are normally\ndistributed within group. We estimate a mean and covariance matrix for each\ngroup and classify using Bayes theorem. With LDA, we estimate a single, pooled\ncovariance matrix, while for QDA we estimate a separate covariance matrix for\neach group. Rarely do we believe in a homogeneous covariance structure between\ngroups, but often there is insufficient data to separately estimate covariance\nmatrices. We propose L1- PDA, a regularized model which adaptively pools\nelements of the precision matrices. Adaptively pooling these matrices decreases\nthe variance of our estimates (as in LDA), without overly biasing them. In this\npaper, we propose and discuss this method, give an efficient algorithm to fit\nit for moderate sized problems, and show its efficacy on real and simulated\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2011 19:30:13 GMT"}, {"version": "v2", "created": "Tue, 6 Dec 2011 23:45:34 GMT"}], "update_date": "2011-12-08", "authors_parsed": [["Simon", "Noah", ""], ["Tibshirani", "Rob", ""]]}, {"id": "1111.2667", "submitter": "Benjamin Rolfs", "authors": "Benjamin T. Rolfs, Bala Rajaratnam", "title": "A note on the lack of symmetry in the graphical lasso", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graphical lasso (glasso) is a widely-used fast algorithm for estimating\nsparse inverse covariance matrices. The glasso solves an L1 penalized maximum\nlikelihood problem and is available as an R library on CRAN. The output from\nthe glasso, a regularized covariance matrix estimate a sparse inverse\ncovariance matrix estimate, not only identify a graphical model but can also\nserve as intermediate inputs into multivariate procedures such as PCA, LDA,\nMANOVA, and others. The glasso indeed produces a covariance matrix estimate\nwhich solves the L1 penalized optimization problem in a dual sense; however,\nthe method for producing the inverse covariance matrix estimator after this\noptimization is inexact and may produce asymmetric estimates. This problem is\nexacerbated when the amount of L1 regularization that is applied is small,\nwhich in turn is more likely to occur if the true underlying inverse covariance\nmatrix is not sparse. The lack of symmetry can potentially have consequences.\nFirst, it implies that the covariance and inverse covariance estimates are not\nnumerical inverses of one another, and second, asymmetry can possibly lead to\nnegative or complex eigenvalues,rendering many multivariate procedures which\nmay depend on the inverse covariance estimator unusable. We demonstrate this\nproblem, explain its causes, and propose possible remedies.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2011 05:51:44 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2012 22:58:52 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Rolfs", "Benjamin T.", ""], ["Rajaratnam", "Bala", ""]]}, {"id": "1111.2730", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin, James V. Burke, Gianluigi Pillonetto", "title": "A statistical and computational theory for robust and sparse Kalman\n  smoothing", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.ST stat.AP stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kalman smoothers reconstruct the state of a dynamical system starting from\nnoisy output samples. While the classical estimator relies on quadratic\npenalization of process deviations and measurement errors, extensions that\nexploit Piecewise Linear Quadratic (PLQ) penalties have been recently proposed\nin the literature. These new formulations include smoothers robust with respect\nto outliers in the data, and smoothers that keep better track of fast system\ndynamics, e.g. jumps in the state values. In addition to L2, well known\nexamples of PLQ penalties include the L1, Huber and Vapnik losses. In this\npaper, we use a dual representation for PLQ penalties to build a statistical\nmodeling framework and a computational theory for Kalman smoothing.\n  We develop a statistical framework by establishing conditions required to\ninterpret PLQ penalties as negative logs of true probability densities. Then,\nwe present a computational framework, based on interior-point methods, that\nsolves the Kalman smoothing problem with PLQ penalties and maintains the linear\ncomplexity in the size of the time series, just as in the L2 case. The\nframework presented extends the computational efficiency of the Mayne-Fraser\nand Rauch-Tung-Striebel algorithms to a much broader non-smooth setting, and\nincludes many known robust and sparse smoothers as special cases.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2011 13:06:55 GMT"}], "update_date": "2011-11-14", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Burke", "James V.", ""], ["Pillonetto", "Gianluigi", ""]]}, {"id": "1111.4157", "submitter": "Tuhin Sahai", "authors": "Tuhin Sahai and Jose Miguel Pasini", "title": "Uncertainty Quantification in Hybrid Dynamical Systems", "comments": null, "journal-ref": "Journal of Computational Physics, vol. 237, pp. 411-427 (2013)", "doi": "10.1016/j.jcp.2012.10.030", "report-no": null, "categories": "stat.CO math.DS stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty quantification (UQ) techniques are frequently used to ascertain\noutput variability in systems with parametric uncertainty. Traditional\nalgorithms for UQ are either system-agnostic and slow (such as Monte Carlo) or\nfast with stringent assumptions on smoothness (such as polynomial chaos and\nQuasi-Monte Carlo). In this work, we develop a fast UQ approach for hybrid\ndynamical systems by extending the polynomial chaos methodology to these\nsystems. To capture discontinuities, we use a wavelet-based Wiener-Haar\nexpansion. We develop a boundary layer approach to propagate uncertainty\nthrough separable reset conditions. We also introduce a transport theory based\napproach for propagating uncertainty through hybrid dynamical systems. Here the\nexpansion yields a set of hyperbolic equations that are solved by integrating\nalong characteristics. The solution of the partial differential equation along\nthe characteristics allows one to quantify uncertainty in hybrid or switching\ndynamical systems. The above methods are demonstrated on example problems.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2011 17:20:29 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2012 17:14:50 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Sahai", "Tuhin", ""], ["Pasini", "Jose Miguel", ""]]}, {"id": "1111.4246", "submitter": "Matthew Hoffman", "authors": "Matthew D. Hoffman and Andrew Gelman", "title": "The No-U-Turn Sampler: Adaptively Setting Path Lengths in Hamiltonian\n  Monte Carlo", "comments": "30 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo (HMC) is a Markov chain Monte Carlo (MCMC) algorithm\nthat avoids the random walk behavior and sensitivity to correlated parameters\nthat plague many MCMC methods by taking a series of steps informed by\nfirst-order gradient information. These features allow it to converge to\nhigh-dimensional target distributions much more quickly than simpler methods\nsuch as random walk Metropolis or Gibbs sampling. However, HMC's performance is\nhighly sensitive to two user-specified parameters: a step size {\\epsilon} and a\ndesired number of steps L. In particular, if L is too small then the algorithm\nexhibits undesirable random walk behavior, while if L is too large the\nalgorithm wastes computation. We introduce the No-U-Turn Sampler (NUTS), an\nextension to HMC that eliminates the need to set a number of steps L. NUTS uses\na recursive algorithm to build a set of likely candidate points that spans a\nwide swath of the target distribution, stopping automatically when it starts to\ndouble back and retrace its steps. Empirically, NUTS perform at least as\nefficiently as and sometimes more efficiently than a well tuned standard HMC\nmethod, without requiring user intervention or costly tuning runs. We also\nderive a method for adapting the step size parameter {\\epsilon} on the fly\nbased on primal-dual averaging. NUTS can thus be used with no hand-tuning at\nall. NUTS is also suitable for applications such as BUGS-style automatic\ninference engines that require efficient \"turnkey\" sampling algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2011 00:39:32 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Hoffman", "Matthew D.", ""], ["Gelman", "Andrew", ""]]}, {"id": "1111.4802", "submitter": "Emmanuel Vazquez", "authors": "Romain Benassi and Julien Bect and Emmanuel Vazquez", "title": "Bayesian optimization using sequential Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of optimizing a real-valued continuous function $f$\nusing a Bayesian approach, where the evaluations of $f$ are chosen sequentially\nby combining prior information about $f$, which is described by a random\nprocess model, and past evaluation results. The main difficulty with this\napproach is to be able to compute the posterior distributions of quantities of\ninterest which are used to choose evaluation points. In this article, we decide\nto use a Sequential Monte Carlo (SMC) approach.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 09:47:51 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Benassi", "Romain", ""], ["Bect", "Julien", ""], ["Vazquez", "Emmanuel", ""]]}, {"id": "1111.4942", "submitter": "Luca Martino", "authors": "Luca Martino and Joaqu\\'in M\\'iguez", "title": "Two adaptive rejection sampling schemes for probability density\n  functions log-convex tails", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo methods are often necessary for the implementation of optimal\nBayesian estimators. A fundamental technique that can be used to generate\nsamples from virtually any target probability distribution is the so-called\nrejection sampling method, which generates candidate samples from a proposal\ndistribution and then accepts them or not by testing the ratio of the target\nand proposal densities. The class of adaptive rejection sampling (ARS)\nalgorithms is particularly interesting because they can achieve high acceptance\nrates. However, the standard ARS method can only be used with log-concave\ntarget densities. For this reason, many generalizations have been proposed.\n  In this work, we investigate two different adaptive schemes that can be used\nto draw exactly from a large family of univariate probability density functions\n(pdf's), not necessarily log-concave, possibly multimodal and with tails of\narbitrary concavity. These techniques are adaptive in the sense that every time\na candidate sample is rejected, the acceptance rate is improved. The two\nproposed algorithms can work properly when the target pdf is multimodal, with\nfirst and second derivatives analytically intractable, and when the tails are\nlog-convex in a infinite domain. Therefore, they can be applied in a number of\nscenarios in which the other generalizations of the standard ARS fail. Two\nillustrative numerical examples are shown.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 17:24:21 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Martino", "Luca", ""], ["M\u00edguez", "Joaqu\u00edn", ""]]}, {"id": "1111.4954", "submitter": "Forrest Crawford", "authors": "Forrest W. Crawford and Vladimir N. Minin and Marc A. Suchard", "title": "Estimation for general birth-death processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.PE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Birth-death processes (BDPs) are continuous-time Markov chains that track the\nnumber of \"particles\" in a system over time. While widely used in population\nbiology, genetics and ecology, statistical inference of the instantaneous\nparticle birth and death rates remains largely limited to restrictive linear\nBDPs in which per-particle birth and death rates are constant. Researchers\noften observe the number of particles at discrete times, necessitating data\naugmentation procedures such as expectation-maximization (EM) to find maximum\nlikelihood estimates. The E-step in the EM algorithm is available in\nclosed-form for some linear BDPs, but otherwise previous work has resorted to\napproximation or simulation. Remarkably, the E-step conditional expectations\ncan also be expressed as convolutions of computable transition probabilities\nfor any general BDP with arbitrary rates. This important observation, along\nwith a convenient continued fraction representation of the Laplace transforms\nof the transition probabilities, allows novel and efficient computation of the\nconditional expectations for all BDPs, eliminating the need for approximation\nor costly simulation. We use this insight to derive EM algorithms that yield\nmaximum likelihood estimation for general BDPs characterized by various rate\nmodels, including generalized linear models. We show that our Laplace\nconvolution technique outperforms competing methods when available and\ndemonstrate a technique to accelerate EM algorithm convergence. Finally, we\nvalidate our approach using synthetic data and then apply our methods to\nestimation of mutation parameters in microsatellite evolution.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2011 17:55:48 GMT"}], "update_date": "2011-11-22", "authors_parsed": [["Crawford", "Forrest W.", ""], ["Minin", "Vladimir N.", ""], ["Suchard", "Marc A.", ""]]}, {"id": "1111.5379", "submitter": "Ziyu Wang", "authors": "Firas Hamze, Ziyu Wang, Nando de Freitas", "title": "Self-Avoiding Random Dynamics on Integer Complex Systems", "comments": "22 pages. 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cond-mat.dis-nn physics.comp-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new specialized algorithm for equilibrium Monte Carlo\nsampling of binary-valued systems, which allows for large moves in the state\nspace. This is achieved by constructing self-avoiding walks (SAWs) in the state\nspace. As a consequence, many bits are flipped in a single MCMC step. We name\nthe algorithm SARDONICS, an acronym for Self-Avoiding Random Dynamics on\nInteger Complex Systems. The algorithm has several free parameters, but we show\nthat Bayesian optimization can be used to automatically tune them. SARDONICS\nperforms remarkably well in a broad number of sampling tasks: toroidal\nferromagnetic and frustrated Ising models, 3D Ising models, restricted\nBoltzmann machines and chimera graphs arising in the design of quantum\ncomputers.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 00:50:15 GMT"}, {"version": "v2", "created": "Fri, 25 Nov 2011 23:20:54 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Hamze", "Firas", ""], ["Wang", "Ziyu", ""], ["de Freitas", "Nando", ""]]}, {"id": "1111.5421", "submitter": "Christophe Andrieu", "authors": "Christophe Andrieu, Matti Vihola", "title": "Markovian stochastic approximation with expanding projections", "comments": "Published in at http://dx.doi.org/10.3150/12-BEJ497 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2014, Vol. 20, No. 2, 545-585", "doi": "10.3150/12-BEJ497", "report-no": "IMS-BEJ-BEJ497", "categories": "math.PR stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic approximation is a framework unifying many random iterative\nalgorithms occurring in a diverse range of applications. The stability of the\nprocess is often difficult to verify in practical applications and the process\nmay even be unstable without additional stabilisation techniques. We study a\nstochastic approximation procedure with expanding projections similar to\nAndrad\\'{o}ttir [Oper. Res. 43 (1995) 1037-1048]. We focus on Markovian noise\nand show the stability and convergence under general conditions. Our framework\nalso incorporates the possibility to use a random step size sequence, which\nallows us to consider settings with a non-smooth family of Markov kernels. We\napply the theory to stochastic approximation expectation maximisation with\nparticle independent Metropolis-Hastings sampling.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2011 07:31:58 GMT"}, {"version": "v2", "created": "Fri, 7 Mar 2014 10:14:28 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["Andrieu", "Christophe", ""], ["Vihola", "Matti", ""]]}, {"id": "1111.5866", "submitter": "Joaquin Miguez", "authors": "Dan Crisan, Joaqu\\'in M\\'iguez", "title": "Particle-kernel estimation of the filter density in state-space models", "comments": "IMPORTANT: This manuscript is identical to the published paper,\n  including a gap in the proof of Theorem 4.2. The Theorem itself is correct.\n  We provide an erratum at the end of this document. Published at\n  http://dx.doi.org/10.3150/13-BEJ545 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli, Vol. 20, No. 4, 1879-1929 (2014)", "doi": "10.3150/13-BEJ545", "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential Monte Carlo (SMC) methods, also known as particle filters, are\nsimulation-based recursive algorithms for the approximation of the a posteriori\nprobability measures generated by state-space dynamical models. At any given\ntime $t$, a SMC method produces a set of samples over the state space of the\nsystem of interest (often termed \"particles\") that is used to build a discrete\nand random approximation of the posterior probability distribution of the state\nvariables, conditional on a sequence of available observations. One potential\napplication of the methodology is the estimation of the densities associated to\nthe sequence of a posteriori distributions. While practitioners have rather\nfreely applied such density approximations in the past, the issue has received\nless attention from a theoretical perspective. In this paper, we address the\nproblem of constructing kernel-based estimates of the posterior probability\ndensity function and its derivatives, and obtain asymptotic convergence results\nfor the estimation errors. In particular, we find convergence rates for the\napproximation errors that hold uniformly on the state space and guarantee that\nthe error vanishes almost surely as the number of particles in the filter\ngrows. Based on this uniform convergence result, we first show how to build\ncontinuous measures that converge almost surely (with known rate) toward the\nposterior measure and then address a few applications. The latter include\nmaximum a posteriori estimation of the system state using the approximate\nderivatives of the posterior density and the approximation of functionals of\nit, for example, Shannon's entropy.\n  This manuscript is identical to the published paper, including a gap in the\nproof of Theorem 4.2. The Theorem itself is correct. We provide an {\\em\nerratum} at the end of this document with a complete proof and a brief\ndiscussion.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2011 22:37:28 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2012 23:29:44 GMT"}, {"version": "v3", "created": "Fri, 30 Mar 2012 15:06:47 GMT"}, {"version": "v4", "created": "Tue, 2 Jul 2013 17:27:21 GMT"}, {"version": "v5", "created": "Thu, 10 Apr 2014 17:11:13 GMT"}, {"version": "v6", "created": "Wed, 24 Sep 2014 14:53:10 GMT"}, {"version": "v7", "created": "Tue, 21 Oct 2014 12:52:49 GMT"}, {"version": "v8", "created": "Wed, 23 Nov 2016 12:15:57 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Crisan", "Dan", ""], ["M\u00edguez", "Joaqu\u00edn", ""]]}, {"id": "1111.6245", "submitter": "Julien Bect", "authors": "Alireza Roodaki and Julien Bect and Gilles Fleury", "title": "Note on the computation of the Metropolis-Hastings ratio for\n  Birth-or-Death moves in trans-dimensional MCMC algorithms for signal\n  decomposition problems", "comments": "Technical report (15 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible jump MCMC (RJ-MCMC) sampling techniques, which allow to jointly\ntackle model selection and parameter estimation problems in a coherent Bayesian\nframework, have become increasingly popular in the signal processing literature\nsince the seminal paper of Andrieu and Doucet (IEEE Trans. Signal Process.,\n47(10), 1999). Crucial to the implementation of any RJ-MCMC sampler is the\ncomputation of the so-called Metropolis-Hastings-Green (MHG) ratio, which\ndetermines the acceptance probability for the proposed moves.\n  It turns out that the expression of the MHG ratio that was given in the paper\nof Andrieu and Doucet for \"Birth-or-Death\" moves---the simplest kind of\ntrans-dimensional move, used in virtually all applications of RJ-MCMC to signal\ndecomposition problems---was erroneous. Unfortunately, this mistake has been\nreproduced in many subsequent papers dealing with RJ-MCMC sampling in the\nsignal processing literature.\n  This note discusses the computation of the MHG ratio, with a focus on the\ncase where the proposal kernel can be decomposed as a mixture of simpler\nkernels, for which the MHG ratio is easy to compute. We provide sufficient\nconditions under which the MHG ratio of the mixture can be deduced from the MHG\nratios of the elementary kernels of which it is composed. As an application, we\nconsider the case of Birth-or-Death moves, and provide a corrected expression\nfor the erroneous ratio in the paper of Andrieu and Doucet.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2011 10:51:34 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2012 14:13:47 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Roodaki", "Alireza", ""], ["Bect", "Julien", ""], ["Fleury", "Gilles", ""]]}, {"id": "1111.6298", "submitter": "Julien Bect", "authors": "Alireza Roodaki and Julien Bect and Gilles Fleury", "title": "Summarizing posterior distributions in signal decomposition problems\n  when the number of components is unknown", "comments": "This work has been submitted to the IEEE for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of summarizing the posterior distributions\nthat typically arise, in a Bayesian framework, when dealing with signal\ndecomposition problems with unknown number of components. Such posterior\ndistributions are defined over union of subspaces of differing dimensionality\nand can be sampled from using modern Monte Carlo techniques, for instance the\nincreasingly popular RJ-MCMC method. No generic approach is available, however,\nto summarize the resulting variable-dimensional samples and extract from them\ncomponent-specific parameters.\n  We propose a novel approach to this problem, which consists in approximating\nthe complex posterior of interest by a \"simple\"---but still\nvariable-dimensional---parametric distribution. The distance between the two\ndistributions is measured using the Kullback-Leibler divergence, and a\nStochastic EM-type algorithm, driven by the RJ-MCMC sampler, is proposed to\nestimate the parameters. The proposed algorithm is illustrated on the\nfundamental signal processing example of joint detection and estimation of\nsinusoids in white Gaussian noise.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2011 21:24:11 GMT"}], "update_date": "2011-11-29", "authors_parsed": [["Roodaki", "Alireza", ""], ["Bect", "Julien", ""], ["Fleury", "Gilles", ""]]}, {"id": "1111.6518", "submitter": "Ruriko Yoshida", "authors": "Ruriko Yoshida and Jing Xi and Shaoceng Wei and Feng Zhou and David\n  Haws", "title": "Semigroups and sequential importance sampling for multiway tables", "comments": "There are some theoretical mistakes. Thus, we would like to withdraw\n  the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When an interval of integers between the lower bound $l_i$ and the upper\nbound $u_i$ is the support of the marginal distribution $n_i|(n_{i-1},\n...,n_1)$, Chen et al, 2005 noticed that sampling from the interval at each\nstep, for $n_i$ during a sequential importance sampling (SIS) procedure, always\nproduces a table which satisfies the marginal constraints. However, in general,\nthe interval may not be equal to the support of the marginal distribution. In\nthis case, the SIS procedure may produce tables which do not satisfy the\nmarginal constraints, leading to rejection Chen et al 2006. In this paper we\nconsider the uniform distribution as the target distribution. First we show\nthat if we fix the number of rows and columns of the design matrix of the model\nfor contingency tables then there exists a polynomial time algorithm in terms\nof the input size to sample a table from the set of all tables satisfying all\nmarginals defined by the given model via the SIS procedure without rejection.\nWe then show experimentally that in general the SIS procedure may have large\nrejection rates even with small tables. Further we show that in general the\nclassical SIS procedure in Chen et al, 2005 can have a large rejection rate\nwhose limit is one. When estimating the number of tables in our simulation\nstudy, we used the univariate and bivariate logistic regression models since\nunder this model the SIS procedure seems to have higher rate of rejections even\nwith small tables.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2011 17:11:27 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 12:19:31 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Yoshida", "Ruriko", ""], ["Xi", "Jing", ""], ["Wei", "Shaoceng", ""], ["Zhou", "Feng", ""], ["Haws", "David", ""]]}]