[{"id": "1110.0110", "submitter": "Alexandros Beskos", "authors": "Alexandros Beskos, Stefano Peluchetti, Gareth Roberts", "title": "\\epsilon-Strong simulation of the Brownian path", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ383 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2012, Vol. 18, No. 4, 1223-1248", "doi": "10.3150/11-BEJ383", "report-no": "IMS-BEJ-BEJ383", "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an iterative sampling method which delivers upper and lower\nbounding processes for the Brownian path. We develop such processes with\nparticular emphasis on being able to unbiasedly simulate them on a personal\ncomputer. The dominating processes converge almost surely in the supremum and\n$L_1$ norms. In particular, the rate of converge in $L_1$ is of the order\n$\\mathcal {O}(\\mathcal{K}^{-1/2})$, $\\mathcal{K}$ denoting the computing cost.\nThe a.s. enfolding of the Brownian path can be exploited in Monte Carlo\napplications involving Brownian paths whence our algorithm (termed the\n$\\varepsilon$-strong algorithm) can deliver unbiased Monte Carlo estimators\nover path expectations, overcoming discretisation errors characterising\nstandard approaches. We will show analytical results from applications of the\n$\\varepsilon$-strong algorithm for estimating expectations arising in option\npricing. We will also illustrate that individual steps of the algorithm can be\nof separate interest, giving new simulation methods for interesting Brownian\ndistributions.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2011 15:56:36 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2012 06:40:04 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Beskos", "Alexandros", ""], ["Peluchetti", "Stefano", ""], ["Roberts", "Gareth", ""]]}, {"id": "1110.0219", "submitter": "Robert B. Gramacy", "authors": "Yuao Hua, Robert B. Gramacy and Heng Lian", "title": "Bayesian Quantile Regression for Single-Index Models", "comments": "26 pages, 8 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using an asymmetric Laplace distribution, which provides a mechanism for\nBayesian inference of quantile regression models, we develop a fully Bayesian\napproach to fitting single-index models in conditional quantile regression. In\nthis work, we use a Gaussian process prior for the unknown nonparametric link\nfunction and a Laplace distribution on the index vector, with the latter\nmotivated by the recent popularity of the Bayesian lasso idea. We design a\nMarkov chain Monte Carlo algorithm for posterior inference. Careful\nconsideration of the singularity of the kernel matrix, and tractability of some\nof the full conditional distributions leads to a partially collapsed approach\nwhere the nonparametric link function is integrated out in some of the sampling\nsteps. Our simulations demonstrate the superior performance of the Bayesian\nmethod versus the frequentist approach. The method is further illustrated by an\napplication to the hurricane data.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2011 19:40:38 GMT"}, {"version": "v2", "created": "Fri, 30 Dec 2011 02:24:12 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Hua", "Yuao", ""], ["Gramacy", "Robert B.", ""], ["Lian", "Heng", ""]]}, {"id": "1110.0310", "submitter": "Harish V", "authors": "Harish Vangala, Rahul Meshram, Prof. Vinod Sharma", "title": "Joint Routing, Scheduling And Power Control For Multihop Wireless\n  Networks With Multiple Antennas", "comments": "Submitted to NCC-2012. First Draft is here. Final version has many\n  changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of Joint Routing, Scheduling and Power-control (JRSP)\nproblem for multihop wireless networks (MHWN) with multiple antennas. We extend\nthe problem and a (sub-optimal) heuristic solution method for JRSP in MHWN with\nsingle antennas. We present an iterative scheme to calculate link\ncapacities(achievable rates) in the interference environment of the network\nusing SINR model. We then present the algorithm for solving the JRSP problem.\nThis completes a feasible system model for MHWN when nodes have multiple\nantennas. We show that the gain we achieve by using multiple antennas in the\nnetwork is linear both in optimal performance as well as heuristic algorithmic\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2011 10:02:09 GMT"}], "update_date": "2011-10-04", "authors_parsed": [["Vangala", "Harish", ""], ["Meshram", "Rahul", ""], ["Sharma", "Prof. Vinod", ""]]}, {"id": "1110.0541", "submitter": "Michael O'Hara", "authors": "Michael James O'Hara", "title": "On the rank-one approximation of symmetric tensors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of symmetric rank-one approximation of symmetric tensors is\nimportant in Independent Components Analysis, also known as Blind Source\nSeparation, as well as polynomial optimization. We analyze the symmetric\nrank-one approximation problem for symmetric tensors and derive several\nperturbation results. Given a symmetric rank-one tensor obscured by noise, we\nprovide bounds on the accuracy of the best symmetric rank-one approximation for\nrecovering the original rank-one structure, and we show that any eigenvector\nwith sufficiently large eigenvalue is related to the rank-one structure as\nwell. Further, we show that for high-dimensional symmetric\napproximately-rank-one tensors, the generalized Rayleigh quotient is mostly\nclose to zero, so the best symmetric rank-one approximation corresponds to a\nprominent global extreme value. We show that each iteration of the Shifted\nSymmetric Higher Order Power Method (SS-HOPM), when applied to a rank-one\nsymmetric tensor, moves towards the principal eigenvector for any input and\nshift parameter, under mild conditions. Finally, we explore the best choice of\nshift parameter for SS-HOPM to recover the principal eigenvector. We show that\nSS-HOPM is guaranteed to converge to an eigenvector of an approximately\nrank-one even-mode tensor for a wider choice of shift parameter than it is for\na general symmetric tensor. We also show that the principal eigenvector is a\nstable fixed point of the SS-HOPM iteration for a wide range of shift\nparameters; together with a numerical experiment, these results lead to a\nnon-obvious recommendation for shift parameter for the symmetric rank-one\napproximation problem.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2011 23:09:44 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2011 21:34:49 GMT"}], "update_date": "2011-12-14", "authors_parsed": [["O'Hara", "Michael James", ""]]}, {"id": "1110.0721", "submitter": "Tomonari Sei", "authors": "Tomonari Sei, Hiroki Shibata, Akimichi Takemura, Katsuyoshi Ohara,\n  Nobuki Takayama", "title": "Properties and applications of Fisher distribution on the rotation group", "comments": "25 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study properties of Fisher distribution (von Mises-Fisher distribution,\nmatrix Langevin distribution) on the rotation group SO(3). In particular we\napply the holonomic gradient descent, introduced by Nakayama et al. (2011), and\na method of series expansion for evaluating the normalizing constant of the\ndistribution and for computing the maximum likelihood estimate. The rotation\ngroup can be identified with the Stiefel manifold of two orthonormal vectors.\nTherefore from the viewpoint of statistical modeling, it is of interest to\ncompare Fisher distributions on these manifolds. We illustrate the difference\nwith an example of near-earth objects data.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2011 15:21:36 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2013 18:27:50 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Sei", "Tomonari", ""], ["Shibata", "Hiroki", ""], ["Takemura", "Akimichi", ""], ["Ohara", "Katsuyoshi", ""], ["Takayama", "Nobuki", ""]]}, {"id": "1110.1248", "submitter": "Axel Gandy", "authors": "Axel Gandy, Patrick Rubin-Delanchy", "title": "An algorithm to compute the power of Monte Carlo tests with guaranteed\n  precision", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1076 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 1, 125-142", "doi": "10.1214/12-AOS1076", "report-no": "IMS-AOS-AOS1076", "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents an algorithm that generates a conservative confidence\ninterval of a specified length and coverage probability for the power of a\nMonte Carlo test (such as a bootstrap or permutation test). It is the first\nmethod that achieves this aim for almost any Monte Carlo test. Previous\nresearch has focused on obtaining as accurate a result as possible for a fixed\ncomputational effort, without providing a guaranteed precision in the above\nsense. The algorithm we propose does not have a fixed effort and runs until a\nconfidence interval with a user-specified length and coverage probability can\nbe constructed. We show that the expected effort required by the algorithm is\nfinite in most cases of practical interest, including situations where the\ndistribution of the p-value is absolutely continuous or discrete with finite\nsupport. The algorithm is implemented in the R-package simctest, available on\nCRAN.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2011 12:50:58 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2013 10:14:16 GMT"}], "update_date": "2013-03-13", "authors_parsed": [["Gandy", "Axel", ""], ["Rubin-Delanchy", "Patrick", ""]]}, {"id": "1110.1880", "submitter": "Konstantin Zuev M", "authors": "James L. Beck and Konstantin M. Zuev", "title": "Asymptotically Independent Markov Sampling: a new MCMC scheme for\n  Bayesian Inference", "comments": "38 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian statistics, many problems can be expressed as the evaluation of\nthe expectation of a quantity of interest with respect to the posterior\ndistribution. Standard Monte Carlo method is often not applicable because the\nencountered posterior distributions cannot be sampled directly. In this case,\nthe most popular strategies are the importance sampling method, Markov chain\nMonte Carlo, and annealing. In this paper, we introduce a new scheme for\nBayesian inference, called Asymptotically Independent Markov Sampling (AIMS),\nwhich is based on the above methods. We derive important ergodic properties of\nAIMS. In particular, it is shown that, under certain conditions, the AIMS\nalgorithm produces a uniformly ergodic Markov chain. The choice of the free\nparameters of the algorithm is discussed and recommendations are provided for\nthis choice, both theoretically and heuristically based. The efficiency of AIMS\nis demonstrated with three numerical examples, which include both multi-modal\nand higher-dimensional target posterior distributions.\n", "versions": [{"version": "v1", "created": "Sun, 9 Oct 2011 20:00:33 GMT"}], "update_date": "2011-10-11", "authors_parsed": [["Beck", "James L.", ""], ["Zuev", "Konstantin M.", ""]]}, {"id": "1110.2435", "submitter": "Tuhin Sahai", "authors": "Amit Surana, Tuhin Sahai and Andrzej Banaszuk", "title": "Iterative Methods for Scalable Uncertainty Quantification in Complex\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of uncertainty management for robust\ndesign, and verification of large dynamic networks whose performance is\naffected by an equally large number of uncertain parameters. Many such networks\n(e.g. power, thermal and communication networks) are often composed of weakly\ninteracting subnetworks. We propose intrusive and non-intrusive iterative\nschemes that exploit such weak interconnections to overcome dimensionality\ncurse associated with traditional uncertainty quantification methods (e.g.\ngeneralized Polynomial Chaos, Probabilistic Collocation) and accelerate\nuncertainty propagation in systems with large number of uncertain parameters.\nThis approach relies on integrating graph theoretic methods and waveform\nrelaxation with generalized Polynomial Chaos, and Probabilistic Collocation,\nrendering these techniques scalable. We analyze convergence properties of this\nscheme and illustrate it on several examples.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2011 17:05:00 GMT"}], "update_date": "2011-10-12", "authors_parsed": [["Surana", "Amit", ""], ["Sahai", "Tuhin", ""], ["Banaszuk", "Andrzej", ""]]}, {"id": "1110.2824", "submitter": "Satoshi Kuriki", "authors": "Satoshi Kuriki, Tetsuhisa Miwa, Anthony J. Hayter", "title": "Abstract tubes associated with perturbed polyhedra with applications to\n  multidimensional normal probability computations", "comments": "15 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $K$ be a closed convex polyhedron defined by a finite number of linear\ninequalities. In this paper we refine the theory of abstract tubes (Naiman and\nWynn, 1997) associated with $K$ when $K$ is perturbed. In particular, we focus\non the perturbation that is lexicographic and in an outer direction. An\nalgorithm for constructing the abstract tube by means of linear programming and\nits implementation are discussed. Using the abstract tube for perturbed $K$\ncombined with the recursive integration technique proposed by Miwa, Hayter and\nKuriki (2003), we show that the multidimensional normal probability for a\npolyhedral region $K$ can be computed efficiently. In addition, abstract tubes\nand the distribution functions of studentized range statistics are exhibited as\nnumerical examples.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 01:40:17 GMT"}], "update_date": "2011-10-14", "authors_parsed": [["Kuriki", "Satoshi", ""], ["Miwa", "Tetsuhisa", ""], ["Hayter", "Anthony J.", ""]]}, {"id": "1110.2873", "submitter": "Fredrik Lindsten", "authors": "Fredrik Lindsten and Thomas B. Sch\\\"on", "title": "On the use of backward simulation in particle Markov chain Monte Carlo\n  methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Andrieu, Doucet and Holenstein (2010) introduced a general\nframework for using particle filters (PFs) to construct proposal kernels for\nMarkov chain Monte Carlo (MCMC) methods. This framework, termed Particle Markov\nchain Monte Carlo (PMCMC), was shown to provide powerful methods for joint\nBayesian state and parameter inference in nonlinear/non-Gaussian state-space\nmodels. However, the mixing of the resulting MCMC kernels can be quite\nsensitive, both to the number of particles used in the underlying PF and to the\nnumber of observations in the data. In the discussion following (Andrieu et\nal., 2010), Whiteley suggested a modified version of one of the PMCMC samplers,\nnamely the particle Gibbs (PG) sampler, and argued that this should improve its\nmixing. In this paper we explore the consequences of this modification and show\nthat it leads to a method which is much more robust to a low number of\nparticles as well as a large number of observations. Furthermore, we discuss\nhow the modified PG sampler can be used as a basis for alternatives to all\nthree PMCMC samplers derived in (Andrieu et al., 2010). We evaluate these\nmethods on several challenging inference problems in a simulation study. One of\nthese is the identification of an epidemiological model for predicting\ninfluenza epidemics, based on search engine query data.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 09:19:30 GMT"}, {"version": "v2", "created": "Tue, 13 Mar 2012 17:29:36 GMT"}], "update_date": "2012-03-14", "authors_parsed": [["Lindsten", "Fredrik", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1110.2894", "submitter": "Robin Evans", "authors": "Robin J. Evans and Antonio Forcina", "title": "Two algorithms for fitting constrained marginal models", "comments": "12 pages", "journal-ref": "Computational Statistics and Data Analysis, Volume 66, pages 1-7,\n  2013", "doi": "10.1016/j.csda.2013.02.001", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study in detail the two main algorithms which have been considered for\nfitting constrained marginal models to discrete data, one based on Lagrange\nmultipliers and the other on a regression model. We show that the updates\nproduced by the two methods are identical, but that the Lagrangian method is\nmore efficient in the case of identically distributed observations. We provide\na generalization of the regression algorithm for modelling the effect of\nexogenous individual-level covariates, a context in which the use of the\nLagrangian algorithm would be infeasible for even moderate sample sizes. An\nextension of the method to likelihood-based estimation under $L_1$-penalties is\nalso considered.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2011 11:18:20 GMT"}, {"version": "v2", "created": "Wed, 2 May 2012 13:06:38 GMT"}, {"version": "v3", "created": "Mon, 24 Dec 2012 16:11:44 GMT"}], "update_date": "2013-05-28", "authors_parsed": [["Evans", "Robin J.", ""], ["Forcina", "Antonio", ""]]}, {"id": "1110.3390", "submitter": "Konstantin Zuev M", "authors": "Konstantin M. Zuev, James L. Beck, Siu-Kui Au, and Lambros S.\n  Katafygiotis", "title": "Bayesian Post-Processor and other Enhancements of Subset Simulation for\n  Estimating Failure Probabilities in High Dimensions", "comments": "35 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of small failure probabilities is one of the most important and\nchallenging computational problems in reliability engineering. The failure\nprobability is usually given by an integral over a high-dimensional uncertain\nparameter space that is difficult to evaluate numerically. This paper focuses\non enhancements to Subset Simulation (SS), proposed by Au and Beck, which\nprovides an efficient algorithm based on MCMC (Markov chain Monte Carlo)\nsimulation for computing small failure probabilities for general\nhigh-dimensional reliability problems. First, we analyze the Modified\nMetropolis algorithm (MMA), an MCMC technique, which is used in SS for sampling\nfrom high-dimensional conditional distributions. We present some observations\non the optimal scaling of MMA, and develop an optimal scaling strategy for this\nalgorithm when it is employed within SS. Next, we provide a theoretical basis\nfor the optimal value of the conditional failure probability $p_0$, an\nimportant parameter one has to choose when using SS. Finally, a Bayesian\npost-processor SS+ for the original SS method is developed where the uncertain\nfailure probability that one is estimating is modeled as a stochastic variable\nwhose possible values belong to the unit interval. Simulated samples from SS\nare viewed as informative data relevant to the system's reliability. Instead of\na single real number as an estimate, SS+ produces the posterior PDF of the\nfailure probability, which takes into account both prior information and the\ninformation in the sampled data. This PDF quantifies the uncertainty in the\nvalue of the failure probability and it may be further used in risk analyses to\nincorporate this uncertainty. The relationship between the original SS and SS+\nis also discussed\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2011 06:21:37 GMT"}], "update_date": "2011-10-18", "authors_parsed": [["Zuev", "Konstantin M.", ""], ["Beck", "James L.", ""], ["Au", "Siu-Kui", ""], ["Katafygiotis", "Lambros S.", ""]]}, {"id": "1110.3392", "submitter": "Qing Zhou", "authors": "Qing Zhou", "title": "Multi-Domain Sampling With Applications to Structural Inference of\n  Bayesian Networks", "comments": "39 pages (double space), 3 figures. To appear in JASA", "journal-ref": "Journal of the American Statistical Association, 106: 1317-1330\n  (2011)", "doi": "10.1198/jasa.2011.ap10346.", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a posterior distribution has multiple modes, unconditional expectations,\nsuch as the posterior mean, may not offer informative summaries of the\ndistribution. Motivated by this problem, we propose to decompose the sample\nspace of a multimodal distribution into domains of attraction of local modes.\nDomain-based representations are defined to summarize the probability masses of\nand conditional expectations on domains of attraction, which are much more\ninformative than the mean and other unconditional expectations. A computational\nmethod, the multi-domain sampler, is developed to construct domain-based\nrepresentations for an arbitrary multimodal distribution. The multi-domain\nsampler is applied to structural learning of protein-signaling networks from\nhigh-throughput single-cell data, where a signaling network is modeled as a\ncausal Bayesian network. Not only does our method provide a detailed landscape\nof the posterior distribution but also improves the accuracy and the predictive\npower of estimated networks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2011 07:16:52 GMT"}], "update_date": "2012-03-05", "authors_parsed": [["Zhou", "Qing", ""]]}, {"id": "1110.3689", "submitter": "Feng Li", "authors": "Feng Li and Mattias Villani", "title": "Efficient Bayesian Multivariate Surface Regression", "comments": null, "journal-ref": "Scandinavian Journal of Statistics, (2013), 40(4)", "doi": "10.1111/sjos.12022", "report-no": null, "categories": "stat.CO stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods for choosing a fixed set of knot locations in additive spline models\nare fairly well established in the statistical literature. While most of these\nmethods are in principle directly extendable to non-additive surface models,\nthey are less likely to be successful in that setting because of the curse of\ndimensionality, especially when there are more than a couple of covariates. We\npropose a regression model for a multivariate Gaussian response that combines\nboth additive splines and interactive splines, and a highly efficient MCMC\nalgorithm that updates all the knot locations jointly. We use shrinkage priors\nto avoid overfitting with different estimated shrinkage factors for the\nadditive and surface part of the model, and also different shrinkage parameters\nfor the different response variables. This makes it possible for the model to\nadapt to varying degrees of nonlinearity in different parts of the data in a\nparsimonious way. Simulated data and an application to firm leverage data show\nthat the approach is computationally efficient, and that allowing for freely\nestimated knot locations can offer a substantial improvement in out-of-sample\npredictive performance.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2011 15:00:42 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2012 16:56:39 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Li", "Feng", ""], ["Villani", "Mattias", ""]]}, {"id": "1110.4400", "submitter": "Bjoern Bornkamp", "authors": "Bj\\\"orn Bornkamp", "title": "Functional Uniform Priors for Nonlinear Modelling", "comments": "submitted for publication", "journal-ref": "updated version published in Biometrics (2012) 68, 893-901,", "doi": "10.1111/j.1541-0420.2012.01747.x", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the topic of finding prior distributions when a major\ncomponent of the statistical model depends on a nonlinear function. Using\nresults on how to construct uniform distributions in general metric spaces, we\npropose a prior distribution that is uniform in the space of functional shapes\nof the underlying nonlinear function and then back-transform to obtain a prior\ndistribution for the original model parameters. The primary application\nconsidered in this article is nonlinear regression, but the idea might be of\ninterest beyond this case. For nonlinear regression the so constructed priors\nhave the advantage that they are parametrization invariant and do not violate\nthe likelihood principle, as opposed to uniform distributions on the parameters\nor the Jeffrey's prior, respectively. The utility of the proposed priors is\ndemonstrated in the context of nonlinear regression modelling in clinical\ndose-finding trials, through a real data example and simulation. In addition\nthe proposed priors are used for calculation of an optimal Bayesian design.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2011 21:03:02 GMT"}], "update_date": "2014-05-09", "authors_parsed": [["Bornkamp", "Bj\u00f6rn", ""]]}, {"id": "1110.4700", "submitter": "Christian P. Robert", "authors": "J.-M. Marin (Universite Montpellier), N. Pillai (Harvard University),\n  C.P. Robert (Universite Paris Dauphine, University of Warwick, and CREST),\n  and J. Rousseau (ENSAE, Universite Paris Dauphine and CREST)", "title": "Relevant statistics for Bayesian model choice", "comments": "30 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-bio.PE stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of the summary statistics used in Bayesian inference and in\nparticular in ABC algorithms has bearings on the validation of the resulting\ninference. Those statistics are nonetheless customarily used in ABC algorithms\nwithout consistency checks. We derive necessary and sufficient conditions on\nsummary statistics for the corresponding Bayes factor to be convergent, namely\nto asymptotically select the true model. Those conditions, which amount to the\nexpectations of the summary statistics to asymptotically differ under both\nmodels, are quite natural and can be exploited in ABC settings to infer whether\nor not a choice of summary statistics is appropriate, via a Monte Carlo\nvalidation.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2011 05:07:49 GMT"}, {"version": "v2", "created": "Fri, 4 May 2012 18:50:31 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2013 18:57:13 GMT"}, {"version": "v4", "created": "Thu, 22 Aug 2013 15:55:26 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Marin", "J. -M.", "", "Universite Montpellier"], ["Pillai", "N.", "", "Harvard University"], ["Robert", "C. P.", "", "Universite Paris Dauphine, University of Warwick, and CREST"], ["Rousseau", "J.", "", "ENSAE, Universite Paris Dauphine and CREST"]]}, {"id": "1110.5383", "submitter": "Hyokun Yun", "authors": "Hyokun Yun, S. V. N. Vishwanathan", "title": "Quilting Stochastic Kronecker Product Graphs to Generate Multiplicative\n  Attribute Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the first sub-quadratic sampling algorithm for the Multiplicative\nAttribute Graph Model (MAGM) of Kim and Leskovec (2010). We exploit the close\nconnection between MAGM and the Kronecker Product Graph Model (KPGM) of\nLeskovec et al. (2010), and show that to sample a graph from a MAGM it suffices\nto sample small number of KPGM graphs and \\emph{quilt} them together. Under a\nrestricted set of technical conditions our algorithm runs in $O((\\log_2(n))^3\n|E|)$ time, where $n$ is the number of nodes and $|E|$ is the number of edges\nin the sampled graph. We demonstrate the scalability of our algorithm via\nextensive empirical evaluation; we can sample a MAGM graph with 8 million nodes\nand 20 billion edges in under 6 hours.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2011 23:47:21 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2012 13:54:17 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Yun", "Hyokun", ""], ["Vishwanathan", "S. V. N.", ""]]}, {"id": "1110.5509", "submitter": "Mahdi Doostparast", "authors": "Mahdi Doostparast", "title": "Goodness-of-fit tests for weibull populations on the basis of records", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Record is used to reduce the time and cost of running experiments\n(Doostparast and Balakrishnan, 2010). It is important to check the adequacy of\nmodels upon which inferences or actions are based (Lawless, 2003, Chapter 10,\np. 465). In the area of goodness of fit based on record data, there are a few\nworks. Smith (1988) proposed a form of residual for testing some parametric\nmodels. But in most cases, the variation inherent in graphical summaries is\nsubstantial, even when the data are generated by assumed model, and the eye can\nnot always determine whether features in a plot are within the bounds of\nnatural random variation. Consequently, formal hypothesis tests are an\nimportant part of model checking (Lawless, 2003).\n  In this paper, Kolmogorov-Smirnov and Cramer-von Mises type goodness of fit\ntests for record data are proposed. Also a new weighted goodness of fit test is\nsuggested. A Monte-Carlo simulation study is conducted to derive the\npercentiles of the statistics proposed. Finally, some real data sets are given\nto investigate results obtained.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2011 14:09:21 GMT"}], "update_date": "2011-10-26", "authors_parsed": [["Doostparast", "Mahdi", ""]]}, {"id": "1110.6054", "submitter": "Benjamin Taylor", "authors": "Benjamin M. Taylor, Tilman M. Davies, Barry S. Rowlingson, Peter J.\n  Diggle", "title": "lgcp An R Package for Inference with Spatio-Temporal Log-Gaussian Cox\n  Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces an R package for spatio-temporal prediction and\nforecasting for log-Gaussian Cox processes. The main computational tool for\nthese models is Markov chain Monte Carlo and the new package, lgcp, therefore\nalso provides an extensible suite of functions for implementing MCMC algorithms\nfor processes of this type. The modelling framework and details of inferential\nprocedures are first presented before a tour of lgcp functionality is given via\na walk-through data-analysis. Topics covered include reading in and converting\ndata, estimation of the key components and parameters of the model, specifying\noutput and simulation quantities, computation of Monte Carlo expectations,\npost-processing and simulation of data sets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2011 11:54:12 GMT"}], "update_date": "2011-10-28", "authors_parsed": [["Taylor", "Benjamin M.", ""], ["Davies", "Tilman M.", ""], ["Rowlingson", "Barry S.", ""], ["Diggle", "Peter J.", ""]]}, {"id": "1110.6451", "submitter": "Roman Jandarov", "authors": "Roman Jandarov, Murali Haran, Ottar Bj{\\o}rnstad and Bryan Grenfell", "title": "Emulating a gravity model to infer the spatiotemporal dynamics of an\n  infectious disease", "comments": "31 pages, 8 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic models for infectious disease dynamics are useful for\nunderstanding the mechanism underlying the spread of infection. When the\nlikelihood function for these models is expensive to evaluate, traditional\nlikelihood-based inference may be computationally intractable. Furthermore,\ntraditional inference may lead to poor parameter estimates and the fitted model\nmay not capture important biological characteristics of the observed data. We\npropose a novel approach for resolving these issues that is inspired by recent\nwork in emulation and calibration for complex computer models. Our motivating\nexample is the gravity time series susceptible-infected-recovered (TSIR) model.\nOur approach focuses on the characteristics of the process that are of\nscientific interest. We find a Gaussian process approximation to the gravity\nmodel using key summary statistics obtained from model simulations. We\ndemonstrate via simulated examples that the new approach is computationally\nexpedient, provides accurate parameter inference, and results in a good model\nfit. We apply our method to analyze measles outbreaks in England and Wales in\ntwo periods, the pre-vaccination period from 1944-1965 and the vaccination\nperiod from 1966-1994. Based on our results, we are able to obtain important\nscientific insights about the transmission of measles. In general, our method\nis applicable to problems where traditional likelihood-based inference is\ncomputationally intractable or produces a poor model fit. It is also an\nalternative to approximate Bayesian computation (ABC) when simulations from the\nmodel are expensive.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2011 20:05:44 GMT"}, {"version": "v2", "created": "Fri, 6 Jan 2012 00:35:39 GMT"}, {"version": "v3", "created": "Thu, 14 Feb 2013 22:52:49 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Jandarov", "Roman", ""], ["Haran", "Murali", ""], ["Bj\u00f8rnstad", "Ottar", ""], ["Grenfell", "Bryan", ""]]}, {"id": "1110.6497", "submitter": "Ziyu Wang", "authors": "Nimalan Mahendran, Ziyu Wang, Firas Hamze, Nando de Freitas", "title": "Bayesian Optimization for Adaptive MCMC", "comments": "This paper contains 12 pages and 6 figures. A similar version of this\n  paper has been submitted to AISTATS 2012 and is currently under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new randomized strategy for adaptive MCMC using\nBayesian optimization. This approach applies to non-differentiable objective\nfunctions and trades off exploration and exploitation to reduce the number of\npotentially costly objective function evaluations. We demonstrate the strategy\nin the complex setting of sampling from constrained, discrete and densely\nconnected probabilistic graphical models where, for each variation of the\nproblem, one needs to adjust the parameters of the proposal mechanism\nautomatically to ensure efficient mixing of the Markov chains.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2011 05:23:36 GMT"}], "update_date": "2011-11-01", "authors_parsed": [["Mahendran", "Nimalan", ""], ["Wang", "Ziyu", ""], ["Hamze", "Firas", ""], ["de Freitas", "Nando", ""]]}, {"id": "1110.6546", "submitter": "Andrea Schirru Mr", "authors": "Andrea Schirru, Simone Pampuri, Giuseppe De Nicolao, Sean McLoone", "title": "Efficient Marginal Likelihood Computation for Gaussian Process\n  Regression", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a Bayesian learning setting, the posterior distribution of a predictive\nmodel arises from a trade-off between its prior distribution and the\nconditional likelihood of observed data. Such distribution functions usually\nrely on additional hyperparameters which need to be tuned in order to achieve\noptimum predictive performance; this operation can be efficiently performed in\nan Empirical Bayes fashion by maximizing the posterior marginal likelihood of\nthe observed data. Since the score function of this optimization problem is in\ngeneral characterized by the presence of local optima, it is necessary to\nresort to global optimization strategies, which require a large number of\nfunction evaluations. Given that the evaluation is usually computationally\nintensive and badly scaled with respect to the dataset size, the maximum number\nof observations that can be treated simultaneously is quite limited. In this\npaper, we consider the case of hyperparameter tuning in Gaussian process\nregression. A straightforward implementation of the posterior log-likelihood\nfor this model requires O(N^3) operations for every iteration of the\noptimization procedure, where N is the number of examples in the input dataset.\nWe derive a novel set of identities that allow, after an initial overhead of\nO(N^3), the evaluation of the score function, as well as the Jacobian and\nHessian matrices, in O(N) operations. We prove how the proposed identities,\nthat follow from the eigendecomposition of the kernel matrix, yield a reduction\nof several orders of magnitude in the computation time for the hyperparameter\noptimization problem. Notably, the proposed solution provides computational\nadvantages even with respect to state of the art approximations that rely on\nsparse kernel matrices.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2011 18:36:00 GMT"}], "update_date": "2011-11-01", "authors_parsed": [["Schirru", "Andrea", ""], ["Pampuri", "Simone", ""], ["De Nicolao", "Giuseppe", ""], ["McLoone", "Sean", ""]]}, {"id": "1110.6796", "submitter": "Daniel Simpson", "authors": "Daniel Simpson, Finn Lindgren and H{\\aa}vard Rue", "title": "Think continuous: Markovian Gaussian models in spatial statistics", "comments": "15 Pages, 5 Figures; 9/2011, Department of Mathematical Sciences,\n  Norwegian University of Science and Technology (NTNU)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Markov random fields (GMRFs) are frequently used as computationally\nefficient models in spatial statistics. Unfortunately, it has traditionally\nbeen difficult to link GMRFs with the more traditional Gaussian random field\nmodels as the Markov property is difficult to deploy in continuous space.\nFollowing the pioneering work of Lindgren et al. (2011), we expound on the link\nbetween Markovian Gaussian random fields and GMRFs. In particular, we discuss\nthe theoretical and practical aspects of fast computation with continuously\nspecified Markovian Gaussian random fields, as well as the clear advantages\nthey offer in terms of clear, parsimonious and interpretable models of\nanisotropy and non-stationarity.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2011 13:58:33 GMT"}], "update_date": "2011-11-01", "authors_parsed": [["Simpson", "Daniel", ""], ["Lindgren", "Finn", ""], ["Rue", "H\u00e5vard", ""]]}]