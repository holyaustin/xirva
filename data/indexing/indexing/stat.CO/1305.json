[{"id": "1305.0320", "submitter": "Radford M. Neal", "authors": "Alexander Y. Shestopaloff and Radford M. Neal", "title": "MCMC for non-linear state space models using ensembles of latent\n  sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-linear state space models are a widely-used class of models for\nbiological, economic, and physical processes. Fitting these models to observed\ndata is a difficult inference problem that has no straightforward solution. We\ntake a Bayesian approach to the inference of unknown parameters of a non-linear\nstate model; this, in turn, requires the availability of efficient Markov Chain\nMonte Carlo (MCMC) sampling methods for the latent (hidden) variables and model\nparameters. Using the ensemble technique of Neal (2010) and the embedded HMM\ntechnique of Neal (2003), we introduce a new Markov Chain Monte Carlo method\nfor non-linear state space models. The key idea is to perform parameter updates\nconditional on an enormously large ensemble of latent sequences, as opposed to\na single sequence, as with existing methods. We look at the performance of this\nensemble method when doing Bayesian inference in the Ricker model of population\ndynamics. We show that for this problem, the ensemble method is vastly more\nefficient than a simple Metropolis method, as well as 1.9 to 12.0 times more\nefficient than a single-sequence embedded HMM method, when all methods are\ntuned appropriately. We also introduce a way of speeding up the ensemble method\nby performing partial backward passes to discard poor proposals at low\ncomputational cost, resulting in a final efficiency gain of 3.4 to 20.4 times\nover the single-sequence method.\n", "versions": [{"version": "v1", "created": "Thu, 2 May 2013 01:01:13 GMT"}], "update_date": "2013-05-03", "authors_parsed": [["Shestopaloff", "Alexander Y.", ""], ["Neal", "Radford M.", ""]]}, {"id": "1305.0759", "submitter": "Pritam Ranjan", "authors": "Blake MacDonald and Pritam Ranjan and Hugh Chipman", "title": "GPfit: An R package for Gaussian Process Model Fitting using a New\n  Optimization Algorithm", "comments": "20 pages, 17 images", "journal-ref": "Journal of Statistical Software, 64 (12), 1-23, 2015", "doi": "10.18637/jss.v064.i12", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian process (GP) models are commonly used statistical metamodels for\nemulating expensive computer simulators. Fitting a GP model can be numerically\nunstable if any pair of design points in the input space are close together.\nRanjan, Haynes, and Karsten (2011) proposed a computationally stable approach\nfor fitting GP models to deterministic computer simulators. They used a genetic\nalgorithm based approach that is robust but computationally intensive for\nmaximizing the likelihood. This paper implements a slightly modified version of\nthe model proposed by Ranjan et al. (2011), as the new R package GPfit. A novel\nparameterization of the spatial correlation function and a new multi-start\ngradient based optimization algorithm yield optimization that is robust and\ntypically faster than the genetic algorithm based approach. We present two\nexamples with R codes to illustrate the usage of the main functions in GPfit.\nSeveral test functions are used for performance comparison with a popular R\npackage mlegp. GPfit is a free software and distributed under the general\npublic license, as part of the R software project (R Development Core Team\n2012).\n", "versions": [{"version": "v1", "created": "Fri, 3 May 2013 15:57:49 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["MacDonald", "Blake", ""], ["Ranjan", "Pritam", ""], ["Chipman", "Hugh", ""]]}, {"id": "1305.1232", "submitter": "Giovanna Jona Lasinio professor", "authors": "Fabio Divino, Natalia Golini, Giovanna Jona Lasinio, Antti Penttinen", "title": "Bayesian Modeling and MCMC Computation in Linear Logistic Regression for\n  Presence-only Data", "comments": "Affiliations: Fabio Divino - Division of Physics, Computer Science\n  and Mathematics, University of Molise Giovanna jona Lasinio and Natalia\n  Golini - Department of Statistical Sciences, University of Rome \"La Sapienza\"\n  Antti Penttinen - Department of Mathematics and Statistics, University of\n  Jyv\\\"{a}skyl\\\"{a} CONTACT: fabio.divino@unimol.it,\n  giovanna.jonalasinio@uniroma1.it", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Presence-only data are referred to situations in which, given a censoring\nmechanism, a binary response can be observed only with respect to on outcome,\nusually called \\textit{presence}. In this work we present a Bayesian approach\nto the problem of presence-only data based on a two levels scheme. A\nprobability law and a case-control design are combined to handle the double\nsource of uncertainty: one due to the censoring and one due to the sampling. We\npropose a new formalization for the logistic model with presence-only data that\nallows further insight into inferential issues related to the model. We\nconcentrate on the case of the linear logistic regression and, in order to make\ninference on the parameters of interest, we present a Markov Chain Monte Carlo\nalgorithm with data augmentation that does not require the a priori knowledge\nof the population prevalence. A simulation study concerning 24,000 simulated\ndatasets related to different scenarios is presented comparing our proposal to\noptimal benchmarks.\n", "versions": [{"version": "v1", "created": "Mon, 6 May 2013 16:03:48 GMT"}], "update_date": "2013-05-07", "authors_parsed": [["Divino", "Fabio", ""], ["Golini", "Natalia", ""], ["Lasinio", "Giovanna Jona", ""], ["Penttinen", "Antti", ""]]}, {"id": "1305.2235", "submitter": "Radford M. Neal", "authors": "Chunyi Wang and Radford M. Neal", "title": "MCMC methods for Gaussian process models using fast approximations for\n  the likelihood", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian Process (GP) models are a powerful and flexible tool for\nnon-parametric regression and classification. Computation for GP models is\nintensive, since computing the posterior density, $\\pi$, for covariance\nfunction parameters requires computation of the covariance matrix, C, a $pn^2$\noperation, where p is the number of covariates and n is the number of training\ncases, and then inversion of C, an $n^3$ operation. We introduce MCMC methods\nbased on the \"temporary mapping and caching\" framework, using a fast\napproximation, $\\pi^*$, as the distribution needed to construct the temporary\nspace. We propose two implementations under this scheme: \"mapping to a\ndiscretizing chain\", and \"mapping with tempered transitions\", both of which are\nexactly correct MCMC methods for sampling $\\pi$, even though their transitions\nare constructed using an approximation. These methods are equivalent when their\ntuning parameters are set at the simplest values, but differ in general. We\ncompare how well these methods work when using several approximations, finding\non synthetic datasets that a $\\pi^*$ based on the \"Subset of Data\" (SOD) method\nis almost always more efficient than standard MCMC using only $\\pi$. On some\ndatasets, a more sophisticated $\\pi^*$ based on the \"Nystr\\\"om-Cholesky\" method\nworks better than SOD.\n", "versions": [{"version": "v1", "created": "Fri, 10 May 2013 00:59:32 GMT"}], "update_date": "2013-05-13", "authors_parsed": [["Wang", "Chunyi", ""], ["Neal", "Radford M.", ""]]}, {"id": "1305.3585", "submitter": "Mathew McLean", "authors": "Mathew W. McLean, Fabian Scheipl, Giles Hooker, Sonja Greven, and\n  David Ruppert", "title": "Bayesian Functional Generalized Additive Models with Sparsely Observed\n  Covariates", "comments": "substantial updates based on referee comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The functional generalized additive model (FGAM) was recently proposed in\nMcLean et al. (2013) as a more flexible alternative to the common functional\nlinear model (FLM) for regressing a scalar on functional covariates. In this\npaper, we develop a Bayesian version of FGAM for the case of Gaussian errors\nwith identity link function. Our approach allows the functional covariates to\nbe sparsely observed and measured with error, whereas the estimation procedure\nof McLean et al. (2013) required that they be noiselessly observed on a regular\ngrid. We consider both Monte Carlo and variational Bayes methods for fitting\nthe FGAM with sparsely observed covariates. Due to the complicated form of the\nmodel posterior distribution and full conditional distributions, standard Monte\nCarlo and variational Bayes algorithms cannot be used. The strategies we use to\nhandle the updating of parameters without closed-form full conditionals should\nbe of independent interest to applied Bayesian statisticians working with\nnonconjugate models. Our numerical studies demonstrate the benefits of our\nalgorithms over a two-step approach of first recovering the complete\ntrajectories using standard techniques and then fitting a functional regression\nmodel. In a real data analysis, our methods are applied to forecasting closing\nprice for items up for auction on the online auction website eBay.\n", "versions": [{"version": "v1", "created": "Wed, 15 May 2013 18:49:44 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 13:56:12 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["McLean", "Mathew W.", ""], ["Scheipl", "Fabian", ""], ["Hooker", "Giles", ""], ["Greven", "Sonja", ""], ["Ruppert", "David", ""]]}, {"id": "1305.3697", "submitter": "Roberto Fontana", "authors": "Roberto Fontana", "title": "Random Latin squares and Sudoku designs generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniform random generation of Latin squares is a classical problem. In this\npaper we prove that both Latin squares and Sudoku designs are maximum cliques\nof properly defined graphs. We have developed a simple algorithm for uniform\nrandom sampling of Latin squares and Sudoku designs. It makes use of recent\ntools for graph analysis. The corresponding SAS code is annexed.\n", "versions": [{"version": "v1", "created": "Thu, 16 May 2013 07:39:18 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Fontana", "Roberto", ""]]}, {"id": "1305.4366", "submitter": "Xiang Zhou", "authors": "Xiang Zhou and Matthew Stephens", "title": "Efficient Algorithms for Multivariate Linear Mixed Models in Genome-wide\n  Association Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate linear mixed models (mvLMMs) have been widely used in many areas\nof genetics, and have attracted considerable recent interest in genome-wide\nassociation studies (GWASs). However, fitting mvLMMs is computationally\nnon-trivial, and no existing method is computationally practical for performing\nthe likelihood ratio test (LRT) for mvLMMs in GWAS settings with moderate\nsample size n. The existing software MTMM perform an approximate LRT for two\nphenotypes, and as we find, its p values can substantially understate the\nsignificance of associations. Here, we present novel computationally-efficient\nalgorithms for fitting mvLMMs, and computing the LRT in GWAS settings. After a\nsingle initial eigen-decomposition (with complexity O(n^3)) the algorithms i)\nreduce computational complexity (per iteration of the optimizer) from cubic to\nlinear in n; and ii) in GWAS analyses, reduces per-marker complexity from cubic\nto quadratic in n. These innovations make it practical to compute the LRT for\nmvLMMs in GWASs for tens of thousands of samples and a moderate number of\nphenotypes (~2-10). With simulations, we show that the LRT provides correct\ncontrol for type I error. With both simulations and real data we find that the\nLRT is more powerful than the approximate LRT from MTMM, and illustrate the\nbenefits of analyzing more than two phenotypes. The method is implemented in\nthe GEMMA software package, freely available at\nhttp://stephenslab.uchicago.edu/software.html\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2013 14:53:48 GMT"}, {"version": "v2", "created": "Wed, 11 Sep 2013 21:10:44 GMT"}], "update_date": "2013-09-13", "authors_parsed": [["Zhou", "Xiang", ""], ["Stephens", "Matthew", ""]]}, {"id": "1305.4390", "submitter": "Libo Sun", "authors": "Libo Sun, Chihoon Lee, and Jennifer A. Hoeting", "title": "A penalized simulated maximum likelihood approach in parameter\n  estimation for stochastic differential equations", "comments": "23 pages, 4 figures, 3 tables", "journal-ref": "Computational Statistics & Data Analysis 84 (2015): 54-67", "doi": "10.1016/j.csda.2014.11.007", "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating parameters of stochastic differential\nequations (SDEs) with discrete-time observations that are either completely or\npartially observed. The transition density between two observations is\ngenerally unknown. We propose an importance sampling approach with an auxiliary\nparameter when the transition density is unknown. We embed the auxiliary\nimportance sampler in a penalized maximum likelihood framework which produces\nmore accurate and computationally efficient parameter estimates. Simulation\nstudies in three different models illustrate promising improvements of the new\npenalized simulated maximum likelihood method. The new procedure is designed\nfor the challenging case when some state variables are unobserved and moreover,\nobserved states are sparse over time, which commonly arises in ecological\nstudies. We apply this new approach to two epidemics of chronic wasting disease\nin mule deer.\n", "versions": [{"version": "v1", "created": "Sun, 19 May 2013 18:42:46 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2013 17:03:19 GMT"}, {"version": "v3", "created": "Wed, 21 May 2014 02:41:56 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2015 18:24:06 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Sun", "Libo", ""], ["Lee", "Chihoon", ""], ["Hoeting", "Jennifer A.", ""]]}, {"id": "1305.4669", "submitter": "Antonio Punzo", "authors": "Antonio Punzo and Paul D. McNicholas", "title": "Parsimonious mixtures of multivariate contaminated normal distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mixture of multivariate contaminated normal distributions is developed for\nmodel-based clustering. In addition to the parameters of the classical normal\nmixture, our contaminated mixture has, for each cluster, a parameter\ncontrolling the proportion of mild outliers and one specifying the degree of\ncontamination. Crucially, these parameters do not have to be specified a\npriori, adding a flexibility to our approach. Parsimony is introduced via\neigen-decomposition of the component covariance matrices, and sufficient\nconditions for the identifiability of all the members of the resulting family\nare provided. An expectation-conditional maximization algorithm is outlined for\nparameter estimation and various implementation issues are discussed. Using a\nlarge scale simulation study, the behaviour of the proposed approach is\ninvestigated and comparison with well-established finite mixtures is provided.\nThe performance of this novel family of models is also illustrated on\nartificial and real data.\n", "versions": [{"version": "v1", "created": "Mon, 20 May 2013 22:29:30 GMT"}, {"version": "v2", "created": "Tue, 31 Dec 2013 21:46:40 GMT"}, {"version": "v3", "created": "Wed, 9 Apr 2014 10:03:32 GMT"}, {"version": "v4", "created": "Mon, 20 Jul 2015 10:35:17 GMT"}, {"version": "v5", "created": "Thu, 19 May 2016 09:58:08 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Punzo", "Antonio", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1305.4886", "submitter": "Christopher Paciorek", "authors": "Christopher J. Paciorek, Benjamin Lipshitz, Wei Zhuo, Prabhat, Cari G.\n  Kaufman, Rollin C. Thomas", "title": "Parallelizing Gaussian Process Calculations in R", "comments": "21 pages, 8 figures", "journal-ref": "Journal of Statistical Software 2015, Vol. 63, Number 10, 1-23", "doi": "10.18637/jss.v063.i10", "report-no": null, "categories": "stat.CO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider parallel computation for Gaussian process calculations to\novercome computational and memory constraints on the size of datasets that can\nbe analyzed. Using a hybrid parallelization approach that uses both threading\n(shared memory) and message-passing (distributed memory), we implement the core\nlinear algebra operations used in spatial statistics and Gaussian process\nregression in an R package called bigGP that relies on C and MPI. The approach\ndivides the matrix into blocks such that the computational load is balanced\nacross processes while communication between processes is limited. The package\nprovides an API enabling R programmers to implement Gaussian process-based\nmethods by using the distributed linear algebra operations without any C or MPI\ncoding. We illustrate the approach and software by analyzing an astrophysics\ndataset with n=67,275 observations.\n", "versions": [{"version": "v1", "created": "Tue, 21 May 2013 17:08:54 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Paciorek", "Christopher J.", ""], ["Lipshitz", "Benjamin", ""], ["Zhuo", "Wei", ""], ["Prabhat", "", ""], ["Kaufman", "Cari G.", ""], ["Thomas", "Rollin C.", ""]]}, {"id": "1305.5017", "submitter": "Luke Bornn", "authors": "Luke Bornn", "title": "PAWL-Forced Simulated Tempering", "comments": "Proceedings of BAYSM, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note, we show how the parallel adaptive Wang-Landau (PAWL)\nalgorithm of Bornn et al. (2013) can be used to automate and improve simulated\ntempering algorithms. While Wang-Landau and other stochastic approximation\nmethods have frequently been applied within the simulated tempering framework,\nthis note demonstrates through a simple example the additional improvements\nbrought about by parallelization, adaptive proposals and automated bin\nsplitting.\n", "versions": [{"version": "v1", "created": "Wed, 22 May 2013 04:01:38 GMT"}], "update_date": "2013-05-23", "authors_parsed": [["Bornn", "Luke", ""]]}, {"id": "1305.5879", "submitter": "Hanwen Huang", "authors": "Hanwen Huang, Yufeng Liu, Ming Yuan, J. S. Marron", "title": "Statistical Significance of Clustering using Soft Thresholding", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Clustering methods have led to a number of important discoveries in\nbioinformatics and beyond. A major challenge in their use is determining which\nclusters represent important underlying structure, as opposed to spurious\nsampling artifacts. This challenge is especially serious, and very few methods\nare available when the data are very high in dimension. Statistical\nSignificance of Clustering (SigClust) is a recently developed cluster\nevaluation tool for high dimensional low sample size data. An important\ncomponent of the SigClust approach is the very definition of a single cluster\nas a subset of data sampled from a multivariate Gaussian distribution. The\nimplementation of SigClust requires the estimation of the eigenvalues of the\ncovariance matrix for the null multivariate Gaussian distribution. We show that\nthe original eigenvalue estimation can lead to a test that suffers from severe\ninflation of type-I error, in the important case where there are huge single\nspikes in the eigenvalues. This paper addresses this critical challenge using a\nnovel likelihood based soft thresholding approach to estimate these eigenvalues\nwhich leads to a much improved SigClust. These major improvements in SigClust\nperformance are shown by both theoretical work and an extensive simulation\nstudy. Applications to some cancer genomic data further demonstrate the\nusefulness of these improvements.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2013 02:08:03 GMT"}, {"version": "v2", "created": "Wed, 29 May 2013 01:08:38 GMT"}], "update_date": "2013-05-30", "authors_parsed": [["Huang", "Hanwen", ""], ["Liu", "Yufeng", ""], ["Yuan", "Ming", ""], ["Marron", "J. S.", ""]]}, {"id": "1305.6736", "submitter": "Ajay Jasra", "authors": "Ajay Jasra, Junshan Wang", "title": "An Adaptive Sequential Monte Carlo Algorithm for Computing Permanents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the computation of the permanent of a binary n by n matrix. It is\nwell- known that the exact computation is a #P complete problem. A variety of\nMarkov chain Monte Carlo (MCMC) computational algorithms have been introduced\nin the literature whose cost, in order to achieve a given level of accuracy, is\nO(n^7 log^4(n)). These algorithms use a particular collection of probability\ndistributions, the `ideal' of which, (in some sense) are not known and need to\nbe approximated. In this paper we propose an adaptive sequential Monte Carlo\n(SMC) algorithm that can both estimate the permanent and the ideal sequence of\nprobabilities on the fly, with little user input. We provide theoretical\nresults associated to the SMC estimate of the permanent, establishing its\nconvergence and analyzing the relative variance of the estimate, in particular\ncomputating explicit bounds on the relative variance which depend upon n. Using\nthis latter result, we provide a lower-bound on the computational cost, in\norder to achieve an arbitrarily small relative variance; we find that this cost\nis O(n^4 log^4(n)). Some numerical simulations are also given.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2013 09:15:48 GMT"}], "update_date": "2013-05-30", "authors_parsed": [["Jasra", "Ajay", ""], ["Wang", "Junshan", ""]]}, {"id": "1305.6738", "submitter": "Efstratios Rappos", "authors": "Efstratios Rappos and Stephan Robert", "title": "Using GPU Simulation to Accurately Fit to the Power-Law Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DC physics.comp-ph physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a methodology for fitting experimental data to the\ndiscrete power-law distribution and provides the results of a detailed\nsimulation exercise used to calculate accurate cutoff values used to assess the\nfit to a power-law distribution when using the maximum likelihood estimation\nfor the exponent of the distribution. Using massively parallel programming\ncomputing, we were able to accelerate by a factor of 60 the computational time\nrequired for these calculations across a range of parameters and construct a\nseries of detailed tables containing the test values to be used in a\nKolmogorov-Smirnov goodness-of-fit test, allowing for an accurate assessment of\nthe power-law fit from empirical data.\n", "versions": [{"version": "v1", "created": "Wed, 29 May 2013 09:26:41 GMT"}], "update_date": "2013-05-30", "authors_parsed": [["Rappos", "Efstratios", ""], ["Robert", "Stephan", ""]]}, {"id": "1305.7285", "submitter": "Subhabrata Majumdar", "authors": "Subhabrata Majumdar, Subhash C. Basak, Gregory D. Grunwald", "title": "Adapting the Interrelated Two-way Clustering method for Quantitative\n  Structure-Activity Relationship (QSAR) Modeling of a Diverse Set of Chemical\n  Compounds", "comments": null, "journal-ref": "Curr. Comput. Aided Drug Des. 9-4 (2013) 463-471", "doi": "10.2174/15734099113096660045", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interrelated Two-way Clustering (ITC) is an unsupervised clustering method\ndeveloped to divide samples into two groups in gene expression data obtained\nthrough microarrays, selecting important genes simultaneously in the process.\nThis has been found to be a better approach than conventional clustering\nmethods like K-means or self-organizing map for the scenarios when number of\nsamples much smaller than number of variables (n<<p). In this paper we used the\nITC approach for classification of a diverse set of 508 chemicals regarding\nmutagenicity. A large number of topological indices (TIs), 3-dimensional, and\nquantum chemical descriptors, as well as atom pairs (APs) have been used as\nexplanatory variables. In this paper, ITC has been used only for predictor\nselection, after which ridge regression is employed to build the final\npredictive model. The proper leave-one-out (LOO) method of cross-validation in\nthis scenario is to take as holdout each of the 508 compounds before predictor\nthinning and compare the predicted values with the experimental data. ITC based\nresults obtained here are comparable to those developed earlier.\n", "versions": [{"version": "v1", "created": "Fri, 31 May 2013 02:31:10 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Majumdar", "Subhabrata", ""], ["Basak", "Subhash C.", ""], ["Grunwald", "Gregory D.", ""]]}]