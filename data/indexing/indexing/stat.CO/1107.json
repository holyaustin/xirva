[{"id": "1107.1546", "submitter": "Gabriel Terejanu", "authors": "Gabriel Terejanu, Puneet Singla, Tarunraj Singh, Peter D. Scott", "title": "Decision Based Uncertainty Propagation Using Adaptive Gaussian Mixtures", "comments": "The 12th International Conference on Information Fusion, Seattle,\n  Washington, July 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.PR nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a decision process based on the approximate probability density\nfunction returned by a data assimilation algorithm, an interaction level\nbetween the decision making level and the data assimilation level is designed\nto incorporate the information held by the decision maker into the data\nassimilation process. Here the information held by the decision maker is a loss\nfunction at a decision time which maps the state space onto real numbers which\nrepresent the threat associated with different possible outcomes or states. The\nnew probability density function obtained will address the region of interest,\nthe area in the state space with the highest threat, and will provide overall a\nbetter approximation to the true conditional probability density function\nwithin it. The approximation used for the probability density function is a\nGaussian mixture and a numerical example is presented to illustrate the\nconcept.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2011 02:16:01 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Terejanu", "Gabriel", ""], ["Singla", "Puneet", ""], ["Singh", "Tarunraj", ""], ["Scott", "Peter D.", ""]]}, {"id": "1107.1547", "submitter": "Gabriel Terejanu", "authors": "Gabriel Terejanu, Puneet Singla, Tarunraj Singh, Peter D. Scott", "title": "Approximate Interval Method for Epistemic Uncertainty Propagation using\n  Polynomial Chaos and Evidence Theory", "comments": "2010 American Control Conference, Baltimore, Maryland, June 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.PR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper builds upon a recent approach to find the approximate bounds of a\nreal function using Polynomial Chaos expansions. Given a function of random\nvariables with compact support probability distributions, the intuition is to\nquantify the uncertainty in the response using Polynomial Chaos expansion and\ndiscard all the information provided about the randomness of the output and\nextract only the bounds of its compact support. To solve for the bounding range\nof polynomials, we transform the Polynomial Chaos expansion in the Bernstein\nform, and use the range enclosure property of Bernstein polynomials to find the\nminimum and maximum value of the response. This procedure is used to propagate\nDempster-Shafer structures on closed intervals through nonlinear functions and\nit is applied on an algebraic challenge problem.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2011 02:20:59 GMT"}], "update_date": "2011-07-11", "authors_parsed": [["Terejanu", "Gabriel", ""], ["Singla", "Puneet", ""], ["Singh", "Tarunraj", ""], ["Scott", "Peter D.", ""]]}, {"id": "1107.1548", "submitter": "Gabriel Terejanu", "authors": "Gabriel Terejanu, Puneet Singla, Tarunraj Singh, Peter D. Scott", "title": "Approximate Propagation of both Epistemic and Aleatory Uncertainty\n  through Dynamic Systems", "comments": "The 13th International Conference on Information Fusion, Edinburgh,\n  UK, July 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.DS math.PR nlin.CD stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When ignorance due to the lack of knowledge, modeled as epistemic uncertainty\nusing Dempster-Shafer structures on closed intervals, is present in the model\nparameters, a new uncertainty propagation method is necessary to propagate both\naleatory and epistemic uncertainty. The new framework proposed here, combines\nboth epistemic and aleatory uncertainty into a second-order uncertainty\nrepresentation which is propagated through a dynamic system driven by white\nnoise. First, a finite parametrization is chosen to model the aleatory\nuncertainty by choosing a representative approximation to the probability\ndensity function conditioned on epistemic variables. The epistemic uncertainty\nis then propagated through the moment evolution equations of the conditional\nprobability density function. This way we are able to model the ignorance when\nthe knowledge about the system is incomplete. The output of the system is a\nDempster-Shafer structure on sets of cumulative distributions which can be\ncombined using different rules of combination and eventually transformed into a\nsingleton cumulative distribution function using Smets' pignistic\ntransformation when decision making is needed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2011 02:25:20 GMT"}], "update_date": "2011-07-11", "authors_parsed": [["Terejanu", "Gabriel", ""], ["Singla", "Puneet", ""], ["Singh", "Tarunraj", ""], ["Scott", "Peter D.", ""]]}, {"id": "1107.1697", "submitter": "Aiyou Chen", "authors": "Aiyou Chen, Jin Cao, Larry Shepp and Tuan Nguyen", "title": "Distinct counting with a self-learning bitmap", "comments": "Journal of the American Statistical Association (accepted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counting the number of distinct elements (cardinality) in a dataset is a\nfundamental problem in database management. In recent years, due to many of its\nmodern applications, there has been significant interest to address the\ndistinct counting problem in a data stream setting, where each incoming data\ncan be seen only once and cannot be stored for long periods of time. Many\nprobabilistic approaches based on either sampling or sketching have been\nproposed in the computer science literature, that only require limited\ncomputing and memory resources. However, the performances of these methods are\nnot scale-invariant, in the sense that their relative root mean square\nestimation errors (RRMSE) depend on the unknown cardinalities. This is not\ndesirable in many applications where cardinalities can be very dynamic or\ninhomogeneous and many cardinalities need to be estimated. In this paper, we\ndevelop a novel approach, called self-learning bitmap (S-bitmap) that is\nscale-invariant for cardinalities in a specified range. S-bitmap uses a binary\nvector whose entries are updated from 0 to 1 by an adaptive sampling process\nfor inferring the unknown cardinality, where the sampling rates are reduced\nsequentially as more and more entries change from 0 to 1. We prove rigorously\nthat the S-bitmap estimate is not only unbiased but scale-invariant. We\ndemonstrate that to achieve a small RRMSE value of $\\epsilon$ or less, our\napproach requires significantly less memory and consumes similar or less\noperations than state-of-the-art methods for many common practice cardinality\nscales. Both simulation and experimental studies are reported.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2011 18:50:16 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Chen", "Aiyou", ""], ["Cao", "Jin", ""], ["Shepp", "Larry", ""], ["Nguyen", "Tuan", ""]]}, {"id": "1107.2205", "submitter": "Giusi Moffa", "authors": "Giusi Moffa and Jack Kuipers", "title": "Sequential Monte Carlo EM for multivariate probit models", "comments": "26 pages, 2 figures. In press, Computational Statistics & Data\n  Analysis", "journal-ref": null, "doi": "10.1016/j.csda.2013.10.019", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate probit models (MPM) have the appealing feature of capturing some\nof the dependence structure between the components of multidimensional binary\nresponses. The key for the dependence modelling is the covariance matrix of an\nunderlying latent multivariate Gaussian. Most approaches to MLE in multivariate\nprobit regression rely on MCEM algorithms to avoid computationally intensive\nevaluations of multivariate normal orthant probabilities. As an alternative to\nthe much used Gibbs sampler a new SMC sampler for truncated multivariate\nnormals is proposed. The algorithm proceeds in two stages where samples are\nfirst drawn from truncated multivariate Student $t$ distributions and then\nfurther evolved towards a Gaussian. The sampler is then embedded in a MCEM\nalgorithm. The sequential nature of SMC methods can be exploited to design a\nfully sequential version of the EM, where the samples are simply updated from\none iteration to the next rather than resampled from scratch. Recycling the\nsamples in this manner significantly reduces the computational cost. An\nalternative view of the standard conditional maximisation step provides the\nbasis for an iterative procedure to fully perform the maximisation needed in\nthe EM algorithm. The identifiability of MPM is also thoroughly discussed. In\nparticular, the likelihood invariance can be embedded in the EM algorithm to\nensure that constrained and unconstrained maximisation are equivalent. A simple\niterative procedure is then derived for either maximisation which takes\neffectively no computational time. The method is validated by applying it to\nthe widely analysed Six Cities dataset and on a higher dimensional simulated\nexample. Previous approaches to the Six Cities overly restrict the parameter\nspace but, by considering the correct invariance, the maximum likelihood is\nquite naturally improved when treating the full unrestricted model.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2011 07:54:26 GMT"}, {"version": "v2", "created": "Thu, 14 Nov 2013 20:52:58 GMT"}], "update_date": "2013-11-15", "authors_parsed": [["Moffa", "Giusi", ""], ["Kuipers", "Jack", ""]]}, {"id": "1107.2691", "submitter": "Paolo D'Alberto", "authors": "Paolo D'Alberto and Ali Dasdan", "title": "On the Weakenesses of Correlation Measures used for Search Engines'\n  Results (Unsupervised Comparison of Search Engine Rankings)", "comments": "16 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correlation of the result lists provided by search engines is fundamental\nand it has deep and multidisciplinary ramifications. Here, we present automatic\nand unsupervised methods to assess whether or not search engines provide\nresults that are comparable or correlated. We have two main contributions:\nFirst, we provide evidence that for more than 80% of the input queries -\nindependently of their frequency - the two major search engines share only\nthree or fewer URLs in their search results, leading to an increasing\ndivergence. In this scenario (divergence), we show that even the most robust\nmeasures based on comparing lists is useless to apply; that is, the small\ncontribution by too few common items will infer no confidence. Second, to\novercome this problem, we propose the fist content-based measures - i.e.,\ndirect comparison of the contents from search results; these measures are based\non the Jaccard ratio and distribution similarity measures (CDF measures). We\nshow that they are orthogonal to each other (i.e., Jaccard and distribution)\nand extend the discriminative power w.r.t. list based measures. Our approach\nstems from the real need of comparing search-engine results, it is automatic\nfrom the query selection to the final evaluation and it apply to any\ngeographical markets, thus designed to scale and to use as first filtering of\nquery selection (necessary) for supervised methods.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jul 2011 22:35:07 GMT"}], "update_date": "2011-07-15", "authors_parsed": [["D'Alberto", "Paolo", ""], ["Dasdan", "Ali", ""]]}, {"id": "1107.4047", "submitter": "Eric Ford", "authors": "Eric B. Ford (UF), Althea V. Moorhead (UF), Dimitri Veras (UF, IoA)", "title": "A Bayesian Surrogate Model for Rapid Time Series Analysis and\n  Application to Exoplanet Observations", "comments": "25 pages, 4 figures, accepted to Bayesian Analysis\n  <http://ba.stat.cmu.edu>, special issue for Ninth Valencia International\n  Conference on Bayesian Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME astro-ph.EP astro-ph.IM stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian surrogate model for the analysis of periodic or\nquasi-periodic time series data. We describe a computationally efficient\nimplementation that enables Bayesian model comparison. We apply this model to\nsimulated and real exoplanet observations. We discuss the results and\ndemonstrate some of the challenges for applying our surrogate model to\nrealistic exoplanet data sets. In particular, we find that analyses of real\nworld data should pay careful attention to the effects of uneven spacing of\nobservations and the choice of prior for the \"jitter\" parameter.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2011 17:47:43 GMT"}], "update_date": "2011-07-21", "authors_parsed": [["Ford", "Eric B.", "", "UF"], ["Moorhead", "Althea V.", "", "UF"], ["Veras", "Dimitri", "", "UF, IoA"]]}, {"id": "1107.5342", "submitter": "Julio Stern", "authors": "Julio M. Stern", "title": "Esparsidade, Estrutura, Escalamento e Estabilidade em Algebra Linear\n  Computacional", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparsity, Structure, Scaling and Stability in Computational Linear Algebra -\nTextbook from the IX School of Computer Science, held on July 24-31 of 1994 at\nRecife, Brazil.\n  Esparsidade, Estrutura, Escalamento e Estabilidade em Algebra Linear\nComputacional - Livro texto da IX Escola de Computacao, realizada nos dias 24 a\n31 de Julho de 1994 em Recife, Brasil.\n  This textbook is written in Portuguese Language.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2011 16:05:37 GMT"}, {"version": "v2", "created": "Thu, 28 Jul 2011 16:54:13 GMT"}], "update_date": "2011-07-29", "authors_parsed": [["Stern", "Julio M.", ""]]}, {"id": "1107.5829", "submitter": "Aaron Smith", "authors": "Aaron Smith", "title": "A Gibbs sampler on the $n$-simplex", "comments": "Published in at http://dx.doi.org/10.1214/12-AAP916 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 1, 114-130", "doi": "10.1214/12-AAP916", "report-no": "IMS-AAP-AAP916", "categories": "math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We determine the mixing time of a simple Gibbs sampler on the unit simplex,\nconfirming a conjecture of Aldous. The upper bound is based on a two-step\ncoupling, where the first step is a simple contraction argument and the second\nstep is a non-Markovian coupling. We also present a MCMC-based perfect sampling\nalgorithm based on our proof which can be applied with Gibbs samplers that are\nharder to analyze.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jul 2011 20:53:00 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2014 12:02:43 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Smith", "Aaron", ""]]}, {"id": "1107.5959", "submitter": "Simon Barthelm\\'e", "authors": "Simon Barthelm\\'e, Nicolas Chopin", "title": "Expectation-Propagation for Likelihood-Free Inference", "comments": "Revised version following peer-review", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many models of interest in the natural and social sciences have no\nclosed-form likelihood function, which means that they cannot be treated using\nthe usual techniques of statistical inference. In the case where such models\ncan be efficiently simulated, Bayesian inference is still possible thanks to\nthe Approximate Bayesian Computation (ABC) algorithm. Although many refinements\nhave been suggested, ABC inference is still far from routine. ABC is often\nexcruciatingly slow due to very low acceptance rates. In addition, ABC requires\nintroducing a vector of \"summary statistics\", the choice of which is relatively\narbitrary, and often require some trial and error, making the whole process\nquite laborious for the user.\n  We introduce in this work the EP-ABC algorithm, which is an adaptation to the\nlikelihood-free context of the variational approximation algorithm known as\nExpectation Propagation (Minka, 2001). The main advantage of EP-ABC is that it\nis faster by a few orders of magnitude than standard algorithms, while\nproducing an overall approximation error which is typically negligible. A\nsecond advantage of EP-ABC is that it replaces the usual global ABC constraint\non the vector of summary statistics computed on the whole dataset, by n local\nconstraints of the form that apply separately to each data-point. As a\nconsequence, it is often possible to do away with summary statistics entirely.\nIn that case, EP-ABC approximates directly the evidence (marginal likelihood)\nof the model.\n  Comparisons are performed in three real-world applications which are typical\nof likelihood-free inference, including one application in neuroscience which\nis novel, and possibly too challenging for standard ABC techniques.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2011 13:15:50 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2012 08:47:33 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Barthelm\u00e9", "Simon", ""], ["Chopin", "Nicolas", ""]]}]