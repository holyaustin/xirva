[{"id": "1204.0105", "submitter": "Ioannis Kosmidis", "authors": "Ioannis Kosmidis", "title": "Improved estimation in cumulative link models", "comments": null, "journal-ref": "J.R.Stat.Soc.B 76 (2014) 169-196", "doi": "10.1111/rssb.12025", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the estimation of cumulative link models for ordinal data, the\nbias-reducing adjusted score equations in \\citet{firth:93} are obtained, whose\nsolution ensures an estimator with smaller asymptotic bias than the maximum\nlikelihood estimator. Their form suggests a parameter-dependent adjustment of\nthe multinomial counts, which, in turn suggests the solution of the adjusted\nscore equations through iterated maximum likelihood fits on adjusted counts,\ngreatly facilitating implementation. Like the maximum likelihood estimator, the\nreduced-bias estimator is found to respect the invariance properties that make\ncumulative link models a good choice for the analysis of categorical data. Its\nadditional finiteness and optimal frequentist properties, along with the\nadequate behaviour of related asymptotic inferential procedures make the\nreduced-bias estimator attractive as a default choice for practical\napplications. Furthermore, the proposed estimator enjoys certain shrinkage\nproperties that are defensible from an experimental point of view relating to\nthe nature of ordinal data.\n", "versions": [{"version": "v1", "created": "Sat, 31 Mar 2012 15:07:44 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2012 19:26:17 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2013 23:39:33 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Kosmidis", "Ioannis", ""]]}, {"id": "1204.0798", "submitter": "Ralph Brinks", "authors": "Ralph Brinks", "title": "Fast Calculation of Calendar Time-, Age- and Duration Dependent Time at\n  Risk in the Lexis Space", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In epidemiology, the person-years method is broadly used to estimate the\nincidence rates of health related events. This needs determination of time at\nrisk stratified by period, age and sometimes by duration of disease or\nexposition. The article describes a fast method for calculating the time at\nrisk in two- or three-dimensional Lexis diagrams based on Siddon's algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 3 Apr 2012 20:21:40 GMT"}], "update_date": "2012-04-05", "authors_parsed": [["Brinks", "Ralph", ""]]}, {"id": "1204.2098", "submitter": "Matthias Katzfuss", "authors": "Matthias Katzfuss", "title": "Bayesian Nonstationary Spatial Modeling for Very Large Datasets", "comments": "16 pages, 2 color figures", "journal-ref": "Environmetrics 24 (2013) 189-200", "doi": "10.1002/env.2200", "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of modern high-resolution measuring instruments\nmounted on satellites, planes, ground-based vehicles and monitoring stations, a\nneed has arisen for statistical methods suitable for the analysis of large\nspatial datasets observed on large spatial domains. Statistical analyses of\nsuch datasets provide two main challenges: First, traditional\nspatial-statistical techniques are often unable to handle large numbers of\nobservations in a computationally feasible way. Second, for large and\nheterogeneous spatial domains, it is often not appropriate to assume that a\nprocess of interest is stationary over the entire domain.\n  We address the first challenge by using a model combining a low-rank\ncomponent, which allows for flexible modeling of medium-to-long-range\ndependence via a set of spatial basis functions, with a tapered remainder\ncomponent, which allows for modeling of local dependence using a compactly\nsupported covariance function. Addressing the second challenge, we propose two\nextensions to this model that result in increased flexibility: First, the model\nis parameterized based on a nonstationary Matern covariance, where the\nparameters vary smoothly across space. Second, in our fully Bayesian model, all\ncomponents and parameters are considered random, including the number,\nlocations, and shapes of the basis functions used in the low-rank component.\n  Using simulated data and a real-world dataset of high-resolution soil\nmeasurements, we show that both extensions can result in substantial\nimprovements over the current state-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 10 Apr 2012 10:36:45 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2012 10:03:30 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2012 11:28:53 GMT"}, {"version": "v4", "created": "Sat, 22 Sep 2012 10:18:06 GMT"}, {"version": "v5", "created": "Fri, 21 Dec 2012 15:58:51 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Katzfuss", "Matthias", ""]]}, {"id": "1204.2410", "submitter": "Marius Hofert", "authors": "Marius Hofert, David Pham", "title": "Densities of nested Archimedean copulas", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested Archimedean copulas recently gained interest since they generalize the\nwell-known class of Archimedean copulas to allow for partial asymmetry.\nSampling algorithms and strategies have been well investigated for nested\nArchimedean copulas. However, for likelihood based inference it is important to\nhave the density. The present work fills this gap. A general formula for the\nderivatives of the nodes and inner generators appearing in nested Archimedean\ncopulas is developed. This leads to a tractable formula for the density of\nnested Archimedean copulas in arbitrary dimensions if the number of nesting\nlevels is not too large. Various examples including famous Archimedean families\nand transformations of such are given. Furthermore, a numerically efficient way\nto evaluate the log-density is presented.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2012 10:54:22 GMT"}, {"version": "v2", "created": "Sun, 28 Oct 2012 22:35:06 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Hofert", "Marius", ""], ["Pham", "David", ""]]}, {"id": "1204.3187", "submitter": "Iain Murray", "authors": "Iain Murray and Lloyd T. Elliott", "title": "Driving Markov chain Monte Carlo with a dependent random stream", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo is a widely-used technique for generating a\ndependent sequence of samples from complex distributions. Conventionally, these\nmethods require a source of independent random variates. Most implementations\nuse pseudo-random numbers instead because generating true independent variates\nwith a physical system is not straightforward. In this paper we show how to\nmodify some commonly used Markov chains to use a dependent stream of random\nnumbers in place of independent uniform variates. The resulting Markov chains\nhave the correct invariant distribution without requiring detailed knowledge of\nthe stream's dependencies or even its marginal distribution. As a side-effect,\nsometimes far fewer random numbers are required to obtain accurate results.\n", "versions": [{"version": "v1", "created": "Sat, 14 Apr 2012 17:11:30 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Murray", "Iain", ""], ["Elliott", "Lloyd T.", ""]]}, {"id": "1204.3235", "submitter": "Xiaogang (Steven) Wang", "authors": "Xiaogang Wang and Jianhong Wu", "title": "Convergent and Anti-diffusive Properties of Mean-Shift Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An analytic framework based on partial differential equations is derived for\ncertain dynamic clustering methods.\n  The proposed mathematical framework is based on the application of the\nconservation law in physics to characterize successive transformations of the\nunderlying probability density function. It is then applied to analyze the\nconvergence and stability of mean shift type of dynamic clustering algorithms.\nTheoretical analysis shows that un-supervised mean-shift type of algorithm is\nintrinsically unstable. It is proved that the only possibility of a correct\nconvergence for unsupervised mean shift type of algorithm is to transform the\noriginal probability density into a multivariate normal distribution with no\ndependence struture. Our analytical results suggest that a more stable and\nconvergent mean shift algorithm might be achieved by adopting a judiciously\nchosen supervision mechanism.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2012 03:35:52 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2013 13:50:39 GMT"}], "update_date": "2013-07-11", "authors_parsed": [["Wang", "Xiaogang", ""], ["Wu", "Jianhong", ""]]}, {"id": "1204.3331", "submitter": "Hua Zhou", "authors": "Hua Zhou and Lexin Li", "title": "Regularized Matrix Regression", "comments": "27 pages, 5 figure", "journal-ref": null, "doi": "10.1111/rssb.12031", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Modern technologies are producing a wealth of data with complex structures.\nFor instance, in two-dimensional digital imaging, flow cytometry, and\nelectroencephalography, matrix type covariates frequently arise when\nmeasurements are obtained for each combination of two underlying variables. To\naddress scientific questions arising from those data, new regression methods\nthat take matrices as covariates are needed, and sparsity or other forms of\nregularization are crucial due to the ultrahigh dimensionality and complex\nstructure of the matrix data. The popular lasso and related regularization\nmethods hinge upon the sparsity of the true signal in terms of the number of\nits nonzero coefficients. However, for the matrix data, the true signal is\noften of, or can be well approximated by, a low rank structure. As such, the\nsparsity is frequently in the form of low rank of the matrix parameters, which\nmay seriously violate the assumption of the classical lasso. In this article,\nwe propose a class of regularized matrix regression methods based on spectral\nregularization. Highly efficient and scalable estimation algorithm is\ndeveloped, and a degrees of freedom formula is derived to facilitate model\nselection along the regularization path. Superior performance of the proposed\nmethod is demonstrated on both synthetic and real examples.\n", "versions": [{"version": "v1", "created": "Sun, 15 Apr 2012 22:58:36 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Zhou", "Hua", ""], ["Li", "Lexin", ""]]}, {"id": "1204.3339", "submitter": "Guilherme Pumi", "authors": "Guilherme Pumi and S\\'ilvia R. C. Lopes", "title": "Parameterization of Copulas and Covariance Decay of Stochastic Processes\n  with Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the problem of constructing stochastic processes with a\npredetermined covariance decay by parameterizing its marginals and a given\nfamily of copulas. We present several examples to illustrate the theory,\nincluding the important Gaussian and Euclidean families of copulas. We\nassociate the theory to common applied time series models and present a general\nmethodology to estimate a given parameter of interest identifiable through the\nprocess' covariance decay. To exemplify the proposed methodology, we present\nsimple Monte Carlo applications to parameter estimation in time series. The\nmethodology is also applied to the S&P500 US stock market index.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 00:54:45 GMT"}], "update_date": "2012-04-17", "authors_parsed": [["Pumi", "Guilherme", ""], ["Lopes", "S\u00edlvia R. C.", ""]]}, {"id": "1204.3547", "submitter": "Dave Higdon", "authors": "Dave Higdon, Matt Pratola, James Gattiker, Earl Lawrence, Salman\n  Habib, Katrin Heitmann, Steve Price, Charles Jackson, Michael Tobis", "title": "Computer Model Calibration using the Ensemble Kalman Filter", "comments": "20 pages; 11 figures", "journal-ref": null, "doi": null, "report-no": "LA-UR-12-20660", "categories": "stat.ME stat.CO", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The ensemble Kalman filter (EnKF) (Evensen, 2009) has proven effective in\nquantifying uncertainty in a number of challenging dynamic, state estimation,\nor data assimilation, problems such as weather forecasting and ocean modeling.\nIn these problems a high-dimensional state parameter is successively updated\nbased on recurring physical observations, with the aid of a computationally\ndemanding forward model that prop- agates the state from one time step to the\nnext. More recently, the EnKF has proven effective in history matching in the\npetroleum engineering community (Evensen, 2009; Oliver and Chen, 2010). Such\napplications typically involve estimating large numbers of parameters,\ndescribing an oil reservoir, using data from production history that accumulate\nover time. Such history matching problems are especially challenging examples\nof computer model calibration since they involve a large number of model\nparameters as well as a computationally demanding forward model. More\ngenerally, computer model calibration combines physical observations with a\ncomputational model - a computer model - to estimate unknown parameters in the\ncomputer model. This paper explores how the EnKF can be used in computer model\ncalibration problems, comparing it to other more common approaches, considering\napplications in climate and cosmology.\n", "versions": [{"version": "v1", "created": "Mon, 16 Apr 2012 16:03:23 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2012 23:54:01 GMT"}], "update_date": "2012-04-25", "authors_parsed": [["Higdon", "Dave", ""], ["Pratola", "Matt", ""], ["Gattiker", "James", ""], ["Lawrence", "Earl", ""], ["Habib", "Salman", ""], ["Heitmann", "Katrin", ""], ["Price", "Steve", ""], ["Jackson", "Charles", ""], ["Tobis", "Michael", ""]]}, {"id": "1204.3972", "submitter": "Bo Dai", "authors": "Yuan Qi and Bo Dai and Yao Zhu", "title": "EigenGP: Sparse Gaussian process models with data-dependent\n  eigenfunctions", "comments": "10 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian processes (GPs) provide a nonparametric representation of functions.\nHowever, classical GP inference suffers from high computational cost and it is\ndifficult to design nonstationary GP priors in practice. In this paper, we\npropose a sparse Gaussian process model, EigenGP, based on the Karhunen-Loeve\n(KL) expansion of a GP prior. We use the Nystrom approximation to obtain data\ndependent eigenfunctions and select these eigenfunctions by evidence\nmaximization. This selection reduces the number of eigenfunctions in our model\nand provides a nonstationary covariance function. To handle nonlinear\nlikelihoods, we develop an efficient expectation propagation (EP) inference\nalgorithm, and couple it with expectation maximization for eigenfunction\nselection. Because the eigenfunctions of a Gaussian kernel are associated with\nclusters of samples - including both the labeled and unlabeled - selecting\nrelevant eigenfunctions enables EigenGP to conduct semi-supervised learning.\nOur experimental results demonstrate improved predictive performance of EigenGP\nover alternative state-of-the-art sparse GP and semisupervised learning methods\nfor regression, classification, and semisupervised classification.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 04:43:24 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2012 21:23:54 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2013 21:55:59 GMT"}], "update_date": "2013-03-15", "authors_parsed": [["Qi", "Yuan", ""], ["Dai", "Bo", ""], ["Zhu", "Yao", ""]]}, {"id": "1204.4148", "submitter": "Vadim Asnin", "authors": "Vadim Asnin", "title": "Algorithm for multivariate data standardization up to third moment", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algorithm for transforming multivariate data to a form with normalized\nfirst, second and third moments is presented.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 17:46:32 GMT"}], "update_date": "2012-04-19", "authors_parsed": [["Asnin", "Vadim", ""]]}, {"id": "1204.4166", "submitter": "Yandong Guo", "authors": "Yuan Qi and Yandong Guo", "title": "Message passing with relaxed moment matching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian learning is often hampered by large computational expense. As a\npowerful generalization of popular belief propagation, expectation propagation\n(EP) efficiently approximates the exact Bayesian computation. Nevertheless, EP\ncan be sensitive to outliers and suffer from divergence for difficult cases. To\naddress this issue, we propose a new approximate inference approach, relaxed\nexpectation propagation (REP). It relaxes the moment matching requirement of\nexpectation propagation by adding a relaxation factor into the KL minimization.\nWe penalize this relaxation with a $l_1$ penalty. As a result, when two\ndistributions in the relaxed KL divergence are similar, the relaxation factor\nwill be penalized to zero and, therefore, we obtain the original moment\nmatching; In the presence of outliers, these two distributions are\nsignificantly different and the relaxation factor will be used to reduce the\ncontribution of the outlier. Based on this penalized KL minimization, REP is\nrobust to outliers and can greatly improve the posterior approximation quality\nover EP. To examine the effectiveness of REP, we apply it to Gaussian process\nclassification, a task known to be suitable to EP. Our classification results\non synthetic and UCI benchmark datasets demonstrate significant improvement of\nREP over EP and Power EP--in terms of algorithmic stability, estimation\naccuracy and predictive performance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Apr 2012 19:21:59 GMT"}, {"version": "v2", "created": "Wed, 29 Aug 2012 16:02:21 GMT"}], "update_date": "2012-08-30", "authors_parsed": [["Qi", "Yuan", ""], ["Guo", "Yandong", ""]]}, {"id": "1204.4248", "submitter": "Eisa Mahmoudi", "authors": "Hojjatollah Zakerzadeh and Eisa Mahmoudi", "title": "A new two parameter lifetime distribution: model and properties", "comments": "arXiv admin note: text overlap with arXiv:1007.0238", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new lifetime distribution which is obtained by compounding\nLindley and geometric distributions, named Lindley-geometric (LG) distribution,\nis introduced. Several properties of the new distribution such as density,\nfailure rate, mean lifetime, moments, and order statistics are derived.\nFurthermore, estimation by maximum likelihood and inference for large sample\nare discussed. The paper is motivated by two applications to real data sets and\nwe hope that this model be able to attract wider applicability in survival and\nreliability.\n", "versions": [{"version": "v1", "created": "Thu, 19 Apr 2012 04:44:41 GMT"}], "update_date": "2012-04-20", "authors_parsed": [["Zakerzadeh", "Hojjatollah", ""], ["Mahmoudi", "Eisa", ""]]}, {"id": "1204.5459", "submitter": "Umberto Picchini", "authors": "Umberto Picchini", "title": "Inference for SDE models via Approximate Bayesian Computation", "comments": "Version accepted for publication in Journal of Computational &\n  Graphical Statistics", "journal-ref": null, "doi": "10.1080/10618600.2013.866048", "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models defined by stochastic differential equations (SDEs) allow for the\nrepresentation of random variability in dynamical systems. The relevance of\nthis class of models is growing in many applied research areas and is already a\nstandard tool to model e.g. financial, neuronal and population growth dynamics.\nHowever inference for multidimensional SDE models is still very challenging,\nboth computationally and theoretically. Approximate Bayesian computation (ABC)\nallow to perform Bayesian inference for models which are sufficiently complex\nthat the likelihood function is either analytically unavailable or\ncomputationally prohibitive to evaluate. A computationally efficient ABC-MCMC\nalgorithm is proposed, halving the running time in our simulations. Focus is on\nthe case where the SDE describes latent dynamics in state-space models; however\nthe methodology is not limited to the state-space framework. Simulation studies\nfor a pharmacokinetics/pharmacodynamics model and for stochastic chemical\nreactions are considered and a MATLAB package implementing our ABC-MCMC\nalgorithm is provided.\n", "versions": [{"version": "v1", "created": "Tue, 24 Apr 2012 18:58:34 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2012 12:19:49 GMT"}, {"version": "v3", "created": "Sun, 5 Aug 2012 08:18:26 GMT"}, {"version": "v4", "created": "Sun, 6 Jan 2013 11:31:32 GMT"}, {"version": "v5", "created": "Tue, 25 Jun 2013 11:27:55 GMT"}, {"version": "v6", "created": "Fri, 8 Nov 2013 08:13:14 GMT"}], "update_date": "2014-08-06", "authors_parsed": [["Picchini", "Umberto", ""]]}, {"id": "1204.5564", "submitter": "Alice Cleynen", "authors": "Alice Cleynen, Michel Koskas, Emilie Lebarbier, Guillem Rigaill,\n  Stephane Robin", "title": "Segmentor3IsBack: an R package for the fast and exact segmentation of\n  Seq-data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Genome annotation is an important issue in biology which has long been\naddressed with gene prediction methods and manual experiments requiring\nbiological expertise. The expanding Next Generation Sequencing technologies and\ntheir enhanced precision allow a new approach to the domain: the segmentation\nof RNA-Seq data to determine gene boundaries. Because of its almost linear\ncomplexity, we propose to use the Pruned Dynamic Programming Algorithm, which\nperformances had been acknowledged for CGH arrays, for Seq-experiment outputs.\nThis requires the adaptation of the algorithm to the negative binomial\ndistribution with which we model the data. We show that if the dispersion in\nthe signal is known, the PDP algorithm can be used and we provide an estimator\nfor this dispersion. We then propose to estimate the number of segments, which\ncan be associated to coding or non-coding regions of the genome, using an\noracle penalty. We illustrate the results of our approach on a real data-set\nand show its good performance. Our algorithm is available as an R package on\nthe CRAN repository.\n", "versions": [{"version": "v1", "created": "Wed, 25 Apr 2012 05:28:32 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2012 13:38:54 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2013 10:03:21 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Cleynen", "Alice", ""], ["Koskas", "Michel", ""], ["Lebarbier", "Emilie", ""], ["Rigaill", "Guillem", ""], ["Robin", "Stephane", ""]]}, {"id": "1204.6516", "submitter": "Maria Eduarda Silva", "authors": "Maria Eduarda Silva, Isabel Pereira", "title": "Detection of additive outliers in Poisson INteger-valued AutoRegressive\n  time series", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outlying observations are commonly encountered in the analysis of time\nseries. In this paper the problem of detecting additive outliers in\ninteger-valued time series is considered. We show how Gibbs sampling can be\nused to detect outlying observations in INAR(1) processes. The methodology\nproposed is illustrated using examples as well as an observed data set.\n", "versions": [{"version": "v1", "created": "Sun, 29 Apr 2012 20:35:21 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Silva", "Maria Eduarda", ""], ["Pereira", "Isabel", ""]]}]