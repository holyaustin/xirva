[{"id": "1505.00965", "submitter": "Desmond Higham J", "authors": "Desmond J. Higham", "title": "An Introduction to Multilevel Monte Carlo for Option Valuation", "comments": "Submitted to International Journal of Computer Mathematics, special\n  issue on Computational Methods in Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.CE physics.data-an q-fin.CP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo is a simple and flexible tool that is widely used in\ncomputational finance. In this context, it is common for the quantity of\ninterest to be the expected value of a random variable defined via a stochastic\ndifferential equation. In 2008, Giles proposed a remarkable improvement to the\napproach of discretizing with a numerical method and applying standard Monte\nCarlo. His multilevel Monte Carlo method offers an order of speed up given by\nthe inverse of epsilon, where epsilon is the required accuracy. So computations\ncan run 100 times more quickly when two digits of accuracy are required. The\nmultilevel philosophy has since been adopted by a range of researchers and a\nwealth of practically significant results has arisen, most of which have yet to\nmake their way into the expository literature.\n  In this work, we give a brief, accessible, introduction to multilevel Monte\nCarlo and summarize recent results applicable to the task of option evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 11:39:16 GMT"}], "update_date": "2015-05-06", "authors_parsed": [["Higham", "Desmond J.", ""]]}, {"id": "1505.01135", "submitter": "Xiaodong Luo", "authors": "Xiaodong Luo, Andreas S. Stordal, Rolf J. Lorentzen and Geir\n  N{\\ae}vdal", "title": "Iterative ensemble smoother as an approximate solution to a regularized\n  minimum-average-cost problem: theory and applications", "comments": "Some insights on iterative ensemble smoother (iES) from the point of\n  view of stochastic programming and potential for further iES algorithm\n  developments", "journal-ref": "SPE Journal, 20, 962 - 982, first online July 2015", "doi": "10.2118/176023-PA", "report-no": null, "categories": "physics.data-an math.OC math.PR physics.ao-ph stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this work is on an alternative implementation of the iterative\nensemble smoother (iES). We show that iteration formulae similar to those used\nin \\cite{chen2013-levenberg,emerick2012ensemble} can be derived by adopting a\nregularized Levenberg-Marquardt (RLM) algorithm \\cite{jin2010regularized} to\napproximately solve a minimum-average-cost (MAC) problem. This not only leads\nto an alternative theoretical tool in understanding and analyzing the behaviour\nof the aforementioned iES, but also provides insights and guidelines for\nfurther developments of the smoothing algorithms. For illustration, we compare\nthe performance of an implementation of the RLM-MAC algorithm to that of the\napproximate iES used in \\cite{chen2013-levenberg} in three numerical examples:\nan initial condition estimation problem in a strongly nonlinear system, a\nfacies estimation problem in a 2D reservoir and the history matching problem in\nthe Brugge field case. In these three specific cases, the RLM-MAC algorithm\nexhibits comparable or even better performance, especially in the strongly\nnonlinear system.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 19:25:12 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2016 08:28:39 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Luo", "Xiaodong", ""], ["Stordal", "Andreas S.", ""], ["Lorentzen", "Rolf J.", ""], ["N\u00e6vdal", "Geir", ""]]}, {"id": "1505.01206", "submitter": "Changshuai Wei", "authors": "Changshuai Wei, Daniel J. Schaid, Qing Lu", "title": "Trees Assembling Mann Whitney Approach for Detecting Genome-wide Joint\n  Association among Low Marginal Effect loci", "comments": null, "journal-ref": "Genet Epidemiol. 2013 Jan;37(1):84-91", "doi": "10.1002/gepi.21693", "report-no": null, "categories": "q-bio.QM stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common complex diseases are likely influenced by the interplay of hundreds,\nor even thousands, of genetic variants. Converging evidence shows that genetic\nvariants with low marginal effects (LME) play an important role in disease\ndevelopment. Despite their potential significance, discovering LME genetic\nvariants and assessing their joint association on high dimensional data (e.g.,\ngenome wide association studies) remain a great challenge. To facilitate joint\nassociation analysis among a large ensemble of LME genetic variants, we\nproposed a computationally efficient and powerful approach, which we call Trees\nAssembling Mann whitney (TAMW). Through simulation studies and an empirical\ndata application, we found that TAMW outperformed multifactor dimensionality\nreduction (MDR) and the likelihood ratio based Mann whitney approach (LRMW)\nwhen the underlying complex disease involves multiple LME loci and their\ninteractions. For instance, in a simulation with 20 interacting LME loci, TAMW\nattained a higher power (power=0.931) than both MDR (power=0.599) and LRMW\n(power=0.704). In an empirical study of 29 known Crohn's disease (CD) loci,\nTAMW also identified a stronger joint association with CD than those detected\nby MDR and LRMW. Finally, we applied TAMW to Wellcome Trust CD GWAS to conduct\na genome wide analysis. The analysis of 459K single nucleotide polymorphisms\nwas completed in 40 hours using parallel computing, and revealed a joint\nassociation predisposing to CD (p-value=2.763e-19). Further analysis of the\nnewly discovered association suggested that 13 genes, such as ATG16L1 and\nLACC1, may play an important role in CD pathophysiological and etiological\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 5 May 2015 22:14:28 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Wei", "Changshuai", ""], ["Schaid", "Daniel J.", ""], ["Lu", "Qing", ""]]}, {"id": "1505.01434", "submitter": "B{\\l}a\\.zej Miasojedow", "authors": "Blazej Miasojedow, Wojciech Niemiro", "title": "Particle Gibbs algorithms for Markov jump processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper we propose a new MCMC algorithm for sampling from the\nposterior distribution of hidden trajectory of a Markov jump process. Our\nalgorithm is based on the idea of exploiting virtual jumps, introduced by Rao\nand Teh (2013). The main novelty is that our algorithm uses particle Gibbs with\nancestor sampling to update the skeleton, while Rao and Teh use forward\nfiltering backward sampling (FFBS). In contrast to previous methods our\nalgorithm can be implemented even if the state space is infinite. In addition,\nthe cost of a single step of the proposed algorithm does not depend on the size\nof the state space. The computational cost of our methood is of order\n$\\mathcal{O}(N\\mathbb{E}(n))$, where $N$ is the number of particles used in the\nPGAS algorithm and $\\mathbb{E}(n)$ is the expected number of jumps (together\nwith virtual ones). The cost of the algorithm of Rao and Teh is of order\n$\\mathcal{O}(|\\mathcal{X}|^2\\mathbb{E}(n))$, where $|\\mathcal{X}|$ is the size\nof the state space. Simulation results show that our algorithm with PGAS\nconverges slightly slower than the algorithm with FFBS, if the size of the\nstate space is not big. However, if the size of the state space increases, the\nproposed method outperforms existing ones. We give special attention to a\nhierarchical version of our algorithm which can be applied to continuous time\nBayesian networks (CTBNs).\n", "versions": [{"version": "v1", "created": "Wed, 6 May 2015 17:03:30 GMT"}], "update_date": "2015-05-07", "authors_parsed": [["Miasojedow", "Blazej", ""], ["Niemiro", "Wojciech", ""]]}, {"id": "1505.01979", "submitter": "J. Martin van Zyl", "authors": "J. Martin van Zyl", "title": "The efficiency of the likelihood ratio to choose between a\n  t-distribution and a normal distribution", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A decision must often be made between heavy-tailed and Gaussian errors for a\nregression or a time series model, and the t-distribution is frequently used\nwhen it is assumed that the errors are heavy-tailed distributed. The\nperformance of the likelihood ratio to choose between the two distributions is\ninvestigated using entropy properties and a simulation study. The proportion of\ntimes or probability that the likelihood of the correct assumption will be\nbigger than the likelihood of the incorrect assumption is estimated.\n", "versions": [{"version": "v1", "created": "Fri, 8 May 2015 10:15:51 GMT"}], "update_date": "2015-05-11", "authors_parsed": [["van Zyl", "J. Martin", ""]]}, {"id": "1505.02227", "submitter": "Tsvetan Asamov", "authors": "Tsvetan Asamov and Warren B. Powell", "title": "Regularized Decomposition of High-Dimensional Multistage Stochastic\n  Programs with Markov Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a quadratic regularization approach for the solution of\nhigh-dimensional multistage stochastic optimization problems characterized by a\npotentially large number of time periods/stages (e.g. hundreds), a\nhigh-dimensional resource state variable, and a Markov information process. The\nresulting algorithms are shown to converge to an optimal policy after a finite\nnumber of iterations under mild technical assumptions. Computational\nexperiments are conducted using the setting of optimizing energy storage over a\nlarge transmission grid, which motivates both the spatial and temporal\ndimensions of our problem. Our numerical results indicate that the proposed\nmethods exhibit significantly faster convergence than their classical\ncounterparts, with greater gains observed for higher-dimensional problems.\n", "versions": [{"version": "v1", "created": "Sat, 9 May 2015 03:26:22 GMT"}, {"version": "v2", "created": "Tue, 19 May 2015 20:18:36 GMT"}, {"version": "v3", "created": "Sun, 26 Feb 2017 22:13:16 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Asamov", "Tsvetan", ""], ["Powell", "Warren B.", ""]]}, {"id": "1505.02350", "submitter": "Andrea Saltelli", "authors": "Sergei Kucherenko, Daniel Albrecht, Andrea Saltelli", "title": "Exploring multi-dimensional spaces: a Comparison of Latin Hypercube and\n  Quasi Monte Carlo Sampling Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three sampling methods are compared for efficiency on a number of test\nproblems of various complexity for which analytic quadratures are available.\nThe methods compared are Monte Carlo with pseudo-random numbers, Latin\nHypercube Sampling, and Quasi Monte Carlo with sampling based on Sobol\nsequences. Generally results show superior performance of the Quasi Monte Carlo\napproach based on Sobol sequences in line with theoretical predictions. Latin\nHypercube Sampling can be more efficient than both Monte Carlo method and Quasi\nMonte Carlo method but the latter inequality holds for a reduced set of\nfunction typology and at small number of sampled points. In conclusion Quasi\nMonte Carlo method would appear the safest bet when integrating functions of\nunknown typology.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2015 07:16:41 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Kucherenko", "Sergei", ""], ["Albrecht", "Daniel", ""], ["Saltelli", "Andrea", ""]]}, {"id": "1505.02417", "submitter": "Dustin Tran", "authors": "Panos Toulis, Dustin Tran, Edoardo M. Airoldi", "title": "Towards stability and optimality in stochastic gradient descent", "comments": "Appears in Artificial Intelligence and Statistics, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Iterative procedures for parameter estimation based on stochastic gradient\ndescent allow the estimation to scale to massive data sets. However, in both\ntheory and practice, they suffer from numerical instability. Moreover, they are\nstatistically inefficient as estimators of the true parameter value. To address\nthese two issues, we propose a new iterative procedure termed averaged implicit\nSGD (AI-SGD). For statistical efficiency, AI-SGD employs averaging of the\niterates, which achieves the optimal Cram\\'{e}r-Rao bound under strong\nconvexity, i.e., it is an optimal unbiased estimator of the true parameter\nvalue. For numerical stability, AI-SGD employs an implicit update at each\niteration, which is related to proximal operators in optimization. In practice,\nAI-SGD achieves competitive performance with other state-of-the-art procedures.\nFurthermore, it is more stable than averaging procedures that do not employ\nproximal updates, and is simple to implement as it requires fewer tunable\nhyperparameters than procedures that do employ proximal updates.\n", "versions": [{"version": "v1", "created": "Sun, 10 May 2015 18:10:07 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2015 03:01:53 GMT"}, {"version": "v3", "created": "Fri, 3 Jun 2016 23:11:21 GMT"}, {"version": "v4", "created": "Tue, 7 Jun 2016 04:02:43 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Toulis", "Panos", ""], ["Tran", "Dustin", ""], ["Airoldi", "Edoardo M.", ""]]}, {"id": "1505.02556", "submitter": "Kees Mulder", "authors": "Kees Tim Mulder, Irene Klugkist", "title": "Extending Bayesian analysis of circular data to comparison of multiple\n  groups", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Circular data are data measured in angles and occur in a variety of\nscientific disciplines. Bayesian methods promise to allow for flexible analysis\nof circular data. Three existing MCMC methods (Gibbs, Metropolis-Hastings, and\nRejection) for a single group of circular data were extended to be used in a\nbetween-subjects design, providing a novel procedure to compare groups of\ncircular data. Investigating the performance of the methods by simulation\nstudy, all methods were found to overestimate the concentration parameter of\nthe posterior, while coverage was reasonable. The rejection sampler performed\nbest. In future research, the MCMC method may be extended to include\ncovariates, or a within-subjects design.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2015 10:36:00 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Mulder", "Kees Tim", ""], ["Klugkist", "Irene", ""]]}, {"id": "1505.02674", "submitter": "Charles-Edouard Br\\'ehier", "authors": "Br\\'ehier Charles-Edouard, Gazeau Maxime, Gouden\\`ege Ludovic,\n  Leli\\`evre Tony, Rousset Mathias", "title": "Unbiasedness of some generalized Adaptive Multilevel Splitting\n  algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generalization of the Adaptive Multilevel Splitting algorithm\nin the discrete time dynamic setting, namely when it is applied to sample rare\nevents associated with paths of Markov chains. By interpreting the algorithm as\na sequential sampler in path space, we are able to build an estimator of the\nrare event probability (and of any non-normalized quantity associated with this\nevent) which is unbiased, whatever the choice of the importance function and\nthe number of replicas. This has practical consequences on the use of this\nalgorithm, which are illustrated through various numerical experiments.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2015 15:40:16 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Charles-Edouard", "Br\u00e9hier", ""], ["Maxime", "Gazeau", ""], ["Ludovic", "Gouden\u00e8ge", ""], ["Tony", "Leli\u00e8vre", ""], ["Mathias", "Rousset", ""]]}, {"id": "1505.02827", "submitter": "R\\'emi Bardenet", "authors": "R\\'emi Bardenet, Arnaud Doucet, Chris Holmes", "title": "On Markov chain Monte Carlo methods for tall data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo methods are often deemed too computationally\nintensive to be of any practical use for big data applications, and in\nparticular for inference on datasets containing a large number $n$ of\nindividual data points, also known as tall datasets. In scenarios where data\nare assumed independent, various approaches to scale up the Metropolis-Hastings\nalgorithm in a Bayesian inference context have been recently proposed in\nmachine learning and computational statistics. These approaches can be grouped\ninto two categories: divide-and-conquer approaches and, subsampling-based\nalgorithms. The aims of this article are as follows. First, we present a\ncomprehensive review of the existing literature, commenting on the underlying\nassumptions and theoretical guarantees of each method. Second, by leveraging\nour understanding of these limitations, we propose an original\nsubsampling-based approach which samples from a distribution provably close to\nthe posterior distribution of interest, yet can require less than $O(n)$ data\npoint likelihood evaluations at each iteration for certain statistical models\nin favourable scenarios. Finally, we have only been able so far to propose\nsubsampling-based methods which display good performance in scenarios where the\nBernstein-von Mises approximation of the target posterior distribution is\nexcellent. It remains an open challenge to develop such methods in scenarios\nwhere the Bernstein-von Mises approximation is poor.\n", "versions": [{"version": "v1", "created": "Mon, 11 May 2015 22:51:02 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Bardenet", "R\u00e9mi", ""], ["Doucet", "Arnaud", ""], ["Holmes", "Chris", ""]]}, {"id": "1505.03001", "submitter": "Ofer Shwartz", "authors": "Ofer Shwartz and Boaz Nadler", "title": "Detecting the large entries of a sparse covariance matrix in\n  sub-quadratic time", "comments": null, "journal-ref": null, "doi": "10.1093/imaiai/iaw004", "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The covariance matrix of a $p$-dimensional random variable is a fundamental\nquantity in data analysis. Given $n$ i.i.d. observations, it is typically\nestimated by the sample covariance matrix, at a computational cost of\n$O(np^{2})$ operations. When $n,p$ are large, this computation may be\nprohibitively slow. Moreover, in several contemporary applications, the\npopulation matrix is approximately sparse, and only its few large entries are\nof interest. This raises the following question, at the focus of our work:\nAssuming approximate sparsity of the covariance matrix, can its large entries\nbe detected much faster, say in sub-quadratic time, without explicitly\ncomputing all its $p^{2}$ entries? In this paper, we present and theoretically\nanalyze two randomized algorithms that detect the large entries of an\napproximately sparse sample covariance matrix using only $O(np\\text{ poly log }\np)$ operations. Furthermore, assuming sparsity of the population matrix, we\nderive sufficient conditions on the underlying random variable and on the\nnumber of samples $n$, for the sample covariance matrix to satisfy our\napproximate sparsity requirements. Finally, we illustrate the performance of\nour algorithms via several simulations.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2015 13:30:06 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2015 08:58:27 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Shwartz", "Ofer", ""], ["Nadler", "Boaz", ""]]}, {"id": "1505.03030", "submitter": "Murray Pollock", "authors": "Murray Pollock", "title": "On the Exact Simulation of (Jump) Diffusion Bridges", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.PR q-fin.CP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we outline methodology to efficiently simulate (jump) diffusion\nbridge sample paths without discretisation error. We achieve this by\nconsidering the simulation of conditioned (jump) diffusion bridge sample paths\nin light of recent work developing a mathematical framework for simulating\nfinite dimensional sample path skeletons (which flexibly characterise the\nentirety of sample paths).\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2015 14:41:08 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Pollock", "Murray", ""]]}, {"id": "1505.03173", "submitter": "Mathieu Gerber", "authors": "Mathieu Gerber and Luke Bornn", "title": "Improving Simulated Annealing through Derandomization", "comments": "33 pages, 4 figures (final version)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.NA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study a version of simulated annealing (SA) on continuous\nstate spaces based on $(t,s)_R$-sequences. The parameter $R\\in\\bar{\\mathbb{N}}$\nregulates the degree of randomness of the input sequence, with the case $R=0$\ncorresponding to IID uniform random numbers and the limiting case $R=\\infty$ to\n$(t,s)$-sequences. Our main result, obtained for rectangular domains, shows\nthat the resulting optimization method, which we refer to as QMC-SA, converges\nalmost surely to the global optimum of the objective function $\\varphi$ for any\n$R\\in\\mathbb{N}$. When $\\varphi$ is univariate, we are in addition able to show\nthat the completely deterministic version of QMC-SA is convergent. A key\nproperty of these results is that they do not require objective-dependent\nconditions on the cooling schedule. As a corollary of our theoretical analysis,\nwe provide a new almost sure convergence result for SA which shares this\nproperty under minimal assumptions on $\\varphi$. We further explain how our\nresults in fact apply to a broader class of optimization methods including for\nexample threshold accepting, for which to our knowledge no convergence results\ncurrently exist. We finally illustrate the superiority of QMC-SA over SA\nalgorithms in a numerical study.\n", "versions": [{"version": "v1", "created": "Tue, 12 May 2015 21:32:02 GMT"}, {"version": "v2", "created": "Mon, 8 Jun 2015 17:17:16 GMT"}, {"version": "v3", "created": "Mon, 23 Nov 2015 16:47:49 GMT"}, {"version": "v4", "created": "Mon, 5 Sep 2016 09:35:22 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Gerber", "Mathieu", ""], ["Bornn", "Luke", ""]]}, {"id": "1505.03366", "submitter": "Mohammed Sedki", "authors": "Matthieu Marbac and Pascale Tubert-Bitter and Mohammed Sedki", "title": "Bayesian model selection in logistic regression for the detection of\n  adverse drug reactions", "comments": "7 pages, 3 figures, submitted to Biometrical Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Spontaneous adverse event reports have a high potential for\ndetecting adverse drug reactions. However, due to their dimension, exploring\nsuch databases requires statistical methods. In this context,\ndisproportionality measures are used. However, by projecting the data onto\ncontingency tables, these methods become sensitive to the problem of\nco-prescriptions and masking effects. Recently, logistic regressions have been\nused with a Lasso type penalty to perform the detection of associations between\ndrugs and adverse events. However, the choice of the penalty value is open to\ncriticism while it strongly influences the results. Results: In this paper, we\npropose to use a logistic regression whose sparsity is viewed as a model\nselection challenge. Since the model space is huge, a Metropolis-Hastings\nalgorithm carries out the model selection by maximizing the BIC criterion.\nThus, we avoid the calibration of penalty or threshold. During our application\non the French pharmacovigilance database, the proposed method is compared to\nwell established approaches on a reference data set, and obtains better rates\nof positive and negative controls. However, many signals are not detected by\nthe proposed method. So, we conclude that this method should be used in\nparallel to existing measures in pharmacovigilance.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 13:07:38 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2015 08:39:39 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Marbac", "Matthieu", ""], ["Tubert-Bitter", "Pascale", ""], ["Sedki", "Mohammed", ""]]}, {"id": "1505.03410", "submitter": "Joseph  Salmon", "authors": "Olivier Fercoq, Alexandre Gramfort, Joseph Salmon", "title": "Mind the duality gap: safer rules for the Lasso", "comments": "erratum to ICML 2015, \"The authors would like to thanks Jalal Fadili\n  and Jingwei Liang for helping clarifying some misleading statements on the\n  equicorrelation set\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Screening rules allow to early discard irrelevant variables from the\noptimization in Lasso problems, or its derivatives, making solvers faster. In\nthis paper, we propose new versions of the so-called $\\textit{safe rules}$ for\nthe Lasso. Based on duality gap considerations, our new rules create safe test\nregions whose diameters converge to zero, provided that one relies on a\nconverging solver. This property helps screening out more variables, for a\nwider range of regularization parameter values. In addition to faster\nconvergence, we prove that we correctly identify the active sets (supports) of\nthe solutions in finite time. While our proposed strategy can cope with any\nsolver, its performance is demonstrated using a coordinate descent algorithm\nparticularly adapted to machine learning use cases. Significant computing time\nreductions are obtained with respect to previous safe rules.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 14:50:34 GMT"}, {"version": "v2", "created": "Tue, 25 Aug 2015 14:52:12 GMT"}, {"version": "v3", "created": "Thu, 3 Dec 2015 21:12:34 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Fercoq", "Olivier", ""], ["Gramfort", "Alexandre", ""], ["Salmon", "Joseph", ""]]}, {"id": "1505.03442", "submitter": "Xingye Qiao", "authors": "Xingye Qiao", "title": "Noncrossing Ordinal Classification", "comments": "32 pages, 9 figures. Accepted for Publication in Statistics and Its\n  Interface", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordinal data are often seen in real applications. Regular multicategory\nclassification methods are not designed for this data type and a more proper\ntreatment is needed. We consider a framework of ordinal classification which\npools the results from binary classifiers together. An inherent difficulty of\nthis framework is that the class prediction can be ambiguous due to boundary\ncrossing. To fix this issue, we propose a noncrossing ordinal classification\nmethod which materializes the framework by imposing noncrossing constraints. An\nasymptotic study of the proposed method is conducted. We show by simulated and\ndata examples that the proposed method can improve the classification\nperformance for ordinal data without the ambiguity caused by boundary\ncrossings.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 16:05:23 GMT"}, {"version": "v2", "created": "Tue, 1 Dec 2015 14:59:36 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2015 20:37:37 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Qiao", "Xingye", ""]]}, {"id": "1505.03506", "submitter": "Konstantin Zuev M", "authors": "Konstantin Zuev", "title": "Subset Simulation Method for Rare Event Estimation: An Introduction", "comments": "14 page, 12 figures, MATLAB code in Zuev K.: Subset Simulation Method\n  for Rare Event Estimation: An Introduction. In: Beer M. et al (Ed.)\n  Encyclopedia of Earthquake Engineering: SpringerReference\n  (www.springerreference.com), 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a detailed introductory description of Subset Simulation,\nan advanced stochastic simulation method for estimation of small probabilities\nof rare failure events. A simple and intuitive derivation of the method is\ngiven along with the discussion on its implementation. The method is\nillustrated with several easy-to-understand examples. For demonstration\npurposes, the MATLAB code for the considered examples is provided. The reader\nis assumed to be familiar only with elementary probability theory and\nstatistics.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 19:41:04 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Zuev", "Konstantin", ""]]}, {"id": "1505.03512", "submitter": "Albert Parker", "authors": "Colin Fox and Albert Parker", "title": "Accelerated Gibbs sampling of normal distributions using matrix\n  splittings and polynomials", "comments": "33 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard Gibbs sampling applied to a multivariate normal distribution with a\nspecified precision matrix is equivalent in fundamental ways to the\nGauss-Seidel iterative solution of linear equations in the precision matrix.\nSpecifically, the iteration operators, the conditions under which convergence\noccurs, and geometric convergence factors (and rates) are identical. These\nresults hold for arbitrary matrix splittings from classical iterative methods\nin numerical linear algebra giving easy access to mature results in that field,\nincluding existing convergence results for antithetic-variable Gibbs sampling,\nREGS sampling, and generalizations. Hence, efficient deterministic stationary\nrelaxation schemes lead to efficient generalizations of Gibbs sampling. The\ntechnique of polynomial acceleration that significantly improves the\nconvergence rate of an iterative solver derived from a \\emph{symmetric} matrix\nsplitting may be applied to accelerate the equivalent generalized Gibbs\nsampler. Identicality of error polynomials guarantees convergence of the\ninhomogeneous Markov chain, while equality of convergence factors ensures that\nthe optimal solver leads to the optimal sampler. Numerical examples are\npresented, including a Chebyshev accelerated SSOR Gibbs sampler applied to a\nstylized demonstration of low-level Bayesian image reconstruction in a large\n3-dimensional linear inverse problem.\n", "versions": [{"version": "v1", "created": "Wed, 13 May 2015 19:57:10 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Fox", "Colin", ""], ["Parker", "Albert", ""]]}, {"id": "1505.03908", "submitter": "Jonas Wallin", "authors": "Jonas Wallin and David Bolin", "title": "Efficient adaptive MCMC through precision estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel adaptive Markov chain Monte Carlo algorithm is presented. The\nalgorithm utilizes sparsity in the partial correlation structure of a density\nto efficiently estimate the covariance matrix through the Cholesky factor of\nthe precision matrix. The algorithm also utilizes the sparsity to sample\nefficiently from both MALA and Metropolis Hasting random walk proposals.\nFurther, an algorithm that estimates the partial correlation structure of a\ndensity is proposed. Combining this with the Cholesky factor estimation\nalgorithm results in an efficient black-box AMCMC method that can be used for\ngeneral densities with unknown dependency structure. The method is compared\nwith regular empirical covariance adaption for two examples. In both examples,\nthe proposed method's covariance estimates converge faster to the true\ncovariance matrix and the computational cost for each iteration is lower.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2015 22:30:23 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2016 14:27:02 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Wallin", "Jonas", ""], ["Bolin", "David", ""]]}, {"id": "1505.03914", "submitter": "Lorenzo Mercuri", "authors": "Stefano M. Iacus, Lorenzo Mercuri, Edit Rroji", "title": "Estimation and Simulation of a COGARCH(p,q) model in the YUIMA project", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show how to simulate and estimate a COGARCH(p,q) model in\nthe R package yuima. Several routines for simulation and estimation are\navailable. Indeed for the generation of a COGARCH(p,q) trajectory, the user can\nchoose between two alternative schemes. The first is based on the Euler\ndiscretization of the stochastic differential equations that identifies a\nCOGARCH(p,q) model while the second one considers the explicit solution of the\nvariance process.\n  Estimation is based on the matching of the empirical with the theoretical\nautocorrelation function. In this case three different approaches are\nimplemented: minimization of the mean square error, minimization of the\nabsolute mean error and the generalized method of moments where the weighting\nmatrix is continuously updated.\n  Numerical examples are given in order to explain methods and classes used in\nthe yuima package.\n", "versions": [{"version": "v1", "created": "Thu, 14 May 2015 23:05:11 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Iacus", "Stefano M.", ""], ["Mercuri", "Lorenzo", ""], ["Rroji", "Edit", ""]]}, {"id": "1505.04305", "submitter": "Jie Sun", "authors": "Bing Wang, Jie Sun, Adilson E. Motter", "title": "Detecting structural breaks in seasonal time series by regularized\n  optimization", "comments": "Safety, Reliability, Risk and Life-Cycle Performance of Structures\n  and Infrastructures (Edited by George Deodatis, Bruce R. Ellingwood and Dan\n  M. Frangopol), CRC Press 2014, Pages 3621-3628", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world systems are often complex, dynamic, and nonlinear. Understanding\nthe dynamics of a system from its observed time series is key to the prediction\nand control of the system's behavior. While most existing techniques tacitly\nassume some form of stationarity or continuity, abrupt changes, which are often\ndue to external disturbances or sudden changes in the intrinsic dynamics, are\ncommon in time series. Structural breaks, which are time points at which the\nstatistical patterns of a time series change, pose considerable challenges to\ndata analysis. Without identification of such break points, the same dynamic\nrule would be applied to the whole period of observation, whereas false\nidentification of structural breaks may lead to overfitting. In this paper, we\ncast the problem of decomposing a time series into its trend and seasonal\ncomponents as an optimization problem. This problem is ill-posed due to the\narbitrariness in the number of parameters. To overcome this difficulty, we\npropose the addition of a penalty function (i.e., a regularization term) that\naccounts for the number of parameters. Our approach simultaneously identifies\nseasonality and trend without the need of iterations, and allows the reliable\ndetection of structural breaks. The method is applied to recorded data on fish\npopulations and sea surface temperature, where it detects structural breaks\nthat would have been neglected otherwise. This suggests that our method can\nlead to a general approach for the monitoring, prediction, and prevention of\nstructural changes in real systems.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2015 18:10:54 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Wang", "Bing", ""], ["Sun", "Jie", ""], ["Motter", "Adilson E.", ""]]}, {"id": "1505.04321", "submitter": "Pierre E. Jacob", "authors": "Pierre E. Jacob (University of Oxford)", "title": "Sequential Bayesian inference for implicit hidden Markov models and\n  current limitations", "comments": "Review article written for ESAIM: proceedings and surveys. 25 pages,\n  10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hidden Markov models can describe time series arising in various fields of\nscience, by treating the data as noisy measurements of an arbitrarily complex\nMarkov process. Sequential Monte Carlo (SMC) methods have become standard tools\nto estimate the hidden Markov process given the observations and a fixed\nparameter value. We review some of the recent developments allowing the\ninclusion of parameter uncertainty as well as model uncertainty. The\nshortcomings of the currently available methodology are emphasised from an\nalgorithmic complexity perspective. The statistical objects of interest for\ntime series analysis are illustrated on a toy \"Lotka-Volterra\" model used in\npopulation ecology. Some open challenges are discussed regarding the\nscalability of the reviewed methodology to longer time series,\nhigher-dimensional state spaces and more flexible models.\n", "versions": [{"version": "v1", "created": "Sat, 16 May 2015 20:11:52 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Jacob", "Pierre E.", "", "University of Oxford"]]}, {"id": "1505.04724", "submitter": "Vishwas Rao", "authors": "Ahmed Attia and Vishwas Rao and Adrian Sandu", "title": "A Hybrid Monte-Carlo Sampling Smoother for Four Dimensional Data\n  Assimilation", "comments": "33 Pages", "journal-ref": null, "doi": null, "report-no": "CSL-TR-19-2015", "categories": "cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper constructs an ensemble-based sampling smoother for\nfour-dimensional data assimilation using a Hybrid/Hamiltonian Monte-Carlo\napproach. The smoother samples efficiently from the posterior probability\ndensity of the solution at the initial time. Unlike the well-known ensemble\nKalman smoother, which is optimal only in the linear Gaussian case, the\nproposed methodology naturally accommodates non-Gaussian errors and non-linear\nmodel dynamics and observation operators. Unlike the four-dimensional\nvariational met\\-hod, which only finds a mode of the posterior distribution,\nthe smoother provides an estimate of the posterior uncertainty. One can use the\nensemble mean as the minimum variance estimate of the state, or can use the\nensemble in conjunction with the variational approach to estimate the\nbackground errors for subsequent assimilation windows. Numerical results\ndemonstrate the advantages of the proposed method compared to the traditional\nvariational and ensemble-based smoothing methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 17:15:49 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Attia", "Ahmed", ""], ["Rao", "Vishwas", ""], ["Sandu", "Adrian", ""]]}, {"id": "1505.04732", "submitter": "Luca Martino", "authors": "L. Martino, V. Elvira, D. Luengo, J. Corander", "title": "Layered Adaptive Importance Sampling", "comments": "Related Matlab codes: an iterative version at\n  http://www.lucamartino.altervista.org/CODE_LAIS_v03.zip and a non-iterative\n  version at http://www.lucamartino.altervista.org/LAIS_non_iterative_code.zip,\n  Statistics and Computing, 2016", "journal-ref": null, "doi": "10.1007/s11222-016-9642-5", "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo methods represent the \"de facto\" standard for approximating\ncomplicated integrals involving multidimensional target distributions. In order\nto generate random realizations from the target distribution, Monte Carlo\ntechniques use simpler proposal probability densities to draw candidate\nsamples. The performance of any such method is strictly related to the\nspecification of the proposal distribution, such that unfortunate choices\neasily wreak havoc on the resulting estimators. In this work, we introduce a\nlayered (i.e., hierarchical) procedure to generate samples employed within a\nMonte Carlo scheme. This approach ensures that an appropriate equivalent\nproposal density is always obtained automatically (thus eliminating the risk of\na catastrophic performance), although at the expense of a moderate increase in\nthe complexity. Furthermore, we provide a general unified importance sampling\n(IS) framework, where multiple proposal densities are employed and several IS\nschemes are introduced by applying the so-called deterministic mixture\napproach. Finally, given these schemes, we also propose a novel class of\nadaptive importance samplers using a population of proposals, where the\nadaptation is driven by independent parallel or interacting Markov Chain Monte\nCarlo (MCMC) chains. The resulting algorithms efficiently combine the benefits\nof both IS and MCMC methods.\n", "versions": [{"version": "v1", "created": "Mon, 18 May 2015 17:40:51 GMT"}, {"version": "v2", "created": "Sat, 30 May 2015 18:34:26 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2016 23:55:32 GMT"}, {"version": "v4", "created": "Sun, 27 Nov 2016 15:48:13 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Martino", "L.", ""], ["Elvira", "V.", ""], ["Luengo", "D.", ""], ["Corander", "J.", ""]]}, {"id": "1505.04875", "submitter": "Alon Kipnis", "authors": "Alon Kipnis and Stefano Rini and Andrea J. Goldsmith", "title": "Indirect Rate-Distortion Function of a Binary i.i.d Source", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The indirect source-coding problem in which a Bernoulli process is compressed\nin a lossy manner from its noisy observations is considered. These noisy\nobservations are obtained by passing the source sequence through a The indirect\nsource-coding problem in which a Bernoulli process is compressed in a lossy\nmanner from its noisy observations is considered. These noisy observations are\nobtained by passing the source sequence through a binary symmetric channel so\nthat the channel crossover probability controls the amount of information\navailable about the source realization at the encoder. We use classic results\nin rate-distortion theory to compute an expression of the rate-distortion\nfunction for this model, where the Bernoulli source is not necessarily\nsymmetric. The indirect rate-distortion function is given in terms of a\nsolution to a simple equation. In addition, we derive an upper bound on the\nindirect rate-distortion function which is given in a closed. These expressions\ncapture precisely the expected behavior that the noisier the observations, the\nsmaller the return from increasing bit-rate to reduce distortion.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 05:00:23 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2015 02:35:18 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Kipnis", "Alon", ""], ["Rini", "Stefano", ""], ["Goldsmith", "Andrea J.", ""]]}, {"id": "1505.05093", "submitter": "Perry De Valpine", "authors": "Perry de Valpine, Daniel Turek, Christopher J. Paciorek, Clifford\n  Anderson-Bergman, Duncan Temple Lang, Rastislav Bodik", "title": "Programming with models: writing statistical algorithms for general\n  model structures with NIMBLE", "comments": "20 pages, 2 figures", "journal-ref": "Journal of Computational and Graphical Statistics (2017) 26:\n  403-413", "doi": "10.1080/10618600.2016.1172487", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe NIMBLE, a system for programming statistical algorithms for\ngeneral model structures within R. NIMBLE is designed to meet three challenges:\nflexible model specification, a language for programming algorithms that can\nuse different models, and a balance between high-level programmability and\nexecution efficiency. For model specification, NIMBLE extends the BUGS language\nand creates model objects, which can manipulate variables, calculate log\nprobability values, generate simulations, and query the relationships among\nvariables. For algorithm programming, NIMBLE provides functions that operate\nwith model objects using two stages of evaluation. The first stage allows\nspecialization of a function to a particular model and/or nodes, such as\ncreating a Metropolis-Hastings sampler for a particular block of nodes. The\nsecond stage allows repeated execution of computations using the results of the\nfirst stage. To achieve efficient second-stage computation, NIMBLE compiles\nmodels and functions via C++, using the Eigen library for linear algebra, and\nprovides the user with an interface to compiled objects. The NIMBLE language\nrepresents a compilable domain-specific language (DSL) embedded within R. This\npaper provides an overview of the design and rationale for NIMBLE along with\nillustrative examples including importance sampling, Markov chain Monte Carlo\n(MCMC) and Monte Carlo expectation maximization (MCEM).\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 17:25:01 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2016 00:40:36 GMT"}, {"version": "v3", "created": "Tue, 12 Apr 2016 23:57:02 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["de Valpine", "Perry", ""], ["Turek", "Daniel", ""], ["Paciorek", "Christopher J.", ""], ["Anderson-Bergman", "Clifford", ""], ["Lang", "Duncan Temple", ""], ["Bodik", "Rastislav", ""]]}, {"id": "1505.05116", "submitter": "Peyman Mohajerin Esfahani", "authors": "Peyman Mohajerin Esfahani and Daniel Kuhn", "title": "Data-driven Distributionally Robust Optimization Using the Wasserstein\n  Metric: Performance Guarantees and Tractable Reformulations", "comments": "42 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider stochastic programs where the distribution of the uncertain\nparameters is only observable through a finite training dataset. Using the\nWasserstein metric, we construct a ball in the space of (multivariate and\nnon-discrete) probability distributions centered at the uniform distribution on\nthe training samples, and we seek decisions that perform best in view of the\nworst-case distribution within this Wasserstein ball. The state-of-the-art\nmethods for solving the resulting distributionally robust optimization problems\nrely on global optimization techniques, which quickly become computationally\nexcruciating. In this paper we demonstrate that, under mild assumptions, the\ndistributionally robust optimization problems over Wasserstein balls can in\nfact be reformulated as finite convex programs---in many interesting cases even\nas tractable linear programs. Leveraging recent measure concentration results,\nwe also show that their solutions enjoy powerful finite-sample performance\nguarantees. Our theoretical results are exemplified in mean-risk portfolio\noptimization as well as uncertainty quantification.\n", "versions": [{"version": "v1", "created": "Tue, 19 May 2015 18:44:03 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2016 12:04:28 GMT"}, {"version": "v3", "created": "Tue, 13 Jun 2017 08:05:46 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Esfahani", "Peyman Mohajerin", ""], ["Kuhn", "Daniel", ""]]}, {"id": "1505.05391", "submitter": "V\\'ictor Elvira", "authors": "V\\'ictor Elvira, Luca Martino, David Luengo, M\\'onica F. Bugallo", "title": "Efficient Multiple Importance Sampling Estimators", "comments": null, "journal-ref": "IEEE Signal Processing Letters, VOL. 22, NO. 10, OCTOBER 2015", "doi": "10.1109/LSP.2015.2432078", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple importance sampling (MIS) methods use a set of proposal\ndistributions from which samples are drawn. Each sample is then assigned an\nimportance weight that can be obtained according to different strategies. This\nwork is motivated by the trade-off between variance reduction and computational\ncomplexity of the different approaches (classical vs. deterministic mixture)\navailable for the weight calculation. A new method that achieves an efficient\ncompromise between both factors is introduced in this paper. It is based on\nforming a partition of the set of proposal distributions and computing the\nweights accordingly. Computer simulations show the excellent performance of the\nassociated \\mbox{\\emph{partial deterministic mixture} MIS estimator.\n", "versions": [{"version": "v1", "created": "Wed, 20 May 2015 14:13:39 GMT"}], "update_date": "2015-05-21", "authors_parsed": [["Elvira", "V\u00edctor", ""], ["Martino", "Luca", ""], ["Luengo", "David", ""], ["Bugallo", "M\u00f3nica F.", ""]]}, {"id": "1505.05571", "submitter": "Radford M. Neal", "authors": "Radford M. Neal", "title": "Fast exact summation using small and large superaccumulators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I present two new methods for exactly summing a set of floating-point\nnumbers, and then correctly rounding to the nearest floating-point number.\nHigher accuracy than simple summation (rounding after each addition) is\nimportant in many applications, such as finding the sample mean of data. Exact\nsummation also guarantees identical results with parallel and serial\nimplementations, since the exact sum is independent of order. The new methods\nuse variations on the concept of a \"superaccumulator\" - a large fixed-point\nnumber that can exactly represent the sum of any reasonable number of\nfloating-point values. One method uses a \"small\" superaccumulator with\nsixty-seven 64-bit chunks, each with 32-bit overlap with the next chunk,\nallowing carry propagation to be done infrequently. The small superaccumulator\nis used alone when summing a small number of terms. For big summations, a\n\"large\" superaccumulator is used as well. It consists of 4096 64-bit chunks,\none for every possible combination of exponent bits and sign bit, plus counts\nof when each chunk needs to be transferred to the small superaccumulator. To\nadd a term to the large superaccumulator, only a single chunk and its\nassociated count need to be updated, which takes very few instructions if\ncarefully implemented. On modern 64-bit processors, exactly summing a large\narray using this combination of large and small superaccumulators takes less\nthan twice the time of simple, inexact, ordered summation, with a serial\nimplementation. A parallel implementation using a small number of processor\ncores can be expected to perform exact summation of large arrays at a speed\nthat reaches the limit imposed by memory bandwidth. Some common methods that\nattempt to improve accuracy without being exact may therefore be pointless, at\nleast for large summations, since they are slower than computing the sum\nexactly.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 01:17:04 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Neal", "Radford M.", ""]]}, {"id": "1505.05770", "submitter": "Danilo Jimenez Rezende", "authors": "Danilo Jimenez Rezende and Shakir Mohamed", "title": "Variational Inference with Normalizing Flows", "comments": "Proceedings of the 32nd International Conference on Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The choice of approximate posterior distribution is one of the core problems\nin variational inference. Most applications of variational inference employ\nsimple families of posterior approximations in order to allow for efficient\ninference, focusing on mean-field or other simple structured approximations.\nThis restriction has a significant impact on the quality of inferences made\nusing variational methods. We introduce a new approach for specifying flexible,\narbitrarily complex and scalable approximate posterior distributions. Our\napproximations are distributions constructed through a normalizing flow,\nwhereby a simple initial density is transformed into a more complex one by\napplying a sequence of invertible transformations until a desired level of\ncomplexity is attained. We use this view of normalizing flows to develop\ncategories of finite and infinitesimal flows and provide a unified view of\napproaches for constructing rich posterior approximations. We demonstrate that\nthe theoretical advantages of having posteriors that better match the true\nposterior, combined with the scalability of amortized variational approaches,\nprovides a clear improvement in performance and applicability of variational\ninference.\n", "versions": [{"version": "v1", "created": "Thu, 21 May 2015 15:36:37 GMT"}, {"version": "v2", "created": "Fri, 22 May 2015 09:13:28 GMT"}, {"version": "v3", "created": "Tue, 26 May 2015 15:46:33 GMT"}, {"version": "v4", "created": "Mon, 22 Jun 2015 18:36:32 GMT"}, {"version": "v5", "created": "Mon, 13 Jun 2016 08:46:44 GMT"}, {"version": "v6", "created": "Tue, 14 Jun 2016 09:01:36 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Rezende", "Danilo Jimenez", ""], ["Mohamed", "Shakir", ""]]}, {"id": "1505.06292", "submitter": "Or Zuk", "authors": "Avishai Wagner and Or Zuk", "title": "Low-Rank Matrix Recovery from Row-and-Column Affine Measurements", "comments": "ICML 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study a row-and-column affine measurement scheme for low-rank\nmatrix recovery. Each measurement is a linear combination of elements in one\nrow or one column of a matrix $X$. This setting arises naturally in\napplications from different domains. However, current algorithms developed for\nstandard matrix recovery problems do not perform well in our case, hence the\nneed for developing new algorithms and theory for our problem. We propose a\nsimple algorithm for the problem based on Singular Value Decomposition ($SVD$)\nand least-squares ($LS$), which we term \\alg. We prove that (a simplified\nversion of) our algorithm can recover $X$ exactly with the minimum possible\nnumber of measurements in the noiseless case. In the general noisy case, we\nprove performance guarantees on the reconstruction accuracy under the Frobenius\nnorm. In simulations, our row-and-column design and \\alg algorithm show\nimproved speed, and comparable and in some cases better accuracy compared to\nstandard measurements designs and algorithms. Our theoretical and experimental\nresults suggest that the proposed row-and-column affine measurements scheme,\ntogether with our recovery algorithm, may provide a powerful framework for\naffine matrix reconstruction.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 08:45:20 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Wagner", "Avishai", ""], ["Zuk", "Or", ""]]}, {"id": "1505.06318", "submitter": "Umberto Picchini", "authors": "Umberto Picchini and Rachele Anderson", "title": "Approximate maximum likelihood estimation using data-cloning ABC", "comments": "25 pages. Minor revision. It includes a parametric bootstrap for the\n  exact MLE for the first example; includes mean bias and RMSE calculations for\n  the third example. Forthcoming in Computational Statistics and Data Analysis", "journal-ref": null, "doi": "10.1016/j.csda.2016.08.006", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A maximum likelihood methodology for a general class of models is presented,\nusing an approximate Bayesian computation (ABC) approach. The typical target of\nABC methods are models with intractable likelihoods, and we combine an ABC-MCMC\nsampler with so-called \"data cloning\" for maximum likelihood estimation.\nAccuracy of ABC methods relies on the use of a small threshold value for\ncomparing simulations from the model and observed data. The proposed\nmethodology shows how to use large threshold values, while the number of\ndata-clones is increased to ease convergence towards an approximate maximum\nlikelihood estimate. We show how to exploit the methodology to reduce the\nnumber of iterations of a standard ABC-MCMC algorithm and therefore reduce the\ncomputational effort, while obtaining reasonable point estimates. Simulation\nstudies show the good performance of our approach on models with intractable\nlikelihoods such as g-and-k distributions, stochastic differential equations\nand state-space models.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 12:31:00 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2015 05:43:32 GMT"}, {"version": "v3", "created": "Fri, 8 Apr 2016 12:22:30 GMT"}, {"version": "v4", "created": "Thu, 11 Aug 2016 09:30:40 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Picchini", "Umberto", ""], ["Anderson", "Rachele", ""]]}, {"id": "1505.06354", "submitter": "Elizabeth Schifano", "authors": "Elizabeth D. Schifano, Jing Wu, Chun Wang, Jun Yan and Ming-Hui Chen", "title": "Online Updating of Statistical Inference in the Big Data Setting", "comments": "Submitted to Technometrics", "journal-ref": "Technometrics 58 (2016) 393-403", "doi": "10.1080/00401706.2016.1142900", "report-no": null, "categories": "stat.CO stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present statistical methods for big data arising from online analytical\nprocessing, where large amounts of data arrive in streams and require fast\nanalysis without storage/access to the historical data. In particular, we\ndevelop iterative estimating algorithms and statistical inferences for linear\nmodels and estimating equations that update as new data arrive. These\nalgorithms are computationally efficient, minimally storage-intensive, and\nallow for possible rank deficiencies in the subset design matrices due to\nrare-event covariates. Within the linear model setting, the proposed\nonline-updating framework leads to predictive residual tests that can be used\nto assess the goodness-of-fit of the hypothesized model. We also propose a new\nonline-updating estimator under the estimating equation setting. Theoretical\nproperties of the goodness-of-fit tests and proposed estimators are examined in\ndetail. In simulation studies and real data applications, our estimator\ncompares favorably with competing approaches under the estimating equation\nsetting.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 17:34:15 GMT"}], "update_date": "2018-06-13", "authors_parsed": [["Schifano", "Elizabeth D.", ""], ["Wu", "Jing", ""], ["Wang", "Chun", ""], ["Yan", "Jun", ""], ["Chen", "Ming-Hui", ""]]}, {"id": "1505.06356", "submitter": "Fredrik Lindsten", "authors": "Fredrik Lindsten, Pete Bunch, Sumeetpal S. Singh, Thomas B. Sch\\\"on", "title": "Particle ancestor sampling for near-degenerate or intractable state\n  transition models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Bayesian inference in sequential latent variable models in\ngeneral, and in nonlinear state space models in particular (i.e., state\nsmoothing). We work with sequential Monte Carlo (SMC) algorithms, which provide\na powerful inference framework for addressing this problem. However, for\ncertain challenging and common model classes the state-of-the-art algorithms\nstill struggle. The work is motivated in particular by two such model classes:\n(i) models where the state transition kernel is (nearly) degenerate, i.e.\n(nearly) concentrated on a low-dimensional manifold, and (ii) models where\npoint-wise evaluation of the state transition density is intractable. Both\ntypes of models arise in many applications of interest, including tracking,\nepidemiology, and econometrics. The difficulties with these types of models is\nthat they essentially rule out forward-backward-based methods, which are known\nto be of great practical importance, not least to construct computationally\nefficient particle Markov chain Monte Carlo (PMCMC) algorithms. To alleviate\nthis, we propose a \"particle rejuvenation\" technique to enable the use of the\nforward-backward strategy for (nearly) degenerate models and, by extension, for\nintractable models. We derive the proposed method specifically within the\ncontext of PMCMC, but we emphasise that it is applicable to any\nforward-backward-based Monte Carlo method.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 17:47:12 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Lindsten", "Fredrik", ""], ["Bunch", "Pete", ""], ["Singh", "Sumeetpal S.", ""], ["Sch\u00f6n", "Thomas B.", ""]]}, {"id": "1505.06357", "submitter": "Fredrik Lindsten", "authors": "Fredrik Lindsten, Pete Bunch, Simo S\\\"arkk\\\"a, Thomas B. Sch\\\"on,\n  Simon J. Godsill", "title": "Rao-Blackwellized particle smoothers for conditionally linear Gaussian\n  models", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2015.2506543", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential Monte Carlo (SMC) methods, such as the particle filter, are by now\none of the standard computational techniques for addressing the filtering\nproblem in general state-space models. However, many applications require\npost-processing of data offline. In such scenarios the smoothing problem--in\nwhich all the available data is used to compute state estimates--is of central\ninterest. We consider the smoothing problem for a class of conditionally linear\nGaussian models. We present a forward-backward-type Rao-Blackwellized particle\nsmoother (RBPS) that is able to exploit the tractable substructure present in\nthese models. Akin to the well known Rao-Blackwellized particle filter, the\nproposed RBPS marginalizes out a conditionally tractable subset of state\nvariables, effectively making use of SMC only for the \"intractable part\" of the\nmodel. Compared to existing RBPS, two key features of the proposed method are:\n(i) it does not require structural approximations of the model, and (ii) the\naforementioned marginalization is done both in the forward direction and in the\nbackward direction.\n", "versions": [{"version": "v1", "created": "Sat, 23 May 2015 17:48:04 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Lindsten", "Fredrik", ""], ["Bunch", "Pete", ""], ["S\u00e4rkk\u00e4", "Simo", ""], ["Sch\u00f6n", "Thomas B.", ""], ["Godsill", "Simon J.", ""]]}, {"id": "1505.06448", "submitter": "Tomasz Badowski", "authors": "Tomasz Badowski", "title": "Adaptive importance sampling via minimization of estimators of\n  cross-entropy, mean square, and inefficiency constant", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inefficiency of using an unbiased estimator in a Monte Carlo procedure\ncan be quantified using an inefficiency constant, equal to the product of the\nvariance of the estimator and its mean computational cost. We develop methods\nfor obtaining the parameters of the importance sampling (IS) change of measure\nvia single- and multi-stage minimization of well-known estimators of\ncross-entropy and the mean square of the IS estimator, as well as of new\nestimators of such a mean square and inefficiency constant. We prove the\nconvergence and asymptotic properties of the minimization results in our\nmethods. We show that if a zero-variance IS parameter exists, then, under\nappropriate assumptions, minimization results of the new estimators converge to\nsuch a parameter at a faster rate than such results of the well-known\nestimators, and a positive definite asymptotic covariance matrix of the\nminimization results of the cross-entropy estimators is four times such a\nmatrix for the well-known mean square estimators. We introduce criteria for\ncomparing the asymptotic efficiency of stochastic optimization methods,\napplicable to the minimization methods of estimators considered in this work.\nIn our numerical experiments for computing expectations of functionals of an\nEuler scheme, the minimization of the new estimators led to the lowest\ninefficiency constants and variances of the IS estimators, followed by the\nminimization of the well-known mean square estimators, and the cross-entropy\nones.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2015 15:35:13 GMT"}, {"version": "v10", "created": "Mon, 26 Oct 2015 17:38:28 GMT"}, {"version": "v11", "created": "Thu, 29 Oct 2015 17:59:33 GMT"}, {"version": "v12", "created": "Tue, 24 Nov 2015 18:08:14 GMT"}, {"version": "v13", "created": "Thu, 17 Dec 2015 20:32:46 GMT"}, {"version": "v14", "created": "Wed, 6 Jan 2016 22:28:48 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2015 17:27:53 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2015 17:02:35 GMT"}, {"version": "v4", "created": "Thu, 25 Jun 2015 17:52:45 GMT"}, {"version": "v5", "created": "Thu, 9 Jul 2015 16:37:06 GMT"}, {"version": "v6", "created": "Tue, 21 Jul 2015 19:01:27 GMT"}, {"version": "v7", "created": "Mon, 27 Jul 2015 16:07:16 GMT"}, {"version": "v8", "created": "Sat, 8 Aug 2015 17:42:16 GMT"}, {"version": "v9", "created": "Mon, 7 Sep 2015 15:39:23 GMT"}], "update_date": "2016-01-08", "authors_parsed": [["Badowski", "Tomasz", ""]]}, {"id": "1505.06473", "submitter": "Christian P. Robert", "authors": "Julyan Arbel (University of Torino), Igor Prunster (University of\n  Torino), Christian P. Robert (Universite Paris-Dauphine), and Robin J. Ryder\n  (Universite Paris-Dauphine)", "title": "Three discussions of the paper \"sequential quasi-Monte Carlo sampling\",\n  by M. Gerber and N. Chopin", "comments": "Published in the Journal of the Royal Statistical Society, volume\n  77(3), pages 559, 569 and 570", "journal-ref": null, "doi": "10.1111/rssb.12104", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a collection of three written discussions of the paper \"sequential\nquasi-Monte Carlo sampling\" by M. Gerber and N. Chopin, following the\npresentation given before the Royal Statistical Society in London on December\n10th, 2014.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2015 20:16:11 GMT"}, {"version": "v2", "created": "Tue, 26 May 2015 15:34:59 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Arbel", "Julyan", "", "University of Torino"], ["Prunster", "Igor", "", "University of\n  Torino"], ["Robert", "Christian P.", "", "Universite Paris-Dauphine"], ["Ryder", "Robin J.", "", "Universite Paris-Dauphine"]]}, {"id": "1505.06475", "submitter": "Wesley Tansey", "authors": "Wesley Tansey and James G. Scott", "title": "A Fast and Flexible Algorithm for the Graph-Fused Lasso", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm for solving the graph-fused lasso (GFL), a method\nfor parameter estimation that operates under the assumption that the signal\ntends to be locally constant over a predefined graph structure. Our key insight\nis to decompose the graph into a set of trails which can then each be solved\nefficiently using techniques for the ordinary (1D) fused lasso. We leverage\nthese trails in a proximal algorithm that alternates between closed form primal\nupdates and fast dual trail updates. The resulting techinque is both faster\nthan previous GFL methods and more flexible in the choice of loss function and\ngraph structure. Furthermore, we present two algorithms for constructing trail\nsets and show empirically that they offer a tradeoff between preprocessing time\nand convergence rate.\n", "versions": [{"version": "v1", "created": "Sun, 24 May 2015 20:18:00 GMT"}, {"version": "v2", "created": "Tue, 26 May 2015 23:04:05 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2015 05:40:58 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Tansey", "Wesley", ""], ["Scott", "James G.", ""]]}, {"id": "1505.07228", "submitter": "Frederic Bois", "authors": "Sagnik Datta, Ghislaine Gayraud, Eric Leclerc, Frederic Y. Bois", "title": "Graph_sampler: a simple tool for fully Bayesian analyses of DAG-models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian networks (BNs) are widely used graphical models usable to draw\nstatistical inference about Directed acyclic graphs (DAGs). We presented here\nGraph_sampler a fast free C language software for structural inference on BNs.\nGraph_sampler uses a fully Bayesian approach in which the marginal likelihood\nof the data and prior information about the network structure are considered.\nThis new software can handle both the continuous as well discrete data and\nbased on the data type two different models are formulated. The software also\nprovides a wide variety of structure priors which can be informative or\nuninformative. We proposed a new and much faster jumping kernel strategy in the\nMetropolis-Hastings algorithm. The source C code distributed is very compact,\nfast, uses low memory and disk storage. We performed out several analyses based\non different simulated data sets and synthetic as well as real networks to\ndiscuss the performance of Graph_sampler.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2015 09:01:38 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2016 15:13:28 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Datta", "Sagnik", ""], ["Gayraud", "Ghislaine", ""], ["Leclerc", "Eric", ""], ["Bois", "Frederic Y.", ""]]}, {"id": "1505.07519", "submitter": "Oliver Serang", "authors": "Julianus Pfeuffer and Oliver Serang", "title": "A Bounded $p$-norm Approximation of Max-Convolution for Sub-Quadratic\n  Bayesian Inference on Additive Factors", "comments": null, "journal-ref": "Journal of Machine Learning Research 17 (2016) 1-39", "doi": null, "report-no": null, "categories": "stat.CO cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Max-convolution is an important problem closely resembling standard\nconvolution; as such, max-convolution occurs frequently across many fields.\nHere we extend the method with fastest known worst-case runtime, which can be\napplied to nonnegative vectors by numerically approximating the Chebyshev norm\n$\\| \\cdot \\|_\\infty$, and use this approach to derive two numerically stable\nmethods based on the idea of computing $p$-norms via fast convolution: The\nfirst method proposed, with runtime in $O( k \\log(k) \\log(\\log(k)) )$ (which is\nless than $18 k \\log(k)$ for any vectors that can be practically realized),\nuses the $p$-norm as a direct approximation of the Chebyshev norm. The second\napproach proposed, with runtime in $O( k \\log(k) )$ (although in practice both\nperform similarly), uses a novel null space projection method, which extracts\ninformation from a sequence of $p$-norms to estimate the maximum value in the\nvector (this is equivalent to querying a small number of moments from a\ndistribution of bounded support in order to estimate the maximum). The $p$-norm\napproaches are compared to one another and are shown to compute an\napproximation of the Viterbi path in a hidden Markov model where the transition\nmatrix is a Toeplitz matrix; the runtime of approximating the Viterbi path is\nthus reduced from $O( n k^2 )$ steps to $O( n $k \\log(k))$ steps in practice,\nand is demonstrated by inferring the U.S. unemployment rate from the S&P 500\nstock index.\n", "versions": [{"version": "v1", "created": "Thu, 28 May 2015 01:03:29 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2015 00:18:21 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Pfeuffer", "Julianus", ""], ["Serang", "Oliver", ""]]}, {"id": "1505.07925", "submitter": "Yun Yang", "authors": "Yun Yang, Martin J. Wainwright, Michael I. Jordan", "title": "On the Computational Complexity of High-Dimensional Bayesian Variable\n  Selection", "comments": "42 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the computational complexity of Markov chain Monte Carlo (MCMC)\nmethods for high-dimensional Bayesian linear regression under sparsity\nconstraints. We first show that a Bayesian approach can achieve\nvariable-selection consistency under relatively mild conditions on the design\nmatrix. We then demonstrate that the statistical criterion of posterior\nconcentration need not imply the computational desideratum of rapid mixing of\nthe MCMC algorithm. By introducing a truncated sparsity prior for variable\nselection, we provide a set of conditions that guarantee both\nvariable-selection consistency and rapid mixing of a particular\nMetropolis-Hastings algorithm. The mixing time is linear in the number of\ncovariates up to a logarithmic factor. Our proof controls the spectral gap of\nthe Markov chain by constructing a canonical path ensemble that is inspired by\nthe steps taken by greedy algorithms for variable selection.\n", "versions": [{"version": "v1", "created": "Fri, 29 May 2015 05:33:22 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Yang", "Yun", ""], ["Wainwright", "Martin J.", ""], ["Jordan", "Michael I.", ""]]}]