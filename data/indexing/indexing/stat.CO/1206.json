[{"id": "1206.0190", "submitter": "Jun Yan", "authors": "Steven Chiou, Sangwook Kang, and Jun Yan", "title": "Fast Accelerated Failure Time Modeling for Case-Cohort Data", "comments": "submitted", "journal-ref": "Stat Comput 2014 24:559-568", "doi": "10.1007/s11222-013-9388-2", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semiparametric accelerated failure time (AFT) models directly relate the\npredicted failure times to covariates and are a useful alternative to models\nthat work on the hazard function or the survival function. For case-cohort\ndata, much less development has been done with AFT models. In addition to the\nmissing covariates outside of the sub-cohort in controls, challenges from AFT\nmodel inferences with full cohort are retained. The regression parameter\nestimator is hard to compute because the most widely used rank-based estimating\nequations are not smooth. Further, its variance depends on the unspecified\nerror distribution, and most methods rely on computationally intensive\nbootstrap to estimate it. We propose fast rank-based inference procedures for\nAFT models, applying recent methodological advances to the context of\ncase-cohort data. Parameters are estimated with an induced smoothing approach\nthat smooths the estimating functions and facilitates the numerical solution.\nVariance estimators are obtained through efficient resampling methods for\nnonsmooth estimating functions that avoids full blown bootstrap. Simulation\nstudies suggest that the recommended procedure provides fast and valid\ninferences among several competing procedures. Application to a tumor study\ndemonstrates the utility of the proposed method in routine data analysis.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 14:14:34 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Chiou", "Steven", ""], ["Kang", "Sangwook", ""], ["Yan", "Jun", ""]]}, {"id": "1206.0338", "submitter": "Joseph  Salmon", "authors": "Joseph Salmon and Zachary Harmany and Charles-Alban Deledalle and\n  Rebecca Willett", "title": "Poisson noise reduction with non-local PCA", "comments": "erratum: Image man is wrongly name pepper in the journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photon-limited imaging arises when the number of photons collected by a\nsensor array is small relative to the number of detector elements. Photon\nlimitations are an important concern for many applications such as spectral\nimaging, night vision, nuclear medicine, and astronomy. Typically a Poisson\ndistribution is used to model these observations, and the inherent\nheteroscedasticity of the data combined with standard noise removal methods\nyields significant artifacts. This paper introduces a novel denoising algorithm\nfor photon-limited images which combines elements of dictionary learning and\nsparse patch-based representations of images. The method employs both an\nadaptation of Principal Component Analysis (PCA) for Poisson noise and recently\ndeveloped sparsity-regularized convex optimization algorithms for\nphoton-limited images. A comprehensive empirical evaluation of the proposed\nmethod helps characterize the performance of this approach relative to other\nstate-of-the-art denoising methods. The results reveal that, despite its\nconceptual simplicity, Poisson PCA-based denoising appears to be highly\ncompetitive in very low light regimes.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2012 02:44:05 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2012 09:29:18 GMT"}, {"version": "v3", "created": "Mon, 17 Dec 2012 23:39:38 GMT"}, {"version": "v4", "created": "Mon, 28 Apr 2014 13:56:09 GMT"}], "update_date": "2014-04-29", "authors_parsed": [["Salmon", "Joseph", ""], ["Harmany", "Zachary", ""], ["Deledalle", "Charles-Alban", ""], ["Willett", "Rebecca", ""]]}, {"id": "1206.1901", "submitter": "Radford M. Neal", "authors": "Radford M. Neal", "title": "MCMC using Hamiltonian dynamics", "comments": null, "journal-ref": null, "doi": "10.1201/b10905", "report-no": null, "categories": "stat.CO physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian dynamics can be used to produce distant proposals for the\nMetropolis algorithm, thereby avoiding the slow exploration of the state space\nthat results from the diffusive behaviour of simple random-walk proposals.\nThough originating in physics, Hamiltonian dynamics can be applied to most\nproblems with continuous state spaces by simply introducing fictitious\n\"momentum\" variables. A key to its usefulness is that Hamiltonian dynamics\npreserves volume, and its trajectories can thus be used to define complex\nmappings without the need to account for a hard-to-compute Jacobian factor - a\nproperty that can be exactly maintained even when the dynamics is approximated\nby discretizing time. In this review, I discuss theoretical and practical\naspects of Hamiltonian Monte Carlo, and present some of its variations,\nincluding using windows of states for deciding on acceptance or rejection,\ncomputing trajectories using fast approximations, tempering during the course\nof a trajectory to handle isolated modes, and short-cut methods that prevent\nuseless trajectories from taking much computation time.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 02:34:11 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Neal", "Radford M.", ""]]}, {"id": "1206.2689", "submitter": "Mark Huber", "authors": "Mark Huber", "title": "Approximation algorithms for the normalizing constant of Gibbs\n  distributions", "comments": "Published in at http://dx.doi.org/10.1214/14-AAP1015 the Annals of\n  Applied Probability (http://www.imstat.org/aap/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Probability 2015, Vol. 25, 974-985", "doi": "10.1214/14-AAP1015", "report-no": "IMS-AAP-AAP1015", "categories": "math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a family of distributions $\\{\\pi_{\\beta}\\}$ where $X\\sim\\pi_{\\beta}$\nmeans that $\\mathbb{P}(X=x)=\\exp(-\\beta H(x))/Z(\\beta)$. Here $Z(\\beta)$ is the\nproper normalizing constant, equal to $\\sum_x\\exp(-\\beta H(x))$. Then\n$\\{\\pi_{\\beta}\\}$ is known as a Gibbs distribution, and $Z(\\beta)$ is the\npartition function. This work presents a new method for approximating the\npartition function to a specified level of relative accuracy using only a\nnumber of samples, that is, $O(\\ln(Z(\\beta))\\ln(\\ln(Z(\\beta))))$ when\n$Z(0)\\geq1$. This is a sharp improvement over previous, similar approaches that\nused a much more complicated algorithm, requiring\n$O(\\ln(Z(\\beta))\\ln(\\ln(Z(\\beta)))^5)$ samples.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 23:49:36 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2015 07:41:45 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Huber", "Mark", ""]]}, {"id": "1206.3251", "submitter": "Tal El-Hay", "authors": "Tal El-Hay, Nir Friedman, Raz Kupferman", "title": "Gibbs Sampling in Factorized Continuous-Time Markov Processes", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-169-178", "categories": "cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central task in many applications is reasoning about processes that change\nover continuous time. Continuous-Time Bayesian Networks is a general compact\nrepresentation language for multi-component continuous-time processes. However,\nexact inference in such processes is exponential in the number of components,\nand thus infeasible for most models of interest. Here we develop a novel Gibbs\nsampling procedure for multi-component processes. This procedure iteratively\nsamples a trajectory for one of the components given the remaining ones. We\nshow how to perform exact sampling that adapts to the natural time scale of the\nsampled process. Moreover, we show that this sampling procedure naturally\nexploits the structure of the network to reduce the computational cost of each\nstep. This procedure is the first that can provide asymptotically unbiased\napproximation in such processes.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:11:00 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["El-Hay", "Tal", ""], ["Friedman", "Nir", ""], ["Kupferman", "Raz", ""]]}, {"id": "1206.3421", "submitter": "Klaus Holst K", "authors": "Klaus K. Holst and Esben Budtz-J{\\o}rgensen", "title": "Linear Latent Variable Models: The lava-package", "comments": null, "journal-ref": "Computational Statistics, Volume 28, Issue 4 , pp 1385-1452", "doi": "10.1007/s00180-012-0344-y", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An R package for specifying and estimating linear latent variable models is\npresented. The philosophy of the implementation is to separate the model\nspecification from the actual data, which leads to a dynamic and easy way of\nmodeling complex hierarchical structures. Several advanced features are\nimplemented including robust standard errors for clustered correlated data,\nmultigroup analyses, non-linear parameter constraints, inference with\nincomplete data, maximum likelihood estimation with censored and binary\nobservations, and instrumental variable estimators. In addition an extensive\nsimulation interface covering a broad range of non-linear generalized\nstructural equation models is described. The model and software are\ndemonstrated in data of measurements of the serotonin transporter in the human\nbrain.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 10:48:20 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Holst", "Klaus K.", ""], ["Budtz-J\u00f8rgensen", "Esben", ""]]}, {"id": "1206.3732", "submitter": "Nina Daskalova", "authors": "Nina Daskalova", "title": "EM Algorithm for Estimation of the Offspring Distribution in Multitype\n  Branching Processes with Terminal Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitype branching processes (MTBP) model branching structures, where the\nnodes of the resulting tree are objects of different types. One field of\napplication of such models in biology is in studies of cell proliferation. A\nsampling scheme that appears frequently is observing the cell count in several\nindependent colonies at discrete time points (sometimes only one). Thus, the\nprocess is not observable in the sense of the whole tree, but only as the\n\"generation\" at given moment in time, which consist of the number of cells of\nevery type. This requires an EM-type algorithm to obtain a maximum likelihood\n(ML) estimation of the parameters of the branching process. A computational\napproach for obtaining such estimation of the offspring distribution is\npresented in the class of Markov branching processes with terminal types.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 08:01:32 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Daskalova", "Nina", ""]]}, {"id": "1206.3974", "submitter": "Antonio Punzo", "authors": "Salvatore Ingrassia and Simona C. Minotti and Antonio Punzo", "title": "Model-based clustering via linear cluster-weighted models", "comments": null, "journal-ref": "Computational Statistics and Data Analysis, 71(4): 159-182, 2014", "doi": "10.1016/j.csda.2013.02.012", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel family of twelve mixture models with random covariates, nested in the\nlinear $t$ cluster-weighted model (CWM), is introduced for model-based\nclustering. The linear $t$ CWM was recently presented as a robust alternative\nto the better known linear Gaussian CWM. The proposed family of models provides\na unified framework that also includes the linear Gaussian CWM as a special\ncase. Maximum likelihood parameter estimation is carried out within the EM\nframework, and both the BIC and the ICL are used for model selection. A simple\nand effective hierarchical random initialization is also proposed for the EM\nalgorithm. The novel model-based clustering technique is illustrated in some\napplications to real data. Finally, a simulation study for evaluating the\nperformance of the BIC and the ICL is presented.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 16:04:25 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2015 17:06:13 GMT"}], "update_date": "2015-03-10", "authors_parsed": [["Ingrassia", "Salvatore", ""], ["Minotti", "Simona C.", ""], ["Punzo", "Antonio", ""]]}, {"id": "1206.3985", "submitter": "Marcelo Pereyra", "authors": "Marcelo Pereyra, Nicolas Dobigeon, Hadj Batatia and Jean-Yves\n  Tourneret", "title": "Computing the Cramer-Rao bound of Markov random field parameters:\n  Application to the Ising and the Potts models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report considers the problem of computing the Cramer-Rao bound for the\nparameters of a Markov random field. Computation of the exact bound is not\nfeasible for most fields of interest because their likelihoods are intractable\nand have intractable derivatives. We show here how it is possible to formulate\nthe computation of the bound as a statistical inference problem that can be\nsolve approximately, but with arbitrarily high accuracy, by using a Monte Carlo\nmethod. The proposed methodology is successfully applied on the Ising and the\nPotts models.% where it is used to assess the performance of three state-of-the\nart estimators of the parameter of these Markov random fields.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 16:49:47 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2013 08:27:46 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2013 13:14:54 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Pereyra", "Marcelo", ""], ["Dobigeon", "Nicolas", ""], ["Batatia", "Hadj", ""], ["Tourneret", "Jean-Yves", ""]]}, {"id": "1206.4666", "submitter": "Mingjun Zhong", "authors": "Mingjun Zhong (Dalian University of Tech.), Mark Girolami (University\n  College London)", "title": "A Bayesian Approach to Approximate Joint Diagonalization of Square\n  Matrices", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian scheme for the approximate diagonalisation of several\nsquare matrices which are not necessarily symmetric. A Gibbs sampler is derived\nto simulate samples of the common eigenvectors and the eigenvalues for these\nmatrices. Several synthetic examples are used to illustrate the performance of\nthe proposed Gibbs sampler and we then provide comparisons to several other\njoint diagonalization algorithms, which shows that the Gibbs sampler achieves\nthe state-of-the-art performance on the examples considered. As a byproduct,\nthe output of the Gibbs sampler could be used to estimate the log marginal\nlikelihood, however we employ the approximation based on the Bayesian\ninformation criterion (BIC) which in the synthetic examples considered\ncorrectly located the number of common eigenvectors. We then succesfully\napplied the sampler to the source separation problem as well as the common\nprincipal component analysis and the common spatial pattern analysis problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:32:46 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Zhong", "Mingjun", "", "Dalian University of Tech."], ["Girolami", "Mark", "", "University\n  College London"]]}, {"id": "1206.4910", "submitter": "Moritz Schauer", "authors": "Frank van der Meulen, Moritz Schauer, Harry van Zanten", "title": "Reversible jump MCMC for nonparametric drift estimation for diffusion\n  processes", "comments": null, "journal-ref": "Computational Statistics & Data Analysis, Volume 71, Pages\n  615-632, ISSN 0167-9473 (2014)", "doi": "10.1016/j.csda.2013.03.002", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of nonparametric Bayesian estimation a Markov chain Monte\nCarlo algorithm is devised and implemented to sample from the posterior\ndistribution of the drift function of a continuously or discretely observed\none-dimensional diffusion. The drift is modeled by a scaled linear combination\nof basis functions with a Gaussian prior on the coefficients. The scaling\nparameter is equipped with a partially conjugate prior. The number of basis\nfunction in the drift is equipped with a prior distribution as well. For\ncontinuous data, a reversible jump Markov chain algorithm enables the\nexploration of the posterior over models of varying dimension. Subsequently, it\nis explained how data-augmentation can be used to extend the algorithm to deal\nwith diffusions observed discretely in time. Some examples illustrate that the\nmethod can give satisfactory results. In these examples a comparison is made\nwith another existing method as well.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 15:16:35 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2013 10:50:55 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["van der Meulen", "Frank", ""], ["Schauer", "Moritz", ""], ["van Zanten", "Harry", ""]]}, {"id": "1206.5102", "submitter": "Stevenn Volant", "authors": "Stevenn Volant, Caroline B\\'erard, Marie-Laure Martin-Magniette and\n  St\\'ephane Robin", "title": "Hidden Markov Models with mixtures as emission distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In unsupervised classification, Hidden Markov Models (HMM) are used to\naccount for a neighborhood structure between observations. The emission\ndistributions are often supposed to belong to some parametric family. In this\npaper, a semiparametric modeling where the emission distributions are a mixture\nof parametric distributions is proposed to get a higher flexibility. We show\nthat the classical EM algorithm can be adapted to infer the model parameters.\nFor the initialisation step, starting from a large number of components, a\nhierarchical method to combine them into the hidden states is proposed. Three\nlikelihood-based criteria to select the components to be combined are\ndiscussed. To estimate the number of hidden states, BIC-like criteria are\nderived. A simulation study is carried out both to determine the best\ncombination between the merging criteria and the model selection criteria and\nto evaluate the accuracy of classification. The proposed method is also\nillustrated using a biological dataset from the model plant Arabidopsis\nthaliana. A R package HMMmix is freely available on the CRAN.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 10:24:55 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Volant", "Stevenn", ""], ["B\u00e9rard", "Caroline", ""], ["Martin-Magniette", "Marie-Laure", ""], ["Robin", "St\u00e9phane", ""]]}, {"id": "1206.5208", "submitter": "James S. Martin", "authors": "James S. Martin and Ajay Jasra and Sumeetpal S. Singh and Nick\n  Whiteley and Emma McCoy", "title": "Approximate Bayesian Computation for Smoothing", "comments": "22 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a method for approximate inference in hidden Markov models\n(HMMs). The method circumvents the need to evaluate conditional densities of\nobservations given the hidden states. It may be considered an instance of\nApproximate Bayesian Computation (ABC) and it involves the introduction of\nauxiliary variables valued in the same space as the observations. The quality\nof the approximation may be controlled to arbitrary precision through a\nparameter \\epsilon>0 . We provide theoretical results which quantify, in terms\nof \\epsilon, the ABC error in approximation of expectations of additive\nfunctionals with respect to the smoothing distributions. Under regularity\nassumptions, this error is O(n\\epsilon), where n is the number of time steps\nover which smoothing is performed. For numerical implementation we adopt the\nforward-only sequential Monte Carlo (SMC) scheme of [16] and quantify the\ncombined error from the ABC and SMC approximations. This forms some of the\nfirst quantitative results for ABC methods which jointly treat the ABC and\nsimulation errors, with a finite number of data and simulated samples. When the\nHMM has unknown static parameters, we consider particle Markov chain Monte\nCarlo [2] (PMCMC) methods for batch statistical inference.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 17:01:56 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Martin", "James S.", ""], ["Jasra", "Ajay", ""], ["Singh", "Sumeetpal S.", ""], ["Whiteley", "Nick", ""], ["McCoy", "Emma", ""]]}, {"id": "1206.5232", "submitter": "Mehdi Molkaraie", "authors": "Mehdi Molkaraie and Hans-Andrea Loeliger", "title": "Extending Monte Carlo Methods to Factor Graphs with Negative and Complex\n  Factors", "comments": "Proc. IEEE Information Theory Workshop (ITW), Lausanne, Switzerland,\n  Sept. 3-7, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The partition function of a factor graph can sometimes be accurately\nestimated by Monte Carlo methods. In this paper, such methods are extended to\nfactor graphs with negative and complex factors.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 19:28:39 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2012 21:21:51 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Molkaraie", "Mehdi", ""], ["Loeliger", "Hans-Andrea", ""]]}, {"id": "1206.5239", "submitter": "Firas Hamze", "authors": "Firas Hamze, Nando de Freitas", "title": "Large-Flip Importance Sampling", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-167-174", "categories": "stat.CO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new Monte Carlo algorithm for complex discrete distributions.\nThe algorithm is motivated by the N-Fold Way, which is an ingenious\nevent-driven MCMC sampler that avoids rejection moves at any specific state.\nThe N-Fold Way can however get \"trapped\" in cycles. We surmount this problem by\nmodifying the sampling process. This correction does introduce bias, but the\nbias is subsequently corrected with a carefully engineered importance sampler.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:51:32 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Hamze", "Firas", ""], ["de Freitas", "Nando", ""]]}, {"id": "1206.5285", "submitter": "Ydo Wexler", "authors": "Ydo Wexler, Dan Geiger", "title": "Importance Sampling via Variational Optimization", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-426-433", "categories": "stat.CO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the exact likelihood of data in large Bayesian networks consisting\nof thousands of vertices is often a difficult task. When these models contain\nmany deterministic conditional probability tables and when the observed values\nare extremely unlikely even alternative algorithms such as variational methods\nand stochastic sampling often perform poorly. We present a new importance\nsampling algorithm for Bayesian networks which is based on variational\ntechniques. We use the updates of the importance function to predict whether\nthe stochastic sampling converged above or below the true likelihood, and\nchange the proposal distribution accordingly. The validity of the method and\nits contribution to convergence is demonstrated on hard networks of large\ngenetic linkage analysis tasks.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:15:41 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Wexler", "Ydo", ""], ["Geiger", "Dan", ""]]}, {"id": "1206.5387", "submitter": "Manjunath B G", "authors": "Manjunath B G and Stefan Wilhelm", "title": "Moments Calculation For the Doubly Truncated Multivariate Normal Density", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present article we derive an explicit expression for the trun- cated\nmean and variance for the multivariate normal distribution with ar- bitrary\nrectangular double truncation. We use the moment generating ap- proach of\nTallis (1961) and extend it to general {\\mu}, {\\Sigma} and all combinations of\ntruncation. As part of the solution we also give a formula for the bivari- ate\nmarginal density of truncated multinormal variates. We also prove an invariance\nproperty of some elements of the inverse covariance after trunca- tion.\nComputer algorithms for computing the truncated mean, variance and the\nbivariate marginal probabilities for doubly truncated multivariate normal\nvariates have been written in R and are presented along with three examples.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 12:37:20 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["G", "Manjunath B", ""], ["Wilhelm", "Stefan", ""]]}, {"id": "1206.5396", "submitter": "Mathias Niepert", "authors": "Mathias Niepert", "title": "Markov Chains on Orbits of Permutation Groups", "comments": "To appear in Proceedings of UAI2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.CO stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach to detecting and utilizing symmetries in\nprobabilistic graphical models with two main contributions. First, we present a\nscalable approach to computing generating sets of permutation groups\nrepresenting the symmetries of graphical models. Second, we introduce orbital\nMarkov chains, a novel family of Markov chains leveraging model symmetries to\nreduce mixing times. We establish an insightful connection between model\nsymmetries and rapid mixing of orbital Markov chains. Thus, we present the\nfirst lifted MCMC algorithm for probabilistic graphical models. Both analytical\nand empirical results demonstrate the effectiveness and efficiency of the\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 14:27:39 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2012 14:54:39 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Niepert", "Mathias", ""]]}, {"id": "1206.6378", "submitter": "Mark Tygert", "authors": "William Perkins, Gary Simon, and Mark Tygert", "title": "Computing the asymptotic power of a Euclidean-distance test for\n  goodness-of-fit", "comments": "14 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A natural (yet unconventional) test for goodness-of-fit measures the\ndiscrepancy between the model and empirical distributions via their Euclidean\ndistance (or, equivalently, via its square). The present paper characterizes\nthe statistical power of such a test against a family of alternative\ndistributions, in the limit that the number of observations is large, with\nevery alternative departing from the model in the same direction. Specifically,\nthe paper provides an efficient numerical method for evaluating the cumulative\ndistribution function (cdf) of the square of the Euclidean distance between the\nmodel and empirical distributions under the alternatives, in the limit that the\nnumber of observations is large. The paper illustrates the scheme by plotting\nthe asymptotic power (as a function of the significance level) for several\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:56:14 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Perkins", "William", ""], ["Simon", "Gary", ""], ["Tygert", "Mark", ""]]}, {"id": "1206.6380", "submitter": "Sungjin Ahn", "authors": "Sungjin Ahn (UC Irvine), Anoop Korattikara (UC Irvine), Max Welling\n  (UC Irvine)", "title": "Bayesian Posterior Sampling via Stochastic Gradient Fisher Scoring", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the following question: Can we approximately sample\nfrom a Bayesian posterior distribution if we are only allowed to touch a small\nmini-batch of data-items for every sample we generate?. An algorithm based on\nthe Langevin equation with stochastic gradients (SGLD) was previously proposed\nto solve this, but its mixing rate was slow. By leveraging the Bayesian Central\nLimit Theorem, we extend the SGLD algorithm so that at high mixing rates it\nwill sample from a normal approximation of the posterior, while for slow mixing\nrates it will mimic the behavior of SGLD with a pre-conditioner matrix. As a\nbonus, the proposed algorithm is reminiscent of Fisher scoring (with stochastic\ngradients) and as such an efficient optimizer during burn-in.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Ahn", "Sungjin", "", "UC Irvine"], ["Korattikara", "Anoop", "", "UC Irvine"], ["Welling", "Max", "", "UC Irvine"]]}, {"id": "1206.6430", "submitter": "John Paisley", "authors": "John Paisley (UC Berkeley), David Blei (Princeton University), Michael\n  Jordan (UC Berkeley)", "title": "Variational Bayesian Inference with Stochastic Search", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean-field variational inference is a method for approximate Bayesian\nposterior inference. It approximates a full posterior distribution with a\nfactorized set of distributions by maximizing a lower bound on the marginal\nlikelihood. This requires the ability to integrate a sum of terms in the log\njoint likelihood using this factorized distribution. Often not all integrals\nare in closed form, which is typically handled by using a lower bound. We\npresent an alternative algorithm based on stochastic optimization that allows\nfor direct optimization of the variational lower bound. This method uses\ncontrol variates to reduce the variance of the stochastic search gradient, in\nwhich existing lower bounds can play an important role. We demonstrate the\napproach on two non-conjugate models: logistic regression and an approximation\nto the HDP.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Paisley", "John", "", "UC Berkeley"], ["Blei", "David", "", "Princeton University"], ["Jordan", "Michael", "", "UC Berkeley"]]}, {"id": "1206.6519", "submitter": "Noah Simon", "authors": "Noah Simon and Robert Tibshirani", "title": "A Permutation Approach to Testing Interactions in Many Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO stat.ME", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  To date, testing interactions in high dimensions has been a challenging task.\nExisting methods often have issues with sensitivity to modeling assumptions and\nheavily asymptotic nominal p-values. To help alleviate these issues, we propose\na permutation-based method for testing marginal interactions with a binary\nresponse. Our method searches for pairwise correlations which differ between\nclasses. In this manuscript, we compare our method on real and simulated data\nto the standard approach of running many pairwise logistic models. On simulated\ndata our method finds more significant interactions at a lower false discovery\nrate (especially in the presence of main effects). On real genomic data,\nalthough there is no gold standard, our method finds apparent signal and tells\na believable story, while logistic regression does not. We also give asymptotic\nconsistency results under not too restrictive assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 20:38:20 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Simon", "Noah", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1206.6532", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin and Tristan van Leeuwen", "title": "Estimating Nuisance Parameters in Inverse Problems", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": "10.1088/0266-5611/28/11/115016", "report-no": null, "categories": "math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many inverse problems include nuisance parameters which, while not of direct\ninterest, are required to recover primary parameters. Structure present in\nthese problems allows efficient optimization strategies - a well known example\nis variable projection, where nonlinear least squares problems which are linear\nin some parameters can be very efficiently optimized. In this paper, we extend\nthe idea of projecting out a subset over the variables to a broad class of\nmaximum likelihood (ML) and maximum a posteriori likelihood (MAP) problems with\nnuisance parameters, such as variance or degrees of freedom. As a result, we\nare able to incorporate nuisance parameter estimation into large-scale\nconstrained and unconstrained inverse problem formulations. We apply the\napproach to a variety of problems, including estimation of unknown variance\nparameters in the Gaussian model, degree of freedom (d.o.f.) parameter\nestimation in the context of robust inverse problems, automatic calibration,\nand optimal experimental design. Using numerical examples, we demonstrate\nimprovement in recovery of primary parameters for several large- scale inverse\nproblems. The proposed approach is compatible with a wide variety of algorithms\nand formulations, and its implementation requires only minor modifications to\nexisting algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 22:14:54 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["van Leeuwen", "Tristan", ""]]}, {"id": "1206.6679", "submitter": "Tim Salimans", "authors": "Tim Salimans and David A. Knowles", "title": "Fixed-Form Variational Posterior Approximation through Stochastic Linear\n  Regression", "comments": null, "journal-ref": "Bayesian Analysis, Volume 8, Number 4 (2013), 837-882", "doi": "10.1214/13-BA858", "report-no": null, "categories": "stat.CO cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general algorithm for approximating nonstandard Bayesian\nposterior distributions. The algorithm minimizes the Kullback-Leibler\ndivergence of an approximating distribution to the intractable posterior\ndistribution. Our method can be used to approximate any posterior distribution,\nprovided that it is given in closed form up to the proportionality constant.\nThe approximation can be any distribution in the exponential family or any\nmixture of such distributions, which means that it can be made arbitrarily\nprecise. Several examples illustrate the speed and accuracy of our\napproximation method in practice.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 13:25:04 GMT"}, {"version": "v2", "created": "Wed, 1 Aug 2012 11:38:52 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2013 06:22:58 GMT"}, {"version": "v4", "created": "Sat, 26 Oct 2013 15:09:54 GMT"}, {"version": "v5", "created": "Wed, 27 Nov 2013 13:19:48 GMT"}, {"version": "v6", "created": "Mon, 28 Jul 2014 11:16:19 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Salimans", "Tim", ""], ["Knowles", "David A.", ""]]}, {"id": "1206.6812", "submitter": "Annalisa Cerquetti", "authors": "Annalisa Cerquetti", "title": "Stirling's approximations for exchangeable Gibbs weights", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We obtain some approximation results for the weights appearing in the\nexchangeable partition probability function identifying Gibbs partition models\nof parameter $\\alpha \\in (0,1)$, as introduced in Gnedin and Pitman (2006). We\nrely on approximation results for central and non-central generalized Stirling\nnumbers and on known results for conditional and unconditional $\\alpha$\ndiversity. We provide an application to an approximate Bayesian nonparametric\nestimation of discovery probability in species sampling problems under\nnormalized inverse Gaussian priors.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 19:58:18 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Cerquetti", "Annalisa", ""]]}, {"id": "1206.6848", "submitter": "Iain Murray", "authors": "Iain Murray, Zoubin Ghahramani, David MacKay", "title": "MCMC for doubly-intractable distributions", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-359-366", "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Chain Monte Carlo (MCMC) algorithms are routinely used to draw samples\nfrom distributions with intractable normalization constants. However, standard\nMCMC algorithms do not apply to doubly-intractable distributions in which there\nare additional parameter-dependent normalization terms; for example, the\nposterior over parameters of an undirected graphical model. An ingenious\nauxiliary-variable scheme (Moeller et al., 2004) offers a solution: exact\nsampling (Propp and Wilson, 1996) is used to sample from a Metropolis-Hastings\nproposal for which the acceptance probability is tractable. Unfortunately the\nacceptance probability of these expensive updates can be low. This paper\nprovides a generalization of Moeller et al. (2004) and a new MCMC algorithm,\nwhich obtains better acceptance probabilities for the same amount of exact\nsampling, and removes the need to estimate model parameters before sampling\nbegins.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:23:56 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Murray", "Iain", ""], ["Ghahramani", "Zoubin", ""], ["MacKay", "David", ""]]}, {"id": "1206.7051", "submitter": "David Blei", "authors": "Matt Hoffman, David M. Blei, Chong Wang, John Paisley", "title": "Stochastic Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop stochastic variational inference, a scalable algorithm for\napproximating posterior distributions. We develop this technique for a large\nclass of probabilistic models and we demonstrate it with two probabilistic\ntopic models, latent Dirichlet allocation and the hierarchical Dirichlet\nprocess topic model. Using stochastic variational inference, we analyze several\nlarge collections of documents: 300K articles from Nature, 1.8M articles from\nThe New York Times, and 3.8M articles from Wikipedia. Stochastic inference can\neasily handle data sets of this size and outperforms traditional variational\ninference, which can only handle a smaller subset. (We also show that the\nBayesian nonparametric topic model outperforms its parametric counterpart.)\nStochastic variational inference lets us apply complex Bayesian models to\nmassive data sets.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 15:23:11 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 15:40:02 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2013 20:23:40 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Hoffman", "Matt", ""], ["Blei", "David M.", ""], ["Wang", "Chong", ""], ["Paisley", "John", ""]]}]