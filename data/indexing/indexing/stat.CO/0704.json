[{"id": "0704.0906", "submitter": "Federico Bassetti", "authors": "Bassetti Federico, Leisen Fabrizio", "title": "Metropolis algorithm and equienergy sampling for two mean field spin\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.CO stat.TH", "license": null, "abstract": "  In this paper we study the Metropolis algorithm in connection with two\nmean--field spin systems, the so called mean--field Ising model and the\nBlume--Emery--Griffiths model. In both this examples the naive choice of\nproposal chain gives rise, for some parameters, to a slowly mixing Metropolis\nchain, that is a chain whose spectral gap decreases exponentially fast (in the\ndimension $N$ of the problem). Here we show how a slight variant in the\nproposal chain can avoid this problem, keeping the mean computational cost\nsimilar to the cost of the usual Metropolis. More precisely we prove that, with\na suitable variant in the proposal, the Metropolis chain has a spectral gap\nwhich decreases polynomially in 1/N. Using some symmetry structure of the\nenergy, the method rests on allowing appropriate jumps within the energy level\nof the starting state.\n", "versions": [{"version": "v1", "created": "Fri, 6 Apr 2007 17:06:39 GMT"}, {"version": "v2", "created": "Tue, 8 May 2007 16:07:29 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Federico", "Bassetti", ""], ["Fabrizio", "Leisen", ""]]}, {"id": "0704.1361", "submitter": "Jack Xin", "authors": "Jie Liu, Jack Xin, Yingyong Qi", "title": "A Dynamic Algorithm for Blind Separation of Convolutive Sound Mixtures", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.NA stat.CO stat.TH", "license": null, "abstract": "  We study an efficient dynamic blind source separation algorithm of\nconvolutive sound mixtures based on updating statistical information in the\nfrequency domain, andminimizing the support of time domain demixing filters by\na weighted least square method. The permutation and scaling indeterminacies of\nseparation, and concatenations of signals in adjacent time frames are resolved\nwith optimization of $l^1 \\times l^\\infty$ norm on cross-correlation\ncoefficients at multiple time lags. The algorithm is a direct method without\niterations, and is adaptive to the environment. Computations on recorded and\nsynthetic mixtures of speech and music signals show excellent performance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Apr 2007 07:39:02 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Liu", "Jie", ""], ["Xin", "Jack", ""], ["Qi", "Yingyong", ""]]}, {"id": "0704.2167", "submitter": "Alexandre Belloni", "authors": "Alexandre Belloni and Victor Chernozhukov", "title": "On the Computational Complexity of MCMC-based Estimators in Large\n  Samples", "comments": "36 pages, 2 figures", "journal-ref": "Ann. Statist. Volume 37, Number 4 (2009), 2011-2055", "doi": "10.1214/08-AOS634", "report-no": null, "categories": "math.ST math.PR stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we examine the implications of the statistical large sample\ntheory for the computational complexity of Bayesian and quasi-Bayesian\nestimation carried out using Metropolis random walks. Our analysis is motivated\nby the Laplace-Bernstein-Von Mises central limit theorem, which states that in\nlarge samples the posterior or quasi-posterior approaches a normal density.\nUsing the conditions required for the central limit theorem to hold, we\nestablish polynomial bounds on the computational complexity of general\nMetropolis random walks methods in large samples. Our analysis covers cases\nwhere the underlying log-likelihood or extremum criterion function is possibly\nnon-concave, discontinuous, and with increasing parameter dimension. However,\nthe central limit theorem restricts the deviations from continuity and\nlog-concavity of the log-likelihood or extremum criterion function in a very\nspecific manner.\n  Under minimal assumptions required for the central limit theorem to hold\nunder the increasing parameter dimension, we show that the Metropolis algorithm\nis theoretically efficient even for the canonical Gaussian walk which is\nstudied in detail. Specifically, we show that the running time of the algorithm\nin large samples is bounded in probability by a polynomial in the parameter\ndimension $d$, and, in particular, is of stochastic order $d^2$ in the leading\ncases after the burn-in period. We then give applications to exponential\nfamilies, curved exponential families, and Z-estimation of increasing\ndimension.\n", "versions": [{"version": "v1", "created": "Tue, 17 Apr 2007 14:48:08 GMT"}, {"version": "v2", "created": "Mon, 4 Aug 2008 13:43:39 GMT"}, {"version": "v3", "created": "Wed, 25 Jan 2012 03:16:04 GMT"}], "update_date": "2012-01-26", "authors_parsed": [["Belloni", "Alexandre", ""], ["Chernozhukov", "Victor", ""]]}]