[{"id": "1012.0073", "submitter": "Richard Barker", "authors": "Richard J. Barker and William A. Link", "title": "Posterior model probabilities computed from model-specific Gibbs output", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible jump Markov chain Monte Carlo (RJMCMC) extends ordinary MCMC\nmethods for use in Bayesian multimodel inference. We show that RJMCMC can be\nimplemented as Gibbs sampling with alternating updates of a model indicator and\na vector-valued \"palette\" of parameters denoted $\\bm \\psi$. Like an artist uses\nthe palette to mix dabs of color for specific needs, we create model-specific\nparameters from the set available in $\\bm \\psi$. This description not only\nremoves some of the mystery of RJMCMC, but also provides a basis for fitting\nmodels one at a time using ordinary MCMC and computing model weights or Bayes\nfactors by post-processing the Monte Carlo output. We illustrate our procedure\nusing several examples.\n", "versions": [{"version": "v1", "created": "Wed, 1 Dec 2010 00:44:09 GMT"}, {"version": "v2", "created": "Thu, 26 May 2011 01:50:19 GMT"}], "update_date": "2011-05-27", "authors_parsed": [["Barker", "Richard J.", ""], ["Link", "William A.", ""]]}, {"id": "1012.0269", "submitter": "Pierre Lafaye de Micheaux", "authors": "C\\'ecile Bordier and Michel Dojat and Pierre Lafaye de Micheaux", "title": "Temporal and Spatial Independent Component Analysis for fMRI data sets\n  embedded in a R package", "comments": "Submitted to JSS", "journal-ref": "Journal of Statistical Software, Vol. 44, Issue 9, Oct 2011", "doi": null, "report-no": null, "categories": "stat.CO physics.med-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For statistical analysis of functional Magnetic Resonance Imaging (fMRI) data\nsets, we propose a data-driven approach based on Independent Component Analysis\n(ICA) implemented in a new version of the AnalyzeFMRI R package. For fMRI data\nsets, spatial dimension being much greater than temporal dimension, spatial ICA\nis the tractable approach generally proposed. However, for some neuroscientific\napplications, temporal independence of source signals can be assumed and\ntemporal ICA becomes then an attracting exploratory technique. In this work, we\nuse a classical linear algebra result ensuring the tractability of temporal\nICA. We report several experiments on synthetic data and real MRI data sets\nthat demonstrate the potential interest of our R package.\n", "versions": [{"version": "v1", "created": "Wed, 1 Dec 2010 18:32:31 GMT"}], "update_date": "2013-07-22", "authors_parsed": [["Bordier", "C\u00e9cile", ""], ["Dojat", "Michel", ""], ["de Micheaux", "Pierre Lafaye", ""]]}, {"id": "1012.1086", "submitter": "Michael McCoy", "authors": "Michael McCoy and Joel Tropp", "title": "Two Proposals for Robust PCA using Semidefinite Programming", "comments": null, "journal-ref": "Electronic Journal of Statistics 5 (2011), 1123--1160", "doi": "10.1214/11-EJS636", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of principal component analysis (PCA) suffers badly in the\npresence of outliers. This paper proposes two novel approaches for robust PCA\nbased on semidefinite programming. The first method, maximum mean absolute\ndeviation rounding (MDR), seeks directions of large spread in the data while\ndamping the effect of outliers. The second method produces a low-leverage\ndecomposition (LLD) of the data that attempts to form a low-rank model for the\ndata by separating out corrupted observations. This paper also presents\nefficient computational methods for solving these SDPs. Numerical experiments\nconfirm the value of these new techniques.\n", "versions": [{"version": "v1", "created": "Mon, 6 Dec 2010 06:56:55 GMT"}, {"version": "v2", "created": "Tue, 7 Dec 2010 02:36:23 GMT"}, {"version": "v3", "created": "Tue, 14 Dec 2010 18:35:32 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["McCoy", "Michael", ""], ["Tropp", "Joel", ""]]}, {"id": "1012.2983", "submitter": "Daniele  Imparato", "authors": "Antonietta Mira, Reza Solgi, Daniele Imparato", "title": "Zero Variance Markov Chain Monte Carlo for Bayesian Estimators", "comments": "26 pages, 4 figures. This is an updated version: the results are the\n  same as the previous one, but presentation is more essential", "journal-ref": "Statistics and Computing, 2012", "doi": "10.1007/s11222-012-9344-6", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interest is in evaluating, by Markov chain Monte Carlo (MCMC) simulation, the\nexpected value of a function with respect to a, possibly unnormalized,\nprobability distribution. A general purpose variance reduction technique for\nthe MCMC estimator, based on the zero-variance principle introduced in the\nphysics literature, is proposed. Conditions for asymptotic unbiasedness of the\nzero-variance estimator are derived. A central limit theorem is also proved\nunder regularity conditions. The potential of the idea is illustrated with real\napplications to probit, logit and GARCH Bayesian models. For all these models,\na central limit theorem and unbiasedness for the zero-variance estimator are\nproved (see the supplementary material available on-line).\n", "versions": [{"version": "v1", "created": "Tue, 14 Dec 2010 10:18:27 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2012 10:55:25 GMT"}], "update_date": "2012-09-19", "authors_parsed": [["Mira", "Antonietta", ""], ["Solgi", "Reza", ""], ["Imparato", "Daniele", ""]]}, {"id": "1012.3768", "submitter": "James M. Flegal", "authors": "James M. Flegal and Radu Herbei", "title": "Exact sampling for intractable probability distributions via a Bernoulli\n  factory", "comments": "28 pages, 2 figures", "journal-ref": "Electronic Journal of Statistics, 2012", "doi": "10.1214/11-EJS663", "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications in the field of statistics require Markov chain Monte Carlo\nmethods. Determining appropriate starting values and run lengths can be both\nanalytically and empirically challenging. A desire to overcome these problems\nhas led to the development of exact, or perfect, sampling algorithms which\nconvert a Markov chain into an algorithm that produces i.i.d. samples from the\nstationary distribution. Unfortunately, very few of these algorithms have been\ndeveloped for the distributions that arise in statistical applications, which\ntypically have uncountable support. Here we study an exact sampling algorithm\nusing a geometrically ergodic Markov chain on a general state space. Our work\nprovides a significant reduction to the number of input draws necessary for the\nBernoulli factory, which enables exact sampling via a rejection sampling\napproach. We illustrate the algorithm on a univariate Metropolis-Hastings\nsampler and a bivariate Gibbs sampler, which provide a proof of concept and\ninsight into hyper-parameter selection. Finally, we illustrate the algorithm on\na Bayesian version of the one-way random effects model with data from a styrene\nexposure study.\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 22:07:03 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2012 05:23:02 GMT"}], "update_date": "2012-03-09", "authors_parsed": [["Flegal", "James M.", ""], ["Herbei", "Radu", ""]]}, {"id": "1012.4411", "submitter": "Alexander Yu. Vlasov", "authors": "Alexander Yu. Vlasov", "title": "Extension of Dirac's chord method to the case of a nonconvex set by use\n  of quasi-probability distributions", "comments": "v4: 13 pages, REVTeX4-1, title changed, close to published version.\n  Copyright (2011) American Institute of Physics. This article may be\n  downloaded for personal use only. Any other use requires prior permission of\n  the author and the American Institute of Physics. The following article\n  appeared in J. Math. Phys. 52, 053516 (2011) and may be found at\n  http://link.aip.org/link/?jmp/52/053516", "journal-ref": "J. Math. Phys. 52, 053516 (2011)", "doi": "10.1063/1.3589958", "report-no": null, "categories": "math-ph math.MP physics.comp-ph stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dirac's chord method may be suitable in different areas of physics for\nthe representation of certain six-dimensional integrals for a convex body using\nthe probability density of the chord length distribution. For a homogeneous\nmodel with a nonconvex body inside a medium with identical properties an\nanalogue of the Dirac's chord method may be obtained, if to use so-called\ngeneralized chord distribution. The function is defined as normalized second\nderivative of the autocorrelation function. For nonconvex bodies this second\nderivative may have negative values and could not be directly related with a\nprobability density. An interpretation of such a function using alternating\nsums of probability densities is considered. Such quasi-probability\ndistributions may be used for Monte Carlo calculations of some integrals for a\nsingle body of arbitrary shape and for systems with two or more objects and\nsuch applications are also discussed in this work.\n", "versions": [{"version": "v1", "created": "Mon, 20 Dec 2010 17:21:21 GMT"}, {"version": "v2", "created": "Tue, 28 Dec 2010 19:37:05 GMT"}, {"version": "v3", "created": "Mon, 10 Jan 2011 15:11:22 GMT"}, {"version": "v4", "created": "Tue, 24 May 2011 15:29:28 GMT"}], "update_date": "2011-05-25", "authors_parsed": [["Vlasov", "Alexander Yu.", ""]]}, {"id": "1012.4726", "submitter": "Rosemary Braun", "authors": "Rosemary Braun and Kenneth Buetow", "title": "Pathways of Distinction Analysis: a new technique for multi-SNP analysis\n  of GWAS data", "comments": "Revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.GN q-bio.MN stat.AP stat.CO", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Genome-wide association studies have become increasingly common due to\nadvances in technology and have permitted the identification of differences in\nsingle nucleotide polymorphism (SNP) alleles that are associated with diseases.\nHowever, while typical GWAS analysis techniques treat markers individually,\ncomplex diseases are unlikely to have a single causative gene. There is thus a\npressing need for multi-SNP analysis methods that can reveal system-level\ndifferences in cases and controls. Here, we present a novel multi-SNP GWAS\nanalysis method called Pathways of Distinction Analysis (PoDA). The method uses\nGWAS data and known pathway-gene and gene-SNP associations to identify pathways\nthat permit, ideally, the distinction of cases from controls. The technique is\nbased upon the hypothesis that if a pathway is related to disease risk, cases\nwill appear more similar to other cases than to controls for the SNPs\nassociated with that pathway. By systematically applying the method to all\npathways of potential interest, we can identify those for which the hypothesis\nholds true, i.e., pathways containing SNPs for which the samples exhibit\ngreater within-class similarity than across classes. Importantly, PoDA improves\non existing single-SNP and SNP-set enrichment analyses in that it does not\nrequire the SNPs in a pathway to exhibit independent main effects. This permits\nPoDA to reveal pathways in which epistatic interactions drives risk. In this\npaper, we detail the PoDA method and apply it to two GWA studies: one of breast\ncancer, and the other of liver cancer. The results obtained strongly suggest\nthat there exist pathway-wide genomic differences that contribute to disease\nsusceptibility. PoDA thus provides an analytical tool that is complementary to\nexisting techniques and has the power to enrich our understanding of disease\ngenomics at the systems-level.\n", "versions": [{"version": "v1", "created": "Tue, 21 Dec 2010 16:50:59 GMT"}, {"version": "v2", "created": "Thu, 17 Mar 2011 22:09:54 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Braun", "Rosemary", ""], ["Buetow", "Kenneth", ""]]}, {"id": "1012.4769", "submitter": "Michael Braun", "authors": "Michael Braun and Andr\\'e Bonfrer", "title": "Scalable Inference of Customer Similarities from Interactions Data using\n  Dirichlet Processes", "comments": null, "journal-ref": "Marketing Science 30:3 513-531 2011", "doi": "10.1287/mksc.1110.0640", "report-no": null, "categories": "stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Under the sociological theory of homophily, people who are similar to one\nanother are more likely to interact with one another. Marketers often have\naccess to data on interactions among customers from which, with homophily as a\nguiding principle, inferences could be made about the underlying similarities.\nHowever, larger networks face a quadratic explosion in the number of potential\ninteractions that need to be modeled. This scalability problem renders\nprobability models of social interactions computationally infeasible for all\nbut the smallest networks. In this paper we develop a probabilistic framework\nfor modeling customer interactions that is both grounded in the theory of\nhomophily, and is flexible enough to account for random variation in who\ninteracts with whom. In particular, we present a novel Bayesian nonparametric\napproach, using Dirichlet processes, to moderate the scalability problems that\nmarketing researchers encounter when working with networked data. We find that\nthis framework is a powerful way to draw insights into latent similarities of\ncustomers, and we discuss how marketers can apply these insights to\nsegmentation and targeting activities.\n", "versions": [{"version": "v1", "created": "Tue, 21 Dec 2010 19:18:49 GMT"}], "update_date": "2011-07-06", "authors_parsed": [["Braun", "Michael", ""], ["Bonfrer", "Andr\u00e9", ""]]}, {"id": "1012.4824", "submitter": "Taufik Abrao", "authors": "Taufik Abr\\~ao, Leonardo D. Oliveira, Bruno A. Angelico and Paul Jean\n  E. Jeszensky", "title": "Input Parameters Optimization in Swarm DS-CDMA Multiuser Detectors", "comments": "21 pages, 15 figures, 4 tables, full paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.CO stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the uplink direct sequence code division multiple access\n(DS-CDMA) multiuser detection problem (MuD) is studied into heuristic\nperspective, named particle swarm optimization (PSO). Regarding different\nsystem improvements for future technologies, such as high-order modulation and\ndiversity exploitation, a complete parameter optimization procedure for the PSO\napplied to MuD problem is provided, which represents the major contribution of\nthis paper. Furthermore, the performance of the PSO-MuD is briefly analyzed via\nMonte-Carlo simulations. Simulation results show that, after convergence, the\nperformance reached by the PSO-MuD is much better than the conventional\ndetector, and somewhat close to the single user bound (SuB). Rayleigh flat\nchannel is initially considered, but the results are further extend to\ndiversity (time and spatial) channels.\n", "versions": [{"version": "v1", "created": "Tue, 21 Dec 2010 22:25:37 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Abr\u00e3o", "Taufik", ""], ["Oliveira", "Leonardo D.", ""], ["Angelico", "Bruno A.", ""], ["Jeszensky", "Paul Jean E.", ""]]}, {"id": "1012.5390", "submitter": "Sumeetpal S Singh", "authors": "Pierre Del Moral, Arnaud Doucet, Sumeetpal Singh", "title": "Forward Smoothing using Sequential Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": "CUED/F-INFENG/TR638 (Cambridge University Engineering Department)", "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential Monte Carlo (SMC) methods are a widely used set of computational\ntools for inference in non-linear non-Gaussian state-space models. We propose a\nnew SMC algorithm to compute the expectation of additive functionals\nrecursively. Essentially, it is an online or forward-only implementation of a\nforward filtering backward smoothing SMC algorithm proposed in Doucet .et .al\n(2000). Compared to the standard path space SMC estimator whose asymptotic\nvariance increases quadratically with time even under favourable mixing\nassumptions, the asymptotic variance of the proposed SMC estimator only\nincreases linearly with time. This forward smoothing procedure allows us to\nimplement on-line maximum likelihood parameter estimation algorithms which do\nnot suffer from the particle path degeneracy problem.\n", "versions": [{"version": "v1", "created": "Fri, 24 Dec 2010 12:01:25 GMT"}], "update_date": "2010-12-27", "authors_parsed": [["Del Moral", "Pierre", ""], ["Doucet", "Arnaud", ""], ["Singh", "Sumeetpal", ""]]}]