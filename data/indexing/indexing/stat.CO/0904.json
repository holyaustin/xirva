[{"id": "0904.0635", "submitter": "Michael Gb Blum", "authors": "Michael Blum (TIMC)", "title": "Approximate Bayesian Computation: a nonparametric perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian Computation is a family of likelihood-free inference\ntechniques that are well-suited to models defined in terms of a stochastic\ngenerating mechanism. In a nutshell, Approximate Bayesian Computation proceeds\nby computing summary statistics s_obs from the data and simulating summary\nstatistics for different values of the parameter theta. The posterior\ndistribution is then approximated by an estimator of the conditional density\ng(theta|s_obs). In this paper, we derive the asymptotic bias and variance of\nthe standard estimators of the posterior distribution which are based on\nrejection sampling and linear adjustment. Additionally, we introduce an\noriginal estimator of the posterior distribution based on quadratic adjustment\nand we show that its bias contains a fewer number of terms than the estimator\nwith linear adjustment. Although we find that the estimators with adjustment\nare not universally superior to the estimator based on rejection sampling, we\nfind that they can achieve better performance when there is a nearly\nhomoscedastic relationship between the summary statistics and the parameter of\ninterest. To make this relationship as homoscedastic as possible, we propose to\nuse transformations of the summary statistics. In different examples borrowed\nfrom the population genetics and epidemiological literature, we show the\npotential of the methods with adjustment and of the transformations of the\nsummary statistics. Supplemental materials containing the details of the proofs\nare available online.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2009 18:52:13 GMT"}, {"version": "v2", "created": "Wed, 6 May 2009 12:08:26 GMT"}, {"version": "v3", "created": "Wed, 13 May 2009 14:08:57 GMT"}, {"version": "v4", "created": "Tue, 8 Sep 2009 07:12:47 GMT"}, {"version": "v5", "created": "Mon, 3 May 2010 19:28:03 GMT"}, {"version": "v6", "created": "Mon, 31 May 2010 09:01:09 GMT"}], "update_date": "2010-07-28", "authors_parsed": [["Blum", "Michael", "", "TIMC"]]}, {"id": "0904.0687", "submitter": "Zhaosong Lu", "authors": "Zhaosong Lu", "title": "Smooth Optimization Approach for Sparse Covariance Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we first study a smooth optimization approach for solving a\nclass of nonsmooth strictly concave maximization problems whose objective\nfunctions admit smooth convex minimization reformulations. In particular, we\napply Nesterov's smooth optimization technique [Y.E. Nesterov, Dokl. Akad. Nauk\nSSSR, 269 (1983), pp. 543--547; Y. E. Nesterov, Math. Programming, 103 (2005),\npp. 127--152] to their dual counterparts that are smooth convex problems. It is\nshown that the resulting approach has ${\\cal O}(1/{\\sqrt{\\epsilon}})$ iteration\ncomplexity for finding an $\\epsilon$-optimal solution to both primal and dual\nproblems. We then discuss the application of this approach to sparse covariance\nselection that is approximately solved as an $l_1$-norm penalized maximum\nlikelihood estimation problem, and also propose a variant of this approach\nwhich has substantially outperformed the latter one in our computational\nexperiments. We finally compare the performance of these approaches with other\nfirst-order methods, namely, Nesterov's ${\\cal O}(1/\\epsilon)$ smooth\napproximation scheme and block-coordinate descent method studied in [A.\nd'Aspremont, O. Banerjee, and L. El Ghaoui, SIAM J. Matrix Anal. Appl., 30\n(2008), pp. 56--66; J. Friedman, T. Hastie, and R. Tibshirani, Biostatistics, 9\n(2008), pp. 432--441] for sparse covariance selection on a set of randomly\ngenerated instances. It shows that our smooth optimization approach\nsubstantially outperforms the first method above, and moreover, its variant\nsubstantially outperforms both methods above.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2009 06:11:13 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Lu", "Zhaosong", ""]]}, {"id": "0904.0688", "submitter": "Zhaosong Lu", "authors": "Zhaosong Lu", "title": "Adaptive First-Order Methods for General Sparse Inverse Covariance\n  Selection", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider estimating sparse inverse covariance of a Gaussian\ngraphical model whose conditional independence is assumed to be partially\nknown. Similarly as in [5], we formulate it as an $l_1$-norm penalized maximum\nlikelihood estimation problem. Further, we propose an algorithm framework, and\ndevelop two first-order methods, that is, the adaptive spectral projected\ngradient (ASPG) method and the adaptive Nesterov's smooth (ANS) method, for\nsolving this estimation problem. Finally, we compare the performance of these\ntwo methods on a set of randomly generated instances. Our computational results\ndemonstrate that both methods are able to solve problems of size at least a\nthousand and number of constraints of nearly a half million within a reasonable\namount of time, and the ASPG method generally outperforms the ANS method.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2009 06:24:01 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Lu", "Zhaosong", ""]]}, {"id": "0904.0691", "submitter": "Zhaosong Lu", "authors": "Zhaosong Lu, Renato D. C. Monteiro, Ming Yuan", "title": "Convex Optimization Methods for Dimension Reduction and Coefficient\n  Estimation in Multivariate Linear Regression", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study convex optimization methods for computing the trace\nnorm regularized least squares estimate in multivariate linear regression. The\nso-called factor estimation and selection (FES) method, recently proposed by\nYuan et al. [22], conducts parameter estimation and factor selection\nsimultaneously and have been shown to enjoy nice properties in both large and\nfinite samples. To compute the estimates, however, can be very challenging in\npractice because of the high dimensionality and the trace norm constraint. In\nthis paper, we explore a variant of Nesterov's smooth method [20] and interior\npoint methods for computing the penalized least squares estimate. The\nperformance of these methods is then compared using a set of randomly generated\ninstances. We show that the variant of Nesterov's smooth method [20] generally\noutperforms the interior point method implemented in SDPT3 version 4.0 (beta)\n[19] substantially . Moreover, the former method is much more memory efficient.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2009 06:34:20 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Lu", "Zhaosong", ""], ["Monteiro", "Renato D. C.", ""], ["Yuan", "Ming", ""]]}, {"id": "0904.0779", "submitter": "Marco Congedo", "authors": "Marco Congedo (GIPSA-lab), Dinh-Tuan Pham (LJK)", "title": "Least-Squares Joint Diagonalization of a matrix set by a congruence\n  transformation", "comments": "2nd Singaporean-French IPAL Symposium, Singapour : Singapour (2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The approximate joint diagonalization (AJD) is an important analytic tool at\nthe base of numerous independent component analysis (ICA) and other blind\nsource separation (BSS) methods, thus finding more and more applications in\nmedical imaging analysis. In this work we present a new AJD algorithm named\nSDIAG (Spheric Diagonalization). It imposes no constraint either on the input\nmatrices or on the joint diagonalizer to be estimated, thus it is very general.\nWhereas it is well grounded on the classical leastsquares criterion, a new\nnormalization reveals a very simple form of the solution matrix. Numerical\nsimulations shown that the algorithm, named SDIAG (spheric diagonalization),\nbehaves well as compared to state-of-the art AJD algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2009 14:22:51 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Congedo", "Marco", "", "GIPSA-lab"], ["Pham", "Dinh-Tuan", "", "LJK"]]}, {"id": "0904.1300", "submitter": "Luca Martino", "authors": "Luca Martino, Joaquin Miguez", "title": "Generalized Rejection Sampling Schemes and Applications in Signal\n  Processing", "comments": null, "journal-ref": "Signal Processing, Volume 90, Issue 11, Pages 2981-2995, 2010", "doi": "10.1016/j.sigpro.2010.04.025", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian methods and their implementations by means of sophisticated Monte\nCarlo techniques, such as Markov chain Monte Carlo (MCMC) and particle filters,\nhave become very popular in signal processing over the last years. However, in\nmany problems of practical interest these techniques demand procedures for\nsampling from probability distributions with non-standard forms, hence we are\noften brought back to the consideration of fundamental simulation algorithms,\nsuch as rejection sampling (RS). Unfortunately, the use of RS techniques\ndemands the calculation of tight upper bounds for the ratio of the target\nprobability density function (pdf) over the proposal density from which\ncandidate samples are drawn. Except for the class of log-concave target pdf's,\nfor which an efficient algorithm exists, there are no general methods to\nanalytically determine this bound, which has to be derived from scratch for\neach specific case. In this paper, we introduce new schemes for (a) obtaining\nupper bounds for likelihood functions and (b) adaptively computing proposal\ndensities that approximate the target pdf closely. The former class of methods\nprovides the tools to easily sample from a posteriori probability distributions\n(that appear very often in signal processing problems) by drawing candidates\nfrom the prior distribution. However, they are even more useful when they are\nexploited to derive the generalized adaptive RS (GARS) algorithm introduced in\nthe second part of the paper. The proposed GARS method yields a sequence of\nproposal densities that converge towards the target pdf and enable a very\nefficient sampling of a broad class of probability distributions, possibly with\nmultiple modes and non-standard forms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2009 10:07:23 GMT"}], "update_date": "2012-05-29", "authors_parsed": [["Martino", "Luca", ""], ["Miguez", "Joaquin", ""]]}, {"id": "0904.2144", "submitter": "Randal Douc", "authors": "Randal Douc, Christian P. Robert", "title": "A vanilla Rao--Blackwellization of Metropolis--Hastings algorithms", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS838 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 1, 261-277", "doi": "10.1214/10-AOS838", "report-no": "IMS-AOS-AOS838", "categories": "stat.CO math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Casella and Robert [Biometrika 83 (1996) 81--94] presented a general\nRao--Blackwellization principle for accept-reject and Metropolis--Hastings\nschemes that leads to significant decreases in the variance of the resulting\nestimators, but at a high cost in computation and storage. Adopting a\ncompletely different perspective, we introduce instead a universal scheme that\nguarantees variance reductions in all Metropolis--Hastings-based estimators\nwhile keeping the computation cost under control. We establish a central limit\ntheorem for the improved estimators and illustrate their performances on toy\nexamples and on a probit model estimation.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2009 15:38:16 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2009 19:23:49 GMT"}, {"version": "v3", "created": "Sat, 24 Oct 2009 03:37:54 GMT"}, {"version": "v4", "created": "Mon, 31 May 2010 05:49:42 GMT"}, {"version": "v5", "created": "Tue, 1 Jun 2010 05:53:36 GMT"}, {"version": "v6", "created": "Tue, 8 Mar 2011 11:14:13 GMT"}], "update_date": "2011-03-09", "authors_parsed": [["Douc", "Randal", ""], ["Robert", "Christian P.", ""]]}, {"id": "0904.2435", "submitter": "Paul Kabaila", "authors": "Paul Kabaila and Khageswor Giri", "title": "Computation of confidence intervals in regression utilizing uncertain\n  prior information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a linear regression model with regression parameter beta\n=(beta_1, ..., beta_p) and independent and identically N(0, sigma^2)distributed\nerrors. Suppose that the parameter of interest is theta = a^T beta where a is a\nspecified vector. Define the parameter tau = c^T beta - t where the vector c\nand the number t are specified and a and c are linearly independent. Also\nsuppose that we have uncertain prior information that tau = 0. Kabaila and Giri\n(2009c) present a new frequentist 1-alpha confidence interval for theta that\nutilizes this prior information. This interval has expected length that (a) is\nrelatively small when the prior information about tau is correct and (b) has a\nmaximum value that is not too large. It coincides with the standard 1-alpha\nconfidence interval (obtained by fitting the full model to the data) when the\ndata strongly contradicts the prior information. At first sight, the\ncomputation of this new confidence interval seems to be infeasible. However, by\nthe use of the various computational devices that are presented in detail in\nthe present paper, this computation becomes feasible and practicable.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2009 06:06:27 GMT"}], "update_date": "2009-04-17", "authors_parsed": [["Kabaila", "Paul", ""], ["Giri", "Khageswor", ""]]}, {"id": "0904.2906", "submitter": "Heng Lian", "authors": "Heng Lian", "title": "Sparse Bayesian Hierarchical Modeling of High-dimensional Clustering\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the most widely used procedures in the analysis of\nmicroarray data, for example with the goal of discovering cancer subtypes based\non observed heterogeneity of genetic marks between different tissues. It is\nwell-known that in such high-dimensional settings, the existence of many noise\nvariables can overwhelm the few signals embedded in the high-dimensional space.\nWe propose a novel Bayesian approach based on Dirichlet process with a sparsity\nprior that simultaneous performs variable selection and clustering, and also\ndiscover variables that only distinguish a subset of the cluster components.\nUnlike previous Bayesian formulations, we use Dirichlet process (DP) for both\nclustering of samples as well as for regularizing the high-dimensional\nmean/variance structure. To solve the computational challenge brought by this\ndouble usage of DP, we propose to make use of a sequential sampling scheme\nembedded within Markov chain Monte Carlo (MCMC) updates to improve the naive\nimplementation of existing algorithms for DP mixture models. Our method is\ndemonstrated on a simulation study and illustrated with the leukemia gene\nexpression dataset.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2009 11:33:01 GMT"}], "update_date": "2009-04-21", "authors_parsed": [["Lian", "Heng", ""]]}, {"id": "0904.3769", "submitter": "Jason Johnson Dr.", "authors": "Jason K. Johnson, Vladimir Y. Chernyak, Michael Chertkov", "title": "Orbit-Product Representation and Correction of Gaussian Belief\n  Propagation", "comments": "8 pages, 3 figures. To appear, ICML '09", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.CO stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new view of Gaussian belief propagation (GaBP) based on a\nrepresentation of the determinant as a product over orbits of a graph. We show\nthat the GaBP determinant estimate captures totally backtracking orbits of the\ngraph and consider how to correct this estimate. We show that the missing\norbits may be grouped into equivalence classes corresponding to backtrackless\norbits and the contribution of each equivalence class is easily determined from\nthe GaBP solution. Furthermore, we demonstrate that this multiplicative\ncorrection factor can be interpreted as the determinant of a backtrackless\nadjacency matrix of the graph with edge weights based on GaBP. Finally, an\nefficient method is proposed to compute a truncated correction factor including\nall backtrackless orbits up to a specified length.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2009 00:25:53 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2009 22:08:58 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2009 00:26:05 GMT"}, {"version": "v4", "created": "Tue, 5 May 2009 01:11:13 GMT"}, {"version": "v5", "created": "Wed, 6 May 2009 00:10:00 GMT"}], "update_date": "2009-05-06", "authors_parsed": [["Johnson", "Jason K.", ""], ["Chernyak", "Vladimir Y.", ""], ["Chertkov", "Michael", ""]]}, {"id": "0904.4891", "submitter": "Robert B. Gramacy", "authors": "Tamara Broderick and Robert B. Gramacy", "title": "Classification and categorical inputs with treed Gaussian process models", "comments": "24 pages (now single spaced), 8 figures, 2 tables, presented at IFCS\n  2009 and accepted at JoC", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing the successes of treed Gaussian process (TGP) models as an\ninterpretable and thrifty model for nonparametric regression, we seek to extend\nthe model to classification. Both treed models and Gaussian processes (GPs)\nhave, separately, enjoyed great success in application to classification\nproblems. An example of the former is Bayesian CART. In the latter, real-valued\nGP output may be utilized for classification via latent variables, which\nprovide classification rules by means of a softmax function. We formulate a\nBayesian model averaging scheme to combine these two models and describe a\nMonte Carlo method for sampling from the full posterior distribution with joint\nproposals for the tree topology and the GP parameters corresponding to latent\nvariables at the leaves. We concentrate on efficient sampling of the latent\nvariables, which is important to obtain good mixing in the expanded parameter\nspace. The tree structure is particularly helpful for this task and also for\ndeveloping an efficient scheme for handling categorical predictors, which\ncommonly arise in classification problems. Our proposed classification TGP\n(CTGP) methodology is illustrated on a collection of synthetic and real data\nsets. We assess performance relative to existing methods and thereby show how\nCTGP is highly flexible, offers tractable inference, produces rules that are\neasy to interpret, and performs well out of sample.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2009 17:20:08 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2010 18:01:28 GMT"}, {"version": "v3", "created": "Sun, 26 Sep 2010 17:42:04 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Broderick", "Tamara", ""], ["Gramacy", "Robert B.", ""]]}]