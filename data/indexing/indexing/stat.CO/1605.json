[{"id": "1605.00230", "submitter": "Leopoldo Catania", "authors": "Leopoldo Catania and Nima Nonejad", "title": "Density Forecasts and the Leverage Effect: Some Evidence from\n  Observation and Parameter-Driven Volatility Models", "comments": "36 pages, 2 figures, 20 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-fin.RM stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The leverage effect refers to the well-established relationship between\nreturns and volatility. When returns fall, volatility increases. We examine the\nrole of the leverage effect with regards to generating density forecasts of\nequity returns using well-known observation and parameter-driven volatility\nmodels. These models differ in their assumptions regarding: The parametric\nspecification, the evolution of the conditional volatility process and how the\nleverage effect is accounted for. The ability of a model to generate accurate\ndensity forecasts when the leverage effect is incorporated or not as well as a\ncomparison between different model-types is carried out using a large number of\nfinancial time-series. We find that, models with the leverage effect generally\ngenerate more accurate density forecasts compared to their no-leverage\ncounterparts. Moreover, we also find that our choice with regards to how to\nmodel the leverage effect and the conditional log-volatility process is\nimportant in generating accurate density forecasts\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 10:16:29 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 18:52:46 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Catania", "Leopoldo", ""], ["Nonejad", "Nima", ""]]}, {"id": "1605.00278", "submitter": "Hans-Christian Ruiz Dipl-Phys", "authors": "H.-Ch. Ruiz and H. J. Kappen", "title": "Particle Smoothing for Hidden Diffusion Processes: Adaptive Path\n  Integral Smoother", "comments": "16 pages, 13 figures", "journal-ref": null, "doi": "10.1109/TSP.2017.2686340", "report-no": null, "categories": "cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle smoothing methods are used for inference of stochastic processes\nbased on noisy observations. Typically, the estimation of the marginal\nposterior distribution given all observations is cumbersome and computational\nintensive. In this paper, we propose a simple algorithm based on path integral\ncontrol theory to estimate the smoothing distribution of continuous-time\ndiffusion processes with partial observations. In particular, we use an\nadaptive importance sampling method to improve the effective sampling size of\nthe posterior over processes given the observations and the reliability of the\nestimation of the marginals. This is achieved by estimating a feedback\ncontroller to sample efficiently from the joint smoothing distributions. We\ncompare the results with estimations obtained from the standard Forward\nFilter/Backward Simulator for two diffusion processes of different complexity.\nWe show that the proposed method gives more reliable estimations than the\nstandard FFBSi when the smoothing distribution is poorly represented by the\nfilter distribution.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 16:56:49 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 15:15:00 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Ruiz", "H. -Ch.", ""], ["Kappen", "H. J.", ""]]}, {"id": "1605.00361", "submitter": "Adrien Hardy", "authors": "R\\'emi Bardenet, Adrien Hardy", "title": "Monte Carlo with Determinantal Point Processes", "comments": "58 pages, 6 figures. To appear in Annals of Applied Probability", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.CA stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that repulsive random variables can yield Monte Carlo methods with\nfaster convergence rates than the typical $N^{-1/2}$, where $N$ is the number\nof integrand evaluations. More precisely, we propose stochastic numerical\nquadratures involving determinantal point processes associated with\nmultivariate orthogonal polynomials, and we obtain root mean square errors that\ndecrease as $N^{-(1+1/d)/2}$, where $d$ is the dimension of the ambient space.\nFirst, we prove a central limit theorem (CLT) for the linear statistics of a\nclass of determinantal point processes, when the reference measure is a product\nmeasure supported on a hypercube, which satisfies the Nevai-class regularity\ncondition, a result which may be of independent interest. Next, we introduce a\nMonte Carlo method based on these determinantal point processes, and prove a\nCLT with explicit limiting variance for the quadrature error, when the\nreference measure satisfies a stronger regularity condition. As a corollary, by\ntaking a specific reference measure and using a construction similar to\nimportance sampling, we obtain a general Monte Carlo method, which applies to\nany measure with continuously derivable density. Loosely speaking, our method\ncan be interpreted as a stochastic counterpart to Gaussian quadrature, which,\nat the price of some convergence rate, is easily generalizable to any dimension\nand has a more explicit error term.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 06:24:06 GMT"}, {"version": "v2", "created": "Sat, 15 Jun 2019 11:20:01 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Bardenet", "R\u00e9mi", ""], ["Hardy", "Adrien", ""]]}, {"id": "1605.00860", "submitter": "Joshua Pritikin", "authors": "Joshua N. Pritikin", "title": "A Computational Note on the Application of the Supplemented EM Algorithm\n  to Item Response Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The EM algorithm is a method for finding the maximum likelihood estimate of a\nmodel in the presence of missing data. Unfortunately, EM does not produce a\nparameter covariance matrix for standard errors. Supplemented EM (SEM; Meng &\nRubin, 1991) is one method for obtaining the parameter covariance matrix. SEM\nis implemented in both open-source (e.g., Chalmers, 2012; Pritikin, Hunter, &\nBoker, 2015) and commercial (e.g., Cai, Thissen, & du Toit, 2011) item response\nmodel estimation software. However, the original formulation of SEM did not\nadequately account for the limitations of IEEE 754 floating-point. Agile-SEM, a\nnovel refinement of SEM, is proposed and compared against the original\nalgorithm and a recent refinement (Tian, Cai, Thissen, & Xin, 2013) in a\nvariety of item response model simulation studies. By controlling for the\nnumerical noise intensity on a per-parameter basis, Agile-SEM demonstrated the\nbest convergence properties, accuracy, and efficiency while, at the same time,\nrequiring fewer tuning parameters. Complete source code is made freely\navailable. The potential generalization of Agile-SEM to other EM application\nbesides item response models is left as future work.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 12:19:55 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Pritikin", "Joshua N.", ""]]}, {"id": "1605.01421", "submitter": "Stefan Widgren", "authors": "Stefan Widgren, Pavol Bauer, Robin Eriksson, Stefan Engblom", "title": "SimInf: An R package for Data-driven Stochastic Disease Spread\n  Simulations", "comments": "The manual has been updated to the latest version of SimInf (v6.0.0).\n  41 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the R package SimInf which provides an efficient and very flexible\nframework to conduct data-driven epidemiological modeling in realistic large\nscale disease spread simulations. The framework integrates infection dynamics\nin subpopulations as continuous-time Markov chains using the Gillespie\nstochastic simulation algorithm and incorporates available data such as births,\ndeaths and movements as scheduled events at predefined time-points. Using C\ncode for the numerical solvers and OpenMP to divide work over multiple\nprocessors ensures high performance when simulating a sample outcome. One of\nour design goal was to make SimInf extendable and enable usage of the numerical\nsolvers from other R extension packages in order to facilitate complex\nepidemiological research. In this paper, we provide a technical description of\nthe framework and demonstrate its use on some basic examples. We also discuss\nhow to specify and extend the framework with user-defined models.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 20:16:20 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 19:04:00 GMT"}, {"version": "v3", "created": "Thu, 3 May 2018 16:56:46 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Widgren", "Stefan", ""], ["Bauer", "Pavol", ""], ["Eriksson", "Robin", ""], ["Engblom", "Stefan", ""]]}, {"id": "1605.01521", "submitter": "Tsvetan Asamov", "authors": "Tsvetan Asamov, Daniel F. Salas and Warren B. Powell", "title": "SDDP vs. ADP: The Effect of Dimensionality in Multistage Stochastic\n  Optimization for Grid Level Energy Storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been widespread interest in the use of grid-level storage to handle\nthe variability from increasing penetrations of wind and solar energy. This\nproblem setting requires optimizing energy storage and release decisions for\nanywhere from a half-dozen, to potentially hundreds of storage devices spread\naround the grid as new technologies evolve. We approach this problem using two\ncompeting algorithmic strategies. The first, developed within the stochastic\nprogramming literature, is stochastic dual dynamic programming (SDDP) which\nuses Benders decomposition to create a multidimensional value function\napproximations, which have been widely used to manage hydro reservoirs. The\nsecond approach, which has evolved using the language of approximate dynamic\nprogramming, uses separable, piecewise linear value function approximations, a\nmethod which has been successfully applied to high-dimensional fleet management\nproblems. This paper brings these two approaches together using a common\nnotational system, and contrasts the algorithmic strategies (which are both a\nform of approximate dynamic programming) used by each approach. The methods are\nthen subjected to rigorous testing using the context of optimizing grid level\nstorage.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 07:37:14 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Asamov", "Tsvetan", ""], ["Salas", "Daniel F.", ""], ["Powell", "Warren B.", ""]]}, {"id": "1605.01931", "submitter": "Luca Scrucca", "authors": "Luca Scrucca", "title": "On some extensions to GA package: hybrid optimisation, parallelisation\n  and islands evolution", "comments": null, "journal-ref": "The R Journal, 2017, 9/1, pp. 187--206", "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic algorithms are stochastic iterative algorithms in which a population\nof individuals evolve by emulating the process of biological evolution and\nnatural selection. The R package GA provides a collection of general purpose\nfunctions for optimisation using genetic algorithms. This paper describes some\nenhancements recently introduced in version 3 of the package. In particular,\nhybrid GAs have been implemented by including the option to perform local\nsearches during the evolution. This allows to combine the power of genetic\nalgorithms with the speed of a local optimiser. Another major improvement is\nthe provision of facilities for parallel computing. Parallelisation has been\nimplemented using both the master-slave approach and the islands evolution\nmodel. Several examples of usage are presented, with both real-world data\nexamples and benchmark functions, showing that often high-quality solutions can\nbe obtained more efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 13:22:01 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Scrucca", "Luca", ""]]}, {"id": "1605.02113", "submitter": "Radu V. Craiu", "authors": "Reihaneh Entezari, Radu V. Craiu, and Jeffrey S. Rosenthal", "title": "Likelihood Inflating Sampling Algorithm", "comments": "32 pages, 3 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Chain Monte Carlo (MCMC) sampling from a posterior distribution\ncorresponding to a massive data set can be computationally prohibitive since\nproducing one sample requires a number of operations that is linear in the data\nsize. In this paper, we introduce a new communication-free parallel method, the\nLikelihood Inflating Sampling Algorithm (LISA), that significantly reduces\ncomputational costs by randomly splitting the dataset into smaller subsets and\nrunning MCMC methods independently in parallel on each subset using different\nprocessors. Each processor will be used to run an MCMC chain that samples\nsub-posterior distributions which are defined using an \"inflated\" likelihood\nfunction. We develop a strategy for combining the draws from different\nsub-posteriors to study the full posterior of the Bayesian Additive Regression\nTrees (BART) model. The performance of the method is tested using both\nsimulated and real data.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 22:43:15 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 06:19:11 GMT"}, {"version": "v3", "created": "Fri, 30 Jun 2017 17:57:32 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Entezari", "Reihaneh", ""], ["Craiu", "Radu V.", ""], ["Rosenthal", "Jeffrey S.", ""]]}, {"id": "1605.02446", "submitter": "Simon Wood", "authors": "Simon N. Wood", "title": "P-splines with derivative based penalties and tensor product smoothing\n  of unevenly distributed data", "comments": null, "journal-ref": null, "doi": "10.1007/s11222-016-9666-x", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The P-splines of Eilers and Marx (1996) combine a B-spline basis with a\ndiscrete quadratic penalty on the basis coefficients, to produce a reduced rank\nspline like smoother. P-splines have three properties that make them very\npopular as reduced rank smoothers: i) the basis and the penalty are sparse,\nenabling efficient computation, especially for Bayesian stochastic simulation;\nii) it is possible to flexibly `mix-and-match' the order of B-spline basis and\npenalty, rather than the order of penalty controlling the order of the basis as\nin spline smoothing; iii) it is very easy to set up the B-spline basis\nfunctions and penalties. The discrete penalties are somewhat less interpretable\nin terms of function shape than the traditional derivative based spline\npenalties, but tend towards penalties proportional to traditional spline\npenalties in the limit of large basis size. However part of the point of\nP-splines is not to use a large basis size. In addition the spline basis\nfunctions arise from solving functional optimization problems involving\nderivative based penalties, so moving to discrete penalties for smoothing may\nnot always be desirable. The purpose of this note is to point out that the\nthree properties of basis-penalty sparsity, mix-and-match penalization and ease\nof setup are readily obtainable with B-splines subject to derivative based\npenalization. The penalty setup typically requires a few lines of code, rather\nthan the two lines typically required for P-splines, but this one off\ndisadvantage seems to be the only one associated with using derivative based\npenalties. As an example application, it is shown how basis-penalty sparsity\nenables efficient computation with tensor product smoothers of scattered data.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 07:26:11 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Wood", "Simon N.", ""]]}, {"id": "1605.03824", "submitter": "Esa Ollila", "authors": "Esa Ollila", "title": "Direction of arrival estimation using robust complex Lasso", "comments": "Paper has appeared in the Proceedings of the 10th European Conference\n  on Antennas and Propagation (EuCAP'2016), Davos, Switzerland, April 10-15,\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lasso (Least Absolute Shrinkage and Selection Operator) has been a\npopular technique for simultaneous linear regression estimation and variable\nselection. In this paper, we propose a new novel approach for robust Lasso that\nfollows the spirit of M-estimation. We define $M$-Lasso estimates of regression\nand scale as solutions to generalized zero subgradient equations. Another\nunique feature of this paper is that we consider complex-valued measurements\nand regression parameters, which requires careful mathematical characterization\nof the problem. An explicit and efficient algorithm for computing the $M$-Lasso\nsolution is proposed that has comparable computational complexity as\nstate-of-the-art algorithm for computing the Lasso solution. Usefulness of the\n$M$-Lasso method is illustrated for direction-of-arrival (DoA) estimation with\nsensor arrays in a single snapshot case.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 14:19:52 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["Ollila", "Esa", ""]]}, {"id": "1605.03992", "submitter": "Brian Segal", "authors": "Brian Segal, Thomas Braun, Michael Elliott, Hui Jiang", "title": "Fast Approximation of Small p-values in Permutation Tests by\n  Partitioning the Permutations", "comments": "64 pages, 34 figures, 12 tables including appendices (22 pages, 8\n  figures, 1 table not including appendices)", "journal-ref": "Biometrics. 74 (2018) 196-206", "doi": "10.1111/biom.12731", "report-no": null, "categories": "stat.CO stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers in genetics and other life sciences commonly use permutation\ntests to evaluate differences between groups. Permutation tests have desirable\nproperties, including exactness if data are exchangeable, and are applicable\neven when the distribution of the test statistic is analytically intractable.\nHowever, permutation tests can be computationally intensive. We propose both an\nasymptotic approximation and a resampling algorithm for quickly estimating\nsmall permutation p-values (e.g. $<10^{-6}$) for the difference and ratio of\nmeans in two-sample tests. Our methods are based on the distribution of test\nstatistics within and across partitions of the permutations, which we define.\nIn this article, we present our methods and demonstrate their use through\nsimulations and an application to cancer genomic data. Through simulations, we\nfind that our resampling algorithm is more computationally efficient than\nanother leading alternative, particularly for extremely small p-values (e.g.\n$<10^{-30}$). Through application to cancer genomic data, we find that our\nmethods can successfully identify up- and down-regulated genes. While we focus\non the difference and ratio of means, we speculate that our approaches may work\nin other settings.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 21:13:03 GMT"}, {"version": "v2", "created": "Sat, 11 Mar 2017 22:46:32 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Segal", "Brian", ""], ["Braun", "Thomas", ""], ["Elliott", "Michael", ""], ["Jiang", "Hui", ""]]}, {"id": "1605.04029", "submitter": "Cheng Li", "authors": "Cheng Li, Sanvesh Srivastava, and David B. Dunson", "title": "Simple, Scalable and Accurate Posterior Interval Estimation", "comments": "50 pages, 6 figures, 11 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a lack of simple and scalable algorithms for uncertainty\nquantification. Bayesian methods quantify uncertainty through posterior and\npredictive distributions, but it is difficult to rapidly estimate summaries of\nthese distributions, such as quantiles and intervals. Variational Bayes\napproximations are widely used, but may badly underestimate posterior\ncovariance. Typically, the focus of Bayesian inference is on point and interval\nestimates for one-dimensional functionals of interest. In small scale problems,\nMarkov chain Monte Carlo algorithms remain the gold standard, but such\nalgorithms face major problems in scaling up to big data. Various modifications\nhave been proposed based on parallelization and approximations based on\nsubsamples, but such approaches are either highly complex or lack theoretical\nsupport and/or good performance outside of narrow settings. We propose a very\nsimple and general posterior interval estimation algorithm, which is based on\nrunning Markov chain Monte Carlo in parallel for subsets of the data and\naveraging quantiles estimated from each subset. We provide strong theoretical\nguarantees and illustrate performance in several applications.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 02:01:08 GMT"}, {"version": "v2", "created": "Sat, 24 Dec 2016 02:24:41 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Li", "Cheng", ""], ["Srivastava", "Sanvesh", ""], ["Dunson", "David B.", ""]]}, {"id": "1605.04281", "submitter": "Sarah Brockhaus", "authors": "Sarah Brockhaus, Andreas Fuest, Andreas Mayr and Sonja Greven", "title": "Signal Regression Models for Location, Scale and Shape with an\n  Application to Stock Returns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss scalar-on-function regression models where all parameters of the\nassumed response distribution can be modeled depending on covariates. We thus\ncombine signal regression models with generalized additive models for location,\nscale and shape (GAMLSS). We compare two fundamentally different methods for\nestimation, a gradient boosting and a penalized likelihood based approach, and\naddress practically important points like identifiability and model choice.\nEstimation by a component-wise gradient boosting algorithm allows for high\ndimensional data settings and variable selection. Estimation by a penalized\nlikelihood based approach has the advantage of directly provided statistical\ninference. The motivating application is a time series of stock returns where\nit is of interest to model both the expectation and the variance depending on\nlagged response values and functional liquidity curves.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 18:50:11 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Brockhaus", "Sarah", ""], ["Fuest", "Andreas", ""], ["Mayr", "Andreas", ""], ["Greven", "Sonja", ""]]}, {"id": "1605.04963", "submitter": "Ajay Jasra", "authors": "Ajay Jasra, Kengo Kamatani, Prince Prepah Osei, Yan Zhou", "title": "Multilevel Particle Filters: Normalizing Constant Estimation", "comments": "arXiv admin note: substantial text overlap with arXiv:1510.04977", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we introduce two new estimates of the normalizing constant\n(or marginal likelihood) for partially observed diffusion (POD) processes, with\ndiscrete observations. One estimate is biased but non-negative and the other is\nunbiased but not almost surely non-negative. Our method uses the multilevel\nparticle filter of Jasra et al (2015). We show that, under assumptions, for\nEuler discretized PODs and a given $\\varepsilon>0$. in order to obtain a mean\nsquare error (MSE) of $\\mathcal{O}(\\varepsilon^2)$ one requires a work of\n$\\mathcal{O}(\\varepsilon^{-2.5})$ for our new estimates versus a standard\nparticle filter that requires a work of $\\mathcal{O}(\\varepsilon^{-3})$. Our\ntheoretical results are supported by numerical simulations.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 22:10:09 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Jasra", "Ajay", ""], ["Kamatani", "Kengo", ""], ["Osei", "Prince Prepah", ""], ["Zhou", "Yan", ""]]}, {"id": "1605.05278", "submitter": "Adam Sykulski Dr", "authors": "Adam M. Sykulski and Donald B. Percival", "title": "Exact Simulation of Noncircular or Improper Complex-Valued Stationary\n  Gaussian Processes using Circulant Embedding", "comments": "Link to published version:\n  http://ieeexplore.ieee.org/document/7738840/", "journal-ref": "2016 IEEE 26th International Workshop on Machine Learning for\n  Signal Processing (MLSP)", "doi": "10.1109/MLSP.2016.7738840", "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides an algorithm for simulating improper (or noncircular)\ncomplex-valued stationary Gaussian processes. The technique utilizes recently\ndeveloped methods for multivariate Gaussian processes from the circulant\nembedding literature. The method can be performed in $\\mathcal{O}(n\\log_2 n)$\noperations, where $n$ is the length of the desired sequence. The method is\nexact, except when eigenvalues of prescribed circulant matrices are negative.\nWe evaluate the performance of the algorithm empirically, and provide a\npractical example where the method is guaranteed to be exact for all $n$, with\nan improper fractional Gaussian noise process.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 18:22:20 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 17:06:15 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Sykulski", "Adam M.", ""], ["Percival", "Donald B.", ""]]}, {"id": "1605.05334", "submitter": "Jonathan Heckman", "authors": "Jonathan J. Heckman, Jeffrey G. Bernstein, Ben Vigoda", "title": "MCMC with Strings and Branes: The Suburban Algorithm (Extended Version)", "comments": "v2: 55 pages, 13 figures, references and clarifications added.\n  Published version. This article is an extended version of \"MCMC with Strings\n  and Branes: The Suburban Algorithm\"", "journal-ref": null, "doi": "10.1142/S0217751X17501330", "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn hep-th stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the physics of strings and branes, we develop a class of Markov\nchain Monte Carlo (MCMC) algorithms involving extended objects. Starting from a\ncollection of parallel Metropolis-Hastings (MH) samplers, we place them on an\nauxiliary grid, and couple them together via nearest neighbor interactions.\nThis leads to a class of \"suburban samplers\" (i.e., spread out Metropolis).\nCoupling the samplers in this way modifies the mixing rate and speed of\nconvergence for the Markov chain, and can in many cases allow a sampler to more\neasily overcome free energy barriers in a target distribution. We test these\ngeneral theoretical considerations by performing several numerical experiments.\nFor suburban samplers with a fluctuating grid topology, performance is strongly\ncorrelated with the average number of neighbors. Increasing the average number\nof neighbors above zero initially leads to an increase in performance, though\nthere is a critical connectivity with effective dimension d_eff ~ 1, above\nwhich \"groupthink\" takes over, and the performance of the sampler declines.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 20:00:06 GMT"}, {"version": "v2", "created": "Fri, 8 Sep 2017 12:55:17 GMT"}], "update_date": "2017-09-13", "authors_parsed": [["Heckman", "Jonathan J.", ""], ["Bernstein", "Jeffrey G.", ""], ["Vigoda", "Ben", ""]]}, {"id": "1605.05397", "submitter": "Geoff Boeing", "authors": "Geoff Boeing and Paul Waddell", "title": "New Insights into Rental Housing Markets across the United States: Web\n  Scraping and Analyzing Craigslist Rental Listings", "comments": "20 pages, 9 figures, Journal of Planning Education and Research.\n  2016. Online first", "journal-ref": null, "doi": "10.1177/0739456X16664789", "report-no": null, "categories": "stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current sources of data on rental housing - such as the census or commercial\ndatabases that focus on large apartment complexes - do not reflect recent\nmarket activity or the full scope of the U.S. rental market. To address this\ngap, we collected, cleaned, analyzed, mapped, and visualized 11 million\nCraigslist rental housing listings. The data reveal fine-grained spatial and\ntemporal patterns within and across metropolitan housing markets in the U.S. We\nfind some metropolitan areas have only single-digit percentages of listings\nbelow fair market rent. Nontraditional sources of volunteered geographic\ninformation offer planners real-time, local-scale estimates of rent and housing\ncharacteristics currently lacking in alternative sources, such as census data.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 23:29:58 GMT"}, {"version": "v2", "created": "Sat, 18 Jun 2016 00:02:15 GMT"}, {"version": "v3", "created": "Sat, 25 Jun 2016 03:31:20 GMT"}, {"version": "v4", "created": "Wed, 24 Aug 2016 06:09:52 GMT"}], "update_date": "2016-08-25", "authors_parsed": [["Boeing", "Geoff", ""], ["Waddell", "Paul", ""]]}, {"id": "1605.05429", "submitter": "John Snyder", "authors": "Patrick McDermott, John Snyder, Rebecca Willison", "title": "Methods for Bayesian Variable Selection with Binary Response Data using\n  the EM Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional Bayesian variable selection problems are often solved using\ncomputationally expensive Markov Chain Montle Carlo (MCMC) techniques.\nRecently, a Bayesian variable selection technique was developed for continuous\ndata using the EM algorithm called EMVS. We extend the EMVS method to binary\ndata by proposing both a logistic and probit extension. To preserve the\ncomputational speed of EMVS we also implemented the Stochastic Dual Coordinate\nDescent (SDCA) algorithm. Further, we conduct two extensive simulation studies\nto show the computational speed of both methods. These simulation studies\nreveal the power of both methods to quickly identify the correct sparse model.\nWhen these EMVS methods are compared to Stochastic Search Variable Selection\n(SSVS), the EMVS methods surpass SSVS both in terms of computational speed and\ncorrectly identifying significant variables. Finally, we illustrate the\neffectiveness of both methods on two well-known gene expression datasets. Our\nresults mirror the results of previous examinations of these datasets with far\nless computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 04:01:05 GMT"}], "update_date": "2016-05-19", "authors_parsed": [["McDermott", "Patrick", ""], ["Snyder", "John", ""], ["Willison", "Rebecca", ""]]}, {"id": "1605.05441", "submitter": "Richard Norton", "authors": "Richard A. Norton and Colin Fox", "title": "Metropolis-Hastings algorithms with autoregressive proposals, and a few\n  examples", "comments": "58 pages. Electronics Technical Reports No. 2016-1, ISSN 1172-496X,\n  May 2016. arXiv admin note: substantial text overlap with arXiv:1501.03150", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse computational efficiency of Metropolis-Hastings algorithms with\nstochastic AR(1) process proposals. These proposals include, as a subclass,\ndiscretized Langevin diffusion (e.g. MALA) and discretized Hamiltonian dynamics\n(e.g. HMC).\n  We derive expressions for the expected acceptance rate and expected jump size\nfor MCMC methods with general stochastic AR(1) process proposals for the case\nwhere the target distribution is absolutely continuous with respect to a\nGaussian and the covariance of the Gaussian is allowed to have off-diagonal\nterms. This allows us to extend what is known about several MCMC methods as\nwell as determining the efficiency of new MCMC methods of this type. In the\nspecial case of Hybrid Monte Carlo, we can determine the optimal integration\ntime and the effect of the choice of mass matrix.\n  By including the effect of Metropolis-Hastings we also extend results by Fox\nand Parker, who used matrix splitting techniques to analyse the performance and\nimprove efficiency of stochastic AR(1) processes for sampling from Gaussian\ndistributions.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 05:08:48 GMT"}, {"version": "v2", "created": "Thu, 19 May 2016 23:08:45 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Norton", "Richard A.", ""], ["Fox", "Colin", ""]]}, {"id": "1605.05454", "submitter": "Takashi Goda", "authors": "Takashi Goda", "title": "Computing the variance of a conditional expectation via non-nested Monte\n  Carlo", "comments": null, "journal-ref": "Operations Research Letters, Volume 45, Issue 1, 63-67, 2017", "doi": "10.1016/j.orl.2016.12.002", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing the variance of a conditional expectation has often been of\nimportance in uncertainty quantification. Sun et al. has introduced an unbiased\nnested Monte Carlo estimator, which they call $1\\frac{1}{2}$-level simulation\nsince the optimal inner-level sample size is bounded as the computational\nbudget increases. In this letter we construct unbiased non-nested Monte Carlo\nestimators based on the so-called pick-freeze scheme due to Sobol'. An\nextension of our approach to compute higher order moments of a conditional\nexpectation is also discussed.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 06:36:23 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 05:00:34 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Goda", "Takashi", ""]]}, {"id": "1605.05537", "submitter": "Jean-Michel Marin", "authors": "Louis Raynal, Jean-Michel Marin, Pierre Pudlo, Mathieu Ribatet,\n  Christian P. Robert and Arnaud Estoup", "title": "ABC random forests for Bayesian parameter inference", "comments": "Main text: 24 pages, 6 figures Supplementary Information: 14 pages, 5\n  figures", "journal-ref": null, "doi": "10.24072/pci.evolbiol.100036", "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This preprint has been reviewed and recommended by Peer Community In\nEvolutionary Biology (http://dx.doi.org/10.24072/pci.evolbiol.100036).\nApproximate Bayesian computation (ABC) has grown into a standard methodology\nthat manages Bayesian inference for models associated with intractable\nlikelihood functions. Most ABC implementations require the preliminary\nselection of a vector of informative statistics summarizing raw data.\nFurthermore, in almost all existing implementations, the tolerance level that\nseparates acceptance from rejection of simulated parameter values needs to be\ncalibrated. We propose to conduct likelihood-free Bayesian inferences about\nparameters with no prior selection of the relevant components of the summary\nstatistics and bypassing the derivation of the associated tolerance level. The\napproach relies on the random forest methodology of Breiman (2001) applied in a\n(non parametric) regression setting. We advocate the derivation of a new random\nforest for each component of the parameter vector of interest. When compared\nwith earlier ABC solutions, this method offers significant gains in terms of\nrobustness to the choice of the summary statistics, does not depend on any type\nof tolerance level, and is a good trade-off in term of quality of point\nestimator precision and credible interval estimations for a given computing\ntime. We illustrate the performance of our methodological proposal and compare\nit with earlier ABC methods on a Normal toy example and a population genetics\nexample dealing with human population evolution. All methods designed here have\nbeen incorporated in the R package abcrf (version 1.7) available on CRAN.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 12:04:38 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 16:28:19 GMT"}, {"version": "v3", "created": "Tue, 4 Jul 2017 14:36:45 GMT"}, {"version": "v4", "created": "Tue, 14 Nov 2017 15:15:23 GMT"}, {"version": "v5", "created": "Fri, 2 Nov 2018 14:17:46 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Raynal", "Louis", ""], ["Marin", "Jean-Michel", ""], ["Pudlo", "Pierre", ""], ["Ribatet", "Mathieu", ""], ["Robert", "Christian P.", ""], ["Estoup", "Arnaud", ""]]}, {"id": "1605.05622", "submitter": "Linda S. L. Tan", "authors": "Linda S. L. Tan and David J. Nott", "title": "Gaussian variational approximation with sparse precision matrices", "comments": "18 pages, 9 figures", "journal-ref": "Statistics and Computing 28 (2018) 259-275", "doi": "10.1007/s11222-017-9729-7", "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning a Gaussian variational approximation to\nthe posterior distribution for a high-dimensional parameter, where we impose\nsparsity in the precision matrix to reflect appropriate conditional\nindependence structure in the model. Incorporating sparsity in the precision\nmatrix allows the Gaussian variational distribution to be both flexible and\nparsimonious, and the sparsity is achieved through parameterization in terms of\nthe Cholesky factor. Efficient stochastic gradient methods which make\nappropriate use of gradient information for the target distribution are\ndeveloped for the optimization. We consider alternative estimators of the\nstochastic gradients which have lower variation and are more stable. Our\napproach is illustrated using generalized linear mixed models and state space\nmodels for time series.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 15:38:16 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2016 05:52:36 GMT"}, {"version": "v3", "created": "Thu, 13 Apr 2017 03:29:26 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Tan", "Linda S. L.", ""], ["Nott", "David J.", ""]]}, {"id": "1605.05671", "submitter": "Natesh Pillai", "authors": "Anirban Bhattacharya, David B. Dunson, Debdeep Pati, Natesh S. Pillai", "title": "Sub-optimality of some continuous shrinkage priors", "comments": "Some of the results were announced in this earlier paper\n  arXiv:1212.6088. To appear in Stochastic Processes and Applications, special\n  issue in memoriam Prof. Evarist Gine", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-component mixture priors provide a traditional way to induce sparsity in\nhigh-dimensional Bayes models. However, several aspects of such a prior,\nincluding computational complexities in high-dimensions, interpretation of\nexact zeros and non-sparse posterior summaries under standard loss functions,\nhas motivated an amazing variety of continuous shrinkage priors, which can be\nexpressed as global-local scale mixtures of Gaussians. Interestingly, we\ndemonstrate that many commonly used shrinkage priors, including the Bayesian\nLasso, do not have adequate posterior concentration in high-dimensional\nsettings.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 17:54:39 GMT"}], "update_date": "2016-05-19", "authors_parsed": [["Bhattacharya", "Anirban", ""], ["Dunson", "David B.", ""], ["Pati", "Debdeep", ""], ["Pillai", "Natesh S.", ""]]}, {"id": "1605.05798", "submitter": "James Johndrow", "authors": "James E. Johndrow, Aaron Smith, Natesh Pillai, David B. Dunson", "title": "MCMC for Imbalanced Categorical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.CC stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern applications collect highly imbalanced categorical data, with\nsome categories relatively rare. Bayesian hierarchical models combat data\nsparsity by borrowing information, while also quantifying uncertainty. However,\nposterior computation presents a fundamental barrier to routine use; a single\nclass of algorithms does not work well in all settings and practitioners waste\ntime trying different types of MCMC approaches. This article was motivated by\nan application to quantitative advertising in which we encountered extremely\npoor computational performance for common data augmentation MCMC algorithms but\nobtained excellent performance for adaptive Metropolis. To obtain a deeper\nunderstanding of this behavior, we give strong theory results on computational\ncomplexity in an infinitely imbalanced asymptotic regime. Our results show\ncomputational complexity of Metropolis is logarithmic in sample size, while\ndata augmentation is polynomial in sample size. The root cause of poor\nperformance of data augmentation is a discrepancy between the rates at which\nthe target density and MCMC step sizes concentrate. In general, MCMC algorithms\nthat have a similar discrepancy will fail in large samples - a result with\nsubstantial practical impact.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 02:45:46 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 15:06:27 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Johndrow", "James E.", ""], ["Smith", "Aaron", ""], ["Pillai", "Natesh", ""], ["Dunson", "David B.", ""]]}, {"id": "1605.06122", "submitter": "Jonathan Heckman", "authors": "Jonathan J. Heckman, Jeffrey G. Bernstein, Ben Vigoda", "title": "MCMC with Strings and Branes: The Suburban Algorithm", "comments": "6 + 4 pages, 11 figures. This article is a condensed version of\n  arXiv:1605.05334", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cond-mat.dis-nn hep-th physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the physics of strings and branes, we introduce a general suite\nof Markov chain Monte Carlo (MCMC) \"suburban samplers\" (i.e., spread out\nMetropolis). The suburban algorithm involves an ensemble of statistical agents\nconnected together by a random network. Performance of the collective in\nreaching a fast and accurate inference depends primarily on the average number\nof nearest neighbor connections. Increasing the average number of neighbors\nabove zero initially leads to an increase in performance, though there is a\ncritical connectivity with effective dimension d_eff ~ 1, above which\n\"groupthink\" takes over, and the performance of the sampler declines.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 20:00:14 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Heckman", "Jonathan J.", ""], ["Bernstein", "Jeffrey G.", ""], ["Vigoda", "Ben", ""]]}, {"id": "1605.06293", "submitter": "J. Martin van Zyl", "authors": "J. Martin van Zyl", "title": "The performance of univariate goodness-of-fit tests for normality based\n  on the empirical characteristic function in large samples", "comments": "5 figures, 5 tables", "journal-ref": "Communications in Statistics: Simulation and Computation, 2018,\n  47(4), pp. 1146-1156", "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An empirical power comparison is made between two tests based on the\nempirical characteristic function and some of the best performing tests for\nnormality. A simple normality test based on the empirical characteristic\nfunction calculated in a single point is shown to outperform the more\ncomplicated Epps-Pulley test and the frequentist tests included in the study in\nlarge samples.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 11:25:15 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2016 12:05:41 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["van Zyl", "J. Martin", ""]]}, {"id": "1605.06311", "submitter": "Karl Granstr\\\"om", "authors": "Karl Granstrom, Maryam Fatemi, Lennart Svensson", "title": "Poisson multi-Bernoulli conjugate prior for multiple extended object\n  filtering", "comments": null, "journal-ref": null, "doi": "10.1109/TAES.2019.2920220", "report-no": null, "categories": "stat.CO cs.CV cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Poisson multi-Bernoulli mixture (PMBM) conjugate prior\nfor multiple extended object filtering. A Poisson point process is used to\ndescribe the existence of yet undetected targets, while a multi-Bernoulli\nmixture describes the distribution of the targets that have been detected. The\nprediction and update equations are presented for the standard transition\ndensity and measurement likelihood. Both the prediction and the update preserve\nthe PMBM form of the density, and in this sense the PMBM density is a conjugate\nprior. However, the unknown data associations lead to an intractably large\nnumber of terms in the PMBM density, and approximations are necessary for\ntractability. A gamma Gaussian inverse Wishart implementation is presented,\nalong with methods to handle the data association problem. A simulation study\nshows that the extended target PMBM filter performs well in comparison to the\nextended target d-GLMB and LMB filters. An experiment with Lidar data\nillustrates the benefit of tracking both detected and undetected targets.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 12:05:59 GMT"}, {"version": "v2", "created": "Wed, 3 Aug 2016 10:00:45 GMT"}, {"version": "v3", "created": "Mon, 24 Apr 2017 08:35:10 GMT"}, {"version": "v4", "created": "Wed, 12 Dec 2018 18:58:25 GMT"}, {"version": "v5", "created": "Mon, 8 Apr 2019 08:14:17 GMT"}, {"version": "v6", "created": "Fri, 6 Dec 2019 09:12:45 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Granstrom", "Karl", ""], ["Fatemi", "Maryam", ""], ["Svensson", "Lennart", ""]]}, {"id": "1605.06376", "submitter": "George Papamakarios", "authors": "George Papamakarios, Iain Murray", "title": "Fast $\\epsilon$-free Inference of Simulation Models with Bayesian\n  Conditional Density Estimation", "comments": "Appeared at NIPS 2016. Fixed typo in Eq (37)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many statistical models can be simulated forwards but have intractable\nlikelihoods. Approximate Bayesian Computation (ABC) methods are used to infer\nproperties of these models from data. Traditionally these methods approximate\nthe posterior over parameters by conditioning on data being inside an\n$\\epsilon$-ball around the observed data, which is only correct in the limit\n$\\epsilon\\!\\rightarrow\\!0$. Monte Carlo methods can then draw samples from the\napproximate posterior to approximate predictions or error bars on parameters.\nThese algorithms critically slow down as $\\epsilon\\!\\rightarrow\\!0$, and in\npractice draw samples from a broader distribution than the posterior. We\npropose a new approach to likelihood-free inference based on Bayesian\nconditional density estimation. Preliminary inferences based on limited\nsimulation data are used to guide later simulations. In some cases, learning an\naccurate parametric representation of the entire true posterior distribution\nrequires fewer model simulations than Monte Carlo ABC methods need to produce a\nsingle sample from an approximate posterior.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 14:34:38 GMT"}, {"version": "v2", "created": "Mon, 13 Jun 2016 14:55:38 GMT"}, {"version": "v3", "created": "Mon, 24 Oct 2016 17:11:50 GMT"}, {"version": "v4", "created": "Mon, 2 Apr 2018 16:05:09 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Papamakarios", "George", ""], ["Murray", "Iain", ""]]}, {"id": "1605.06420", "submitter": "Jonathan Huggins", "authors": "Jonathan H. Huggins, James Zou", "title": "Quantifying the accuracy of approximate diffusions and Markov chains", "comments": "In Proceedings of the 19th International Conference on Artificial\n  Intelligence and Statistics (AISTATS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chains and diffusion processes are indispensable tools in machine\nlearning and statistics that are used for inference, sampling, and modeling.\nWith the growth of large-scale datasets, the computational cost associated with\nsimulating these stochastic processes can be considerable, and many algorithms\nhave been proposed to approximate the underlying Markov chain or diffusion. A\nfundamental question is how the computational savings trade off against the\nstatistical error incurred due to approximations. This paper develops general\nresults that address this question. We bound the Wasserstein distance between\nthe equilibrium distributions of two diffusions as a function of their mixing\nrates and the deviation in their drifts. We show that this error bound is tight\nin simple Gaussian settings. Our general result on continuous diffusions can be\ndiscretized to provide insights into the computational-statistical trade-off of\nMarkov chains. As an illustration, we apply our framework to derive\nfinite-sample error bounds of approximate unadjusted Langevin dynamics. We\ncharacterize computation-constrained settings where, by using fast-to-compute\napproximate gradients in the Langevin dynamics, we obtain more accurate samples\ncompared to using the exact gradients. Finally, as an additional application of\nour approach, we quantify the accuracy of approximate zig-zag sampling. Our\ntheoretical analyses are supported by simulation experiments.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 16:17:22 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 17:30:56 GMT"}, {"version": "v3", "created": "Wed, 1 Mar 2017 15:06:21 GMT"}, {"version": "v4", "created": "Wed, 30 Aug 2017 14:50:01 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Huggins", "Jonathan H.", ""], ["Zou", "James", ""]]}, {"id": "1605.06423", "submitter": "Jonathan Huggins", "authors": "Jonathan H. Huggins, Trevor Campbell, Tamara Broderick", "title": "Coresets for Scalable Bayesian Logistic Regression", "comments": "In Proceedings of Advances in Neural Information Processing Systems\n  (NIPS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of Bayesian methods in large-scale data settings is attractive\nbecause of the rich hierarchical models, uncertainty quantification, and prior\nspecification they provide. Standard Bayesian inference algorithms are\ncomputationally expensive, however, making their direct application to large\ndatasets difficult or infeasible. Recent work on scaling Bayesian inference has\nfocused on modifying the underlying algorithms to, for example, use only a\nrandom data subsample at each iteration. We leverage the insight that data is\noften redundant to instead obtain a weighted subset of the data (called a\ncoreset) that is much smaller than the original dataset. We can then use this\nsmall coreset in any number of existing posterior inference algorithms without\nmodification. In this paper, we develop an efficient coreset construction\nalgorithm for Bayesian logistic regression models. We provide theoretical\nguarantees on the size and approximation quality of the coreset -- both for\nfixed, known datasets, and in expectation for a wide class of data generative\nmodels. Crucially, the proposed approach also permits efficient construction of\nthe coreset in both streaming and parallel settings, with minimal additional\neffort. We demonstrate the efficacy of our approach on a number of synthetic\nand real-world datasets, and find that, in practice, the size of the coreset is\nindependent of the original dataset size. Furthermore, constructing the coreset\ntakes a negligible amount of time compared to that required to run MCMC on it.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 16:26:45 GMT"}, {"version": "v2", "created": "Thu, 27 Oct 2016 14:12:19 GMT"}, {"version": "v3", "created": "Mon, 6 Feb 2017 15:11:30 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Huggins", "Jonathan H.", ""], ["Campbell", "Trevor", ""], ["Broderick", "Tamara", ""]]}, {"id": "1605.06585", "submitter": "Arabin Kumar Dey", "authors": "Arabin Kumar Dey, Abhilash Jha and Sanku Dey", "title": "Bayesian Analysis of Modified Weibull distribution under progressively\n  censored competing risk model", "comments": "17 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study bayesian analysis of Modified Weibull distribution\nunder progressively censored competing risk model. This study is made for\nprogressively censored data. We use deterministic scan Gibbs sampling combined\nwith slice sampling to generate from the posterior distribution. Posterior\ndistribution is formed by taking prior distribution as reference prior. A real\nlife data analysis is shown for illustrative purpose.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 04:42:44 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Dey", "Arabin Kumar", ""], ["Jha", "Abhilash", ""], ["Dey", "Sanku", ""]]}, {"id": "1605.06718", "submitter": "Adam Sykulski Dr", "authors": "Adam M. Sykulski, Sofia C. Olhede, Arthur P. Guillaumin, Jonathan M.\n  Lilly, Jeffrey J. Early", "title": "The De-Biased Whittle Likelihood", "comments": "To appear shortly in Biometrika. Full published version includes\n  extensions of theory to non-Gaussian processes, and new simulation examples\n  with an AR(4) and non-Gaussian process", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Whittle likelihood is a widely used and computationally efficient\npseudo-likelihood. However, it is known to produce biased parameter estimates\nfor large classes of models. We propose a method for de-biasing Whittle\nestimates for second-order stationary stochastic processes. The de-biased\nWhittle likelihood can be computed in the same $\\mathcal{O}(n\\log n)$\noperations as the standard approach. We demonstrate the superior performance of\nthe method in simulation studies and in application to a large-scale\noceanographic dataset, where in both cases the de-biased approach reduces bias\nby up to two orders of magnitude, achieving estimates that are close to exact\nmaximum likelihood, at a fraction of the computational cost. We prove that the\nmethod yields estimates that are consistent at an optimal convergence rate of\n$n^{-1/2}$, under weaker assumptions than standard theory, where we do not\nrequire that the power spectral density is continuous in frequency. We describe\nhow the method can be easily combined with standard methods of bias reduction,\nsuch as tapering and differencing, to further reduce bias in parameter\nestimates.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 00:47:52 GMT"}, {"version": "v2", "created": "Wed, 22 Nov 2017 23:38:15 GMT"}, {"version": "v3", "created": "Wed, 12 Sep 2018 15:39:43 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Sykulski", "Adam M.", ""], ["Olhede", "Sofia C.", ""], ["Guillaumin", "Arthur P.", ""], ["Lilly", "Jonathan M.", ""], ["Early", "Jeffrey J.", ""]]}, {"id": "1605.07072", "submitter": "Christian Mueller", "authors": "Christian L. M\\\"uller, Richard Bonneau, Zachary Kurtz", "title": "Generalized Stability Approach for Regularized Graphical Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.MN stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting regularization parameters in penalized high-dimensional graphical\nmodels in a principled, data-driven, and computationally efficient manner\ncontinues to be one of the key challenges in high-dimensional statistics. We\npresent substantial computational gains and conceptual generalizations of the\nStability Approach to Regularization Selection (StARS), a state-of-the-art\ngraphical model selection scheme. Using properties of the Poisson-Binomial\ndistribution and convex non-asymptotic distributional modeling we propose lower\nand upper bounds on the StARS graph regularization path which results in\ngreatly reduced computational cost without compromising regularization\nselection. We also generalize the StARS criterion from single edge to induced\nsubgraph (graphlet) stability. We show that simultaneously requiring edge and\ngraphlet stability leads to superior graph recovery performance independent of\ngraph topology. These novel insights render Gaussian graphical model selection\na routine task on standard multi-core computers.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 16:08:46 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["M\u00fcller", "Christian L.", ""], ["Bonneau", "Richard", ""], ["Kurtz", "Zachary", ""]]}, {"id": "1605.07604", "submitter": "Alp Kucukelbir", "authors": "Alp Kucukelbir, David M. Blei", "title": "Posterior Dispersion Indices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic modeling is cyclical: we specify a model, infer its posterior,\nand evaluate its performance. Evaluation drives the cycle, as we revise our\nmodel based on how it performs. This requires a metric. Traditionally,\npredictive accuracy prevails. Yet, predictive accuracy does not tell the whole\nstory. We propose to evaluate a model through posterior dispersion. The idea is\nto analyze how each datapoint fares in relation to posterior uncertainty around\nthe hidden structure. We propose a family of posterior dispersion indices (PDI)\nthat capture this idea. A PDI identifies rich patterns of model mismatch in\nthree real data examples: voting preferences, supermarket shopping, and\npopulation genetics.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 19:58:02 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Kucukelbir", "Alp", ""], ["Blei", "David M.", ""]]}, {"id": "1605.07811", "submitter": "Jon Cockayne", "authors": "Jon Cockayne, Chris Oates, Tim Sullivan, Mark Girolami", "title": "Probabilistic Numerical Methods for Partial Differential Equations and\n  Bayesian Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.NA math.NA math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a probabilistic numerical method for solution of partial\ndifferential equations (PDEs) and studies application of that method to\nPDE-constrained inverse problems. This approach enables the solution of\nchallenging inverse problems whilst accounting, in a statistically principled\nway, for the impact of discretisation error due to numerical solution of the\nPDE. In particular, the approach confers robustness to failure of the numerical\nPDE solver, with statistical inferences driven to be more conservative in the\npresence of substantial discretisation error. Going further, the problem of\nchoosing a PDE solver is cast as a problem in the Bayesian design of\nexperiments, where the aim is to minimise the impact of solver error on\nstatistical inferences; here the challenge of non-linear PDEs is also\nconsidered. The method is applied to parameter inference problems in which\ndiscretisation error in non-negligible and must be accounted for in order to\nreach conclusions that are statistically valid.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 10:22:19 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 08:55:10 GMT"}, {"version": "v3", "created": "Tue, 11 Jul 2017 15:22:34 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Cockayne", "Jon", ""], ["Oates", "Chris", ""], ["Sullivan", "Tim", ""], ["Girolami", "Mark", ""]]}, {"id": "1605.07826", "submitter": "Matthew Graham", "authors": "Matthew M. Graham and Amos J. Storkey", "title": "Asymptotically exact inference in differentiable generative models", "comments": "14 pages, 5 figures. Accepted for AISTATS 2017, camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many generative models can be expressed as a differentiable function of\nrandom inputs drawn from some simple probability density. This framework\nincludes both deep generative architectures such as Variational Autoencoders\nand a large class of procedurally defined simulator models. We present a method\nfor performing efficient MCMC inference in such models when conditioning on\nobservations of the model output. For some models this offers an asymptotically\nexact inference method where Approximate Bayesian Computation might otherwise\nbe employed. We use the intuition that inference corresponds to integrating a\ndensity across the manifold corresponding to the set of inputs consistent with\nthe observed outputs. This motivates the use of a constrained variant of\nHamiltonian Monte Carlo which leverages the smooth geometry of the manifold to\ncoherently move between inputs exactly consistent with observations. We\nvalidate the method by performing inference tasks in a diverse set of models.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 11:10:36 GMT"}, {"version": "v2", "created": "Tue, 12 Jul 2016 20:39:35 GMT"}, {"version": "v3", "created": "Wed, 12 Oct 2016 21:31:22 GMT"}, {"version": "v4", "created": "Thu, 2 Mar 2017 22:07:33 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Graham", "Matthew M.", ""], ["Storkey", "Amos J.", ""]]}, {"id": "1605.07924", "submitter": "Theodore  Kypraios", "authors": "Jessica E. Stockdale, Theodore Kypraios, Philip D. O'Neill", "title": "Modelling and Bayesian analysis of the Abakaliki Smallpox Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Abakaliki smallpox data have appeared numerous times in the\nepidemic modelling literature, but in almost all cases only a specific subset\nof the data is considered. There is one previous analysis of the full data set,\nbut this relies on approximation methods to derive a likelihood. The data\nthemselves continue to be of interest due to concerns about the possible\nre-emergence of smallpox as a bioterrorism weapon. We present the first full\nBayesian analysis using data-augmentation Markov chain Monte Carlo methods\nwhich avoid the need for likelihood approximations. Results include estimates\nof basic model parameters as well as reproduction numbers and the likely path\nof infection. Model assessment is carried out using simulation-based methods.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 15:11:25 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Stockdale", "Jessica E.", ""], ["Kypraios", "Theodore", ""], ["O'Neill", "Philip D.", ""]]}, {"id": "1605.08122", "submitter": "Natesh Pillai", "authors": "Natesh S. Pillai, Aaron Smith", "title": "On the Mixing Time of Kac's Walk and Other High-Dimensional Gibbs\n  Samplers with Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the total variation mixing time of Kac's random walk on the\nspecial orthogonal group $\\mathrm{SO}(n)$ has been a long-standing open\nproblem. In this paper, we construct a novel non-Markovian coupling for\nbounding this mixing time. The analysis of our coupling entails controlling the\nsmallest singular value of a certain random matrix with highly dependent\nentries. The dependence of the entries in our matrix makes it not-amenable to\nexisting techniques in random matrix theory. To circumvent this difficulty, we\nextend some recent bounds on the smallest singular values of matrices with\nindependent entries to our setting. These bounds imply that the mixing time of\nKac's walk on the group $\\mathrm{SO}(n)$ is between $C_{1} n^{2}$ and $C_{2}\nn^{4} \\log(n)$ for some explicit constants $0 < C_{1}, C_{2} < \\infty$,\nsubstantially improving on the bound of $O(n^{5} \\log(n)^{2})$ by Jiang. Our\nmethods may also be applied to other high dimensional Gibbs samplers with\nconstraints and thus are of independent interest. In addition to giving\nanalytical bounds on the mixing time, our approach allows us to compute\nrigorous estimates of the mixing time by simulating the eigenvalues of a random\nmatrix.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 02:09:23 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Pillai", "Natesh S.", ""], ["Smith", "Aaron", ""]]}, {"id": "1605.08576", "submitter": "Christopher Nemeth", "authors": "Christopher Nemeth and Chris Sherlock", "title": "Merging MCMC Subposteriors through Gaussian-Process Approximations", "comments": "Accepted to Bayesian Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chain Monte Carlo (MCMC) algorithms have become powerful tools for\nBayesian inference. However, they do not scale well to large-data problems.\nDivide-and-conquer strategies, which split the data into batches and, for each\nbatch, run independent MCMC algorithms targeting the corresponding\nsubposterior, can spread the computational burden across a number of separate\nworkers. The challenge with such strategies is in recombining the subposteriors\nto approximate the full posterior. By creating a Gaussian-process approximation\nfor each log-subposterior density we create a tractable approximation for the\nfull posterior. This approximation is exploited through three methodologies:\nfirstly a Hamiltonian Monte Carlo algorithm targeting the expectation of the\nposterior density provides a sample from an approximation to the posterior;\nsecondly, evaluating the true posterior at the sampled points leads to an\nimportance sampler that, asymptotically, targets the true posterior\nexpectations; finally, an alternative importance sampler uses the full\nGaussian-process distribution of the approximation to the log-posterior density\nto re-weight any initial sample and provide both an estimate of the posterior\nexpectation and a measure of the uncertainty in it.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 10:51:48 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 14:35:44 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Nemeth", "Christopher", ""], ["Sherlock", "Chris", ""]]}, {"id": "1605.08732", "submitter": "Yair Heller", "authors": "Yair Heller, Ruth Heller", "title": "Computing the Bergsma Dassios sign-covariance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bergsma and Dassios (2014) introduced an independence measure which is zero\nif and only if two random variables are independent. This measure can be\nnaively calculated in $O(n^4)$. Weihs et al. (2015) showed that it can be\ncalculated in $O(n^2 \\log n)$. In this note we will show that using the methods\ndescribed in Heller et al. (2016), the measure can easily be calculated in only\n$O(n^2)$.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2016 18:07:10 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Heller", "Yair", ""], ["Heller", "Ruth", ""]]}, {"id": "1605.08978", "submitter": "Bruno Sudret", "authors": "M. Moustapha and B. Sudret and J.-M. Bourinet and B. Guillaume", "title": "Quantile-based optimization under uncertainties using adaptive Kriging\n  surrogate models", "comments": null, "journal-ref": null, "doi": null, "report-no": "RSUQ-2016-005", "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainties are inherent to real-world systems. Taking them into account is\ncrucial in industrial design problems and this might be achieved through\nreliability-based design optimization (RBDO) techniques. In this paper, we\npropose a quantile-based approach to solve RBDO problems. We first transform\nthe safety constraints usually formulated as admissible probabilities of\nfailure into constraints on quantiles of the performance criteria. In this\nformulation, the quantile level controls the degree of conservatism of the\ndesign. Starting with the premise that industrial applications often involve\nhigh-fidelity and time-consuming computational models, the proposed approach\nmakes use of Kriging surrogate models (a.k.a. Gaussian process modeling).\nThanks to the Kriging variance (a measure of the local accuracy of the\nsurrogate), we derive a procedure with two stages of enrichment of the design\nof computer experiments (DoE) used to construct the surrogate model. The first\nstage globally reduces the Kriging epistemic uncertainty and adds points in the\nvicinity of the limit-state surfaces describing the system performance to be\nattained. The second stage locally checks, and if necessary, improves the\naccuracy of the quantiles estimated along the optimization iterations.\nApplications to three analytical examples and to the optimal design of a car\nbody subsystem (minimal mass under mechanical safety constraints) show the\naccuracy and the remarkable efficiency brought by the proposed procedure.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 08:44:14 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Moustapha", "M.", ""], ["Sudret", "B.", ""], ["Bourinet", "J. -M.", ""], ["Guillaume", "B.", ""]]}, {"id": "1605.09009", "submitter": "Bruno Sudret", "authors": "K. Konakli and B. Sudret", "title": "Global sensitivity analysis using low-rank tensor approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": "RSUQ-2016-004", "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of global sensitivity analysis, the Sobol' indices constitute\na powerful tool for assessing the relative significance of the uncertain input\nparameters of a model. We herein introduce a novel approach for evaluating\nthese indices at low computational cost, by post-processing the coefficients of\npolynomial meta-models belonging to the class of low-rank tensor\napproximations. Meta-models of this class can be particularly efficient in\nrepresenting responses of high-dimensional models, because the number of\nunknowns in their general functional form grows only linearly with the input\ndimension. The proposed approach is validated in example applications, where\nthe Sobol' indices derived from the meta-model coefficients are compared to\nreference indices, the latter obtained by exact analytical solutions or\nMonte-Carlo simulation with extremely large samples. Moreover, low-rank tensor\napproximations are confronted to the popular polynomial chaos expansion\nmeta-models in case studies that involve analytical rank-one functions and\nfinite-element models pertinent to structural mechanics and heat conduction. In\nthe examined applications, indices based on the novel approach tend to converge\nfaster to the reference solution with increasing size of the experimental\ndesign used to build the meta-model.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 14:36:53 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Konakli", "K.", ""], ["Sudret", "B.", ""]]}, {"id": "1605.09445", "submitter": "Mark Huber", "authors": "Mark Huber", "title": "An estimator for Poisson means whose relative error distribution is\n  known", "comments": "10 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose that $X_1,X_2,\\ldots$ are a stream of independent, identically\ndistributed Poisson random variables with mean $\\mu$. This work presents a new\nestimate $\\mu_k$ for $\\mu$ with the property that the distribution of the\nrelative error in the estimate ($(\\hat \\mu_k/\\mu) - 1$) is known, and does not\ndepend on $\\mu$ in any way. This enables the construction of simple exact\nconfidence intervals for the estimate, as well as a means of obtaining fast\napproximation algorithms for high dimensional integration using TPA. The new\nestimate requires a random number of Poisson draws, and so is best suited to\nMonte Carlo applications. As an example of such an application, the method is\napplied to obtain an exact confidence interval for the normalizing constant of\nthe Ising model.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 23:11:18 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Huber", "Mark", ""]]}, {"id": "1605.09454", "submitter": "Guillaume Basse", "authors": "Guillaume W. Basse, Natesh S. Pillai and Aaron Smith", "title": "Parallel Markov Chain Monte Carlo via Spectral Clustering", "comments": "Appeared in Proceedings of the 19th International Conference on\n  Artificial Intelligence and Statistics (AISTATS) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As it has become common to use many computer cores in routine applications,\nfinding good ways to parallelize popular algorithms has become increasingly\nimportant. In this paper, we present a parallelization scheme for Markov chain\nMonte Carlo (MCMC) methods based on spectral clustering of the underlying state\nspace, generalizing earlier work on parallelization of MCMC methods by state\nspace partitioning. We show empirically that this approach speeds up MCMC\nsampling for multimodal distributions and that it can be usefully applied in\ngreater generality than several related algorithms. Our algorithm converges\nunder reasonable conditions to an `optimal' MCMC algorithm. We also show that\nour approach can be asymptotically far more efficient than naive\nparallelization, even in situations such as completely flat target\ndistributions where no unique optimal algorithm exists. Finally, we combine\ntheoretical and empirical bounds to provide practical guidance on the choice of\ntuning parameters.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 00:40:09 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Basse", "Guillaume W.", ""], ["Pillai", "Natesh S.", ""], ["Smith", "Aaron", ""]]}, {"id": "1605.09466", "submitter": "Robert B. Gramacy", "authors": "Victor Picheny, Robert B. Gramacy, Stefan M. Wild, Sebastien Le\n  Digabel", "title": "Bayesian optimization under mixed constraints with a slack-variable\n  augmented Lagrangian", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An augmented Lagrangian (AL) can convert a constrained optimization problem\ninto a sequence of simpler (e.g., unconstrained) problems, which are then\nusually solved with local solvers. Recently, surrogate-based Bayesian\noptimization (BO) sub-solvers have been successfully deployed in the AL\nframework for a more global search in the presence of inequality constraints;\nhowever, a drawback was that expected improvement (EI) evaluations relied on\nMonte Carlo. Here we introduce an alternative slack variable AL, and show that\nin this formulation the EI may be evaluated with library routines. The slack\nvariables furthermore facilitate equality as well as inequality constraints,\nand mixtures thereof. We show how our new slack \"ALBO\" compares favorably to\nthe original. Its superiority over conventional alternatives is reinforced on\nseveral mixed constraint examples.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 02:14:18 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Picheny", "Victor", ""], ["Gramacy", "Robert B.", ""], ["Wild", "Stefan M.", ""], ["Digabel", "Sebastien Le", ""]]}, {"id": "1605.09503", "submitter": "Pritam Ranjan", "authors": "Pritam Ranjan, Mark Thomas, Holger Teismann, Sujay Mukhoti", "title": "Inverse problem for time-series valued computer model via scalarization", "comments": "23 pages (submitted to OJS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For an expensive to evaluate computer simulator, even the estimate of the\noverall surface can be a challenging problem. In this paper, we focus on the\nestimation of the inverse solution, i.e., to find the set(s) of input\ncombinations of the simulator that generates (or gives good approximation of) a\npre-determined simulator output. Ranjan et al. (2008) proposed an expected\nimprovement criterion under a sequential design framework for the inverse\nproblem with a scalar valued simulator. In this paper, we focus on the inverse\nproblem for a time-series valued simulator. We have used a few simulated and\ntwo real examples for performance comparison.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2016 06:00:24 GMT"}, {"version": "v2", "created": "Sat, 4 Jun 2016 06:08:23 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Ranjan", "Pritam", ""], ["Thomas", "Mark", ""], ["Teismann", "Holger", ""], ["Mukhoti", "Sujay", ""]]}]