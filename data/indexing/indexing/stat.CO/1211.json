[{"id": "1211.0032", "submitter": "Kushal  Dey", "authors": "Bikram Karmakar and Kumaresh Dhara and Kushal Kumar Dey and Analabha\n  Basu and Anil Ghosh", "title": "Test for the statistical significance of a treatment effect in the\n  presence of hidden sub-populations", "comments": "This paper has been presented at the 'Contemporary Issues and\n  Applications of Statistics' conference held at Indian Statistical Institute,\n  Kolkata", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For testing the statistical significance of a treatment effect, we usually\ncompare between two parts of a population, one is exposed to the treatment, and\nthe other is not exposed to it. Standard parametric and nonparametric\ntwo-sample tests are often used for this comparison. But direct applications of\nthese tests can yield misleading results, especially when the population has\nsome hidden sub-populations, and the impact of this sub-population difference\non the study variables dominates the treatment effect. This problem becomes\nmore evident if these subpopulations have widely different proportions of\nrepresentatives in the samples taken from these two parts, which are often\nreferred to as the treatment group and the control group. In this article, we\nmake an attempt to overcome this problem. Our propose methods use suitable\nclustering algorithms to find the hidden sub-populations and then eliminate the\nsub-population effect by using suitable transformations. Standard two-sample\ntests, when they are applied on the transformed data, yield better results.\nSome simulated and real data sets are analyzed to show the utility of the\nproposed methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 21:22:28 GMT"}], "update_date": "2012-11-02", "authors_parsed": [["Karmakar", "Bikram", ""], ["Dhara", "Kumaresh", ""], ["Dey", "Kushal Kumar", ""], ["Basu", "Analabha", ""], ["Ghosh", "Anil", ""]]}, {"id": "1211.0056", "submitter": "Zhaosong Lu", "authors": "Zhaosong Lu", "title": "Iterative Hard Thresholding Methods for $l_0$ Regularized Convex Cone\n  Programming", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.NA stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider $l_0$ regularized convex cone programming problems.\nIn particular, we first propose an iterative hard thresholding (IHT) method and\nits variant for solving $l_0$ regularized box constrained convex programming.\nWe show that the sequence generated by these methods converges to a local\nminimizer. Also, we establish the iteration complexity of the IHT method for\nfinding an $\\epsilon$-local-optimal solution. We then propose a method for\nsolving $l_0$ regularized convex cone programming by applying the IHT method to\nits quadratic penalty relaxation and establish its iteration complexity for\nfinding an $\\epsilon$-approximate local minimizer. Finally, we propose a\nvariant of this method in which the associated penalty parameter is dynamically\nupdated, and show that every accumulation point is a local minimizer of the\nproblem.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 23:47:04 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2012 04:04:35 GMT"}], "update_date": "2012-11-05", "authors_parsed": [["Lu", "Zhaosong", ""]]}, {"id": "1211.0158", "submitter": "Piyush Tagade", "authors": "Piyush Tagade and Han-Lim Choi", "title": "A Generalized Polynomial Chaos-Based Method for Efficient Bayesian\n  Calibration of Uncertain Computational Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the Bayesian calibration of dynamic models with\nparametric and structural uncertainties, in particular where the uncertain\nparameters are unknown/poorly known spatio-temporally varying subsystem models.\nIndependent stationary Gaussian processes with uncertain hyper-parameters\ndescribe uncertainties of the model structure and parameters while\nKarhunnen-Loeve expansion is adopted to spectrally represent these Gaussian\nprocesses. The Karhunnen-Loeve expansion of a prior Gaussian process is\nprojected on a generalized Polynomial Chaos basis, whereas intrusive Galerkin\nprojection is utilized to calculate the associated coefficients of the\nsimulator output. Bayesian inference is used to update the prior probability\ndistribution of the generalized Polynomial Chaos basis, which along with the\nchaos expansion coefficients represent the posterior probability distribution.\nParameters of the posterior distribution are identified that quantify\ncredibility of the simulator model. The proposed method is demonstrated for\ncalibration of a simulator of quasi-one-dimensional flow through a divergent\nnozzle.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 12:18:40 GMT"}], "update_date": "2012-11-02", "authors_parsed": [["Tagade", "Piyush", ""], ["Choi", "Han-Lim", ""]]}, {"id": "1211.0160", "submitter": "Piyush Tagade", "authors": "Piyush Tagade and Han-Lim Choi", "title": "A Dynamic Bi-orthogonal Field Equation Approach for Efficient Bayesian\n  Calibration of Large-Scale Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.PR math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel computationally efficient dynamic\nbi-orthogonality based approach for calibration of a computer simulator with\nhigh dimensional parametric and model structure uncertainty. The proposed\nmethod is based on a decomposition of the solution into mean and a random field\nusing a generic Karhunnen-Loeve expansion. The random field is represented as a\nconvolution of separable Hilbert spaces in stochastic and spacial dimensions\nthat are spectrally represented using respective orthogonal bases. In\nparticular, the present paper investigates generalized polynomial chaos bases\nfor stochastic dimension and eigenfunction bases for spacial dimension. Dynamic\northogonality is used to derive closed form equations for the time evolution of\nmean, spacial and the stochastic fields. The resultant system of equations\nconsists of a partial differential equation (PDE) that define dynamic evolution\nof the mean, a set of PDEs to define the time evolution of eigenfunction bases,\nwhile a set of ordinary differential equations (ODEs) define dynamics of the\nstochastic field. This system of dynamic evolution equations efficiently\npropagates the prior parametric uncertainty to the system response. The\nresulting bi-orthogonal expansion of the system response is used to reformulate\nthe Bayesian inference for efficient exploration of the posterior distribution.\nEfficacy of the proposed method is investigated for calibration of a 2D\ntransient diffusion simulator with uncertain source location and diffusivity.\nComputational efficiency of the method is demonstrated against a Monte Carlo\nmethod and a generalized polynomial chaos approach.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 12:24:58 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2012 20:43:20 GMT"}], "update_date": "2012-11-14", "authors_parsed": [["Tagade", "Piyush", ""], ["Choi", "Han-Lim", ""]]}, {"id": "1211.0174", "submitter": "Aki Vehtari", "authors": "Jaakko Riihim\\\"aki and Aki Vehtari", "title": "Laplace approximation for logistic Gaussian process density estimation\n  and regression", "comments": "The v2 and v3 files are the same, but the v3 metadata now has the\n  correct title and abstract", "journal-ref": "Bayesian analysis, 9(2):425-448, 2014", "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logistic Gaussian process (LGP) priors provide a flexible alternative for\nmodelling unknown densities. The smoothness properties of the density estimates\ncan be controlled through the prior covariance structure of the LGP, but the\nchallenge is the analytically intractable inference. In this paper, we present\napproximate Bayesian inference for LGP density estimation in a grid using\nLaplace's method to integrate over the non-Gaussian posterior distribution of\nlatent function values and to determine the covariance function parameters with\ntype-II maximum a posteriori (MAP) estimation. We demonstrate that Laplace's\nmethod with MAP is sufficiently fast for practical interactive visualisation of\n1D and 2D densities. Our experiments with simulated and real 1D data sets show\nthat the estimation accuracy is close to a Markov chain Monte Carlo\napproximation and state-of-the-art hierarchical infinite Gaussian mixture\nmodels. We also construct a reduced-rank approximation to speed up the\ncomputations for dense 2D grids, and demonstrate density regression with the\nproposed Laplace approach.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 13:31:17 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2013 14:19:51 GMT"}, {"version": "v3", "created": "Mon, 7 Oct 2013 10:57:33 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Riihim\u00e4ki", "Jaakko", ""], ["Vehtari", "Aki", ""]]}, {"id": "1211.0815", "submitter": "Lucio Barabesi", "authors": "Lucio Barabesi, Luca Pratelli", "title": "A note on a universal random variate generator for integer-valued random\n  variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A universal generator for integer-valued square-integrable random variables\nis introduced. The generator relies on a rejection technique based on a\ngeneralization of the inversion formula for integer-valued random variables.\nThe proposal gives rise to a simple algorithm which may be implemented in a few\ncode lines and which may show good performance when the classical families of\ndistributions - such as the Poisson and the Binomial - are considered. In\naddition, the method is suitable for the computer generation of integer-valued\nrandom variables which display closed-form characteristic functions, but do not\npossess a probability function expressible in a simple analytical way. As an\nexample of such a framework, an application to the Poisson-Tweedie distribution\nis provided.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2012 10:26:28 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Barabesi", "Lucio", ""], ["Pratelli", "Luca", ""]]}, {"id": "1211.0947", "submitter": "Sebastian Bitzer", "authors": "Sebastian Bitzer and Izzet B. Yildiz and Stefan J. Kiebel", "title": "Online Discrimination of Nonlinear Dynamics with Switching Differential\n  Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How to recognise whether an observed person walks or runs? We consider a\ndynamic environment where observations (e.g. the posture of a person) are\ncaused by different dynamic processes (walking or running) which are active one\nat a time and which may transition from one to another at any time. For this\nsetup, switching dynamic models have been suggested previously, mostly, for\nlinear and nonlinear dynamics in discrete time. Motivated by basic principles\nof computations in the brain (dynamic, internal models) we suggest a model for\nswitching nonlinear differential equations. The switching process in the model\nis implemented by a Hopfield network and we use parametric dynamic movement\nprimitives to represent arbitrary rhythmic motions. The model generates\nobserved dynamics by linearly interpolating the primitives weighted by the\nswitching variables and it is constructed such that standard filtering\nalgorithms can be applied. In two experiments with synthetic planar motion and\na human motion capture data set we show that inference with the unscented\nKalman filter can successfully discriminate several dynamic processes online.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2012 17:50:56 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Bitzer", "Sebastian", ""], ["Yildiz", "Izzet B.", ""], ["Kiebel", "Stefan J.", ""]]}, {"id": "1211.1171", "submitter": "Antonio Punzo", "authors": "Salvatore Ingrassia and Simona C. Minotti and Antonio Punzo and\n  Giorgio Vittadini", "title": "Generalized Linear Gaussian Cluster-Weighted Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster-Weighted Modeling (CWM) is a flexible mixture approach for modeling\nthe joint probability of data coming from a heterogeneous population as a\nweighted sum of the products of marginal distributions and conditional\ndistributions. In this paper, we introduce a wide family of Cluster Weighted\nmodels in which the conditional distributions are assumed to belong to the\nexponential family with canonical links which will be referred to as\nGeneralized Linear Gaussian Cluster Weighted Models. Moreover, we show that, in\na suitable sense, mixtures of generalized linear models can be considered as\nnested in Generalized Linear Gaussian Cluster Weighted Models. The proposal is\nillustrated through many numerical studies based on both simulated and real\ndata sets.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2012 10:10:22 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2012 16:17:47 GMT"}], "update_date": "2012-12-20", "authors_parsed": [["Ingrassia", "Salvatore", ""], ["Minotti", "Simona C.", ""], ["Punzo", "Antonio", ""], ["Vittadini", "Giorgio", ""]]}, {"id": "1211.1183", "submitter": "Antonio Punzo", "authors": "Angelo Mazza and Antonio Punzo and Brian McGuire", "title": "KernSmoothIRT: An R Package for Kernel Smoothing in Item Response Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item response theory (IRT) models are a class of statistical models used to\ndescribe the response behaviors of individuals to a set of items having a\ncertain number of options. They are adopted by researchers in social science,\nparticularly in the analysis of performance or attitudinal data, in psychology,\neducation, medicine, marketing and other fields where the aim is to measure\nlatent constructs. Most IRT analyses use parametric models that rely on\nassumptions that often are not satisfied. In such cases, a nonparametric\napproach might be preferable; nevertheless, there are not many software\napplications allowing to use that. To address this gap, this paper presents the\nR package KernSmoothIRT. It implements kernel smoothing for the estimation of\noption characteristic curves, and adds several plotting and analytical tools to\nevaluate the whole test/questionnaire, the items, and the subjects. In order to\nshow the package's capabilities, two real datasets are used, one employing\nmultiple-choice responses, and the other scaled responses.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2012 11:26:30 GMT"}, {"version": "v2", "created": "Tue, 15 Apr 2014 09:56:38 GMT"}], "update_date": "2014-04-16", "authors_parsed": [["Mazza", "Angelo", ""], ["Punzo", "Antonio", ""], ["McGuire", "Brian", ""]]}, {"id": "1211.1184", "submitter": "Antonio Punzo", "authors": "Angelo Mazza and Antonio Punzo", "title": "DBKGrad: An R Package for Mortality Rates Graduation by Fixed and\n  Adaptive Discrete Beta Kernel Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernel smoothing represents a useful approach in the graduation of mortality\nrates. Though there exist several options for performing kernel smoothing in\nstatistical software packages, there have been very few contributions to date\nthat have focused on applications of these techniques in the graduation\ncontext. Also, although it has been shown that the use of a variable or\nadaptive smoothing parameter, based on the further information provided by the\nexposed to the risk of death, provides additional benefits, specific\ncomputational tools for this approach are essentially absent. Furthermore,\nlittle attention has been given to providing methods in available software for\nany kind of subsequent analysis with respect to the graduated mortality rates.\nTo facilitate analyses in the field, the R package DBKGrad is introduced. Among\nthe available kernel approaches, it considers a recent discrete beta kernel\nestimator, in both its fixed and adaptive variants. In this approach, boundary\nbias is automatically reduced and age is pragmatically considered as a discrete\nvariable. The bandwidth, fixed or adaptive, is allowed to be manually given by\nthe user or selected by cross-validation. Pointwise confidence intervals, for\neach considered age, are also provided. An application to mortality rates from\nthe Sicily Region (Italy) for the year 2008 is also presented to exemplify the\nuse of the package.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2012 11:27:08 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["Mazza", "Angelo", ""], ["Punzo", "Antonio", ""]]}, {"id": "1211.1405", "submitter": "Radu Craiu Dr", "authors": "Lizhen Xu, Radu V. Craiu and Lei Sun", "title": "Bayesian Latent Variable Modeling of Longitudinal Family Data for\n  Genetic Pleiotropy Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by genetic association studies of pleiotropy, we propose here a\nBayesian latent variable approach to jointly study multiple outcomes or\nphenotypes. The proposed method models both continuous and binary phenotypes,\nand it accounts for serial and familial correlations when longitudinal and\npedigree data have been collected. We present a Bayesian estimation method for\nthe model parameters, and we develop a novel MCMC algorithm that builds upon\nhierarchical centering and parameter expansion techniques to efficiently sample\nthe posterior distribution. We discuss phenotype and model selection in the\nBayesian setting, and we study the performance of two selection strategies\nbased on Bayes factors and spike-and-slab priors. We evaluate the proposed\nmethod via extensive simulations and demonstrate its utility with an\napplication to a genome-wide association study of various complication\nphenotypes related to type 1 diabetes.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2012 21:35:00 GMT"}], "update_date": "2012-11-08", "authors_parsed": [["Xu", "Lizhen", ""], ["Craiu", "Radu V.", ""], ["Sun", "Lei", ""]]}, {"id": "1211.1592", "submitter": "Ying Hung", "authors": "Ying Hung, V. Roshan Joseph, and Shreyes N. Melkote", "title": "Analysis of Computer Experiments with Functional Response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is motivated by a computer experiment conducted for optimizing\nresidual stresses in the machining of metals. Although kriging is widely used\nin the analysis of computer experiments, it cannot be easily applied to model\nthe residual stresses because they are obtained as a profile. The high\ndimensionality caused by this functional response introduces severe\ncomputational challenges in kriging. It is well known that if the functional\ndata are observed on a regular grid, the computations can be simplified using\nan application of Kronecker products. However, the case of irregular grid is\nquite complex. In this paper, we develop a Gibbs sampling-based expectation\nmaximization algorithm, which converts the irregularly spaced data into a\nregular grid so that the Kronecker product-based approach can be employed for\nefficiently fitting a kriging model to the functional data.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 16:36:24 GMT"}], "update_date": "2012-11-08", "authors_parsed": [["Hung", "Ying", ""], ["Joseph", "V. Roshan", ""], ["Melkote", "Shreyes N.", ""]]}, {"id": "1211.2190", "submitter": "Luca Martino", "authors": "Jesse Read, Luca Martino, David Luengo", "title": "Efficient Monte Carlo Methods for Multi-Dimensional Learning with\n  Classifier Chains", "comments": "Submitted to Pattern Recognition", "journal-ref": "Pattern Recognition, Volume 47, Issue 3, Pages: 1535-1546, 2014", "doi": "10.1016/j.patcog.2013.10.006", "report-no": null, "categories": "cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-dimensional classification (MDC) is the supervised learning problem\nwhere an instance is associated with multiple classes, rather than with a\nsingle class, as in traditional classification problems. Since these classes\nare often strongly correlated, modeling the dependencies between them allows\nMDC methods to improve their performance - at the expense of an increased\ncomputational cost. In this paper we focus on the classifier chains (CC)\napproach for modeling dependencies, one of the most popular and highest-\nperforming methods for multi-label classification (MLC), a particular case of\nMDC which involves only binary classes (i.e., labels). The original CC\nalgorithm makes a greedy approximation, and is fast but tends to propagate\nerrors along the chain. Here we present novel Monte Carlo schemes, both for\nfinding a good chain sequence and performing efficient inference. Our\nalgorithms remain tractable for high-dimensional data sets and obtain the best\npredictive performance across several real data sets.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 17:21:48 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2012 18:39:35 GMT"}, {"version": "v3", "created": "Mon, 15 Apr 2013 16:43:20 GMT"}, {"version": "v4", "created": "Sat, 7 Sep 2013 13:10:06 GMT"}], "update_date": "2014-05-20", "authors_parsed": [["Read", "Jesse", ""], ["Martino", "Luca", ""], ["Luengo", "David", ""]]}, {"id": "1211.2207", "submitter": "Thorbjorn Gudmundsson", "authors": "Thorbj\\\"orn Gudmundsson and Henrik Hult", "title": "Markov chain Monte Carlo for computing rare-event probabilities for a\n  heavy-tailed random walk", "comments": "22 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a method based on a Markov chain Monte Carlo (MCMC) algorithm\nis proposed to compute the probability of a rare event. The conditional\ndistribution of the underlying process given that the rare event occurs has the\nprobability of the rare event as its normalizing constant. Using the MCMC\nmethodology a Markov chain is simulated, with that conditional distribution as\nits invariant distribution, and information about the normalizing constant is\nextracted from its trajectory. The algorithm is described in full generality\nand applied to the problem of computing the probability that a heavy-tailed\nrandom walk exceeds a high threshold. An unbiased estimator of the reciprocal\nprobability is constructed whose normalized variance vanishes asymptotically.\nThe algorithm is extended to random sums and its performance is illustrated\nnumerically and compared to existing importance sampling algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 18:41:35 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Gudmundsson", "Thorbj\u00f6rn", ""], ["Hult", "Henrik", ""]]}, {"id": "1211.2442", "submitter": "Lidia  Rejt\\\"o K", "authors": "Vill\\\"o Csisz\\'ar, P\\'eter Hussami, J\\'anos Koml\\'os, Tam\\'as F.\n  M\\'ori, L\\'idia Rejt\\\"o and G\\'abor Tusn\\'ady", "title": "Testing goodness-of-fit of random graph models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random graphs are matrices with independent 0, 1 elements with probabilities\ndetermined by a small number of parameters. One of the oldest model is the\nRasch model where the odds are ratios of positive numbers scaling the rows and\ncolumns. Later Persi Diaconis with his coworkers rediscovered the model for\nsymmetric matrices and called the model beta. Here we give goodnes-of-fit tests\nfor the model and extend the model to a version of the block model introduced\nby Holland, Laskey, and Leinhard.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2012 17:50:58 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Csisz\u00e1r", "Vill\u00f6", ""], ["Hussami", "P\u00e9ter", ""], ["Koml\u00f3s", "J\u00e1nos", ""], ["M\u00f3ri", "Tam\u00e1s F.", ""], ["Rejt\u00f6", "L\u00eddia", ""], ["Tusn\u00e1dy", "G\u00e1bor", ""]]}, {"id": "1211.2532", "submitter": "Benjamin Rolfs", "authors": "Dominique Guillot and Bala Rajaratnam and Benjamin T. Rolfs and Arian\n  Maleki and Ian Wong", "title": "Iterative Thresholding Algorithm for Sparse Inverse Covariance\n  Estimation", "comments": "25 pages, 1 figure, 4 tables. Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The L1-regularized maximum likelihood estimation problem has recently become\na topic of great interest within the machine learning, statistics, and\noptimization communities as a method for producing sparse inverse covariance\nestimators. In this paper, a proximal gradient method (G-ISTA) for performing\nL1-regularized covariance matrix estimation is presented. Although numerous\nalgorithms have been proposed for solving this problem, this simple proximal\ngradient method is found to have attractive theoretical and numerical\nproperties. G-ISTA has a linear rate of convergence, resulting in an O(log e)\niteration complexity to reach a tolerance of e. This paper gives eigenvalue\nbounds for the G-ISTA iterates, providing a closed-form linear convergence\nrate. The rate is shown to be closely related to the condition number of the\noptimal point. Numerical convergence results and timing comparisons for the\nproposed method are presented. G-ISTA is shown to perform very well, especially\nwhen the optimal point is well-conditioned.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 08:35:26 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2012 01:22:30 GMT"}, {"version": "v3", "created": "Tue, 27 Nov 2012 04:48:51 GMT"}], "update_date": "2012-11-28", "authors_parsed": [["Guillot", "Dominique", ""], ["Rajaratnam", "Bala", ""], ["Rolfs", "Benjamin T.", ""], ["Maleki", "Arian", ""], ["Wong", "Ian", ""]]}, {"id": "1211.2548", "submitter": "Pierre Pudlo", "authors": "Jean-Michel Marin (1), Pierre Pudlo (1,2), Mohammed Sedki (1,3) ((1)\n  University Montpellier 2 - I3M, (2) INRA - CBGP, (3) University Paris-Sud -\n  CRESP)", "title": "Consistency of the Adaptive Multiple Importance Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among Monte Carlo techniques, the importance sampling requires fine tuning of\na proposal distribution, which is now fluently resolved through iterative\nschemes. The Adaptive Multiple Importance Sampling (AMIS) of Cornuet et al.\n(2012) provides a significant improvement in stability and effective sample\nsize due to the introduction of a recycling procedure. However, the consistency\nof the AMIS estimator remains largely open. In this work we prove the\nconvergence of the AMIS, at a cost of a slight modification in the learning\nprocess. Contrary to Douc et al. (2007a), results are obtained here in the\nasymptotic regime where the number of iterations is going to infinity while the\nnumber of drawings per iteration is a fixed, but growing sequence of integers.\nHence some of the results shed new light on adaptive population Monte Carlo\nalgorithms in that last regime.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 10:14:46 GMT"}, {"version": "v2", "created": "Mon, 26 May 2014 14:08:45 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Marin", "Jean-Michel", ""], ["Pudlo", "Pierre", ""], ["Sedki", "Mohammed", ""]]}, {"id": "1211.3210", "submitter": "Alice Cleynen", "authors": "Alice Cleynen and The Minh Luong and Guillem Rigaill and Gregory Nuel", "title": "Fast estimation of the ICL criterion for change-point detection problems\n  with applications to Next-Generation Sequencing data", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the Integrated Completed Likelihood (ICL) as a\nuseful criterion for estimating the number of changes in the underlying\ndistribution of data in problems where detecting the precise location of these\nchanges is the main goal. The exact computation of the ICL requires O(Kn2)\noperations (with K the number of segments and n the number of data-points)\nwhich is prohibitive in many practical situations with large sequences of data.\nWe describe a framework to estimate the ICL with O(Kn) complexity. Our approach\nis general in the sense that it can accommodate any given model distribution.\nWe checked the run-time and validity of our approach on simulated data and\ndemonstrate its good performance when analyzing real Next-Generation Sequencing\n(NGS) data using a negative binomial model.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2012 05:50:46 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2013 09:43:31 GMT"}], "update_date": "2013-07-02", "authors_parsed": [["Cleynen", "Alice", ""], ["Luong", "The Minh", ""], ["Rigaill", "Guillem", ""], ["Nuel", "Gregory", ""]]}, {"id": "1211.3759", "submitter": "Babak Shahbaba", "authors": "Shiwei Lan, Vassilios Stathopoulos, Babak Shahbaba, and Mark Girolami", "title": "Lagrangian Dynamical Monte Carlo", "comments": null, "journal-ref": "Journal of Computational and Graphical Statistics, Volume 24,\n  Issue 2, 2015", "doi": "10.1080/10618600.2014.902764", "report-no": null, "categories": "stat.CO math.DS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo (HMC) improves the computational efficiency of the\nMetropolis algorithm by reducing its random walk behavior. Riemannian Manifold\nHMC (RMHMC) further improves HMC's performance by exploiting the geometric\nproperties of the parameter space. However, the geometric integrator used for\nRMHMC involves implicit equations that require costly numerical analysis (e.g.,\nfixed-point iteration). In some cases, the computational overhead for solving\nimplicit equations undermines RMHMC's benefits. To avoid this problem, we\npropose an explicit geometric integrator that replaces the momentum variable in\nRMHMC by velocity. We show that the resulting transformation is equivalent to\ntransforming Riemannian Hamilton dynamics to Lagrangian dynamics. Experimental\nresults show that our method improves RMHMC's overall computational efficiency.\nAll computer programs and data sets are available online\n(http://www.ics.uci.edu/~babaks/Site/Codes.html) in order to allow replications\nof the results reported in this paper.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2012 21:36:40 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2012 22:08:20 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Lan", "Shiwei", ""], ["Stathopoulos", "Vassilios", ""], ["Shahbaba", "Babak", ""], ["Girolami", "Mark", ""]]}, {"id": "1211.3907", "submitter": "Eric Chi", "authors": "Eric C. Chi, Hua Zhou, and Kenneth Lange", "title": "Distance Majorization and Its Applications", "comments": "29 pages, 6 figures", "journal-ref": "Mathematical Programming Series A, 146:409-436, 2014", "doi": "10.1007/s10107-013-0697-1", "report-no": null, "categories": "math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of minimizing a continuously differentiable convex function over\nan intersection of closed convex sets is ubiquitous in applied mathematics. It\nis particularly interesting when it is easy to project onto each separate set,\nbut nontrivial to project onto their intersection. Algorithms based on Newton's\nmethod such as the interior point method are viable for small to medium-scale\nproblems. However, modern applications in statistics, engineering, and machine\nlearning are posing problems with potentially tens of thousands of parameters\nor more. We revisit this convex programming problem and propose an algorithm\nthat scales well with dimensionality. Our proposal is an instance of a\nsequential unconstrained minimization technique and revolves around three\nideas: the majorization-minimization (MM) principle, the classical penalty\nmethod for constrained optimization, and quasi-Newton acceleration of\nfixed-point algorithms. The performance of our distance majorization algorithms\nis illustrated in several applications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2012 14:47:43 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2013 19:25:09 GMT"}, {"version": "v3", "created": "Mon, 11 Mar 2013 14:29:39 GMT"}, {"version": "v4", "created": "Thu, 23 May 2013 17:30:10 GMT"}, {"version": "v5", "created": "Tue, 11 Jun 2013 23:08:53 GMT"}], "update_date": "2014-08-06", "authors_parsed": [["Chi", "Eric C.", ""], ["Zhou", "Hua", ""], ["Lange", "Kenneth", ""]]}, {"id": "1211.3946", "submitter": "David  Bolin", "authors": "David Bolin and Finn Lindgren", "title": "Excursion and contour uncertainty regions for latent Gaussian models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An interesting statistical problem is to find regions where some studied\nprocess exceeds a certain level. Estimating such regions so that the\nprobability for exceeding the level in the entire set is equal to some\npredefined value is a difficult problem that occurs in several areas of\napplications ranging from brain imaging to astrophysics. In this work, a method\nfor solving this problem, as well as the related problem of finding uncertainty\nregions for contour curves, for latent Gaussian models is proposed. The method\nis based on using a parametric family for the excursion sets in combination\nwith a sequential importance sampling method for estimating joint\nprobabilities. The accuracy of the method is investigated using simulated data\nand two environmental applications are presented. In the first application,\nareas where the air pollution in the Piemonte region in northern Italy exceeds\nthe daily limit value, set by the European Union for human health protection,\nare estimated. In the second application, regions in the African Sahel that\nexperienced an increase in vegetation after the drought period in the early\n1980s are estimated.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2012 16:31:27 GMT"}], "update_date": "2012-11-19", "authors_parsed": [["Bolin", "David", ""], ["Lindgren", "Finn", ""]]}, {"id": "1211.4262", "submitter": "Kushal  Dey", "authors": "Kushal Kr. Dey and Kumaresh Dhara and Bikram Karmakar and Sukalyan\n  Sengupta", "title": "Univariate and data-depth based multivariate control charts using\n  trimmed mean and winsorized standard deviation", "comments": "This paper consists of 15 pages, 2 figures, and 5 tables. This paper\n  was presented by Kumaresh Dhara at the 29th Quality Productivity and Research\n  Conference (QPRC) 2012 held at California State University, Long Beach, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the years, the most popularly used control chart for statistical process\ncontrol has been Shewhart's $\\bar{X}-S$ or $\\bar{X}-R$ chart along with its\nmultivariate generalizations. But, such control charts suffer from the lack of\nrobustness. In this paper, we propose a modified and improved version of\nShewhart chart, based on trimmed mean and winsorized variance that proves\nrobust and more efficient. We have generalized this approach of ours with\nsuitable modifications using depth functions for Multivariate control charts\nand EWMA charts as well. We have discussed the theoretical properties of our\nproposed statistics and have shown the efficiency of our methodology on\nunivariate and multivariate simulated datasets. We have also compared our\napproach to the other popular alternatives to Shewhart Chart already proposed\nand established the efficacy of our methodology.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2012 22:06:48 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Dey", "Kushal Kr.", ""], ["Dhara", "Kumaresh", ""], ["Karmakar", "Bikram", ""], ["Sengupta", "Sukalyan", ""]]}, {"id": "1211.4483", "submitter": "Nicolas Chopin", "authors": "Nicolas Chopin, Judith Rousseau and Brunero Liseo", "title": "Computational aspects of Bayesian spectral density estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaussian time-series models are often specified through their spectral\ndensity. Such models present several computational challenges, in particular\nbecause of the non-sparse nature of the covariance matrix. We derive a fast\napproximation of the likelihood for such models. We propose to sample from the\napproximate posterior (that is, the prior times the approximate likelihood),\nand then to recover the exact posterior through importance sampling. We show\nthat the variance of the importance sampling weights vanishes as the sample\nsize goes to infinity. We explain why the approximate posterior may typically\nmulti-modal, and we derive a Sequential Monte Carlo sampler based on an\nannealing sequence in order to sample from that target distribution.\nPerformance of the overall approach is evaluated on simulated and real\ndatasets. In addition, for one real world dataset, we provide some numerical\nevidence that a Bayesian approach to semi-parametric estimation of spectral\ndensity may provide more reasonable results than its Frequentist counter-parts.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 16:24:40 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Chopin", "Nicolas", ""], ["Rousseau", "Judith", ""], ["Liseo", "Brunero", ""]]}, {"id": "1211.4601", "submitter": "Aleksandr Aravkin", "authors": "Aleksandr Y. Aravkin and James V. Burke", "title": "Smoothing Dynamic Systems with State-Dependent Covariance Matrices", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kalman filtering and smoothing algorithms are used in many areas, including\ntracking and navigation, medical applications, and financial trend filtering.\nOne of the basic assumptions required to apply the Kalman smoothing framework\nis that error covariance matrices are known and given. In this paper, we study\na general class of inference problems where covariance matrices can depend\nfunctionally on unknown parameters. In the Kalman framework, this allows\nmodeling situations where covariance matrices may depend functionally on the\nstate sequence being estimated. We present an extended formulation and\ngeneralized Gauss-Newton (GGN) algorithm for inference in this context. When\napplied to dynamic systems inference, we show the algorithm can be implemented\nto preserve the computational efficiency of the classic Kalman smoother. The\nnew approach is illustrated with a synthetic numerical example.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 21:42:27 GMT"}, {"version": "v2", "created": "Thu, 20 Mar 2014 19:47:51 GMT"}], "update_date": "2014-03-21", "authors_parsed": [["Aravkin", "Aleksandr Y.", ""], ["Burke", "James V.", ""]]}, {"id": "1211.4801", "submitter": "Vassilios Stathopoulos", "authors": "Vassilios Stathopoulos and Mark A. Girolami", "title": "MCMC inference for Markov Jump Processes via the Linear Noise\n  Approximation", "comments": null, "journal-ref": null, "doi": "10.1098/rsta.2011.0541", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian analysis for Markov jump processes is a non-trivial and challenging\nproblem. Although exact inference is theoretically possible, it is\ncomputationally demanding thus its applicability is limited to a small class of\nproblems. In this paper we describe the application of Riemann manifold MCMC\nmethods using an approximation to the likelihood of the Markov jump process\nwhich is valid when the system modelled is near its thermodynamic limit. The\nproposed approach is both statistically and computationally efficient while the\nconvergence rate and mixing of the chains allows for fast MCMC inference. The\nmethodology is evaluated using numerical simulations on two problems from\nchemical kinetics and one from systems biology.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 16:52:23 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Stathopoulos", "Vassilios", ""], ["Girolami", "Mark A.", ""]]}, {"id": "1211.5052", "submitter": "Ricardo Monge", "authors": "Osvaldo Skliar, Ricardo E. Monge, Sherry Gapper, Guillermo Oviedo", "title": "A Mathematical Random Number Generator (MRNG)", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel Mathematical Random Number Generator (MRNG) is presented here. In\nthis case, \"mathematical\" refers to the fact that to construct that generator\nit is not necessary to resort to a physical phenomenon, such as the thermal\nnoise of an electronic device, but rather to a mathematical procedure. The MRNG\ngenerates binary strings - in principle, as long as desired - which may be\nconsidered genuinely random in the sense that they pass the statistical tests\ncurrently accepted to evaluate the randomness of those strings. From those\nstrings, the MRNG also generates random numbers expressed in base 10. An MRNG\nhas been installed as a facility on the following web page:\nhttp://www.appliedmathgroup.org. This generator may be used for applications in\ntasks in: a) computational simulation of probabilistic-type systems, and b) the\nrandom selection of samples of different populations. Users interested in\napplications in cryptography can build another MRNG, but they would have to\nwithhold information - specified in section 5 - from people who are not\nauthorized to decode messages encrypted using that resource.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2012 15:06:41 GMT"}], "update_date": "2012-11-22", "authors_parsed": [["Skliar", "Osvaldo", ""], ["Monge", "Ricardo E.", ""], ["Gapper", "Sherry", ""], ["Oviedo", "Guillermo", ""]]}, {"id": "1211.5290", "submitter": "Geoffrey McLachlan", "authors": "Sharon X. Lee, Geoffrey J. McLachlan", "title": "EMMIX-uskew: An R Package for Fitting Mixtures of Multivariate Skew\n  t-distributions via the EM Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an algorithm for fitting finite mixtures of unrestricted\nMultivariate Skew t (FM-uMST) distributions. The package EMMIX-uskew implements\na closed-form expectation-maximization (EM) algorithm for computing the maximum\nlikelihood (ML) estimates of the parameters for the (unrestricted) FM-MST model\nin R. EMMIX-uskew also supports visualization of fitted contours in two and\nthree dimensions, and random sample generation from a specified FM-uMST\ndistribution.\n  Finite mixtures of skew t-distributions have proven to be useful in modelling\nheterogeneous data with asymmetric and heavy tail behaviour, for example,\ndatasets from flow cytometry. In recent years, various versions of mixtures\nwith multivariate skew t (MST) distributions have been proposed. However, these\nmodels adopted some restricted characterizations of the component MST\ndistributions so that the E-step of the EM algorithm can be evaluated in closed\nform. This paper focuses on mixtures with unrestricted MST components, and\ndescribes an iterative algorithm for the computation of the ML estimates of its\nmodel parameters.\n  The usefulness of the proposed algorithm is demonstrated in three\napplications to real data sets. The first example illustrates the use of the\nmain function fmmst in the package by fitting a MST distribution to a bivariate\nunimodal flow cytometric sample. The second example fits a mixture of MST\ndistributions to the Australian Institute of Sport (AIS) data, and demonstrate\nthat EMMIX-uskew can provide better clustering results than mixtures with\nrestricted MST components. In the third example, EMMIX-uskew is applied to\nclassify cells in a trivariate flow cytometric dataset. Comparisons with other\navailable methods suggests that the EMMIX-uskew result achieved a lower\nmisclassification rate with respect to the labels given by benchmark gating\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2012 13:54:45 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2013 03:11:34 GMT"}], "update_date": "2013-03-29", "authors_parsed": [["Lee", "Sharon X.", ""], ["McLachlan", "Geoffrey J.", ""]]}, {"id": "1211.5901", "submitter": "Nicolas Chopin", "authors": "Sumeetpal S. Singh and Nicolas Chopin and Nick Whiteley", "title": "Bayesian learning of noisy Markov decision processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the inverse reinforcement learning problem, that is, the problem\nof learning from, and then predicting or mimicking a controller based on\nstate/action data. We propose a statistical model for such data, derived from\nthe structure of a Markov decision process. Adopting a Bayesian approach to\ninference, we show how latent variables of the model can be estimated, and how\npredictions about actions can be made, in a unified framework. A new Markov\nchain Monte Carlo (MCMC) sampler is devised for simulation from the posterior\ndistribution. This step includes a parameter expansion step, which is shown to\nbe essential for good convergence properties of the MCMC sampler. As an\nillustration, the method is applied to learning a human controller.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2012 09:55:27 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["Singh", "Sumeetpal S.", ""], ["Chopin", "Nicolas", ""], ["Whiteley", "Nick", ""]]}, {"id": "1211.6451", "submitter": "Paul McNicholas", "authors": "Sakyajit Bhattacharya and Paul D. McNicholas", "title": "A LASSO-Penalized BIC for Mixture Model Selection", "comments": null, "journal-ref": null, "doi": "10.1007/s11634-013-0155-1", "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficacy of family-based approaches to mixture model-based clustering and\nclassification depends on the selection of parsimonious models. Current wisdom\nsuggests the Bayesian information criterion (BIC) for mixture model selection.\nHowever, the BIC has well-known limitations, including a tendency to\noverestimate the number of components as well as a proclivity for, often\ndrastically, underestimating the number of components in higher dimensions.\nWhile the former problem might be soluble through merging components, the\nlatter is impossible to mitigate in clustering and classification applications.\nIn this paper, a LASSO-penalized BIC (LPBIC) is introduced to overcome this\nproblem. This approach is illustrated based on applications of extensions of\nmixtures of factor analyzers, where the LPBIC is used to select both the number\nof components and the number of latent factors. The LPBIC is shown to match or\noutperform the BIC in several situations.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2012 21:11:41 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Bhattacharya", "Sakyajit", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1211.6851", "submitter": "Chiheb-Eddine Ben n'cir C.B.N'cir", "authors": "Chiheb-Eddine Ben N'Cir and Nadia Essoussi", "title": "Classification Recouvrante Bas\\'ee sur les M\\'ethodes \\`a Noyau", "comments": "Les 43\\`emes Journ\\'ees de Statistique", "journal-ref": "Les 43\\`emes Journ\\'ees de Statistique 2011", "doi": null, "report-no": null, "categories": "cs.LG stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overlapping clustering problem is an important learning issue in which\nclusters are not mutually exclusive and each object may belongs simultaneously\nto several clusters. This paper presents a kernel based method that produces\noverlapping clusters on a high feature space using mercer kernel techniques to\nimprove separability of input patterns. The proposed method, called\nOKM-K(Overlapping $k$-means based kernel method), extends OKM (Overlapping\n$k$-means) method to produce overlapping schemes. Experiments are performed on\noverlapping dataset and empirical results obtained with OKM-K outperform\nresults obtained with OKM.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2012 09:22:19 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["N'Cir", "Chiheb-Eddine Ben", ""], ["Essoussi", "Nadia", ""]]}, {"id": "1211.7283", "submitter": "Cedric Herzet", "authors": "Cedric Herzet, Charles Soussen, Jerome Idier, Remi Gribonval", "title": "Coherence-based Partial Exact Recovery Condition for OMP/OLS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT physics.data-an stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the exact recovery of the support of a k-sparse vector with\nOrthogonal Matching Pursuit (OMP) and Orthogonal Least Squares (OLS) in a\nnoiseless setting. We consider the scenario where OMP/OLS have selected good\natoms during the first l iterations (l<k) and derive a new sufficient and\nworst-case necessary condition for their success in k steps. Our result is\nbased on the coherence \\mu of the dictionary and relaxes Tropp's well-known\ncondition \\mu<1/(2k-1) to the case where OMP/OLS have a partial knowledge of\nthe support.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2012 15:11:24 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Herzet", "Cedric", ""], ["Soussen", "Charles", ""], ["Idier", "Jerome", ""], ["Gribonval", "Remi", ""]]}]