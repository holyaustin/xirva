[{"id": "0809.0660", "submitter": "Stephane Chretien", "authors": "Stephane Chretien", "title": "An Alternating l1 approach to the compressed sensing problem", "comments": "7 pages, 1 figure, presented at ICIAM 07", "journal-ref": "IEEE Signal Processing Letters, Feb. 2010 Volume : 17 , Issue: 2\n  On page(s): 181 - 184", "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing is a new methodology for constructing sensors which allow\nsparse signals to be efficiently recovered using only a small number of\nobservations. The recovery problem can often be stated as the one of finding\nthe solution of an underdetermined system of linear equations with the smallest\npossible support. The most studied relaxation of this hard combinatorial\nproblem is the $l_1$-relaxation consisting of searching for solutions with\nsmallest $l_1$-norm. In this short note, based on the ideas of Lagrangian\nduality, we introduce an alternating $l_1$ relaxation for the recovery problem\nenjoying higher recovery rates in practice than the plain $l_1$ relaxation and\nthe recent reweighted $l_1$ method of Cand\\`es, Wakin and Boyd.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2008 16:08:08 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2009 21:40:07 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2009 22:53:16 GMT"}], "update_date": "2010-11-04", "authors_parsed": [["Chretien", "Stephane", ""]]}, {"id": "0809.0974", "submitter": "Lutz D\\\"umbgen", "authors": "Rudolf Beran and Lutz Duembgen", "title": "Least Squares and Shrinkage Estimation under Bimonotonicity Constraints", "comments": null, "journal-ref": "Statistics and Computing, Volume 20, Number 2 (2010), pp. 177-189", "doi": "10.1007/s11222-009-9124-0", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe active set type algorithms for minimization of a\nsmooth function under general order constraints, an important case being\nfunctions on the set of bimonotone r-by-s matrices. These algorithms can be\nused, for instance, to estimate a bimonotone regression function via least\nsquares or (a smooth approximation of) least absolute deviations. Another\napplication is shrinkage estimation in image denoising or, more generally,\nregression problems with two ordinal factors after representing the data in a\nsuitable basis which is indexed by pairs (i,j) in {1,...,r}x{1,...,s}. Various\nnumerical examples illustrate our methods.\n", "versions": [{"version": "v1", "created": "Fri, 5 Sep 2008 09:38:00 GMT"}, {"version": "v2", "created": "Fri, 12 Sep 2008 16:21:20 GMT"}, {"version": "v3", "created": "Mon, 26 Jan 2009 18:39:14 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Beran", "Rudolf", ""], ["Duembgen", "Lutz", ""]]}, {"id": "0809.1260", "submitter": "Benjamin Recht", "authors": "Benjamin Recht, Weiyu Xu, Babak Hassibi", "title": "Necessary and Sufficient Conditions for Success of the Nuclear Norm\n  Heuristic for Rank Minimization", "comments": "21 pages, 3 figures. A short version of this paper will appear at the\n  47th IEEE Conference on Decision and Control", "journal-ref": null, "doi": "10.1109/CDC.2008.4739332", "report-no": null, "categories": "math.OC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimizing the rank of a matrix subject to constraints is a challenging\nproblem that arises in many applications in control theory, machine learning,\nand discrete geometry. This class of optimization problems, known as rank\nminimization, is NP-HARD, and for most practical problems there are no\nefficient algorithms that yield exact solutions. A popular heuristic algorithm\nreplaces the rank function with the nuclear norm--equal to the sum of the\nsingular values--of the decision variable. In this paper, we provide a\nnecessary and sufficient condition that quantifies when this heuristic\nsuccessfully finds the minimum rank solution of a linear constraint set. We\nadditionally provide a probability distribution over instances of the affine\nrank minimization problem such that instances sampled from this distribution\nsatisfy our conditions for success with overwhelming probability provided the\nnumber of constraints is appropriately large. Finally, we give empirical\nevidence that these probabilistic bounds provide accurate predictions of the\nheuristic's performance in non-asymptotic scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2008 23:54:15 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Recht", "Benjamin", ""], ["Xu", "Weiyu", ""], ["Hassibi", "Babak", ""]]}, {"id": "0809.1878", "submitter": "Alexandre B. Simas", "authors": "Alexandre B. Simas, Wagner Barreto-Souza and Andr\\'ea V. Rocha", "title": "Improved estimators for a general class of beta regression models", "comments": null, "journal-ref": "Computational Statistics and Data Analysis 54 (2010) 348-366", "doi": "10.1016/j.csda.2009.08.017", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider an extension of the beta regression model proposed\nby Ferrari and Cribari-Neto (2004). We extend their model in two different\nways, first, we let the regression structure be nonlinear, second, we allow a\nregression structure for the precision parameter, moreover, this regression\nstructure may also be nonlinear. Generally, the beta regression is useful to\nsituations where the response is restricted to the standard unit interval and\nthe regression structure involves regressors and unknown parameters. We derive\ngeneral formulae for second-order biases of the maximum likelihood estimators\nand use them to define bias-corrected estimators. Our formulae generalizes the\nresults obtained by Ospina et al. (2006), and are easily implemented by means\nof supplementary weighted linear regressions. We also compare these\nbias-corrected estimators with three different estimators which are also\nbias-free to the second-order, one analytical and the other two based on\nbootstrap methods. These estimators are compared by simulation. We present an\nempirical application.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2008 20:50:49 GMT"}], "update_date": "2009-10-24", "authors_parsed": [["Simas", "Alexandre B.", ""], ["Barreto-Souza", "Wagner", ""], ["Rocha", "Andr\u00e9a V.", ""]]}, {"id": "0809.1889", "submitter": "Alexandre B. Simas", "authors": "Wagner Barreto-Souza, Alessandro H. S. Santos and Gauss M. Cordeiro", "title": "The Beta Generalized Exponential Distribution", "comments": null, "journal-ref": "Journal of Statistical Computation and Simulation, 80 , 159 - 172.\n  (2010)", "doi": "10.1080/00949650802552402", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the beta generalized exponential distribution that includes the\nbeta exponential and generalized exponential distributions as special cases. We\nprovide a comprehensive mathematical treatment of this distribution. We derive\nthe moment generating function and the $r$th moment thus generalizing some\nresults in the literature. Expressions for the density, moment generating\nfunction and $r$th moment of the order statistics also are obtained. We discuss\nestimation of the parameters by maximum likelihood and provide the information\nmatrix. We observe in one application to real data set that this model is quite\nflexible and can be used quite effectively in analyzing positive data in place\nof the beta exponential and generalized exponential distributions.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2008 22:02:09 GMT"}], "update_date": "2010-08-17", "authors_parsed": [["Barreto-Souza", "Wagner", ""], ["Santos", "Alessandro H. S.", ""], ["Cordeiro", "Gauss M.", ""]]}, {"id": "0809.2274", "submitter": "Mark Tygert", "authors": "Vladimir Rokhlin, Arthur Szlam, and Mark Tygert", "title": "A randomized algorithm for principal component analysis", "comments": "26 pages, 6 tables, 1 figure; to appear in the SIAM Journal on Matrix\n  Analysis and Applications", "journal-ref": "A randomized algorithm for principal component analysis, SIAM\n  Journal on Matrix Analysis and Applications, 31 (3): 1100-1124, 2009", "doi": null, "report-no": "UCLA Computational and Applied Math Technical Report 08-60", "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) requires the computation of a low-rank\napproximation to a matrix containing the data being analyzed. In many\napplications of PCA, the best possible accuracy of any rank-deficient\napproximation is at most a few digits (measured in the spectral norm, relative\nto the spectral norm of the matrix being approximated). In such circumstances,\nefficient algorithms have not come with guarantees of good accuracy, unless one\nor both dimensions of the matrix being approximated are small. We describe an\nefficient algorithm for the low-rank approximation of matrices that produces\naccuracy very close to the best possible, for matrices of arbitrary sizes. We\nillustrate our theoretical results via several numerical examples.\n", "versions": [{"version": "v1", "created": "Fri, 12 Sep 2008 19:38:02 GMT"}, {"version": "v2", "created": "Tue, 21 Oct 2008 16:39:16 GMT"}, {"version": "v3", "created": "Sun, 23 Nov 2008 19:45:19 GMT"}, {"version": "v4", "created": "Sun, 5 Jul 2009 21:27:06 GMT"}], "update_date": "2010-06-04", "authors_parsed": [["Rokhlin", "Vladimir", ""], ["Szlam", "Arthur", ""], ["Tygert", "Mark", ""]]}, {"id": "0809.2300", "submitter": "Kevin Lin", "authors": "Jonathan B. Goodman and Kevin K. Lin", "title": "Coupling Control Variates for Markov Chain Monte Carlo", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2009.03.043", "report-no": null, "categories": "math.NA physics.comp-ph stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that Markov couplings can be used to improve the accuracy of Markov\nchain Monte Carlo calculations in some situations where the steady-state\nprobability distribution is not explicitly known. The technique generalizes the\nnotion of control variates from classical Monte Carlo integration. We\nillustrate it using two models of nonequilibrium transport.\n", "versions": [{"version": "v1", "created": "Fri, 12 Sep 2008 22:49:05 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Goodman", "Jonathan B.", ""], ["Lin", "Kevin K.", ""]]}, {"id": "0809.3187", "submitter": "Tarik Borogovac", "authors": "T. Borogovac, F. J. Alexander, P. Vakili", "title": "A Control Variate Approach for Improving Efficiency of Ensemble Monte\n  Carlo", "comments": "15 pages, 2 ps figures, elsart.cls", "journal-ref": null, "doi": null, "report-no": "LA-UR-08-05399", "categories": "cs.CE cond-mat.stat-mech stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new approach to control variates for improving\ncomputational efficiency of Ensemble Monte Carlo. We present the approach using\nsimulation of paths of a time-dependent nonlinear stochastic equation. The core\nidea is to extract information at one or more nominal model parameters and use\nthis information to gain estimation efficiency at neighboring parameters. This\nidea is the basis of a general strategy, called DataBase Monte Carlo (DBMC),\nfor improving efficiency of Monte Carlo. In this paper we describe how this\nstrategy can be implemented using the variance reduction technique of Control\nVariates (CV). We show that, once an initial setup cost for extracting\ninformation is incurred, this approach can lead to significant gains in\ncomputational efficiency. The initial setup cost is justified in projects that\nrequire a large number of estimations or in those that are to be performed\nunder real-time constraints.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2008 15:29:40 GMT"}], "update_date": "2008-09-25", "authors_parsed": [["Borogovac", "T.", ""], ["Alexander", "F. J.", ""], ["Vakili", "P.", ""]]}, {"id": "0809.4047", "submitter": "Luis Mendo", "authors": "Luis Mendo and Jose M. Hernando", "title": "Improved Sequential Stopping Rule for Monte Carlo Simulation", "comments": "2 figures. Paper accepted in IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presents an improved result on the negative-binomial Monte Carlo\ntechnique analyzed in a previous paper for the estimation of an unknown\nprobability p. Specifically, the confidence level associated to a relative\ninterval [p/\\mu_2, p\\mu_1], with \\mu_1, \\mu_2 > 1, is proved to exceed its\nasymptotic value for a broader range of intervals than that given in the\nreferred paper, and for any value of p. This extends the applicability of the\nestimator, relaxing the conditions that guarantee a given confidence level.\n", "versions": [{"version": "v1", "created": "Tue, 23 Sep 2008 23:35:02 GMT"}], "update_date": "2008-09-25", "authors_parsed": [["Mendo", "Luis", ""], ["Hernando", "Jose M.", ""]]}, {"id": "0809.4178", "submitter": "Michael GB Blum", "authors": "M. G. B. Blum, O. Francois", "title": "Non-linear regression models for Approximate Bayesian Computation", "comments": "4 figures; version 3 minor changes; to appear in Statistics and\n  Computing", "journal-ref": "Statistics and Computing, 20: 63-73 (2010)", "doi": "10.1007/s11222-009-9116-0", "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian inference on the basis of summary statistics is\nwell-suited to complex problems for which the likelihood is either\nmathematically or computationally intractable. However the methods that use\nrejection suffer from the curse of dimensionality when the number of summary\nstatistics is increased. Here we propose a machine-learning approach to the\nestimation of the posterior density by introducing two innovations. The new\nmethod fits a nonlinear conditional heteroscedastic regression of the parameter\non the summary statistics, and then adaptively improves estimation using\nimportance sampling. The new algorithm is compared to the state-of-the-art\napproximate Bayesian methods, and achieves considerable reduction of the\ncomputational burden in two examples of inference in statistical genetics and\nin a queueing model.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2008 13:09:50 GMT"}, {"version": "v2", "created": "Mon, 23 Feb 2009 09:51:42 GMT"}], "update_date": "2010-05-04", "authors_parsed": [["Blum", "M. G. B.", ""], ["Francois", "O.", ""]]}, {"id": "0809.4627", "submitter": "Mingfu Zhu", "authors": "Mingfu Zhu, Guangran Jiang and Shuhong Gao", "title": "Solving the 100 Swiss Francs Problem", "comments": null, "journal-ref": null, "doi": "10.1007/s11786-011-0068-3", "report-no": null, "categories": "stat.CO math.AG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sturmfels offered 100 Swiss Francs in 2005 to a conjecture, which deals with\na special case of the maximum likelihood estimation for a latent class model.\nThis paper confirms the conjecture positively.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2008 13:31:13 GMT"}, {"version": "v2", "created": "Sat, 27 Aug 2011 19:19:12 GMT"}], "update_date": "2011-09-28", "authors_parsed": [["Zhu", "Mingfu", ""], ["Jiang", "Guangran", ""], ["Gao", "Shuhong", ""]]}, {"id": "0809.4654", "submitter": "Hugo Maruri Aguilar", "authors": "Ron A. Bates, Hugo Maruri-Aguilar, Henry P. Wynn", "title": "Smooth supersaturated models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In areas such as kernel smoothing and non-parametric regression there is\nemphasis on smooth interpolation and smooth statistical models. Splines are\nknown to have optimal smoothness properties in one and higher dimensions. It is\nshown, with special attention to polynomial models, that smooth interpolators\ncan be constructed by first extending the monomial basis and then minimising a\nmeasure of smoothness with respect to the free parameters in the extended\nbasis. Algebraic methods are a help in choosing the extended basis which can\nalso be found as a saturated basis for an extended experimental design with\ndummy design points. One can get arbitrarily close to optimal smoothing for any\ndimension and over any region, giving a simple alternative models of spline\ntype. The relationship to splines is shown in one and two dimensions. A case\nstudy is given which includes benchmarking against kriging methods.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2008 15:12:29 GMT"}], "update_date": "2008-09-29", "authors_parsed": [["Bates", "Ron A.", ""], ["Maruri-Aguilar", "Hugo", ""], ["Wynn", "Henry P.", ""]]}]