[{"id": "1412.0158", "submitter": "Shiwei Lan", "authors": "Shiwei Lan, Julia A. Palacios, Michael Karcher, Vladimir N. Minin and\n  Babak Shahbaba", "title": "An Efficient Bayesian Inference Framework for Coalescent-Based\n  Nonparametric Phylodynamics", "comments": null, "journal-ref": null, "doi": "10.1093/bioinformatics/btv378", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phylodynamics focuses on the problem of reconstructing past population size\ndynamics from current genetic samples taken from the population of interest.\nThis technique has been extensively used in many areas of biology, but is\nparticularly useful for studying the spread of quickly evolving infectious\ndiseases agents, e.g.,\\ influenza virus. Phylodynamics inference uses a\ncoalescent model that defines a probability density for the genealogy of\nrandomly sampled individuals from the population. When we assume that such a\ngenealogy is known, the coalescent model, equipped with a Gaussian process\nprior on population size trajectory, allows for nonparametric Bayesian\nestimation of population size dynamics. While this approach is quite powerful,\nlarge data sets collected during infectious disease surveillance challenge the\nstate-of-the-art of Bayesian phylodynamics and demand computationally more\nefficient inference framework. To satisfy this demand, we provide a\ncomputationally efficient Bayesian inference framework based on Hamiltonian\nMonte Carlo for coalescent process models. Moreover, we show that by splitting\nthe Hamiltonian function we can further improve the efficiency of this\napproach. Using several simulated and real datasets, we show that our method\nprovides accurate estimates of population size dynamics and is substantially\nfaster than alternative methods based on elliptical slice sampler and\nMetropolis-adjusted Langevin algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 29 Nov 2014 21:45:18 GMT"}], "update_date": "2015-07-23", "authors_parsed": [["Lan", "Shiwei", ""], ["Palacios", "Julia A.", ""], ["Karcher", "Michael", ""], ["Minin", "Vladimir N.", ""], ["Shahbaba", "Babak", ""]]}, {"id": "1412.0436", "submitter": "Luis Torgo", "authors": "Luis Torgo", "title": "An Infra-Structure for Performance Estimation and Experimental\n  Comparison of Predictive Models in R", "comments": "Updated to version 1.0.2 of the R package. Added a small section on\n  package installation. Made explicit the reference to the R package version\n  number within the document", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.LG cs.SE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes an infra-structure provided by the R package\nperformanceEstimation that allows to estimate the predictive performance of\ndifferent approaches (workflows) to predictive tasks. The infra-structure is\ngeneric in the sense that it can be used to estimate the values of any\nperformance metrics, for any workflow on different predictive tasks, namely,\nclassification, regression and time series tasks. The package also includes\nseveral standard workflows that allow users to easily set up their experiments\nlimiting the amount of work and information they need to provide. The overall\ngoal of the infra-structure provided by our package is to facilitate the task\nof estimating the predictive performance of different modeling approaches to\npredictive tasks in the R environment.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 11:35:47 GMT"}, {"version": "v2", "created": "Sat, 6 Dec 2014 18:13:14 GMT"}, {"version": "v3", "created": "Thu, 18 Jun 2015 09:40:18 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2015 15:03:45 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Torgo", "Luis", ""]]}, {"id": "1412.0561", "submitter": "Joshua Habiger", "authors": "Joshua D Habiger", "title": "Multiple Test Functions and Adjusted p-Values for Test Statistics with\n  Discrete Distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The randomized $p$-value, (nonrandomized) mid-$p$-value and abstract\nrandomized $p$-value have all been recommended for testing a null hypothesis\nwhenever the test statistic has a discrete distribution. This paper provides a\nunifying framework for these approaches and extends it to the multiple testing\nsetting. In particular, multiplicity adjusted versions of the aforementioned\n$p$-values and multiple test functions are developed. It is demonstrated that,\nwhenever the usual nonrandomized and randomized decisions to reject or retain\nthe null hypothesis may differ, the (adjusted) abstract randomized $p$-value\nand test function should be reported, especially when the number of tests is\nlarge. It is shown that the proposed approach dominates the traditional\nrandomized and nonrandomized approaches in terms of bias and variability. Tools\nfor plotting adjusted abstract randomized $p$-values and for computing multiple\ntest functions are developed. Examples are used to illustrate the method and to\nmotivate a new type of multiplicity adjusted mid-$p$-value.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 17:43:15 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Habiger", "Joshua D", ""]]}, {"id": "1412.1605", "submitter": "Anatoli Juditsky B.", "authors": "Anatoli Juditsky and Arkadi Nemirovski", "title": "On sequential hypotheses testing via convex optimization", "comments": "arXiv admin note: substantial text overlap with arXiv:1311.6765", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach to sequential testing which is an adaptive\n(on-line) extension of the (off-line) framework developed in [10]. It relies\nupon testing of pairs of hypotheses in the case where each hypothesis states\nthat the vector of parameters underlying the dis- tribution of observations\nbelongs to a convex set. The nearly optimal under appropriate conditions test\nis yielded by a solution to an efficiently solvable convex optimization prob-\nlem. The proposed methodology can be seen as a computationally friendly\nreformulation of the classical sequential testing.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 10:11:03 GMT"}, {"version": "v2", "created": "Fri, 24 Feb 2017 14:57:52 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Juditsky", "Anatoli", ""], ["Nemirovski", "Arkadi", ""]]}, {"id": "1412.1684", "submitter": "Yang Feng", "authors": "Diego Franco Saldana, Yi Yu, and Yang Feng", "title": "How Many Communities Are There?", "comments": "26 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic blockmodels and variants thereof are among the most widely used\napproaches to community detection for social networks and relational data. A\nstochastic blockmodel partitions the nodes of a network into disjoint sets,\ncalled communities. The approach is inherently related to clustering with\nmixture models; and raises a similar model selection problem for the number of\ncommunities. The Bayesian information criterion (BIC) is a popular solution,\nhowever, for stochastic blockmodels, the conditional independence assumption\ngiven the communities of the endpoints among different edges is usually\nviolated in practice. In this regard, we propose composite likelihood BIC\n(CL-BIC) to select the number of communities, and we show it is robust against\npossible misspecifications in the underlying stochastic blockmodel assumptions.\nWe derive the requisite methodology and illustrate the approach using both\nsimulated and real data. Supplementary materials containing the relevant\ncomputer code are available online.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 14:47:47 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 18:56:30 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Saldana", "Diego Franco", ""], ["Yu", "Yi", ""], ["Feng", "Yang", ""]]}, {"id": "1412.1735", "submitter": "Elias Chaibub Neto", "authors": "E. Chaibub Neto", "title": "Speeding up bootstrap computations: a vectorized implementation for\n  statistics based on sample moments", "comments": "9 pages, 3 figures; changed the title", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we propose a vectorized implementation of the non-parametric\nbootstrap for statistics based on sample moments. Basically, we adopt the\nmultinomial sampling formulation of the non-parametric bootstrap, and compute\nbootstrap replications of sample moment statistics by simply weighting the\nobserved data according to multinomial counts, instead of evaluating the\nstatistic on a re-sampled version of the observed data. Using this formulation\nwe can generate a matrix of bootstrap weights and compute the entire vector of\nbootstrap replications with a few matrix multiplications. Vectorization is\nparticularly important for matrix-oriented programming languages such as R,\nwhere matrix/vector calculations tend to be faster than scalar operations\nimplemented in a loop. We illustrate the gain in computational speed achieved\nby the vectorized implementation in real and simulated data sets, when\nbootstrapping Pearson's sample correlation coefficient.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 17:12:31 GMT"}, {"version": "v2", "created": "Thu, 11 Dec 2014 17:48:30 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Neto", "E. Chaibub", ""]]}, {"id": "1412.2129", "submitter": "Diana Cai", "authors": "Diana Cai and Nathanael Ackerman and Cameron Freer", "title": "An iterative step-function estimator for graphons", "comments": "27 pages, 8 figures. Updated and expanded throughout", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exchangeable graphs arise via a sampling procedure from measurable functions\nknown as graphons. A natural estimation problem is how well we can recover a\ngraphon given a single graph sampled from it. One general framework for\nestimating a graphon uses step-functions obtained by partitioning the nodes of\nthe graph according to some clustering algorithm. We propose an iterative\nstep-function estimator (ISFE) that, given an initial partition, iteratively\nclusters nodes based on their edge densities with respect to the previous\niteration's partition. We analyze ISFE and demonstrate its performance in\ncomparison with other graphon estimation techniques.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 20:59:21 GMT"}, {"version": "v2", "created": "Tue, 12 May 2015 00:18:50 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Cai", "Diana", ""], ["Ackerman", "Nathanael", ""], ["Freer", "Cameron", ""]]}, {"id": "1412.2183", "submitter": "Pengfei Zang", "authors": "Richard A. Davis, Pengfei Zang, Tian Zheng", "title": "Reduced-Rank Covariance Estimation in Vector Autoregressive Modeling", "comments": "36 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider reduced-rank modeling of the white noise covariance matrix in a\nlarge dimensional vector autoregressive (VAR) model. We first propose the\nreduced-rank covariance estimator under the setting where independent\nobservations are available. We derive the reduced-rank estimator based on a\nlatent variable model for the vector observation and give the analytical form\nof its maximum likelihood estimate. Simulation results show that the\nreduced-rank covariance estimator outperforms two competing covariance\nestimators for estimating large dimensional covariance matrices from\nindependent observations. Then we describe how to integrate the proposed\nreduced-rank estimator into the fitting of large dimensional VAR models, where\nwe consider two scenarios that require different model fitting procedures. In\nthe VAR modeling context, our reduced-rank covariance estimator not only\nprovides interpretable descriptions of the dependence structure of VAR\nprocesses but also leads to improvement in model-fitting and forecasting over\nunrestricted covariance estimators. Two real data examples are presented to\nillustrate these fitting procedures.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 23:53:40 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Davis", "Richard A.", ""], ["Zang", "Pengfei", ""], ["Zheng", "Tian", ""]]}, {"id": "1412.2291", "submitter": "Konstantin Usevich", "authors": "Konstantin Usevich and Ivan Markovsky", "title": "Adjusted least squares fitting of algebraic hypersurfaces", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": "10.1016/j.laa.2015.07.023", "report-no": null, "categories": "stat.CO cs.CG cs.CV math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of fitting a set of points in Euclidean space by an\nalgebraic hypersurface. We assume that points on a true hypersurface, described\nby a polynomial equation, are corrupted by zero mean independent Gaussian\nnoise, and we estimate the coefficients of the true polynomial equation. The\nadjusted least squares estimator accounts for the bias present in the ordinary\nleast squares estimator. The adjusted least squares estimator is based on\nconstructing a quasi-Hankel matrix, which is a bias-corrected matrix of\nmoments. For the case of unknown noise variance, the estimator is defined as a\nsolution of a polynomial eigenvalue problem. In this paper, we present new\nresults on invariance properties of the adjusted least squares estimator and an\nimproved algorithm for computing the estimator for an arbitrary set of\nmonomials in the polynomial equation.\n", "versions": [{"version": "v1", "created": "Sat, 6 Dec 2014 22:22:33 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2015 17:00:19 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Usevich", "Konstantin", ""], ["Markovsky", "Ivan", ""]]}, {"id": "1412.2844", "submitter": "Quentin Stout", "authors": "Janis Hardwick and Quentin F. Stout", "title": "Optimal Reduced Isotonic Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Isotonic regression is a shape-constrained nonparametric regression in which\nthe regression is an increasing step function. For $n$ data points, the number\nof steps in the isotonic regression may be as large as $n$. As a result,\nstandard isotonic regression has been criticized as overfitting the data or\nmaking the representation too complicated. So-called \"reduced\" isotonic\nregression constrains the outcome to be a specified number of steps $b$, $b\n\\leq n$. However, because the previous algorithms for finding the reduced $L_2$\nregression took $\\Theta(n+bm^2)$ time, where $m$ is the number of steps of the\nunconstrained isotonic regression, researchers felt that the algorithms were\ntoo slow and instead used approximations. Other researchers had results that\nwere approximations because they used a greedy top-down approach. Here we give\nan algorithm to find an exact solution in $\\Theta(n+bm)$ time, and a simpler\nalgorithm taking $\\Theta(n+b m \\log m)$ time. These algorithms also determine\noptimal $k$-means clustering of weighted 1-dimensional data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 03:18:48 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Hardwick", "Janis", ""], ["Stout", "Quentin F.", ""]]}, {"id": "1412.2967", "submitter": "Ricardo Ehlers", "authors": "Jose A. Fioruci, Ricardo S. Ehlers, Francisco Louzada", "title": "BayesDccGarch - An Implementation of Multivariate GARCH DCC Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate GARCH models are important tools to describe the dynamics of\nmultivariate times series of financial returns. Nevertheless, these models have\nbeen much less used in practice due to the lack of reliable software. This\npaper describes the {\\tt R} package {\\bf BayesDccGarch} which was developed to\nimplement recently proposed inference procedures to estimate and compare\nmultivariate GARCH models allowing for asymmetric and heavy tailed\ndistributions.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 14:10:01 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Fioruci", "Jose A.", ""], ["Ehlers", "Ricardo S.", ""], ["Louzada", "Francisco", ""]]}, {"id": "1412.3013", "submitter": "Radford M. Neal", "authors": "Alexander Y. Shestopaloff and Radford M. Neal", "title": "Efficient Bayesian inference for stochastic volatility models with\n  ensemble MCMC methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce efficient ensemble Markov Chain Monte Carlo\n(MCMC) sampling methods for Bayesian computations in the univariate stochastic\nvolatility model. We compare the performance of our ensemble MCMC methods with\nan improved version of a recent sampler of Kastner and Fruwirth-Schnatter\n(2014). We show that ensemble samplers are more efficient than this state of\nthe art sampler by a factor of about 3.1, on a data set simulated from the\nstochastic volatility model. This performance gain is achieved without the\nensemble MCMC sampler relying on the assumption that the latent process is\nlinear and Gaussian, unlike the sampler of Kastner and Fruwirth-Schnatter.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 16:35:10 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Shestopaloff", "Alexander Y.", ""], ["Neal", "Radford M.", ""]]}, {"id": "1412.3078", "submitter": "Jun Wei Ng", "authors": "Jun Wei Ng and Marc Peter Deisenroth", "title": "Hierarchical Mixture-of-Experts Model for Large-Scale Gaussian Process\n  Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a practical and scalable Gaussian process model for large-scale\nnonlinear probabilistic regression. Our mixture-of-experts model is\nconceptually simple and hierarchically recombines computations for an overall\napproximation of a full Gaussian process. Closed-form and distributed\ncomputations allow for efficient and massive parallelisation while keeping the\nmemory consumption small. Given sufficient computing resources, our model can\nhandle arbitrarily large data sets, without explicit sparse approximations. We\nprovide strong experimental evidence that our model can be applied to large\ndata sets of sizes far beyond millions. Hence, our model has the potential to\nlay the foundation for general large-scale Gaussian process research.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 20:03:06 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Ng", "Jun Wei", ""], ["Deisenroth", "Marc Peter", ""]]}, {"id": "1412.3501", "submitter": "Ajay Jasra", "authors": "Alex Beskos, Dan Crisan, Ajay Jasra, Kengo Kamatani, Yan Zhou", "title": "A Stable Particle Filter in High-Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the numerical approximation of the filtering problem in high\ndimensions, that is, when the hidden state lies in $\\mathbb{R}^d$ with $d$\nlarge. For low dimensional problems, one of the most popular numerical\nprocedures for consistent inference is the class of approximations termed\nparticle filters or sequential Monte Carlo methods. However, in high\ndimensions, standard particle filters (e.g. the bootstrap particle filter) can\nhave a cost that is exponential in $d$ for the algorithm to be stable in an\nappropriate sense. We develop a new particle filter, called the\n\\emph{space-time particle filter}, for a specific family of state-space models\nin discrete time. This new class of particle filters provide consistent Monte\nCarlo estimates for any fixed $d$, as do standard particle filters. Moreover,\nwe expect that the state-space particle filter will scale much better with $d$\nthan the standard filter. We illustrate this analytically for a model of a\nsimple i.i.d. structure and one of a Markovian structure in the $d$-dimensional\nspace-direction, when we show that the algorithm exhibits certain stability\nproperties as $d$ increases at a cost $\\mathcal{O}(nNd^2)$, where $n$ is the\ntime parameter and $N$ is the number of Monte Carlo samples, that are fixed and\nindependent of $d$. Similar results are expected to hold, under a more general\nstructure than the i.i.d.~one. independently of the dimension. Our theoretical\nresults are also supported by numerical simulations on practical models of\ncomplex structures. The results suggest that it is indeed possible to tackle\nsome high dimensional filtering problems using the space-time particle filter\nthat standard particle filters cannot handle.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 00:03:57 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Beskos", "Alex", ""], ["Crisan", "Dan", ""], ["Jasra", "Ajay", ""], ["Kamatani", "Kengo", ""], ["Zhou", "Yan", ""]]}, {"id": "1412.3510", "submitter": "Mark Tygert", "authors": "Arthur Szlam, Yuval Kluger, and Mark Tygert", "title": "An implementation of a randomized algorithm for principal component\n  analysis", "comments": "13 pages, 4 figures", "journal-ref": "ACM TOMS, 43(3): 28:1-28:14, 2016", "doi": null, "report-no": null, "categories": "stat.CO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed intense development of randomized methods for\nlow-rank approximation. These methods target principal component analysis (PCA)\nand the calculation of truncated singular value decompositions (SVD). The\npresent paper presents an essentially black-box, fool-proof implementation for\nMathworks' MATLAB, a popular software platform for numerical computation. As\nillustrated via several tests, the randomized algorithms for low-rank\napproximation outperform or at least match the classical techniques (such as\nLanczos iterations) in basically all respects: accuracy, computational\nefficiency (both speed and memory usage), ease-of-use, parallelizability, and\nreliability. However, the classical procedures remain the methods of choice for\nestimating spectral norms, and are far superior for calculating the least\nsingular values and corresponding singular vectors (or singular subspaces).\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 00:52:41 GMT"}], "update_date": "2017-01-02", "authors_parsed": [["Szlam", "Arthur", ""], ["Kluger", "Yuval", ""], ["Tygert", "Mark", ""]]}, {"id": "1412.3565", "submitter": "David Robinson", "authors": "David Robinson", "title": "broom: An R Package for Converting Statistical Analysis Objects Into\n  Tidy Data Frames", "comments": "A reproducible version of the manuscript can be found at\n  https://github.com/dgrtwo/broom_paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The concept of \"tidy data\" offers a powerful framework for structuring data\nto ease manipulation, modeling and visualization. However, most R functions,\nboth those built-in and those found in third-party packages, produce output\nthat is not tidy, and that is therefore difficult to reshape, recombine, and\notherwise manipulate. Here I introduce the broom package, which turns the\noutput of model objects into tidy data frames that are suited to further\nanalysis, manipulation, and visualization with input-tidy tools. Broom defines\nthe \"tidy\", \"augment\" and \"glance\" generics, which arrange a model into three\nlevels of tidy output respectively: the component level, the observation level,\nand the model level. I provide examples to demonstrate how these generics work\nwith tidy tools to allow analysis and modeling of data that is divided into\nsubsets, to recombine results from bootstrap replicates, and to perform\nsimulations that investigate the effect of varying input parameters.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 08:07:03 GMT"}, {"version": "v2", "created": "Fri, 19 Dec 2014 18:32:07 GMT"}], "update_date": "2014-12-22", "authors_parsed": [["Robinson", "David", ""]]}, {"id": "1412.3617", "submitter": "Paul Fearnhead", "authors": "Kaylea Haynes, Idris A. Eckley and Paul Fearnhead", "title": "Efficient penalty search for multiple changepoint problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the multiple changepoint setting, various search methods have been\nproposed which involve optimising either a constrained or penalised cost\nfunction over possible numbers and locations of changepoints using dynamic\nprogramming. Such methods are typically computationally intensive. Recent work\nin the penalised optimisation setting has focussed on developing a\npruning-based approach which gives an improved computational cost that, under\ncertain conditions, is linear in the number of data points. Such an approach\nnaturally requires the specification of a penalty to avoid under/over-fitting.\nWork has been undertaken to identify the appropriate penalty choice for data\ngenerating processes with known distributional form, but in many applications\nthe model assumed for the data is not correct and these penalty choices are not\nalways appropriate. Consequently it is desirable to have an approach that\nenables us to compare segmentations for different choices of penalty. To this\nend we present a method to obtain optimal changepoint segmentations of data\nsequences for all penalty values across a continuous range. This permits an\nevaluation of the various segmentations to identify a suitably parsimonious\npenalty choice. The computational complexity of this approach can be linear in\nthe number of data points and linear in the difference between the number of\nchangepoints in the optimal segmentations for the smallest and largest penalty\nvalues. This can be orders of magnitude faster than alternative approaches that\nfind optimal segmentations for a range of the number of changepoints.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 11:49:47 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Haynes", "Kaylea", ""], ["Eckley", "Idris A.", ""], ["Fearnhead", "Paul", ""]]}, {"id": "1412.3779", "submitter": "Adrien Todeschini", "authors": "Adrien Todeschini, Fran\\c{c}ois Caron, Marc Fuentes, Pierrick Legrand\n  and Pierre Del Moral", "title": "Biips: Software for Bayesian Inference with Interacting Particle Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biips is a software platform for automatic Bayesian inference with\ninteracting particle systems. Biips allows users to define their statistical\nmodel in the probabilistic programming BUGS language, as well as to add custom\nfunctions or samplers within this language. Then it runs sequential Monte Carlo\nbased algorithms (particle filters, particle independent Metropolis-Hastings,\nparticle marginal Metropolis-Hastings) in a black-box manner so that to\napproximate the posterior distribution of interest as well as the marginal\nlikelihood. The software is developed in C++ with interfaces with the softwares\nR, Matlab and Octave.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 19:51:34 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Todeschini", "Adrien", ""], ["Caron", "Fran\u00e7ois", ""], ["Fuentes", "Marc", ""], ["Legrand", "Pierrick", ""], ["Del Moral", "Pierre", ""]]}, {"id": "1412.4128", "submitter": "Mu Zhu", "authors": "W. James Murdoch and Mu Zhu", "title": "Expanded Alternating Optimization of Nonconvex Functions with\n  Applications to Matrix Factorization and Penalized Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general technique for improving alternating optimization (AO) of\nnonconvex functions. Starting from the solution given by AO, we conduct another\nsequence of searches over subspaces that are both meaningful to the\noptimization problem at hand and different from those used by AO. To\ndemonstrate the utility of our approach, we apply it to the matrix\nfactorization (MF) algorithm for recommender systems and the coordinate descent\nalgorithm for penalized regression (PR), and show meaningful improvements using\nboth real-world (for MF) and simulated (for PR) data sets. Moreover, we\ndemonstrate for MF that, by constructing search spaces customized to the given\ndata set, we can significantly increase the convergence rate of our technique.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 21:04:15 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Murdoch", "W. James", ""], ["Zhu", "Mu", ""]]}, {"id": "1412.4452", "submitter": "Shujun Bi", "authors": "Shujun Bi, Xiaolan Liu and Shaohua Pan", "title": "Exact penalty decomposition method for zero-norm minimization based on\n  MPEC formulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We reformulate the zero-norm minimization problem as an equivalent\nmathematical program with equilibrium constraints and establish that its\npenalty problem, induced by adding the complementarity constraint to the\nobjective, is exact. Then, by the special structure of the exact penalty\nproblem, we propose a decomposition method that can seek a global optimal\nsolution of the zero-norm minimization problem under the null space condition\nin [M. A. Khajehnejad et al. IEEE Trans. Signal. Process., 59(2011), pp.\n1985-2001] by solving a finite number of weighted $l_1$-norm minimization\nproblems. To handle the weighted $l_1$-norm subproblems, we develop a partial\nproximal point algorithm where the subproblems may be solved approximately with\nthe limited memory BFGS (L-BFGS) or the semismooth Newton-CG. Finally, we apply\nthe exact penalty decomposition method with the weighted $l_1$-norm subproblems\nsolved by combining the L-BFGS with the semismooth Newton-CG to several types\nof sparse optimization problems, and compare its performance with that of the\npenalty decomposition method [Z. Lu and Y. Zhang, SIAM J. Optim., 23(2013), pp.\n2448- 2478], the iterative support detection method [Y. L. Wang and W. T. Yin,\nSIAM J. Sci. Comput., 3(2010), pp. 462-491] and the state-of-the-art code\nFPC_AS [Z. W. Wen et al. SIAM J. Sci. Comput., 32(2010), pp. 1832-1857].\nNumerical comparisons indicate that the proposed method is very efficient in\nterms of the recoverability and the required computing time.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 03:18:34 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Bi", "Shujun", ""], ["Liu", "Xiaolan", ""], ["Pan", "Shaohua", ""]]}, {"id": "1412.4459", "submitter": "Ajay Jasra", "authors": "Alex Beskos, Ajay Jasra, Ege Muzaffer, Andrew Stuart", "title": "Sequential Monte Carlo Methods for Bayesian Elliptic Inverse Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we consider a Bayesian inverse problem associated to elliptic\npartial differential equations (PDEs) in two and three dimensions. This class\nof inverse problems is important in applications such as hydrology, but the\ncomplexity of the link function between unknown field and measurements can make\nit difficult to draw inference from the associated posterior. We prove that for\nthis inverse problem a basic SMC method has a Monte Carlo rate of convergence\nwith constants which are independent of the dimension of the discretization of\nthe problem; indeed convergence of the SMC method is established in a function\nspace setting. We also develop an enhancement of the sequential Monte Carlo\n(SMC) methods for inverse problems which were introduced in \\cite{kantas}; the\nenhancement is designed to deal with the additional complexity of this elliptic\ninverse problem. The efficacy of the methodology, and its desirable theoretical\nproperties, are demonstrated on numerical examples in both two and three\ndimensions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 04:28:25 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Beskos", "Alex", ""], ["Jasra", "Ajay", ""], ["Muzaffer", "Ege", ""], ["Stuart", "Andrew", ""]]}, {"id": "1412.4825", "submitter": "Alireza Mahani", "authors": "Alireza S. Mahani, Mansour T.A. Sharabiani", "title": "Efficient SIMD RNG for Varying-Parameter Streams: C++ Class BatchRNG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single-Instruction, Multiple-Data (SIMD) random number generators (RNGs) take\nadvantage of vector units to offer significant performance gain over\nnon-vectorized libraries, but they often rely on batch production of deviates\nfrom distributions with fixed parameters. In many statistical applications such\nas Gibbs sampling, parameters of sampled distributions change from one\niteration to the next, requiring that random deviates be generated\none-at-a-time. This situation can render vectorized RNGs inefficient, and even\ninferior to their scalar counterparts. The C++ class BatchRNG uses buffers of\nbase distributions such uniform, Gaussian and exponential to take advantage of\nvector units while allowing for sequences of deviates to be generated with\nvarying parameters. These small buffers are consumed and replenished as needed\nduring a program execution. Performance tests using Intel Vector Statistical\nLibrary (VSL) on various probability distributions illustrates the\neffectiveness of the proposed batching strategy.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 22:27:57 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Mahani", "Alireza S.", ""], ["Sharabiani", "Mansour T. A.", ""]]}, {"id": "1412.4845", "submitter": "Ernest Ryu", "authors": "Ernest K. Ryu and Stephen P. Boyd", "title": "Adaptive Importance Sampling via Stochastic Convex Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the variance of the Monte Carlo estimator that is importance\nsampled from an exponential family is a convex function of the natural\nparameter of the distribution. With this insight, we propose an adaptive\nimportance sampling algorithm that simultaneously improves the choice of\nsampling distribution while accumulating a Monte Carlo estimate. Exploiting\nconvexity, we prove that the method's unbiased estimator has variance that is\nasymptotically optimal over the exponential family.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 00:30:36 GMT"}, {"version": "v2", "created": "Fri, 9 Jan 2015 00:44:09 GMT"}], "update_date": "2015-01-12", "authors_parsed": [["Ryu", "Ernest K.", ""], ["Boyd", "Stephen P.", ""]]}, {"id": "1412.4869", "submitter": "Aki Vehtari", "authors": "Aki Vehtari, Andrew Gelman, Tuomas Sivula, Pasi Jyl\\\"anki, Dustin\n  Tran, Swupnil Sahai, Paul Blomstedt, John P. Cunningham, David Schiminovich,\n  Christian Robert", "title": "Expectation propagation as a way of life: A framework for Bayesian\n  inference on partitioned data", "comments": "Minor revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common divide-and-conquer approach for Bayesian computation with big data\nis to partition the data, perform local inference for each piece separately,\nand combine the results to obtain a global posterior approximation. While being\nconceptually and computationally appealing, this method involves the\nproblematic need to also split the prior for the local inferences; these\nweakened priors may not provide enough regularization for each separate\ncomputation, thus eliminating one of the key advantages of Bayesian methods. To\nresolve this dilemma while still retaining the generalizability of the\nunderlying local inference method, we apply the idea of expectation propagation\n(EP) as a framework for distributed Bayesian inference. The central idea is to\niteratively update approximations to the local likelihoods given the state of\nthe other approximations and the prior. The present paper has two roles: we\nreview the steps that are needed to keep EP algorithms numerically stable, and\nwe suggest a general approach, inspired by EP, for approaching data\npartitioning problems in a way that achieves the computational benefits of\nparallelism while allowing each local update to make use of relevant\ninformation from the other sites. In addition, we demonstrate how the method\ncan be applied in a hierarchical context to make use of partitioning of both\ndata and parameters. The paper describes a general algorithmic framework,\nrather than a specific algorithm, and presents an example implementation for\nit.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 03:47:38 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 13:06:17 GMT"}, {"version": "v3", "created": "Sat, 10 Mar 2018 21:52:41 GMT"}, {"version": "v4", "created": "Tue, 2 Jul 2019 19:33:01 GMT"}, {"version": "v5", "created": "Sat, 30 Nov 2019 14:11:25 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Vehtari", "Aki", ""], ["Gelman", "Andrew", ""], ["Sivula", "Tuomas", ""], ["Jyl\u00e4nki", "Pasi", ""], ["Tran", "Dustin", ""], ["Sahai", "Swupnil", ""], ["Blomstedt", "Paul", ""], ["Cunningham", "John P.", ""], ["Schiminovich", "David", ""], ["Robert", "Christian", ""]]}, {"id": "1412.5122", "submitter": "Pavlo Mozharovskyi", "authors": "Xiaohui Liu, Karl Mosler, Pavlo Mozharovskyi", "title": "Fast computation of Tukey trimmed regions and median in dimension $p>2$", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Given data in $\\mathbb{R}^{p}$, a Tukey $\\kappa$-trimmed region is the set of\nall points that have at least Tukey depth $\\kappa$ w.r.t. the data. As they are\nvisual, affine equivariant and robust, Tukey regions are useful tools in\nnonparametric multivariate analysis. While these regions are easily defined and\ninterpreted, their practical use in applications has been impeded so far by the\nlack of efficient computational procedures in dimension $p > 2$. We construct\ntwo novel algorithms to compute a Tukey $\\kappa$-trimmed region, a na\\\"{i}ve\none and a more sophisticated one that is much faster than known algorithms.\nFurther, a strict bound on the number of facets of a Tukey region is derived.\nIn a large simulation study the novel fast algorithm is compared with the\nna\\\"{i}ve one, which is slower and by construction exact, yielding in every\ncase the same correct results. Finally, the approach is extended to an\nalgorithm that calculates the innermost Tukey region and its barycenter, the\nTukey median.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 18:56:04 GMT"}, {"version": "v2", "created": "Wed, 6 Dec 2017 11:58:37 GMT"}, {"version": "v3", "created": "Thu, 8 Nov 2018 18:02:02 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Liu", "Xiaohui", ""], ["Mosler", "Karl", ""], ["Mozharovskyi", "Pavlo", ""]]}, {"id": "1412.5250", "submitter": "Ines Wilms", "authors": "William B. Nicholson, Ines Wilms, Jacob Bien, David S. Matteson", "title": "High Dimensional Forecasting via Interpretable Vector Autoregression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vector autoregression (VAR) is a fundamental tool for modeling multivariate\ntime series. However, as the number of component series is increased, the VAR\nmodel becomes overparameterized. Several authors have addressed this issue by\nincorporating regularized approaches, such as the lasso in VAR estimation.\nTraditional approaches address overparameterization by selecting a low lag\norder, based on the assumption of short range dependence, assuming that a\nuniversal lag order applies to all components. Such an approach constrains the\nrelationship between the components and impedes forecast performance. The\nlasso-based approaches work much better in high-dimensional situations but do\nnot incorporate the notion of lag order selection.\n  We propose a new class of hierarchical lag structures (HLag) that embed the\nnotion of lag selection into a convex regularizer. The key modeling tool is a\ngroup lasso with nested groups which guarantees that the sparsity pattern of\nlag coefficients honors the VAR's ordered structure. The HLag framework offers\nthree structures, which allow for varying levels of flexibility. A simulation\nstudy demonstrates improved performance in forecasting and lag order selection\nover previous approaches, and a macroeconomic application further highlights\nforecasting improvements as well as HLag's convenient, interpretable output.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 03:36:06 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 16:55:02 GMT"}, {"version": "v3", "created": "Sat, 8 Sep 2018 17:08:29 GMT"}, {"version": "v4", "created": "Mon, 7 Sep 2020 18:18:55 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Nicholson", "William B.", ""], ["Wilms", "Ines", ""], ["Bien", "Jacob", ""], ["Matteson", "David S.", ""]]}, {"id": "1412.5492", "submitter": "Matthew Parno", "authors": "Matthew Parno and Youssef Marzouk", "title": "Transport map accelerated Markov chain Monte Carlo", "comments": null, "journal-ref": "SIAM/ASA Journal on Uncertainty Quantification. Vol. 6, No. 2, pp.\n  645-682 (2018)", "doi": "10.1137/17M1134640", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new framework for efficient sampling from complex probability\ndistributions, using a combination of optimal transport maps and the\nMetropolis-Hastings rule. The core idea is to use continuous transportation to\ntransform typical Metropolis proposal mechanisms (e.g., random walks, Langevin\nmethods) into non-Gaussian proposal distributions that can more effectively\nexplore the target density. Our approach adaptively constructs a lower\ntriangular transport map-an approximation of the Knothe-Rosenblatt\nrearrangement-using information from previous MCMC states, via the solution of\nan optimization problem. This optimization problem is convex regardless of the\nform of the target distribution. It is solved efficiently using a Newton method\nthat requires no gradient information from the target probability distribution;\nthe target distribution is instead represented via samples. Sequential updates\nenable efficient and parallelizable adaptation of the map even for large\nnumbers of samples. We show that this approach uses inexact or truncated maps\nto produce an adaptive MCMC algorithm that is ergodic for the exact target\ndistribution. Numerical demonstrations on a range of parameter inference\nproblems show order-of-magnitude speedups over standard MCMC techniques,\nmeasured by the number of effectively independent samples produced per target\ndensity evaluation and per unit of wallclock time.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 17:30:05 GMT"}, {"version": "v2", "created": "Fri, 19 Dec 2014 17:39:55 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2015 16:19:32 GMT"}, {"version": "v4", "created": "Wed, 23 Aug 2017 19:32:39 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Parno", "Matthew", ""], ["Marzouk", "Youssef", ""]]}, {"id": "1412.5565", "submitter": "Lawrence Bardwell", "authors": "Lawrence Bardwell and Paul Fearnhead", "title": "Bayesian detection of abnormal segments in multiple time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel Bayesian approach to analysing multiple time-series with\nthe aim of detecting abnormal regions. These are regions where the properties\nof the data change from some normal or baseline behaviour. We allow for the\npossibility that such changes will only be present in a, potentially small,\nsubset of the time-series. We develop a general model for this problem, and\nshow how it is possible to accurately and efficiently perform Bayesian\ninference, based upon recursions that enable independent sampling from the\nposterior distribution. A motivating application for this problem comes from\ndetecting copy number variation (CNVs), using data from multiple individuals.\nPooling information across individuals can increase the power of detecting\nCNVs, but often a specific CNV will only be present in a small subset of the\nindividuals. We evaluate the Bayesian method on both simulated and real CNV\ndata, and give evidence that this approach is more accurate than a recently\nproposed method for analysing such data.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 20:33:58 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2015 12:05:40 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Bardwell", "Lawrence", ""], ["Fearnhead", "Paul", ""]]}, {"id": "1412.6368", "submitter": "Cl\\'ement Walter", "authors": "Cl\\'ement Walter", "title": "Point Process-based Monte Carlo estimation", "comments": "13 pages + 4 pages of appendix, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the issue of estimating the expectation of a real-valued\nrandom variable of the form $X = g(\\mathbf{U})$ where $g$ is a deterministic\nfunction and $\\mathbf{U}$ can be a random finite- or infinite-dimensional\nvector. Using recent results on rare event simulation, we propose a unified\nframework for dealing with both probability and mean estimation for such random\nvariables, \\emph{i.e.} linking algorithms such as Tootsie Pop Algorithm (TPA)\nor Last Particle Algorithm with nested sampling. Especially, it extends nested\nsampling as follows: first the random variable $X$ does not need to be bounded\nany more: it gives the principle of an ideal estimator with an infinite number\nof terms that is unbiased and always better than a classical Monte Carlo\nestimator -- in particular it has a finite variance as soon as there exists $k\n\\in \\mathbb{R} > 1$ such that $\\operatorname{E}[X^k] < \\infty$. Moreover we\naddress the issue of nested sampling termination and show that a random\ntruncation of the sum can preserve unbiasedness while increasing the variance\nonly by a factor up to 2 compared to the ideal case. We also build an unbiased\nestimator with fixed computational budget which supports a Central Limit\nTheorem and discuss parallel implementation of nested sampling, which can\ndramatically reduce its computational cost. Finally we extensively study the\ncase where $X$ is heavy-tailed.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 15:09:59 GMT"}, {"version": "v2", "created": "Thu, 8 Jan 2015 08:54:23 GMT"}, {"version": "v3", "created": "Wed, 21 Jan 2015 15:48:52 GMT"}, {"version": "v4", "created": "Tue, 12 May 2015 11:55:41 GMT"}, {"version": "v5", "created": "Wed, 9 Sep 2015 10:02:52 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Walter", "Cl\u00e9ment", ""]]}, {"id": "1412.6370", "submitter": "Jan Palczewski", "authors": "Blazej Miasojedow, Wojciech Niemiro, Jan Palczewski, Wojciech Rejchel", "title": "Adaptive Monte Carlo Maximum Likelihood", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-18781-5_14", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Monte Carlo approximations to the maximum likelihood estimator in\nmodels with intractable norming constants. This paper deals with adaptive Monte\nCarlo algorithms, which adjust control parameters in the course of simulation.\nWe examine asymptotics of adaptive importance sampling and a new algorithm,\nwhich uses resampling and MCMC. This algorithm is designed to reduce problems\nwith degeneracy of importance weights. Our analysis is based on martingale\nlimit theorems. We also describe how adaptive maximization algorithms of\nNewton-Raphson type can be combined with the resampling techniques. The paper\nincludes results of a small scale simulation study in which we compare the\nperformance of adaptive and non-adaptive Monte Carlo maximum likelihood\nalgorithms.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 15:12:37 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Miasojedow", "Blazej", ""], ["Niemiro", "Wojciech", ""], ["Palczewski", "Jan", ""], ["Rejchel", "Wojciech", ""]]}, {"id": "1412.6675", "submitter": "Xiaoyue Cheng", "authors": "Xiaoyue Cheng, Dianne Cook, Heike Hofmann", "title": "Enabling Interactivity on Displays of Multivariate Time Series and\n  Longitudinal Data", "comments": "28 pages, 12 figures, 5 tables. Submitted for journal publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Temporal data is information measured in the context of time. This contextual\nstructure provides components that need to be explored to understand the data\nand that can form the basis of interactions applied to the plots. In\nmultivariate time series we expect to see temporal dependence, long term and\nseasonal trends and cross-correlations. In longitudinal data we also expect\nwithin and between subject dependence. Time series and longitudinal data,\nalthough analyzed differently, are often plotted using similar displays. We\nprovide a taxonomy of interactions on plots that can enable exploring temporal\ncomponents of these data types, and describe how to build these interactions\nusing data transformations. Because temporal data is often accompanied other\ntypes of data we also describe how to link the temporal plots with other\ndisplays of data. The ideas are conceptualized into a data pipeline for\ntemporal data, and implemented into the R package cranvas. This package\nprovides many different types of interactive graphics that can be used together\nto explore data or diagnose a model fit.\n", "versions": [{"version": "v1", "created": "Sat, 20 Dec 2014 17:49:40 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Cheng", "Xiaoyue", ""], ["Cook", "Dianne", ""], ["Hofmann", "Heike", ""]]}, {"id": "1412.6760", "submitter": "Jim Griffin", "authors": "Jim Griffin, Krzysztof Latuszynski and Mark Steel", "title": "Individual adaptation: an adaptive MCMC scheme for variable selection\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing size of data sets has lead to variable selection in regression\nbecoming increasingly important. Bayesian approaches are attractive since they\nallow uncertainty about the choice of variables to be formally included in the\nanalysis. The application of fully Bayesian variable selection methods to large\ndata sets is computationally challenging. We describe an adaptive Markov chain\nMonte Carlo approach called Individual Adaptation which adjusts a general\nproposal to the data. We show that the algorithm is ergodic and discuss its use\nwithin parallel tempering and sequential Monte Carlo approaches. We illustrate\nthe use of the method on two data sets including a gene expression analysis\nwith 22 577 variables.\n", "versions": [{"version": "v1", "created": "Sun, 21 Dec 2014 10:29:28 GMT"}, {"version": "v2", "created": "Mon, 29 Dec 2014 07:52:32 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Griffin", "Jim", ""], ["Latuszynski", "Krzysztof", ""], ["Steel", "Mark", ""]]}, {"id": "1412.6890", "submitter": "Balasubramanian Narasimhan", "authors": "Balasubramanian Narasimhan, Daniel L. Rubin, Samuel M. Gross, Marina\n  Bendersky, Philip W. Lavori", "title": "Software for Distributed Computation on Medical Databases: A\n  Demonstration Project", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.MS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bringing together the information latent in distributed medical databases\npromises to personalize medical care by enabling reliable, stable modeling of\noutcomes with rich feature sets (including patient characteristics and\ntreatments received). However, there are barriers to aggregation of medical\ndata, due to lack of standardization of ontologies, privacy concerns,\nproprietary attitudes toward data, and a reluctance to give up control over end\nuse. Aggregation of data is not always necessary for model fitting. In models\nbased on maximizing a likelihood, the computations can be distributed, with\naggregation limited to the intermediate results of calculations on local data,\nrather than raw data. Distributed fitting is also possible for singular value\ndecomposition. There has been work on the technical aspects of shared\ncomputation for particular applications, but little has been published on the\nsoftware needed to support the \"social networking\" aspect of shared computing,\nto reduce the barriers to collaboration. We describe a set of software tools\nthat allow the rapid assembly of a collaborative computational project, based\non the flexible and extensible R statistical software and other open source\npackages, that can work across a heterogeneous collection of database\nenvironments, with full transparency to allow local officials concerned with\nprivacy protections to validate the safety of the method. We describe the\nprinciples, architecture, and successful test results for the site-stratified\nCox model and rank-k Singular Value Decomposition (SVD).\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 07:17:01 GMT"}, {"version": "v2", "created": "Fri, 10 Feb 2017 02:03:23 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Narasimhan", "Balasubramanian", ""], ["Rubin", "Daniel L.", ""], ["Gross", "Samuel M.", ""], ["Bendersky", "Marina", ""], ["Lavori", "Philip W.", ""]]}, {"id": "1412.7146", "submitter": "Andrzej  Cichocki", "authors": "Andrzej Cichocki, Sergio Cruces and Shun-Ichi Amari", "title": "Log-Determinant Divergences Revisited: Alpha--Beta and Gamma Log-Det\n  Divergences", "comments": "35 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we review and extend a family of log-det divergences for\nsymmetric positive definite (SPD) matrices and discuss their fundamental\nproperties. We show how to generate from parameterized Alpha-Beta (AB) and\nGamma Log-det divergences many well known divergences, for example, the Stein's\nloss, S-divergence, called also Jensen-Bregman LogDet (JBLD) divergence, the\nLogdet Zero (Bhattacharryya) divergence, Affine Invariant Riemannian Metric\n(AIRM) as well as some new divergences. Moreover, we establish links and\ncorrespondences among many log-det divergences and display them on alpha-beta\nplain for various set of parameters. Furthermore, this paper bridges these\ndivergences and shows also their links to divergences of multivariate and\nmultiway Gaussian distributions. Closed form formulas are derived for gamma\ndivergences of two multivariate Gaussian densities including as special cases\nthe Kullback-Leibler, Bhattacharryya, R\\'enyi and Cauchy-Schwartz divergences.\nSymmetrized versions of the log-det divergences are also discussed and\nreviewed. A class of divergences is extended to multiway divergences for\nseparable covariance (precision) matrices.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 06:22:16 GMT"}, {"version": "v2", "created": "Tue, 23 Dec 2014 14:48:13 GMT"}], "update_date": "2014-12-24", "authors_parsed": [["Cichocki", "Andrzej", ""], ["Cruces", "Sergio", ""], ["Amari", "Shun-Ichi", ""]]}, {"id": "1412.7299", "submitter": "Christopher Nemeth", "authors": "Christopher Nemeth, Chris Sherlock and Paul Fearnhead", "title": "Particle Metropolis-adjusted Langevin algorithms", "comments": "Accepted to Biometrika. Main text: 22 pages and 3 figures.\n  Supplementary material: 18 pages and 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new sampling scheme based on Langevin dynamics that is\napplicable within pseudo-marginal and particle Markov chain Monte Carlo\nalgorithms. We investigate this algorithm's theoretical properties under\nstandard asymptotics, which correspond to an increasing dimension of the\nparameters, $n$. Our results show that the behaviour of the algorithm depends\ncrucially on how accurately one can estimate the gradient of the log target\ndensity. If the error in the estimate of the gradient is not sufficiently\ncontrolled as dimension increases, then asymptotically there will be no\nadvantage over the simpler random-walk algorithm. However, if the error is\nsufficiently well-behaved, then the optimal scaling of this algorithm will be\n$O(n^{-1/6})$ compared to $O(n^{-1/2})$ for the random walk. Our theory also\ngives guidelines on how to tune the number of Monte Carlo samples in the\nlikelihood estimate and the proposal step-size.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 09:53:09 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2015 16:29:52 GMT"}, {"version": "v3", "created": "Fri, 27 May 2016 12:52:55 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Nemeth", "Christopher", ""], ["Sherlock", "Chris", ""], ["Fearnhead", "Paul", ""]]}, {"id": "1412.7392", "submitter": "Arnak Dalalyan S.", "authors": "Arnak S. Dalalyan", "title": "Theoretical guarantees for approximate sampling from smooth and\n  log-concave densities", "comments": "To appear in JRSS B", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling from various kinds of distributions is an issue of paramount\nimportance in statistics since it is often the key ingredient for constructing\nestimators, test procedures or confidence intervals. In many situations, the\nexact sampling from a given distribution is impossible or computationally\nexpensive and, therefore, one needs to resort to approximate sampling\nstrategies. However, there is no well-developed theory providing meaningful\nnonasymptotic guarantees for the approximate sampling procedures, especially in\nthe high-dimensional problems. This paper makes some progress in this direction\nby considering the problem of sampling from a distribution having a smooth and\nlog-concave density defined on \\(\\RR^p\\), for some integer \\(p>0\\). We\nestablish nonasymptotic bounds for the error of approximating the target\ndistribution by the one obtained by the Langevin Monte Carlo method and its\nvariants. We illustrate the effectiveness of the established guarantees with\nvarious experiments. Underlying our analysis are insights from the theory of\ncontinuous-time diffusion processes, which may be of interest beyond the\nframework of log-concave densities considered in the present work.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 15:00:57 GMT"}, {"version": "v2", "created": "Wed, 31 Dec 2014 03:15:50 GMT"}, {"version": "v3", "created": "Thu, 8 Jan 2015 03:29:23 GMT"}, {"version": "v4", "created": "Thu, 17 Sep 2015 16:02:53 GMT"}, {"version": "v5", "created": "Fri, 19 Feb 2016 23:19:39 GMT"}, {"version": "v6", "created": "Sat, 3 Dec 2016 08:41:19 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Dalalyan", "Arnak S.", ""]]}, {"id": "1412.7461", "submitter": "Aki Vehtari", "authors": "Aki Vehtari, Tommi Mononen, Ville Tolvanen, Tuomas Sivula and Ole\n  Winther", "title": "Bayesian leave-one-out cross-validation approximations for Gaussian\n  latent variable models", "comments": null, "journal-ref": "Journal of Machine Learning Research, 17(103):1-38, 2016", "doi": null, "report-no": null, "categories": "stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The future predictive performance of a Bayesian model can be estimated using\nBayesian cross-validation. In this article, we consider Gaussian latent\nvariable models where the integration over the latent values is approximated\nusing the Laplace method or expectation propagation (EP). We study the\nproperties of several Bayesian leave-one-out (LOO) cross-validation\napproximations that in most cases can be computed with a small additional cost\nafter forming the posterior approximation given the full data. Our main\nobjective is to assess the accuracy of the approximative LOO cross-validation\nestimators. That is, for each method (Laplace and EP) we compare the\napproximate fast computation with the exact brute force LOO computation.\nSecondarily, we evaluate the accuracy of the Laplace and EP approximations\nthemselves against a ground truth established through extensive Markov chain\nMonte Carlo simulation. Our empirical results show that the approach based upon\na Gaussian approximation to the LOO marginal distribution (the so-called cavity\ndistribution) gives the most accurate and reliable results among the fast\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 18:25:57 GMT"}, {"version": "v2", "created": "Mon, 4 Apr 2016 11:27:21 GMT"}, {"version": "v3", "created": "Mon, 23 May 2016 20:19:39 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Vehtari", "Aki", ""], ["Mononen", "Tommi", ""], ["Tolvanen", "Ville", ""], ["Sivula", "Tuomas", ""], ["Winther", "Ole", ""]]}, {"id": "1412.7550", "submitter": "Johan Westerborn", "authors": "Jimmy Olsson and Johan Westerborn", "title": "Efficient particle-based online smoothing in general hidden Markov\n  models: the PaRIS algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel algorithm, the particle-based, rapid incremental\nsmoother (PaRIS), for efficient online approximation of smoothed expectations\nof additive state functionals in general hidden Markov models. The algorithm,\nwhich has a linear computational complexity under weak assumptions and very\nlimited memory requirements, is furnished with a number of convergence results,\nincluding a central limit theorem. An interesting feature of PaRIS, which\nsamples on-the-fly from the retrospective dynamics induced by the particle\nfilter, is that it requires two or more backward draws per particle in order to\ncope with degeneracy of the sampled trajectories and to stay numerically stable\nin the long run with an asymptotic variance that grows only linearly with time.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 21:25:24 GMT"}], "update_date": "2014-12-25", "authors_parsed": [["Olsson", "Jimmy", ""], ["Westerborn", "Johan", ""]]}, {"id": "1412.7560", "submitter": "Franck Jabot", "authors": "Franck Jabot, Guillaume Lagarrigues, Beno\\^it Courbaud, Nicolas\n  Dumoulin", "title": "A comparison of emulation methods for Approximate Bayesian Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.PE stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian Computation (ABC) is a family of statistical inference\ntechniques, which is increasingly used in biology and other scientific fields.\nIts main benefit is to be applicable to models for which the computation of the\nmodel likelihood is intractable. The basic idea of ABC is to empirically\napproximate the model likelihood by using intensive realizations of model runs.\nDue to computing time limitations, ABC has thus been mainly applied to models\nthat are relatively quick to simulate. We here aim at briefly introducing the\nfield of statistical emulation of computer code outputs and to demonstrate its\npotential for ABC applications. Emulation consists in replacing the costly to\nsimulate model by another (quick to simulate) statistical model called emulator\nor meta-model. This emulator is fitted to a small number of outputs of the\noriginal model, and is subsequently used as a surrogate during the inference\nprocedure. In this contribution, we first detail the principles of model\nemulation, with a special reference to the ABC context in which the description\nof the stochasticity of model realizations is as important as the description\nof the trends linking model parameters and outputs. We then compare several\nemulation strategies in an ABC context, using as case study a stochastic\necological model of community dynamics. We finally describe a novel\nemulation-based sequential ABC algorithm which is shown to decrease computing\ntime by a factor of two on the studied example, compared to previous sequential\nABC algorithms. Routines to perform emulation-based ABC were made available\nwithin the R package EasyABC.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 08:18:48 GMT"}], "update_date": "2014-12-25", "authors_parsed": [["Jabot", "Franck", ""], ["Lagarrigues", "Guillaume", ""], ["Courbaud", "Beno\u00eet", ""], ["Dumoulin", "Nicolas", ""]]}, {"id": "1412.7784", "submitter": "Alireza Mahani", "authors": "Alireza S. Mahani, Mansour T.A. Sharabiani", "title": "Multivariate-from-Univariate MCMC Sampler: R Package MfUSampler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The R package MfUSampler provides Monte Carlo Markov Chain machinery for\ngenerating samples from multivariate probability distributions using univariate\nsampling algorithms such as Slice Sampler and Adaptive Rejection Sampler. The\nsampler function performs a full cycle of univariate sampling steps, one\ncoordinate at a time. In each step, the latest sample values obtained for other\ncoordinates are used to form the conditional distributions. The concept is an\nextension of Gibbs sampling where each step involves, not an independent sample\nfrom the conditional distribution, but a Markov transition for which the\nconditional distribution is invariant. The software relies on proportionality\nof conditional distributions to the joint distribution to implement a thin\nwrapper for producing conditionals. Examples illustrate basic usage as well as\nmethods for improving performance. By encapsulating the\nmultivariate-from-univariate logic, MfUSampler provides a reliable library for\nrapid prototyping of custom Bayesian models while allowing for incremental\nperformance optimizations such as utilization of conjugacy, conditional\nindependence, and porting function evaluations to compiled languages.\n", "versions": [{"version": "v1", "created": "Thu, 25 Dec 2014 04:26:32 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Mahani", "Alireza S.", ""], ["Sharabiani", "Mansour T. A.", ""]]}, {"id": "1412.8293", "submitter": "Jiyan Yang", "authors": "Haim Avron, Vikas Sindhwani, Jiyan Yang, Michael Mahoney", "title": "Quasi-Monte Carlo Feature Maps for Shift-Invariant Kernels", "comments": "A short version of this paper has been presented in ICML 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of improving the efficiency of randomized Fourier\nfeature maps to accelerate training and testing speed of kernel methods on\nlarge datasets. These approximate feature maps arise as Monte Carlo\napproximations to integral representations of shift-invariant kernel functions\n(e.g., Gaussian kernel). In this paper, we propose to use Quasi-Monte Carlo\n(QMC) approximations instead, where the relevant integrands are evaluated on a\nlow-discrepancy sequence of points as opposed to random point sets as in the\nMonte Carlo approach. We derive a new discrepancy measure called box\ndiscrepancy based on theoretical characterizations of the integration error\nwith respect to a given sequence. We then propose to learn QMC sequences\nadapted to our setting based on explicit box discrepancy minimization. Our\ntheoretical analyses are complemented with empirical results that demonstrate\nthe effectiveness of classical and adaptive QMC techniques for this problem.\n", "versions": [{"version": "v1", "created": "Mon, 29 Dec 2014 10:00:39 GMT"}, {"version": "v2", "created": "Sun, 9 Aug 2015 07:20:00 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Avron", "Haim", ""], ["Sindhwani", "Vikas", ""], ["Yang", "Jiyan", ""], ["Mahoney", "Michael", ""]]}, {"id": "1412.8695", "submitter": "Nikolas Kantas", "authors": "Nikolas Kantas, Arnaud Doucet, Sumeetpal S. Singh, Jan Maciejowski,\n  Nicolas Chopin", "title": "On Particle Methods for Parameter Estimation in State-Space Models", "comments": "Published at http://dx.doi.org/10.1214/14-STS511 in the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2015, Vol. 30, No. 3, 328-351", "doi": "10.1214/14-STS511", "report-no": "IMS-STS-STS511", "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear non-Gaussian state-space models are ubiquitous in statistics,\neconometrics, information engineering and signal processing. Particle methods,\nalso known as Sequential Monte Carlo (SMC) methods, provide reliable numerical\napproximations to the associated state inference problems. However, in most\napplications, the state-space model of interest also depends on unknown static\nparameters that need to be estimated from the data. In this context, standard\nparticle methods fail and it is necessary to rely on more sophisticated\nalgorithms. The aim of this paper is to present a comprehensive review of\nparticle methods that have been proposed to perform static parameter estimation\nin state-space models. We discuss the advantages and limitations of these\nmethods and illustrate their performance on simple models.\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 17:21:00 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2015 12:02:31 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Kantas", "Nikolas", ""], ["Doucet", "Arnaud", ""], ["Singh", "Sumeetpal S.", ""], ["Maciejowski", "Jan", ""], ["Chopin", "Nicolas", ""]]}]