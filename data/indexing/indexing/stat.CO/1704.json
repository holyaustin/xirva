[{"id": "1704.00117", "submitter": "Kody Law", "authors": "Ajay Jasra, Kengo Kamatani, Kody Law, Yan Zhou", "title": "A Multi-Index Markov Chain Monte Carlo Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we consider computing expectations w.r.t.~probability laws\nassociated to a certain class of stochastic systems. In order to achieve such a\ntask, one must not only resort to numerical approximation of the expectation,\nbut also to a biased discretization of the associated probability. We are\nconcerned with the situation for which the discretization is required in\nmultiple dimensions, for instance in space and time. In such contexts, it is\nknown that the multi-index Monte Carlo (MIMC) method can improve upon\ni.i.d.~sampling from the most accurate approximation of the probability law.\nIndeed by a non-trivial modification of the multilevel Monte Carlo (MLMC)\nmethod and it can reduce the work to obtain a given level of error, relative to\nthe afore mentioned i.i.d.~sampling and relative even to MLMC. In this article\nwe consider the case when such probability laws are too complex to sampled\nindependently. We develop a modification of the MIMC method which allows one to\nuse standard Markov chain Monte Carlo (MCMC) algorithms to replace independent\nand coupled sampling, in certain contexts. We prove a variance theorem which\nshows that using our MIMCMC method is preferable, in the sense above, to\ni.i.d.~sampling from the most accurate approximation, under assumptions. The\nmethod is numerically illustrated on a problem associated to a stochastic\npartial differential equation (SPDE).\n", "versions": [{"version": "v1", "created": "Sat, 1 Apr 2017 03:57:44 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 14:29:45 GMT"}, {"version": "v3", "created": "Fri, 27 Oct 2017 00:49:38 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Jasra", "Ajay", ""], ["Kamatani", "Kengo", ""], ["Law", "Kody", ""], ["Zhou", "Yan", ""]]}, {"id": "1704.00520", "submitter": "Marko J\\\"arvenp\\\"a\\\"a", "authors": "Marko J\\\"arvenp\\\"a\\\"a, Michael U. Gutmann, Arijus Pleska, Aki Vehtari,\n  Pekka Marttinen", "title": "Efficient acquisition rules for model-based approximate Bayesian\n  computation", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": "10.1214/18-BA1121", "report-no": null, "categories": "stat.ML stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Bayesian computation (ABC) is a method for Bayesian inference\nwhen the likelihood is unavailable but simulating from the model is possible.\nHowever, many ABC algorithms require a large number of simulations, which can\nbe costly. To reduce the computational cost, Bayesian optimisation (BO) and\nsurrogate models such as Gaussian processes have been proposed. Bayesian\noptimisation enables one to intelligently decide where to evaluate the model\nnext but common BO strategies are not designed for the goal of estimating the\nposterior distribution. Our paper addresses this gap in the literature. We\npropose to compute the uncertainty in the ABC posterior density, which is due\nto a lack of simulations to estimate this quantity accurately, and define a\nloss function that measures this uncertainty. We then propose to select the\nnext evaluation location to minimise the expected loss. Experiments show that\nthe proposed method often produces the most accurate approximations as compared\nto common BO strategies.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 10:40:15 GMT"}, {"version": "v2", "created": "Fri, 29 Sep 2017 18:43:02 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 13:57:47 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["J\u00e4rvenp\u00e4\u00e4", "Marko", ""], ["Gutmann", "Michael U.", ""], ["Pleska", "Arijus", ""], ["Vehtari", "Aki", ""], ["Marttinen", "Pekka", ""]]}, {"id": "1704.00543", "submitter": "Jouni Helske", "authors": "Satu Helske, Jouni Helske", "title": "Mixture Hidden Markov Models for Sequence Data: The seqHMM Package in R", "comments": "33 pages, 8 figures", "journal-ref": "Journal of Statistical Software, 88(3), 1 - 32 (2019)", "doi": "10.18637/jss.v088.i03", "report-no": null, "categories": "stat.CO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequence analysis is being more and more widely used for the analysis of\nsocial sequences and other multivariate categorical time series data. However,\nit is often complex to describe, visualize, and compare large sequence data,\nespecially when there are multiple parallel sequences per subject. Hidden\n(latent) Markov models (HMMs) are able to detect underlying latent structures\nand they can be used in various longitudinal settings: to account for\nmeasurement error, to detect unobservable states, or to compress information\nacross several types of observations. Extending to mixture hidden Markov models\n(MHMMs) allows clustering data into homogeneous subsets, with or without\nexternal covariates.\n  The seqHMM package in R is designed for the efficient modeling of sequences\nand other categorical time series data containing one or multiple subjects with\none or multiple interdependent sequences using HMMs and MHMMs. Also other\nrestricted variants of the MHMM can be fitted, e.g., latent class models,\nMarkov models, mixture Markov models, or even ordinary multinomial regression\nmodels with suitable parameterization of the HMM. Good graphical presentations\nof data and models are useful during the whole analysis process from the first\nglimpse at the data to model fitting and presentation of results. The package\nprovides easy options for plotting parallel sequence data, and proposes\nvisualizing HMMs as directed graphs.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 12:09:19 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2019 17:46:40 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Helske", "Satu", ""], ["Helske", "Jouni", ""]]}, {"id": "1704.00587", "submitter": "Salima El", "authors": "Salima El Kolei (ENSAI), Fr\\'ed\\'eric Patras (JAD)", "title": "Analysis, detection and correction of misspecified discrete time state\n  space models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Misspecifications (i.e. errors on the parameters) of state space models lead\nto incorrect inference of the hidden states. This paper studies weakly\nnonlin-ear state space models with additive Gaussian noises and proposes a\nmethod for detecting and correcting misspecifications. The latter induce a\nbiased estimator of the hidden state but also happen to induce correlation on\ninnovations and other residues. This property is used to find a well-defined\nobjective function for which an optimisation routine is applied to recover the\ntrue parameters of the model. It is argued that this method can consistently\nestimate the bias on the parameter. We demonstrate the algorithm on various\nmodels of increasing complexity.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 13:49:25 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Kolei", "Salima El", "", "ENSAI"], ["Patras", "Fr\u00e9d\u00e9ric", "", "JAD"]]}, {"id": "1704.00680", "submitter": "John Jakeman", "authors": "T. Butler, J. D. Jakeman and T. Wildey", "title": "A Consistent Bayesian Formulation for Stochastic Inverse Problems Based\n  on Push-forward Measures", "comments": null, "journal-ref": null, "doi": "10.1137/16M1087229", "report-no": null, "categories": "math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate, and present a numerical method for solving, an inverse problem\nfor inferring parameters of a deterministic model from stochastic observational\ndata (quantities of interest). The solution, given as a probability measure, is\nderived using a Bayesian updating approach for measurable maps that finds a\nposterior probability measure, that when propagated through the deterministic\nmodel produces a push-forward measure that exactly matches the observed\nprobability measure on the data. Our approach for finding such posterior\nmeasures, which we call consistent Bayesian inference, is simple and only\nrequires the computation of the push-forward probability measure induced by the\ncombination of a prior probability measure and the deterministic model. We\nestablish existence and uniqueness of observation-consistent posteriors and\npresent stability and error analysis. We also discuss the relationships between\nconsistent Bayesian inference, classical/statistical Bayesian inference, and a\nrecently developed measure-theoretic approach for inference. Finally,\nanalytical and numerical results are presented to highlight certain properties\nof the consistent Bayesian approach and the differences between this approach\nand the two aforementioned alternatives for inference.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 16:50:14 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Butler", "T.", ""], ["Jakeman", "J. D.", ""], ["Wildey", "T.", ""]]}, {"id": "1704.00963", "submitter": "Eero Siivola", "authors": "Eero Siivola, Aki Vehtari, Jarno Vanhatalo, Javier Gonz\\'alez, Michael\n  Riis Andersen", "title": "Correcting boundary over-exploration deficiencies in Bayesian\n  optimization with virtual derivative sign observations", "comments": "6 pages, 7 figures", "journal-ref": "2018 IEEE 28th International Workshop on Machine Learning for\n  Signal Processing (MLSP)", "doi": null, "report-no": null, "categories": "stat.ML stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian optimization (BO) is a global optimization strategy designed to find\nthe minimum of an expensive black-box function, typically defined on a compact\nsubset of $\\mathcal{R}^d$, by using a Gaussian process (GP) as a surrogate\nmodel for the objective. Although currently available acquisition functions\naddress this goal with different degree of success, an over-exploration effect\nof the contour of the search space is typically observed. However, in problems\nlike the configuration of machine learning algorithms, the function domain is\nconservatively large and with a high probability the global minimum does not\nsit on the boundary of the domain. We propose a method to incorporate this\nknowledge into the search process by adding virtual derivative observations in\nthe \\gp at the boundary of the search space. We use the properties of GPs to\nimpose conditions on the partial derivatives of the objective. The method is\napplicable with any acquisition function, it is easy to use and consistently\nreduces the number of evaluations required to optimize the objective\nirrespective of the acquisition used. We illustrate the benefits of our\napproach in an extensive experimental comparison.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 11:40:20 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 14:50:39 GMT"}, {"version": "v3", "created": "Fri, 21 Sep 2018 11:49:01 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Siivola", "Eero", ""], ["Vehtari", "Aki", ""], ["Vanhatalo", "Jarno", ""], ["Gonz\u00e1lez", "Javier", ""], ["Andersen", "Michael Riis", ""]]}, {"id": "1704.01113", "submitter": "Matti Raitoharju", "authors": "Matti Raitoharju, Lennart Svensson, \\'Angel F. Garc\\'ia-Fern\\'andez\n  and Robert Pich\\'e", "title": "Damped Posterior Linearization Filter", "comments": null, "journal-ref": null, "doi": "10.1109/LSP.2018.2806304", "report-no": null, "categories": "math.OC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The iterated posterior linearization filter (IPLF) is an algorithm for\nBayesian state estimation that performs the measurement update using iterative\nstatistical regression. The main result behind IPLF is that the posterior\napproximation is more accurate when the statistical regression of measurement\nfunction is done in the posterior instead of the prior as is done in\nnon-iterative Kalman filter extensions. In IPLF, each iteration in principle\ngives a better posterior estimate to obtain a better statistical regression and\nmore accurate posterior estimate in the next iteration. However, IPLF may\ndiverge. IPLF's fixed- points are not described as solutions to an optimization\nproblem, which makes it challenging to improve its convergence properties. In\nthis letter, we introduce a double-loop version of IPLF, where the inner loop\ncomputes the posterior mean using an optimization algorithm. Simulation results\nare presented to show that the proposed algorithm has better convergence than\nIPLF and its accuracy is similar to or better than other state-of-the-art\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 17:48:39 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 08:30:58 GMT"}], "update_date": "2018-02-19", "authors_parsed": [["Raitoharju", "Matti", ""], ["Svensson", "Lennart", ""], ["Garc\u00eda-Fern\u00e1ndez", "\u00c1ngel F.", ""], ["Pich\u00e9", "Robert", ""]]}, {"id": "1704.01168", "submitter": "Eric Nalisnick", "authors": "Eric Nalisnick, Padhraic Smyth", "title": "Learning Approximately Objective Priors", "comments": "UAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Informative Bayesian priors are often difficult to elicit, and when this is\nthe case, modelers usually turn to noninformative or objective priors. However,\nobjective priors such as the Jeffreys and reference priors are not tractable to\nderive for many models of interest. We address this issue by proposing\ntechniques for learning reference prior approximations: we select a parametric\nfamily and optimize a black-box lower bound on the reference prior objective to\nfind the member of the family that serves as a good approximation. We\nexperimentally demonstrate the method's effectiveness by recovering Jeffreys\npriors and learning the Variational Autoencoder's reference prior.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 20:07:26 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 04:23:54 GMT"}, {"version": "v3", "created": "Fri, 4 Aug 2017 18:53:05 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Nalisnick", "Eric", ""], ["Smyth", "Padhraic", ""]]}, {"id": "1704.01445", "submitter": "Jack Fitzsimons", "authors": "Jack Fitzsimons, Kurt Cutajar, Michael Osborne, Stephen Roberts,\n  Maurizio Filippone", "title": "Bayesian Inference of Log Determinants", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The log-determinant of a kernel matrix appears in a variety of machine\nlearning problems, ranging from determinantal point processes and generalized\nMarkov random fields, through to the training of Gaussian processes. Exact\ncalculation of this term is often intractable when the size of the kernel\nmatrix exceeds a few thousand. In the spirit of probabilistic numerics, we\nreinterpret the problem of computing the log-determinant as a Bayesian\ninference problem. In particular, we combine prior knowledge in the form of\nbounds from matrix theory and evidence derived from stochastic trace estimation\nto obtain probabilistic estimates for the log-determinant and its associated\nuncertainty within a given computational budget. Beyond its novelty and\ntheoretic appeal, the performance of our proposal is competitive with\nstate-of-the-art approaches to approximating the log-determinant, while also\nquantifying the uncertainty due to budget-constrained evidence.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 14:23:53 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Fitzsimons", "Jack", ""], ["Cutajar", "Kurt", ""], ["Osborne", "Michael", ""], ["Roberts", "Stephen", ""], ["Filippone", "Maurizio", ""]]}, {"id": "1704.02030", "submitter": "Yuling Yao", "authors": "Yuling Yao, Aki Vehtari, Daniel Simpson, Andrew Gelman", "title": "Using stacking to average Bayesian predictive distributions", "comments": null, "journal-ref": null, "doi": "10.1214/17-BA1091", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widely recommended procedure of Bayesian model averaging is flawed in the\nM-open setting in which the true data-generating process is not one of the\ncandidate models being fit. We take the idea of stacking from the point\nestimation literature and generalize to the combination of predictive\ndistributions, extending the utility function to any proper scoring rule, using\nPareto smoothed importance sampling to efficiently compute the required\nleave-one-out posterior distributions and regularization to get more stability.\nWe compare stacking of predictive distributions to several alternatives:\nstacking of means, Bayesian model averaging (BMA), pseudo-BMA using AIC-type\nweighting, and a variant of pseudo-BMA that is stabilized using the Bayesian\nbootstrap. Based on simulations and real-data applications, we recommend\nstacking of predictive distributions, with BB-pseudo-BMA as an approximate\nalternative when computation cost is an issue.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 21:49:24 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 05:09:48 GMT"}, {"version": "v3", "created": "Sat, 16 Sep 2017 02:31:39 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Yao", "Yuling", ""], ["Vehtari", "Aki", ""], ["Simpson", "Daniel", ""], ["Gelman", "Andrew", ""]]}, {"id": "1704.02369", "submitter": "Boqian Zhang", "authors": "Boqian Zhang and Vinayak Rao", "title": "Efficient parameter sampling for Markov jump processes", "comments": "42 pages, 17 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov jump processes (MJPs) are continuous-time stochastic processes widely\nused in a variety of applied disciplines. Inference for MJPs typically proceeds\nvia Markov chain Monte Carlo, the state-of-the-art being a uniformization-based\nauxiliary variable Gibbs sampler. This was designed for situations where the\nMJP parameters are known, and Bayesian inference over unknown parameters is\ntypically carried out by incorporating it into a larger Gibbs sampler. This\nstrategy of sampling parameters given path, and path given parameters can\nresult in poor Markov chain mixing. In this work, we propose a simple and\nelegant algorithm to address this problem. Our scheme brings\nMetropolis-Hastings approaches for discrete-time hidden Markov models to the\ncontinuous-time setting, resulting in a complete and clean recipe for parameter\nand path inference in MJPs. In our experiments, we demonstrate superior\nperformance over Gibbs sampling, as well as another popular approach, particle\nMCMC. We also show our sampler inherits geometric mixing from an `ideal'\nsampler that operates without computational constraints.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 20:42:21 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 00:43:25 GMT"}, {"version": "v3", "created": "Sun, 12 Apr 2020 04:52:28 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Zhang", "Boqian", ""], ["Rao", "Vinayak", ""]]}, {"id": "1704.02577", "submitter": "Myrl Marmarelis", "authors": "Myrl G. Marmarelis", "title": "Efficient and Robust Polylinear Analysis of Noisy Time Series", "comments": "6 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method is proposed to generate an optimal fit of a number of connected\nlinear trend segments onto time-series data. To be able to efficiently handle\nmany lines, the method employs a stochastic search procedure to determine\noptimal transition point locations. Traditional methods use exhaustive grid\nsearches, which severely limit the scale of the problems for which they can be\nutilized. The proposed approach is tried against time series with severe noise\nto demonstrate its robustness, and then it is applied to real medical data as\nan illustrative example.\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 09:15:15 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Marmarelis", "Myrl G.", ""]]}, {"id": "1704.02706", "submitter": "Wei Pan", "authors": "Wei Pan (1), Xinming An (2), Qing Yang (1) ((1) Duke University, (2)\n  SAS Institute Inc.)", "title": "Computing and Graphing Probability Values of Pearson Distributions: A\n  SAS/IML Macro", "comments": null, "journal-ref": "Source Code for Biology and Medicine 14:1-6 (2019)", "doi": "10.1186/s13029-019-0076-2", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any empirical data can be approximated to one of Pearson distributions using\nthe first four moments of the data (Elderton and Johnson, 1969; Pearson, 1895;\nSolomon and Stephens, 1978). Thus, Pearson distributions made statistical\nanalysis possible for data with unknown distributions. There are both extant\nold-fashioned in-print tables (Pearson and Hartley, 1972) and contemporary\ncomputer programs (Amos and Daniel, 1971; Bouver and Bargmann, 1974; Bowman and\nShenton, 1979; Davis and Stephens, 1983; Pan, 2009) available for obtaining\npercentage points of Pearson distributions corresponding to certain\npre-specifed percentages (or probability values) (e.g., 1.0%, 2.5%, 5.0%,\netc.), but they are little useful in statistical analysis because we have to\nrely on unwieldy second difference interpolation to calculate a probability\nvalue of a Pearson distribution corresponding to any given percentage point,\nsuch as an observed test statistic in hypothesis testing. Thus, the present\nstudy develops a SAS/IML macro program to compute and graph probability values\nof Pearson distributions for any given percentage point so as to facilitate\nresearchers to conduct statistical analysis on data with unknown distributions.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 04:28:17 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Pan", "Wei", ""], ["An", "Xinming", ""], ["Yang", "Qing", ""]]}, {"id": "1704.02771", "submitter": "Luca Martino", "authors": "L. Martino, V. Elvira, G. Camps-Valls", "title": "Group Importance Sampling for Particle Filtering and MCMC", "comments": "To appear in Digital Signal Processing. Related Matlab demos are\n  provided at https://github.com/lukafree/GIS.git", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.CE cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian methods and their implementations by means of sophisticated Monte\nCarlo techniques have become very popular in signal processing over the last\nyears. Importance Sampling (IS) is a well-known Monte Carlo technique that\napproximates integrals involving a posterior distribution by means of weighted\nsamples. In this work, we study the assignation of a single weighted sample\nwhich compresses the information contained in a population of weighted samples.\nPart of the theory that we present as Group Importance Sampling (GIS) has been\nemployed implicitly in different works in the literature. The provided analysis\nyields several theoretical and practical consequences. For instance, we discuss\nthe application of GIS into the Sequential Importance Resampling framework and\nshow that Independent Multiple Try Metropolis schemes can be interpreted as a\nstandard Metropolis-Hastings algorithm, following the GIS approach. We also\nintroduce two novel Markov Chain Monte Carlo (MCMC) techniques based on GIS.\nThe first one, named Group Metropolis Sampling method, produces a Markov chain\nof sets of weighted samples. All these sets are then employed for obtaining a\nunique global estimator. The second one is the Distributed Particle\nMetropolis-Hastings technique, where different parallel particle filters are\njointly used to drive an MCMC algorithm. Different resampled trajectories are\ncompared and then tested with a proper acceptance probability. The novel\nschemes are tested in different numerical experiments such as learning the\nhyperparameters of Gaussian Processes, two localization problems in a wireless\nsensor network (with synthetic and real data) and the tracking of vegetation\nparameters given satellite observations, where they are compared with several\nbenchmark Monte Carlo techniques. Three illustrative Matlab demos are also\nprovided.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 09:20:47 GMT"}, {"version": "v2", "created": "Mon, 17 Apr 2017 14:22:22 GMT"}, {"version": "v3", "created": "Fri, 28 Apr 2017 20:51:47 GMT"}, {"version": "v4", "created": "Sat, 4 Aug 2018 09:19:51 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Martino", "L.", ""], ["Elvira", "V.", ""], ["Camps-Valls", "G.", ""]]}, {"id": "1704.02791", "submitter": "Andrew Golightly", "authors": "Andrew Golightly and Theodore Kypraios", "title": "Efficient SMC$^2$ schemes for stochastic kinetic models", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitting stochastic kinetic models represented by Markov jump processes within\nthe Bayesian paradigm is complicated by the intractability of the observed data\nlikelihood. There has therefore been considerable attention given to the design\nof pseudo-marginal Markov chain Monte Carlo algorithms for such models.\nHowever, these methods are typically computationally intensive, often require\ncareful tuning and must be restarted from scratch upon receipt of new\nobservations. Sequential Monte Carlo (SMC) methods on the other hand aim to\nefficiently reuse posterior samples at each time point. Despite their appeal,\napplying SMC schemes in scenarios with both dynamic states and static\nparameters is made difficult by the problem of particle degeneracy. A\nprincipled approach for overcoming this problem is to move each parameter\nparticle through a Metropolis-Hastings kernel that leaves the target invariant.\nThis rejuvenation step is key to a recently proposed SMC$^2$ algorithm, which\ncan be seen as the pseudo-marginal analogue of an idealised scheme known as\niterated batch importance sampling. Computing the parameter weights in SMC$^2$\nrequires running a particle filter over dynamic states to unbiasedly estimate\nthe intractable observed data likelihood contributions at each time point. In\nthis paper, we propose to use an auxiliary particle filter inside the SMC$^2$\nscheme. Our method uses two recently proposed constructs for sampling\nconditioned jump processes and we find that the resulting inference schemes\ntypically require fewer state particles than when using a simple bootstrap\nfilter. Using two applications, we compare the performance of the proposed\napproach with various competing methods, including two global MCMC schemes.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 10:33:05 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 13:06:40 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Golightly", "Andrew", ""], ["Kypraios", "Theodore", ""]]}, {"id": "1704.03216", "submitter": "Robert J. B. Goudie", "authors": "Robert J. B. Goudie, Rebecca M. Turner, Daniela De Angelis, Andrew\n  Thomas", "title": "MultiBUGS: A parallel implementation of the BUGS modelling framework for\n  faster Bayesian inference", "comments": "20 pages, 4 figures", "journal-ref": "Journal of Statistical Software, 95(7), 2020", "doi": "10.18637/jss.v095.i07", "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MultiBUGS (https://www.multibugs.org) is a new version of the general-purpose\nBayesian modelling software BUGS that implements a generic algorithm for\nparallelising Markov chain Monte Carlo (MCMC) algorithms to speed up posterior\ninference of Bayesian models. The algorithm parallelises evaluation of the\nproduct-form likelihoods formed when a parameter has many children in the\ndirected acyclic graph (DAG) representation; and parallelises sampling of\nconditionally-independent sets of parameters. A heuristic algorithm is used to\ndecide which approach to use for each parameter and to apportion computation\nacross computational cores. This enables MultiBUGS to automatically parallelise\nthe broad range of statistical models that can be fitted using BUGS-language\nsoftware, making the dramatic speed-ups of modern multi-core computing\naccessible to applied statisticians, without requiring any experience of\nparallel programming. We demonstrate the use of MultiBUGS on simulated data\ndesigned to mimic a hierarchical e-health linked-data study of methadone\nprescriptions including 425,112 observations and 20,426 random effects.\nPosterior inference for the e-health model takes several hours in existing\nsoftware, but MultiBUGS can perform inference in only 28 minutes using 48\ncomputational cores.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 09:38:33 GMT"}, {"version": "v2", "created": "Tue, 3 Oct 2017 07:38:24 GMT"}, {"version": "v3", "created": "Wed, 10 Oct 2018 11:21:26 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2018 15:05:55 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Goudie", "Robert J. B.", ""], ["Turner", "Rebecca M.", ""], ["De Angelis", "Daniela", ""], ["Thomas", "Andrew", ""]]}, {"id": "1704.03239", "submitter": "Gregor Kastner", "authors": "Gregor Kastner and Florian Huber", "title": "Sparse Bayesian vector autoregressions in huge dimensions", "comments": null, "journal-ref": "Journal of Forecasting (2020)", "doi": "10.1002/for.2680", "report-no": null, "categories": "stat.CO econ.EM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bayesian vector autoregressive (VAR) model with multivariate\nstochastic volatility that is capable of handling vast dimensional information\nsets. Three features are introduced to permit reliable estimation of the model.\nFirst, we assume that the reduced-form errors in the VAR feature a factor\nstochastic volatility structure, allowing for conditional equation-by-equation\nestimation. Second, we apply recently developed global-local shrinkage priors\nto the VAR coefficients to cure the curse of dimensionality. Third, we utilize\nrecent innovations to efficiently sample from high-dimensional multivariate\nGaussian distributions. This makes simulation-based fully Bayesian inference\nfeasible when the dimensionality is large but the time series length is\nmoderate. We demonstrate the merits of our approach in an extensive simulation\nstudy and apply the model to US macroeconomic data to evaluate its forecasting\ncapabilities.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 11:14:41 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 16:04:35 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 07:29:27 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Kastner", "Gregor", ""], ["Huber", "Florian", ""]]}, {"id": "1704.03338", "submitter": "Matthew Graham", "authors": "Matthew M. Graham and Amos J. Storkey", "title": "Continuously tempered Hamiltonian Monte Carlo", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonian Monte Carlo (HMC) is a powerful Markov chain Monte Carlo (MCMC)\nmethod for performing approximate inference in complex probabilistic models of\ncontinuous variables. In common with many MCMC methods, however, the standard\nHMC approach performs poorly in distributions with multiple isolated modes. We\npresent a method for augmenting the Hamiltonian system with an extra continuous\ntemperature control variable which allows the dynamic to bridge between\nsampling a complex target distribution and a simpler unimodal base\ndistribution. This augmentation both helps improve mixing in multimodal targets\nand allows the normalisation constant of the target distribution to be\nestimated. The method is simple to implement within existing HMC code,\nrequiring only a standard leapfrog integrator. We demonstrate experimentally\nthat the method is competitive with annealed importance sampling and simulating\ntempering methods at sampling from challenging multimodal distributions and\nestimating their normalising constants.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 15:01:03 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Graham", "Matthew M.", ""], ["Storkey", "Amos J.", ""]]}, {"id": "1704.03459", "submitter": "Edward Higson", "authors": "Edward Higson, Will Handley, Mike Hobson and Anthony Lasenby", "title": "Dynamic nested sampling: an improved algorithm for parameter estimation\n  and evidence calculation", "comments": "14 pages + appendix, 16 figures. Added signal reconstruction\n  numerical example using dyPolyChord. Moderate updates to text and appendices", "journal-ref": "Statistics and Computing 29, 5 (2019) p891-913", "doi": "10.1007/s11222-018-9844-0", "report-no": null, "categories": "stat.CO astro-ph.IM physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce dynamic nested sampling: a generalisation of the nested sampling\nalgorithm in which the number of \"live points\" varies to allocate samples more\nefficiently. In empirical tests the new method significantly improves\ncalculation accuracy compared to standard nested sampling with the same number\nof samples; this increase in accuracy is equivalent to speeding up the\ncomputation by factors of up to ~72 for parameter estimation and ~7 for\nevidence calculations. We also show that the accuracy of both parameter\nestimation and evidence calculations can be improved simultaneously. In\naddition, unlike in standard nested sampling, more accurate results can be\nobtained by continuing the calculation for longer. Popular standard nested\nsampling implementations can be easily adapted to perform dynamic nested\nsampling, and several dynamic nested sampling software packages are now\npublicly available.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 18:00:00 GMT"}, {"version": "v2", "created": "Wed, 13 Dec 2017 18:59:59 GMT"}, {"version": "v3", "created": "Mon, 14 May 2018 18:00:02 GMT"}, {"version": "v4", "created": "Sun, 7 Oct 2018 17:32:57 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Higson", "Edward", ""], ["Handley", "Will", ""], ["Hobson", "Mike", ""], ["Lasenby", "Anthony", ""]]}, {"id": "1704.03472", "submitter": "Alan Heavens", "authors": "Alan Heavens, Yabebal Fantaye, Arrykrishna Mootoovaloo, Hans Eggers,\n  Zafiirah Hosenie, Steve Kroon, Elena Sellentin", "title": "Marginal Likelihoods from Monte Carlo Markov Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO astro-ph.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a method for computing the marginal likelihood,\nalso known as the model likelihood or Bayesian evidence, from Markov Chain\nMonte Carlo (MCMC), or other sampled posterior distributions. In order to do\nthis, one needs to be able to estimate the density of points in parameter\nspace, and this can be challenging in high numbers of dimensions. Here we\npresent a Bayesian analysis, where we obtain the posterior for the marginal\nlikelihood, using $k$th nearest-neighbour distances in parameter space, using\nthe Mahalanobis distance metric, under the assumption that the points in the\nchain (thinned if required) are independent. We generalise the algorithm to\napply to importance-sampled chains, where each point is assigned a weight. We\nillustrate this with an idealised posterior of known form with an analytic\nmarginal likelihood, and show that for chains of length $\\sim 10^5$ points, the\ntechnique is effective for parameter spaces with up to $\\sim 20$ dimensions. We\nalso argue that $k=1$ is the optimal choice, and discuss failure modes for the\nalgorithm. In a companion paper (Heavens et al. 2017) we apply the technique to\nthe main MCMC chains from the 2015 Planck analysis of cosmic background\nradiation data, to infer that quantitatively the simplest 6-parameter flat\n$\\Lambda$CDM standard model of cosmology is preferred over all extensions\nconsidered.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 18:01:44 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Heavens", "Alan", ""], ["Fantaye", "Yabebal", ""], ["Mootoovaloo", "Arrykrishna", ""], ["Eggers", "Hans", ""], ["Hosenie", "Zafiirah", ""], ["Kroon", "Steve", ""], ["Sellentin", "Elena", ""]]}, {"id": "1704.03581", "submitter": "Alexander Terenin", "authors": "Alexander Terenin, M{\\aa}ns Magnusson, Leif Jonsson, and David Draper", "title": "P\\'olya Urn Latent Dirichlet Allocation: a doubly sparse massively\n  parallel sampler", "comments": null, "journal-ref": "IEEE Transactions on Pattern Analysis and Machine Intelligence\n  41(7):1709-1719, 2019", "doi": "10.1109/TPAMI.2018.2832641", "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet Allocation (LDA) is a topic model widely used in natural\nlanguage processing and machine learning. Most approaches to training the model\nrely on iterative algorithms, which makes it difficult to run LDA on big\ncorpora that are best analyzed in parallel and distributed computational\nenvironments. Indeed, current approaches to parallel inference either don't\nconverge to the correct posterior or require storage of large dense matrices in\nmemory. We present a novel sampler that overcomes both problems, and we show\nthat this sampler is faster, both empirically and theoretically, than previous\nGibbs samplers for LDA. We do so by employing a novel P\\'olya-urn-based\napproximation in the sparse partially collapsed sampler for LDA. We prove that\nthe approximation error vanishes with data size, making our algorithm\nasymptotically exact, a property of importance for large-scale topic models. In\naddition, we show, via an explicit example, that - contrary to popular belief\nin the topic modeling literature - partially collapsed samplers can be more\nefficient than fully collapsed samplers. We conclude by comparing the\nperformance of our algorithm with that of other approaches on well-known\ncorpora.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 01:02:27 GMT"}, {"version": "v2", "created": "Fri, 23 Jun 2017 20:00:08 GMT"}, {"version": "v3", "created": "Mon, 23 Apr 2018 12:48:23 GMT"}, {"version": "v4", "created": "Sun, 10 Jun 2018 22:10:28 GMT"}, {"version": "v5", "created": "Tue, 17 Jul 2018 12:39:06 GMT"}, {"version": "v6", "created": "Fri, 3 Aug 2018 13:07:04 GMT"}, {"version": "v7", "created": "Thu, 22 Oct 2020 16:14:22 GMT"}], "update_date": "2020-10-23", "authors_parsed": [["Terenin", "Alexander", ""], ["Magnusson", "M\u00e5ns", ""], ["Jonsson", "Leif", ""], ["Draper", "David", ""]]}, {"id": "1704.03721", "submitter": "Hien Nguyen", "authors": "Hien Duy Nguyen", "title": "A Stream-Suitable Kolmogorov-Smirnov-Type Test for Big Data Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data has become an ever more commonplace setting that is encountered by\ndata analysts. In the Big Data setting, analysts are faced with very large\nnumbers of observations as well as data that arrive as a stream, both of which\nare phenomena that many traditional statistical techniques are unable to\ncontend with. Unfortunately, many of these traditional techniques are useful\nand cannot be discarded. One such technique is the Kolmogorov-Smirnov (KS) test\nfor goodness-of-fit (GoF). A Big Data and stream-appropriate KS-type test is\nderived via the chunked-and-averaged (CA) estimator paradigm. The new test is\ntermed the CAKS GoF test. The CAKS test statistic is proved to be\nasymptotically normal, allowing for the large sample testing of GoF.\nFurthermore, theoretical results demonstrate that the CAKS test is consistent\nagainst both fixed alternatives, where the null and the true data generating\ndistribution are a fixed distance apart, and alternatives that approach the\nnull at a slow enough rate. Numerical results demonstrate that the CAKS test is\neffective in identifying deviation in the distribution with respect to changes\nin mean, variance, and shape. Furthermore, it is found that the CAKS test is\nfaster than the KS test, for large numbers of observation, and can be applied\nto sample sizes of 10^{9} and beyond.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 12:18:46 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Nguyen", "Hien Duy", ""]]}, {"id": "1704.04629", "submitter": "Luca Martino", "authors": "Luca Martino, Victor Elvira", "title": "Metropolis Sampling", "comments": "Wiley StatsRef-Statistics Reference Online, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo (MC) sampling methods are widely applied in Bayesian inference,\nsystem simulation and optimization problems. The Markov Chain Monte Carlo\n(MCMC) algorithms are a well-known class of MC methods which generate a Markov\nchain with the desired invariant distribution. In this document, we focus on\nthe Metropolis-Hastings (MH) sampler, which can be considered as the atom of\nthe MCMC techniques, introducing the basic notions and different properties. We\ndescribe in details all the elements involved in the MH algorithm and the most\nrelevant variants. Several improvements and recent extensions proposed in the\nliterature are also briefly discussed, providing a quick but exhaustive\noverview of the current Metropolis-based sampling's world.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 12:15:30 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Martino", "Luca", ""], ["Elvira", "Victor", ""]]}, {"id": "1704.04839", "submitter": "Li Ma", "authors": "Jacopo Soriano and Li Ma", "title": "Mixture modeling on related samples by $\\psi$-stick breaking and kernel\n  perturbation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been great interest recently in applying nonparametric kernel\nmixtures in a hierarchical manner to model multiple related data samples\njointly. In such settings several data features are commonly present: (i) the\nrelated samples often share some, if not all, of the mixture components but\nwith differing weights, (ii) only some, not all, of the mixture components vary\nacross the samples, and (iii) often the shared mixture components across\nsamples are not aligned perfectly in terms of their location and spread, but\nrather display small misalignments either due to systematic cross-sample\ndifference or more often due to uncontrolled, extraneous causes. Properly\nincorporating these features in mixture modeling will enhance the efficiency of\ninference, whereas ignoring them not only reduces efficiency but can jeopardize\nthe validity of the inference due to issues such as confounding. We introduce\ntwo techniques for incorporating these features in modeling related data\nsamples using kernel mixtures. The first technique, called $\\psi$-stick\nbreaking, is a joint generative process for the mixing weights through the\nbreaking of both a stick shared by all the samples for the components that do\nnot vary in size across samples and an idiosyncratic stick for each sample for\nthose components that do vary in size. The second technique is to imbue random\nperturbation into the kernels, thereby accounting for cross-sample\nmisalignment. These techniques can be used either separately or together in\nboth parametric and nonparametric kernel mixtures. We derive efficient Bayesian\ninference recipes based on MCMC sampling for models featuring these techniques,\nand illustrate their work through both simulated data and a real flow cytometry\ndata set in prediction/estimation, cross-sample calibration, and testing\nmulti-sample differences.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 00:58:37 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Soriano", "Jacopo", ""], ["Ma", "Li", ""]]}, {"id": "1704.04926", "submitter": "Fabio Rapallo", "authors": "Cristiano Bocci and Fabio Rapallo", "title": "Exact tests to compare contingency tables under quasi-independence and\n  quasi-symmetry", "comments": "14 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we define log-linear models to compare several square\ncontingency tables under the quasi-independence or the quasi-symmetry model,\nand the relevant Markov bases are theoretically characterized. Through Markov\nbases, an exact test to evaluate if two or more tables fit a common model is\nintroduced. Two real-data examples illustrate the use of these models in\ndifferent fields of applications.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 10:49:12 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Bocci", "Cristiano", ""], ["Rapallo", "Fabio", ""]]}, {"id": "1704.05098", "submitter": "Yun Yang", "authors": "Yun Yang", "title": "Statistical inference for high dimensional regression via Constrained\n  Lasso", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.CO stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new method for estimation and constructing\nconfidence intervals for low-dimensional components in a high-dimensional\nmodel. The proposed estimator, called Constrained Lasso (CLasso) estimator, is\nobtained by simultaneously solving two estimating equations---one imposing a\nzero-bias constraint for the low-dimensional parameter and the other forming an\n$\\ell_1$-penalized procedure for the high-dimensional nuisance parameter. By\ncarefully choosing the zero-bias constraint, the resulting estimator of the low\ndimensional parameter is shown to admit an asymptotically normal limit\nattaining the Cram\\'{e}r-Rao lower bound in a semiparametric sense. We propose\na tuning-free iterative algorithm for implementing the CLasso. We show that\nwhen the algorithm is initialized at the Lasso estimator, the de-sparsified\nestimator proposed in van de Geer et al. [\\emph{Ann. Statist.} {\\bf 42} (2014)\n1166--1202] is asymptotically equivalent to the first iterate of the algorithm.\nWe analyse the asymptotic properties of the CLasso estimator and show the\nglobally linear convergence of the algorithm. We also demonstrate encouraging\nempirical performance of the CLasso through numerical studies.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 19:21:33 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Yang", "Yun", ""]]}, {"id": "1704.06017", "submitter": "Thong The Pham", "authors": "Thong Pham, Paul Sheridan, Hidetoshi Shimodaira", "title": "PAFit: an R Package for the Non-Parametric Estimation of Preferential\n  Attachment and Node Fitness in Temporal Complex Networks", "comments": "Conditionally accepted to Journal of Statistical Software", "journal-ref": null, "doi": "10.18637/jss.v092.i03", "report-no": null, "categories": "physics.data-an cs.SI physics.soc-ph stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world systems are profitably described as complex networks that\ngrow over time. Preferential attachment and node fitness are two simple growth\nmechanisms that not only explain certain structural properties commonly\nobserved in real-world systems, but are also tied to a number of applications\nin modeling and inference. While there are statistical packages for estimating\nvarious parametric forms of the preferential attachment function, there is no\nsuch package implementing non-parametric estimation procedures. The\nnon-parametric approach to the estimation of the preferential attachment\nfunction allows for comparatively finer-grained investigations of the\n`rich-get-richer' phenomenon that could lead to novel insights in the search to\nexplain certain nonstandard structural properties observed in real-world\nnetworks. This paper introduces the R package PAFit, which implements\nnon-parametric procedures for estimating the preferential attachment function\nand node fitnesses in a growing network, as well as a number of functions for\ngenerating complex networks from these two mechanisms. The main computational\npart of the package is implemented in C++ with OpenMP to ensure scalability to\nlarge-scale networks. We first introduce the main functionalities of PAFit\nthrough simulated examples, and then use the package to analyze a collaboration\nnetwork between scientists in the field of complex networks. The results\nindicate the joint presence of `rich-get-richer' and `fit-get-richer' phenomena\nin the collaboration network. The estimated attachment function is observed to\nbe near-linear, which we interpret as meaning that the chance an author gets a\nnew collaborator is proportional to their current number of collaborators.\nFurthermore, the estimated author fitnesses reveal a host of familiar faces\nfrom the complex networks community among the field's topmost fittest network\nscientists.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 05:19:13 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 09:14:52 GMT"}, {"version": "v3", "created": "Fri, 30 Jun 2017 02:14:46 GMT"}, {"version": "v4", "created": "Thu, 26 Apr 2018 15:52:38 GMT"}, {"version": "v5", "created": "Wed, 24 Oct 2018 04:26:11 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Pham", "Thong", ""], ["Sheridan", "Paul", ""], ["Shimodaira", "Hidetoshi", ""]]}, {"id": "1704.06064", "submitter": "Giacomo Zanella", "authors": "Omiros Papaspiliopoulos and Giacomo Zanella", "title": "A note on MCMC for nested multilevel regression models via belief\n  propagation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the quest for scalable Bayesian computational algorithms we need to\nexploit the full potential of existing methodologies. In this note we point out\nthat message passing algorithms, which are very well developed for inference in\ngraphical models, appear to be largely unexplored for scalable inference in\nBayesian multilevel regression models. We show that nested multilevel\nregression models with Gaussian errors lend themselves very naturally to the\ncombined use of belief propagation and MCMC. Specifically, the posterior\ndistribution of the regression parameters conditionally on covariance\nhyperparameters is a high-dimensional Gaussian that can be sampled exactly (as\nwell as marginalized) using belief propagation at a cost that scales linearly\nin the number of parameters and data. We derive an algorithm that works\nefficiently even for conditionally singular Gaussian distributions, e.g., when\nthere are linear constraints between the parameters at different levels. We\nshow that allowing for such non-invertible Gaussians is critical for belief\npropagation to be applicable to a large class of nested multilevel models. From\na different perspective, the methodology proposed can be seen as a\ngeneralization of forward-backward algorithms for sampling to multilevel\nregressions with tree-structure graphical models, as opposed to single-branch\ntrees used in classical Kalman filter contexts.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 09:39:54 GMT"}, {"version": "v2", "created": "Mon, 4 Sep 2017 16:19:10 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Papaspiliopoulos", "Omiros", ""], ["Zanella", "Giacomo", ""]]}, {"id": "1704.06374", "submitter": "Scott Sisson", "authors": "G. S. Rodrigues and D. Prangle and S. A. Sisson", "title": "Recalibration: A post-processing method for approximate Bayesian\n  computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new recalibration post-processing method is presented to improve the\nquality of the posterior approximation when using Approximate Bayesian\nComputation (ABC) algorithms. Recalibration may be used in conjunction with\nexisting post-processing methods, such as regression-adjustments. In addition,\nthis work extends and strengthens the links between ABC and indirect inference\nalgorithms, allowing more extensive use of misspecified auxiliary models in the\nABC context. The method is illustrated using simulated examples to demonstrate\nthe effects of recalibration under various conditions, and through an\napplication to an analysis of stereological extremes both with and without the\nuse of auxiliary models. Code to implement recalibration post-processing is\navailable in the R package, abctools.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 01:08:14 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Rodrigues", "G. S.", ""], ["Prangle", "D.", ""], ["Sisson", "S. A.", ""]]}, {"id": "1704.06947", "submitter": "Prabhat Kc", "authors": "Prabhat KC, K. Aditya Mohan, Charudatta Phatak, Charles Bouman, Marc\n  De Graef", "title": "3D Reconstruction of the Magnetic Vector Potential using Model Based\n  Iterative Reconstruction", "comments": "28 pages, 14 figures, submitted to Ultramicroscopy", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cond-mat.mes-hall cond-mat.mtrl-sci physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lorentz Transmission Electron Microscopy (TEM) observations of magnetic\nnanoparticles contain information on the magnetic and electrostatic potentials.\nVector Field Electron Tomography (VFET) can be used to reconstruct\nelectromagnetic potentials of the nanoparticles from their corresponding LTEM\nimages. The VFET approach is based on the conventional filtered back projection\napproach to tomographic reconstructions and the availability of an incomplete\nset of measurements due to experimental limitations means that the\nreconstructed vector fields exhibit significant artifacts. In this paper, we\noutline a model-based iterative reconstruction (MBIR) algorithm to reconstruct\nthe magnetic vector potential of magnetic nanoparticles. We combine a forward\nmodel for image formation in TEM experiments with a prior model to formulate\nthe tomographic problem as a maximum a-posteriori probability estimation\nproblem (MAP). The MAP cost function is minimized iteratively to determine the\nvector potential. A comparative reconstruction study of simulated as well as\nexperimental data sets show that the MBIR approach yields quantifiably better\nreconstructions than the VFET approach.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 16:23:33 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["KC", "Prabhat", ""], ["Mohan", "K. Aditya", ""], ["Phatak", "Charudatta", ""], ["Bouman", "Charles", ""], ["De Graef", "Marc", ""]]}, {"id": "1704.06988", "submitter": "Matthias Katzfuss", "authors": "Matthias Katzfuss, Jonathan R. Stroud, Christopher K. Wikle", "title": "Ensemble Kalman methods for high-dimensional hierarchical dynamic\n  space-time models", "comments": null, "journal-ref": "Journal of the American Statistical Association, Theory & Methods\n  (2019+)", "doi": "10.1080/01621459.2019.1592753", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new class of filtering and smoothing methods for inference in\nhigh-dimensional, nonlinear, non-Gaussian, spatio-temporal state-space models.\nThe main idea is to combine the ensemble Kalman filter and smoother, developed\nin the geophysics literature, with state-space algorithms from the statistics\nliterature. Our algorithms address a variety of estimation scenarios, including\non-line and off-line state and parameter estimation. We take a Bayesian\nperspective, for which the goal is to generate samples from the joint posterior\ndistribution of states and parameters. The key benefit of our approach is the\nuse of ensemble Kalman methods for dimension reduction, which allows inference\nfor high-dimensional state vectors. We compare our methods to existing ones,\nincluding ensemble Kalman filters, particle filters, and particle MCMC. Using a\nreal data example of cloud motion and data simulated under a number of\nnonlinear and non-Gaussian scenarios, we show that our approaches outperform\nthese existing methods.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 21:51:54 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2018 22:03:51 GMT"}], "update_date": "2019-03-22", "authors_parsed": [["Katzfuss", "Matthias", ""], ["Stroud", "Jonathan R.", ""], ["Wikle", "Christopher K.", ""]]}, {"id": "1704.07223", "submitter": "Jack Fitzsimons", "authors": "Jack Fitzsimons, Diego Granziol, Kurt Cutajar, Michael Osborne,\n  Maurizio Filippone, Stephen Roberts", "title": "Entropic Trace Estimates for Log Determinants", "comments": "16 pages, 4 figures, 2 tables, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.IT math.IT stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scalable calculation of matrix determinants has been a bottleneck to the\nwidespread application of many machine learning methods such as determinantal\npoint processes, Gaussian processes, generalised Markov random fields, graph\nmodels and many others. In this work, we estimate log determinants under the\nframework of maximum entropy, given information in the form of moment\nconstraints from stochastic trace estimation. The estimates demonstrate a\nsignificant improvement on state-of-the-art alternative methods, as shown on a\nwide variety of UFL sparse matrices. By taking the example of a general Markov\nrandom field, we also demonstrate how this approach can significantly\naccelerate inference in large-scale learning methods involving the log\ndeterminant.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 13:45:21 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Fitzsimons", "Jack", ""], ["Granziol", "Diego", ""], ["Cutajar", "Kurt", ""], ["Osborne", "Michael", ""], ["Filippone", "Maurizio", ""], ["Roberts", "Stephen", ""]]}, {"id": "1704.07272", "submitter": "Kody Law", "authors": "Ajay Jasra, Kody Law, and Carina Suciu", "title": "Advanced Multilevel Monte Carlo Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article reviews the application of advanced Monte Carlo techniques in\nthe context of Multilevel Monte Carlo (MLMC). MLMC is a strategy employed to\ncompute expectations which can be biased in some sense, for instance, by using\nthe discretization of a associated probability law. The MLMC approach works\nwith a hierarchy of biased approximations which become progressively more\naccurate and more expensive. Using a telescoping representation of the most\naccurate approximation, the method is able to reduce the computational cost for\na given level of error versus i.i.d. sampling from this latter approximation.\nAll of these ideas originated for cases where exact sampling from couples in\nthe hierarchy is possible. This article considers the case where such exact\nsampling is not currently possible. We consider Markov chain Monte Carlo and\nsequential Monte Carlo methods which have been introduced in the literature and\nwe describe different strategies which facilitate the application of MLMC\nwithin these methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 15:08:32 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Jasra", "Ajay", ""], ["Law", "Kody", ""], ["Suciu", "Carina", ""]]}, {"id": "1704.07414", "submitter": "Ricardo Ehlers", "authors": "Ian M Danilevicz, Ricardo S Ehlers", "title": "BDSAR: a new package on Bregman divergence for Bayesian simultaneous\n  autoregressive models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  BDSAR is an R package which estimates distances between probability\ndistributions and facilitates a dynamic and powerful analysis of diagnostics\nfor Bayesian models from the class of Simultaneous Autoregressive (SAR) spatial\nmodels. The package offers a new and fine plot to compare models as well as it\nworks in an intuitive way to allow any analyst to easily build fine plots.\nThese are helpful to promote insights about influential observations in the\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 18:48:32 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Danilevicz", "Ian M", ""], ["Ehlers", "Ricardo S", ""]]}, {"id": "1704.07645", "submitter": "Fabrizio Leisen", "authors": "Alan Riva Palacio and Fabrizio Leisen", "title": "Bayesian nonparametric estimation of survival functions with\n  multiple-samples information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real problems, dependence structures more general than\nexchangeability are required. For instance, in some settings partial\nexchangeability is a more reasonable assumption. For this reason, vectors of\ndependent Bayesian nonparametric priors have recently gained popularity. They\nprovide flexible models which are tractable from a computational and\ntheoretical point of view. In this paper, we focus on their use for estimating\nsurvival functions with multiple-samples information. Our methodology allows to\nmodel the dependence among survival times of different groups of observations\nand extend previous work to an arbitrary dimension . Theoretical results about\nthe posterior behaviour of the underlying dependent vector of completely random\nmeasures are provided. The performance of the model is tested on a simulated\ndataset arising from a distributional Clayton copula.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 11:52:11 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 13:52:33 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Palacio", "Alan Riva", ""], ["Leisen", "Fabrizio", ""]]}, {"id": "1704.07806", "submitter": "David Woodruff", "authors": "David L. Woodruff (1) and Stefan Zillmann (2) ((1) University of\n  California Davis (2) University of Duisburg-Essen)", "title": "A Note on Experiments and Software For Multidimensional Order Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note we describe experiments on an implementation of two methods\nproposed in the literature for computing regions that correspond to a notion of\norder statistics for multidimensional data. Our implementation, which works for\nany dimension greater than one, is the only that we know of to be publicly\navailable. Experiments run using the software confirm that half-space peeling\ngenerally gives better results than directly peeling convex hulls, but at a\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 17:34:52 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Woodruff", "David L.", ""], ["Zillmann", "Stefan", ""]]}, {"id": "1704.07949", "submitter": "Keith Pedersen", "authors": "Keith Pedersen", "title": "Reconditioning your quantile function", "comments": "11 pages, 3 figures, 2 algorithms", "journal-ref": null, "doi": null, "report-no": "IIT-CAPP-17-1", "categories": "stat.CO physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monte Carlo simulation is an important tool for modeling highly nonlinear\nsystems (like particle colliders and cellular membranes), and random,\nfloating-point numbers are their fuel. These random samples are frequently\ngenerated via the inversion method, which harnesses the mapping of the quantile\nfunction Q(u) (e.g. to generate proposal variates for rejection sampling). Yet\nthe increasingly large sample size of these simulations makes them vulnerable\nto a flaw in the inversion method; Q(u) is ill-conditioned in a distribution's\ntails, stripping precision from its sample. This flaw stems from limitations in\nmachine arithmetic which are often overlooked during implementation (e.g. in\npopular C++ and Python libraries). This paper introduces a robust inversion\nmethod, which reconditions Q(u) by carefully drawing and using uniform\nvariates. pqRand, a free C++ and Python package, implements this novel method\nfor a number of popular distributions (exponential, normal, gamma, and more).\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 02:37:12 GMT"}, {"version": "v2", "created": "Sat, 10 Jun 2017 00:00:01 GMT"}, {"version": "v3", "created": "Thu, 15 Feb 2018 05:08:32 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Pedersen", "Keith", ""]]}, {"id": "1704.08742", "submitter": "Patrick Breheny", "authors": "Yaohui Zeng, Tianbao Yang, Patrick Breheny", "title": "Hybrid safe-strong rules for efficient optimization in lasso-type\n  problems", "comments": "31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lasso model has been widely used for model selection in data mining,\nmachine learning, and high-dimensional statistical analysis. However, with the\nultrahigh-dimensional, large-scale data sets now collected in many real-world\napplications, it is important to develop algorithms to solve the lasso that\nefficiently scale up to problems of this size. Discarding features from certain\nsteps of the algorithm is a powerful technique for increasing efficiency and\naddressing the Big Data challenge. In this paper, we propose a family of hybrid\nsafe-strong rules (HSSR) which incorporate safe screening rules into the\nsequential strong rule (SSR) to remove unnecessary computational burden. In\nparticular, we present two instances of HSSR, namely SSR-Dome and SSR-BEDPP,\nfor the standard lasso problem. We further extend SSR-BEDPP to the elastic net\nand group lasso problems to demonstrate the generalizability of the hybrid\nscreening idea. Extensive numerical experiments with synthetic and real data\nsets are conducted for both the standard lasso and the group lasso problems.\nResults show that our proposed hybrid rules can substantially outperform\nexisting state-of-the-art rules.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 20:53:16 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 19:41:25 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 16:27:57 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Zeng", "Yaohui", ""], ["Yang", "Tianbao", ""], ["Breheny", "Patrick", ""]]}, {"id": "1704.08891", "submitter": "Edouard Ollier", "authors": "Gersende Fort, Edouard Ollier, Adeline Samson", "title": "Stochastic Proximal Gradient Algorithms for Penalized Mixed Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by penalized likelihood maximization in complex models, we study\noptimization problems where neither the function to optimize nor its gradient\nhave an explicit expression, but its gradient can be approximated by a Monte\nCarlo technique. We propose a new algorithm based on a stochastic approximation\nof the Proximal-Gradient (PG) algorithm. This new algorithm, named Stochastic\nApproximation PG (SAPG) is the combination of a stochastic gradient descent\nstep which - roughly speaking - computes a smoothed approximation of the past\ngradient along the iterations, and a proximal step. The choice of the step size\nand the Monte Carlo batch size for the stochastic gradient descent step in SAPG\nare discussed. Our convergence results cover the cases of biased and unbiased\nMonte Carlo approximations. While the convergence analysis of the Monte\nCarlo-PG is already addressed in the literature (see Atchad\\'e et al. [2016]),\nthe convergence analysis of SAPG is new. The two algorithms are compared on a\nlinear mixed effect model as a toy example. A more challenging application is\nproposed on non-linear mixed effect models in high dimension with a\npharmacokinetic data set including genomic covariates. To our best knowledge,\nour work provides the first convergence result of a numerical method designed\nto solve penalized Maximum Likelihood in a non-linear mixed effect model.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 12:08:39 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 08:55:47 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Fort", "Gersende", ""], ["Ollier", "Edouard", ""], ["Samson", "Adeline", ""]]}]