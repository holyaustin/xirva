[{"id": "1710.01452", "submitter": "Xuefeng Gao", "authors": "Xuefeng Gao, Xiang Zhou, Lingjiong Zhu", "title": "Transform Analysis for Hawkes Processes with Applications in Dark Pool\n  Trading", "comments": null, "journal-ref": "Quantitative Finance, 2018 Vol. 18, No. 2, 265-282", "doi": null, "report-no": null, "categories": "q-fin.TR math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hawkes processes are a class of simple point processes that are self-exciting\nand have clustering effect, with wide applications in finance, social networks\nand many other fields. This paper considers a self-exciting Hawkes process\nwhere the baseline intensity is time-dependent, the exciting function is a\ngeneral function and the jump sizes of the intensity process are independent\nand identically distributed non-negative random variables. This Hawkes model is\nnon-Markovian in general. We obtain closed-form formulas for the Laplace\ntransform, moments and the distribution of the Hawkes process. To illustrate\nthe applications of our results, we use the Hawkes process to model the\nclustered arrival of trades in a dark pool and analyze various performance\nmetrics including time-to-first-fill, time-to-complete-fill and the expected\nfill rate of a resting dark order.\n", "versions": [{"version": "v1", "created": "Wed, 4 Oct 2017 03:25:47 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Gao", "Xuefeng", ""], ["Zhou", "Xiang", ""], ["Zhu", "Lingjiong", ""]]}, {"id": "1710.03734", "submitter": "Michael Benzaquen", "authors": "Michael Benzaquen and Jean-Philippe Bouchaud", "title": "Market impact with multi-timescale liquidity", "comments": "17 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extended version of the recently proposed \"LLOB\" model for the\ndynamics of latent liquidity in financial markets. By allowing for finite\ncancellation and deposition rates within a continuous reaction-diffusion setup,\nwe account for finite memory effects on the dynamics of the latent order book.\nWe compute in particular the finite memory corrections to the square root\nimpact law, as well as the impact decay and the permanent impact of a\nmeta-order. The latter is found to be linear in the traded volume and\nindependent of the trading rate, as dictated by no-arbitrage arguments. In\naddition, we consider the case of a spectrum of cancellation and deposition\nrates, which allows us to obtain a square root impact law for moderate\nparticipation rates, as observed empirically. Our multi-scale framework also\nprovides an alternative solution to the so-called price diffusivity puzzle in\nthe presence of a long-range correlated order flow.\n", "versions": [{"version": "v1", "created": "Tue, 10 Oct 2017 17:26:02 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 15:32:38 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Benzaquen", "Michael", ""], ["Bouchaud", "Jean-Philippe", ""]]}, {"id": "1710.03870", "submitter": "Matthew Dixon", "authors": "Matthew F Dixon", "title": "A High Frequency Trade Execution Model for Supervised Learning", "comments": "arXiv admin note: substantial text overlap with arXiv:1707.05642,\n  High Frequency, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a high frequency trade execution model to evaluate the\neconomic impact of supervised machine learners. Extending the concept of a\nconfusion matrix, we present a 'trade information matrix' to attribute the\nexpected profit and loss of the high frequency strategy under execution\nconstraints, such as fill probabilities and position dependent trade rules, to\ncorrect and incorrect predictions. We apply the trade execution model and trade\ninformation matrix to Level II E-mini S&P 500 futures history and demonstrate\nan estimation approach for measuring the sensitivity of the P&L to the error of\na Recurrent Neural Network. Our approach directly evaluates the performance\nsensitivity of a market making strategy to prediction error and augments\ntraditional market simulation based testing.\n", "versions": [{"version": "v1", "created": "Wed, 11 Oct 2017 00:57:26 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 16:38:59 GMT"}, {"version": "v3", "created": "Tue, 5 Dec 2017 16:56:57 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Dixon", "Matthew F", ""]]}, {"id": "1710.06350", "submitter": "Ilija Zovko", "authors": "Ilija I. Zovko", "title": "Navigating dark liquidity (How Fisher catches Poisson in the Dark)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to reduce signalling, traders may resort to limiting access to dark\nvenues and imposing limits on minimum fill sizes they are willing to trade.\nHowever, doing this also restricts the liquidity available to the trader since\nan ever increasing quantity of orders are traded by algos in clips. An\nalternative is to attempt to monitor signalling in real time and dynamically\nmake adjustments to the dark liquidity accessed.\n  In practice, price slippage against the order is commonly taken as an\nindication of signalling. However, estimating slippage is difficult and\nrequires a large number of fills to reliably detect it. Ultimately, even if\ndetected, it fails to capture an important element of causality between dark\nfills and lit prints - a signature of information leakage. In the extreme, this\ncan lead to scaling back trading at a time when slippage is caused by a\ncompeting trader consuming liquidity, and the appropriate action would be to\nscale trading up -- not down -- in order to capture good prices.\n  In this paper we describe a methodology aimed to address this dichotomy of\ntrading objectives, allowing to maximally capture available liquidity while at\nthe same time protecting the trader from excessive signalling. The method is\ndesigned to profile dark liquidity in a dynamic fashion, on a per fill basis,\nin contrast to historical venue analyses based on estimated slippage. This\nallows for a dynamic and real-time control of the desired liquidity exposure.\n", "versions": [{"version": "v1", "created": "Tue, 17 Oct 2017 15:47:02 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Zovko", "Ilija I.", ""]]}, {"id": "1710.07959", "submitter": "Shanshan Wang", "authors": "Shanshan Wang, Sebastian Neus\\\"u{\\ss} and Thomas Guhr", "title": "Grasping asymmetric information in market impacts", "comments": null, "journal-ref": "Eur. Phys. J. B (2018) 91: 266", "doi": "10.1140/epjb/e2018-80599-5", "report-no": null, "categories": "q-fin.TR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The price impact for a single trade is estimated by the immediate response on\nan event time scale, i.e., the immediate change of midpoint prices before and\nafter a trade. We work out the price impacts across a correlated financial\nmarket. We quantify the asymmetries of the distributions and of the market\nstructures of cross-impacts, and find that the impacts across the market are\nasymmetric and non-random. Using spectral statistics and Shannon entropy, we\nvisualize the asymmetric information in price impacts. Also, we introduce an\nentropy of impacts to estimate the randomness between stocks. We show that the\nuseful information is encoded in the impacts corresponding to small entropy.\nThe stocks with large number of trades are more likely to impact others, while\nthe less traded stocks have higher probability to be impacted by others.\n", "versions": [{"version": "v1", "created": "Sun, 22 Oct 2017 15:10:56 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 08:36:52 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Wang", "Shanshan", ""], ["Neus\u00fc\u00df", "Sebastian", ""], ["Guhr", "Thomas", ""]]}, {"id": "1710.08860", "submitter": "Jean De Carufel", "authors": "Jean de Carufel and Martin Brooks and Michael Stieber and Paul Britton", "title": "A Topological Approach to Scaling in Financial Data", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a large body of work, built on tools developed in mathematics and\nphysics, demonstrating that financial market prices exhibit self-similarity at\ndifferent scales. In this paper, we explore the use of analytical topology to\ncharacterize financial price series. While wavelet and Fourier transforms\ndecompose a signal into sets of wavelets and power spectrum respectively, the\napproach presented herein decomposes a time series into components of its total\nvariation. This property is naturally suited for the analysis of scaling\ncharacteristics in fractals.\n", "versions": [{"version": "v1", "created": "Tue, 24 Oct 2017 15:56:29 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["de Carufel", "Jean", ""], ["Brooks", "Martin", ""], ["Stieber", "Michael", ""], ["Britton", "Paul", ""]]}]