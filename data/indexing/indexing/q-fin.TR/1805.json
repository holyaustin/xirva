[{"id": "1805.00268", "submitter": "Johannes Bock", "authors": "Johannes Bock", "title": "Quantifying macroeconomic expectations in stock markets using Google\n  Trends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among other macroeconomic indicators, the monthly release of U.S.\nunemployment rate figures in the Employment Situation report by the U.S. Bureau\nof Labour Statistics gets a lot of media attention and strongly affects the\nstock markets. I investigate whether a profitable investment strategy can be\nconstructed by predicting the likely changes in U.S. unemployment before the\nofficial news release using Google query volumes for related search terms. I\nfind that massive new data sources of human interaction with the Internet not\nonly improves U.S. unemployment rate predictability, but can also enhance\nmarket timing of trading strategies when considered jointly with macroeconomic\ndata. My results illustrate the potential of combining extensive behavioural\ndata sets with economic data to anticipate investor expectations and stock\nmarket moves.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 10:35:26 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Bock", "Johannes", ""]]}, {"id": "1805.02741", "submitter": "Mathieu Rosenbaum", "authors": "Omar El Euch, Thibaut Mastrolia, Mathieu Rosenbaum, Nizar Touzi", "title": "Optimal make-take fees for market making regulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an exchange who wishes to set suitable make-take fees to attract\nliquidity on its platform. Using a principal-agent approach, we are able to\ndescribe in quasi-explicit form the optimal contract to propose to a market\nmaker. This contract depends essentially on the market maker inventory\ntrajectory and on the volatility of the asset. We also provide the optimal\nquotes that should be displayed by the market maker. The simplicity of our\nformulas allows us to analyze in details the effects of optimal contracting\nwith an exchange, compared to a situation without contract. We show in\nparticular that it leads to higher quality liquidity and lower trading costs\nfor investors.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 20:59:46 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 22:11:57 GMT"}], "update_date": "2019-11-27", "authors_parsed": [["Euch", "Omar El", ""], ["Mastrolia", "Thibaut", ""], ["Rosenbaum", "Mathieu", ""], ["Touzi", "Nizar", ""]]}, {"id": "1805.04728", "submitter": "Wonse Kim", "authors": "Wonse Kim, Sungjae Jun", "title": "Effects of a Price limit Change on Market Stability at the Intraday\n  Horizon in the Korean Stock Market", "comments": "Accepted in Applied Economics Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the effects of a price limit change on the volatility\nof the Korean stock market's (KRX) intraday stock price process. Based on the\nmost recent transaction data from the KRX, which experienced a change in the\nprice limit on June 15, 2015, we examine the change in realized variance after\nthe price limit change to investigate the overall effects of the change on the\nintraday market volatility. We then analyze the effects in more detail by\napplying the discrete Fourier transform (DFT) to the data set. We find evidence\nthat the market becomes more volatile in the intraday horizon because of the\nincrease in the amplitudes of the low-frequency components of the price\nprocesses after the price limit change. Therefore, liquidity providers are in a\nworse situation than they were prior to the change.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 14:56:03 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Kim", "Wonse", ""], ["Jun", "Sungjae", ""]]}, {"id": "1805.06682", "submitter": "Ioane Muni Toke", "authors": "Ioane Muni Toke and Nakahiro Yoshida", "title": "Analyzing order flows in limit order books with ratios of Cox-type\n  intensities", "comments": "38 pages, 9 figures, 3 tables", "journal-ref": null, "doi": "10.1080/14697688.2019.1637927", "report-no": null, "categories": "q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Cox-type model for relative intensities of orders flows in a\nlimit order book. The model assumes that all intensities share a common\nbaseline intensity, which may for example represent the global market activity.\nParameters can be estimated by quasi likelihood maximization, without any\ninterference from the baseline intensity. Consistency and asymptotic behavior\nof the estimators are given in several frameworks, and model selection is\ndiscussed with information criteria and penalization. The model is well-suited\nfor high-frequency financial data: fitted models using easily interpretable\ncovariates show an excellent agreement with empirical data. Extensive\ninvestigation on tick data consequently helps identifying trading signals and\nimportant factors determining the limit order book dynamics. We also illustrate\nthe potential use of the framework for out-of-sample predictions.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 10:22:20 GMT"}, {"version": "v2", "created": "Tue, 12 Mar 2019 08:56:15 GMT"}, {"version": "v3", "created": "Thu, 22 Aug 2019 13:01:58 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Toke", "Ioane Muni", ""], ["Yoshida", "Nakahiro", ""]]}, {"id": "1805.07134", "submitter": "Paul Jusselin", "authors": "Paul Jusselin and Mathieu Rosenbaum", "title": "No-arbitrage implies power-law market impact and rough volatility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.MF q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Market impact is the link between the volume of a (large) order and the price\nmove during and after the execution of this order. We show that under\nno-arbitrage assumption, the market impact function can only be of power-law\ntype. Furthermore, we prove that this implies that the macroscopic price is\ndiffusive with rough volatility, with a one-to-one correspondence between the\nexponent of the impact function and the Hurst parameter of the volatility.\nHence we simply explain the universal rough behavior of the volatility as a\nconsequence of the no-arbitrage property. From a mathematical viewpoint, our\nstudy relies in particular on new results about hyper-rough stochastic Volterra\nequations.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 10:46:35 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Jusselin", "Paul", ""], ["Rosenbaum", "Mathieu", ""]]}, {"id": "1805.07478", "submitter": "Son Le", "authors": "Son Le", "title": "Algorithmic Trading with Fitted Q Iteration and Heston Model", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the use of the fitted Q iteration in algorithmic trading. We show\nthat the fitted Q iteration helps alleviate the dimension problem that the\nbasic Q-learning algorithm faces in application to trading. Furthermore, we\nintroduce a procedure including model fitting and data simulation to enrich\ntraining data as the lack of data is often a problem in realistic application.\nWe experiment our method on both simulated environment that permits arbitrage\nopportunity and real-world environment by using prices of 450 stocks. In the\nformer environment, the method performs well, implying that our method works in\ntheory. To perform well in the real-world environment, the agents trained might\nrequire more training (iteration) and more meaningful variables with predictive\nvalue.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:47:31 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Le", "Son", ""]]}, {"id": "1805.08454", "submitter": "James Paulin", "authors": "James Paulin, Anisoara Calinescu and Michael Wooldridge", "title": "Understanding Flash Crash Contagion and Systemic Risk: A Micro-Macro\n  Agent-Based Approach", "comments": "37 pages, 9 figures", "journal-ref": "Journal of Economic Dynamics and Control 100 (2019) p.200-229", "doi": "10.1016/j.jedc.2018.12.008", "report-no": null, "categories": "q-fin.TR cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to advance the understanding of the conditions\nthat give rise to flash crash contagion, particularly with respect to\noverlapping asset portfolio crowding. To this end, we designed, implemented,\nand assessed a hybrid micro-macro agent-based model, where price impact arises\nendogenously through the limit order placement activity of algorithmic traders.\nOur novel hybrid microscopic and macroscopic model allows us to quantify\nsystemic risk not just in terms of system stability, but also in terms of the\nspeed of financial distress propagation over intraday timescales. We find that\nsystemic risk is strongly dependent on the behaviour of algorithmic traders, on\nleverage management practices, and on network topology. Our results demonstrate\nthat, for high-crowding regimes, contagion speed is a non-monotone function of\nportfolio diversification. We also find the surprising result that, in certain\ncircumstances, increased portfolio crowding is beneficial to systemic\nstability. We are not aware of previous studies that have exhibited this\nphenomenon, and our results establish the importance of considering non-uniform\nasset allocations in future studies. Finally, we characterise the time window\navailable for regulatory interventions during the propagation of flash crash\ndistress, with results suggesting ex ante precautions may have higher efficacy\nthan ex post reactions.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 08:30:52 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Paulin", "James", ""], ["Calinescu", "Anisoara", ""], ["Wooldridge", "Michael", ""]]}, {"id": "1805.08550", "submitter": "Laura Alessandretti", "authors": "Laura Alessandretti, Abeer ElBahrawy, Luca Maria Aiello, Andrea\n  Baronchelli", "title": "Anticipating cryptocurrency prices using machine learning", "comments": "Complexity, 2018", "journal-ref": null, "doi": "10.1155/2018/8983590", "report-no": null, "categories": "physics.soc-ph cs.LG q-fin.GN q-fin.ST q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and AI-assisted trading have attracted growing interest for\nthe past few years. Here, we use this approach to test the hypothesis that the\ninefficiency of the cryptocurrency market can be exploited to generate abnormal\nprofits. We analyse daily data for $1,681$ cryptocurrencies for the period\nbetween Nov. 2015 and Apr. 2018. We show that simple trading strategies\nassisted by state-of-the-art machine learning algorithms outperform standard\nbenchmarks. Our results show that nontrivial, but ultimately simple,\nalgorithmic mechanisms can help anticipate the short-term evolution of the\ncryptocurrency market.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 12:45:54 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 13:49:41 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2018 12:33:33 GMT"}, {"version": "v4", "created": "Fri, 9 Nov 2018 09:05:02 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Alessandretti", "Laura", ""], ["ElBahrawy", "Abeer", ""], ["Aiello", "Luca Maria", ""], ["Baronchelli", "Andrea", ""]]}, {"id": "1805.09763", "submitter": "Daniel Fraiman", "authors": "Daniel Fraiman", "title": "A self-organized criticality participative pricing mechanism for selling\n  zero-marginal cost products", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's economy, selling a new zero-marginal cost product is a real\nchallenge, as it is difficult to determine a product's \"correct\" sales price\nbased on its profit and dissemination. As an example, think of the price of a\nnew app or video game. New sales mechanisms for selling this type of product\nneed to be designed, in particular ones that consider consumer preferences and\nreality. Current auction mechanisms establish a time deadline for the auction\nto take place. This deadline is set to increase the number of bidders and thus\nthe final offering price. Consumers want to obtain the product as quickly as\npossible from the moment they become interested in it, and this time does not\nalways coincide with the seller's deadline. Naturally, consumers also want to\npay a price they consider \"fair\". Here we introduce an auction model where\nbuyers continuously place bids and the challenge is to decide quickly whether\nor not to accept them. The model does not include a deadline for placing bids,\nand exhibits self-organized criticality; it presents a critical price from\nwhich a bid is accepted with probability one, and avalanches of sales above\nthis value are observed. This model is of particular interest for startup\ncompanies interested in profit as well as making the product known on the\nmarket.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 16:28:32 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 02:31:51 GMT"}, {"version": "v3", "created": "Thu, 7 Jan 2021 18:27:11 GMT"}, {"version": "v4", "created": "Mon, 26 Apr 2021 14:10:34 GMT"}, {"version": "v5", "created": "Thu, 17 Jun 2021 17:57:07 GMT"}], "update_date": "2021-06-18", "authors_parsed": [["Fraiman", "Daniel", ""]]}, {"id": "1805.11036", "submitter": "Torsten Trimborn", "authors": "Torsten Trimborn", "title": "A Macroscopic Portfolio Model: From Rational Agents to Bounded\n  Rationality", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.03291", "journal-ref": null, "doi": "10.1007/s11579-019-00235-z", "report-no": null, "categories": "q-fin.PM math.DS q-fin.CP q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a microscopic model of interacting financial agents, where each\nagent is characterized by two portfolios; money invested in bonds and money\ninvested in stocks. Furthermore, each agent is faced with an optimization\nproblem in order to determine the optimal asset allocation. The stock price\nevolution is driven by the aggregated investment decision of all agents. In\nfact, we are faced with a differential game since all agents aim to invest\noptimal. Mathematically such a problem is ill posed and we introduce the\nconcept of Nash equilibrium solutions to ensure the existence of a solution.\nEspecially, we denote an agent who solves this Nash equilibrium exactly a\nrational agent. As next step we use model predictive control to approximate the\ncontrol problem. This enables us to derive a precise mathematical\ncharacterization of the degree of rationality of a financial agent. This is a\nnovel concept in portfolio optimization and can be regarded as a general\napproach. In a second step we consider the case of a fully myopic agent, where\nwe can solve the optimal investment decision of investors analytically. We\nselect the running cost to be the expected missed revenue of an agent and we\nassume quadratic transaction costs. More precisely the expected revenues are\ndetermined by a combination of a fundamentalist or chartist strategy. Then we\nderive the mean field limit of the microscopic model in order to obtain a\nmacroscopic portfolio model. The novelty in comparison to existent\nmacroeconomic models in literature is that our model is derived from\nmicroeconomic dynamics. The resulting portfolio model is a three dimensional\nODE system which enables us to derive analytical results. Simulations reveal,\nthat our model is able to replicate the most prominent features of financial\nmarkets, namely booms and crashes.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 09:28:21 GMT"}, {"version": "v2", "created": "Fri, 26 Oct 2018 14:37:17 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Trimborn", "Torsten", ""]]}]