[{"id": "0706.0153", "submitter": "Gabriela Ciuperca", "authors": "Gabriela Ciuperca", "title": "The M-estimator in a multi-phase random nonlinear model", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers M-estimation of a nonlinear regression model with\nmultiple change-points occuring at unknown times. The multi-phase random design\nregression model, discontinuous in each change-point, have an arbitrary error\n$\\epsilon$. In the case when the number of jumps is known, the M-estimator of\nlocations of breaks and of regression parameters are studied. These estimators\nare consistent and the distribution of the regression parameter estimators is\nGaussian. The estimator of each change-point converges, with the rate $n^{-1}$,\nto the smallest minimizer of the independent compound Poisson processes. The\nresults are valid for a large class of error distributions.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2007 13:33:22 GMT"}, {"version": "v2", "created": "Fri, 4 Jul 2008 08:43:56 GMT"}, {"version": "v3", "created": "Mon, 22 Sep 2008 08:08:10 GMT"}], "update_date": "2008-09-22", "authors_parsed": [["Ciuperca", "Gabriela", ""]]}, {"id": "0706.1062", "submitter": "Aaron Clauset", "authors": "Aaron Clauset, Cosma Rohilla Shalizi, M. E. J. Newman", "title": "Power-law distributions in empirical data", "comments": "43 pages, 11 figures, 7 tables, 4 appendices; code available at\n  http://www.santafe.edu/~aaronc/powerlaws/", "journal-ref": "SIAM Review 51, 661-703 (2009)", "doi": "10.1137/070710111", "report-no": null, "categories": "physics.data-an cond-mat.dis-nn stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power-law distributions occur in many situations of scientific interest and\nhave significant consequences for our understanding of natural and man-made\nphenomena. Unfortunately, the detection and characterization of power laws is\ncomplicated by the large fluctuations that occur in the tail of the\ndistribution -- the part of the distribution representing large but rare events\n-- and by the difficulty of identifying the range over which power-law behavior\nholds. Commonly used methods for analyzing power-law data, such as\nleast-squares fitting, can produce substantially inaccurate estimates of\nparameters for power-law distributions, and even in cases where such methods\nreturn accurate answers they are still unsatisfactory because they give no\nindication of whether the data obey a power law at all. Here we present a\nprincipled statistical framework for discerning and quantifying power-law\nbehavior in empirical data. Our approach combines maximum-likelihood fitting\nmethods with goodness-of-fit tests based on the Kolmogorov-Smirnov statistic\nand likelihood ratios. We evaluate the effectiveness of the approach with tests\non synthetic data and give critical comparisons to previous approaches. We also\napply the proposed methods to twenty-four real-world data sets from a range of\ndifferent disciplines, each of which has been conjectured to follow a power-law\ndistribution. In some cases we find these conjectures to be consistent with the\ndata while in others the power law is ruled out.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2007 19:33:07 GMT"}, {"version": "v2", "created": "Mon, 2 Feb 2009 17:49:43 GMT"}], "update_date": "2009-11-12", "authors_parsed": [["Clauset", "Aaron", ""], ["Shalizi", "Cosma Rohilla", ""], ["Newman", "M. E. J.", ""]]}, {"id": "0706.1287", "submitter": "Robert Kohn", "authors": "Helen Armstrong, Christopher K. Carter, Kevin F. Wong and Robert Kohn", "title": "Bayesian Covariance Matrix Estimation using a Mixture of Decomposable\n  Graphical Models", "comments": "28 pages and 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  A Bayesian approach is used to estimate the covariance matrix of Gaussian\ndata. Ideas from Gaussian graphical models and model selection are used to\nconstruct a prior for the covariance matrix that is a mixture over all\ndecomposable graphs. For this prior the probability of each graph size is\nspecified by the user and graphs of equal size are assigned equal probability.\nMost previous approaches assume that all graphs are equally probable. We show\nempirically that the prior that assigns equal probability over graph sizes\noutperforms the prior that assigns equal probability over all graphs, both in\nidentifying the correct decomposable graph and in more efficiently estimating\nthe covariance matrix.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2007 04:55:02 GMT"}], "update_date": "2007-06-12", "authors_parsed": [["Armstrong", "Helen", ""], ["Carter", "Christopher K.", ""], ["Wong", "Kevin F.", ""], ["Kohn", "Robert", ""]]}, {"id": "0706.1408", "submitter": "Luke A. Prendergast", "authors": "Luke A. Prendergast, Jodie A. Smith", "title": "Sensitivity of principal Hessian direction analysis", "comments": "Published at http://dx.doi.org/10.1214/07-EJS064 in the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2007, Vol. 1, 253-267", "doi": "10.1214/07-EJS064", "report-no": "IMS-EJS-EJS_2007_64", "categories": "stat.ME", "license": null, "abstract": "  We provide sensitivity comparisons for two competing versions of the\ndimension reduction method principal Hessian directions (pHd). These\ncomparisons consider the effects of small perturbations on the estimation of\nthe dimension reduction subspace via the influence function. We show that the\ntwo versions of pHd can behave completely differently in the presence of\ncertain observational types. Our results also provide evidence that outliers in\nthe traditional sense may or may not be highly influential in practice. Since\ninfluential observations may lurk within otherwise typical data, we consider\nthe influence function in the empirical setting for the efficient detection of\ninfluential observations in practice.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2007 06:36:56 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Prendergast", "Luke A.", ""], ["Smith", "Jodie A.", ""]]}, {"id": "0706.1776", "submitter": "Roberto D. Pascual-Marqui", "authors": "Roberto D. Pascual-Marqui", "title": "Coherence and phase synchronization: generalization to pairs of\n  multivariate time series, and removal of zero-lag contributions", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": null, "abstract": "  Coherence and phase synchronization between time series corresponding to\ndifferent spatial locations are usually interpreted as indicators of the\nconnectivity between locations. In neurophysiology, time series of electric\nneuronal activity are essential for studying brain interconnectivity. Such\nsignals can either be invasively measured from depth electrodes, or computed\nfrom very high time resolution, non-invasive, extracranial recordings of scalp\nelectric potential differences (EEG: electroencephalogram) and magnetic fields\n(MEG: magnetoencephalogram) by means of a tomography such as sLORETA\n(standardized low resolution brain electromagnetic tomography). There are two\nproblems in this case. First, in the usual situation of unknown cortical\ngeometry, the estimated signal at each brain location is a vector with three\ncomponents (i.e. a current density vector), which means that coherence and\nphase synchronization must be generalized to pairs of multivariate time series.\nSecond, the inherent low spatial resolution of the EEG/MEG tomography\nintroduces artificially high zero-lag coherence and phase synchronization. In\nthis report, solutions to both problems are presented. Two additional\ngeneralizations are briefly mentioned: (1) conditional coherence and phase\nsynchronization; and (2) non-stationary time-frequency analysis. Finally, a\nnon-parametric randomization method for connectivity significance testing is\noutlined. The new connectivity measures proposed here can be applied to pairs\nof univariate EEG/MEG signals, as is traditional in the published literature.\nHowever, these calculations cannot be interpreted as connectivity, since it is\nin general incorrect to associate an extracranial electrode or sensor to the\nunderlying cortex.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2007 19:48:30 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2007 11:35:14 GMT"}, {"version": "v3", "created": "Thu, 12 Jul 2007 12:24:44 GMT"}], "update_date": "2007-07-12", "authors_parsed": [["Pascual-Marqui", "Roberto D.", ""]]}, {"id": "0706.2040", "submitter": "Edoardo Airoldi", "authors": "Edoardo M Airoldi", "title": "Getting started in probabilistic graphical models", "comments": "12 pages, 1 figure", "journal-ref": "Airoldi EM (2007) Getting started in probabilistic graphical\n  models. PLoS Comput Biol 3(12): e252", "doi": "10.1371/journal.pcbi.0030252", "report-no": null, "categories": "q-bio.QM cs.LG physics.soc-ph stat.ME stat.ML", "license": null, "abstract": "  Probabilistic graphical models (PGMs) have become a popular tool for\ncomputational analysis of biological data in a variety of domains. But, what\nexactly are they and how do they work? How can we use PGMs to discover patterns\nthat are biologically relevant? And to what extent can PGMs help us formulate\nnew hypotheses that are testable at the bench? This note sketches out some\nanswers and illustrates the main ideas behind the statistical approach to\nbiological pattern discovery.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2007 14:52:06 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2007 19:25:59 GMT"}], "update_date": "2010-02-22", "authors_parsed": [["Airoldi", "Edoardo M", ""]]}, {"id": "0706.2912", "submitter": "Satoshi Aoki", "authors": "Satoshi Aoki and Masami Miyakawa", "title": "Statistical testing procedure for the interaction effects of several\n  controllable factors in two-valued input-output systems", "comments": "14pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  Suppose several two-valued input-output systems are designed by setting the\nlevels of several controllable factors. For this situation, Taguchi method has\nproposed to assign the controllable factors to the orthogonal array and use\nANOVA model for the standardized SN ratio, which is a natural measure for\nevaluating the performance of each input-output system. Though this procedure\nis simple and useful in application indeed, the result can be unreliable when\nthe estimated standard errors of the standardized SN ratios are unbalanced. In\nthis paper, we treat the data arising from the full factorial or fractional\nfactorial designs of several controllable factors as the frequencies of\nhigh-dimensional contingency tables, and propose a general testing procedure\nfor the main effects or the interaction effects of the controllable factors.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2007 04:48:48 GMT"}], "update_date": "2007-06-21", "authors_parsed": [["Aoki", "Satoshi", ""], ["Miyakawa", "Masami", ""]]}, {"id": "0706.3435", "submitter": "Zoltan Szabo", "authors": "Zoltan Szabo, Barnabas Poczos, Andras Lorincz", "title": "Undercomplete Blind Subspace Deconvolution via Linear Prediction", "comments": "12 pages", "journal-ref": "European Conference on Machine Learning (ECML), pages 740-747,\n  2007", "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  We present a novel solution technique for the blind subspace deconvolution\n(BSSD) problem, where temporal convolution of multidimensional hidden\nindependent components is observed and the task is to uncover the hidden\ncomponents using the observation only. We carry out this task for the\nundercomplete case (uBSSD): we reduce the original uBSSD task via linear\nprediction to independent subspace analysis (ISA), which we can solve. As it\nhas been shown recently, applying temporal concatenation can also reduce uBSSD\nto ISA, but the associated ISA problem can easily become `high dimensional'\n[1]. The new reduction method circumvents this dimensionality problem. We\nperform detailed studies on the efficiency of the proposed technique by means\nof numerical simulations. We have found several advantages: our method can\nachieve high quality estimations for smaller number of samples and it can cope\nwith deeper temporal convolutions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2007 10:15:39 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Szabo", "Zoltan", ""], ["Poczos", "Barnabas", ""], ["Lorincz", "Andras", ""]]}, {"id": "0706.3985", "submitter": "John Aston", "authors": "John A. D. Aston, Donald E. K. Martin", "title": "Distributions associated with general runs and patterns in hidden Markov\n  models", "comments": "Published in at http://dx.doi.org/10.1214/07-AOAS125 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2007, Vol. 1, No. 2, 585-611", "doi": "10.1214/07-AOAS125", "report-no": "IMS-AOAS-AOAS125", "categories": "stat.ME stat.AP stat.CO", "license": null, "abstract": "  This paper gives a method for computing distributions associated with\npatterns in the state sequence of a hidden Markov model, conditional on\nobserving all or part of the observation sequence. Probabilities are computed\nfor very general classes of patterns (competing patterns and generalized later\npatterns), and thus, the theory includes as special cases results for a large\nclass of problems that have wide application. The unobserved state sequence is\nassumed to be Markovian with a general order of dependence. An auxiliary Markov\nchain is associated with the state sequence and is used to simplify the\ncomputations. Two examples are given to illustrate the use of the methodology.\nWhereas the first application is more to illustrate the basic steps in applying\nthe theory, the second is a more detailed application to DNA sequences, and\nshows that the methods can be adapted to include restrictions related to\nbiological knowledge.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2007 09:15:55 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2007 14:49:46 GMT"}], "update_date": "2007-12-18", "authors_parsed": [["Aston", "John A. D.", ""], ["Martin", "Donald E. K.", ""]]}, {"id": "0706.4108", "submitter": "John Rice", "authors": "Peter Bickel, Bas Kleijn, and John Rice", "title": "Event Weighted Tests for Detecting Periodicity in Photon Arrival Times", "comments": null, "journal-ref": null, "doi": "10.1086/590399", "report-no": null, "categories": "stat.ME astro-ph stat.AP", "license": null, "abstract": "  This paper treats the problem of detecting periodicity in a sequence of\nphoton arrival times, which occurs, for example, in attempting to detect\ngamma-ray pulsars. A particular focus is on how auxiliary information,\ntypically source intensity, background intensity, and incidence angles and\nenergies associated with each photon arrival should be used to maximize the\ndetection power. We construct a class of likelihood-based tests, score tests,\nwhich give rise to event weighting in a principled and natural way, and derive\nexpressions quantifying the power of the tests. These results can be used to\ncompare the efficacies of different weight functions, including cuts in energy\nand incidence angle. The test is targeted toward a template for the periodic\nlightcurve, and we quantify how deviation from that template affects the power\nof detection.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2007 22:00:46 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Bickel", "Peter", ""], ["Kleijn", "Bas", ""], ["Rice", "John", ""]]}, {"id": "0706.4190", "submitter": "Cheolwoo Park", "authors": "Vitaliana Rondonotti, J. S. Marron, Cheolwoo Park", "title": "SiZer for time series: A new approach to the analysis of trends", "comments": "Published at http://dx.doi.org/10.1214/07-EJS006 in the Electronic\n  Journal of Statistics (http://www.i-journals.org/ejs/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Electronic Journal of Statistics 2007, Vol. 1, 268-289", "doi": "10.1214/07-EJS006", "report-no": "IMS-EJS-EJS_2007_6", "categories": "stat.ME", "license": null, "abstract": "  Smoothing methods and SiZer are a useful statistical tool for discovering\nstatistically significant structure in data. Based on scale space ideas\noriginally developed in the computer vision literature, SiZer (SIgnificant ZERo\ncrossing of the derivatives) is a graphical device to assess which observed\nfeatures are `really there' and which are just spurious sampling artifacts. In\nthis paper, we develop SiZer like ideas in time series analysis to address the\nimportant issue of significance of trends. This is not a straightforward\nextension, since one data set does not contain the information needed to\ndistinguish `trend' from `dependence'. A new visualization is proposed, which\nshows the statistician the range of trade-offs that are available. Simulation\nand real data results illustrate the effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2007 10:39:45 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Rondonotti", "Vitaliana", ""], ["Marron", "J. S.", ""], ["Park", "Cheolwoo", ""]]}]