[{"id": "1002.0152", "submitter": "Thibault Espinasse", "authors": "Thibault Espinasse (IMT), Fabrice Gamboa (IMT), Jean-Michel Loubes\n  (IMT)", "title": "Estimation error for blind Gaussian time series prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the issue of the blind prediction of a Gaussian time series. For\nthis, we construct a projection operator build by plugging an empirical\ncovariance estimation into a Schur complement decomposition of the projector.\nThis operator is then used to compute the predictor. Rates of convergence of\nthe estimates are given.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2010 20:21:44 GMT"}, {"version": "v2", "created": "Tue, 5 Jul 2011 15:05:53 GMT"}], "update_date": "2011-07-06", "authors_parsed": [["Espinasse", "Thibault", "", "IMT"], ["Gamboa", "Fabrice", "", "IMT"], ["Loubes", "Jean-Michel", "", "IMT"]]}, {"id": "1002.0299", "submitter": "Adam Barrett DPhil", "authors": "Adam B. Barrett, Lionel Barnett, Anil K. Seth", "title": "Multivariate Granger Causality and Generalized Variance", "comments": "added 1 reference, minor change to discussion, typos corrected; 28\n  pages, 3 figures, 1 table, LaTeX", "journal-ref": "Physical Rev E, Vol 81, 041907 (2010)", "doi": "10.1103/PhysRevE.81.041907", "report-no": null, "categories": "q-bio.NC physics.data-an q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Granger causality analysis is a popular method for inference on directed\ninteractions in complex systems of many variables. A shortcoming of the\nstandard framework for Granger causality is that it only allows for examination\nof interactions between single (univariate) variables within a system, perhaps\nconditioned on other variables. However, interactions do not necessarily take\nplace between single variables, but may occur among groups, or \"ensembles\", of\nvariables. In this study we establish a principled framework for Granger\ncausality in the context of causal interactions among two or more multivariate\nsets of variables. Building on Geweke's seminal 1982 work, we offer new\njustifications for one particular form of multivariate Granger causality based\non the generalized variances of residual errors. Taken together, our results\nsupport a comprehensive and theoretically consistent extension of Granger\ncausality to the multivariate case. Treated individually, they highlight\nseveral specific advantages of the generalized variance measure, which we\nillustrate using applications in neuroscience as an example. We further show\nhow the measure can be used to define \"partial\" Granger causality in the\nmultivariate context and we also motivate reformulations of \"causal density\"\nand \"Granger autonomy\". Our results are directly applicable to experimental\ndata and promise to reveal new types of functional relations in complex\nsystems, neural and otherwise.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2010 18:31:12 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2010 17:43:51 GMT"}], "update_date": "2010-04-14", "authors_parsed": [["Barrett", "Adam B.", ""], ["Barnett", "Lionel", ""], ["Seth", "Anil K.", ""]]}, {"id": "1002.0616", "submitter": "Stephan Huckemann", "authors": "Stephan Huckemann", "title": "Dynamic shape analysis and comparison of leaf growth", "comments": "19 pages, 16 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the statistical analysis of shape a goal beyond the analysis of static\nshapes lies in the quantification of `same' deformation of different shapes.\nTypically, shape spaces are modelled as Riemannian manifolds on which parallel\ntransport along geodesics naturally qualifies as a measure for the `similarity'\nof deformation. Since these spaces are usually defined as combinations of\nRiemannian immersions and submersions, only for few well featured spaces such\nas spheres or complex projective spaces (which are Kendall's spaces for 2D\nshapes), parallel transport along geodesics can be computed explicitly. In this\ncontribution a general numerical method to compute parallel transport along\ngeodesics when no explicit formula is available is provided. This method is\napplied to the shape spaces of closed 2D contours based on angular direction\nand to Kendall's spaces of shapes of arbitrary dimension. In application to the\ntemporal evolution of leaf shape over a growing period, one leaf's shape-growth\ndynamics can be applied to another leaf. For a specific poplar tree\ninvestigated it is found that leaves of initially and terminally different\nshape evolve rather parallel, i.e. with comparable dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2010 14:59:12 GMT"}], "update_date": "2010-02-04", "authors_parsed": [["Huckemann", "Stephan", ""]]}, {"id": "1002.0738", "submitter": "Stephan Huckemann", "authors": "Stephan Huckemann", "title": "Inference on 3D Procrustes means: tree bole growth, rank-deficient\n  diffusion tensors and perturbation models", "comments": "27 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Central Limit Theorem (CLT) for extrinsic and intrinsic means on\nmanifolds is extended to a generalization of Fr\\'echet means. Examples are the\nProcrustes mean for 3D Kendall shapes as well as a mean introduced by Ziezold.\nThis allows for one-sample tests previously not possible, and to numerically\nassess the `inconsistency of the Procrustes mean' for a perturbation model and\n`inconsistency' within a model recently proposed for diffusion tensor imaging.\nAlso it is shown that the CLT can be extended to mildly rank deficient\ndiffusion tensors. An application to forestry gives the temporal evolution of\nDouglas fir tree stems tending strongly towards cylinders at early ages and\ntending away with increased competition.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2010 13:50:07 GMT"}, {"version": "v2", "created": "Wed, 2 Feb 2011 22:32:32 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Huckemann", "Stephan", ""]]}, {"id": "1002.0795", "submitter": "Stephan Huckemann", "authors": "Stephan Huckemann", "title": "On the meaning of mean shape", "comments": "32 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various concepts of mean shape previously unrelated in the literature are\nbrought into relation. In particular for non-manifolds such as Kendall's 3D\nshape space, this paper answers the question, for which means one may apply a\ntwo-sample test. The answer is positive if intrinsic or Ziezold means are used.\nThe underlying general result of manifold stability of a mean on a shape space,\nthe quotient due to an isometric action of a compact Lie group on a Riemannian\nmanifold, blends the Slice Theorem from differential geometry with the\nstatistics of shape. For 3D Procrustes means, however, a counterexample is\ngiven. To further elucidate on subtleties of means, for spheres and Kendall's\nshape spaces, a first order relationship between intrinsic,\nresidual/Procrustean and extrinsic/Ziezold means is derived stating that for\nhigh concentration the latter approximately divides the (generalized) geodesic\nsegment between the former two by the ratio $1:3$. This fact, consequences of\ncoordinate choices for the power of tests and other details, e.g. that\nextrinsic Schoenberg means may increase dimension are discussed and illustrated\nby simulations and exemplary datasets.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2010 17:09:01 GMT"}, {"version": "v2", "created": "Thu, 12 May 2011 10:15:31 GMT"}], "update_date": "2011-05-13", "authors_parsed": [["Huckemann", "Stephan", ""]]}, {"id": "1002.1059", "submitter": "Nicolas Dobigeon", "authors": "Olivier Eches, Nicolas Dobigeon and Jean-Yves Tourneret", "title": "Enhancing hyperspectral image unmixing with spatial correlations", "comments": "Manuscript accepted for publication in IEEE Trans. Geoscience and\n  Remote Sensing", "journal-ref": "IEEE Trans. Geoscience and Remote Sensing, vol. 49, no. 11, pp.\n  4239-4247, Nov. 2011", "doi": "10.1109/TGRS.2011.2140119", "report-no": null, "categories": "stat.ME physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new algorithm for hyperspectral image unmixing. Most\nof the unmixing algorithms proposed in the literature do not take into account\nthe possible spatial correlations between the pixels. In this work, a Bayesian\nmodel is introduced to exploit these correlations. The image to be unmixed is\nassumed to be partitioned into regions (or classes) where the statistical\nproperties of the abundance coefficients are homogeneous. A Markov random field\nis then proposed to model the spatial dependency of the pixels within any\nclass. Conditionally upon a given class, each pixel is modeled by using the\nclassical linear mixing model with additive white Gaussian noise. This strategy\nis investigated the well known linear mixing model. For this model, the\nposterior distributions of the unknown parameters and hyperparameters allow\nones to infer the parameters of interest. These parameters include the\nabundances for each pixel, the means and variances of the abundances for each\nclass, as well as a classification map indicating the classes of all pixels in\nthe image. To overcome the complexity of the posterior distribution of\ninterest, we consider Markov chain Monte Carlo methods that generate samples\ndistributed according to the posterior of interest. The generated samples are\nthen used for parameter and hyperparameter estimation. The accuracy of the\nproposed algorithms is illustrated on synthetic and real data.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2010 19:17:04 GMT"}, {"version": "v2", "created": "Fri, 27 Aug 2010 09:39:08 GMT"}, {"version": "v3", "created": "Wed, 19 Jan 2011 10:54:13 GMT"}, {"version": "v4", "created": "Tue, 4 Sep 2012 06:59:33 GMT"}], "update_date": "2012-09-05", "authors_parsed": [["Eches", "Olivier", ""], ["Dobigeon", "Nicolas", ""], ["Tourneret", "Jean-Yves", ""]]}, {"id": "1002.2017", "submitter": "Robert Kohn", "authors": "Weijun Xu, Li Yang and Robert Kohn", "title": "Computationally Efficient Estimation of Factor Multivariate Stochastic\n  Volatility Models", "comments": "32 pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An MCMC simulation method based on a two stage delayed rejection\nMetropolis-Hastings algorithm is proposed to estimate a factor multivariate\nstochastic volatility model. The first stage uses kstep iteration towards the\nmode, with k small, and the second stage uses an adaptive random walk proposal\ndensity. The marginal likelihood approach of Chib (1995) is used to choose the\nnumber of factors, with the posterior density ordinates approximated by\nGaussian copula. Simulation and real data applications suggest that the\nproposed simulation method is computationally much more efficient than the\napproach of Chib. Nardari and Shephard (2006}. This increase in computational\nefficiency is particularly important in calculating marginal likelihoods\nbecause it is necessary to carry out the simulation a number of times to\nestimate the posterior ordinates for a given marginal likelihood. In addition\nto the MCMC method, the paper also proposes a fast approximate EM method to\nestimate the factor multivariate stochastic volatility model. The estimates\nfrom the approximate EM method are of interest in their own right, but are\nespecially useful as initial inputs to MCMC methods, making them more efficient\ncomputationally. The methodology is illustrated using simulated and real\nexamples.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2010 02:55:05 GMT"}], "update_date": "2010-02-11", "authors_parsed": [["Xu", "Weijun", ""], ["Yang", "Li", ""], ["Kohn", "Robert", ""]]}, {"id": "1002.2080", "submitter": "Christian P. Robert", "authors": "Christian P. Robert, Jean-Michel Marin, and Judith Rousseau", "title": "Bayesian Inference", "comments": "This is a 20 page chapter for the upcoming Handbook of Statistical\n  Systems Biology (D. Balding, M. Stumpf, M. Girolami, eds.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter provides a overview of Bayesian inference, mostly emphasising\nthat it is a universal method for summarising uncertainty and making estimates\nand predictions using probability statements conditional on observed data and\nan assumed model (Gelman 2008). The Bayesian perspective is thus applicable to\nall aspects of statistical inference, while being open to the incorporation of\ninformation items resulting from earlier experiments and from expert opinions.\nWe provide here the basic elements of Bayesian analysis when considered for\nstandard models, refering to Marin and Robert (2007) and to Robert (2007) for\nbook-length entries.1 In the following, we refrain from embarking upon\nphilosophical discussions about the nature of knowledge (see, e.g., Robert\n2007, Chapter 10), opting instead for a mathematically sound presentation of an\neminently practical statistical methodology. We indeed believe that the most\nconvincing arguments for adopting a Bayesian version of data analyses are in\nthe versatility of this tool and in the large range of existing applications,\nrather than in those polemical arguments.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2010 11:53:25 GMT"}], "update_date": "2010-02-11", "authors_parsed": [["Robert", "Christian P.", ""], ["Marin", "Jean-Michel", ""], ["Rousseau", "Judith", ""]]}, {"id": "1002.2168", "submitter": "Jessica Kasza", "authors": "Jessica Kasza, Gary Glonek, Patty Solomon", "title": "Estimating Bayesian networks for high-dimensional data with complex mean\n  structure and random effects", "comments": "24 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of Bayesian networks given high-dimensional data, in\nparticular gene expression data, has been the focus of much recent research.\nWhilst there are several methods available for the estimation of such networks,\nthese typically assume that the data consist of independent and identically\ndistributed samples. However, it is often the case that the available data have\na more complex mean structure plus additional components of variance, which\nmust then be accounted for in the estimation of a Bayesian network. In this\npaper, score metrics that take account of such complexities are proposed for\nuse in conjunction with score-based methods for the estimation of Bayesian\nnetworks. We propose firstly, a fully Bayesian score metric, and secondly, a\nmetric inspired by the notion of restricted maximum likelihood. We demonstrate\nthe performance of these new metrics for the estimation of Bayesian networks\nusing simulated data with known complex mean structures. We then present the\nanalysis of expression levels of grape berry genes adjusting for exogenous\nvariables believed to affect the expression levels of the genes. Demonstrable\nbiological effects can be inferred from the estimated conditional independence\nrelationships and correlations amongst the grape-berry genes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2010 18:45:27 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2011 04:55:29 GMT"}], "update_date": "2011-12-01", "authors_parsed": [["Kasza", "Jessica", ""], ["Glonek", "Gary", ""], ["Solomon", "Patty", ""]]}, {"id": "1002.2684", "submitter": "Christian P. Robert", "authors": "Christian P. Robert and Jean-Michel Marin", "title": "On computational tools for Bayesian data analysis", "comments": "This is a chapter for the book \"Bayesian Methods and Expert\n  Elicitation\" edited by Klaus Bocker, 23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While Robert and Rousseau (2010) addressed the foundational aspects of\nBayesian analysis, the current chapter details its practical aspects through a\nreview of the computational methods available for approximating Bayesian\nprocedures. Recent innovations like Monte Carlo Markov chain, sequential Monte\nCarlo methods and more recently Approximate Bayesian Computation techniques\nhave considerably increased the potential for Bayesian applications and they\nhave also opened new avenues for Bayesian inference, first and foremost\nBayesian model choice.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 15:50:53 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2010 07:12:50 GMT"}], "update_date": "2010-02-25", "authors_parsed": [["Robert", "Christian P.", ""], ["Marin", "Jean-Michel", ""]]}, {"id": "1002.2702", "submitter": "Christian P. Robert", "authors": "Christian P. Robert", "title": "Bayesian computational methods", "comments": "This is a revised version of a chapter written for the Handbook of\n  Computational Statistics, edited by J. Gentle, W. Hardle and Y. Mori in 2003,\n  in preparation for the second edition", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we will first present the most standard computational\nchallenges met in Bayesian Statistics, focussing primarily on mixture\nestimation and on model choice issues, and then relate these problems with\ncomputational solutions. Of course, this chapter is only a terse introduction\nto the problems and solutions related to Bayesian computations. For more\ncomplete references, see Robert and Casella (2004, 2009), or Marin and Robert\n(2007), among others. We also restrain from providing an introduction to\nBayesian Statistics per se and for comprehensive coverage, address the reader\nto Robert (2007), (again) among others.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2010 15:36:25 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Robert", "Christian P.", ""]]}, {"id": "1002.2706", "submitter": "Leonardo Bottolo", "authors": "Leonardo Bottolo, Sylvia Richardson", "title": "Evolutionary Stochastic Search for Bayesian model exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implementing Bayesian variable selection for linear Gaussian regression\nmodels for analysing high dimensional data sets is of current interest in many\nfields. In order to make such analysis operational, we propose a new sampling\nalgorithm based upon Evolutionary Monte Carlo and designed to work under the\n\"large p, small n\" paradigm, thus making fully Bayesian multivariate analysis\nfeasible, for example, in genetics/genomics experiments. Two real data examples\nin genomics are presented, demonstrating the performance of the algorithm in a\nspace of up to 10,000 covariates. Finally the methodology is compared with a\nrecently proposed search algorithms in an extensive simulation study.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2010 13:57:26 GMT"}], "update_date": "2010-02-16", "authors_parsed": [["Bottolo", "Leonardo", ""], ["Richardson", "Sylvia", ""]]}, {"id": "1002.2928", "submitter": "Torsten Ensslin", "authors": "Torsten Ensslin, Mona Frommert", "title": "Reconstruction of signals with unknown spectra in information field\n  theory with parameter uncertainty", "comments": "21 pages, 5 figures, accepted by PRD", "journal-ref": "Phys.Rev.D83:105014,2011", "doi": "10.1103/PhysRevD.83.105014", "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.IT math.IT physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal reconstruction of cosmic metric perturbations and other signals\nrequires knowledge of their power spectra and other parameters. If these are\nnot known a priori, they have to be measured simultaneously from the same data\nused for the signal reconstruction. We formulate the general problem of signal\ninference in the presence of unknown parameters within the framework of\ninformation field theory. We develop a generic parameter uncertainty\nrenormalized estimation (PURE) technique and address the problem of\nreconstructing Gaussian signals with unknown power-spectrum with five different\napproaches: (i) separate maximum-a-posteriori power spectrum measurement and\nsubsequent reconstruction, (ii) maximum-a-posteriori power reconstruction with\nmarginalized power-spectrum, (iii) maximizing the joint posterior of signal and\nspectrum, (iv) guessing the spectrum from the variance in the Wiener filter\nmap, and (v) renormalization flow analysis of the field theoretical problem\nproviding the PURE filter. In all cases, the reconstruction can be described or\napproximated as Wiener filter operations with assumed signal spectra derived\nfrom the data according to the same recipe, but with differing coefficients.\nAll of these filters, except the renormalized one, exhibit a perception\nthreshold in case of a Jeffreys prior for the unknown spectrum. Data modes,\nwith variance below this threshold do not affect the signal reconstruction at\nall. Filter (iv) seems to be similar to the so called Karhune-Loeve and\nFeldman-Kaiser-Peacock estimators for galaxy power spectra used in cosmology,\nwhich therefore should also exhibit a marginal perception threshold if\ncorrectly implemented. We present statistical performance tests and show that\nthe PURE filter is superior to the others.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2010 18:22:24 GMT"}, {"version": "v2", "created": "Sat, 4 Dec 2010 14:33:34 GMT"}, {"version": "v3", "created": "Tue, 10 May 2011 08:30:51 GMT"}], "update_date": "2011-06-02", "authors_parsed": [["Ensslin", "Torsten", ""], ["Frommert", "Mona", ""]]}, {"id": "1002.3128", "submitter": "Daniel Percival", "authors": "Daniel Percival, Kathryn Roeder, Roni Rosenfeld, Larry Wasserman", "title": "Structured, sparse regression with application to HIV drug resistance", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS428 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 2A, 628-644", "doi": "10.1214/10-AOAS428", "report-no": "IMS-AOAS-AOAS428", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new version of forward stepwise regression. Our modification\nfinds solutions to regression problems where the selected predictors appear in\na structured pattern, with respect to a predefined distance measure over the\ncandidate predictors. Our method is motivated by the problem of predicting\nHIV-1 drug resistance from protein sequences. We find that our method improves\nthe interpretability of drug resistance while producing comparable predictive\naccuracy to standard methods. We also demonstrate our method in a simulation\nstudy and present some theoretical results and connections.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2010 18:10:20 GMT"}, {"version": "v2", "created": "Wed, 8 Sep 2010 14:45:16 GMT"}, {"version": "v3", "created": "Mon, 1 Aug 2011 07:15:17 GMT"}], "update_date": "2011-08-02", "authors_parsed": [["Percival", "Daniel", ""], ["Roeder", "Kathryn", ""], ["Rosenfeld", "Roni", ""], ["Wasserman", "Larry", ""]]}, {"id": "1002.3241", "submitter": "Anastasia Papavasiliou", "authors": "Anastasia Papavasiliou", "title": "Coarse-grained modeling of multiscale diffusions: the p-variation\n  estimates", "comments": "18 pages, ISAAC conference 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating parameters of the limiting equation of a\nmultiscale diffusion in the case of averaging and homogenization, given data\nfrom the corresponding multiscale system. First, we review some recent results\nthat make use of the maximum likelihood of the limiting equation. In\nparticular, it has been shown that in the averaging case, the MLE will be\nasymptotically consistent in the limit while in the homogenization case, the\nMLE will be asymptotically consistent only if we subsample the data. Then, we\nfocus on the problem of estimating the diffusion coefficient. We suggest a\nnovel approach that makes use of the total $p$-variation, as defined in the\ntheory of rough paths and avoids the subsampling step. The method is applied to\na multiscale OU process.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2010 11:06:25 GMT"}], "update_date": "2010-02-18", "authors_parsed": [["Papavasiliou", "Anastasia", ""]]}, {"id": "1002.3315", "submitter": "Yang Feng", "authors": "Jianqing Fan, Yang Feng, Yichao Wu", "title": "High-dimensional variable selection for Cox's proportional hazards model", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection in high dimensional space has challenged many contemporary\nstatistical problems from many frontiers of scientific disciplines. Recent\ntechnology advance has made it possible to collect a huge amount of covariate\ninformation such as microarray, proteomic and SNP data via bioimaging\ntechnology while observing survival information on patients in clinical\nstudies. Thus, the same challenge applies to the survival analysis in order to\nunderstand the association between genomics information and clinical\ninformation about the survival time. In this work, we extend the sure screening\nprocedure Fan and Lv (2008) to Cox's proportional hazards model with an\niterative version available. Numerical simulation studies have shown\nencouraging performance of the proposed method in comparison with other\ntechniques such as LASSO. This demonstrates the utility and versatility of the\niterative sure independent screening scheme.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2010 17:23:19 GMT"}, {"version": "v2", "created": "Wed, 19 May 2010 19:34:18 GMT"}], "update_date": "2010-05-20", "authors_parsed": [["Fan", "Jianqing", ""], ["Feng", "Yang", ""], ["Wu", "Yichao", ""]]}, {"id": "1002.3448", "submitter": "Lutz D\\\"{u}mbgen", "authors": "Lutz Duembgen, Richard Samworth, Dominic Schuhmacher", "title": "Approximation by log-concave distributions, with applications to\n  regression", "comments": "Version 3 is the technical report cited in the published paper.\n  Published in at http://dx.doi.org/10.1214/10-AOS853 the Annals of Statistics\n  (http://www.imstat.org/aos/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2011, Vol. 39, No. 2, 702-730", "doi": "10.1214/10-AOS853", "report-no": "IMS-AOS-AOS853", "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the approximation of arbitrary distributions $P$ on $d$-dimensional\nspace by distributions with log-concave density. Approximation means minimizing\na Kullback--Leibler-type functional. We show that such an approximation exists\nif and only if $P$ has finite first moments and is not supported by some\nhyperplane. Furthermore we show that this approximation depends continuously on\n$P$ with respect to Mallows distance $D_1(\\cdot,\\cdot)$. This result implies\nconsistency of the maximum likelihood estimator of a log-concave density under\nfairly general conditions. It also allows us to prove existence and consistency\nof estimators in regression models with a response $Y=\\mu(X)+\\epsilon$, where\n$X$ and $\\epsilon$ are independent, $\\mu(\\cdot)$ belongs to a certain class of\nregression functions while $\\epsilon$ is a random error with log-concave\ndensity and mean zero.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2010 08:38:43 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2010 15:16:33 GMT"}, {"version": "v3", "created": "Thu, 26 Aug 2010 22:09:16 GMT"}, {"version": "v4", "created": "Wed, 11 May 2011 09:17:35 GMT"}], "update_date": "2011-10-17", "authors_parsed": [["Duembgen", "Lutz", ""], ["Samworth", "Richard", ""], ["Schuhmacher", "Dominic", ""]]}, {"id": "1002.3640", "submitter": "Yaming Yu", "authors": "Yaming Yu", "title": "Improved EM for Mixture Proportions with Applications to Nonparametric\n  ML Estimation for Censored Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improved EM strategies, based on the idea of efficient data augmentation\n(Meng and van Dyk 1997, 1998), are presented for ML estimation of mixture\nproportions. The resulting algorithms inherit the simplicity, ease of\nimplementation, and monotonic convergence properties of EM, but have\nconsiderably improved speed. Because conventional EM tends to be slow when\nthere exists a large overlap between the mixture components, we can improve the\nspeed without sacrificing the simplicity or stability, if we can reformulate\nthe problem so as to reduce the amount of overlap. We propose simple\n\"squeezing\" strategies for that purpose. Moreover, for high-dimensional\nproblems, such as computing the nonparametric MLE of the distribution function\nwith censored data, a natural and effective remedy for conventional EM is to\nadd exchange steps (based on improved EM) between adjacent mixture components,\nwhere the overlap is most severe. Theoretical considerations show that the\nresulting EM-type algorithms, when carefully implemented, are globally\nconvergent. Simulated and real data examples show dramatic improvement in speed\nin realistic situations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2010 23:23:27 GMT"}], "update_date": "2010-02-22", "authors_parsed": [["Yu", "Yaming", ""]]}, {"id": "1002.3784", "submitter": "Juerg Schelldorfer js", "authors": "J\\\"urg Schelldorfer, Peter B\\\"uhlmann and Sara van de Geer", "title": "Estimation for High-Dimensional Linear Mixed-Effects Models Using\n  $\\ell_1$-Penalization", "comments": null, "journal-ref": "Scandinavian Journal of Statistics 2011, 38: 197-214", "doi": "10.1111/j.1467-9469.2011.00740.x", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an $\\ell_1$-penalized estimation procedure for high-dimensional\nlinear mixed-effects models. The models are useful whenever there is a grouping\nstructure among high-dimensional observations, i.e. for clustered data. We\nprove a consistency and an oracle optimality result and we develop an algorithm\nwith provable numerical convergence. Furthermore, we demonstrate the\nperformance of the method on simulated and a real high-dimensional data set.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2010 17:08:03 GMT"}, {"version": "v2", "created": "Thu, 25 Nov 2010 14:05:02 GMT"}], "update_date": "2011-05-12", "authors_parsed": [["Schelldorfer", "J\u00fcrg", ""], ["B\u00fchlmann", "Peter", ""], ["van de Geer", "Sara", ""]]}, {"id": "1002.3798", "submitter": "Moritz Deger", "authors": "Moritz Deger, Moritz Helias, Stefano Cardanobile, Fatihcan M. Atay and\n  Stefan Rotter", "title": "Non-equilibrium dynamics of stochastic point processes with\n  refractoriness", "comments": "8 pages, 4 figures", "journal-ref": "Phys Rev E 82, 021129 (2010)", "doi": "10.1103/PhysRevE.82.021129", "report-no": null, "categories": "math.PR q-bio.NC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic point processes with refractoriness appear frequently in the\nquantitative analysis of physical and biological systems, such as the\ngeneration of action potentials by nerve cells, the release and reuptake of\nvesicles at a synapse, and the counting of particles by detector devices. Here\nwe present an extension of renewal theory to describe ensembles of point\nprocesses with time varying input. This is made possible by a representation in\nterms of occupation numbers of two states: Active and refractory. The dynamics\nof these occupation numbers follows a distributed delay differential equation.\nIn particular, our theory enables us to uncover the effect of refractoriness on\nthe time-dependent rate of an ensemble of encoding point processes in response\nto modulation of the input. We present exact solutions that demonstrate generic\nfeatures, such as stochastic transients and oscillations in the step response\nas well as resonances, phase jumps and frequency doubling in the transfer of\nperiodic signals. We show that a large class of renewal processes can indeed be\nregarded as special cases of the model we analyze. Hence our approach\nrepresents a widely applicable framework to define and analyze non-stationary\nrenewal processes.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2010 18:57:47 GMT"}, {"version": "v2", "created": "Sat, 8 May 2010 09:02:08 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2010 05:17:10 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Deger", "Moritz", ""], ["Helias", "Moritz", ""], ["Cardanobile", "Stefano", ""], ["Atay", "Fatihcan M.", ""], ["Rotter", "Stefan", ""]]}, {"id": "1002.4112", "submitter": "Nicole Kraemer", "authors": "Nicole Kraemer, Masashi Sugiyama", "title": "The Degrees of Freedom of Partial Least Squares Regression", "comments": "to appear in the Journal of the American Statistical Association", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The derivation of statistical properties for Partial Least Squares regression\ncan be a challenging task. The reason is that the construction of latent\ncomponents from the predictor variables also depends on the response variable.\nWhile this typically leads to good performance and interpretable models in\npractice, it makes the statistical analysis more involved. In this work, we\nstudy the intrinsic complexity of Partial Least Squares Regression. Our\ncontribution is an unbiased estimate of its Degrees of Freedom. It is defined\nas the trace of the first derivative of the fitted values, seen as a function\nof the response. We establish two equivalent representations that rely on the\nclose connection of Partial Least Squares to matrix decompositions and Krylov\nsubspace techniques. We show that the Degrees of Freedom depend on the\ncollinearity of the predictor variables: The lower the collinearity is, the\nhigher the Degrees of Freedom are. In particular, they are typically higher\nthan the naive approach that defines the Degrees of Freedom as the number of\ncomponents. Further, we illustrate how the Degrees of Freedom approach can be\nused for the comparison of different regression methods. In the experimental\nsection, we show that our Degrees of Freedom estimate in combination with\ninformation criteria is useful for model selection.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2010 13:31:02 GMT"}, {"version": "v2", "created": "Tue, 25 Jan 2011 09:32:34 GMT"}, {"version": "v3", "created": "Wed, 9 Feb 2011 15:58:58 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Kraemer", "Nicole", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "1002.4338", "submitter": "Saralees Nadarajah", "authors": "C. S. Withers, S. Nadarajah", "title": "The distribution and quantiles of functionals of weighted empirical\n  distributions when observations have different distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper extends Edgeworth-Cornish-Fisher expansions for the distribution\nand quantiles of nonparametric estimates in two ways. Firstly it allows\nobservations to have different distributions. Secondly it allows the\nobservations to be weighted in a predetermined way. The use of weighted\nestimates has a long history including applications to regression, rank\nstatistics and Bayes theory. However, asymptotic results have generally been\nonly first order (the CLT and weak convergence). We give third order\nasymptotics for the distribution and percentiles of any smooth functional of a\nweighted empirical distribution, thus allowing a considerable increase in\naccuracy over earlier CLT results.\n  Consider independent non-identically distributed ({\\it non-iid}) observations\n$X_{1n}, ..., X_{nn}$ in $R^s$. Let $\\hat{F}(x)$ be their {\\it weighted\nempirical distribution} with weights $w_{1n}, ..., w_{nn}$. We obtain cumulant\nexpansions and hence Edgeworth-Cornish-Fisher expansions for $T(\\hat{F})$ for\nany smooth functional $T(\\cdot)$ by extending the concepts of von Mises\nderivatives to signed measures of total measure 1. As an example we give the\ncumulant coefficients needed for Edgeworth-Cornish-Fisher expansions to\n$O(n^{-3/2})$ for the sample variance when observations are non-iid.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2010 14:36:42 GMT"}], "update_date": "2010-02-24", "authors_parsed": [["Withers", "C. S.", ""], ["Nadarajah", "S.", ""]]}, {"id": "1002.4658", "submitter": "Huan Xu Dr.", "authors": "Huan Xu, Constantine Caramanis, Shie Mannor", "title": "Principal Component Analysis with Contaminated Data: The High\n  Dimensional Case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the dimensionality-reduction problem (finding a subspace\napproximation of observed data) for contaminated data in the high dimensional\nregime, where the number of observations is of the same magnitude as the number\nof variables of each observation, and the data set contains some (arbitrarily)\ncorrupted observations. We propose a High-dimensional Robust Principal\nComponent Analysis (HR-PCA) algorithm that is tractable, robust to contaminated\npoints, and easily kernelizable. The resulting subspace has a bounded deviation\nfrom the desired one, achieves maximal robustness -- a breakdown point of 50%\nwhile all existing algorithms have a breakdown point of zero, and unlike\nordinary PCA algorithms, achieves optimality in the limit case where the\nproportion of corrupted points goes to zero.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2010 23:24:17 GMT"}, {"version": "v2", "created": "Thu, 13 May 2010 03:06:22 GMT"}], "update_date": "2010-05-14", "authors_parsed": [["Xu", "Huan", ""], ["Caramanis", "Constantine", ""], ["Mannor", "Shie", ""]]}, {"id": "1002.4775", "submitter": "Robert Kohn", "authors": "Ralph Silva, Robert Kohn, Paolo Giordani, Xiuyan Mun", "title": "A copula based approach to adaptive sampling", "comments": "33 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our article is concerned with adaptive sampling schemes for Bayesian\ninference that update the proposal densities using previous iterates. We\nintroduce a copula based proposal density which is made more efficient by\ncombining it with antithetic variable sampling. We compare the copula based\nproposal to an adaptive proposal density based on a multivariate mixture of\nnormals and an adaptive random walk Metropolis proposal. We also introduce a\nrefinement of the random walk proposal which performs better for multimodal\ntarget distributions. We compare the sampling schemes using challenging but\nrealistic models and priors applied to real data examples. The results show\nthat for the examples studied, the adaptive independent \\MH{} proposals are\nmuch more efficient than the adaptive random walk proposals and that in general\nthe copula based proposal has the best acceptance rates and lowest\ninefficiencies.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2010 12:47:50 GMT"}], "update_date": "2010-02-26", "authors_parsed": [["Silva", "Ralph", ""], ["Kohn", "Robert", ""], ["Giordani", "Paolo", ""], ["Mun", "Xiuyan", ""]]}]