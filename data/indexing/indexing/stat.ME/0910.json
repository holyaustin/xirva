[{"id": "0910.0264", "submitter": "Angel Baigorri R.", "authors": "A. R. Baigorri, C. R. Goncalves, P. A. A. Resende", "title": "Markov Chain Order Estimation and Relative Entropy", "comments": "Revised for better and shorter proof, new numerical simulations as\n  well as improved references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the $f-divergence$ also called relative entropy as a measure of\ndiversity between probability densities and review its basic properties. In the\nsequence we define a few objects which capture relevant information from the\nsample of a Markov Chain to be used in the definition of a couple of estimators\ni.e. the Local Dependency Level and Global Dependency Level for a Markov chain\nsample. After exploring their properties we propose a new estimator for the\nMarkov chain order. Finally we show a few tables containing numerical\nsimulation results, comparing the performance of the new estimator with the\nwell known and already established AIC and BIC estimators.\n", "versions": [{"version": "v1", "created": "Thu, 1 Oct 2009 20:37:00 GMT"}, {"version": "v2", "created": "Fri, 30 Oct 2009 18:49:35 GMT"}, {"version": "v3", "created": "Mon, 30 Nov 2009 18:36:41 GMT"}, {"version": "v4", "created": "Thu, 2 Jun 2011 21:51:52 GMT"}, {"version": "v5", "created": "Tue, 19 Jun 2012 12:21:00 GMT"}], "update_date": "2012-06-20", "authors_parsed": [["Baigorri", "A. R.", ""], ["Goncalves", "C. R.", ""], ["Resende", "P. A. A.", ""]]}, {"id": "0910.0745", "submitter": "David R. Bickel", "authors": "David R. Bickel", "title": "Estimating the null distribution for conditional inference and\n  genome-scale screening", "comments": null, "journal-ref": "D. R. Bickel, Estimating the null distribution to adjust observed\n  confidence levels for genome-scale screening, Biometrics 67, 363-370 (2011)", "doi": "10.1111/j.1541-0420.2010.01491.x", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a novel approach to the multiple testing problem, Efron (2004; 2007)\nformulated estimators of the distribution of test statistics or nominal\np-values under a null distribution suitable for modeling the data of thousands\nof unaffected genes, non-associated single-nucleotide polymorphisms, or other\nbiological features. Estimators of the null distribution can improve not only\nthe empirical Bayes procedure for which it was originally intended, but also\nmany other multiple comparison procedures. Such estimators serve as the\ngroundwork for the proposed multiple comparison procedure based on a recent\nfrequentist method of minimizing posterior expected loss, exemplified with a\nnon-additive loss function designed for genomic screening rather than for\nvalidation.\n  The merit of estimating the null distribution is examined from the vantage\npoint of conditional inference in the remainder of the paper. In a simulation\nstudy of genome-scale multiple testing, conditioning the observed confidence\nlevel on the estimated null distribution as an approximate ancillary statistic\nmarkedly improved conditional inference. To enable researchers to determine\nwhether to rely on a particular estimated null distribution for inference or\ndecision making, an information-theoretic score is provided that quantifies the\nbenefit of conditioning. As the sum of the degree of ancillarity and the degree\nof inferential relevance, the score reflects the balance conditioning would\nstrike between the two conflicting terms.\n  Applications to gene expression microarray data illustrate the methods\nintroduced.\n", "versions": [{"version": "v1", "created": "Mon, 5 Oct 2009 12:32:12 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Bickel", "David R.", ""]]}, {"id": "0910.0949", "submitter": "Dariusz Plewczynski", "authors": "Dariusz Plewczynski (ICM, Interdisciplinary Centre for Mathematical\n  and Computational Modelling, University of Warsaw, Pawinskiego 5a Street,\n  02-106 Warsaw, Poland)", "title": "BRAINSTORMING: Consensus Learning in Practice", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here an introduction to Brainstorming approach, that was recently\nproposed as a consensus meta-learning technique, and used in several practical\napplications in bioinformatics and chemoinformatics. The consensus learning\ndenotes heterogeneous theoretical classification method, where one trains an\nensemble of machine learning algorithms using different types of input training\ndata representations. In the second step all solutions are gathered and the\nconsensus is build between them. Therefore no early solution, given even by a\ngenerally low performing algorithm, is not discarder until the late phase of\nprediction, when the final conclusion is drawn by comparing different machine\nlearning models. This final phase, i.e. consensus learning, is trying to\nbalance the generality of solution and the overall performance of trained\nmodel.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 08:47:29 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Plewczynski", "Dariusz", "", "ICM, Interdisciplinary Centre for Mathematical\n  and Computational Modelling, University of Warsaw, Pawinskiego 5a Street,\n  02-106 Warsaw, Poland"]]}, {"id": "0910.1022", "submitter": "David Blei", "authors": "David M. Blei and Peter I. Frazier", "title": "Distance Dependent Chinese Restaurant Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the distance dependent Chinese restaurant process (CRP), a\nflexible class of distributions over partitions that allows for\nnon-exchangeability. This class can be used to model many kinds of dependencies\nbetween data in infinite clustering models, including dependencies across time\nor space. We examine the properties of the distance dependent CRP, discuss its\nconnections to Bayesian nonparametric mixture models, and derive a Gibbs\nsampler for both observed and mixture settings. We study its performance with\nthree text corpora. We show that relaxing the assumption of exchangeability\nwith distance dependent CRPs can provide a better fit to sequential data. We\nalso show its alternative formulation of the traditional CRP leads to a\nfaster-mixing Gibbs sampling algorithm than the one based on the original\nformulation.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 14:46:20 GMT"}, {"version": "v2", "created": "Fri, 17 Dec 2010 17:21:52 GMT"}, {"version": "v3", "created": "Tue, 9 Aug 2011 21:30:47 GMT"}], "update_date": "2011-08-11", "authors_parsed": [["Blei", "David M.", ""], ["Frazier", "Peter I.", ""]]}, {"id": "0910.1027", "submitter": "Heng Lian", "authors": "Heng Lian", "title": "Time-varying Coefficients Estimation in Differential Equation Models\n  with Noisy Time-varying Covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of estimating time-varying coefficients in ordinary\ndifferential equations. Current theory only applies to the case when the\nassociated state variables are observed without measurement errors as presented\nin \\cite{chenwu08b,chenwu08}. The difficulty arises from the quadratic\nfunctional of observations that one needs to deal with instead of the linear\nfunctional that appears when state variables contain no measurement errors. We\nderive the asymptotic bias and variance for the previously proposed two-step\nestimators using quadratic regression functional theory.\n", "versions": [{"version": "v1", "created": "Tue, 6 Oct 2009 14:42:15 GMT"}], "update_date": "2009-10-07", "authors_parsed": [["Lian", "Heng", ""]]}, {"id": "0910.1359", "submitter": "Nicolas Gauvrit", "authors": "Nicolas Gauvrit and Jean-Paul Delahaye", "title": "Scatter and regularity imply Benford's law... and more", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A random variable (r.v.) X is said to follow Benford's law if log(X) is\nuniform mod 1. Many experimental data sets prove to follow an approximate\nversion of it, and so do many mathematical series and continuous random\nvariables. This phenomenon received some interest, and several explanations\nhave been put forward. Most of them focus on specific data, depending on strong\nassumptions, often linked with the log function.\n  Some authors hinted - implicitly - that the two most important\ncharacteristics of a random variable when it comes to Benford are regularity\nand scatter.\n  In a first part, we prove two theorems, making up a formal version of this\nintuition: scattered and regular r.v.'s do approximately follow Benford's law.\nThe proofs only need simple mathematical tools, making the analysis easy.\nPrevious explanations thus become corollaries of a more general and simpler\none.\n  These results suggest that Benford's law does not depend on properties linked\nwith the log function. We thus propose and test a general version of the\nBenford's law. The success of these tests may be viewed as an a posteriori\nvalidation of the analysis formulated in the first part.\n", "versions": [{"version": "v1", "created": "Wed, 7 Oct 2009 20:08:04 GMT"}], "update_date": "2009-10-09", "authors_parsed": [["Gauvrit", "Nicolas", ""], ["Delahaye", "Jean-Paul", ""]]}, {"id": "0910.1473", "submitter": "Marie-Colette van Lieshout", "authors": "M.N.M. van Lieshout", "title": "Moment analysis of the Delaunay tessellation field estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Campbell--Mecke theorem is used to derive explicit expressions for the\nmean and variance of Schaap and Van de Weygaert's Delaunay tessellation field\nestimator. Special attention is paid to Poisson processes.\n", "versions": [{"version": "v1", "created": "Thu, 8 Oct 2009 11:28:11 GMT"}], "update_date": "2009-10-09", "authors_parsed": [["van Lieshout", "M. N. M.", ""]]}, {"id": "0910.2098", "submitter": "Pierre Latouche", "authors": "Pierre Latouche, Etienne Birmel\\'e, Christophe Ambroise", "title": "Overlapping stochastic block models with application to the French\n  political blogosphere", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS382 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 1, 309-336", "doi": "10.1214/10-AOAS382", "report-no": "IMS-AOAS-AOAS382", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex systems in nature and in society are often represented as networks,\ndescribing the rich set of interactions between objects of interest. Many\ndeterministic and probabilistic clustering methods have been developed to\nanalyze such structures. Given a network, almost all of them partition the\nvertices into disjoint clusters, according to their connection profile.\nHowever, recent studies have shown that these techniques were too restrictive\nand that most of the existing networks contained overlapping clusters. To\ntackle this issue, we present in this paper the Overlapping Stochastic Block\nModel. Our approach allows the vertices to belong to multiple clusters, and, to\nsome extent, generalizes the well-known Stochastic Block Model [Nowicki and\nSnijders (2001)]. We show that the model is generically identifiable within\nclasses of equivalence and we propose an approximate inference procedure, based\non global and local variational techniques. Using toy data sets as well as the\nFrench Political Blogosphere network and the transcriptional network of\nSaccharomyces cerevisiae, we compare our work with other approaches.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2009 07:27:54 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2010 09:05:54 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2010 14:26:28 GMT"}, {"version": "v4", "created": "Fri, 15 Apr 2011 08:42:29 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Latouche", "Pierre", ""], ["Birmel\u00e9", "Etienne", ""], ["Ambroise", "Christophe", ""]]}, {"id": "0910.2145", "submitter": "Nicolai Meinshausen", "authors": "Nicolai Meinshausen", "title": "Node harvest", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS367 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 4, 2049-2072", "doi": "10.1214/10-AOAS367", "report-no": "IMS-AOAS-AOAS367", "categories": "stat.ML stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When choosing a suitable technique for regression and classification with\nmultivariate predictor variables, one is often faced with a tradeoff between\ninterpretability and high predictive accuracy. To give a classical example,\nclassification and regression trees are easy to understand and interpret. Tree\nensembles like Random Forests provide usually more accurate predictions. Yet\ntree ensembles are also more difficult to analyze than single trees and are\noften criticized, perhaps unfairly, as `black box' predictors. Node harvest is\ntrying to reconcile the two aims of interpretability and predictive accuracy by\ncombining positive aspects of trees and tree ensembles. Results are very sparse\nand interpretable and predictive accuracy is extremely competitive, especially\nfor low signal-to-noise data. The procedure is simple: an initial set of a few\nthousand nodes is generated randomly. If a new observation falls into just a\nsingle node, its prediction is the mean response of all training observation\nwithin this node, identical to a tree-like prediction. A new observation falls\ntypically into several nodes and its prediction is then the weighted average of\nthe mean responses across all these nodes. The only role of node harvest is to\n`pick' the right nodes from the initial large ensemble of nodes by choosing\nnode weights, which amounts in the proposed algorithm to a quadratic\nprogramming problem with linear inequality constraints. The solution is sparse\nin the sense that only very few nodes are selected with a nonzero weight. This\nsparsity is not explicitly enforced. Maybe surprisingly, it is not necessary to\nselect a tuning parameter for optimal predictive accuracy. Node harvest can\nhandle mixed data and missing values and is shown to be simple to interpret and\ncompetitive in predictive accuracy on a variety of data sets.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2009 12:12:46 GMT"}, {"version": "v2", "created": "Fri, 7 Jan 2011 09:02:24 GMT"}], "update_date": "2011-01-10", "authors_parsed": [["Meinshausen", "Nicolai", ""]]}, {"id": "0910.2325", "submitter": "Christian P. Robert", "authors": "Jean-Michel Marin and Christian P. Robert", "title": "Importance sampling methods for Bayesian discrimination between embedded\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys some well-established approaches on the approximation of\nBayes factors used in Bayesian model choice, mostly as covered in Chen et al.\n(2000). Our focus here is on methods that are based on importance sampling\nstrategies rather than variable dimension techniques like reversible jump MCMC,\nincluding: crude Monte Carlo, maximum likelihood based importance sampling,\nbridge and harmonic mean sampling, as well as Chib's method based on the\nexploitation of a functional equality. We demonstrate in this survey how these\ndifferent methods can be efficiently implemented for testing the significance\nof a predictive variable in a probit model. Finally, we compare their\nperformances on a real dataset.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 14:48:38 GMT"}], "update_date": "2009-10-14", "authors_parsed": [["Marin", "Jean-Michel", ""], ["Robert", "Christian P.", ""]]}, {"id": "0910.2497", "submitter": "John Hartigan", "authors": "Alexander Barvinok and J.A.Hartigan", "title": "Maximum entropy Edgeworth estimates of the number of integer points in\n  polytopes", "comments": "29 pages 3 tables Revision updates references,and sharpens statement\n  and proof of theorem 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract: The number of points $x=(x_1 ,x_2 ,...x_n)$ that lie in an integer\ncube $C$ in $R^n$ and satisfy the constraints $\\sum_j h_{ij}(x_j )=s_i ,1\\le\ni\\le d$ is approximated by an Edgeworth-corrected Gaussian formula based on the\nmaximum entropy density $p$ on $x \\in C$, that satisfies $E\\sum_j h_{ij}(x_j\n)=s_i ,1\\le i\\le d$. Under $p$, the variables $X_1 ,X_2 ,...X_n $ are\nindependent with densities of exponential form. Letting $S_i$ denote the random\nvariable $\\sum_j h_{ij}(X_j )$, conditional on $S=s, X$ is uniformly\ndistributed over the integers in $C$ that satisfy $S=s$. The number of points\nin $C$ satisfying $S=s$ is $p \\{S=s\\}\\exp (I(p))$ where $I(p)$ is the entropy\nof the density $p$. We estimate $p \\{S=s\\}$ by $p_Z(s)$, the density at $s$ of\nthe multivariate Gaussian $Z$ with the same first two moments as $S$; and when\n$d$ is large we use in addition an Edgeworth factor that requires the first\nfour moments of $S$ under $p$. The asymptotic validity of the\nEdgeworth-corrected estimate is proved and demonstrated for counting\ncontingency tables with given row and column sums as the number of rows and\ncolumns approaches infinity, and demonstrated for counting the number of graphs\nwith a given degree sequence, as the number of vertices approaches infinity.\n", "versions": [{"version": "v1", "created": "Tue, 13 Oct 2009 23:39:30 GMT"}, {"version": "v2", "created": "Fri, 6 Aug 2010 21:11:14 GMT"}], "update_date": "2010-08-10", "authors_parsed": [["Barvinok", "Alexander", ""], ["Hartigan", "J. A.", ""]]}, {"id": "0910.2585", "submitter": "Thomas Brendan Murphy", "authors": "Thomas Brendan Murphy, Nema Dean, Adrian E. Raftery", "title": "Variable selection and updating in model-based discriminant analysis for\n  high dimensional data with food authenticity applications", "comments": "Published in at http://dx.doi.org/10.1214/09-AOAS279 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2010, Vol. 4, No. 1, 396-421", "doi": "10.1214/09-AOAS279", "report-no": "IMS-AOAS-AOAS279", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Food authenticity studies are concerned with determining if food samples have\nbeen correctly labeled or not. Discriminant analysis methods are an integral\npart of the methodology for food authentication. Motivated by food authenticity\napplications, a model-based discriminant analysis method that includes variable\nselection is presented. The discriminant analysis model is fitted in a\nsemi-supervised manner using both labeled and unlabeled data. The method is\nshown to give excellent classification performance on several high-dimensional\nmulticlass food authenticity data sets with more variables than observations.\nThe variables selected by the proposed method provide information about which\nvariables are meaningful for classification purposes. A headlong search\nstrategy for variable selection is shown to be efficient in terms of\ncomputation and achieves excellent classification performance. In applications\nto several food authenticity data sets, our proposed method outperformed\ndefault implementations of Random Forests, AdaBoost, transductive SVMs and\nBayesian Multinomial Regression by substantial margins.\n", "versions": [{"version": "v1", "created": "Wed, 14 Oct 2009 10:39:44 GMT"}, {"version": "v2", "created": "Thu, 7 Oct 2010 12:51:36 GMT"}], "update_date": "2010-10-08", "authors_parsed": [["Murphy", "Thomas Brendan", ""], ["Dean", "Nema", ""], ["Raftery", "Adrian E.", ""]]}, {"id": "0910.3095", "submitter": "Richard A. Davis", "authors": "David R. Brillinger, Richard A. Davis", "title": "A Conversation with Murray Rosenblatt", "comments": "Published in at http://dx.doi.org/10.1214/08-STS267 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 116-140", "doi": "10.1214/08-STS267", "report-no": "IMS-STS-STS267", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On an exquisite March day in 2006, David Brillinger and Richard Davis sat\ndown with Murray and Ady Rosenblatt at their home in La Jolla, California for\nan enjoyable day of reminiscences and conversation. Our mentor, Murray\nRosenblatt, was born on September 7, 1926 in New York City and attended City\nCollege of New York before entering graduate school at Cornell University in\n1946. After completing his Ph.D. in 1949 under the direction of the renowned\nprobabilist Mark Kac, the Rosenblatts' moved to Chicago where Murray became an\ninstructor/assistant professor in the Committee of Statistics at the University\nof Chicago. Murray's academic career then took him to the University of Indiana\nand Brown University before his joining the University of California at San\nDiego in 1964. Along the way, Murray established himself as one of the most\ncelebrated and leading figures in probability and statistics with particular\nemphasis on time series and Markov processes. In addition to being a fellow of\nthe Institute of Mathematical Statistics and American Association for the\nAdvancement of Science, he was a Guggenheim fellow (1965--1966, 1971--1972) and\nwas elected to the National Academy of Sciences in 1984. Among his many\ncontributions, Murray conducted seminal work on density estimation, central\nlimit theorems under strong mixing, spectral domain methods and long memory\nprocesses. Murray and Ady Rosenblatt were married in 1949 and have two\nchildren, Karin and Daniel.\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2009 12:16:08 GMT"}], "update_date": "2009-10-19", "authors_parsed": [["Brillinger", "David R.", ""], ["Davis", "Richard A.", ""]]}, {"id": "0910.3112", "submitter": "N. I. Fisher", "authors": "R. J. Beran, N. I. Fisher", "title": "An Evening Spent with Bill van Zwet", "comments": "Published in at http://dx.doi.org/10.1214/08-STS261 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 87-115", "doi": "10.1214/08-STS261", "report-no": "IMS-STS-STS261", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Willem Rutger van Zwet was born in Leiden, the Netherlands, on March 31,\n1934. He received his high school education at the Gymnasium Haganum in The\nHague and obtained his Masters degree in Mathematics at the University of\nLeiden in 1959. After serving in the army for almost two years, he obtained his\nPh.D. at the University of Amsterdam in 1964, with Jan Hemelrijk as advisor. In\n1965, he was appointed Associate Professor of Statistics at the University of\nLeiden and promoted to Full Professor in 1968. He remained in Leiden until his\nretirement in 1999, while also serving as Associate Professor at the University\nof Oregon (1965), William Newman Professor at the University of North Carolina\nat Chapel Hill (1990--1996), frequent visitor and Miller Professor (1997) at\nthe University of California at Berkeley, director of the Thomas Stieltjes\nInstitute of Mathematics in the Netherlands (1992--1999), and founding director\nof the European research institute EURANDOM (1997--2000). At Leiden, he was\nDean of the School of Mathematics and Natural Sciences (1982--1984). He served\nas chair of the scientific council and member of the board of the Mathematics\nCentre at Amsterdam (1983--1996) and the Leiden University Fund (1993--2005).\n", "versions": [{"version": "v1", "created": "Fri, 16 Oct 2009 13:33:12 GMT"}], "update_date": "2009-10-19", "authors_parsed": [["Beran", "R. J.", ""], ["Fisher", "N. I.", ""]]}, {"id": "0910.3529", "submitter": "Robert Adler", "authors": "Robert Adler, John Ewing, Peter Taylor", "title": "Citation Statistics", "comments": "This paper commented in: [arXiv:0910.3532], [arXiv:0910.3537],\n  [arXiv:0910.3543], [arXiv:0910.3546]. Rejoinder in [arXiv:0910.3548].\n  Published in at http://dx.doi.org/10.1214/09-STS285 the Statistical Science\n  (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 1-14", "doi": "10.1214/09-STS285", "report-no": "IMS-STS-STS285", "categories": "stat.ME cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a report about the use and misuse of citation data in the assessment\nof scientific research. The idea that research assessment must be done using\n``simple and objective'' methods is increasingly prevalent today. The ``simple\nand objective'' methods are broadly interpreted as bibliometrics, that is,\ncitation data and the statistics derived from them. There is a belief that\ncitation statistics are inherently more accurate because they substitute simple\nnumbers for complex judgments, and hence overcome the possible subjectivity of\npeer review. But this belief is unfounded.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2009 12:57:23 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Adler", "Robert", ""], ["Ewing", "John", ""], ["Taylor", "Peter", ""]]}, {"id": "0910.3532", "submitter": "Bernard W. Silverman", "authors": "Bernard W. Silverman", "title": "Comment: Bibliometrics in the Context of the UK Research Assessment\n  Exercise", "comments": "Published in at http://dx.doi.org/10.1214/09-STS285A the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 15-16", "doi": "10.1214/09-STS285A", "report-no": "IMS-STS-STS285A", "categories": "stat.ME cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research funding and reputation in the UK have, for over two decades, been\nincreasingly dependent on a regular peer-review of all UK departments. This is\nto move to a system more based on bibliometrics. Assessment exercises of this\nkind influence the behavior of institutions, departments and individuals, and\ntherefore bibliometrics will have effects beyond simple measurement.\n[arXiv:0910.3529]\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2009 11:49:52 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Silverman", "Bernard W.", ""]]}, {"id": "0910.3537", "submitter": "Sune Lehmann", "authors": "Sune Lehmann, Benny E. Lautrup, Andrew D. Jackson", "title": "Comment: Citation Statistics", "comments": "Published in at http://dx.doi.org/10.1214/09-STS285B the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 17-20", "doi": "10.1214/09-STS285B", "report-no": "IMS-STS-STS285B", "categories": "stat.ME cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the paper \"Citation Statistics\" by the Joint Committee on\nQuantitative Assessment of Research [arXiv:0910.3529]. In particular, we focus\non a necessary feature of \"good\" measures for ranking scientific authors: that\ngood measures must able to accurately distinguish between authors.\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2009 12:02:16 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Lehmann", "Sune", ""], ["Lautrup", "Benny E.", ""], ["Jackson", "Andrew D.", ""]]}, {"id": "0910.3543", "submitter": "Harvey Goldstein", "authors": "David Spiegelhalter, Harvey Goldstein", "title": "Comment: Citation Statistics", "comments": "Published in at http://dx.doi.org/10.1214/09-STS285C the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 21-24", "doi": "10.1214/09-STS285C", "report-no": "IMS-STS-STS285C", "categories": "stat.ME cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on \"Citation Statistics\" [arXiv:0910.3529]\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2009 12:17:05 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Spiegelhalter", "David", ""], ["Goldstein", "Harvey", ""]]}, {"id": "0910.3546", "submitter": "Peter Gavin Hall", "authors": "Peter Gavin Hall", "title": "Comment: Citation Statistics", "comments": "Published in at http://dx.doi.org/10.1214/09-STS285D the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 25-26", "doi": "10.1214/09-STS285D", "report-no": "IMS-STS-STS285D", "categories": "stat.ME cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on \"Citation Statistics\" [arXiv:0910.3529]\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2009 12:31:00 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Hall", "Peter Gavin", ""]]}, {"id": "0910.3548", "submitter": "Robert Adler", "authors": "Robert Adler, John Ewing, Peter Taylor", "title": "Rejoinder: Citation Statistics", "comments": "Published in at http://dx.doi.org/10.1214/09-STS285REJ the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 27-28", "doi": "10.1214/09-STS285REJ", "report-no": "IMS-STS-STS285REJ", "categories": "stat.ME cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rejoinder to \"Citation Statistics\" [arXiv:0910.3529]\n", "versions": [{"version": "v1", "created": "Mon, 19 Oct 2009 12:48:32 GMT"}], "update_date": "2009-10-20", "authors_parsed": [["Adler", "Robert", ""], ["Ewing", "John", ""], ["Taylor", "Peter", ""]]}, {"id": "0910.3752", "submitter": "Gary King", "authors": "Kosuke Imai, Gary King, Clayton Nall", "title": "The Essential Role of Pair Matching in Cluster-Randomized Experiments,\n  with Application to the Mexican Universal Health Insurance Evaluation", "comments": "This paper commented in: [arXiv:0910.3754], [arXiv:0910.3756].\n  Rejoinder in [arXiv:0910.3758]. Published in at\n  http://dx.doi.org/10.1214/08-STS274 the Statistical Science\n  (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 29-53", "doi": "10.1214/08-STS274", "report-no": "IMS-STS-STS274", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A basic feature of many field experiments is that investigators are only able\nto randomize clusters of individuals--such as households, communities, firms,\nmedical practices, schools or classrooms--even when the individual is the unit\nof interest. To recoup the resulting efficiency loss, some studies pair similar\nclusters and randomize treatment within pairs. However, many other studies\navoid pairing, in part because of claims in the literature, echoed by clinical\ntrials standards organizations, that this matched-pair, cluster-randomization\ndesign has serious problems. We argue that all such claims are unfounded. We\nalso prove that the estimator recommended for this design in the literature is\nunbiased only in situations when matching is unnecessary; its standard error is\nalso invalid. To overcome this problem without modeling assumptions, we develop\na simple design-based estimator with much improved statistical properties. We\nalso propose a model-based approach that includes some of the benefits of our\ndesign-based estimator as well as the estimator in the literature. Our methods\nalso address individual-level noncompliance, which is common in applications\nbut not allowed for in most existing methods. We show that from the perspective\nof bias, efficiency, power, robustness or research costs, and in large or small\nsamples, pairing should be used in cluster-randomized experiments whenever\nfeasible; failing to do so is equivalent to discarding a considerable fraction\nof one's data. We develop these techniques in the context of a randomized\nevaluation we are conducting of the Mexican Universal Health Insurance Program.\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2009 07:34:19 GMT"}], "update_date": "2009-10-21", "authors_parsed": [["Imai", "Kosuke", ""], ["King", "Gary", ""], ["Nall", "Clayton", ""]]}, {"id": "0910.3754", "submitter": "Marc Scott", "authors": "Jennifer Hill, Marc Scott", "title": "Comment: The Essential Role of Pair Matching", "comments": "Published in at http://dx.doi.org/10.1214/09-STS274A the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 54-58", "doi": "10.1214/09-STS274A", "report-no": "IMS-STS-STS274A", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on \"The Essential Role of Pair Matching in Cluster-Randomized\nExperiments, with Application to the Mexican Universal Health Insurance\nEvaluation\" [arXiv:0910.3752]\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2009 07:05:19 GMT"}], "update_date": "2009-10-21", "authors_parsed": [["Hill", "Jennifer", ""], ["Scott", "Marc", ""]]}, {"id": "0910.3756", "submitter": "Dylan S. Small", "authors": "Kai Zhang, Dylan S. Small", "title": "Comment: The Essential Role of Pair Matching in Cluster-Randomized\n  Experiments, with Application to the Mexican Universal Health Insurance\n  Evaluation", "comments": "Published in at http://dx.doi.org/10.1214/09-STS274B the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 59-64", "doi": "10.1214/09-STS274B", "report-no": "IMS-STS-STS274B", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on ``The Essential Role of Pair Matching in Cluster-Randomized\nExperiments, with Application to the Mexican Universal Health Insurance\nEvaluation'' [arXiv:0910.3752]\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2009 07:17:00 GMT"}], "update_date": "2009-10-21", "authors_parsed": [["Zhang", "Kai", ""], ["Small", "Dylan S.", ""]]}, {"id": "0910.3758", "submitter": "Gary King", "authors": "Kosuke Imai, Gary King, Clayton Nall", "title": "Rejoinder: Matched Pairs and the Future of Cluster-Randomized\n  Experiments", "comments": "Published in at http://dx.doi.org/10.1214/09-STS274REJ the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 1, 65-72", "doi": "10.1214/09-STS274REJ", "report-no": "IMS-STS-STS274REJ", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rejoinder to \"The Essential Role of Pair Matching in Cluster-Randomized\nExperiments, with Application to the Mexican Universal Health Insurance\nEvaluation\" [arXiv:0910.3752]\n", "versions": [{"version": "v1", "created": "Tue, 20 Oct 2009 07:26:53 GMT"}], "update_date": "2009-10-21", "authors_parsed": [["Imai", "Kosuke", ""], ["King", "Gary", ""], ["Nall", "Clayton", ""]]}, {"id": "0910.4443", "submitter": "Tom Britton", "authors": "Tom Britton", "title": "Stochastic epidemic models: a survey", "comments": "26 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.AP stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a survey paper on stochastic epidemic models. A simple\nstochastic epidemic model is defined and exact and asymptotic model properties\n(relying on a large community) are presented. The purpose of modelling is\nillustrated by studying effects of vaccination and also in terms of inference\nprocedures for important parameters, such as the basic reproduction number and\nthe critical vaccination coverage. Several generalizations towards realism,\ne.g. multitype and household epidemic models, are also presented, as is a model\nfor endemic diseases.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2009 06:09:32 GMT"}], "update_date": "2009-11-05", "authors_parsed": [["Britton", "Tom", ""]]}, {"id": "0910.4472", "submitter": "Tina Toni", "authors": "Tina Toni and Michael P. H. Stumpf", "title": "Tutorial on ABC rejection and ABC SMC for parameter estimation and model\n  selection", "comments": "This tutorial forms a part of the supplementary material of the paper\n  \"T. Toni, M. P. H. Stumpf, Simulation-based model selection for dynamical\n  systems in systems and population biology, Bioinformatics, 2009 (in press)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this tutorial we schematically illustrate four algorithms:\n  (1) ABC rejection for parameter estimation\n  (2) ABC SMC for parameter estimation\n  (3) ABC rejection for model selection on the joint space\n  (4) ABC SMC for model selection on the joint space.\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2009 13:03:35 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2010 10:00:37 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Toni", "Tina", ""], ["Stumpf", "Michael P. H.", ""]]}, {"id": "0910.4558", "submitter": "Yannick Deville", "authors": "Yannick Deville (1), Alain Deville (2), Shahram Hosseini (1) ((1)\n  Laboratoire d'Astrophysique de Toulouse-Tarbes, Universite de Toulouse, CNRS,\n  Toulouse, France, (2) IM2NP, Universite de Provence, Marseille, France)", "title": "Effect of indirect dependencies on \"A mutual information minimization\n  approach for a class of nonlinear recurrent separating systems\"", "comments": "7 pages, 0 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper [4], Duarte and Jutten investigated the Blind Source\nSeparation (BSS) problem, for the nonlinear mixing model that they introduced\nin that paper. They proposed to solve this problem by using\ninformation-theoretic tools, more precisely by minimizing the mutual\ninformation (MI) of the outputs of the separating structure. When applying the\nMI approach to BSS problems, one usually determines the analytical expressions\nof the derivatives of the MI with respect to the parameters of the considered\nseparating model. In the literature, these calculations were mainly reported\nfor linear mixtures up to now. They are more complex for nonlinear mixtures,\ndue to dependencies between the considered quantities. Moreover, the notations\ncommonly employed by the BSS community in such calculations may become\nmisleading when using them for nonlinear mixtures, due to the above-mentioned\ndependencies. We claim that the calculations reported in [4] contain an error,\nbecause they did not take into account all these dependencies. In this\ndocument, we therefore explain this phenomenon, by showing the effect of\nindirect dependencies on the application of the MI approach to the mixing and\nseparating models considered in [4]. We thus introduce a corrected expression\nof the gradient of the considered BSS criterion based on MI. This correct\ngradient may then e.g. be used to optimize the adaptive coefficients of the\nconsidered separating system by means of the well-known gradient descent\nalgorithm. As explained hereafter, this investigation has some similarities\nwith an analysis that we previously reported in another arXiv document [3].\nHowever, these two investigations concern different problems (mixture and\nseparating structure, mathematical tools: see paper).\n", "versions": [{"version": "v1", "created": "Fri, 23 Oct 2009 18:01:30 GMT"}, {"version": "v2", "created": "Sun, 25 Oct 2009 19:20:00 GMT"}], "update_date": "2009-10-26", "authors_parsed": [["Deville", "Yannick", ""], ["Deville", "Alain", ""], ["Hosseini", "Shahram", ""]]}, {"id": "0910.4610", "submitter": "Jieqi Yu", "authors": "Jieqi Yu, Haipeng Zheng, Sanjeev R. Kulkarni, H. Vincent Poor", "title": "Outlier Elimination for Robust Ellipse and Ellipsoid Fitting", "comments": "4 pages, 9 figures, accepted by The Third International Workshop on\n  Computational Advances in Multi-Sensor Adaptive Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, an outlier elimination algorithm for ellipse/ellipsoid fitting\nis proposed. This two-stage algorithm employs a proximity-based outlier\ndetection algorithm (using the graph Laplacian), followed by a model-based\noutlier detection algorithm similar to random sample consensus (RANSAC). These\ntwo stages compensate for each other so that outliers of various types can be\neliminated with reasonable computation. The outlier elimination algorithm\nconsiderably improves the robustness of ellipse/ellipsoid fitting as\ndemonstrated by simulations.\n", "versions": [{"version": "v1", "created": "Sat, 24 Oct 2009 00:53:45 GMT"}], "update_date": "2009-10-27", "authors_parsed": [["Yu", "Jieqi", ""], ["Zheng", "Haipeng", ""], ["Kulkarni", "Sanjeev R.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "0910.4696", "submitter": "Christian P. Robert", "authors": "Christian P. Robert and Jean-Michel Marin", "title": "Bayesian Core: The Complete Solution Manual", "comments": "118+vii pages, 21 figures, 152 solutions", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This solution manual contains the unabridged and original solutions to all\nthe exercises proposed in Bayesian Core, along with R programs when necessary.\n", "versions": [{"version": "v1", "created": "Mon, 26 Oct 2009 18:52:32 GMT"}], "update_date": "2009-10-27", "authors_parsed": [["Robert", "Christian P.", ""], ["Marin", "Jean-Michel", ""]]}, {"id": "0910.5060", "submitter": "Chris C. Holmes", "authors": "Chris C. Holmes, Fran\\c{c}ois Caron, Jim E. Griffin, David A. Stephens", "title": "Two-sample Bayesian Nonparametric Hypothesis Testing", "comments": "Published at http://dx.doi.org/10.1214/14-BA914 in the Bayesian\n  Analysis (http://projecteuclid.org/euclid.ba) by the International Society of\n  Bayesian Analysis (http://bayesian.org/)", "journal-ref": "Bayesian Analysis 2015, Vol. 10, No. 2, 297-320", "doi": "10.1214/14-BA914", "report-no": "VTeX-BA-BA914", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we describe Bayesian nonparametric procedures for two-sample\nhypothesis testing. Namely, given two sets of samples\n$\\mathbf{y}^{\\scriptscriptstyle(1)}\\;$\\stackrel{\\scriptscriptstyle{iid}}{\\s\nim}$\\;F^{\\scriptscriptstyle(1)}$ and $\\mathbf{y}^{\\scriptscriptstyle(2\n)}\\;$\\stackrel{\\scriptscriptstyle{iid}}{\\sim}$\\;F^{\\scriptscriptstyle( 2)}$,\nwith $F^{\\scriptscriptstyle(1)},F^{\\scriptscriptstyle(2)}$ unknown, we wish to\nevaluate the evidence for the null hypothesis\n$H_0:F^{\\scriptscriptstyle(1)}\\equiv F^{\\scriptscriptstyle(2)}$ versus the\nalternative $H_1:F^{\\scriptscriptstyle(1)}\\neq F^{\\scriptscriptstyle(2)}$. Our\nmethod is based upon a nonparametric P\\'{o}lya tree prior centered either\nsubjectively or using an empirical procedure. We show that the P\\'{o}lya tree\nprior leads to an analytic expression for the marginal likelihood under the two\nhypotheses and hence an explicit measure of the probability of the null\n$\\mathrm{Pr}(H_0|\\{\\mathbf\n{y}^{\\scriptscriptstyle(1)},\\mathbf{y}^{\\scriptscriptstyle(2)}\\}\\mathbf{)}$.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2009 08:37:19 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2012 14:01:45 GMT"}, {"version": "v3", "created": "Mon, 11 May 2015 12:57:37 GMT"}], "update_date": "2015-05-12", "authors_parsed": [["Holmes", "Chris C.", ""], ["Caron", "Fran\u00e7ois", ""], ["Griffin", "Jim E.", ""], ["Stephens", "David A.", ""]]}, {"id": "0910.5185", "submitter": "P. J. C. Spreij", "authors": "Bert van Es, Peter Spreij, Harry van Zanten", "title": "Nonparametric methods for volatility density estimation", "comments": null, "journal-ref": "Advanced Mathematical Methods for Finance, Chapter 11, 293-312,\n  Giulia di Nunno, Bernt {\\O}ksendal Eds., Springer (2011)", "doi": null, "report-no": null, "categories": "stat.ME math.ST q-fin.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic volatility modelling of financial processes has become\nincreasingly popular. The proposed models usually contain a stationary\nvolatility process. We will motivate and review several nonparametric methods\nfor estimation of the density of the volatility process. Both models based on\ndiscretely sampled continuous time processes and discrete time models will be\ndiscussed.\n  The key insight for the analysis is a transformation of the volatility\ndensity estimation problem to a deconvolution model for which standard methods\nexist. Three type of nonparametric density estimators are reviewed: the\nFourier-type deconvolution kernel density estimator, a wavelet deconvolution\ndensity estimator and a penalized projection estimator. The performance of\nthese estimators will be compared. Key words: stochastic volatility models,\ndeconvolution, density estimation, kernel estimator, wavelets, minimum contrast\nestimation, mixing\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2009 17:38:41 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["van Es", "Bert", ""], ["Spreij", "Peter", ""], ["van Zanten", "Harry", ""]]}, {"id": "0910.5449", "submitter": "David Friedenberg", "authors": "David A. Friedenberg and Christopher R. Genovese", "title": "Straight to the Source: Detecting Aggregate Objects in Astronomical\n  Images with Proper Error Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP astro-ph.IM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next generation of telescopes will acquire terabytes of image data on a\nnightly basis. Collectively, these large images will contain billions of\ninteresting objects, which astronomers call sources. The astronomers' task is\nto construct a catalog detailing the coordinates and other properties of the\nsources. The source catalog is the primary data product for most telescopes and\nis an important input for testing new astrophysical theories, but to construct\nthe catalog one must first detect the sources. Existing algorithms for catalog\ncreation are effective at detecting sources, but do not have rigorous\nstatistical error control. At the same time, there are several multiple testing\nprocedures that provide rigorous error control, but they are not designed to\ndetect sources that are aggregated over several pixels. In this paper, we\npropose a technique that does both, by providing rigorous statistical error\ncontrol on the aggregate objects themselves rather than the pixels. We\ndemonstrate the effectiveness of this approach on data from the Chandra X-ray\nObservatory Satellite. Our technique effectively controls the rate of false\nsources, yet still detects almost all of the sources detected by procedures\nthat do not have such rigorous error control and have the advantage of\nadditional data in the form of follow up observations, which will not be\navailable for upcoming large telescopes. In fact, we even detect a new source\nthat was missed by previous studies. The statistical methods developed in this\npaper can be extended to problems beyond Astronomy, as we will illustrate with\nan example from Neuroimaging.\n", "versions": [{"version": "v1", "created": "Wed, 28 Oct 2009 18:31:46 GMT"}], "update_date": "2009-10-29", "authors_parsed": [["Friedenberg", "David A.", ""], ["Genovese", "Christopher R.", ""]]}, {"id": "0910.5872", "submitter": "Beatriz Susana Marron", "authors": "Beatriz Marron and Ana Tablar", "title": "Estimation of safety areas for epidemic spread", "comments": "20 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study safety areas in epidemic spred. The aim of this work\nis, given the evolution of epidemic at time $t$, find a safety set at time\n$t+h$. This is, a random set $K_{t+h}$ such that the probability that infection\nreaches $K_{t+h}$ at time $t+h$ is small.\n  More precisely, inspired on the study of epidemic spread, we consider a model\nin which the measure $\\mu_n(A)$ is the incidence -density of infectives\nindividuals- in the set $A$, at time $n$ and\n$$\\mu_{n+1}(A)(\\omega)=\\int_S{\\pi_{n+1}(A;s)(\\omega)\\mu_n(ds)(\\omega)}, {for\nany Borel set} A, $$ with random transition kernels of the form\n$$\\pi_n(.;.)(\\omega)=\\Pi(.;.)(\\xi_n(\\omega),Y_n(\\omega)),$$ where $\\xi$, $Y$\nsatisfy some ergodic conditions. The support of $\\mu_n$ is called $S_n$. We\nalso assume that $S_0$ is compact with regular border and that for any $x,y$\nthe kernel $\\Pi(.;.)(x,y)$ has compact support. A random set $K_{n+1}$ is a\nsafety area of level $\\alpha$ if: [{$i$)}] $K_{n+1}$ {\\rm is a function of}\n$S_0, S_1, ...,S_n.$\n  [{$ii$)}] $P(K_{n+1} \\cap S_{n+1} \\neq \\emptyset)\\leq \\alpha.$ We present a\nmethod to find these safety areas and some related results.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2009 14:05:01 GMT"}], "update_date": "2009-11-02", "authors_parsed": [["Marron", "Beatriz", ""], ["Tablar", "Ana", ""]]}]