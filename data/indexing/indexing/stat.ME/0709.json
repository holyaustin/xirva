[{"id": "0709.0111", "submitter": "Djalil Chafai", "authors": "Djalil Chafai (UPTE, IMT), Didier Concordet (UPTE, IMT)", "title": "A new method for the estimation of variance matrix with prescribed zeros\n  in nonlinear mixed effects models", "comments": "Accepted for publication in Statistics and Computing", "journal-ref": "Statistics and Computing 19, 2 (2009) 129-138", "doi": "10.1007/s11222-008-9076-9", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for the Maximum Likelihood Estimator (MLE) of\nnonlinear mixed effects models when the variance matrix of Gaussian random\neffects has a prescribed pattern of zeros (PPZ). The method consists in\ncoupling the recently developed Iterative Conditional Fitting (ICF) algorithm\nwith the Expectation Maximization (EM) algorithm. It provides positive definite\nestimates for any sample size, and does not rely on any structural assumption\non the PPZ. It can be easily adapted to many versions of EM.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2007 16:36:14 GMT"}, {"version": "v2", "created": "Tue, 25 Nov 2008 20:14:07 GMT"}], "update_date": "2009-02-11", "authors_parsed": [["Chafai", "Djalil", "", "UPTE, IMT"], ["Concordet", "Didier", "", "UPTE, IMT"]]}, {"id": "0709.0139", "submitter": "David Stephens", "authors": "Emma J. McCoy, Sofia C. Olhede and David A. Stephens", "title": "Non-Regular Likelihood Inference for Seasonally Persistent Processes", "comments": "57 pages, including 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": null, "abstract": "  The estimation of parameters in the frequency spectrum of a seasonally\npersistent stationary stochastic process is addressed. For seasonal persistence\nassociated with a pole in the spectrum located away from frequency zero, a new\nWhittle-type likelihood is developed that explicitly acknowledges the location\nof the pole. This Whittle likelihood is a large sample approximation to the\ndistribution of the periodogram over a chosen grid of frequencies, and\nconstitutes an approximation to the time-domain likelihood of the data, via the\nlinear transformation of an inverse discrete Fourier transform combined with a\ndemodulation. The new likelihood is straightforward to compute, and as will be\ndemonstrated has good, yet non-standard, properties. The asymptotic behaviour\nof the proposed likelihood estimators is studied; in particular,\n$N$-consistency of the estimator of the spectral pole location is established.\nLarge finite sample and asymptotic distributions of the score and observed\nFisher information are given, and the corresponding distributions of the\nmaximum likelihood estimators are deduced. A study of the small sample\nproperties of the likelihood approximation is provided, and its superior\nperformance to previously suggested methods is shown, as well as agreement with\nthe developed distributional approximations.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2007 00:49:16 GMT"}], "update_date": "2007-09-04", "authors_parsed": [["McCoy", "Emma J.", ""], ["Olhede", "Sofia C.", ""], ["Stephens", "David A.", ""]]}, {"id": "0709.0258", "submitter": "Boris Efros A", "authors": "Ery Arias-Castro, Boris Efros and Ofer Levi", "title": "Networks of Polynomial Pieces with Application to the Analysis of Point\n  Clouds and Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Holder smoothness classes of surfaces for which we construct\npiecewise polynomial approximation networks, which are graphs with polynomial\npieces as nodes and edges between polynomial pieces that are in `good\ncontinuation' of each other. Little known to the community, a similar\nconstruction was used by Kolmogorov and Tikhomirov in their proof of their\ncelebrated entropy results for Holder classes.\n  We show how to use such networks in the context of detecting geometric\nobjects buried in noise to approximate the scan statistic, yielding an\noptimization problem akin to the Traveling Salesman. In the same context, we\ndescribe an alternative approach based on computing the longest path in the\nnetwork after appropriate thresholding.\n  For the special case of curves, we also formalize the notion of `good\ncontinuation' between beamlets in any dimension, obtaining more economical\npiecewise linear approximation networks for curves.\n  We include some numerical experiments illustrating the use of the beamlet\nnetwork in characterizing the filamentarity content of 3D datasets, and show\nthat even a rudimentary notion of good continuity may bring substantial\nimprovement.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2007 15:16:09 GMT"}, {"version": "v2", "created": "Wed, 3 Dec 2008 23:48:17 GMT"}], "update_date": "2008-12-04", "authors_parsed": [["Arias-Castro", "Ery", ""], ["Efros", "Boris", ""], ["Levi", "Ofer", ""]]}, {"id": "0709.0334", "submitter": "Lutz Duembgen", "authors": "Lutz Duembgen, Kaspar Rufibach", "title": "Maximum likelihood estimation of a log-concave density and its\n  distribution function: Basic properties and uniform consistency", "comments": "Published in at http://dx.doi.org/10.3150/08-BEJ141 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm), Version 3 is\n  the extended technical report cited in version 4", "journal-ref": "Bernoulli 2009, Vol. 15, No. 1, 40-68", "doi": "10.3150/08-BEJ141", "report-no": "IMS-BEJ-BEJ141", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonparametric maximum likelihood estimation of a log-concave\nprobability density and its distribution and hazard function. Some general\nproperties of these estimators are derived from two characterizations. It is\nshown that the rate of convergence with respect to supremum norm on a compact\ninterval for the density and hazard rate estimator is at least\n$(\\log(n)/n)^{1/3}$ and typically $(\\log(n)/n)^{2/5}$, whereas the difference\nbetween the empirical and estimated distribution function vanishes with rate\n$o_{\\mathrm{p}}(n^{-1/2})$ under certain regularity assumptions.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2007 05:18:31 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2007 11:53:42 GMT"}, {"version": "v3", "created": "Tue, 8 Jan 2008 08:49:19 GMT"}, {"version": "v4", "created": "Mon, 9 Feb 2009 14:29:19 GMT"}], "update_date": "2009-02-10", "authors_parsed": [["Duembgen", "Lutz", ""], ["Rufibach", "Kaspar", ""]]}, {"id": "0709.1309", "submitter": "Heng Lian", "authors": "Heng Lian", "title": "Bayes and empirical Bayes changepoint problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": null, "abstract": "  We generalize the approach of Liu and Lawrence (1999) for multiple\nchangepoint problems where the number of changepoints is unknown. The approach\nis based on dynamic programming recursion for efficient calculation of the\nmarginal probability of the data with the hidden parameters integrated out. For\nthe estimation of the hyperparameters, we propose to use Monte Carlo EM when\ntraining data are available. We argue that there is some advantages of using\nsamples from the posterior which takes into account the uncertainty of the\nchangepoints, compared to the traditional MAP estimator, which is also more\nexpensive to compute in this context. The samples from the posterior obtained\nby our algorithm are independent, getting rid of the convergence issue\nassociated with the MCMC approach. We illustrate our approach on limited\nsimulations and some real data set.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2007 04:31:05 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Lian", "Heng", ""]]}, {"id": "0709.1616", "submitter": "Bin Wang", "authors": "Bin Wang, Xiaofeng Wang", "title": "Bandwidth Selection for Weighted Kernel Density Estimation", "comments": "Will be rewritten for resubmission", "journal-ref": null, "doi": null, "report-no": "IMS-EJS-EJS_2007_112", "categories": "stat.ME", "license": null, "abstract": "  In the this paper, the authors propose to estimate the density of a targeted\npopulation with a weighted kernel density estimator (wKDE) based on a weighted\nsample. Bandwidth selection for wKDE is discussed. Three mean integrated\nsquared error based bandwidth estimators are introduced and their performance\nis illustrated via Monte Carlo simulation. The least-squares cross-validation\nmethod and the adaptive weight kernel density estimator are also studied. The\nauthors also consider the boundary problem for interval bounded data and apply\nthe new method to a real data set subject to informative censoring.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2007 13:14:55 GMT"}, {"version": "v2", "created": "Thu, 13 Sep 2007 12:13:34 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2011 23:03:25 GMT"}], "update_date": "2011-11-28", "authors_parsed": [["Wang", "Bin", ""], ["Wang", "Xiaofeng", ""]]}, {"id": "0709.1663", "submitter": "Efang Kong", "authors": "Efang Kong, Oliver Linton and Yingcun Xia", "title": "Uniform Bahadur Representation for Local Polynomial Estimates of\n  M-Regression and Its Application to The Additive Model", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": null, "abstract": "  We use local polynomial fitting to estimate the nonparametric M-regression\nfunction for strongly mixing stationary processes\n$\\{(Y_{i},\\underline{X}_{i})\\}$. We establish a strong uniform consistency rate\nfor the Bahadur representation of estimators of the regression function and its\nderivatives. These results are fundamental for statistical inference and for\napplications that involve plugging in such estimators into other functionals\nwhere some control over higher order terms are required. We apply our results\nto the estimation of an additive M-regression model.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2007 15:34:02 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2007 11:06:45 GMT"}], "update_date": "2007-11-29", "authors_parsed": [["Kong", "Efang", ""], ["Linton", "Oliver", ""], ["Xia", "Yingcun", ""]]}, {"id": "0709.2007", "submitter": "Markus Rei{\\ss}", "authors": "Michael H. Neumann, Markus Reiss", "title": "Nonparametric estimation for L\\'evy processes from low-frequency\n  observations", "comments": "24 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": null, "abstract": "  We suppose that a L\\'evy process is observed at discrete time points. A\nrather general construction of minimum-distance estimators is shown to give\nconsistent estimators of the L\\'evy-Khinchine characteristics as the number of\nobservations tends to infinity, keeping the observation distance fixed. For a\nspecific $C^2$-criterion this estimator is rate-optimal. The connection with\ndeconvolution and inverse problems is explained. A key step in the proof is a\nuniform control on the deviations of the empirical characteristic function on\nthe whole real line.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2007 07:46:20 GMT"}, {"version": "v2", "created": "Thu, 29 May 2008 12:12:39 GMT"}], "update_date": "2008-05-29", "authors_parsed": [["Neumann", "Michael H.", ""], ["Reiss", "Markus", ""]]}, {"id": "0709.2050", "submitter": "Vivian Viallon", "authors": "Bertrand Maillot and Vivian Viallon", "title": "Uniform limit laws of the logarithm for nonparametric estimators of the\n  regression function in presence of censored data", "comments": "34 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": null, "abstract": "  In this paper, we establish uniform-in-bandwidth limit laws of the logarithm\nfor nonparametric Inverse Probability of Censoring Weighted (I.P.C.W.)\nestimators of the multivariate regression function under random censorship. A\nsimilar result is deduced for estimators of the conditional distribution\nfunction. The uniform-in-bandwidth consistency for estimators of the\nconditional density and the conditional hazard rate functions are also derived\nfrom our main result. Moreover, the logarithm laws we establish are shown to\nyield almost sure simultaneous asymptotic confidence bands for the functions we\nconsider. Examples of confidence bands obtained from simulated data are\ndisplayed.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2007 12:07:42 GMT"}], "update_date": "2007-09-14", "authors_parsed": [["Maillot", "Bertrand", ""], ["Viallon", "Vivian", ""]]}, {"id": "0709.2776", "submitter": "Hacene Belbachir", "authors": "Abdelhakim Aknouche Hac\\`ene Belbachir Fay\\c{c}al Hamdi", "title": "A note on calculating autocovariances of periodic ARMA models", "comments": "3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.CO stat.CO", "license": null, "abstract": "  An analytically simple and tractable formula for the start-up autocovariances\nof periodic ARMA (PARMA) models is provided.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2007 09:10:25 GMT"}], "update_date": "2007-09-19", "authors_parsed": [["Hamdi", "Abdelhakim Aknouche Hac\u00e8ne Belbachir Fay\u00e7al", ""]]}, {"id": "0709.2943", "submitter": "Francisco Cribari-Neto", "authors": "Audrey H.M.A. Cysneiros, Francisco Cribari-Neto, Carlos A.G. Araujo Jr", "title": "On Birnbaum-Saunders Inference", "comments": "Paper accepted for publication in Computational Statistics and Data\n  Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": null, "abstract": "  The Birnbaum-Saunders distribution, also known as the fatigue-life\ndistribution, is frequently used in reliability studies. We obtain adjustments\nto the Birnbaum--Saunders profile likelihood function. The modified versions of\nthe likelihood function were obtained for both the shape and scale parameters,\ni.e., we take the shape parameter to be of interest and the scale parameter to\nbe of nuisance, and then consider the situation in which the interest lies in\nperforming inference on the scale parameter with the shape parameter entering\nthe modeling in nuisance fashion. Modified profile maximum likelihood\nestimators are obtained by maximizing the corresponding adjusted likelihood\nfunctions. We present numerical evidence on the finite sample behavior of the\ndifferent estimators and associated likelihood ratio tests. The results favor\nthe adjusted estimators and tests we propose. A novel aspect of the profile\nlikelihood adjustments obtained in this paper is that they yield improved point\nestimators and tests. The two profile likelihood adjustments work well when\ninference is made on the shape parameter, and one of them displays superior\nbehavior when it comes to performing hypothesis testing inference on the scale\nparameter. Two empirical applications are briefly presented.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2007 01:41:55 GMT"}, {"version": "v2", "created": "Sun, 6 Apr 2008 14:29:13 GMT"}], "update_date": "2008-04-06", "authors_parsed": [["Cysneiros", "Audrey H. M. A.", ""], ["Cribari-Neto", "Francisco", ""], ["Araujo", "Carlos A. G.", "Jr"]]}, {"id": "0709.2982", "submitter": "Hacene Belbachir", "authors": "Abdehakim Aknouche, Abdelouhab Bibi", "title": "Quasi-maximum likelihood estimation of periodic GARCH processes", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": null, "abstract": "  This paper establishes the strong consistency and asymptotic normality of the\nquasi-maximum likelihood estimator (QMLE) for a GARCH process with periodically\ntime-varying parameters. We first give a necessary and sufficient condition for\nthe existence of a strictly periodically stationary solution for the periodic\nGARCH (P-GARCH) equation. As a result, it is shown that the moment of some\npositive order of the P-GARCH solution is finite, under which we prove the\nstrong consistency and asymptotic normality (CAN) of the QMLE without any\ncondition on the moments of the underlying process.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2007 10:10:45 GMT"}], "update_date": "2007-09-20", "authors_parsed": [["Aknouche", "Abdehakim", ""], ["Bibi", "Abdelouhab", ""]]}, {"id": "0709.2997", "submitter": "Eva Riccomagno", "authors": "Roberto Notari, Eva Riccomagno, Maria-Piera Rogantin", "title": "Two polynomial representations of experimental design", "comments": "13 pages", "journal-ref": "Journal of Statistical Theory and Practice, 1:3-4, 329-346 (2008)", "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": null, "abstract": "  In the context of algebraic statistics an experimental design is described by\na set of polynomials called the design ideal. This, in turn, is generated by\nfinite sets of polynomials. Two types of generating sets are mostly used in the\nliterature: Groebner bases and indicator functions. We briefly describe them\nboth, how they are used in the analysis and planning of a design and how to\nswitch between them. Examples include fractions of full factorial designs and\ndesigns for mixture experiments.\n", "versions": [{"version": "v1", "created": "Wed, 19 Sep 2007 11:50:48 GMT"}], "update_date": "2008-09-10", "authors_parsed": [["Notari", "Roberto", ""], ["Riccomagno", "Eva", ""], ["Rogantin", "Maria-Piera", ""]]}, {"id": "0709.3192", "submitter": "Olivier P. Faugeras", "authors": "Olivier P. Faugeras (LSTA)", "title": "A quantile-copula approach to conditional density estimation", "comments": "with short simulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": null, "abstract": "  We present a new non-parametric estimator of the conditional density of the\nkernel type. It is based on an efficient transformation of the data by quantile\ntransform. By use of the copula representation, it turns out to have a\nremarkable product form. We study its asymptotic properties and compare its\nbias and variance to competitors based on nonparametric regression.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2007 11:17:23 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2008 17:14:33 GMT"}, {"version": "v3", "created": "Thu, 12 Jun 2008 11:44:16 GMT"}], "update_date": "2008-06-13", "authors_parsed": [["Faugeras", "Olivier P.", "", "LSTA"]]}, {"id": "0709.3377", "submitter": "Eva Riccomagno", "authors": "Eva Riccomagno and Jim Q Smith", "title": "Algebraic causality: Bayes nets and beyond", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  The relationship between algebraic geometry and the inferential framework of\nthe Bayesian Networks with hidden variables has now been fruitfully explored\nand exploited by a number of authors. More recently the algebraic formulation\nof Causal Bayesian Networks has also been investigated in this context. After\nreviewing these newer relationships, we proceed to demonstrate that many of the\nideas embodied in the concept of a ``causal model'' can be more generally\nexpressed directly in terms of a partial order and a family of polynomial maps.\nThe more conventional graphical constructions, when available, remain a\npowerful tool.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2007 09:18:32 GMT"}], "update_date": "2007-09-24", "authors_parsed": [["Riccomagno", "Eva", ""], ["Smith", "Jim Q", ""]]}, {"id": "0709.3380", "submitter": "Eva Riccomagno", "authors": "Eva Riccomagno and Jim Q. Smith", "title": "The causal manipulation of chain event graphs", "comments": "49 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  Discrete Bayesian Networks have been very successful as a framework both for\ninference and for expressing certain causal hypotheses. In this paper we\npresent a class of graphical models called the chain event graph (CEG) models,\nthat generalises the class of discrete BN models. It provides a flexible and\nexpressive framework for representing and analysing the implications of causal\nhypotheses, expressed in terms of the effects of a manipulation of the\ngenerating underlying system. We prove that, as for a BN, identifiability\nanalyses of causal effects can be performed through examining the topology of\nthe CEG graph, leading to theorems analogous to the back-door theorem for the\nBN.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2007 09:43:41 GMT"}], "update_date": "2007-09-24", "authors_parsed": [["Riccomagno", "Eva", ""], ["Smith", "Jim Q.", ""]]}, {"id": "0709.3535", "submitter": "Alessandro Rinaldo", "authors": "S.E. Fienberg, P. Hersh, A. Rinaldo and Y. Zhou", "title": "Maximum Likelihood Estimation in Latent Class Models For Contingency\n  Table Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": null, "abstract": "  Statistical models with latent structure have a history going back to the\n1950s and have seen widespread use in the social sciences and, more recently,\nin computational biology and in machine learning. Here we study the basic\nlatent class model proposed originally by the sociologist Paul F. Lazarfeld for\ncategorical variables, and we explain its geometric structure. We draw\nparallels between the statistical and geometric properties of latent class\nmodels and we illustrate geometrically the causes of many problems associated\nwith maximum likelihood estimation and related statistical inference. In\nparticular, we focus on issues of non-identifiability and determination of the\nmodel dimension, of maximization of the likelihood function and on the effect\nof symmetric data. We illustrate these phenomena with a variety of synthetic\nand real-life tables, of different dimension and complexity. Much of the\nmotivation for this work stems from the \"100 Swiss Francs\" problem, which we\nintroduce and describe in detail.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2007 21:28:54 GMT"}], "update_date": "2007-09-25", "authors_parsed": [["Fienberg", "S. E.", ""], ["Hersh", "P.", ""], ["Rinaldo", "A.", ""], ["Zhou", "Y.", ""]]}, {"id": "0709.3545", "submitter": "Robert Kohn", "authors": "Sally Wood, Robert Kohn, Remy Cottet, Wenxin Jiang, Martin Tanner", "title": "Locally Adaptive Nonparametric Binary Regression", "comments": "31 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  A nonparametric and locally adaptive Bayesian estimator is proposed for\nestimating a binary regression. Flexibility is obtained by modeling the binary\nregression as a mixture of probit regressions with the argument of each probit\nregression having a thin plate spline prior with its own smoothing parameter\nand with the mixture weights depending on the covariates. The estimator is\ncompared to a single spline estimator and to a recently proposed locally\nadaptive estimator. The methodology is illustrated by applying it to both\nsimulated and real examples.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2007 22:48:10 GMT"}], "update_date": "2007-09-25", "authors_parsed": [["Wood", "Sally", ""], ["Kohn", "Robert", ""], ["Cottet", "Remy", ""], ["Jiang", "Wenxin", ""], ["Tanner", "Martin", ""]]}, {"id": "0709.3765", "submitter": "E.A. Thompson", "authors": "E.A. Thompson", "title": "1953: An unrecognized summit in human genetic linkage analysis", "comments": "Published in at http://dx.doi.org/10.1214/07-SS027 the Statistics\n  Surveys (http://www.i-journals.org/ss/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistics Surveys 2007, Vol. 1, 1-15", "doi": "10.1214/07-SS027", "report-no": "IMS-SS-SS_2007_27", "categories": "stat.ME", "license": null, "abstract": "  This paper summarizes and discusses the methodological research in human\ngenetic linkage analysis, leading up to and following from the paper of C. A.\nB. Smith presented as a Royal Statistical Society discussion paper in 1953.\nThis paper was given as the Fisher XXVII Memorial Lecture, in Cambridge,\nDecember 4, 2006.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2007 13:39:46 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Thompson", "E. A.", ""]]}, {"id": "0709.3860", "submitter": "Collet", "authors": "J\\'er\\^ome Collet", "title": "Estimating copula measure using ranks and subsampling: a simulation\n  study", "comments": "2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  We describe here a new method to estimate copula measure. From N observations\nof two variables X and Y, we draw a huge number m of subsamples (size n<N), and\nwe compute the joint ranks in these subsamples. Then, for each bivariate rank\n(p,q) (0<p,q<n+1), we count the number of subsamples such that there exist an\nobservation of the subsample with bivariate rank (p,q). This counting gives an\nestimate of the density of the copula. The simulation study shows that this\nmethod seems to gives a better than the usual kernel method. The main advantage\nof this new method is then we do not need to choose and justify the kernel. In\nexchange, we have to choose a subsample size: this is in fact a problem very\nsimilar to the bandwidth choice. We have then reduced the overall difficulty.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2007 17:22:40 GMT"}], "update_date": "2007-09-26", "authors_parsed": [["Collet", "J\u00e9r\u00f4me", ""]]}, {"id": "0709.3884", "submitter": "Giovanni Montana", "authors": "Giovanni Montana, Kostas Triantafyllopoulos, and Theodoros Tsagaris", "title": "Flexible least squares for temporal data mining and statistical\n  arbitrage", "comments": "28 pages, 6 figures, submitted to journal", "journal-ref": "Expert Systems with Applications (2009), 36, 2819-2830.", "doi": "10.1016/j.eswa.2008.01.062", "report-no": null, "categories": "q-fin.ST stat.AP stat.ME", "license": null, "abstract": "  A number of recent emerging applications call for studying data streams,\npotentially infinite flows of information updated in real-time. When multiple\nco-evolving data streams are observed, an important task is to determine how\nthese streams depend on each other, accounting for dynamic dependence patterns\nwithout imposing any restrictive probabilistic law governing this dependence.\nIn this paper we argue that flexible least squares (FLS), a penalized version\nof ordinary least squares that accommodates for time-varying regression\ncoefficients, can be deployed successfully in this context. Our motivating\napplication is statistical arbitrage, an investment strategy that exploits\npatterns detected in financial data streams. We demonstrate that FLS is\nalgebraically equivalent to the well-known Kalman filter equations, and take\nadvantage of this equivalence to gain a better understanding of FLS and suggest\na more efficient algorithm. Promising experimental results obtained from a\nFLS-based algorithmic trading system for the S&P 500 Futures Index are\nreported.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2007 15:25:14 GMT"}], "update_date": "2009-02-08", "authors_parsed": [["Montana", "Giovanni", ""], ["Triantafyllopoulos", "Kostas", ""], ["Tsagaris", "Theodoros", ""]]}, {"id": "0709.3906", "submitter": "Simon Wood", "authors": "Simon N. Wood", "title": "Fast stable direct fitting and smoothness selection for Generalized\n  Additive Models", "comments": null, "journal-ref": null, "doi": "10.1111/j.1467-9868.2007.00646.x", "report-no": null, "categories": "stat.ME stat.CO", "license": null, "abstract": "  Existing computationally efficient methods for penalized likelihood GAM\nfitting employ iterative smoothness selection on working linear models (or\nworking mixed models). Such schemes fail to converge for a non-negligible\nproportion of models, with failure being particularly frequent in the presence\nof concurvity. If smoothness selection is performed by optimizing `whole model'\ncriteria these problems disappear, but until now attempts to do this have\nemployed finite difference based optimization schemes which are computationally\ninefficient, and can suffer from false convergence. This paper develops the\nfirst computationally efficient method for direct GAM smoothness selection. It\nis highly stable, but by careful structuring achieves a computational\nefficiency that leads, in simulations, to lower mean computation times than the\nschemes based on working-model smoothness selection. The method also offers a\nreliable way of fitting generalized additive mixed models.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2007 10:31:42 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Wood", "Simon N.", ""]]}, {"id": "0709.3920", "submitter": "Zvika Ben-Haim", "authors": "Zvika Ben-Haim and Yonina C. Eldar", "title": "Blind Minimax Estimation", "comments": "12 pages, 7 figures", "journal-ref": "IEEE Transactions on Information Theory, 53(9): 3145-3157, Sep.\n  2007", "doi": "10.1109/TIT.2007.903118", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": null, "abstract": "  We consider the linear regression problem of estimating an unknown,\ndeterministic parameter vector based on measurements corrupted by colored\nGaussian noise. We present and analyze blind minimax estimators (BMEs), which\nconsist of a bounded parameter set minimax estimator, whose parameter set is\nitself estimated from measurements. Thus, one does not require any prior\nassumption or knowledge, and the proposed estimator can be applied to any\nlinear regression problem. We demonstrate analytically that the BMEs strictly\ndominate the least-squares estimator, i.e., they achieve lower mean-squared\nerror for any value of the parameter vector. Both Stein's estimator and its\npositive-part correction can be derived within the blind minimax framework.\nFurthermore, our approach can be readily extended to a wider class of\nestimation problems than Stein's estimator, which is defined only for white\nnoise and non-transformed measurements. We show through simulations that the\nBMEs generally outperform previous extensions of Stein's technique.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2007 11:03:51 GMT"}], "update_date": "2007-09-26", "authors_parsed": [["Ben-Haim", "Zvika", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "0709.4079", "submitter": "Adom Giffin", "authors": "Adom Giffin", "title": "Inferring Diversity: Life After Shannon", "comments": "Presented at the 7th International Conference on Complex Systems,\n  Boston, 2007. 8 pages, no figures. Version 2 changes the a sign in the final\n  entropy and a footnote is revised to clairify that this entropy has the same\n  form as the thermodynamic entropy", "journal-ref": "InterJournal of Complex Systems, 2201 (2008)", "doi": null, "report-no": null, "categories": "stat.ME nlin.AO q-bio.GN q-bio.PE", "license": null, "abstract": "  The diversity of a community that cannot be fully counted must be inferred.\nThe two preeminent inference methods are the MaxEnt method, which uses\ninformation in the form of constraints and Bayes' rule which uses information\nin the form of data. It has been shown that these two methods are special cases\nof the method of Maximum (relative) Entropy (ME). We demonstrate how this\nmethod can be used as a measure of diversity that not only reproduces the\nfeatures of Shannon's index but exceeds them by allowing more types of\ninformation to be included in the inference. A specific example is solved in\ndetail. Additionally, the entropy that is found is the same form as the\nthermodynamic entropy.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2007 04:41:28 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2007 17:17:05 GMT"}, {"version": "v3", "created": "Mon, 29 Oct 2007 02:18:27 GMT"}], "update_date": "2008-08-25", "authors_parsed": [["Giffin", "Adom", ""]]}, {"id": "0709.4323", "submitter": "Satoshi Aoki", "authors": "Satoshi Aoki and Akimichi Takemura", "title": "Markov basis for design of experiments with three-level factors", "comments": "17 pages", "journal-ref": "Algebraic and Geometric Methods in Statistics, Cambridge\n  University Press, 2009, 225--238", "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  We consider Markov basis arising from fractional factorial designs with\nthree-level factors. Once we have a Markov basis, $p$ values for various\nconditional tests are estimated by the Markov chain Monte Carlo procedure. For\ndesigned experiments with a single count observation for each run, we formulate\na generalized linear model and consider a sample space with the same sufficient\nstatistics to the observed data. Each model is characterized by a covariate\nmatrix, which is constructed from the main and the interaction effects we\nintend to measure. We investigate fractional factorial designs with $3^{p-q}$\nruns noting correspondences to the models for $3^{p-q}$ contingency tables.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2007 07:22:03 GMT"}, {"version": "v2", "created": "Mon, 4 Feb 2008 00:37:28 GMT"}], "update_date": "2009-11-22", "authors_parsed": [["Aoki", "Satoshi", ""], ["Takemura", "Akimichi", ""]]}]