[{"id": "1001.0188", "submitter": "Alexandre Belloni", "authors": "Alexandre Belloni, Victor Chernozhukov", "title": "Least squares after model selection in high-dimensional sparse models", "comments": "Published in at http://dx.doi.org/10.3150/11-BEJ410 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2013, Vol. 19, No. 2, 521-547", "doi": "10.3150/11-BEJ410", "report-no": "IMS-BEJ-BEJ410", "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study post-model selection estimators that apply ordinary\nleast squares (OLS) to the model selected by first-step penalized estimators,\ntypically Lasso. It is well known that Lasso can estimate the nonparametric\nregression function at nearly the oracle rate, and is thus hard to improve\nupon. We show that the OLS post-Lasso estimator performs at least as well as\nLasso in terms of the rate of convergence, and has the advantage of a smaller\nbias. Remarkably, this performance occurs even if the Lasso-based model\nselection \"fails\" in the sense of missing some components of the \"true\"\nregression model. By the \"true\" model, we mean the best s-dimensional\napproximation to the nonparametric regression function chosen by the oracle.\nFurthermore, OLS post-Lasso estimator can perform strictly better than Lasso,\nin the sense of a strictly faster rate of convergence, if the Lasso-based model\nselection correctly includes all components of the \"true\" model as a subset and\nalso achieves sufficient sparsity. In the extreme case, when Lasso perfectly\nselects the \"true\" model, the OLS post-Lasso estimator becomes the oracle\nestimator. An important ingredient in our analysis is a new sparsity bound on\nthe dimension of the model selected by Lasso, which guarantees that this\ndimension is at most of the same order as the dimension of the \"true\" model.\nOur rate results are nonasymptotic and hold in both parametric and\nnonparametric models. Moreover, our analysis is not limited to the Lasso\nestimator acting as a selector in the first step, but also applies to any other\nestimator, for example, various forms of thresholded Lasso, with good rates and\ngood sparsity properties. Our analysis covers both traditional thresholding and\na new practical, data-driven thresholding scheme that induces additional\nsparsity subject to maintaining a certain goodness of fit. The latter scheme\nhas theoretical guarantees similar to those of Lasso or OLS post-Lasso, but it\ndominates those procedures as well as traditional thresholding in a wide\nvariety of experiments.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2009 22:10:59 GMT"}, {"version": "v2", "created": "Fri, 26 Mar 2010 14:43:22 GMT"}, {"version": "v3", "created": "Sat, 11 Jun 2011 22:56:57 GMT"}, {"version": "v4", "created": "Thu, 25 Aug 2011 02:30:15 GMT"}, {"version": "v5", "created": "Wed, 20 Mar 2013 12:16:15 GMT"}], "update_date": "2013-03-21", "authors_parsed": [["Belloni", "Alexandre", ""], ["Chernozhukov", "Victor", ""]]}, {"id": "1001.0597", "submitter": "XuanLong Nguyen", "authors": "XuanLong Nguyen", "title": "Inference of global clusters from locally distributed data", "comments": "27 pages, 12 figures", "journal-ref": "Published in Bayesian Analysis, 5(4), 817--846, 2010", "doi": null, "report-no": "Technical report 504, Department of Statistics, University of\n  Michigan", "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of analyzing the heterogeneity of clustering\ndistributions for multiple groups of observed data, each of which is indexed by\na covariate value, and inferring global clusters arising from observations\naggregated over the covariate domain. We propose a novel Bayesian nonparametric\nmethod reposing on the formalism of spatial modeling and a nested hierarchy of\nDirichlet processes. We provide an analysis of the model properties, relating\nand contrasting the notions of local and global clusters. We also provide an\nefficient inference algorithm, and demonstrate the utility of our method in\nseveral data examples, including the problem of object tracking and a global\nclustering analysis of functional data where the functional identity\ninformation is not available.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2010 22:47:31 GMT"}, {"version": "v2", "created": "Fri, 21 Jan 2011 15:42:15 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Nguyen", "XuanLong", ""]]}, {"id": "1001.0863", "submitter": "Shahram Hosseini", "authors": "Shahram Hosseini, Yannick Deville", "title": "Correction to: \"Blind maximum likelihood separation of a\n  linear-quadratic mixture\"", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An error occurred in the computation of a gradient in our paper entitled\n\"Blind maximum likelihood separation of a linear-quadratic mixture\", presented\nin ICA'2004. The equations (20) in Appendix and (17) in the text were not\ncorrect. The current paper presents the correct version of these equations.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jan 2010 11:15:35 GMT"}], "update_date": "2010-01-07", "authors_parsed": [["Hosseini", "Shahram", ""], ["Deville", "Yannick", ""]]}, {"id": "1001.1014", "submitter": "Daniel Gervini", "authors": "Daniel Gervini", "title": "Outlier detection and trimmed estimation for general functional data", "comments": null, "journal-ref": "Statistica Sinica, 2012, volume 22, pages 1639-1660", "doi": "10.5705/ss.2010.282", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces trimmed estimators for the mean and covariance\nfunction of general functional data. The estimators are based on a new measure\nof outlyingness or data depth that is well defined on any metric space,\nalthough this paper focuses on Euclidean spaces. We compute the breakdown point\nof the estimators and show that the optimal breakdown point is attainable for\nthe appropriate choice of tuning parameters. The small-sample behavior of the\nestimators is studied by simulation, and we show that they have better\noutlier-resistance properties than alternative estimators. This is confirmed by\ntwo real-data applications, that also show that the outlyingness measure can be\nused as a graphical outlier-detection tool in functional spaces where visual\nscreening of the data is difficult.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2010 01:14:37 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2012 18:21:55 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Gervini", "Daniel", ""]]}, {"id": "1001.1833", "submitter": "Ansgar Steland", "authors": "Ansgar Steland", "title": "Weighted Dickey-Fuller Processes for Detecting Stationarity", "comments": null, "journal-ref": "Journal of Statistical Planning and Inference 2007, 137 (12),\n  4011-4030", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming at monitoring a time series to detect stationarity as soon as\npossible, we introduce monitoring procedures based on kernel-weighted\nsequential Dickey-Fuller (DF) processes, and related stopping times, which may\nbe called weighted Dickey-Fuller control charts. Under rather weak assumptions,\n(functional) central limit theorems are established under the unit root null\nhypothesis and local-to-unity alternatives. For gen- eral dependent and\nheterogeneous innovation sequences the limit processes depend on a nuisance\nparameter. In this case of practical interest, one can use estimated control\nlimits obtained from the estimated asymptotic law. Another easy-to-use approach\nis to transform the DF processes to obtain limit laws which are invariant with\nrespect to the nuisance pa- rameter. We provide asymptotic theory for both\napproaches and compare their statistical behavior in finite samples by\nsimulation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 09:51:16 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Steland", "Ansgar", ""]]}, {"id": "1001.1841", "submitter": "Ansgar Steland", "authors": "Ansgar Steland, Ewaryst Rafalowicz", "title": "A Binary Control Chart to Detect Small Jumps", "comments": null, "journal-ref": "Statistics 2009, 43 (3), 295-311", "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic N p chart gives a signal if the number of successes in a sequence\nof inde- pendent binary variables exceeds a control limit. Motivated by\nengineering applications in industrial image processing and, to some extent,\nfinancial statistics, we study a simple modification of this chart, which uses\nonly the most recent observations. Our aim is to construct a control chart for\ndetecting a shift of an unknown size, allowing for an unknown distribution of\nthe error terms. Simulation studies indicate that the proposed chart is su-\nperior in terms of out-of-control average run length, when one is interest in\nthe detection of very small shifts. We provide a (functional) central limit\ntheorem under a change-point model with local alternatives which explains that\nunexpected and interesting behavior. Since real observations are often not\nindependent, the question arises whether these re- sults still hold true for\nthe dependent case. Indeed, our asymptotic results work under the fairly\ngeneral condition that the observations form a martingale difference array.\nThis enlarges the applicability of our results considerably, firstly, to a\nlarge class time series models, and, secondly, to locally dependent image data,\nas we demonstrate by an example.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 10:43:50 GMT"}], "update_date": "2010-01-13", "authors_parsed": [["Steland", "Ansgar", ""], ["Rafalowicz", "Ewaryst", ""]]}, {"id": "1001.1845", "submitter": "Ansgar Steland", "authors": "Ansgar Steland", "title": "Sequentially Updated Residuals and Detection of Stationary Errors in\n  Polynomial Regression Models", "comments": null, "journal-ref": "Sequential Analysis 2008, 27 (3), 304-329", "doi": null, "report-no": null, "categories": "math.PR math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question whether a time series behaves as a random walk or as a station-\nary process is an important and delicate problem, particularly arising in\nfinancial statistics, econometrics, and engineering. This paper studies the\nproblem to detect sequentially that the error terms in a polynomial regression\nmodel no longer behave as a random walk but as a stationary process. We provide\nthe asymptotic distribution theory for a monitoring procedure given by a\ncontrol chart, i.e., a stopping time, which is related to a well known unit\nroot test statistic calculated from sequentially updated residuals. We provide\na functional central limit theorem for the corresponding stochastic process\nwhich implies a central limit theorem for the control chart. The finite sample\nproperties are investigated by a simulation study.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2010 10:57:21 GMT"}], "update_date": "2010-01-13", "authors_parsed": [["Steland", "Ansgar", ""]]}, {"id": "1001.2055", "submitter": "Yanan Fan Dr", "authors": "Y Fan and S A Sisson", "title": "Reversible jump Markov chain Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To appear to MCMC handbook, S. P. Brooks, A. Gelman, G. Jones and X.-L. Meng\n(eds), Chapman & Hall.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 01:54:50 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Fan", "Y", ""], ["Sisson", "S A", ""]]}, {"id": "1001.2058", "submitter": "Yanan Fan Dr", "authors": "S A Sisson and Y Fan", "title": "Likelihood-free Markov chain Monte Carlo", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To appear to MCMC handbook, S. P. Brooks, A. Gelman, G. Jones and X.-L. Meng\n(eds), Chapman & Hall.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 02:03:16 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Sisson", "S A", ""], ["Fan", "Y", ""]]}, {"id": "1001.2136", "submitter": "Serena Arima", "authors": "Serena Arima and Luca Tardella", "title": "An alternative marginal likelihood estimator for phylogenetic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-bio.QM stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian phylogenetic methods are generating noticeable enthusiasm in the\nfield of molecular systematics. Many phylogenetic models are often at stake and\ndifferent approaches are used to compare them within a Bayesian framework. The\nBayes factor, defined as the ratio of the marginal likelihoods of two competing\nmodels, plays a key role in Bayesian model selection. We focus on an\nalternative estimator of the marginal likelihood whose computation is still a\nchallenging problem. Several computational solutions have been proposed none of\nwhich can be considered outperforming the others simultaneously in terms of\nsimplicity of implementation, computational burden and precision of the\nestimates. Practitioners and researchers, often led by available software, have\nprivileged so far the simplicity of the harmonic mean estimator (HM) and the\narithmetic mean estimator (AM). However it is known that the resulting\nestimates of the Bayesian evidence in favor of one model are biased and often\ninaccurate up to having an infinite variance so that the reliability of the\ncorresponding conclusions is doubtful. Our new implementation of the\ngeneralized harmonic mean (GHM) idea recycles MCMC simulations from the\nposterior, shares the computational simplicity of the original HM estimator,\nbut, unlike it, overcomes the infinite variance issue. The alternative\nestimator is applied to simulated phylogenetic data and produces fully\nsatisfactory results outperforming those simple estimators currently provided\nby most of the publicly available software.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 12:06:44 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2010 13:18:50 GMT"}], "update_date": "2010-06-22", "authors_parsed": [["Arima", "Serena", ""], ["Tardella", "Luca", ""]]}, {"id": "1001.2166", "submitter": "Mehrdad Ghaemi", "authors": "Mehrdad Ghaemi, Zahra Zabihinpour, Yazdan Asgari", "title": "Computer Simulation Study of the Levy Flight Process", "comments": "14 pages, 7 figures", "journal-ref": "Physica A 388 (2009) 1509-1514", "doi": "10.1016/j.physa.2008.12.071", "report-no": null, "categories": "nlin.CD cond-mat.stat-mech stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walk simulation of the Levy flight shows a linear relation between the\nmean square displacement <r2> and time. We have analyzed different aspects of\nthis linearity. It is shown that the restriction of jump length to a maximum\nvalue (lm) affects the diffusion coefficient, even though it remains constant\nfor lm greater than 1464. So, this factor has no effect on the linearity. In\naddition, it is shown that the number of samples does not affect the results.\nWe have demonstrated that the relation between the mean square displacement and\ntime remains linear in a continuous space, while continuous variables just\nreduce the diffusion coefficient. The results are also implied that the\nmovement of a levy flight particle is similar to the case the particle moves in\neach time step with an average length of jumping <l>. Finally, it is shown that\nthe non-linear relation of the Levy flight will be satisfied if we use time\naverage instead of ensemble average. The difference between time average and\nensemble average results points that the Levy distribution may be a non-ergodic\ndistribution.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 13:57:00 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Ghaemi", "Mehrdad", ""], ["Zabihinpour", "Zahra", ""], ["Asgari", "Yazdan", ""]]}, {"id": "1001.2185", "submitter": "Alexandre B. Simas", "authors": "Alexandre B. Simas, Andr\\'ea V. Rocha, Wagner Barreto-Souza", "title": "Improved estimators for dispersion models with dispersion covariates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss improved estimators for the regression and the\ndispersion parameters in an extended class of dispersion models (J{\\o}rgensen,\n1996). This class extends the regular dispersion models by letting the\ndispersion parameter vary throughout the observations, and contains the\ndispersion models as particular case. General formulae for the second-order\nbias are obtained explicitly in dispersion models with dispersion covariates,\nwhich generalize previous results by Botter and Cordeiro (1998), Cordeiro and\nMcCullagh (1991), Cordeiro and Vasconcellos (1999), and Paula (1992). The\npractical use of the formulae is that we can derive closed-form expressions for\nthe second-order biases of the maximum likelihood estimators of the regression\nand dispersion parameters when the information matrix has a closed-form.\nVarious expressions for the second-order biases are given for special models.\nThe formulae have advantages for numerical purposes because they require only a\nsupplementary weighted linear regression. We also compare these bias-corrected\nestimators with two different estimators which are also bias-free to the\nsecond-order that are based on bootstrap methods. These estimators are compared\nby simulation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 14:45:55 GMT"}], "update_date": "2010-01-14", "authors_parsed": [["Simas", "Alexandre B.", ""], ["Rocha", "Andr\u00e9a V.", ""], ["Barreto-Souza", "Wagner", ""]]}, {"id": "1001.2187", "submitter": "Alexandre B. Simas", "authors": "Alexandre B. Simas, Gauss M. Cordeiro, Andr\\'ea V. Rocha", "title": "Skewness of maximum likelihood estimators in dispersion models", "comments": null, "journal-ref": "Journal of Statistical Planning and Inference, 140, 2111-2121,\n  2010.", "doi": "10.1016/j.jspi.2010.02.007", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the dispersion models with a regression structure to extend the\ngeneralized linear models, the exponential family nonlinear models (Cordeiro\nand Paula, 1989) and the proper dispersion models (J{\\o}rgensen, 1997a). We\nprovide a matrix expression for the skewness of the maximum likelihood\nestimators of the regression parameters in dispersion models. The formula is\nsuitable for computer implementation and can be applied for several important\nsubmodels discussed in the literature. Expressions for the skewness of the\nmaximum likelihood estimators of the precision and dispersion parameters are\nalso derived. In particular, our results extend previous formulas obtained by\nCordeiro and Cordeiro (2001) and Cavalcanti et al. (2009). A simulation study\nis perfomed to show the practice importance of our results.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 20:00:32 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Simas", "Alexandre B.", ""], ["Cordeiro", "Gauss M.", ""], ["Rocha", "Andr\u00e9a V.", ""]]}, {"id": "1001.2286", "submitter": "Mark Tygert", "authors": "Mark Tygert", "title": "Statistical tests for whether a given set of independent, identically\n  distributed draws does not come from a specified probability density", "comments": "18 pages, 5 figures, 6 tables", "journal-ref": "Proceedings of the National Academy of Sciences (USA), 107 (38):\n  16471-16476, 2010", "doi": "10.1073/pnas.1008446107", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss several tests for whether a given set of independent and\nidentically distributed (i.i.d.) draws does not come from a specified\nprobability density function. The most commonly used are Kolmogorov-Smirnov\ntests, particularly Kuiper's variant, which focus on discrepancies between the\ncumulative distribution function for the specified probability density and the\nempirical cumulative distribution function for the given set of i.i.d. draws.\nUnfortunately, variations in the probability density function often get\nsmoothed over in the cumulative distribution function, making it difficult to\ndetect discrepancies in regions where the probability density is small in\ncomparison with its values in surrounding regions. We discuss tests without\nthis deficiency, complementing the classical methods. The tests of the present\npaper are based on the plain fact that it is unlikely to draw a random number\nwhose probability is small, provided that the draw is taken from the same\ndistribution used in calculating the probability (thus, if we draw a random\nnumber whose probability is small, then we can be confident that we did not\ndraw the number from the same distribution used in calculating the\nprobability).\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2010 20:11:55 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2010 17:06:56 GMT"}, {"version": "v3", "created": "Mon, 25 Jan 2010 03:02:36 GMT"}, {"version": "v4", "created": "Mon, 15 Feb 2010 17:53:31 GMT"}, {"version": "v5", "created": "Mon, 19 Apr 2010 18:38:49 GMT"}, {"version": "v6", "created": "Thu, 3 Jun 2010 17:11:03 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Tygert", "Mark", ""]]}, {"id": "1001.2615", "submitter": "Ryota Tomioka", "authors": "Ryota Tomioka, Taiji Suzuki", "title": "Sparsity-accuracy trade-off in MKL", "comments": "8pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We empirically investigate the best trade-off between sparse and\nuniformly-weighted multiple kernel learning (MKL) using the elastic-net\nregularization on real and simulated datasets. We find that the best trade-off\nparameter depends not only on the sparsity of the true kernel-weight spectrum\nbut also on the linear dependence among kernels and the number of samples.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2010 05:53:23 GMT"}], "update_date": "2010-01-18", "authors_parsed": [["Tomioka", "Ryota", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1001.2685", "submitter": "Sander Greenland", "authors": "Sander Greenland", "title": "Relaxation Penalties and Priors for Plausible Modeling of Nonidentified\n  Bias Sources", "comments": "Published in at http://dx.doi.org/10.1214/09-STS291 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 195-210", "doi": "10.1214/09-STS291", "report-no": "IMS-STS-STS291", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In designed experiments and surveys, known laws or design feat ures provide\nchecks on the most relevant aspects of a model and identify the target\nparameters. In contrast, in most observational studies in the health and social\nsciences, the primary study data do not identify and may not even bound target\nparameters. Discrepancies between target and analogous identified parameters\n(biases) are then of paramount concern, which forces a major shift in modeling\nstrategies. Conventional approaches are based on conditional testing of\nequality constraints, which correspond to implausible point-mass priors. When\nthese constraints are not identified by available data, however, no such\ntesting is possible. In response, implausible constraints can be relaxed into\npenalty functions derived from plausible prior distributions. The resulting\nmodels can be fit within familiar full or partial likelihood frameworks. The\nabsence of identification renders all analyses part of a sensitivity analysis.\nIn this view, results from single models are merely examples of what might be\nplausibly inferred. Nonetheless, just one plausible inference may suffice to\ndemonstrate inherent limitations of the data. Points are illustrated with\nmisclassified data from a study of sudden infant death syndrome. Extensions to\nconfounding, selection bias and more complex data structures are outlined.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2010 13:21:15 GMT"}], "update_date": "2010-01-18", "authors_parsed": [["Greenland", "Sander", ""]]}, {"id": "1001.2697", "submitter": "Brenda F. Kurland", "authors": "Brenda F. Kurland, Laura L. Johnson, Brian L. Egleston, Paula H. Diehr", "title": "Longitudinal Data with Follow-up Truncated by Death: Match the Analysis\n  Method to Research Aims", "comments": "Published in at http://dx.doi.org/10.1214/09-STS293 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 211-222", "doi": "10.1214/09-STS293", "report-no": "IMS-STS-STS293", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse analysis approaches have been proposed to distinguish data missing\ndue to death from nonresponse, and to summarize trajectories of longitudinal\ndata truncated by death. We demonstrate how these analysis approaches arise\nfrom factorizations of the distribution of longitudinal data and survival\ninformation. Models are illustrated using cognitive functioning data for older\nadults. For unconditional models, deaths do not occur, deaths are independent\nof the longitudinal response, or the unconditional longitudinal response is\naveraged over the survival distribution. Unconditional models, such as random\neffects models fit to unbalanced data, may implicitly impute data beyond the\ntime of death. Fully conditional models stratify the longitudinal response\ntrajectory by time of death. Fully conditional models are effective for\ndescribing individual trajectories, in terms of either aging (age, or years\nfrom baseline) or dying (years from death). Causal models (principal\nstratification) as currently applied are fully conditional models, since group\ndifferences at one timepoint are described for a cohort that will survive past\na later timepoint. Partly conditional models summarize the longitudinal\nresponse in the dynamic cohort of survivors. Partly conditional models are\nserial cross-sectional snapshots of the response, reflecting the average\nresponse in survivors at a given timepoint rather than individual trajectories.\nJoint models of survival and longitudinal response describe the evolving health\nstatus of the entire cohort. Researchers using longitudinal data should\nconsider which method of accommodating deaths is consistent with research aims,\nand use analysis methods accordingly.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jan 2010 14:26:54 GMT"}], "update_date": "2010-01-18", "authors_parsed": [["Kurland", "Brenda F.", ""], ["Johnson", "Laura L.", ""], ["Egleston", "Brian L.", ""], ["Diehr", "Paula H.", ""]]}, {"id": "1001.2906", "submitter": "Christian P. Robert", "authors": "Christian P. Robert and George Casella", "title": "Introducing Monte Carlo Methods with R Solutions to Odd-Numbered\n  Exercises", "comments": "87 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the solution manual to the odd-numbered exercises in our book\n\"Introducing Monte Carlo Methods with R\", published by Springer Verlag on\nDecember 10, 2009, and made freely available to everyone.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2010 17:43:52 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Robert", "Christian P.", ""], ["Casella", "George", ""]]}, {"id": "1001.2967", "submitter": "Jos\\'{e} M. Bernardo", "authors": "Jos\\'e M. Bernardo", "title": "Comment on \"Harold Jeffreys's Theory of Probability Revisited\"", "comments": "Published in at http://dx.doi.org/10.1214/09-STS284E the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 173-175", "doi": "10.1214/09-STS284E", "report-no": "IMS-STS-STS284E", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on \"Harold Jeffreys's Theory of Probability Revisited\"\n[arXiv:0804.3173]\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 07:43:15 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Bernardo", "Jos\u00e9 M.", ""]]}, {"id": "1001.2968", "submitter": "Andrew Gelman", "authors": "Andrew Gelman", "title": "Bayes, Jeffreys, Prior Distributions and the Philosophy of Statistics", "comments": "Published in at http://dx.doi.org/10.1214/09-STS284D the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 176-178", "doi": "10.1214/09-STS284D", "report-no": "IMS-STS-STS284D", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion of \"Harold Jeffreys's Theory of Probability revisited,\" by\nChristian Robert, Nicolas Chopin, and Judith Rousseau, for Statistical Science\n[arXiv:0804.3173]\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 08:02:28 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Gelman", "Andrew", ""]]}, {"id": "1001.2970", "submitter": "Robert Kass", "authors": "Robert Kass", "title": "Comment: The Importance of Jeffreys's Legacy", "comments": "Published in at http://dx.doi.org/10.1214/09-STS284A the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 179-182", "doi": "10.1214/09-STS284A", "report-no": "IMS-STS-STS284A", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theory of Probability is distinguished by several high-level philosophical\nattitudes, some stressed by Jeffreys, some implicit. By reviewing these we may\nrecognize the importance in this work in the historical development of\nstatistics. [arXiv:0804.3173]\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 14:47:18 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Kass", "Robert", ""]]}, {"id": "1001.2975", "submitter": "Stephen Senn", "authors": "Stephen Senn", "title": "Comment on \"Harold Jeffreys's Theory of Probability Revisited\"", "comments": "Published in at http://dx.doi.org/10.1214/09-STS284B the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 185-186", "doi": "10.1214/09-STS284B", "report-no": "IMS-STS-STS284B", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on \"Harold Jeffreys's Theory of Probability Revisited\"\n[arXiv:0804.3173]\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 08:40:54 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Senn", "Stephen", ""]]}, {"id": "1001.2985", "submitter": "Arnold Zellner", "authors": "Arnold Zellner", "title": "Comment on \"Harold Jeffreys's Theory of Probability Revisited\"", "comments": "Published in at http://dx.doi.org/10.1214/09-STS284C the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 187-190", "doi": "10.1214/09-STS284C", "report-no": "IMS-STS-STS284C", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on \"Harold Jeffreys's Theory of Probability Revisited\"\n[arXiv:0804.3173]\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 09:23:42 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Zellner", "Arnold", ""]]}, {"id": "1001.3011", "submitter": "James G. Booth", "authors": "James G. Booth, Walter T. Federer, Martin T. Wells, Russell D.\n  Wolfinger", "title": "A Multivariate Variance Components Model for Analysis of Covariance in\n  Designed Experiments", "comments": "Published in at http://dx.doi.org/10.1214/09-STS294 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 223-237", "doi": "10.1214/09-STS294", "report-no": "IMS-STS-STS294", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional methods for covariate adjustment of treatment means in designed\nexperiments are inherently conditional on the observed covariate values. In\norder to develop a coherent general methodology for analysis of covariance, we\npropose a multivariate variance components model for the joint distribution of\nthe response and covariates. It is shown that, if the design is orthogonal with\nrespect to (random) blocking factors, then appropriate adjustments to treatment\nmeans can be made using the univariate variance components model obtained by\nconditioning on the observed covariate values. However, it is revealed that\nsome widely used models are incorrectly specified, leading to biased estimates\nand incorrect standard errors. The approach clarifies some issues that have\nbeen the source of ongoing confusion in the statistics literature.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 10:39:39 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Booth", "James G.", ""], ["Federer", "Walter T.", ""], ["Wells", "Martin T.", ""], ["Wolfinger", "Russell D.", ""]]}, {"id": "1001.3073", "submitter": "Dennis Lindley", "authors": "Dennis Lindley", "title": "Comment on \"Harold Jeffreys's Theory of Probability Revisited\"", "comments": "Published in at http://dx.doi.org/10.1214/09-STS284F the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 183-184", "doi": "10.1214/09-STS284F", "report-no": "IMS-STS-STS284F", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comment on \"Harold Jeffreys's Theory of Probability Revisited\"\n[arXiv:0804.3173]\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2010 14:24:58 GMT"}], "update_date": "2010-01-19", "authors_parsed": [["Lindley", "Dennis", ""]]}, {"id": "1001.3253", "submitter": "Joseph B. Kadane", "authors": "Joseph B. Kadane", "title": "Bayesian Thought in Early Modern Detective Stories: Monsieur Lecoq, C.\n  Auguste Dupin and Sherlock Holmes", "comments": "Published in the Statistical Science (http://www.imstat.org/sts/) by\n  the Institute of Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 238-243", "doi": "10.1214/09-STS298", "report-no": "IMS-STS-STS298", "categories": "stat.ME math.HO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews the maxims used by three early modern fictional\ndetectives: Monsieur Lecoq, C. Auguste Dupin and Sherlock Holmes. It find\nsimilarities between these maxims and Bayesian thought. Poe's Dupin uses ideas\nvery similar to Bayesian game theory. Sherlock Holmes' statements also show\nthought patterns justifiable in Bayesian terms.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 10:30:29 GMT"}], "update_date": "2010-01-20", "authors_parsed": [["Kadane", "Joseph B.", ""]]}, {"id": "1001.3272", "submitter": "Martin T. Wells", "authors": "Martin T. Wells", "title": "A Conversation with Shayle R. Searle", "comments": "Published in at http://dx.doi.org/10.1214/08-STS259 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2009, Vol. 24, No. 2, 244-254", "doi": "10.1214/08-STS259", "report-no": "IMS-STS-STS259", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Born in New Zealand, Shayle Robert Searle earned a bachelor's degree (1949)\nand a master's degree (1950) from Victoria University, Wellington, New Zealand.\nAfter working for an actuary, Searle went to Cambridge University where he\nearned a Diploma in mathematical statistics in 1953. Searle won a Fulbright\ntravel award to Cornell University, where he earned a doctorate in animal\nbreeding, with a strong minor in statistics in 1959, studying under Professor\nCharles Henderson. In 1962, Cornell invited Searle to work in the university's\ncomputing center, and he soon joined the faculty as an assistant professor of\nbiological statistics. He was promoted to associate professor in 1965, and\nbecame a professor of biological statistics in 1970. Searle has also been a\nvisiting professor at Texas A&M University, Florida State University,\nUniversit\\\"{a}t Augsburg and the University of Auckland. He has published\nseveral statistics textbooks and has authored more than 165 papers. Searle is a\nFellow of the American Statistical Association, the Royal Statistical Society,\nand he is an elected member of the International Statistical Institute. He also\nhas received the prestigious Alexander von Humboldt U.S. Senior Scientist\nAward, is an Honorary Fellow of the Royal Society of New Zealand and was\nrecently awarded the D.Sc. Honoris Causa by his alma mater, Victoria University\nof Wellington, New Zealand.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2010 11:56:37 GMT"}], "update_date": "2010-01-20", "authors_parsed": [["Wells", "Martin T.", ""]]}, {"id": "1001.3742", "submitter": "Winston Wei Dou", "authors": "Winston Wei Dou, David Pollard, Harrison H. Zhou", "title": "Estimation in functional regression for general exponential families", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1027 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 5, 2421-2451", "doi": "10.1214/12-AOS1027", "report-no": "IMS-AOS-AOS1027", "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies a class of exponential family models whose canonical\nparameters are specified as linear functionals of an unknown\ninfinite-dimensional slope function. The optimal minimax rates of convergence\nfor slope function estimation are established. The estimators that achieve the\noptimal rates are constructed by constrained maximum likelihood estimation with\nparameters whose dimension grows with sample size. A change-of-measure\nargument, inspired by Le Cam's theory of asymptotic equivalence, is used to\neliminate the bias caused by the nonlinearity of exponential family models.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2010 08:47:31 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2013 10:04:37 GMT"}], "update_date": "2013-02-14", "authors_parsed": [["Dou", "Winston Wei", ""], ["Pollard", "David", ""], ["Zhou", "Harrison H.", ""]]}, {"id": "1001.3859", "submitter": "Yaming Yu", "authors": "Yaming Yu", "title": "Strict Monotonicity and Convergence Rate of Titterington's Algorithm for\n  Computing D-optimal Designs", "comments": null, "journal-ref": "Computational Statistics and Data Analysis 54 (2010) 1419--1425.", "doi": "10.1016/j.csda.2010.01.026", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a class of multiplicative algorithms introduced by Silvey et al.\n(1978) for computing D-optimal designs. Strict monotonicity is established for\na variant considered by Titterington (1978). A formula for the rate of\nconvergence is also derived. This is used to explain why modifications\nconsidered by Titterington (1978) and Dette et al. (2008) usually converge\nfaster.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2010 17:58:19 GMT"}], "update_date": "2010-02-26", "authors_parsed": [["Yu", "Yaming", ""]]}, {"id": "1001.3886", "submitter": "Jiashun Jin Dr", "authors": "Aurore Delaigle, Peter Hall, Jiashun Jin", "title": "Robustness and accuracy of methods for high dimensional data analysis\n  based on Student's t statistic", "comments": "37 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Student's $t$ statistic is finding applications today that were never\nenvisaged when it was introduced more than a century ago. Many of these\napplications rely on properties, for example robustness against heavy tailed\nsampling distributions, that were not explicitly considered until relatively\nrecently. In this paper we explore these features of the $t$ statistic in the\ncontext of its application to very high dimensional problems, including feature\nselection and ranking, highly multiple hypothesis testing, and sparse, high\ndimensional signal detection. Robustness properties of the $t$-ratio are\nhighlighted, and it is established that those properties are preserved under\napplications of the bootstrap. In particular, bootstrap methods correct for\nskewness, and therefore lead to second-order accuracy, even in the extreme\ntails. Indeed, it is shown that the bootstrap, and also the more popular but\nless accurate $t$-distribution and normal approximations, are more effective in\nthe tails than towards the middle of the distribution. These properties\nmotivate new methods, for example bootstrap-based techniques for signal\ndetection, that confine attention to the significant tail of a statistic.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2010 01:52:52 GMT"}], "update_date": "2010-01-25", "authors_parsed": [["Delaigle", "Aurore", ""], ["Hall", "Peter", ""], ["Jin", "Jiashun", ""]]}, {"id": "1001.3895", "submitter": "Lei Qi", "authors": "Lei Qi, Dacheng Xiu and Jianqing Fan", "title": "Non-Gaussian Quasi Maximum Likelihood Estimation of GARCH Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The non-Gaussian quasi maximum likelihood estimator is frequently used in\nGARCH models with intension to improve the efficiency of the GARCH parameters.\nHowever, unless the quasi-likelihood happens to be the true one, non-Gaussian\nQMLE methods suffers inconsistency even if shape parameters in the\nquasi-likelihood are estimated. To correct this bias, we identify an unknown\nscale parameter that is critical to the consistent estimation of non-Gaussian\nQMLE, and propose a two-step non-Gaussian QMLE (2SNG-QMLE) for estimation of\nthe scale parameter and GARCH parameters. This novel approach is consistent and\nasymptotically normal. Moreover, it has higher efficiency than the Gaussian\nQMLE, particularly when the innovation error has heavy tails. Two extensions\nare proposed to further improve the efficiency of 2SNG-QMLE. The impact of\nrelative heaviness of tails of the innovation and quasi-likelihood\ndistributions on the asymptotic efficiency has been thoroughly investigated.\nMonte Carlo simulations and an empirical study confirm the advantages of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jan 2010 22:24:44 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2010 00:56:37 GMT"}], "update_date": "2010-06-15", "authors_parsed": [["Qi", "Lei", ""], ["Xiu", "Dacheng", ""], ["Fan", "Jianqing", ""]]}, {"id": "1001.4019", "submitter": "Mu Zhu", "authors": "Xiao Tang and Mu Zhu", "title": "Classifying Network Data with Deep Kernel Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by a growing interest in analyzing network data, we study the\nproblem of node classification on graphs, focusing on approaches based on\nkernel machines. Conventionally, kernel machines are linear classifiers in the\nimplicit feature space. We argue that linear classification in the feature\nspace of kernels commonly used for graphs is often not enough to produce good\nresults. When this is the case, one naturally considers nonlinear classifiers\nin the feature space. We show that repeating this process produces something we\ncall \"deep kernel machines.\" We provide some examples where deep kernel\nmachines can make a big difference in classification performance, and point out\nsome connections to various recent literature on deep architectures in\nartificial intelligence and machine learning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2010 15:20:11 GMT"}], "update_date": "2010-01-25", "authors_parsed": [["Tang", "Xiao", ""], ["Zhu", "Mu", ""]]}, {"id": "1001.4070", "submitter": "Nicolas Delorme", "authors": "Nicolas Delorme (SENS), Julie Boich\\'e, Michel Raspaud (SENS)", "title": "Relative Age Effect in Elite Sports: Methodological Bias or Real\n  Discrimination?", "comments": null, "journal-ref": "European Journal of Sport Science 10, 2 (2010) 91-96", "doi": "10.1080/17461390903271584", "report-no": null, "categories": "stat.ME physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sport sciences researchers talk about a relative age effect when they observe\na biased distribution of elite athletes' birthdates, with an\nover-representation of those born at the beginning of the competitive year and\nan under-representation of those born at the end. Using the whole sample of the\nFrench male licensed soccer players (n = 1,831,524), our study suggests that\nthere could be an important bias in the statistical test of this effect. This\nbias could in turn lead to falsely conclude to a systemic discrimination in the\nrecruitment of professional players. Our findings question the accuracy of past\nresults concerning the existence of this effect at the elite level.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2010 20:53:18 GMT"}], "update_date": "2010-01-25", "authors_parsed": [["Delorme", "Nicolas", "", "SENS"], ["Boich\u00e9", "Julie", "", "SENS"], ["Raspaud", "Michel", "", "SENS"]]}, {"id": "1001.4083", "submitter": "Luke Bornn", "authors": "Luke Bornn, Raphael Gottardo, Arnaud Doucet", "title": "Grouping Priors and the Bayesian Elastic Net", "comments": null, "journal-ref": null, "doi": null, "report-no": "Technical Report #254, Department of Statistics, University of\n  British Columbia", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the literature surrounding Bayesian penalized regression, the two primary\nchoices of prior distribution on the regression coefficients are zero-mean\nGaussian and Laplace. While both have been compared numerically and\ntheoretically, there remains little guidance on which to use in real-life\nsituations. We propose two viable solutions to this problem in the form of\nprior distributions which combine and compromise between Laplace and Gaussian\npriors, respectively. Through cross-validation the prior which optimizes\nprediction performance is automatically selected. We then demonstrate the\nimproved performance of these new prior distributions relative to Laplace and\nGaussian priors in both a simulated and experimental environment.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2010 21:26:00 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Bornn", "Luke", ""], ["Gottardo", "Raphael", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1001.4208", "submitter": "Abel Rodriguez", "authors": "Abel Rodriguez, Alex Lenkoski and Adrian Dobra", "title": "Sparse covariance estimation in heterogeneous samples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard Gaussian graphical models (GGMs) implicitly assume that the\nconditional independence among variables is common to all observations in the\nsample. However, in practice, observations are usually collected form\nheterogeneous populations where such assumption is not satisfied, leading in\nturn to nonlinear relationships among variables. To tackle these problems we\nexplore mixtures of GGMs; in particular, we consider both infinite mixture\nmodels of GGMs and infinite hidden Markov models with GGM emission\ndistributions. Such models allow us to divide a heterogeneous population into\nhomogenous groups, with each cluster having its own conditional independence\nstructure. The main advantage of considering infinite mixtures is that they\nallow us easily to estimate the number of number of subpopulations in the\nsample. As an illustration, we study the trends in exchange rate fluctuations\nin the pre-Euro era. This example demonstrates that the models are very\nflexible while providing extremely interesting interesting insights into\nreal-life applications.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2010 21:49:00 GMT"}], "update_date": "2010-01-26", "authors_parsed": [["Rodriguez", "Abel", ""], ["Lenkoski", "Alex", ""], ["Dobra", "Adrian", ""]]}, {"id": "1001.4351", "submitter": "Olle Gunnarsson", "authors": "O. Gunnarsson, M. W. Haverkort and G. Sangiovanni", "title": "Analytical continuation of imaginary axis data using maximum entropy", "comments": "10 pages and 8 figures", "journal-ref": "Phys. Rev. B 81, 155107 (2010)", "doi": "10.1103/PhysRevB.81.155107", "report-no": null, "categories": "physics.data-an cond-mat.str-el stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the maximum entropy (MaxEnt) approach for analytical continuation of\nspectral data from imaginary times to real frequencies. The total error is\ndivided in a statistical error, due to the noise in the input data, and a\nsystematic error, due to deviations of the default function, used in the MaxEnt\napproach, from the exact spectrum. We find that the MaxEnt approach in its\nclassical formulation can lead to a nonoptimal balance between the two types of\nerrors, leading to an unnecessary large statistical error. The statistical\nerror can be reduced by splitting up the data in several batches, performing a\nMaxEnt calculation for each batch and averaging. This can outweigh an increase\nin the systematic error resulting from this approach. The output from the\nMaxEnt result can be used as a default function for a new MaxEnt calculation.\nSuch iterations often lead to worse results due to an increase in the\nstatistical error. By splitting up the data in batches, the statistical error\nis reduced and and the increase resulting from iterations can be outweighed by\na decrease in the systematic error. Finally we consider a linearized version to\nobtain a better understanding of the method.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2010 09:29:07 GMT"}], "update_date": "2010-11-16", "authors_parsed": [["Gunnarsson", "O.", ""], ["Haverkort", "M. W.", ""], ["Sangiovanni", "G.", ""]]}, {"id": "1001.4656", "submitter": "Christian P. Robert", "authors": "Christian P. Robert and Judith Rousseau", "title": "On Bayesian Data Analysis", "comments": "16 pages, 2 figures, 2 tables, chapter of the contributed volume\n  \"Bayesian Methods and Expert Elicitation\", Risk Book, London", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This introduction to Bayesian statistics presents the main concepts as well\nas the principal reasons advocated in favour of a Bayesian modelling. We cover\nthe various approaches to prior determination as well as the basis asymptotic\narguments in favour of using Bayes estimators. The testing aspects of Bayesian\ninference are also examined in details.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2010 11:25:35 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2010 21:22:45 GMT"}], "update_date": "2010-02-09", "authors_parsed": [["Robert", "Christian P.", ""], ["Rousseau", "Judith", ""]]}, {"id": "1001.5004", "submitter": "Marcel R\\'emon", "authors": "M. R\\'emon", "title": "\"Additivity\" versus \"Maxitivity\" at the heart of the paradoxical and\n  efficient nature of Statistics", "comments": "19 pages, 40 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike the Probability Theory based on additivity, Statistical Inference\nseems to hesitate between \"Additivity\" and a so-called \"Maxitivity\" approach.\nAfter a brief overview of three types of principles for any (parametric)\nstatistical theory and the proof that these principles are mutually exclusive,\nthe paper shows that two kinds of support measures are conceivable, an additive\none and a maxitive one (based on maximization operators). Unfortunately, none\nof them is able to cope with the ignorance part of the statistical experiment\nand, in the meantime, with the partial information given through the structure\nof the data. To conclude, the author promotes the combined use of both\napproaches, as an efficient middle-of-the-road position for the statistician.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2010 19:33:12 GMT"}], "update_date": "2010-01-28", "authors_parsed": [["R\u00e9mon", "M.", ""]]}, {"id": "1001.5447", "submitter": "Thomas Hotz", "authors": "Thomas Hotz, Philipp Marnitz, Rahel Stichtenoth, Laurie Davies, Zakhar\n  Kabluchko and Axel Munk", "title": "Locally adaptive image denoising by a statistical multiresolution\n  criterion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate how one can choose the smoothing parameter in image denoising\nby a statistical multiresolution criterion, both globally and locally. Using\ninhomogeneous diffusion and total variation regularization as examples for\nlocalized regularization schemes, we present an efficient method for locally\nadaptive image denoising. As expected, the smoothing parameter serves as an\nedge detector in this framework. Numerical examples illustrate the usefulness\nof our approach. We also present an application in confocal microscopy.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2010 18:06:33 GMT"}], "update_date": "2010-02-01", "authors_parsed": [["Hotz", "Thomas", ""], ["Marnitz", "Philipp", ""], ["Stichtenoth", "Rahel", ""], ["Davies", "Laurie", ""], ["Kabluchko", "Zakhar", ""], ["Munk", "Axel", ""]]}]