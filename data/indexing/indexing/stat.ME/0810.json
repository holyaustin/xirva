[{"id": "0810.0430", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Estimating the Parameters of Binomial and Poisson Distributions via\n  Multistage Sampling", "comments": "12 pages, no figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have developed a new class of sampling schemes for\nestimating parameters of binomial and Poisson distributions. Without any\ninformation of the unknown parameters, our sampling schemes rigorously\nguarantee prescribed levels of precision and confidence.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2008 14:37:32 GMT"}, {"version": "v2", "created": "Thu, 16 Oct 2008 16:27:12 GMT"}, {"version": "v3", "created": "Tue, 3 Feb 2009 20:07:31 GMT"}, {"version": "v4", "created": "Sun, 5 Apr 2009 21:20:35 GMT"}, {"version": "v5", "created": "Tue, 7 Apr 2009 16:35:34 GMT"}, {"version": "v6", "created": "Sat, 10 Oct 2009 21:21:07 GMT"}], "update_date": "2009-10-11", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0810.0744", "submitter": "Phaedon-Stelios Koutsourelakis", "authors": "P.S. Koutsourelakis", "title": "A multi-resolution, non-parametric, Bayesian framework for\n  identification of spatially-varying model parameters", "comments": null, "journal-ref": null, "doi": "10.1016/j.jcp.2009.05.016", "report-no": null, "categories": "math-ph math.MP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a hierarchical, multi-resolution framework for the\nidentification of model parameters and their spatially variability from noisy\nmeasurements of the response or output. Such parameters are frequently\nencountered in PDE-based models and correspond to quantities such as density or\npressure fields, elasto-plastic moduli and internal variables in solid\nmechanics, conductivity fields in heat diffusion problems, permeability fields\nin fluid flow through porous media etc. The proposed model has all the\nadvantages of traditional Bayesian formulations such as the ability to produce\nmeasures of confidence for the inferences made and providing not only\npredictive estimates but also quantitative measures of the predictive\nuncertainty. In contrast to existing approaches it utilizes a parsimonious,\nnon-parametric formulation that favors sparse representations and whose\ncomplexity can be determined from the data. The proposed framework in\nnon-intrusive and makes use of a sequence of forward solvers operating at\nvarious resolutions. As a result, inexpensive, coarse solvers are used to\nidentify the most salient features of the unknown field(s) which are\nsubsequently enriched by invoking solvers operating at finer resolutions. This\nleads to significant computational savings particularly in problems involving\ncomputationally demanding forward models but also improvements in accuracy. It\nis based on a novel, adaptive scheme based on Sequential Monte Carlo sampling\nwhich is embarrassingly parallelizable and circumvents issues with slow mixing\nencountered in Markov Chain Monte Carlo schemes.\n", "versions": [{"version": "v1", "created": "Sat, 4 Oct 2008 03:24:21 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Koutsourelakis", "P. S.", ""]]}, {"id": "0810.0758", "submitter": "Elvan Ceyhan", "authors": "Elvan Ceyhan", "title": "Class-Specific Tests of Spatial Segregation Based on Nearest Neighbor\n  Contingency Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": "KU-EC-08-7", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatial interaction between two or more classes (or species) has\nimportant consequences in many fields and might cause multivariate clustering\npatterns such as segregation or association. The spatial pattern of segregation\noccurs when members of a class tend to be found near members of the same class\n(i.e., conspecifics), while association occurs when members of a class tend to\nbe found near members of the other class or classes. These patterns can be\ntested using a nearest neighbor contingency table (NNCT). The null hypothesis\nis randomness in the nearest neighbor (NN) structure, which may result from --\namong other patterns -- random labeling (RL) or complete spatial randomness\n(CSR) of points from two or more classes (which is called the CSR independence,\nhenceforth). In this article, we consider Dixon's class-specific tests of\nsegregation and introduce a new class-specific test, which is a new\ndecomposition of Dixon's overall chi-square segregation statistic. We\ndemonstrate that the tests we consider provide information on different aspects\nof the spatial interaction between the classes and they are conditional under\nthe CSR independence pattern, but not under the RL pattern. We analyze the\ndistributional properties and prove the consistency of these tests; compare the\nempirical significant levels (Type I error rates) and empirical power estimates\nof the tests using Monte Carlo simulations. We demonstrate that the new\nclass-specific tests also have comparable performance with the currently\navailable tests based on NNCTs in terms of Type I error and power estimates.\nFor illustrative purposes, we use three example data sets. We also provide\nguidelines for using these tests.\n", "versions": [{"version": "v1", "created": "Sat, 4 Oct 2008 11:58:21 GMT"}, {"version": "v2", "created": "Thu, 9 Oct 2008 14:34:33 GMT"}], "update_date": "2008-10-09", "authors_parsed": [["Ceyhan", "Elvan", ""]]}, {"id": "0810.1150", "submitter": "Christian Robert Y", "authors": "Christian Y. Robert", "title": "Inference for the limiting cluster size distribution of extreme values", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS551 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 1, 271-310", "doi": "10.1214/07-AOS551", "report-no": "IMS-AOS-AOS551", "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any limiting point process for the time normalized exceedances of high levels\nby a stationary sequence is necessarily compound Poisson under appropriate long\nrange dependence conditions. Typically exceedances appear in clusters. The\nunderlying Poisson points represent the cluster positions and the\nmultiplicities correspond to the cluster sizes. In the present paper we\nintroduce estimators of the limiting cluster size probabilities, which are\nconstructed through a recursive algorithm. We derive estimators of the extremal\nindex which plays a key role in determining the intensity of cluster positions.\nWe study the asymptotic properties of the estimators and investigate their\nfinite sample behavior on simulated data.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2008 10:26:08 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2009 08:38:04 GMT"}], "update_date": "2009-03-03", "authors_parsed": [["Robert", "Christian Y.", ""]]}, {"id": "0810.2010", "submitter": "Heng Lian", "authors": "Heng Lian", "title": "A note on conditional Akaike information for Poisson regression with\n  random effects", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular model selection approach for generalized linear mixed-effects\nmodels is the Akaike information criterion, or AIC. Among others,\n\\cite{vaida05} pointed out the distinction between the marginal and conditional\ninference depending on the focus of research. The conditional AIC was derived\nfor the linear mixed-effects model which was later generalized by\n\\cite{liang08}. We show that the similar strategy extends to Poisson regression\nwith random effects, where condition AIC can be obtained based on our\nobservations. Simulation studies demonstrate the usage of the criterion.\n", "versions": [{"version": "v1", "created": "Sat, 11 Oct 2008 08:15:14 GMT"}], "update_date": "2008-10-14", "authors_parsed": [["Lian", "Heng", ""]]}, {"id": "0810.2124", "submitter": "Elena Kulinskaya", "authors": "Elena Kulinskaya (Imperial College London)", "title": "On two-sided p-values for non-symmetric distributions", "comments": "20 pages, 4 Postscript figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-sided statistical tests and p-values are well defined only when the test\nstatistic in question has a symmetric distribution. A new two-sided p-value\ncalled conditional p-value $P_C$ is introduced here. It is closely related to\nthe doubled p-value and has an intuitive appeal. Its use is advocated for both\ncontinuous and discrete distributions. An important advantage of this p-value\nis that equivalent 1-sided tests are transformed into $P_C$-equivalent 2-sided\ntests. It is compared to the widely used doubled and minimum likelihood\np-values. Examples include the variance test, the binomial and the Fisher's\nexact test.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2008 19:49:58 GMT"}], "update_date": "2008-10-14", "authors_parsed": [["Kulinskaya", "Elena", "", "Imperial College London"]]}, {"id": "0810.3177", "submitter": "Catherine Matias", "authors": "Christophe Ambroise and Julien Chiquet and Catherine Matias", "title": "Inferring sparse Gaussian graphical models with latent structure", "comments": "35 pages, 15 figures", "journal-ref": "Electron. J. Statist. Volume 3 (2009), 205-238.", "doi": "10.1214/08-EJS314", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our concern is selecting the concentration matrix's nonzero coefficients for\na sparse Gaussian graphical model in a high-dimensional setting. This\ncorresponds to estimating the graph of conditional dependencies between the\nvariables. We describe a novel framework taking into account a latent structure\non the concentration matrix. This latent structure is used to drive a penalty\nmatrix and thus to recover a graphical model with a constrained topology. Our\nmethod uses an $\\ell_1$ penalized likelihood criterion. Inference of the graph\nof conditional dependencies between the variates and of the hidden variables is\nperformed simultaneously in an iterative \\textsc{em}-like algorithm. The\nperformances of our method is illustrated on synthetic as well as real data,\nthe latter concerning breast cancer.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2008 16:07:54 GMT"}], "update_date": "2010-04-05", "authors_parsed": [["Ambroise", "Christophe", ""], ["Chiquet", "Julien", ""], ["Matias", "Catherine", ""]]}, {"id": "0810.3946", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Multistage Hypothesis Tests for the Mean of a Normal Distribution", "comments": "34 pages, 28 figures, added adaptive scanning algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have developed new multistage tests which guarantee\nprescribed level of power and are more efficient than previous tests in terms\nof average sampling number and the number of sampling operations. Without\ntruncation, the maximum sampling numbers of our testing plans are absolutely\nbounded. Based on geometrical arguments, we have derived extremely tight bounds\nfor the operating characteristic function. To reduce the computational\ncomplexity for the relevant integrals, we propose adaptive scanning algorithms\nwhich are not only useful for present hypothesis testing problem but also for\nother problem areas.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2008 00:06:27 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2009 00:39:00 GMT"}, {"version": "v3", "created": "Sun, 12 Jun 2011 14:41:09 GMT"}], "update_date": "2011-06-14", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0810.4214", "submitter": "Marloes Maathuis", "authors": "Marloes H. Maathuis, Markus Kalisch, Peter B\\\"uhlmann", "title": "Estimating high-dimensional intervention effects from observational data", "comments": "Published in at http://dx.doi.org/10.1214/09-AOS685 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 6A, 3133-3164", "doi": "10.1214/09-AOS685", "report-no": "IMS-AOS-AOS685", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We assume that we have observational data generated from an unknown\nunderlying directed acyclic graph (DAG) model. A DAG is typically not\nidentifiable from observational data, but it is possible to consistently\nestimate the equivalence class of a DAG. Moreover, for any given DAG, causal\neffects can be estimated using intervention calculus. In this paper, we combine\nthese two parts. For each DAG in the estimated equivalence class, we use\nintervention calculus to estimate the causal effects of the covariates on the\nresponse. This yields a collection of estimated causal effects for each\ncovariate. We show that the distinct values in this set can be consistently\nestimated by an algorithm that uses only local information of the graph. This\nlocal approach is computationally fast and feasible in high-dimensional\nproblems. We propose to use summary measures of the set of possible causal\neffects to determine variable importance. In particular, we use the minimum\nabsolute value of this set, since that is a lower bound on the size of the\ncausal effect. We demonstrate the merits of our methods in a simulation study\nand on a data set about riboflavin production.\n", "versions": [{"version": "v1", "created": "Thu, 23 Oct 2008 06:51:27 GMT"}, {"version": "v2", "created": "Tue, 20 Jan 2009 19:22:46 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2009 12:10:09 GMT"}], "update_date": "2009-09-02", "authors_parsed": [["Maathuis", "Marloes H.", ""], ["Kalisch", "Markus", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "0810.4807", "submitter": "Caroline Chaux", "authors": "Jean-Christophe Pesquet, Amel Benazza-Benyahia and Caroline Chaux", "title": "A SURE Approach for Digital Signal/Image Deconvolution Problems", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2009.2026077", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we are interested in the classical problem of restoring data\ndegraded by a convolution and the addition of a white Gaussian noise. The\noriginality of the proposed approach is two-fold. Firstly, we formulate the\nrestoration problem as a nonlinear estimation problem leading to the\nminimization of a criterion derived from Stein's unbiased quadratic risk\nestimate. Secondly, the deconvolution procedure is performed using any analysis\nand synthesis frames that can be overcomplete or not. New theoretical results\nconcerning the calculation of the variance of the Stein's risk estimate are\nalso provided in this work. Simulations carried out on natural images show the\ngood performance of our method w.r.t. conventional wavelet-based restoration\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2008 13:25:24 GMT"}, {"version": "v2", "created": "Tue, 28 Oct 2008 14:33:42 GMT"}, {"version": "v3", "created": "Wed, 29 Oct 2008 10:05:17 GMT"}, {"version": "v4", "created": "Mon, 15 Dec 2008 17:56:52 GMT"}, {"version": "v5", "created": "Mon, 30 Mar 2009 13:19:13 GMT"}, {"version": "v6", "created": "Tue, 7 Jul 2009 17:59:45 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Pesquet", "Jean-Christophe", ""], ["Benazza-Benyahia", "Amel", ""], ["Chaux", "Caroline", ""]]}, {"id": "0810.5474", "submitter": "Robert Kohn", "authors": "David J. Nott and Robert J. Kohn and Mark Fielding", "title": "Approximating the marginal likelihood using copula", "comments": "29 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model selection is an important activity in modern data analysis and the\nconventional Bayesian approach to this problem involves calculation of marginal\nlikelihoods for different models, together with diagnostics which examine\nspecific aspects of model fit. Calculating the marginal likelihood is a\ndifficult computational problem. Our article proposes some extensions of the\nLaplace approximation for this task that are related to copula models and which\nare easy to apply. Variations which can be used both with and without\nsimulation from the posterior distribution are considered, as well as use of\nthe approximations with bridge sampling and in random effects models with a\nlarge number of latent variables. The use of a t-copula to obtain higher\naccuracy when multivariate dependence is not well captured by a Gaussian copula\nis also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2008 12:05:12 GMT"}], "update_date": "2008-10-31", "authors_parsed": [["Nott", "David J.", ""], ["Kohn", "Robert J.", ""], ["Fielding", "Mark", ""]]}, {"id": "0810.5551", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "A Theory of Truncated Inverse Sampling", "comments": "31 pages, no figure, revised proofs", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have established a new framework of truncated inverse\nsampling for estimating mean values of non-negative random variables such as\nbinomial, Poisson, hyper-geometrical, and bounded variables. We have derived\nexplicit formulas and computational methods for designing sampling schemes to\nensure prescribed levels of precision and confidence for point estimators.\nMoreover, we have developed interval estimation methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2008 19:52:55 GMT"}, {"version": "v2", "created": "Tue, 11 Nov 2008 02:38:09 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0810.5655", "submitter": "Wenxin Jiang", "authors": "Wenxin Jiang, Martin A. Tanner", "title": "Gibbs posterior for variable selection in high-dimensional\n  classification and data mining", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS547 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2008, Vol. 36, No. 5, 2207-2231", "doi": "10.1214/07-AOS547", "report-no": "IMS-AOS-AOS547", "categories": "stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the popular approach of \"Bayesian variable selection\" (BVS), one uses\nprior and posterior distributions to select a subset of candidate variables to\nenter the model. A completely new direction will be considered here to study\nBVS with a Gibbs posterior originating in statistical mechanics. The Gibbs\nposterior is constructed from a risk function of practical interest (such as\nthe classification error) and aims at minimizing a risk function without\nmodeling the data probabilistically. This can improve the performance over the\nusual Bayesian approach, which depends on a probability model which may be\nmisspecified. Conditions will be provided to achieve good risk performance,\neven in the presence of high dimensionality, when the number of candidate\nvariables \"$K$\" can be much larger than the sample size \"$n$.\" In addition, we\ndevelop a convenient Markov chain Monte Carlo algorithm to implement BVS with\nthe Gibbs posterior.\n", "versions": [{"version": "v1", "created": "Fri, 31 Oct 2008 10:38:41 GMT"}], "update_date": "2008-11-03", "authors_parsed": [["Jiang", "Wenxin", ""], ["Tanner", "Martin A.", ""]]}]