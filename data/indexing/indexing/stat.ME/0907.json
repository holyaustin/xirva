[{"id": "0907.0139", "submitter": "David R. Bickel", "authors": "David R. Bickel", "title": "Coherent frequentism", "comments": "The confidence-measure theory of inference and decision is explicitly\n  extended to vector parameters of interest. The derivation of upper and lower\n  confidence levels from valid and nonconservative set estimators is formalized", "journal-ref": "Bickel, D. R. (2012). Coherent Frequentism: A Decision Theory\n  Based on Confidence Sets. Communications in Statistics - Theory and Methods,\n  41(8), 1478-1496", "doi": "10.1080/03610926.2010.543302", "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By representing the range of fair betting odds according to a pair of\nconfidence set estimators, dual probability measures on parameter space called\nfrequentist posteriors secure the coherence of subjective inference without any\nprior distribution. The closure of the set of expected losses corresponding to\nthe dual frequentist posteriors constrains decisions without arbitrarily\nforcing optimization under all circumstances. This decision theory reduces to\nthose that maximize expected utility when the pair of frequentist posteriors is\ninduced by an exact or approximate confidence set estimator or when an\nautomatic reduction rule is applied to the pair. In such cases, the resulting\nfrequentist posterior is coherent in the sense that, as a probability\ndistribution of the parameter of interest, it satisfies the axioms of the\ndecision-theoretic and logic-theoretic systems typically cited in support of\nthe Bayesian posterior. Unlike the p-value, the confidence level of an interval\nhypothesis derived from such a measure is suitable as an estimator of the\nindicator of hypothesis truth since it converges in sample-space probability to\n1 if the hypothesis is true or to 0 otherwise under general conditions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2009 12:59:47 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2009 12:16:58 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2009 19:44:52 GMT"}], "update_date": "2012-05-02", "authors_parsed": [["Bickel", "David R.", ""]]}, {"id": "0907.0421", "submitter": "Nikolai Chernov", "authors": "A. Al-Sharadqah and N. Chernov", "title": "Error analysis for circle fitting algorithms", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of fitting circles (or circular arcs) to data points\nobserved with errors in both variables. A detailed error analysis for all\npopular circle fitting methods -- geometric fit, Kasa fit, Pratt fit, and\nTaubin fit -- is presented. Our error analysis goes deeper than the traditional\nexpansion to the leading order. We obtain higher order terms, which show\nexactly why and by how much circle fits differ from each other. Our analysis\nallows us to construct a new algebraic (non-iterative) circle fitting algorithm\nthat outperforms all the existing methods, including the (previously regarded\nas unbeatable) geometric fit.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2009 16:17:07 GMT"}], "update_date": "2009-07-03", "authors_parsed": [["Al-Sharadqah", "A.", ""], ["Chernov", "N.", ""]]}, {"id": "0907.0512", "submitter": "Satoshi Aoki", "authors": "Satoshi Aoki", "title": "Some optimal criteria of model-robustness for two-level non-regular\n  fractional factorial designs", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some optimal criteria to evaluate model-robustness of non-regular\ntwo-level fractional factorial designs. Our method is based on minimizing the\nsum of squares of all the off-diagonal elements in the information matrix, and\nconsidering expectation under appropriate distribution functions for unknown\ncontamination of the interaction effects. By considering uniform distributions\non symmetric support, our criteria can be expressed as linear combinations of\n$B_s(d)$ characteristic, which is used to characterize the generalized minimum\naberration. We give some empirical studies for 12-run non-regular designs to\nevaluate our method.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2009 01:19:32 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2009 01:01:08 GMT"}], "update_date": "2009-11-24", "authors_parsed": [["Aoki", "Satoshi", ""]]}, {"id": "0907.1823", "submitter": "Andrey Pepelyshev", "authors": "Andrey Pepelyshev", "title": "Improvement of random LHD for high dimensions", "comments": "6 pages, Proceedings of the 6th St. Petersburg Workshop on\n  Simulation, 1091-1096", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designs of experiments for multivariate case are reviewed. Fast algorithm of\nconstruction of good Latin hypercube designs is developed.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2009 13:46:00 GMT"}], "update_date": "2009-07-13", "authors_parsed": [["Pepelyshev", "Andrey", ""]]}, {"id": "0907.2079", "submitter": "Yong Zhang", "authors": "Zhaosong Lu and Yong Zhang", "title": "An Augmented Lagrangian Approach for Sparse Principal Component Analysis", "comments": "42 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.LG math.ST stat.AP stat.CO stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Principal component analysis (PCA) is a widely used technique for data\nanalysis and dimension reduction with numerous applications in science and\nengineering. However, the standard PCA suffers from the fact that the principal\ncomponents (PCs) are usually linear combinations of all the original variables,\nand it is thus often difficult to interpret the PCs. To alleviate this\ndrawback, various sparse PCA approaches were proposed in literature [15, 6, 17,\n28, 8, 25, 18, 7, 16]. Despite success in achieving sparsity, some important\nproperties enjoyed by the standard PCA are lost in these methods such as\nuncorrelation of PCs and orthogonality of loading vectors. Also, the total\nexplained variance that they attempt to maximize can be too optimistic. In this\npaper we propose a new formulation for sparse PCA, aiming at finding sparse and\nnearly uncorrelated PCs with orthogonal loading vectors while explaining as\nmuch of the total variance as possible. We also develop a novel augmented\nLagrangian method for solving a class of nonsmooth constrained optimization\nproblems, which is well suited for our formulation of sparse PCA. We show that\nit converges to a feasible point, and moreover under some regularity\nassumptions, it converges to a stationary point. Additionally, we propose two\nnonmonotone gradient methods for solving the augmented Lagrangian subproblems,\nand establish their global and local convergence. Finally, we compare our\nsparse PCA approach with several existing methods on synthetic, random, and\nreal data, respectively. The computational results demonstrate that the sparse\nPCs produced by our approach substantially outperform those by other methods in\nterms of total explained variance, correlation of PCs, and orthogonality of\nloading vectors.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2009 00:45:51 GMT"}], "update_date": "2009-07-14", "authors_parsed": [["Lu", "Zhaosong", ""], ["Zhang", "Yong", ""]]}, {"id": "0907.2135", "submitter": "Robert B. Gramacy", "authors": "Robert B. Gramacy and Ester Pantaleo", "title": "Shrinkage regression for multivariate inference with missing data, and\n  an application to portfolio balancing", "comments": "25 pages, 4 figures, 2 tables, to appear in BA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Portfolio balancing requires estimates of covariance between asset returns.\nReturns data have histories which greatly vary in length, since assets begin\npublic trading at different times. This can lead to a huge amount of missing\ndata--too much for the conventional imputation-based approach. Fortunately, a\nwell-known factorization of the MVN likelihood under the prevailing historical\nmissingness pattern leads to a simple algorithm of OLS regressions that is much\nmore reliable. When there are more assets than returns, however, OLS becomes\nunstable. Gramacy, et al. (2008), showed how classical shrinkage regression may\nbe used instead, thus extending the state of the art to much bigger asset\ncollections, with further accuracy and interpretation advantages. In this\npaper, we detail a fully Bayesian hierarchical formulation that extends the\nframework further by allowing for heavy-tailed errors, relaxing the historical\nmissingness assumption, and accounting for estimation risk. We illustrate how\nthis approach compares favorably to the classical one using synthetic data and\nan investment exercise with real returns. An accompanying R package is on CRAN.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2009 11:04:34 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2010 19:05:41 GMT"}, {"version": "v3", "created": "Sat, 27 Feb 2010 10:32:03 GMT"}], "update_date": "2010-02-27", "authors_parsed": [["Gramacy", "Robert B.", ""], ["Pantaleo", "Ester", ""]]}, {"id": "0907.2478", "submitter": "Andrew Gelman", "authors": "Andrew Gelman, Jennifer Hill, Masanao Yajima", "title": "Why we (usually) don't have to worry about multiple comparisons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applied researchers often find themselves making statistical inferences in\nsettings that would seem to require multiple comparisons adjustments. We\nchallenge the Type I error paradigm that underlies these corrections. Moreover\nwe posit that the problem of multiple comparisons can disappear entirely when\nviewed from a hierarchical Bayesian perspective. We propose building multilevel\nmodels in the settings where multiple comparisons arise.\n  Multilevel models perform partial pooling (shifting estimates toward each\nother), whereas classical procedures typically keep the centers of intervals\nstationary, adjusting for multiple comparisons by making the intervals wider\n(or, equivalently, adjusting the $p$-values corresponding to intervals of fixed\nwidth). Thus, multilevel models address the multiple comparisons problem and\nalso yield more efficient estimates, especially in settings with low\ngroup-level variation, which is where multiple comparisons are a particular\nconcern.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2009 01:34:16 GMT"}], "update_date": "2009-07-16", "authors_parsed": [["Gelman", "Andrew", ""], ["Hill", "Jennifer", ""], ["Yajima", "Masanao", ""]]}, {"id": "0907.2480", "submitter": "Andrew Gelman", "authors": "Andrew Gelman", "title": "Thoughts on new statistical procedures for age-period-cohort analyses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Age-period-cohort analysis is mathematically intractable because of\nfundamental nonidentifiability of linear trends. However, some understanding\ncan be gained in the context of individual problems.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2009 01:41:24 GMT"}], "update_date": "2009-07-16", "authors_parsed": [["Gelman", "Andrew", ""]]}, {"id": "0907.2770", "submitter": "Lizhen Xu", "authors": "Lizhen Xu, Radu V. Craiu, Lei Sun", "title": "Bayesian methods to overcome the winner's curse in genetic studies", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS373 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 1, 201-231", "doi": "10.1214/10-AOAS373", "report-no": "IMS-AOAS-AOAS373", "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter estimates for associated genetic variants, report ed in the initial\ndiscovery samples, are often grossly inflated compared to the values observed\nin the follow-up replication samples. This type of bias is a consequence of the\nsequential procedure in which the estimated effect of an associated genetic\nmarker must first pass a stringent significance threshold. We propose a\nhierarchical Bayes method in which a spike-and-slab prior is used to account\nfor the possibility that the significant test result may be due to chance. We\nexamine the robustness of the method using different priors corresponding to\ndifferent degrees of confidence in the testing results and propose a Bayesian\nmodel averaging procedure to combine estimates produced by different models.\nThe Bayesian estimators yield smaller variance compared to the conditional\nlikelihood estimator and outperform the latter in studies with low power. We\ninvestigate the performance of the method with simulations and applications to\nfour real data examples.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2009 08:01:08 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2011 11:55:44 GMT"}], "update_date": "2011-04-15", "authors_parsed": [["Xu", "Lizhen", ""], ["Craiu", "Radu V.", ""], ["Sun", "Lei", ""]]}, {"id": "0907.2829", "submitter": "Sorana Bolboaca", "authors": "Lorentz Jantschi", "title": "Distribution Fitting 1. Parameters Estimation under Assumption of\n  Agreement between Observation and Model", "comments": "8 pages, 6 figures, 2 tables, 6 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The methods for parameter estimation under assumption of agreement between\nobservation and model are reviewed. The distribution parameters are obtained\nfor one set of experimental data by using different estimation methods under\nassumption of Gauss-Laplace theoretical distribution. The results are presented\nand discussed.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2009 13:10:06 GMT"}], "update_date": "2009-07-17", "authors_parsed": [["Jantschi", "Lorentz", ""]]}, {"id": "0907.2832", "submitter": "Sorana Bolboaca", "authors": "Lorentz Jantschi and Sorana D. Bolboaca", "title": "Distribution Fitting 2. Pearson-Fisher, Kolmogorov-Smirnov,\n  Anderson-Darling, Wilks-Shapiro, Cramer-von-Misses and Jarque-Bera statistics", "comments": "8 pages, 1 figure, 4 tables, 14 equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The methods measuring the departure between observation and the model were\nreviewed. The following statistics were applied on two experimental data sets:\nChi-Squared, Kolmogorov-Smirnov, Anderson-Darling, Wilks-Shapiro, and\nJarque-Bera. Both investigated sets proved not to be normal distributed. The\nGrubbs test identified one outlier and after its removal the normality of the\nset of 205 chemical active compounds was accepted. The second data set proved\nnot to have any outliers. Kolmogorov-Smirnov statistic is less affected by the\nexistence of outliers (positive variation expressed as percentage smaller than\n2). The outliers bring to Kolmogorov-Smirnov statistic errors of type II and to\nthe Anderson-Darling statistic errors of type I.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2009 13:16:31 GMT"}], "update_date": "2009-07-17", "authors_parsed": [["Jantschi", "Lorentz", ""], ["Bolboaca", "Sorana D.", ""]]}, {"id": "0907.3166", "submitter": "Kathy Dopp", "authors": "Kathy Dopp", "title": "Checking election outcome accuracy Post-election audit sampling", "comments": "37 pages + 19 pages of appendices & references, 3 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article\n  * provides an overview of post-election audit sampling research and compares\nvarious approaches to calculating post-election audit sample sizes, focusing on\nrisklimiting audits,\n  * discusses fundamental concepts common to all risk-limiting post-election\naudits, presenting new margin error bounds, sampling weights and sampling\nprobabilities that improve upon existing approaches and work for any size audit\nunit and for single or multi-winner election contests,\n  * provides two new simple formulas for estimating post-election audit sample\nsizes in cases when detailed data, expertise, or tools are not available,\n  * summarizes four improved methods for calculating risk-limiting election\naudit sample sizes, showing how to apply precise margin error bounds to improve\nthe accuracy and efficacy of existing methods, and\n  * discusses sampling mistakes that reduce post-election audit effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2009 21:55:49 GMT"}], "update_date": "2009-09-30", "authors_parsed": [["Dopp", "Kathy", ""]]}, {"id": "0907.3355", "submitter": "Laurie Faisandier", "authors": "Laurie Faisandier (TIMC), Vincent Bonneterre (TIMC), R\\'egis De\n  Gaudemaris (TIMC), Dominique J Bicout (EPSP)", "title": "A network-based approach for surveillance of occupational health\n  exposures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of surveillance of health problems, the research carried out\nby the French national occupational disease surveillance and prevention network\n(R\\'eseau National de Vigilance et de Pr\\'evention des Pathologies\nProfessionnelles, RNV3P) aims to develop, among other approaches, methods of\nsurveillance, statistical analysis and modeling in order to study the structure\nand change over time of relationships between disease and exposure, and to\ndetect emerging disease-exposure associations. In this perspective, this paper\naims to present the concept of the \"exposome\" and to explain on what bases it\nis constructed. The exposome is defined as a network of relationships between\noccupational health problems that have in common one or several elements of\noccupational exposure (exposures, occupation and/or activity sector). The paper\nalso aims to outline its potential for the study and programmed surveillance of\ncomposite disease-occupational exposure associations. We illustrate this\napproach by applying it to a sample from the RNV3P data, taking malignant\ntumours and focusing on the subgroup of non-Hodgkin lymphomas.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2009 08:35:54 GMT"}], "update_date": "2009-07-21", "authors_parsed": [["Faisandier", "Laurie", "", "TIMC"], ["Bonneterre", "Vincent", "", "TIMC"], ["De Gaudemaris", "R\u00e9gis", "", "TIMC"], ["Bicout", "Dominique J", "", "EPSP"]]}, {"id": "0907.3410", "submitter": "Laurie Faisandier", "authors": "Laurie Faisandier (TIMC), R\\'egis De Gaudemaris (TIMC), Dominique J\n  Bicout (EPSP)", "title": "Occupational Health Problem Network : the Exposome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a thinking on the concept of relational networks applied to the\nfrench national occupational disease surveillance and prevention network\n(R\\'eseau National de Vigilance et de Pr\\'evention des Pathologies\nProfessionnelles, RNV3P). This approach consists in searching common exposures\nto occupational health problems.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2009 14:24:38 GMT"}], "update_date": "2009-07-21", "authors_parsed": [["Faisandier", "Laurie", "", "TIMC"], ["De Gaudemaris", "R\u00e9gis", "", "TIMC"], ["Bicout", "Dominique J", "", "EPSP"]]}, {"id": "0907.3426", "submitter": "Theodore Alexandrov", "authors": "Theodore Alexandrov, Klaus Steinhorst, Oliver Keszoecze, Stefan\n  Schiffler", "title": "SparseCodePicking: feature extraction in mass spectrometry using sparse\n  coding algorithms", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML physics.med-ph stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass spectrometry (MS) is an important technique for chemical profiling which\ncalculates for a sample a high dimensional histogram-like spectrum. A crucial\nstep of MS data processing is the peak picking which selects peaks containing\ninformation about molecules with high concentrations which are of interest in\nan MS investigation. We present a new procedure of the peak picking based on a\nsparse coding algorithm. Given a set of spectra of different classes, i.e. with\ndifferent positions and heights of the peaks, this procedure can extract peaks\nby means of unsupervised learning. Instead of an $l_1$-regularization penalty\nterm used in the original sparse coding algorithm we propose using an\nelastic-net penalty term for better regularization. The evaluation is done by\nmeans of simulation. We show that for a large region of parameters the proposed\npeak picking method based on the sparse coding features outperforms a mean\nspectrum-based method. Moreover, we demonstrate the procedure applying it to\ntwo real-life datasets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jul 2009 15:50:22 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2009 08:58:10 GMT"}], "update_date": "2009-10-05", "authors_parsed": [["Alexandrov", "Theodore", ""], ["Steinhorst", "Klaus", ""], ["Keszoecze", "Oliver", ""], ["Schiffler", "Stefan", ""]]}, {"id": "0907.3837", "submitter": "Michael A. Newton", "authors": "Michael A. Newton, Lisa M. Chung", "title": "Gamma-based clustering via ordered means with application to\n  gene-expression analysis", "comments": "Published in at http://dx.doi.org/10.1214/10-AOS805 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2010, Vol. 38, No. 6, 3217-3244", "doi": "10.1214/10-AOS805", "report-no": "IMS-AOS-AOS805", "categories": "stat.ME math.ST stat.CO stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discrete mixture models provide a well-known basis for effective clustering\nalgorithms, although technical challenges have limited their scope. In the\ncontext of gene-expression data analysis, a model is presented that mixes over\na finite catalog of structures, each one representing equality and inequality\nconstraints among latent expected values. Computations depend on the\nprobability that independent gamma-distributed variables attain each of their\npossible orderings. Each ordering event is equivalent to an event in\nindependent negative-binomial random variables, and this finding guides a\ndynamic-programming calculation. The structuring of mixture-model components\naccording to constraints among latent means leads to strict concavity of the\nmixture log likelihood. In addition to its beneficial numerical properties, the\nclustering method shows promising results in an empirical study.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2009 19:01:48 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2009 17:05:14 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2010 20:05:00 GMT"}, {"version": "v4", "created": "Fri, 9 Nov 2012 11:12:41 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Newton", "Michael A.", ""], ["Chung", "Lisa M.", ""]]}, {"id": "0907.3944", "submitter": "Nozer Singpurwalla", "authors": "Nozer D. Singpurwalla", "title": "The Utility of Reliability and Survival", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliability (survival analysis, to biostatisticians) is a key ingredient for\nmak- ing decisions that mitigate the risk of failure. The other key ingredient\nis utility. A decision theoretic framework harnesses the two, but to invoke\nthis framework we must distinguish between chance and probability. We describe\na functional form for the utility of chance that incorporates all dispositions\nto risk, and pro- pose a probability of choice model for eliciting this\nutility. To implement the model a subject is asked to make a series of binary\nchoices between gambles and certainty. These choices endow a statistical\ncharacter to the problem of utility elicitation. The workings of our approach\nare illustrated via a live example in- volving a military planner. The material\nis general because it is germane to any situation involving the valuation of\nchance.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2009 21:50:20 GMT"}], "update_date": "2009-07-24", "authors_parsed": [["Singpurwalla", "Nozer D.", ""]]}, {"id": "0907.4010", "submitter": "Christian P. Robert", "authors": "Christian P. Robert", "title": "Simulation of truncated normal variables", "comments": "This 1992 paper appeared in 1995 in Statistics and Computing and the\n  gist of it is contained in Monte Carlo Statistical Methods (2004), but I\n  receive weekly requests for reprints so here it is!", "journal-ref": "Statistics and Computing, 1995, 5, 121-125", "doi": "10.1007/BF00143942", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide in this paper simulation algorithms for one-sided and two-sided\ntruncated normal distributions. These algorithms are then used to simulate\nmultivariate normal variables with restricted parameter space for any\ncovariance structure.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2009 09:07:22 GMT"}], "update_date": "2009-07-24", "authors_parsed": [["Robert", "Christian P.", ""]]}, {"id": "0907.4077", "submitter": "Shanti Venetiaan", "authors": "S.A. Venetiaan", "title": "A fifth order expansion for the distribution function of the maximum\n  likelihood estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, expansions for the maximum likelihood estimator of location\nand its distribution funtion are extended to fifth order. Since the proofs are\nstraightforward extentions of proofs given in earlier papers for orders less\nthan the fifth, they are not given here. The purpose of the paper is mainly to\npresent the higher order expansions.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2009 14:47:56 GMT"}], "update_date": "2009-07-24", "authors_parsed": [["Venetiaan", "S. A.", ""]]}, {"id": "0907.4698", "submitter": "Yilun Chen", "authors": "Yilun Chen, Ami Wiesel, Yonina C. Eldar, Alfred O. Hero III", "title": "Shrinkage Algorithms for MMSE Covariance Estimation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2010.2053029", "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address covariance estimation in the sense of minimum mean-squared error\n(MMSE) for Gaussian samples. Specifically, we consider shrinkage methods which\nare suitable for high dimensional problems with a small number of samples\n(large p small n). First, we improve on the Ledoit-Wolf (LW) method by\nconditioning on a sufficient statistic. By the Rao-Blackwell theorem, this\nyields a new estimator called RBLW, whose mean-squared error dominates that of\nLW for Gaussian variables. Second, to further reduce the estimation error, we\npropose an iterative approach which approximates the clairvoyant shrinkage\nestimator. Convergence of this iterative method is established and a closed\nform expression for the limit is determined, which is referred to as the oracle\napproximating shrinkage (OAS) estimator. Both RBLW and OAS estimators have\nsimple expressions and are easily implemented. Although the two methods are\ndeveloped from different persepctives, their structure is identical up to\nspecified constants. The RBLW estimator provably dominates the LW method.\nNumerical simulations demonstrate that the OAS approach can perform even better\nthan RBLW, especially when n is much less than p. We also demonstrate the\nperformance of these techniques in the context of adaptive beamforming.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2009 16:42:53 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Chen", "Yilun", ""], ["Wiesel", "Ami", ""], ["Eldar", "Yonina C.", ""], ["Hero", "Alfred O.", "III"]]}, {"id": "0907.4716", "submitter": "Krzysztof Latuszynski", "authors": "Krzysztof Latuszynski", "title": "Regeneration and Fixed-Width Analysis of Markov Chain Monte Carlo\n  Algorithms", "comments": "PhD thesis, University of Warsaw, supervisor - Wojciech Niemiro", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the thesis we take the split chain approach to analyzing Markov chains and\nuse it to establish fixed-width results for estimators obtained via Markov\nchain Monte Carlo procedures (MCMC). Theoretical results include necessary and\nsufficient conditions in terms of regeneration for central limit theorems for\nergodic Markov chains and a regenerative proof of a CLT version for uniformly\nergodic Markov chains with $E_{\\pi}f^2< \\infty.$ To obtain asymptotic\nconfidence intervals for MCMC estimators, strongly consistent estimators of the\nasymptotic variance are essential. We relax assumptions required to obtain such\nestimators. Moreover, under a drift condition, nonasymptotic fixed-width\nresults for MCMC estimators for a general state space setting (not necessarily\ncompact) and not necessarily bounded target function $f$ are obtained. The last\nchapter is devoted to the idea of adaptive Monte Carlo simulation and provides\nconvergence results and law of large numbers for adaptive procedures under\npath-stability condition for transition kernels.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2009 17:46:24 GMT"}], "update_date": "2009-07-28", "authors_parsed": [["Latuszynski", "Krzysztof", ""]]}, {"id": "0907.4728", "submitter": "Alain Celisse", "authors": "Sylvain Arlot (LIENS), Alain Celisse (MIA)", "title": "A survey of cross-validation procedures for model selection", "comments": null, "journal-ref": "Statistics Surveys 4 (2010) 40--79", "doi": "10.1214/09-SS054", "report-no": null, "categories": "math.ST stat.AP stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Used to estimate the risk of an estimator or to perform model selection,\ncross-validation is a widespread strategy because of its simplicity and its\napparent universality. Many results exist on the model selection performances\nof cross-validation procedures. This survey intends to relate these results to\nthe most recent advances of model selection theory, with a particular emphasis\non distinguishing empirical statements from rigorous theoretical results. As a\nconclusion, guidelines are provided for choosing the best cross-validation\nprocedure according to the particular features of the problem in hand.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2009 18:37:23 GMT"}], "update_date": "2011-02-01", "authors_parsed": [["Arlot", "Sylvain", "", "LIENS"], ["Celisse", "Alain", "", "MIA"]]}, {"id": "0907.4865", "submitter": "Denis Belomestny", "authors": "Denis Belomestny", "title": "Spectral estimation of the L\\'evy density in partially observed affine\n  models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The problem of estimating the L\\'evy density of a partially observed\nmultidimensional affine process from low-frequency and mixed-frequency data is\nconsidered. The estimation methodology is based on the log-affine\nrepresentation of the conditional characteristic function of an affine process\nand local linear smoothing in time. We derive almost sure uniform rates of\nconvergence for the estimated L\\'evy density both in mixed-frequency and\nlow-frequency setups and prove that these rates are optimal in the minimax\nsense. Finally, the performance of the estimation algorithms is illustrated in\nthe case of the Bates stochastic volatility model.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2009 08:57:08 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2010 08:48:26 GMT"}, {"version": "v3", "created": "Tue, 15 Feb 2011 14:07:18 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Belomestny", "Denis", ""]]}, {"id": "0907.4915", "submitter": "Krzysztof Latuszynski", "authors": "Krzysztof Latuszynski, Blazej Miasojedow, Wojciech Niemiro", "title": "Nonasymptotic bounds on the estimation error for regenerative MCMC\n  algorithms", "comments": "29 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": "CRiSM research paper 09-23", "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MCMC methods are used in Bayesian statistics not only to sample from\nposterior distributions but also to estimate expectations. Underlying functions\nare most often defined on a continuous state space and can be unbounded. We\nconsider a regenerative setting and Monte Carlo estimators based on i.i.d.\nblocks of a Markov chain trajectory. The main result is an inequality for the\nmean square error. We also consider confidence bounds. We first derive the\nresults in terms of the asymptotic variance and then bound the asymptotic\nvariance for both uniformly ergodic and geometrically ergodic Markov chains.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2009 13:37:55 GMT"}], "update_date": "2009-07-29", "authors_parsed": [["Latuszynski", "Krzysztof", ""], ["Miasojedow", "Blazej", ""], ["Niemiro", "Wojciech", ""]]}]