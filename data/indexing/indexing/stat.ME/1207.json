[{"id": "1207.0105", "submitter": "Ryan Martin", "authors": "Ryan Martin, Duncan Ermini Leaf, Chuanhai Liu", "title": "Optimal inferential models for a Poisson mean", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical inference on the mean of a Poisson distribution is a\nfundamentally important problem with modern applications in, e.g., particle\nphysics. The discreteness of the Poisson distribution makes this problem\nsurprisingly challenging, even in the large-sample case. Here we propose a new\napproach, based on the recently developed framework of inferential models\n(IMs). Specifically, we construct optimal, or at least approximately optimal,\nIMs for two important classes of assertions/hypotheses about the Poisson mean.\nFor point assertions, we develop a novel recursive sorting algorithm to\nconstruct this optimal IM. Numerical comparisons of the proposed method to\nexisting methods are given, for both the mean and the more challenging\nmean-plus-background problem.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2012 15:06:23 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Martin", "Ryan", ""], ["Leaf", "Duncan Ermini", ""], ["Liu", "Chuanhai", ""]]}, {"id": "1207.0187", "submitter": "Ruth Heller", "authors": "Marina Bogomolov and Ruth Heller", "title": "Discovering findings that replicate from a primary study of high\n  dimension to a follow-up study", "comments": null, "journal-ref": "Journal of the American Statistical Association Volume 108, Issue\n  504, 2013", "doi": "10.1080/01621459.2013.829002", "report-no": "arXiv:1207.0187v3", "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of identifying whether findings replicate from one\nstudy of high dimension to another, when the primary study guides the selection\nof hypotheses to be examined in the follow-up study as well as when there is no\ndivision of roles into the primary and the follow-up study. We show that\nexisting meta-analysis methods are not appropriate for this problem, and\nsuggest novel methods instead. We prove that our multiple testing procedures\ncontrol for appropriate error-rates. The suggested FWER controlling procedure\nis valid for arbitrary dependence among the test statistics within each study.\nA more powerful procedure is suggested for FDR control. We prove that this\nprocedure controls the FDR if the test statistics are independent within the\nprimary study, and independent or have dependence of type PRDS in the follow-up\nstudy. For arbitrary dependence within the primary study, and either arbitrary\ndependence or dependence of type PRDS in the follow-up study, simple\nconservative modifications of the procedure control the FDR. We demonstrate the\nusefulness of these procedures via simulations and real data examples.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2012 07:02:29 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2012 14:49:35 GMT"}, {"version": "v3", "created": "Fri, 24 May 2013 05:49:51 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Bogomolov", "Marina", ""], ["Heller", "Ruth", ""]]}, {"id": "1207.0258", "submitter": "Hidemaro Suwa", "authors": "Hidemaro Suwa and Synge Todo", "title": "General Construction of Irreversible Kernel in Markov Chain Monte Carlo", "comments": "16 pages, 8 figures; submitted to the proceedings of The Tenth\n  International Conference on Monte Carlo and Quasi-Monte Carlo Methods in\n  Scientific Computing (MCQMC 2012), which will be published by\n  Springer-Verlag, in a book entitled Monte Carlo and Quasi-Monte Carlo Methods\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech math-ph math.MP math.NA physics.data-an stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Markov chain Monte Carlo update method to construct an irreversible\nkernel has been reviewed and extended to general state spaces. The several\nconvergence conditions of the Markov chain were discussed. The alternative\nmethods to the Gibbs sampler and the Metropolis-Hastings algorithm were\nproposed and assessed in some models. The distribution convergence and the\nsampling efficiency are significantly improved in the Potts model, the\nbivariate Gaussian model, and so on. This approach using the irreversible\nkernel can be applied to any Markov chain Monte Carlo sampling and it is\nexpected to improve the efficiency in general.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 00:21:15 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Suwa", "Hidemaro", ""], ["Todo", "Synge", ""]]}, {"id": "1207.0327", "submitter": "Adam D. Bull", "authors": "Adam D. Bull", "title": "Spatially-adaptive sensing in nonparametric regression", "comments": null, "journal-ref": "Annals of Statistics 41(1):41-62, 2013", "doi": "10.1214/12-AOS1064", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While adaptive sensing has provided improved rates of convergence in sparse\nregression and classification, results in nonparametric regression have so far\nbeen restricted to quite specific classes of functions. In this paper, we\ndescribe an adaptive-sensing algorithm which is applicable to general\nnonparametric-regression problems. The algorithm is spatially adaptive, and\nachieves improved rates of convergence over spatially inhomogeneous functions.\nOver standard function classes, it likewise retains the spatial adaptivity\nproperties of a uniform design.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 10:18:49 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2012 17:19:58 GMT"}, {"version": "v3", "created": "Tue, 12 Mar 2013 07:49:49 GMT"}, {"version": "v4", "created": "Wed, 13 Mar 2013 10:31:22 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Bull", "Adam D.", ""]]}, {"id": "1207.0538", "submitter": "Darren Homrighausen", "authors": "Darren Homrighausen and Christopher R. Genovese", "title": "Efficient Estimators for Sequential and Resolution-Limited Inverse\n  Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem in the sciences is that a signal of interest is observed\nonly indirectly, through smooth functionals of the signal whose values are then\nobscured by noise. In such inverse problems, the functionals dampen or entirely\neliminate some of the signal's interesting features. This makes it difficult or\neven impossible to fully reconstruct the signal, even without noise. In this\npaper, we develop methods for handling sequences of related inverse problems,\nwith the problems varying either systematically or randomly over time. Such\nsequences often arise with automated data collection systems, like the data\npipelines of large astronomical instruments such as the Large Synoptic Survey\nTelescope (LSST). The LSST will observe each patch of the sky many times over\nits lifetime under varying conditions. A possible additional complication in\nthese problems is that the observational resolution is limited by the\ninstrument, so that even with many repeated observations, only an approximation\nof the underlying signal can be reconstructed. We propose an efficient\nestimator for reconstructing a signal of interest given a sequence of related,\nresolution-limited inverse problems. We demonstrate our method's effectiveness\nin some representative examples and provide theoretical support for its\nadoption.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2012 22:37:39 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Homrighausen", "Darren", ""], ["Genovese", "Christopher R.", ""]]}, {"id": "1207.0558", "submitter": "Sam Clifford", "authors": "Sam Clifford, Bjarke M{\\o}lgaard, Sama Low Choy, Jukka Corander,\n  Kaarle H\\\"ameri, Kerrie Mengersen and Tareq Hussein", "title": "Bayesian semi-parametric forecasting of ultrafine particle number\n  concentration with penalised splines and autoregressive errors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP physics.ao-ph physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observational time series data often exhibit both cyclic temporal trends and\nautocorrelation and may also depend on covariates. As such, there is a need for\nflexible regression models that are able to capture these trends and model any\nresidual autocorrelation simultaneously. Modelling the autocorrelation in the\nresiduals leads to more realistic forecasts than an assumption of independence.\nIn this paper we propose a method which combines spline-based semi-parametric\nregression modelling with the modelling of auto-regressive errors.\n  The method is applied to a simulated data set in order to show its efficacy\nand to ultrafine particle number concentration in Helsinki, Finland, to show\nits use in real world problems.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 01:24:26 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2012 00:12:37 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2012 01:12:22 GMT"}, {"version": "v4", "created": "Tue, 25 Sep 2012 06:46:13 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Clifford", "Sam", ""], ["M\u00f8lgaard", "Bjarke", ""], ["Choy", "Sama Low", ""], ["Corander", "Jukka", ""], ["H\u00e4meri", "Kaarle", ""], ["Mengersen", "Kerrie", ""], ["Hussein", "Tareq", ""]]}, {"id": "1207.0730", "submitter": "Yakov Nikitin", "authors": "Ya.Yu. Nikitin, K.Yu. Volkova", "title": "Asymptotic Efficiency of Goodness-of-fit Tests for the Power Function\n  Distribution Based on Puri--Rubin Characterization", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct integral and supremum type goodness-of-fit tests for the family\nof power distribution functions. Test statistics are functionals of\n$U-$empirical processes and are based on the classical characterization of\npower function distribution family belonging to Puri and Rubin. We describe the\nlogarithmic large deviation asymptotics of test statistics under\nnull-hypothesis, and calculate their local Bahadur efficiency under common\nparametric alternatives. Conditions of local optimality of new statistics are\ngiven.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 16:04:04 GMT"}], "update_date": "2014-08-21", "authors_parsed": [["Nikitin", "Ya. Yu.", ""], ["Volkova", "K. Yu.", ""]]}, {"id": "1207.0752", "submitter": "Zhijian Wang Dr.", "authors": "Bin Xu, Zhijian Wang", "title": "Test MaxEnt in Social Strategy Transitions with Experimental Two-Person\n  Constant Sum 2$\\times$2 Games", "comments": "Keyward: game theory, experimental economics, MaxEnt, mixed strategy\n  Nash Equilibrium, social dynamics, evolution, social state transition,\n  evolutionary game theory, cycles; Result in Physics 2012", "journal-ref": null, "doi": "10.1016/j.rinp.2012.09.002", "report-no": null, "categories": "stat.ME nlin.CD physics.soc-ph stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By using laboratory experimental data, we test the uncertainty of social\nstrategy transitions in various competing environments of fixed paired\ntwo-person constant sum $2 \\times 2$ games. It firstly shows that, the\ndistributions of social strategy transitions are not erratic but obey the\nprinciple of the maximum entropy (MaxEnt). This finding indicates that human\nsubject social systems and natural systems could have wider common backgrounds.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 17:11:07 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2012 16:02:08 GMT"}], "update_date": "2012-09-10", "authors_parsed": [["Xu", "Bin", ""], ["Wang", "Zhijian", ""]]}, {"id": "1207.0797", "submitter": "Antonella Capitanio", "authors": "Antonella Capitanio", "title": "On the canonical form of scale mixtures of skew-normal distributions", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The canonical form of scale mixtures of multivariate skew-normal distribution\nis defined, emphasizing its role in summarizing some key properties of this\nclass of distributions. It is also shown that the canonical form corresponds to\nan affine invariant co-ordinate system as defined in Tyler \\emph{et} al.\n(2009), and a method for obtaining the linear transform that converts a scale\nmixture of multivariate skew-normal distribution into a canonical form is\npresented. Related results, where the particular case of the multivariate skew\n$t$ distribution is considered in greater detail, are the general expression of\nthe Mardia indices of multivariate skewness and kurtosis and the reduction of\ndimensionality in calculating the mode.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 19:42:44 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Capitanio", "Antonella", ""]]}, {"id": "1207.0939", "submitter": "Antonio Punzo", "authors": "Antonio Punzo", "title": "Flexible Mixture Modeling with the Polynomial Gaussian Cluster-Weighted\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the mixture modeling frame, this paper presents the polynomial Gaussian\ncluster-weighted model (CWM). It extends the linear Gaussian CWM, for bivariate\ndata, in a twofold way. Firstly, it allows for possible nonlinear dependencies\nin the mixture components by considering a polynomial regression. Secondly, it\nis not restricted to be used for model-based clustering only being\ncontextualized in the most general model-based classification framework.\nMaximum likelihood parameter estimates are derived using the EM algorithm and\nmodel selection is carried out using the Bayesian information criterion (BIC)\nand the integrated completed likelihood (ICL). The paper also investigates the\nconditions under which the posterior probabilities of component-membership from\na polynomial Gaussian CWM coincide with those of other well-established\nmixture-models which are related to it. With respect to these models, the\npolynomial Gaussian CWM has shown to give excellent clustering and\nclassification results when applied to the artificial and real data considered\nin the paper.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 10:46:14 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Punzo", "Antonio", ""]]}, {"id": "1207.1221", "submitter": "Mathias Drton", "authors": "Michael Finegold, Mathias Drton", "title": "Robust Bayesian inference of networks using Dirichlet t-distributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian graphical modeling provides an appealing way to obtain uncertainty\nestimates when inferring network structures, and much recent progress has been\nmade for Gaussian models. These models have been used extensively in\napplications to gene expression data, even in cases where there appears to be\nsignificant deviations from the Gaussian model. For more robust inferences, it\nis natural to consider extensions to t-distribution models. We argue that the\nclassical multivariate t-distribution, defined using a single latent Gamma\nrandom variable to rescale a Gaussian random vector, is of little use in highly\nmultivariate settings, and propose other, more flexible t-distributions. Using\nan independent Gamma-divisor for each component of the random vector defines\nwhat we term the alternative t-distribution. The associated model allows one to\nextract information from highly multivariate data even when most experiments\ncontain outliers for some of their measurements. However, the use of this\nalternative model comes at increased computational cost and imposes constraints\non the achievable correlation structures, raising the need for a compromise\nbetween the classical and alternative models. To this end we propose the use of\nDirichlet processes for adaptive clustering of the latent Gamma-scalars, each\nof which may then divide a group of latent Gaussian variables. Dirichlet\nprocesses are commonly used to cluster independent observations; here they are\nused instead to cluster the dependent components of a single observation. The\nresulting Dirichlet t-distribution interpolates naturally between the two\nextreme cases of the classical and alternative t-distributions and combines\nmore appealing modeling of the multivariate dependence structure with favorable\ncomputational properties.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2012 11:07:27 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Finegold", "Michael", ""], ["Drton", "Mathias", ""]]}, {"id": "1207.1365", "submitter": "Ayesha R. Ali", "authors": "Ayesha R. Ali, Thomas S. Richardson, Peter L. Spirtes, Jiji Zhang", "title": "Towards Characterizing Markov Equivalence Classes for Directed Acyclic\n  Graphs with Latent Variables", "comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2005-PG-10-17", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that there may be many causal explanations that are\nconsistent with a given set of data. Recent work has been done to represent the\ncommon aspects of these explanations into one representation. In this paper, we\naddress what is less well known: how do the relationships common to every\ncausal explanation among the observed variables of some DAG process change in\nthe presence of latent variables? Ancestral graphs provide a class of graphs\nthat can encode conditional independence relations that arise in DAG models\nwith latent and selection variables. In this paper we present a set of\norientation rules that construct the Markov equivalence class representative\nfor ancestral graphs, given a member of the equivalence class. These rules are\nsound and complete. We also show that when the equivalence class includes a\nDAG, the equivalence class representative is the essential graph for the said\nDAG\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 16:03:21 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Ali", "Ayesha R.", ""], ["Richardson", "Thomas S.", ""], ["Spirtes", "Peter L.", ""], ["Zhang", "Jiji", ""]]}, {"id": "1207.1376", "submitter": "Zhihong Cai", "authors": "Zhihong Cai, Manabu Kuroki", "title": "Counterfactual Reasoning in Linear Structural Equation Models", "comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2005-PG-77-84", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the case where causal relations among variables can be described as\na Gaussian linear structural equation model. This paper deals with the problem\nof clarifying how the variance of a response variable would have changed if a\ntreatment variable were assigned to some value (counterfactually), given that a\nset of variables is observed (actually). In order to achieve this aim, we\nreformulate the formulas of the counterfactual distribution proposed by Balke\nand Pearl (1995) through both the total effects and a covariance matrix of\nobserved variables. We further extend the framework of Balke and Pearl (1995)\nfrom point observations to interval observations, and from an unconditional\nplan to a conditional plan. The results of this paper enable us to clarify the\nproperties of counterfactual distribution and establish an optimal plan.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 16:08:28 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Cai", "Zhihong", ""], ["Kuroki", "Manabu", ""]]}, {"id": "1207.1389", "submitter": "Frederick Eberhardt", "authors": "Frederick Eberhardt, Clark Glymour, Richard Scheines", "title": "On the Number of Experiments Sufficient and in the Worst Case Necessary\n  to Identify All Causal Relations Among N Variables", "comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2005-PG-178-184", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that if any number of variables are allowed to be simultaneously and\nindependently randomized in any one experiment, log2(N) + 1 experiments are\nsufficient and in the worst case necessary to determine the causal relations\namong N >= 2 variables when no latent variables, no sample selection bias and\nno feedback cycles are present. For all K, 0 < K < 1/(2N) we provide an upper\nbound on the number experiments required to determine causal structure when\neach experiment simultaneously randomizes K variables. For large N, these\nbounds are significantly lower than the N - 1 bound required when each\nexperiment randomizes at most one variable. For kmax < N/2, we show that\n(N/kmax-1)+N/(2kmax)log2(kmax) experiments aresufficient and in the worst case\nnecessary. We over a conjecture as to the minimal number of experiments that\nare in the worst case sufficient to identify all causal relations among N\nobserved variables that are a subset of the vertices of a DAG.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 16:14:28 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Eberhardt", "Frederick", ""], ["Glymour", "Clark", ""], ["Scheines", "Richard", ""]]}, {"id": "1207.1392", "submitter": "Manabu Kuroki", "authors": "Manabu Kuroki, Zhihong Cai, Hiroki Motogaito", "title": "The Graphical Identification for Total Effects by using Surrogate\n  Variables", "comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2005-PG-340-345", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the case where cause-effect relationships between variables can be\ndescribed as a directed acyclic graph and the corresponding linear structural\nequation model. This paper provides graphical identifiability criteria for\ntotal effects by using surrogate variables in the case where it is difficult to\nobserve a treatment/response variable. The results enable us to judge from\ngraph structure whether a total effect can be identified through the\nobservation of surrogate variables.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 16:15:46 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Kuroki", "Manabu", ""], ["Cai", "Zhihong", ""], ["Motogaito", "Hiroki", ""]]}, {"id": "1207.1419", "submitter": "Jiji Zhang", "authors": "Jiji Zhang, Peter L. Spirtes", "title": "A Transformational Characterization of Markov Equivalence for Directed\n  Acyclic Graphs with Latent Variables", "comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2005-PG-667-674", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different directed acyclic graphs (DAGs) may be Markov equivalent in the\nsense that they entail the same conditional independence relations among the\nobserved variables. Chickering (1995) provided a transformational\ncharacterization of Markov equivalence for DAGs (with no latent variables),\nwhich is useful in deriving properties shared by Markov equivalent DAGs, and,\nwith certain generalization, is needed to prove the asymptotic correctness of a\nsearch procedure over Markov equivalence classes, known as the GES algorithm.\nFor DAG models with latent variables, maximal ancestral graphs (MAGs) provide a\nneat representation that facilitates model search. However, no transformational\ncharacterization -- analogous to Chickering's -- of Markov equivalent MAGs is\nyet available. This paper establishes such a characterization for directed\nMAGs, which we expect will have similar uses as it does for DAGs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 16:27:40 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Zhang", "Jiji", ""], ["Spirtes", "Peter L.", ""]]}, {"id": "1207.1428", "submitter": "Jin Tian", "authors": "Jin Tian", "title": "Generating Markov Equivalent Maximal Ancestral Graphs by Single Edge\n  Replacement", "comments": "Appears in Proceedings of the Twenty-First Conference on Uncertainty\n  in Artificial Intelligence (UAI2005)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2005-PG-591-598", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximal ancestral graphs (MAGs) are used to encode conditional independence\nrelations in DAG models with hidden variables. Different MAGs may represent the\nsame set of conditional independences and are called Markov equivalent. This\npaper considers MAGs without undirected edges and shows conditions under which\nan arrow in a MAG can be reversed or interchanged with a bi-directed edge so as\nto yield a Markov equivalent MAG.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 16:30:04 GMT"}], "update_date": "2012-07-09", "authors_parsed": [["Tian", "Jin", ""]]}, {"id": "1207.1727", "submitter": "Paul McNicholas", "authors": "Brian C. Franczak, Ryan P. Browne, Paul D. McNicholas", "title": "Mixtures of Shifted Asymmetric Laplace Distributions", "comments": null, "journal-ref": null, "doi": "10.1109/TPAMI.2013.216", "report-no": null, "categories": "stat.ME stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mixture of shifted asymmetric Laplace distributions is introduced and used\nfor clustering and classification. A variant of the EM algorithm is developed\nfor parameter estimation by exploiting the relationship with the general\ninverse Gaussian distribution. This approach is mathematically elegant and\nrelatively computationally straightforward. Our novel mixture modelling\napproach is demonstrated on both simulated and real data to illustrate\nclustering and classification applications. In these analyses, our mixture of\nshifted asymmetric Laplace distributions performs favourably when compared to\nthe popular Gaussian approach. This work, which marks an important step in the\nnon-Gaussian model-based clustering and classification direction, concludes\nwith discussion as well as suggestions for future work.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 20:06:48 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2012 18:40:24 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2012 21:03:10 GMT"}], "update_date": "2017-10-09", "authors_parsed": [["Franczak", "Brian C.", ""], ["Browne", "Ryan P.", ""], ["McNicholas", "Paul D.", ""]]}, {"id": "1207.1865", "submitter": "Susanne Ditlevsen", "authors": "Susanne Ditlevsen, Adeline Samson", "title": "Estimation in the partially observed stochastic Morris-Lecar neuronal\n  model with particle filter and stochastic approximation methods", "comments": "Published in at http://dx.doi.org/10.1214/14-AOAS729 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2014, Vol. 8, No. 2, 674-702", "doi": "10.1214/14-AOAS729", "report-no": "IMS-AOAS-AOAS729", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parameter estimation in multidimensional diffusion models with only one\ncoordinate observed is highly relevant in many biological applications, but a\nstatistically difficult problem. In neuroscience, the membrane potential\nevolution in single neurons can be measured at high frequency, but biophysical\nrealistic models have to include the unobserved dynamics of ion channels. One\nsuch model is the stochastic Morris-Lecar model, defined by a nonlinear\ntwo-dimensional stochastic differential equation. The coordinates are coupled,\nthat is, the unobserved coordinate is nonautonomous, the model exhibits\noscillations to mimic the spiking behavior, which means it is not of\ngradient-type, and the measurement noise from intracellular recordings is\ntypically negligible. Therefore, the hidden Markov model framework is\ndegenerate, and available methods break down. The main contributions of this\npaper are an approach to estimate in this ill-posed situation and nonasymptotic\nconvergence results for the method. Specifically, we propose a sequential Monte\nCarlo particle filter algorithm to impute the unobserved coordinate, and then\nestimate parameters maximizing a pseudo-likelihood through a stochastic version\nof the Expectation-Maximization algorithm. It turns out that even the rate\nscaling parameter governing the opening and closing of ion channels of the\nunobserved coordinate can be reasonably estimated. An experimental data set of\nintracellular recordings of the membrane potential of a spinal motoneuron of a\nred-eared turtle is analyzed, and the performance is further evaluated in a\nsimulation study.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 12:18:07 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2014 21:01:26 GMT"}, {"version": "v3", "created": "Thu, 31 Jul 2014 12:03:26 GMT"}], "update_date": "2014-08-01", "authors_parsed": [["Ditlevsen", "Susanne", ""], ["Samson", "Adeline", ""]]}, {"id": "1207.1888", "submitter": "David  Biagioni", "authors": "David J. Biagioni and Ryan Elmore and Wesley Jones", "title": "Keeping greed good: sparse regression under design uncertainty with\n  application to biomass characterization", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the classic measurement error regression scenario\nin which our independent, or design, variables are observed with several\nsources of additive noise. We will show that our motivating example's\nreplicated measurements on both the design and dependent variables may be\nleveraged to enhance a sparse regression algorithm. Specifically, we estimate\nthe variance and use it to scale our design variables. We demonstrate the\nefficacy of scaling from several points of view and validate it empirically\nwith a biomass characterization data set using two of the most widely used\nsparse algorithms: least angle regression (LARS) and the Dantzig selector (DS).\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 17:15:59 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Biagioni", "David J.", ""], ["Elmore", "Ryan", ""], ["Jones", "Wesley", ""]]}, {"id": "1207.1977", "submitter": "Doris Entner", "authors": "Doris Entner, Patrik O. Hoyer", "title": "Estimating a Causal Order among Groups of Variables in Linear Models", "comments": "To appear at the International Conference on Artificial Neural\n  Networks 2012 (proceedings to be published in LNCS, Springer); To be\n  presented at the UAI Workshop on Causal Structure Learning 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The machine learning community has recently devoted much attention to the\nproblem of inferring causal relationships from statistical data. Most of this\nwork has focused on uncovering connections among scalar random variables. We\ngeneralize existing methods to apply to collections of multi-dimensional random\nvectors, focusing on techniques applicable to linear models. The performance of\nthe resulting algorithms is evaluated and compared in simulations, which show\nthat our methods can, in many cases, provide useful information on causal\nrelationships even for relatively small sample sizes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2012 08:05:44 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Entner", "Doris", ""], ["Hoyer", "Patrik O.", ""]]}, {"id": "1207.2296", "submitter": "Thomas Opitz", "authors": "Thomas Opitz", "title": "Extremal t processes: Elliptical domain of attraction and a spectral\n  representation", "comments": null, "journal-ref": null, "doi": "10.1016/j.jmva.2013.08.008", "report-no": null, "categories": "stat.ME stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extremal t process was proposed in the literature for modeling spatial\nextremes within a copula framework based on the extreme value limit of\nelliptical t distributions (Davison, Padoan and Ribatet (2012)). A major\ndrawback of this max-stable model was the lack of a spectral representation\nsuch that for instance direct simulation was infeasible. The main contribution\nof this note is to propose such a spectral construction for the extremal t\nprocess. Interestingly, the extremal Gaussian process introduced by Schlather\n(2002) appears as a special case. We further highlight the role of the extremal\nt process as the maximum attractor for processes with finite-dimensional\nelliptical distributions. All results naturally also hold within the\nmultivariate domain.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 10:25:00 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2012 15:09:51 GMT"}, {"version": "v3", "created": "Thu, 9 Aug 2012 12:08:03 GMT"}, {"version": "v4", "created": "Wed, 29 Aug 2012 15:56:17 GMT"}, {"version": "v5", "created": "Tue, 18 Sep 2012 08:52:11 GMT"}, {"version": "v6", "created": "Mon, 25 Mar 2013 10:47:41 GMT"}], "update_date": "2013-08-23", "authors_parsed": [["Opitz", "Thomas", ""]]}, {"id": "1207.2338", "submitter": "Steven Geinitz", "authors": "Steven Geinitz, Reinhard Furrer, and Stephan R. Sain", "title": "MMANOVA: A general multilevel framework for multivariate analysis of\n  variance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical analysis of variance requires that model terms be labeled as fixed\nor random and typically culminate by comparing variability from each batch\n(factor) to variability from errors; without a standard methodology to assess\nthe magnitude of a batch's variability, to compare variability between batches,\nnor to consider the uncertainty in this assessment. In this paper we support\nrecent work, placing ANOVA into a general multilevel framework, then refine\nthis through batch level model specifications, and develop it further by\nextension to the multivariate case. Adopting a Bayesian multilevel model\nparametrization, with improper batch level prior densities, we derive a method\nthat facilitates comparison across all sources of variability. Whereas\nclassical multivariate ANOVA often utilizes a single covariance criterion, e.g.\ndeterminant for Wilks' lambda distribution, the method allows arbitrary\ncovariance criteria to be employed. The proposed method also addresses\ncomputation. By introducing implicit batch level constraints, which yield\nimproper priors, the full posterior is efficiently factored, thus alleviating\ncomputational demands. For a large class of models, the partitioning mitigates,\nor even obviates the need for methods such as MCMC. The method is illustrated\nwith simulated examples and an application focusing on climate projections with\nglobal climate models.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 13:20:35 GMT"}, {"version": "v2", "created": "Sun, 15 Jul 2012 09:37:36 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Geinitz", "Steven", ""], ["Furrer", "Reinhard", ""], ["Sain", "Stephan R.", ""]]}, {"id": "1207.2622", "submitter": "Fabio Rapallo", "authors": "Sonja Kuhnt, Fabio Rapallo and Andr\\'e Rehage", "title": "Outlier Detection in Contingency Tables based on Minimal Patterns", "comments": "24 pages; a simulation study has been added", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new technique for the detection of outliers in contingency tables is\nintroduced. Outliers thereby are unexpected cell counts with respect to\nclassical loglinear Poisson models. Subsets of cell counts called minimal\npatterns are defined, corresponding to non-singular design matrices and leading\nto potentially uncontaminated maximum-likelihood estimates of the model\nparameters and thereby the expected cell counts. A criterion to easily produce\nminimal patterns in the two-way case under independence is derived, based on\nthe analysis of the positions of the chosen cells. A simulation study and a\ncouple of real-data examples are presented to illustrate the performances of\nthe newly developed outlier identification algorithm, and to compare it with\nother existing methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 12:55:50 GMT"}, {"version": "v2", "created": "Wed, 14 Nov 2012 14:12:00 GMT"}], "update_date": "2012-11-15", "authors_parsed": [["Kuhnt", "Sonja", ""], ["Rapallo", "Fabio", ""], ["Rehage", "Andr\u00e9", ""]]}, {"id": "1207.2968", "submitter": "Hugo Maruri-Aguilar", "authors": "Hugo Maruri-Aguilar and Henry P. Wynn", "title": "The algebraic method in experimental design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algebraic method provides useful techniques to identify models in designs\nand to understand aliasing of polynomial models. The present note surveys the\ntopic of Gr\\\"obner bases in experimental design and then describes the notion\nof confounding and the algebraic fan of a design. The ideas are illustrated\nwith a variety of design examples ranging from Latin squares to screening\ndesigns.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 13:59:34 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Maruri-Aguilar", "Hugo", ""], ["Wynn", "Henry P.", ""]]}, {"id": "1207.3100", "submitter": "Eric Laber", "authors": "Eric B. Laber, Daniel J. Lizotte, Bradley Ferguson", "title": "Set-valued dynamic treatment regimes for competing outcomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic treatment regimes operationalize the clinical decision process as a\nsequence of functions, one for each clinical decision, where each function\ntakes as input up-to-date patient information and gives as output a single\nrecommended treatment. Current methods for estimating optimal dynamic treatment\nregimes, for example Q-learning, require the specification of a single outcome\nby which the `goodness' of competing dynamic treatment regimes are measured.\nHowever, this is an over-simplification of the goal of clinical decision\nmaking, which aims to balance several potentially competing outcomes. For\nexample, often a balance must be struck between treatment effectiveness and\nside-effect burden. We propose a method for constructing dynamic treatment\nregimes that accommodates competing outcomes by recommending sets of treatments\nat each decision point. Formally, we construct a sequence of set-valued\nfunctions that take as input up-to-date patient information and give as output\na recommended subset of the possible treatments. For a given patient history,\nthe recommended set of treatments contains all treatments that are not inferior\naccording to any of the competing outcomes. When there is more than one\ndecision point, constructing these set-valued functions requires solving a\nnon-trivial enumeration problem. We offer an exact enumeration algorithm by\nrecasting the problem as a linear mixed integer program. The proposed methods\nare illustrated using data from a depression study and the CATIE schizophrenia\nstudy.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 21:10:08 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2012 18:50:17 GMT"}], "update_date": "2012-08-08", "authors_parsed": [["Laber", "Eric B.", ""], ["Lizotte", "Daniel J.", ""], ["Ferguson", "Bradley", ""]]}, {"id": "1207.3246", "submitter": "Quentin Giai Gianetto", "authors": "Quentin Giai Gianetto and Hamdi Raissi", "title": "Testing instantaneous causality in presence of non constant\n  unconditional variance", "comments": "Keywords : VAR model, Unconditionally heteroscedastic errors,\n  instantaneous causality", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of testing instantaneous causality between variables with\ntime-varying unconditional variance is investigated. It is shown that the\nclassical tests based on the assumption of stationary processes must be avoided\nin our non standard framework. More precisely we underline that the standard\ntest does not control the type I errors, while the tests with White (1980) and\nHeteroscedastic Autocorrelation Consistent (HAC) corrections can suffer from a\nsevere loss of power when the variance is not constant. Consequently a modified\ntest based on a bootstrap procedure is proposed. The relevance of the modified\ntest is underlined through a simulation study. The tests considered in this\npaper are also compared by investigating the instantaneous causality relations\nbetween US macroeconomic variables.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2012 13:57:42 GMT"}, {"version": "v2", "created": "Fri, 11 Apr 2014 11:42:49 GMT"}], "update_date": "2014-04-14", "authors_parsed": [["Gianetto", "Quentin Giai", ""], ["Raissi", "Hamdi", ""]]}, {"id": "1207.3554", "submitter": "Akisato Kimura", "authors": "Akisato Kimura, Masashi Sugiyama, Sakano Hitoshi, Hirokazu Kameoka", "title": "Designing various component analysis at will", "comments": "Accepted to IAPR International Conference on Pattern Recognition,\n  submitted to IPSJ Transactions on Mathematical Modeling and its Applications\n  (TOM). Just only one-page abstract for new due to novelty violation for\n  journal submission. The details will be disclosed in late September", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NA stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a generic framework of component analysis (CA) methods\nintroducing a new expression for scatter matrices and Gram matrices, called\nGeneralized Pairwise Expression (GPE). This expression is quite compact but\nhighly powerful: The framework includes not only (1) the standard CA methods\nbut also (2) several regularization techniques, (3) weighted extensions, (4)\nsome clustering methods, and (5) their semi-supervised extensions. This paper\nalso presents quite a simple methodology for designing a desired CA method from\nthe proposed framework: Adopting the known GPEs as templates, and generating a\nnew method by combining these templates appropriately.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 00:07:44 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2012 23:45:32 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Kimura", "Akisato", ""], ["Sugiyama", "Masashi", ""], ["Hitoshi", "Sakano", ""], ["Kameoka", "Hirokazu", ""]]}, {"id": "1207.3840", "submitter": "Jonathan Taylor", "authors": "Jonathan E. Taylor and Keith J. Worsley", "title": "Detecting sparse cone alternatives for Gaussian random fields, with an\n  application to fMRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our problem is to find a good approximation to the P-value of the maximum of\na random field of test statistics for a cone alternative at each point in a\nsample of Gaussian random fields. These test statistics have been proposed in\nthe neuroscience literature for the analysis of fMRI data allowing for unknown\ndelay in the hemodynamic response. However the null distribution of the maximum\nof this 3D random field of test statistics, and hence the threshold used to\ndetect brain activation, was unsolved. To find a solution, we approximate the\nP-value by the expected Euler characteristic (EC) of the excursion set of the\ntest statistic random field. Our main result is the required EC density,\nderived using the Gaussian Kinematic Formula.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 22:51:31 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Taylor", "Jonathan E.", ""], ["Worsley", "Keith J.", ""]]}, {"id": "1207.4085", "submitter": "Xi Luo", "authors": "Xi Luo, Steven Gee, Vikaas S. Sohal, Dylan S. Small", "title": "A Point-process Response Model for Spike Trains from Single Neurons in\n  Neural Circuits under Optogenetic Stimulation", "comments": "24 pages, 7 figures. R package pro implementing the proposed method\n  is available on CRAN at https://CRAN.R-project.org/package=pro . Published by\n  Statistics in Medicine at\n  http://onlinelibrary.wiley.com/doi/10.1002/sim.6742/full", "journal-ref": "Stat Med. 2016; 35(3): 455-74", "doi": "10.1002/sim.6742", "report-no": null, "categories": "stat.ME q-bio.NC stat.AP stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optogenetics is a new tool to study neuronal circuits that have been\ngenetically modified to allow stimulation by flashes of light. We study\nrecordings from single neurons within neural circuits under optogenetic\nstimulation. The data from these experiments present a statistical challenge of\nmodeling a high frequency point process (neuronal spikes) while the input is\nanother high frequency point process (light flashes). We further develop a\ngeneralized linear model approach to model the relationships between two point\nprocesses, employing additive point-process response functions. The resulting\nmodel, Point-process Responses for Optogenetics (PRO), provides explicit\nnonlinear transformations to link the input point process with the output one.\nSuch response functions may provide important and interpretable scientific\ninsights into the properties of the biophysical process that governs neural\nspiking in response to optogenetic stimulation. We validate and compare the PRO\nmodel using a real dataset and simulations, and our model yields a superior\narea-under-the- curve value as high as 93% for predicting every future spike.\nFor our experiment on the recurrent layer V circuit in the prefrontal cortex,\nthe PRO model provides evidence that neurons integrate their inputs in a\nsophisticated manner. Another use of the model is that it enables understanding\nhow neural circuits are altered under various disease conditions and/or\nexperimental conditions by comparing the PRO parameters.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 18:51:17 GMT"}, {"version": "v2", "created": "Thu, 22 Dec 2016 03:48:50 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Luo", "Xi", ""], ["Gee", "Steven", ""], ["Sohal", "Vikaas S.", ""], ["Small", "Dylan S.", ""]]}, {"id": "1207.4118", "submitter": "Mathias Drton", "authors": "Mathias Drton, Thomas S. Richardson", "title": "Iterative Conditional Fitting for Gaussian Ancestral Graph Models", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-130-137", "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ancestral graph models, introduced by Richardson and Spirtes (2002),\ngeneralize both Markov random fields and Bayesian networks to a class of graphs\nwith a global Markov property that is closed under conditioning and\nmarginalization. By design, ancestral graphs encode precisely the conditional\nindependence structures that can arise from Bayesian networks with selection\nand unobserved (hidden/latent) variables. Thus, ancestral graph models provide\na potentially very useful framework for exploratory model selection when\nunobserved variables might be involved in the data-generating process but no\nparticular hidden structure can be specified. In this paper, we present the\nIterative Conditional Fitting (ICF) algorithm for maximum likelihood estimation\nin Gaussian ancestral graph models. The name reflects that in each step of the\nprocedure a conditional distribution is estimated, subject to constraints,\nwhile a marginal distribution is held fixed. This approach is in duality to the\nwell-known Iterative Proportional Fitting algorithm, in which marginal\ndistributions are fitted while conditional distributions are held fixed.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:44:26 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Drton", "Mathias", ""], ["Richardson", "Thomas S.", ""]]}, {"id": "1207.4140", "submitter": "Manabu Kuroki", "authors": "Manabu Kuroki, Zhihong Cai", "title": "Selection of Identifiability Criteria for Total Effects by using Path\n  Diagrams", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-333-340", "categories": "stat.ME cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pearl has provided the back door criterion, the front door criterion and the\nconditional instrumental variable (IV) method as identifiability criteria for\ntotal effects. In some situations, these three criteria can be applied to\nidentifying total effects simultaneously. For the purpose of increasing\nestimating accuracy, this paper compares the three ways of identifying total\neffects in terms of the asymptotic variance, and concludes that in some\nsituations the superior of them can be recognized directly from the graph\nstructure.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:53:48 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Kuroki", "Manabu", ""], ["Cai", "Zhihong", ""]]}, {"id": "1207.4145", "submitter": "Nebojsa Jojic", "authors": "Nebojsa Jojic, Vladimir Jojic, David Heckerman", "title": "Joint discovery of haplotype blocks and complex trait associations from\n  SNP sequences", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-286-292", "categories": "q-bio.GN cs.CE stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Haplotypes, the global patterns of DNA sequence variation, have important\nimplications for identifying complex traits. Recently, blocks of limited\nhaplotype diversity have been discovered in human chromosomes, intensifying the\nresearch on modelling the block structure as well as the transitions or\nco-occurrence of the alleles in these blocks as a way to compress the\nvariability and infer the associations more robustly. The haplotype block\nstructure analysis is typically complicated by the fact that the phase\ninformation for each SNP is missing, i.e., the observed allele pairs are not\ngiven in a consistent order across the sequence. The techniques for\ncircumventing this require additional information, such as family data, or a\nmore complex sequencing procedure. In this paper we present a hierarchical\nstatistical model and the associated learning and inference algorithms that\nsimultaneously deal with the allele ambiguity per locus, missing data, block\nestimation, and the complex trait association. While the blo structure may\ndiffer from the structures inferred by other methods, which use the pedigree\ninformation or previously known alleles, the parameters we estimate, including\nthe learned block structure and the estimated block transitions per locus,\ndefine a good model of variability in the set. The method is completely\ndatadriven and can detect Chron's disease from the SNP data taken from the\nhuman chromosome 5q31 with the detection rate of 80% and a small error\nvariance.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 14:55:26 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Jojic", "Nebojsa", ""], ["Jojic", "Vladimir", ""], ["Heckerman", "David", ""]]}, {"id": "1207.4159", "submitter": "Bo Wang", "authors": "Bo Wang, D. Titterington", "title": "Convergence and asymptotic normality of variational Bayesian\n  approximations for exponential family models with missing values", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-577-584", "categories": "math.ST stat.CO stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the properties of variational Bayes approximations for exponential\nfamily models with missing values. It is shown that the iterative algorithm for\nobtaining the variational Bayesian estimator converges locally to the true\nvalue with probability 1 as the sample size becomes inde nitely large.\nMoreover, the variational posterior distribution is proved to be asymptotically\nnormal.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 15:01:58 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Wang", "Bo", ""], ["Titterington", "D.", ""]]}, {"id": "1207.4161", "submitter": "Jin Tian", "authors": "Jin Tian", "title": "Identifying Conditional Causal Effects", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-561-568", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns the assessment of the effects of actions from a\ncombination of nonexperimental data and causal assumptions encoded in the form\nof a directed acyclic graph in which some variables are presumed to be\nunobserved. We provide a procedure that systematically identifies cause effects\nbetween two sets of variables conditioned on some other variables, in time\npolynomial in the number of variables in the graph. The identifiable\nconditional causal effects are expressed in terms of the observed joint\ndistribution.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 15:02:32 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Tian", "Jin", ""]]}, {"id": "1207.4162", "submitter": "Bo Thiesson", "authors": "Bo Thiesson, David Maxwell Chickering, David Heckerman, Christopher\n  Meek", "title": "ARMA Time-Series Modeling with Graphical Models", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-552-560", "categories": "stat.AP cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We express the classic ARMA time-series model as a directed graphical model.\nIn doing so, we find that the deterministic relationships in the model make it\neffectively impossible to use the EM algorithm for learning model parameters.\nTo remedy this problem, we replace the deterministic relationships with\nGaussian distributions having a small variance, yielding the stochastic ARMA\n(ARMA) model. This modification allows us to use the EM algorithm to learn\nparmeters and to forecast,even in situations where some data is missing. This\nmodification, in conjunction with the graphicalmodel approach, also allows us\nto include cross predictors in situations where there are multiple times series\nand/or additional nontemporal covariates. More surprising,experiments suggest\nthat the move to stochastic ARMA yields improved accuracy through better\nsmoothing. We demonstrate improvements afforded by cross prediction and better\nsmoothing on real data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 15:03:00 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2012 20:45:28 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Thiesson", "Bo", ""], ["Chickering", "David Maxwell", ""], ["Heckerman", "David", ""], ["Meek", "Christopher", ""]]}, {"id": "1207.4173", "submitter": "Judea Pearl", "authors": "Judea Pearl", "title": "Robustness of Causal Claims", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-446-453", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A causal claim is any assertion that invokes causal relationships between\nvariables, for example that a drug has a certain effect on preventing a\ndisease. Causal claims are established through a combination of data and a set\nof causal assumptions called a causal model. A claim is robust when it is\ninsensitive to violations of some of the causal assumptions embodied in the\nmodel. This paper gives a formal definition of this notion of robustness and\nestablishes a graphical condition for quantifying the degree of robustness of a\ngiven causal claim. Algorithms for computing the degree of robustness are also\npresented.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 15:07:41 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Pearl", "Judea", ""]]}, {"id": "1207.4178", "submitter": "Peter Hooper", "authors": "Peter Hooper", "title": "Dependent Dirichlet Priors and Optimal Linear Estimators for Belief Net\n  Parameters", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-251-259", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Bayesian belief network is a model of a joint distribution over a finite\nset of variables, with a DAG structure representing immediate dependencies\namong the variables. For each node, a table of parameters (CPtable) represents\nlocal conditional probabilities, with rows indexed by conditioning events\n(assignments to parents). CP-table rows are usually modeled as independent\nrandom vectors, each assigned a Dirichlet prior distribution. The assumption\nthat rows are independent permits a relatively simple analysis but may not\nreflect actual prior opinion about the parameters. Rows representing similar\nconditioning events often have similar conditional probabilities. This paper\nintroduces a more flexible family of \"dependent Dirichlet\" prior distributions,\nwhere rows are not necessarily independent. Simple methods are developed to\napproximate the Bayes estimators of CP-table parameters with optimal linear\nestimators; i.e., linear combinations of sample proportions and prior means.\nThis approach yields more efficient estimators by sharing information among\nrows. Improvements in efficiency can be substantial when a CP-table has many\nrows and samples sizes are small.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 19:46:25 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Hooper", "Peter", ""]]}, {"id": "1207.4300", "submitter": "Oliver Grothe", "authors": "Oliver Grothe", "title": "A higher order correlation unscented Kalman filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many nonlinear extensions of the Kalman filter, e.g., the extended and the\nunscented Kalman filter, reduce the state densities to Gaussian densities. This\napproximation gives sufficient results in many cases. However, this filters\nonly estimate states that are correlated with the observation. Therefore,\nsequential estimation of diffusion parameters, e.g., volatility, which are not\ncorrelated with the observations is not possible. While other filters overcome\nthis problem with simulations, we extend the measurement update of the Gaussian\ntwo-moment filters by a higher order correlation measurement update. We\nexplicitly state formulas for a higher order unscented Kalman filter within a\ncontinuous-discrete state space. We demonstrate the filter in the context of\nparameter estimation of an Ornstein-Uhlenbeck process.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 08:39:58 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Grothe", "Oliver", ""]]}, {"id": "1207.4385", "submitter": "Maria Giovanna Ranalli", "authors": "Alina Matei and M. Giovanna Ranalli", "title": "Dealing with nonresponse in survey sampling: a latent modeling approach", "comments": "28 pages", "journal-ref": "Survey Methodology, June 2015, Vol. 41, No. 1, pp. 145-164", "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonresponse is present in almost all surveys and can severely bias estimates.\nIt is usually distinguished between unit and item nonresponse: in the former,\nwe completely fail to have information from a unit selected in the sample,\nwhile in the latter, we observe only part of the information on the selected\nunit. Unit nonresponse is usually dealt with by reweighting: each unit selected\nin the sample has associated a sampling weight and an unknown response\nprobability; the initial sampling weight is multiplied by the inverse of\nestimated response probability. Item nonresponse is usually dealt with by\nimputation. By noting that for a particular survey variable, we just have\nobserved and unobserved values, in this work we exploit the connection between\nunit and item nonresponse. In particular, we assume that the factors that drive\nunit response are the same as those that drive item response on selected\nvariables of interest. Response probabilities are then estimated by using a\nlogistic regression with a latent covariate that measures such will to respond\nand that can explain part of the unknown behavior of a unit to participate in\nthe survey. The latent covariate is estimated using latent trait models. Such\napproach is particularly relevant for sensitive items and, therefore, can\nhandle non-ignorable nonresponse. Auxiliary information known for both\nrespondents and nonrespondents can be included either in the latent variable\nmodel or in the logistic model. The approach can be also used when auxiliary\ninformation is not available, and we focus here on this case. The theoretical\nproperties of the proposed estimators are sketched and simulations studies are\nconducted to illustrate their finite size sample performance.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 14:44:52 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2013 10:22:28 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Matei", "Alina", ""], ["Ranalli", "M. Giovanna", ""]]}, {"id": "1207.4510", "submitter": "Jelena Bradic", "authors": "Jelena Bradic and Rui Song", "title": "Structured Estimation in Nonparameteric Cox Model", "comments": null, "journal-ref": "Electron. J. Statist. Volume 9, Number 1 (2015), 492-534", "doi": "10.1214/15-EJS1004", "report-no": null, "categories": "math.ST stat.ME stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To better understand the interplay of censoring and sparsity we develop\nfinite sample properties of nonparametric Cox proportional hazard's model. Due\nto high impact of sequencing data, carrying genetic information of each\nindividual, we work with over-parametrized problem and propose general class of\ngroup penalties suitable for sparse structured variable selection and\nestimation. Novel non-asymptotic sandwich bounds for the partial likelihood are\ndeveloped. We establish how they extend notion of local asymptotic normality\n(LAN) of Le Cam's. Such non-asymptotic LAN principles are further extended to\nhigh dimensional spaces where $p \\gg n$. Finite sample prediction properties of\npenalized estimator in non-parametric Cox proportional hazards model, under\nsuitable censoring conditions, agree with those of penalized estimator in\nlinear models.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 22:14:52 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2014 18:47:42 GMT"}, {"version": "v3", "created": "Fri, 19 Sep 2014 00:57:38 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Bradic", "Jelena", ""], ["Song", "Rui", ""]]}, {"id": "1207.4566", "submitter": "Zaiying Zhou", "authors": "Zai-Ying Zhou", "title": "A Random Weighting Approach for Posterior Distributions", "comments": "17 pages, 0 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Bayesian theory, calculating a posterior probability distribution is\nhighly important but usually difficult. Therefore, some methods have been put\nforward to deal with such problem, among which, the most popular one is the\nasymptotic expansions for posterior distributions. In this paper, we propose an\nalternative method, named random weighting method, for scaled posterior\ndistributions, and give an ideal convergence speed, which serves as the\ntheoretical guarantee for methods of numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 06:56:28 GMT"}], "update_date": "2012-07-20", "authors_parsed": [["Zhou", "Zai-Ying", ""]]}, {"id": "1207.4959", "submitter": "Mathias Bourel", "authors": "Mathias Bourel and Badih Ghattas", "title": "Aggregating density estimators: an empirical study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present some new density estimation algorithms obtained by bootstrap\naggregation like Bagging. Our algorithms are analyzed and empirically compared\nto other methods found in the statistical literature, like stacking and\nboosting for density estimation. We show by extensive simulations that ensemble\nlearning are effective for density estimation like for classification. Although\nour algorithms do not always outperform other methods, some of them are as\nsimple as bagging, more intuitive and has computational lower cost.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 14:16:20 GMT"}], "update_date": "2012-07-23", "authors_parsed": [["Bourel", "Mathias", ""], ["Ghattas", "Badih", ""]]}, {"id": "1207.5103", "submitter": "Richard D. Gill", "authors": "Richard D. Gill", "title": "Statistics, Causality and Bell's Theorem", "comments": "Published in at http://dx.doi.org/10.1214/14-STS490 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2014, Vol. 29, No. 4, 512-528", "doi": "10.1214/14-STS490", "report-no": "IMS-STS-STS490", "categories": "stat.AP physics.hist-ph quant-ph stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bell's [Physics 1 (1964) 195-200] theorem is popularly supposed to establish\nthe nonlocality of quantum physics. Violation of Bell's inequality in\nexperiments such as that of Aspect, Dalibard and Roger [Phys. Rev. Lett. 49\n(1982) 1804-1807] provides empirical proof of nonlocality in the real world.\nThis paper reviews recent work on Bell's theorem, linking it to issues in\ncausality as understood by statisticians. The paper starts with a proof of a\nstrong, finite sample, version of Bell's inequality and thereby also of Bell's\ntheorem, which states that quantum theory is incompatible with the conjunction\nof three formerly uncontroversial physical principles, here referred to as\nlocality, realism and freedom. Locality is the principle that the direction of\ncausality matches the direction of time, and that causal influences need time\nto propagate spatially. Realism and freedom are directly connected to\nstatistical thinking on causality: they relate to counterfactual reasoning, and\nto randomisation, respectively. Experimental loopholes in state-of-the-art Bell\ntype experiments are related to statistical issues of post-selection in\nobservational studies, and the missing at random assumption. They can be\navoided by properly matching the statistical analysis to the actual\nexperimental design, instead of by making untestable assumptions of\nindependence between observed and unobserved variables. Methodological and\nstatistical issues in the design of quantum Randi challenges (QRC) are\ndiscussed. The paper argues that Bell's theorem (and its experimental\nconfirmation) should lead us to relinquish not locality, but realism.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2012 05:24:44 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2013 00:26:31 GMT"}, {"version": "v3", "created": "Sat, 22 Mar 2014 15:20:10 GMT"}, {"version": "v4", "created": "Fri, 4 Apr 2014 22:46:52 GMT"}, {"version": "v5", "created": "Mon, 5 May 2014 15:55:13 GMT"}, {"version": "v6", "created": "Fri, 30 Jan 2015 10:55:43 GMT"}], "update_date": "2015-02-02", "authors_parsed": [["Gill", "Richard D.", ""]]}, {"id": "1207.5136", "submitter": "Jonas Peters", "authors": "Jonas Peters, Dominik Janzing and Bernhard Sch\\\"olkopf", "title": "Causal Inference on Time Series using Structural Equation Models", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 26, 154-162,\n  2014", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference uses observations to infer the causal structure of the data\ngenerating system. We study a class of functional models that we call Time\nSeries Models with Independent Noise (TiMINo). These models require independent\nresidual time series, whereas traditional methods like Granger causality\nexploit the variance of residuals. There are two main contributions: (1)\nTheoretical: By restricting the model class (e.g. to additive noise) we can\nprovide a more general identifiability result than existing ones. This result\nincorporates lagged and instantaneous effects that can be nonlinear and do not\nneed to be faithful, and non-instantaneous feedbacks between the time series.\n(2) Practical: If there are no feedback loops between time series, we propose\nan algorithm based on non-linear independence tests of time series. When the\ndata are causally insufficient, or the data generating process does not satisfy\nthe model assumptions, this algorithm may still give partial results, but\nmostly avoids incorrect answers. An extension to (non-instantaneous) feedbacks\nis possible, but not discussed. It outperforms existing methods on artificial\nand real data. Code can be provided upon request.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2012 13:31:56 GMT"}], "update_date": "2016-08-18", "authors_parsed": [["Peters", "Jonas", ""], ["Janzing", "Dominik", ""], ["Sch\u00f6lkopf", "Bernhard", ""]]}, {"id": "1207.5313", "submitter": "Kengo Kato", "authors": "Kengo Kato", "title": "Two-step estimation of high dimensional additive models", "comments": "49 pages, 3 tables; minor errors corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the two-step estimation of a high dimensional\nadditive regression model, in which the number of nonparametric additive\ncomponents is potentially larger than the sample size but the number of\nsignificant additive components is sufficiently small. The approach\ninvestigated consists of two steps. The first step implements the variable\nselection, typically by the group Lasso, and the second step applies the\npenalized least squares estimation with Sobolev penalties to the selected\nadditive components. Such a procedure is computationally simple to implement\nand, in our numerical experiments, works reasonably well. Despite its intuitive\nnature, the theoretical properties of this two-step procedure have to be\ncarefully analyzed, since the effect of the first step variable selection is\nrandom, and generally it may contain redundant additive components and at the\nsame time miss significant additive components. This paper derives a generic\nperformance bound on the two-step estimation procedure allowing for these\nsituations, and studies in detail the overall performance when the first step\nvariable selection is implemented by the group Lasso.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2012 07:52:53 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2013 09:52:02 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Kato", "Kengo", ""]]}, {"id": "1207.5355", "submitter": "Nicolas Dobigeon", "authors": "Marcelo Pereyra and Nicolas Dobigeon and Hadj Batatia and Jean-Yves\n  Tourneret", "title": "Estimating the granularity coefficient of a Potts-Markov random field\n  within an MCMC algorithm", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2013.2249076", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of estimating the Potts parameter B jointly\nwith the unknown parameters of a Bayesian model within a Markov chain Monte\nCarlo (MCMC) algorithm. Standard MCMC methods cannot be applied to this problem\nbecause performing inference on B requires computing the intractable\nnormalizing constant of the Potts model. In the proposed MCMC method the\nestimation of B is conducted using a likelihood-free Metropolis-Hastings\nalgorithm. Experimental results obtained for synthetic data show that\nestimating B jointly with the other unknown parameters leads to estimation\nresults that are as good as those obtained with the actual value of B. On the\nother hand, assuming that the value of B is known can degrade estimation\nperformance significantly if this value is incorrect. To illustrate the\ninterest of this method, the proposed algorithm is successfully applied to real\nbidimensional SAR and tridimensional ultrasound images.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2012 11:13:20 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Pereyra", "Marcelo", ""], ["Dobigeon", "Nicolas", ""], ["Batatia", "Hadj", ""], ["Tourneret", "Jean-Yves", ""]]}, {"id": "1207.5371", "submitter": "Aasa Feragen", "authors": "Aasa Feragen, Pechin Lo, Marleen de Bruijne, Mads Nielsen, Francois\n  Lauze", "title": "Towards a theory of statistical tree-shape analysis", "comments": "36 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.CV math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to develop statistical methods for shapes with a tree-structure, we\nconstruct a shape space framework for tree-like shapes and study metrics on the\nshape space. This shape space has singularities, corresponding to topological\ntransitions in the represented trees. We study two closely related metrics on\nthe shape space, TED and QED. QED is a quotient Euclidean distance arising\nnaturally from the shape space formulation, while TED is the classical tree\nedit distance. Using Gromov's metric geometry we gain new insight into the\ngeometries defined by TED and QED. We show that the new metric QED has nice\ngeometric properties which facilitate statistical analysis, such as existence\nand local uniqueness of geodesics and averages. TED, on the other hand, does\nnot share the geometric advantages of QED, but has nice algorithmic properties.\nWe provide a theoretical framework and experimental results on synthetic data\ntrees as well as airway trees from pulmonary CT scans. This way, we effectively\nillustrate that our framework has both the theoretical and qualitative\nproperties necessary to build a theory of statistical tree-shape analysis.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2012 12:25:50 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Feragen", "Aasa", ""], ["Lo", "Pechin", ""], ["de Bruijne", "Marleen", ""], ["Nielsen", "Mads", ""], ["Lauze", "Francois", ""]]}, {"id": "1207.5649", "submitter": "Andrey Feuerverger", "authors": "Andrey Feuerverger, Yu He, Shashi Khatri", "title": "Statistical Significance of the Netflix Challenge", "comments": "Published in at http://dx.doi.org/10.1214/11-STS368 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2012, Vol. 27, No. 2, 202-231", "doi": "10.1214/11-STS368", "report-no": "IMS-STS-STS368", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the legacy of the Netflix contest, we provide an overview of what\nhas been learned---from our own efforts, and those of others---concerning the\nproblems of collaborative filtering and recommender systems. The data set\nconsists of about 100 million movie ratings (from 1 to 5 stars) involving some\n480 thousand users and some 18 thousand movies; the associated ratings matrix\nis about 99% sparse. The goal is to predict ratings that users will give to\nmovies; systems which can do this accurately have significant commercial\napplications, particularly on the world wide web. We discuss, in some detail,\napproaches to \"baseline\" modeling, singular value decomposition (SVD), as well\nas kNN (nearest neighbor) and neural network models; temporal effects,\ncross-validation issues, ensemble methods and other considerations are\ndiscussed as well. We compare existing models in a search for new models, and\nalso discuss the mission-critical issues of penalization and parameter\nshrinkage which arise when the dimensions of a parameter space reaches into the\nmillions. Although much work on such problems has been carried out by the\ncomputer science and machine learning communities, our goal here is to address\na statistical audience, and to provide a primarily statistical treatment of the\nlessons that have been learned from this remarkable set of data.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 10:35:17 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Feuerverger", "Andrey", ""], ["He", "Yu", ""], ["Khatri", "Shashi", ""]]}, {"id": "1207.5651", "submitter": "Petros Dellaportas", "authors": "Petros Dellaportas, Jonathan J. Forster, Ioannis Ntzoufras", "title": "Joint Specification of Model Space and Parameter Space Prior\n  Distributions", "comments": "Published in at http://dx.doi.org/10.1214/11-STS369 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2012, Vol. 27, No. 2, 232-246", "doi": "10.1214/11-STS369", "report-no": "IMS-STS-STS369", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the specification of prior distributions for Bayesian model\ncomparison, focusing on regression-type models. We propose a particular joint\nspecification of the prior distribution across models so that sensitivity of\nposterior model probabilities to the dispersion of prior distributions for the\nparameters of individual models (Lindley's paradox) is diminished. We\nillustrate the behavior of inferential and predictive posterior quantities in\nlinear and log-linear regressions under our proposed prior densities with a\nseries of simulated and real data examples.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 10:39:32 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Dellaportas", "Petros", ""], ["Forster", "Jonathan J.", ""], ["Ntzoufras", "Ioannis", ""]]}, {"id": "1207.5653", "submitter": "Christine Choirat", "authors": "Christine Choirat, Raffaello Seri", "title": "Estimation in Discrete Parameter Models", "comments": "Published in at http://dx.doi.org/10.1214/11-STS371 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2012, Vol. 27, No. 2, 278-293", "doi": "10.1214/11-STS371", "report-no": "IMS-STS-STS371", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some estimation problems, especially in applications dealing with\ninformation theory, signal processing and biology, theory provides us with\nadditional information allowing us to restrict the parameter space to a finite\nnumber of points. In this case, we speak of discrete parameter models. Even\nthough the problem is quite old and has interesting connections with testing\nand model selection, asymptotic theory for these models has hardly ever been\nstudied. Therefore, we discuss consistency, asymptotic distribution theory,\ninformation inequalities and their relations with efficiency and\nsuperefficiency for a general class of $m$-estimators.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 10:49:18 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Choirat", "Christine", ""], ["Seri", "Raffaello", ""]]}, {"id": "1207.5655", "submitter": "Arthur Cohen", "authors": "Arthur Cohen, Harold Sackrowitz", "title": "The Interval Property in Multiple Testing of Pairwise Differences", "comments": "Published in at http://dx.doi.org/10.1214/11-STS372 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2012, Vol. 27, No. 2, 294-307", "doi": "10.1214/11-STS372", "report-no": "IMS-STS-STS372", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usual step-down and step-up multiple testing procedures most often lack\nan important intuitive, practical, and theoretical property called the interval\nproperty. In short, the interval property is simply that for an individual\nhypothesis, among the several to be tested, the acceptance sections of relevant\nstatistics are intervals. Lack of the interval property is a serious\nshortcoming. This shortcoming is demonstrated for testing various pairwise\ncomparisons in multinomial models, multivariate normal models and in\nnonparametric models. Residual based stepwise multiple testing procedures that\ndo have the interval property are offered in all these cases.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 10:53:07 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Cohen", "Arthur", ""], ["Sackrowitz", "Harold", ""]]}, {"id": "1207.5656", "submitter": "Jerome Sacks", "authors": "Jerome Sacks, Donald Ylvisaker", "title": "After 50+ Years in Statistics, An Exchange", "comments": "Published in at http://dx.doi.org/10.1214/12-STS386 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2012, Vol. 27, No. 2, 308-318", "doi": "10.1214/12-STS386", "report-no": "IMS-STS-STS386", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an exchange between Jerome Sacks and Donald Ylvisaker covering their\ncareer paths along with some related history and philosophy of Statistics.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 10:56:50 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Sacks", "Jerome", ""], ["Ylvisaker", "Donald", ""]]}, {"id": "1207.5947", "submitter": "Fabian Scheipl", "authors": "Fabian Scheipl, Ana-Maria Staicu, Sonja Greven", "title": "Functional Additive Mixed Models", "comments": "26 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extensive framework for additive regression models for\ncorrelated functional responses, allowing for multiple partially nested or\ncrossed functional random effects with flexible correlation structures for,\ne.g., spatial, temporal, or longitudinal functional data. Additionally, our\nframework includes linear and nonlinear effects of functional and scalar\ncovariates that may vary smoothly over the index of the functional response. It\naccommodates densely or sparsely observed functional responses and predictors\nwhich may be observed with additional error and includes both spline-based and\nfunctional principal component-based terms. Estimation and inference in this\nframework is based on standard additive mixed models, allowing us to take\nadvantage of established methods and robust, flexible algorithms. We provide\neasy-to-use open source software in the pffr() function for the R-package\nrefund. Simulations show that the proposed method recovers relevant effects\nreliably, handles small sample sizes well and also scales to larger data sets.\nApplications with spatially and longitudinally observed functional data\ndemonstrate the flexibility in modeling and interpretability of results of our\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 10:29:36 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2013 13:01:33 GMT"}, {"version": "v3", "created": "Mon, 22 Jul 2013 08:18:05 GMT"}, {"version": "v4", "created": "Wed, 24 Jul 2013 09:01:47 GMT"}, {"version": "v5", "created": "Mon, 25 Nov 2013 14:00:52 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Scheipl", "Fabian", ""], ["Staicu", "Ana-Maria", ""], ["Greven", "Sonja", ""]]}, {"id": "1207.6076", "submitter": "Dino Sejdinovic", "authors": "Dino Sejdinovic, Bharath Sriperumbudur, Arthur Gretton, Kenji Fukumizu", "title": "Equivalence of distance-based and RKHS-based statistics in hypothesis\n  testing", "comments": "Published in at http://dx.doi.org/10.1214/13-AOS1140 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2013, Vol. 41, No. 5, 2263-2291", "doi": "10.1214/13-AOS1140", "report-no": "IMS-AOS-AOS1140", "categories": "stat.ME cs.LG math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a unifying framework linking two classes of statistics used in\ntwo-sample and independence testing: on the one hand, the energy distances and\ndistance covariances from the statistics literature; on the other, maximum mean\ndiscrepancies (MMD), that is, distances between embeddings of distributions to\nreproducing kernel Hilbert spaces (RKHS), as established in machine learning.\nIn the case where the energy distance is computed with a semimetric of negative\ntype, a positive definite kernel, termed distance kernel, may be defined such\nthat the MMD corresponds exactly to the energy distance. Conversely, for any\npositive definite kernel, we can interpret the MMD as energy distance with\nrespect to some negative-type semimetric. This equivalence readily extends to\ndistance covariance using kernels on the product space. We determine the class\nof probability distributions for which the test statistics are consistent\nagainst all alternatives. Finally, we investigate the performance of the family\nof distance kernels in two-sample and independence tests: we show in particular\nthat the energy distance most commonly employed in statistics is just one\nmember of a parametric family of kernels, and that other choices from this\nfamily can yield more powerful tests.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 18:17:20 GMT"}, {"version": "v2", "created": "Mon, 11 Mar 2013 11:29:37 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2013 12:22:53 GMT"}], "update_date": "2013-11-13", "authors_parsed": [["Sejdinovic", "Dino", ""], ["Sriperumbudur", "Bharath", ""], ["Gretton", "Arthur", ""], ["Fukumizu", "Kenji", ""]]}, {"id": "1207.6323", "submitter": "Soosan Beheshti", "authors": "Masoud Hashemi and Soosan Beheshti", "title": "Adaptive Bayesian Denoising for General Gaussian Distributed (GGD)\n  Signals in Wavelet Domain", "comments": "8pages,6 figures, journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimum Bayes estimator for General Gaussian Distributed (GGD) data in\nwavelet is provided. The GGD distribution describes a wide class of signals\nincluding natural images. A wavelet thresholding method for image denoising is\nproposed. Interestingly, we show that the Bayes estimator for this class of\nsignals is well estimated by a thresholding approach. This result analytically\nconfirms the importance of thresholding for noisy GGD signals. We provide the\noptimum soft thresholding value that mimics the behavior of the Bayes estimator\nand minimizes the resulting error.\n  The value of the threshold in BayesShrink, which is one of the most used and\nefficient soft thresholding methods, has been provided heuristically in the\nliterature. Our proposed method, denoted by Rigorous BayesShrink\n(R-BayesShrink), explains the theory of BayesShrink threshold and proves its\noptimality for a subclass of GDD signals. R-BayesShrink improves and\ngeneralizes the existing BayesShrink for the class of GGD signals. While the\nBayesShrink threshold is independent from the wavelet coefficient distribution\nand is just a function of noise and noiseless signal variance, our method\nadapts to the distribution of wavelet coefficients of each scale. It is shown\nthat BayesShrink is a special case of our method when shape parameter in GGD is\none or signal follows Laplace distribution. Our simulation results confirm the\noptimality of R-BayesShrink in GGD denoising with regards to Peak Signal to\nNoise Ratio (PSNR) and Structural Similarity (SSIM) index.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 16:37:31 GMT"}], "update_date": "2012-07-27", "authors_parsed": [["Hashemi", "Masoud", ""], ["Beheshti", "Soosan", ""]]}, {"id": "1207.6353", "submitter": "Yuejie Chi", "authors": "Yuejie Chi, Yonina C. Eldar and Robert Calderbank", "title": "PETRELS: Parallel Subspace Estimation and Tracking by Recursive Least\n  Squares from Partial Observations", "comments": "submitted to IEEE Trans. Signal Processing. Part of the result was\n  reported at ICASSP 2012 and won the best student paper award", "journal-ref": null, "doi": "10.1109/TSP.2013.2282910", "report-no": null, "categories": "stat.ME cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real world data sets exhibit an embedding of low-dimensional structure\nin a high-dimensional manifold. Examples include images, videos and internet\ntraffic data. It is of great significance to reduce the storage requirements\nand computational complexity when the data dimension is high. Therefore we\nconsider the problem of reconstructing a data stream from a small subset of its\nentries, where the data is assumed to lie in a low-dimensional linear subspace,\npossibly corrupted by noise. We further consider tracking the change of the\nunderlying subspace, which can be applied to applications such as video\ndenoising, network monitoring and anomaly detection. Our problem can be viewed\nas a sequential low-rank matrix completion problem in which the subspace is\nlearned in an on-line fashion. The proposed algorithm, dubbed Parallel\nEstimation and Tracking by REcursive Least Squares (PETRELS), first identifies\nthe underlying low-dimensional subspace via a recursive procedure for each row\nof the subspace matrix in parallel with discounting for previous observations,\nand then reconstructs the missing entries via least-squares estimation if\nrequired. Numerical examples are provided for direction-of-arrival estimation\nand matrix completion, comparing PETRELS with state of the art batch\nalgorithms.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 18:02:40 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2013 18:54:15 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Chi", "Yuejie", ""], ["Eldar", "Yonina C.", ""], ["Calderbank", "Robert", ""]]}, {"id": "1207.6606", "submitter": "Zhansheng Cao", "authors": "Michel Broniatowski and Zhansheng Cao", "title": "Weighted sampling, Maximum Likelihood and minimum divergence estimators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores Maximum Likelihood in parametric models in the context of\nSanov type Large Deviation Probabilities. MLE in parametric models under\nweighted sampling is shown to be associated with the minimization of a specific\ndivergence criterion defined with respect to the distribution of the weights.\nSome properties of the resulting inferential procedure are presented; Bahadur\nefficiency of tests are also considered in this context.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2012 18:12:46 GMT"}], "update_date": "2012-07-30", "authors_parsed": [["Broniatowski", "Michel", ""], ["Cao", "Zhansheng", ""]]}, {"id": "1207.6817", "submitter": "Rahul Mukerjee", "authors": "Runchu Zhang and Rahul Mukerjee", "title": "Highly Efficient Factorial Designs for cDNA Microarray Experiments: Use\n  of Approximate Theory Together with a Step-up Step-down Procedure", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A general method for obtaining highly efficient factorial designs of\nrelatively small sizes is developed for cDNA microarray experiments. The method\nallows the main effects and interactions of successive orders to be of possibly\nunequal importance. First, the approximate theory is em-ployed to get an\noptimal design measure which is then discretized. It is, however, observed that\na na\\\"ive discretization may fail to yield an exact design of the stipulated\nsize and, even when it yields such an exact design, there is often scope for\nimprovement in efficiency. To address these issues, we propose a step-up/down\nprocedure which is seen to work very well. The resulting highly efficient\ndesigns are found to remain almost free from possible dye-color effects under a\nsuitable dye-color assignment. They are also seen to be quite robust to\nheteroscedasticity as may be caused by biological variability. We focus on the\nbaseline and all-to-next parametrizations but our method works equally well\nalso for hybrids of the two and other parametrizations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 01:24:14 GMT"}], "update_date": "2012-07-31", "authors_parsed": [["Zhang", "Runchu", ""], ["Mukerjee", "Rahul", ""]]}, {"id": "1207.6868", "submitter": "Laurent Zwald", "authors": "Laurent Zwald, Sophie Lambert-Lacroix", "title": "The BerHu penalty and the grouped effect", "comments": "38 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Huber's criterion is a useful method for robust regression. The adaptive\nleast absolute shrinkage and selection operator (lasso) is a popular technique\nfor simultaneous estimation and variable selection. In the case of small sample\nsize and large covariables numbers, this penalty is not very satisfactory\nvariable selection method. In this paper, we introduce an adaptive reversed\nversion of Huber's criterion as a penalty function. We call this penalty\nadaptive Berhu penalty. As for elastic net penalty, small coefficients\ncontribute their $\\ell_1$ norm to this penalty while larger coefficients cause\nit to grow quadratically (as ridge regression). We show that the estimator\nassociated with criterion such that ordinary least square or Huber's one\ncombining with adaptive Berhu penalty enjoys the oracle properties. In\naddition, this procedure encourages a grouping effect. This approach is\ncompared with adaptive elastic net regularization. Extensive simulation studies\ndemonstrate satisfactory finite-sample performance of such procedure. A real\nexample is analyzed for illustration purposes.\n  Keywords : Adaptive Berhu penalty; concomitant scale; elastic net penalty;\nHuber's criterion; oracle property; robust estimation.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 08:57:30 GMT"}], "update_date": "2012-07-31", "authors_parsed": [["Zwald", "Laurent", ""], ["Lambert-Lacroix", "Sophie", ""]]}, {"id": "1207.6886", "submitter": "Sebastian Engelke", "authors": "Sebastian Engelke, Alexander Malinowski, Zakhar Kabluchko, Martin\n  Schlather", "title": "Estimation of Huesler-Reiss distributions and Brown-Resnick processes", "comments": "26 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of extreme-value parameters from observations in the max-domain of\nattraction (MDA) of a multivariate max-stable distribution commonly uses\naggregated data such as block maxima. Since we expect that additional\ninformation is contained in the non-aggregated, single \"large\" observations, we\nintroduce a new approach of inference based on a multivariate\npeaks-over-threshold method. We show that for any process in the MDA of the\nfrequently used H\\\"usler-Reiss model or its spatial extension, the\nBrown-Resnick process, suitably defined conditional increments asymptotically\nfollow a multivariate Gaussian distribution. This leads to computationally\nefficient estimates of the H\\\"usler-Reiss parameter matrix. Further, the\nresults enable parametric inference for Brown-Resnick processes. A simulation\nstudy compares the performance of the new estimators to other commonly used\nmethods. As an application, we fit a non-isotropic Brown-Resnick process to the\nextremes of 12 year data of daily wind speed measurements.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 10:25:30 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2012 13:32:04 GMT"}], "update_date": "2012-09-26", "authors_parsed": [["Engelke", "Sebastian", ""], ["Malinowski", "Alexander", ""], ["Kabluchko", "Zakhar", ""], ["Schlather", "Martin", ""]]}, {"id": "1207.7218", "submitter": "Francesco Finazzi", "authors": "Francesco Finazzi", "title": "Geostatistical modeling in the presence of interaction between the\n  measuring instruments, with an application to the estimation of spatial\n  market potentials", "comments": "Published in at http://dx.doi.org/10.1214/12-AOAS588 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2013, Vol. 7, No. 1, 81-101", "doi": "10.1214/12-AOAS588", "report-no": "IMS-AOAS-AOAS588", "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of recovering the spatial market potential\nof a retail product from spatially distributed sales data. In order to tackle\nthe problem in a general way, the concept of spatial potential is introduced.\nThe potential is concurrently measured at different spatial locations and the\nmeasurements are analyzed in order to recover the spatial potential. The\nmeasuring instruments used to collect the data interact with each other, that\nis, the measurement at a given spatial location is affected by the concurrent\nmeasurements at other locations. An approach based on a novel geostatistical\nmodel is developed. In particular, the model is able to handle both the\nmeasuring instrument interaction and the missing data. A model estimation\nprocedure based on the expectation-maximization algorithm is provided as well\nas standard inferential tools. The model is applied to the estimation of the\nspatial market potential of a newspaper for the city of Bergamo, Italy. The\nestimated spatial market potential is eventually analyzed in order to identify\nthe areas with the highest potential, to identify the areas where it is\nprofitable to open additional newsstands and to evaluate the newspaper total\nmarket volume of the city.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2012 12:14:42 GMT"}, {"version": "v2", "created": "Mon, 15 Apr 2013 12:39:25 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Finazzi", "Francesco", ""]]}, {"id": "1207.7306", "submitter": "Christopher DuBois", "authors": "Christopher DuBois, Carter T. Butts, Daniel McFarland, Padhraic Smyth", "title": "Hierarchical Models for Relational Event Sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction within small groups can often be represented as a sequence of\nevents, where each event involves a sender and a recipient. Recent methods for\nmodeling network data in continuous time model the rate at which individuals\ninteract conditioned on the previous history of events as well as actor\ncovariates. We present a hierarchical extension for modeling multiple such\nsequences, facilitating inferences about event-level dynamics and their\nvariation across sequences. The hierarchical approach allows one to share\ninformation across sequences in a principled manner---we illustrate the\nefficacy of such sharing through a set of prediction experiments. After\ndiscussing methods for adequacy checking and model selection for this class of\nmodels, the method is illustrated with an analysis of high school classroom\ndynamics.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2012 16:17:06 GMT"}], "update_date": "2012-08-01", "authors_parsed": [["DuBois", "Christopher", ""], ["Butts", "Carter T.", ""], ["McFarland", "Daniel", ""], ["Smyth", "Padhraic", ""]]}]