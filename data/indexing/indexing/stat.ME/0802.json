[{"id": "0802.0191", "submitter": "Kostas Triantafyllopoulos", "authors": "K. Triantafyllopoulos", "title": "Covariance estimation for multivariate conditionally Gaussian dynamic\n  linear models", "comments": "21 pages, 2 figures, 6 tables", "journal-ref": "Journal of Forecasting (2007), 26(8), pp. 551-569.", "doi": "10.1002/for.1039", "report-no": null, "categories": "stat.ME stat.AP", "license": null, "abstract": "  In multivariate time series, the estimation of the covariance matrix of the\nobservation innovations plays an important role in forecasting as it enables\nthe computation of the standardized forecast error vectors as well as it\nenables the computation of confidence bounds of the forecasts. We develop an\non-line, non-iterative Bayesian algorithm for estimation and forecasting. It is\nempirically found that, for a range of simulated time series, the proposed\ncovariance estimator has good performance converging to the true values of the\nunknown observation covariance matrix. Over a simulated time series, the new\nmethod approximates the correct estimates, produced by a non-sequential Monte\nCarlo simulation procedure, which is used here as the gold standard. The\nspecial, but important, vector autoregressive (VAR) and time-varying VAR models\nare illustrated by considering London metal exchange data consisting of spot\nprices of aluminium, copper, lead and zinc.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 19:48:03 GMT"}], "update_date": "2008-02-04", "authors_parsed": [["Triantafyllopoulos", "K.", ""]]}, {"id": "0802.0213", "submitter": "Kostas Triantafyllopoulos", "authors": "K. Triantafyllopoulos and P.J. Harrison", "title": "Posterior mean and variance approximation for regression and time series\n  problems", "comments": "25 pages, 2 figures, 2 tables", "journal-ref": "Statistics (2008), 42, pp. 329-350.", "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": null, "abstract": "  This paper develops a methodology for approximating the posterior first two\nmoments of the posterior distribution in Bayesian inference. Partially\nspecified probability models, which are defined only by specifying means and\nvariances, are constructed based upon second-order conditional independence, in\norder to facilitate posterior updating and prediction of required\ndistributional quantities. Such models are formulated particularly for\nmultivariate regression and time series analysis with unknown observational\nvariance-covariance components. The similarities and differences of these\nmodels with the Bayes linear approach are established. Several subclasses of\nimportant models, including regression and time series models with errors\nfollowing multivariate $t$, inverted multivariate $t$ and Wishart\ndistributions, are discussed in detail. Two numerical examples consisting of\nsimulated data and of US investment and change in inventory data illustrate the\nproposed methodology.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 22:18:34 GMT"}], "update_date": "2009-01-27", "authors_parsed": [["Triantafyllopoulos", "K.", ""], ["Harrison", "P. J.", ""]]}, {"id": "0802.0214", "submitter": "Kostas Triantafyllopoulos", "authors": "K. Triantafyllopoulos", "title": "Multivariate stochastic volatility with Bayesian dynamic linear models", "comments": "24 pages, 3 figures, 2 tables", "journal-ref": "Journal of Statistical Planning and Inference (2008), 138(4), pp.\n  1021-1037", "doi": "10.1016/j.jspi.2007.03.057", "report-no": null, "categories": "q-fin.ST stat.AP stat.ME", "license": null, "abstract": "  This paper develops a Bayesian procedure for estimation and forecasting of\nthe volatility of multivariate time series. The foundation of this work is the\nmatrix-variate dynamic linear model, for the volatility of which we adopt a\nmultiplicative stochastic evolution, using Wishart and singular multivariate\nbeta distributions. A diagonal matrix of discount factors is employed in order\nto discount the variances element by element and therefore allowing a flexible\nand pragmatic variance modelling approach. Diagnostic tests and sequential\nmodel monitoring are discussed in some detail. The proposed estimation theory\nis applied to a four-dimensional time series, comprising spot prices of\naluminium, copper, lead and zinc of the London metal exchange. The empirical\nfindings suggest that the proposed Bayesian procedure can be effectively\napplied to financial data, overcoming many of the disadvantages of existing\nvolatility models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 22:35:49 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Triantafyllopoulos", "K.", ""]]}, {"id": "0802.0218", "submitter": "Kostas Triantafyllopoulos", "authors": "K. Triantafyllopoulos", "title": "Multivariate control charts based on Bayesian state space models", "comments": "19 pages, 6 figures", "journal-ref": "Quality and Reliability Engineering International (2006), 22(6),\n  pp. 693-707", "doi": "10.1002/qre.807", "report-no": null, "categories": "stat.ME stat.AP", "license": null, "abstract": "  This paper develops a new multivariate control charting method for vector\nautocorrelated and serially correlated processes. The main idea is to propose a\nBayesian multivariate local level model, which is a generalization of the\nShewhart-Deming model for autocorrelated processes, in order to provide the\npredictive error distribution of the process and then to apply a univariate\nmodified EWMA control chart to the logarithm of the Bayes' factors of the\npredictive error density versus the target error density. The resulting chart\nis proposed as capable to deal with both the non-normality and the\nautocorrelation structure of the log Bayes' factors. The new control charting\nscheme is general in application and it has the advantage to control\nsimultaneously not only the process mean vector and the dispersion covariance\nmatrix, but also the entire target distribution of the process. Two examples of\nLondon metal exchange data and of production time series data illustrate the\ncapabilities of the new control chart.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 22:46:05 GMT"}], "update_date": "2008-02-05", "authors_parsed": [["Triantafyllopoulos", "K.", ""]]}, {"id": "0802.0219", "submitter": "Kostas Triantafyllopoulos", "authors": "K. Triantafyllopoulos", "title": "Dynamic generalized linear models for non-Gaussian time series\n  forecasting", "comments": "38 pages, 12 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": null, "abstract": "  The purpose of this paper is to provide a discussion, with illustrating\nexamples, on Bayesian forecasting for dynamic generalized linear models\n(DGLMs). Adopting approximate Bayesian analysis, based on conjugate forms and\non Bayes linear estimation, we describe the theoretical framework and then we\nprovide detailed examples of response distributions, including binomial,\nPoisson, negative binomial, geometric, normal, log-normal, gamma, exponential,\nWeibull, Pareto, beta, and inverse Gaussian. We give numerical illustrations\nfor all distributions (except for the normal). Putting together all the above\ndistributions, we give a unified Bayesian approach to non-Gaussian time series\nanalysis, with applications from finance and medicine to biology and the\nbehavioural sciences. Throughout the models we discuss Bayesian forecasting\nand, for each model, we derive the multi-step forecast mean. Finally, we\ndescribe model assessment using the likelihood function, and Bayesian model\nmonitoring.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 22:52:41 GMT"}], "update_date": "2008-02-05", "authors_parsed": [["Triantafyllopoulos", "K.", ""]]}, {"id": "0802.0220", "submitter": "Kostas Triantafyllopoulos", "authors": "K. Triantafyllopoulos", "title": "Forecasting with time-varying vector autoregressive models", "comments": "17 pages, 7 figures, tables 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.AP stat.ME", "license": null, "abstract": "  The purpose of this paper is to propose a time-varying vector autoregressive\nmodel (TV-VAR) for forecasting multivariate time series. The model is casted\ninto a state-space form that allows flexible description and analysis. The\nvolatility covariance matrix of the time series is modelled via inverted\nWishart and singular multivariate beta distributions allowing a fully conjugate\nBayesian inference. Model performance and model comparison is done via the\nlikelihood function, sequential Bayes factors, the mean of squared standardized\nforecast errors, the mean of absolute forecast errors (known also as mean\nabsolute deviation), and the mean forecast error. Bayes factors are also used\nin order to choose the autoregressive order of the model. Multi-step\nforecasting is discussed in detail and a flexible formula is proposed to\napproximate the forecast function. Two examples, consisting of bivariate data\nof IBM shares and of foreign exchange (FX) rates for 8 currencies, illustrate\nthe methods. For the IBM data we discuss model performance and multi-step\nforecasting in some detail. For the FX data we discuss sequential portfolio\nallocation; for both data sets our empirical findings suggest that the TV-VAR\nmodels outperform the widely used VAR models.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 22:58:24 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2008 12:00:10 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Triantafyllopoulos", "K.", ""]]}, {"id": "0802.0223", "submitter": "Kostas Triantafyllopoulos", "authors": "K. Triantafyllopoulos", "title": "Multivariate stochastic volatility using state space models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.AP stat.ME", "license": null, "abstract": "  A Bayesian procedure is developed for multivariate stochastic volatility,\nusing state space models. An autoregressive model for the log-returns is\nemployed. We generalize the inverted Wishart distribution to allow for\ndifferent correlation structure between the observation and state innovation\nvectors and we extend the convolution between the Wishart and the multivariate\nsingular beta distribution. A multiplicative model based on the generalized\ninverted Wishart and multivariate singular beta distributions is proposed for\nthe evolution of the volatility and a flexible sequential volatility updating\nis employed. The proposed algorithm for the volatility is fast and\ncomputationally cheap and it can be used for on-line forecasting. The methods\nare illustrated with an example consisting of foreign exchange rates data of 8\ncurrencies. The empirical results suggest that time-varying correlations can be\nestimated efficiently, even in situations of high dimensional data.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2008 23:34:43 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Triantafyllopoulos", "K.", ""]]}, {"id": "0802.0443", "submitter": "Mathieu Ribatet", "authors": "Bertrand Iooss (LCFR, - M\\'ethodes d'Analyse Stochastique des Codes et\n  Traitements Num\\'eriques), Mathieu Ribatet (UR HHLY), Amandine Marrel (LMTE)", "title": "Global Sensitivity Analysis of Stochastic Computer Models with joint\n  metamodels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global sensitivity analysis method, used to quantify the influence of\nuncertain input variables on the response variability of a numerical model, is\napplicable to deterministic computer code (for which the same set of input\nvariables gives always the same output value). This paper proposes a global\nsensitivity analysis methodology for stochastic computer code (having a\nvariability induced by some uncontrollable variables). The framework of the\njoint modeling of the mean and dispersion of heteroscedastic data is used. To\ndeal with the complexity of computer experiment outputs, non parametric joint\nmodels (based on Generalized Additive Models and Gaussian processes) are\ndiscussed. The relevance of these new models is analyzed in terms of the\nobtained variance-based sensitivity indices with two case studies. Results show\nthat the joint modeling approach leads accurate sensitivity index estimations\neven when clear heteroscedasticity is present.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2008 15:31:30 GMT"}, {"version": "v2", "created": "Tue, 13 Jan 2009 12:48:49 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2009 09:36:49 GMT"}], "update_date": "2009-06-08", "authors_parsed": [["Iooss", "Bertrand", "", "LCFR, - M\u00e9thodes d'Analyse Stochastique des Codes et\n  Traitements Num\u00e9riques"], ["Ribatet", "Mathieu", "", "UR HHLY"], ["Marrel", "Amandine", "", "LMTE"]]}, {"id": "0802.0450", "submitter": "Qingzhao Yu", "authors": "Qingzhao Yu, Bin Li, Richard Scribner, Deborah Cohen", "title": "Hierarchical Additive Modeling of Nonlinear Association with Spatial\n  Correlations-An Application to Relate Alcohol Outlet Density and Neighborhood\n  Assault Rates", "comments": "26 pages, 4 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous studies have suggested a link between alcohol outlets and assaultive\nviolence. In this paper, we explore the effects of alcohol availability on\nassault crimes at the census tract level over time. The statistical analysis is\nchallenged by several features of the data: (1) the effects of possible\ncovariates (for example, the alcohol outlet density of each census tract) on\nthe assaultive crime rates may be complex; (2) the covariates may be highly\ncorrelated with each other; (3) there are a lot of missing inputs in the data;\nand (4) spatial correlations exist in the outcome assaultive crime rates. We\npropose a hierarchical additive model, where the nonlinear correlations and the\ncomplex interaction effects are modeled using the multiple additive regression\ntrees (MART) and the spatial variances in the assaultive rates that cannot be\nexplained by the specified covariates are smoothed trough the Conditional\nAutoregressive (CAR) model. We develop a two-stage algorithm that connect the\nnon-parametric trees with CAR to look for important variables covariates\nassociated with the assaultive crime rates, while taking account of the spatial\ncorrelations among adjacent census tracts. The proposed methods are applied to\nthe Los Angeles assaultive data (1990-1999) and compared with traditional\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2008 15:56:31 GMT"}], "update_date": "2008-02-05", "authors_parsed": [["Yu", "Qingzhao", ""], ["Li", "Bin", ""], ["Scribner", "Richard", ""], ["Cohen", "Deborah", ""]]}, {"id": "0802.0523", "submitter": "Christopher Withers", "authors": "Christopher S. Withers and Saralees Nadarajah", "title": "The distribution of the maximum of a first order moving average: the\n  continuous case", "comments": "15 A4 pages. Version 4 corrects (3.8). Version 3 expands Section 2.\n  Version 2 corrected recurrence relation (2.5)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the distribution of $M_n$, the maximum of a sequence of $n$\nobservations from a moving average of order 1. Solutions are first given in\nterms of repeated integrals and then for the case where the underlying\nindependent random variables have an absolutely continuous density. When the\ncorrelation is positive, $$ P(M_n %\\max^n_{i=1} X_i \\leq x) =\\\n\\sum_{j=1}^\\infty \\beta_{jx} \\nu_{jx}^{n} \\approx B_{x} \\nu_{1x}^{n} $$ where\n%$\\{X_i\\}$ is a moving average of order 1 with positive correlation, and\n$\\{\\nu_{jx}\\}$ are the eigenvalues (singular values) of a Fredholm kernel and\n$\\nu_{1x}$ is the eigenvalue of maximum magnitude. A similar result is given\nwhen the correlation is negative. The result is analogous to large deviations\nexpansions for estimates, since the maximum need not be standardized to have a\nlimit. % there are more terms, and $$P(M_n <x) \\approx B'_{x}\\\n(1+\\nu_{1x})^n.$$\n  For the continuous case the integral equations for the left and right\neigenfunctions are converted to first order linear differential equations. The\neigenvalues satisfy an equation of the form $$\\sum_{i=1}^\\infty\nw_i(\\lambda-\\theta_i)^{-1}=\\lambda-\\theta_0$$ for certain known weights\n$\\{w_i\\}$ and eigenvalues $\\{\\theta_i\\}$ of a given matrix. This can be solved\nby truncating the sum to an increasing number of terms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2008 22:13:18 GMT"}, {"version": "v2", "created": "Fri, 23 Jan 2009 00:21:33 GMT"}, {"version": "v3", "created": "Tue, 3 Feb 2009 00:25:57 GMT"}, {"version": "v4", "created": "Tue, 1 Sep 2009 03:43:04 GMT"}, {"version": "v5", "created": "Mon, 7 Sep 2009 02:28:36 GMT"}], "update_date": "2009-09-07", "authors_parsed": [["Withers", "Christopher S.", ""], ["Nadarajah", "Saralees", ""]]}, {"id": "0802.0529", "submitter": "Christopher Withers", "authors": "Christopher S. Withers and Saralees Nadarajah", "title": "The distribution of the maximum of a first order moving average: the\n  discrete case", "comments": "13 pages. This version gives full solutions to the examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give the distribution of $M_n$, the maximum of a sequence of $n$\nobservations from a moving average of order 1. Solutions are first given in\nterms of repeated integrals and then for the case where the underlying\nindependent random variables are discrete. When the correlation is positive, $$\nP(M_n \\max^n_{i=1} X_i \\leq x) = \\sum_{j=1}^\\infty \\beta_{jx} \\nu_{jx}^{n}\n\\approx B_{x} r{1x}^{n} $$ where $\\{\\nu_{jx}\\}$ are the eigenvalues of a\ncertain matrix, $r_{1x}$ is the maximum magnitude of the eigenvalues, and $I$\ndepends on the number of possible values of the underlying random variables.\nThe eigenvalues do not depend on $x$ only on its range.\n", "versions": [{"version": "v1", "created": "Mon, 4 Feb 2008 22:47:43 GMT"}, {"version": "v2", "created": "Mon, 9 Mar 2009 00:30:01 GMT"}, {"version": "v3", "created": "Mon, 6 Apr 2009 04:18:07 GMT"}], "update_date": "2009-04-06", "authors_parsed": [["Withers", "Christopher S.", ""], ["Nadarajah", "Saralees", ""]]}, {"id": "0802.0557", "submitter": "Allan R. Sampson", "authors": "Allan R. Sampson", "title": "A Conversation with Ingram Olkin", "comments": "Published in at http://dx.doi.org/10.1214/088342307000000122 the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 3, 450-475", "doi": "10.1214/088342307000000122", "report-no": "IMS-STS-STS231", "categories": "stat.ME", "license": null, "abstract": "  Ingram Olkin was born on July 23, 1924 in Waterbury, Connecticut. His family\nmoved to New York in 1934 and he graduated from DeWitt Clinton High School in\n1941. He served three years in the Air Force during World War II and obtained a\nB.S. in mathematics at the City College of New York in 1947. After receiving an\nM.A. in mathematical statistics from Columbia in 1949, he completed his\ngraduate studies in the Department of Statistics at the University of North\nCarolina in 1951. His dissertation was written under the direction of S. N. Roy\nand Harold Hotelling. He joined the Department of Mathematics at Michigan State\nUniversity in 1951 as an Assistant Professor, subsequently being promoted to\nProfessor. In 1960, he took a position as Chair of the Department of Statistics\nat the University of Minnesota. He moved to Stanford University in 1961 to take\na joint position as Professor of Statistics and Professor of Education; he was\nalso Chair of the Department of Statistics from 1973--1976. In 2007, Ingram\nbecame Professor Emeritus. Ingram was Editor of the Annals of Mathematical\nStatistics (1971--1972) and served as the first editor of the Annals of\nStatistics from 1972--1974. He was a primary force in the founding of the\nJournal of Educational Statistics, for which he was also Associate Editor\nduring 1977--1985. In 1984, he was President of the Institute of Mathematical\nStatistics. Among his many professional activities, he has served as Chair of\nthe Committee of Presidents of Statistical Societies (COPSS), Chair of the\nCommittee on Applied and Theoretical Statistics of the National Research\nCouncil, Chair of the Management Board of the American Education Research\nAssociation, and as Trustee for the National Institute of Statistical Sciences.\nHe has been honored by the American Statistical Association (ASA) with a Wilks\nMedal (1992) and a Founder's Award (1992). The American Psychological\nAssociation gave him a Lifetime Contribution Award (1997) and he was elected to\nthe National Academy of Education in 2005. He received the COPSS Elizabeth L.\nScott Award in 1998 and delivered the R. A. Fisher Lecture in 2000. In 2003,\nthe City University of New York gave him a Townsend Harris Medal. An author of\n5 books, an editor of 10 books, and an author of more than 200 publications,\nIngram has made major contributions to statistics and education. His research\nhas focused on multivariate analysis, majorization and inequalities,\ndistribution theory, and meta-analysis. A volume in celebration of Ingram's\n65th birthday contains a brief biography and an interview [Gleser, Perlman,\nPress and Sampson (1989)]. Ingram was chosen in 1997 to participate in the\nAmerican Statistical Association Distinguished Statistician Video Series and a\nvideotaped conversation and a lecture (Olkin, 1997) are available from the ASA\n(1997, DS041, DS042).\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2008 09:12:43 GMT"}], "update_date": "2008-02-08", "authors_parsed": [["Sampson", "Allan R.", ""]]}, {"id": "0802.0615", "submitter": "Elvan Ceyhan", "authors": "E. Ceyhan, C. E. Priebe, D. J. Marchette", "title": "A New Family of Random Graphs for Testing Spatial Segregation", "comments": "31 pages, 15 figures", "journal-ref": "Canadian Journal of Statistics (2007), 35(1):27-50", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a graph-based approach for testing spatial point patterns. This\napproach falls under the category of data-random graphs, which have been\nintroduced and used for statistical pattern recognition in recent years. Our\ngoal is to test complete spatial randomness against segregation and association\nbetween two or more classes of points. To attain this goal, we use a particular\ntype of parametrized random digraph called proximity catch digraph (PCD) which\nis based based on relative positions of the data points from various classes.\nThe statistic we employ is the relative density of the PCD. When scaled\nproperly, the relative density of the PCD is a $U$-statistic. We derive the\nasymptotic distribution of the relative density, using the standard central\nlimit theory of $U$-statistics. The finite sample performance of the test\nstatistic is evaluated by Monte Carlo simulations, and the asymptotic\nperformance is assessed via Pitman's asymptotic efficiency, thereby yielding\nthe optimal parameters for testing. Furthermore, the methodology discussed in\nthis article is also valid for data in multiple dimensions.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2008 13:34:46 GMT"}], "update_date": "2008-02-06", "authors_parsed": [["Ceyhan", "E.", ""], ["Priebe", "C. E.", ""], ["Marchette", "D. J.", ""]]}, {"id": "0802.0622", "submitter": "Elvan Ceyhan", "authors": "E. Ceyhan, C. E. Priebe, J. C.Wierman", "title": "Relative Density of the Random $r$-Factor Proximity Catch Digraph for\n  Testing Spatial Patterns of Segregation and Association", "comments": "29 pages, 21 figures", "journal-ref": "Computational Statistics & Data Analysis (2006), 50(8):1925-1964", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical pattern classification methods based on data-random graphs were\nintroduced recently. In this approach, a random directed graph is constructed\nfrom the data using the relative positions of the data points from various\nclasses. Different random graphs result from different definitions of the\nproximity region associated with each data point and different graph statistics\ncan be employed for data reduction. The approach used in this article is based\non a parameterized family of proximity maps determining an associated family of\ndata-random digraphs. The relative arc density of the digraph is used as the\nsummary statistic, providing an alternative to the domination number employed\npreviously. An important advantage of the relative arc density is that,\nproperly re-scaled, it is a $U$-statistic, facilitating analytic study of its\nasymptotic distribution using standard $U$-statistic central limit theory. The\napproach is illustrated with an application to the testing of spatial patterns\nof segregation and association. Knowledge of the asymptotic distribution allows\nevaluation of the Pitman and Hodges-Lehmann asymptotic efficacies, and\nselection of the proximity map parameter to optimize efficiency. Furthermore\nthe approach presented here also has the advantage of validity for data in any\ndimension.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2008 14:17:29 GMT"}], "update_date": "2008-02-06", "authors_parsed": [["Ceyhan", "E.", ""], ["Priebe", "C. E.", ""], ["Wierman", "J. C.", ""]]}, {"id": "0802.0638", "submitter": "Elvan Ceyhan", "authors": "E. Ceyhan, C. E. Priebe", "title": "The Use of Domination Number of a Random Proximity Catch Digraph for\n  Testing Spatial Patterns of Segregation and Association", "comments": "13 pages, 7 figures", "journal-ref": "Statistics & Probability Letters (2005), 73, 37-50", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Priebe et al. (2001) introduced the class cover catch digraphs and computed\nthe distribution of the domination number of such digraphs for one dimensional\ndata. In higher dimensions these calculations are extremely difficult due to\nthe geometry of the proximity regions; and only upper-bounds are available. In\nthis article, we introduce a new type of data-random proximity map and the\nassociated (di)graph in $\\mathbb R^d$. We find the asymptotic distribution of\nthe domination number and use it for testing spatial point patterns of\nsegregation and association.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2008 15:22:56 GMT"}], "update_date": "2008-02-06", "authors_parsed": [["Ceyhan", "E.", ""], ["Priebe", "C. E.", ""]]}, {"id": "0802.0743", "submitter": "M. J. Bayarri", "authors": "M. J. Bayarri, M. E. Castellanos", "title": "Bayesian Checking of the Second Levels of Hierarchical Models", "comments": "This paper commented in: [arXiv:0802.0746], [arXiv:0802.0747],\n  [arXiv:0802.0749], [arXiv:0802.0752]. Rejoinder in [arXiv:0802.0754].\n  Published in at http://dx.doi.org/10.1214/07-STS235 the Statistical Science\n  (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 3, 322-343", "doi": "10.1214/07-STS235", "report-no": "IMS-STS-STS235", "categories": "stat.ME", "license": null, "abstract": "  Hierarchical models are increasingly used in many applications. Along with\nthis increased use comes a desire to investigate whether the model is\ncompatible with the observed data. Bayesian methods are well suited to\neliminate the many (nuisance) parameters in these complicated models; in this\npaper we investigate Bayesian methods for model checking. Since we contemplate\nmodel checking as a preliminary, exploratory analysis, we concentrate on\nobjective Bayesian methods in which careful specification of an informative\nprior distribution is avoided. Numerous examples are given and different\nproposals are investigated and critically compared.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 08:31:37 GMT"}], "update_date": "2008-02-08", "authors_parsed": [["Bayarri", "M. J.", ""], ["Castellanos", "M. E.", ""]]}, {"id": "0802.0746", "submitter": "M. Evans", "authors": "M. Evans", "title": "Comment: Bayesian Checking of the Second Levels of Hierarchical Models", "comments": "Published in at http://dx.doi.org/10.1214/07-STS235C the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 3, 344-348", "doi": "10.1214/07-STS235C", "report-no": "IMS-STS-STS235C", "categories": "stat.ME", "license": null, "abstract": "  We discuss the methods of Evans and Moshonov [Bayesian Analysis 1 (2006)\n893--914, Bayesian Statistics and Its Applications (2007) 145--159] concerning\nchecking for prior-data conflict and their relevance to the method proposed in\nthis paper. [arXiv:0802.0743]\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 07:23:14 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Evans", "M.", ""]]}, {"id": "0802.0747", "submitter": "Andrew Gelman", "authors": "Andrew Gelman", "title": "Comment: Bayesian Checking of the Second Levels of Hierarchical Models", "comments": "Published in at http://dx.doi.org/10.1214/07-STS235A the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 3, 349-352", "doi": "10.1214/07-STS235A", "report-no": "IMS-STS-STS235A", "categories": "stat.ME", "license": null, "abstract": "  Comment: Bayesian Checking of the Second Levels of Hierarchical Models\n[arXiv:0802.0743]\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 07:31:54 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Gelman", "Andrew", ""]]}, {"id": "0802.0749", "submitter": "Valen E. Johnson", "authors": "Valen E. Johnson", "title": "Comment: Bayesian Checking of the Second Levels of Hierarchical Models", "comments": "Published in at http://dx.doi.org/10.1214/07-STS235D the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 3, 353-358", "doi": "10.1214/07-STS235D", "report-no": "IMS-STS-STS235D", "categories": "stat.ME", "license": null, "abstract": "  Comment: Bayesian Checking of the Second Levels of Hierarchical Models\n[arXiv:0802.0743]\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 07:38:22 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Johnson", "Valen E.", ""]]}, {"id": "0802.0752", "submitter": "Michael D. Larsen", "authors": "Michael D. Larsen, Lu Lu", "title": "Comment: Bayesian Checking of the Second Level of Hierarchical Models:\n  Cross-Validated Posterior Predictive Checks Using Discrepancy Measures", "comments": "Published in at http://dx.doi.org/10.1214/07-STS235B the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 3, 359-362", "doi": "10.1214/07-STS235B", "report-no": "IMS-STS-STS235B", "categories": "stat.ME", "license": null, "abstract": "  Comment: Bayesian Checking of the Second Level of Hierarchical Models\n[arXiv:0802.0743]\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 08:07:49 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Larsen", "Michael D.", ""], ["Lu", "Lu", ""]]}, {"id": "0802.0754", "submitter": "M. J. Bayarri", "authors": "M. J. Bayarri, M. E. Castellanos", "title": "Rejoinder: Bayesian Checking of the Second Levels of Hierarchical Models", "comments": "Published in at http://dx.doi.org/10.1214/07-STS235REJ the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 3, 363-367", "doi": "10.1214/07-STS235REJ", "report-no": "IMS-STS-STS235REJ", "categories": "stat.ME", "license": null, "abstract": "  Rejoinder: Bayesian Checking of the Second Levels of Hierarchical Models\n[arXiv:0802.0743]\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 08:21:31 GMT"}], "update_date": "2008-02-08", "authors_parsed": [["Bayarri", "M. J.", ""], ["Castellanos", "M. E.", ""]]}, {"id": "0802.0793", "submitter": "Xavier Bry", "authors": "Xavier Bry (I3M), Thomas Verron (CEFE), Pierre Cazes (CEREMADE)", "title": "A multiple covariance approach to PLS regression with several predictor\n  groups: Structural Equation Exploratory Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": null, "abstract": "  A variable group Y is assumed to depend upon R thematic variable groups X 1,\n>..., X R . We assume that components in Y depend linearly upon components in\nthe Xr's. In this work, we propose a multiple covariance criterion which\nextends that of PLS regression to this multiple predictor groups situation. On\nthis criterion, we build a PLS-type exploratory method - Structural Equation\nExploratory Regression (SEER) - that allows to simultaneously perform dimension\nreduction in groups and investigate the linear model of the components. SEER\nuses the multidimensional structure of each group. An application example is\ngiven.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 13:40:03 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2008 09:00:04 GMT"}], "update_date": "2008-02-12", "authors_parsed": [["Bry", "Xavier", "", "I3M"], ["Verron", "Thomas", "", "CEFE"], ["Cazes", "Pierre", "", "CEREMADE"]]}, {"id": "0802.0794", "submitter": "Xavier Bry", "authors": "Xavier Bry (I3M), Thomas Verron (CEFE)", "title": "Mod\\'elisation factorielle des interactions entre deux ensembles\n  d'observations : la m\\'ethode PLS-FILM (Partial Least Squares Factor\n  Interaction Linear Modelling)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": null, "abstract": "  In this work, we consider a data array encoding interactions between two sets\nof observations respectively referred to as \"subjects\" and \"objects\". Besides,\ndescriptions of subjects and objects are available through two variable sets.\nWe propose a geometrically grounded exploratory technique to analyze the\ninteractions using descriptions of subjects and objects: interactions are\nmodelled using a hierarchy of subject-factors and object-factors built up from\nthese descriptions. Our method bridges the gap between those of Chessel (RLQ\nanalysis) and Martens (L-PLS), although it only has rank 1 components in common\nwith them.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 13:40:42 GMT"}], "update_date": "2008-02-07", "authors_parsed": [["Bry", "Xavier", "", "I3M"], ["Verron", "Thomas", "", "CEFE"]]}, {"id": "0802.0837", "submitter": "Sylvain Arlot", "authors": "Sylvain Arlot (LM-Orsay, INRIA Futurs), Pascal Massart (LM-Orsay,\n  INRIA Futurs)", "title": "Data-driven calibration of penalties for least-squares regression", "comments": null, "journal-ref": "Journal of Machine Learning Research 10 (2009) 245-279", "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalization procedures often suffer from their dependence on multiplying\nfactors, whose optimal values are either unknown or hard to estimate from the\ndata. We propose a completely data-driven calibration algorithm for this\nparameter in the least-squares regression framework, without assuming a\nparticular shape for the penalty. Our algorithm relies on the concept of\nminimal penalty, recently introduced by Birge and Massart (2007) in the context\nof penalized least squares for Gaussian homoscedastic regression. On the\npositive side, the minimal penalty can be evaluated from the data themselves,\nleading to a data-driven estimation of an optimal penalty which can be used in\npractice; on the negative side, their approach heavily relies on the\nhomoscedastic Gaussian nature of their stochastic framework. The purpose of\nthis paper is twofold: stating a more general heuristics for designing a\ndata-driven penalty (the slope heuristics) and proving that it works for\npenalized least-squares regression with a random design, even for\nheteroscedastic non-Gaussian data. For technical reasons, some exact\nmathematical results will be proved only for regressogram bin-width selection.\nThis is at least a first step towards further results, since the approach and\nthe method that we use are indeed general.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2008 16:42:13 GMT"}, {"version": "v2", "created": "Thu, 20 Mar 2008 07:29:39 GMT"}, {"version": "v3", "created": "Fri, 19 Sep 2008 08:38:49 GMT"}, {"version": "v4", "created": "Wed, 17 Dec 2008 09:21:55 GMT"}], "update_date": "2010-07-02", "authors_parsed": [["Arlot", "Sylvain", "", "LM-Orsay, INRIA Futurs"], ["Massart", "Pascal", "", "LM-Orsay,\n  INRIA Futurs"]]}, {"id": "0802.0964", "submitter": "Tim Hesterberg", "authors": "Tim Hesterberg, Nam Hee Choi, Lukas Meier, Chris Fraley", "title": "Least angle and $\\ell_1$ penalized regression: A review", "comments": "Published in at http://dx.doi.org/10.1214/08-SS035 the Statistics\n  Surveys (http://www.i-journals.org/ss/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistics Surveys 2008, Vol. 2, 61-93", "doi": "10.1214/08-SS035", "report-no": "IMS-SS-SS_2008_35", "categories": "stat.ME stat.ML", "license": null, "abstract": "  Least Angle Regression is a promising technique for variable selection\napplications, offering a nice alternative to stepwise regression. It provides\nan explanation for the similar behavior of LASSO ($\\ell_1$-penalized\nregression) and forward stagewise regression, and provides a fast\nimplementation of both. The idea has caught on rapidly, and sparked a great\ndeal of research interest. In this paper, we give an overview of Least Angle\nRegression and the current state of related research.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2008 12:53:59 GMT"}, {"version": "v2", "created": "Wed, 21 May 2008 06:40:12 GMT"}], "update_date": "2008-05-21", "authors_parsed": [["Hesterberg", "Tim", ""], ["Choi", "Nam Hee", ""], ["Meier", "Lukas", ""], ["Fraley", "Chris", ""]]}, {"id": "0802.1008", "submitter": "Bertrand Iooss", "authors": "Amandine Marrel (LMTE), Bertrand Iooss (LCFR), Beatrice Laurent (IMT),\n  Olivier Roustant", "title": "Calculations of Sobol indices for the Gaussian process metamodel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": null, "abstract": "  Global sensitivity analysis of complex numerical models can be performed by\ncalculating variance-based importance measures of the input variables, such as\nthe Sobol indices. However, these techniques, requiring a large number of model\nevaluations, are often unacceptable for time expensive computer codes. A well\nknown and widely used decision consists in replacing the computer code by a\nmetamodel, predicting the model responses with a negligible computation time\nand rending straightforward the estimation of Sobol indices. In this paper, we\ndiscuss about the Gaussian process model which gives analytical expressions of\nSobol indices. Two approaches are studied to compute the Sobol indices: the\nfirst based on the predictor of the Gaussian process model and the second based\non the global stochastic process model. Comparisons between the two estimates,\nmade on analytical examples, show the superiority of the second approach in\nterms of convergence and robustness. Moreover, the second approach allows to\nintegrate the modeling error of the Gaussian process model by directly giving\nsome confidence intervals on the Sobol indices. These techniques are finally\napplied to a real case of hydrogeological modeling.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2008 15:31:17 GMT"}], "update_date": "2008-02-08", "authors_parsed": [["Marrel", "Amandine", "", "LMTE"], ["Iooss", "Bertrand", "", "LCFR"], ["Laurent", "Beatrice", "", "IMT"], ["Roustant", "Olivier", ""]]}, {"id": "0802.1669", "submitter": "Nicholas Chia", "authors": "Nicholas Chia and Junji Nakano", "title": "M-decomposability, elliptical unimodal densities, and applications to\n  clustering and kernel density estimation", "comments": "30 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chia and Nakano (2009) introduced the concept of M-decomposability of\nprobability densities in one-dimension. In this paper, we generalize\nM-decomposability to any dimension. We prove that all elliptical unimodal\ndensities are M-undecomposable. We also derive an inequality to show that it is\nbetter to represent an M-decomposable density via a mixture of unimodal\ndensities. Finally, we demonstrate the application of M-decomposability to\nclustering and kernel density estimation, using real and simulated data. Our\nresults show that M-decomposability can be used as a non-parametric criterion\nto locate modes in probability densities.\n", "versions": [{"version": "v1", "created": "Tue, 12 Feb 2008 16:41:30 GMT"}, {"version": "v2", "created": "Wed, 21 Apr 2010 12:40:03 GMT"}], "update_date": "2010-04-22", "authors_parsed": [["Chia", "Nicholas", ""], ["Nakano", "Junji", ""]]}, {"id": "0802.2050", "submitter": "Kevin Carter", "authors": "Kevin M. Carter, Raviv Raich, William G. Finn, and Alfred O. Hero", "title": "FINE: Fisher Information Non-parametric Embedding", "comments": "30 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problems of clustering, classification, and visualization of\nhigh-dimensional data when no straightforward Euclidean representation exists.\nTypically, these tasks are performed by first reducing the high-dimensional\ndata to some lower dimensional Euclidean space, as many manifold learning\nmethods have been developed for this task. In many practical problems however,\nthe assumption of a Euclidean manifold cannot be justified. In these cases, a\nmore appropriate assumption would be that the data lies on a statistical\nmanifold, or a manifold of probability density functions (PDFs). In this paper\nwe propose using the properties of information geometry in order to define\nsimilarities between data sets using the Fisher information metric. We will\nshow this metric can be approximated using entirely non-parametric methods, as\nthe parameterization of the manifold is generally unknown. Furthermore, by\nusing multi-dimensional scaling methods, we are able to embed the corresponding\nPDFs into a low-dimensional Euclidean space. This not only allows for\nclassification of the data, but also visualization of the manifold. As a whole,\nwe refer to our framework as Fisher Information Non-parametric Embedding\n(FINE), and illustrate its uses on a variety of practical problems, including\nbio-medical applications and document classification.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2008 16:40:17 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Carter", "Kevin M.", ""], ["Raich", "Raviv", ""], ["Finn", "William G.", ""], ["Hero", "Alfred O.", ""]]}, {"id": "0802.2087", "submitter": "Andries Lenstra", "authors": "Chris A.J. Klaassen, Andries J. Lenstra", "title": "Why stratification may hurt, & how much", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are circumstances under which stratified sampling is worse than simple\nrandom sampling, even if the allocation of the sample sizes is optimal. This\nphenomenon was discovered more than sixty years ago, but is not as widely known\nas one might expect. We provide it with lower and upper bounds for its badness\nas well as with an explanation.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2008 19:35:42 GMT"}], "update_date": "2008-02-15", "authors_parsed": [["Klaassen", "Chris A. J.", ""], ["Lenstra", "Andries J.", ""]]}, {"id": "0802.2155", "submitter": "Tewfik Kernane", "authors": "Ahmed Guellil (USTHB), Tewfik Kernane (USTHB)", "title": "A New Approach of Point Estimation from Truncated or Grouped and\n  Censored Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new approach for estimating the parameters of a probability\ndistribution. It consists on combining two new methods of estimation. The first\nis based on the definition of a new distance measuring the difference between\nvariations of two distributions on a finite number of points from their support\nand on using this measure for estimation purposes by the method of minimum\ndistance. For the second method, given an empirical discrete distribution, we\nbuild up an auxiliary discrete theoretical distribution having the same support\nof the first and depending on the same parameters of the parent distribution of\nthe data from which the empirical distribution emanated. We estimate then the\nparameters from the empirical distribution by the usual statistical methods. In\npractice, we propose to compute the two estimations, the second based on\nmaximum likelihood principle of known theoretical properties, and the first\nbeing as a control of the effectiveness of the obtained estimation, and for\nwhich we prove the convergence in probability, so we have also a criterion on\nthe quality of the information contained in the observations. We apply the\napproach to truncated or grouped and censored data situations to give the\nflavour on the effectiveness of the approach. We give also some interesting\nperspectives of the approach including model selection from truncated data,\nestimation of the initial trial value in the celebrate EM algorithm in the case\nof truncation and merged normal populations, a test of goodness of fit based on\nthe new distance, quality of estimations and data.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2008 09:03:10 GMT"}, {"version": "v2", "created": "Mon, 29 Dec 2008 07:30:30 GMT"}], "update_date": "2008-12-30", "authors_parsed": [["Guellil", "Ahmed", "", "USTHB"], ["Kernane", "Tewfik", "", "USTHB"]]}, {"id": "0802.2377", "submitter": "Sofia Olhede Professor", "authors": "J. M. Lilly and S. C. Olhede", "title": "Higher-Order Properties of Analytic Wavelets", "comments": "15 pages, 6 Postscript figures", "journal-ref": "Lilly, J. M., and S. C. Olhede, (2009). Higher-order properties of\n  analytic wavelets. IEEE Transactions on Signal Processing, 57 (1), 146--160", "doi": "10.1109/TSP.2008.2007607", "report-no": "Research Report 289", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The influence of higher-order wavelet properties on the analytic wavelet\ntransform behavior is investigated, and wavelet functions offering advantageous\nperformance are identified. This is accomplished through detailed investigation\nof the generalized Morse wavelets, a two-parameter family of exactly analytic\ncontinuous wavelets. The degree of time/frequency localization, the existence\nof a mapping between scale and frequency, and the bias involved in estimating\nproperties of modulated oscillatory signals, are proposed as important\nconsiderations. Wavelet behavior is found to be strongly impacted by the degree\nof asymmetry of the wavelet in both the frequency and the time domain, as\nquantified by the third central moments. A particular subset of the generalized\nMorse wavelets, recognized as deriving from an inhomogeneous Airy function,\nemerge as having particularly desirable properties. These \"Airy wavelets\"\nsubstantially outperform the only approximately analytic Morlet wavelets for\nhigh time localization. Special cases of the generalized Morse wavelets are\nexamined, revealing a broad range of behaviors which can be matched to the\ncharacteristics of a signal.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2008 12:07:38 GMT"}, {"version": "v2", "created": "Sun, 15 Feb 2009 09:32:33 GMT"}], "update_date": "2011-10-18", "authors_parsed": [["Lilly", "J. M.", ""], ["Olhede", "S. C.", ""]]}, {"id": "0802.2426", "submitter": "Bertrand Iooss", "authors": "Claire Cannamela, Josselin Garnier, Bertrand Iooss", "title": "Controlled stratification for quantile estimation", "comments": "Published in at http://dx.doi.org/10.1214/08-AOAS186 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2008, Vol. 2, No. 4, 1554-1580", "doi": "10.1214/08-AOAS186", "report-no": "IMS-AOAS-AOAS186", "categories": "stat.ME math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose and discuss variance reduction techniques for the\nestimation of quantiles of the output of a complex model with random input\nparameters. These techniques are based on the use of a reduced model, such as a\nmetamodel or a response surface. The reduced model can be used as a control\nvariate; or a rejection method can be implemented to sample the realizations of\nthe input parameters in prescribed relevant strata; or the reduced model can be\nused to determine a good biased distribution of the input parameters for the\nimplementation of an importance sampling strategy. The different strategies are\nanalyzed and the asymptotic variances are computed, which shows the benefit of\nan adaptive controlled stratification method. This method is finally applied to\na real example (computation of the peak cladding temperature during a\nlarge-break loss of coolant accident in a nuclear reactor).\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2008 07:19:52 GMT"}, {"version": "v2", "created": "Tue, 27 Jan 2009 12:56:56 GMT"}], "update_date": "2009-01-27", "authors_parsed": [["Cannamela", "Claire", ""], ["Garnier", "Josselin", ""], ["Iooss", "Bertrand", ""]]}, {"id": "0802.2581", "submitter": "Hisayuki Hara", "authors": "Hisayuki Hara and Akimichi Takemura", "title": "A Localization Approach to Improve Iterative Proportional Scaling in\n  Gaussian Graphical Models", "comments": "12 pages", "journal-ref": "Communications in Statistics Theory and Methods, 39, No.8,\n  1643-1654, 2010", "doi": "10.1080/03610920802238662", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss an efficient implementation of the iterative proportional scaling\nprocedure in the multivariate Gaussian graphical models. We show that the\ncomputational cost can be reduced by localization of the update procedure in\neach iterative step by using the structure of a decomposable model obtained by\ntriangulation of the graph associated with the model. Some numerical\nexperiments demonstrate the competitive performance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2008 03:00:55 GMT"}, {"version": "v2", "created": "Wed, 28 May 2008 01:07:24 GMT"}], "update_date": "2010-07-22", "authors_parsed": [["Hara", "Hisayuki", ""], ["Takemura", "Akimichi", ""]]}, {"id": "0802.2603", "submitter": "Hisayuki Hara", "authors": "Hisayuki Hara, Akimichi Takemura and Ruriko Yoshida", "title": "A Markov Basis for Conditional Test of Common Diagonal Effect in\n  Quasi-Independence Model for Square Contingency Tables", "comments": "15 pages", "journal-ref": "Comput. Statist. Data Anal. (2009), 53, 1006-1014", "doi": "10.1016/j.csda.2008.11.030", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In two-way contingency tables we sometimes find that frequencies along the\ndiagonal cells are relatively larger(or smaller) compared to off-diagonal\ncells, particularly in square tables with the common categories for the rows\nand the columns. In this case the quasi-independence model with an additional\nparameter for each of the diagonal cells is usually fitted to the data. A\nsimpler model than the quasi-independence model is to assume a common\nadditional parameter for all the diagonal cells. We consider testing the\ngoodness of fit of the common diagonal effect by Markov chain Monte Carlo\n(MCMC) method. We derive an explicit form of a Markov basis for performing the\nconditional test of the common diagonal effect. Once a Markov basis is given,\nMCMC procedure can be easily implemented by techniques of algebraic statistics.\nWe illustrate the procedure with some real data sets.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2008 07:36:20 GMT"}, {"version": "v2", "created": "Tue, 22 Jul 2008 05:00:49 GMT"}], "update_date": "2009-01-29", "authors_parsed": [["Hara", "Hisayuki", ""], ["Takemura", "Akimichi", ""], ["Yoshida", "Ruriko", ""]]}, {"id": "0802.2643", "submitter": "Gloria Mateu-Figueras", "authors": "G. Mateu-Figueras, V. Pawlowsky-Glahn, J.J. Egozcue", "title": "The normal distribution in some constrained sample spaces", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phenomena with a constrained sample space appear frequently in practice. This\nis the case e.g. with strictly positive data and with compositional data, like\npercentages and the like. If the natural measure of difference is not the\nabsolute one, it is possible to use simple algebraic properties to show that it\nis more convenient to work with a geometry that is not the usual Euclidean\ngeometry in real space, and with a measure which is not the usual Lebesgue\nmeasure, leading to alternative models which better fit the phenomenon under\nstudy. The general approach is presented and illustrated both on the positive\nreal line and on the D-part simplex.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2008 12:30:04 GMT"}], "update_date": "2008-02-20", "authors_parsed": [["Mateu-Figueras", "G.", ""], ["Pawlowsky-Glahn", "V.", ""], ["Egozcue", "J. J.", ""]]}, {"id": "0802.2959", "submitter": "Keyur Desai", "authors": "Keyur Desai, J.R. Deller, Jr. and J. Justin McCormick", "title": "Tellipsoid: Exploiting inter-gene correlation for improved detection of\n  differential gene expression", "comments": "19 pages, Submitted to Bioinformatics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivation: Algorithms for differential analysis of microarray data are vital\nto modern biomedical research. Their accuracy strongly depends on effective\ntreatment of inter-gene correlation. Correlation is ordinarily accounted for in\nterms of its effect on significance cut-offs. In this paper it is shown that\ncorrelation can, in fact, be exploited {to share information across tests},\nwhich, in turn, can increase statistical power.\n  Results: Vastly and demonstrably improved differential analysis approaches\nare the result of combining identifiability (the fact that in most microarray\ndata sets, a large proportion of genes can be identified a priori as\nnon-differential) with optimization criteria that incorporate correlation. As a\nspecial case, we develop a method which builds upon the widely used two-sample\nt-statistic based approach and uses the Mahalanobis distance as an optimality\ncriterion. Results on the prostate cancer data of Singh et al. (2002) suggest\nthat the proposed method outperforms all published approaches in terms of\nstatistical power.\n  Availability: The proposed algorithm is implemented in MATLAB and in R. The\nsoftware, called Tellipsoid, and relevant data sets are available at\nhttp://www.egr.msu.edu/~desaikey\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2008 02:10:10 GMT"}], "update_date": "2012-08-27", "authors_parsed": [["Desai", "Keyur", ""], ["Deller,", "J. R.", "Jr."], ["McCormick", "J. Justin", ""]]}, {"id": "0802.3143", "submitter": "Joseph Rynkiewicz", "authors": "Joseph Rynkiewicz (CES, Samos)", "title": "Estimation of linear autoregressive models with Markov-switching, the\n  E.M. algorithm revisited", "comments": null, "journal-ref": "INVESTIGACI\\'ON OPERACIONAL 25, 2 (2004) 166-173", "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": null, "abstract": "  This work concerns estimation of linear autoregressive models with\nMarkov-switching using expectation maximisation (E.M.) algorithm. Our method\ngeneralise the method introduced by Elliot for general hidden Markov models and\navoid to use backward recursion.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2008 15:55:06 GMT"}], "update_date": "2008-02-22", "authors_parsed": [["Rynkiewicz", "Joseph", "", "CES, Samos"]]}, {"id": "0802.3276", "submitter": "Lutz D\\\"umbgen", "authors": "Angelika Rohde and Lutz Duembgen", "title": "Adaptive Confidence Sets for the Optimal Approximating Model", "comments": null, "journal-ref": null, "doi": null, "report-no": "Technical report 73, IMSV, University of Bern", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the setting of high-dimensional linear models with Gaussian noise, we\ninvestigate the possibility of confidence statements connected to model\nselection. Although there exist numerous procedures for adaptive point\nestimation, the construction of adaptive confidence regions is severely limited\n(cf. Li, 1989). The present paper sheds new light on this gap. We develop exact\nand adaptive confidence sets for the best approximating model in terms of risk.\nOne of our constructions is based on a multiscale procedure and a particular\ncoupling argument. Utilizing exponential inequalities for noncentral\nchi-squared distributions, we show that the risk and quadratic loss of all\nmodels within our confidence region are uniformly bounded by the minimal risk\ntimes a factor close to one.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2008 09:44:37 GMT"}, {"version": "v2", "created": "Tue, 3 Jun 2008 11:40:43 GMT"}, {"version": "v3", "created": "Wed, 7 Oct 2009 08:21:04 GMT"}], "update_date": "2009-10-07", "authors_parsed": [["Rohde", "Angelika", ""], ["Duembgen", "Lutz", ""]]}, {"id": "0802.3364", "submitter": "Hannes Leeb", "authors": "Hannes Leeb", "title": "Evaluation and selection of models for out-of-sample prediction when the\n  sample size is small relative to the complexity of the data-generating\n  process", "comments": "Published in at http://dx.doi.org/10.3150/08-BEJ127 the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2008, Vol. 14, No. 3, 661-690", "doi": "10.3150/08-BEJ127", "report-no": "IMS-BEJ-BEJ127", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression with random design, we study the problem of selecting a model\nthat performs well for out-of-sample prediction. We do not assume that any of\nthe candidate models under consideration are correct. Our analysis is based on\nexplicit finite-sample results. Our main findings differ from those of other\nanalyses that are based on traditional large-sample limit approximations\nbecause we consider a situation where the sample size is small relative to the\ncomplexity of the data-generating process, in the sense that the number of\nparameters in a `good' model is of the same order as sample size. Also, we\nallow for the case where the number of candidate models is (much) larger than\nsample size.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2008 19:54:48 GMT"}, {"version": "v2", "created": "Fri, 24 Oct 2008 10:31:23 GMT"}], "update_date": "2008-10-24", "authors_parsed": [["Leeb", "Hannes", ""]]}, {"id": "0802.3459", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Estimating Traffic Parameters with Rigorous Error Control", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To perform a queuing analysis or design in a communications context, we need\nto estimate the values of the input parameters, specifically the mean of the\narrival rate and service time. In this paper, we propose an approach for\nestimating the arrival rate of Poisson processes and the average service time\nfor servers under the assumption that the service time is exponential. In\nparticular, we derive sample size (i.e., the number of i.i.d. observations)\nrequired to obtain an estimate satisfying a pre-specified relative accuracy\nwith a given confidence level. A remarkable feature of this approach is that no\na priori information about the parameter is needed. In contrast to conventional\nmethods such as, standard error estimation and confidence interval\nconstruction, which only provides post-experimental evaluations of the\nestimate, this approach allows experimenters to rigorously control the error of\nestimation.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2008 20:03:02 GMT"}], "update_date": "2008-02-26", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0802.3539", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Interval Estimation of Bounded Variable Means via Inverse Sampling", "comments": "11 pages, no figure, added proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop interval estimation methods for means of bounded\nrandom variables based on a sequential procedure such that the sampling is\ncontinued until the sample sum is no less than a prescribed threshold.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2008 21:25:24 GMT"}, {"version": "v2", "created": "Fri, 7 Mar 2008 17:17:45 GMT"}], "update_date": "2008-03-07", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0802.4190", "submitter": "Eric Gautier", "authors": "Eric Gautier (CREST)", "title": "Bayesian Estimation of Inequalities with Non-Rectangular Censored Survey\n  Data", "comments": null, "journal-ref": "Annals Of Applied Statistics 5, 2B (2011) 1632-1656", "doi": "10.1214/10-AOAS443", "report-no": null, "categories": "stat.AP stat.ME", "license": null, "abstract": "  Synthetic indices are used in Economics to measure various aspects of\nmonetary inequalities. These scalar indices take as input the distribution over\na finite population, for example the population of a specific country. In this\narticle we consider the case of the French 2004 Wealth survey. We have at hand\na partial measurement on the distribution of interest consisting of bracketed\nand sometimes missing data, over a subsample of the population of interest. We\npresent in this article the statistical methodology used to obtain point and\ninterval estimates taking into account the various uncertainties. The\ninequality indices being nonlinear in the input distribution, we rely on a\nsimulation based approach where the model for the wealth per household is\nmultivariate. Using the survey data as well as matched auxiliary tax\ndeclarations data, we have at hand a quite intricate non-rectangle\nmultidimensional censoring. For practical issues we use a Bayesian approach.\nInference using Monte-Carlo approximations relies on a Monte-Carlo Markov chain\nalgorithm namely the Gibbs sampler. The quantities interesting to the decision\nmaker are taken to be the various inequality indices for the French population.\nTheir distribution conditional on the data of the subsample are assumed to be\nnormal centered on the design-based estimates with variance computed through\nlinearization and taking into account the sample design and total nonresponse.\nExogeneous selection of the subsample, in particular the nonresponse mechanism,\nis assumed and we condition on the adequate covariates.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2008 12:35:02 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Gautier", "Eric", "", "CREST"]]}]