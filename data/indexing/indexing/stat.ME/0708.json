[{"id": "0708.0165", "submitter": "Graciela Boente", "authors": "Graciela Boente, Xuming He, Jianhui Zhou", "title": "Robust estimates in generalized partially linear models", "comments": "Published at http://dx.doi.org/10.1214/009053606000000858 in the\n  Annals of Statistics (http://www.imstat.org/aos/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2006, Vol. 34, No. 6, 2856-2878", "doi": "10.1214/009053606000000858", "report-no": "IMS-AOS-AOS0136", "categories": "stat.ME", "license": null, "abstract": "  In this paper, we introduce a family of robust estimates for the parametric\nand nonparametric components under a generalized partially linear model, where\nthe data are modeled by $y_i|(\\mathbf{x}_i,t_i)\\sim F(\\cdot,\\mu_i)$ with\n$\\mu_i=H(\\eta(t_i)+\\mathbf{x}_i^{$\\mathrm{T}$}\\beta)$, for some known\ndistribution function F and link function H. It is shown that the estimates of\n$\\beta$ are root-n consistent and asymptotically normal. Through a Monte Carlo\nstudy, the performance of these estimators is compared with that of the\nclassical ones.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2007 14:33:41 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Boente", "Graciela", ""], ["He", "Xuming", ""], ["Zhou", "Jianhui", ""]]}, {"id": "0708.0169", "submitter": "Mikhail Langovoy", "authors": "Mikhail Langovoy", "title": "Data-driven goodness-of-fit tests", "comments": "Fully remastered version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and study a general method for construction of consistent\nstatistical tests on the basis of possibly indirect, corrupted, or partially\navailable observations. The class of tests devised in the paper contains\nNeyman's smooth tests, data-driven score tests, and some types of multi-sample\ntests as basic examples. Our tests are data-driven and are additionally\nincorporated with model selection rules. The method allows to use a wide class\nof model selection rules that are based on the penalization idea. In\nparticular, many of the optimal penalties, derived in statistical literature,\ncan be used in our tests. We establish the behavior of model selection rules\nand data-driven tests under both the null hypothesis and the alternative\nhypothesis, derive an explicit detectability rule for alternative hypotheses,\nand prove a master consistency theorem for the tests from the class. The paper\nshows that the tests are applicable to a wide range of problems, including\nhypothesis testing in statistical inverse problems, multi-sample problems, and\nnonparametric hypothesis testing.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2007 14:54:16 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2007 10:04:44 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2007 12:01:41 GMT"}, {"version": "v4", "created": "Thu, 21 Sep 2017 15:20:30 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Langovoy", "Mikhail", ""]]}, {"id": "0708.0279", "submitter": "Tim Bedford", "authors": "Tim Bedford, John Quigley, Lesley Walls", "title": "Expert Elicitation for Reliable System Design", "comments": "This paper commented in: [arXiv:0708.0285], [arXiv:0708.0287],\n  [arXiv:0708.0288]. Rejoinder in [arXiv:0708.0293]. Published at\n  http://dx.doi.org/10.1214/088342306000000510 in the Statistical Science\n  (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 428-450", "doi": "10.1214/088342306000000510", "report-no": "IMS-STS-STS204", "categories": "stat.ME", "license": null, "abstract": "  This paper reviews the role of expert judgement to support reliability\nassessments within the systems engineering design process. Generic design\nprocesses are described to give the context and a discussion is given about the\nnature of the reliability assessments required in the different systems\nengineering phases. It is argued that, as far as meeting reliability\nrequirements is concerned, the whole design process is more akin to a\nstatistical control process than to a straightforward statistical problem of\nassessing an unknown distribution. This leads to features of the expert\njudgement problem in the design context which are substantially different from\nthose seen, for example, in risk assessment. In particular, the role of experts\nin problem structuring and in developing failure mitigation options is much\nmore prominent, and there is a need to take into account the reliability\npotential for future mitigation measures downstream in the system life cycle.\nAn overview is given of the stakeholders typically involved in large scale\nsystems engineering design projects, and this is used to argue the need for\nmethods that expose potential judgemental biases in order to generate analyses\nthat can be said to provide rational consensus about uncertainties. Finally, a\nnumber of key points are developed with the aim of moving toward a framework\nthat provides a holistic method for tracking reliability assessment through the\ndesign process.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 08:12:24 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Bedford", "Tim", ""], ["Quigley", "John", ""], ["Walls", "Lesley", ""]]}, {"id": "0708.0285", "submitter": "Norman Fenton", "authors": "Norman Fenton, Martin Neil", "title": "Comment: Expert Elicitation for Reliable System Design", "comments": "Published at http://dx.doi.org/10.1214/088342306000000529 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 451-453", "doi": "10.1214/088342306000000529", "report-no": "IMS-STS-STS204A", "categories": "stat.ME", "license": null, "abstract": "  Comment: Expert Elicitation for Reliable System Design [arXiv:0708.0279]\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 07:13:09 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Fenton", "Norman", ""], ["Neil", "Martin", ""]]}, {"id": "0708.0287", "submitter": "Andrew Koehler", "authors": "Andrew Koehler", "title": "Comment: Expert Elicitation for Reliable System Design", "comments": "Published at http://dx.doi.org/10.1214/088342306000000538 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 454-455", "doi": "10.1214/088342306000000538", "report-no": "IMS-STS-STS204B", "categories": "stat.ME", "license": null, "abstract": "  Comment: Expert Elicitation for Reliable System Design [arXiv:0708.0279]\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 07:36:31 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Koehler", "Andrew", ""]]}, {"id": "0708.0288", "submitter": "Wenbin Wang", "authors": "Wenbin Wang", "title": "Comment: Expert Elicitation for Reliable System Design", "comments": "Published at http://dx.doi.org/10.1214/088342306000000547 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 456-459", "doi": "10.1214/088342306000000547", "report-no": "IMS-STS-STS204C", "categories": "stat.ME", "license": null, "abstract": "  Comment: Expert Elicitation for Reliable System Design [arXiv:0708.0279]\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 07:48:24 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Wang", "Wenbin", ""]]}, {"id": "0708.0293", "submitter": "Tim Bedford", "authors": "Tim Bedford, John Quigley, Lesley Walls", "title": "Rejoinder: Expert Elicitation for Reliable System Design", "comments": "Published at http://dx.doi.org/10.1214/088342306000000556 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 460-462", "doi": "10.1214/088342306000000556", "report-no": "IMS-STS-STS204REJ", "categories": "stat.ME", "license": null, "abstract": "  Rejoinder: Expert Elicitation for Reliable System Design [arXiv:0708.0279]\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 08:02:18 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Bedford", "Tim", ""], ["Quigley", "John", ""], ["Walls", "Lesley", ""]]}, {"id": "0708.0295", "submitter": "Alyson Wilson", "authors": "Sallie Keller-McNulty, Alyson Wilson, Christine Anderson-Cook", "title": "Reliability", "comments": "Published at http://dx.doi.org/10.1214/088342306000000664 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 427-427", "doi": "10.1214/088342306000000664", "report-no": "IMS-STS-STS214INTRO", "categories": "stat.ME", "license": null, "abstract": "  This special volume of Statistical Sciences presents some innovative, if not\nprovocative, ideas in the area of reliability, or perhaps more appropriately\nnamed, integrated system assessment. In this age of exponential growth in\nscience, engineering and technology, the capability to evaluate the\nperformance, reliability and safety of complex systems presents new challenges.\nToday's methodology must respond to the ever-increasing demands for such\nevaluations to provide key information for decision and policy makers at all\nlevels of government and industry--problems ranging from international security\nto space exploration. We, the co-editors of this volume and the authors,\nbelieve that scientific progress in reliability assessment requires the\ndevelopment of processes, methods and tools that combine diverse information\ntypes (e.g., experiments, computer simulations, expert knowledge) from diverse\nsources (e.g., scientists, engineers, business developers, technology\nintegrators, decision makers) to assess quantitative performance metrics that\ncan aid decision making under uncertainty. These are highly interdisciplinary\nproblems. The principal role of statistical sciences is to bring statistical\nrigor, thinking and methodology to these problems.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 08:29:46 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Keller-McNulty", "Sallie", ""], ["Wilson", "Alyson", ""], ["Anderson-Cook", "Christine", ""]]}, {"id": "0708.0302", "submitter": "Scott Vander Wiel", "authors": "John M. Chambers, David A. James, Diane Lambert, Scott Vander Wiel", "title": "Monitoring Networked Applications With Incremental Quantile Estimation", "comments": "This paper commented in: [arXiv:0708.0317], [arXiv:0708.0336],\n  [arXiv:0708.0338]. Rejoinder in [arXiv:0708.0339]. Published at\n  http://dx.doi.org/10.1214/088342306000000583 in the Statistical Science\n  (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 463-475", "doi": "10.1214/088342306000000583", "report-no": "IMS-STS-STS214", "categories": "stat.ME", "license": null, "abstract": "  Networked applications have software components that reside on different\ncomputers. Email, for example, has database, processing, and user interface\ncomponents that can be distributed across a network and shared by users in\ndifferent locations or work groups. End-to-end performance and reliability\nmetrics describe the software quality experienced by these groups of users,\ntaking into account all the software components in the pipeline. Each user\nproduces only some of the data needed to understand the quality of the\napplication for the group, so group performance metrics are obtained by\ncombining summary statistics that each end computer periodically (and\nautomatically) sends to a central server. The group quality metrics usually\nfocus on medians and tail quantiles rather than on averages. Distributed\nquantile estimation is challenging, though, especially when passing large\namounts of data around the network solely to compute quality metrics is\nundesirable. This paper describes an Incremental Quantile (IQ) estimation\nmethod that is designed for performance monitoring at arbitrary levels of\nnetwork aggregation and time resolution when only a limited amount of data can\nbe transferred. Applications to both real and simulated data are provided.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 13:23:09 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Chambers", "John M.", ""], ["James", "David A.", ""], ["Lambert", "Diane", ""], ["Wiel", "Scott Vander", ""]]}, {"id": "0708.0317", "submitter": "Lorraine Denby", "authors": "Lorraine Denby, James M. Landwehr, Jean Meloche", "title": "Comment: Monitoring Networked Applications With Incremental Quantile\n  Estimation", "comments": "Published at http://dx.doi.org/10.1214/088342306000000619 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 476-478", "doi": "10.1214/088342306000000619", "report-no": "IMS-STS-STS214B", "categories": "stat.ME", "license": null, "abstract": "  Comment: Monitoring Networked Applications With Incremental Quantile\nEstimation [arXiv:0708.0302]\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 11:00:00 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Denby", "Lorraine", ""], ["Landwehr", "James M.", ""], ["Meloche", "Jean", ""]]}, {"id": "0708.0336", "submitter": "Earl Lawrence", "authors": "Earl Lawrence, George Michailidis, Vijayan N. Nair", "title": "Comment: Monitoring Networked Applications With Incremental Quantile\n  Estimation", "comments": "Published at http://dx.doi.org/10.1214/088342306000000600 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 479-482", "doi": "10.1214/088342306000000600", "report-no": "IMS-STS-STS214A", "categories": "stat.ME", "license": null, "abstract": "  Our comments are in two parts. First, we make some observations regarding the\nmethodology in Chambers et al. [arXiv:0708.0302]. Second, we briefly describe\nanother interesting network monitoring problem that arises in the context of\nassessing quality of service, such as loss rates and delay distributions, in\npacket-switched networks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 12:46:18 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Lawrence", "Earl", ""], ["Michailidis", "George", ""], ["Nair", "Vijayan N.", ""]]}, {"id": "0708.0338", "submitter": "Bin Yu", "authors": "Bin Yu", "title": "Comment: Monitoring Networked Applications With Incremental Quantile\n  Estimation", "comments": "Published at http://dx.doi.org/10.1214/088342306000000628 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 483-484", "doi": "10.1214/088342306000000628", "report-no": "IMS-STS-STS214C", "categories": "stat.ME", "license": null, "abstract": "  Comment: Monitoring Networked Applications With Incremental Quantile\nEstimation [arXiv:0708.0302]\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 12:59:51 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Yu", "Bin", ""]]}, {"id": "0708.0339", "submitter": "Scott Vander Wiel", "authors": "John M. Chambers, David A. James, Diane Lambert, Scott Vander Wiel", "title": "Rejoinder: Monitoring Networked Applications With Incremental Quantile\n  Estimation", "comments": "Published at http://dx.doi.org/10.1214/088342306000000592 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 485-486", "doi": "10.1214/088342306000000592", "report-no": "IMS-STS-STS214REJ", "categories": "stat.ME", "license": null, "abstract": "  Rejoinder: Monitoring Networked Applications With Incremental Quantile\nEstimation [arXiv:0708.0302]\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 13:14:05 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Chambers", "John M.", ""], ["James", "David A.", ""], ["Lambert", "Diane", ""], ["Wiel", "Scott Vander", ""]]}, {"id": "0708.0343", "submitter": "Edsel A. Pe\\~{n}a", "authors": "Edsel A. Pe\\~na", "title": "Dynamic Modeling and Statistical Analysis of Event Times", "comments": "Published at http://dx.doi.org/10.1214/088342306000000349 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 487-500", "doi": "10.1214/088342306000000349", "report-no": "IMS-STS-STS212", "categories": "stat.ME", "license": null, "abstract": "  This review article provides an overview of recent work in the modeling and\nanalysis of recurrent events arising in engineering, reliability, public\nhealth, biomedicine and other areas. Recurrent event modeling possesses unique\nfacets making it different and more difficult to handle than single event\nsettings. For instance, the impact of an increasing number of event occurrences\nneeds to be taken into account, the effects of covariates should be considered,\npotential association among the interevent times within a unit cannot be\nignored, and the effects of performed interventions after each event occurrence\nneed to be factored in. A recent general class of models for recurrent events\nwhich simultaneously accommodates these aspects is described. Statistical\ninference methods for this class of models are presented and illustrated\nthrough applications to real data sets. Some existing open research problems\nare described.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 13:35:57 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Pe\u00f1a", "Edsel A.", ""]]}, {"id": "0708.0346", "submitter": "Mei-Ling Ting Lee", "authors": "Mei-Ling Ting Lee, G. A. Whitmore", "title": "Threshold Regression for Survival Analysis: Modeling Event Times by a\n  Stochastic Process Reaching a Boundary", "comments": "Published at http://dx.doi.org/10.1214/088342306000000330 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 501-513", "doi": "10.1214/088342306000000330", "report-no": "IMS-STS-STS210", "categories": "stat.ME", "license": null, "abstract": "  Many researchers have investigated first hitting times as models for survival\ndata. First hitting times arise naturally in many types of stochastic\nprocesses, ranging from Wiener processes to Markov chains. In a survival\ncontext, the state of the underlying process represents the strength of an item\nor the health of an individual. The item fails or the individual experiences a\nclinical endpoint when the process reaches an adverse threshold state for the\nfirst time. The time scale can be calendar time or some other operational\nmeasure of degradation or disease progression. In many applications, the\nprocess is latent (i.e., unobservable). Threshold regression refers to\nfirst-hitting-time models with regression structures that accommodate covariate\ndata. The parameters of the process, threshold state and time scale may depend\non the covariates. This paper reviews aspects of this topic and discusses\nfruitful avenues for future research.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 14:00:45 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Lee", "Mei-Ling Ting", ""], ["Whitmore", "G. A.", ""]]}, {"id": "0708.0355", "submitter": "Alyson G. Wilson", "authors": "Alyson G. Wilson, Todd L. Graves, Michael S. Hamada, C. Shane Reese", "title": "Advances in Data Combination, Analysis and Collection for System\n  Reliability Assessment", "comments": "Published at http://dx.doi.org/10.1214/088342306000000439 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 514-531", "doi": "10.1214/088342306000000439", "report-no": "IMS-STS-STS208", "categories": "stat.ME", "license": null, "abstract": "  The systems that statisticians are asked to assess, such as nuclear weapons,\ninfrastructure networks, supercomputer codes and munitions, have become\nincreasingly complex. It is often costly to conduct full system tests. As such,\nwe present a review of methodology that has been proposed for addressing system\nreliability with limited full system testing. The first approaches presented in\nthis paper are concerned with the combination of multiple sources of\ninformation to assess the reliability of a single component. The second general\nset of methodology addresses the combination of multiple levels of data to\ndetermine system reliability. We then present developments for complex systems\nbeyond traditional series/parallel representations through the use of Bayesian\nnetworks and flowgraph models. We also include methodological contributions to\nresource allocation considerations for system relability assessment. We\nillustrate each method with applications primarily encountered at Los Alamos\nNational Laboratory.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 14:42:06 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Wilson", "Alyson G.", ""], ["Graves", "Todd L.", ""], ["Hamada", "Michael S.", ""], ["Reese", "C. Shane", ""]]}, {"id": "0708.0362", "submitter": "Bo Henry Lindqvist", "authors": "Bo Henry Lindqvist", "title": "On the Statistical Modeling and Analysis of Repairable Systems", "comments": "Published at http://dx.doi.org/10.1214/088342306000000448 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 532-551", "doi": "10.1214/088342306000000448", "report-no": "IMS-STS-STS211", "categories": "stat.ME", "license": null, "abstract": "  We review basic modeling approaches for failure and maintenance data from\nrepairable systems. In particular we consider imperfect repair models, defined\nin terms of virtual age processes, and the trend-renewal process which extends\nthe nonhomogeneous Poisson process and the renewal process. In the case where\nseveral systems of the same kind are observed, we show how observed covariates\nand unobserved heterogeneity can be included in the models. We also consider\nvarious approaches to trend testing. Modern reliability data bases usually\ncontain information on the type of failure, the type of maintenance and so\nforth in addition to the failure times themselves. Basing our work on recent\nliterature we present a framework where the observed events are modeled as\nmarked point processes, with marks labeling the types of events. Throughout the\npaper the emphasis is more on modeling than on statistical inference.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 15:13:56 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Lindqvist", "Bo Henry", ""]]}, {"id": "0708.0369", "submitter": "Luis A. Escobar", "authors": "Luis A. Escobar, William Q. Meeker", "title": "A Review of Accelerated Test Models", "comments": "Published at http://dx.doi.org/10.1214/088342306000000321 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 552-577", "doi": "10.1214/088342306000000321", "report-no": "IMS-STS-STS209", "categories": "stat.ME", "license": null, "abstract": "  Engineers in the manufacturing industries have used accelerated test (AT)\nexperiments for many decades. The purpose of AT experiments is to acquire\nreliability information quickly. Test units of a material, component, subsystem\nor entire systems are subjected to higher-than-usual levels of one or more\naccelerating variables such as temperature or stress. Then the AT results are\nused to predict life of the units at use conditions. The extrapolation is\ntypically justified (correctly or incorrectly) on the basis of physically\nmotivated models or a combination of empirical model fitting with a sufficient\namount of previous experience in testing similar units. The need to extrapolate\nin both time and the accelerating variables generally necessitates the use of\nfully parametric models. Statisticians have made important contributions in the\ndevelopment of appropriate stochastic models for AT data [typically a\ndistribution for the response and regression relationships between the\nparameters of this distribution and the accelerating variable(s)], statistical\nmethods for AT planning (choice of accelerating variable levels and allocation\nof available test units to those levels) and methods of estimation of suitable\nreliability metrics. This paper provides a review of many of the AT models that\nhave been used successfully in this area.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 16:11:49 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Escobar", "Luis A.", ""], ["Meeker", "William Q.", ""]]}, {"id": "0708.0378", "submitter": "Paul Kvam", "authors": "Paul Kvam", "title": "A Conversation With Harry Martz", "comments": "Published at http://dx.doi.org/10.1214/088342306000000646 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2006, Vol. 21, No. 4, 578-585", "doi": "10.1214/088342306000000646", "report-no": "IMS-STS-STS213", "categories": "stat.ME", "license": null, "abstract": "  Harry F. Martz was born June 16, 1942 and grew up in Cumberland, Maryland. He\nreceived a Bachelor of Science degree in mathematics (with a minor in physics)\nfrom Frostburg State University in 1964, and earned a Ph.D. in statistics at\nVirginia Polytechnic Institute and State University in 1968. He started his\nstatistics career at Texas Tech University's Department of Industrial\nEngineering and Statistics right after graduation. In 1978, he joined the\ntechnical staff at Los Alamos National Laboratory (LANL) in Los Alamos, New\nMexico after first working as Full Professor in the Department of Industrial\nEngineering at Utah State University in the fall of 1977. He has had a prolific\n23-year career with the statistics group at LANL; over the course of his\ncareer, Martz has published over 80 research papers in books and refereed\njournals, one book (with co-author Ray Waller), and has four patents associated\nwith his work at LANL. He is a fellow of the American Statistical Association\nand has received numerous awards, including the Technometrics Frank Wilcoxon\nPrize for Best Applications Paper (1996), Los Alamos National Laboratory\nAchievement Award (1998), R&D 100 Award by R&D Magazine (2003), Council for\nChemical Research Collaboration Success Award (2004), and Los Alamos National\nLaboratory's Distinguished Licensing Award (2004). Since retiring as a\nTechnical Staff member at LANL in 2001, he has worked as a LANL Laboratory\nAssociate.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2007 16:41:04 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Kvam", "Paul", ""]]}, {"id": "0708.0656", "submitter": "Wei-Liem Loh", "authors": "Wei-Liem Loh", "title": "A multivariate central limit theorem for randomized orthogonal array\n  sampling designs in computer experiments", "comments": "89 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": null, "abstract": "  Let $f:[0,1)^d \\to {\\mathbb R}$ be an integrable function. An objective of\nmany computer experiments is to estimate $\\int_{[0,1)^d} f(x) dx$ by evaluating\nf at a finite number of points in [0,1)^d. There is a design issue in the\nchoice of these points and a popular choice is via the use of randomized\northogonal arrays. This article proves a multivariate central limit theorem for\na class of randomized orthogonal array sampling designs [Owen (1992a)] as well\nas for a class of OA-based Latin hypercubes [Tang (1993)].\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2007 03:35:36 GMT"}], "update_date": "2007-08-07", "authors_parsed": [["Loh", "Wei-Liem", ""]]}, {"id": "0708.0959", "submitter": "David Madigan", "authors": "Susana Eyheramendy, David Madigan", "title": "A flexible Bayesian generalized linear model for dichotomous response\n  data with an application to text categorization", "comments": "Published at http://dx.doi.org/10.1214/074921707000000067 in the IMS\n  Lecture Notes Monograph Series\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "IMS Lecture Notes Monograph Series 2007, Vol. 54, 76-91", "doi": "10.1214/074921707000000067", "report-no": "IMS-LNMS54-LNMS5406", "categories": "stat.ME", "license": null, "abstract": "  We present a class of sparse generalized linear models that include probit\nand logistic regression as special cases and offer some extra flexibility. We\nprovide an EM algorithm for learning the parameters of these models from data.\nWe apply our method in text classification and in simulated data and show that\nour method outperforms the logistic and probit models and also the elastic net,\nin general by a substantial margin.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2007 14:29:19 GMT"}], "update_date": "2007-08-22", "authors_parsed": [["Eyheramendy", "Susana", ""], ["Madigan", "David", ""]]}, {"id": "0708.0968", "submitter": "Javier Cabrera", "authors": "Javier Cabrera, Ching-Ray Yu", "title": "Estimating the proportion of differentially expressed genes in\n  comparative DNA microarray experiments", "comments": "Published at http://dx.doi.org/10.1214/074921707000000076 in the IMS\n  Lecture Notes Monograph Series\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "IMS Lecture Notes Monograph Series 2007, Vol. 54, 92-102", "doi": "10.1214/074921707000000076", "report-no": "IMS-LNMS54-LNMS5407", "categories": "stat.ME", "license": null, "abstract": "  DNA microarray experiments, a well-established experimental technique, aim at\nunderstanding the function of genes in some biological processes. One of the\nmost common experiments in functional genomics research is to compare two\ngroups of microarray data to determine which genes are differentially\nexpressed. In this paper, we propose a methodology to estimate the proportion\nof differentially expressed genes in such experiments. We study the performance\nof our method in a simulation study where we compare it to other standard\nmethods. Finally we compare the methods in real data from two toxicology\nexperiments with mice.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2007 14:53:31 GMT"}], "update_date": "2007-08-22", "authors_parsed": [["Cabrera", "Javier", ""], ["Yu", "Ching-Ray", ""]]}, {"id": "0708.0978", "submitter": "Cun-Hui Zhang", "authors": "Weihua Tang, Cun-Hui Zhang", "title": "Empirical Bayes methods for controlling the false discovery rate with\n  dependent data", "comments": "Published at http://dx.doi.org/10.1214/074921707000000111 in the IMS\n  Lecture Notes Monograph Series\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "IMS Lecture Notes Monograph Series 2007, Vol. 54, 151-160", "doi": "10.1214/074921707000000111", "report-no": "IMS-LNMS54-LNMS5411", "categories": "stat.ME", "license": null, "abstract": "  False discovery rate (FDR) has been widely used as an error measure in large\nscale multiple testing problems, but most research in the area has been focused\non procedures for controlling the FDR based on independent test statistics or\nthe properties of such procedures for test statistics with certain types of\nstochastic dependence. Based on an approach proposed in Tang and Zhang (2005),\nwe further develop in this paper empirical Bayes methods for controlling the\nFDR with dependent data. We implement our methodology in a time series model\nand report the results of a simulation study to demonstrate the advantages of\nthe empirical Bayes approach.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2007 15:32:21 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Tang", "Weihua", ""], ["Zhang", "Cun-Hui", ""]]}, {"id": "0708.0980", "submitter": "Yosef Rinott", "authors": "Yosef Rinott, Natalie Shlomo", "title": "A smoothing model for sample disclosure risk estimation", "comments": "Published at http://dx.doi.org/10.1214/074921707000000120 in the IMS\n  Lecture Notes Monograph Series\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "IMS Lecture Notes Monograph Series 2007, Vol. 54, 161-171", "doi": "10.1214/074921707000000120", "report-no": "IMS-LNMS54-LNMS5412", "categories": "stat.ME", "license": null, "abstract": "  When a sample frequency table is published, disclosure risk arises when some\nindividuals can be identified on the basis of their values in certain\nattributes in the table called key variables, and then their values in other\nattributes may be inferred, and their privacy is violated. On the basis of the\nsample to be released, and possibly some partial knowledge of the whole\npopulation, an agency which considers releasing the sample, has to estimate the\ndisclosure risk. Risk arises from non-empty sample cells which represent small\npopulation cells and from population uniques in particular. Therefore risk\nestimation requires assessing how many of the relevant population cells are\nlikely to be small. Various methods have been proposed for this task, and we\npresent a method in which estimation of a population cell frequency is based on\nsmoothing using a local neighborhood of this cell, that is, cells having\nsimilar or close values in all attributes. We provide some preliminary results\nand experiments with this method. Comparisons are made to two other methods: 1.\na log-linear models approach in which inference on a given cell is based on a\n``neighborhood'' of cells determined by the log-linear model. Such\nneighborhoods have one or some common attributes with the cell in question, but\nsome other attributes may differ significantly. 2 The Argus method in which\ninference on a given cell is based only on the sample frequency in the specific\ncell, on the sample design and on some known marginal distributions of the\npopulation, without learning from any type of ``neighborhood'' of the given\ncell, nor from any model which uses the structure of the table.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2007 15:40:51 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Rinott", "Yosef", ""], ["Shlomo", "Natalie", ""]]}, {"id": "0708.1069", "submitter": "John E. Kolassa", "authors": "Juan Zhang, John E. Kolassa", "title": "A comparison of the accuracy of saddlepoint conditional cumulative\n  distribution function approximations", "comments": "Published at http://dx.doi.org/10.1214/074921707000000193 in the IMS\n  Lecture Notes Monograph Series\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "IMS Lecture Notes Monograph Series 2007, Vol. 54, 250-259", "doi": "10.1214/074921707000000193", "report-no": "IMS-LNMS54-LNMS5419", "categories": "stat.ME", "license": null, "abstract": "  Consider a model parameterized by a scalar parameter of interest and a\nnuisance parameter vector. Inference about the parameter of interest may be\nbased on the signed root of the likelihood ratio statistic R. The standard\nnormal approximation to the conditional distribution of R typically has error\nof order O(n^{-1/2}), where n is the sample size. There are several\nmodifications for R, which reduce the order of error in the approximations. In\nthis paper, we mainly investigate Barndorff-Nielsen's modified directed\nlikelihood ratio statistic, Severini's empirical adjustment, and DiCiccio and\nMartin's two modifications, involving the Bayesian approach and the conditional\nlikelihood ratio statistic. For each modification, two formats were employed to\napproximate the conditional cumulative distribution function; these are\nBarndorff-Nielson formats and the Lugannani and Rice formats. All\napproximations were applied to inference on the ratio of means for two\nindependent exponential random variables. We constructed one and two-sided\nhypotheses tests and used the actual sizes of the tests as the measurements of\naccuracy to compare those approximations.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2007 09:31:47 GMT"}], "update_date": "2007-08-22", "authors_parsed": [["Zhang", "Juan", ""], ["Kolassa", "John E.", ""]]}, {"id": "0708.1079", "submitter": "George Michailidis", "authors": "Earl Lawrence, George Michailidis, Vijayan N. Nair", "title": "Statistical inverse problems in active network tomography", "comments": "Published at http://dx.doi.org/10.1214/074921707000000049 in the IMS\n  Lecture Notes Monograph Series\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "IMS Lecture Notes Monograph Series 2007, Vol. 54, 24-44", "doi": "10.1214/074921707000000049", "report-no": "IMS-LNMS54-LNMS5403", "categories": "stat.ME", "license": null, "abstract": "  The analysis of computer and communication networks gives rise to some\ninteresting inverse problems. This paper is concerned with active network\ntomography where the goal is to recover information about quality-of-service\n(QoS) parameters at the link level from aggregate data measured on end-to-end\nnetwork paths. The estimation and monitoring of QoS parameters, such as loss\nrates and delays, are of considerable interest to network engineers and\nInternet service providers. The paper provides a review of the inverse problems\nand recent research on inference for loss rates and delay distributions. Some\nnew results on parametric inference for delay distributions are also developed.\nIn addition, a real application on Internet telephony is discussed.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2007 10:56:24 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Lawrence", "Earl", ""], ["Michailidis", "George", ""], ["Nair", "Vijayan N.", ""]]}, {"id": "0708.1085", "submitter": "J. M. Landwehr", "authors": "A. Adhikari, L. Denby, J. M. Landwehr, J. Meloche", "title": "Using data network metrics, graphics, and topology to explore network\n  characteristics", "comments": "Published at http://dx.doi.org/10.1214/074921707000000058 in the IMS\n  Lecture Notes Monograph Series\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "IMS Lecture Notes Monograph Series 2007, Vol. 54, 62-75", "doi": "10.1214/074921707000000058", "report-no": "IMS-LNMS54-LNMS5405", "categories": "stat.ME", "license": null, "abstract": "  Yehuda Vardi introduced the term network tomography and was the first to\npropose and study how statistical inverse methods could be adapted to attack\nimportant network problems (Vardi, 1996). More recently, in one of his final\npapers, Vardi proposed notions of metrics on networks to define and measure\ndistances between a network's links, its paths, and also between different\nnetworks (Vardi, 2004). In this paper, we apply Vardi's general approach for\nnetwork metrics to a real data network by using data obtained from special data\nnetwork tools and testing procedures presented here. We illustrate how the\nmetrics help explicate interesting features of the traffic characteristics on\nthe network. We also adapt the metrics in order to condition on traffic passing\nthrough a portion of the network, such as a router or pair of routers, and show\nfurther how this approach helps to discover and explain interesting network\ncharacteristics.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2007 11:43:13 GMT"}], "update_date": "2007-08-22", "authors_parsed": [["Adhikari", "A.", ""], ["Denby", "L.", ""], ["Landwehr", "J. M.", ""], ["Meloche", "J.", ""]]}, {"id": "0708.1107", "submitter": "Rebecka Jornsten", "authors": "Sara L\\'opez-Pintado, Rebecka Jornsten", "title": "Functional analysis via extensions of the band depth", "comments": "Published at http://dx.doi.org/10.1214/074921707000000085 in the IMS\n  Lecture Notes Monograph Series\n  (http://www.imstat.org/publications/lecnotes.htm) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "IMS Lecture Notes Monograph Series 2007, Vol. 54, 103-120", "doi": "10.1214/074921707000000085", "report-no": "IMS-LNMS54-LNMS5408", "categories": "stat.ME", "license": null, "abstract": "  The notion of data depth has long been in use to obtain robust location and\nscale estimates in a multivariate setting. The depth of an observation is a\nmeasure of its centrality, with respect to a data set or a distribution. The\ndata depths of a set of multivariate observations translates to a\ncenter-outward ordering of the data. Thus, data depth provides a generalization\nof the median to a multivariate setting (the deepest observation), and can also\nbe used to screen for extreme observations or outliers (the observations with\nlow data depth). Data depth has been used in the development of a wide range of\nrobust and non-parametric methods for multivariate data, such as non-parametric\ntests of location and scale [Li and Liu (2004)], multivariate rank-tests [Liu\nand Singh (1993)], non-parametric classification and clustering [Jornsten\n(2004)], and robust regression [Rousseeuw and Hubert (1999)]. Many different\nnotions of data depth have been developed for multivariate data. In contrast,\ndata depth measures for functional data have only recently been proposed\n[Fraiman and Muniz (1999), L\\'{o}pez-Pintado and Romo (2006a)]. While the\ndefinitions of both of these data depth measures are motivated by the\nfunctional aspect of the data, the measures themselves are in fact invariant\nwith respect to permutations of the domain (i.e. the compact interval on which\nthe functions are defined). Thus, these measures are equally applicable to\nmultivariate data where there is no explicit ordering of the data dimensions.\nIn this paper we explore some extensions of functional data depths, so as to\ntake the ordering of the data dimensions into account.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2007 14:32:41 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["L\u00f3pez-Pintado", "Sara", ""], ["Jornsten", "Rebecka", ""]]}, {"id": "0708.1566", "submitter": "K Rao Balaji", "authors": "K. Balaji Rao", "title": "Markov Chain Modelling for Reliability Estimation of Engineering Systems\n  at Different Scales - Some Considerations", "comments": "10 pages (including cover page) International Conference on Civil\n  Engineering in the New Millennium: Opportunities and Challenges, January\n  11-14, 2007", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": null, "abstract": "  The concepts of probability, statistics and stochastic theory are being\nsuccessfully used in structural engineering. Markov Chain modelling is a simple\nstochastic process model that has found its application in both describing\nstochastic evolution of system and in system reliability estimation. The recent\ndevelopments in Markov Chain Monte Carlo and the possible integration of\nBayesian theory within Markov Chain theory have enhanced its application\npossibilities. However, the application possibility can be furthered to range\nover wider scales of application (perhaps from nano- to macro-) by considering\nthe developments in Physics (in particular Quantum Physics). This paper tries\nto present the results of quantum physics that would help in interpretation of\ntransition probability matrix. However, care has to be taken in the choice of\ndensities in computing the transition probability matrix. The paper is based on\navailable literature, and the aim is only to make an attempt to show how Markov\nChain can be used to model systems at various scales.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2007 13:36:44 GMT"}], "update_date": "2007-08-14", "authors_parsed": [["Rao", "K. Balaji", ""]]}, {"id": "0708.1593", "submitter": "Adom Giffin", "authors": "Adom Giffin and Ariel Caticha", "title": "Updating Probabilities with Data and Moments", "comments": "Presented at the 27th International Workshop on Bayesian Inference\n  and Maximum Entropy Methods in Science and Engineering, Saratoga Springs, NY,\n  July 8-13, 2007. 10 pages, 1 figure V2 has a small typo in the end of the\n  appendix that was fixed. aj=mj+1 is now aj=m(k-j)+1", "journal-ref": null, "doi": "10.1063/1.2821302", "report-no": null, "categories": "physics.data-an cs.IT math.IT math.ST physics.comp-ph physics.pop-ph stat.AP stat.CO stat.ME stat.TH", "license": null, "abstract": "  We use the method of Maximum (relative) Entropy to process information in the\nform of observed data and moment constraints. The generic \"canonical\" form of\nthe posterior distribution for the problem of simultaneous updating with data\nand moments is obtained. We discuss the general problem of non-commuting\nconstraints, when they should be processed sequentially and when\nsimultaneously. As an illustration, the multinomial example of die tosses is\nsolved in detail for two superficially similar but actually very different\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2007 19:25:41 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2007 20:23:25 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Giffin", "Adom", ""], ["Caticha", "Ariel", ""]]}, {"id": "0708.1627", "submitter": "Ivan Fernandez-Val", "authors": "Victor Chernozhukov, Ivan Fernandez-Val, Alfred Galichon", "title": "Rearranging Edgeworth-Cornish-Fisher Expansions", "comments": "17 pages, 3 figures", "journal-ref": "Economic Theory February 2010, Volume 42, Issue 2, pp 419-435", "doi": "10.1007/s00199-008-0431-z", "report-no": null, "categories": "stat.ME econ.EM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper applies a regularization procedure called increasing rearrangement\nto monotonize Edgeworth and Cornish-Fisher expansions and any other related\napproximations of distribution and quantile functions of sample statistics.\nBesides satisfying the logical monotonicity, required of distribution and\nquantile functions, the procedure often delivers strikingly better\napproximations to the distribution and quantile functions of the sample mean\nthan the original Edgeworth-Cornish-Fisher expansions.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2007 22:11:35 GMT"}, {"version": "v2", "created": "Fri, 31 May 2013 02:23:22 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Chernozhukov", "Victor", ""], ["Fernandez-Val", "Ivan", ""], ["Galichon", "Alfred", ""]]}, {"id": "0708.1866", "submitter": "Ricardo Lopez-Ruiz", "authors": "Ricardo Lopez-Ruiz, Jaime Sanudo and Xavier Calbet", "title": "On the equivalence of the microcanonical and the canonical ensembles: a\n  geometrical approach", "comments": "9 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CD cond-mat.stat-mech stat.ME", "license": null, "abstract": "  In this paper, we consider the volume enclosed by the microcanonical ensemble\nin phase space as a statistical ensemble. This can be interpreted as an\nintermediate image between the microcanonical and the canonical pictures. By\nmaintaining the ergodic hypothesis over this ensemble, that is, the\nequiprobability of all its accessible states, the equivalence of this ensemble\nin the thermodynamic limit with the microcanonical and the canonical ensembles\nis suggested by means of geometrical arguments. The Maxwellian and the\nBoltzmann-Gibbs distributions are obtained from this formalism. In the\nappendix, the derivation of the Boltzmann factor from a new microcanonical\nimage of the canonical ensemble is also given.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2007 11:39:45 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2007 09:07:59 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2007 14:46:46 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Lopez-Ruiz", "Ricardo", ""], ["Sanudo", "Jaime", ""], ["Calbet", "Xavier", ""]]}, {"id": "0708.2020", "submitter": "Alberto Elices", "authors": "A. Elices", "title": "Models with time-dependent parameters using transform methods:\n  application to Heston's model", "comments": "10 pages, 10 figures, 6 tables, error corrected in sections VI and\n  VII, references added in sections I and VI, Submitted to the Journal of\n  Mathematical Finance", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PR math.PR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a methodology to introduce time-dependent parameters for\na wide family of models preserving their analytic tractability. This family\nincludes hybrid models with stochastic volatility, stochastic interest-rates,\njumps and their non-hybrid counterparts. The methodology is applied to Heston's\nmodel. A bootstrapping algorithm is presented for calibration. A case study\nworks out the calibration of the time-dependent parameters to the volatility\nsurface of the Eurostoxx 50 index. The methodology is also applied to the\nanalytic valuation of forward start vanilla options driven by Heston's model.\nThis result is used to explore the forward skew of the case study.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2007 10:12:42 GMT"}, {"version": "v2", "created": "Mon, 20 Oct 2008 11:46:43 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Elices", "A.", ""]]}, {"id": "0708.3517", "submitter": "Rob Tibshirani", "authors": "Jerome Friedman, Trevor Hastie, Robert Tibshirani", "title": "Sparse inverse covariance estimation with the lasso", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  We consider the problem of estimating sparse graphs by a lasso penalty\napplied to the inverse covariance matrix. Using a coordinate descent procedure\nfor the lasso, we develop a simple algorithm that is remarkably fast: in the\nworst cases, it solves a 1000 node problem (~500,000 parameters) in about a\nminute, and is 50 to 2000 times faster than competing methods. It also provides\na conceptual link between the exact problem and the approximation suggested by\nMeinhausen and Buhlmann (2006). We illustrate the method on some cell-signaling\ndata from proteomics.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2007 00:04:03 GMT"}], "update_date": "2007-08-28", "authors_parsed": [["Friedman", "Jerome", ""], ["Hastie", "Trevor", ""], ["Tibshirani", "Robert", ""]]}, {"id": "0708.3774", "submitter": "R. Dennis Cook", "authors": "R. Dennis Cook", "title": "Fisher Lecture: Dimension Reduction in Regression", "comments": "This paper commented in: [arXiv:0708.3776], [arXiv:0708.3777],\n  [arXiv:0708.3779]. Rejoinder in [arXiv:0708.3781]. Published at\n  http://dx.doi.org/10.1214/088342306000000682 in the Statistical Science\n  (http://www.imstat.org/sts/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 1, 1-26", "doi": "10.1214/088342306000000682", "report-no": "IMS-STS-STS225", "categories": "stat.ME", "license": null, "abstract": "  Beginning with a discussion of R. A. Fisher's early written remarks that\nrelate to dimension reduction, this article revisits principal components as a\nreductive method in regression, develops several model-based extensions and\nends with descriptions of general approaches to model-based and model-free\ndimension reduction in regression. It is argued that the role for principal\ncomponents and related methodology may be broader than previously seen and that\nthe common practice of conditioning on observed values of the predictors may\nunnecessarily limit the choice of regression methodology.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2007 13:29:05 GMT"}], "update_date": "2007-08-30", "authors_parsed": [["Cook", "R. Dennis", ""]]}, {"id": "0708.3776", "submitter": "Ronald Christensen", "authors": "Ronald Christensen", "title": "Comment: Fisher Lecture: Dimension Reduction in Regression", "comments": "Published at http://dx.doi.org/10.1214/088342307000000041 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 1, 27-31", "doi": "10.1214/088342307000000041", "report-no": "IMS-STS-STS225A", "categories": "stat.ME", "license": null, "abstract": "  Comment: Fisher Lecture: Dimension Reduction in Regression [arXiv:0708.3774]\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2007 12:54:35 GMT"}], "update_date": "2007-08-30", "authors_parsed": [["Christensen", "Ronald", ""]]}, {"id": "0708.3777", "submitter": "Bing Li", "authors": "Bing Li", "title": "Comment: Fisher Lecture: Dimension Reduction in Regression", "comments": "Published at http://dx.doi.org/10.1214/088342307000000069 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 1, 32-35", "doi": "10.1214/088342307000000069", "report-no": "IMS-STS-STS225C", "categories": "stat.ME", "license": null, "abstract": "  Comment: Fisher Lecture: Dimension Reduction in Regression [arXiv:0708.3774]\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2007 13:01:27 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Li", "Bing", ""]]}, {"id": "0708.3779", "submitter": "Lexin Li", "authors": "Lexin Li, Christopher J. Nachtsheim", "title": "Comment: Fisher Lecture: Dimension Reduction in Regression", "comments": "Published at http://dx.doi.org/10.1214/088342307000000050 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 1, 36-39", "doi": "10.1214/088342307000000050", "report-no": "IMS-STS-STS225B", "categories": "stat.ME", "license": null, "abstract": "  Comment: Fisher Lecture: Dimension Reduction in Regression [arXiv:0708.3774]\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2007 13:06:40 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Li", "Lexin", ""], ["Nachtsheim", "Christopher J.", ""]]}, {"id": "0708.3781", "submitter": "R. Dennis Cook", "authors": "R. Dennis Cook", "title": "Rejoinder: Fisher Lecture: Dimension Reduction in Regression", "comments": "Published at http://dx.doi.org/10.1214/088342307000000078 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 1, 40-43", "doi": "10.1214/088342307000000078", "report-no": "IMS-STS-STS225REJ", "categories": "stat.ME", "license": null, "abstract": "  Rejoinder: Fisher Lecture: Dimension Reduction in Regression\n[arXiv:0708.3774]\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2007 13:18:35 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Cook", "R. Dennis", ""]]}, {"id": "0708.3796", "submitter": "Stephen T. Buckland", "authors": "Stephen T. Buckland, Ken B. Newman, Carmen Fern\\'andez, Len Thomas,\n  John Harwood", "title": "Embedding Population Dynamics Models in Inference", "comments": "Published at http://dx.doi.org/10.1214/088342306000000673 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 1, 44-58", "doi": "10.1214/088342306000000673", "report-no": "IMS-STS-STS224", "categories": "stat.ME", "license": null, "abstract": "  Increasing pressures on the environment are generating an ever-increasing\nneed to manage animal and plant populations sustainably, and to protect and\nrebuild endangered populations. Effective management requires reliable\nmathematical models, so that the effects of management action can be predicted,\nand the uncertainty in these predictions quantified. These models must be able\nto predict the response of populations to anthropogenic change, while handling\nthe major sources of uncertainty. We describe a simple ``building block''\napproach to formulating discrete-time models. We show how to estimate the\nparameters of such models from time series of data, and how to quantify\nuncertainty in those estimates and in numbers of individuals of different types\nin populations, using computer-intensive Bayesian methods. We also discuss\nadvantages and pitfalls of the approach, and give an example using the British\ngrey seal population.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2007 14:22:23 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Buckland", "Stephen T.", ""], ["Newman", "Ken B.", ""], ["Fern\u00e1ndez", "Carmen", ""], ["Thomas", "Len", ""], ["Harwood", "John", ""]]}, {"id": "0708.3797", "submitter": "Gareth O. Roberts", "authors": "Omiros Papaspiliopoulos, Gareth O. Roberts, Martin Sk\\\"old", "title": "A General Framework for the Parametrization of Hierarchical Models", "comments": "Published at http://dx.doi.org/10.1214/088342307000000014 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 1, 59-73", "doi": "10.1214/088342307000000014", "report-no": "IMS-STS-STS228", "categories": "stat.ME", "license": null, "abstract": "  In this paper, we describe centering and noncentering methodology as\ncomplementary techniques for use in parametrization of broad classes of\nhierarchical models, with a view to the construction of effective MCMC\nalgorithms for exploring posterior distributions from these models. We give a\nclear qualitative understanding as to when centering and noncentering work\nwell, and introduce theory concerning the convergence time complexity of Gibbs\nsamplers using centered and noncentered parametrizations. We give general\nrecipes for the construction of noncentered parametrizations, including an\nauxiliary variable technique called the state-space expansion technique. We\nalso describe partially noncentered methods, and demonstrate their use in\nconstructing robust Gibbs sampler algorithms whose convergence properties are\nnot overly sensitive to the data.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2007 14:45:04 GMT"}], "update_date": "2007-08-30", "authors_parsed": [["Papaspiliopoulos", "Omiros", ""], ["Roberts", "Gareth O.", ""], ["Sk\u00f6ld", "Martin", ""]]}, {"id": "0708.3961", "submitter": "Mark R. Segal", "authors": "Mark R. Segal", "title": "Chess, Chance and Conspiracy", "comments": "Published at http://dx.doi.org/10.1214/088342306000000574 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 1, 98-108", "doi": "10.1214/088342306000000574", "report-no": "IMS-STS-STS220", "categories": "stat.ME", "license": null, "abstract": "  Chess and chance are seemingly strange bedfellows. Luck and/or randomness\nhave no apparent role in move selection when the game is played at the highest\nlevels. However, when competition is at the ultimate level, that of the World\nChess Championship (WCC), chess and conspiracy are not strange bedfellows,\nthere being a long and colorful history of accusations levied between\nparticipants. One such accusation, frequently repeated, was that all the games\nin the 1985 WCC (Karpov vs Kasparov) were fixed and prearranged move by move.\nThat this claim was advanced by a former World Champion, Bobby Fischer, argues\nthat it ought be investigated. That the only published, concrete basis for this\nclaim consists of an observed run of particular moves, allows this\ninvestigation to be performed using probabilistic and statistical methods. In\nparticular, we employ imbedded finite Markov chains to evaluate run statistic\ndistributions. Further, we demonstrate how both chess computers and game data\nbases can be brought to bear on the problem.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2007 14:06:18 GMT"}], "update_date": "2007-08-30", "authors_parsed": [["Segal", "Mark R.", ""]]}, {"id": "0708.3965", "submitter": "David R. Bellhouse", "authors": "David R. Bellhouse, Christian Genest", "title": "Maty's Biography of Abraham De Moivre, Translated, Annotated and\n  Augmented", "comments": "Published at http://dx.doi.org/10.1214/088342306000000268 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 1, 109-136", "doi": "10.1214/088342306000000268", "report-no": "IMS-STS-STS156", "categories": "stat.ME", "license": null, "abstract": "  November 27, 2004, marked the 250th anniversary of the death of Abraham De\nMoivre, best known in statistical circles for his famous large-sample\napproximation to the binomial distribution, whose generalization is now\nreferred to as the Central Limit Theorem. De Moivre was one of the great\npioneers of classical probability theory. He also made seminal contributions in\nanalytic geometry, complex analysis and the theory of annuities. The first\nbiography of De Moivre, on which almost all subsequent ones have since relied,\nwas written in French by Matthew Maty. It was published in 1755 in the Journal\nbritannique. The authors provide here, for the first time, a complete\ntranslation into English of Maty's biography of De Moivre. New material, much\nof it taken from modern sources, is given in footnotes, along with numerous\nannotations designed to provide additional clarity to Maty's biography for\ncontemporary readers.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2007 14:33:34 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Bellhouse", "David R.", ""], ["Genest", "Christian", ""]]}, {"id": "0708.3974", "submitter": "Ronald Herman Randles", "authors": "Ronald Herman Randles", "title": "A Conversation with Robert V. Hogg", "comments": "Published at http://dx.doi.org/10.1214/088342306000000637 in the\n  Statistical Science (http://www.imstat.org/sts/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2007, Vol. 22, No. 1, 137-152", "doi": "10.1214/088342306000000637", "report-no": "IMS-STS-STS221", "categories": "stat.ME", "license": null, "abstract": "  Robert Vincent Hogg was born on November 8, 1924 in Hannibal, Missouri. He\nearned a Ph.D. in statistics at the University of Iowa in 1950, where his\nadvisor was Allen Craig. Following graduation, he joined the mathematics\nfaculty at the University of Iowa. He was the founding Chair when the\nDepartment of Statistics was created at Iowa in 1965 and he served in that\ncapacity for 19 years. At Iowa he also served as Chair of the Quality\nManagement and Productivity Program and the Hanson Chair of Manufacturing\nProductivity. He became Professor Emeritus in 2001 after 51 years on the Iowa\nfaculty. He is a Fellow of the Institute of Mathematical Statistics and the\nAmerican Statistical Association plus an Elected Member of the International\nStatistical Institute. He was President of the American Statistical Association\n(1988) and chaired two of its winter conferences (1992, 1994). He received the\nASA's Founder's Award (1991) and the Gottfried Noether Award (2001) for\ncontributions to nonparametric statistics. His publications through 1996 are\ndescribed in Communications in Statistics--Theory and Methods (1996),\n2467--2481. This interview was conducted on April 14, 2004 at the Department of\nStatistics, University of Florida, Gainesville, Florida, and revised in the\nsummer of 2006.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2007 15:06:56 GMT"}], "update_date": "2009-09-29", "authors_parsed": [["Randles", "Ronald Herman", ""]]}, {"id": "0708.4131", "submitter": "Laura L.R. Rifo", "authors": "Laura L. R. Rifo, Soledad Torres", "title": "Full Bayesian analysis for a class of jump-diffusion models", "comments": "15 pages, 7 figures; real data analysis added", "journal-ref": null, "doi": "10.1063/1.3039004", "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  A new Bayesian significance test is adjusted for jump detection in a\ndiffusion process. This is an advantageous procedure for temporal data having\nextreme valued outliers, like financial data, pluvial or tectonic forces\nrecords and others.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2007 12:19:33 GMT"}, {"version": "v2", "created": "Sat, 23 Feb 2008 00:06:12 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Rifo", "Laura L. R.", ""], ["Torres", "Soledad", ""]]}, {"id": "0708.4376", "submitter": "Kostas Triantafyllopoulos", "authors": "Kostas Triantafyllopoulos and Giovanni Montana", "title": "Fast estimation of multivariate stochastic volatility", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST stat.AP stat.ME", "license": null, "abstract": "  In this paper we develop a Bayesian procedure for estimating multivariate\nstochastic volatility (MSV) using state space models. A multiplicative model\nbased on inverted Wishart and multivariate singular beta distributions is\nproposed for the evolution of the volatility, and a flexible sequential\nvolatility updating is employed. Being computationally fast, the resulting\nestimation procedure is particularly suitable for on-line forecasting. Three\nperformance measures are discussed in the context of model selection: the\nlog-likelihood criterion, the mean of standardized one-step forecast errors,\nand sequential Bayes factors. Finally, the proposed methods are applied to a\ndata set comprising eight exchange rates vis-a-vis the US dollar.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2007 17:56:38 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2007 19:39:19 GMT"}], "update_date": "2008-12-02", "authors_parsed": [["Triantafyllopoulos", "Kostas", ""], ["Montana", "Giovanni", ""]]}]