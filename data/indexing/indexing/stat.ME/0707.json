[{"id": "0707.0143", "submitter": "Matt Wand Professor", "authors": "M.P. Wand and J.T. Ormerod", "title": "On semiparametric regression with O'Sullivan penalised splines", "comments": "19 pages with 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  This is an expos\\'e on the use of O'Sullivan penalised splines in\ncontemporary semiparametric regression, including mixed model and Bayesian\nformulations. O'Sullivan penalised splines are similar to P-splines, but have\nan advantage of being a direct generalisation of smoothing splines. Exact\nexpressions for the O'Sullivan penalty matrix are obtained. Comparisons between\nthe two reveals that O'Sullivan penalised splines more closely mimic the\nnatural boundary behaviour of smoothing splines. Implementation in modern\ncomputing environments such as Matlab, R and BUGS is discussed.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2007 05:12:37 GMT"}], "update_date": "2007-07-03", "authors_parsed": [["Wand", "M. P.", ""], ["Ormerod", "J. T.", ""]]}, {"id": "0707.0246", "submitter": "Christian Paroissin", "authors": "Christian Paroissin (LMA - PAU)", "title": "A new graphical tool of outliers detection in regression models based on\n  recursive estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  We present in this paper a new tool for outliers detection in the context of\nmultiple regression models. This graphical tool is based on recursive\nestimation of the parameters. Simulations were carried out to illustrate the\nperformance of this graphical procedure. As a conclusion, this tool is applied\nto real data containing outliers according to the classical available tools.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2007 14:58:54 GMT"}], "update_date": "2007-07-03", "authors_parsed": [["Paroissin", "Christian", "", "LMA - PAU"]]}, {"id": "0707.0303", "submitter": "Ingo Steinwart", "authors": "Ingo Steinwart, Don Hush, Clint Scovel", "title": "Learning from dependent observations", "comments": "submitted to Journal of Multivariate Analysis", "journal-ref": null, "doi": null, "report-no": "Los Alamos National Laboratory Technical Report LA-UR-06-3507", "categories": "stat.ML stat.ME", "license": null, "abstract": "  In most papers establishing consistency for learning algorithms it is assumed\nthat the observations used for training are realizations of an i.i.d. process.\nIn this paper we go far beyond this classical framework by showing that support\nvector machines (SVMs) essentially only require that the data-generating\nprocess satisfies a certain law of large numbers. We then consider the\nlearnability of SVMs for $\\a$-mixing (not necessarily stationary) processes for\nboth classification and regression, where for the latter we explicitly allow\nunbounded noise.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2007 20:16:49 GMT"}], "update_date": "2007-07-04", "authors_parsed": [["Steinwart", "Ingo", ""], ["Hush", "Don", ""], ["Scovel", "Clint", ""]]}, {"id": "0707.0322", "submitter": "Marian Anghel", "authors": "Ingo Steinwart, Marian Anghel", "title": "Consistency of support vector machines for forecasting the evolution of\n  an unknown ergodic dynamical system from observations with unknown noise", "comments": "Published in at http://dx.doi.org/10.1214/07-AOS562 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2009, Vol. 37, No. 2, 841-875", "doi": "10.1214/07-AOS562", "report-no": "IMS-AOS-AOS562", "categories": "stat.ME math.DS math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of forecasting the next (observable) state of an\nunknown ergodic dynamical system from a noisy observation of the present state.\nOur main result shows, for example, that support vector machines (SVMs) using\nGaussian RBF kernels can learn the best forecaster from a sequence of noisy\nobservations if (a) the unknown observational noise process is bounded and has\na summable $\\alpha$-mixing rate and (b) the unknown ergodic dynamical system is\ndefined by a Lipschitz continuous function on some compact subset of\n$\\mathbb{R}^d$ and has a summable decay of correlations for Lipschitz\ncontinuous functions. In order to prove this result we first establish a\ngeneral consistency result for SVMs and all stochastic processes that satisfy a\nmixing notion that is substantially weaker than $\\alpha$-mixing.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2007 23:56:10 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2009 14:20:48 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Steinwart", "Ingo", ""], ["Anghel", "Marian", ""]]}, {"id": "0707.0481", "submitter": "Ann Lee", "authors": "Ann B. Lee, Boaz Nadler, Larry Wasserman", "title": "Treelets--An adaptive multi-scale basis for sparse unordered data", "comments": "This paper commented in: [arXiv:0807.4011], [arXiv:0807.4016],\n  [arXiv:0807.4018], [arXiv:0807.4019], [arXiv:0807.4023], [arXiv:0807.4024].\n  Rejoinder in [arXiv:0807.4028]. Published in at\n  http://dx.doi.org/10.1214/07-AOAS137 the Annals of Applied Statistics\n  (http://www.imstat.org/aoas/) by the Institute of Mathematical Statistics\n  (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2008, Vol. 2, No. 2, 435-471", "doi": "10.1214/07-AOAS137", "report-no": "IMS-AOAS-AOAS137", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many modern applications, including analysis of gene expression and text\ndocuments, the data are noisy, high-dimensional, and unordered--with no\nparticular meaning to the given order of the variables. Yet, successful\nlearning is often possible due to sparsity: the fact that the data are\ntypically redundant with underlying structures that can be represented by only\na few features. In this paper we present treelets--a novel construction of\nmulti-scale bases that extends wavelets to nonsmooth signals. The method is\nfully adaptive, as it returns a hierarchical tree and an orthonormal basis\nwhich both reflect the internal structure of the data. Treelets are especially\nwell-suited as a dimensionality reduction and feature selection tool prior to\nregression and classification, in situations where sample sizes are small and\nthe data are sparse with unknown groupings of correlated or collinear\nvariables. The method is also simple to implement and analyze theoretically.\nHere we describe a variety of situations where treelets perform better than\nprincipal component analysis, as well as some common variable selection and\ncluster averaging schemes. We illustrate treelets on a blocked covariance model\nand on several data sets (hyperspectral image data, DNA microarray data, and\ninternet advertisements) with highly complex dependencies between variables.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2007 19:22:35 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2007 19:19:22 GMT"}, {"version": "v3", "created": "Fri, 25 Jul 2008 08:43:51 GMT"}], "update_date": "2008-07-25", "authors_parsed": [["Lee", "Ann B.", ""], ["Nadler", "Boaz", ""], ["Wasserman", "Larry", ""]]}, {"id": "0707.0660", "submitter": "Vladimir Vovk", "authors": "Vladimir Vovk", "title": "Strong confidence intervals for autoregression", "comments": "7 pages, 2 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": null, "abstract": "  In this short note I apply the methodology of game-theoretic probability to\ncalculating non-asymptotic confidence intervals for the coefficient of a simple\nfirst order scalar autoregressive model. The most distinctive feature of the\nproposed procedure is that with high probability it produces confidence\nintervals that always cover the true parameter value when applied sequentially.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2007 16:44:59 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Vovk", "Vladimir", ""]]}, {"id": "0707.0837", "submitter": "Xinjia Chen", "authors": "Xinjia Chen, Kemin Zhou and Jorge L. Aravena", "title": "Explicit Formula for Constructing Binomial Confidence Interval with\n  Guaranteed Coverage Probability", "comments": "20 pages, 27 figures", "journal-ref": "Communications in Statistics -- Theory and Methods, vol. 37, pp.\n  1173--1180, 2008", "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": null, "abstract": "  In this paper, we derive an explicit formula for constructing the confidence\ninterval of binomial parameter with guaranteed coverage probability. The\nformula overcomes the limitation of normal approximation which is asymptotic in\nnature and thus inevitably introduce unknown errors in applications. Moreover,\nthe formula is very tight in comparison with classic Clopper-Pearson's approach\nfrom the perspective of interval width. Based on the rigorous formula, we also\nobtain approximate formulas with excellent performance of coverage probability.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2007 17:16:37 GMT"}], "update_date": "2008-05-12", "authors_parsed": [["Chen", "Xinjia", ""], ["Zhou", "Kemin", ""], ["Aravena", "Jorge L.", ""]]}, {"id": "0707.2113", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Exact Computation of Minimum Sample Size for Estimation of Binomial\n  Parameters", "comments": "18 pages, no figures, removed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": null, "abstract": "  It is a common contention that it is an ``impossible mission'' to exactly\ndetermine the minimum sample size for the estimation of a binomial parameter\nwith prescribed margin of error and confidence level. In this paper, we\ninvestigate such a very old but also extremely important problem and\ndemonstrate that the difficulty for obtaining the exact solution is not\ninsurmountable. Unlike the classical approximate sample size method based on\nthe central limit theorem, we develop a new approach for computing the minimum\nsample size that does not require any approximation. Moreover, our approach\novercomes the conservatism of existing rigorous sample size methods derived\nfrom Bernoulli's theorem or Chernoff bounds.\n  Our computational machinery consists of two essential ingredients. First, we\nprove that the minimum of coverage probability with respect to a binomial\nparameter bounded in an interval is attained at a discrete set of finite many\nvalues of the binomial parameter. This allows for reducing infinite many\nevaluations of coverage probability to finite many evaluations. Second, a\nrecursive bounding technique is developed to further improve the efficiency of\ncomputation.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2007 02:05:59 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2007 20:55:50 GMT"}], "update_date": "2007-08-02", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0707.2115", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Exact Computation of Minimum Sample Size for Estimating Proportion of\n  Finite Population", "comments": "13 pages, no figure, fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": null, "abstract": "  In this paper, we develop an exact method for the determination of the\nminimum sample size for estimating the proportion of a finite population with\nprescribed margin of error and confidence level. By characterizing the behavior\nof the coverage probability with respect to the proportion, we show that the\ncomputational complexity can be significantly reduced and bounded regardless\npopulation size.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2007 02:14:16 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2007 02:32:09 GMT"}, {"version": "v3", "created": "Sat, 21 Jul 2007 14:57:22 GMT"}, {"version": "v4", "created": "Thu, 2 Aug 2007 21:32:28 GMT"}], "update_date": "2007-08-03", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0707.2116", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Exact Computation of Minimum Sample size for Estimation of Poisson\n  Parameters", "comments": "10 pages, no figure, revised the last paragraph of page 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an approach for the exact determination of the\nminimum sample size for the estimation of a Poisson parameter with prescribed\nmargin of error and confidence level. The exact computation is made possible by\nreducing infinite many evaluations of coverage probability to finite many\nevaluations. Such reduction is based on our discovery that the minimum of\ncoverage probability with respect to a Poisson parameter bounded in an interval\nis attained at a discrete set of finite many values.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2007 02:19:04 GMT"}, {"version": "v2", "created": "Thu, 2 Aug 2007 21:01:46 GMT"}, {"version": "v3", "created": "Thu, 19 Jun 2008 19:09:49 GMT"}], "update_date": "2008-06-19", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0707.2158", "submitter": "Robert Kohn", "authors": "Remy Cottet, Robert Kohn and David Nott", "title": "Variable Selection and Model Averaging in Semiparametric Overdispersed\n  Generalized Linear Models", "comments": "8 graphs 35 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  We express the mean and variance terms in a double exponential regression\nmodel as additive functions of the predictors and use Bayesian variable\nselection to determine which predictors enter the model, and whether they enter\nlinearly or flexibly. When the variance term is null we obtain a generalized\nadditive model, which becomes a generalized linear model if the predictors\nenter the mean linearly. The model is estimated using Markov chain Monte Carlo\nsimulation and the methodology is illustrated using real and simulated data\nsets.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2007 16:00:44 GMT"}], "update_date": "2007-07-17", "authors_parsed": [["Cottet", "Remy", ""], ["Kohn", "Robert", ""], ["Nott", "David", ""]]}, {"id": "0707.2257", "submitter": "Man-Wai Ho", "authors": "Man-Wai Ho", "title": "A Bayes method for a Bathtub Failure Rate via two $\\mathbf{S}$-paths", "comments": "30 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": null, "abstract": "  A class of semi-parametric hazard/failure rates with a bathtub shape is of\ninterest. It does not only provide a great deal of flexibility over existing\nparametric methods in the modeling aspect but also results in a closed and\ntractable Bayes estimator for the bathtub-shaped failure rate (BFR). Such an\nestimator is derived to be a finite sum over two $\\mathbf{S}$-paths due to an\nexplicit posterior analysis in terms of two (conditionally independent)\n$\\mathbf{S}$-paths. These, newly discovered, explicit results can be proved to\nbe a Rao-Blackwellization of counterpart results in terms of partitions that\nare readily available by a specialization of James (2005)'s work. We develop\nboth iterative and non-iterative computational procedures based on existing\nefficient Monte Carlo methods for sampling one single $\\mathbf{S}$-path.\nNmerical simulations are given to demonstrate the practicality and the\neffectiveness of our methodology. Last but not least, two applications of the\nproposed method are discussed, of which one is about a Bayesian test for\nfailure rates and the other is related to modeling with covariates.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2007 03:37:39 GMT"}], "update_date": "2007-07-17", "authors_parsed": [["Ho", "Man-Wai", ""]]}, {"id": "0707.2814", "submitter": "Xinjia Chen", "authors": "Xinjia Chen", "title": "Coverage Probability of Random Intervals", "comments": "21 pages, 2 figure, revised Theorem 7", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a general theory on the coverage probability of\nrandom intervals defined in terms of discrete random variables with continuous\nparameter spaces. The theory shows that the minimum coverage probabilities of\nrandom intervals with respect to corresponding parameters are achieved at\ndiscrete finite sets and that the coverage probabilities are continuous and\nunimodal when parameters are varying in between interval endpoints. The theory\napplies to common important discrete random variables including binomial\nvariable, Poisson variable, negative binomial variable and hypergeometrical\nrandom variable. The theory can be used to make relevant statistical inference\nmore rigorous and less conservative.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2007 13:19:17 GMT"}, {"version": "v10", "created": "Thu, 17 Sep 2009 21:56:14 GMT"}, {"version": "v11", "created": "Sun, 13 Mar 2011 23:18:24 GMT"}, {"version": "v12", "created": "Wed, 16 Mar 2011 04:53:41 GMT"}, {"version": "v13", "created": "Mon, 11 Apr 2011 01:24:21 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2007 18:02:16 GMT"}, {"version": "v3", "created": "Mon, 23 Jul 2007 18:56:07 GMT"}, {"version": "v4", "created": "Wed, 1 Aug 2007 00:10:01 GMT"}, {"version": "v5", "created": "Tue, 7 Aug 2007 09:45:45 GMT"}, {"version": "v6", "created": "Sat, 25 Aug 2007 21:30:35 GMT"}, {"version": "v7", "created": "Mon, 3 Sep 2007 00:53:34 GMT"}, {"version": "v8", "created": "Thu, 19 Jun 2008 18:38:17 GMT"}, {"version": "v9", "created": "Sun, 3 Aug 2008 00:43:25 GMT"}], "update_date": "2011-04-12", "authors_parsed": [["Chen", "Xinjia", ""]]}, {"id": "0707.4643", "submitter": "Lutz Duembgen", "authors": "Lutz Duembgen, Andre Huesler, Kaspar Rufibach", "title": "Active Set and EM Algorithms for Log-Concave Densities Based on Complete\n  and Censored Data", "comments": "Changes in versions 3-4: Updated references, corrections of minor\n  errors, shortened section on EM algorithm (which will be treated in more\n  detail in a separate paper)", "journal-ref": null, "doi": null, "report-no": "Technical report 61, IMSV, University of Bern", "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an active set algorithm for the maximum likelihood estimation of a\nlog-concave density based on complete data. Building on this fast algorithm, we\nindidate an EM algorithm to treat arbitrarily censored or binned data.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2007 15:47:44 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2007 05:45:26 GMT"}, {"version": "v3", "created": "Fri, 13 Aug 2010 11:37:45 GMT"}, {"version": "v4", "created": "Fri, 18 Mar 2011 12:56:04 GMT"}], "update_date": "2011-03-21", "authors_parsed": [["Duembgen", "Lutz", ""], ["Huesler", "Andre", ""], ["Rufibach", "Kaspar", ""]]}]