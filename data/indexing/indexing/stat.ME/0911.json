[{"id": "0911.0047", "submitter": "Ethan Anderes", "authors": "Ethan Anderes and Michael Stein", "title": "Local likelihood estimation of local parameters for nonstationary random\n  fields", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a weighted local likelihood estimate for the parameters that\ngovern the local spatial dependency of a locally stationary random field. The\nadvantage of this local likelihood estimate is that it smoothly downweights the\ninfluence of far away observations, works for irregular sampling locations, and\nwhen designed appropriately, can trade bias and variance for reducing\nestimation error. This paper starts with an exposition of our technique on the\nproblem of estimating an unknown positive function when multiplied by a\nstationary random field. This example gives concrete evidence of the benefits\nof our local likelihood as compared to na\\\"ive local likelihoods where the\nstationary model is assumed throughout a neighborhood. We then discuss the\ndifficult problem of estimating a bandwidth parameter that controls the amount\nof influence from distant observations. Finally we present a simulation\nexperiment for estimating the local smoothness of a local Mat\\'ern random field\nwhen observing the field at random sampling locations in $[0,1]^2$.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2009 00:57:51 GMT"}], "update_date": "2009-11-03", "authors_parsed": [["Anderes", "Ethan", ""], ["Stein", "Michael", ""]]}, {"id": "0911.0108", "submitter": "Yaming Yu", "authors": "Yaming Yu", "title": "D-optimal designs via a cocktail algorithm", "comments": "A number of changes after accounting for the referees' comments\n  including new examples in Section 4 and more detailed explanations throughout", "journal-ref": "Statistics and Computing 21 (2011) 475-481", "doi": "10.1007/s11222-010-9183-2", "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fast new algorithm is proposed for numerical computation of (approximate)\nD-optimal designs. This \"cocktail algorithm\" extends the well-known vertex\ndirection method (VDM; Fedorov 1972) and the multiplicative algorithm (Silvey,\nTitterington and Torsney, 1978), and shares their simplicity and monotonic\nconvergence properties. Numerical examples show that the cocktail algorithm can\nlead to dramatically improved speed, sometimes by orders of magnitude, relative\nto either the multiplicative algorithm or the vertex exchange method (a variant\nof VDM). Key to the improved speed is a new nearest neighbor exchange strategy,\nwhich acts locally and complements the global effect of the multiplicative\nalgorithm. Possible extensions to related problems such as nonparametric\nmaximum likelihood estimation are mentioned.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2009 20:32:12 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2009 22:40:35 GMT"}, {"version": "v3", "created": "Wed, 19 May 2010 16:29:00 GMT"}], "update_date": "2011-08-15", "authors_parsed": [["Yu", "Yaming", ""]]}, {"id": "0911.0230", "submitter": "Robert Kohn", "authors": "Ralph Silva, Paolo Giordani, Robert Kohn and Mike Pitt", "title": "Particle filtering within adaptive Metropolis Hastings sampling", "comments": "37 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that it is feasible to carry out exact Bayesian inference for\nnon-Gaussian state space models using an adaptive Metropolis Hastings sampling\nscheme with the likelihood approximated by the particle filter. Furthermore, an\nadapyive independent Metropolis Hastings sampler based on a mixture of normals\nproposal is computationally much more efficient than an adaptive random walk\nproposal because the cost of constructing a good adaptive proposal is\nnegligible compared to the cost of approximating the likelihood. Independent\nMetropolis Hastings proposals are also attractive because they are easy to run\nin parallel on multiple processors. We also show that when the particle filter\nis used, the marginal likelihood of any model is obtained in an efficient and\nunbiased manner, making model comparison straightforward.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2009 13:43:29 GMT"}], "update_date": "2009-11-03", "authors_parsed": [["Silva", "Ralph", ""], ["Giordani", "Paolo", ""], ["Kohn", "Robert", ""], ["Pitt", "Mike", ""]]}, {"id": "0911.0930", "submitter": "Vladimir Minin", "authors": "Vladimir N. Minin, John D. O'Brien, Arseni Seregin", "title": "Imputation Estimators Partially Correct for Model Misspecification", "comments": "major rewrite, beta-binomial example removed, model based clustering\n  is added to the mixture model example, Bayesian approach is now illustrated\n  with the genetics example", "journal-ref": null, "doi": "10.2202/1544-6115.1650", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference problems with incomplete observations often aim at estimating\npopulation properties of unobserved quantities. One simple way to accomplish\nthis estimation is to impute the unobserved quantities of interest at the\nindividual level and then take an empirical average of the imputed values. We\nshow that this simple imputation estimator can provide partial protection\nagainst model misspecification. We illustrate imputation estimators' robustness\nto model specification on three examples: mixture model-based clustering,\nestimation of genotype frequencies in population genetics, and estimation of\nMarkovian evolutionary distances. In the final example, using a representative\nmodel misspecification, we demonstrate that in non-degenerate cases, the\nimputation estimator dominates the plug-in estimate asymptotically. We conclude\nby outlining a Bayesian implementation of the imputation-based estimation.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2009 21:02:20 GMT"}, {"version": "v2", "created": "Fri, 23 Apr 2010 21:46:55 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Minin", "Vladimir N.", ""], ["O'Brien", "John D.", ""], ["Seregin", "Arseni", ""]]}, {"id": "0911.0985", "submitter": "Christian P. Robert", "authors": "Pierre Jacob, Nicolas Chopin, Christian P. Robert and Havard Rue", "title": "Comments on \"Particle Markov chain Monte Carlo\" by C. Andrieu, A.\n  Doucet, and R. Hollenstein", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the compilation of our comments submitted to the Journal of the Royal\nStatistical Society, Series B, to be published within the discussion of the\nRead Paper of Andrieu, Doucet and Hollenstein.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2009 07:10:03 GMT"}], "update_date": "2009-11-06", "authors_parsed": [["Jacob", "Pierre", ""], ["Chopin", "Nicolas", ""], ["Robert", "Christian P.", ""], ["Rue", "Havard", ""]]}, {"id": "0911.1117", "submitter": "Ana Cecilia Tablar", "authors": "Beatriz Marron, Ana Tablar", "title": "Irregular sets and Central Limit Theorems for dependent triangular\n  arrays", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous papers, we studied the asymptotic behaviour of\n$S_N(A,X)=(2N+1)^{-d/2}\\sum_{n \\in A_N} X_n,$ where $X$ is a centered,\nstationary and weakly dependent random field, and $A_N=A \\cap [-N,N]^d$, $A\n\\subset \\mathbb{Z}^d$. This leads to the definition of asymptotically\nmeasurable sets, which enjoy the property that $S_N(A;X)$ has a Gaussian weak\nlimit for any $X$ belonging to a certain class. Here we extend this type of\nresults to the case of weakly dependent triangular arrays and present an\napplication of this technique to regression models. Indeed, we prove that CLT\nand related results hold for $X_n^N=\\varphi(\\xi_n^N,Y_n^N), n \\in\n\\mathbb{Z}^d$, where $\\varphi$ satisfies certain regularity conditions, $\\xi$\nand $Y$ are independent random fields, $\\xi$ is weakly dependent and $Y$\nsatisfies some Strong Law of Large Numbers.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2009 20:05:09 GMT"}], "update_date": "2009-11-06", "authors_parsed": [["Marron", "Beatriz", ""], ["Tablar", "Ana", ""]]}, {"id": "0911.1159", "submitter": "Andre Fujita", "authors": "Andre Fujita, Joao Ricardo Sato, Kaname Kojima, Luciana Rodrigues\n  Gomes, Masao Nagasaki, Mari Cleide Sogayar, Satoru Miyano", "title": "Identification and quantification of Granger causality between gene sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wiener and Granger have introduced an intuitive concept of causality between\ntwo variables which is based on the idea that an effect never occurs before its\ncause. Later, Geweke has generalized this concept to a multivariate Granger\ncausality, i.e., n variables Granger-cause another variable. Although Granger\ncausality is not \"effective causality\", this concept is useful to infer\ndirectionality and information flow in observational data. Granger causality is\nusually identified by using VAR models due to their simplicity. In the last few\nyears, several VAR-based models were presented in order to model gene\nregulatory networks. Here, we generalize the multivariate Granger causality\nconcept in order to identify Granger causalities between sets of gene\nexpressions, i.e., whether a set of n genes Granger-causes another set of m\ngenes, aiming at identifying and quantifying the flow of information between\ngene networks (or pathways). The concept of Granger causality for sets of\nvariables is presented. Moreover, a method for its identification with a\nbootstrap test is proposed. This method is applied in simulated and also in\nactual biological gene expression data in order to model regulatory networks.\nThis concept may be useful to understand the complete information flow from one\nnetwork or pathway to the other, mainly in regulatory networks. Linking this\nconcept to graph theory, sink and source can be generalized to node sets.\nMoreover, hub and centrality for sets of genes can be defined based on total\ninformation flow. Another application is in annotation, when the functionality\nof a set of genes is unknown, but this set is Granger caused by another set of\ngenes which is well studied. Therefore, this information may be useful to infer\nor construct some hypothesis about the unknown set of genes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2009 01:16:13 GMT"}], "update_date": "2009-11-09", "authors_parsed": [["Fujita", "Andre", ""], ["Sato", "Joao Ricardo", ""], ["Kojima", "Kaname", ""], ["Gomes", "Luciana Rodrigues", ""], ["Nagasaki", "Masao", ""], ["Sogayar", "Mari Cleide", ""], ["Miyano", "Satoru", ""]]}, {"id": "0911.1318", "submitter": "Loet Leydesdorff", "authors": "Leo Egghe, Loet Leydesdorff", "title": "The relation between Pearson's correlation coefficient r and Salton's\n  cosine measure", "comments": null, "journal-ref": "Journal of the American Society for Information Science and\n  Technology 60(5) (2009) 1027-1036", "doi": "10.1016/j.eswa.2012.07.016", "report-no": null, "categories": "cs.IR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relation between Pearson's correlation coefficient and Salton's cosine\nmeasure is revealed based on the different possible values of the division of\nthe L1-norm and the L2-norm of a vector. These different values yield a sheaf\nof increasingly straight lines which form together a cloud of points, being the\ninvestigated relation. The theoretical results are tested against the author\nco-citation relations among 24 informetricians for whom two matrices can be\nconstructed, based on co-citations: the asymmetric occurrence matrix and the\nsymmetric co-citation matrix. Both examples completely confirm the theoretical\nresults. The results enable us to specify an algorithm which provides a\nthreshold value for the cosine above which none of the corresponding Pearson\ncorrelations would be negative. Using this threshold value can be expected to\noptimize the visualization of the vector space.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2009 18:09:07 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Egghe", "Leo", ""], ["Leydesdorff", "Loet", ""]]}, {"id": "0911.1472", "submitter": "Bastiaan Geelhoed", "authors": "Bastiaan Geelhoed", "title": "Variable Second-Order Inclusion Probabilities as a Tool to Predict the\n  Sampling Variance", "comments": "This work was presented at the Third World Conference on Sampling and\n  Blending, October 2007, Porto Alegre, Brasil", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generalization of Gy's theory for the variance of the fundamental sampling\nerror is reviewed. Practical situations where the generalized model potentially\nleads to more accurate variance estimates are identified as: clustering of\nparticles, differences in densities or sizes of the particles or repulsive\ninter-particle forces. Two general approaches for estimating an input parameter\nfor the generalized model are discussed. The first approach consists of\nmodelling based on physical properties of particles such as size, density and\nelectrostatic forces between particles. The second approach uses image analysis\nof actual samples. Further research into both methods is proposed and a\nsuggestion is made to use line-intercept sampling combined with Markov Chain\nmodelling in the second approach.\n  It is concluded that although, at the moment, it is too early for a routine\napplication of the generalized theory, the generalization has the potential of\nproviding more accurate variance estimates than are possible in the theory of\nGy. Therefore, further research into the development and expansion of the\ngeneralized theory is worthwhile.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2009 22:29:18 GMT"}], "update_date": "2009-11-10", "authors_parsed": [["Geelhoed", "Bastiaan", ""]]}, {"id": "0911.1768", "submitter": "James Scott", "authors": "James G. Scott", "title": "Benchmarking Historical Corporate Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses Bayesian tree models for statistical benchmarking in data\nsets with awkward marginals and complicated dependence structures. The method\nis applied to a very large database on corporate performance over the last four\ndecades. The results of this study provide a formal basis for making\ncross-peer-group comparisons among companies in very different industries and\noperating environments. This is done by using models for Bayesian multiple\nhypothesis testing to determine which firms, if any, have systematically\noutperformed their peer groups over time. We conclude that systematic\noutperformance, while it seems to exist, is quite rare worldwide.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2009 00:35:27 GMT"}, {"version": "v2", "created": "Mon, 25 Oct 2010 19:03:49 GMT"}], "update_date": "2010-10-26", "authors_parsed": [["Scott", "James G.", ""]]}, {"id": "0911.1894", "submitter": "Yanan Fan Dr", "authors": "Y. Fan, J.-L Dortet-Bernadet, S. A. Sisson", "title": "On Bayesian Curve Fitting Via Auxiliary Variables", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we revisit the auxiliary variable method introduced in Smith\nand kohn (1996) for the fitting of P-th order spline regression models with an\nunknown number of knot points. We introduce modifications which allow the\nlocation of knot points to be random, and we further consider an extension of\nthe method to handle models with non-Gaussian errors. We provide a new\nalgorithm for the MCMC sampling of such models. Simulated data examples are\nused to compare the performance of our method with existing ones. Finally, we\nmake a connection with some change-point problems, and show how they can be\nre-parameterised to the variable selection setting.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2009 12:18:06 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2009 16:25:32 GMT"}], "update_date": "2009-11-11", "authors_parsed": [["Fan", "Y.", ""], ["Dortet-Bernadet", "J. -L", ""], ["Sisson", "S. A.", ""]]}, {"id": "0911.1928", "submitter": "Andrew Smith", "authors": "Arne Kovac and Andrew D.A.C. Smith", "title": "Regression on a Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The `Signal plus Noise' model for nonparametric regression can be extended to\nthe case of observations taken at the vertices of a graph. This model includes\nmany familiar regression problems. This article discusses the use of the edges\nof a graph to measure roughness in penalized regression. Distance between\nestimate and observation is measured at every vertex in the $L_2$ norm, and\nroughness is penalized on every edge in the $L_1$ norm. Thus the ideas of\ntotal-variation penalization can be extended to a graph. The resulting\nminimization problem presents special computational challenges, so we describe\na new, fast algorithm and demonstrate its use with examples.\n  Further examples include a graphical approach that gives an improved estimate\nof the baseline in spectroscopic analysis, and a simulation applicable to\ndiscrete spatial variation. In our example, penalized regression outperforms\nkernel smoothing in terms of identifying local extreme values. In all examples\nwe use fully automatic procedures for setting the smoothing parameters.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2009 15:29:49 GMT"}], "update_date": "2009-11-11", "authors_parsed": [["Kovac", "Arne", ""], ["Smith", "Andrew D. A. C.", ""]]}, {"id": "0911.2093", "submitter": "Adelchi Azzalini", "authors": "Adelchi Azzalini and Antonella Capitanio", "title": "Statistical applications of the multivariate skew-normal distribution", "comments": "full-length version of the published paper, 32 pages, with 7 figures,\n  uses psfrag", "journal-ref": "J. Royal Statistical Society, series B, 61 (1999) 579-602", "doi": "10.1111/1467-9868.00194", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Azzalini & Dalla Valle (1996) have recently discussed the multivariate\nskew-normal distribution which extends the class of normal distributions by the\naddition of a shape parameter. The first part of the present paper examines\nfurther probabilistic properties of the distribution, with special emphasis on\naspects of statistical relevance. Inferential and other statistical issues are\ndiscussed in the following part, with applications to some multivariate\nstatistics problems, illustrated by numerical examples. Finally, a further\nextension is described which introduces a skewing factor of an elliptical\ndensity.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2009 10:50:27 GMT"}], "update_date": "2009-11-12", "authors_parsed": [["Azzalini", "Adelchi", ""], ["Capitanio", "Antonella", ""]]}, {"id": "0911.2342", "submitter": "Adelchi Azzalini", "authors": "Adelchi Azzalini and Antonella Capitanio", "title": "Distributions generated by perturbation of symmetry with emphasis on a\n  multivariate skew $t$ distribution", "comments": "full-length version of the published paper, 31 pages with 9 figures", "journal-ref": "J. Royal Statistical Society, series B, 65 (2003), 367-389", "doi": "10.1111/1467-9868.00391", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fairly general procedure is studied to perturbate a multivariate density\nsatisfying a weak form of multivariate symmetry, and to generate a whole set of\nnon-symmetric densities. The approach is general enough to encompass a number\nof recent proposals in the literature, variously related to the skew normal\ndistribution. The special case of skew elliptical densities is examined in\ndetail, establishing connections with existing similar work. The final part of\nthe paper specializes further to a form of multivariate skew $t$ density.\nLikelihood inference for this distribution is examined, and it is illustrated\nwith numerical examples.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 10:11:53 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Azzalini", "Adelchi", ""], ["Capitanio", "Antonella", ""]]}, {"id": "0911.2375", "submitter": "Philipp R\\\"utimann", "authors": "Philipp R\\\"utimann, Peter B\\\"uhlmann", "title": "High dimensional sparse covariance estimation via directed acyclic\n  graphs", "comments": null, "journal-ref": "Electronic Journal of Statistics, 3, (2009), 1133-1160\n  (electronic)", "doi": "10.1214/09-EJS534", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a graph-based technique for estimating sparse covariance matrices\nand their inverses from high-dimensional data. The method is based on learning\na directed acyclic graph (DAG) and estimating parameters of a multivariate\nGaussian distribution based on a DAG. For inferring the underlying DAG we use\nthe PC-algorithm and for estimating the DAG-based covariance matrix and its\ninverse, we use a Cholesky decomposition approach which provides a positive\n(semi-)definite sparse estimate. We present a consistency result in the\nhigh-dimensional framework and we compare our method with the Glasso for\nsimulated and real data.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 13:43:13 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2009 11:27:39 GMT"}], "update_date": "2010-01-18", "authors_parsed": [["R\u00fctimann", "Philipp", ""], ["B\u00fchlmann", "Peter", ""]]}, {"id": "0911.2381", "submitter": "Ferm\\'in Moscoso del Prado Mart\\'in", "authors": "Ferm\\'in Moscoso del Prado Mart\\'in", "title": "Analytical Determination of Fractal Structure in Stochastic Time Series", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cond-mat.stat-mech cs.LG nlin.CD stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current methods for determining whether a time series exhibits fractal\nstructure (FS) rely on subjective assessments on estimators of the Hurst\nexponent (H). Here, I introduce the Bayesian Assessment of Scaling, an\nanalytical framework for drawing objective and accurate inferences on the FS of\ntime series. The technique exploits the scaling property of the diffusion\nassociated to a time series. The resulting criterion is simple to compute and\nrepresents an accurate characterization of the evidence supporting different\nhypotheses on the scaling regime of a time series. Additionally, a closed-form\nMaximum Likelihood estimator of H is derived from the criterion, and this\nestimator outperforms the best available estimators.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2009 13:08:20 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Mart\u00edn", "Ferm\u00edn Moscoso del Prado", ""]]}, {"id": "0911.2634", "submitter": "Giorgio Vittadini Mr", "authors": "Salvatore Ingrassia, Simona C. Minotti, Giorgio Vittadini", "title": "Local statistical modeling by cluster-weighted", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate statistical properties of Cluster-Weighted Modeling, which is\na framework for supervised learning originally developed in order to recreate a\ndigital violin with traditional inputs and realistic sound. The analysis is\ncarried out in comparison with Finite Mixtures of Regression models. Based on\nsome geometrical arguments, we highlight that Cluster-WeightedModeling provides\na quite general framework for local statistical modeling. Theoretical results\nare illustrated on the ground of some numerical simulations.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2009 15:20:29 GMT"}, {"version": "v2", "created": "Mon, 13 Sep 2010 09:35:36 GMT"}, {"version": "v3", "created": "Wed, 15 Jun 2011 09:47:06 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Ingrassia", "Salvatore", ""], ["Minotti", "Simona C.", ""], ["Vittadini", "Giorgio", ""]]}, {"id": "0911.2888", "submitter": "Lotfi Chaari", "authors": "L. Cha\\^ari, J.-C. Pesquet, J.-Y. Tourneret, Ph. Ciuciu and A.\n  Benazza-Benyahia", "title": "A Hierarchical Bayesian Model for Frame Representation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2010.2055562", "report-no": null, "categories": "stat.ME math.PR math.ST stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many signal processing problems, it may be fruitful to represent the\nsignal under study in a frame. If a probabilistic approach is adopted, it\nbecomes then necessary to estimate the hyper-parameters characterizing the\nprobability distribution of the frame coefficients. This problem is difficult\nsince in general the frame synthesis operator is not bijective. Consequently,\nthe frame coefficients are not directly observable. This paper introduces a\nhierarchical Bayesian model for frame representation. The posterior\ndistribution of the frame coefficients and model hyper-parameters is derived.\nHybrid Markov Chain Monte Carlo algorithms are subsequently proposed to sample\nfrom this posterior distribution. The generated samples are then exploited to\nestimate the hyper-parameters and the frame coefficients of the target signal.\nValidation experiments show that the proposed algorithms provide an accurate\nestimation of the frame coefficients and hyper-parameters. Application to\npractical problems of image denoising show the impact of the resulting Bayesian\nestimation on the recovered signal quality.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2009 17:07:28 GMT"}], "update_date": "2015-05-14", "authors_parsed": [["Cha\u00e2ri", "L.", ""], ["Pesquet", "J. -C.", ""], ["Tourneret", "J. -Y.", ""], ["Ciuciu", "Ph.", ""], ["Benazza-Benyahia", "A.", ""]]}, {"id": "0911.2948", "submitter": "RadhaKrishna Ganti", "authors": "Radha Krishna Ganti and Martin Haenggi", "title": "Spatial Analysis of Opportunistic Downlink Relaying in a Two-Hop\n  Cellular System", "comments": "Submitted to IEEE Transactions on Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NI math.IT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a two-hop cellular system in which the mobile nodes help the base\nstation by relaying information to the dead spots. While two-hop cellular\nschemes have been analyzed previously, the distribution of the node locations\nhas not been explicitly taken into account. In this paper, we model the node\nlocations of the base stations and the mobile stations as a point process on\nthe plane and then analyze the performance of two different two-hop schemes in\nthe downlink. In one scheme the node nearest to the destination that has\ndecoded information from the base station in the first hop is used as the\nrelay. In the second scheme the node with the best channel to the relay that\nreceived information in the first hop acts as a relay. In both these schemes we\nobtain the success probability of the two hop scheme, accounting for the\ninterference from all other cells. We use tools from stochastic geometry and\npoint process theory to analyze the two hop schemes. Besides the results\nobtained a main contribution of the paper is to introduce a mathematical\nframework that can be used to analyze arbitrary relaying schemes. Some of the\nmain contributions of this paper are the analytical techniques introduced for\nthe inclusion of the spatial locations of the nodes into the mathematical\nanalysis.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2009 04:09:54 GMT"}], "update_date": "2009-11-19", "authors_parsed": [["Ganti", "Radha Krishna", ""], ["Haenggi", "Martin", ""]]}, {"id": "0911.3520", "submitter": "Alicia Nieto-Reyes", "authors": "Juan .A. Cuesta-Albertos, Fabrice Gamboa Alicia Nieto-Reyes", "title": "A random-projection based procedure to test if a stationary process is\n  Gaussian", "comments": "31 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the statistical problem of testing if a stationary\nprocess is Gaussian. The observation consists in a finite sample path of the\nprocess. Using a random projection technique introduced and studied in\nCuesta-Albertos et al. 2007 in the frame of goodness of fit test for functional\ndata, we perform some decision rules. These rules really stand on the whole\ndistribution of the process and not only on its marginal distribution at a\nfixed order. The main idea is to test the Gaussianity on the marginal\ndistribution of some random linear combinations of the process. This leads to\nconsistent decision rules. Some numerical simulations show the pertinence of\nour approach.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2009 12:32:03 GMT"}], "update_date": "2009-11-19", "authors_parsed": [["Cuesta-Albertos", "Juan . A.", ""], ["Nieto-Reyes", "Fabrice Gamboa Alicia", ""]]}, {"id": "0911.3866", "submitter": "Julien Cornebise", "authors": "Julien Cornebise and Gareth W. Peters", "title": "Comments on \"Particle Markov Chain Monte Carlo\" by C. Andrieu, A. Doucet\n  and R. Hollenstein", "comments": "This merged extended version of our two comments to be published in\n  the discussion of Andrieu, C., A. Doucet, and R. Holenstein (2010), Particle\n  Markov chain Monte Carlo methods. J. R. Statis. Soc. B 72 (2), 1-33. is\n  available as a technical report of Statistical and Applied Mathematical\n  Sciences Institute (SAMSI), see http://www.samsi.info/TR/tr2009-07.pdf", "journal-ref": null, "doi": null, "report-no": "2009-07", "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We merge in this note our two discussions about the Read Paper \"Particle\nMarkov chain Monte Carlo\" (Andrieu, Doucet, and Holenstein, 2010) presented on\nOctober 16th 2009 at the Royal Statistical Society, appearing in the Journal of\nthe Royal Statistical Society Series B. We also present a more detailed version\nof the ABC extension.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2009 20:47:13 GMT"}], "update_date": "2009-11-20", "authors_parsed": [["Cornebise", "Julien", ""], ["Peters", "Gareth W.", ""]]}, {"id": "0911.4046", "submitter": "Ryota Tomioka", "authors": "Ryota Tomioka, Taiji Suzuki, Masashi Sugiyama", "title": "Super-Linear Convergence of Dual Augmented-Lagrangian Algorithm for\n  Sparsity Regularized Estimation", "comments": "51 pages, 9 figures", "journal-ref": "Journal of Machine Learning Research, 12(May):1537-1586, 2011", "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the convergence behaviour of a recently proposed algorithm for\nregularized estimation called Dual Augmented Lagrangian (DAL). Our analysis is\nbased on a new interpretation of DAL as a proximal minimization algorithm. We\ntheoretically show under some conditions that DAL converges super-linearly in a\nnon-asymptotic and global sense. Due to a special modelling of sparse\nestimation problems in the context of machine learning, the assumptions we make\nare milder and more natural than those made in conventional analysis of\naugmented Lagrangian algorithms. In addition, the new interpretation enables us\nto generalize DAL to wide varieties of sparse estimation problems. We\nexperimentally confirm our analysis in a large scale $\\ell_1$-regularized\nlogistic regression problem and extensively compare the efficiency of DAL\nalgorithm to previously proposed algorithms on both synthetic and benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2009 13:44:28 GMT"}, {"version": "v2", "created": "Wed, 12 May 2010 12:33:07 GMT"}, {"version": "v3", "created": "Sun, 2 Jan 2011 07:04:21 GMT"}], "update_date": "2011-06-07", "authors_parsed": [["Tomioka", "Ryota", ""], ["Suzuki", "Taiji", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "0911.4546", "submitter": "James P. Hobert", "authors": "James P. Hobert, Vivekananda Roy, Christian P. Robert", "title": "Improving the Convergence Properties of the Data Augmentation Algorithm\n  with an Application to Bayesian Mixture Modeling", "comments": "Published in at http://dx.doi.org/10.1214/11-STS365 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2011, Vol. 26, No. 3, 332-351", "doi": "10.1214/11-STS365", "report-no": "IMS-STS-STS365", "categories": "stat.ME stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reversible Markov chains that drive the data augmentation (DA) and\nsandwich algorithms define self-adjoint operators whose spectra encode the\nconvergence properties of the algorithms. When the target distribution has\nuncountable support, as is nearly always the case in practice, it is generally\nquite difficult to get a handle on these spectra. We show that, if the\naugmentation space is finite, then (under regularity conditions) the operators\ndefined by the DA and sandwich chains are compact, and the spectra are finite\nsubsets of $[0,1)$. Moreover, we prove that the spectrum of the sandwich\noperator dominates the spectrum of the DA operator in the sense that the\nordered elements of the former are all less than or equal to the corresponding\nelements of the latter. As a concrete example, we study a widely used DA\nalgorithm for the exploration of posterior densities associated with Bayesian\nmixture models [J. Roy. Statist. Soc. Ser. B 56 (1994) 363--375]. In\nparticular, we compare this mixture DA algorithm with an alternative algorithm\nproposed by Fr\\\"{u}hwirth-Schnatter [J. Amer. Statist. Assoc. 96 (2001)\n194--209] that is based on random label switching.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2009 05:32:19 GMT"}, {"version": "v2", "created": "Sat, 4 Jun 2011 11:44:11 GMT"}, {"version": "v3", "created": "Fri, 3 Feb 2012 14:29:05 GMT"}], "update_date": "2012-02-06", "authors_parsed": [["Hobert", "James P.", ""], ["Roy", "Vivekananda", ""], ["Robert", "Christian P.", ""]]}, {"id": "0911.4744", "submitter": "Yogesh Dwivedi", "authors": "Yogesh Dwivedi, Suhasini Subba Rao", "title": "A test for second order stationarity of a time series based on the\n  Discrete Fourier Transform (Technical Report)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We consider a zero mean discrete time series, and define its discrete Fourier\ntransform at the canonical frequencies. It is well known that the discrete\nFourier transform is asymptotically uncorrelated at the canonical frequencies\nif and if only the time series is second order stationary. Exploiting this\nimportant property, we construct a Portmanteau type test statistic for testing\nstationarity of the time series. It is shown that under the null of\nstationarity, the test statistic is approximately a chi square distribution. To\nexamine the power of the test statistic, the asymptotic distribution under the\nlocally stationary alternative is established. It is shown to be a type of\nnoncentral chi-square, where the noncentrality parameter measures the deviation\nfrom stationarity. The test is illustrated with simulations, where is it shown\nto have good power. Some real examples are also included to illustrate the\ntest.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2009 01:02:36 GMT"}], "update_date": "2009-11-26", "authors_parsed": [["Dwivedi", "Yogesh", ""], ["Rao", "Suhasini Subba", ""]]}, {"id": "0911.5357", "submitter": "Mathieu Ribatet", "authors": "Mathieu Ribatet, Daniel Cooley and Anthony C. Davison", "title": "Bayesian Inference from Composite Likelihoods, with an Application to\n  Spatial Extremes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Composite likelihoods are increasingly used in applications where the full\nlikelihood is analytically unknown or computationally prohibitive. Although the\nmaximum composite likelihood estimator has frequentist properties akin to those\nof the usual maximum likelihood estimator, Bayesian inference based on\ncomposite likelihoods has yet to be explored. In this paper we investigate the\nuse of the Metropolis--Hastings algorithm to compute a pseudo-posterior\ndistribution based on the composite likelihood. Two methodologies for adjusting\nthe algorithm are presented and their performance on approximating the true\nposterior distribution is investigated using simulated data sets and real data\non spatial extremes of rainfall.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2009 21:45:12 GMT"}, {"version": "v2", "created": "Wed, 6 Jul 2011 20:41:05 GMT"}], "update_date": "2011-07-08", "authors_parsed": [["Ribatet", "Mathieu", ""], ["Cooley", "Daniel", ""], ["Davison", "Anthony C.", ""]]}, {"id": "0911.5439", "submitter": "Ali Shojaie", "authors": "Ali Shojaie and George Michailidis", "title": "Penalized Likelihood Methods for Estimation of Sparse High Dimensional\n  Directed Acyclic Graphs", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed acyclic graphs (DAGs) are commonly used to represent causal\nrelationships among random variables in graphical models. Applications of these\nmodels arise in the study of physical, as well as biological systems, where\ndirected edges between nodes represent the influence of components of the\nsystem on each other. The general problem of estimating DAGs from observed data\nis computationally NP-hard, Moreover two directed graphs may be observationally\nequivalent. When the nodes exhibit a natural ordering, the problem of\nestimating directed graphs reduces to the problem of estimating the structure\nof the network. In this paper, we propose a penalized likelihood approach that\ndirectly estimates the adjacency matrix of DAGs. Both lasso and adaptive lasso\npenalties are considered and an efficient algorithm is proposed for estimation\nof high dimensional DAGs. We study variable selection consistency of the two\npenalties when the number of variables grows to infinity with the sample size.\nWe show that although lasso can only consistently estimate the true network\nunder stringent assumptions, adaptive lasso achieves this task under mild\nregularity conditions. The performance of the proposed methods is compared to\nalternative methods in simulated, as well as real, data examples.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2009 23:47:30 GMT"}], "update_date": "2009-12-01", "authors_parsed": [["Shojaie", "Ali", ""], ["Michailidis", "George", ""]]}, {"id": "0911.5460", "submitter": "Yiyuan She", "authors": "Yiyuan She", "title": "An Iterative Algorithm for Fitting Nonconvex Penalized Generalized\n  Linear Models with Grouped Predictors", "comments": "Computational Statistics and Data Analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional data pose challenges in statistical learning and modeling.\nSometimes the predictors can be naturally grouped where pursuing the\nbetween-group sparsity is desired. Collinearity may occur in real-world\nhigh-dimensional applications where the popular $l_1$ technique suffers from\nboth selection inconsistency and prediction inaccuracy. Moreover, the problems\nof interest often go beyond Gaussian models. To meet these challenges,\nnonconvex penalized generalized linear models with grouped predictors are\ninvestigated and a simple-to-implement algorithm is proposed for computation. A\nrigorous theoretical result guarantees its convergence and provides tight\npreliminary scaling. This framework allows for grouped predictors and nonconvex\npenalties, including the discrete $l_0$ and the `$l_0+l_2$' type penalties.\nPenalty design and parameter tuning for nonconvex penalties are examined.\nApplications of super-resolution spectrum estimation in signal processing and\ncancer classification with joint gene selection in bioinformatics show the\nperformance improvement by nonconvex penalized estimation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2009 06:27:48 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2009 08:07:21 GMT"}, {"version": "v3", "created": "Sun, 18 Apr 2010 04:39:15 GMT"}, {"version": "v4", "created": "Fri, 9 Jul 2010 22:06:34 GMT"}, {"version": "v5", "created": "Thu, 10 Nov 2011 20:19:34 GMT"}], "update_date": "2011-11-11", "authors_parsed": [["She", "Yiyuan", ""]]}, {"id": "0911.5628", "submitter": "Alexandre Patriota", "authors": "Alexandre G. Patriota, Joao R. Sato, Betsabe G. Blas", "title": "Vector Autoregressive Models With Measurement Errors for Testing Ganger\n  Causality", "comments": "manuscript submitted for possible publication", "journal-ref": null, "doi": "10.1016/j.stamet.2010.02.001", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a method for estimating parameters of a vector\nautoregression (VAR) observed in white noise. The estimation method assumes the\nnoise variance matrix is known and does not require any iterative process. This\nstudy provides consistent estimators and shows the asymptotic distribution of\nthe parameters required for conducting tests of Granger causality. Methods in\nthe existing statistical literature cannot be used for testing Granger\ncausality, since under the null hypothesis the model becomes unidentifiable.\nMeasurement error effects on parameter estimates were evaluated by using\ncomputational simulations. The results show that the proposed approach produces\nempirical false positive rates close to the adopted nominal level (even for\nsmall samples) and has a good performance around the null hypothesis. The\napplicability and usefulness of the proposed approach are illustrated using a\nfunctional magnetic resonance imaging dataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2009 12:49:31 GMT"}], "update_date": "2010-03-01", "authors_parsed": [["Patriota", "Alexandre G.", ""], ["Sato", "Joao R.", ""], ["Blas", "Betsabe G.", ""]]}]