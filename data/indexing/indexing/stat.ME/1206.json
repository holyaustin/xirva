[{"id": "1206.0576", "submitter": "Alessandro Baldi Antognini", "authors": "Alessandro Baldi Antognini, Maroussa Zagoraiou", "title": "Multi-objective optimal designs in comparative clinical trials with\n  covariates: The reinforced doubly adaptive biased coin design", "comments": "Published in at http://dx.doi.org/10.1214/12-AOS1007 the Annals of\n  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Annals of Statistics 2012, Vol. 40, No. 3, 1315-1345", "doi": "10.1214/12-AOS1007", "report-no": "IMS-AOS-AOS1007", "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present paper deals with the problem of allocating patients to two\ncompeting treatments in the presence of covariates or prognostic factors in\norder to achieve a good trade-off among ethical concerns, inferential precision\nand randomness in the treatment allocations. In particular we suggest a\nmultipurpose design methodology that combines efficiency and ethical gain when\nthe linear homoscedastic model with both treatment/covariate interactions and\ninteractions among covariates is adopted. The ensuing compound optimal\nallocations of the treatments depend on the covariates and their distribution\non the population of interest, as well as on the unknown parameters of the\nmodel. Therefore, we introduce the reinforced doubly adaptive biased coin\ndesign, namely a general class of covariate-adjusted response-adaptive\nprocedures that includes both continuous and discontinuous randomization\nfunctions, aimed to target any desired allocation proportion. The properties of\nthis proposal are described both theoretically and through simulations.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 10:38:11 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2012 11:02:41 GMT"}], "update_date": "2012-08-17", "authors_parsed": [["Antognini", "Alessandro Baldi", ""], ["Zagoraiou", "Maroussa", ""]]}, {"id": "1206.0622", "submitter": "David  Bolin", "authors": "David Bolin", "title": "Spatial Mat\\'ern fields driven by non-Gaussian noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The article studies non-Gaussian extensions of a recently discovered link\nbetween certain Gaussian random fields, expressed as solutions to stochastic\npartial differential equations (SPDEs), and Gaussian Markov random fields. The\nfocus is on non-Gaussian random fields with Mat\\'ern covariance functions, and\nin particular we show how the SPDE formulation of a Laplace moving average\nmodel can be used to obtain an efficient simulation method as well as an\naccurate parameter estimation technique for the model. This should be seen as a\ndemonstration of how these techniques can be used, and generalizations to more\ngeneral SPDEs are readily available.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 13:52:19 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2012 14:04:25 GMT"}], "update_date": "2012-06-15", "authors_parsed": [["Bolin", "David", ""]]}, {"id": "1206.0867", "submitter": "Jian-feng Yao", "authors": "Z. Bai and D. Jiang and J. Yao and S. Zheng", "title": "Testing linear hypotheses in high-dimensional regressions", "comments": "Accepted 02/2012 for publication in \"Statistics\". 20 pages, 2 pages\n  and 2 tables", "journal-ref": "Statistics: A Journal of Theoretical and Applied Statistics\n  47(6):1207-1223, June 2013,", "doi": "10.1080/02331888.2012.708031", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a multivariate linear model, Wilk's likelihood ratio test (LRT)\nconstitutes one of the cornerstone tools. However, the computation of its\nquantiles under the null or the alternative requires complex analytic\napproximations and more importantly, these distributional approximations are\nfeasible only for moderate dimension of the dependent variable, say $p\\le 20$.\nOn the other hand, assuming that the data dimension $p$ as well as the number\n$q$ of regression variables are fixed while the sample size $n$ grows, several\nasymptotic approximations are proposed in the literature for Wilk's $\\bLa$\nincluding the widely used chi-square approximation. In this paper, we consider\nnecessary modifications to Wilk's test in a high-dimensional context,\nspecifically assuming a high data dimension $p$ and a large sample size $n$.\nBased on recent random matrix theory, the correction we propose to Wilk's test\nis asymptotically Gaussian under the null and simulations demonstrate that the\ncorrected LRT has very satisfactory size and power, surely in the large $p$ and\nlarge $n$ context, but also for moderately large data dimensions like $p=30$ or\n$p=50$. As a byproduct, we give a reason explaining why the standard chi-square\napproximation fails for high-dimensional data. We also introduce a new\nprocedure for the classical multiple sample significance test in MANOVA which\nis valid for high-dimensional data.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 10:05:09 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Bai", "Z.", ""], ["Jiang", "D.", ""], ["Yao", "J.", ""], ["Zheng", "S.", ""]]}, {"id": "1206.0980", "submitter": "Guoqing Diao", "authors": "Guoqing Diao, Donglin Zeng and Song Yang", "title": "Efficient Semiparametric Estimation of Short-term and Long-term Hazard\n  Ratios with Right-Censored Data", "comments": "35 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proportional hazards assumption in the commonly used Cox model for\ncensored failure time data is often violated in scientific studies. Yang and\nPrentice (2005) proposed a novel semiparametric two-sample model that includes\nthe proportional hazards model and the proportional odds model as sub-models,\nand accommodates crossing survival curves. The model leaves the baseline hazard\nunspecified and the two model parameters can be interpreted as the short-term\nand long-term hazard ratios. Inference procedures were developed based on a\npseudo score approach. Although extension to accommodate covariates was\nmentioned, no formal procedures have been provided or proved. Furthermore, the\npseudo score approach may not be asymptotically efficient. We study the\nextension of the short-term and long-term hazard ratio model of Yang and\nPrentice (2005) to accommodate potentially time-dependent covariates. We\ndevelop efficient likelihood-based estimation and inference procedures. The\nnonparametric maximum likelihood estimators are shown to be consistent,\nasymptotically normal, and asymptotically efficient. Extensive simulation\nstudies demonstrate that the proposed methods perform well in practical\nsettings. The proposed method captured the phenomenon of crossing hazards in a\ncancer clinical trial and identified a genetic marker with significant\nlong-term effect missed by using the proportional hazards model on age-at-onset\nof alcoholism in a genetic study.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2012 16:24:20 GMT"}], "update_date": "2012-06-06", "authors_parsed": [["Diao", "Guoqing", ""], ["Zeng", "Donglin", ""], ["Yang", "Song", ""]]}, {"id": "1206.1194", "submitter": "Nicolas Verzelen", "authors": "Nadine Hilgert (MISTEA), Andr\\'e Mas (I3M), Nicolas Verzelen (MISTEA)", "title": "Minimax adaptive tests for the Functional Linear model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce two novel procedures to test the nullity of the slope function\nin the functional linear model with real output. The test statistics combine\nmultiple testing ideas and random projections of the input data through\nfunctional Principal Component Analysis. Interestingly, the procedures are\ncompletely data-driven and do not require any prior knowledge on the smoothness\nof the slope nor on the smoothness of the covariate functions. The levels and\npowers against local alternatives are assessed in a nonasymptotic setting. This\nallows us to prove that these procedures are minimax adaptive (up to an\nunavoidable \\log\\log n multiplicative term) to the unknown regularity of the\nslope. As a side result, the minimax separation distances of the slope are\nderived for a large range of regularity classes. A numerical study illustrates\nthese theoretical results.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 12:05:30 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2013 19:45:25 GMT"}], "update_date": "2013-02-12", "authors_parsed": [["Hilgert", "Nadine", "", "MISTEA"], ["Mas", "Andr\u00e9", "", "I3M"], ["Verzelen", "Nicolas", "", "MISTEA"]]}, {"id": "1206.1425", "submitter": "Adriaan Blommaert", "authors": "Adriaan Blommaert, Niel Hens, Philippe Beutels", "title": "Data Mining for Longitudinal Data under Multicollinearity and Time\n  Dependence using Penalized Generalized Estimating Equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Penalized generalized estimating equations with Elastic Net or L2-Smoothly\nClipped Absolute Deviation penalization are proposed to simultaneously select\nthe most important variables and estimate their effects for longitudinal\nGaussian data when multicollinearity is present. The method is able to\nconsistently select and estimate the main effects even when strong correlations\nare present. In addition, the potential pitfall of time-dependent covariates is\nclarified. Both asymptotic theory and simulation results reveal the\neffectiveness of penalization as a data mining tool for longitudinal data,\nespecially when a large number of variables is present. The method is\nillustrated by mining for the main determinants of life expectancy in Europe.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 09:06:44 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2012 14:21:40 GMT"}], "update_date": "2012-11-26", "authors_parsed": [["Blommaert", "Adriaan", ""], ["Hens", "Niel", ""], ["Beutels", "Philippe", ""]]}, {"id": "1206.1660", "submitter": "Cheng Wang", "authors": "Cheng Wang, Longbing Cao and Baiqi Miao", "title": "Optimal feature selection for sparse linear discriminant analysis and\n  its applications in gene expression data", "comments": "20 pages, 3 figures, 5 tables, accepted by Computational Statistics\n  and Data Analysis", "journal-ref": null, "doi": "10.1016/j.csda.2013.04.003", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the theoretical rules of feature selection in linear\ndiscriminant analysis (LDA), and a new feature selection method is proposed for\nsparse linear discriminant analysis. An $l_1$ minimization method is used to\nselect the important features from which the LDA will be constructed. The\nasymptotic results of this proposed two-stage LDA (TLDA) are studied,\ndemonstrating that TLDA is an optimal classification rule whose convergence\nrate is the best compared to existing methods. The experiments on simulated and\nreal datasets are consistent with the theoretical results and show that TLDA\nperforms favorably in comparison with current methods. Overall, TLDA uses a\nlower minimum number of features or genes than other approaches to achieve a\nbetter result with a reduced misclassification rate.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 04:47:48 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2012 05:40:05 GMT"}, {"version": "v3", "created": "Thu, 5 Jul 2012 05:08:53 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2013 12:06:53 GMT"}], "update_date": "2013-04-23", "authors_parsed": [["Wang", "Cheng", ""], ["Cao", "Longbing", ""], ["Miao", "Baiqi", ""]]}, {"id": "1206.1708", "submitter": "Christian P. Robert", "authors": "Christian P. Robert (Universite Paris-Dauphine, IUF, and CREST)", "title": "Comments on \"Confidence distribution, the frequentist distribution\n  estimator of a parameter --- a review\" by Min-ge Xie and Kesar Singh", "comments": "5 pages, two figures, to appear in International Statistical Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is a discussion of the paper \"Confidence distribution\" by Min-ge\nXie and Kesar Singh, to appear in the International Statistical Review.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 09:17:14 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Robert", "Christian P.", "", "Universite Paris-Dauphine, IUF, and CREST"]]}, {"id": "1206.1739", "submitter": "Linus Bengtsson", "authors": "Linus Bengtsson, Xin Lu, Quoc Cuong Nguyen, Martin Camitz, Nguyen Le\n  Hoang, Fredrik Liljeros, Anna Thorson", "title": "Implementation of Web-Based Respondent-Driven Sampling among Men who\n  Have Sex with Men in Vietnam", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0049417", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Lack of representative data about hidden groups, like men who have\nsex with men (MSM), hinders an evidence-based response to the HIV epidemics.\nRespondent-driven sampling (RDS) was developed to overcome sampling challenges\nin studies of populations like MSM for which sampling frames are absent.\nInternet-based RDS (webRDS) can potentially circumvent limitations of the\noriginal RDS method. We aimed to implement and evaluate webRDS among a hidden\npopulation.\n  Methods and Design: This cross-sectional study took place 18 February to 12\nApril, 2011 among MSM in Vietnam. Inclusion criteria were men, aged 18 and\nabove, who had ever had sex with another man and were living in Vietnam.\nParticipants were invited by an MSM friend, logged in, and answered a survey.\nParticipants could recruit up to four MSM friends. We evaluated the system by\nits success in generating sustained recruitment and the degree to which the\nsample compositions stabilized with increasing sample size.\n  Results: Twenty starting participants generated 676 participants over 24\nrecruitment waves. Analyses did not show evidence of bias due to ineligible\nparticipation. Estimated mean age was 22 year and 82% came from the two large\nmetropolitan areas. 32 out of 63 provinces were represented. The median number\nof sexual partners during the last six months was two. The sample composition\nstabilized well for 16 out of 17 variables.\n  Conclusion: Results indicate that webRDS could be implemented at a low cost\namong Internet-using MSM in Vietnam. WebRDS may be a promising method for\nsampling of Internet-using MSM and other hidden groups.\n  Key words: Respondent-driven sampling, Online sampling, Men who have sex with\nmen, Vietnam, Sexual risk behavior\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 12:04:04 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Bengtsson", "Linus", ""], ["Lu", "Xin", ""], ["Nguyen", "Quoc Cuong", ""], ["Camitz", "Martin", ""], ["Hoang", "Nguyen Le", ""], ["Liljeros", "Fredrik", ""], ["Thorson", "Anna", ""]]}, {"id": "1206.1818", "submitter": "Larry Tang", "authors": "Liansheng Larry Tang, Aiyi Liu, Zhen Chen, Enrique F. Schisterman, Bo\n  Zhang, and Zhuang Miao", "title": "Nonparametric ROC Summary Statistics for Correlated Diagnostic Marker\n  Data", "comments": "13 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose efficient nonparametric statistics to compare medical imaging\nmodalities in multi-reader multi-test data and to compare markers in\nlongitudinal ROC data. The proposed methods are based on the weighted area\nunder the ROC curve which includes the area under the curve and the partial\narea under the curve as special cases. The methods maximize the local power for\ndetecting the difference between imaging modalities. The asymptotic results of\nthe proposed methods are developed under a complex correlation structure. Our\nsimulation studies show that the proposed statistics result in much better\npowers than existing statistics. We applied the proposed statistics to an\nendometriosis diagnosis study.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 16:54:20 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Tang", "Liansheng Larry", ""], ["Liu", "Aiyi", ""], ["Chen", "Zhen", ""], ["Schisterman", "Enrique F.", ""], ["Zhang", "Bo", ""], ["Miao", "Zhuang", ""]]}, {"id": "1206.1850", "submitter": "Elvan Ceyhan", "authors": "Elvan Ceyhan", "title": "New Cell-Specific and Overall Tests of Spatial Interaction Based on\n  Nearest Neighbor Contingency Tables", "comments": "39 pages, 25 Figures, 5 Tables. arXiv admin note: substantial text\n  overlap with arXiv:0805.1629", "journal-ref": null, "doi": null, "report-no": "KU-EC-13-1", "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial interaction patterns such as segregation and association can be\ntested using nearest neighbor contingency tables (NNCTs). We introduce new\ncell-specific (or pairwise) and overall segregation tests and determine their\nasymptotic distributions. In particular, we demonstrate that cell-specific\ntests enjoy asymptotic normality, while overall tests have chi-square\ndistributions asymptotically. We also perform an extensive Monte Carlo\nsimulation study to compare the finite sample performance of the tests in terms\nof empirical size and power. In addition to the cell-specific tests as post-hoc\ntests for overall tests, we discuss one-class-versus-rest type of NNCT-tests\nafter an overall test yields significant interaction. We also introduce the\nconcepts of total, strong, and partial segregation/association to label levels\nof these patterns. We compare these new tests with the existing NNCT-tests in\nliterature with simulations as well and illustrate the NNCT-tests on an\necological data set.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 19:53:27 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2013 03:02:38 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Ceyhan", "Elvan", ""]]}, {"id": "1206.1955", "submitter": "Sofia Olhede Professor", "authors": "Sofia C. Olhede and Hernando Ombao", "title": "Covariance of Replicated Modulated Cyclical Time Series", "comments": "25 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the novel class of modulated cyclostationary processes,\na class of non-stationary processes exhibiting frequency coupling, and proposes\na method of their estimation from repeated trials. Cyclostationary processes\nalso exhibit frequency correlation but have Loeve spectra whose support lies\nonly on parallel lines in the dual-frequency plane. Such extremely sparse\nstructure does not adequately represent many biological processes. Thus, we\npropose a model that, in the time domain, modulates the covariance of\ncyclostationary processes and consequently broadens their frequency support in\nthe dual-frequency plane. The spectra and the cross-coherence of the proposed\nmodulated cyclostationary process are first estimated using multitaper methods.\nA shrinkage procedure is then applied to each trial-specific estimate to reduce\nthe estimation risk.\n  Multiple trials of each series are observed. When combining information\nacross trials, we carefully take into account the bias that may be introduced\nby phase misalignment and the fact that the Loeve spectra and cross-coherence\nacross replicates may only be \"similar\" - but not necessarily identical -\nacross replicates. The application of the inference methods developed for the\nmodulated cyclostationary model to EEG data also demonstrates that the proposed\nmodel captures statistically significant cross-frequency interactions, that\nought to be further examined by neuroscientists.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jun 2012 16:42:57 GMT"}, {"version": "v2", "created": "Wed, 24 Oct 2012 13:01:44 GMT"}], "update_date": "2012-10-25", "authors_parsed": [["Olhede", "Sofia C.", ""], ["Ombao", "Hernando", ""]]}, {"id": "1206.2054", "submitter": "Jon Sporring", "authors": "S{\\o}ren Feodor Nielsen and Jon Sporring", "title": "Maximum A Posteriori Covariance Estimation Using a Power Inverse Wishart\n  Prior", "comments": "29 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of the covariance matrix is an initial step in many\nmultivariate statistical methods such as principal components analysis and\nfactor analysis, but in many practical applications the dimensionality of the\nsample space is large compared to the number of samples, and the usual maximum\nlikelihood estimate is poor. Typically, improvements are obtained by modelling\nor regularization. From a practical point of view, these methods are often\ncomputationally heavy and rely on approximations. As a fast substitute, we\npropose an easily calculable maximum a posteriori (MAP) estimator based on a\nnew class of prior distributions generalizing the inverse Wishart prior,\ndiscuss its properties, and demonstrate the estimator on simulated and real\ndata.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jun 2012 20:23:31 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Nielsen", "S\u00f8ren Feodor", ""], ["Sporring", "Jon", ""]]}, {"id": "1206.2380", "submitter": "Karl Rohe", "authors": "Karl Rohe, Tai Qin, Haoyang Fan", "title": "The Highest Dimensional Stochastic Blockmodel with a Regularized\n  Estimator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the high dimensional Stochastic Blockmodel for a random network, the\nnumber of clusters (or blocks) K grows with the number of nodes N. Two previous\nstudies have examined the statistical estimation performance of spectral\nclustering and the maximum likelihood estimator under the high dimensional\nmodel; neither of these results allow K to grow faster than N^{1/2}. We study a\nmodel where, ignoring log terms, K can grow proportionally to N. Since the\nnumber of clusters must be smaller than the number of nodes, no reasonable\nmodel allows K to grow faster; thus, our asymptotic results are the \"highest\"\ndimensional. To push the asymptotic setting to this extreme, we make additional\nassumptions that are motivated by empirical observations in physical\nanthropology (Dunbar, 1992), and an in depth study of massive empirical\nnetworks (Leskovec et al 2008). Furthermore, we develop a regularized maximum\nlikelihood estimator that leverages these insights and we prove that, under\ncertain conditions, the proportion of nodes that the regularized estimator\nmisclusters converges to zero. This is the first paper to explicitly introduce\nand demonstrate the advantages of statistical regularization in a parametric\nform for network analysis.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 21:02:48 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2013 16:25:09 GMT"}], "update_date": "2013-08-02", "authors_parsed": [["Rohe", "Karl", ""], ["Qin", "Tai", ""], ["Fan", "Haoyang", ""]]}, {"id": "1206.2398", "submitter": "Georg M. Goerg", "authors": "Georg M. Goerg and Cosma Rohilla Shalizi", "title": "LICORS: Light Cone Reconstruction of States for Non-parametric\n  Forecasting of Spatio-Temporal Systems", "comments": "Main text: 30 pages; supplementary material: 12 pages; 5+2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME nlin.CG physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new, non-parametric forecasting method for data where continuous\nvalues are observed discretely in space and time. Our method, \"light-cone\nreconstruction of states\" (LICORS), uses physical principles to identify\npredictive states which are local properties of the system, both in space and\ntime. LICORS discovers the number of predictive states and their predictive\ndistributions automatically, and consistently, under mild assumptions on the\ndata source. We provide an algorithm to implement our method, along with a\ncross-validation scheme to pick control settings. Simulations show that\nCV-tuned LICORS outperforms standard methods in forecasting challenging\nspatio-temporal dynamics. Our work provides applied researchers with a new,\nhighly automatic method to analyze and forecast spatio-temporal data.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 23:22:22 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2012 21:45:46 GMT"}], "update_date": "2012-08-07", "authors_parsed": [["Goerg", "Georg M.", ""], ["Shalizi", "Cosma Rohilla", ""]]}, {"id": "1206.2557", "submitter": "Ivan Kojadinovic", "authors": "Axel B\\\"ucher, Ivan Kojadinovic, Tom Rohmer and Johan Segers", "title": "Detecting changes in cross-sectional dependence in multivariate time\n  series", "comments": "32 pages, 6 tables", "journal-ref": "Journal of Multivariate Analysis 132, pages 111-128, 2014", "doi": "10.1016/j.jmva.2014.07.012", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical and more recent tests for detecting distributional changes in\nmultivariate time series often lack power against alternatives that involve\nchanges in the cross-sectional dependence structure. To be able to detect such\nchanges better, a test is introduced based on a recently studied variant of the\nsequential empirical copula process. In contrast to earlier attempts, ranks are\ncomputed with respect to relevant subsamples, with beneficial consequences for\nthe sensitivity of the test. For the computation of p-values we propose a\nmultiplier resampling scheme that takes the serial dependence into account. The\nlarge-sample theory for the test statistic and the resampling scheme is\ndeveloped. The finite-sample performance of the procedure is assessed by Monte\nCarlo simulations. Two case studies involving time series of financial returns\nare presented as well.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jun 2012 14:59:34 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2013 21:54:18 GMT"}, {"version": "v3", "created": "Fri, 6 Dec 2013 13:29:20 GMT"}, {"version": "v4", "created": "Wed, 21 May 2014 13:36:09 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["B\u00fccher", "Axel", ""], ["Kojadinovic", "Ivan", ""], ["Rohmer", "Tom", ""], ["Segers", "Johan", ""]]}, {"id": "1206.2696", "submitter": "Zaili Fang", "authors": "Zaili Fang, Inyoung Kim, Patrick Schaumont", "title": "Flexible Variable Selection for Recovering Sparsity in Nonadditive\n  Nonparametric Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variable selection for recovering sparsity in nonadditive nonparametric\nmodels has been challenging. This problem becomes even more difficult due to\ncomplications in modeling unknown interaction terms among high dimensional\nvariables. There is currently no variable selection method to overcome these\nlimitations. Hence, in this paper we propose a variable selection approach that\nis developed by connecting a kernel machine with the nonparametric multiple\nregression model. The advantages of our approach are that it can: (1) recover\nthe sparsity, (2) automatically model unknown and complicated interactions, (3)\nconnect with several existing approaches including linear nonnegative garrote,\nkernel learning and automatic relevant determinants (ARD), and (4) provide\nflexibility for both additive and nonadditive nonparametric models. Our\napproach may be viewed as a nonlinear version of a nonnegative garrote method.\nWe model the smoothing function by a least squares kernel machine and construct\nthe nonnegative garrote objective function as the function of the similarity\nmatrix. Since the multiple regression similarity matrix can be written as an\nadditive form of univariate similarity matrices corresponding to input\nvariables, applying a sparse scale parameter on each univariate similarity\nmatrix can reveal its relevance to the response variable. We also derive the\nasymptotic properties of our approach, and show that it provides a square root\nconsistent estimator of the scale parameters. Furthermore, we prove that\nsparsistency is satisfied with consistent initial kernel function coefficients\nunder certain conditions and give the necessary and sufficient conditions for\nsparsistency. An efficient coordinate descent/backfitting algorithm is\ndeveloped. A resampling procedure for our variable selection methodology is\nalso proposed to improve power.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 01:15:09 GMT"}], "update_date": "2012-06-14", "authors_parsed": [["Fang", "Zaili", ""], ["Kim", "Inyoung", ""], ["Schaumont", "Patrick", ""]]}, {"id": "1206.2715", "submitter": "Zaili Fang", "authors": "Zaili Fang, Inyoung Kim", "title": "A Graphical View of Bayesian Variable Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Ising prior with the network information for the \"in\" or\n\"out\" binary random variable in Bayesian variable selections has received more\nand more attentions. In this paper, we discover that even without the\ninformative prior a Bayesian variable selection problem itself can be\nconsidered as a complete graph and described by a Ising model with random\ninteractions. There are many advantages of treating variable selection as a\ngraphical model, such as it is easy to employ the single site updating as well\nas the cluster updating algorithm, suitable for problems with small sample size\nand larger variable number, easy to extend to nonparametric regression models\nand incorporate graphical prior information and so on. In a Bayesian variable\nselection Ising model the interactions are determined by the linear model\ncoefficients, so we systematically study the performance of different scale\nnormal mixture priors for the model coefficients by adopting the global-local\nshrinkage strategy. Our results prove that the best prior of the model\ncoefficients in terms of variable selection should maintain substantial weight\non small shrinkage instead of large shrinkage. We also discuss the connection\nbetween the tempering algorithms for Ising models and the global-local\nshrinkage approach, showing that the shrinkage parameter plays a tempering\nrole. The methods are illustrated with simulated and real data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 04:29:27 GMT"}], "update_date": "2012-06-14", "authors_parsed": [["Fang", "Zaili", ""], ["Kim", "Inyoung", ""]]}, {"id": "1206.2716", "submitter": "Zaili Fang", "authors": "Zaili Fang, Inyoung Kim, Jeesun Jung", "title": "Semiparametric Mixed Model for Evaluating Pathway-Environment\n  Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A biological pathway represents a set of genes that serves a particular\ncellular or a physiological function. The genes within the same pathway are\nexpected to function together and hence may interact with each other. It is\nalso known that many genes, and so pathways, interact with other environmental\nvariables. However, no formal procedure has yet been developed to evaluate the\npathway-environment interaction. In this article, we propose a semiparametric\nmethod to model the pathway-environment interaction. The method connects a\nleast square kernel machine and a semiparametric mixed effects model. We model\nnonparametrically the environmental effect via a natural cubic spline. Both a\npathway effect and an interaction between a pathway and an environmental effect\nare modeled nonparametrically via a kernel machine, and we estimate variance\ncomponent representing an interaction effect under a semiparametric mixed\neffects model. We then employ a restricted likelihood ratio test and a score\ntest to evaluate the main pathway effect and the pathway-environment\ninteraction. The approach was applied to a genetic pathway data of Type II\ndiabetes, and pathways with either a significant main pathway effect, an\ninteraction effect or both were identified. Other methods previously developed\ndetermined many as having a significant main pathway effect only. Furthermore,\namong those significant pathways, we discovered some pathways having a\nsignificant pathway-environment interaction effect, a result that other methods\nwould not be able to detect.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 04:36:55 GMT"}], "update_date": "2012-06-14", "authors_parsed": [["Fang", "Zaili", ""], ["Kim", "Inyoung", ""], ["Jung", "Jeesun", ""]]}, {"id": "1206.2743", "submitter": "Katharina Proksch", "authors": "Katharina Proksch, Nicolai Bissantz, Holger Dette", "title": "Confidence bands for multivariate and time dependent inverse regression\n  models", "comments": "Published at http://dx.doi.org/10.3150/13-BEJ563 in the Bernoulli\n  (http://isi.cbs.nl/bernoulli/) by the International Statistical\n  Institute/Bernoulli Society (http://isi.cbs.nl/BS/bshome.htm)", "journal-ref": "Bernoulli 2015, Vol. 21, No. 1, 144-175", "doi": "10.3150/13-BEJ563", "report-no": "IMS-BEJ-BEJ563", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniform asymptotic confidence bands for a multivariate regression function in\nan inverse regression model with a convolution-type operator are constructed.\nThe results are derived using strong approximation methods and a limit theorem\nfor the supremum of a stationary Gaussian field over an increasing system of\nsets. As a particular application, asymptotic confidence bands for a time\ndependent regression function $f_t(x)$ ($x\\in \\mathbb {R}^d,t\\in \\mathbb {R}$)\nin a convolution-type inverse regression model are obtained. Finally, we\ndemonstrate the practical feasibility of our proposed methods in a simulation\nstudy and an application to the estimation of the luminosity profile of the\nelliptical galaxy NGC5017. To the best knowledge of the authors, the results\npresented in this paper are the first which provide uniform confidence bands\nfor multivariate nonparametric function estimation in inverse problems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 08:23:54 GMT"}, {"version": "v2", "created": "Tue, 7 Apr 2015 07:04:49 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Proksch", "Katharina", ""], ["Bissantz", "Nicolai", ""], ["Dette", "Holger", ""]]}, {"id": "1206.2966", "submitter": "Ivan Fernandez-Val", "authors": "Ivan Fernandez-Val and Joonhwah Lee", "title": "Panel Data Models with Nonadditive Unobserved Heterogeneity: Estimation\n  and Inference", "comments": "51 pages, 4 tables, 1 figure, it includes supplementary appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME econ.EM math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers fixed effects estimation and inference in linear and\nnonlinear panel data models with random coefficients and endogenous regressors.\nThe quantities of interest -- means, variances, and other moments of the random\ncoefficients -- are estimated by cross sectional sample moments of GMM\nestimators applied separately to the time series of each individual. To deal\nwith the incidental parameter problem introduced by the noise of the\nwithin-individual estimators in short panels, we develop bias corrections.\nThese corrections are based on higher-order asymptotic expansions of the GMM\nestimators and produce improved point and interval estimates in moderately long\npanels. Under asymptotic sequences where the cross sectional and time series\ndimensions of the panel pass to infinity at the same rate, the uncorrected\nestimator has an asymptotic bias of the same order as the asymptotic variance.\nThe bias corrections remove the bias without increasing variance. An empirical\nexample on cigarette demand based on Becker, Grossman and Murphy (1994) shows\nsignificant heterogeneity in the price effect across U.S. states.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 23:10:58 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2013 22:03:17 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Fernandez-Val", "Ivan", ""], ["Lee", "Joonhwah", ""]]}, {"id": "1206.3125", "submitter": "Stanislav Volgushev", "authors": "Stanislav Volgushev, Melanie Birke, Holger Dette, Natalie Neumeyer", "title": "Significance testing in quantile regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of testing significance of predictors in multivariate\nnonparametric quantile regression. A stochastic process is proposed, which is\nbased on a comparison of the responses with a nonparametric quantile regression\nestimate under the null hypothesis. It is demonstrated that under the null\nhypothesis this process converges weakly to a centered Gaussian process and the\nasymptotic properties of the test under fixed and local alternatives are also\ndiscussed. In particular we show, that - in contrast to the nonparametric\napproach based on estimation of $L^2$-distances - the new test is able to\ndetect local alternatives which converge to the null hypothesis with any rate\n$a_n \\to 0$ such that $a_n \\sqrt{n} \\to \\infty$ (here $n$ denotes the sample\nsize). We also present a small simulation study illustrating the finite sample\nproperties of a bootstrap version of the the corresponding Kolmogorov-Smirnov\ntest.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2012 14:51:29 GMT"}], "update_date": "2012-06-15", "authors_parsed": [["Volgushev", "Stanislav", ""], ["Birke", "Melanie", ""], ["Dette", "Holger", ""], ["Neumeyer", "Natalie", ""]]}, {"id": "1206.3239", "submitter": "Zhihong Cai", "authors": "Zhihong Cai, Manabu Kuroki", "title": "On Identifying Total Effects in the Presence of Latent Variables and\n  Selection bias", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-62-69", "categories": "stat.ME cs.AI stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assume that cause-effect relationships between variables can be described as\na directed acyclic graph and the corresponding linear structural equation\nmodel.We consider the identification problem of total effects in the presence\nof latent variables and selection bias between a treatment variable and a\nresponse variable. Pearl and his colleagues provided the back door criterion,\nthe front door criterion (Pearl, 2000) and the conditional instrumental\nvariable method (Brito and Pearl, 2002) as identifiability criteria for total\neffects in the presence of latent variables, but not in the presence of\nselection bias. In order to solve this problem, we propose new graphical\nidentifiability criteria for total effects based on the identifiable factor\nmodels. The results of this paper are useful to identify total effects in\nobservational studies and provide a new viewpoint to the identification\nconditions of factor models.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 14:59:34 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Cai", "Zhihong", ""], ["Kuroki", "Manabu", ""]]}, {"id": "1206.3245", "submitter": "Philip Dawid", "authors": "Philip Dawid, Vanessa Didelez", "title": "Identifying Optimal Sequential Decisions", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": "In Proc. 24th Annual Conference on Uncertainty in Artificial\n  Intelligence (2008), edited by D. McAllester and P. Myllymaki. AUAI Press,\n  113-120", "doi": null, "report-no": "UAI-P-2008-PG-113-120", "categories": "cs.AI math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider conditions that allow us to find an optimal strategy for\nsequential decisions from a given data situation. For the case where all\ninterventions are unconditional (atomic), identifiability has been discussed by\nPearl & Robins (1995). We argue here that an optimal strategy must be\nconditional, i.e. take the information available at each decision point into\naccount. We show that the identification of an optimal sequential decision\nstrategy is more restrictive, in the sense that conditional interventions might\nnot always be identified when atomic interventions are. We further demonstrate\nthat a simple graphical criterion for the identifiability of an optimal\nstrategy can be given.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:06:54 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Dawid", "Philip", ""], ["Didelez", "Vanessa", ""]]}, {"id": "1206.3267", "submitter": "Manabu Kuroki", "authors": "Manabu Kuroki, Zhihong Cai", "title": "The Evaluation of Causal Effects in Studies with an Unobserved\n  Exposure/Outcome Variable: Bounds and Identification", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-333-340", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of evaluating the causal effect using\nobservational data in the presence of an unobserved exposure/ outcome variable,\nwhen cause-effect relationships between variables can be described as a\ndirected acyclic graph and the corresponding recursive factorization of a joint\ndistribution. First, we propose identifiability criteria for causal effects\nwhen an unobserved exposure/outcome variable is considered to contain more than\ntwo categories. Next, when unmeasured variables exist between an unobserved\noutcome variable and its proxy variables, we provide the tightest bounds based\non the potential outcome approach. The results of this paper are helpful to\nevaluate causal effects in the case where it is difficult or expensive to\nobserve an exposure/ outcome variable in many practical fields.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:36:40 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Kuroki", "Manabu", ""], ["Cai", "Zhihong", ""]]}, {"id": "1206.3268", "submitter": "Seyoung Kim", "authors": "Seyoung Kim, Eric P. Xing", "title": "Feature Selection via Block-Regularized Regression", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-325-332", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying co-varying causal elements in very high dimensional feature space\nwith internal structures, e.g., a space with as many as millions of linearly\nordered features, as one typically encounters in problems such as whole genome\nassociation (WGA) mapping, remains an open problem in statistical learning. We\npropose a block-regularized regression model for sparse variable selection in a\nhigh-dimensional space where the covariates are linearly ordered, and are\npossibly subject to local statistical linkages (e.g., block structures) due to\nspacial or temporal proximity of the features. Our goal is to identify a small\nsubset of relevant covariates that are not merely from random positions in the\nordering, but grouped as contiguous blocks from large number of ordered\ncovariates. Following a typical linear regression framework between the\nfeatures and the response, our proposed model employs a sparsity-enforcing\nLaplacian prior for the regression coefficients, augmented by a 1st-order\nMarkovian process along the feature sequence that \"activates\" the regression\ncoefficients in a coupled fashion. We describe a sampling-based learning\nalgorithm and demonstrate the performance of our method on simulated and\nbiological data for marker identification under WGA.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:37:09 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Kim", "Seyoung", ""], ["Xing", "Eric P.", ""]]}, {"id": "1206.3273", "submitter": "Gustavo Lacerda", "authors": "Gustavo Lacerda, Peter L. Spirtes, Joseph Ramsey, Patrik O. Hoyer", "title": "Discovering Cyclic Causal Models by Independent Components Analysis", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-366-374", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize Shimizu et al's (2006) ICA-based approach for discovering\nlinear non-Gaussian acyclic (LiNGAM) Structural Equation Models (SEMs) from\ncausally sufficient, continuous-valued observational data. By relaxing the\nassumption that the generating SEM's graph is acyclic, we solve the more\ngeneral problem of linear non-Gaussian (LiNG) SEM discovery. LiNG discovery\nalgorithms output the distribution equivalence class of SEMs which, in the\nlarge sample limit, represents the population distribution. We apply a LiNG\ndiscovery algorithm to simulated data. Finally, we give sufficient conditions\nunder which only one of the SEMs in the output class is 'stable'.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:39:27 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Lacerda", "Gustavo", ""], ["Spirtes", "Peter L.", ""], ["Ramsey", "Joseph", ""], ["Hoyer", "Patrik O.", ""]]}, {"id": "1206.3278", "submitter": "David Mimno", "authors": "David Mimno, Andrew McCallum", "title": "Topic Models Conditioned on Arbitrary Features with\n  Dirichlet-multinomial Regression", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-411-418", "categories": "cs.IR stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although fully generative models have been successfully used to model the\ncontents of text documents, they are often awkward to apply to combinations of\ntext data and document metadata. In this paper we propose a\nDirichlet-multinomial regression (DMR) topic model that includes a log-linear\nprior on document-topic distributions that is a function of observed features\nof the document, such as author, publication venue, references, and dates. We\nshow that by selecting appropriate features, DMR topic models can meet or\nexceed the performance of several previously published topic models designed\nfor specific data.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:42:17 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Mimno", "David", ""], ["McCallum", "Andrew", ""]]}, {"id": "1206.3287", "submitter": "Harald Steck", "authors": "Harald Steck", "title": "Learning the Bayesian Network Structure: Dirichlet Prior versus Data", "comments": "Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty\n  in Artificial Intelligence (UAI2008)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2008-PG-511-518", "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Bayesian approach to structure learning of graphical models, the\nequivalent sample size (ESS) in the Dirichlet prior over the model parameters\nwas recently shown to have an important effect on the maximum-a-posteriori\nestimate of the Bayesian network structure. In our first contribution, we\ntheoretically analyze the case of large ESS-values, which complements previous\nwork: among other results, we find that the presence of an edge in a Bayesian\nnetwork is favoured over its absence even if both the Dirichlet prior and the\ndata imply independence, as long as the conditional empirical distribution is\nnotably different from uniform. In our second contribution, we focus on\nrealistic ESS-values, and provide an analytical approximation to the \"optimal\"\nESS-value in a predictive sense (its accuracy is also validated\nexperimentally): this approximation provides an understanding as to which\nproperties of the data have the main effect determining the \"optimal\"\nESS-value.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jun 2012 15:45:39 GMT"}], "update_date": "2012-06-18", "authors_parsed": [["Steck", "Harald", ""]]}, {"id": "1206.3985", "submitter": "Marcelo Pereyra", "authors": "Marcelo Pereyra, Nicolas Dobigeon, Hadj Batatia and Jean-Yves\n  Tourneret", "title": "Computing the Cramer-Rao bound of Markov random field parameters:\n  Application to the Ising and the Potts models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report considers the problem of computing the Cramer-Rao bound for the\nparameters of a Markov random field. Computation of the exact bound is not\nfeasible for most fields of interest because their likelihoods are intractable\nand have intractable derivatives. We show here how it is possible to formulate\nthe computation of the bound as a statistical inference problem that can be\nsolve approximately, but with arbitrarily high accuracy, by using a Monte Carlo\nmethod. The proposed methodology is successfully applied on the Ising and the\nPotts models.% where it is used to assess the performance of three state-of-the\nart estimators of the parameter of these Markov random fields.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 16:49:47 GMT"}, {"version": "v2", "created": "Fri, 12 Jul 2013 08:27:46 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2013 13:14:54 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Pereyra", "Marcelo", ""], ["Dobigeon", "Nicolas", ""], ["Batatia", "Hadj", ""], ["Tourneret", "Jean-Yves", ""]]}, {"id": "1206.3991", "submitter": "Bityukov Sergey", "authors": "Sergey Bitioukov and Nikolai Krasnikov", "title": "On the relation between frequentist and Bayesian approaches for the case\n  of Poisson statistics", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose modified frequentist definition for the determination of\nconfidence intervals for the case of Poisson statistics. Namely, we require\nthat 1-\\beta' \\geq \\sum_{n=o}^{n_{obs}+k} P(n|\\lambda) \\geq \\alpha'. We show\nthat this definition is equivalent to the Bayesian method with prior\n\\pi(\\lambda) \\sim \\lambda^{k}. We also propose modified frequentist definition\nfor the case of nonzero background.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 17:06:18 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["Bitioukov", "Sergey", ""], ["Krasnikov", "Nikolai", ""]]}, {"id": "1206.4008", "submitter": "Eisa Mahmoudi", "authors": "Eisa Mahmoudi and Mitra Shiran", "title": "Exponentiated Weibull-Geometric Distribution and its Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new lifetime distribution, which is called the exponentiated\nWeibull-geometric (EWG) distribution, is introduced. This new distribution\nobtained by compounding the exponentiated Weibull and geometric distributions.\nThe EWG distribution includes as special cases the generalized\nexponential-geometric (GEG), complementary Weibull-geometric (CWG),\ncomplementary exponential-geometric (CEG), exponentiated Rayleigh-geometric\n(ERG) and Rayleigh-geometric (RG) distributions.\n  The hazard function of the EWG distribution can be decreasing, increasing,\nbathtub-shaped and unimodal among others. Several properties of the EWG\ndistribution such as quantiles and moments, maximum likelihood estimation\nprocedure via an EM-algorithm, R\\'{e}nyi and Shannon entropies, moments of\norder statistics, residual life function and probability weighted moments are\nstudied in this paper. In the end, we give two applications with real data sets\nto show the flexibility of the new distribution.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 18:04:07 GMT"}], "update_date": "2012-12-23", "authors_parsed": [["Mahmoudi", "Eisa", ""], ["Shiran", "Mitra", ""]]}, {"id": "1206.4091", "submitter": "Ryan Martin", "authors": "Ryan Martin and Chuanhai Liu", "title": "Inferential models: A framework for prior-free posterior probabilistic\n  inference", "comments": "29 pages with 3 figures. Main text is the same as the published\n  version. Appendix B is an addition, not in the published version, that\n  contains some corrections and extensions of two of the main theorems", "journal-ref": "Journal of the American Statistical Association, 2013, Vol. 108,\n  Number 501, pages 301-313", "doi": "10.1080/01621459.2012.747960", "report-no": null, "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posterior probabilistic statistical inference without priors is an important\nbut so far elusive goal. Fisher's fiducial inference, Dempster-Shafer theory of\nbelief functions, and Bayesian inference with default priors are attempts to\nachieve this goal but, to date, none has given a completely satisfactory\npicture. This paper presents a new framework for probabilistic inference, based\non inferential models (IMs), which not only provides data-dependent\nprobabilistic measures of uncertainty about the unknown parameter, but does so\nwith an automatic long-run frequency calibration property. The key to this new\napproach is the identification of an unobservable auxiliary variable associated\nwith observable data and unknown parameter, and the prediction of this\nauxiliary variable with a random set before conditioning on data. Here we\npresent a three-step IM construction, and prove a frequency-calibration\nproperty of the IM's belief function under mild conditions. A corresponding\noptimality theory is developed, which helps to resolve the non-uniqueness\nissue. Several examples are presented to illustrate this new approach.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 22:31:42 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2012 15:49:38 GMT"}, {"version": "v3", "created": "Sat, 23 Mar 2013 13:34:19 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Martin", "Ryan", ""], ["Liu", "Chuanhai", ""]]}, {"id": "1206.4189", "submitter": "Yuan-chin Chang yc.ivan.chang", "authors": "Yuan-chin Ivan Chang", "title": "Sequential Estimation in Item Calibration with A Two-Stage Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we apply a two-stage sequential design to item calibration\nproblems under a three-parameter logistic model assumption. The measurement\nerrors of the estimates of the latent trait levels of examinees are considered\nin our procedure. Moreover, a sequential procedure is employed to guarantee\nthat the estimates of the parameters reach a prescribed accuracy criterion when\nthe iteration is stopped, which fully takes the advantage of sequential design.\nStatistical properties of both the item parameter estimates and the sequential\nprocedure are discussed. We compare the performance of the proposed method with\nthat of the procedures based on some conventional designs using numerical\nstudies.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 12:17:07 GMT"}, {"version": "v2", "created": "Tue, 21 May 2013 23:36:12 GMT"}], "update_date": "2013-05-23", "authors_parsed": [["Chang", "Yuan-chin Ivan", ""]]}, {"id": "1206.4615", "submitter": "Yingjian Wang", "authors": "Yingjian Wang (Duke University), Lawrence Carin (Duke University)", "title": "Levy Measure Decompositions for the Beta and Gamma Processes", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop new representations for the Levy measures of the beta and gamma\nprocesses. These representations are manifested in terms of an infinite sum of\nwell-behaved (proper) beta and gamma distributions. Further, we demonstrate how\nthese infinite sums may be truncated in practice, and explicitly characterize\ntruncation errors. We also perform an analysis of the characteristics of\nposterior distributions, based on the proposed decompositions. The\ndecompositions provide new insights into the beta and gamma processes (and\ntheir generalizations), and we demonstrate how the proposed representation\nunifies some properties of the two. This paper is meant to provide a rigorous\nfoundation for and new perspectives on Levy processes, as these are of\nincreasing importance in machine learning.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:01:58 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Wang", "Yingjian", "", "Duke University"], ["Carin", "Lawrence", "", "Duke University"]]}, {"id": "1206.4631", "submitter": "Edoardo Airoldi", "authors": "Edoardo M Airoldi, Jonathan M Bischof", "title": "A Poisson convolution model for characterizing topical content with word\n  frequency and exclusivity", "comments": "Originally appeared in ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An ongoing challenge in the analysis of document collections is how to\nsummarize content in terms of a set of inferred themes that can be interpreted\nsubstantively in terms of topics. The current practice of parametrizing the\nthemes in terms of most frequent words limits interpretability by ignoring the\ndifferential use of words across topics. We argue that words that are both\ncommon and exclusive to a theme are more effective at characterizing topical\ncontent. We consider a setting where professional editors have annotated\ndocuments to a collection of topic categories, organized into a tree, in which\nleaf-nodes correspond to the most specific topics. Each document is annotated\nto multiple categories, at different levels of the tree. We introduce a\nhierarchical Poisson convolution model to analyze annotated documents in this\nsetting. The model leverages the structure among categories defined by\nprofessional editors to infer a clear semantic description for each topic in\nterms of words that are both frequent and exclusive. We carry out a large\nrandomized experiment on Amazon Turk to demonstrate that topic summaries based\non the FREX score are more interpretable than currently established frequency\nbased summaries, and that the proposed model produces more efficient estimates\nof exclusivity than with currently models. We also develop a parallelized\nHamiltonian Monte Carlo sampler that allows the inference to scale to millions\nof documents.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:11:38 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2012 17:32:26 GMT"}, {"version": "v3", "created": "Mon, 28 Jul 2014 03:02:39 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Airoldi", "Edoardo M", ""], ["Bischof", "Jonathan M", ""]]}, {"id": "1206.4645", "submitter": "Lauren Hannah", "authors": "Lauren Hannah (Duke University), David Dunson (Duke University)", "title": "Ensemble Methods for Convex Regression with Applications to Geometric\n  Programming Based Circuit Design", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convex regression is a promising area for bridging statistical estimation and\ndeterministic convex optimization. New piecewise linear convex regression\nmethods are fast and scalable, but can have instability when used to\napproximate constraints or objective functions for optimization. Ensemble\nmethods, like bagging, smearing and random partitioning, can alleviate this\nproblem and maintain the theoretical properties of the underlying estimator. We\nempirically examine the performance of ensemble methods for prediction and\noptimization, and then apply them to device modeling and constraint\napproximation for geometric programming based circuit design.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:19:58 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Hannah", "Lauren", "", "Duke University"], ["Dunson", "David", "", "Duke University"]]}, {"id": "1206.4666", "submitter": "Mingjun Zhong", "authors": "Mingjun Zhong (Dalian University of Tech.), Mark Girolami (University\n  College London)", "title": "A Bayesian Approach to Approximate Joint Diagonalization of Square\n  Matrices", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Bayesian scheme for the approximate diagonalisation of several\nsquare matrices which are not necessarily symmetric. A Gibbs sampler is derived\nto simulate samples of the common eigenvectors and the eigenvalues for these\nmatrices. Several synthetic examples are used to illustrate the performance of\nthe proposed Gibbs sampler and we then provide comparisons to several other\njoint diagonalization algorithms, which shows that the Gibbs sampler achieves\nthe state-of-the-art performance on the examples considered. As a byproduct,\nthe output of the Gibbs sampler could be used to estimate the log marginal\nlikelihood, however we employ the approximation based on the Bayesian\ninformation criterion (BIC) which in the synthetic examples considered\ncorrectly located the number of common eigenvectors. We then succesfully\napplied the sampler to the source separation problem as well as the common\nprincipal component analysis and the common spatial pattern analysis problems.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:32:46 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Zhong", "Mingjun", "", "Dalian University of Tech."], ["Girolami", "Mark", "", "University\n  College London"]]}, {"id": "1206.4685", "submitter": "Yan Liu", "authors": "Yan Liu (USC), Taha Bahadori (USC), Hongfei Li (IBM T.J. Watson\n  Research Center)", "title": "Sparse-GEV: Sparse Latent Space Model for Multivariate Extreme Value\n  Time Serie Modeling", "comments": "ICML2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications of time series models, such as climate analysis and\nsocial media analysis, we are often interested in extreme events, such as\nheatwave, wind gust, and burst of topics. These time series data usually\nexhibit a heavy-tailed distribution rather than a Gaussian distribution. This\nposes great challenges to existing approaches due to the significantly\ndifferent assumptions on the data distributions and the lack of sufficient past\ndata on extreme events. In this paper, we propose the Sparse-GEV model, a\nlatent state model based on the theory of extreme value modeling to\nautomatically learn sparse temporal dependence and make predictions. Our model\nis theoretically significant because it is among the first models to learn\nsparse temporal dependencies among multivariate extreme value time series. We\ndemonstrate the superior performance of our algorithm to the state-of-art\nmethods, including Granger causality, copula approach, and transfer entropy, on\none synthetic dataset, one climate dataset and two Twitter datasets.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:42:15 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Liu", "Yan", "", "USC"], ["Bahadori", "Taha", "", "USC"], ["Li", "Hongfei", "", "IBM T.J. Watson\n  Research Center"]]}, {"id": "1206.4832", "submitter": "Debarghya Ghoshdastidar", "authors": "Debarghya Ghoshdastidar, Ambedkar Dukkipati, Shalabh Bhatnagar", "title": "Smoothed Functional Algorithms for Stochastic Optimization using\n  q-Gaussian Distributions", "comments": null, "journal-ref": null, "doi": "10.1145/2628434", "report-no": null, "categories": "cs.IT cs.LG math.IT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smoothed functional (SF) schemes for gradient estimation are known to be\nefficient in stochastic optimization algorithms, specially when the objective\nis to improve the performance of a stochastic system. However, the performance\nof these methods depends on several parameters, such as the choice of a\nsuitable smoothing kernel. Different kernels have been studied in literature,\nwhich include Gaussian, Cauchy and uniform distributions among others. This\npaper studies a new class of kernels based on the q-Gaussian distribution, that\nhas gained popularity in statistical physics over the last decade. Though the\nimportance of this family of distributions is attributed to its ability to\ngeneralize the Gaussian distribution, we observe that this class encompasses\nalmost all existing smoothing kernels. This motivates us to study SF schemes\nfor gradient estimation using the q-Gaussian distribution. Using the derived\ngradient estimates, we propose two-timescale algorithms for optimization of a\nstochastic objective function in a constrained setting with projected gradient\nsearch approach. We prove the convergence of our algorithms to the set of\nstationary points of an associated ODE. We also demonstrate their performance\nnumerically through simulations on a queuing model.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 11:03:50 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2012 14:35:25 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2012 04:39:45 GMT"}, {"version": "v4", "created": "Fri, 21 Sep 2012 05:48:05 GMT"}, {"version": "v5", "created": "Sat, 6 Apr 2013 09:20:52 GMT"}, {"version": "v6", "created": "Thu, 3 Jul 2014 04:56:30 GMT"}], "update_date": "2014-07-04", "authors_parsed": [["Ghoshdastidar", "Debarghya", ""], ["Dukkipati", "Ambedkar", ""], ["Bhatnagar", "Shalabh", ""]]}, {"id": "1206.4881", "submitter": "Jesse Hoey", "authors": "Jesse Hoey", "title": "The Two-Way Likelihood Ratio (G) Test and Comparison to Two-Way Chi\n  Squared Test", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a derivation of the Two-Way Likelihood Ratio (G) Test and\nComparison to the Two-Way Chi Squared Test\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 13:54:12 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2012 18:23:51 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Hoey", "Jesse", ""]]}, {"id": "1206.4937", "submitter": "Ivan Kojadinovic", "authors": "Mark Holmes, Ivan Kojadinovic and Jean-Fran\\c{c}ois Quessy", "title": "Nonparametric tests for change-point detection \\`a la Gombay and\n  Horv\\'ath", "comments": "30 pages, 6 tables", "journal-ref": "Journal of Multivariate Analysis 115, pages 16-32, 2013", "doi": null, "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nonparametric test for change-point detection proposed by Gombay and\nHorv\\'ath is revisited and extended in the broader setting of empirical process\ntheory. The resulting testing procedure for potentially multivariate\nobservations is based on a sequential generalization of the functional\nmultiplier central limit theorem and on modifications of Gombay and Horv\\'ath's\nseminal approach that appears to improve the finite-sample behavior of the\ntests. A large number of candidate test statistics based on processes indexed\nby lower-left orthants and half-spaces are considered and their performance is\nstudied through extensive Monte Carlo experiments involving univariate,\nbivariate and trivariate data sets. Finally, practical recommendations are\nprovided and the tests are illustrated on trivariate hydrological data.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 16:47:11 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2012 20:43:52 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Holmes", "Mark", ""], ["Kojadinovic", "Ivan", ""], ["Quessy", "Jean-Fran\u00e7ois", ""]]}, {"id": "1206.5014", "submitter": "You Ling", "authors": "You Ling, Sankaran Mahadevan", "title": "Quantitative model validation techniques: new insights", "comments": "40 pages, 9 figures. Submitted to Reliability Engineering and System\n  Safety on Dec 10, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops new insights into quantitative methods for the validation\nof computational model prediction. Four types of methods are investigated,\nnamely classical and Bayesian hypothesis testing, a reliability-based method,\nand an area metric-based method. Traditional Bayesian hypothesis testing is\nextended based on interval hypotheses on distribution parameters and equality\nhypotheses on probability distributions, in order to validate models with\ndeterministic/stochastic output for given inputs. Two types of validation\nexperiments are considered - fully characterized (all the model/experimental\ninputs are measured and reported as point values) and partially characterized\n(some of the model/experimental inputs are not measured or are reported as\nintervals). Bayesian hypothesis testing can minimize the risk in model\nselection by properly choosing the model acceptance threshold, and its results\ncan be used in model averaging to avoid Type I/II errors. It is shown that\nBayesian interval hypothesis testing, the reliability-based method, and the\narea metric-based method can account for the existence of directional bias,\nwhere the mean predictions of a numerical model may be consistently below or\nabove the corresponding experimental observations. It is also found that under\nsome specific conditions, the Bayes factor metric in Bayesian equality\nhypothesis testing and the reliability-based metric can both be mathematically\nrelated to the p-value metric in classical hypothesis testing. Numerical\nstudies are conducted to apply the above validation methods to gas damping\nprediction for radio frequency (RF) microelectromechanical system (MEMS)\nswitches. The model of interest is a general polynomial chaos (gPC) surrogate\nmodel constructed based on expensive runs of a physics-based simulation model,\nand validation data are collected from fully characterized experiments.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 20:41:48 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Ling", "You", ""], ["Mahadevan", "Sankaran", ""]]}, {"id": "1206.5015", "submitter": "You Ling", "authors": "You Ling, Joshua Mullins, Sankaran Mahadevan", "title": "Calibration of multi-physics computational models using Bayesian\n  networks", "comments": "38 pages, 10 figures, Submitted to the Journal of Computational\n  Physics on May 3, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper develops a Bayesian network-based method for the calibration of\nmulti-physics models, integrating various sources of uncertainty with\ninformation from computational models and experimental data. We adopt the\nKennedy and O'Hagan (KOH) framework for model calibration under uncertainty,\nand develop extensions to multi-physics models and various scenarios of\navailable data. Both aleatoric uncertainty (due to natural variability) and\nepistemic uncertainty (due to lack of information, including data uncertainty\nand model uncertainty) are accounted for in the calibration process.\nChallenging aspects of Bayesian calibration for multi-physics models are\ninvestigated, including: (1) calibration with different forms of experimental\ndata (e.g., interval data and time series data), (2) determination of the\nidentifiability of model parameters when the analytical expression of model is\nknown or unknown, (3) calibration of multiple physics models sharing common\nparameters, which enables efficient use of data especially when the\nexperimental resources are limited. A first-order Taylor series expansion-based\nmethod is proposed to determine which model parameters are identifiable.\nFollowing the KOH framework, a probabilistic discrepancy function is estimated\nand added to the prediction of the calibrated model, attempting to account for\nmodel uncertainty. This discrepancy function is modeled as a Gaussian process\nwhen sufficient data are available for multiple model input combinations, and\nis modeled as a random variable when the available data are limited. The\noverall approach is illustrated using two application examples related to\nmicroelectromechanical system (MEMS) devices: (1) calibration of a dielectric\ncharging model with time-series data, and (2) calibration of two physics models\n(pull-in voltage and creep) using measurements of different physical quantities\nin different devices.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 20:43:48 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Ling", "You", ""], ["Mullins", "Joshua", ""], ["Mahadevan", "Sankaran", ""]]}, {"id": "1206.5070", "submitter": "Dominik Wied", "authors": "Dominik Wied and Herold Dehling and Maarten van Kampen and Daniel\n  Vogel", "title": "A fluctuation test for constant Spearman's rho with nuisance-free limit\n  distribution", "comments": null, "journal-ref": null, "doi": "10.1016/j.csda.2013.03.005", "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A CUSUM type test for constant correlation that goes beyond a previously\nsuggested correlation constancy test by considering Spearman's rho in arbitrary\ndimensions is proposed. Since the new test does not require the existence of\nany moments, the applicability on usually heavy-tailed financial data is\ngreatly improved. The asymptotic null distribution is calculated using an\ninvariance principle for the sequential empirical copula process. The limit\ndistribution is free of nuisance parameters and critical values can be obtained\nwithout bootstrap techniques. A local power result and an analysis of the\nbehavior of the test in small samples is provided.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 07:12:15 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2014 09:13:11 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Wied", "Dominik", ""], ["Dehling", "Herold", ""], ["van Kampen", "Maarten", ""], ["Vogel", "Daniel", ""]]}, {"id": "1206.5208", "submitter": "James S. Martin", "authors": "James S. Martin and Ajay Jasra and Sumeetpal S. Singh and Nick\n  Whiteley and Emma McCoy", "title": "Approximate Bayesian Computation for Smoothing", "comments": "22 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a method for approximate inference in hidden Markov models\n(HMMs). The method circumvents the need to evaluate conditional densities of\nobservations given the hidden states. It may be considered an instance of\nApproximate Bayesian Computation (ABC) and it involves the introduction of\nauxiliary variables valued in the same space as the observations. The quality\nof the approximation may be controlled to arbitrary precision through a\nparameter \\epsilon>0 . We provide theoretical results which quantify, in terms\nof \\epsilon, the ABC error in approximation of expectations of additive\nfunctionals with respect to the smoothing distributions. Under regularity\nassumptions, this error is O(n\\epsilon), where n is the number of time steps\nover which smoothing is performed. For numerical implementation we adopt the\nforward-only sequential Monte Carlo (SMC) scheme of [16] and quantify the\ncombined error from the ABC and SMC approximations. This forms some of the\nfirst quantitative results for ABC methods which jointly treat the ABC and\nsimulation errors, with a finite number of data and simulated samples. When the\nHMM has unknown static parameters, we consider particle Markov chain Monte\nCarlo [2] (PMCMC) methods for batch statistical inference.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jun 2012 17:01:56 GMT"}], "update_date": "2012-06-25", "authors_parsed": [["Martin", "James S.", ""], ["Jasra", "Ajay", ""], ["Singh", "Sumeetpal S.", ""], ["Whiteley", "Nick", ""], ["McCoy", "Emma", ""]]}, {"id": "1206.5245", "submitter": "Ad Feelders", "authors": "Ad Feelders", "title": "A new parameter Learning Method for Bayesian Networks with Qualitative\n  Influences", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-117-124", "categories": "cs.AI cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new method for parameter learning in Bayesian networks with\nqualitative influences. This method extends our previous work from networks of\nbinary variables to networks of discrete variables with ordered values. The\nspecified qualitative influences correspond to certain order restrictions on\nthe parameters in the network. These parameters may therefore be estimated\nusing constrained maximum likelihood estimation. We propose an alternative\nmethod, based on the isotonic regression. The constrained maximum likelihood\nestimates are fairly complicated to compute, whereas computation of the\nisotonic regression estimates only requires the repeated application of the\nPool Adjacent Violators algorithm for linear orders. Therefore, the isotonic\nregression estimator is to be preferred from the viewpoint of computational\ncomplexity. Through experiments on simulated and real data, we show that the\nnew learning method is competitive in performance to the constrained maximum\nlikelihood estimator, and that both estimators improve on the standard\nestimator.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:54:06 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Feelders", "Ad", ""]]}, {"id": "1206.5246", "submitter": "Michael Eichler", "authors": "Michael Eichler, Vanessa Didelez", "title": "Causal Reasoning in Graphical Time Series Models", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-109-116", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a definition of causality for time series in terms of the effect\nof an intervention in one component of a multivariate time series on another\ncomponent at some later point in time. Conditions for identifiability,\ncomparable to the back-door and front-door criteria, are presented and can also\nbe verified graphically. Computation of the causal effect is derived and\nillustrated for the linear case.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:54:25 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Eichler", "Michael", ""], ["Didelez", "Vanessa", ""]]}, {"id": "1206.5254", "submitter": "Francois Caron", "authors": "Francois Caron, Manuel Davy, Arnaud Doucet", "title": "Generalized Polya Urn for Time-varying Dirichlet Process Mixtures", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-33-40", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dirichlet Process Mixtures (DPMs) are a popular class of statistical models\nto perform density estimation and clustering. However, when the data available\nhave a distribution evolving over time, such models are inadequate. We\nintroduce here a class of time-varying DPMs which ensures that at each time\nstep the random distribution follows a DPM model. Our model relies on an\nintuitive and simple generalized Polya urn scheme. Inference is performed using\nMarkov chain Monte Carlo and Sequential Monte Carlo. We demonstrate our model\non various applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 14:57:41 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Caron", "Francois", ""], ["Davy", "Manuel", ""], ["Doucet", "Arnaud", ""]]}, {"id": "1206.5262", "submitter": "Roland R. Ramsahai", "authors": "Roland R. Ramsahai", "title": "Causal Bounds and Instruments", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-310-317", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instrumental variables have proven useful, in particular within the social\nsciences and economics, for making inference about the causal effect of a\nrandom variable, B, on another random variable, C, in the presence of\nunobserved confounders. In the case where relationships are linear, causal\neffects can be identified exactly from studying the regression of C on A and\nthe regression of B on A, where A is the instrument. In the more general case,\nbounds have been developed in the literature for the causal effect of B on C,\ngiven observational data on the joint distribution of C, B and A. Using an\napproach based on the analysis of convex polytopes, we develop bounds for the\nsame causal effect when given data on (C,A) and (B,A) only. The bounds\ndeveloped are thus in direct analogy to the standard use of instruments in\neconometrics, but we make no assumption of linearity. Use of the bounds is\nillustrated for experiments with partial compliance. The bounds are, for\nexample, relevant in genetic epidemiology, where the 'Mendelian instrument' S\nrepresents a genotype, and where joint data on all of C, B and A may rarely be\navailable but studies involving pairs of these may be abundant. Other examples\nof bounding causal effects are considered to show that the method applies to\nDAGs in general, subject to certain conditions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:01:24 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Ramsahai", "Roland R.", ""]]}, {"id": "1206.5272", "submitter": "Manabu Kuroki", "authors": "Manabu Kuroki, Zhihong Cai", "title": "Evaluation of the Causal Effect of Control Plans in Nonrecursive\n  Structural Equation Models", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-227-234", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When observational data is available from practical studies and a directed\ncyclic graph for how various variables affect each other is known based on\nsubstantive understanding of the process, we consider a problem in which a\ncontrol plan of a treatment variable is conducted in order to bring a response\nvariable close to a target value with variation reduction. We formulate an\noptimal control plan concerning a certain treatment variable through path\ncoefficients in the framework of linear nonrecursive structural equation\nmodels. Based on the formulation, we clarify the properties of causal effects\nwhen conducting a control plan. The results enable us to evaluate the effect of\na control plan on the variance from observational data.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:05:31 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Kuroki", "Manabu", ""], ["Cai", "Zhihong", ""]]}, {"id": "1206.5275", "submitter": "Changsung Kang", "authors": "Changsung Kang, Jin Tian", "title": "Polynomial Constraints in Causal Bayesian Networks", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-200-208", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the implicitization procedure to generate polynomial equality\nconstraints on the set of distributions induced by local interventions on\nvariables governed by a causal Bayesian network with hidden variables. We show\nhow we may reduce the complexity of the implicitization problem and make the\nproblem tractable in certain causal Bayesian networks. We also show some\npreliminary results on the algebraic structure of polynomial constraints. The\nresults have applications in distinguishing between causal models and in\ntesting causal models with combined observational and experimental data.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:06:26 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Kang", "Changsung", ""], ["Tian", "Jin", ""]]}, {"id": "1206.5278", "submitter": "Michael P. Holmes", "authors": "Michael P. Holmes, Alexander G. Gray, Charles Lee Isbell", "title": "Fast Nonparametric Conditional Density Estimation", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-175-182", "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional density estimation generalizes regression by modeling a full\ndensity f(yjx) rather than only the expected value E(yjx). This is important\nfor many tasks, including handling multi-modality and generating prediction\nintervals. Though fundamental and widely applicable, nonparametric conditional\ndensity estimators have received relatively little attention from statisticians\nand little or none from the machine learning community. None of that work has\nbeen applied to greater than bivariate data, presumably due to the\ncomputational difficulty of data-driven bandwidth selection. We describe the\ndouble kernel conditional density estimator and derive fast dual-tree-based\nalgorithms for bandwidth selection using a maximum likelihood criterion. These\ntechniques give speedups of up to 3.8 million in our experiments, and enable\nthe first applications to previously intractable large multivariate datasets,\nincluding a redshift prediction problem from the Sloan Digital Sky Survey.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:08:36 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Holmes", "Michael P.", ""], ["Gray", "Alexander G.", ""], ["Isbell", "Charles Lee", ""]]}, {"id": "1206.5282", "submitter": "Jiji Zhang", "authors": "Jiji Zhang", "title": "A Characterization of Markov Equivalence Classes for Directed Acyclic\n  Graphs with Latent Variables", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-450-457", "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different directed acyclic graphs (DAGs) may be Markov equivalent in the\nsense that they entail the same conditional independence relations among the\nobserved variables. Meek (1995) characterizes Markov equivalence classes for\nDAGs (with no latent variables) by presenting a set of orientation rules that\ncan correctly identify all arrow orientations shared by all DAGs in a Markov\nequivalence class, given a member of that class. For DAG models with latent\nvariables, maximal ancestral graphs (MAGs) provide a neat representation that\nfacilitates model search. Earlier work (Ali et al. 2005) has identified a set\nof orientation rules sufficient to construct all arrowheads common to a Markov\nequivalence class of MAGs. In this paper, we provide extra rules sufficient to\nconstruct all common tails as well. We end up with a set of orientation rules\nsound and complete for identifying commonalities across a Markov equivalence\nclass of MAGs, which is particularly useful for causal inference.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:14:16 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Zhang", "Jiji", ""]]}, {"id": "1206.5289", "submitter": "Jin Tian", "authors": "Jin Tian", "title": "A Criterion for Parameter Identification in Structural Equation Models", "comments": "Appears in Proceedings of the Twenty-Third Conference on Uncertainty\n  in Artificial Intelligence (UAI2007)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2007-PG-392-399", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the problem of identifying direct causal effects in\nrecursive linear structural equation models. The paper establishes a sufficient\ncriterion for identifying individual causal effects and provides a procedure\ncomputing identified causal effects in terms of observed covariance matrix.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 15:17:07 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Tian", "Jin", ""]]}, {"id": "1206.5367", "submitter": "Dominik Wied", "authors": "Pedro Galeano and Dominik Wied", "title": "Multiple break detection in the correlation structure of random\n  variables", "comments": null, "journal-ref": null, "doi": "10.1016/j.csda.2013.02.031", "report-no": null, "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlations between random variables play an important role in applications,\ne.g.\\ in financial analysis. More precisely, accurate estimates of the\ncorrelation between financial returns are crucial in portfolio management. In\nparticular, in periods of financial crisis, extreme movements in asset prices\nare found to be more highly correlated than small movements. It is precisely\nunder these conditions that investors are extremely concerned about changes on\ncorrelations. A binary segmentation procedure to detect the number and position\nof multiple change points in the correlation structure of random variables is\nproposed. The procedure assumes that expectations and variances are constant\nand that there are sudden shifts in the correlations. It is shown analytically\nthat the proposed algorithm asymptotically gives the correct number of change\npoints and the change points are consistently estimated. It is also shown by\nsimulation studies and by an empirical application that the algorithm yields\nreasonable results.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2012 08:03:49 GMT"}, {"version": "v2", "created": "Thu, 30 Jan 2014 09:17:54 GMT"}], "update_date": "2014-01-31", "authors_parsed": [["Galeano", "Pedro", ""], ["Wied", "Dominik", ""]]}, {"id": "1206.5681", "submitter": "Leonardo Bastos", "authors": "Leonardo S. Bastos and Adriana A. Pinho and Claudia Code\\c{c}o and\n  Francisco I. Bastos", "title": "Binary regression analysis with network structure of respondent-driven\n  sampling data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Respondent-driven sampling (RDS) is a procedure to sample from hard-to-reach\npopulations. It has been widely used in several countries, especially in the\nmonitoring of HIV/AIDS and other sexually transmitted infections. Hard-to-reach\npopulations have had a key role in the dynamics of such epidemics and must\ninform evidence-based initiatives aiming to curb their spread. In this paper,\nwe present a simple test for network dependence for a binary response variable.\nWe estimate the prevalence of the response variable. We also propose a binary\nregression model taking into account the RDS structure which is included in the\nmodel through a latent random effect with a correlation structure. The proposed\nmodel is illustrated in a RDS study for HIV and Syphilis in men who have sex\nwith men implemented in Campinas (Brazil).\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 13:45:20 GMT"}], "update_date": "2012-06-26", "authors_parsed": [["Bastos", "Leonardo S.", ""], ["Pinho", "Adriana A.", ""], ["Code\u00e7o", "Claudia", ""], ["Bastos", "Francisco I.", ""]]}, {"id": "1206.5862", "submitter": "Tamara Broderick", "authors": "Tamara Broderick, Michael I. Jordan, Jim Pitman", "title": "Cluster and Feature Modeling from Combinatorial Stochastic Processes", "comments": "Published in at http://dx.doi.org/10.1214/13-STS434 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2013, Vol. 28, No. 3, 289-312", "doi": "10.1214/13-STS434", "report-no": "IMS-STS-STS434", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the focal points of the modern literature on Bayesian nonparametrics\nhas been the problem of clustering, or partitioning, where each data point is\nmodeled as being associated with one and only one of some collection of groups\ncalled clusters or partition blocks. Underlying these Bayesian nonparametric\nmodels are a set of interrelated stochastic processes, most notably the\nDirichlet process and the Chinese restaurant process. In this paper we provide\na formal development of an analogous problem, called feature modeling, for\nassociating data points with arbitrary nonnegative integer numbers of groups,\nnow called features or topics. We review the existing combinatorial stochastic\nprocess representations for the clustering problem and develop analogous\nrepresentations for the feature modeling problem. These representations include\nthe beta process and the Indian buffet process as well as new representations\nthat provide insight into the connections between these processes. We thereby\nbring the same level of completeness to the treatment of Bayesian nonparametric\nfeature modeling that has previously been achieved for Bayesian nonparametric\nclustering.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 00:08:50 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2013 07:33:31 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Broderick", "Tamara", ""], ["Jordan", "Michael I.", ""], ["Pitman", "Jim", ""]]}, {"id": "1206.6053", "submitter": "Le-Yu Chen", "authors": "Le-Yu Chen and Jerzy Szroeter", "title": "Testing Multiple Inequality Hypotheses : A Smoothed Indicator Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a class of origin-smooth approximators of indicators\nunderlying the sum-of-negative-part statistic for testing multiple\ninequalities. The need for simulation or bootstrap to obtain test critical\nvalues is thereby obviated. A simple procedure is enabled using fixed critical\nvalues. The test is shown to have correct asymptotic size in the uniform sense\nthat supremum finite-sample rejection probability over null-restricted data\ndistributions tends asymptotically to nominal significance level. This applies\nunder weak assumptions allowing for estimator covariance singularity. The test\nis unbiased for a wide class of local alternatives. A new theorem establishes\ndirections in which the test is locally most powerful. The proposed procedure\nis compared with predominant existing tests in structure, theory and\nsimulation.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 17:11:38 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Chen", "Le-Yu", ""], ["Szroeter", "Jerzy", ""]]}, {"id": "1206.6070", "submitter": "Karla Diaz-Ordaz Ms", "authors": "Karla Diaz-Ordaz, Michael G. Kenward and Richard Grieve", "title": "Handling missing values in cost-effectiveness analyses that use data\n  from cluster randomised trials", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Public policy-makers use cost-effectiveness analyses (CEA) to decide which\nhealth and social care interventions to provide. Appropriate methods have not\nbeen developed for handling missing data in complex settings, such as for CEA\nthat use data from cluster randomised trials (CRTs). We present a multilevel\nmultiple imputation (MI) approach that recognises when missing data have a\nhierarchical structure, and is compatible with the bivariate multilevel models\nused to report cost-effectiveness. We contrast the multilevel MI approach with\nsingle-level MI and complete case analysis in a CEA alongside a CRT. The paper\nhighlights the importance of adopting a principled approach to handling missing\nvalues in settings with complex data structures.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 18:22:58 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Diaz-Ordaz", "Karla", ""], ["Kenward", "Michael G.", ""], ["Grieve", "Richard", ""]]}, {"id": "1206.6367", "submitter": "Mark Tygert", "authors": "Jacob Carruth, Mark Tygert, and Rachel Ward", "title": "A comparison of the discrete Kolmogorov-Smirnov statistic and the\n  Euclidean distance", "comments": "15 pages, 6 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goodness-of-fit tests gauge whether a given set of observations is consistent\n(up to expected random fluctuations) with arising as independent and\nidentically distributed (i.i.d.) draws from a user-specified probability\ndistribution known as the \"model.\" The standard gauges involve the discrepancy\nbetween the model and the empirical distribution of the observed draws. Some\nmeasures of discrepancy are cumulative; others are not. The most popular\ncumulative measure is the Kolmogorov-Smirnov statistic; when all probability\ndistributions under consideration are discrete, a natural noncumulative measure\nis the Euclidean distance between the model and the empirical distributions. In\nthe present paper, both mathematical analysis and its illustration via various\ndata sets indicate that the Kolmogorov-Smirnov statistic tends to be more\npowerful than the Euclidean distance when there is a natural ordering for the\nvalues that the draws can take -- that is, when the data is ordinal -- whereas\nthe Euclidean distance is more reliable and more easily understood than the\nKolmogorov-Smirnov statistic when there is no natural ordering (or partial\norder) -- that is, when the data is nominal.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:15:25 GMT"}], "update_date": "2012-06-28", "authors_parsed": [["Carruth", "Jacob", ""], ["Tygert", "Mark", ""], ["Ward", "Rachel", ""]]}, {"id": "1206.6385", "submitter": "Philip Bachman", "authors": "Doina Precup (McGill University), Philip Bachman (McGill University)", "title": "Improved Estimation in Time Varying Models", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally adapted parameterizations of a model (such as locally weighted\nregression) are expressive but often suffer from high variance. We describe an\napproach for reducing the variance, based on the idea of estimating\nsimultaneously a transformed space for the model, as well as locally adapted\nparameterizations in this new space. We present a new problem formulation that\ncaptures this idea and illustrate it in the important context of time varying\nmodels. We develop an algorithm for learning a set of bases for approximating a\ntime varying sparse network; each learned basis constitutes an archetypal\nsparse network structure. We also provide an extension for learning task-driven\nbases. We present empirical results on synthetic data sets, as well as on a BCI\nEEG classification task.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Precup", "Doina", "", "McGill University"], ["Bachman", "Philip", "", "McGill University"]]}, {"id": "1206.6391", "submitter": "Alexis Boukouvalas", "authors": "Alexis Boukouvalas (Aston University), Remi Barillec (Aston\n  University), Dan Cornford (Aston University)", "title": "Gaussian Process Quantile Regression using Expectation Propagation", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct quantile regression involves estimating a given quantile of a response\nvariable as a function of input variables. We present a new framework for\ndirect quantile regression where a Gaussian process model is learned,\nminimising the expected tilted loss function. The integration required in\nlearning is not analytically tractable so to speed up the learning we employ\nthe Expectation Propagation algorithm. We describe how this work relates to\nother quantile regression methods and apply the method on both synthetic and\nreal data sets. The method is shown to be competitive with state of the art\nmethods whilst allowing for the leverage of the full Gaussian process\nprobabilistic framework.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Boukouvalas", "Alexis", "", "Aston University"], ["Barillec", "Remi", "", "Aston\n  University"], ["Cornford", "Dan", "", "Aston University"]]}, {"id": "1206.6408", "submitter": "Haijie Gu", "authors": "Haijie Gu (Carnegie Mellon University), John Lafferty (University of\n  Chicago)", "title": "Sequential Nonparametric Regression", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME astro-ph.IM cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present algorithms for nonparametric regression in settings where the data\nare obtained sequentially. While traditional estimators select bandwidths that\ndepend upon the sample size, for sequential data the effective sample size is\ndynamically changing. We propose a linear time algorithm that adjusts the\nbandwidth for each new data point, and show that the estimator achieves the\noptimal minimax rate of convergence. We also propose the use of online expert\nmixing algorithms to adapt to unknown smoothness of the regression function. We\nprovide simulations that confirm the theoretical results, and demonstrate the\neffectiveness of the methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Gu", "Haijie", "", "Carnegie Mellon University"], ["Lafferty", "John", "", "University of\n  Chicago"]]}, {"id": "1206.6433", "submitter": "Melanie Rey", "authors": "Melanie Rey (University of Basel), Volker Roth (University of Basel)", "title": "Copula Mixture Model for Dependency-seeking Clustering", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a copula mixture model to perform dependency-seeking clustering\nwhen co-occurring samples from different data sources are available. The model\ntakes advantage of the great flexibility offered by the copulas framework to\nextend mixtures of Canonical Correlation Analysis to multivariate data with\narbitrary continuous marginal densities. We formulate our model as a\nnon-parametric Bayesian mixture, while providing efficient MCMC inference.\nExperiments on synthetic and real data demonstrate that the increased\nflexibility of the copula mixture significantly improves the clustering and the\ninterpretability of the results.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Rey", "Melanie", "", "University of Basel"], ["Roth", "Volker", "", "University of Basel"]]}, {"id": "1206.6456", "submitter": "Mingyuan Zhou", "authors": "Mingyuan Zhou (Duke University), Lingbo Li (Duke University), David\n  Dunson (Duke University), Lawrence Carin (Duke University)", "title": "Lognormal and Gamma Mixed Negative Binomial Regression", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In regression analysis of counts, a lack of simple and efficient algorithms\nfor posterior computation has made Bayesian approaches appear unattractive and\nthus underdeveloped. We propose a lognormal and gamma mixed negative binomial\n(NB) regression model for counts, and present efficient closed-form Bayesian\ninference; unlike conventional Poisson models, the proposed approach has two\nfree parameters to include two different kinds of random effects, and allows\nthe incorporation of prior information, such as sparsity in the regression\ncoefficients. By placing a gamma distribution prior on the NB dispersion\nparameter r, and connecting a lognormal distribution prior with the logit of\nthe NB probability parameter p, efficient Gibbs sampling and variational Bayes\ninference are both developed. The closed-form updates are obtained by\nexploiting conditional conjugacy via both a compound Poisson representation and\na Polya-Gamma distribution based data augmentation approach. The proposed\nBayesian inference can be implemented routinely, while being easily\ngeneralizable to more complex settings involving multivariate dependence\nstructures. The algorithms are illustrated using real examples.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Zhou", "Mingyuan", "", "Duke University"], ["Li", "Lingbo", "", "Duke University"], ["Dunson", "David", "", "Duke University"], ["Carin", "Lawrence", "", "Duke University"]]}, {"id": "1206.6459", "submitter": "Chris Bracegirdle", "authors": "Chris Bracegirdle (University College London), David Barber\n  (University College London)", "title": "Bayesian Conditional Cointegration", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cointegration is an important topic for time-series, and describes a\nrelationship between two series in which a linear combination is stationary.\nClassically, the test for cointegration is based on a two stage process in\nwhich first the linear relation between the series is estimated by Ordinary\nLeast Squares. Subsequently a unit root test is performed on the residuals. A\nwell-known deficiency of this classical approach is that it can lead to\nerroneous conclusions about the presence of cointegration. As an alternative,\nwe present a framework for estimating whether cointegration exists using\nBayesian inference which is empirically superior to the classical approach.\nFinally, we apply our technique to model segmented cointegration in which\ncointegration may exist only for limited time. In contrast to previous\napproaches our model makes no restriction on the number of possible\ncointegration segments.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Bracegirdle", "Chris", "", "University College London"], ["Barber", "David", "", "University College London"]]}, {"id": "1206.6488", "submitter": "Han Liu", "authors": "Han Liu (Johns Hopkins University), Fang Han (Johns Hopkins\n  University), Ming Yuan (Georgia Institute of Technology), John Lafferty\n  (University of Chicago), Larry Wasserman (Carnegie Mellon University)", "title": "The Nonparanormal SKEPTIC", "comments": "Appears in Proceedings of the 29th International Conference on\n  Machine Learning (ICML 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a semiparametric approach, named nonparanormal skeptic, for\nestimating high dimensional undirected graphical models. In terms of modeling,\nwe consider the nonparanormal family proposed by Liu et al (2009). In terms of\nestimation, we exploit nonparametric rank-based correlation coefficient\nestimators including the Spearman's rho and Kendall's tau. In high dimensional\nsettings, we prove that the nonparanormal skeptic achieves the optimal\nparametric rate of convergence in both graph and parameter estimation. This\nresult suggests that the nonparanormal graphical models are a safe replacement\nof the Gaussian graphical models, even when the data are Gaussian.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 19:59:59 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Liu", "Han", "", "Johns Hopkins University"], ["Han", "Fang", "", "Johns Hopkins\n  University"], ["Yuan", "Ming", "", "Georgia Institute of Technology"], ["Lafferty", "John", "", "University of Chicago"], ["Wasserman", "Larry", "", "Carnegie Mellon University"]]}, {"id": "1206.6519", "submitter": "Noah Simon", "authors": "Noah Simon and Robert Tibshirani", "title": "A Permutation Approach to Testing Interactions in Many Dimensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.CO stat.ME", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  To date, testing interactions in high dimensions has been a challenging task.\nExisting methods often have issues with sensitivity to modeling assumptions and\nheavily asymptotic nominal p-values. To help alleviate these issues, we propose\na permutation-based method for testing marginal interactions with a binary\nresponse. Our method searches for pairwise correlations which differ between\nclasses. In this manuscript, we compare our method on real and simulated data\nto the standard approach of running many pairwise logistic models. On simulated\ndata our method finds more significant interactions at a lower false discovery\nrate (especially in the presence of main effects). On real genomic data,\nalthough there is no gold standard, our method finds apparent signal and tells\na believable story, while logistic regression does not. We also give asymptotic\nconsistency results under not too restrictive assumptions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 20:38:20 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Simon", "Noah", ""], ["Tibshirani", "Robert", ""]]}, {"id": "1206.6570", "submitter": "Jingwei  Liu", "authors": "Jingwei Liu", "title": "Extension of Three-Variable Counterfactual Casual Graphic Model: from\n  Two-Value to Three-Value Random Variable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extension of counterfactual causal graphic model with three variables of\nvertex set in directed acyclic graph (DAG) is discussed in this paper by\nextending two- value distribution to three-value distribution of the variables\ninvolved in DAG. Using the conditional independence as ancillary information, 6\nkinds of extension counterfactual causal graphic models with some variables are\nextended from two-value distribution to three-value distribution and the\nsufficient conditions of identifiability are derived.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 06:14:12 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2012 10:54:26 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Liu", "Jingwei", ""]]}, {"id": "1206.6701", "submitter": "Paul T Edlefsen", "authors": "Paul T. Edlefsen", "title": "Evaluating the dependence of a non-leaky intervention's partial efficacy\n  on a categorical mark", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address discrete-marks survival analysis, also known as categorical sieve\nanalysis, for a setting of a randomized placebo-controlled treatment\nintervention to prevent infection by a pathogen to which multiple exposures are\npossible, with a finite number of types of \"failure\". In particular, we address\nthe case of interventions that are partially efficacious due to a combination\nof failure-type-dependent efficacy and subject-dependent efficacy, for an\nintervention that is \"non-leaky\" (where \"leaky\" interventions are those for\nwhich each exposure event has a chance of resulting in a \"failure\" outcome, so\nmultiple exposures to pathogens of a single type increase the chance of\nfailure). We introduce the notion of some-or-none interventions, which are\ncompletely effective only against some of the failure types, and are completely\nineffective against the others. Under conditions of no intervention-induced\nfailures, we introduce a framework and Bayesian and frequentist methods to\ndetect and quantify the extent to which an intervention's partial efficacy is\nattributable to uneven efficacy across the failure types rather than to\nincomplete \"take\" of the intervention. These new methods provide more power\nthan existing methods to detect sieve effects when the conditions hold. We\ndemonstrate the new framework and methods with simulation results and new\nanalyses of genomic signatures of HIV-1 vaccine effects in the STEP and RV144\nvaccine efficacy trials.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 14:28:10 GMT"}, {"version": "v2", "created": "Fri, 3 Jan 2014 19:32:25 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Edlefsen", "Paul T.", ""]]}, {"id": "1206.6721", "submitter": "Sara van de Geer", "authors": "Sara van de Geer, Patric M\\\"uller", "title": "Quasi-Likelihood and/or Robust Estimation in High Dimensions", "comments": "Published in at http://dx.doi.org/10.1214/12-STS397 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2012, Vol. 27, No. 4, 469-480", "doi": "10.1214/12-STS397", "report-no": "IMS-STS-STS397", "categories": "math.ST stat.ME stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the theory for the high-dimensional generalized linear model with\nthe Lasso. After a short review on theoretical results in literature, we\npresent an extension of the oracle results to the case of quasi-likelihood\nloss. We prove bounds for the prediction error and $\\ell_1$-error. The results\nare derived under fourth moment conditions on the error distribution. The case\nof robust loss is also given. We moreover show that under an irrepresentable\ncondition, the $\\ell_1$-penalized quasi-likelihood estimator has no false\npositives.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 15:09:16 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2013 14:13:32 GMT"}], "update_date": "2013-01-07", "authors_parsed": [["van de Geer", "Sara", ""], ["M\u00fcller", "Patric", ""]]}, {"id": "1206.6821", "submitter": "Carlos Brito", "authors": "Carlos Brito, Judea Pearl", "title": "Graphical Condition for Identification in recursive SEM", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-47-54", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper concerns the problem of predicting the effect of actions or\ninterventions on a system from a combination of (i) statistical data on a set\nof observed variables, and (ii) qualitative causal knowledge encoded in the\nform of a directed acyclic graph (DAG). The DAG represents a set of linear\nequations called Structural Equations Model (SEM), whose coefficients are\nparameters representing direct causal effects. Reliable quantitative\nconclusions can only be obtained from the model if the causal effects are\nuniquely determined by the data. That is, if there exists a unique\nparametrization for the model that makes it compatible with the data. If this\nis the case, the model is called identified. The main result of the paper is a\ngeneral sufficient condition for identification of recursive SEM models.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 15:39:51 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Brito", "Carlos", ""], ["Pearl", "Judea", ""]]}, {"id": "1206.6829", "submitter": "Changsung Kang", "authors": "Changsung Kang, Jin Tian", "title": "Inequality Constraints in Causal Models with Hidden Variables", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-233-240", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a class of inequality constraints on the set of distributions\ninduced by local interventions on variables governed by a causal Bayesian\nnetwork, in which some of the variables remain unmeasured. We derive bounds on\ncausal effects that are not directly measured in randomized experiments. We\nderive instrumental inequality type of constraints on nonexperimental\ndistributions. The results have applications in testing causal models with\nobservational or experimental data.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:15:29 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Kang", "Changsung", ""], ["Tian", "Jin", ""]]}, {"id": "1206.6830", "submitter": "Manfred Jaeger", "authors": "Manfred Jaeger", "title": "The AI&M Procedure for Learning from Incomplete Data", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-225-232", "categories": "stat.ME cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate methods for parameter learning from incomplete data that is\nnot missing at random. Likelihood-based methods then require the optimization\nof a profile likelihood that takes all possible missingness mechanisms into\naccount. Optimzing this profile likelihood poses two main difficulties:\nmultiple (local) maxima, and its very high-dimensional parameter space. In this\npaper a new method is presented for optimizing the profile likelihood that\naddresses the second difficulty: in the proposed AI&M (adjusting imputation and\nmazimization) procedure the optimization is performed by operations in the\nspace of data completions, rather than directly in the parameter space of the\nprofile likelihood. We apply the AI&M method to learning parameters for\nBayesian networks. The method is compared against conservative inference, which\ntakes into account each possible data completion, and against EM. The results\nindicate that likelihood-based inference is still feasible in the case of\nunknown missingness mechanisms, and that conservative inference is\nunnecessarily weak. On the other hand, our results also provide evidence that\nthe EM algorithm is still quite effective when the data is not missing at\nrandom.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:15:42 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Jaeger", "Manfred", ""]]}, {"id": "1206.6839", "submitter": "Michael Eichler", "authors": "Michael Eichler", "title": "Fitting Graphical Interaction Models to Multivariate Time Series", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-147-154", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical interaction models have become an important tool for analysing\nmultivariate time series. In these models, the interrelationships among the\ncomponents of a time series are described by undirected graphs in which the\nvertices depict the components while the edges indictate possible dependencies\nbetween the components. Current methods for the identification of the graphical\nstructure are based on nonparametric spectral stimation, which prevents\napplication of common model selection strategies. In this paper, we present a\nparametric approach for graphical interaction modelling of multivariate\nstationary time series. The proposed models generalize covariance selection\nmodels to the time series setting and are formulated in terms of inverse\ncovariances. We show that these models correspond to vector autoregressive\nmodels under conditional independence constraints encoded by undirected graphs.\nFurthermore, we discuss maximum likelihood estimation based on Whittle's\napproximation to the log-likelihood function and propose an iterative method\nfor solving the resulting likelihood equations. The concepts are illustrated by\nan example.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:19:31 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Eichler", "Michael", ""]]}, {"id": "1206.6840", "submitter": "Vanessa Didelez", "authors": "Vanessa Didelez, Philip Dawid, Sara Geneletti", "title": "Direct and Indirect Effects of Sequential Treatments", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": "In Proc. 22nd Annual Conference on Uncertainty in Artificial\n  Intelligence (2006), edited by R. Dechter and T. S. Richardson. AUAI Press,\n  Arlington, Virginia, 138-146", "doi": null, "report-no": "UAI-P-2006-PG-138-146", "categories": "stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we review the notion of direct causal effect as introduced by\nPearl (2001). We show how it can be formulated without counterfactuals, using\nintervention indicators instead. This allows to consider the natural direct\neffect as a special case of sequential treatments discussed by Dawid and\nDidelez (2005) which immediately yields conditions for identifiability as well\nas a graphical way of checking identifiability. The results are contrasted with\nthe criteria given by Pearl (2001) and Robins (2003).\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:19:46 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Didelez", "Vanessa", ""], ["Dawid", "Philip", ""], ["Geneletti", "Sara", ""]]}, {"id": "1206.6843", "submitter": "Joseph Ramsey", "authors": "Joseph Ramsey, Jiji Zhang, Peter L. Spirtes", "title": "Adjacency-Faithfulness and Conservative Causal Inference", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-401-408", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most causal inference algorithms in the literature (e.g., Pearl (2000),\nSpirtes et al. (2000), Heckerman et al. (1999)) exploit an assumption usually\nreferred to as the causal Faithfulness or Stability condition. In this paper,\nwe highlight two components of the condition used in constraint-based\nalgorithms, which we call \"Adjacency-Faithfulness\" and\n\"Orientation-Faithfulness\". We point out that assuming Adjacency-Faithfulness\nis true, it is in principle possible to test the validity of\nOrientation-Faithfulness. Based on this observation, we explore the consequence\nof making only the Adjacency-Faithfulness assumption. We show that the familiar\nPC algorithm has to be modified to be (asymptotically) correct under the\nweaker, Adjacency-Faithfulness assumption. Roughly the modified algorithm,\ncalled Conservative PC (CPC), checks whether Orientation-Faithfulness holds in\nthe orientation phase, and if not, avoids drawing certain causal conclusions\nthe PC algorithm would draw. However, if the stronger, standard causal\nFaithfulness condition actually obtains, the CPC algorithm is shown to output\nthe same pattern as the PC algorithm does in the large sample limit. We also\npresent a simulation study showing that the CPC algorithm runs almost as fast\nas the PC algorithm, and outputs significantly fewer false causal arrowheads\nthan the PC algorithm does on realistic sample sizes. We end our paper by\ndiscussing how score-based algorithms such as GES perform when the\nAdjacency-Faithfulness but not the standard causal Faithfulness condition\nholds, and how to extend our work to the FCI algorithm, which allows for the\npossibility of latent variables.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:21:05 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Ramsey", "Joseph", ""], ["Zhang", "Jiji", ""], ["Spirtes", "Peter L.", ""]]}, {"id": "1206.6845", "submitter": "Ian Porteous", "authors": "Ian Porteous, Alexander T. Ihler, Padhraic Smyth, Max Welling", "title": "Gibbs Sampling for (Coupled) Infinite Mixture Models in the Stick\n  Breaking Representation", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-385-392", "categories": "stat.ME cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonparametric Bayesian approaches to clustering, information retrieval,\nlanguage modeling and object recognition have recently shown great promise as a\nnew paradigm for unsupervised data analysis. Most contributions have focused on\nthe Dirichlet process mixture models or extensions thereof for which efficient\nGibbs samplers exist. In this paper we explore Gibbs samplers for infinite\ncomplexity mixture models in the stick breaking representation. The advantage\nof this representation is improved modeling flexibility. For instance, one can\ndesign the prior distribution over cluster sizes or couple multiple infinite\nmixture models (e.g. over time) at the level of their parameters (i.e. the\ndependent Dirichlet process model). However, Gibbs samplers for infinite\nmixture models (as recently introduced in the statistics literature) seem to\nmix poorly over cluster labels. Among others issues, this can have the adverse\neffect that labels for the same cluster in coupled mixture models are mixed up.\nWe introduce additional moves in these samplers to improve mixing over cluster\nlabels and to bring clusters into correspondence. An application to modeling of\nstorm trajectories is used to illustrate these ideas.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:21:35 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Porteous", "Ian", ""], ["Ihler", "Alexander T.", ""], ["Smyth", "Padhraic", ""], ["Welling", "Max", ""]]}, {"id": "1206.6848", "submitter": "Iain Murray", "authors": "Iain Murray, Zoubin Ghahramani, David MacKay", "title": "MCMC for doubly-intractable distributions", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-359-366", "categories": "stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Chain Monte Carlo (MCMC) algorithms are routinely used to draw samples\nfrom distributions with intractable normalization constants. However, standard\nMCMC algorithms do not apply to doubly-intractable distributions in which there\nare additional parameter-dependent normalization terms; for example, the\nposterior over parameters of an undirected graphical model. An ingenious\nauxiliary-variable scheme (Moeller et al., 2004) offers a solution: exact\nsampling (Propp and Wilson, 1996) is used to sample from a Metropolis-Hastings\nproposal for which the acceptance probability is tractable. Unfortunately the\nacceptance probability of these expensive updates can be low. This paper\nprovides a generalization of Moeller et al. (2004) and a new MCMC algorithm,\nwhich obtains better acceptance probabilities for the same amount of exact\nsampling, and removes the need to estimate model parameters before sampling\nbegins.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:23:56 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Murray", "Iain", ""], ["Ghahramani", "Zoubin", ""], ["MacKay", "David", ""]]}, {"id": "1206.6853", "submitter": "Subramani Mani", "authors": "Subramani Mani, Peter L. Spirtes, Gregory F. Cooper", "title": "A theoretical study of Y structures for causal discovery", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-314-323", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several existing algorithms that under appropriate assumptions can\nreliably identify a subset of the underlying causal relationships from\nobservational data. This paper introduces the first computationally feasible\nscore-based algorithm that can reliably identify causal relationships in the\nlarge sample limit for discrete models, while allowing for the possibility that\nthere are unobserved common causes. In doing so, the algorithm does not ever\nneed to assign scores to causal structures with unobserved common causes. The\nalgorithm is based on the identification of so called Y substructures within\nBayesian network structures that can be learned from observational data. An\nexample of a Y substructure is A -> C, B -> C, C -> D. After providing\nbackground on causal discovery, the paper proves the conditions under which the\nalgorithm is reliable in the large sample limit.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:25:15 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Mani", "Subramani", ""], ["Spirtes", "Peter L.", ""], ["Cooper", "Gregory F.", ""]]}, {"id": "1206.6861", "submitter": "Manabu Kuroki", "authors": "Manabu Kuroki, Zhihong Cai", "title": "Stratified Analysis of `Probabilities of Causation'", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-249-256", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes new formulas for the probabilities of causation difined\nby Pearl (2000). Tian and Pearl (2000a, 2000b) showed how to bound the\nquantities of the probabilities of causation from experimental and\nobservational data, under the minimal assumptions about the data-generating\nprocess. We derive narrower bounds than Tian-Pearl bounds by making use of the\ncovariate information measured in experimental and observational studies. In\naddition, we provide identifiable case under no-prevention assumption and\ndiscuss the covariate selection problem from the viewpoint of estimation\naccuracy. These results are helpful in providing more evidence for public\npolicy assessment and dicision making problems.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:27:37 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Kuroki", "Manabu", ""], ["Cai", "Zhihong", ""]]}, {"id": "1206.6874", "submitter": "Ricardo Silva", "authors": "Ricardo Silva, Zoubin Ghahramani", "title": "Bayesian Inference for Gaussian Mixed Graph Models", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-453-460", "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce priors and algorithms to perform Bayesian inference in Gaussian\nmodels defined by acyclic directed mixed graphs. Such a class of graphs,\ncomposed of directed and bi-directed edges, is a representation of conditional\nindependencies that is closed under marginalization and arises naturally from\ncausal models which allow for unmeasured confounding. Monte Carlo methods and a\nvariational approximation for such models are presented. Our algorithms for\nBayesian inference allow the evaluation of posterior distributions for several\nquantities of interest, including causal effects that are not identifiable from\ndata alone but could otherwise be inferred where informative prior knowledge\nabout confounding is available.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:30:29 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Silva", "Ricardo", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1206.6876", "submitter": "Ilya Shpitser", "authors": "Ilya Shpitser, Judea Pearl", "title": "Identification of Conditional Interventional Distributions", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-437-444", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subject of this paper is the elucidation of effects of actions from\ncausal assumptions represented as a directed graph, and statistical knowledge\ngiven as a probability distribution. In particular, we are interested in\npredicting conditional distributions resulting from performing an action on a\nset of variables and, subsequently, taking measurements of another set. We\nprovide a necessary and sufficient graphical condition for the cases where such\ndistributions can be uniquely computed from the available information, as well\nas an algorithm which performs this computation whenever the condition holds.\nFurthermore, we use our results to prove completeness of do-calculus [Pearl,\n1995] for the same identification problem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:30:55 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Shpitser", "Ilya", ""], ["Pearl", "Judea", ""]]}, {"id": "1206.6877", "submitter": "Prakash P. Shenoy", "authors": "Prakash P. Shenoy", "title": "Inference in Hybrid Bayesian Networks Using Mixtures of Gaussians", "comments": "Appears in Proceedings of the Twenty-Second Conference on Uncertainty\n  in Artificial Intelligence (UAI2006)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2006-PG-428-436", "categories": "cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this paper is to describe a method for exact inference in\ngeneral hybrid Bayesian networks (BNs) (with a mixture of discrete and\ncontinuous chance variables). Our method consists of approximating general\nhybrid Bayesian networks by a mixture of Gaussians (MoG) BNs. There exists a\nfast algorithm by Lauritzen-Jensen (LJ) for making exact inferences in MoG\nBayesian networks, and there exists a commercial implementation of this\nalgorithm. However, this algorithm can only be used for MoG BNs. Some\nlimitations of such networks are as follows. All continuous chance variables\nmust have conditional linear Gaussian distributions, and discrete chance nodes\ncannot have continuous parents. The methods described in this paper will enable\nus to use the LJ algorithm for a bigger class of hybrid Bayesian networks. This\nincludes networks with continuous chance nodes with non-Gaussian distributions,\nnetworks with no restrictions on the topology of discrete and continuous\nvariables, networks with conditionally deterministic variables that are a\nnonlinear function of their continuous parents, and networks with continuous\nchance variables whose variances are functions of their parents.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jun 2012 16:31:08 GMT"}], "update_date": "2012-07-02", "authors_parsed": [["Shenoy", "Prakash P.", ""]]}, {"id": "1206.6910", "submitter": "Anton Korobeynikov", "authors": "Nina Golyandina and Anton Korobeynikov", "title": "Basic Singular Spectrum Analysis and Forecasting with R", "comments": null, "journal-ref": "Computational Statistics and Data Analysis, Volume 71, March 2014,\n  Pages 934-954", "doi": "10.1016/j.csda.2013.04.009", "report-no": null, "categories": "stat.ME stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Singular Spectrum Analysis (SSA) as a tool for analysis and forecasting of\ntime series is considered. The main features of the Rssa package, which\nimplements the SSA algorithms and methodology in R, are described and examples\nof its use are presented. Analysis, forecasting and parameter estimation are\ndemonstrated by means of case study with an accompanying code in R.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2012 22:22:44 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2013 22:13:31 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Golyandina", "Nina", ""], ["Korobeynikov", "Anton", ""]]}, {"id": "1206.6927", "submitter": "Cheryl Brooks", "authors": "Cheryl J. Flynn, Patrick O. Perry", "title": "Profile Likelihood Biclustering", "comments": "40 pages, 11 figures; R package in development at\n  https://github.com/patperry/biclustpl", "journal-ref": "Electron. J. Statist., Volume 14, Number 1 (2020), 731-768", "doi": "10.1214/19-EJS1667", "report-no": null, "categories": "stat.ME math.ST stat.ML stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biclustering, the process of simultaneously clustering the rows and columns\nof a data matrix, is a popular and effective tool for finding structure in a\nhigh-dimensional dataset. Many biclustering procedures appear to work well in\npractice, but most do not have associated consistency guarantees. To address\nthis shortcoming, we propose a new biclustering procedure based on profile\nlikelihood. The procedure applies to a broad range of data modalities,\nincluding binary, count, and continuous observations. We prove that the\nprocedure recovers the true row and column classes when the dimensions of the\ndata matrix tend to infinity, even if the functional form of the data\ndistribution is misspecified. The procedure requires computing a combinatorial\nsearch, which can be expensive in practice. Rather than performing this search\ndirectly, we propose a new heuristic optimization procedure based on the\nKernighan-Lin heuristic, which has nice computational properties and performs\nwell in simulations. We demonstrate our procedure with applications to\ncongressional voting records, and microarray analysis.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 01:19:35 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2013 19:49:59 GMT"}, {"version": "v3", "created": "Fri, 8 Jan 2016 17:16:09 GMT"}, {"version": "v4", "created": "Tue, 2 Jun 2020 18:48:47 GMT"}], "update_date": "2020-06-04", "authors_parsed": [["Flynn", "Cheryl J.", ""], ["Perry", "Patrick O.", ""]]}, {"id": "1206.7051", "submitter": "David Blei", "authors": "Matt Hoffman, David M. Blei, Chong Wang, John Paisley", "title": "Stochastic Variational Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop stochastic variational inference, a scalable algorithm for\napproximating posterior distributions. We develop this technique for a large\nclass of probabilistic models and we demonstrate it with two probabilistic\ntopic models, latent Dirichlet allocation and the hierarchical Dirichlet\nprocess topic model. Using stochastic variational inference, we analyze several\nlarge collections of documents: 300K articles from Nature, 1.8M articles from\nThe New York Times, and 3.8M articles from Wikipedia. Stochastic inference can\neasily handle data sets of this size and outperforms traditional variational\ninference, which can only handle a smaller subset. (We also show that the\nBayesian nonparametric topic model outperforms its parametric counterpart.)\nStochastic variational inference lets us apply complex Bayesian models to\nmassive data sets.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2012 15:23:11 GMT"}, {"version": "v2", "created": "Thu, 18 Apr 2013 15:40:02 GMT"}, {"version": "v3", "created": "Mon, 22 Apr 2013 20:23:40 GMT"}], "update_date": "2013-04-24", "authors_parsed": [["Hoffman", "Matt", ""], ["Blei", "David M.", ""], ["Wang", "Chong", ""], ["Paisley", "John", ""]]}]