[{"id": "1906.00553", "submitter": "Martin Obschonka", "authors": "Martin Obschonka, David B. Audretsch", "title": "Artificial Intelligence and Big Data in Entrepreneurship: A New Era Has\n  Begun", "comments": null, "journal-ref": null, "doi": "10.1007/s11187-019-00202-4", "report-no": null, "categories": "econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While the disruptive potential of artificial intelligence (AI) and Big Data\nhas been receiving growing attention and concern in a variety of research and\napplication fields over the last few years, it has not received much scrutiny\nin contemporary entrepreneurship research so far. Here we present some\nreflections and a collection of papers on the role of AI and Big Data for this\nemerging area in the study and application of entrepreneurship research. While\nbeing mindful of the potentially overwhelming nature of the rapid progress in\nmachine intelligence and other Big Data technologies for contemporary\nstructures in entrepreneurship research, we put an emphasis on the reciprocity\nof the co-evolving fields of entrepreneurship research and practice. How can AI\nand Big Data contribute to a productive transformation of the research field\nand the real-world phenomena (e.g., 'smart entrepreneurship')? We also discuss,\nhowever, ethical issues as well as challenges around a potential contradiction\nbetween entrepreneurial uncertainty and rule-driven AI rationality. The\neditorial gives researchers and practitioners orientation and showcases avenues\nand examples for concrete research in this field. At the same time, however, it\nis not unlikely that we will encounter unforeseeable and currently inexplicable\ndevelopments in the field soon. We call on entrepreneurship scholars,\neducators, and practitioners to proactively prepare for future scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 03:52:47 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Obschonka", "Martin", ""], ["Audretsch", "David B.", ""]]}, {"id": "1906.00946", "submitter": "Alex Garivaltis", "authors": "Alex Garivaltis", "title": "The Laws of Motion of the Broker Call Rate in the United States", "comments": "40 pages, 15 figures, 4 tables", "journal-ref": "International Journal of Financial Studies, 7(4), 56 (2019)", "doi": "10.3390/ijfs7040056", "report-no": null, "categories": "econ.EM econ.GN q-fin.EC q-fin.GN q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, which is the third installment of the author's trilogy on\nmargin loan pricing, we analyze $1,367$ monthly observations of the U.S. broker\ncall money rate, which is the interest rate at which stock brokers can borrow\nto fund their margin loans to retail clients. We describe the basic features\nand mean-reverting behavior of this series and juxtapose the\nempirically-derived laws of motion with the author's prior theories of margin\nloan pricing (Garivaltis 2019a-b). This allows us to derive stochastic\ndifferential equations that govern the evolution of the margin loan interest\nrate and the leverage ratios of sophisticated brokerage clients (namely,\ncontinuous time Kelly gamblers). Finally, we apply Merton's (1974) arbitrage\ntheory of corporate liability pricing to study theoretical constraints on the\nrisk premia that could be generated in the market for call money. Apparently,\nif there is no arbitrage in the U.S. financial markets, the implication is that\nthe total volume of call loans must constitute north of $70\\%$ of the value of\nall leveraged portfolios.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 17:57:21 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Garivaltis", "Alex", ""]]}, {"id": "1906.01025", "submitter": "Alex Garivaltis", "authors": "Alex Garivaltis", "title": "Two Resolutions of the Margin Loan Pricing Puzzle", "comments": "23 pages, 5 figures", "journal-ref": "Research in Economics (73)2, pp.199-207 (2019)", "doi": null, "report-no": null, "categories": "econ.GN econ.TH q-fin.EC q-fin.GN q-fin.PM q-fin.RM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper supplies two possible resolutions of Fortune's (2000) margin-loan\npricing puzzle. Fortune (2000) noted that the margin loan interest rates\ncharged by stock brokers are very high in relation to the actual (low) credit\nrisk and the cost of funds. If we live in the Black-Scholes world, the brokers\nare presumably making arbitrage profits by shorting dynamically precise amounts\nof their clients' portfolios. First, we extend Fortune's (2000) application of\nMerton's (1974) no-arbitrage approach to allow for brokers that can only revise\ntheir hedges finitely many times during the term of the loan. We show that\nextremely small differences in the revision frequency can easily explain the\nobserved variation in margin loan pricing. In fact, four additional revisions\nper three-day period serve to explain all of the currently observed\nheterogeneity. Second, we study monopolistic (or oligopolistic) margin loan\npricing by brokers whose clients are continuous-time Kelly gamblers. The broker\nsolves a general stochastic control problem that yields simple and pleasant\nformulas for the optimal interest rate and the net interest margin. If the\nauthor owned a brokerage, he would charge an interest rate of\n$(r+\\nu)/2-\\sigma^2/4$, where $r$ is the cost of funds, $\\nu$ is the\ncompound-annual growth rate of the S&P 500 index, and $\\sigma$ is the\nvolatility.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 18:57:56 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Garivaltis", "Alex", ""]]}, {"id": "1906.02216", "submitter": "Alex Garivaltis", "authors": "Alex Garivaltis", "title": "Game-Theoretic Optimal Portfolios in Continuous Time", "comments": "14 pages, 1 figure", "journal-ref": "Economic Theory Bulletin, pp.1-9 (2018)", "doi": null, "report-no": null, "categories": "q-fin.PM econ.GN econ.TH q-fin.EC q-fin.GN q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a two-person trading game in continuous time whereby each player\nchooses a constant rebalancing rule $b$ that he must adhere to over $[0,t]$. If\n$V_t(b)$ denotes the final wealth of the rebalancing rule $b$, then Player 1\n(the `numerator player') picks $b$ so as to maximize\n$\\mathbb{E}[V_t(b)/V_t(c)]$, while Player 2 (the `denominator player') picks\n$c$ so as to minimize it. In the unique Nash equilibrium, both players use the\ncontinuous-time Kelly rule $b^*=c^*=\\Sigma^{-1}(\\mu-r\\textbf{1})$, where\n$\\Sigma$ is the covariance of instantaneous returns per unit time, $\\mu$ is the\ndrift vector of the stock market, and $\\textbf{1}$ is a vector of ones. Thus,\neven over very short intervals of time $[0,t]$, the desire to perform well\nrelative to other traders leads one to adopt the Kelly rule, which is\nordinarily derived by maximizing the asymptotic exponential growth rate of\nwealth. Hence, we find agreement with Bell and Cover's (1988) result in\ndiscrete time.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 18:01:31 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Garivaltis", "Alex", ""]]}, {"id": "1906.02223", "submitter": "Olivier Walther", "authors": "Olivier Walther and Denis Retaille", "title": "Mapping the Sahelian Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter examines the geographical meaning of the Sahel, its fluid\nboundaries, and its spatial dynamics. Unlike other approaches that define the\nSahel as a bioclimatic zone or as an ungoverned area, it shows that the Sahel\nis primarily a space of circulation in which uncertainty has historically been\novercome by mobility. The first part of the paper discusses how pre-colonial\nempires relied on a network of markets and cities that facilitated trade and\nsocial relationships across the region and beyond. The second part explores\nchanging regional mobility patterns precipitated by colonial powers and the new\napproach they developed to control networks and flows. The third part discusses\nthe contradiction between the mobile strategies adopted by local herders,\nfarmers and traders in the Sahel and the territorial development initiatives of\nmodern states and international donors. Particular attention is paid in the\nlast section to how the Sahel was progressively redefined through a security\nlens.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 18:05:59 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Walther", "Olivier", ""], ["Retaille", "Denis", ""]]}, {"id": "1906.02486", "submitter": "Georgios Piliouras", "authors": "Thiparat Chotibut, Fryderyk Falniowski, Micha{\\l} Misiurewicz,\n  Georgios Piliouras", "title": "The route to chaos in routing games: When is Price of Anarchy too\n  optimistic?", "comments": "51 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT econ.GN math.DS nlin.CD physics.soc-ph q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing games are amongst the most studied classes of games. Their two most\nwell-known properties are that learning dynamics converge to equilibria and\nthat all equilibria are approximately optimal. In this work, we perform a\nstress test for these classic results by studying the ubiquitous dynamics,\nMultiplicative Weights Update, in different classes of congestion games,\nuncovering intricate non-equilibrium phenomena. As the system demand increases,\nthe learning dynamics go through period-doubling bifurcations, leading to\ninstabilities, chaos and large inefficiencies even in the simplest case of\nnon-atomic routing games with two paths of linear cost where the Price of\nAnarchy is equal to one.\n  Starting with this simple class, we show that every system has a carrying\ncapacity, above which it becomes unstable. If the equilibrium flow is a\nsymmetric $50-50\\%$ split, the system exhibits one period-doubling bifurcation.\nA single periodic attractor of period two replaces the attracting fixed point.\nAlthough the Price of Anarchy is equal to one, in the large population limit\nthe time-average social cost for all but a zero measure set of initial\nconditions converges to its worst possible value. For asymmetric equilibrium\nflows, increasing the demand eventually forces the system into Li-Yorke chaos\nwith positive topological entropy and periodic orbits of all possible periods.\nRemarkably, in all non-equilibrating regimes, the time-average flows on the\npaths converge exactly to the equilibrium flows, a property akin to no-regret\nlearning in zero-sum games. These results are robust. We extend them to routing\ngames with arbitrarily many strategies, polynomial cost functions, non-atomic\nas well as atomic routing games and heteregenous users. Our results are also\napplicable to any sequence of shrinking learning rates, e.g., $1/\\sqrt{T}$, by\nallowing for a dynamically increasing population size.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jun 2019 09:07:20 GMT"}, {"version": "v2", "created": "Sun, 24 Nov 2019 17:10:08 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Chotibut", "Thiparat", ""], ["Falniowski", "Fryderyk", ""], ["Misiurewicz", "Micha\u0142", ""], ["Piliouras", "Georgios", ""]]}, {"id": "1906.02904", "submitter": "Yanfang Mo", "authors": "Yanfang Mo, Wei Chen, Li Qiu, Pravin Varaiya", "title": "Market Implementation of Multiple-Arrival Multiple-Deadline\n  Differentiated Energy Services", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.automatica.2020.108933", "report-no": null, "categories": "cs.SY econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An increasing concern in power systems is how to elicit flexibilities in\ndemand, which leads to nontraditional electricity products for accommodating\nloads of different flexibility levels. We have proposed Multiple-Arrival\nMultiple-Deadline (MAMD) differentiated energy services for the flexible loads\nwhich require constant power for specified durations. Such loads are\nindifferent to the actual power delivery time as long as the duration\nrequirements are satisfied between the specified arrival times and deadlines.\nThe focus of this paper is the market implementation of such services. In a\nforward market, we establish the existence of an efficient competitive\nequilibrium to verify the economic feasibility, which implies that selfish\nmarket participants can attain the maximum social welfare in a distributed\nmanner. We also show the strengths of the MAMD services by simulation.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 05:39:02 GMT"}, {"version": "v2", "created": "Thu, 12 Mar 2020 14:02:33 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Mo", "Yanfang", ""], ["Chen", "Wei", ""], ["Qiu", "Li", ""], ["Varaiya", "Pravin", ""]]}, {"id": "1906.03044", "submitter": "Hannes Ullrich", "authors": "Michael Allan Ribers and Hannes Ullrich", "title": "Battling Antibiotic Resistance: Can Machine Learning Improve\n  Prescribing?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY cs.LG q-fin.EC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Antibiotic resistance constitutes a major health threat. Predicting bacterial\ncauses of infections is key to reducing antibiotic misuse, a leading driver of\nantibiotic resistance. We train a machine learning algorithm on administrative\nand microbiological laboratory data from Denmark to predict diagnostic test\noutcomes for urinary tract infections. Based on predictions, we develop\npolicies to improve prescribing in primary care, highlighting the relevance of\nphysician expertise and policy implementation when patient distributions vary\nover time. The proposed policies delay antibiotic prescriptions for some\npatients until test results are known and give them instantly to others. We\nfind that machine learning can reduce antibiotic use by 7.42 percent without\nreducing the number of treated bacterial infections. As Denmark is one of the\nmost conservative countries in terms of antibiotic use, this result is likely\nto be a lower bound of what can be achieved elsewhere.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jun 2019 14:38:13 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Ribers", "Michael Allan", ""], ["Ullrich", "Hannes", ""]]}, {"id": "1906.04086", "submitter": "Rita Maria del Rio-Chanona", "authors": "R. Maria del Rio-Chanona, Penny Mealy, Mariano Beguerisse-D\\'iaz,\n  Francois Lafond and J. Doyne Farmer", "title": "Automation and occupational mobility: A data-driven network model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN physics.soc-ph q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The potential impact of automation on the labor market is a topic that has\ngenerated significant interest and concern amongst scholars, policymakers, and\nthe broader public. A number of studies have estimated occupation-specific risk\nprofiles by examining the automatability of associated skills and tasks.\nHowever, relatively little work has sought to take a more holistic view on the\nprocess of labor reallocation and how employment prospects are impacted as\ndisplaced workers transition into new jobs. In this paper, we develop a new\ndata-driven model to analyze how workers move through an empirically derived\noccupational mobility network in response to automation scenarios which\nincrease labor demand for some occupations and decrease it for others. At the\nmacro level, our model reproduces a key stylized fact in the labor market known\nas the Beveridge curve and provides new insights for explaining the curve's\ncounter-clockwise cyclicality. At the micro level, our model provides\noccupation-specific estimates of changes in short and long-term unemployment\ncorresponding to a given automation shock. We find that the network structure\nplays an important role in determining unemployment levels, with occupations in\nparticular areas of the network having very few job transition opportunities.\nSuch insights could be fruitfully applied to help design more efficient and\neffective policies aimed at helping workers adapt to the changing nature of the\nlabor market.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 15:59:27 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 10:00:13 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2020 09:29:06 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["del Rio-Chanona", "R. Maria", ""], ["Mealy", "Penny", ""], ["Beguerisse-D\u00edaz", "Mariano", ""], ["Lafond", "Francois", ""], ["Farmer", "J. Doyne", ""]]}, {"id": "1906.04522", "submitter": "Donovan Platt", "authors": "Donovan Platt", "title": "Bayesian Estimation of Economic Simulation Models using Neural Networks", "comments": "26 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN q-fin.CP q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in computing power and the potential to make more realistic\nassumptions due to increased flexibility have led to the increased prevalence\nof simulation models in economics. While models of this class, and particularly\nagent-based models, are able to replicate a number of empirically-observed\nstylised facts not easily recovered by more traditional alternatives, such\nmodels remain notoriously difficult to estimate due to their lack of tractable\nlikelihood functions. While the estimation literature continues to grow,\nexisting attempts have approached the problem primarily from a frequentist\nperspective, with the Bayesian estimation literature remaining comparatively\nless developed. For this reason, we introduce a Bayesian estimation protocol\nthat makes use of deep neural networks to construct an approximation to the\nlikelihood, which we then benchmark against a prominent alternative from the\nexisting literature. Overall, we find that our proposed methodology\nconsistently results in more accurate estimates in a variety of settings,\nincluding the estimation of financial heterogeneous agent models and the\nidentification of changes in dynamics occurring in models incorporating\nstructural breaks.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 12:17:34 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Platt", "Donovan", ""]]}, {"id": "1906.04652", "submitter": "Oliver Hulme", "authors": "David Meder, Finn Rabe, Tobias Morville, Kristoffer H. Madsen, Magnus\n  T. Koudahl, Ray J. Dolan, Hartwig R. Siebner, Oliver J. Hulme", "title": "Ergodicity-breaking reveals time optimal decision making in humans", "comments": "43 pages including supplementary methods & materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ergodicity describes an equivalence between the expectation value and the\ntime average of observables. Applied to human behaviour, ergodic theories of\ndecision-making reveal how individuals should tolerate risk in different\nenvironments. To optimise wealth over time, agents should adapt their utility\nfunction according to the dynamical setting they face. Linear utility is\noptimal for additive dynamics, whereas logarithmic utility is optimal for\nmultiplicative dynamics. Whether humans approximate time optimal behavior\nacross different dynamics is unknown. Here we compare the effects of additive\nversus multiplicative gamble dynamics on risky choice. We show that utility\nfunctions are modulated by gamble dynamics in ways not explained by prevailing\ndecision theory. Instead, as predicted by time optimality, risk aversion\nincreases under multiplicative dynamics, distributing close to the values that\nmaximise the time average growth of wealth. We suggest that our findings\nmotivate a need for explicitly grounding theories of decision-making on ergodic\nconsiderations.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 15:26:02 GMT"}, {"version": "v2", "created": "Wed, 12 Jun 2019 09:40:43 GMT"}, {"version": "v3", "created": "Wed, 19 Jun 2019 15:17:20 GMT"}, {"version": "v4", "created": "Fri, 25 Sep 2020 10:12:43 GMT"}, {"version": "v5", "created": "Tue, 15 Dec 2020 09:18:35 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Meder", "David", ""], ["Rabe", "Finn", ""], ["Morville", "Tobias", ""], ["Madsen", "Kristoffer H.", ""], ["Koudahl", "Magnus T.", ""], ["Dolan", "Ray J.", ""], ["Siebner", "Hartwig R.", ""], ["Hulme", "Oliver J.", ""]]}, {"id": "1906.04711", "submitter": "Matias Barenstein", "authors": "Matias Barenstein", "title": "ProPublica's COMPAS Data Revisited", "comments": "28 pages, 13 figures (v3); fixed figure and footnote formatting;\n  edited writing, organization, references, and appendix, results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.CY cs.LG q-fin.EC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I examine the COMPAS recidivism risk score and criminal history data\ncollected by ProPublica in 2016 that fueled intense debate and research in the\nnascent field of 'algorithmic fairness'. ProPublica's COMPAS data is used in an\nincreasing number of studies to test various definitions of algorithmic\nfairness. This paper takes a closer look at the actual datasets put together by\nProPublica. In particular, the sub-datasets built to study the likelihood of\nrecidivism within two years of a defendant's original COMPAS survey screening\ndate. I take a new yet simple approach to visualize these data, by analyzing\nthe distribution of defendants across COMPAS screening dates. I find that\nProPublica made an important data processing error when it created these\ndatasets, failing to implement a two-year sample cutoff rule for recidivists in\nsuch datasets (whereas it implemented a two-year sample cutoff rule for\nnon-recidivists). When I implement a simple two-year COMPAS screen date cutoff\nrule for recidivists, I estimate that in the two-year general recidivism\ndataset ProPublica kept over 40% more recidivists than it should have. This\nfundamental problem in dataset construction affects some statistics more than\nothers. It obviously has a substantial impact on the recidivism rate;\nartificially inflating it. For the two-year general recidivism dataset created\nby ProPublica, the two-year recidivism rate is 45.1%, whereas, with the simple\nCOMPAS screen date cutoff correction I implement, it is 36.2%. Thus, the\ntwo-year recidivism rate in ProPublica's dataset is inflated by over 24%. This\nalso affects the positive and negative predictive values. On the other hand,\nthis data processing error has little impact on some of the other key\nstatistical measures, which are less susceptible to changes in the relative\nshare of recidivists, such as the false positive and false negative rates, and\nthe overall accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jun 2019 17:27:25 GMT"}, {"version": "v2", "created": "Thu, 13 Jun 2019 17:50:08 GMT"}, {"version": "v3", "created": "Mon, 8 Jul 2019 19:11:38 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Barenstein", "Matias", ""]]}, {"id": "1906.05269", "submitter": "Seyyedmilad Talebzadehhosseini", "authors": "Seyyedmilad Talebzadehhosseini, Steven R. Scheinert, and Ivan Garibay", "title": "Growing green: the role of path dependency and structural jumps in the\n  green economy expansion", "comments": "31 Pages, 2 figures, working paper and will be submitted to a journal\n  for peer review soon", "journal-ref": "https://www.ipsonet.org/publications/open-access/policy-and-complex-systems/policy-and-complex-systems-volume-6-number-1-spring-2020", "doi": "10.18278/jpcs.6.1.2", "report-no": null, "categories": "econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing research argues that countries increase their production basket by\nadding products which require similar capabilities to those they already\nproduce, a process referred to as path dependency. Green economic growth is a\nglobal movement that seeks to achieve economic expansion while at the same time\nmitigating environmental risks. We postulate that countries engaging in green\neconomic growth are motivated to invest strategically to develop new\ncapabilities that will help them transition to a green economy. As a result,\nthey could potentially increase their production baskets not only by a path\ndependent process but also by the non path dependent process we term, high\ninvestment structural jumps. The main objective of this research is to\ndetermine whether countries increase their green production basket mainly by a\nprocess of path dependency, or alternatively, by a process of structural jumps.\nWe analyze data from 65 countries and over a period from years 2007 to 2017. We\nfocus on China as our main case study. The results of this research show that\ncountries not only increase their green production baskets based on their\navailable capabilities, following path dependency, but also expand to products\nthat path dependency does not predict by investing in innovating and developing\nnew environmental related technologies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 17:50:29 GMT"}, {"version": "v2", "created": "Sat, 25 Apr 2020 21:42:31 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Talebzadehhosseini", "Seyyedmilad", ""], ["Scheinert", "Steven R.", ""], ["Garibay", "Ivan", ""]]}, {"id": "1906.06711", "submitter": "Nikolay Kudrin", "authors": "Graham Elliott, Nikolay Kudrin, Kaspar Wuthrich", "title": "Detecting p-hacking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We theoretically analyze the problem of testing for $p$-hacking based on\ndistributions of $p$-values across multiple studies. We provide general results\nfor when such distributions have testable restrictions (are non-increasing)\nunder the null of no $p$-hacking. We find novel additional testable\nrestrictions for $p$-values based on $t$-tests. Specifically, the shape of the\npower functions results in both complete monotonicity as well as bounds on the\ndistribution of $p$-values. These testable restrictions result in more powerful\ntests for the null hypothesis of no $p$-hacking. When there is also publication\nbias, our tests are joint tests for $p$-hacking and publication bias. A\nreanalysis of two prominent datasets shows the usefulness of our new tests.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jun 2019 14:44:26 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 21:58:55 GMT"}, {"version": "v3", "created": "Fri, 12 Jun 2020 01:19:03 GMT"}, {"version": "v4", "created": "Thu, 26 Nov 2020 06:29:14 GMT"}, {"version": "v5", "created": "Tue, 25 May 2021 05:06:12 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Elliott", "Graham", ""], ["Kudrin", "Nikolay", ""], ["Wuthrich", "Kaspar", ""]]}, {"id": "1906.07491", "submitter": "Marcin W\\k{a}torek", "authors": "Robert G\\k{e}barowski, Pawe{\\l} O\\'swi\\k{e}cimka, Marcin W\\k{a}torek,\n  Stanis{\\l}aw Dro\\.zd\\.z", "title": "Detecting correlations and triangular arbitrage opportunities in the\n  Forex by means of multifractal detrended cross-correlations analysis", "comments": "accepted in Nonlinear Dynamics", "journal-ref": "Nonlinear Dynamics 98, 2349-2364 (2019)", "doi": "10.1007/s11071-019-05335-5", "report-no": null, "categories": "q-fin.ST cs.CE econ.GN physics.data-an q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multifractal detrended cross-correlation methodology is described and applied\nto Foreign exchange (Forex) market time series. Fluctuations of high frequency\nexchange rates of eight major world currencies over 2010-2018 period are used\nto study cross-correlations. The study is motivated by fundamental questions in\ncomplex systems' response to significant environmental changes and by potential\napplications in investment strategies, including detecting triangular arbitrage\nopportunities. Dominant multiscale cross-correlations between the exchange\nrates are found to typically occur at smaller fluctuation levels. However\nhierarchical organization of ties expressed in terms of dendrograms, with a\nnovel application of the multiscale cross-correlation coefficient, are more\npronounced at large fluctuations. The cross-correlations are quantified to be\nstronger on average between those exchange rate pairs that are bound within\ntriangular relations. Some pairs from outside triangular relations are however\nidentified to be exceptionally strongly correlated as compared to the average\nstrength of triangular correlations.This in particular applies to those\nexchange rates that involve Australian and New Zealand dollars and reflects\ntheir economic relations. Significant events with impact on the Forex are shown\nto induce triangular arbitrage opportunities which at the same time reduce\ncross--correlations on the smallest time scales and act destructively on the\nmultiscale organization of correlations. In 2010--2018 such instances took\nplace in connection with the Swiss National Bank intervention and the weakening\nof British pound sterling accompanying the initiation of Brexit procedure. The\nmethodology could be applicable to temporal and multiscale pattern detection in\nany time series.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 10:56:40 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 11:59:49 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["G\u0119barowski", "Robert", ""], ["O\u015bwi\u0119cimka", "Pawe\u0142", ""], ["W\u0105torek", "Marcin", ""], ["Dro\u017cd\u017c", "Stanis\u0142aw", ""]]}, {"id": "1906.08244", "submitter": "Abdul Rahman Shaikh", "authors": "Abdul Rahman Shaikh and Hamed Alhoori", "title": "Predicting Patent Citations to measure Economic Impact of Scholarly\n  Research", "comments": "2 Pages, 1 figure, JCDL conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.LG econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A crucial goal of funding research and development has always been to advance\neconomic development. On this basis, a consider-able body of research\nundertaken with the purpose of determining what exactly constitutes economic\nimpact and how to accurately measure that impact has been published. Numerous\nindicators have been used to measure economic impact, although no single\nindicator has been widely adapted. Based on patent data collected from\nAltmetric we predict patent citations through various social media features\nusing several classification models. Patents citing a research paper implies\nthe potential it has for direct application inits field. These predictions can\nbe utilized by researchers in deter-mining the practical applications for their\nwork when applying for patents.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jun 2019 18:25:32 GMT"}], "update_date": "2019-06-20", "authors_parsed": [["Shaikh", "Abdul Rahman", ""], ["Alhoori", "Hamed", ""]]}, {"id": "1906.08617", "submitter": "Milan Van Den Heuvel", "authors": "Marnix Van Soom, Milan van den Heuvel, Jan Ryckebusch, Koen Schoors", "title": "Loan maturity aggregation in interbank lending networks obscures\n  mesoscale structure and economic functions", "comments": null, "journal-ref": "Sci Rep, vol. 9, Aug. 2019", "doi": "10.1038/s41598-019-48924-5", "report-no": null, "categories": "q-fin.GN econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the 2007-2009 financial crisis, substantial academic effort has been\ndedicated to improving our understanding of interbank lending networks (ILNs).\nBecause of data limitations or by choice, the literature largely lacks multiple\nloan maturities. We employ a complete interbank loan contract dataset to\ninvestigate whether maturity details are informative of the network structure.\nApplying the layered stochastic block model of Peixoto (2015) and other tools\nfrom network science on a time series of bilateral loans with multiple maturity\nlayers in the Russian ILN, we find that collapsing all such layers consistently\nobscures mesoscale structure. The optimal maturity granularity lies between\ncompletely collapsing and completely separating the maturity layers and depends\non the development phase of the interbank market, with a more developed market\nrequiring more layers for optimal description. Closer inspection of the\ninferred maturity bins associated with the optimal maturity granularity reveals\nspecific economic functions, from liquidity intermediation to financing.\nCollapsing a network with multiple underlying maturity layers or extracting one\nsuch layer, common in economic research, is therefore not only an incomplete\nrepresentation of the ILN's mesoscale structure, but also conceals existing\neconomic functions. This holds important insights and opportunities for\ntheoretical and empirical studies on interbank market functioning, contagion,\nstability, and on the desirable level of regulatory data disclosure.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 14:22:35 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Van Soom", "Marnix", ""], ["Heuvel", "Milan van den", ""], ["Ryckebusch", "Jan", ""], ["Schoors", "Koen", ""]]}, {"id": "1906.08667", "submitter": "Johannes Wachs", "authors": "Johannes Wachs, J\\'anos Kert\\'esz", "title": "A network approach to cartel detection in public auction markets", "comments": null, "journal-ref": "Scientific Reports, 2019", "doi": "10.1038/s41598-019-47198-1", "report-no": null, "categories": "physics.soc-ph cs.SI econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Competing firms can increase profits by setting prices collectively, imposing\nsignificant costs on consumers. Such groups of firms are known as cartels and\nbecause this behavior is illegal, their operations are secretive and difficult\nto detect. Cartels feel a significant internal obstacle: members feel short-run\nincentives to cheat. Here we present a network-based framework to detect\npotential cartels in bidding markets based on the idea that the chance a group\nof firms can overcome this obstacle and sustain cooperation depends on the\npatterns of its interactions. We create a network of firms based on their\nco-bidding behavior, detect interacting groups, and measure their cohesion and\nexclusivity, two group-level features of their collective behavior. Applied to\na market for school milk, our method detects a known cartel and calculates that\nit has high cohesion and exclusivity. In a comprehensive set of nearly 150,000\npublic contracts awarded by the Republic of Georgia from 2011 to 2016, detected\ngroups with high cohesion and exclusivity are significantly more likely to\ndisplay traditional markers of cartel behavior. We replicate this relationship\nbetween group topology and the emergence of cooperation in a simulation model.\nOur method presents a scalable, unsupervised method to find groups of firms in\nbidding markets ideally positioned to form lasting cartels.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jun 2019 14:44:46 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Wachs", "Johannes", ""], ["Kert\u00e9sz", "J\u00e1nos", ""]]}, {"id": "1906.08872", "submitter": "Brendan Hoover", "authors": "Brendan Hoover, Richard S. Middleton, and Sean Yaw", "title": "CostMAP: An open-source software package for developing cost surfaces", "comments": "Pre-print, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cost Surfaces are a quantitative means of assigning social, environmental,\nand engineering costs that impact movement across landscapes. Cost surfaces are\na crucial aspect of route optimization and least cost path (LCP) calculations\nand are used in a wide range of disciplines including computer science,\nlandscape ecology, and energy infrastructure modeling. Linear features present\na key weakness to traditional routing calculations along costs surfaces because\nthey cannot identify whether moving from a cell to its adjacent neighbors\nconstitutes crossing a linear barrier (increased cost) or following a corridor\n(reduced cost). Following and avoiding linear features can drastically change\npredicted routes. In this paper, we introduce an approach to address this\n\"adjacency\" issue using a search kernel that identifies these critical barriers\nand corridors. We have built this approach into a new Java-based open-source\nsoftware package called CostMAP (cost surface multi-layer aggregation program),\nwhich calculates cost surfaces and cost networks using the search kernel.\nCostMAP not only includes the new adjacency capability, it is also a versatile\nmulti-platform package that allows users to input multiple GIS data layers and\nto set weights and rules for developing a weighted-cost network. We compare\nCostMAP performance with traditional cost surface approaches and show\nsignificant performance gains, both following corridors and avoiding barriers,\nusing examples in a movement ecology framework and pipeline routing for carbon\ncapture, and storage (CCS). We also demonstrate that the new software can\nstraightforwardly calculate cost surfaces on a national scale.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 20:30:13 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Hoover", "Brendan", ""], ["Middleton", "Richard S.", ""], ["Yaw", "Sean", ""]]}, {"id": "1906.09698", "submitter": "Yuan Yuan", "authors": "Yuan Yuan, Tracy Liu, Chenhao Tan, Qian Chen, Alex Pentland, Jie Tang", "title": "Gift Contagion in Online Groups: Evidence From WeChat Red Packets", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN cs.HC cs.SI q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gifts are important instruments for forming bonds in interpersonal\nrelationships. Our study analyzes the phenomenon of gift contagion in online\ngroups. Gift contagion encourages social bonds of prompting further gifts; it\nmay also promote group interaction and solidarity. Using data on 36 million\nonline red packet gifts on China's social site WeChat, we leverage a natural\nexperimental design to identify the social contagion of gift giving in online\ngroups. Our natural experiment is enabled by the randomization of the gift\namount allocation algorithm on WeChat, which addresses the common challenge of\ncausal identifications in observational data. Our study provides evidence of\ngift contagion: on average, receiving one additional dollar causes a recipient\nto send 18 cents back to the group within the subsequent 24 hours. Decomposing\nthis effect, we find that it is mainly driven by the extensive margin -- more\nrecipients are triggered to send red packets. Moreover, we find that this\neffect is stronger for \"luckiest draw\" recipients, suggesting the presence of a\ngroup norm regarding the next red packet sender. Finally, we investigate the\nmoderating effects of group- and individual-level social network\ncharacteristics on gift contagion as well as the causal impact of receiving\ngifts on group network structure. Our study has implications for promoting\ngroup dynamics and designing marketing strategies for product adoption.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 03:08:13 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 09:59:25 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 23:34:41 GMT"}, {"version": "v4", "created": "Mon, 5 Apr 2021 09:09:23 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Yuan", "Yuan", ""], ["Liu", "Tracy", ""], ["Tan", "Chenhao", ""], ["Chen", "Qian", ""], ["Pentland", "Alex", ""], ["Tang", "Jie", ""]]}, {"id": "1906.10030", "submitter": "Yan Yang", "authors": "Yan Yang", "title": "A New Solution to Market Definition: An Approach Based on\n  Multi-dimensional Substitutability Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Market definition is an important component in the premerger investigation,\nbut the models used in the market definition have not developed much in the\npast three decades since the Critical Loss Analysis (CLA) was proposed in 1989.\nThe CLA helps the Hypothetical Monopolist Test to determine whether the\nhypothetical monopolist is going to profit from the small but significant and\nnon-transitory increase in price (SSNIP). However, the CLA has long been\ncriticized by academic scholars for its tendency to conclude a narrow market.\nAlthough the CLA was adopted by the 2010 Horizontal Merger Guidelines (the 2010\nGuidelines), the criticisms are likely still valid. In this dissertation, we\ndiscussed the mathematical deduction of CLA, the data used, and the SSNIP\ndefined by the Agencies. Based on our research, we concluded that the narrow\nmarket conclusion was due to the incorrect implementation of the CLA; not the\nmodel itself. On the other hand, there are other unresolvable problems in the\nCLA and the Hypothetical Monopolist Test. The SSNIP test and the CLA are bright\nresolutions for market definition problem during their time, but we have more\nadvanced tools to solve the task nowadays. In this dissertation, we propose a\nmodel which is based directly on the multi-dimensional substitutability between\nthe products and is capable of maximizing the substitutability of product\nfeatures within each group. Since the 2010 Guidelines does not exclude the use\nof models other than the ones mentioned by the Guidelines, our method can\nhopefully supplement the current models to show a better picture of the\nsubstitutive relations and provide a more stable definition of the market.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 15:42:33 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Yang", "Yan", ""]]}, {"id": "1906.10084", "submitter": "Alex Garivaltis", "authors": "Alex Garivaltis", "title": "Long Run Feedback in the Broker Call Money Market", "comments": "35 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN econ.TH q-fin.CP q-fin.EC q-fin.GN q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I unravel the basic long run dynamics of the broker call money market, which\nis the pile of cash that funds margin loans to retail clients (read: continuous\ntime Kelly gamblers). Call money is assumed to supply itself perfectly\ninelastically, and to continuously reinvest all principal and interest. I show\nthat the relative size of the money market (that is, relative to the Kelly\nbankroll) is a martingale that nonetheless converges in probability to zero.\nThe margin loan interest rate is a submartingale that converges in mean square\nto the choke price $r_\\infty:=\\nu-\\sigma^2/2$, where $\\nu$ is the asymptotic\ncompound growth rate of the stock market and $\\sigma$ is its annual volatility.\nIn this environment, the gambler no longer beats the market asymptotically a.s.\nby an exponential factor (as he would under perfectly elastic supply). Rather,\nhe beats the market asymptotically with very high probability (think 98%) by a\nfactor (say 1.87, or 87% more final wealth) whose mean cannot exceed what the\nleverage ratio was at the start of the model (say, $2:1$). Although the ratio\nof the gambler's wealth to that of an equivalent buy-and-hold investor is a\nsubmartingale (always expected to increase), his realized compound growth rate\nconverges in mean square to $\\nu$. This happens because the equilibrium\nleverage ratio converges to $1:1$ in lockstep with the gradual rise of margin\nloan interest rates.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 17:01:51 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Garivaltis", "Alex", ""]]}, {"id": "1906.10624", "submitter": "Ingo Hoffmann", "authors": "Christoph J. B\\\"orner, Ingo Hoffmann, Fabian Poetter, Tim Schmitz", "title": "On Capital Allocation under Information Constraints", "comments": "22 pages, 2 Figure, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attempts to allocate capital across a selection of different investments are\noften hampered by the fact that investors' decisions are made under limited\ninformation (no historical return data) and during an extremely limited\ntimeframe. Nevertheless, in some cases, rational investors with a certain level\nof experience are able to ordinally rank investment alternatives through\nrelative assessments of the probabilities that investments will be successful.\nHowever, to apply traditional portfolio optimization models, analysts must use\nhistorical (or simulated/expected) return data as the basis for their\ncalculations. This paper develops an alternative portfolio optimization\nframework that is able to handle this kind of information (given by an ordinal\nranking of investment alternatives) and to calculate an optimal capital\nallocation based on a Cobb-Douglas function, which we call the Sorted Weighted\nPortfolio (SWP). Considering risk-neutral investors, we show that the results\nof this portfolio optimization model usually outperform the output generated by\nthe (intuitive) Equally Weighted Portfolio (EWP) of different investment\nalternatives, which is the result of optimization when one is unable to\nincorporate additional data (the ordinal ranking of the alternatives). To\nfurther extend this work, we show that our model can also address risk-averse\ninvestors to capture correlation effects.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jun 2019 08:57:56 GMT"}, {"version": "v2", "created": "Tue, 21 Apr 2020 04:33:15 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["B\u00f6rner", "Christoph J.", ""], ["Hoffmann", "Ingo", ""], ["Poetter", "Fabian", ""], ["Schmitz", "Tim", ""]]}, {"id": "1906.10865", "submitter": "Frederico Botafogo", "authors": "Frederico Botafogo", "title": "The Syntax of the Accounting Language: A First Step", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review and interpret two basic propositions published by Ellerman (2014).\nThe propositions address the algebraic structure of T accounts and double entry\nbookkeeping (DEB). The paper builds on this previous contribution with the view\nof reconciling the two, apparently dichotomous, perspectives of accounting\nmeasurement: the one that focuses preferably on the stock of wealth and to the\none that focuses preferably on the flow of income. The paper claims that\nT-accounts and DEB have an underlying algebraic structure suitable for\napproaching measurement from either or both perspectives. Accountants\npreferences for stocks or flows can be framed in ways which are mutually\nconsistent. The paper is a first step in addressing this consistency issue. It\navoids the difficult mathematics of abstract algebra by applying the concept of\nsyntax to accounting numbers such that the accounting procedure qualifies as a\nformal language with which accountants convey meaning.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 06:31:06 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Botafogo", "Frederico", ""]]}, {"id": "1906.11968", "submitter": "Tim Hasso", "authors": "Matthias Pelster, Bastian Breitmayer and Tim Hasso", "title": "Are cryptocurrency traders pioneers or just risk-seekers? Evidence from\n  brokerage accounts", "comments": "10 pages", "journal-ref": "Economics Letters, 182, 98-100 (2019)", "doi": "10.1016/j.econlet.2019.06.013", "report-no": null, "categories": "q-fin.GN econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Are cryptocurrency traders driven by a desire to invest in a new asset class\nto diversify their portfolio or are they merely seeking to increase their\nlevels of risk? To answer this question, we use individual-level brokerage data\nand study their behavior in stock trading around the time they engage in their\nfirst cryptocurrency trade. We find that when engaging in cryptocurrency\ntrading investors simultaneously increase their risk-seeking behavior in stock\ntrading as they increase their trading intensity and use of leverage. The\nincrease in risk-seeking in stocks is particularly pronounced when volatility\nin cryptocurrency returns is low, suggesting that their overall behavior is\ndriven by excitement-seeking.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jun 2019 21:17:34 GMT"}], "update_date": "2019-07-01", "authors_parsed": [["Pelster", "Matthias", ""], ["Breitmayer", "Bastian", ""], ["Hasso", "Tim", ""]]}]