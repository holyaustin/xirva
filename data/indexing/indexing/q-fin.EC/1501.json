[{"id": "1501.00434", "submitter": "Jean-Philippe Bouchaud", "authors": "Stanislao Gualdi, Marco Tarzia, Francesco Zamponi, Jean-Philippe\n  Bouchaud", "title": "Monetary Policy and Dark Corners in a stylized Agent-Based Model", "comments": "Contribution to the CRISIS project, 25 pages, 21 figures, pseudo-code\n  of the model, revised and improved version", "journal-ref": "Journal of Economic Interaction and Coordination 12, 507-537\n  (2017)", "doi": "10.1007/s11403-016-0174-z", "report-no": null, "categories": "q-fin.EC physics.soc-ph q-fin.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend in a minimal way the stylized model introduced in in \"Tipping\nPoints in Macroeconomic Agent Based Models\" [JEDC 50, 29-61 (2015)], with the\naim of investigating the role and efficacy of monetary policy of a `Central\nBank' that sets the interest rate such as to steer the economy towards a\nprescribed inflation and employment level. Our major finding is that provided\nits policy is not too aggressive (in a sense detailed in the paper) the Central\nBank is successful in achieving its goals. However, the existence of different\nequilibrium states of the economy, separated by phase boundaries (or \"dark\ncorners\"), can cause the monetary policy itself to trigger instabilities and be\ncounter-productive. In other words, the Central Bank must navigate in a narrow\nwindow: too little is not enough, too much leads to instabilities and wildly\noscillating economies. This conclusion strongly contrasts with the prediction\nof DSGE models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2015 16:31:20 GMT"}, {"version": "v2", "created": "Tue, 12 Jan 2016 19:33:34 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Gualdi", "Stanislao", ""], ["Tarzia", "Marco", ""], ["Zamponi", "Francesco", ""], ["Bouchaud", "Jean-Philippe", ""]]}, {"id": "1501.00882", "submitter": "Dominik Grafenhofer", "authors": "Dominik Grafenhofer, Wolgang Kuhle", "title": "Observing Each Other's Observations in the Electronic Mail Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.EC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a Bayesian coordination game where agents receive private\ninformation on the game's payoff structure. In addition, agents receive private\nsignals on each other's private information. We show that once agents possess\nthese different types of information, there exists a coordination game in the\nevaluation of this information. And even though the precisions of both signal\ntypes is exogenous, the precision with which agents predict each other's\nactions at equilibrium turns out to be endogenous. As a consequence, we find\nthat there exist multiple equilibria if the private signals' precision is high.\nThese equilibria differ with regard to the way that agents weight their private\ninformation to reason about each other's actions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 16:15:30 GMT"}], "update_date": "2015-01-06", "authors_parsed": [["Grafenhofer", "Dominik", ""], ["Kuhle", "Wolgang", ""]]}, {"id": "1501.02276", "submitter": "Brian Ward", "authors": "Tim Leung and Brian Ward", "title": "The Golden Target: Analyzing the Tracking Performance of Leveraged Gold\n  ETFs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST q-fin.EC q-fin.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the empirical tracking performance of leveraged ETFs on\ngold, and their price relationships with gold spot and futures. For tracking\nthe gold spot, we find that our optimized portfolios with short-term gold\nfutures are highly effective in replicating prices. The market-traded gold ETF\n(GLD) also exhibits a similar tracking performance. However, we show that\nleveraged gold ETFs tend to underperform their corresponding leveraged\nbenchmark. Moreover, the underperformance worsens over a longer holding period.\nIn contrast, we illustrate that a dynamic portfolio of gold futures tracks\nsignificantly better than various static portfolios. The dynamic portfolio also\nconsistently outperforms the respective market-traded LETFs for different\nleverage ratios over multiple years.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2015 21:13:54 GMT"}, {"version": "v2", "created": "Thu, 22 Jan 2015 17:50:56 GMT"}], "update_date": "2015-01-23", "authors_parsed": [["Leung", "Tim", ""], ["Ward", "Brian", ""]]}, {"id": "1501.02513", "submitter": "Marcin Pitera", "authors": "Piotr Jaworski and Marcin Pitera", "title": "The 20-60-20 Rule", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-fin.EC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we discuss an empirical phenomena known as the 20-60-20 rule.\nIt says that if we split the population into three groups, according to some\narbitrary benchmark criterion, then this particular ratio implies some sort of\nbalance. From practical point of view, this feature often leads to efficient\nmanagement or control. We provide a mathematical illustration, justifying the\noccurrence of this rule in many real world situations. We show that for any\npopulation, which could be described using multivariate normal vector, this\nfixed ratio leads to a global equilibrium state, when dispersion and linear\ndependance measurement is considered.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2015 00:41:49 GMT"}, {"version": "v2", "created": "Thu, 20 Aug 2015 04:15:01 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Jaworski", "Piotr", ""], ["Pitera", "Marcin", ""]]}, {"id": "1501.04682", "submitter": "Peter Sarlin", "authors": "Markus Holopainen, Peter Sarlin", "title": "Toward robust early-warning models: A horse race, ensembles and model\n  uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CE q-fin.CP q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents first steps toward robust models for crisis prediction.\nWe conduct a horse race of conventional statistical methods and more recent\nmachine learning methods as early-warning models. As individual models are in\nthe literature most often built in isolation of other methods, the exercise is\nof high relevance for assessing the relative performance of a wide variety of\nmethods. Further, we test various ensemble approaches to aggregating the\ninformation products of the built models, providing a more robust basis for\nmeasuring country-level vulnerabilities. Finally, we provide approaches to\nestimating model uncertainty in early-warning exercises, particularly model\nperformance uncertainty and model output uncertainty. The approaches put\nforward in this paper are shown with Europe as a playground. Generally, our\nresults show that the conventional statistical approaches are outperformed by\nmore advanced machine learning methods, such as k-nearest neighbors and neural\nnetworks, and particularly by model aggregation approaches through ensemble\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jan 2015 00:18:18 GMT"}, {"version": "v2", "created": "Wed, 4 Feb 2015 15:55:18 GMT"}, {"version": "v3", "created": "Fri, 1 Apr 2016 14:22:36 GMT"}], "update_date": "2016-04-04", "authors_parsed": [["Holopainen", "Markus", ""], ["Sarlin", "Peter", ""]]}, {"id": "1501.05771", "submitter": "Nikolay Klemashev", "authors": "Nikolay Klemashev, Alexander Shananin", "title": "Positively-homogeneous Konus-Divisia indices and their applications to\n  demand analysis and forecasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to revealed preference theory and its applications to\ntesting economic data for consistency with utility maximization hypothesis,\nconstruction of index numbers, and forecasting. The quantitative measures of\ninconsistency of economic data with utility maximization behavior are also\ndiscussed. The structure of the paper is based on comparison between the two\ntests of revealed preference theory - generalized axiom of revealed preference\n(GARP) and homothetic axiom of revealed prefernce (HARP). We do this comparison\nboth theoretically and empirically. In particular we assess empirically the\npower of these tests for consistency with maximization behavior and the size of\nforecasting sets based on them. For the forecasting problem we show that when\nusing HARP there is an effective way of building the forecasting set since this\nset is given by the solution of the system of linear inequalities. The paper\nalso touches upon the question of testing a set of Engel curves rather than\nfinite set of observations for consistency with utility maximization behavior\nand shows that this question has effective solution when we require the\nrationalizing utility function to be positively homogeneous.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jan 2015 11:22:46 GMT"}], "update_date": "2015-01-26", "authors_parsed": [["Klemashev", "Nikolay", ""], ["Shananin", "Alexander", ""]]}]