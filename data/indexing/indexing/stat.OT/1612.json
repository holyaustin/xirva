[{"id": "1612.01619", "submitter": "Robert McCulloch", "authors": "Hugh A. Chipman, Edward I. George, Robert E. McCulloch, Thomas S.\n  Shively", "title": "High-dimensional nonparametric monotone function estimation using BART", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the estimation of a regression relationship between Y and a large set of\npotential predictors x 1 , . . . , x p , the flexible nature of a nonparametric\napproach such as BART (Bayesian Additive Regression Trees) allows for a much\nricher set of possibilities than a more restrictive parametric approach.\nHowever, it may often occur that subject matter considerations suggest the\nrelationship will be monotone in one or more of the predictors. For such\nsituations, we propose monotone BART, a constrained version of BART that uses\nthe monotonicity information to improve function estimation without the need of\nusing a parametric form. Imposing monotonicity, when appropriate, results in\n(i) function estimates that are smoother and more interpretable, (ii) better\nout-of-sample predictive performance, (iii) less uncertainty, and (iv) less\nsensitivity to prior choice. While some of the key aspects of the unconstrained\nBART model carry over directly to monotone BART, the imposition of the\nmonotonicity constraints necessitates a fundamental rethinking of how the model\nis implemented. In particular, in the original BART algorithm, the Markov Chain\nMonte Carlo algorithm relied on a conditional conjugacy that is no longer\navailable in a high-dimensional, constrained space.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 01:24:34 GMT"}, {"version": "v2", "created": "Sun, 18 Aug 2019 15:03:18 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Chipman", "Hugh A.", ""], ["George", "Edward I.", ""], ["McCulloch", "Robert E.", ""], ["Shively", "Thomas S.", ""]]}, {"id": "1612.02252", "submitter": "Amy Wagaman", "authors": "Amy Wagaman", "title": "Building Communication Skills in a Theoretical Statistics Course", "comments": "slightly modified version of JSM 2016 proceedings paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The traditional theoretical statistics course which develops the theoretical\nunderpinnings of the discipline (usually following a probability course) is\nundergoing near-continuous revision in the statistics community. In particular,\nrecent versions of this course have incorporated more and more computation. We\ntake a look at a different aspect of the revision - building student\ncommunication skills in the course, in both written and verbal forms, to allow\nstudents to demonstrate their ability to explain statistical concepts. Two\nseparate projects are discussed, both of which were engaged in by a class of\nsize 17 in Spring 2015. The first project had a computational aspect (performed\nusing R), a statistical theory component, and a writing component, and was\nbased on the historical German tank problem. The second project involved a\nclass presentation and written report summarizing, critiquing, and/or\nexplaining an article selected from The American Statistician.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 14:04:11 GMT"}], "update_date": "2016-12-08", "authors_parsed": [["Wagaman", "Amy", ""]]}, {"id": "1612.05292", "submitter": "Giulio D'Agostini", "authors": "Giulio D'Agostini", "title": "Probability, propensity and probabilities of propensities (and of\n  probabilities)", "comments": "Invited contribution to the proceedings MaxEnt 2016 based on the talk\n  given at the workshop (Ghent, Belgium, 10-15 July 2016), supplemented by work\n  done within the program Probability and Statistics in Forensic Science at the\n  Isaac Newton Institute for Mathematical Sciences, Cambridge", "journal-ref": "AIP Conference Proceedings 1853, 030001 (2017);\n  https://doi.org/10.1063/1.4985350", "doi": "10.1063/1.4985350", "report-no": "INI preprint NI16052", "categories": "math.HO math.PR physics.data-an physics.hist-ph stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of doing Science in condition of uncertainty is illustrated with\na toy experiment in which the inferential and the forecasting aspects are both\npresent. The fundamental aspects of probabilistic reasoning, also relevant in\nreal life applications, arise quite naturally and the resulting discussion\namong non-ideologized, free-minded people offers an opportunity for\nclarifications.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 17:24:19 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["D'Agostini", "Giulio", ""]]}, {"id": "1612.07140", "submitter": "Stephanie Hicks", "authors": "Stephanie C. Hicks, Rafael A. Irizarry", "title": "A Guide to Teaching Data Science", "comments": "2 tables, 3 figures, 2 supplemental figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand for data science education is surging and traditional courses offered\nby statistics departments are not meeting the needs of those seeking training.\nThis has led to a number of opinion pieces advocating for an update to the\nStatistics curriculum. The unifying recommendation is computing should play a\nmore prominent role. We strongly agree with this recommendation, but advocate\nthe main priority is to bring applications to the forefront as proposed by\nNolan and Speed (1999). We also argue that the individuals tasked with\ndeveloping data science courses should not only have statistical training, but\nalso have experience analyzing data with the main objective of solving\nreal-world problems. Here, we share a set of general principles and offer a\ndetailed guide derived from our successful experience developing and teaching a\ngraduate-level, introductory data science course centered entirely on case\nstudies. We argue for the importance of statistical thinking, as defined by\nWild and Pfannkuck (1999) and describe how our approach teaches students three\nkey skills needed to succeed in data science, which we refer to as creating,\nconnecting, and computing. This guide can also be used for statisticians\nwanting to gain more practical knowledge about data science before embarking on\nteaching an introductory course.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 14:32:35 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 11:28:19 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Hicks", "Stephanie C.", ""], ["Irizarry", "Rafael A.", ""]]}, {"id": "1612.07542", "submitter": "Nileshkumar Vaishnav", "authors": "Nileshkumar Vaishnav and Aditya Tatu", "title": "A Graph Downsampling Technique Based On Graph Fourier Transform", "comments": "Written in journal paper format, inlcudes 8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we provide a Graph Fourier Transform based approach to\ndownsample signals on graphs. For bandlimited signals on a graph, a test is\nprovided to identify whether signal reconstruction is possible from the given\ndownsampled signal. Moreover, if the signal is not bandlimited, we provide a\nquality measure for comparing different downsampling schemes. Using this\nquality measure, we propose a greedy downsampling algorithm. Most of the\nprevailing approaches consider undirected graphs, and exploit the topological\nproperties of the graph in order to downsample the grid, while the proposed\nmethod exploits spectral properties of graph signals, and is applicable to\ndirected graphs, undirected graphs, and graphs with negative edge-weights. We\nprovide several experiments demonstrating our downsampling scheme, and compare\nour quality measure with measures like normalized cuts.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 10:59:59 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Vaishnav", "Nileshkumar", ""], ["Tatu", "Aditya", ""]]}]