[{"id": "2004.00527", "submitter": "Thomas Shaw", "authors": "Thomas Shaw, Jesper M{\\o}ller and Rasmus Waagepetersen", "title": "Globally intensity-reweighted estimators for $K$- and pair correlation\n  functions", "comments": "31 pages, 9 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce new estimators of the inhomogeneous $K$-function and the pair\ncorrelation function of a spatial point process as well as the cross\n$K$-function and the cross pair correlation function of a bivariate spatial\npoint process under the assumption of second-order intensity-reweighted\nstationarity. These estimators rely on a 'global' normalization factor which\ndepends on an aggregation of the intensity function, whilst the existing\nestimators depend 'locally' on the intensity function at the individual\nobserved points. The advantages of our new global estimators over the existing\nlocal estimators are demonstrated by theoretical considerations and a\nsimulation study.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 15:51:58 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2020 20:12:58 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Shaw", "Thomas", ""], ["M\u00f8ller", "Jesper", ""], ["Waagepetersen", "Rasmus", ""]]}, {"id": "2004.00973", "submitter": "Abdulaziz Alenazi Dr", "authors": "Abdulaziz Alenazi", "title": "A Monte Carlo comparison of categorical tests of independence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $X^2$ and $G^2$ tests are the most frequently applied tests for testing\nthe independence of two categorical variables. However, no one, to the best of\nour knowledge has compared them, extensively, and ultimately answer the\nquestion of which to use and when. Further, their applicability in cases with\nzero frequencies has been debated and (non parametric) permutation tests are\nsuggested. In this work we perform extensive Monte Carlo simulation studies\nattempting to answer both aforementioned points. As expected, in large sample\nsized cases ($>1,000$) the $X^2$ and $G^2$ are indistinguishable. In the small\nsample sized cases ($\\leq 1,000$) though, we provide strong evidence supporting\nthe use of the $X^2$ test regardless of zero frequencies for the case of\nunconditional independence. Also, we suggest the use of the permutation based\n$G^2$ test for testing conditional independence, at the cost of being\ncomputationally more expensive. The $G^2$ test exhibited inferior performance\nand its use should be limited.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 13:18:51 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Alenazi", "Abdulaziz", ""]]}, {"id": "2004.01534", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj and Benjamin Renoust", "title": "Layer entanglement in multiplex, temporal multiplex, and coupled\n  multilayer networks", "comments": "Accepted to ANS. arXiv admin note: text overlap with arXiv:1910.05300", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.MA cs.SI stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex networks, such as transportation networks, social networks, or\nbiological networks, capture the complex system they model often by\nrepresenting only one type of interactions. In real world systems, there may be\nmany different aspects that connect entities together. These can be captured\nusing multilayer networks, which combine different modalities of interactions\nin a single model. Coupling in multilayer networks may exhibit different\nproperties which can be related to the very nature of the data they model (or\nto events in time-dependant data). We hypothesise that such properties may be\nreflected in the way layers are intertwined. In this paper, we investigated\nthese through the prism of layer entanglement in coupled multilayer networks.\nWe test over 30 real-life networks in 6 different disciplines (social, genetic,\ntransport, co-authorship, trade, and neuronal networks). We further propose a\nrandom generator, displaying comparable patterns of elementary layer\nentanglement and transition coupling entanglement across 1,329,696 synthetic\ncoupled multilayer networks. Our experiments demonstrate difference of layer\nentanglement across disciplines, and even suggest a link between entanglement\nintensity and homophily. We additionally study entanglement in 3 real world\ntemporal datasets displaying a potential rise in entanglement activity prior to\nother network activity.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 17:11:34 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2020 08:03:01 GMT"}], "update_date": "2020-10-16", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["Renoust", "Benjamin", ""]]}, {"id": "2004.02708", "submitter": "Fulvia Mecatti Dr", "authors": "Fulvia Mecatti and Charalambos Sismanidis and Emanuela Furfaro", "title": "Sequential adaptive strategy for population-based sampling of a rare and\n  clustered disease", "comments": "21 pages, 1 tenable, 3 figures - Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An innovative sampling strategy is proposed, which applies to large-scale\npopulation-based surveys targeting a rare trait that is unevenly spread over a\ngeographical area of interest. Our proposal is characterised by the ability to\ntailor the data collection to specific features and challenges of the survey at\nhand. It is based on integrating an adaptive component into a sequential\nselection, which aims to both intensify detection of positive cases, upon\nexploiting the spatial clusterisation, and provide a flexible framework for\nmanaging logistical and budget constraints. To account for the selection bias,\na ready-to-implement weighting system is provided to release unbiased and\naccurate estimates. Empirical evidence is illustrated from tuberculosis\nprevalence surveys, which are recommended in many countries and supported by\nthe WHO as an emblematic example of the need for an improved sampling design.\nSimulation results are also given to illustrate strengths and weaknesses of the\nproposed sampling strategy with respect to traditional cross-sectional\nsampling.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:46:22 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Mecatti", "Fulvia", ""], ["Sismanidis", "Charalambos", ""], ["Furfaro", "Emanuela", ""]]}, {"id": "2004.04019", "submitter": "Mauricio Santillana", "authors": "Dianbo Liu, Leonardo Clemente, Canelle Poirier, Xiyu Ding, Matteo\n  Chinazzi, Jessica T Davis, Alessandro Vespignani, Mauricio Santillana", "title": "A machine learning methodology for real-time forecasting of the\n  2019-2020 COVID-19 outbreak using Internet searches, news alerts, and\n  estimates from mechanistic models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG q-bio.PE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a timely and novel methodology that combines disease estimates\nfrom mechanistic models with digital traces, via interpretable machine-learning\nmethodologies, to reliably forecast COVID-19 activity in Chinese provinces in\nreal-time. Specifically, our method is able to produce stable and accurate\nforecasts 2 days ahead of current time, and uses as inputs (a) official health\nreports from Chinese Center Disease for Control and Prevention (China CDC), (b)\nCOVID-19-related internet search activity from Baidu, (c) news media activity\nreported by Media Cloud, and (d) daily forecasts of COVID-19 activity from\nGLEAM, an agent-based mechanistic model. Our machine-learning methodology uses\na clustering technique that enables the exploitation of geo-spatial\nsynchronicities of COVID-19 activity across Chinese provinces, and a data\naugmentation technique to deal with the small number of historical disease\nactivity observations, characteristic of emerging outbreaks. Our model's\npredictive power outperforms a collection of baseline models in 27 out of the\n32 Chinese provinces, and could be easily extended to other geographies\ncurrently affected by the COVID-19 outbreak to help decision makers.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 14:39:32 GMT"}], "update_date": "2020-04-09", "authors_parsed": [["Liu", "Dianbo", ""], ["Clemente", "Leonardo", ""], ["Poirier", "Canelle", ""], ["Ding", "Xiyu", ""], ["Chinazzi", "Matteo", ""], ["Davis", "Jessica T", ""], ["Vespignani", "Alessandro", ""], ["Santillana", "Mauricio", ""]]}, {"id": "2004.04265", "submitter": "Mason Youngblood", "authors": "Mason Youngblood", "title": "Extremist ideology as a complex contagion: the spread of far-right\n  radicalization in the United States between 2005-2017", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SI stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing levels of far-right extremist violence have generated public\nconcern about the spread of radicalization in the United States. Previous\nresearch suggests that radicalized individuals are destabilized by various\nenvironmental (or endemic) factors, exposed to extremist ideology, and\nsubsequently reinforced by members of their community. As such, the spread of\nradicalization may proceed through a social contagion process, in which\nextremist ideologies behave like complex contagions that require multiple\nexposures for adoption. In this study, I applied an epidemiological method\ncalled two-component spatio-temporal intensity modeling to data from 416\nfar-right extremists exposed in the United States between 2005 and 2017. The\nresults indicate that patterns of far-right radicalization in the United States\nare consistent with a complex contagion process, in which reinforcement is\nrequired for transmission. Both social media usage and group membership enhance\nthe spread of extremist ideology, suggesting that online and physical\norganizing remain primary recruitment tools of the far-right movement.\nAdditionally, I identified several endemic factors, such as poverty, that\nincrease the probability of radicalization in particular regions. Future\nresearch should investigate how specific interventions, such as online\ncounter-narratives to battle propaganda, may be effectively implemented to\nmitigate the spread of far-right extremism in the United States.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 19:06:34 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Youngblood", "Mason", ""]]}, {"id": "2004.04267", "submitter": "Shivangi Singh", "authors": "Shivangi Singh and Chanchal Kundu", "title": "On Weighted Generalized Entropy for Double Truncated Distribution", "comments": "20 pages, 11 figures. arXiv admin note: text overlap with\n  arXiv:math/0703489 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of weighted Renyi's entropy for truncated random variables has\nrecently been proposed in the information-theoretic literature. In this paper,\nwe introduce a generalized measure of it for double truncated distribution,\nnamely weighted generalized interval entropy (WGIE), and study it in the\ncontext of reliability analysis. Several properties, including monotonicity,\nbounds and uniqueness of WGIE are investigated. Moreover, a simulation study is\ncarried out to demonstrate the performance of the estimates of the proposed\nmeasure using simulated and real data sets. The role of WGIE in reliability\nmodeling has also been investigated for a real-life problem.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 10:09:22 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Singh", "Shivangi", ""], ["Kundu", "Chanchal", ""]]}, {"id": "2004.04373", "submitter": "Onur Avci", "authors": "Onur Avci, Osama Abdeljaber, Serkan Kiranyaz, Mohammed Hussein, Moncef\n  Gabbouj, Daniel J. Inman", "title": "A Review of Vibration-Based Damage Detection in Civil Structures: From\n  Traditional Methods to Machine Learning and Deep Learning Applications", "comments": "51 pages, 45 figures, MSSP (Elsevier) submission", "journal-ref": null, "doi": "10.1016/j.ymssp.2020.107077", "report-no": null, "categories": "eess.SP cs.LG stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Monitoring structural damage is extremely important for sustaining and\npreserving the service life of civil structures. While successful monitoring\nprovides resolute and staunch information on the health, serviceability,\nintegrity and safety of structures; maintaining continuous performance of a\nstructure depends highly on monitoring the occurrence, formation and\npropagation of damage. Damage may accumulate on structures due to different\nenvironmental and human-induced factors. Numerous monitoring and detection\napproaches have been developed to provide practical means for early warning\nagainst structural damage or any type of anomaly. Considerable effort has been\nput into vibration-based methods, which utilize the vibration response of the\nmonitored structure to assess its condition and identify structural damage.\nMeanwhile, with emerging computing power and sensing technology in the last\ndecade, Machine Learning (ML) and especially Deep Learning (DL) algorithms have\nbecome more feasible and extensively used in vibration-based structural damage\ndetection with elegant performance and often with rigorous accuracy. While\nthere have been multiple review studies published on vibration-based structural\ndamage detection, there has not been a study where the transition from\ntraditional methods to ML and DL methods are described and discussed. This\npaper aims to fulfill this gap by presenting the highlights of the traditional\nmethods and provide a comprehensive review of the most recent applications of\nML and DL algorithms utilized for vibration-based structural damage detection\nin civil structures.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 05:39:21 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Avci", "Onur", ""], ["Abdeljaber", "Osama", ""], ["Kiranyaz", "Serkan", ""], ["Hussein", "Mohammed", ""], ["Gabbouj", "Moncef", ""], ["Inman", "Daniel J.", ""]]}, {"id": "2004.04734", "submitter": "Roman Marchant", "authors": "Roman Marchant, Noelle I. Samia, Ori Rosen, Martin A. Tanner, and\n  Sally Cripps", "title": "Learning as We Go: An Examination of the Statistical Accuracy of COVID19\n  Daily Death Count Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides a formal evaluation of the predictive performance of a\nmodel (and its various updates) developed by the Institute for Health Metrics\nand Evaluation (IHME) for predicting daily deaths attributed to COVID19 for\neach state in the United States. The IHME models have received extensive\nattention in social and mass media, and have influenced policy makers at the\nhighest levels of the United States government. For effective policy making the\naccurate assessment of uncertainty, as well as accurate point predictions, are\nnecessary because the risks inherent in a decision must be taken into account,\nespecially in the present setting of a novel disease affecting millions of\nlives. To assess the accuracy of the IHME models, we examine both forecast\naccuracy as well as the predictive performance of the 95% prediction intervals\nprovided by the IHME models. We find that the initial IHME model underestimates\nthe uncertainty surrounding the number of daily deaths substantially.\nSpecifically, the true number of next day deaths fell outside the IHME\nprediction intervals as much as 70% of the time, in comparison to the expected\nvalue of 5%. In addition, we note that the performance of the initial model\ndoes not improve with shorter forecast horizons. Regarding the updated models,\nour analyses indicate that the later models do not show any improvement in the\naccuracy of the point estimate predictions. In fact, there is some evidence\nthat this accuracy has actually decreased over the initial models. Moreover,\nwhen considering the updated models, while we observe a larger percentage of\nstates having actual values lying inside the 95% prediction intervals (PI), our\nanalysis suggests that this observation may be attributed to the widening of\nthe PIs. The width of these intervals calls into question the usefulness of the\npredictions to drive policy making and resource allocation.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 01:12:12 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 02:58:24 GMT"}, {"version": "v3", "created": "Mon, 4 May 2020 01:00:28 GMT"}, {"version": "v4", "created": "Sun, 24 May 2020 12:38:22 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Marchant", "Roman", ""], ["Samia", "Noelle I.", ""], ["Rosen", "Ori", ""], ["Tanner", "Martin A.", ""], ["Cripps", "Sally", ""]]}, {"id": "2004.05217", "submitter": "Marco Pollo Almeida", "authors": "Marco Pollo Almeida, Rafael Paixao, Pedro Ramos, Vera Tomazella,\n  Francisco Louzada, Ricardo Ehlers", "title": "Multiple repairable systems under dependent competing risks with\n  nonparametric Frailty", "comments": "17 pages, 14 figures. This article is part of the doctoral thesis of\n  the first author and appears in the bibliography of this article", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The aim of this article is to analyze data from multiple repairable systems\nunder the presence of dependent competing risks. In order to model this\ndependence structure, we adopted the well-known shared frailty model. This\nmodel provides a suitable theoretical basis for generating dependence between\nthe components failure times in the dependent competing risks model. It is\nknown that the dependence effect in this scenario influences the estimates of\nthe model parameters. Hence, under the assumption that the cause-specific\nintensities follow a PLP, we propose a frailty-induced dependence approach to\nincorporate the dependence among the cause-specific recurrent processes.\nMoreover, the misspecification of the frailty distribution may lead to errors\nwhen estimating the parameters of interest. Because of this, we considered a\nBayesian nonparametric approach to model the frailty density in order to offer\nmore flexibility and to provide consistent estimates for the PLP model, as well\nas insights about heterogeneity among the systems. Both simulation studies and\nreal case studies are provided to illustrate the proposed approaches and\ndemonstrate their validity.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 20:16:25 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Almeida", "Marco Pollo", ""], ["Paixao", "Rafael", ""], ["Ramos", "Pedro", ""], ["Tomazella", "Vera", ""], ["Louzada", "Francisco", ""], ["Ehlers", "Ricardo", ""]]}, {"id": "2004.05796", "submitter": "Hongqiao Wang", "authors": "Hongqiao Wang and Xiang Zhou", "title": "Explicit Estimation of Derivatives from Data and Differential Equations\n  by Gaussian Process Regression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we employ the Bayesian inference framework to solve the problem\nof estimating the solution and particularly, its derivatives, which satisfy a\nknown differential equation, from the given noisy and scarce observations of\nthe solution data only. To address the key issue of accuracy and robustness of\nderivative estimation, we use the Gaussian processes to jointly model the\nsolution, the derivatives, and the differential equation. By regarding the\nlinear differential equation as a linear constraint, a Gaussian process\nregression with constraint method (GPRC) is developed to improve the accuracy\nof prediction of derivatives. For nonlinear differential equations, we propose\na Picard-iteration-like approximation of linearization around the Gaussian\nprocess obtained only from data so that our GPRC can be still iteratively\napplicable. Besides, a product of experts method is applied to ensure the\ninitial or boundary condition is considered to further enhance the prediction\naccuracy of the derivatives. We present several numerical results to illustrate\nthe advantages of our new method in comparison to the standard data-driven\nGaussian process regression.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 07:08:02 GMT"}, {"version": "v2", "created": "Thu, 8 Oct 2020 04:36:28 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Wang", "Hongqiao", ""], ["Zhou", "Xiang", ""]]}, {"id": "2004.06054", "submitter": "Xin Gao", "authors": "Xin Gao, Li Li, Li Luo", "title": "Decomposition of Total Effect with the Notion of Natural Counterfactual\n  Interaction Effect", "comments": "72 pages in total, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mediation analysis serves as a crucial tool to obtain causal inference based\non directed acyclic graphs, which has been widely employed in the areas of\nbiomedical science, social science, epidemiology and psychology. Decomposition\nof total effect provides a deep insight to fully understand the casual\ncontribution from each path and interaction term. Since the four-way\ndecomposition method was proposed to identify the mediated interaction effect\nin counterfactual framework, the idea had been extended to a more sophisticated\nscenario with non-sequential multiple mediators. However, the method exhibits\nlimitations as the causal structure contains direct causal edges between\nmediators, such as inappropriate modeling of dependence and\nnon-identifiability. We develop the notion of natural counterfactual\ninteraction effect and find that the decomposition of total effect can be\nconsistently realized with our proposed notion. Furthermore, natural\ncounterfactual interaction effect overcomes the drawbacks and possesses a clear\nand significant interpretation, which may largely improve the capacity of\nresearchers to analyze highly complex causal structures.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 16:29:58 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Gao", "Xin", ""], ["Li", "Li", ""], ["Luo", "Li", ""]]}, {"id": "2004.06178", "submitter": "Charles Manski", "authors": "Charles F. Manski and Francesca Molinari", "title": "Estimating the COVID-19 Infection Rate: Anatomy of an Inference Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a consequence of missing data on tests for infection and imperfect\naccuracy of tests, reported rates of population infection by the SARS CoV-2\nvirus are lower than actual rates of infection. Hence, reported rates of severe\nillness conditional on infection are higher than actual rates. Understanding\nthe time path of the COVID-19 pandemic has been hampered by the absence of\nbounds on infection rates that are credible and informative. This paper\nexplains the logical problem of bounding these rates and reports illustrative\nfindings, using data from Illinois, New York, and Italy. We combine the data\nwith assumptions on the infection rate in the untested population and on the\naccuracy of the tests that appear credible in the current context. We find that\nthe infection rate might be substantially higher than reported. We also find\nthat the infection fatality rate in Italy is substantially lower than reported.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2020 20:04:34 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Manski", "Charles F.", ""], ["Molinari", "Francesca", ""]]}, {"id": "2004.06464", "submitter": "Genki Ichinose", "authors": "Genki Ichinose, Daiki Miyagawa, Junji Ito, Naoki Masuda", "title": "Winning by hiding behind others: An analysis of speed skating data", "comments": "10 pages, 5 figures", "journal-ref": "PLoS ONE 15, e0237470, 2020", "doi": "10.1371/journal.pone.0237470", "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In some athletic races, such as cycling and types of speed skating races,\nathletes have to complete a relatively long distance at a high speed in the\npresence of direct opponents. To win such a race, athletes are motivated to\nhide behind others to suppress energy consumption before a final moment of the\nrace. This situation seems to produce a social dilemma: players want to hide\nbehind others, whereas if a group of players attempts to do so, they may all\nlose to other players that overtake them. To support that speed skaters are\ninvolved in such a social dilemma, we analyzed video footage data for 14 mass\nstart skating races to find that skaters that hid behind others to avoid air\nresistance for a long time before the final lap tended to win. Furthermore, the\nfinish rank of the skaters in mass start races was independent of the record of\nthe same skaters in time-trial races measured in the absence of direct\nopponents. The results suggest that how to strategically cope with a skater's\ndilemma may be a key determinant for winning long-distance and high-speed races\nwith direct opponents.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 13:10:14 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2020 12:54:12 GMT"}], "update_date": "2020-08-14", "authors_parsed": [["Ichinose", "Genki", ""], ["Miyagawa", "Daiki", ""], ["Ito", "Junji", ""], ["Masuda", "Naoki", ""]]}, {"id": "2004.06721", "submitter": "Daniel Torres-Salinas Dr", "authors": "Daniel Torres-Salinas", "title": "Daily growth rate of scientific production on Covid-19. Analysis in\n  databases and open access repositories", "comments": "in Spanish", "journal-ref": null, "doi": "10.3145/epi.2020.mar.15", "report-no": null, "categories": "cs.DL cs.IR stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scientific community is facing one of its greatest challenges in solving\na global health problem: COVID-19 pandemic. This situation has generated an\nunprecedented volume of publications. What is the volume, in terms of\npublications, of research on COVID-19? The general objective of this research\nwork is to obtain a global vision of the daily growth of scientific production\non COVID-19 in different databases (Dimensions, Web of Science Core Collection,\nScopus-Elsevier, Pubmed and eight repositories). In relation to the results\nobtained, Dimensions indexes a total of 9435 publications (69% with peer review\nand 2677 preprints) well above Scopus (1568) and WoS (718). This is a classic\nbiliometric phenomenon of exponential growth (R2 = 0.92). The global growth\nrate is 500 publications and the production doubles every 15 days. In the case\nof Pubmed the weekly growth is around 1000 publications. Of the eight\nrepositories analysed, Pubmed Central, Medrxiv and SSRN are the leaders.\nDespite their enormous contribution, the journals continue to be the core of\nscientific communication. Finally, it has been established that three out of\nevery four publications on the COVID-19 are available in open access. The\ninformation explosion demands a serious and coordinated response from\ninformation professionals, which places us at the centre of the information\npandemic.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2020 16:30:01 GMT"}], "update_date": "2020-04-16", "authors_parsed": [["Torres-Salinas", "Daniel", ""]]}, {"id": "2004.07052", "submitter": "Per Block", "authors": "Per Block, Marion Hoffman, Isabel J. Raabe, Jennifer Beam Dowd,\n  Charles Rahal, Ridhi Kashyap, Melinda C. Mills", "title": "Social network-based distancing strategies to flatten the COVID 19 curve\n  in a post-lockdown world", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph q-bio.PE stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social distancing and isolation have been introduced widely to counter the\nCOVID-19 pandemic. However, more moderate contact reduction policies become\ndesirable owing to adverse social, psychological, and economic consequences of\na complete or near-complete lockdown. Adopting a social network approach, we\nevaluate the effectiveness of three targeted distancing strategies designed to\n'keep the curve flat' and aid compliance in a post-lockdown world. These are\nlimiting interaction to a few repeated contacts, seeking similarity across\ncontacts, and strengthening communities via triadic strategies. We simulate\nstochastic infection curves that incorporate core elements from infection\nmodels, ideal-type social network models, and statistical relational event\nmodels. We demonstrate that strategic reduction of contact can strongly\nincrease the efficiency of social distancing measures, introducing the\npossibility of allowing some social contact while keeping risks low. This\napproach provides nuanced insights to policy makers for effective social\ndistancing that can mitigate negative consequences of social isolation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 12:29:29 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 22:22:00 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Block", "Per", ""], ["Hoffman", "Marion", ""], ["Raabe", "Isabel J.", ""], ["Dowd", "Jennifer Beam", ""], ["Rahal", "Charles", ""], ["Kashyap", "Ridhi", ""], ["Mills", "Melinda C.", ""]]}, {"id": "2004.07859", "submitter": "Hiteshi Tandon", "authors": "Hiteshi Tandon, Prabhat Ranjan, Tanmoy Chakraborty and Vandana Suhag", "title": "Coronavirus (COVID-19): ARIMA based time-series analysis to forecast\n  near future", "comments": "Pages: 11, Tables: 4, Figures: 6; Author Contributions: H.T. and T.C.\n  conceptualized the project. H.T. designed the study, performed the\n  computations and investigations, contributed to data analysis and wrote the\n  manuscript. P.R. provided the resources. T.C. and V.S. supervised the study\n  and reviewed the manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE q-bio.QM stat.CO stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  COVID-19, a novel coronavirus, is currently a major worldwide threat. It has\ninfected more than a million people globally leading to hundred-thousands of\ndeaths. In such grave circumstances, it is very important to predict the future\ninfected cases to support prevention of the disease and aid in the healthcare\nservice preparation. Following that notion, we have developed a model and then\nemployed it for forecasting future COVID-19 cases in India. The study indicates\nan ascending trend for the cases in the coming days. A time series analysis\nalso presents an exponential increase in the number of cases. It is supposed\nthat the present prediction models will assist the government and medical\npersonnel to be prepared for the upcoming conditions and have more readiness in\nhealthcare systems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 18:12:08 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Tandon", "Hiteshi", ""], ["Ranjan", "Prabhat", ""], ["Chakraborty", "Tanmoy", ""], ["Suhag", "Vandana", ""]]}, {"id": "2004.09010", "submitter": "Imran Razzak Dr", "authors": "Arshia Rehman, Saeeda Naz, Imran Razzak", "title": "Leveraging Big Data Analytics in Healthcare Enhancement: Trends,\n  Challenges and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clinicians decisions are becoming more and more evidence-based meaning in no\nother field the big data analytics so promising as in healthcare. Due to the\nsheer size and availability of healthcare data, big data analytics has\nrevolutionized this industry and promises us a world of opportunities. It\npromises us the power of early detection, prediction, prevention and helps us\nto improve the quality of life. Researchers and clinicians are working to\ninhibit big data from having a positive impact on health in the future.\nDifferent tools and techniques are being used to analyze, process, accumulate,\nassimilate and manage large amount of healthcare data either in structured or\nunstructured form. In this paper, we would like to address the need of big data\nanalytics in healthcare: why and how can it help to improve life?. We present\nthe emerging landscape of big data and analytical techniques in the five\nsub-disciplines of healthcare i.e.medical image analysis and imaging\ninformatics, bioinformatics, clinical informatics, public health informatics\nand medical signal analytics. We presents different architectures, advantages\nand repositories of each discipline that draws an integrated depiction of how\ndistinct healthcare activities are accomplished in the pipeline to facilitate\nindividual patients from multiple perspectives. Finally the paper ends with the\nnotable applications and challenges in adoption of big data analytics in\nhealthcare.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 06:46:58 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Rehman", "Arshia", ""], ["Naz", "Saeeda", ""], ["Razzak", "Imran", ""]]}, {"id": "2004.10326", "submitter": "Hyoshin Kim", "authors": "Hyoshin Kim, Nancy McMillan, Jeffrey Geppert and Laura Aume", "title": "Comparison of Clinical Episode Outcomes between Bundled Payments for\n  Care Improvement (BPCI) Initiative Participants and Non-Participants", "comments": "15 pages, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To evaluate differences in major outcomes between Bundled Payments\nfor Care Improvement (BPCI) participating providers and non-participating\nproviders for both Major Joint Replacement of the Lower Extremity (MJRLE) and\nAcute Myocardial Infarction (AMI) episodes. Methods: A\ndifference-in-differences approach estimated the differential change in\noutcomes for Medicare beneficiaries who had an MJRLE or AMI at a BPCI\nparticipating hospital between the baseline (January 2011 through September\n2013) and intervention (October 2013 through December 2016) periods and\nbeneficiaries with the same episode (MJRLE or AMI) at a matched comparison\nhospital. Main Outcomes and Measures: Medicare payments, LOS, and readmissions\nduring the episode, which includes the anchor hospitalization and the 90-day\npost discharge period. Results: Mean total Medicare payments for an MJRLE\nepisode and the 90-day post discharge period declined $444 more (p < 0.0001)\nfor Medicare beneficiaries with episodes initiated in a BPCI-participating\nprovider than for the beneficiaries in a comparison provider. This reduction\nwas mainly due to reduced institutional post-acute care (PAC) payments. Slight\nreductions in carrier payments and LOS were estimated. Readmission rates were\nnot statistically different between the BPCI and the comparison populations.\nThese findings suggest that PAC use can be reduced without adverse effects on\nrecovery from MJRLE. The lack of statistically significant differences in\neffects for AMI could be explained by a smaller sample size or more\nheterogenous recovery paths in AMI. Conclusions: Our findings suggest that, as\ncurrently designed, bundled payments can be effective in reducing payments for\nMJRLE episodes of care, but not necessarily for AMI. Most savings came from the\ndeclines in PAC. These findings are consistent with the results reported in the\nBPCI model evaluation for CMS.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 22:18:03 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Kim", "Hyoshin", ""], ["McMillan", "Nancy", ""], ["Geppert", "Jeffrey", ""], ["Aume", "Laura", ""]]}, {"id": "2004.11267", "submitter": "Ramona Maraia", "authors": "Antti Solonen, Ramona Maraia, Sebastian Springer, Heikki Haario, Marko\n  Laine, Olle R\\\"aty, Jukka-Pekka Jalkanen, Matti Antola", "title": "Hierarchical Bayesian propulsion power models for marine vessels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing the magnitude of fuel consumption of marine traffic is a\nchallenging task. The consumption can be reduced by the ways the vessels are\noperated, to achieve both improved cost efficiency and reduced CO2 emissions.\nMathematical models for predicting ships' consumption are in a central role in\nboth of these tasks. Nowadays, many ships are equipped with data collection\nsystems, which enable data-based calibration of the consumption models.\nTypically this calibration procedure is carried out independently for each\nparticular ship, using only data collected from the ship in question. In this\npaper, we demonstrate a hierarchical Bayesian modeling approach, where we fit a\nsingle model over many vessels, with the assumption that the parameters of\nvessels of same type and similar characteristics (e.g. vessel size) are likely\nclose to each other. The benefits of such an approach are two-fold; 1) we can\nborrow information about parameters that are not well informed by the\nvessel-specific data using data from similar ships, and 2) we can use the final\nhierarchical model to predict the behavior of a vessel from which we don't have\nany data, based only on its characteristics. In this paper, we discuss the\nbasic concept and present a first simple version of the model. We apply the\nStan statistical modeling tool for the model fitting and use real data from 64\ncruise ships collected via the widely used commercial Eniram platform. By using\nBayesian statistical methods we obtain uncertainties for the model predictions,\ntoo. The prediction accuracy of the model is compared to an existing data-free\nmodeling approach.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 15:59:34 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 06:49:24 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Solonen", "Antti", ""], ["Maraia", "Ramona", ""], ["Springer", "Sebastian", ""], ["Haario", "Heikki", ""], ["Laine", "Marko", ""], ["R\u00e4ty", "Olle", ""], ["Jalkanen", "Jukka-Pekka", ""], ["Antola", "Matti", ""]]}, {"id": "2004.12716", "submitter": "Guy Nason Prof.", "authors": "Rebecca Killick, Marina I. Knight, Guy P. Nason and Idris A. Eckley", "title": "The Local Partial Autocorrelation Function and Some Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.ME stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical regular and partial autocorrelation functions are powerful\ntools for stationary time series modelling and analysis. However, it is\nincreasingly recognized that many time series are not stationary and the use of\nclassical global autocorrelations can give misleading answers. This article\nintroduces two estimators of the local partial autocorrelation function and\nestablishes their asymptotic properties. The article then illustrates the use\nof these new estimators on both simulated and real time series. The examples\nclearly demonstrate the strong practical benefits of local estimators for time\nseries that exhibit nonstationarities.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 11:32:05 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Killick", "Rebecca", ""], ["Knight", "Marina I.", ""], ["Nason", "Guy P.", ""], ["Eckley", "Idris A.", ""]]}]