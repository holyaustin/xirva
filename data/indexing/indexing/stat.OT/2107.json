[{"id": "2107.01060", "submitter": "Trystan Surawy-Stepney", "authors": "Trystan Surawy-Stepney, Jonas Kahn, Richard Kueng, Madalin Guta", "title": "Projected Least-Squares Quantum Process Tomography", "comments": "13+9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph math-ph math.MP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and investigate a new method of quantum process tomography (QPT)\nwhich we call projected least squares (PLS). In short, PLS consists of first\ncomputing the least-squares estimator of the Choi matrix of an unknown channel,\nand subsequently projecting it onto the convex set of Choi matrices. We\nconsider four experimental setups including direct QPT with Pauli eigenvectors\nas input and Pauli measurements, and ancilla-assisted QPT with mutually\nunbiased bases (MUB) measurements. In each case, we provide a closed form\nsolution for the least-squares estimator of the Choi matrix. We propose a\nnovel, two-step method for projecting these estimators onto the set of matrices\nrepresenting physical quantum channels, and a fast numerical implementation in\nthe form of the hyperplane intersection projection algorithm. We provide\nrigorous, non-asymptotic concentration bounds, sampling complexities and\nconfidence regions for the Frobenius and trace-norm error of the estimators.\nFor the Frobenius error, the bounds are linear in the rank of the Choi matrix,\nand for low ranks, they improve the error rates of the least squares estimator\nby a factor $d^2$, where $d$ is the system dimension. We illustrate the method\nwith numerical experiments involving channels on systems with up to 7 qubits,\nand find that PLS has highly competitive accuracy and computational\ntractability.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 13:13:13 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Surawy-Stepney", "Trystan", ""], ["Kahn", "Jonas", ""], ["Kueng", "Richard", ""], ["Guta", "Madalin", ""]]}, {"id": "2107.02522", "submitter": "Yudi Pawitan", "authors": "Yudi Pawitan", "title": "A nonBayesian view of Hempel's paradox of the ravens", "comments": "10 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Hempel's paradox of the ravens, seeing a red pencil is considered as\nsupporting evidence that all ravens are black. Also known as the Paradox of\nConfirmation, the paradox and its many resolutions indicate that we cannot\nunderestimate the logical and statistical elements needed in the assessment of\nevidence in support of a hypothesis. Most of the previous analyses of the\nparadox are within the Bayesian framework. These analyses and Hempel himself\ngenerally accept the paradoxical conclusion; it feels paradoxical supposedly\nbecause the amount of evidence is extremely small. Here I describe a\nnonBayesian analysis of various statistical models with an accompanying\nlikelihood-based reasoning. The analysis shows that the paradox feels\nparadoxical because there are natural models where observing a red pencil has\nno relevance to the color of ravens. In general the value of the evidence\ndepends crucially on the sampling scheme and on the assumption about the\nunderlying parameters of the relevant model.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 10:28:50 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 09:45:42 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Pawitan", "Yudi", ""]]}, {"id": "2107.02537", "submitter": "Alfredo Egidio dos Reis", "authors": "Yacine Koucha and Alfredo D. Egidio dos Reis", "title": "Approximations to ultimate ruin probabilities with a Wienner process\n  perturbation", "comments": "Master dissertation work, 18 pages, 4 figures, 8 numerical tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM math.PR q-fin.ST stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we adapt the classic Cram\\'er-Lundberg collective risk theory\nmodel to a perturbed model by adding a Wiener process to the compound Poisson\nprocess, which can be used to incorporate premium income uncertainty, interest\nrate fluctuations and changes in the number of policyholders. Our study is part\nof a Master dissertation, our aim is to make a short overview and present\nadditionally some new approximation methods for the infinite time ruin\nprobabilities for the perturbed risk model. We present four different\napproximation methods for the perturbed risk model. The first method is based\non iterative upper and lower approximations to the maximal aggregate loss\ndistribution. The second method relies on a four-moment exponential De Vylder\napproximation. The third method is based on the first-order Pad\\'e\napproximation of the Renyi and De Vylder approximations. The last method is the\nsecond order Pad\\'e-Ramsay approximation. These are generated by fitting one,\ntwo, three or four moments of the claim amount distribution, which greatly\ngeneralizes the approximations. We test the precision of approximations using a\ncombination of light and heavy tailed distributions for the individual claim\namount. We assess the ultimate ruin probability and present numerical results\nfor the exponential, gamma, and mixed exponential claim distributions,\ndemonstrating the high accuracy of these four methods. Analytical and numerical\nmethods are used to highlight the practical implications of our findings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 11:06:05 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Koucha", "Yacine", ""], ["Reis", "Alfredo D. Egidio dos", ""]]}, {"id": "2107.03249", "submitter": "Christoph Gerlinger", "authors": "Sarah B\\\"ohme, Christoph Gerlinger, Susanne Huschens, Annett Kucka,\n  Niclas K\\\"urschner, Friedhelm Leverkus, Michael Schlichting, Waldemar\n  Siemens, Kati Sternberg, Liping Hofmann-Xu", "title": "Patient-reported outcomes in the context of the benefit assessment in\n  Germany", "comments": "46 pages, 3 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.OT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Since the 2011 Act on the Reform of the Market for Medicinal Products,\nbenefit dossiers are submitted by pharmaceutical companies to facilitate the\nHealth Technology Assessment (HTA) appraisals in Germany. The Institute for\nQuality and Efficiency in Health Care conducts the added benefit assessment\nfollowing their General Methods Paper, which was updated November 5, 2020. This\nWhite Paper is dedicated to patient-reported outcomes (PRO) to highlight their\nimportance for the added benefit assessment. We focus on methodological aspects\nbut consider also other relevant requirements and challenges, which are\ndemanded by G-BA and IQWiG. The following topics will be presented and\ndiscussed: 1. Role of PRO in HTA decision making exemplary to benefit\nassessment in Germany 2. Guidances of PRO evaluations 3. PRO Estimand framework\n4. Perception and requirements for PRO within the German benefit assessment 5.\nValidity of instrument 6. Response thresholds for assessing clinical relevance\nof PRO 7. PRO endpoints / outcome measures / operationalization 8. Missing PRO\ndata 9. PRO after treatment discontinuation This White Paper aims to provide\ndeeper insights about new requirements concerning PRO evaluations for HTA\ndecision making in Germany, highlight points to consider that should inform\nglobal development in terms of study planning and frame the requirements also\nin the context of global recommendations and guidelines. We also aim to enhance\nthe understanding of the complexity when preparing the benefit dossier and\npromote further scientific discussions where appropriate.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:26:49 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 08:03:31 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["B\u00f6hme", "Sarah", ""], ["Gerlinger", "Christoph", ""], ["Huschens", "Susanne", ""], ["Kucka", "Annett", ""], ["K\u00fcrschner", "Niclas", ""], ["Leverkus", "Friedhelm", ""], ["Schlichting", "Michael", ""], ["Siemens", "Waldemar", ""], ["Sternberg", "Kati", ""], ["Hofmann-Xu", "Liping", ""]]}, {"id": "2107.05145", "submitter": "David Schneider", "authors": "David C. Schneider (Department of Ocean Sciences, Memorial University,\n  St. John's NL A1C5S7 Canada), Roy Thompson (5 College Drive, Tunbridge Wells,\n  Kent, TN2 3PN UK)", "title": "Discovery of Bayes' Table at Tunbridge Wells", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT physics.data-an", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In 1755 Thomas Bayes expressed an interest in the problem of combining\nrepeated measurements of the location of a star. Bayes described a tandem\nset-up of a ball thrown on a table, followed by repeated throws of a second\nball. Bayes' table has long been taken as a billiard table, for which there is\nno evidence. We report the discovery of Bayes' table, a bowling green located\nhalf a km uphill (SE) from the meeting house where Bayes served as minister for\ntwo decades. Bayes' drawing shows a rectangular space marked off in yards,\nwhich allows calculation of an interval measurement of uncertainty. The Bayes\nrule interval from 2.5% to 97.5% is from 0.56 - 0.42 = 0.12 perches equivalent\nto 0.61 m. The discovery of Bayes' table establishes the physical basis for\nBayes' symmetrical probability model, a fixed parameter binomial ({\\theta} =\n0.5). The discovery establishes Bayes as the founder of statistical science,\ndefined as the application of mathematics to scientific measurement.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 23:37:00 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Schneider", "David C.", "", "Department of Ocean Sciences, Memorial University,\n  St. John's NL A1C5S7 Canada"], ["Thompson", "Roy", "", "5 College Drive, Tunbridge Wells,\n  Kent, TN2 3PN UK"]]}, {"id": "2107.06223", "submitter": "Sara Lopes De Moraes", "authors": "Sara Lopes de Moraes, Ricardo Almendra, Ligia Vizeu Barrozo", "title": "Impact of heat waves and cold spells on cause-specific mortality in the\n  city of Sao Paulo, Brazil", "comments": "28 pages, 2 tables, and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.OT", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The impact of heat waves and cold spells on mortality has become a major\npublic health problem worldwide, especially among older adults living in low-\nto middle-income countries. This study aimed to investigate the effects of heat\nwaves and cold spells under different definitions on cause-specific mortality\namong people aged 65 years and over in Sao Paulo from 2006 to 2015. A\nquasi-Poisson generalized linear model with a distributed lag model was used to\ninvestigate the association between cause-specific mortality and extreme air\ntemperature events. To evaluate the effects of the intensity under different\ndurations, we considered 12 heat wave and nine cold spell definitions. Our\nresults showed an increase in cause-specific deaths related to heat waves and\ncold spells under several definitions. The highest risk of death related to\nheat waves was identified mostly at higher temperature thresholds with longer\nevents. We verified that men were more vulnerable to die from an ischemic\nstroke on heat waves and cold spells days than women, while women presented a\nhigher risk of dying from ischemic heart diseases during cold spells and tended\nto have a higher risk of chronic obstructive pulmonary disease than men.\nIdentification of heat wave- and cold spell-related mortality is important for\nthe development and promotion of public health measures.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 16:23:05 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["de Moraes", "Sara Lopes", ""], ["Almendra", "Ricardo", ""], ["Barrozo", "Ligia Vizeu", ""]]}, {"id": "2107.13894", "submitter": "Lorenzo Trapani", "authors": "Matteo Barigozzi, Giuseppe Cavaliere, Lorenzo Trapani", "title": "Inference in heavy-tailed non-stationary multivariate time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.EM stat.OT", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We study inference on the common stochastic trends in a non-stationary,\n$N$-variate time series $y_{t}$, in the possible presence of heavy tails. We\npropose a novel methodology which does not require any knowledge or estimation\nof the tail index, or even knowledge as to whether certain moments (such as the\nvariance) exist or not, and develop an estimator of the number of stochastic\ntrends $m$ based on the eigenvalues of the sample second moment matrix of\n$y_{t}$. We study the rates of such eigenvalues, showing that the first $m$\nones diverge, as the sample size $T$ passes to infinity, at a rate faster by\n$O\\left(T \\right)$ than the remaining $N-m$ ones, irrespective of the tail\nindex. We thus exploit this eigen-gap by constructing, for each eigenvalue, a\ntest statistic which diverges to positive infinity or drifts to zero according\nto whether the relevant eigenvalue belongs to the set of the first $m$\neigenvalues or not. We then construct a randomised statistic based on this,\nusing it as part of a sequential testing procedure, ensuring consistency of the\nresulting estimator of $m$. We also discuss an estimator of the common trends\nbased on principal components and show that, up to a an invertible linear\ntransformation, such estimator is consistent in the sense that the estimation\nerror is of smaller order than the trend itself. Finally, we also consider the\ncase in which we relax the standard assumption of \\textit{i.i.d.} innovations,\nby allowing for heterogeneity of a very general form in the scale of the\ninnovations. A Monte Carlo study shows that the proposed estimator for $m$\nperforms particularly well, even in samples of small size. We complete the\npaper by presenting four illustrative applications covering commodity prices,\ninterest rates data, long run PPP and cryptocurrency markets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 11:02:30 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Barigozzi", "Matteo", ""], ["Cavaliere", "Giuseppe", ""], ["Trapani", "Lorenzo", ""]]}, {"id": "2107.14055", "submitter": "Golnaz Shahtahmassebi", "authors": "Golnaz Shahtahmassebi and Lascelles Wright", "title": "Profit and loss manipulations by online trading brokers", "comments": "20 pages, 7 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR stat.OT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Online trading has attracted millions of people around the world. In March\n2021, it was reported there were 18 million accounts from just one broker.\nHistorically, manipulation in financial markets is considered to be\nfraudulently influencing share, currency pairs or any other indices prices.\nThis article introduces the idea that online trading platform technical issues\ncan be considered as brokers manipulation to control traders profit and loss.\nMore importantly it shows these technical issues are the contributing factors\nof the 82% risk of retail traders losing money. We identify trading platform\ntechnical issues of one of the world's leading online trading providers and\ncalculate retail traders losses caused by these issues. To do this, we\nindependently record each trade details using the REST API response provided by\nthe broker. We show traders log activity files is the only way to assess any\nsuspected profit or loss manipulation by the broker. Therefore, it is essential\nfor any retail trader to have access to their log files. We compare our\nfindings with broker's Trustpilot customer reviews. We illustrate how traders'\nprofit and loss can be negatively affected by broker's platform technical\nissues such as not being able to close profitable trades, closing trades with\ndelays, disappearance of trades, disappearance of profit from clients\nstatements, profit and loss discrepancies, stop loss not being triggered, stop\nloss or limit order triggered too early. Although regulatory bodies try to\nensure that consumers get a fair deal, these attempts are hugely insufficient\nin protecting retail traders. Therefore, regulatory bodies such as the FCA\nshould take these technical issues seriously and not rely on brokers' internal\ninvestigations, because under any other circumstances, these platform\nmanipulations would be considered as crimes and connivingly misappropriating\nfunds.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 14:47:44 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Shahtahmassebi", "Golnaz", ""], ["Wright", "Lascelles", ""]]}]