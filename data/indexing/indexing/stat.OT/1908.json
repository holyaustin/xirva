[{"id": "1908.04670", "submitter": "Bo-Qiang Ma", "authors": "Mingshu Cong, Bo-Qiang Ma", "title": "A Proof of First Digit Law from Laplace Transform", "comments": "13 latex pages, 2 figures, final version for publication", "journal-ref": "Chin.Phys.Lett.36 (2019) 070201", "doi": "10.1088/0256-307X/36/7/070201", "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first digit law, also known as Benford's law or the significant digit\nlaw, is an empirical phenomenon that the leading digit of numbers from real\nworld sources favors small ones in a form $\\log(1+{1}/{d})$, where $d=1, 2,\n..., 9$. Such a law keeps elusive for over one hundred years because it was\nobscure whether this law is due to the logical consequence of the number system\nor some mysterious mechanism of the nature. We provide a simple and elegant\nproof of this law from the application of the Laplace transform, which is an\nimportant tool of mathematical methods in physics. We reveal that the first\ndigit law is originated from the basic property of the number system, thus it\nshould be attributed as a basic mathematical knowledge for wide applications.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 14:38:40 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Cong", "Mingshu", ""], ["Ma", "Bo-Qiang", ""]]}, {"id": "1908.06346", "submitter": "Julio Stern", "authors": "Julio Michael Stern", "title": "Karl Pearson and the Logic of Science: Renouncing Causal Understanding\n  (the Bride) and Inverted Spinozism", "comments": null, "journal-ref": "South American Journal of Logic, v.4, n.1, pp.219-252, 2018", "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Karl Pearson is the leading figure of XX century statistics. He and his\nco-workers crafted the core of the theory, methods and language of frequentist\nor classical statistics -- the prevalent inductive logic of contemporary\nscience. However, before working in statistics, K.Pearson had other interests\nin life, namely, in this order, philosophy, physics, and biological heredity.\nKey concepts of his philosophical and epistemological system of anti-Spinozism\n(a form of transcendental idealism) are carried over to his subsequent works on\nthe logic of scientific discovery. This article's main goal is to analyze\nK.Pearson early philosophical and theological ideas and to investigate how the\nsame ideas came to influence contemporary science, either directly or\nindirectly -- by the use of variant theories, methods and dialects of\nstatistics, corresponding to variant statistical inference procedures and their\nspecific belief calculi.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2019 23:07:14 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Stern", "Julio Michael", ""]]}, {"id": "1908.06934", "submitter": "Guillaume Marrelec", "authors": "Guillaume Marrelec, Alain Giron", "title": "Cumulants of multiinformation density in the case of a multivariate\n  normal distribution", "comments": null, "journal-ref": "Statistics and Probability Letters 156, 108587 (2020)", "doi": "10.1016/j.spl.2019.108587", "report-no": null, "categories": "math.ST cs.IT math.IT stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a generalization of information density to a partitioning into $N\n\\geq 2$ subvectors. We calculate its cumulant-generating function and its\ncumulants, showing that these quantities are only a function of all the\nregression coefficients associated with the partitioning.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 17:12:54 GMT"}, {"version": "v2", "created": "Wed, 13 Nov 2019 10:39:14 GMT"}], "update_date": "2019-11-14", "authors_parsed": [["Marrelec", "Guillaume", ""], ["Giron", "Alain", ""]]}, {"id": "1908.07372", "submitter": "Santosh Kumar Radha", "authors": "Santosh Kumar Radha", "title": "Stochastic differential theory of cricket", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph math.PR stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new formalism for analyzing the progression of cricket game using\nStochastic differential equation (SDE) is introduced. This theory enables a\nquantitative way of representing every team using three key variables which\nhave physical meaning associated with them. This is in contrast with the\ntraditional system of rating/ranking teams based on combination of different\nstatical cumulants. Further more, using this formalism, a new method to\ncalculate the winning probability as a progression of number of balls is given.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 14:59:35 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Radha", "Santosh Kumar", ""]]}, {"id": "1908.07521", "submitter": "Sreejith Sreekumar Dr", "authors": "Sreejith Sreekumar and Deniz Gunduz", "title": "Distributed Hypothesis Testing over a Noisy Channel: Error-exponents\n  Trade-off", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A two-terminal distributed binary hypothesis testing (HT) problem over a\nnoisy channel is studied. The two terminals, called the observer and the\ndecision maker, each has access to $n$ independent and identically distributed\nsamples, denoted by $\\mathbf{U}$ and $\\mathbf{V}$, respectively. The observer\ncommunicates to the decision maker over a discrete memoryless channel (DMC),\nand the decision maker performs a binary hypothesis test on the joint\nprobability distribution of $(\\mathbf{U},\\mathbf{V})$ based on $\\mathbf{V}$ and\nthe noisy information received from the observer. The trade-off between the\nexponents of the type I and type II error probabilities in HT is investigated.\nTwo inner bounds are obtained, one using a separation-based scheme that\ninvolves type-based compression and unequal error-protection channel coding,\nand the other using a joint scheme that incorporates type-based hybrid coding.\nThe separation-based scheme is shown to recover the inner bound obtained by Han\nand Kobayashi for the special case of a rate-limited noiseless channel, and\nalso the one obtained by the authors previously for a corner point of the\ntrade-off. Exact single-letter characterization of the optimal trade-off is\nestablished for the special case of testing for the marginal distribution of\n$\\mathbf{U}$, when $\\mathbf{V}$ is unavailable. Our results imply that a\nseparation holds in this case, in the sense that the optimal trade-off is\nachieved by a scheme that performs independent HT and channel coding. Finally,\nwe show via an example that the joint scheme achieves a strictly tighter bound\nthan the separation-based scheme for some points of the error-exponent\ntrade-off.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 16:21:09 GMT"}, {"version": "v2", "created": "Sat, 2 May 2020 02:27:30 GMT"}, {"version": "v3", "created": "Tue, 5 May 2020 02:02:20 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Sreekumar", "Sreejith", ""], ["Gunduz", "Deniz", ""]]}, {"id": "1908.08991", "submitter": "Taha Yasseri", "authors": "Victor Martins Maimone and Taha Yasseri", "title": "Football is becoming boring; Network analysis of 88 thousands matches in\n  11 major leagues", "comments": "Preprint under review: 7 pages + Supporting Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SI stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Football is a major sport with worldwide popularity. In recent years\nexcessive monetization of the game has been argued to have affected the quality\nof the match in different ways. In one hand playing football has become a high\nincome profession and the players are highly motivated to perform well; on the\nother hand stronger teams have higher income and therefore they can afford\nbetter and more expensive players leading to even stronger appearance in\ntournaments that can make the game more imbalanced and hence predictable. In\nthis work we take a data-heavy network science approach to measure\npredictability of football over 26 years in major European leagues. We\nbenchmark our model against betting house predictions and after establishing\nits robustness we show that over time, the games in major leagues have become\nmore predictable. We provide further support for this observation by showing\nthat inequality between teams has increased in accord with the trends in\npredictability and the home field advantage has been vanishing ubiquitously.\nThis is a first attempt to study football at a large scale and within a\nhistorical framework.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 19:25:02 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Maimone", "Victor Martins", ""], ["Yasseri", "Taha", ""]]}, {"id": "1908.09431", "submitter": "Weijian Liu", "authors": "Weijian Liu, Jun Liu, Yongchan Gao, Guoshi Wang, Yong-Liang Wang", "title": "Multichannel signal detection in interference and noise when signal\n  mismatch happens", "comments": null, "journal-ref": null, "doi": "10.1016/j.sigpro.2019.107268", "report-no": null, "categories": "eess.SP stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of detecting a multichannel signal in\ninterference and noise when signal mismatch happens. We first propose two\nselective detectors, since their strong selectivity is preferred in some\nsituations. However, these two detectors would not be suitable candidates if a\nrobust detector is needed. To overcome this shortcoming, we then devise a\ntunable detector, which is parametrized by a non-negative scaling factor,\nreferred to as the tunable parameter. By adjusting the tunable parameter, the\nproposed detector can smoothly change its capability in rejecting or robustly\ndetecting a mismatch signal. Moreover, one selective detector and the tunable\ndetector with an appropriate tunable parameter can provide nearly the same\ndetection performance as existing detectors in the absence of signal mismatch.\nWe obtain analytical expressions for the probabilities of detection (PDs) and\nprobabilities of false alarm (PFAs) of the three proposed detectors, which are\nverified by Monte Carlo simulations.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 01:46:19 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Liu", "Weijian", ""], ["Liu", "Jun", ""], ["Gao", "Yongchan", ""], ["Wang", "Guoshi", ""], ["Wang", "Yong-Liang", ""]]}, {"id": "1908.09830", "submitter": "Adrian Dobra", "authors": "Zhihang Dong, Yen-Chi Chen and Adrian Dobra", "title": "A statistical framework for measuring the temporal stability of human\n  mobility patterns", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT physics.soc-ph stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the growing popularity of human mobility studies that collect GPS\nlocation data, the problem of determining the minimum required length of GPS\nmonitoring has not been addressed in the current statistical literature. In\nthis paper we tackle this problem by laying out a theoretical framework for\nassessing the temporal stability of human mobility based on GPS location data.\nWe define several measures of the temporal dynamics of human spatiotemporal\ntrajectories based on the average velocity process, and on activity\ndistributions in a spatial observation window. We demonstrate the use of our\nmethods with data that comprise the GPS locations of 185 individuals over the\ncourse of 18 months. Our empirical results suggest that GPS monitoring should\nbe performed over periods of time that are significantly longer than what has\nbeen previously suggested. Furthermore, we argue that GPS study designs should\ntake into account demographic groups.\n  KEYWORDS: Density estimation; global positioning systems (GPS); human\nmobility; spatiotemporal trajectories; temporal dynamics\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 18:35:01 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Dong", "Zhihang", ""], ["Chen", "Yen-Chi", ""], ["Dobra", "Adrian", ""]]}, {"id": "1908.10024", "submitter": "Wenpin Tang", "authors": "Wenpin Tang and Fengmin Tang", "title": "The Poisson binomial distribution -- Old & New", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an expository article on the Poisson binomial distribution. We review\nlesser known results and recent progress on this topic, including geometry of\npolynomials and distribution learning. We also provide examples to illustrate\nthe use of the Poisson binomial machinery. Some open questions of approximating\nrational fractions of the Poisson binomial are presented.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 04:38:23 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Tang", "Wenpin", ""], ["Tang", "Fengmin", ""]]}, {"id": "1908.10971", "submitter": "Fan Tian", "authors": "Fan Tian, Tam\\'as Budav\\'ari, Amitabh Basu, Stephen H. Lubow, Richard\n  L. White", "title": "Robust Registration of Astronomy Catalogs with Applications to the\n  Hubble Space Telescope", "comments": null, "journal-ref": null, "doi": "10.3847/1538-3881/ab3f38", "report-no": null, "categories": "astro-ph.IM stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Astrometric calibration of images with a small field of view is often\ninferior to the internal accuracy of the source detections due to the small\nnumber of accessible guide stars. One important experiment with such challenges\nis the Hubble Space Telescope (HST). A possible solution is to cross-calibrate\noverlapping fields instead of just relying on standard stars. Following the\napproach of \\citet{2012ApJ...761..188B}, we use infinitesimal 3D rotations for\nfine-tuning the calibration but devise a better objective that is robust to a\nlarge number of false candidates in the initial set of associations. Using\nBayesian statistics, we accommodate bad data by explicitly modeling the\nquality, which yields a formalism essentially identical to an $M$-estimation in\nrobust statistics. Our results on simulated and real catalogs show great\npotentials for improving the HST calibration, and those with similar\nchallenges.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 22:20:02 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Tian", "Fan", ""], ["Budav\u00e1ri", "Tam\u00e1s", ""], ["Basu", "Amitabh", ""], ["Lubow", "Stephen H.", ""], ["White", "Richard L.", ""]]}, {"id": "1908.11364", "submitter": "Jean-Philippe Montillet Dr.", "authors": "Machiel S. Bos, Jean-Philippe Montillet, Simon D.P. Williams, Rui M.S.\n  Fernandes", "title": "Introduction to Geodetic Time Series Analysis", "comments": "24 pages, 6 figures; Chapter 2 in the Book Geodetic Time Series\n  Analysis edited by J.P. Montillet and M. S. Bos", "journal-ref": null, "doi": "10.1007/978-3-030-21718-1_2", "report-no": null, "categories": "stat.OT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This contribution is the chapter 2 of the book \"geodetic time series\nanalysis\" (10.1007/978-3-030-21718-1). The book is dedicated to the art of\nfitting a trajectory model to those geodetic time series in order to extract\naccurate geophysical information with realistic error bars in geodymanics and\nenvironmental geodesy related studies. In the vast amount of the literature\npublished on this topic in the past 25 years, we are specifically interested in\nparametric algorithms which are estimating both functional and stochastic\nmodels using various Bayesian statistical tools (maximum likelihood, Monte\nCarlo Markov chain, Kalman filter, least squares variance component estimation,\ninformation criteria). This chapter will focus on how the parameters of the\ntrajectory model can be estimated. It is meant to give researchers new to this\ntopic an easy introduction to the theory with references to key books and\narticles where more details can be found. In addition, we hope that it\nrefreshes some of the details for the more experienced readers. We pay special\nattention to the modelling of the noise which has received much attention in\nthe literature in the last years and highlight some of the numerical aspects.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 20:24:50 GMT"}], "update_date": "2019-08-30", "authors_parsed": [["Bos", "Machiel S.", ""], ["Montillet", "Jean-Philippe", ""], ["Williams", "Simon D. P.", ""], ["Fernandes", "Rui M. S.", ""]]}]