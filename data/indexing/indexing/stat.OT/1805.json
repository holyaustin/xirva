[{"id": "1805.01291", "submitter": "Stephane Blondeau da Silva", "authors": "St\\'ephane Blondeau da Silva (XLIM-MATHIS)", "title": "Benford or not Benford: new results on digits beyond the first", "comments": "arXiv admin note: substantial text overlap with arXiv:1804.06186", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will see that the proportion of d as p th digit, where p >\n1 and d $\\in$ 0, 9, in data (obtained thanks to the hereunder developed model)\nis more likely to follow a law whose probability distribution is determined by\na specific upper bound, rather than the generalization of Benford's Law to\ndigits beyond the first one. These probability distributions fluctuate around\ntheoretical values determined by Hill in 1995. Knowing beforehand the value of\nthe upper bound can be a way to find a better adjusted law than Hill's one.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 09:49:27 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["da Silva", "St\u00e9phane Blondeau", "", "XLIM-MATHIS"]]}, {"id": "1805.01345", "submitter": "Yaakov Malinovsky", "authors": "Yaakov Malinovsky", "title": "Conjectures on Optimal Nested Generalized Group Testing Algorithm", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a finite population of $N$ items, where item $i$ has a probability\n$p_i$ to be defective. The goal is to identify all items by means of group\ntesting. This is the generalized group testing problem (hereafter GGTP). In the\ncase of $\\displaystyle p_1=\\cdots=p_{N}=p$ \\cite{YH1990} proved that the\npairwise testing algorithm is the optimal nested algorithm, with respect to the\nexpected number of tests, for all $N$ if and only if $\\displaystyle p \\in\n[1-1/\\sqrt{2},\\,(3-\\sqrt{5})/2]$ (R-range hereafter) (an optimal at the\nboundary values). In this note, we present a result that helps to define the\ngeneralized pairwise testing algorithm (hereafter GPTA) for the GGTP. We\npresent two conjectures: (1) when all $p_i, i=1,\\ldots,N$ belong to the\nR-range, GPTA is the optimal procedure among nested procedures applied to $p_i$\nof nondecreasing order; (2) if all $p_i, i=1,\\ldots,N$ belong to the R-range,\nGPTA the optimal nested procedure, i.e., minimises the expected total number of\ntests with respect to all possible testing orders in the class of nested\nprocedures. Although these conjectures are logically reasonable, we were only\nable to empirically verify the first one up to a particular level of $N$. We\nalso provide a short survey of GGTP.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 14:56:43 GMT"}, {"version": "v2", "created": "Wed, 12 Sep 2018 15:45:20 GMT"}, {"version": "v3", "created": "Thu, 27 Feb 2020 12:49:46 GMT"}], "update_date": "2020-02-28", "authors_parsed": [["Malinovsky", "Yaakov", ""]]}, {"id": "1805.01834", "submitter": "Steffen Unkel PD Dr.", "authors": "Steffen Unkel, Marjan Amiri, Norbert Benda, Jan Beyersmann, Dietrich\n  Knoerzer, Katrin Kupas, Frank Langer, Friedhelm Leverkus, Anja Loos, Claudia\n  Ose, Tanja Proctor, Claudia Schmoor, Carsten Schwenke, Guido Skipka, Kristina\n  Unnebrink, Florian Voss, Tim Friede", "title": "On estimands and the analysis of adverse events in the presence of\n  varying follow-up times within the benefit assessment of therapies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of adverse events (AEs) is a key component in the assessment of\na drug's safety profile. Inappropriate analysis methods may result in\nmisleading conclusions about a therapy's safety and consequently its\nbenefit-risk ratio. The statistical analysis of AEs is complicated by the fact\nthat the follow-up times can vary between the patients included in a clinical\ntrial. This paper takes as its focus the analysis of AE data in the presence of\nvarying follow-up times within the benefit assessment of therapeutic\ninterventions. Instead of approaching this issue directly and solely from an\nanalysis point of view, we first discuss what should be estimated in the\ncontext of safety data, leading to the concept of estimands. Although the\ncurrent discussion on estimands is mainly related to efficacy evaluation, the\nconcept is applicable to safety endpoints as well. Within the framework of\nestimands, we present statistical methods for analysing AEs with the focus\nbeing on the time to the occurrence of the first AE of a specific type. We give\nrecommendations which estimators should be used for the estimands described.\nFurthermore, we state practical implications of the analysis of AEs in clinical\ntrials and give an overview of examples across different indications. We also\nprovide a review of current practices of health technology assessment (HTA)\nagencies with respect to the evaluation of safety data. Finally, we describe\nproblems with meta-analyses of AE data and sketch possible solutions.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 16:03:37 GMT"}, {"version": "v2", "created": "Fri, 21 Sep 2018 08:28:51 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Unkel", "Steffen", ""], ["Amiri", "Marjan", ""], ["Benda", "Norbert", ""], ["Beyersmann", "Jan", ""], ["Knoerzer", "Dietrich", ""], ["Kupas", "Katrin", ""], ["Langer", "Frank", ""], ["Leverkus", "Friedhelm", ""], ["Loos", "Anja", ""], ["Ose", "Claudia", ""], ["Proctor", "Tanja", ""], ["Schmoor", "Claudia", ""], ["Schwenke", "Carsten", ""], ["Skipka", "Guido", ""], ["Unnebrink", "Kristina", ""], ["Voss", "Florian", ""], ["Friede", "Tim", ""]]}, {"id": "1805.05090", "submitter": "Lukas Lehnert", "authors": "Lukas W. Lehnert, Hanna Meyer, Wolfgang A. Obermeier, Brenner Silva,\n  Bianca Regeling, J\\\"org Bendix", "title": "Hyperspectral Data Analysis in R: the hsdar Package", "comments": null, "journal-ref": null, "doi": "10.18637/jss.v089.i12", "report-no": null, "categories": "stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hyperspectral remote sensing is a promising tool for a variety of\napplications including ecology, geology, analytical chemistry and medical\nresearch. This article presents the new \\hsdar package for R statistical\nsoftware, which performs a variety of analysis steps taken during a typical\nhyperspectral remote sensing approach. The package introduces a new class for\nefficiently storing large hyperspectral datasets such as hyperspectral cubes\nwithin R. The package includes several important hyperspectral analysis tools\nsuch as continuum removal, normalized ratio indices and integrates two widely\nused radiation transfer models. In addition, the package provides methods to\ndirectly use the functionality of the caret package for machine learning tasks.\nTwo case studies demonstrate the package's range of functionality: First, plant\nleaf chlorophyll content is estimated and second, cancer in the human larynx is\ndetected from hyperspectral data.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 09:57:25 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Lehnert", "Lukas W.", ""], ["Meyer", "Hanna", ""], ["Obermeier", "Wolfgang A.", ""], ["Silva", "Brenner", ""], ["Regeling", "Bianca", ""], ["Bendix", "J\u00f6rg", ""]]}, {"id": "1805.07580", "submitter": "Aleksey Polunchenko", "authors": "Aleksey S. Polunchenko and Andrey Pepelyshev", "title": "Analytic moment and Laplace transform formulae for the quasi-stationary\n  distribution of the Shiryaev diffusion on an interval", "comments": "24 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive analytic closed-form moment and Laplace transform formulae for the\nquasi-stationary distribution of the classical Shiryaev diffusion restricted to\nthe interval $[0,A]$ with absorption at a given $A>0$.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 12:17:51 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Polunchenko", "Aleksey S.", ""], ["Pepelyshev", "Andrey", ""]]}, {"id": "1805.11012", "submitter": "Ernest Fokoue", "authors": "Ernest Fokoue", "title": "To Bayes or Not To Bayes? That's no longer the question!", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper seeks to provide a thorough account of the ubiquitous nature of\nthe Bayesian paradigm in modern statistics, data science and artificial\nintelligence. Once maligned, on the one hand by those who philosophically hated\nthe very idea of subjective probability used in prior specification, and on the\nother hand because of the intractability of the computations needed for\nBayesian estimation and inference, the Bayesian school of thought now permeates\nand pervades virtually all areas of science, applied science, engineering,\nsocial science and even liberal arts, often in unsuspected ways. Thanks in part\nto the availability of powerful computing resources, but also to the literally\nunavoidable inherent presence of the quintessential building blocks of the\nBayesian paradigm in all walks of life, the Bayesian way of handling\nstatistical learning, estimation and inference is not only mainstream but also\nbecoming the most central approach to learning from the data. This paper\nexplores some of the most relevant elements to help to the reader appreciate\nthe pervading power and presence of the Bayesian paradigm in statistics,\nartificial intelligence and data science, with an emphasis on how the Gospel\naccording to Reverend Thomas Bayes has turned out to be the truly good news,\nand some cases the amazing saving grace, for all who seek to learn\nstatistically from the data. To further help the reader gain deeper and\ntangible practical insights into the Bayesian machinery, we point to some\ncomputational tools designed for the R Statistical Software Environment to help\nexplore Bayesian statistical learning.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:12:18 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Fokoue", "Ernest", ""]]}, {"id": "1805.11516", "submitter": "V. J.  Vieland", "authors": "Veronica J. Vieland", "title": "Absolutely Zero Evidence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical analysis is often used to evaluate the evidence for or against\nscientific hypotheses, and various statistics (e.g., p-values, likelihood\nratios, Bayes factors) are interpreted as measures of evidence strength. Here I\nconsider evidence measurement from the point of view of representational\nmeasurement theory, and argue that familiar evidence statistics do not conform\nto any legitimate measurement scale type. I then consider the notion of an\nabsolute scale for evidence measurement, in a sense to be defined, focusing\nparticularly on the notion of absolute 0 evidence, which turns out to be\nsomething other than what one might have expected.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 14:50:04 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Vieland", "Veronica J.", ""]]}, {"id": "1805.12052", "submitter": "Benjamin Francis", "authors": "Benjamin L. Francis, Mark K. Transtrum", "title": "Unwinding the model manifold: choosing similarity measures to remove\n  local minima in sloppy dynamical systems", "comments": "16 pages, 14 figures, supplementary material merged with main article", "journal-ref": "Phys. Rev. E 100, 012206 (2019)", "doi": "10.1103/PhysRevE.100.012206", "report-no": null, "categories": "cond-mat.stat-mech nlin.CD physics.data-an stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of parameter sensitivity in models of\ncomplex dynamical systems through the lens of information geometry. We\ncalculate the sensitivity of model behavior to variations in parameters. In\nmost cases, models are sloppy, that is, exhibit an exponential hierarchy of\nparameter sensitivities. We propose a parameter classification scheme based on\nhow the sensitivities scale at long observation times. We show that for\noscillatory models, either with a limit cycle or a strange attractor,\nsensitivities can become arbitrarily large, which implies a high\neffective-dimensionality on the model manifold. Sloppy models with a single\nfixed point have model manifolds with low effective-dimensionality, previously\ndescribed as a \"hyper-ribbon\". In contrast, models with high effective\ndimensionality translate into multimodal fitting problems. We define a measure\nof curvature on the model manifold which we call the \\emph{winding frequency}\nthat estimates the linear density of local minima in the model's parameter\nspace. We then show how alternative choices of fitting metrics can \"unwind\" the\nmodel manifold and give low winding frequencies. This prescription translates\nthe model manifold from one of high effective-dimensionality into the\n\"hyper-ribbon\" structures observed elsewhere. This translation opens the door\nfor applications of sloppy model analysis and model reduction methods developed\nfor models with low effective-dimensionality.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 16:14:29 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 23:42:05 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Francis", "Benjamin L.", ""], ["Transtrum", "Mark K.", ""]]}]