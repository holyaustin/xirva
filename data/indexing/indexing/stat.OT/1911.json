[{"id": "1911.00535", "submitter": "Alex Reinhart", "authors": "Alex Reinhart, Ciaran Evans, Amanda Luby, Josue Orellana, Mikaela\n  Meyer, Jerzy Wieczorek, Peter Elliott, Philipp Burckhardt, Rebecca Nugent", "title": "Think-aloud interviews: A tool for exploring student statistical\n  reasoning", "comments": "26 pages, 3 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As undergraduate statistics education rapidly changes to incorporate new\ntopics and skills, statistics educators need tools to evaluate student learning\nand understand how students think. Think-aloud interviews, in which students\nanswer questions while narrating their thinking aloud, are a valuable education\nresearch tool for detecting misconceptions and developing robust assessments.\n  While think-aloud interviews have been widely used for education research in\nother fields, in statistics education they have been primarily used to vet\nconcept inventory questions for confusing wording or poor design. Here, we\nargue for their much more comprehensive use to explore student reasoning and\niteratively draft questions. To motivate the use of think-aloud interviews, we\ndescribe two case studies on correlation, causation, and sampling\ndistributions. In these, think-alouds revealed unexpected student reasoning and\nsuggested new ways to assess difficult statistical topics. These case studies\nillustrate the usefulness of think-aloud interviews for studying student\nthinking, and we argue for their wider use in statistics education research.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 18:15:00 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 20:20:04 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2021 20:38:09 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Reinhart", "Alex", ""], ["Evans", "Ciaran", ""], ["Luby", "Amanda", ""], ["Orellana", "Josue", ""], ["Meyer", "Mikaela", ""], ["Wieczorek", "Jerzy", ""], ["Elliott", "Peter", ""], ["Burckhardt", "Philipp", ""], ["Nugent", "Rebecca", ""]]}, {"id": "1911.01607", "submitter": "Inez Maria Zwetsloot", "authors": "Inez Maria Zwetsloot, Tahir Mahmood and William H. Woodall", "title": "Multivariate Time-Between-Events Monitoring -- An overview and some\n  (overlooked) underlying complexities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review methods for monitoring multivariate time-between-events (TBE) data.\nWe present some underlying complexities that have been overlooked in the\nliterature. It is helpful to classify multivariate TBE monitoring applications\ninto two fundamentally different scenarios. One scenario involves monitoring\nindividual vectors of TBE data. The other involves the monitoring of several,\npossibly correlated, temporal point processes in which events could occur at\ndifferent rates. We discuss performance measures and advise the use of\ntime-between-signal based metrics for the design and comparison of methods. We\nre-evaluate an existing multivariate TBE monitoring method, offer some advice\nand some directions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2019 04:01:55 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Zwetsloot", "Inez Maria", ""], ["Mahmood", "Tahir", ""], ["Woodall", "William H.", ""]]}, {"id": "1911.03336", "submitter": "Carlos Ruiz", "authors": "Andr\\'es M. Alonso, F. Javier Nogales and Carlos Ruiz", "title": "Hierarchical Clustering for Smart Meter Electricity Loads based on\n  Quantile Autocovariances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to improve the efficiency and sustainability of electricity systems,\nmost countries worldwide are deploying advanced metering infrastructures, and\nin particular household smart meters, in the residential sector. This\ntechnology is able to record electricity load time series at a very high\nfrequency rates, information that can be exploited to develop new clustering\nmodels to group individual households by similar consumptions patterns. To this\nend, in this work we propose three hierarchical clustering methodologies that\nallow capturing different characteristics of the time series. These are based\non a set of \"dissimilarity\" measures computed over different features: quantile\nauto-covariances, and simple and partial autocorrelations. The main advantage\nis that they allow summarizing each time series in a few representative\nfeatures so that they are computationally efficient, robust against outliers,\neasy to automatize, and scalable to hundreds of thousands of smart meters\nseries. We evaluate the performance of each clustering model in a real-world\nsmart meter dataset with thousands of half-hourly time series. The results show\nhow the obtained clusters identify relevant consumption behaviors of households\nand capture part of their geo-demographic segmentation. Moreover, we apply a\nsupervised classification procedure to explore which features are more relevant\nto define each cluster.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2019 15:47:34 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Alonso", "Andr\u00e9s M.", ""], ["Nogales", "F. Javier", ""], ["Ruiz", "Carlos", ""]]}, {"id": "1911.04235", "submitter": "Maike Santos", "authors": "Maike A. F. dos Santos", "title": "Mittag-Leffler functions in superstatistics", "comments": null, "journal-ref": null, "doi": "10.1016/j.chaos.2019.109484", "report-no": null, "categories": "cond-mat.stat-mech math-ph math.MP physics.data-an stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, there is a series of complexities in biophysics that require a\nsuitable approach to determine the measurable quantity. In this way, the\nsuperstatistics has been an important tool to investigate dynamic aspects of\nparticles, organisms and substances immersed in systems with non-homogeneous\ntemperatures (or diffusivity). The superstatistics admits a general Boltzmann\nfactor that depends on the distribution of intensive parameters $\\beta$\n(inverse-diffusivity). Each value of intensive parameter is associated with a\nlocal equilibrium in the system. In this work, we investigate the consequences\nof Mittag-Leffler function on the definition of f-distribution of a complex\nsystem. Thus, using the techniques belonging to the fractional calculus with\nnon-singular kernels, we constructed a distribution to intensive parameters\nusing the Mittag-Leffler function. This function implies distributions with\npower-law behaviour to high energy values in the context of Cohen-Beck\nsuperstatistics. This work aims to present the generalised probabilities\ndistribution in statistical mechanics under a new perspective of the\nMittag-Leffler function inspired in Atangana-Baleanu and Prabhakar forms.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2019 11:24:05 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Santos", "Maike A. F. dos", ""]]}, {"id": "1911.04317", "submitter": "Aravind Sampathkumar", "authors": "Jiayi He, Aravind Sampath Kumar, Arun Chada, Bhyrav Mutnury, James\n  Drewniak", "title": "Machine Learning for high speed channel optimization", "comments": "3 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Design of printed circuit board (PCB) stack-up requires the consideration of\ncharacteristic impedance, insertion loss and crosstalk. As there are many\nparameters in a PCB stack-up design, the optimization of these parameters needs\nto be efficient and accurate. A less optimal stack-up would lead to expensive\nPCB material choices in high speed designs. In this paper, an efficient global\noptimization method using parallel and intelligent Bayesian optimization is\nproposed for the stripline design.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2019 23:46:26 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["He", "Jiayi", ""], ["Kumar", "Aravind Sampath", ""], ["Chada", "Arun", ""], ["Mutnury", "Bhyrav", ""], ["Drewniak", "James", ""]]}, {"id": "1911.04616", "submitter": "Ziheng Chen", "authors": "Ziheng Chen and Hongshik Ahn", "title": "Item Response Theory based Ensemble in Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG stat.AP stat.CO stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a novel probabilistic framework to improve the\naccuracy of a weighted majority voting algorithm. In order to assign higher\nweights to the classifiers which can correctly classify hard-to-classify\ninstances, we introduce the Item Response Theory (IRT) framework to evaluate\nthe samples' difficulty and classifiers' ability simultaneously. Three models\nare created with different assumptions suitable for different cases. When\nmaking an inference, we keep a balance between the accuracy and complexity. In\nour experiment, all the base models are constructed by single trees via\nbootstrap. To explain the models, we illustrate how the IRT ensemble model\nconstructs the classifying boundary. We also compare their performance with\nother widely used methods and show that our model performs well on 19 datasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2019 23:48:18 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Chen", "Ziheng", ""], ["Ahn", "Hongshik", ""]]}, {"id": "1911.05610", "submitter": "Rui Zhang", "authors": "Rui Zhang, Yao Xie, Rui Yao, Feng Qiu", "title": "Online detection of cascading change-points", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.SY eess.SP eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an online detection procedure for cascading failures in the\nnetwork from sequential data, which can be modeled as multiple correlated\nchange-points happening during a short period. We consider a temporal diffusion\nnetwork model to capture the temporal dynamic structure of multiple\nchange-points and develop a sequential Shewhart procedure based on the\ngeneralized likelihood ratio statistics based on the diffusion network model\nassuming unknown post-change distribution parameters. We also tackle the\ncomputational complexity posed by the unknown propagation. Numerical\nexperiments demonstrate the good performance for detecting cascade failures.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 19:19:42 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2020 19:55:05 GMT"}, {"version": "v3", "created": "Wed, 11 Nov 2020 18:27:21 GMT"}, {"version": "v4", "created": "Fri, 5 Feb 2021 22:05:26 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Zhang", "Rui", ""], ["Xie", "Yao", ""], ["Yao", "Rui", ""], ["Qiu", "Feng", ""]]}, {"id": "1911.08628", "submitter": "Emi Tanaka", "authors": "Emi Tanaka and Francis K. C. Hui", "title": "Symbolic Formulae for Linear Mixed Models", "comments": null, "journal-ref": null, "doi": "10.1007/978-981-15-1960-4_1", "report-no": null, "categories": "stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A statistical model is a mathematical representation of an often simplified\nor idealised data-generating process. In this paper, we focus on a particular\ntype of statistical model, called linear mixed models (LMMs), that is widely\nused in many disciplines e.g.~agriculture, ecology, econometrics, psychology.\nMixed models, also commonly known as multi-level, nested, hierarchical or panel\ndata models, incorporate a combination of fixed and random effects, with LMMs\nbeing a special case. The inclusion of random effects in particular gives LMMs\nconsiderable flexibility in accounting for many types of complex correlated\nstructures often found in data. This flexibility, however, has given rise to a\nnumber of ways by which an end-user can specify the precise form of the LMM\nthat they wish to fit in statistical software. In this paper, we review the\nsoftware design for specification of the LMM (and its special case, the linear\nmodel), focusing in particular on the use of high-level symbolic model formulae\nand two popular but contrasting R-packages in lme4 and asreml.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2019 23:30:17 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Tanaka", "Emi", ""], ["Hui", "Francis K. C.", ""]]}, {"id": "1911.09049", "submitter": "Russell Bowater", "authors": "Russell J. Bowater", "title": "Sharp hypotheses and bispatial inference", "comments": "Corrected, rewritten and extended. *Final version*", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental class of inferential problems are those characterised by there\nhaving been a substantial degree of pre-data (or prior) belief that the value\nof a model parameter was equal or lay close to a specified value, which may,\nfor example, be the value that indicates the absence of an effect. Standard\nways of tackling problems of this type, including the Bayesian method, are\noften highly inadequate in practice. To address this issue, an inferential\nframework called bispatial inference is put forward, which can be viewed as\nboth a generalisation and radical reinterpretation of existing approaches to\ninference that are based on P values. It is shown that to obtain an appropriate\npost-data density function for a given parameter, it is often convenient to\ncombine a special type of bispatial inference, which is constructed around\none-sided P values, with a previously outlined form of fiducial inference.\nFinally, by using what are called post-data opinion curves, this\nbispatial-fiducial theory is naturally extended to deal with the general\nscenario in which any number of parameters may be unknown. The application of\nthe theory is illustrated in various examples, which are especially relevant to\nthe analysis of clinical trial data.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2019 17:24:29 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2021 18:28:26 GMT"}], "update_date": "2021-01-26", "authors_parsed": [["Bowater", "Russell J.", ""]]}, {"id": "1911.13170", "submitter": "Edward Wheatcroft", "authors": "Edward Wheatcroft, Henry Wynn, Chris J. Dent, Jim Q. Smith, Claire L.\n  Copeland, Daniel Ralph, and Stan Zachary", "title": "The Scenario Culture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scenario Analysis is a risk assessment tool that aims to evaluate the impact\nof a small number of distinct plausible future scenarios. In this paper, we\nprovide an overview of important aspects of Scenario Analysis including when it\nis appropriate, the design of scenarios, uncertainty and encouraging\ncreativity. Each of these issues is discussed in the context of climate, energy\nand legal scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 15:07:25 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Wheatcroft", "Edward", ""], ["Wynn", "Henry", ""], ["Dent", "Chris J.", ""], ["Smith", "Jim Q.", ""], ["Copeland", "Claire L.", ""], ["Ralph", "Daniel", ""], ["Zachary", "Stan", ""]]}]