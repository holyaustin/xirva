[{"id": "2103.00117", "submitter": "Xiaojun Zheng", "authors": "Xiaojun Zheng, Simon Mak, Yao Xie", "title": "Online High-Dimensional Change-Point Detection using Topological Data\n  Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.AT stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Data Analysis (TDA) is a rapidly growing field, which studies\nmethods for learning underlying topological structures present in complex data\nrepresentations. TDA methods have found recent success in extracting useful\ngeometric structures for a wide range of applications, including protein\nclassification, neuroscience, and time-series analysis. However, in many such\napplications, one is also interested in sequentially detecting changes in this\ntopological structure. We propose a new method called Persistence Diagram based\nChange-Point (PD-CP), which tackles this problem by integrating the widely-used\npersistence diagrams in TDA with recent developments in nonparametric\nchange-point detection. The key novelty in PD-CP is that it leverages the\ndistribution of points on persistence diagrams for online detection of\ntopological changes. We demonstrate the effectiveness of PD-CP in an\napplication to solar flare monitoring.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2021 03:43:57 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 22:10:54 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Zheng", "Xiaojun", ""], ["Mak", "Simon", ""], ["Xie", "Yao", ""]]}, {"id": "2103.01658", "submitter": "Alessio Russo", "authors": "Alessio Russo, Alexandre Proutiere", "title": "Minimizing Information Leakage of Abrupt Changes in Stochastic Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work investigates the problem of analyzing privacy for general Markov\nprocesses. These processes may be affected by changes, or exogenous signals,\nthat need to remain private. Privacy refers to the disclosure of information of\nthese changes through observations of the underlying Markov chain. In contrast\nto previous work on privacy, we study the problem for an online sequence of\ndata. We use theoretical tools from optimal detection theory to motivate a\ndefinition of online privacy based on the average amount of information per\nobservation of the stochastic system in consideration. Two cases are\nconsidered: the full-information case, where the eavesdropper measures all but\nthe signals that indicate a change, and the limited-information case, where the\neavesdropper only measures the state of the Markov process. For both cases, we\nprovide ways to derive privacy upper-bounds and compute policies that attain a\nhigher privacy level. It turns out that the problem of computing privacy-aware\npolicies is concave, and we conclude with some examples and numerical\nsimulations for both cases.\n", "versions": [{"version": "v1", "created": "Tue, 2 Mar 2021 11:41:10 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Russo", "Alessio", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "2103.03910", "submitter": "Samuel Clark", "authors": "Samuel J. Clark", "title": "Health and Demographic Surveillance Systems and the 2030 Agenda:\n  Sustainable Development Goals", "comments": "This is a UN Population Division experts' group meeting paper\n  summarizing the potential for health and demographic surveillance system\n  sites to contribute to population-level indictor production as part of the\n  sustainable development goals framework", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The health and demographic surveillance system (HDSS) is an old method for\nintensively monitoring a population to assess the effects of healthcare or\nother population-level interventions - often clinical trials. The strengths of\nHDSS include very detailed descriptions of whole populations with frequent\nupdates. This often provides long time series of accurate population and health\nindicators for the HDSS study population. The primary weakness of HDSS is that\nthe data describe only the HDSS study population and cannot be generalized\nbeyond that.\n  The 2030 agenda is the ecosystem of activities - many including\npopulation-level monitoring - that relate to the United Nations (UN)\nSustainable Development Goals (SDG). With respect to the 2030 agenda, HDSS can\ncontribute by: continuing to conduct cause-and-effect studies; contributing to\ndata triangulation or amalgamation initiatives; characterizing the bias in and\ncalibrating 'big data'; and contributing more to the rapid training of\ndata-oriented professionals, especially in the population and health fields.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 19:37:52 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Clark", "Samuel J.", ""]]}, {"id": "2103.04139", "submitter": "Ashwini Venkatasubramaniam", "authors": "Ashwini Venkatasubramaniam and Julian Wolfson", "title": "visTree: Visualization of Subgroups for a Decision Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Decision trees are flexible prediction models which are constructed to\nquantify outcome-covariate relationships and characterize relevant population\nsubgroups. However, the standard graphical representation of fitted decision\ntrees highlights individual split points, and hence is suboptimal for\nvisualizing defined subgroups. In this paper, we present a novel visual\nrepresentation of decision trees which shifts the primary focus to\ncharacterizing subgroups, both in terms of their defining covariates and their\noutcome distribution. We implement our method in the \\texttt{visTree} package,\nwhich builds on the toolkit and infrastructure provided by the\n\\texttt{partykit} package and enables the visualization to be applied to varied\ndecision trees. Individual functions are demonstrated using data from the Box\nLunch study [French et al., 2014], a randomized trial to evaluate the effect of\nexposure to different lunch sizes on energy intake and body weight among\nworking adults.\n", "versions": [{"version": "v1", "created": "Sat, 6 Mar 2021 15:23:29 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Venkatasubramaniam", "Ashwini", ""], ["Wolfson", "Julian", ""]]}, {"id": "2103.05689", "submitter": "Lucy D'Agostino McGowan", "authors": "Lucy D'Agostino McGowan, Roger D. Peng, Stephanie C. Hicks", "title": "Design Principles for Data Analysis", "comments": "arXiv admin note: text overlap with arXiv:1903.07639", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data science revolution has led to an increased interest in the practice\nof data analysis. While much has been written about statistical thinking, a\ncomplementary form of thinking that appears in the practice of data analysis is\ndesign thinking -- the problem-solving process to understand the people for\nwhom a product is being designed. For a given problem, there can be significant\nor subtle differences in how a data analyst (or producer of a data analysis)\nconstructs, creates, or designs a data analysis, including differences in the\nchoice of methods, tooling, and workflow. These choices can affect the data\nanalysis products themselves and the experience of the consumer of the data\nanalysis. Therefore, the role of a producer can be thought of as designing the\ndata analysis with a set of design principles. Here, we introduce design\nprinciples for data analysis and describe how they can be mapped to data\nanalyses in a quantitative, objective and informative manner. We also provide\nempirical evidence of variation of principles within and between both producers\nand consumers of data analyses. Our work leads to two insights: it suggests a\nformal mechanism to describe data analyses based on the design principles for\ndata analysis, and it provides a framework to teach students how to build data\nanalyses using formal design principles.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2021 19:48:25 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["McGowan", "Lucy D'Agostino", ""], ["Peng", "Roger D.", ""], ["Hicks", "Stephanie C.", ""]]}, {"id": "2103.07424", "submitter": "Tiandong Wang", "authors": "Tiandong Wang and Sidney Resnick", "title": "Measuring Reciprocity in a Directed Preferential Attachment Network", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph math.PR stat.OT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Empirical studies show that online social networks have not only in- and\nout-degree distributions with Pareto-like tails but also a high proportion of\nreciprocal edges. A classical directed preferential attachment (PA) model\ngenerates in- and out-degree distribution with power-law tails, but theoretical\nproperties of the reciprocity feature in this model have not yet been studied.\nWe derive the asymptotic results on the number of reciprocal edges between two\nfixed nodes, as well as the proportion of reciprocal edges in the entire PA\nnetwork. We see that with certain choices of parameters, the proportion of\nreciprocal edges in a directed PA network is close to 0, which differs from the\nempirical observation. This points out one potential problem of fitting a\nclassical PA model to a given network dataset with high reciprocity and\nindicates alternative models need to be considered.\n", "versions": [{"version": "v1", "created": "Fri, 12 Mar 2021 17:41:47 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Wang", "Tiandong", ""], ["Resnick", "Sidney", ""]]}, {"id": "2103.07746", "submitter": "Shu Wang", "authors": "Shu Wang, Ji-Hyun Lee", "title": "A Simulation Study Evaluating Phase I Clinical Trial Designs for\n  Combinational Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, more and more clinical trials choose combinational agents as the\nintervention to achieve better therapeutic responses. However, dose-finding for\ncombinational agents is much more complicated than single agent as the full\norder of combination dose toxicity is unknown. Therefore, regular phase I\ndesigns are not able to identify the maximum tolerated dose (MTD) of\ncombinational agents. Motivated by such needs, plenty of novel phase I clinical\ntrial designs for combinational agents were proposed. With so many available\ndesigns, research that compare their performances, explore parameters' impacts,\nand provide recommendations is very limited. Therefore, we conducted a\nsimulation study to evaluate multiple phase I designs that proposed to identify\nsingle MTD for combinational agents under various scenarios. We also explored\ninfluences of different design parameters. In the end, we summarized the pros\nand cons of each design, and provided a general guideline in design selection.\n", "versions": [{"version": "v1", "created": "Sat, 13 Mar 2021 16:37:22 GMT"}], "update_date": "2021-03-16", "authors_parsed": [["Wang", "Shu", ""], ["Lee", "Ji-Hyun", ""]]}, {"id": "2103.10463", "submitter": "Andr\\'e Gillibert", "authors": "Andr\\'e Gillibert (1 and 2), Jacques B\\'enichou (2 and 3), Bruno\n  Falissard (1) ((1) INSERM UMR 1178, Universit\\'e Paris Sud, Maison de Solenn,\n  Paris, France (2) Department of Biostatistics and Clinical Research, CHU\n  Rouen, Rouen, France (3) Inserm U 1219, Normandie University, Rouen, France)", "title": "Two-sided confidence interval of a binomial proportion: how to choose?", "comments": "20 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Introduction: estimation of confidence intervals (CIs) of binomial\nproportions has been reviewed more than once but the directional\ninterpretation, distinguishing the overestimation from the underestimation, was\nneglected while the sample size and theoretical proportion variances from\nexperiment to experiment have not been formally taken in account. Herein, we\ndefine and apply new evaluation criteria, then give recommendations for the\npractical use of these CIs.\n  Materials & methods: Google Scholar was used for bibliographic research.\nEvaluation criteria were (i) one-sided conditional errors, (ii) one-sided local\naverage errors assuming a random theoretical proportion and (iii) expected\nhalf-widths of CIs.\n  Results: Wald's CI did not control any of the risks, even when the expected\nnumber of successes reached 32. The likelihood ratio CI had a better balance\nthan the logistic Wald CI. The Clopper-Pearson mid-P CI controlled well\none-sided local average errors whereas the simple Clopper-Pearson CI was\nstrictly conservative on both one-sided conditional errors. The percentile and\nbasic bootstrap CIs had the same bias order as Wald's CI whereas the\nstudentized CIs and BCa, modified for discrete bootstrap distributions, were\nless biased but not as efficient as the parametric methods. The half-widths of\nCIs mirrored local average errors.\n  Conclusion: we recommend using the Clopper-Pearson mid-P CI for the\nestimation of a proportion except for observed-theoretical proportion\ncomparison under controlled experimental conditions in which the\nClopper-Pearson CI may be better.\n", "versions": [{"version": "v1", "created": "Wed, 17 Mar 2021 14:53:13 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Gillibert", "Andr\u00e9", "", "1 and 2"], ["B\u00e9nichou", "Jacques", "", "2 and 3"], ["Falissard", "Bruno", ""]]}, {"id": "2103.11147", "submitter": "Anis Mohamed Haddouche", "authors": "Anis M. Haddouche and Wei Lu", "title": "A unified approach for covariance matrix estimation under Stein loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address the problem of estimating a covariance matrix of a\nmultivariate Gaussian distribution, relative to a Stein loss function, from a\ndecision theoretic point of view. We investigate the case where the covariance\nmatrix is invertible and the case when it is non--invertible in a unified\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2021 10:01:18 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Haddouche", "Anis M.", ""], ["Lu", "Wei", ""]]}, {"id": "2103.11309", "submitter": "Jason Whyte PhD", "authors": "Jason M. Whyte", "title": "Branching out into Structural Identifiability Analysis with Maple:\n  Interactive Exploration of Uncontrolled Linear Time-Invariant Structures", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": "10.1007/978-3-030-81698-8_27", "report-no": null, "categories": "eess.SY cs.SY stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppose we wish to predict the behaviour of a physical system. We may choose\nto represent the system by model structure $S$ (a set of related mathematical\nmodels defined by parametric relationships between system variables), and a\nparameter set $\\Theta$. Each parameter vector in $\\Theta$ is associated with a\ncompletely specified model in $S$. We use $S$ with system observations in\nestimating the \"true\" (unknown) parameter vector. Inconveniently, multiple\nparameter vectors may cause $S$ to approximate the data equally well. If we\ncannot distinguish between such alternatives, and these lead to dissimilar\npredictions, we cannot confidently use $S$ in decision making. This result may\nrender efforts in data collection and modelling fruitless. This outcome occurs\nwhen $S$ lacks the property of structural global identifiability (SGI).\nFortunately, we can test various classes of structures for SGI prior to data\ncollection. A non-SGI result may guide changes to our structure or experimental\ndesign towards obtaining a better outcome. We aim to assist the testing of\nstructures for SGI through bespoke Maple 2020 procedures. We consider\ncontinuous-time, uncontrolled, linear time-invariant state-space structures.\nHere, the time evolution of the state-variable vector ${\\bf x}$ is modelled by\na system of constant-coefficient, ordinary differential equations. We utilise\nthe \"transfer function\" approach, which is also applicable to the\n\"compartmental\" subclass (mass is conserved). Our use of Maple's \"Explore\"\nenables an interactive consideration of a parent structure and its variants,\nobtained as the user changes which components of ${\\bf x}$ are observed, or\nhave non-zero initial conditions. Such changes may influence the information\ncontent of the idealised output available for the SGI test, and hence, its\nresult. Our approach may inform the interactive analysis of structures from\nother classes.\n", "versions": [{"version": "v1", "created": "Sun, 21 Mar 2021 05:30:02 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 01:25:20 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Whyte", "Jason M.", ""]]}, {"id": "2103.12581", "submitter": "Andr\\'e Gillibert", "authors": "Andr\\'e Gillibert (1 and 2), Jacques B\\'enichou (2 and 3), Bruno\n  Falissard (1) ((1) Universit\\'e Paris Sud, Maison de Solenn, Paris, France\n  (2) Department of Biostatistics and Clinical Research, CHU Rouen, Rouen,\n  France (3) Normandie University, Rouen, France)", "title": "The case for balanced hypothesis tests and equal-tailed confidence\n  intervals", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Introduction: there is an ongoing debate about directional inference of\ntwo-sided hypothesis tests for which some authors argue that rejecting $\\theta\n= \\theta_0$ does not allow to conclude that $\\theta > \\theta_0$ or $\\theta <\n\\theta_0$ but only that $\\theta \\neq \\theta_0$, while others argue that this is\na minor error without practical consequence.\n  Discussion: new elements are brought to the debate. It is shown that the\ndirectional interpretation of some non-directional hypothesis tests about\nReceiver Operating Characteristic (ROC) and survival curves may lead to\ninflated type III error rates with a probability of concluding that a\ndifference exists in the opposite side of the actual difference that can reach\n50% in the worst case. Some of the issues of directional tests also apply to\ntwo-sided confidence intervals (CIs). It is shown that equal-tailed CIs should\nbe preferred to shortest CIs. New assessment criteria of two-sided CIs and\nhypothesis tests are proposed to provide a reliable directional interpretation:\npartial left-sided and right-sided $\\alpha$ error rates for hypothesis tests,\nprobabilities of overestimation and underestimation $\\alpha_L$ and $\\alpha_U$\nand interval half-widths for two-sided CIs.\n  Conclusion: two-sided CIs and two-sided tests are interpreted directionally.\nThis implies that directional interpretation be taken in account in the\ndevelopment and evaluation of confidence intervals and tests.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2021 17:30:46 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Gillibert", "Andr\u00e9", "", "1 and 2"], ["B\u00e9nichou", "Jacques", "", "2 and 3"], ["Falissard", "Bruno", ""]]}, {"id": "2103.13521", "submitter": "Kayvan Sadeghi", "authors": "Kayvan Sadeghi and Terry Soo", "title": "Conditions and Assumptions for Constraint-based Causal Structure\n  Learning", "comments": "30 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.LG stat.ML stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper formalizes constraint-based structure learning of the \"true\" causal\ngraph from observed data when unobserved variables are also existent. We define\na \"generic\" structure learning algorithm, which provides conditions that, under\nthe faithfulness assumption, the output of all known exact algorithms in the\nliterature must satisfy, and which outputs graphs that are Markov equivalent to\nthe causal graph. More importantly, we provide clear assumptions, weaker than\nfaithfulness, under which the same generic algorithm outputs Markov equivalent\ngraphs to the causal graph. We provide the theory for the general class of\nmodels under the assumption that the distribution is Markovian to the true\ncausal graph, and we specialize the definitions and results for structural\ncausal models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Mar 2021 23:08:00 GMT"}], "update_date": "2021-03-26", "authors_parsed": [["Sadeghi", "Kayvan", ""], ["Soo", "Terry", ""]]}, {"id": "2103.15678", "submitter": "Abdenbi El Azri Azri", "authors": "Nafidi Ahmed and El Azri Abdenbi", "title": "Inference in the stochastic Cox-Ingersol-Ross diffusion process with\n  continuous sampling: Computational aspects and simulation", "comments": "6 pages with 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider a stochastic model based on the Cox- Ingersoll-\nRoss model (CIR). The stochastic model is parameterized analytically by\napplying It\\^o's calculus and the trend functions of the proposed process is\ncalculated. The parameter estimators are then derived by means of two\nprocedures: the first is used to estimate the parameters in the drift\ncoefficient by the maximum likelihood (ML) method, based on continuous\nsampling, and the second procedure approximates the diffusion coefficient by\ntwo methods. Finally, a simulation of the process is presented. Thus, a typical\nsimulated trajectory of the process and its estimators is obtained.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 15:02:59 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ahmed", "Nafidi", ""], ["Abdenbi", "El Azri", ""]]}, {"id": "2103.15704", "submitter": "Marcos Matabuena", "authors": "Marcos Matabuena, Sherveen Riazati, Nick Caplan and Phil Hayes", "title": "Are Multilevel functional models the next step in sports biomechanics\n  and wearable technology? A case study of Knee Biomechanics patterns in\n  typical training sessions of recreational runners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper illustrates how multilevel functional models can detect and\ncharacterize biomechanical changes along different sport training sessions. Our\nanalysis focuses on the relevant cases to identify differences in knee\nbiomechanics in recreational runners during low and high-intensity exercise\nsessions with the same energy expenditure by recording $20$ steps. To do so, we\nreview the existing literature of multilevel models, and then, we propose a new\nhypothesis test to look at the changes between different levels of the\nmultilevel model as low and high-intensity training sessions. We also evaluate\nthe reliability of measures recorded in three-dimension knee angles from the\nfunctional intra-class correlation coefficient (ICC) obtained from the\ndecomposition performed with the multilevel funcional model taking into account\n$20$ measures recorded in each test. The results show that there are no\nstatistically significant differences between the two modes of exercise.\nHowever, we have to be careful with the conclusions since, as we have shown,\nhuman gait-patterns are very individual and heterogeneous between groups of\nathletes, and other alternatives to the p-value may be more appropriate to\ndetect statistical differences in biomechanical changes in this context.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2021 15:43:09 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 22:19:27 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Matabuena", "Marcos", ""], ["Riazati", "Sherveen", ""], ["Caplan", "Nick", ""], ["Hayes", "Phil", ""]]}, {"id": "2103.16004", "submitter": "Gregory Hunt", "authors": "Gregory J. Hunt and Johann A. Gagnon-Bartsch", "title": "Containerized Analyses Enable Interactive and Reproducible Statistics", "comments": "21 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent decades the analysis of data has become increasingly computational.\nCorrespondingly, this has changed how scientific and statistical work is\nshared. For example, it is now commonplace for underlying analysis code and\ndata to be proffered alongside journal publications and conference talks.\nUnfortunately, sharing code faces several challenges. First, it is often\ndifficult to take code from one computer and run it on another. Code\nconfiguration, version, and dependency issues often make this challenging.\nSecondly, even if the code runs, it is often hard to understand or interact\nwith the analysis. This makes it difficult to assess the code and its findings,\nfor example, in a peer review process. In this paper we advocate for two\npractical approaches to help make sharing interactive and reproducible analyses\neasy: (1) analysis containerization, a technology that fully encapsulates an\nanalysis, data, code and dependencies into a shareable format, and (2) code\nnotebooks, an accessible format for interacting with third-party analyses. We\nwill demonstrate that the combination of these two technologies is powerful and\nthat containerizing interactive code notebooks can help make it easy for\nstatisticians to share code, analyses, and ideas.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2021 00:30:24 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Hunt", "Gregory J.", ""], ["Gagnon-Bartsch", "Johann A.", ""]]}]