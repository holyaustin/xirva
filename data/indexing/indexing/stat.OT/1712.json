[{"id": "1712.00544", "submitter": "Xiao-Li Meng", "authors": "Xiao-Li Meng", "title": "Conducting Highly Principled Data Science: A Statistician's Job and Joy", "comments": "To appear in the special issue on \"The Role of Statistics in the Era\n  of Big Data\" in Statistics and Probability Letters (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly Principled Data Science insists on methodologies that are: (1)\nscientifically justified, (2) statistically principled, and (3) computationally\nefficient. An astrostatistics collaboration, together with some reminiscences,\nillustrates the increased roles statisticians can and should play to ensure\nthis trio, and to advance the science of data along the way.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 04:13:17 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 11:52:17 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Meng", "Xiao-Li", ""]]}, {"id": "1712.02410", "submitter": "Matthew Beckman", "authors": "Matthew Beckman, Robert delMas", "title": "Statistics students' identification of inferential model elements within\n  contexts of their own invention", "comments": null, "journal-ref": "ZDM Mathematics Education 50(7). 1295-1309 (2018)", "doi": "10.1007/s11858-018-0986-5", "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical thinking partially depends upon an iterative process by which\nessential features of a problem setting are identified and mapped onto an\nabstract model or archetype, and then translated back into the context of the\noriginal problem setting (Wild and Pfannkuch 1999). Assessment in introductory\nstatistics often relies on tasks that present students with data in context and\nexpects them to choose and describe an appropriate model. This study explores\npost-secondary student responses to an alternative task that prompts students\nto clearly identify a sample, population, statistic, and parameter using a\ncontext of their own invention. The data include free text narrative responses\nof a random sample of 500 students from a sample of more than 1600 introductory\nstatistics students. Results suggest that students' responses often portrayed\nsample and population accurately. Portrayals of statistic and parameter were\nless reliable and were associated with descriptions of a wide variety of other\nconcepts. Responses frequently attributed a variable of some kind to the\nstatistic, or a study design detail to the parameter. Implications for\ninstruction and research are discussed, including a call for emphasis on a\nmodeling paradigm in introductory statistics.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 21:15:11 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2019 17:35:21 GMT"}], "update_date": "2019-02-21", "authors_parsed": [["Beckman", "Matthew", ""], ["delMas", "Robert", ""]]}, {"id": "1712.03168", "submitter": "Yaakov Malinovsky", "authors": "Yaakov Malinovsky", "title": "On optimal policy in the group testing with incomplete identification", "comments": "Submitted for publication, Revised", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a very large (infinite) population of items, where each item\nindependent from the others is defective with probability p, or good with\nprobability q=1-p. The goal is to identify N good items as quickly as possible.\nThe following group testing policy (policy A) is considered: test items\ntogether in the groups, if the test outcome of group i of size n_i is negative,\nthen accept all items in this group as good, otherwise discard the group. Then,\nmove to the next group and continue until exact N good items are found. The\ngoal is to find an optimal testing configuration, i.e., group sizes, under\npolicy A, such that the expected waiting time to obtain N good items is\nminimal. Recently, Gusev (2012) found an optimal group testing configuration\nunder the assumptions of constant group size and N=\\infty. In this note, an\noptimal solution under policy A for finite N is provided. Keywords: Dynamic\nprogramming; Optimal design; Partition problem; Shur-convexity\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 16:54:22 GMT"}, {"version": "v2", "created": "Sat, 14 Apr 2018 23:27:34 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Malinovsky", "Yaakov", ""]]}, {"id": "1712.04801", "submitter": "Hoang Vuong", "authors": "Quan-Hoang Vuong", "title": "Open data, open review and open dialogue in making social sciences\n  plausible", "comments": "5 pages", "journal-ref": "Vuong QH. (2017). Open data, open review and open dialogue in\n  making social sciences plausible. Nature: Scientific Data Updates, 12\n  December 2017", "doi": null, "report-no": null, "categories": "stat.OT stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nowadays, protecting trust in social sciences also means engaging in open\ncommunity dialogue, which helps to safeguard robustness and improve efficiency\nof research methods. The combination of open data, open review and open\ndialogue may sound simple but implementation in the real world will not be\nstraightforward. However, in view of Begley and Ellis's (2012) statement that,\n\"the scientific process demands the highest standards of quality, ethics and\nrigour,\" they are worth implementing. More importantly, they are feasible to\nwork on and likely will help to restore plausibility to social sciences\nresearch. Therefore, I feel it likely that the triplet of open data, open\nreview and open dialogue will gradually emerge to become policy requirements\nregardless of the research funding source.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 14:47:26 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Vuong", "Quan-Hoang", ""]]}, {"id": "1712.07349", "submitter": "Jennifer Bryan", "authors": "Jennifer Bryan and Hadley Wickham", "title": "Data Science: A Three Ring Circus or a Big Tent?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is part of a collection of discussion pieces on David Donoho's paper 50\nYears of Data Science, appearing in Volume 26, Issue 4 of the Journal of\nComputational and Graphical Statistics (2017).\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 07:41:45 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Bryan", "Jennifer", ""], ["Wickham", "Hadley", ""]]}]