[{"id": "1904.01491", "submitter": "Christopher Rembold", "authors": "Christopher M Rembold", "title": "Statistical testing in a Linear Probability Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine that you could calculate of posttest probabilities, i.e. Bayes\ntheorem with simple addition. This is possible if we stop thinking of\nprobabilities as ranging from 0 to 1.0. There is a naturally occurring linear\nprobability space when data are transformed into the logarithm of the odds\nratio (log10 odds). In this space, probabilities are replaced by W (Weight)\nwhere W=log10(probability/(1-probability)). I would like to argue the multiple\nbenefits of performing statistical testing in a linear probability space: 1)\nStatistical testing is accurate in linear probability space but not in other\nspaces. 2) Effect size is called Impact (I) and is the difference in means\nbetween two treatments (I=Wmean2-Wmean1). 3) Bayes theorem is simply\nWposttest=Wpretest+Itest. 4) Significance (p value) is replaced by Certainty\n(C) which is the W of the p value. Methods to transform data into and out of\nlinear probability space are described.\n", "versions": [{"version": "v1", "created": "Tue, 2 Apr 2019 15:28:40 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Rembold", "Christopher M", ""]]}, {"id": "1904.02107", "submitter": "Kathleen Champion", "authors": "Kathleen Champion, Bethany Lusch, J. Nathan Kutz, Steven L. Brunton", "title": "Data-driven discovery of coordinates and governing equations", "comments": "25 pages, 6 figures; added acknowledgments", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of governing equations from scientific data has the potential\nto transform data-rich fields that lack well-characterized quantitative\ndescriptions. Advances in sparse regression are currently enabling the\ntractable identification of both the structure and parameters of a nonlinear\ndynamical system from data. The resulting models have the fewest terms\nnecessary to describe the dynamics, balancing model complexity with descriptive\nability, and thus promoting interpretability and generalizability. This\nprovides an algorithmic approach to Occam's razor for model discovery. However,\nthis approach fundamentally relies on an effective coordinate system in which\nthe dynamics have a simple representation. In this work, we design a custom\nautoencoder to discover a coordinate transformation into a reduced space where\nthe dynamics may be sparsely represented. Thus, we simultaneously learn the\ngoverning equations and the associated coordinate system. We demonstrate this\napproach on several example high-dimensional dynamical systems with\nlow-dimensional behavior. The resulting modeling framework combines the\nstrengths of deep neural networks for flexible representation and sparse\nidentification of nonlinear dynamics (SINDy) for parsimonious models. It is the\nfirst method of its kind to place the discovery of coordinates and models on an\nequal footing.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 23:42:53 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 23:51:45 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Champion", "Kathleen", ""], ["Lusch", "Bethany", ""], ["Kutz", "J. Nathan", ""], ["Brunton", "Steven L.", ""]]}, {"id": "1904.02961", "submitter": "Aleksey Polunchenko", "authors": "Kexuan Li and Aleksey S. Polunchenko and Andrey Pepelyshev", "title": "Analytic Evaluation of the Fractional Moments for the Quasi-Stationary\n  Distribution of the Shiryaev Martingale on an Interval", "comments": "Accepted for publication in Communications in Statistics - Simulation\n  and Computation. arXiv admin note: text overlap with arXiv:1805.07580", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO math.PR stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quasi-stationary distribution of the classical Shiryaev\ndiffusion restricted to the interval $[0,A]$ with absorption at a fixed $A>0$.\nWe derive analytically a closed-form formula for the distribution's fractional\nmoment of an {\\em arbitrary} given order $s\\in\\mathbb{R}$; the formula is\nconsistent with that previously found by Polunchenko and Pepelyshev (2018) for\nthe case of $s\\in\\mathbb{N}$. We also show by virtue of the formula that, if\n$s<1$, then the $s$-th fractional moment of the quasi-stationary distribution\nbecomes that of the exponential distribution (with mean $1/2$) in the limit as\n$A\\to+\\infty$; the limiting exponential distribution is the stationary\ndistribution of the reciprocal of the Shiryaev diffusion.\n", "versions": [{"version": "v1", "created": "Fri, 5 Apr 2019 09:46:54 GMT"}], "update_date": "2019-04-08", "authors_parsed": [["Li", "Kexuan", ""], ["Polunchenko", "Aleksey S.", ""], ["Pepelyshev", "Andrey", ""]]}, {"id": "1904.04330", "submitter": "Brad McNeney", "authors": "JinCheol Choi, Donghuan Lu, Mirza Faisal Beg, Jinko Graham and Brad\n  McNeney", "title": "The Contribution Plot: Decomposition and Graphical Display of the RV\n  Coefficient, with Application to Genetic and Brain Imaging Biomarkers of\n  Alzheimer's Disease", "comments": "20 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Alzheimer's disease (AD) is a chronic neurodegenerative disease that causes\nmemory loss and decline in cognitive abilities. AD is the sixth leading cause\nof death in the United States, affecting an estimated 5 million Americans. To\nassess the association between multiple genetic variants and multiple\nmeasurements of structural changes in the brain a recent study of AD used a\nmultivariate measure of linear dependence, the RV coefficient. The authors\ndecomposed the RV coefficient into contributions from individual variants and\ndisplayed these contributions graphically. We investigate the properties of\nsuch a `contribution plot' in terms of an underlying linear model, and discuss\nestimation of the components of the plot when the correlation signal may be\nsparse. The contribution plot is applied to simulated data and to genomic and\nbrain imaging data from the Alzheimer's Disease Neuroimaging Initiative.\n", "versions": [{"version": "v1", "created": "Mon, 8 Apr 2019 20:00:20 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Choi", "JinCheol", ""], ["Lu", "Donghuan", ""], ["Beg", "Mirza Faisal", ""], ["Graham", "Jinko", ""], ["McNeney", "Brad", ""]]}, {"id": "1904.05329", "submitter": "Jaewon Chung", "authors": "Jaewon Chung, Benjamin D. Pedigo, Eric W. Bridgeford, Bijan K.\n  Varjavand, Hayden S. Helm, Joshua T. Vogelstein", "title": "GraSPy: Graph Statistics in Python", "comments": null, "journal-ref": "Journal of Machine Learning Research 20.158 (2019): 1-7", "doi": null, "report-no": null, "categories": "cs.SI stat.ML stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce GraSPy, a Python library devoted to statistical inference,\nmachine learning, and visualization of random graphs and graph populations.\nThis package provides flexible and easy-to-use algorithms for analyzing and\nunderstanding graphs with a scikit-learn compliant API. GraSPy can be\ndownloaded from Python Package Index (PyPi), and is released under the Apache\n2.0 open-source license. The documentation and all releases are available at\nhttps://neurodata.io/graspy.\n", "versions": [{"version": "v1", "created": "Fri, 29 Mar 2019 18:58:31 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 03:20:16 GMT"}, {"version": "v3", "created": "Wed, 14 Aug 2019 22:37:02 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Chung", "Jaewon", ""], ["Pedigo", "Benjamin D.", ""], ["Bridgeford", "Eric W.", ""], ["Varjavand", "Bijan K.", ""], ["Helm", "Hayden S.", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1904.05662", "submitter": "Spencer Wheatley Dr.", "authors": "Spencer Wheatley and Didier Sornette", "title": "Statistical witchhunts: Science, justice & the p-value crisis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide accessible insight into the current 'replication crisis' in\n'statistical science', by revisiting the old metaphor of 'court trial as\nhypothesis test'. Inter alia, we define and diagnose harmful statistical\nwitch-hunting both in justice and science, which extends to the replication\ncrisis itself, where a hunt on p-values is currently underway.\n", "versions": [{"version": "v1", "created": "Thu, 11 Apr 2019 12:28:16 GMT"}, {"version": "v2", "created": "Mon, 1 Jul 2019 16:05:32 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Wheatley", "Spencer", ""], ["Sornette", "Didier", ""]]}, {"id": "1904.08730", "submitter": "Surojit Biswas", "authors": "Surojit Biswas and Nitin Gupta", "title": "Some ordering properties of highest and lowest order statistics with\n  exponentiated Gumble type-II distributed components", "comments": "16 pages, 1 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we have studied the stochastic comparisons of the highest and\nlowest order statistics of exponentiated Gumble type-II distribution with three\nparameters. We have compared both the statistics by using three different\nstochastic ordering. First, we consider a system with different scale and outer\nshape parameters and then we study the usual stochastic ordering of the lowest\nand highest order statistics in the sense of multivariate chain majorization.\nIn addition, we construct two examples to support our results. Second, by using\nthe vector majorization technique, we study the usual stochastic ordering, the\nreversed failure rate ordering and the likelihood ratio ordering with respect\nto different outer shape parameters, next, by varying the inner shape\nparameter, we discuss the usual stochastic order of the lowest order statistics\nand we have shown that the highest order statistics are not comparable in the\nusual stochastic ordering by an example.\n", "versions": [{"version": "v1", "created": "Thu, 18 Apr 2019 12:32:45 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Biswas", "Surojit", ""], ["Gupta", "Nitin", ""]]}, {"id": "1904.10118", "submitter": "Taiane Prass", "authors": "Taiane Schaedler Prass, S\\'ilvia Regina Costa Lopes, Jos\\'e G.\n  D\\'orea, Rejane C. Marques and Katiane G. Brand\\~ao", "title": "Amazon Forest Fires Between 2001 and 2006 and Birth Weight in Porto\n  Velho", "comments": null, "journal-ref": "Bulletin of Environmental Contamination and Toxicology, July 2012,\n  Volume 89, Issue 1, pp 1-7", "doi": "10.1007/s00128-012-0621-z", "report-no": null, "categories": "stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Birth weight data (22,012 live-births) from a public hospital in Porto Velho\n(Amazon) was used in multiple statistical models to assess the effects of\nforest-fire smoke on human reproductive outcome. Mean birth weights for girls\n(3,139 g) and boys (3,393 g) were considered statistically different (p-value <\n2.2e-16). Among all models analyzed, the means were considered statistically\ndifferent only when treated as a function of month and year (p-value = 0.0989,\ngirls and 0.0079, boys) . The R 2 statistics indicate that the regression\nmodels considered are able to explain 65 % (girls) and 54 % (boys) of the\nvariation of the mean birth weight.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 01:48:03 GMT"}, {"version": "v2", "created": "Thu, 25 Apr 2019 01:09:34 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Prass", "Taiane Schaedler", ""], ["Lopes", "S\u00edlvia Regina Costa", ""], ["D\u00f3rea", "Jos\u00e9 G.", ""], ["Marques", "Rejane C.", ""], ["Brand\u00e3o", "Katiane G.", ""]]}, {"id": "1904.10172", "submitter": "Antonio Calcagn\\`i", "authors": "Antonio Calcagn\\`i, Massimiliano Pastore, and Gianmarco Alto\\`e", "title": "ssMousetrack: Analysing computerized tracking data via Bayesian\n  state-space models in {R}", "comments": null, "journal-ref": "Math. Comput. Appl. 2020, 25(3), 41", "doi": "10.3390/mca25030041", "report-no": null, "categories": "stat.CO stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technological advances have provided new settings to enhance\nindividual-based data collection and computerized-tracking data have became\ncommon in many behavioral and social research. By adopting instantaneous\ntracking devices such as computer-mouse, wii, and joysticks, such data provide\nnew insights for analysing the dynamic unfolding of response process.\nssMousetrack is a R package for modeling and analysing computerized-tracking\ndata by means of a Bayesian state-space approach. The package provides a set of\nfunctions to prepare data, fit the model, and assess results via simple\ndiagnostic checks. This paper describes the package and illustrates how it can\nbe used to model and analyse computerized-tracking data. A case study is also\nincluded to show the use of the package in empirical case studies.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 06:30:24 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Calcagn\u00ec", "Antonio", ""], ["Pastore", "Massimiliano", ""], ["Alto\u00e8", "Gianmarco", ""]]}, {"id": "1904.10406", "submitter": "George Vega Yon", "authors": "George G. Vega Yon, Andrew Slaughter, Kayla de la Haye", "title": "Exponential Random Graph models for Little Networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.socnet.2020.07.005", "report-no": null, "categories": "stat.ME stat.OT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Statistical models for social networks have enabled researchers to study\ncomplex social phenomena that give rise to observed patterns of relationships\namong social actors and to gain a rich understanding of the interdependent\nnature of social ties and actors. Much of this research has focused on social\nnetworks within medium to large social groups. To date, these advances in\nstatistical models for social networks, and in particular, of\nExponential-Family Random Graph Models (ERGMS), have rarely been applied to the\nstudy of small networks, despite small network data in teams, families, and\npersonal networks being common in many fields. In this paper, we revisit the\nestimation of ERGMs for small networks and propose using exhaustive enumeration\nwhen possible. We developed an R package that implements the estimation of\npooled ERGMs for small networks using Maximum Likelihood Estimation (MLE),\ncalled \"ergmito\". Based on the results of an extensive simulation study to\nassess the properties of the MLE estimator, we conclude that there are several\nbenefits of direct MLE estimation compared to approximate methods and that this\ncreates opportunities for valuable methodological innovations that can be\napplied to modeling social networks with ERGMs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Apr 2019 16:16:15 GMT"}, {"version": "v2", "created": "Wed, 3 Jun 2020 17:17:12 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Yon", "George G. Vega", ""], ["Slaughter", "Andrew", ""], ["de la Haye", "Kayla", ""]]}, {"id": "1904.11006", "submitter": "Gwendolyn Eadie", "authors": "Gwendolyn Eadie, Daniela Huppenkothen, Aaron Springford, and Tyler\n  McCormick", "title": "Introducing Bayesian Analysis with $\\text{m&m's}^\\circledR$: an\n  active-learning exercise for undergraduates", "comments": "Accepted to the Journal of Statistics Education (in press); 15 pages,\n  7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT astro-ph.IM physics.data-an stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present an active-learning strategy for undergraduates that applies\nBayesian analysis to candy-covered chocolate $\\text{m&m's}^\\circledR$. The\nexercise is best suited for small class sizes and tutorial settings, after\nstudents have been introduced to the concepts of Bayesian statistics. The\nexercise takes advantage of the non-uniform distribution of\n$\\text{m&m's}^\\circledR~$ colours, and the difference in distributions made at\ntwo different factories. In this paper, we provide the intended learning\noutcomes, lesson plan and step-by-step guide for instruction, and open-source\nteaching materials. We also suggest an extension to the exercise for the\ngraduate-level, which incorporates hierarchical Bayesian analysis.\n", "versions": [{"version": "v1", "created": "Tue, 16 Apr 2019 23:29:42 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Eadie", "Gwendolyn", ""], ["Huppenkothen", "Daniela", ""], ["Springford", "Aaron", ""], ["McCormick", "Tyler", ""]]}, {"id": "1904.11242", "submitter": "Wenting Yu", "authors": "Wenting Yu, Fei Shen, Chen Min", "title": "Governance on Social Media Data: Different Focuses between Government\n  and Internet Company", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How governments and Internet companies regulate user data on social media\nattracts public attention. This study tried to answer two questions: What kind\nof countries send more requests for Facebook user data? What kind of countries\nget more requests replies from Facebook? We aim to figure out how a country's\neconomic, political and social factors affect its government requests for user\ndata and Facebook's responses rate to those requests. Results show that\ncountries with higher GDP per capita, a higher level of human freedom and a\nlower level of rule of law send more requests for user data; while Facebook\ntends to reply to government requests from countries with a higher level of\nhuman freedom and a lower level of political stability. In conclusion,\ngovernments and Facebook show different focuses on governance on social media\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 25 Apr 2019 09:55:44 GMT"}], "update_date": "2019-04-26", "authors_parsed": [["Yu", "Wenting", ""], ["Shen", "Fei", ""], ["Min", "Chen", ""]]}, {"id": "1904.11752", "submitter": "Oliver Gordon Mr", "authors": "Oliver Gordon, Dominic Coy, Jack Matthews, Easel Kandola-McNicholas,\n  Owain Llewellyn, Adeel Bokhari, Philip Moriarty", "title": "Rushing or Dragging? An Analysis of the \"Universality\" of Correlated\n  Fluctuations in Hi-Hat Timing and Dynamics", "comments": null, "journal-ref": null, "doi": "10.17639/nott.344", "report-no": null, "categories": "physics.soc-ph stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A previous analysis of fluctuations in a virtuoso (Jeff Porcaro) drum\nperformance [R\\\"as\\\"anen et al., PLoS ONE 10(6): e0127902 (2015)] demonstrated\nthat the rhythmic signal comprised both long range correlations and short range\nanti-correlations, with a characteristic timescale distinguishing the two\nregimes. We have extended R\\\"as\\\"anen et al.'s approach to a much larger number\nof drum samples (N=132, provided by a total of 58 participants) and to a\ndifferent performance (viz., Rush's Tom Sawyer). A key focus of our study was\nto test whether the fluctuation dynamics discovered by R\\\"as\\\"anen et al. are\n\"universal\" in the following sense: is the crossover from short-range to\nlong-range correlated fluctuations a general phenomenon or is it restricted to\nparticular drum patterns and/or specific drummers? We find no compelling\nevidence to suggest that the short-range to long-range correlation crossover\nthat is characteristic of Porcaro's performance is a common feature of temporal\nfluctuations in drum patterns. Moreover, level of experience and/or playing\ntechnique surprisingly do not play a role in influencing a short-range to\nlong-range correlation cross-over. Our study also highlights that a great deal\nof caution needs to be taken when using the detrended fluctuation analysis\ntechnique, particularly with regard to anti-correlated signals.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 10:37:28 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Gordon", "Oliver", ""], ["Coy", "Dominic", ""], ["Matthews", "Jack", ""], ["Kandola-McNicholas", "Easel", ""], ["Llewellyn", "Owain", ""], ["Bokhari", "Adeel", ""], ["Moriarty", "Philip", ""]]}, {"id": "1904.11907", "submitter": "Stephanie Hicks", "authors": "Stephanie C. Hicks, Roger D. Peng", "title": "Evaluating the Success of a Data Analysis", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A fundamental problem in the practice and teaching of data science is how to\nevaluate the quality of a given data analysis, which is different than the\nevaluation of the science or question underlying the data analysis. Previously,\nwe defined a set of principles for describing data analyses that can be used to\ncreate a data analysis and to characterize the variation between data analyses.\nHere, we introduce a metric of quality evaluation that we call the success of a\ndata analysis, which is different than other potential metrics such as\ncompleteness, validity, or honesty. We define a successful data analysis as the\nmatching of principles between the analyst and the audience on which the\nanalysis is developed. In this paper, we propose a statistical model and\ngeneral framework for evaluating the success of a data analysis. We argue that\nthis framework can be used as a guide for practicing data scientists and\nstudents in data science courses for how to build a successful data analysis.\n", "versions": [{"version": "v1", "created": "Fri, 26 Apr 2019 15:48:56 GMT"}], "update_date": "2019-04-29", "authors_parsed": [["Hicks", "Stephanie C.", ""], ["Peng", "Roger D.", ""]]}, {"id": "1904.12190", "submitter": "Sebastian Avalos", "authors": "Sebastian Avalos and Julian M. Ortiz", "title": "Geological modeling using a recursive convolutional neural networks\n  approach", "comments": "CIM convention 2019 - Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Resource models are constrained by the extent of geological units that often\ndepend on the lithology, alteration and mineralization. A three dimensional\nmodel of these geological units must be built from scarce information coming\nfrom drillholes and limited understanding about the geological setting in which\nthe ore deposit is places. In this work, we present a new technique for\nmultiple-point geostatistical simulation based on a recursive convolutional\nneural network approach (RCNN). The method requires conditioning data and a\ntraining image that depicts the type of geological structures expected to be\nfound in the deposit. This training image is used to learn the patterns of\ncategories found and these are imposed in the final simulated model conditioned\nby the categories found during logging at the actual drill-hole samples. A\nlithological modeling process is carried out in a copper deposit in Chile to\ndemonstrate the method. Comparison with current techniques and spatial metrics\nare used to clarify concepts and RCNN properties. Also, strengths and\nweaknesses of the methodology are discussed by briefly reviewing the\ntheoretical perspective and looking into some of its practical aspects.\n", "versions": [{"version": "v1", "created": "Sat, 27 Apr 2019 18:13:43 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Avalos", "Sebastian", ""], ["Ortiz", "Julian M.", ""]]}, {"id": "1904.13207", "submitter": "Einolah Deiri", "authors": "Fateme Maleki Jebeli, Einolah Deiri", "title": "Methods of Estimation for the Three-Parameter Reflected Weibull\n  Distribution", "comments": "24 pages, 14 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose methods for the estimation of parameters for the\nthree-parameter Reflected Weibull distribution. The Moment estimator , Maximum\nlikelihood estimator and Location and Scale Parameters free maximum likelihood\nestimator. The Location and Scale Parameters free maximum likelihood estimator\nis based on a data transformation, which avoids the problem of unbounded\nlikelihood estimator. Through Mont Carlo simulations, we further show that the\nLocation and Scale Parameters free maximum likelihood estimator performs better\nthan methods moment and maximum likelihood estimator in terms of bias and root\nmean squared error. Finally, two examples based on real data sets are presented\nto illustrate methods.\n", "versions": [{"version": "v1", "created": "Sun, 28 Apr 2019 05:39:25 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Jebeli", "Fateme Maleki", ""], ["Deiri", "Einolah", ""]]}, {"id": "1904.13365", "submitter": "Nagdev Amruthnath", "authors": "Nagdev Amruthnath, Tarun Gupta", "title": "Fault Diagnosis using Clustering. What Statistical Test to use for\n  Hypothesis Testing?", "comments": null, "journal-ref": "Machine Learning and Applications: An International Journal\n  (MLAIJ), 2019", "doi": "10.5121/mlaij.2019.6102", "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive maintenance and condition-based monitoring systems have seen\nsignificant prominence in recent years to minimize the impact of machine\ndowntime on production and its costs. Predictive maintenance involves using\nconcepts of data mining, statistics, and machine learning to build models that\nare capable of performing early fault detection, diagnosing the faults and\npredicting the time to failure. Fault diagnosis has been one of the core areas\nwhere the actual failure mode of the machine is identified. In fluctuating\nenvironments such as manufacturing, clustering techniques have proved to be\nmore reliable compared to supervised learning methods. One of the fundamental\nchallenges of clustering is developing a test hypothesis and choosing an\nappropriate statistical test for hypothesis testing. Most statistical analyses\nuse some underlying assumptions of the data which most real-world data is\nincapable of satisfying those assumptions. This paper is dedicated to\novercoming the following challenge by developing a test hypothesis for fault\ndiagnosis application using clustering technique and performing PERMANOVA test\nfor hypothesis testing.\n", "versions": [{"version": "v1", "created": "Tue, 30 Apr 2019 16:54:05 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Amruthnath", "Nagdev", ""], ["Gupta", "Tarun", ""]]}]