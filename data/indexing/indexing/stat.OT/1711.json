[{"id": "1711.01598", "submitter": "Xuan Bi", "authors": "Xuan Bi, Annie Qu and Xiaotong Shen", "title": "Multilayer tensor factorization with applications to recommender systems", "comments": "Accepted by the Annals of Statistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML stat.AP stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems have been widely adopted by electronic commerce and\nentertainment industries for individualized prediction and recommendation,\nwhich benefit consumers and improve business intelligence. In this article, we\npropose an innovative method, namely the recommendation engine of multilayers\n(REM), for tensor recommender systems. The proposed method utilizes the\nstructure of a tensor response to integrate information from multiple modes,\nand creates an additional layer of nested latent factors to accommodate\nbetween-subjects dependency. One major advantage is that the proposed method is\nable to address the \"cold-start\" issue in the absence of information from new\ncustomers, new products or new contexts. Specifically, it provides more\neffective recommendations through sub-group information. To achieve scalable\ncomputation, we develop a new algorithm for the proposed method, which\nincorporates a maximum block improvement strategy into the cyclic\nblockwise-coordinate-descent algorithm. In theory, we investigate both\nalgorithmic properties for global and local convergence, along with the\nasymptotic consistency of estimated parameters. Finally, the proposed method is\napplied in simulations and IRI marketing data with 116 million observations of\nproduct sales. Numerical studies demonstrate that the proposed method\noutperforms existing competitors in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 14:40:07 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Bi", "Xuan", ""], ["Qu", "Annie", ""], ["Shen", "Xiaotong", ""]]}, {"id": "1711.02580", "submitter": "Jinpeng Guo", "authors": "Jinpeng Guo, Feng Liu, Jianhui Wang, Ming Cao, Shengwei Mei", "title": "Quantifying the Influence of Component Failure Probability on Cascading\n  Blackout Risk", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The risk of cascading blackouts greatly relies on failure probabilities of\nindividual components in power grids. To quantify how component failure\nprobabilities (CFP) influences blackout risk (BR), this paper proposes a\nsample-induced semi-analytic approach to characterize the relationship between\nCFP and BR. To this end, we first give a generic component failure probability\nfunction (CoFPF) to describe CFP with varying parameters or forms. Then the\nexact relationship between BR and CoFPFs is built on the abstract\nMarkov-sequence model of cascading outages. Leveraging a set of samples\ngenerated by blackout simulations, we further establish a sample-induced\nsemi-analytic mapping between the unbiased estimation of BR and CoFPFs.\nFinally, we derive an efficient algorithm that can directly calculate the\nunbiased estimation of BR when the CoFPFs change. Since no additional\nsimulations are required, the algorithm is computationally scalable and\nefficient. Numerical experiments well confirm the theory and the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 04:52:05 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Guo", "Jinpeng", ""], ["Liu", "Feng", ""], ["Wang", "Jianhui", ""], ["Cao", "Ming", ""], ["Mei", "Shengwei", ""]]}, {"id": "1711.02639", "submitter": "Marcelo Tavares", "authors": "Marcelo T. de Oliveira, Edson Katekawa", "title": "On the Virtues of Automated QSAR The New Kid on the Block", "comments": "Automated QSAR, kernel PLS, prediction, QSAR, validation", "journal-ref": "Future Medicinal Chemistry, 2017", "doi": "10.4155/FMC-2017-0170", "report-no": null, "categories": "stat.OT", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Quantitative Structure-Activity Relationship (QSAR) has proved an invaluable\ntool in medicinal chemistry. Data availability at unprecedented levels through\nvarious databases have collaborated to a resurgence in the interest for QSAR.\nIn this context, rapid generation of quality predictive models is highly\ndesirable for hit identification and lead optimization. We showcase the\napplication of an automated QSAR approach, which randomly selects multiple\ntraining/test sets and utilizes machine-learning algorithms to generate\npredictive models. Results demonstrate that AutoQSAR produces models of\nimproved or similar quality to those generated by practitioners in the field\nbut in just a fraction of the time. Despite the potential of the concept to the\nbenefit of the community, the AutoQSAR opportunity has been largely\nundervalued.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 18:00:22 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["de Oliveira", "Marcelo T.", ""], ["Katekawa", "Edson", ""]]}, {"id": "1711.04316", "submitter": "Olga Goulko", "authors": "Olga Goulko, Alexander Gaenko, Emanuel Gull, Nikolay Prokof'ev, Boris\n  Svistunov", "title": "Implementation of the Bin Hierarchy Method for restoring a smooth\n  function from a sampled histogram", "comments": "Code is available at https://github.com/olgagoulko/BHM/tree/GPLv3", "journal-ref": "Computer Physics Communications 236, 205-213 (2019)", "doi": "10.1016/j.cpc.2018.09.019", "report-no": null, "categories": "stat.OT cond-mat.other physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present $\\texttt{BHM}$, a tool for restoring a smooth function from a\nsampled histogram using the bin hierarchy method. The theoretical background of\nthe method is presented in [arXiv:1707.07625]. The code automatically generates\na smooth polynomial spline with the minimal acceptable number of knots from the\ninput data. It works universally for any sufficiently regular shaped\ndistribution and any level of data quality, requiring almost no external\nparameter specification. It is particularly useful for large-scale numerical\ndata analysis. This paper explains the details of the implementation and the\nuse of the program.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 15:51:26 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Goulko", "Olga", ""], ["Gaenko", "Alexander", ""], ["Gull", "Emanuel", ""], ["Prokof'ev", "Nikolay", ""], ["Svistunov", "Boris", ""]]}, {"id": "1711.07801", "submitter": "Harry Crane", "authors": "Harry Crane", "title": "Why \"Redefining Statistical Significance\" Will Not Improve\n  Reproducibility and Could Make the Replication Crisis Worse", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent proposal to \"redefine statistical significance\" (Benjamin, et al.\nNature Human Behaviour, 2017) claims that false positive rates \"would\nimmediately improve\" by factors greater than two and replication rates would\ndouble simply by changing the conventional cutoff for 'statistical\nsignificance' from P<0.05 to P<0.005. I analyze the veracity of these claims,\nfocusing especially on how Benjamin, et al neglect the effects of P-hacking in\nassessing the impact of their proposal. My analysis shows that once P-hacking\nis accounted for the perceived benefits of the lower threshold all but\ndisappear, prompting two main conclusions: (i) The claimed improvements to\nfalse positive rate and replication rate in Benjamin, et al (2017) are\nexaggerated and misleading. (ii) There are plausible scenarios under which the\nlower cutoff will make the replication crisis worse.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 14:26:42 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Crane", "Harry", ""]]}, {"id": "1711.09400", "submitter": "Elham Taghizadeh", "authors": "Elham Taghizadeh and Mostafa Abedzadeh and Mostafa Setak", "title": "A Multi Objective Reliable Location-Inventory Capacitated Disruption\n  Facility Problem with Penalty Cost Solve with Efficient Meta Historic\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS stat.OT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Logistics network is expected that opened facilities work continuously for a\nlong time horizon without any failure, but in real world problems, facilities\nmay face disruptions. This paper studies a reliable joint inventory location\nproblem to optimize the cost of facility locations, customers assignment, and\ninventory management decisions when facilities face failure risks and do not\nwork. In our model we assume when a facility is out of work, its customers may\nbe reassigned to other operational facilities otherwise they must endure high\npenalty costs associated with losing service. For defining the model closer to\nreal world problems, the model is proposed based on pmedian problem and the\nfacilities are considered to have limited capacities. We define a new binary\nvariable for showing that customers are not assigned to any facilities. Our\nproblem involves a biobjective model, the first one minimizes the sum of\nfacility construction costs and expected inventory holding costs, the second\none function that mentions for the first one is minimized maximum expected\ncustomer costs under normal and failure scenarios. For solving this model we\nuse NSGAII and MOSS algorithms have been applied to find the Pareto archive\nsolution. Also, Response Surface Methodology (RSM) is applied for optimizing\nthe NSGAII Algorithm Parameters. We compare the performance of two algorithms\nwith three metrics and the results show NSGAII is more suitable for our model.\n", "versions": [{"version": "v1", "created": "Sun, 26 Nov 2017 15:04:06 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Taghizadeh", "Elham", ""], ["Abedzadeh", "Mostafa", ""], ["Setak", "Mostafa", ""]]}, {"id": "1711.10262", "submitter": "Peter Green", "authors": "Peter J. Diggle, Peter J. Green and Bernard W. Silverman", "title": "Julian Ernst Besag, 26 March 1945 -- 6 August 2010, a biographical\n  memoir", "comments": "26 pages, 14 figures; minor revisions, omission of full bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Julian Besag was an outstanding statistical scientist, distinguished for his\npioneering work on the statistical theory and analysis of spatial processes,\nespecially conditional lattice systems. His work has been seminal in\nstatistical developments over the last several decades ranging from image\nanalysis to Markov chain Monte Carlo methods. He clarified the role of\nauto-logistic and auto-normal models as instances of Markov random fields and\npaved the way for their use in diverse applications. Later work included\ninvestigations into the efficacy of nearest neighbour models to accommodate\nspatial dependence in the analysis of data from agricultural field trials,\nimage restoration from noisy data, and texture generation using lattice models.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 12:54:53 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 16:54:37 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Diggle", "Peter J.", ""], ["Green", "Peter J.", ""], ["Silverman", "Bernard W.", ""]]}, {"id": "1711.10421", "submitter": "Xiaoyue Niu", "authors": "Bomin Kim, Kevin Lee, Lingzhou Xue, and Xiaoyue Niu", "title": "A Review of Dynamic Network Models with Latent Variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a selective review of statistical modeling of dynamic networks. We\nfocus on models with latent variables, specifically, the latent space models\nand the latent class models (or stochastic blockmodels), which investigate both\nthe observed features and the unobserved structure of networks. We begin with\nan overview of the static models, and then we introduce the dynamic extensions.\nFor each dynamic model, we also discuss its applications that have been studied\nin the literature, with the data source listed in Appendix. Based on the\nreview, we summarize a list of open problems and challenges in dynamic network\nmodeling with latent variables.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 16:31:21 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 15:38:06 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Kim", "Bomin", ""], ["Lee", "Kevin", ""], ["Xue", "Lingzhou", ""], ["Niu", "Xiaoyue", ""]]}]