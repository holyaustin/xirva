[{"id": "1606.00546", "submitter": "Florian Ziel", "authors": "Florian Ziel, Carsten Croonenbroeck, Daniel Ambach", "title": "Forecasting wind power - Modeling periodic and non-linear effects under\n  conditional heteroscedasticity", "comments": null, "journal-ref": "Applied Energy, 177 (2016) 285-297", "doi": "10.1016/j.apenergy.2016.05.111", "report-no": null, "categories": "stat.AP stat.CO stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present an approach that enables joint wind speed and wind\npower forecasts for a wind park. We combine a multivariate seasonal time\nvarying threshold autoregressive moving average (TVARMA) model with a power\nthreshold generalized autoregressive conditional heteroscedastic (power-TGARCH)\nmodel. The modeling framework incorporates diurnal and annual periodicity\nmodeling by periodic B-splines, conditional heteroscedasticity and a complex\nautoregressive structure with non-linear impacts. In contrast to usually\ntime-consuming estimation approaches as likelihood estimation, we apply a\nhigh-dimensional shrinkage technique. We utilize an iteratively re-weighted\nleast absolute shrinkage and selection operator (lasso) technique. It allows\nfor conditional heteroscedasticity, provides fast computing times and\nguarantees a parsimonious and regularized specification, even though the\nparameter space may be vast. We are able to show that our approach provides\naccurate forecasts of wind power at a turbine-specific level for forecasting\nhorizons of up to 48 h (short- to medium-term forecasts).\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 06:01:14 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Ziel", "Florian", ""], ["Croonenbroeck", "Carsten", ""], ["Ambach", "Daniel", ""]]}, {"id": "1606.00770", "submitter": "Sergei Kucherenko", "authors": "Sergei Kucherenko, Shufang Song", "title": "Different numerical estimators for main effect global sensitivity\n  indices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variance-based method of global sensitivity indices based on Sobol\nsensitivity indices became very popular among practitioners due to its easiness\nof interpretation. For complex practical problems computation of Sobol indices\ngenerally requires a large number of function evaluations to achieve reasonable\nconvergence. Four different direct formulas for computing Sobol main effect\nsensitivity indices are compared on a set of test problems for which there are\nanalytical results. These formulas are based on high-dimensional integrals\nwhich are evaluated using MC and QMC techniques. Direct formulas are also\ncompared with a different approach based on the so-called double loop\nreordering formula. It is found that the double loop reordering (DLR) approach\nshows a superior performance among all methods both for models with independent\nand dependent variables.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 17:11:38 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Kucherenko", "Sergei", ""], ["Song", "Shufang", ""]]}, {"id": "1606.01183", "submitter": "Richard Samworth", "authors": "Richard J. Samworth", "title": "Peter Hall's work on high-dimensional data and classification", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, I summarise Peter Hall's contributions to high-dimensional\ndata, including their geometric representations and variable selection methods\nbased on ranking. I also discuss his work on classification problems,\nconcluding with some personal reflections on my own interactions with him.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 16:52:22 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Samworth", "Richard J.", ""]]}, {"id": "1606.01202", "submitter": "Charlotte Werndl", "authors": "Charlotte Werndl and Roman Frigg", "title": "When Does a Boltzmannian Equilibrium Exist?", "comments": "Forthcoming in: Daniel Bedingham, Owen Maroney and Christopher\n  Timpson (eds.): Quantum Foundations of Statistical Mechanics, Oxford: Oxford\n  University Press. arXiv admin note: text overlap with arXiv:1510.02260", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech math-ph math.DS math.MP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The received wisdom in statistical mechanics is that isolated systems, when\nleft to themselves, approach equilibrium. But under what circumstances does an\nequilibrium state exist and an approach to equilibrium take place? In this\npaper we address these questions from the vantage point of the long-run\nfraction of time definition of Boltzmannian equilibrium that we developed in\ntwo recent papers (Werndl and Frigg 2015a, 2015b). After a short summary of\nBoltzmannian statistical mechanics and our definition of equilibrium, we state\nan existence theorem which provides general criteria for the existence of an\nequilibrium state. We first illustrate how the theorem works with a toy\nexample, which allows us to illustrate the various elements of the theorem in a\nsimple setting. After commenting on the ergodic programme, we discuss\nequilibria in a number of different gas systems: the ideal gas, the dilute gas,\nthe Kac gas, the stadium gas, the mushroom gas and the multi-mushroom gas. In\nthe conclusion we briefly summarise the main points and highlight open\nquestions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 17:53:33 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Werndl", "Charlotte", ""], ["Frigg", "Roman", ""]]}, {"id": "1606.02352", "submitter": "Ryan Martin", "authors": "Ryan Martin", "title": "A statistical inference course based on p-values", "comments": "16 pages, 2 figures", "journal-ref": "The American Statistician, 2017, volume 71, number 2, pages\n  128--136", "doi": "10.1080/00031305.2016.1208629", "report-no": null, "categories": "stat.OT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introductory statistical inference texts and courses treat the point\nestimation, hypothesis testing, and interval estimation problems separately,\nwith primary emphasis on large-sample approximations. Here I present an\nalternative approach to teaching this course, built around p-values,\nemphasizing provably valid inference for all sample sizes. Details about\ncomputation and marginalization are also provided, with several illustrative\nexamples, along with a course outline.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 23:36:00 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Martin", "Ryan", ""]]}, {"id": "1606.03189", "submitter": "Bethany Shifflett Bethany Shifflett", "authors": "Bethany Shifflett", "title": "Bringing Order to the Chaos in the Brickyard", "comments": "19 pages (including references), 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An allegory published in 1963 titled Chaos in the Brickyard spoke to the\ndecline in the quality of research. In the intervening time greater awareness\nof the issues and actions to improve research endeavors have emerged. Still,\nproblems persist. This paper is intended to clarify some of the challenges,\nparticularly with respect to quantitative research, then suggest ways to\nimprove the quality of published research. The paper highlights where feasible\nrefinements in analytical techniques can be made and provides a guide to\nfundamental principles related to data analysis in research.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2016 05:47:56 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Shifflett", "Bethany", ""]]}, {"id": "1606.05598", "submitter": "Noah Silbert", "authors": "Noah H. Silbert and Robin D. Thomas", "title": "Identifiability and testability in GRT with Individual Differences", "comments": "24 pages, 5 figures, under review at the Journal of Mathematical\n  Psychology", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Silbert and Thomas (2013) showed that failures of decisional separability are\nnot, in general, identifiable in fully parameterized $2 \\times 2$ Gaussian GRT\nmodels. A recent extension of $2 \\times 2$ GRT models (GRTwIND) was developed\nto solve this problem and a conceptually similar problem with the simultaneous\nidentifiability of means and marginal variances in GRT models. Central to the\nability of GRTwIND to solve these problems is the assumption of universal\nperception, which consists of shared perceptual distributions modified by\nattentional and global scaling parameters (Soto et al., 2015). If universal\nperception is valid, GRTwIND solves both issues. In this paper, we show that\nGRTwIND with universal perception and subject-specific failures of decisional\nseparability is mathematically, and thereby empirically, equivalent to a model\nwith decisional separability and failure of universal perception. We then\nprovide a formal proof of the fact that means and marginal variances are not,\nin general, simultaneously identifiable in $2 \\times 2$ GRT models, including\nGRTwIND. These results can be taken to delineate precisely what the assumption\nof universal perception must consist of. Based on these results and related\nrecent mathematical developments in the GRT framework, we propose that, in\naddition to requiring a fixed subset of parameters to determine the location\nand scale of any given GRT model, some subset of parameters must be set in GRT\nmodels to fix the orthogonality of the modeled perceptual dimensions, a central\nconceptual underpinning of the GRT framework. We conclude with a discussion of\nperceptual primacy and its relationship to universal perception.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 17:32:41 GMT"}, {"version": "v2", "created": "Fri, 29 Jul 2016 19:43:56 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Silbert", "Noah H.", ""], ["Thomas", "Robin D.", ""]]}, {"id": "1606.09017", "submitter": "David Navon", "authors": "David Navon and Yoav Cohen", "title": "Consider avoiding the .05 significance level", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is suggested that some shortcomings of Null Hypothesis Significance\nTesting (NHST), viewed from the perspective of Bayesian statistics, turn benign\nonce the traditional threshold p value of .05 is substituted by a sufficiently\nsmaller value. To illustrate, the posterior probability of H0 stating P=.5,\ngiven data that just render it rejected by NHST with a p value of .05 (and a\nuniform prior), is shown here to be not much smaller than .50 for most values\nof N below 100 (and even exceeds .50 for N>=100); in contrast, with a p value\nof .001 posterior probability does not exceed .06 for N<=100 (neither .25 for\nN<9000). Yet more interesting, posterior probability becomes quite independent\nof N with a p value of .0001, hence practically satisfying the alpha postulate\n- set by Cornfield (1966) as the condition for p value being a measure of\nevidence in itself. In view of the low prospect that most researchers will soon\nconvert to use Bayesian statistics in any form, we thus suggest that\nresearchers who elect the conservative option of resorting to NHST be\nencouraged to avoid as much as possible using a p value of .05 as a threshold\nfor rejecting H0. The analysis presented here may be used to discuss afresh\nwhich level of threshold p value seems to be a reasonable, practical\nsubstitute.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 09:27:40 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Navon", "David", ""], ["Cohen", "Yoav", ""]]}]