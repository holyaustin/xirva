[{"id": "2009.00646", "submitter": "Yijun Zuo", "authors": "Yijun Zuo", "title": "Finite sample breakdown point of multivariate regression depth median", "comments": "20 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Depth induced multivariate medians (multi-dimensional maximum depth\nestimators) in regression serve as robust alternatives to the traditional least\nsquares and least absolute deviations estimators. The induced median\n($\\bs{\\beta}^*_{RD}$) from regression depth (RD) of Rousseeuw and Hubert (1999)\n(RH99) is one of the most prevailing estimators in regression.\n  The maximum regression depth median possesses outstanding robustness similar\nto the univariate location counterpart. Indeed, the %maximum depth estimator\ninduced from $\\mbox{RD}$, $\\bs{\\beta}^*_{RD}$ can, asymptotically, resist up to\n$33\\%$ contamination without breakdown, in contrast to the $0\\%$ for the\ntraditional estimators %(i.e. they could break down by a single bad point) (see\nVan Aelst and Rousseeuw, 2000) (VAR00). The results from VAR00 are pioneering\nand innovative, yet they are limited to regression symmetric populations and\nthe $\\epsilon$-contamination and maximum bias model.\n  With finite fixed sample size practice, the most prevailing measure of\nrobustness for estimators is the finite sample breakdown point (FSBP) (Donoho\n(1982), Donoho and Huber (1983)). A lower bound (LB) of the FSBP for the\n$\\bs{\\beta}^*_{RD}$, which is not sharp, was given in RH99 (in a corollary of a\nconjecture).\n  An exact FSBP (or even a sharper LB) for the $\\bs{\\beta}^*_{RD}$ remained\nopen in the last two decades. This article establishes a sharper lower and\nupper bounds of (and an exact) FSBP for the $\\bs{\\beta}^*_{RD}$, revealing an\nintrinsic connection between the regression depth of $\\bs{\\beta}^*_{RD}$ and\nits FSBP. This justifies the employment of the $\\bs{\\beta}^*_{RD}$ as a robust\nalternative to the traditional estimators and demonstrating the necessity and\nthe merit of using the FSBP in finite sample real practice instead of an\nasymptotic breakdown value.\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2020 18:15:50 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 01:54:43 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zuo", "Yijun", ""]]}, {"id": "2009.00912", "submitter": "Nikolaos Mastrantonas", "authors": "Nikolaos Mastrantonas, Pedro Herrera-Lormendez, Linus Magnusson,\n  Florian Pappenberger, J\\\"org Matschullat", "title": "Extreme precipitation events in the Mediterranean: Spatiotemporal\n  characteristics and connection to large-scale atmospheric flow patterns", "comments": "Submitted to International Journal of Climatology", "journal-ref": null, "doi": "10.1002/joc.6985", "report-no": null, "categories": "physics.ao-ph stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Mediterranean is strongly affected by Extreme Precipitation Events\n(EPEs), sometimes leading to negative impacts on society, economy, and the\nenvironment. Understanding such natural hazards and their drivers is essential\nto mitigate related risks. Here, EPEs over the Mediterranean between 1979 and\n2019 are analyzed, using ERA5 dataset from ECMWF. EPEs are determined based on\nthe 99th percentile of the daily distribution (P99). The different EPE\ncharacteristics are assessed, based on seasonality and spatiotemporal\ndependencies. To better understand the connection to large-scale atmospheric\nflow patterns, Empirical Orthogonal Function (EOF) analysis and subsequent\nK-means clustering are used to quantify the importance of weather regimes to\nEPE frequency. The analysis is performed for three different variables,\ndepicting atmospheric variability in the lower and middle troposphere: Sea\nlevel pressure (SLP), temperature at 850 hPa (T850), and geopotential height at\n500 hPa (Z500). Results show a clear spatial division in EPEs occurrence, with\nwinter (autumn) being the season of highest EPEs frequency for the eastern\n(western) Mediterranean. There is a high degree of temporal dependencies with\n20% of the EPEs (median value of all studied grid-cells), occurring up to 1\nweek after a preceding P99 event at the same location. Local orography is a key\nmodulator of the spatiotemporal connections and substantially enhances the\nprobability of co-occurrence of EPEs even for distant locations. The clustering\nclearly demonstrates the prevalence of distinct synoptic-scale atmospheric\nconditions during the occurrence of EPEs for different locations within the\nregion. Results indicate that clustering based on a combination of SLP and Z500\ncan increase the conditional probability of EPEs by more than three (3) times\n(median value for all grid cells) from the nominal probability of 1% for the\nP99 EPEs.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2020 09:30:15 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Mastrantonas", "Nikolaos", ""], ["Herrera-Lormendez", "Pedro", ""], ["Magnusson", "Linus", ""], ["Pappenberger", "Florian", ""], ["Matschullat", "J\u00f6rg", ""]]}, {"id": "2009.02099", "submitter": "Yudi Pawitan", "authors": "Yudi Pawitan", "title": "Defending the P-value", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attacks on the P-value are nothing new, but the recent attacks are\nincreasingly more serious. They come from more mainstream sources, with\nwidening targets such as a call to retire the significance testing altogether.\nWhile well meaning, I believe these attacks are nevertheless misdirected:\nBlaming the P-value for the naturally tentative trial-and-error process of\nscientific discoveries, and presuming that banning the P-value would make the\nprocess cleaner and less error-prone. However tentative, the skeptical\nscientists still have to form unambiguous opinions, proximately to move forward\nin their investigations and ultimately to present results to the wider\ncommunity. With obvious reasons, they constantly need to balance between the\nfalse-positive and false-negative errors. How would banning the P-value or\nsignificance tests help in this balancing act? It seems trite to say that this\nbalance will always depend on the relative costs or the trade-off between the\nerrors. These costs are highly context specific, varying by area of\napplications or by stage of investigation. A calibrated but tunable knob, such\nas that given by the P-value, is needed for controlling this balance. This\npaper presents detailed arguments in support of the P-value.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2020 10:29:07 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Pawitan", "Yudi", ""]]}, {"id": "2009.03650", "submitter": "Martin Roessler", "authors": "Martin Roessler, Jochen Schmitt, Olaf Schoffer", "title": "Can we trust the standardized mortality ratio? A formal analysis and\n  evaluation based on axiomatic requirements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The standardized mortality ratio (SMR) is often used to assess\nand compare hospital performance. While it has been recognized that hospitals\nmay differ in their SMRs due to differences in patient composition, there is a\nlack of rigorous analysis of this and other - largely unrecognized - properties\nof the SMR. Methods: This paper proposes five axiomatic requirements for\nadequate standardized mortality measures: strict monotonicity, case-mix\ninsensitivity, scale insensitivity, equivalence principle, and dominance\nprinciple. Given these axiomatic requirements, effects of variations in patient\ncomposition, hospital size, and actual and expected mortality rates on the SMR\nwere examined using basic algebra and calculus. In this regard, we\ndistinguished between standardization using expected mortality rates derived\nfrom a different dataset (external standardization) and standardization based\non a dataset including the considered hospitals (internal standardization).\nResults: Under external standardization, the SMR fulfills the axiomatic\nrequirements of strict monotonicity and scale insensitivity but violates the\nrequirement of case-mix insensitivity, the equivalence principle, and the\ndominance principle. All axiomatic requirements not fulfilled under external\nstandardization are also not fulfilled under internal standardization. In\naddition, the SMR under internal standardization is scale sensitive and\nviolates the axiomatic requirement of strict monotonicity. Conclusions: The SMR\nfulfills only two (none) out of the five proposed axiomatic requirements under\nexternal (internal) standardization. Generally, the SMRs of hospitals are\ndifferently affected by variations in case mix and actual and expected\nmortality rates unless the hospitals are identical in these characteristics.\nThese properties hamper valid assessment and comparison of hospital performance\nbased on the SMR.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 11:44:20 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Roessler", "Martin", ""], ["Schmitt", "Jochen", ""], ["Schoffer", "Olaf", ""]]}, {"id": "2009.04747", "submitter": "Mohammad Ghorbani Dr.", "authors": "Mohammad Ghorbani, Nafiseh Vafaei, Ji\\v{r}\\'i Dvo\\v{r}\\'ak, Mari\n  Myllym\\\"aki", "title": "Testing the first-order separability hypothesis for spatio-temporal\n  point patterns", "comments": "21 pages, 8 Figures (21 plots)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST stat.AP stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  First-order separability of a spatio-temporal point process plays a\nfundamental role in the analysis of spatio-temporal point pattern data. While\nit is often a convenient assumption that simplifies the analysis greatly,\nexisting non-separable structures should be accounted for in the model\nconstruction. We propose three different tests to investigate this hypothesis\nas a step of preliminary data analysis. The first two tests are exact or\nasymptotically exact for Poisson processes. The first test based on\npermutations and global envelopes allows us to detect at which spatial and\ntemporal locations or lags the data deviate from the null hypothesis. The\nsecond test is a simple and computationally cheap $\\chi^2$-test. The third test\nis based on statistical reconstruction method and can be generally applied for\nnon-Poisson processes. The performance of the first two tests is studied in a\nsimulation study for Poisson and non-Poisson models. The third test is applied\nto the real data of the UK 2001 epidemic foot and mouth disease.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2020 09:35:16 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Ghorbani", "Mohammad", ""], ["Vafaei", "Nafiseh", ""], ["Dvo\u0159\u00e1k", "Ji\u0159\u00ed", ""], ["Myllym\u00e4ki", "Mari", ""]]}, {"id": "2009.04834", "submitter": "Alex Cloud", "authors": "Alex Cloud, Eric Laber", "title": "Variance decompositions for extensive-form games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantitative measures of randomness in games are useful for game design and\nhave implications for gambling law. We treat the outcome of a game as a random\nvariable and derive a closed-form expression and estimator for the variance in\nthe outcome attributable to a player of the game. We analyze poker hands to\nshow that randomness in the cards dealt has little influence on the outcomes of\neach hand. A simple example is given to demonstrate how variance decompositions\ncan be used to measure other interesting properties of games.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2020 20:13:39 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Cloud", "Alex", ""], ["Laber", "Eric", ""]]}, {"id": "2009.05247", "submitter": "Morteza Mohammadi", "authors": "Morteza Mohammadi, Mohammad Amini, and Mahdi Emadi", "title": "A simulation study of semiparametric estimation in copula models based\n  on minimum Alpha-Divergence", "comments": "14 pages", "journal-ref": null, "doi": "10.19139/soic-2310-5070-974", "report-no": null, "categories": "stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to introduce two semiparametric methods for the\nestimation of copula parameter. These methods are based on minimum\nAlpha-Divergence between a non-parametric estimation of copula density using\nlocal likelihood probit transformation method and a true copula density\nfunction. A Monte Carlo study is performed to measure the performance of these\nmethods based on Hellinger distance and Neyman divergence as special cases of\nAlpha-Divergence. Simulation results are compared to the Maximum\nPseudo-Likelihood (MPL) estimation as a conventional estimation method in\nwell-known bivariate copula models. These results show that the proposed method\nbased on Minimum Pseudo Hellinger Distance estimation has a good performance in\nsmall sample size and weak dependency situations. The parameter estimation\nmethods are applied to a real data set in Hydrology.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 06:22:37 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Mohammadi", "Morteza", ""], ["Amini", "Mohammad", ""], ["Emadi", "Mahdi", ""]]}, {"id": "2009.05319", "submitter": "Sabarinath Vinod Nair", "authors": "Sabarinath Vinod Nair, Shreya Sharma and Swarnava Ghosh", "title": "A Study on the Possible Effects of the Implementation of the Nordic\n  Model in India on Crime Rates and Sexually Transmitted Diseases", "comments": "9 pages, 8 tables, 3 figures, Presented the research paper in a\n  National Conference on Theoretical and Applied Statistics held at Kristu\n  Jayanti College, Bengaluru. (January 2020), The Research paper was presented\n  at the 'Science Exhibition' held at CHRIST (Deemed to be University) and\n  secured the Second Runners' up. (March 2020)", "journal-ref": "Volume 5 Issue 9, September-2020", "doi": null, "report-no": "IJSDR2009049", "categories": "stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prostitution is one of the root causes of sex trafficking and the\ntransmission of sexual diseases. The rules and regulations followed by the\nIndian government to regulate the same, fall under the umbrella of the\nabolitionism model. Neo-abolitionism (also known as the Nordic model) is a new\nlegislative model that has been introduced by the Nordic countries to regulate\nprostitution. The purpose of this research paper is to examine the possible\neffects of the application of the Nordic model on the crime rates and the\nspread of sexually transmitted diseases in India. Further, we also aim to study\nthe effects of the implementation of Neo-abolitionism in Sweden.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2020 10:05:26 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Nair", "Sabarinath Vinod", ""], ["Sharma", "Shreya", ""], ["Ghosh", "Swarnava", ""]]}, {"id": "2009.06615", "submitter": "Ales Zahorski", "authors": "Ales Zahorski", "title": "Multilevel regression with poststratification for the national level\n  Viber/Street poll on the 2020 presidential election in Belarus", "comments": "45 pages, 23 figures, 18 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.LG stat.ME stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Independent sociological polls are forbidden in Belarus. Online polls\nperformed without sound scientific rigour do not yield representative results.\nYet, both inside and outside Belarus it is of great importance to obtain\nprecise estimates of the ratings of all candidates. These ratings could\nfunction as reliable proxies for the election's outcomes. We conduct an\nindependent poll based on the combination of the data collected via Viber and\non the streets of Belarus. The Viber and the street data samples consist of\nalmost 45000 and 1150 unique observations respectively. Bayesian regressions\nwith poststratification were build to estimate ratings of the candidates and\nrates of early voting turnout for the population as a whole and within various\nfocus subgroups. We show that both the officially announced results of the\nelection and early voting rates are highly improbable. With a probability of at\nleast 95%, Sviatlana Tikhanouskaya's rating lies between 75% and 80%, whereas\nAliaksandr Lukashenka's rating lies between 13% and 18% and early voting rate\npredicted by the method ranges from 9% to 13% of those who took part in the\nelection. These results contradict the officially announced outcomes, which are\n10.12%, 80.11%, and 49.54% respectively and lie far outside even the 99.9%\ncredible intervals predicted by our model. The only marginal groups of people\nwhere the upper bounds of the 99.9% credible intervals of the rating of\nLukashenka are above 50% are people older than 60 and uneducated people. For\nall other marginal subgroups, including rural residents, even the upper bounds\nof 99.9% credible intervals for Lukashenka are far below 50%. The same is true\nfor the population as a whole. Thus, with a probability of at least 99.9%\nLukashenka could not have had enough electoral support to win the 2020\npresidential election in Belarus.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2020 17:55:04 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Zahorski", "Ales", ""]]}, {"id": "2009.06810", "submitter": "Andrew Flores", "authors": "Andrew Z. Flores, Jessica Montag, Jon Willits", "title": "Using Known Words to Learn More Words: A Distributional Analysis of\n  Child Vocabulary Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why do children learn some words before others? Understanding individual\nvariability across children and also variability across words, may be\ninformative of the learning processes that underlie language learning. We\ninvestigated item-based variability in vocabulary development using lexical\nproperties of distributional statistics derived from a large corpus of\nchild-directed speech. Unlike previous analyses, we predicted word trajectories\ncross-sectionally, shedding light on trends in vocabulary development that may\nnot have been evident at a single time point. We also show that whether one\nlooks at a single age group or across ages as a whole, the best distributional\npredictor of whether a child knows a word is the number of other known words\nwith which that word tends to co-occur. Keywords: age of acquisition;\nvocabulary development; lexical diversity; child-directed speech;\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2020 01:18:21 GMT"}], "update_date": "2020-09-16", "authors_parsed": [["Flores", "Andrew Z.", ""], ["Montag", "Jessica", ""], ["Willits", "Jon", ""]]}, {"id": "2009.07765", "submitter": "Yaakov Malinovsky", "authors": "Yaakov Malinovsky", "title": "A note on the closed-form solution for the longest head run problem of\n  Abraham de Moivre", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of the longest head run was introduced and solved by Abraham de\nMoivre in the second edition of his book Doctrine of Chances (de Moivre, 1738).\nThe closed-form solution as a finite sum involving binomial coefficients was\nprovided in Uspensky (1937). Since then, the problem and its variations and\nextensions have found broad interest and diverse applications. Surprisingly, a\nvery simple closed form can be obtained, which we present in this note.\n", "versions": [{"version": "v1", "created": "Wed, 16 Sep 2020 15:48:33 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 16:26:05 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Malinovsky", "Yaakov", ""]]}, {"id": "2009.11646", "submitter": "Halaleh Kamari", "authors": "Halaleh Kamari, Sylvie Huet, Marie-Luce Taupin", "title": "Risk upper bounds for RKHS ridge group sparse estimator in the\n  regression model with non-Gaussian and non-bounded error", "comments": "Previously this appeared as arXiv:1905.13695v3 which was submitted as\n  a replacement by accident. arXiv admin note: text overlap with\n  arXiv:1701.04671", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of estimating a meta-model of an unknown regression\nmodel with non-Gaussian and non-bounded error. The meta-model belongs to a\nreproducing kernel Hilbert space constructed as a direct sum of Hilbert spaces\nleading to an additive decomposition including the variables and interactions\nbetween them. The estimator of this meta-model is calculated by minimizing an\nempirical least-squares criterion penalized by the sum of the Hilbert norm and\nthe empirical $L^2$-norm. In this context, the upper bounds of the empirical\n$L^2$ risk and the $L^2$ risk of the estimator are established.\n", "versions": [{"version": "v1", "created": "Tue, 22 Sep 2020 20:28:06 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Kamari", "Halaleh", ""], ["Huet", "Sylvie", ""], ["Taupin", "Marie-Luce", ""]]}]