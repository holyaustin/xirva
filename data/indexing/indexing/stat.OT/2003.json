[{"id": "2003.01973", "submitter": "Boya Lai", "authors": "Nozer D. Singpurwalla and Boya Lai", "title": "What Does the \"Mean\" Really Mean?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The arithmetic average of a collection of observed values of a homogeneous\ncollection of quantities is often taken to be the most representative\nobservation. There are several arguments supporting this choice the moment of\ninertia being the most familiar. But what does this mean?\n  In this note, we bring forth the Kolmogorov-Nagumo point of view that the\narithmetic average is a special case of a sequence of functions of a special\nkind, the quadratic and the geometric means being some of the other cases. The\nmedian fails to belong to this class of functions. The Kolmogorov-Nagumo\ninterpretation is the most defensible and the most definitive one for the\narithmetic average, but its essence boils down to the fact that this average is\nmerely an abstraction which has meaning only within its mathematical set-up.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 09:51:36 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Singpurwalla", "Nozer D.", ""], ["Lai", "Boya", ""]]}, {"id": "2003.02791", "submitter": "Lok Ting Yuen", "authors": "Christine Yuen and Piotr Fryzlewicz", "title": "Exploiting disagreement between high-dimensional variable selectors for\n  uncertainty visualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Combined Selection and Uncertainty Visualizer (CSUV), which\nestimates the set of true covariates in high-dimensional linear regression and\nvisualizes selection uncertainties by exploiting the (dis)agreement among\ndifferent base selectors. Our proposed method selects covariates that get\nselected the most frequently by the different variable selection methods on\nsubsampled data. The method is generic and can be used with different existing\nvariable selection methods. We demonstrate its variable selection performance\nusing real and simulated data. The variable selection method and its\nuncertainty illustration tool are publicly available as R package CSUV\n(https://github.com/christineyuen/CSUV). The graphical tool is also available\nonline via https://csuv.shinyapps.io/csuv\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 17:40:37 GMT"}], "update_date": "2020-03-06", "authors_parsed": [["Yuen", "Christine", ""], ["Fryzlewicz", "Piotr", ""]]}, {"id": "2003.02941", "submitter": "Mickael Albertus", "authors": "Mickael Albertus", "title": "Exponential increase of test power for Z-test and Chi-square test with\n  auxiliary information", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.AP stat.CO stat.ME stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this article is to study how an auxiliary information can be\nused to improve the power of two famous statistical tests: the $ Z$-test and\nthe chi-square test. This information can be of any nature - probability of\nsets of partitions, expectation of a function, ... - and is not even required\nto be an exact information, it can be given by an estimate based on a larger\nsample for example. Some definitions of auxiliary information can be found in\nthe statistical literature and will be recalled. In this article, the notion of\nauxiliary information is discussed here from a very general point of view.\nThese two statistical tests are modified so that the auxiliary information is\ntaken into account. One show in particular that the power of these tests is\nincreased exponentially. Some statistical examples are treated to show the\nconcreteness of this method.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 21:46:21 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Albertus", "Mickael", ""]]}, {"id": "2003.03098", "submitter": "Boya Lai", "authors": "Nozer D. Singpurwalla and Boya Lai", "title": "Bernoulli Trials With Skewed Propensities for Certification and\n  Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impetus for writing this paper are the well publicized media reports that\nsoftware failure was the cause of the two recent mishaps of the Boeing 737 Max\naircraft. The problem considered here though, is a specific one, in the sense\nthat it endeavors to address the general matter of conditions under which an\nitem such as a drug, a material specimen, or a complex, system can be certified\nfor use based on a large number of Bernoulli trials, all successful. More\nbroadly, the paper is an attempt to answer the old and honorable philosophical\nquestion, namely,\" when can empirical testing on its own validate a law of\nnature?\" Our message is that the answer depends on what one starts with,\nnamely, what is one's prior distribution, what unknown does this prior\ndistribution endow, and what has been observed as data.\n  The paper is expository in that it begins with a historical overview, and\nends with some new ideas and proposals for addressing the question posed. In\nthe sequel, it also articulates on Popper's notion of \"propensity\" and its role\nin providing a proper framework for Bayesian inference under Bernoulli trials,\nas well as the need to engage with posterior distributions that are\nsubjectively specified; that is, without a recourse to the usual Bayesian prior\nto posterior iteration.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 09:25:14 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Singpurwalla", "Nozer D.", ""], ["Lai", "Boya", ""]]}, {"id": "2003.03152", "submitter": "Boya Lai", "authors": "Nozer D. Singpurwalla and Boya Lai", "title": "How and Why Did Probability Theory Come About?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is a top down historical perspective on the several phases in the\ndevelopment of probability from its prehistoric origins to its modern day\nevolution, as one of the key methodologies in artificial intelligence, data\nscience, and machine learning. It is written in honor of Barry Arnold's\nbirthday for his many contributions to statistical theory and methodology.\nDespite the fact that much of Barry's work is technical, a descriptive document\nto mark his achievements should not be viewed as being out of line. Barry's\ndissertation adviser at Stanford (he received a Ph.D. in Statistics there) was\na philosopher of Science who dug deep in the foundations and roots of\nprobability, and it is this breadth of perspective is what Barry has inherent.\nThe paper is based on lecture materials compiled by the first author from\nvarious published sources, and over a long period of time. The material below\ngives a limited list of references, because the cast of characters is many, and\ntheir contributions are a part of the historical heritage of those of us who\nare interested in probability, statistics, and the many topics they have\nspawned.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 12:17:10 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Singpurwalla", "Nozer D.", ""], ["Lai", "Boya", ""]]}, {"id": "2003.03686", "submitter": "Stefano M. Iacus", "authors": "Stefano Maria Iacus and Fabrizio Natale and Michele Vespe", "title": "Flight restrictions from China during the COVID-2019 Coronavirus\n  outbreak", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short note provides estimates of the number of passengers that travel\nfrom China to all world airports in the period October 2019 - March 2020 on the\nbasis of historical data. From this baseline we subtract the expected reduction\nin the number of passengers taking into account the temporary ban of some\nroutes which was put in place since 23 January 2020 following the COVID-2019\nCoronavirus outbreak. The results indicate a reduction of the number of\npassengers in the period January - March 2020 of -2.5%. This calculation\nconsiders only the complete closure of routes (not just direct flights) and not\nthe reduction in the number of passengers on still active direct and indirect\nconnections. At the moment of writing, with such partial information it is\npremature to quantify economic losses on the civil air transport and tourism\nindustry. This note is meant to provide a baseline that be extended to all\ncountries of origin and updated as more recent data will become available.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 23:40:38 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Iacus", "Stefano Maria", ""], ["Natale", "Fabrizio", ""], ["Vespe", "Michele", ""]]}, {"id": "2003.03970", "submitter": "Jun Hu", "authors": "Jun Hu and Xianggui Qu", "title": "Bayes' Theorem under Conditional Independence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we provide a substantial discussion on the statistical\nconcept of conditional independence, which is not routinely mentioned in most\nelementary statistics and mathematical statistics textbooks. Under the\nassumption of conditional independence, an extended version of Bayes' Theorem\nis then proposed with illustrations from both hypothetical and real-world\nexamples of disease diagnosis.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 08:51:42 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Hu", "Jun", ""], ["Qu", "Xianggui", ""]]}, {"id": "2003.04008", "submitter": "Richard D. Gill", "authors": "R. D. Gill", "title": "Anna Karenina and The Two Envelopes Problem", "comments": "Final corrections (fingers crossed)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT math.PR math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Anna Karenina principle is named after the opening sentence in the\neponymous novel: Happy families are all alike; every unhappy family is unhappy\nin its own way. The Two Envelopes Problem (TEP) is a much-studied paradox in\nprobability theory, mathematical economics, logic, and philosophy. Time and\nagain a new analysis is published in which an author claims finally to explain\nwhat actually goes wrong in this paradox. Each author (the present author\nincluded) emphasizes what is new in their approach and concludes that earlier\napproaches did not get to the root of the matter. We observe that though a\nlogical argument is only correct if every step is correct, an apparently\nlogical argument which goes astray can be thought of as going astray at\ndifferent places. This leads to a comparison between the literature on TEP and\na successful movie franchise: it generates a succession of sequels, and even\nprequels, each with a different director who approaches the same basic premise\nin a personal way. We survey resolutions in the literature with a view to\nsynthesis, correct common errors, and give a new theorem on order properties of\nan exchangeable pair of random variables, at the heart of most TEP variants and\ninterpretations. A theorem on asymptotic independence between the amount in\nyour envelope and the question whether it is smaller or larger shows that the\npathological situation of improper priors or infinite expectation values has\nconsequences as we merely approach such a situation.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 09:54:28 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 10:03:23 GMT"}, {"version": "v3", "created": "Wed, 17 Mar 2021 10:11:04 GMT"}, {"version": "v4", "created": "Mon, 29 Mar 2021 08:50:22 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Gill", "R. D.", ""]]}, {"id": "2003.05510", "submitter": "Mariano Amo-Salas", "authors": "Jes\\'us L\\'opez-Fidalgo and Mariano Amo-Salas", "title": "Optimal dose calibration in radiotherapy", "comments": "17 pages, 3 figures, 2 tables", "journal-ref": null, "doi": "10.1016/j.radphyschem.2020.108917", "report-no": null, "categories": "stat.AP stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the tools provided by the theory of Optimal Experimental\nDesign are applied to a nonlinear calibration model. This is motivated by the\nneed of estimating radiation doses using radiochromic films for radiotherapy\npurposes. The calibration model is in this case nonlinear and the explanatory\nvariable cannot be worked out explicitly from the model. In this case an\nexperimental design has to be found on the dependent variable. For that, the\ninverse function theorem will be used to obtain an information matrix to be\noptimized. Optimal designs on the response variable are computed from two\ndifferent perspectives, first for fitting the model and estimating each of the\nparameters and then for predicting the proper dose to be applied to the\npatient. While the first is a common point of view in a general context of the\nOptimal Experimental Design, the latter is actually the main objective of the\ncalibration problem for the practitioners and algorithms for computing these\noptimal designs are also provided.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 20:23:04 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["L\u00f3pez-Fidalgo", "Jes\u00fas", ""], ["Amo-Salas", "Mariano", ""]]}, {"id": "2003.05814", "submitter": "Alejandro  Cholaquidis", "authors": "Alejandro Cholaquidis, Ricardo Fraiman, and Leonardo Moreno", "title": "Level set and density estimation on manifolds", "comments": "21 pages, y figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of the estimation of the level sets L_f({\\lambda}) of\nthe density f of a random vector X supported on a smooth manifold M\\subsetR^d ,\nfrom an iid sample of X. To do that we introduce a kernel-based estimator f^n,h\n, which is a slightly modified version of the one proposed in [45], and proves\nits a.s. uniform convergence to f . Then, we propose two estimators of L f\n({\\lambda}), the first one is a plug-in: L f^n,h ({\\lambda}), which is proven\nto be a.s. consistent in Hausdorff distance and distance in measure, if L\nf({\\lambda}) does not meet the boundary of M . While the second one assumes\nthat L f({\\lambda}) is r-convex, and is estimated by means of the r-convex hull\nof L f^n,h({\\lambda}). The performance of our proposal is illustrated through\nsome simulated examples. In a real data example we analyze the intensity and\ndirection of strong and moderate winds.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 14:19:01 GMT"}, {"version": "v2", "created": "Sun, 28 Mar 2021 01:13:47 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Cholaquidis", "Alejandro", ""], ["Fraiman", "Ricardo", ""], ["Moreno", "Leonardo", ""]]}, {"id": "2003.06500", "submitter": "Dirk Eddelbuettel", "authors": "Dirk Eddelbuettel and Alton Barbehenn", "title": "An R Autograder for PrairieLearn", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe how we both use and extend the PrarieLearn framework by taking\nadvantage of its built-in support for external auto-graders. By using a custom\nDocker container, we can match our course requirements perfectly. Moreover, by\nrelying on the flexibility of the interface we can customize our Docker\ncontainer. A specific extension for unit testing is described which creates\ncontext-dependent difference between student answers and reference solution\nproviding a more comprehensive response at test time.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 22:46:48 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Eddelbuettel", "Dirk", ""], ["Barbehenn", "Alton", ""]]}, {"id": "2003.06797", "submitter": "David Salgado", "authors": "David Salgado and Bogdan Oancea", "title": "On new data sources for the production of official statistics", "comments": "38 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past years we have witnessed the rise of new data sources for the\npotential production of official statistics, which, by and large, can be\nclassified as survey, administrative, and digital data. Apart from the\ndifferences in their generation and collection, we claim that their lack of\nstatistical metadata, their economic value, and their lack of ownership by data\nholders pose several entangled challenges lurking the incorporation of new data\ninto the routinely production of official statistics. We argue that every\nchallenge must be duly overcome in the international community to bring new\nstatistical products based on these sources. These challenges can be naturally\nclassified into different entangled issues regarding access to data,\nstatistical methodology, quality, information technologies, and management. We\nidentify the most relevant to be necessarily tackled before new data sources\ncan be definitively considered fully incorporated into the production of\nofficial statistics.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2020 11:33:18 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Salgado", "David", ""], ["Oancea", "Bogdan", ""]]}, {"id": "2003.09507", "submitter": "Thomas Muehlenstaedt", "authors": "Thomas Muehlenstaedt, Maria Lanzerath", "title": "Space Filling Split Plot Design using Fast Flexible Filling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, an adaption of an algorithm for the creation of experimental\ndesigns by Lekivetz and Jones (2015) is suggested, dealing with constraints\naround randomization. Split-plot design of experiments is used, when the levels\nof some factors cannot be modified as easily as others. While most split-plot\ndesigns deal in the context of I-optimal or D-optimal designs for continuous\nresponse outputs, a space filling design strategy is suggested in here. The\nproposed designs are evaluated based on different design criteria, as well as\nan analytical example.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 21:39:48 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Muehlenstaedt", "Thomas", ""], ["Lanzerath", "Maria", ""]]}, {"id": "2003.09650", "submitter": "Vydas \\v{C}ekanavi\\v{c}ius", "authors": "V. \\v{C}ekanavi\\v{c}ius and P. Vellaisamy", "title": "Compound Poisson approximations in $\\ell_p$-norm for sums of weakly\n  dependent vectors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distribution of the sum of 1-dependent lattice vectors with supports on\ncoordinate axes is approximated by a multivariate compound Poisson distribution\nand by signed compound Poisson measure. The local and $\\ell_\\alpha$-norms are\nused to obtain the error bounds. The Heinrich method is used for the proofs.\n", "versions": [{"version": "v1", "created": "Sat, 21 Mar 2020 13:03:30 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 11:20:24 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["\u010cekanavi\u010dius", "V.", ""], ["Vellaisamy", "P.", ""]]}, {"id": "2003.10234", "submitter": "Romit Maulik", "authors": "Romit Maulik, Junghwa Choi, Wesley Wehde, Prasanna Balaprakash", "title": "Determining feature importance for actionable climate change mitigation\n  policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the importance of public support for policy change and implementation,\npublic policymakers and researchers have attempted to understand the factors\nassociated with this support for climate change mitigation policy. In this\narticle, we compare the feasibility of using different supervised learning\nmethods for regression using a novel socio-economic data set which measures\npublic support for potential climate change mitigation policies. Following this\nmodel selection, we utilize gradient boosting regression, a well-known\ntechnique in the machine learning community, but relatively uncommon in public\npolicy and public opinion research, and seek to understand what factors among\nthe several examined in previous studies are most central to shaping public\nsupport for mitigation policies in climate change studies. The use of this\nmethod provides novel insights into the most important factors for public\nsupport for climate change mitigation policies. Using national survey data, we\nfind that the perceived risks associated with climate change are more decisive\nfor shaping public support for policy options promoting renewable energy and\nregulating pollutants. However, we observe a very different behavior related to\npublic support for increasing the use of nuclear energy where climate change\nrisk perception is no longer the sole decisive feature. Our findings indicate\nthat public support for renewable energy is inherently different from that for\nnuclear energy reliance with the risk perception of climate change, dominant\nfor the former, playing a subdued role for the latter.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 01:06:52 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Maulik", "Romit", ""], ["Choi", "Junghwa", ""], ["Wehde", "Wesley", ""], ["Balaprakash", "Prasanna", ""]]}, {"id": "2003.10878", "submitter": "Giulio D'Agostini", "authors": "Giulio D'Agostini", "title": "The Gauss' Bayes Factor", "comments": "13 pages, 2 figures (Version 2 benefits of editorial improvements)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.HO math.ST physics.data-an physics.hist-ph stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 'Theoria motus corporum coelestium in sectionibus conicis solem ambientum'\nGauss presents, as a theorem and with emphasis, the rule to update the ratio of\nprobabilities of complementary hypotheses, in the light of an observed event\nwhich could be due to either of them. Although he focused on a priori equally\nprobable hypotheses, in order to solve the problem on which he was interested\nin, the theorem can be easily extended to the general case. But, curiously, I\nhave not been able to find references to his result in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 10:22:39 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2020 13:19:17 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["D'Agostini", "Giulio", ""]]}, {"id": "2003.11021", "submitter": "Gian Maria Campedelli", "authors": "Gian Maria Campedelli, Alberto Aziani, Serena Favarin", "title": "Exploring the Effects of COVID-19 Containment Policies on Crime: An\n  Empirical Analysis of the Short-term Aftermath in Los Angeles", "comments": "40 pages, 3 figures. Forthcoming at American Journal of Criminal\n  Justice", "journal-ref": "Am J Crim Just (2020)", "doi": "10.1007/s12103-020-09578-6", "report-no": null, "categories": "stat.OT econ.GN q-fin.EC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This work investigates whether and how COVID-19 containment policies had an\nimmediate impact on crime trends in Los Angeles. The analysis is conducted\nusing Bayesian structural time-series and focuses on nine crime categories and\non the overall crime count, daily monitored from January 1st 2017 to March 28th\n2020. We concentrate on two post-intervention time windows - from March 4th to\nMarch 16th and from March 4th to March 28th 2020 - to dynamically assess the\nshort-term effects of mild and strict policies. In Los Angeles, overall crime\nhas significantly decreased, as well as robbery, shoplifting, theft, and\nbattery. No significant effect has been detected for vehicle theft, burglary,\nassault with a deadly weapon, intimate partner assault, and homicide. Results\nsuggest that, in the first weeks after the interventions are put in place,\nsocial distancing impacts more directly on instrumental and less serious\ncrimes. Policy implications are also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 22:36:21 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2020 22:54:33 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 09:02:46 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Campedelli", "Gian Maria", ""], ["Aziani", "Alberto", ""], ["Favarin", "Serena", ""]]}, {"id": "2003.11635", "submitter": "Peter Aronow", "authors": "Peter M. Aronow, Fredrik S\\\"avje", "title": "Review of The Book of Why: The New Science of Cause and Effect", "comments": null, "journal-ref": "J. Amer. Statist. Assoc. (2020) 115: 482--485", "doi": "10.1080/01621459.2020.1721245", "report-no": null, "categories": "stat.OT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Book review published as: Aronow, Peter M. and Fredrik S\\\"avje (2020), \"The\nBook of Why: The New Science of Cause and Effect.\" Journal of the American\nStatistical Association, 115: 482-485.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 21:03:51 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Aronow", "Peter M.", ""], ["S\u00e4vje", "Fredrik", ""]]}, {"id": "2003.12530", "submitter": "Renata Pelissari", "authors": "Renata Pelissari and Leonardo Tomazeli Duarte", "title": "Identification of Choquet capacity in multicriteria sorting problems\n  through stochastic inverse analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multicriteria decision aiding (MCDA), the Choquet integral has been used\nas an aggregation operator to deal with the case of interacting decision\ncriteria. While the application of the Choquet integral for ranking problems\nhave been receiving most of the attention, this paper rather focuses on\nmulticriteria sorting problems (MCSP). In the Choquet integral context, a\npractical problem that arises is related to the elicitation of parameters known\nas the Choquet capacities. We address the problem of Choquet capacity\nidentification for MCSP by applying the Stochastic Acceptability Multicriteri\nAnalysis (SMAA), proposing the SMAA-S-Choquet method. The proposed method is\nalso able to model uncertain data that may be present in both decision matrix\nand limiting profiles, the latter a parameter associated with the sorting\nproblematic. We also introduce two new descriptive measures in order to conduct\nreverse analysis regarding the capacities: the Scenario Acceptability Index and\nthe Scenario Central Capacity vector.\n", "versions": [{"version": "v1", "created": "Fri, 27 Mar 2020 16:46:09 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Pelissari", "Renata", ""], ["Duarte", "Leonardo Tomazeli", ""]]}, {"id": "2003.13518", "submitter": "F. E. Guerra-Pujol", "authors": "F. E. Guerra-Pujol", "title": "Ramsey's contributions to probability and legal theory", "comments": "book review, 16 pp", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Review of Cheryl Misak, Frank Ramsey: A Sheer Excess of Powers (Oxford\nUniversity Press, 2020).\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 14:45:25 GMT"}, {"version": "v2", "created": "Mon, 13 Jul 2020 23:32:21 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Guerra-Pujol", "F. E.", ""]]}]