[{"id": "1410.0403", "submitter": "Thomas Muehlenstaedt", "authors": "Thomas Muehlenstaedt, Jana Fruth, Olivier Roustant", "title": "Computer experiments with functional inputs and scalar outputs by a\n  norm-based approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework for designing and analyzing computer experiments is presented,\nwhich is constructed for dealing with functional and real number inputs and\nreal number outputs. For designing experiments with both functional and real\nnumber inputs a two stage approach is suggested. The first stage consists of\nconstructing a candidate set for each functional input and during the second\nstage an optimal combination of the found candidate sets and a Latin hypercube\nfor the real number inputs is searched for. The resulting designs can be\nconsidered to be generalizations of Latin hypercubes. GP models are explored as\nmetamodel. The functional inputs are incorporated into the kriging model by\napplying norms in order to define distances between two functional inputs. In\norder to make the calculation of these norms computationally feasible, the use\nof B-splines is promoted.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 22:37:08 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Muehlenstaedt", "Thomas", ""], ["Fruth", "Jana", ""], ["Roustant", "Olivier", ""]]}, {"id": "1410.1107", "submitter": "Roger Bilisoly", "authors": "Roger Bilisoly", "title": "Using Board Games and Mathematica to Teach the Fundamentals of Finite\n  Stationary Markov Chains", "comments": "A proceedings article based on a Joint Statistical Meetings talk in\n  2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov chains are an important example for a course on stochastic processes\nbecause simple board games can be used to illustrate the fundamental concepts.\nFor example, a looping board game (like Monopoly) consists of all recurrent\nstates, and a game where players win by reaching a final square (like Chutes\nand Ladders) consists of all transient states except for the last one. With the\navailability of computer algebra packages, these games can be analyzed. For\nexample, the mean times in transient states and the stationary probabilities\nfor recurrent states are easily computed. This article analyzes some simple\nboard games with Mathematica, and indicates how this can be extended to more\ncomplex situations.\n", "versions": [{"version": "v1", "created": "Sun, 5 Oct 2014 01:49:22 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Bilisoly", "Roger", ""]]}, {"id": "1410.1802", "submitter": "Enkelejd Hashorva", "authors": "E. Hashorva and Z. Tan", "title": "Piterbarg's max-discretisation theorem for stationary vector Gaussian\n  processes observed on different grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST stat.OT stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we derive Piterbarg's max-discretisation theorem for two\ndifferent grids considering centered stationary vector Gaussian processes. So\nfar in the literature results in this direction have been derived for the joint\ndistribution of the maximum of Gaussian processes over $[0,T]$ and over a grid\n$ \\mathfrak{R}(\\delta_1(T))=\\{k\\delta_1(T): k=0,1,\\cdots\\}$. In this paper we\nextend recent findings by considering additionally the \\bE{maximum} over\nanother grid $ \\mathfrak{R}(\\delta_2(T))$. We derive the joint limiting\ndistribution of maximum of stationary Gaussian vector processes for different\nchoices of such grids by letting $T\\to \\infty$.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2014 16:39:23 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Hashorva", "E.", ""], ["Tan", "Z.", ""]]}, {"id": "1410.2759", "submitter": "Johanna Hardin", "authors": "Johanna Hardin, Ghassan Sarkis, and P.C. Urc", "title": "Network Analysis with the Enron Email Corpus", "comments": "in Journal of Statistics Education, Volume 23, Number 2, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the Enron email corpus to study relationships in a network by applying\nsix different measures of centrality. Our results came out of an in-semester\nundergraduate research seminar. The Enron corpus is well suited to statistical\nanalyses at all levels of undergraduate education. Through this note's focus on\ncentrality, students can explore the dependence of statistical models on\ninitial assumptions and the interplay between centrality measures and\nhierarchical ranking, and they can use completed studies as springboards for\nfuture research. The Enron corpus also presents opportunities for research into\nmany other areas of analysis, including social networks, clustering, and\nnatural language processing.\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2014 12:14:46 GMT"}, {"version": "v2", "created": "Fri, 9 Jan 2015 19:22:58 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2015 20:25:38 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["Hardin", "Johanna", ""], ["Sarkis", "Ghassan", ""], ["Urc", "P. C.", ""]]}, {"id": "1410.3127", "submitter": "Johanna Hardin", "authors": "Johanna Hardin, Roger Hoerl, Nicholas J. Horton, Deborah Nolan", "title": "Data Science in Statistics Curricula: Preparing Students to \"Think with\n  Data\"", "comments": null, "journal-ref": null, "doi": "10.1080/00031305.2015.1077729", "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of students are completing undergraduate degrees in\nstatistics and entering the workforce as data analysts. In these positions,\nthey are expected to understand how to utilize databases and other data\nwarehouses, scrape data from Internet sources, program solutions to complex\nproblems in multiple languages, and think algorithmically as well as\nstatistically. These data science topics have not traditionally been a major\ncomponent of undergraduate programs in statistics. Consequently, a curricular\nshift is needed to address additional learning outcomes. The goal of this paper\nis to motivate the importance of data science proficiency and to provide\nexamples and resources for instructors to implement data science in their own\nstatistics curricula. We provide case studies from seven institutions. These\nvaried approaches to teaching data science demonstrate curricular innovations\nto address new needs. Also included here are examples of assignments designed\nfor courses that foster engagement of undergraduates with data and data\nscience.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 18:17:04 GMT"}, {"version": "v2", "created": "Wed, 22 Apr 2015 11:27:18 GMT"}, {"version": "v3", "created": "Tue, 4 Aug 2015 20:16:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Hardin", "Johanna", ""], ["Hoerl", "Roger", ""], ["Horton", "Nicholas J.", ""], ["Nolan", "Deborah", ""]]}, {"id": "1410.3929", "submitter": "Juan Augusto Maya Eng.", "authors": "Juan Augusto Maya, Leonardo Rey Vega and Cecilia G. Galarza", "title": "Distributed Detection of a Random Process over a Multiple Access Channel\n  under Energy and Bandwidth Constraints", "comments": "This paper was submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT cs.IT math.IT stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a binary hypothesis testing problem built on a wireless sensor\nnetwork (WSN) for detecting a stationary random process distributed both in\nspace and time with circularly-symmetric complex Gaussian distribution under\nthe Neyman-Pearson framework. Using an analog scheme, the sensors transmit\ndifferent linear combinations of their measurements through a multiple access\nchannel (MAC) to reach the fusion center (FC), whose task is to decide whether\nthe process is present or not. Considering an energy constraint on each node\ntransmission and a limited amount of channel uses, we compute the miss error\nexponent of the proposed scheme using Large Deviation Theory (LDT) and show\nthat the proposed strategy is asymptotically optimal (when the number of\nsensors approaches to infinity) among linear orthogonal schemes. We also show\nthat the proposed scheme obtains significant energy saving in the low\nsignal-to-noise ratio regime, which is the typical scenario of WSNs. Finally, a\nMonte Carlo simulation of a 2-dimensional process in space validates the\nanalytical results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 04:47:12 GMT"}], "update_date": "2014-10-20", "authors_parsed": [["Maya", "Juan Augusto", ""], ["Vega", "Leonardo Rey", ""], ["Galarza", "Cecilia G.", ""]]}, {"id": "1410.4515", "submitter": "Kung-Sik Chan", "authors": "Kung-Sik Chan, Qiwei Yao", "title": "A Conversation with Howell Tong", "comments": "Published in at http://dx.doi.org/10.1214/13-STS464 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2014, Vol. 29, No. 3, 425-438", "doi": "10.1214/13-STS464", "report-no": "IMS-STS-STS464", "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following conversation is partly based on an interview that took place in\nthe Hong Kong University of Science and Technology in July 2013.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 13:15:50 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Chan", "Kung-Sik", ""], ["Yao", "Qiwei", ""]]}, {"id": "1410.5772", "submitter": "Lutz Bornmann Dr.", "authors": "Lutz Bornmann, Werner Marx", "title": "Methods for the generation of normalized citation impact scores in\n  bibliometrics: Which method best reflects the judgements of experts?", "comments": "Accepted for publication in the Journal of Informetrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluative bibliometrics compares the citation impact of researchers,\nresearch groups and institutions with each other across time scales and\ndisciplines. Both factors - discipline and period - have an influence on the\ncitation count which is independent of the quality of the publication.\nNormalizing the citation impact of papers for these two factors started in the\nmid-1980s. Since then, a range of different methods have been presented for\nproducing normalized citation impact scores. The current study uses a data set\nof over 50,000 records to test which of the methods so far presented correlate\nbetter with the assessment of papers by peers. The peer assessments come from\nF1000Prime - a post-publication peer review system of the biomedical\nliterature. Of the normalized indicators, the current study involves not only\ncited-side indicators, such as the mean normalized citation score, but also\nciting-side indicators. As the results show, the correlations of the indicators\nwith the peer assessments all turn out to be very similar. Since F1000 focuses\non biomedicine, it is important that the results of this study are validated by\nother studies based on datasets from other disciplines or (ideally) based on\nmulti-disciplinary datasets.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 07:57:32 GMT"}, {"version": "v2", "created": "Tue, 9 Dec 2014 10:58:06 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Bornmann", "Lutz", ""], ["Marx", "Werner", ""]]}, {"id": "1410.6002", "submitter": "J. Martin van Zyl", "authors": "J. Martin van Zyl", "title": "Estimating the Tail Index by using Model Averaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ideas of model averaging are used to find weights in peak-over-threshold\nproblems using a possible range of thresholds. A range of the largest\nobservations are chosen and considered as possible thresholds, each time\nperforming estimation. Weights based on an information criterion for each\nthreshold are calculated. A weighted estimate of the threshold and shape\nparameter can be calculated.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 11:20:45 GMT"}, {"version": "v2", "created": "Wed, 29 Oct 2014 10:17:21 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["van Zyl", "J. Martin", ""]]}, {"id": "1410.7967", "submitter": "Michael Wakin", "authors": "Chia Wei Lim and Michael B. Wakin", "title": "Technical Report: Compressive Temporal Higher Order Cyclostationary\n  Statistics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of nonlinear transformations to a cyclostationary signal for\nthe purpose of revealing hidden periodicities has proven to be useful for\napplications requiring signal selectivity and noise tolerance. The fact that\nthe hidden periodicities, referred to as cyclic moments, are often compressible\nin the Fourier domain motivates the use of compressive sensing (CS) as an\nefficient acquisition protocol for capturing such signals. In this work, we\nconsider the class of Temporal Higher Order Cyclostationary Statistics (THOCS)\nestimators when CS is used to acquire the cyclostationary signal assuming\ncompressible cyclic moments in the Fourier domain. We develop a theoretical\nframework for estimating THOCS using the low-rate nonuniform sampling protocol\nfrom CS and illustrate the performance of this framework using simulated data.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 13:20:14 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Lim", "Chia Wei", ""], ["Wakin", "Michael B.", ""]]}, {"id": "1410.8868", "submitter": "Glenn Webb Dr", "authors": "Glenn Webb", "title": "Precinct Size Matters - The Large Precinct Bias in US Presidential\n  Elections", "comments": "14 pages, 12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Examination of precinct level data in US presidential elections reveals a\ncorrelation of large precincts and increased fraction of Republican votes. The\nlarge precinct bias is analyzed with respect to voter heterogeneity and voter\ninconvenience as precinct size increases. The analysis shows that voter\ninconvenience is a significant factor in election outcomes in certain states,\nand may significantly disadvantage Democratic candidates.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 17:58:15 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Webb", "Glenn", ""]]}]