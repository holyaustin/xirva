[{"id": "1310.2442", "submitter": "Miron L. Straf", "authors": "Miron L. Straf, Judith M. Tanur", "title": "A Conversation with Stephen E. Fienberg", "comments": "Published in at http://dx.doi.org/10.1214/12-STS411 the Statistical\n  Science (http://www.imstat.org/sts/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistical Science 2013, Vol. 28, No. 3, 447-463", "doi": "10.1214/12-STS411", "report-no": "IMS-STS-STS411", "categories": "stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The following conversation is based in part on a transcript of a 2009\ninterview funded by Pfizer Global Research-Connecticut, the American\nStatistical Association and the Department of Statistics at the University of\nConnecticut-Storrs as part of the \"Conversations with Distinguished\nStatisticians in Memory of Professor Harry O. Posten\".\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 11:46:37 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Straf", "Miron L.", ""], ["Tanur", "Judith M.", ""]]}, {"id": "1310.7141", "submitter": "Amy Wagaman", "authors": "Amy S. Wagaman", "title": "Meeting Student Needs for Multivariate Data Analysis: A Case Study in\n  Teaching a Multivariate Data Analysis Course with No Pre-requisites", "comments": "Article is 20 pages. Appendix is 20 pages of example material from\n  the course", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.OT physics.ed-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern students encounter big, messy data sets long before setting foot in\nour classrooms. Many of our students need to develop skills in exploratory data\nanalysis and multivariate analysis techniques for their jobs after college, but\nthese topics are not covered in introductory statistics courses. This case\nstudy describes my experience in designing and teaching a course on\nmultivariate data analysis with no pre-requisites, using real data, active\nlearning, and other activities to help students tackle the material.\n", "versions": [{"version": "v1", "created": "Sat, 26 Oct 2013 18:40:08 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Wagaman", "Amy S.", ""]]}, {"id": "1310.7163", "submitter": "Lihong Li", "authors": "Lihong Li", "title": "Generalized Thompson Sampling for Contextual Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thompson Sampling, one of the oldest heuristics for solving multi-armed\nbandits, has recently been shown to demonstrate state-of-the-art performance.\nThe empirical success has led to great interests in theoretical understanding\nof this heuristic. In this paper, we approach this problem in a way very\ndifferent from existing efforts. In particular, motivated by the connection\nbetween Thompson Sampling and exponentiated updates, we propose a new family of\nalgorithms called Generalized Thompson Sampling in the expert-learning\nframework, which includes Thompson Sampling as a special case. Similar to most\nexpert-learning algorithms, Generalized Thompson Sampling uses a loss function\nto adjust the experts' weights. General regret bounds are derived, which are\nalso instantiated to two important loss functions: square loss and logarithmic\nloss. In contrast to existing bounds, our results apply to quite general\ncontextual bandits. More importantly, they quantify the effect of the \"prior\"\ndistribution on the regret bounds.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2013 06:29:55 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Li", "Lihong", ""]]}]