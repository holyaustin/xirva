[{"id": "1606.00144", "submitter": "Jesus Malo", "authors": "Borja Galan, Marina Martinez-Garcia, Praveen Cyriac, Thomas Batard,\n  Marcelo Bertalmio and Jesus Malo", "title": "Derivatives and inverse of a linear-nonlinear multi-layer spatial vision\n  model", "comments": "Paper: 26 pages, 49 references, plus 32 slides from MODVIS-16\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear-nonlinear transforms are interesting in vision science because they\nare key in modeling a number of perceptual experiences such as color, motion or\nspatial texture. Here we first show that a number of issues in vision may be\naddressed through an analytic expression of the Jacobian of these\nlinear-nonlinear transforms. The particular model analyzed afterwards (an\nextension of [Malo & Simoncelli SPIE 2015]) is illustrative because it consists\nof a cascade of standard linear-nonlinear modules. Each module roughly\ncorresponds to a known psychophysical mechanism: (1) linear spectral\nintegration and nonlinear brightness-from-luminance computation, (2) linear\npooling of local brightness and nonlinear normalization for local contrast\ncomputation, (3) linear frequency selectivity and nonlinear normalization for\nspatial contrast masking, and (4) linear wavelet-like decomposition and\nnonlinear normalization for frequency-dependent masking. Beyond being the\nappropriate technical report with the missing details in [Malo & Simoncelli\nSPIE 2015], the interest of the presented analytic results and numerical\nmethods transcend the particular model because of the ubiquity of the\nlinear-nonlinear structure. Part of this material was presented at MODVIS 2016\n(see slides of the conference talk in the appendix at the end of this\ndocument).\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 07:32:02 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2016 05:35:39 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Galan", "Borja", ""], ["Martinez-Garcia", "Marina", ""], ["Cyriac", "Praveen", ""], ["Batard", "Thomas", ""], ["Bertalmio", "Marcelo", ""], ["Malo", "Jesus", ""]]}, {"id": "1606.00157", "submitter": "Zhaofei Yu", "authors": "Zhaofei Yu, David Kappel, Robert Legenstein, Sen Song, Feng Chen,\n  Wolfgang Maass", "title": "CaMKII activation supports reward-based neural network optimization\n  through Hamiltonian sampling", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic plasticity is implemented and controlled through over thousand\ndifferent types of molecules in the postsynaptic density and presynaptic\nboutons that assume a staggering array of different states through\nphosporylation and other mechanisms. One of the most prominent molecule in the\npostsynaptic density is CaMKII, that is described in molecular biology as a\n\"memory molecule\" that can integrate through auto-phosporylation Ca-influx\nsignals on a relatively large time scale of dozens of seconds. The functional\nimpact of this memory mechanism is largely unknown. We show that the\nexperimental data on the specific role of CaMKII activation in dopamine-gated\nspine consolidation suggest a general functional role in speeding up\nreward-guided search for network configurations that maximize reward\nexpectation. Our theoretical analysis shows that stochastic search could in\nprinciple even attain optimal network configurations by emulating one of the\nmost well-known nonlinear optimization methods, simulated annealing. But this\noptimization is usually impeded by slowness of stochastic search at a given\ntemperature. We propose that CaMKII contributes a momentum term that\nsubstantially speeds up this search. In particular, it allows the network to\novercome saddle points of the fitness function. The resulting improved\nstochastic policy search can be understood on a more abstract level as\nHamiltonian sampling, which is known to be one of the most efficient stochastic\nsearch methods.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 08:12:34 GMT"}, {"version": "v2", "created": "Thu, 29 Sep 2016 09:51:22 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 16:57:22 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Yu", "Zhaofei", ""], ["Kappel", "David", ""], ["Legenstein", "Robert", ""], ["Song", "Sen", ""], ["Chen", "Feng", ""], ["Maass", "Wolfgang", ""]]}, {"id": "1606.00257", "submitter": "Damien Chablat", "authors": "Jing Chang (IRCCyN), Damien Chablat (IRCCyN), Fouad Bennis (IRCCyN),\n  Liang Ma", "title": "Estimating the EMG response exclusively to fatigue during sustained\n  static maximum voluntary contraction", "comments": "7th International Conference on Applied Human Factors and Ergonomics,\n  Jul 2016, Orlando United States. 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.TO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase of surface electromyography (sEMG) root-mean-square (RMS) is\nvery frequently used to determine fatigue. However, as RMS is also influenced\nby muscle force,its effective usage as indicator of fatigue is mainly limited\nto isometric, constant force tasks.This research develops a simple me-thodto\npreclude the effect of muscle force, hereby estimates the EMG amplitude\nresponse exclusively to fatigue with RMS. Experiment was carried out on the\nbiceps brachiis of 15 subjects (7males, 8 females) during sustained static\nmaximum voluntary contractions (sMVC).Result shows that the sEMG RMS response\nto fatigue increasesto 21.27% while muscle force decreasing to 50%MVC, which\nimplies that more and more extra effort is needed as muscle fatigue\nintensifies. It would be promising to use the RMS response exclusively to\nfatigue as an indicator of muscle fatigue.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 13:06:26 GMT"}], "update_date": "2016-06-02", "authors_parsed": [["Chang", "Jing", "", "IRCCyN"], ["Chablat", "Damien", "", "IRCCyN"], ["Bennis", "Fouad", "", "IRCCyN"], ["Ma", "Liang", ""]]}, {"id": "1606.00258", "submitter": "Valeriy I. Sbitnev", "authors": "Valeriy I. Sbitnev", "title": "Quantum consciousness in warm, wet, and noisy brain", "comments": "20 pages, 11 figures", "journal-ref": "Mod. Phys. Lett. B, v. 30, 1650329 (25 pages), 2016", "doi": "10.1142/S0217984916503292", "report-no": null, "categories": "q-bio.NC physics.flu-dyn quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of quantum consciousness stems from dynamic flows of hydrogen\nions in brain liquid. This liquid contains vast areas of the fourth phase of\nwater with hexagonal packing of its molecules, the so-called exclusion zone\n(EZ) of water. The hydrogen ion motion on such hexagonal lattices shows as the\nhopping of the ions forward and the holes (vacant places) backward, caused by\nthe Grotthuss mechanism. By supporting this motion using external infrasound\nsources, one may achieve the appearance of the superfluid state of the EZ\nwater. Flows of the hydrogen ions are described by the modified Navier-Stokes\nequation. It, along with the continuity equation, yields the nonlinear\nSchrodinger equation, which describes the quantum effects of these flows, such\nas the tunneling at long distances or the interference on gap junctions.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2016 10:47:02 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2016 07:25:56 GMT"}, {"version": "v3", "created": "Thu, 14 Jul 2016 08:26:28 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Sbitnev", "Valeriy I.", ""]]}, {"id": "1606.00800", "submitter": "Brian Mitchell", "authors": "Brian A. Mitchell and Linda R. Petzold", "title": "Multi-View Treelet Transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.SI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current multi-view factorization methods make assumptions that are not\nacceptable for many kinds of data, and in particular, for graphical data with\nhierarchical structure. At the same time, current hierarchical methods work\nonly in the single-view setting. We generalize the Treelet Transform to the\nMulti-View Treelet Transform (MVTT) to allow for the capture of hierarchical\nstructure when multiple views are available. Further, we show how this\ngeneralization is consistent with the existing theory and how it might be used\nin denoising empirical networks and in computing the shared response of\nfunctional brain data.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jun 2016 18:51:09 GMT"}, {"version": "v2", "created": "Fri, 17 Jun 2016 19:07:46 GMT"}], "update_date": "2016-06-20", "authors_parsed": [["Mitchell", "Brian A.", ""], ["Petzold", "Linda R.", ""]]}, {"id": "1606.00821", "submitter": "Diego Mateos", "authors": "R. Guevara Erra, D. M. Mateos, R. Wennberg, J.L. Perez Velazquez", "title": "Towards a statistical mechanics of consciousness: maximization of number\n  of connections is associated with conscious awareness", "comments": "17 page, 4 figures, 2 tables", "journal-ref": null, "doi": "10.1103/PhysRevE.94.052402", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  It has been said that complexity lies between order and disorder. In the case\nof brain activity, and physiology in general, complexity issues are being\nconsidered with increased emphasis. We sought to identify features of brain\norganization that are optimal for sensory processing, and that may guide the\nemergence of cognition and consciousness, by analysing neurophysiological\nrecordings in conscious and unconscious states. We find a surprisingly simple\nresult: normal wakeful states are characterised by the greatest number of\npossible configurations of interactions between brain networks, representing\nhighest entropy values. Therefore, the information content is larger in the\nnetwork associated to conscious states, suggesting that consciousness could be\nthe result of an optimization of information processing. These findings\nencapsulate three main current theories of cognition, as discussed in the text,\nand more specifically the conceptualization of consciousness in terms of brain\ncomplexity. We hope our study represents the preliminary attempt at finding\norganising principles of brain function that will help to guide in a more\nformal sense inquiry into how consciousness arises from the organization of\nmatter.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jun 2016 17:45:43 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 19:42:45 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Erra", "R. Guevara", ""], ["Mateos", "D. M.", ""], ["Wennberg", "R.", ""], ["Velazquez", "J. L. Perez", ""]]}, {"id": "1606.01017", "submitter": "Mahmoud Hassan", "authors": "Ahmad Mheich, Mahmoud Hassan, Olivier Dufor, Mohamad Khalil and\n  Fabrice Wendling", "title": "Combining EEG source connectivity and network similarity: Application to\n  object categorization in the human brain", "comments": "5 pages, 2 figures. Accepted for 2016 IEEE Workshop on Statistical\n  Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in cognitive neuroscience is to evaluate the ability of the\nhuman brain to categorize or group visual stimuli based on common features.\nThis categorization process is very fast and occurs in few hundreds of\nmillisecond time scale. However, an accurate tracking of the spatiotemporal\ndynamics of large-scale brain networks is still an unsolved issue. Here, we\nshow the combination of recently developed method called dense-EEG source\nconnectivity to identify functional brain networks with excellent temporal and\nspatial resolutions and an algorithm, called SimNet, to compute brain networks\nsimilarity. Two categories of visual stimuli were analysed in this study:\nimmobile and mobile. Networks similarity was assessed within each category\n(intra-condition) and between categories (inter-condition). Results showed high\nsimilarity within each category and low similarity between the two categories.\nA significant difference between similarities computed in the intra and\ninter-conditions was observed at the period of 120-190ms supposed to be related\nto visual recognition and memory access. We speculate that these observations\nwill be very helpful toward understanding the object categorization in the\nhuman brain from a network perspective.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 09:32:51 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Mheich", "Ahmad", ""], ["Hassan", "Mahmoud", ""], ["Dufor", "Olivier", ""], ["Khalil", "Mohamad", ""], ["Wendling", "Fabrice", ""]]}, {"id": "1606.01164", "submitter": "Dmitry Krotov", "authors": "Dmitry Krotov, John J Hopfield", "title": "Dense Associative Memory for Pattern Recognition", "comments": "Accepted for publication at NIPS 2016", "journal-ref": "Advances in Neural Information Processing Systems 29 (2016),\n  1172-1180", "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of associative memory is studied, which stores and reliably retrieves\nmany more patterns than the number of neurons in the network. We propose a\nsimple duality between this dense associative memory and neural networks\ncommonly used in deep learning. On the associative memory side of this duality,\na family of models that smoothly interpolates between two limiting cases can be\nconstructed. One limit is referred to as the feature-matching mode of pattern\nrecognition, and the other one as the prototype regime. On the deep learning\nside of the duality, this family corresponds to feedforward neural networks\nwith one hidden layer and various activation functions, which transmit the\nactivities of the visible neurons to the hidden layer. This family of\nactivation functions includes logistics, rectified linear units, and rectified\npolynomials of higher degrees. The proposed duality makes it possible to apply\nenergy-based intuition from associative memory to analyze computational\nproperties of neural networks with unusual activation functions - the higher\nrectified polynomials which until now have not been used in deep learning. The\nutility of the dense memories is illustrated for two test cases: the logical\ngate XOR and the recognition of handwritten digits from the MNIST data set.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 16:17:01 GMT"}, {"version": "v2", "created": "Tue, 27 Sep 2016 16:05:36 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Krotov", "Dmitry", ""], ["Hopfield", "John J", ""]]}, {"id": "1606.01239", "submitter": "Reza Moazzezi", "authors": "Reza Moazzezi", "title": "Grid-like structure is optimal for path integration", "comments": "13 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid cells in medial entorhinal cortex are believed to play a key role in\npath integration. However, the relation between path integration and the\ngrid-like arrangement of their firing field remains unclear. We provide\ntheoretical evidence that grid-like structure and path integration are closely\nrelated. In one dimension, the grid-like structure provides the optimal\nsolution for path integration assuming that the noise correlation structure is\nGaussian. In two dimensions, assuming that the noise is Gaussian, rectangular\ngrid-like structure is the optimal solution provided that 1- both noise\ncorrelation and receptive field structures of the neurons can be\nmultiplicatively decomposed into orthogonal components and 2- the eigenvalues\nof the decomposed correlation matrices decrease faster than the square of the\nfrequency of the corresponding eigenvectors. We will also address the decoding\nmechanism and show that the problem of decoding reduces to the problem of\nextracting task relevant information in the presence of task irrelevant\ninformation. Change-based Population Coding provides the optimal solution for\nthis problem.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 19:55:11 GMT"}], "update_date": "2016-06-06", "authors_parsed": [["Moazzezi", "Reza", ""]]}, {"id": "1606.01272", "submitter": "Mikhail Shneider", "authors": "M.N. Shneider", "title": "Bypassing damaged nervous tissue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown the principal possibility of bypassing damaged demyelinated\nportions of the nervous tissue, thereby restoring its normal function for the\npassage of action potentials.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 20:47:39 GMT"}, {"version": "v2", "created": "Tue, 7 Jun 2016 19:22:20 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Shneider", "M. N.", ""]]}, {"id": "1606.01358", "submitter": "Daqing Guo", "authors": "Daqing Guo, Mingming Chen, Matjaz Perc, Shengdun Wu, Chuan Xia,\n  Yangsong Zhang, Peng Xu, Yang Xia, Dezhong Yao", "title": "Firing regulation of fast-spiking interneurons by autaptic inhibition", "comments": "6 pages, 5 figures", "journal-ref": "EPL 114 (2016) 30001", "doi": "10.1209/0295-5075/114/30001", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast-spiking (FS) interneurons in the brain are self-innervated by powerful\ninhibitory GABAergic autaptic connections. By computational modelling, we\ninvestigate how autaptic inhibition regulates the firing response of such\ninterneurons. Our results indicate that autaptic inhibition both boosts the\ncurrent threshold for action potential generation as well as modulates the\ninput-output gain of FS interneurons. The autaptic transmission delay is\nidentified as a key parameter that controls the firing patterns and determines\nmultistability regions of FS interneurons. Furthermore, we observe that\nneuronal noise influences the firing regulation of FS interneurons by autaptic\ninhibition and extends their dynamic range for encoding inputs. Importantly,\nautaptic inhibition modulates noise-induced irregular firing of FS\ninterneurons, such that coherent firing appears at an optimal autaptic\ninhibition level. Our result reveal the functional roles of autaptic inhibition\nin taming the firing dynamics of FS interneurons.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2016 09:45:00 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Guo", "Daqing", ""], ["Chen", "Mingming", ""], ["Perc", "Matjaz", ""], ["Wu", "Shengdun", ""], ["Xia", "Chuan", ""], ["Zhang", "Yangsong", ""], ["Xu", "Peng", ""], ["Xia", "Yang", ""], ["Yao", "Dezhong", ""]]}, {"id": "1606.01552", "submitter": "Qianli Liao", "authors": "Joel Z. Leibo, Qianli Liao, Winrich Freiwald, Fabio Anselmi, Tomaso\n  Poggio", "title": "View-tolerant face recognition and Hebbian learning imply\n  mirror-symmetric neural tuning to head orientation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primate brain contains a hierarchy of visual areas, dubbed the ventral\nstream, which rapidly computes object representations that are both specific\nfor object identity and relatively robust against identity-preserving\ntransformations like depth-rotations. Current computational models of object\nrecognition, including recent deep learning networks, generate these properties\nthrough a hierarchy of alternating selectivity-increasing filtering and\ntolerance-increasing pooling operations, similar to simple-complex cells\noperations. While simulations of these models recapitulate the ventral stream's\nprogression from early view-specific to late view-tolerant representations,\nthey fail to generate the most salient property of the intermediate\nrepresentation for faces found in the brain: mirror-symmetric tuning of the\nneural population to head orientation. Here we prove that a class of\nhierarchical architectures and a broad set of biologically plausible learning\nrules can provide approximate invariance at the top level of the network. While\nmost of the learning rules do not yield mirror-symmetry in the mid-level\nrepresentations, we characterize a specific biologically-plausible Hebb-type\nlearning rule that is guaranteed to generate mirror-symmetric tuning to faces\ntuning at intermediate levels of the architecture.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jun 2016 20:10:43 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Leibo", "Joel Z.", ""], ["Liao", "Qianli", ""], ["Freiwald", "Winrich", ""], ["Anselmi", "Fabio", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1606.01651", "submitter": "Yoshua Bengio", "authors": "Yoshua Bengio, Benjamin Scellier, Olexa Bilaniuk, Joao Sacramento and\n  Walter Senn", "title": "Feedforward Initialization for Fast Inference of Deep Generative\n  Networks is biologically plausible", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deep multi-layered generative models such as Boltzmann machines\nor Hopfield nets in which computation (which implements inference) is both\nrecurrent and stochastic, but where the recurrence is not to model sequential\nstructure, only to perform computation. We find conditions under which a simple\nfeedforward computation is a very good initialization for inference, after the\ninput units are clamped to observed values. It means that after the feedforward\ninitialization, the recurrent network is very close to a fixed point of the\nnetwork dynamics, where the energy gradient is 0. The main condition is that\nconsecutive layers form a good auto-encoder, or more generally that different\ngroups of inputs into the unit (in particular, bottom-up inputs on one hand,\ntop-down inputs on the other hand) are consistent with each other, producing\nthe same contribution into the total weighted sum of inputs. In biological\nterms, this would correspond to having each dendritic branch correctly\npredicting the aggregate input from all the dendritic branches, i.e., the soma\npotential. This is consistent with the prediction that the synaptic weights\ninto dendritic branches such as those of the apical and basal dendrites of\npyramidal cells are trained to minimize the prediction error made by the\ndendritic branch when the target is the somatic activity. Whereas previous work\nhas shown how to achieve fast negative phase inference (when the model is\nunclamped) in a predictive recurrent model, this contribution helps to achieve\nfast positive phase inference (when the target output is clamped) in such\nrecurrent neural models.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 08:09:19 GMT"}, {"version": "v2", "created": "Tue, 28 Jun 2016 00:10:22 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Bengio", "Yoshua", ""], ["Scellier", "Benjamin", ""], ["Bilaniuk", "Olexa", ""], ["Sacramento", "Joao", ""], ["Senn", "Walter", ""]]}, {"id": "1606.01684", "submitter": "Daqing Guo", "authors": "Daqing Guo, Shengdun Wu, Mingming Chen, Matjaz Perc, Yangsong Zhang,\n  Jingling Ma, Yan Cui, Peng Xu, Yang Xia, and Dezhong Yao", "title": "Regulation of Irregular Neuronal Firing by Autaptic Transmission", "comments": "27 pages, 8 figures", "journal-ref": "Sci. Rep. 6 (2016) 26096", "doi": "10.1038/srep26096", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of self-feedback autaptic transmission in modulating\nspike-time irregularity is still poorly understood. By using a biophysical\nmodel that incorporates autaptic coupling, we here show that self-innervation\nof neurons participates in the modulation of irregular neuronal firing,\nprimarily by regulating the occurrence frequency of burst firing. In\nparticular, we find that both excitatory and electrical autapses increase the\noccurrence of burst firing, thus reducing neuronal firing regularity. In\ncontrast, inhibitory autapses suppress burst firing and therefore tend to\nimprove the regularity of neuronal firing. Importantly, we show that these\nfindings are independent of the firing properties of individual neurons, and as\nsuch can be observed for neurons operating in different modes. Our results\nprovide an insightful mechanistic understanding of how different types of\nautapses shape irregular firing at the single-neuron level, and they highlight\nthe functional importance of autaptic self-innervation in taming and modulating\nneurodynamics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 10:40:41 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Guo", "Daqing", ""], ["Wu", "Shengdun", ""], ["Chen", "Mingming", ""], ["Perc", "Matjaz", ""], ["Zhang", "Yangsong", ""], ["Ma", "Jingling", ""], ["Cui", "Yan", ""], ["Xu", "Peng", ""], ["Xia", "Yang", ""], ["Yao", "Dezhong", ""]]}, {"id": "1606.01884", "submitter": "Enrico Prati", "authors": "Enrico Prati", "title": "Atomic scale nanoelectronics for quantum neuromorphic devices: comparing\n  different materials", "comments": "15 pag, 2 fig, in press on International Journal of Nanotechnology\n  2016", "journal-ref": null, "doi": "10.1504/IJNT.2016.078543", "report-no": null, "categories": "cs.ET cond-mat.mes-hall q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I review the advancements of atomic scale nanoelectronics towards quantum\nneuromorphics. First, I summarize the key properties of elementary combinations\nof few neurons, namely long-- and short--term plasticity, spike-timing\ndependent plasticity (associative plasticity), quantumness and stochastic\neffects, and their potential computational employment. Next, I review several\natomic scale device technologies developed to control electron transport at the\natomic level, including single atom implantation for atomic arrays and CMOS\nquantum dots, single atom memories, Ag$_2$S and Cu$_2$S atomic switches,\nhafnium based RRAMs, organic material based transistors, Ge$_2$Sb$_2$Te$_5$\nsynapses. Each material/method proved successful in achieving some of the\nproperties observed in real neurons. I compare the different methods towards\nthe creation of a new generation of naturally inspired and biophysically\nmeaningful artificial neurons, in order to replace the rigid CMOS based\nneuromorphic hardware. The most challenging aspect to address appears to obtain\nboth the stochastic/quantum behavior and the associative plasticity, which are\ncurrently observed only below and above 20 nm length scale respectively, by\nemploying the same material.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2016 12:27:16 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Prati", "Enrico", ""]]}, {"id": "1606.02344", "submitter": "Tammo Rukat", "authors": "Tammo Rukat, Adam Baker, Andrew Quinn, Mark Woolrich", "title": "Resting state brain networks from EEG: Hidden Markov states vs.\n  classical microstates", "comments": "Presented at MLINI-2015 workshop, 2015 (arXiv:abs/1605.04435)", "journal-ref": null, "doi": null, "report-no": "MLINI/2015/09", "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional brain networks exhibit dynamics on the sub-second temporal scale\nand are often assumed to embody the physiological substrate of cognitive\nprocesses. Here we analyse the temporal and spatial dynamics of these states,\nas measured by EEG, with a hidden Markov model and compare this approach to\nclassical EEG microstate analysis. We find dominating state lifetimes of\n100--150\\,ms for both approaches. The state topographies show obvious\nsimilarities. However, they also feature distinct spatial and especially\ntemporal properties. These differences may carry physiological meaningful\ninformation originating from patterns in the data that the HMM is able to\nintegrate while the microstate analysis is not. This hypothesis is supported by\na consistently high pairwise correlation of the temporal evolution of EEG\nmicrostates which is not observed for the HMM states and which seems unlikely\nto be a good description of the underlying physiology. However, further\ninvestigation is required to determine the robustness and the functional and\nclinical relevance of EEG HMM states in comparison to EEG microstates.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 21:59:31 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Rukat", "Tammo", ""], ["Baker", "Adam", ""], ["Quinn", "Andrew", ""], ["Woolrich", "Mark", ""]]}, {"id": "1606.02349", "submitter": "Marius C\\u{a}t\\u{a}lin Iordan", "authors": "Marius C\\u{a}t\\u{a}lin Iordan, Armand Joulin, Diane M. Beck, Li\n  Fei-Fei", "title": "Locally-Optimized Inter-Subject Alignment of Functional Cortical Regions", "comments": "Presented at MLINI-2015 workshop, 2015 (arXiv:cs/0101200)", "journal-ref": null, "doi": null, "report-no": "MLINI/2015/04", "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inter-subject registration of cortical areas is necessary in functional\nimaging (fMRI) studies for making inferences about equivalent brain function\nacross a population. However, many high-level visual brain areas are defined as\npeaks of functional contrasts whose cortical position is highly variable. As\nsuch, most alignment methods fail to accurately map functional regions of\ninterest (ROIs) across participants. To address this problem, we propose a\nlocally optimized registration method that directly predicts the location of a\nseed ROI on a separate target cortical sheet by maximizing the functional\ncorrelation between their time courses, while simultaneously allowing for\nnon-smooth local deformations in region topology. Our method outperforms the\ntwo most commonly used alternatives (anatomical landmark-based AFNI alignment\nand cortical convexity-based FreeSurfer alignment) in overlap between predicted\nregion and functionally-defined LOC. Furthermore, the maps obtained using our\nmethod are more consistent across subjects than both baseline measures.\nCritically, our method represents an important step forward towards predicting\nbrain regions without explicit localizer scans and deciphering the poorly\nunderstood relationship between the location of functional regions, their\nanatomical extent, and the consistency of computations those regions perform\nacross people.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jun 2016 22:40:30 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Iordan", "Marius C\u0103t\u0103lin", ""], ["Joulin", "Armand", ""], ["Beck", "Diane M.", ""], ["Fei-Fei", "Li", ""]]}, {"id": "1606.02372", "submitter": "Joaquin Rapela", "authors": "Joaquin Rapela", "title": "Entrainment of traveling waves to rhythmic motor acts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We hypothesized that rhythmic motor acts entrain neural oscillations in\nspeech production brain regions. We tested this hypothesis in an experiment\nwhere a subject produced consonant-vowel (CV) syllables in a rhythmic fashion,\nwhile we performed ECoG recordings. Over the ventral sensorimotor cortex (vSMC)\nwe detected significant concentration of phase across trials at the specific\nfrequency of speech production. We also observed amplitude modulations. In\naddition we found significant coupling between the phase of brain oscillations\nat the frequency of speech production and their amplitude in the high-gamma\nrange (i.e., phase-amplitude coupling, PAC). Furthermore, we saw that brain\noscillations at the frequency of speech production organized as traveling waves\n(TWs), synchronized to the rhythm of speech production. It has been\nhypothesized that PAC is a mechanism to allow low-frequency oscillations to\nsynchronize with high-frequency neural activity so that spiking occurs at\nbehaviorally relevant times. If this hypothesis is true, when PAC coexists with\nTWs, we expect a specific organization of PAC curves. We observed this\norganization experimentally and verified that the peaks of high-gamma\noscillations, and therefore spiking, occur at the same times across electrodes.\nImportantly, we observed that these spiking times were synchronized with the\nrhythm of speech production. To our knowledge, this is the first report of\nmotor actions organizing (a) the phase coherence of low-frequency brain\noscillations, (b) the coupling between the phase of these oscillations and the\namplitude of high-frequency oscillations, and (c) TW. It is also the first\ndemonstration that TWs induce an organization of PAC so that spiking across\nspatial locations is synchronized to behaviorally relevant times.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 02:01:20 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Rapela", "Joaquin", ""]]}, {"id": "1606.02587", "submitter": "Keith Smith", "authors": "Keith Smith, Benjamin Ricaud, Nauman Shahid, Stephen Rhodes, John M.\n  Starr, Agustin Ibanez, Mario A. Parra, Javier Escudero, Pierre Vandergheynst", "title": "Locating Temporal Functional Dynamics of Visual Short-Term Memory\n  Binding using Graph Modular Dirichlet Energy", "comments": null, "journal-ref": "K. Smith et al., Scientific Reports, 7: 42013, 2017", "doi": "10.1038/srep42013", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual short-term memory binding tasks are a promising early marker for\nAlzheimer's disease (AD). To uncover functional deficits of AD in these tasks\nit is meaningful to first study unimpaired brain function. Electroencephalogram\nrecordings were obtained from encoding and maintenance periods of tasks\nperformed by healthy young volunteers. We probe the task's transient\nphysiological underpinnings by contrasting shape only (Shape) and shape-colour\nbinding (Bind) conditions, displayed in the left and right sides of the screen,\nseparately. Particularly, we introduce and implement a novel technique named\nModular Dirichlet Energy (MDE) which allows robust and flexible analysis of the\nfunctional network with unprecedented temporal precision. We find that\nconnectivity in the Bind condition is less integrated with the global network\nthan in the Shape condition in occipital and frontal modules during the\nencoding period of the right screen condition. Using MDE we are able to discern\ndriving effects in the occipital module between 100-140ms, coinciding with the\nP100 visually evoked potential, followed by a driving effect in the frontal\nmodule between 140-180ms, suggesting that the differences found constitute an\ninformation processing difference between these modules. This provides\ntemporally precise information over a heterogeneous population in promising\ntasks for the detection of AD.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 14:53:32 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 13:28:14 GMT"}, {"version": "v3", "created": "Thu, 8 Sep 2016 08:56:45 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Smith", "Keith", ""], ["Ricaud", "Benjamin", ""], ["Shahid", "Nauman", ""], ["Rhodes", "Stephen", ""], ["Starr", "John M.", ""], ["Ibanez", "Agustin", ""], ["Parra", "Mario A.", ""], ["Escudero", "Javier", ""], ["Vandergheynst", "Pierre", ""]]}, {"id": "1606.02627", "submitter": "Umut G\\\"u\\c{c}l\\\"u", "authors": "Umut G\\\"u\\c{c}l\\\"u, Jordy Thielen, Michael Hanke, Marcel A. J. van\n  Gerven", "title": "Brains on Beats", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We developed task-optimized deep neural networks (DNNs) that achieved\nstate-of-the-art performance in different evaluation scenarios for automatic\nmusic tagging. These DNNs were subsequently used to probe the neural\nrepresentations of music. Representational similarity analysis revealed the\nexistence of a representational gradient across the superior temporal gyrus\n(STG). Anterior STG was shown to be more sensitive to low-level stimulus\nfeatures encoded in shallow DNN layers whereas posterior STG was shown to be\nmore sensitive to high-level stimulus features encoded in deep DNN layers.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 16:33:41 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["G\u00fc\u00e7l\u00fc", "Umut", ""], ["Thielen", "Jordy", ""], ["Hanke", "Michael", ""], ["van Gerven", "Marcel A. J.", ""]]}, {"id": "1606.02765", "submitter": "Yuri A. Dabaghian", "authors": "Andrey Babichev and Yuri Dabaghian", "title": "Transient cell assembly networks encode persistent spatial memories", "comments": "23 pages, 7 figures, 4 suppl. figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While cognitive representations of an environment can last for days and even\nmonths, the synaptic architecture of the neuronal networks that underlie these\nrepresentations constantly changes due to various forms of synaptic and\nstructural plasticity at a much faster timescale. This raises an immediate\nquestion: how can a transient network maintain a stable representation of\nspace? In the following, we propose a computational model for describing\nemergence of the hippocampal cognitive map in a network of transient place cell\nassemblies and demonstrate, using methods of algebraic topology, that such a\nnetwork can maintain a robust map of the environment.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jun 2016 21:38:22 GMT"}], "update_date": "2016-06-10", "authors_parsed": [["Babichev", "Andrey", ""], ["Dabaghian", "Yuri", ""]]}, {"id": "1606.02840", "submitter": "Tijl Grootswagers", "authors": "Tijl Grootswagers, Susan G. Wardle, Thomas A. Carlson", "title": "Decoding dynamic brain patterns from evoked responses: A tutorial on\n  multivariate pattern analysis applied to time-series neuroimaging data", "comments": "64 pages, 15 figures", "journal-ref": null, "doi": "10.1162/jocn_a_01068", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate pattern analysis (MVPA) or brain decoding methods have become\nstandard practice in analysing fMRI data. Although decoding methods have been\nextensively applied in Brain Computing Interfaces (BCI), these methods have\nonly recently been applied to time-series neuroimaging data such as MEG and EEG\nto address experimental questions in Cognitive Neuroscience. In a\ntutorial-style review, we describe a broad set of options to inform future\ntime-series decoding studies from a Cognitive Neuroscience perspective. Using\nexample MEG data, we illustrate the effects that different options in the\ndecoding analysis pipeline can have on experimental results where the aim is to\n'decode' different perceptual stimuli or cognitive states over time from\ndynamic brain activation patterns. We show that decisions made at both\npreprocessing (e.g., dimensionality reduction, subsampling, trial averaging)\nand decoding (e.g., classifier selection, cross-validation design) stages of\nthe analysis can significantly affect the results. In addition to standard\ndecoding, we describe extensions to MVPA for time-varying neuroimaging data\nincluding representational similarity analysis, temporal generalisation, and\nthe interpretation of classifier weight maps. Finally, we outline important\ncaveats in the design and interpretation of time-series decoding experiments.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 07:00:21 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2016 04:54:01 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Grootswagers", "Tijl", ""], ["Wardle", "Susan G.", ""], ["Carlson", "Thomas A.", ""]]}, {"id": "1606.03063", "submitter": "William Levy Ph. D.", "authors": "William B Levy, Toby Berger, Mustafa Sungkar", "title": "Neural computation from first principles: Using the maximum entropy\n  method to obtain an optimal bits-per-joule neuron", "comments": null, "journal-ref": "IEEE Trans. Molecular, Biological, and Multi-scale Communication,\n  v2, Dec. 2016, 154-165", "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimization results are one method for understanding neural computation from\nNature's perspective and for defining the physical limits on neuron-like\nengineering. Earlier work looks at individual properties or performance\ncriteria and occasionally a combination of two, such as energy and information.\nHere we make use of Jaynes' maximum entropy method and combine a larger set of\nconstraints, possibly dimensionally distinct, each expressible as an\nexpectation. The method identifies a likelihood-function and a sufficient\nstatistic arising from each such optimization. This likelihood is a\nfirst-hitting time distribution in the exponential class. Particular constraint\nsets are identified that, from an optimal inference perspective, justify\nearlier neurocomputational models. Interactions between constraints, mediated\nthrough the inferred likelihood, restrict constraint-set parameterizations,\ne.g., the energy-budget limits estimation performance which, in turn, matches\nan axonal communication constraint. Such linkages are, for biologists,\nexperimental predictions of the method. In addition to the related likelihood,\nat least one type of constraint set implies marginal distributions, and in this\ncase, a Shannon bits/joule statement arises.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2016 23:00:17 GMT"}, {"version": "v2", "created": "Tue, 19 Dec 2017 21:36:06 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Levy", "William B", ""], ["Berger", "Toby", ""], ["Sungkar", "Mustafa", ""]]}, {"id": "1606.03071", "submitter": "Umut G\\\"u\\c{c}l\\\"u", "authors": "Umut G\\\"u\\c{c}l\\\"u, Marcel A. J. van Gerven", "title": "Modeling the dynamics of human brain activity with recurrent neural\n  networks", "comments": null, "journal-ref": null, "doi": "10.3389/fncom.2017.00007", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Encoding models are used for predicting brain activity in response to sensory\nstimuli with the objective of elucidating how sensory information is\nrepresented in the brain. Encoding models typically comprise a nonlinear\ntransformation of stimuli to features (feature model) and a linear\ntransformation of features to responses (response model). While there has been\nextensive work on developing better feature models, the work on developing\nbetter response models has been rather limited. Here, we investigate the extent\nto which recurrent neural network models can use their internal memories for\nnonlinear processing of arbitrary feature sequences to predict feature-evoked\nresponse sequences as measured by functional magnetic resonance imaging. We\nshow that the proposed recurrent neural network models can significantly\noutperform established response models by accurately estimating long-term\ndependencies that drive hemodynamic responses. The results open a new window\ninto modeling the dynamics of brain activity in response to sensory stimuli.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2016 19:22:13 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["G\u00fc\u00e7l\u00fc", "Umut", ""], ["van Gerven", "Marcel A. J.", ""]]}, {"id": "1606.03430", "submitter": "Thomas Boyer-Kassem", "authors": "Thomas Boyer-Kassem, S\\'ebastien Duch\\^ene, Eric Guerci", "title": "Quantum-like models cannot account for the conjunction fallacy", "comments": "29 pages, 4 figures, 6 tables in Theory and Decision (2016)", "journal-ref": null, "doi": "10.1007/s11238-016-9549-9", "report-no": null, "categories": "physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human agents happen to judge that a conjunction of two terms is more probable\nthan one of the terms, in contradiction with the rules of classical\nprobabilities---this is the conjunction fallacy. One of the most discussed\naccounts of this fallacy is currently the quantum-like explanation, which\nrelies on models exploiting the mathematics of quantum mechanics. The aim of\nthis paper is to investigate the empirical adequacy of major quantum-like\nmodels which represent beliefs with quantum states. We first argue that they\ncan be tested in three different ways, in a question order effect configuration\nwhich is different from the traditional conjunction fallacy experiment. We then\ncarry out our proposed experiment, with varied methodologies from experimental\neconomics. The experimental results we get are at odds with the predictions of\nthe quantum-like models. This strongly suggests that this quantum-like account\nof the conjunction fallacy fails. Future possible research paths are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 12 Oct 2015 12:47:45 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 10:30:05 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Boyer-Kassem", "Thomas", ""], ["Duch\u00eane", "S\u00e9bastien", ""], ["Guerci", "Eric", ""]]}, {"id": "1606.03592", "submitter": "Robert Leech", "authors": "Peter J. Hellyer, Claudia Clopath, Angie A. Kehagia, Federico E.\n  Turkheimer, Robert Leech", "title": "Balanced activation in a simple embodied neural simulation", "comments": "26 pages, 7 figures, associated github repository:\n  https://github.com/c3nl-neuraldynamics/Avatar", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there have been many computational simulations of\nspontaneous neural dynamics. Here, we explore a model of spontaneous neural\ndynamics and allow it to control a virtual agent moving in a simple\nenvironment. This setup generates interesting brain-environment feedback\ninteractions that rapidly destabilize neural and behavioral dynamics and\nsuggest the need for homeostatic mechanisms. We investigate roles for both\nlocal homeostatic plasticity (local inhibition adjusting over time to balance\nexcitatory input) as well as macroscopic task negative activity (that\ncompensates for task positive, sensory input) in regulating both neural\nactivity and resulting behavior (trajectories through the environment). Our\nresults suggest complementary functional roles for both local homeostatic\nplasticity and balanced activity across brain regions in maintaining neural and\nbehavioral dynamics. These findings suggest important functional roles for\nhomeostatic systems in maintaining neural and behavioral dynamics and suggest a\nnovel functional role for frequently reported macroscopic task-negative\npatterns of activity (e.g., the default mode network).\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2016 13:39:43 GMT"}, {"version": "v2", "created": "Thu, 18 Aug 2016 09:52:31 GMT"}], "update_date": "2016-08-19", "authors_parsed": [["Hellyer", "Peter J.", ""], ["Clopath", "Claudia", ""], ["Kehagia", "Angie A.", ""], ["Turkheimer", "Federico E.", ""], ["Leech", "Robert", ""]]}, {"id": "1606.03813", "submitter": "Adam Marblestone", "authors": "Adam Marblestone, Greg Wayne, Konrad Kording", "title": "Towards an integration of deep learning and neuroscience", "comments": null, "journal-ref": null, "doi": "10.3389/fncom.2016.00094", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscience has focused on the detailed implementation of computation,\nstudying neural codes, dynamics and circuits. In machine learning, however,\nartificial neural networks tend to eschew precisely designed codes, dynamics or\ncircuits in favor of brute force optimization of a cost function, often using\nsimple and relatively uniform initial architectures. Two recent developments\nhave emerged within machine learning that create an opportunity to connect\nthese seemingly divergent perspectives. First, structured architectures are\nused, including dedicated systems for attention, recursion and various forms of\nshort- and long-term memory storage. Second, cost functions and training\nprocedures have become more complex and are varied across layers and over time.\nHere we think about the brain in terms of these ideas. We hypothesize that (1)\nthe brain optimizes cost functions, (2) these cost functions are diverse and\ndiffer across brain locations and over development, and (3) optimization\noperates within a pre-structured architecture matched to the computational\nproblems posed by behavior. Such a heterogeneously optimized system, enabled by\na series of interacting cost functions, serves to make learning data-efficient\nand precisely targeted to the needs of the organism. We suggest directions by\nwhich neuroscience could seek to refine and test these hypotheses.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 05:08:39 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Marblestone", "Adam", ""], ["Wayne", "Greg", ""], ["Kording", "Konrad", ""]]}, {"id": "1606.04057", "submitter": "Sarah Marzen", "authors": "Sarah Marzen and Simon DeDeo", "title": "Weak universality in sensory tradeoffs", "comments": null, "journal-ref": "Phys. Rev. E 94, 060101 (2016)", "doi": "10.1103/PhysRevE.94.060101", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many organisms, the number of sensory neurons is largely determined\nduring development, before strong environmental cues are present. This is\ndespite the fact that environments can fluctuate drastically both from\ngeneration to generation and within an organism's lifetime. How can organisms\nget by by hard-coding the number of sensory neurons? We approach this question\nusing rate-distortion theory. A combination of simulation and theory suggests\nthat when environments are large, the rate-distortion function---a proxy for\nmaterial costs, timing delays, and energy requirements---depends only on\ncoarse-grained environmental statistics that are expected to change on\nevolutionary, rather than ontogenetic, timescales.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jun 2016 18:18:11 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Marzen", "Sarah", ""], ["DeDeo", "Simon", ""]]}, {"id": "1606.04344", "submitter": "Javier Garcia", "authors": "Javier O. Garcia, Justin Brooks, Scott Kerick, Tony Johnson, Tim\n  Mullen, and Jean M. Vettel", "title": "Estimating direction in brain-behavior interactions: Proactive and\n  reactive brain states in driving", "comments": "In review at NeuroImage", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional neuroimaging analyses have revealed the computational\nspecificity of localized brain regions, exploiting the power of the subtraction\ntechnique in fMRI and event-related potential analyses in EEG. Moving beyond\nthis convention, many researchers have begun exploring network-based\nneurodynamics and coordination between brain regions as a function of\nbehavioral parameters or environmental statistics; however, most approaches\naverage evoked activity across the experimental session to study task-dependent\nnetworks. Here, we examined on-going oscillatory activity and use a methodology\nto estimate directionality in brain-behavior interactions. After source\nreconstruction, activity within specific frequency bands in a priori regions of\ninterest was linked to continuous behavioral measurements, and we used a\npredictive filtering scheme to estimate the asymmetry between brain-to-behavior\nand behavior-to-brain prediction. We applied this approach to a simulated\ndriving task and examine directed relationships between brain activity and\ncontinuous driving behavior (steering or heading error). Our results indicated\nthat two neuro-behavioral states emerge in this naturalistic environment: a\nProactive brain state that actively plans the response to the sensory\ninformation, and a Reactive brain state that processes incoming information and\nreacts to environmental statistics.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 13:29:08 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Garcia", "Javier O.", ""], ["Brooks", "Justin", ""], ["Kerick", "Scott", ""], ["Johnson", "Tony", ""], ["Mullen", "Tim", ""], ["Vettel", "Jean M.", ""]]}, {"id": "1606.04460", "submitter": "Charles Blundell", "authors": "Charles Blundell and Benigno Uria and Alexander Pritzel and Yazhe Li\n  and Avraham Ruderman and Joel Z Leibo and Jack Rae and Daan Wierstra and\n  Demis Hassabis", "title": "Model-Free Episodic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art deep reinforcement learning algorithms take many millions of\ninteractions to attain human-level performance. Humans, on the other hand, can\nvery quickly exploit highly rewarding nuances of an environment upon first\ndiscovery. In the brain, such rapid learning is thought to depend on the\nhippocampus and its capacity for episodic memory. Here we investigate whether a\nsimple model of hippocampal episodic control can learn to solve difficult\nsequential decision-making tasks. We demonstrate that it not only attains a\nhighly rewarding strategy significantly faster than state-of-the-art deep\nreinforcement learning algorithms, but also achieves a higher overall reward on\nsome of the more challenging domains.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2016 17:03:46 GMT"}], "update_date": "2016-06-15", "authors_parsed": [["Blundell", "Charles", ""], ["Uria", "Benigno", ""], ["Pritzel", "Alexander", ""], ["Li", "Yazhe", ""], ["Ruderman", "Avraham", ""], ["Leibo", "Joel Z", ""], ["Rae", "Jack", ""], ["Wierstra", "Daan", ""], ["Hassabis", "Demis", ""]]}, {"id": "1606.04698", "submitter": "Andrea Tacchetti", "authors": "Andrea Tacchetti and Leyla Isik and Tomaso Poggio", "title": "Invariant recognition drives neural representations of action sequences", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1005859", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing the actions of others from visual stimuli is a crucial aspect of\nhuman visual perception that allows individuals to respond to social cues.\nHumans are able to identify similar behaviors and discriminate between distinct\nactions despite transformations, like changes in viewpoint or actor, that\nsubstantially alter the visual appearance of a scene. This ability to\ngeneralize across complex transformations is a hallmark of human visual\nintelligence. Advances in understanding motion perception at the neural level\nhave not always translated in precise accounts of the computational principles\nunderlying what representation our visual cortex evolved or learned to compute.\nHere we test the hypothesis that invariant action discrimination might fill\nthis gap. Recently, the study of artificial systems for static object\nperception has produced models, CNNs, that achieve human level performance in\ncomplex discriminative tasks. Within this class of models, architectures that\nbetter support invariant object recognition also produce image representations\nthat match those implied by human and primate neural data. However, whether\nthese models produce representations of action sequences that support\nrecognition across complex transformations and closely follow neural\nrepresentations remains unknown. Here we show that spatiotemporal CNNs\nappropriately categorize video stimuli into actions, and that deliberate model\nmodifications that improve performance on an invariant action recognition task\nlead to data representations that better match human neural recordings. Our\nresults support our hypothesis that performance on invariant discrimination\ndictates the neural representations of actions computed by human visual cortex.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 09:40:46 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 21:20:44 GMT"}, {"version": "v3", "created": "Thu, 20 Apr 2017 19:12:55 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Tacchetti", "Andrea", ""], ["Isik", "Leyla", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1606.04719", "submitter": "Eduardo  Cocca Padovani", "authors": "Eduardo C. Padovani", "title": "Characterization of the Community Structure of Large Scale Functional\n  Brain Networks During Ketamine-Medetomidine Anesthetic Induction", "comments": "24 pages, 8 figures. arXiv admin note: text overlap with\n  arXiv:1604.00002", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central questions in neuroscience is to understand the way\ncommunication is organized in the brain, trying to comprehend how cognitive\ncapacities or physiological states of the organism are potentially related to\nbrain activities involving interactions of several brain areas. One important\ncharacteristic of the functional brain networks is that they are modularly\nstructured, being this modular architecture regarded to account for a series of\nproperties and functional dynamics. In the neurobiological context, communities\nmay indicate brain regions that are involved in one same activity, representing\nneural segregated processes. Several studies have demonstrated the modular\ncharacter of organization of brain activities. However, empirical evidences\nregarding to its dynamics and relation to different levels of consciousness\nhave not been reported yet. Within this context, this research sought to\ncharacterize the community structure of functional brain networks during an\nanesthetic induction process. The experiment was based on intra-cranial\nrecordings of neural activities of an old world macaque of the species Macaca\nfuscata during a Ketamine-Medetomidine anesthetic induction process. Networks\nwere serially estimated in time intervals of five seconds. Changes were\nobserved within about one and a half minutes after the administration of the\nanesthetics, revealing the occurrence of a transition on the community\nstructure. The awake state was characterized by the presence of large clusters\ninvolving frontal and parietal regions, while the anesthetized state by the\npresence of communities in the primary visual and motor cortices, being the\nareas of the secondary associative cortex most affected. The results report the\ninfluence of general anesthesia on the structure of functional clusters,\ncontributing for understanding some new aspects of neural correlates of\nconsciousness.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 10:56:10 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Padovani", "Eduardo C.", ""]]}, {"id": "1606.04876", "submitter": "Christos Papadimitriou", "authors": "Christos H. Papadimitriou", "title": "On the optimality of grid cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid cells, discovered more than a decade ago [5], are neurons in the brain\nof mammals that fire when the animal is located near certain specific points in\nits familiar terrain. Intriguingly, these points form, for a single cell, a\ntwo-dimensional triangular grid, not unlike our Figure 3. Grid cells are widely\nbelieved to be involved in path integration, that is, the maintenance of a\nlocation state through the summation of small displacements. We provide\ntheoretical evidence for this assertion by showing that cells with grid-like\ntuning curves are indeed well adapted for the path integration task. In\nparticular we prove that, in one dimension under Gaussian noise, the\nsensitivity of measuring small displacements is maximized by a population of\nneurons whose tuning curves are near-sinusoids -- that is to say, with peaks\nforming a one-dimensional grid. We also show that effective computation of the\ndisplacement is possible through a second population of cells whose sinusoid\ntuning curves are in phase difference from the first. In two dimensions, under\nadditional assumptions it can be shown that measurement sensitivity is\noptimized by the product of two sinusoids, again yielding a grid-like pattern.\nWe discuss the connection of our results to the triangular grid pattern\nobserved in animals.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 17:36:44 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Papadimitriou", "Christos H.", ""]]}, {"id": "1606.05004", "submitter": "Jean Vettel PhD", "authors": "Jean M. Vettel, Julia R. Green, Laurie Heller, Michael J. Tarr", "title": "Temporal and Semantic Effects on Multisensory Integration", "comments": "in revision from JoN", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do we integrate modality-specific perceptual information arising from the\nsame physical event into a coherent percept? One possibility is that observers\nrely on information across perceptual modalities that shares temporal structure\nand/or semantic associations. To explore the contributions of these two factors\nin multisensory integration, we manipulated the temporal and semantic\nrelationships between auditory and visual information produced by real-world\nevents, such as paper tearing or cards being shuffled. We identified distinct\nneural substrates for integration based on temporal structure as compared to\nintegration based on event semantics. Semantically incongruent events recruited\nleft frontal regions, while temporally asynchronous events recruited right\nfrontal cortices. At the same time, both forms of incongruence recruited\nsubregions in the temporal, occipital, and lingual cortices. Finally, events\nthat were both temporally and semantically congruent modulated activity in the\nparahippocampus and anterior temporal lobe. Taken together, these results\nindicate that low-level perceptual properties such as temporal synchrony and\nhigh-level knowledge such as semantics play a role in our coherent perceptual\nexperience of physical events.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 23:39:57 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Vettel", "Jean M.", ""], ["Green", "Julia R.", ""], ["Heller", "Laurie", ""], ["Tarr", "Michael J.", ""]]}, {"id": "1606.05006", "submitter": "Jean Vettel PhD", "authors": "Jean M. Vettel, Justin Kantner, Matthew Jaswa, Michael Miller", "title": "Animated 3D Human Models for Use in Person Recognition Experiments", "comments": "In revision from BRM", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of increasingly realistic experimental stimuli and task\nenvironments is important for understanding behavior outside the laboratory. We\nreport a process for generating 3D human model stimuli that combines commonly\nused graphics software and enables the flexible generation of animated human\nmodels while providing parametric control over individualized identity\nfeatures. Our approach creates novel head models using FaceGen Modeller,\nattaches them to commercially-purchased 3D avatar bodies in 3D Studio Max, and\ngenerates Cal3D human models that are compatible with many virtual 3D\nenvironments. Stimuli produced by this method can be embedded as animated 3D\navatars in interactive simulations or presented as 2D images embedded in scenes\nfor use in traditional laboratory experiments. The inherent flexibility in this\nmethod makes the stimuli applicable to a broad range of basic and applied\nresearch questions in the domain of person perception. We describe the steps of\nthe stimulus generation process, provide an example of their use in a\nrecognition memory paradigm, and highlight the adaptability of the method for\nrelated avenues of research.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2016 23:43:53 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Vettel", "Jean M.", ""], ["Kantner", "Justin", ""], ["Jaswa", "Matthew", ""], ["Miller", "Michael", ""]]}, {"id": "1606.05522", "submitter": "Antony Passaro", "authors": "Antony D. Passaro, Jean M. Vettel, Jonathan McDaniel, Vernon Lawhern,\n  Piotr J. Franaszczuk, Stephen M. Gordon", "title": "A novel method linking neural connectivity to behavioral fluctuations:\n  Behavior-Regressed Connectivity", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: During an experimental session, behavioral performance\nfluctuates, yet most neuroimaging analyses of functional connectivity derive a\nsingle connectivity pattern. These conventional connectivity approaches assume\nthat since the underlying behavior of the task remains constant, the\nconnectivity pattern is also constant.\n  New Method: We introduce a novel method, behavior-regressed connectivity\n(BRC), to directly examine behavioral fluctuations within an experimental\nsession and capture their relationship to changes in functional connectivity.\nThis method employs the weighted phase lag index (WPLI) applied to a window of\ntrials with a weighting function. Using two datasets, the BRC results are\ncompared to conventional connectivity results during two time windows: the one\nsecond before stimulus onset to identify predictive relationships, and the one\nsecond after onset to capture task-dependent relationships.\n  Results: In both tasks, we replicate the expected results for the\nconventional connectivity analysis, and extend our understanding of the\nbrain-behavior relationship using the BRC analysis, demonstrating\nsubject-specific connectivity patterns that correspond to both positive and\nnegative relationships with behavior.\n  Comparison with Existing Method(s): Conventional connectivity analyses assume\na consistent relationship between behaviors and functional connectivity, but\nthe BRC method examines performance variability within an experimental session\nto understand dynamic connectivity and transient behavior.\n  Conclusion: The BRC approach examines connectivity as it covaries with\nbehavior to complement the knowledge of underlying neural activity derived from\nconventional connectivity analyses. Within this framework, BRC may be\nimplemented for the purpose of understanding performance variability both\nwithin and between participants.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 13:41:07 GMT"}, {"version": "v2", "created": "Tue, 10 Oct 2017 17:47:24 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Passaro", "Antony D.", ""], ["Vettel", "Jean M.", ""], ["McDaniel", "Jonathan", ""], ["Lawhern", "Vernon", ""], ["Franaszczuk", "Piotr J.", ""], ["Gordon", "Stephen M.", ""]]}, {"id": "1606.05579", "submitter": "Irina Higgins", "authors": "Irina Higgins, Loic Matthey, Xavier Glorot, Arka Pal, Benigno Uria,\n  Charles Blundell, Shakir Mohamed, Alexander Lerchner", "title": "Early Visual Concept Learning with Unsupervised Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated discovery of early visual concepts from raw image data is a major\nopen challenge in AI research. Addressing this problem, we propose an\nunsupervised approach for learning disentangled representations of the\nunderlying factors of variation. We draw inspiration from neuroscience, and\nshow how this can be achieved in an unsupervised generative model by applying\nthe same learning pressures as have been suggested to act in the ventral visual\nstream in the brain. By enforcing redundancy reduction, encouraging statistical\nindependence, and exposure to data with transform continuities analogous to\nthose to which human infants are exposed, we obtain a variational autoencoder\n(VAE) framework capable of learning disentangled factors. Our approach makes\nfew assumptions and works well across a wide variety of datasets. Furthermore,\nour solution has useful emergent properties, such as zero-shot inference and an\nintuitive understanding of \"objectness\".\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 16:19:46 GMT"}, {"version": "v2", "created": "Mon, 19 Sep 2016 19:50:49 GMT"}, {"version": "v3", "created": "Tue, 20 Sep 2016 09:30:26 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Higgins", "Irina", ""], ["Matthey", "Loic", ""], ["Glorot", "Xavier", ""], ["Pal", "Arka", ""], ["Uria", "Benigno", ""], ["Blundell", "Charles", ""], ["Mohamed", "Shakir", ""], ["Lerchner", "Alexander", ""]]}, {"id": "1606.05642", "submitter": "Mohammad Javad Faraji", "authors": "Mohammadjavad Faraji, Kerstin Preuschoff, Wulfram Gerstner", "title": "Balancing New Against Old Information: The Role of Surprise in Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surprise describes a range of phenomena from unexpected events to behavioral\nresponses. We propose a measure of surprise and use it for surprise-driven\nlearning. Our surprise measure takes into account data likelihood as well as\nthe degree of commitment to a belief via the entropy of the belief\ndistribution. We find that surprise-minimizing learning dynamically adjusts the\nbalance between new and old information without the need of knowledge about the\ntemporal statistics of the environment. We apply our framework to a dynamic\ndecision-making task and a maze exploration task. Our surprise minimizing\nframework is suitable for learning in complex environments, even if the\nenvironment undergoes gradual or sudden changes and could eventually provide a\nframework to study the behavior of humans and animals encountering surprising\nevents.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2016 19:54:43 GMT"}, {"version": "v2", "created": "Wed, 1 Mar 2017 20:31:24 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Faraji", "Mohammadjavad", ""], ["Preuschoff", "Kerstin", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1606.06249", "submitter": "Jason Steffener", "authors": "Jason Steffener, Karen Li, Syrina Alain and Johannes Frasnelli", "title": "Quantifying Neural Efficiency and Capacity: A Differential Equation\n  Interpretation of Polynomial Contrasts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task based neuroimaging tools for the study of cognitive neuroscience provide\ninsight into understanding how the brain responds to increasing cognitive\ndemand. Theoretical models of neural-cognitive relationships have been\ndeveloped based on observations of linear and non-linear increases in brain\nactivity. Neural efficiency and capacity are two parameters of current\ntheoretical models. These two theoretical parameters describe the rate of\nincrease of brain activity and the upper limits of the increases, respectively.\nThe current work demonstrates that a quadratic model of increasing brain\nactivity in response to the n-back task is a solution to a differential\nequation model. This reinterpretation of a standard approach to analyzing a\ncommon cognitive task provides a wealth of new insight. The results include\nbrain wide measures of neural efficiency and capacity. The quantification of\nneural-cognitive relationships provides evidence to support current cognitive\nneuroscience theories. In addition, the methods provide a framework for\nunderstanding the neural mechanisms of working memory. This allows estimation\nof the effects of experimental manipulations within a conceptual research\nframework. The proposed methods were applied to twenty-one healthy young adults\nwhile engaging in four levels of the n-back task. All methods are easily\napplicable using standard current software packages for neuroimaging.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jun 2016 18:59:18 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Steffener", "Jason", ""], ["Li", "Karen", ""], ["Alain", "Syrina", ""], ["Frasnelli", "Johannes", ""]]}, {"id": "1606.06284", "submitter": "Amanda Mejia", "authors": "Amanda F. Mejia, Mary Beth Nebel, Anita D. Barber, Ann S. Choe and\n  Martin A. Lindquist", "title": "Effects of Scan Length and Shrinkage on Reliability of Resting-State\n  Functional Connectivity in the Human Connectome Project", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we use data from the Human Connectome Project (N=461) to\ninvestigate the effect of scan length on reliability of resting-state\nfunctional connectivity (rsFC) estimates produced from resting-state functional\nmagnetic resonance imaging (rsfMRI). Additionally, we study the benefits of\nempirical Bayes shrinkage, in which subject-level estimates borrow strength\nfrom the population average by trading a small increase in bias for a greater\nreduction in variance. For each subject, we compute raw and shrinkage estimates\nof rsFC between 300 regions identified through independent components analysis\n(ICA) based on rsfMRI scans varying from 3 to 30 minutes in length. The time\ncourse for each region is determined using dual regression, and rsFC is\nestimated as the Pearson correlation between each pair of time courses.\nShrinkage estimates for each subject are computed as a weighted average between\nthe raw subject-level estimate and the population average estimate, where the\nweight is determined for each connection by the relationship of within-subject\nvariance to between-subject variance. We find that shrinkage estimates exhibit\ngreater reliability than raw estimates for most connections, with 30-40%\nimprovement using scans less than 10 minutes in length and 10-20% improvement\nusing scans of 20-30 minutes. We also observe significant spatial variability\nin reliability of both raw and shrinkage estimates, with connections within the\ndefault mode and motor networks exhibiting the greatest reliability and\nbetween-network connections exhibiting the poorest reliability. We conclude\nthat the scan length required for reliable estimation of rsFC depends on the\nspecific connections of interest, and shrinkage can be used to increase\nreliability of rsFC, even when produced from long, high-quality rsfMRI scans.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jun 2016 15:34:11 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Mejia", "Amanda F.", ""], ["Nebel", "Mary Beth", ""], ["Barber", "Anita D.", ""], ["Choe", "Ann S.", ""], ["Lindquist", "Martin A.", ""]]}, {"id": "1606.06391", "submitter": "Ludmila Brochini", "authors": "L. Brochini, A.A. Costa, M. Abadi, A.C. Roque, J. Stolfi and O.\n  Kinouchi", "title": "Phase transitions and self-organized criticality in networks of\n  stochastic spiking neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase transitions and critical behavior are crucial issues both in\ntheoretical and experimental neuroscience. We report analytic and computational\nresults about phase transitions and self-organized criticality (SOC) in\nnetworks with general stochastic neurons. The stochastic neuron has a firing\nprobability given by a smooth monotonic function $\\Phi(V)$ of the membrane\npotential $V$, rather than a sharp firing threshold. We find that such networks\ncan operate in several dynamic regimes (phases) depending on the average\nsynaptic weight and the shape of the firing function $\\Phi$. In particular, we\nencounter both continuous and discontinuous phase transitions to absorbing\nstates. At the continuous transition critical boundary, neuronal avalanches\noccur whose distributions of size and duration are given by power laws, as\nobserved in biological neural networks. We also propose and test a new\nmechanism to produce SOC: the use of dynamic neuronal gains -- a form of\nshort-term plasticity probably in the axon initial segment (AIS) -- instead of\ndepressing synapses at the dendrites (as previously studied in the literature).\nThe new self-organization mechanism produces a slightly supercritical state,\nthat we called SOSC, in accord to some intuitions of Alan Turing.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 01:12:09 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 22:00:49 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Brochini", "L.", ""], ["Costa", "A. A.", ""], ["Abadi", "M.", ""], ["Roque", "A. C.", ""], ["Stolfi", "J.", ""], ["Kinouchi", "O.", ""]]}, {"id": "1606.06439", "submitter": "Gael Varoquaux", "authors": "Ga\\\"el Varoquaux (PARIETAL, NEUROSPIN), Matthieu Kowalski (PARIETAL,\n  L2S), Bertrand Thirion (NEUROSPIN, PARIETAL)", "title": "Social-sparsity brain decoders: faster spatial sparsity", "comments": "in Pattern Recognition in NeuroImaging, Jun 2016, Trento, Italy. 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatially-sparse predictors are good models for brain decoding: they give\naccurate predictions and their weight maps are interpretable as they focus on a\nsmall number of regions. However, the state of the art, based on total\nvariation or graph-net, is computationally costly. Here we introduce sparsity\nin the local neighborhood of each voxel with social-sparsity, a structured\nshrinkage operator. We find that, on brain imaging classification problems,\nsocial-sparsity performs almost as well as total-variation models and better\nthan graph-net, for a fraction of the computational cost. It also very clearly\noutlines predictive regions. We give details of the model and the algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 06:51:57 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Varoquaux", "Ga\u00ebl", "", "PARIETAL, NEUROSPIN"], ["Kowalski", "Matthieu", "", "PARIETAL,\n  L2S"], ["Thirion", "Bertrand", "", "NEUROSPIN, PARIETAL"]]}, {"id": "1606.06443", "submitter": "Zhang Chong", "authors": "Chong Zhang, Jochen Triesch and Bertram E. Shi", "title": "An active efficient coding model of the optokinetic nystagmus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optokinetic nystagmus (OKN) is an involuntary eye movement responsible for\nstabilizing retinal images in the presence of relative motion between an\nobserver and the environment. Fully understanding the development of\noptokinetic nystagmus requires a neurally plausible computational model that\naccounts for the neural development and the behavior. To date, work in this\narea has been limited. We propose a neurally plausible framework for the joint\ndevelopment of disparity and motion tuning in the visual cortex, the\noptokinetic and vergence eye movements. This framework models the joint\nemergence of both perception and behavior, and accounts for the importance of\nthe development of normal vergence control and binocular vision in achieving\nnormal monocular OKN (mOKN) behaviors. Because the model includes behavior, we\ncan simulate the same perturbations as performed in past experiments, such as\nartificially induced strabismus. The proposed model agrees both qualitatively\nand quantitatively with a number of findings from the literature on both\nbinocular vision as well as the optokinetic reflex. Finally, our model also\nmakes quantitative predictions about the OKN behavior using the same methods\nused to characterize the OKN in the experimental literature.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 07:01:18 GMT"}, {"version": "v2", "created": "Sun, 2 Oct 2016 07:24:00 GMT"}, {"version": "v3", "created": "Tue, 11 Oct 2016 07:07:35 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Zhang", "Chong", ""], ["Triesch", "Jochen", ""], ["Shi", "Bertram E.", ""]]}, {"id": "1606.06564", "submitter": "Alessandro Fontana", "authors": "Alessandro Fontana", "title": "An artificial neural network to find correlation patterns in an\n  arbitrary number of variables", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Methods to find correlation among variables are of interest to many\ndisciplines, including statistics, machine learning, (big) data mining and\nneurosciences. Parameters that measure correlation between two variables are of\nlimited utility when used with multiple variables. In this work, I propose a\nsimple criterion to measure correlation among an arbitrary number of variables,\nbased on a data set. The central idea is to i) design a function of the\nvariables that can take different forms depending on a set of parameters, ii)\ncalculate the difference between a statistics associated to the function\ncomputed on the data set and the same statistics computed on a randomised\nversion of the data set, called \"scrambled\" data set, and iii) optimise the\nparameters to maximise this difference. Many such functions can be organised in\nlayers, which can in turn be stacked one on top of the other, forming a neural\nnetwork. The function parameters are searched with an enhanced genetic\nalgortihm called POET and the resulting method is tested on a cancer gene data\nset. The method may have potential implications for some issues that affect the\nfield of neural networks, such as overfitting, the need to process huge amounts\nof data for training and the presence of \"adversarial examples\".\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 13:35:43 GMT"}, {"version": "v2", "created": "Fri, 30 Jun 2017 17:52:10 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Fontana", "Alessandro", ""]]}, {"id": "1606.06571", "submitter": "Henning U. Voss", "authors": "Henning U. Voss and Nigel Stepp", "title": "A negative group delay model for feedback-delayed manual tracking", "comments": "6 pages, 1 table, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose that feedback-delayed manual tracking performance is limited by\nfundamental constraints imposed by the physics of negative group delay. To test\nthis hypothesis, the results of an experiment in which subjects demonstrate\nboth reactive and predictive dynamics are modeled by a linear system with\ndelay-induced negative group delay. Although one of the simplest real-time\npredictors conceivable, this model explains key components of experimental\nobservations. Most notably, it explains the observation that prediction time\nlinearly increases with feedback delay, up to a certain point when tracking\nperformance deteriorates. It also explains the transition from reactive to\npredictive behavior with increasing feedback delay. The model contains only one\nfree parameter, the feedback gain, which has been fixed by comparison with one\nset of experimental observations for the reactive case. Our model provides\nquantitative predictions that can be tested in further experiments.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2016 13:50:09 GMT"}, {"version": "v2", "created": "Fri, 24 Jun 2016 19:11:05 GMT"}], "update_date": "2016-06-27", "authors_parsed": [["Voss", "Henning U.", ""], ["Stepp", "Nigel", ""]]}, {"id": "1606.07029", "submitter": "Sven Peter", "authors": "Sven Peter, Daniel Durstewitz, Ferran Diego, Fred A. Hamprecht", "title": "Sparse convolutional coding for neuronal ensemble identification", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cell ensembles, originally proposed by Donald Hebb in 1949, are subsets of\nsynchronously firing neurons and proposed to explain basic firing behavior in\nthe brain. Despite having been studied for many years no conclusive evidence\nhas been presented yet for their existence and involvement in information\nprocessing such that their identification is still a topic of modern research,\nespecially since simultaneous recordings of large neuronal population have\nbecome possible in the past three decades. These large recordings pose a\nchallenge for methods allowing to identify individual neurons forming cell\nensembles and their time course of activity inside the vast amounts of spikes\nrecorded. Related work so far focused on the identification of purely simulta-\nneously firing neurons using techniques such as Principal Component Analysis.\nIn this paper we propose a new algorithm based on sparse convolution coding\nwhich is also able to find ensembles with temporal structure. Application of\nour algorithm to synthetically generated datasets shows that it outperforms\nprevious work and is able to accurately identify temporal cell ensembles even\nwhen those contain overlapping neurons or when strong background noise is\npresent.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jun 2016 18:06:52 GMT"}], "update_date": "2016-06-23", "authors_parsed": [["Peter", "Sven", ""], ["Durstewitz", "Daniel", ""], ["Diego", "Ferran", ""], ["Hamprecht", "Fred A.", ""]]}, {"id": "1606.07372", "submitter": "Noah Apthorpe", "authors": "Noah J. Apthorpe, Alexander J. Riordan, Rob E. Aguilar, Jan Homann, Yi\n  Gu, David W. Tank, H. Sebastian Seung", "title": "Automatic Neuron Detection in Calcium Imaging Data Using Convolutional\n  Networks", "comments": "9 pages, 5 figures, 2 ancillary files; minor changes for camera-ready\n  version. appears in Advances in Neural Information Processing Systems 29\n  (NIPS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calcium imaging is an important technique for monitoring the activity of\nthousands of neurons simultaneously. As calcium imaging datasets grow in size,\nautomated detection of individual neurons is becoming important. Here we apply\na supervised learning approach to this problem and show that convolutional\nnetworks can achieve near-human accuracy and superhuman speed. Accuracy is\nsuperior to the popular PCA/ICA method based on precision and recall relative\nto ground truth annotation by a human expert. These results suggest that\nconvolutional networks are an efficient and flexible tool for the analysis of\nlarge-scale calcium imaging data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 16:49:40 GMT"}, {"version": "v2", "created": "Wed, 21 Dec 2016 23:40:08 GMT"}], "update_date": "2016-12-23", "authors_parsed": [["Apthorpe", "Noah J.", ""], ["Riordan", "Alexander J.", ""], ["Aguilar", "Rob E.", ""], ["Homann", "Jan", ""], ["Gu", "Yi", ""], ["Tank", "David W.", ""], ["Seung", "H. Sebastian", ""]]}, {"id": "1606.07398", "submitter": "Janina Hesse", "authors": "Janina Hesse, Jan-Hendrik Schleimer, Susanne Schreiber", "title": "Qualitative changes in spike-based neural coding and synchronization at\n  the saddle-node loop bifurcation", "comments": "16 pages, 6 figures, substantial extension of the manuscript", "journal-ref": "Phys. Rev. E 95, 052203 (2017)", "doi": "10.1103/PhysRevE.95.052203", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information processing in the brain crucially depends on encoding properties\nof single neurons, with particular relevance of the spike-generation mechanism.\nThe latter hinges upon the bifurcation type at the transition point between\nresting state and limit cycle spiking. Prominent qualitative changes in\nencoding have previously been attributed to a specific switch of such a\nbifurcation at the Bogdanov-Takens (BT) point. This study unveils another,\nhighly relevant and so far underestimated transition point: the saddle-node\nloop bifurcation. As we show, this bifurcation turns out to induce even more\ndrastic changes in spike-based coding than the BT transition. This result\narises from a direct effect of the saddle-node loop bifurcation on the limit\ncycle and hence spike dynamics, in contrast to the BT bifurcation, whose\nimmediate influence is exerted upon the subthreshold dynamics and hence only\nindirectly relates to spiking. We specifically demonstrate that the saddle-node\nloop bifurcation (i) ubiquitously occurs in planar neuron models with a\nsaddle-node on invariant cycle onset bifurcation, and (ii) results in a\nsymmetry breaking of the system's phase-response curve. The latter entails\nclose to optimal coding and synchronization properties in event-based\ninformation processing units, such as neurons. The saddle-node loop bifurcation\nleads to a peak in synchronization range and provides an attractive mechanism\nfor the so far unresolved facilitation of high frequencies in neuronal\nprocessing. The derived bifurcation structure is of interest in any system for\nwhich a relaxation limit is admissible, such as Josephson junctions and\nchemical oscillators. On the experimental side, our theory applies to optical\nstimulation of nerve cells, and reveals that these techniques could manipulate\na variety of information processing characteristics in nerve cells beyond pure\nactivation.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jun 2016 18:33:50 GMT"}, {"version": "v2", "created": "Sat, 12 Nov 2016 17:50:58 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Hesse", "Janina", ""], ["Schleimer", "Jan-Hendrik", ""], ["Schreiber", "Susanne", ""]]}, {"id": "1606.08232", "submitter": "Valmir C. Barbosa", "authors": "Valmir C. Barbosa", "title": "Information integration from distributed threshold-based interactions", "comments": null, "journal-ref": "Complexity (2017), 7046359", "doi": "10.1155/2017/7046359", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a collection of distributed units that interact with one another\nthrough the sending of messages. Each message carries a positive ($+1$) or\nnegative ($-1$) tag and causes the receiving unit to send out messages as a\nfunction of the tags it has received and a threshold. This simple model\nabstracts some of the essential characteristics of several systems used in the\nfield of artificial intelligence, and also of biological systems epitomized by\nthe brain. We study the integration of information inside a temporal window as\nthe model's dynamics unfolds. We quantify information integration by the total\ncorrelation, relative to the window's duration ($w$), of a set of random\nvariables valued as a function of message arrival. Total correlation refers to\nthe rise of information gain above and beyond that which the units already\nachieve individually, being therefore related to consciousness studies in some\nmodels. We report on extensive computational experiments that explore the\ninterrelations of the model's parameters (two probabilities and the threshold),\nhighlighting relevant scenarios of message traffic and how they impact the\nbehavior of total correlation as a function of $w$. We find that total\ncorrelation can occur at significant fractions of the maximum possible value\nand provide semi-analytical results on the message-traffic characteristics\nassociated with values of $w$ for which it peaks. We then reinterpret the\nmodel's parameters in terms of the current best estimates of some quantities\npertaining to cortical structure and dynamics. We find the resulting\npossibilities for best values of $w$ to be well aligned with the time frames\nwithin which percepts are thought to be processed and eventually rendered\nconscious.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 12:15:39 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Barbosa", "Valmir C.", ""]]}, {"id": "1606.08313", "submitter": "Pedro Mediano", "authors": "Pedro A.M. Mediano, Juan Carlos Farah and Murray Shanahan", "title": "Integrated Information and Metastability in Systems of Coupled\n  Oscillators", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that sets of oscillators in a modular network can exhibit a\nrich variety of metastable chimera states, in which synchronisation and\ndesynchronisation coexist. Independently, under the guise of integrated\ninformation theory, researchers have attempted to quantify the extent to which\na complex dynamical system presents a balance of integrated and segregated\nactivity. In this paper we bring these two areas of research together by\nshowing that the system of oscillators in question exhibits a critical peak of\nintegrated information that coincides with peaks in other measures such as\nmetastability and coalition entropy.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 15:15:35 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Mediano", "Pedro A. M.", ""], ["Farah", "Juan Carlos", ""], ["Shanahan", "Murray", ""]]}, {"id": "1606.08370", "submitter": "Paul Smolen", "authors": "Paul Smolen, Yili Zhang and John H. Byrne", "title": "The right time to learn: mechanisms and optimization of spaced learning", "comments": "34 pages, 5 figures", "journal-ref": "Nature Reviews Neuroscience 2016 Feb; 17(2):77-88", "doi": "10.1038/nrn.2015.18", "report-no": null, "categories": "q-bio.NC q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many types of learning, spaced training that involves repeated long\ninter-trial intervals (ITIs) leads to more robust memory formation than does\nmassed training that involves short or no intervals. Several cognitive theories\nhave been proposed to explain this superiority, but only recently has data\nbegun to delineate the underlying cellular and molecular mechanisms of spaced\ntraining. We review these theories and data here. Computational models of the\nimplicated signaling cascades have predicted that spaced training with\nirregular ITIs can enhance learning. This strategy of using models to predict\noptimal spaced training protocols, combined with pharmacotherapy, suggests\nnovel ways to rescue impaired synaptic plasticity and learning.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jun 2016 17:16:25 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Smolen", "Paul", ""], ["Zhang", "Yili", ""], ["Byrne", "John H.", ""]]}, {"id": "1606.08567", "submitter": "Bruno. Cessac", "authors": "B. Cessac, A. Le Ny, E. Loecherbach", "title": "On the mathematical consequences of binning spike trains", "comments": "22 pages, 6 figures", "journal-ref": "Neural Computation, January 2017, Vol. 29, No. 1, Pages 146-170", "doi": null, "report-no": null, "categories": "q-bio.NC math-ph math.MP physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a mathematical analysis of hidden effects induced by binning\nspike trains of neurons. Assuming that the original spike train has been\ngenerated by a discrete Markov process, we show that binning generates a\nstochastic process which is not Markov any more, but is instead a Variable\nLength Markov Chain (VLMC) with unbounded memory. We also show that the law of\nthe binned raster is a Gibbs measure in the DLR (Dobrushin-Lanford-Ruelle)\nsense coined in mathematical statistical mechanics. This allows the derivation\nof several important consequences on statistical properties of binned spike\ntrains. In particular, we introduce the DLR framework as a natural setting to\nmathematically formalize anticipation, i.e. to tell \"how good\" our nervous\nsystem is at making predictions. In a probabilistic sense, this corresponds to\ncondition a process by its future and we discuss how binning may affect our\nconclusions on this ability. We finally comment what could be the consequences\nof binning in the detection of spurious phase transitions or in the detection\nof wrong evidences of criticality.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 06:12:31 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Cessac", "B.", ""], ["Ny", "A. Le", ""], ["Loecherbach", "E.", ""]]}, {"id": "1606.08724", "submitter": "Natalia Bielczyk Ms", "authors": "Natalia Bielczyk, Alberto Llera, Jan Buitelaar, Jeffrey Glennon,\n  Christian Beckmann", "title": "Increasing robustness of pairwise methods for effective connectivity in\n  Magnetic Resonance Imaging by using fractional moment series of BOLD signal\n  distributions", "comments": "41 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating causal interactions in the brain from functional magnetic\nresonance imaging (fMRI) data remains a challenging task. Multiple studies have\ndemonstrated that all current approaches to determine direction of connectivity\nperform poorly even when applied to synthetic fMRI datasets. Recent advances in\nthis field include methods for pairwise inference, which involve creating a\nsparse connectome in the first step, and then using a classifier in order to\ndetermine the directionality of connection between of every pair of nodes in\nthe second step. In this work, we introduce an advance to the second step of\nthis procedure, by building a classifier based on fractional moments of the\nBOLD distribution combined into cumulants. The classifier is trained on\ndatasets generated under the Dynamic Causal Modeling (DCM) generative model.\nThe directionality is inferred based upon statistical dependencies between the\ntwo node time series, e.g. assigning a causal link from time series of low\nvariance to time series of high variance. Our approach outperforms or performs\nas well as other methods for effective connectivity when applied to the\nbenchmark datasets. Crucially, it is also more resilient to confounding effects\nsuch as differential noise level across different areas of the connectome.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 14:26:43 GMT"}, {"version": "v2", "created": "Fri, 11 Aug 2017 08:52:56 GMT"}, {"version": "v3", "created": "Mon, 14 Aug 2017 07:04:37 GMT"}, {"version": "v4", "created": "Thu, 30 May 2019 09:02:37 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Bielczyk", "Natalia", ""], ["Llera", "Alberto", ""], ["Buitelaar", "Jan", ""], ["Glennon", "Jeffrey", ""], ["Beckmann", "Christian", ""]]}, {"id": "1606.08889", "submitter": "Thierry Mora", "authors": "Christophe Gardella, Olivier Marre, Thierry Mora", "title": "A tractable method for describing complex couplings between neurons and\n  population rate", "comments": null, "journal-ref": "eNeuro 3(4) e0160-15.2016 (2016)", "doi": "10.1523/ENEURO.0160-15.2016", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons within a population are strongly correlated, but how to simply\ncapture these correlations is still a matter of debate. Recent studies have\nshown that the activity of each cell is influenced by the population rate,\ndefined as the summed activity of all neurons in the population. However, an\nexplicit, tractable model for these interactions is still lacking. Here we\nbuild a probabilistic model of population activity that reproduces the firing\nrate of each cell, the distribution of the population rate, and the linear\ncoupling between them. This model is tractable, meaning that its parameters can\nbe learned in a few seconds on a standard computer even for large population\nrecordings. We inferred our model for a population of 160 neurons in the\nsalamander retina. In this population, single-cell firing rates depended in\nunexpected ways on the population rate. In particular, some cells had a\npreferred population rate at which they were most likely to fire. These complex\ndependencies could not be explained by a linear coupling between the cell and\nthe population rate. We designed a more general, still tractable model that\ncould fully account for these non-linear dependencies. We thus provide a simple\nand computationally tractable way to learn models that reproduce the dependence\nof each neuron on the population rate.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2016 21:03:10 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Gardella", "Christophe", ""], ["Marre", "Olivier", ""], ["Mora", "Thierry", ""]]}, {"id": "1606.09095", "submitter": "Lars Rothkegel", "authors": "Lars O. M. Rothkegel, Hans A. Trukenbrod, Heiko H. Sch\\\"utt, Felix A.\n  Wichmann, Ralf Engbert", "title": "Influence of initial fixation position in scene viewing", "comments": "34 pages with 10 figures submitted to Vision Research. Reviews\n  Received on June 8th, 2016 (Minor Revision). Updated Version will be uploaded\n  within the year 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During scene perception our eyes generate complex sequences of fixations.\nPredictors of fixation locations are bottom-up factors like luminance contrast,\ntop-down factors like viewing instruction, and systematic biases like the\ntendency to place fixations near the center of an image. However, comparatively\nlittle is known about the dynamics of scanpaths after experimental manipulation\nof specific fixation locations. Here we investigate the influence of initial\nfixation position on subsequent eye-movement behavior on an image. We presented\n64 colored photographs to participants who started their scanpaths from one of\ntwo experimentally controlled positions in the right or left part of an image.\nAdditionally, we computed the images' saliency maps and classified them as\nbalanced images or images with high saliency values on either the left or right\nside of a picture. As a result of the starting point manipulation, we found\nlong transients of mean fixation position and a tendency to overshoot to the\nimage side opposite to the starting position. Possible mechanisms for the\ngeneration of this overshoot were investigated using numerical simulations of\nstatistical and dynamical models. We conclude that inhibitory tagging is a\nviable mechanism for dynamical planning of scanpaths.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 13:42:56 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2016 10:52:50 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Rothkegel", "Lars O. M.", ""], ["Trukenbrod", "Hans A.", ""], ["Sch\u00fctt", "Heiko H.", ""], ["Wichmann", "Felix A.", ""], ["Engbert", "Ralf", ""]]}, {"id": "1606.09115", "submitter": "Federico Battiston", "authors": "Federico Battiston, Vincenzo Nicosia, Mario Chavez, Vito Latora", "title": "Multilayer motif analysis of brain networks", "comments": "9 pages, 6 figures", "journal-ref": "Chaos 27, 047404 (2017)", "doi": "10.1063/1.4979282", "report-no": null, "categories": "physics.soc-ph cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, network science has shed new light both on the structural\n(anatomical) and on the functional (correlations in the activity) connectivity\namong the different areas of the human brain. The analysis of brain networks\nhas made possible to detect the central areas of a neural system, and to\nidentify its building blocks by looking at overabundant small subgraphs, known\nas motifs. However, network analysis of the brain has so far mainly focused on\nanatomical and functional networks as separate entities. The recently developed\nmathematical framework of multi-layer networks allows to perform an analysis of\nthe human brain where the structural and functional layers are considered\ntogether. In this work we describe how to classify the subgraphs of a multiplex\nnetwork, and we extend motif analysis to networks with an arbitrary number of\nlayers. We then extract multi-layer motifs in brain networks of healthy\nsubjects by considering networks with two layers, anatomical and functional,\nrespectively obtained from diffusion and functional magnetic resonance imaging.\nResults indicate that subgraphs in which the presence of a physical connection\nbetween brain areas (links at the structural layer) coexists with a non-trivial\npositive correlation in their activities are statistically overabundant.\nFinally, we investigate the existence of a reinforcement mechanism between the\ntwo layers by looking at how the probability to find a link in one layer\ndepends on the intensity of the connection in the other one. Showing that\nfunctional connectivity is non-trivially constrained by the underlying\nanatomical network, our work contributes to a better understanding of the\ninterplay between structure and function in the human brain.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 14:23:07 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 17:11:36 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Battiston", "Federico", ""], ["Nicosia", "Vincenzo", ""], ["Chavez", "Mario", ""], ["Latora", "Vito", ""]]}, {"id": "1606.09185", "submitter": "John Medaglia", "authors": "John D. Medaglia, Shi Gu, Fabio Pasqualetti, Rebecca L. Ashare, Caryn\n  Lerman, Joseph Kable, Danielle S. Bassett", "title": "Cognitive Control in the Controllable Connectome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognition is supported by neurophysiological processes that occur both in\nlocal anatomical neighborhoods and in distributed large-scale circuits. Recent\nevidence from network control theory suggests that white matter pathways\nlinking large-scale brain regions provide a critical substrate constraining the\nability of single areas to affect control on those processes. Yet, no direct\nevidence exists for a relationship between brain network controllability and\ncognitive control performance. Here, we address this gap by constructing\nstructural brain networks from diffusion tensor imaging data acquired in 125\nhealthy adult individuals. We define a simplified model of brain dynamics and\nsimulate network control to quantify modal and boundary controllability, which\ntogether describe complementary features of a region's theoretically predicted\npreference to drive the brain into different cognitive states. We observe that\nindividual differences in these control features derived from structural\nconnectivity are significantly correlated with individual differences in\ncognitive control performance, as measured by a continuous performance\nattention test, a color/shape switching task, the Stroop inhibition task, and a\nspatial n-back working memory task. Indeed, control hubs like anterior\ncingulate are distinguished from default mode and frontal association areas in\nterms of the relationship between their control properties and individual\ndifferences in cognitive function. These results provide the first empirical\nevidence that network control forms a fundamental mechanism of cognitive\ncontrol.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 17:07:52 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Medaglia", "John D.", ""], ["Gu", "Shi", ""], ["Pasqualetti", "Fabio", ""], ["Ashare", "Rebecca L.", ""], ["Lerman", "Caryn", ""], ["Kable", "Joseph", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1606.09277", "submitter": "Dominika Lyzwa", "authors": "Dominika Lyzwa and Florentin W\\\"org\\\"otter", "title": "Response and noise correlations to complex natural sounds in the\n  auditory midbrain", "comments": "19 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How natural communication sounds are spatially represented across the\ninferior colliculus, the main center of convergence for auditory information in\nthe midbrain, is not known. The neural representation of the acoustic stimuli\nresults from the interplay of locally differing input and the organization of\nspectral and temporal neural preferences that change gradually across the\nnucleus. This raises the question how similar the neural representation of the\ncommunication sounds is across these gradients of neural preferences, and\nwhether it also changes gradually. Multi-unit cluster spike trains were\nrecorded from guinea pigs presented with a spectrotemporally rich set of eleven\nspecies-specific communication sounds. Using cross-correlation, we analyzed the\nresponse similarity of spiking activity across a broad frequency range for\nsimilarly and differently frequency-tuned neurons. Furthermore, we separated\nthe contribution of the stimulus to the correlations to investigate whether\nsimilarity is only attributable to the stimulus, or, whether interactions exist\nbetween the multi-unit clusters that lead to correlations and whether these\nfollow the same representation as the response similarity. We found that\nsimilarity of responses is dependent on the neurons' spatial distance for\nsimilarly and differently frequency-tuned neurons, and that similarity\ndecreases gradually with spatial distance. Significant neural correlations\nexist, and contribute to the response similarity. Our findings suggest that for\nmulti-unit clusters in the mammalian inferior colliculus, the gradual response\nsimilarity with spatial distance to natural complex sounds is shaped by neural\ninteractions and the gradual organization of neural preferences.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2016 20:42:29 GMT"}], "update_date": "2016-07-01", "authors_parsed": [["Lyzwa", "Dominika", ""], ["W\u00f6rg\u00f6tter", "Florentin", ""]]}, {"id": "1606.09459", "submitter": "Jacek Urbanek PhD", "authors": "Jacek K. Urbanek, Jaroslaw Harezlak, Nancy W. Glynn, Tamara Harris,\n  Ciprian Crainiceanu, Vadim Zipunnikov", "title": "Stride variability measures derived from wrist- and hip-worn\n  accelerometers", "comments": null, "journal-ref": "Gait & Posture 52, 2017", "doi": "10.1016/j.gaitpost.2016.11.045", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many epidemiological and clinical studies use accelerometry to objectively\nmeasure physical activity using the activity counts, vector magnitude, or\nnumber of steps. These measures use just a fraction of the information in the\nraw accelerometry data as they are typically summarized at the minute level. To\naddress this problem we define and estimate two gait measures of temporal\nstride-to-stride variability based on raw accelerometry data: Amplitude\nDeviation (AD) and Phase Deviation (PD). We explore the sensitivity of our\napproach to on-body placement of the accelerometer by comparing hip, left and\nright wrist placements. We illustrate the approach by estimating AD and PD in\n46 elderly participants in the Developmental Epidemiologic Cohort Study (DECOS)\nwho worn accelerometers during a 400 meter walk test. We also show that AD and\nPD have a statistically significant association with the gait speed and\nsit-to-stand test performance\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 12:25:11 GMT"}], "update_date": "2016-12-16", "authors_parsed": [["Urbanek", "Jacek K.", ""], ["Harezlak", "Jaroslaw", ""], ["Glynn", "Nancy W.", ""], ["Harris", "Tamara", ""], ["Crainiceanu", "Ciprian", ""], ["Zipunnikov", "Vadim", ""]]}, {"id": "1606.09545", "submitter": "Kimberly Schlesinger", "authors": "Elizabeth N. Davison, Benjamin O. Turner, Kimberly J. Schlesinger,\n  Michael B. Miller, Scott T. Grafton, Danielle S. Bassett, Jean M. Carlson", "title": "Individual Differences in Dynamic Functional Brain Connectivity Across\n  the Human Lifespan", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1005178", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual differences in brain functional networks may be related to complex\npersonal identifiers, including health, age, and ability. Understanding and\nquantifying these differences is a necessary first step towards developing\npredictive methods derived from network topology. Here, we present a method to\nquantify individual differences in brain functional dynamics by applying\nhypergraph analysis, a method from dynamic network theory. Using a summary\nmetric derived from the hypergraph formalism---hypergraph cardinality---we\ninvestigate individual variations in two separate and complementary data sets.\nThe first data set (\"multi-task\") consists of 77 individuals engaging in four\nconsecutive cognitive tasks. We observed that hypergraph cardinality exhibits\nvariation across individuals while remaining consistent within individuals\nbetween tasks; moreover, one of the memory tasks evinced a marginally\nsignificant correspondence between hypergraph cardinality and age. This finding\nmotivated a similar analysis of the second data set (\"age-memory\"), in which 95\nindividuals of varying ages performed a memory task with a similar structure to\nthe multi-task memory task. With the increased age range in the age-memory data\nset, the correlation between hypergraph cardinality and age correspondence\nbecomes significant. We discuss these results in the context of the well-known\nfinding linking age with network structure, and suggest that age-related\nchanges in brain function can be better understood by taking an integrative\napproach that incorporates information about the dynamics of functional\ninteractions.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 15:51:14 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Davison", "Elizabeth N.", ""], ["Turner", "Benjamin O.", ""], ["Schlesinger", "Kimberly J.", ""], ["Miller", "Michael B.", ""], ["Grafton", "Scott T.", ""], ["Bassett", "Danielle S.", ""], ["Carlson", "Jean M.", ""]]}]