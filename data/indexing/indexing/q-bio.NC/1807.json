[{"id": "1807.00053", "submitter": "Aran Nayebi", "authors": "Aran Nayebi, Daniel Bear, Jonas Kubilius, Kohitij Kar, Surya Ganguli,\n  David Sussillo, James J. DiCarlo, Daniel L. K. Yamins", "title": "Task-Driven Convolutional Recurrent Models of the Visual System", "comments": "NIPS 2018 Camera Ready Version, 16 pages including supplementary\n  information, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feed-forward convolutional neural networks (CNNs) are currently\nstate-of-the-art for object classification tasks such as ImageNet. Further,\nthey are quantitatively accurate models of temporally-averaged responses of\nneurons in the primate brain's visual system. However, biological visual\nsystems have two ubiquitous architectural features not shared with typical\nCNNs: local recurrence within cortical areas, and long-range feedback from\ndownstream areas to upstream areas. Here we explored the role of recurrence in\nimproving classification performance. We found that standard forms of\nrecurrence (vanilla RNNs and LSTMs) do not perform well within deep CNNs on the\nImageNet task. In contrast, novel cells that incorporated two structural\nfeatures, bypassing and gating, were able to boost task accuracy substantially.\nWe extended these design principles in an automated search over thousands of\nmodel architectures, which identified novel local recurrent cells and\nlong-range feedback connections useful for object recognition. Moreover, these\ntask-optimized ConvRNNs matched the dynamics of neural activity in the primate\nvisual system better than feedforward networks, suggesting a role for the\nbrain's recurrent connections in performing difficult visual behaviors.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2018 20:27:23 GMT"}, {"version": "v2", "created": "Sat, 27 Oct 2018 03:49:01 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Nayebi", "Aran", ""], ["Bear", "Daniel", ""], ["Kubilius", "Jonas", ""], ["Kar", "Kohitij", ""], ["Ganguli", "Surya", ""], ["Sussillo", "David", ""], ["DiCarlo", "James J.", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1807.00082", "submitter": "Thomas Dean", "authors": "Thomas Dean, Maurice Chiang, Marcus Gomez, Nate Gruver, Yousef Hindy,\n  Michelle Lam, Peter Lu, Sophia Sanchez, Rohun Saxena, Michael Smith, Lucy\n  Wang, Catherine Wong", "title": "Amanuensis: The Programmer's Apprentice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This document provides an overview of the material covered in a course taught\nat Stanford in the spring quarter of 2018. The course draws upon insight from\ncognitive and systems neuroscience to implement hybrid connectionist and\nsymbolic reasoning systems that leverage and extend the state of the art in\nmachine learning by integrating human and machine intelligence. As a concrete\nexample we focus on digital assistants that learn from continuous dialog with\nan expert software engineer while providing initial value as powerful\nanalytical, computational and mathematical savants. Over time these savants\nlearn cognitive strategies (domain-relevant problem solving skills) and develop\nintuitions (heuristics and the experience necessary for applying them) by\nlearning from their expert associates. By doing so these savants elevate their\ninnate analytical skills allowing them to partner on an equal footing as\nversatile collaborators - effectively serving as cognitive extensions and\ndigital prostheses, thereby amplifying and emulating their human partner's\nconceptually-flexible thinking patterns and enabling improved access to and\ncontrol over powerful computing resources.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 22:59:08 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 13:33:18 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Dean", "Thomas", ""], ["Chiang", "Maurice", ""], ["Gomez", "Marcus", ""], ["Gruver", "Nate", ""], ["Hindy", "Yousef", ""], ["Lam", "Michelle", ""], ["Lu", "Peter", ""], ["Sanchez", "Sophia", ""], ["Saxena", "Rohun", ""], ["Smith", "Michael", ""], ["Wang", "Lucy", ""], ["Wong", "Catherine", ""]]}, {"id": "1807.00509", "submitter": "David Hofmann", "authors": "Chenfei Zhang, David Hofmann, Andreas Neef and Fred Wolf", "title": "Ultrafast population coding and axo-somatic compartmentalization", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cortical neurons in the fluctuation driven regime can realize ultrafast\npopulation encoding. The underlying biophysical mechanisms, however, are not\nwell understood. Reducing the sharpness of the action potential onset can\nimpair ultrafast population encoding, but it is not clear whether a sharp\naction potential onset is sufficient for ultrafast population encoding. One\nhypothesis proposes that the sharp action potential onset is caused by the\nelectrotonic separation of the site of action potential initiation from the\nsoma, and that this spatial separation also results in ultrafast population\nencoding. Here we examined this hypothesis by studying the linear response\nproperties of model neurons with a defined initiation site. We find that\nplacing the initiation site at different axonal positions has only a weak\nimpact on the linear response function of the model. It fails to generate the\nultrafast response and high bandwidth that is observed in cortical neurons.\nFurthermore, the high frequency regime of the linear response function of this\nmodel is insensitive to correlation times of the input current contradicting\nempirical evidence. When we increase the voltage sensitivity of sodium channels\nat the initiation site, the two empirically observed phenomena can be\nrecovered. We provide an explanation for the dissociation of sharp action\npotential onset and ultrafast response. By investigating varying soma sizes, we\nfurthermore highlight the effect of neuron morphology on the linear response.\nOur results show that a sharp onset of action potentials is not sufficient for\nthe ultrafast response. In the light of recent reports of activity-dependent\nrepositioning of the axon initial segment, our study predicts that a more\ndistal initiation site can lead to an increased sharpness of the somatic\nwaveform but it does not affect the linear response of a population of neurons.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 08:04:57 GMT"}, {"version": "v2", "created": "Tue, 3 Jul 2018 09:24:14 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Zhang", "Chenfei", ""], ["Hofmann", "David", ""], ["Neef", "Andreas", ""], ["Wolf", "Fred", ""]]}, {"id": "1807.00764", "submitter": "Keith Hayton", "authors": "Keith Hayton and Dimitrios Moirogiannis and Marcelo Magnasco", "title": "A Nonhyperbolic Toy Model of Cochlear Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cochlea displays complex and highly nonlinear behavior in response to\nwide-ranging auditory stimuli. While there have been many recent advancements\nin the modeling of cochlear dynamics, it remains unclear what mathematical\nstructures underlie the essential features of the extended cochlea. We\nconstruct a dynamical system consisting of a series of strongly coupled\ncritical oscillators to show that high-dimensional nonhyperbolic dynamics can\naccount for high-order compressive nonlinearities, amplification of weak input,\nfrequency selectivity, and traveling waves of activity. As a single Hopf\nbifurcation generically gives rise to features of cochlea at a local level, the\nnonhyperbolicity mechanism proposed in this paper can be seen as a\nhigher-dimensional analogue for the entire extended cochlea.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 16:02:54 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2018 10:32:14 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Hayton", "Keith", ""], ["Moirogiannis", "Dimitrios", ""], ["Magnasco", "Marcelo", ""]]}, {"id": "1807.01469", "submitter": "Zihao Xu", "authors": "Zihao Xu", "title": "Shot Noise Neuron Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a shot noise-based leaky integrated and firing\nneuron model and provide a detailed analysis of the performance of this model\ncompared to the traditional diffusion approximated model. In theoretical\nneuroscience, there are three general neuron models in the field: Compartmental\nneuron model is a conductance-based model, in which it views the biological\nneurons as a large circuit. The problem of this model comes from its structural\ncomplexity and the number of its free parameters; Leaky integrated and firing\nmodel is a more flexible model due to the special design called\nthreshold-resetting, in which the voltage of the neuron is reset after reaching\nthe threshold. This model is proposed as an alternative to the compartment\nmodel to provide a more biologically realistic model that can capture spike\ntiming behaviors that are observed in experiments. In addition to that, it is\nmore computationally efficient since it has much less free parameters; Firing\nrate-based neuron model uses the firing rate of the neuron as the coupling\nterms in the coupled neuronal network models. Models of this kind can be easily\nanalyzed on the network level. Theoretical analysis for this model proves the\nexistence of phase transition and shows that the computational capacity is\nboosted in the chaotic regime.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 07:38:43 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Xu", "Zihao", ""]]}, {"id": "1807.01479", "submitter": "Johannes Zierenberg", "authors": "Johannes Zierenberg and Jens Wilting and Viola Priesemann", "title": "Homeostatic plasticity and external input shape neural network dynamics", "comments": "14 pages, 8 figures, accepted at Phys. Rev. X", "journal-ref": "Phys. Rev. X 8, 031018 (2018)", "doi": "10.1103/PhysRevX.8.031018", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vitro and in vivo spiking activity clearly differ. Whereas networks in\nvitro develop strong bursts separated by periods of very little spiking\nactivity, in vivo cortical networks show continuous activity. This is puzzling\nconsidering that both networks presumably share similar single-neuron dynamics\nand plasticity rules. We propose that the defining difference between in vitro\nand in vivo dynamics is the strength of external input. In vitro, networks are\nvirtually isolated, whereas in vivo every brain area receives continuous input.\nWe analyze a model of spiking neurons in which the input strength, mediated by\nspike rate homeostasis, determines the characteristics of the dynamical state.\nIn more detail, our analytical and numerical results on various network\ntopologies show consistently that under increasing input, homeostatic\nplasticity generates distinct dynamic states, from bursting, to\nclose-to-critical, reverberating and irregular states. This implies that the\ndynamic state of a neural network is not fixed but can readily adapt to the\ninput strengths. Indeed, our results match experimental spike recordings in\nvitro and in vivo: the in vitro bursting behavior is consistent with a state\ngenerated by very low network input (< 0.1%), whereas in vivo activity suggests\nthat on the order of 1% recorded spikes are input-driven, resulting in\nreverberating dynamics. Importantly, this predicts that one can abolish the\nubiquitous bursts of in vitro preparations, and instead impose dynamics\ncomparable to in vivo activity by exposing the system to weak long-term\nstimulation, thereby opening new paths to establish an in vivo-like assay in\nvitro for basic as well as neurological studies.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 08:30:38 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Zierenberg", "Johannes", ""], ["Wilting", "Jens", ""], ["Priesemann", "Viola", ""]]}, {"id": "1807.01491", "submitter": "David Gall", "authors": "David Gall and Genevi\\`eve Dupont", "title": "Tonic activation of extrasynaptic NMDA receptors decreases intrinsic\n  excitability and promotes bistability in a model of neuronal activity", "comments": "20 pages, 5 figures", "journal-ref": "Int J Mol Sci. 2019 Dec 27;21(1). pii: E206", "doi": "10.3390/ijms21010206", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NMDA receptors (NMDA-R) typically contribute to excitatory synaptic\ntransmission in the central nervous system. While calcium influx through NMDA-R\nplays a critical role in synaptic plasticity, experimental evidence indicates\nthat NMDAR-mediated calcium influx also modifies neuronal excitability through\nthe activation of calcium-activated potassium channels. This mechanism has not\nyet been studied theoretically. Our theoretical model provides a simple\ndescription of neuronal electrical activity that takes into account the tonic\nactivity of extrasynaptic NMDA receptors and a cytosolic calcium compartment.\nWe show that calcium influx mediated by the tonic activity of NMDA-R can be\ncoupled directly to the activation of calcium-activated potassium channels,\nresulting in an overall inhibitory effect on neuronal excitability.\nFurthermore, the presence of tonic NMDA-R activity promotes bistability in\nelectrical activity by dramatically increasing the stimulus interval where both\na stable steady state and repetitive firing can coexist. These results could\nprovide an intrinsic mechanism for the constitution of memory traces in\nneuronal circuits. They also shed light on the way by which $\\beta$-amyloids\ncan alter neuronal activity when interfering with NMDA-R in Alzheimer's disease\nand cerebral ischemia.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 09:17:50 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 10:21:54 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Gall", "David", ""], ["Dupont", "Genevi\u00e8ve", ""]]}, {"id": "1807.01585", "submitter": "Joram Soch", "authors": "Joram Soch", "title": "cvBMS and cvBMA: filling in the gaps", "comments": "14 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With this technical report, we provide mathematical and implementational\ndetails of cross-validated Bayesian model selection (cvBMS) and averaging\n(cvBMA) that could not be communicated in the corresponding peer-reviewed\njournal articles. This will allow statisticians and developers to comprehend\ninternal functionalities of cvBMS and cvBMA for further development of these\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 07:19:40 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Soch", "Joram", ""]]}, {"id": "1807.01597", "submitter": "Joos Behncke", "authors": "Joos Behncke, Robin Tibor Schirrmeister, Wolfram Burgard, Tonio Ball", "title": "The role of robot design in decoding error-related information from EEG\n  signals of a human observer", "comments": null, "journal-ref": null, "doi": "10.5220/0006934900610066", "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For utilization of robotic assistive devices in everyday life, means for\ndetection and processing of erroneous robot actions are a focal aspect in the\ndevelopment of collaborative systems, especially when controlled via brain\nsignals. Though, the variety of possible scenarios and the diversity of used\nrobotic systems pose a challenge for error decoding from recordings of brain\nsignals such as via EEG. For example, it is unclear whether humanoid\nappearances of robotic assistants have an influence on the performance. In this\npaper, we designed a study in which two different robots executed the same task\nboth in an erroneous and a correct manner. We find error-related EEG signals of\nhuman observers indicating that the performance of the error decoding was\nindependent of robot design. However, we can show that it was possible to\nidentify which robot performed the instructed task by means of the EEG signals.\nIn this case, deep convolutional neural networks (deep ConvNets) could reach\nsignificantly higher accuracies than both regularized Linear Discriminanat\nAnalysis (rLDA) and filter bank common spatial patterns (FB-CSP) combined with\nrLDA. Our findings indicate that decoding information about robot action\nsuccess from the EEG, particularly when using deep neural networks, may be an\napplicable approach for a broad range of robot designs.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 14:06:31 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 09:53:33 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Behncke", "Joos", ""], ["Schirrmeister", "Robin Tibor", ""], ["Burgard", "Wolfram", ""], ["Ball", "Tonio", ""]]}, {"id": "1807.02103", "submitter": "Pae Hongju", "authors": "Kyumin Moon and Hongju Pae", "title": "Making Sense of Consciousness as Integrated Information: Evolution and\n  Issues of IIT", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this article is to provide an overall critical appraisal of\nIntegrated Information Theory(IIT) of consciousness. We explore how it has\nevolved and what problems are involved in the theory. IIT is a hypothesis that\nconsciousness can be explained in terms of integrated information. It argues\nthat a number of fundamental properties of experience can be properly analyzed\nand explained by physical systems' informational properties. Throughout the\nlast decade, there have been many advances in IIT's theoretical structure and\nmathematical model. In addition, like all hypotheses in the field of science of\nconsciousness, IIT has given rise to several controversies and issues. In this\ncontext, a critical survey for IIT is urgently needed. To this end, we first\nintroduce fundamental concepts of IIT and related issues. Thereafter, we\ndiscuss major transitions IIT has been through and point out related\nintra-model issues. Finally, in the last section, some theoretical, extra-model\nissues involved in IIT's principles are presented. The article concludes by\nsuggesting that, for the sake of future development, IIT should more seriously\ntake metacognitive accessibility to experience.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 08:17:16 GMT"}, {"version": "v2", "created": "Sun, 30 Sep 2018 14:28:34 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Moon", "Kyumin", ""], ["Pae", "Hongju", ""]]}, {"id": "1807.02126", "submitter": "Kanika Bansal", "authors": "Kanika Bansal, Javier O. Garcia, Steven H. Tompson, Timothy Verstynen,\n  Jean M. Vettel, and Sarah F. Muldoon", "title": "Cognitive chimera states in human brain networks", "comments": null, "journal-ref": null, "doi": "10.1126/sciadv.aau8535", "report-no": null, "categories": "q-bio.NC math.DS physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain is a complex dynamical system that gives rise to cognition\nthrough spatiotemporal patterns of coherent and incoherent activity between\nbrain regions. As different regions dynamically interact to perform cognitive\ntasks, variable patterns of partial synchrony can be observed, forming chimera\nstates. We propose that the emergence of such states plays a fundamental role\nin the cognitive organization of the brain, and present a novel\ncognitively-informed, chimera-based framework to explore how large-scale brain\narchitecture affects brain dynamics and function. Using personalized brain\nnetwork models, we systematically study how regional brain stimulation produces\ndifferent patterns of synchronization across predefined cognitive systems. We\nthen analyze these emergent patterns within our novel framework to understand\nthe impact of subject-specific and region-specific structural variability on\nbrain dynamics. Our results suggest a classification of cognitive systems into\nfour groups with differing levels of subject and regional variability that\nreflect their different functional roles.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 18:03:19 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Bansal", "Kanika", ""], ["Garcia", "Javier O.", ""], ["Tompson", "Steven H.", ""], ["Verstynen", "Timothy", ""], ["Vettel", "Jean M.", ""], ["Muldoon", "Sarah F.", ""]]}, {"id": "1807.02155", "submitter": "Konstantinos Michmizos", "authors": "Guangzhi Tang, Konstantinos P. Michmizos", "title": "Gridbot: An autonomous robot controlled by a Spiking Neural Network\n  mimicking the brain's navigational system", "comments": "8 pages, 3 Figures, International Conference on Neuromorphic Systems\n  (ICONS 2018)", "journal-ref": null, "doi": "10.1145/3229884.3229888", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is true that the \"best\" neural network is not necessarily the one with the\nmost \"brain-like\" behavior. Understanding biological intelligence, however, is\na fundamental goal for several distinct disciplines. Translating our\nunderstanding of intelligence to machines is a fundamental problem in robotics.\nPropelled by new advancements in Neuroscience, we developed a spiking neural\nnetwork (SNN) that draws from mounting experimental evidence that a number of\nindividual neurons is associated with spatial navigation. By following the\nbrain's structure, our model assumes no initial all-to-all connectivity, which\ncould inhibit its translation to a neuromorphic hardware, and learns an\nuncharted territory by mapping its identified components into a limited number\nof neural representations, through spike-timing dependent plasticity (STDP). In\nour ongoing effort to employ a bioinspired SNN-controlled robot to real-world\nspatial mapping applications, we demonstrate here how an SNN may robustly\ncontrol an autonomous robot in mapping and exploring an unknown environment,\nwhile compensating for its own intrinsic hardware imperfections, such as\npartial or total loss of visual input.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 19:09:45 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Tang", "Guangzhi", ""], ["Michmizos", "Konstantinos P.", ""]]}, {"id": "1807.02390", "submitter": "Nida Obatake", "authors": "Molly Hoch and Samuel Muthiah and Nida Obatake", "title": "On the identification of $k$-inductively pierced codes using toric\n  ideals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural codes are binary codes in $\\{0,1\\}^n$; here we focus on the ones which\nrepresent the firing patterns of a type of neurons called place cells. There is\nmuch interest in determining which neural codes can be realized by a collection\nof convex sets. However, drawing representations of these convex sets,\nparticularly as the number of neurons in a code increases, can be very\ndifficult. Nevertheless, for a class of codes that are said to be\n$k$-inductively pierced for $k=0,1,2$ there is an algorithm for drawing Euler\ndiagrams. Here we use the toric ideal of a code to show sufficient conditions\nfor a code to be 1- or 2-inductively pierced, so that we may use the existing\nalgorithm to draw realizations of such codes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 13:06:11 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Hoch", "Molly", ""], ["Muthiah", "Samuel", ""], ["Obatake", "Nida", ""]]}, {"id": "1807.02479", "submitter": "Noemi Montobbio", "authors": "Noemi Montobbio, Alessandro Sarti, Giovanna Citti", "title": "A metric model for the functional architecture of the visual cortex", "comments": "21 pages, 9 figures. Added acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.MG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this work is to construct a model for the functional\narchitecture of the primary visual cortex (V1), based on a structure of metric\nmeasure space induced by the underlying organization of receptive profiles\n(RPs) of visual cells. In order to account for the horizontal connectivity of\nV1 in such a context, a diffusion process compatible with the geometry of the\nspace is defined following the classical approach of K.-T. Sturm. The\nconstruction of our distance function does neither require any group\nparameterization of the family of RPs, nor involve any differential structure.\nAs such, it adapts to non-parameterized sets of RPs, possibly obtained through\nnumerical procedures; it also allows to model the lateral connectivity arising\nfrom non-differential metrics such as the one induced on a pinwheel surface by\na family of filters of vanishing scale. On the other hand, when applied to the\nclassical framework of Gabor filters, this construction yields a distance\napproximating the sub-Riemannian structure proposed as a model for V1 by G.\nCitti and A. Sarti [J Math Imaging Vis 24: 307 (2006)], thus showing itself to\nbe consistent with existing cortex models.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 16:46:32 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 13:48:36 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Montobbio", "Noemi", ""], ["Sarti", "Alessandro", ""], ["Citti", "Giovanna", ""]]}, {"id": "1807.02514", "submitter": "Konstantinos Michmizos", "authors": "Ioannis Polykretis, Vladimir Ivanov, Konstantinos P. Michmizos", "title": "A Neural-Astrocytic Network Architecture: Astrocytic calcium waves\n  modulate synchronous neuronal activity", "comments": "International Conference on Neuromorphic Systems (ICONS) 2018", "journal-ref": null, "doi": "10.1145/3229884.3229890", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the role of astrocytes in brain computation is a nascent\nchallenge, promising immense rewards, in terms of new neurobiological knowledge\nthat can be translated into artificial intelligence. In our ongoing effort to\nidentify principles endow-ing the astrocyte with unique functions in brain\ncomputation, and translate them into neural-astrocytic networks (NANs), we\npropose a biophysically realistic model of an astrocyte that preserves the\nexperimentally observed spatial allocation of its distinct subcellular\ncompartments. We show how our model may encode, and modu-late, the extent of\nsynchronous neural activity via calcium waves that propagate intracellularly\nacross the astrocytic compartments. This relationship between neural activity\nand astrocytic calcium waves has long been speculated but it is still lacking a\nmechanistic explanation. Our model suggests an astrocytic \"calcium cascade\"\nmechanism for neuronal synchronization, which may empower NANs by imposing\nperiodic neural modulation known to reduce coding errors. By expanding our\nnotions of information processing in astrocytes, our work aims to solidify a\ncomputational role for non-neuronal cells and incorporate them into artificial\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 18:04:28 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Polykretis", "Ioannis", ""], ["Ivanov", "Vladimir", ""], ["Michmizos", "Konstantinos P.", ""]]}, {"id": "1807.02575", "submitter": "Jonas M. T\\\"olle Dr. math.", "authors": "Christian Kuehn and Jonas M. T\\\"olle", "title": "A gradient flow formulation for the stochastic Amari neural field model", "comments": "21 pages, 1 figure, 75 references", "journal-ref": "J. Math. Biol. 79 (2019), no. 4, 1227--1252", "doi": "10.1007/s00285-019-01393-w", "report-no": null, "categories": "math.AP math.DS math.FA math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study stochastic Amari-type neural field equations, which are mean-field\nmodels for neural activity in the cortex. We prove that under certain\nassumptions on the coupling kernel, the neural field model can be viewed as a\ngradient flow in a nonlocal Hilbert space. This makes all gradient flow methods\navailable for the analysis, which could previously not be used, as it was not\nknown, whether a rigorous gradient flow formulation exists. We show that the\nequation is well-posed in the nonlocal Hilbert space in the sense that\nsolutions starting in this space also remain in it for all times and space-time\nregularity results hold for the case of spatially correlated noise. Uniqueness\nof invariant measures, ergodic properties for the associated Feller semigroups,\nand several examples of kernels are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 21:56:54 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 11:53:32 GMT"}], "update_date": "2019-11-11", "authors_parsed": [["Kuehn", "Christian", ""], ["T\u00f6lle", "Jonas M.", ""]]}, {"id": "1807.02612", "submitter": "Muhammad Yousefnezhad", "authors": "Tonglin Xu, Muhammad Yousefnezhad, Daoqiang Zhang", "title": "Gradient Hyperalignment for multi-subject fMRI data alignment", "comments": "15th Pacific Rim International Conference on Artificial Intelligence\n  (PRICAI 2018), Nanjing, China, August 28-31, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-subject fMRI data analysis is an interesting and challenging problem in\nhuman brain decoding studies. The inherent anatomical and functional\nvariability across subjects make it necessary to do both anatomical and\nfunctional alignment before classification analysis. Besides, when it comes to\nbig data, time complexity becomes a problem that cannot be ignored. This paper\nproposes Gradient Hyperalignment (Gradient-HA) as a gradient-based functional\nalignment method that is suitable for multi-subject fMRI datasets with large\namounts of samples and voxels. The advantage of Gradient-HA is that it can\nsolve independence and high dimension problems by using Independent Component\nAnalysis (ICA) and Stochastic Gradient Ascent (SGA). Validation using\nmulti-classification tasks on big data demonstrates that Gradient-HA method has\nless time complexity and better or comparable performance compared with other\nstate-of-the-art functional alignment methods.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 05:02:04 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Xu", "Tonglin", ""], ["Yousefnezhad", "Muhammad", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1807.02741", "submitter": "Carina Curto", "authors": "Carina Curto, Elizabeth Gross, Jack Jeffries, Katherine Morrison, Zvi\n  Rosen, Anne Shiu, and Nora Youngs", "title": "Algebraic signatures of convex and non-convex codes", "comments": "22 pages, 6 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A convex code is a binary code generated by the pattern of intersections of a\ncollection of open convex sets in some Euclidean space. Convex codes are\nrelevant to neuroscience as they arise from the activity of neurons that have\nconvex receptive fields. In this paper, we use algebraic methods to determine\nif a code is convex. Specifically, we use the neural ideal of a code, which is\na generalization of the Stanley-Reisner ideal. Using the neural ideal together\nwith its standard generating set, the canonical form, we provide algebraic\nsignatures of certain families of codes that are non-convex. We connect these\nsignatures to the precise conditions on the arrangement of sets that prevent\nthe codes from being convex. Finally, we also provide algebraic signatures for\nsome families of codes that are convex, including the class of\nintersection-complete codes. These results allow us to detect convexity and\nnon-convexity in a variety of situations, and point to some interesting open\nquestions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 02:43:04 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Curto", "Carina", ""], ["Gross", "Elizabeth", ""], ["Jeffries", "Jack", ""], ["Morrison", "Katherine", ""], ["Rosen", "Zvi", ""], ["Shiu", "Anne", ""], ["Youngs", "Nora", ""]]}, {"id": "1807.02755", "submitter": "Timothy Wanger", "authors": "Timothy J. Wanger", "title": "An ALE meta-analytic comparison of verbal working memory tasks", "comments": "24 pages, 6 Tables/Figures, Keywords: fMRI, meta-analysis, 2-back,\n  3-back, PASAT", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The n-back and Paced Auditory Serial Addition Test (PASAT) are\ncommonly used verbal working memory tasks that have partially overlapping uses\nin clinical and experimental psychology. We performed three activation\nlikelihood estimation (ALE) meta-analyses, comparing two load levels of the\nn-back task (2-back, 3-back) to the PASAT and to each-other. These analyses\naimed to determine the involvement of cognitive and emotional brain regions for\nthese tasks. Results: We observed higher overall likelihood of activation the\nfrontal eye fields in the 3-back. The PASAT exhibited higher overall activation\nin the bilateral supplementary motor areas (SMA), left supramarginal gyrus, and\nleft superior parietal lobule. Furthermore, the 3-back exhibited higher\nactivation in the right SMA, and anterior mid-cingulate cortex versus the\n2-back, and the PASAT exhibited higher activation in a cluster near the right\npremotor area versus the 2-back. A laterality effect was observed in the\ndorsolateral prefrontal cortex between the PASAT (left) and 3-back(right).\nThese data suggest greater activation of regions traditionally associated with\nthe phonological loop during the PASAT, compared to the 2- and 3-back tasks.\nFurthermore, individual ALE analyses suggest involvement of emotional\nprocessing and salience network regions (insula, cingulate) in addition to the\nwell-established verbal working memory regions (Broca's region, bilateral SMA,\npremotor, posterior parietal cortices) in all 3 tasks. Conclusions: Here we\nidentify regions activated by the PASAT, which has not been meta-analytically\nreviewed prior to this study. Using ALE meta-analysis, we have also identified\nmeaningful differences in activation associated with specific cognitive and\nemotional aspects of verbal working memory during these tasks.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 05:06:58 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Wanger", "Timothy J.", ""]]}, {"id": "1807.02885", "submitter": "Moo K. Chung", "authors": "Moo K. Chung, Zhan Luo, Alex D. Leow, Andrew L. Alexander, Richard J.\n  Davidson, H. Hill Goldsmith", "title": "Exact Combinatorial Inference for Brain Images", "comments": "Accepted for publication in MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The permutation test is known as the exact test procedure in statistics.\nHowever, often it is not exact in practice and only an approximate method since\nonly a small fraction of every possible permutation is generated. Even for a\nsmall sample size, it often requires to generate tens of thousands\npermutations, which can be a serious computational bottleneck. In this paper,\nwe propose a novel combinatorial inference procedure that enumerates all\npossible permutations combinatorially without any resampling. The proposed\nmethod is validated against the standard permutation test in simulation studies\nwith the ground truth. The method is further applied in twin DTI study in\ndetermining the genetic contribution of the minimum spanning tree of the\nstructural brain connectivity.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 21:07:27 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Chung", "Moo K.", ""], ["Luo", "Zhan", ""], ["Leow", "Alex D.", ""], ["Alexander", "Andrew L.", ""], ["Davidson", "Richard J.", ""], ["Goldsmith", "H. Hill", ""]]}, {"id": "1807.03023", "submitter": "Marco Pisanello", "authors": "Marco Pisanello, Filippo Pisano, Minsuk Hyun, Emanuela Maglie, Antonio\n  Balena, Massimo De Vittorio, Bernardo L Sabatini, Ferruccio Pisanello", "title": "Analytical and empirical measurement of fiber photometry signal volume\n  in brain tissue", "comments": "20 pages, 6 figures, 5 supplementary figures (3 pages), 5\n  supplementary scripts (18 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.optics physics.bio-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fiber photometry permits monitoring fluorescent indicators of neural activity\nin behaving animals. Optical fibers are typically used to excite and collect\nfluorescence from genetically-encoded calcium indicators expressed by a subset\nof neurons in a circuit of interest. However, a quantitative understanding of\nthe brain volumes from which signal is collected and how this depends on the\nproperties of the optical fibers are lacking. Here we analytically model and\nexperimentally measure the light emission and collection fields for optical\nfibers in solution and scattering tissue, providing a comprehensive\ncharacterization of fibers commonly employed for fiber photometry. Since\nphotometry signals depend on both excitation and collection efficiency, a\ncombined confocal/2-photon microscope was developed to evaluate these\nparameters independently. We find that the 80% of the effective signal arises\nfrom a 10^5-10^6 um3 volume extending ~200 um from the fiber face, and thus\npermitting a spatial interpretation of measurements made with fiber photometry.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 10:17:34 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Pisanello", "Marco", ""], ["Pisano", "Filippo", ""], ["Hyun", "Minsuk", ""], ["Maglie", "Emanuela", ""], ["Balena", "Antonio", ""], ["De Vittorio", "Massimo", ""], ["Sabatini", "Bernardo L", ""], ["Pisanello", "Ferruccio", ""]]}, {"id": "1807.03174", "submitter": "Tito Arecchi", "authors": "F. T. Arecchi", "title": "A quantum uncertainty entails entangled linguistic sequences", "comments": "14 pages. arXiv admin note: substantial text overlap with\n  arXiv:1506.00610", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronization of finite spike sequences is the way two brain regions\ncompare their content and extract the most suitable sequence. This is the core\nof the linguistic comparison between a word and a previous one retrieved by\nmemory. Classifying the information content of neural spike trains, an\nuncertainty relation emerges between the bit size of a word and its duration.\nThis uncertainty affects the task of synchronizing spike trains of different\nduration representing different words, entailing the occurrence of entangled\nsequences, so that word comparison amounts to a measurement based quantum\ncomputation. Entanglement explains the inverse Bayes inference that connects\ndifferent words in a linguistic search. The behaviour here discussed provides\nan explanation for other reported evidences of quantum effects in human\ncognitive processes lacking a plausible framework, since either no assignment\nof an appropriate quantum constant had been associated, or speculating on\nmicroscopic processes dependent on Planck's constant resulted in unrealistic\nde-coherence times.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 09:04:59 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Arecchi", "F. T.", ""]]}, {"id": "1807.03238", "submitter": "Asim Iqbal", "authors": "Asim Iqbal, Asfandyar Sheikh, Theofanis Karayannis", "title": "Exploring Brain-wide Development of Inhibition through Deep Learning", "comments": "33 pages, 21 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce here a fully automated convolutional neural network-based method\nfor brain image processing to Detect Neurons in different brain Regions during\nDevelopment (DeNeRD). Our method takes a developing mouse brain as input and i)\nregisters the brain sections against a developing mouse reference atlas, ii)\ndetects various types of neurons, and iii) quantifies the neural density in\nmany unique brain regions at different postnatal (P) time points. Our method is\ninvariant to the shape, size and expression of neurons and by using DeNeRD, we\ncompare the brain-wide neural density of all GABAergic neurons in developing\nbrains of ages P4, P14 and P56. We discover and report 6 different clusters of\nregions in the mouse brain in which GABAergic neurons develop in a differential\nmanner from early age (P4) to adulthood (P56). These clusters reveal key steps\nof GABAergic cell development that seem to track with the functional\ndevelopment of diverse brain regions as the mouse transitions from a passive\nreceiver of sensory information (<P14) to an active seeker (>P14).\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 15:39:09 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Iqbal", "Asim", ""], ["Sheikh", "Asfandyar", ""], ["Karayannis", "Theofanis", ""]]}, {"id": "1807.03696", "submitter": "Peter Taylor", "authors": "Nishant Sinha, Yujiang Wang, Justin Dauwels, Marcus Kaiser, Thomas\n  Thesen, Rob Forsyth, Peter Neal Taylor", "title": "Computer modelling of connectivity change suggests epileptogenesis\n  mechanisms in idiopathic generalised epilepsy", "comments": null, "journal-ref": "NeuroImage.Clinical 21 (2019) 101655", "doi": "10.1016/j.nicl.2019.101655", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Patients with idiopathic generalised epilepsy (IGE) typically have normal\nconventional magnetic resonance imaging (MRI), hence MRI based diagnosis is\nchallenging. Anatomical abnormalities underlying brain dysfunctions in IGE are\nunclear and their relation to the pathomechanisms of epileptogenesis is poorly\nunderstood. In this study, we applied connectometry, an advanced quantitative\nneuroimaging technique for investigating localised changes in white-matter\ntissue. Analysing white matter structures of 32 subjects we incorporated our\nfindings in a computational model of seizure dynamics to suggest a plausible\nmechanism of epileptogenesis. Patients with IGE have significant bilateral\nalterations in major white-matter fascicles. In the cingulum, fornix, and\nsuperior longitudinal fasciculus, tract integrity is compromised, whereas in\nspecific parts of tracts between thalamus and the precentral gyrus, tract\nintegrity is enhanced in patients. Combining these alterations in a logistic\nregression model, we computed the decision boundary that discriminated patients\nand controls. The computational model, informed with the findings on the tract\nabnormalities, specifically highlighted the importance of enhanced\ncortico-reticular connections along with impaired cortico-cortical connections\nin inducing pathological seizure-like dynamics. We emphasise taking\ndirectionality of brain connectivity into consideration towards understanding\nthe pathological mechanisms; this is possible by combining neuroimaging and\ncomputational modelling. Our imaging evidence of structural alterations suggest\nthe loss of cortico-cortical and enhancement of cortico-thalamic fibre\nintegrity in IGE. We further suggest that impaired connectivity from cortical\nregions to the thalamic reticular nucleus offers a therapeutic target for\nselectively modifying the brain circuit for reversing the mechanisms leading to\nepileptogenesis.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 15:11:19 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 09:31:25 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Sinha", "Nishant", ""], ["Wang", "Yujiang", ""], ["Dauwels", "Justin", ""], ["Kaiser", "Marcus", ""], ["Thesen", "Thomas", ""], ["Forsyth", "Rob", ""], ["Taylor", "Peter Neal", ""]]}, {"id": "1807.04334", "submitter": "Vernon Lawhern", "authors": "Jonathan R. McDaniel, Stephen M. Gordon, Amelia J. Solon, Vernon J.\n  Lawhern", "title": "Analyzing P300 Distractors for Target Reconstruction", "comments": "4 pages, 3 figures", "journal-ref": "40th Annual International Conference of the IEEE Engineering in\n  Medicine and Biology Society (EMBC), Honolulu, HI, USA, 2018, pp. 2543-2546", "doi": "10.1109/EMBC.2018.8512854", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  P300-based brain-computer interfaces (BCIs) are often trained per-user and\nper-application space. Training such models requires ground truth knowledge of\ntarget and non-target stimulus categories during model training, which imparts\nbias into the model. Additionally, not all non-targets are created equal; some\nmay contain visual features that resemble targets or may otherwise be visually\nsalient. Current research has indicated that non-target distractors may elicit\nattenuated P300 responses based on the perceptual similarity of these\ndistractors to the target category. To minimize this bias, and enable a more\nnuanced analysis, we use a generalized BCI approach that is fit to neither user\nnor task. We do not seek to improve the overall accuracy of the BCI with our\ngeneralized approach; we instead demonstrate the utility of our approach for\nidentifying target-related image features. When combined with other intelligent\nagents, such as computer vision systems, the performance of the generalized\nmodel equals that of the user-specific models, without any user specific data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 20:07:27 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["McDaniel", "Jonathan R.", ""], ["Gordon", "Stephen M.", ""], ["Solon", "Amelia J.", ""], ["Lawhern", "Vernon J.", ""]]}, {"id": "1807.04520", "submitter": "Pierre Baudot", "authors": "Pierre Baudot", "title": "Elements of Consciousness and Cognition. Biology, Mathematic, Physics\n  and Panpsychism: an Information Topology Perspective", "comments": "73 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This review presents recent and older results on elementary quantitative and\nqualitative aspects of consciousness and cognition and tackles the question\n\"What is consciousness?\" conjointly from biological, neuroscience-cognitive,\nphysical and mathematical points of view. It proposes to unify various results\nand theories by means of information topology.\n  The first chapter presents the postulates and results on elementary\nperception at various organizational scales of the nervous system and proposes\nthe hypothesis of an electrodynamic intrinsic nature of consciousness which is\nsustained by an analogical code. It underlines the diversity of the learning\nmechanisms that sustain the dynamics of perception and consciousness, including\nadaptive and homeostatic processes on multiple scales.\n  The second chapter investigates the logical aspects of cognition and\nconsciousness and proposes an axiomatization based on measure and probability\ntheory. Topos and constructive logic are presented as providing an intrinsic\nprobabilistic logic, with the long-term aim of avoiding the paradoxical\ndecomposition induced by the Axiom of Choice. We sketch an elementary procedure\nallowing an expression of the information of a mathematical formula a la Godel.\nWe then present the formalism of information topology and propose that it\nprovides a preliminary basis for synthesizing the main models of cognition and\nconsciousness within a formal Gestalt theory. Information topology establishes\na characterization of information theory functions, allowing for a precise\nexpression of information structures and patterns. It provides a quantification\nof the structure of statistical interactions and their expression in terms of\nstatistical physics and machine learning. Notably, those topological methods\nallow conciliation of some of the main theories of consciousness.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 18:03:57 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 14:50:43 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Baudot", "Pierre", ""]]}, {"id": "1807.04691", "submitter": "Jennifer Stiso", "authors": "Jennifer Stiso and Danielle Bassett", "title": "Spatial Embedding Imposes Constraints on the Network Architectures of\n  Neural Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A fundamental understanding of the network architecture of the brain is\nnecessary for the further development of theories explicating circuit function.\nPerhaps as a derivative of its initial application to abstract informational\nsystems, network science provides many methods and summary statistics that\naddress the network's topological characteristics with little or no thought to\nits physical instantiation. Recent progress has capitalized on quantitative\ntools from network science to parsimoniously describe and predict neural\nactivity and connectivity across multiple spatial and temporal scales. Yet, for\nembedded systems, physical laws can directly constrain processes of network\ngrowth, development, and function, and an appreciation of those physical laws\nis therefore critical to an understanding of the system. Recent evidence\ndemonstrates that the constraints imposed by the physical shape of the brain,\nand by the mechanical forces at play in its development, have marked effects on\nthe observed network topology and function. Here, we review the rules imposed\nby space on the development of neural networks and show that these rules give\nrise to a specific set of complex topologies. We present evidence that these\nfundamental wiring rules affect the repertoire of neural dynamics that can\nemerge from the system, and thereby inform our understanding of network\ndysfunction in disease. We also discuss several computational tools,\nmathematical models, and algorithms that have proven useful in delineating the\neffects of spatial embedding on a given networked system and are important\nconsiderations for addressing future problems in network neuroscience. Finally,\nwe outline several open questions regarding the network architectures that\nsupport circuit function, the answers to which will require a thorough and\nhonest appraisal of the role of physical space in brain network anatomy and\nphysiology.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 15:57:20 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Stiso", "Jennifer", ""], ["Bassett", "Danielle", ""]]}, {"id": "1807.04745", "submitter": "Garren Gaut", "authors": "Garren Gaut, Xiangrui Li, Brandon Turner, William A. Cunningham,\n  Zhong-Lin Lu, Mark Steyvers", "title": "Predicting Task and Subject Differences with Functional Connectivity and\n  BOLD Variability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research has found that functional connectivity (FC) can accurately\npredict the identity of a subject performing a task and the type of task being\nperformed. We replicate these results using a large dataset collected at the\nOSU Center for Cognitive and Behavioral Brain Imaging. We also introduce a\nnovel perspective on task and subject identity prediction: BOLD Variability\n(BV). Conceptually, BV is a region-specific measure based on the variance\nwithin each brain region. BV is simple to compute, interpret, and visualize. We\nshow that both FC and BV are predictive of task and subject, even across\nscanning sessions separated by multiple years. Subject differences rather than\ntask differences account for the majority of changes in BV and FC. Similar to\nresults in FC, we show that BV is reduced during cognitive tasks relative to\nrest.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 17:53:57 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Gaut", "Garren", ""], ["Li", "Xiangrui", ""], ["Turner", "Brandon", ""], ["Cunningham", "William A.", ""], ["Lu", "Zhong-Lin", ""], ["Steyvers", "Mark", ""]]}, {"id": "1807.05097", "submitter": "Matthias Hennig", "authors": "Michael Deistler, Martino Sorbaro, Michael E. Rule and Matthias H.\n  Hennig", "title": "Local learning rules to attenuate forgetting in neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hebbian synaptic plasticity inevitably leads to interference and forgetting\nwhen different, overlapping memory patterns are sequentially stored in the same\nnetwork. Recent work on artificial neural networks shows that an\ninformation-geometric approach can be used to protect important weights to slow\ndown forgetting. This strategy however is biologically implausible as it\nrequires knowledge of the history of previously learned patterns. In this work,\nwe show that a purely local weight consolidation mechanism, based on estimating\nenergy landscape curvatures from locally available statistics, prevents pattern\ninterference. Exploring a local calculation of energy curvature in the\nsparse-coding limit, we demonstrate that curvature-aware learning rules reduce\nforgetting in the Hopfield network. We further show that this method connects\ninformation-geometric global learning rules based on the Fisher information to\nlocal spike-dependent rules accessible to biological neural networks. We\nconjecture that, if combined with other learning procedures, it could provide a\nbuilding-block for content-aware learning strategies that use only quantities\ncomputable in biological neural networks to attenuate pattern interference and\ncatastrophic forgetting. Additionally, this work clarifies how global\ninformation-geometric structure in a learning problem can be exposed in local\nmodel statistics, building a deeper theoretical connection between the\nstatistics of single units in a network, and the global structure of the\ncollective learning space.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 14:12:49 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Deistler", "Michael", ""], ["Sorbaro", "Martino", ""], ["Rule", "Michael E.", ""], ["Hennig", "Matthias H.", ""]]}, {"id": "1807.05142", "submitter": "Zahra Aminzare", "authors": "Zahra Aminzare and Philip Holmes", "title": "Heterogeneous inputs to central pattern generators can shape insect\n  gaits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our previous work, we studied an interconnected bursting neuron model for\ninsect locomotion, and its corresponding phase oscillator model, which at high\nspeed can generate stable tripod gaits with three legs off the ground\nsimultaneously in swing, and at low speed can generate stable tetrapod gaits\nwith two legs off the ground simultaneously in swing. However, at low speed\nseveral other stable locomotion patterns, that are not typically observed as\ninsect gaits, may coexist. In the present paper, by adding heterogeneous\nexternal input to each oscillator, we modify the bursting neuron model so that\nits corresponding phase oscillator model produces only one stable gait at each\nspeed, specifically: a unique stable tetrapod gait at low speed, a unique\nstable tripod gait at high speed, and a unique branch of stable transition\ngaits connecting them. This suggests that control signals originating in the\nbrain and central nervous system can modify gait patterns.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:38:19 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Aminzare", "Zahra", ""], ["Holmes", "Philip", ""]]}, {"id": "1807.05214", "submitter": "Zhixin Lu", "authors": "Zhixin Lu, Danielle S. Bassett", "title": "Invertible generalized synchronization: A putative mechanism for\n  implicit learning in biological and artificial neural systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regardless of the marked differences between biological and artificial neural\nsystems, one fundamental similarity is that they are essentially dynamical\nsystems that can learn to imitate other dynamical systems, without knowing\ntheir governing equations. The brain is able to learn the dynamic nature of the\nphysical world via experience; analogously, artificial neural systems can learn\nthe long-term behavior of complex dynamical systems from data. Yet, precisely\nhow this implicit learning occurs remains unknown. Here, we draw inspiration\nfrom human neuroscience and from reservoir computing to propose a\nfirst-principles framework explicating putative mechanisms of implicit\nlearning. Specifically, we show that an arbitrary dynamical system implicitly\nlearns other dynamical attractors by embedding them into its own phase space\nthrough invertible generalized synchronization. By sustaining the embedding\nthrough fine-tuned feedback loops, the arbitrary dynamical system can imitate\nthe attractor dynamics it has learned. To evaluate the mechanism's relevance,\nwe construct several distinct neural network models that adaptively learn and\nimitate multiple attractors. We observe and explain the emergence of 5 distinct\nphenomena reminiscent of cognitive functions: (i) imitating a dynamical system\npurely from learning the time series, (ii) learning multiple attractors by a\nsingle system, (iii) switching among the imitations of multiple attractors,\neither spontaneously or driven by external cues, (iv) filling-in missing\nvariables from incomplete observations of a learned dynamical system, and (v)\ndeciphering superimposed input from different dynamical systems. Collectively,\nour findings support the notion that artificial and biological neural networks\ncan learn the dynamic nature of their environment, and systems within their\nenvironment, through the mechanism of invertible generalized synchronization.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 00:50:52 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 14:41:45 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Lu", "Zhixin", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1807.05222", "submitter": "German I. Parisi", "authors": "German I. Parisi, Jonathan Tong, Pablo Barros, Brigitte R\\\"oder,\n  Stefan Wermter", "title": "Towards Modeling the Interaction of Spatial-Associative Neural Network\n  Representations for Multisensory Perception", "comments": "Workshop on Computational Models for Crossmodal Learning, IEEE\n  ICDL-EPIROB 2017, Lisbon, Portugal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our daily perceptual experience is driven by different neural mechanisms that\nyield multisensory interaction as the interplay between exogenous stimuli and\nendogenous expectations. While the interaction of multisensory cues according\nto their spatiotemporal properties and the formation of multisensory\nfeature-based representations have been widely studied, the interaction of\nspatial-associative neural representations has received considerably less\nattention. In this paper, we propose a neural network architecture that models\nthe interaction of spatial-associative representations to perform causal\ninference of audiovisual stimuli. We investigate the spatial alignment of\nexogenous audiovisual stimuli modulated by associative congruence. In the\nspatial layer, topographically arranged networks account for the interaction of\naudiovisual input in terms of population codes. In the associative layer,\ncongruent audiovisual representations are obtained via the experience-driven\ndevelopment of feature-based associations. Levels of congruency are obtained as\na by-product of the neurodynamics of self-organizing networks, where the amount\nof neural activation triggered by the input can be expressed via a nonlinear\ndistance function. Our novel proposal is that activity-driven levels of\ncongruency can be used as top-down modulatory projections to spatially\ndistributed representations of sensory input, e.g. semantically related\naudiovisual pairs will yield a higher level of integration than unrelated\npairs. Furthermore, levels of neural response in unimodal layers may be seen as\nsensory reliability for the dynamic weighting of crossmodal cues. We describe a\nseries of planned experiments to validate our model in the tasks of\nmultisensory interaction on the basis of semantic congruence and unimodal cue\nreliability.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 13:12:01 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Parisi", "German I.", ""], ["Tong", "Jonathan", ""], ["Barros", "Pablo", ""], ["R\u00f6der", "Brigitte", ""], ["Wermter", "Stefan", ""]]}, {"id": "1807.05616", "submitter": "Fabrizio De Vico Fallani", "authors": "Fabrizio De Vico Fallani and Danielle S. Bassett", "title": "Network neuroscience for optimizing brain-computer interfaces", "comments": null, "journal-ref": "Physics of Life Reviews 2019", "doi": "10.1016/j.plrev.2018.10.001", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human-machine interactions are being increasingly explored to create\nalternative ways of communication and to improve our daily life. Based on a\nclassification of the user's intention from the user's underlying neural\nactivity, brain-computer interfaces (BCIs) allow direct interactions with the\nexternal environment while bypassing the traditional effector of the\nmusculoskeletal system. Despite the enormous potential of BCIs, there are still\na number of challenges that limit their societal impact, ranging from the\ncorrect decoding of a human's thoughts, to the application of effective\nlearning strategies. Despite several important engineering advances, the basic\nneuroscience behind these challenges remains poorly explored. Indeed, BCIs\ninvolve complex dynamic changes related to neural plasticity at a diverse range\nof spatiotemporal scales. One promising antidote to this complexity lies in\nnetwork science, which provides a natural language in which to model the\norganizational principles of brain architecture and function as manifest in its\ninterconnectivity. Here, we briefly review the main limitations currently\naffecting BCIs, and we offer our perspective on how they can be addressed by\nmeans of network theoretic approaches. We posit that the emerging field of\nnetwork neuroscience will prove to be an effective tool to unlock human-machine\ninteractions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 21:36:10 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Fallani", "Fabrizio De Vico", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1807.05684", "submitter": "Ehtibar Dzhafarov", "authors": "Irina Basieva, V\\'ictor H. Cervantes, Ehtibar N. Dzhafarov, Andrei\n  Khrennikov", "title": "True Contextuality Beats Direct Influences in Human Decision Making", "comments": "Journal of Experimental Psychology: General 148, 1925-1937", "journal-ref": "Journal of Experimental Psychology: General 148, 1925-1937", "doi": "10.1037/xge0000585", "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In quantum physics there are well-known situations when measurements of the\nsame property in different contexts (under different conditions) have the same\nprobability distribution, but cannot be represented by one and the same random\nvariable. Such systems of random variables are called contextual. More\ngenerally, true contextuality is observed when different contexts force\nmeasurements of the same property (in psychology, responses to the same\nquestion) to be more dissimilar random variables than warranted by the\ndifference of their distributions. The difference in distributions is itself a\nform of context-dependence, but of another nature: it is attributable to direct\ncausal influences exerted by contexts upon the random variables. The\nContextuality-by-Default (CbD) theory allows one to separate true contextuality\nfrom direct influences in the overall context-dependence. The CbD analysis of\nnumerous previous attempts to demonstrate contextuality in human judgments\nshows that all context-dependence in them can be accounted for by direct\ninfluences, with no true contextuality present. However, contextual systems in\nhuman behavior can be found. In this paper we present a series of crowdsourcing\nexperiments that exhibit true contextuality in simple decision making.}{The\ndesign of these experiments is an elaboration of one introduced in the \"Snow\nQueen\" experiment (Decision 5, 193-204, 2018), where contextuality was for the\nfirst time demonstrated unequivocally.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 05:31:04 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 23:05:06 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2019 14:50:14 GMT"}, {"version": "v4", "created": "Sat, 30 May 2020 16:47:08 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Basieva", "Irina", ""], ["Cervantes", "V\u00edctor H.", ""], ["Dzhafarov", "Ehtibar N.", ""], ["Khrennikov", "Andrei", ""]]}, {"id": "1807.05740", "submitter": "Ivan Lazarevich", "authors": "Ivan Lazarevich and Sergey Stasenko and Maia Rozhnova and Evgeniya\n  Pankratova and Alexander Dityatev and Victor Kazantsev", "title": "Dynamics of the brain extracellular matrix governed by interactions with\n  neural cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal and glial cells release diverse proteoglycans and glycoproteins,\nwhich aggregate in the extracellular space and form the extracellular matrix\n(ECM) that may in turn regulate major cellular functions. Brain cells also\nrelease extracellular proteases that may degrade the ECM, and both synthesis\nand degradation of ECM are activity-dependent. In this study we introduce a\nmathematical model describing population dynamics of neurons interacting with\nECM molecules over extended timescales. It is demonstrated that depending on\nthe prevalent biophysical mechanism of ECM-neuronal interactions, different\ndynamical regimes of ECM activity can be observed, including bistable states\nwith stable stationary levels of ECM molecule concentration, spontaneous ECM\noscillations, and coexistence of ECM oscillations and a stationary state,\nallowing dynamical switches between activity regimes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 09:06:42 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Lazarevich", "Ivan", ""], ["Stasenko", "Sergey", ""], ["Rozhnova", "Maia", ""], ["Pankratova", "Evgeniya", ""], ["Dityatev", "Alexander", ""], ["Kazantsev", "Victor", ""]]}, {"id": "1807.06203", "submitter": "Ding Zhou", "authors": "E. Kelly Buchanan, Ian Kinsella, Ding Zhou, Rong Zhu, Pengcheng Zhou,\n  Felipe Gerhard, John Ferrante, Ying Ma, Sharon Kim, Mohammed Shaik, Yajie\n  Liang, Rongwen Lu, Jacob Reimer, Paul Fahey, Taliah Muhammad, Graham Dempsey,\n  Elizabeth Hillman, Na Ji, Andreas Tolias, Liam Paninski", "title": "Penalized matrix decomposition for denoising, compression, and improved\n  demixing of functional imaging data", "comments": "36 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Calcium imaging has revolutionized systems neuroscience, providing the\nability to image large neural populations with single-cell resolution. The\nresulting datasets are quite large, which has presented a barrier to routine\nopen sharing of this data, slowing progress in reproducible research. State of\nthe art methods for analyzing this data are based on non-negative matrix\nfactorization (NMF); these approaches solve a non-convex optimization problem,\nand are effective when good initializations are available, but can break down\nin low-SNR settings where common initialization approaches fail. Here we\nintroduce an approach to compressing and denoising functional imaging data. The\nmethod is based on a spatially-localized penalized matrix decomposition (PMD)\nof the data to separate (low-dimensional) signal from (temporally-uncorrelated)\nnoise. This approach can be applied in parallel on local spatial patches and is\ntherefore highly scalable, does not impose non-negativity constraints or\nrequire stringent identifiability assumptions (leading to significantly more\nrobust results compared to NMF), and estimates all parameters directly from the\ndata, so no hand-tuning is required. We have applied the method to a wide range\nof functional imaging data (including one-photon, two-photon, three-photon,\nwidefield, somatic, axonal, dendritic, calcium, and voltage imaging datasets):\nin all cases, we observe ~2-4x increases in SNR and compression rates of\n20-300x with minimal visible loss of signal, with no adjustment of\nhyperparameters; this in turn facilitates the process of demixing the observed\nactivity into contributions from individual neurons. We focus on two\nchallenging applications: dendritic calcium imaging data and voltage imaging\ndata in the context of optogenetic stimulation. In both cases, we show that our\nnew approach leads to faster and much more robust extraction of activity from\nthe data.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 04:00:07 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Buchanan", "E. Kelly", ""], ["Kinsella", "Ian", ""], ["Zhou", "Ding", ""], ["Zhu", "Rong", ""], ["Zhou", "Pengcheng", ""], ["Gerhard", "Felipe", ""], ["Ferrante", "John", ""], ["Ma", "Ying", ""], ["Kim", "Sharon", ""], ["Shaik", "Mohammed", ""], ["Liang", "Yajie", ""], ["Lu", "Rongwen", ""], ["Reimer", "Jacob", ""], ["Fahey", "Paul", ""], ["Muhammad", "Taliah", ""], ["Dempsey", "Graham", ""], ["Hillman", "Elizabeth", ""], ["Ji", "Na", ""], ["Tolias", "Andreas", ""], ["Paninski", "Liam", ""]]}, {"id": "1807.06398", "submitter": "Mahmoud Hassan", "authors": "J. Rizkallah, P. Benquet, A. Kabbara, O. Dufor, F. Wendling, M. Hassan", "title": "Dynamic reshaping of functional brain networks during visual object\n  recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging evidence shows that the modular organization of the human brain\nallows for better and efficient cognitive performance. Many of these cognitive\nfunctions are very fast and occur in subsecond time scale such as the visual\nobject recognition. Here, we investigate brain network modularity while\ncontrolling stimuli meaningfulness and measuring participant reaction time. We\nparticularly raised two questions: i) does the dynamic brain network modularity\nchange during the recognition of meaningful and meaningless visual images? And\nii) is there a correlation between network modularity and the reaction time of\nparticipants? To tackle these issues, we collected dense electroencephalography\n(EEG, 256 channels) data from 20 healthy human subjects performing a cognitive\ntask consisting of naming meaningful (tools, animals) and meaningless\n(scrambled) images. Functional brain networks in both categories were estimated\nat subsecond time scale using the EEG source connectivity method. By using\nmultislice modularity algorithms, we tracked the reconfiguration of functional\nnetworks during the recognition of both meaningful and meaningless images.\nResults showed a difference in the module characteristics of both conditions in\nterm of integration (interactions between modules) and occurrence (probability\non average of any two brain regions to fall in the same module during the\ntask). Integration and occurrence were greater for meaningless than for\nmeaningful images. Our findings revealed also that the occurrence within the\nright frontal regions and the left occipito-temporal can help to predict the\nability of the brain to rapidly recognize and name visual stimuli. We speculate\nthat these observations are applicable not only to other fast cognitive\nfunctions but also to detect fast disconnections that can occur in some brain\ndisorders.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 13:06:46 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 11:19:53 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Rizkallah", "J.", ""], ["Benquet", "P.", ""], ["Kabbara", "A.", ""], ["Dufor", "O.", ""], ["Wendling", "F.", ""], ["Hassan", "M.", ""]]}, {"id": "1807.07590", "submitter": "David Piech", "authors": "David K. Piech, Benjamin C. Johnson, Konlin Shen, M. Meraj Ghanbari,\n  Ka Yiu Li, Ryan M. Neely, Joshua E. Kay, Jose M. Carmena, Michel M. Maharbiz,\n  Rikky Muller", "title": "StimDust: A mm-scale implantable wireless precision neural stimulator\n  with ultrasonic power and communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural stimulation is a powerful technique for modulating physiological\nfunctions and for writing information into the nervous system as part of\nbrain-machine interfaces. Current clinically approved neural stimulators\nrequire batteries and are many cubic centimetres in size -- typically much\nlarger than their intended targets. We present a complete wireless neural\nstimulation system consisting of a 1.7 mm3 wireless, batteryless, leadless\nimplantable stimulator (the \"mote\"), an ultrasonic wireless link for power and\nbi-directional communication, and a hand-held external transceiver. The mote\nconsists of a piezoceramic transducer, an energy storage capacitor, and a\nstimulator integrated circuit (IC). The IC harvests ultrasonic power with high\nefficiency, decodes stimulation parameter downlink data, and generates\ncurrent-controlled stimulation pulses. Stimulation parameters are time-encoded\non the fly through the wireless link rather than being programmed and stored on\nthe mote, reducing power consumption and on-chip memory requirements and\nenabling complex stimulation protocols with high-temporal resolution and\nlow-latency feedback for use in closed-loop stimulation. Uplink data indicates\nwhether the mote is currently stimulating; it is encoded by the mote via\nbackscatter modulation and is demodulated at the external transceiver. We show\nthat the mote operates at an acoustic intensity that is 7.8% of the FDA limit\nfor diagnostic ultrasound and characterize the acoustic wireless link's\nrobustness to expected real-world misalignment. We demonstrate the in vivo\nperformance of the system with motes acutely implanted with a cuff on the\nsciatic nerve of anesthetized rats and show highly repeatable stimulation\nacross a wide range of physiological responses.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 18:11:16 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 19:02:33 GMT"}, {"version": "v3", "created": "Wed, 27 Feb 2019 20:09:02 GMT"}, {"version": "v4", "created": "Tue, 16 Jul 2019 04:59:49 GMT"}, {"version": "v5", "created": "Sat, 15 Feb 2020 03:21:43 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Piech", "David K.", ""], ["Johnson", "Benjamin C.", ""], ["Shen", "Konlin", ""], ["Ghanbari", "M. Meraj", ""], ["Li", "Ka Yiu", ""], ["Neely", "Ryan M.", ""], ["Kay", "Joshua E.", ""], ["Carmena", "Jose M.", ""], ["Maharbiz", "Michel M.", ""], ["Muller", "Rikky", ""]]}, {"id": "1807.07632", "submitter": "Ronald Fox", "authors": "Ronald F. Fox", "title": "Critique of the Fox-Lu model for Hodgkin-Huxley fluctuations in neuron\n  ion channels", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a well known result that every FP equation has an antecedent Langevin\nequation LE Fox and Lu proposed such a description for ion channels in 1994.\nTheir contraction followed the works of van Kampen and of T. Kurtz. The\ncontraction produces a diffusion term with a state dependent diffusion matrix,\nD, that arises from the coupling matrix, S, in the LE. This S connected the\nnoise terms to the channel subunit variables in the LE. Fox and Lu and many\nothers later on observed that SS = D. Since D was determined by the contraction\nof the MC equations into the FP equation, this left the problem of determining\nthe square root matrix, S, for every time step of the simulation. Since this is\ntime consuming, Fox and Lu introduced simplified models not requiring the\nsquare root of a matrix. Subsequently, numerous studies were published that\nshowed the several shortcomings of these simplified models. In 2011, Goldwyn et\nal. [6] rediscovered the overlooked original matrix dependent approach in the\nFox-Lu 1994 paper. They showed that it produced results in very good agreement\nwith the MC results. In 1991, Fox and Keizer [7] wrote a paper on an unrelated\ntopic that utilized the work of van Kampen and of Kurtz. In that work the\nconnection between D and S is SST = D. ST is the adjoint (transpose) of S. D\nremains a positive definite symmetric matrix but S need not be. Fox has\nreproduced the 2012 results of Orio and Soudry for potassium channels and has\nalso found in closed form the solution for the more complicated sodium\nchannels. The square root problem generally must be done numerically, but the\nCholesky is always doable in closed form. Thereby the S matrix for sodium is\ngiven explicitly for the first time in this paper\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 00:18:39 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 12:10:58 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Fox", "Ronald F.", ""]]}, {"id": "1807.07669", "submitter": "\\'Eric Merle", "authors": "\\'Eric Merle", "title": "Modelling of consciousness and interpretation of quantum mechanics", "comments": "117 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I start from the fundamental principles of non-relativistic quantum\nmechanics, without probability, and interpret them using the notion of\ncoexistence: a quantum state can be read, not uniquely, as a coexistence of\nother quantum states, which are pairwise orthogonal. In this formalism, I prove\nthat a conscious observer is necessarily a physical object that can memorize\nlocal events by setting one of its parts in an exactly specified constant\nquantum state (hypotheses H1, H2 and H3). Then I define the probability of a\nfuture event as the proportion of initial observers, all identical, who will\nactually experience that event. It then becomes possible to establish the usual\nresults of quantum mechanics. Furthermore, I detail the link between\nprobabilities and relative frequencies. Additionally, I study the biological\nfeasibility of this modelling of observer's mind.\n  The second part of this paper completes the neuronal description of the mind\nfunctions, based on current neuroscientific knowledge. It provides a model that\nis compatible with the assumptions of the first part and consistent with our\ndaily conscious experience. In particular, it develops a model of\nself-consciousness based on an explicit use of the random component of neuron\nbehaviour; according to the first part, that random is in fact the coexistence\nof a multiplicity of possibilities. So, when the mind measures the random part\nof certain neurons in the brain, he goes himself within each of these\npossibilities. The mind has a decision-making component that is active in this\nsituation, appearing then as the cause of the choice of this possibility among\nall the others. This models the self-consciousness which then ensures the unity\nof our conscious experience by equating this experience with ``what the ego is\nconscious about''. The conclusion details the points that remain to be\ndeveloped.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 00:09:41 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Merle", "\u00c9ric", ""]]}, {"id": "1807.07687", "submitter": "Ursula Tooley", "authors": "Ursula A. Tooley, Allyson P. Mackey, Rastko Ciric, Kosha Ruparel,\n  Tyler M. Moore, Ruben C. Gur, Raquel E. Gur, Theodore D. Satterthwaite,\n  Danielle S. Bassett", "title": "Influence of Neighborhood SES on Functional Brain Network Development", "comments": "9 pages, 6 figures. Cerebral Cortex (2019)", "journal-ref": null, "doi": "10.1093/cercor/bhz066", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Higher socioeconomic status (SES) in childhood is associated with increased\ncognitive abilities, higher academic achievement, and decreased incidence of\nmental illness later in development. Accumulating evidence suggests that these\neffects may be due to changes in brain development induced by environmental\nfactors. While prior work has mapped the associations between neighborhood SES\nand brain structure, little is known about the relationship between SES and\nintrinsic neural dynamics. Here, we capitalize upon a large community-based\nsample (Philadelphia Neurodevelopmental Cohort, ages 8-22 years, n=1012) to\nexamine developmental changes in functional brain network topology as estimated\nfrom resting state functional magnetic resonance imaging data. We\nquantitatively characterize this topology using a local measure of network\nsegregation known as the clustering coefficient, and find that it accounts for\na greater degree of SES-associated variance than meso-scale segregation\ncaptured by modularity. While whole-brain clustering increased with age,\nhigh-SES youth displayed faster increases in clustering than low-SES youth, and\nthis effect was most pronounced for regions in the limbic, somatomotor, and\nventral attention systems. The effect of SES on developmental increases in\nclustering was strongest for connections of intermediate physical length,\nconsistent with faster decreases in local connectivity in these regions in\nlow-SES youth, and tracked changes in BOLD signal complexity in the form of\nregional homogeneity. Our findings suggest that neighborhood SES may\nfundamentally alter intrinsic patterns of inter-regional interactions in the\nhuman brain in a manner that is consistent with greater segregation of\ninformation processing in late childhood and adolescence.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 01:32:22 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 01:25:11 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Tooley", "Ursula A.", ""], ["Mackey", "Allyson P.", ""], ["Ciric", "Rastko", ""], ["Ruparel", "Kosha", ""], ["Moore", "Tyler M.", ""], ["Gur", "Ruben C.", ""], ["Gur", "Raquel E.", ""], ["Satterthwaite", "Theodore D.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1807.07866", "submitter": "Riccardo Gallotti", "authors": "Riccardo Gallotti and Jelena Grujic", "title": "A quantitative description of the transition between intuitive altruism\n  and rational deliberation in iterated Prisoner's Dilemma experiments", "comments": null, "journal-ref": "Sci Rep 9, 17046 (2019)", "doi": "10.1038/s41598-019-52359-3", "report-no": null, "categories": "physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is intuitive: pro-social or anti-social behaviour? To answer this\nfundamental question, recent studies analyse decision times in game theory\nexperiments under the assumption that intuitive decisions are fast and that\ndeliberation is slow. These analyses keep track of the average time taken to\nmake decisions under different conditions. Lacking any knowledge of the\nunderlying dynamics, such simplistic approach might however lead to erroneous\ninterpretations. Here we model the cognitive basis of strategic cooperative\ndecision making using the Drift Diffusion Model to discern between deliberation\nand intuition and describe the evolution of the decision making in iterated\nPrisoner's Dilemma experiments. We find that, although initially people's\nintuitive decision is to cooperate, rational deliberation quickly becomes\ndominant over an initial intuitive bias towards cooperation, which is fostered\nby positive interactions as much as frustrated by a negative one. However, this\ninitial pro-social tendency is resilient, as after a pause it resets to the\nsame initial value. These results illustrate the new insight that can be\nachieved thanks to a quantitative modelling of human behavior.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 14:33:04 GMT"}, {"version": "v2", "created": "Sat, 11 Apr 2020 16:09:23 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Gallotti", "Riccardo", ""], ["Grujic", "Jelena", ""]]}, {"id": "1807.08018", "submitter": "Houman Safaai", "authors": "Houman Safaai, Arno Onken, Christopher D. Harvey, Stefano Panzeri", "title": "Information estimation using nonparametric copulas", "comments": "17 pages, 13 figures", "journal-ref": "Phys. Rev. E 98, 053302 (2018)", "doi": "10.1103/PhysRevE.98.053302", "report-no": null, "categories": "stat.ME cs.IT math.IT q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimation of mutual information between random variables has become crucial\nin a range of fields, from physics to neuroscience to finance. Estimating\ninformation accurately over a wide range of conditions relies on the\ndevelopment of flexible methods to describe statistical dependencies among\nvariables, without imposing potentially invalid assumptions on the data. Such\nmethods are needed in cases that lack prior knowledge of their statistical\nproperties and that have limited sample numbers. Here we propose a powerful and\ngenerally applicable information estimator based on non-parametric copulas.\nThis estimator, called the non-parametric copula-based estimator (NPC), is\ntailored to take into account detailed stochastic relationships in the data\nindependently of the data's marginal distributions. The NPC estimator can be\nused both for continuous and discrete numerical variables and thus provides a\nsingle framework for the mutual information estimation of both continuous and\ndiscrete data. By extensive validation on artificial samples drawn from various\nstatistical distributions, we found that the NPC estimator compares well\nagainst commonly used alternatives. Unlike methods not based on copulas, it\nallows an estimation of information that is robust to changes of the details of\nthe marginal distributions. Unlike parametric copula methods, it remains\naccurate regardless of the precise form of the interactions between the\nvariables. In addition, the NPC estimator had accurate information estimates\neven at low sample numbers, in comparison to alternative estimators. The NPC\nestimator therefore provides a good balance between general applicability to\narbitrarily shaped statistical dependencies in the data and shows accurate and\nrobust performance when working with small sample sizes.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 20:17:59 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 20:56:28 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Safaai", "Houman", ""], ["Onken", "Arno", ""], ["Harvey", "Christopher D.", ""], ["Panzeri", "Stefano", ""]]}, {"id": "1807.08129", "submitter": "Marinho Lopes", "authors": "Marinho A. Lopes and Alexander V. Goltsev", "title": "Distinct dynamical behavior in Erd\\H{o}s-R\\'enyi networks, regular\n  random networks, ring lattices, and all-to-all neuronal networks", "comments": "9 pages, 4 figures", "journal-ref": "Phys. Rev. E 99, 022303 (2019)", "doi": "10.1103/PhysRevE.99.022303", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal network dynamics depends on network structure. In this paper we\nstudy how network topology underpins the emergence of different dynamical\nbehaviors in neuronal networks. In particular, we consider neuronal network\ndynamics on Erd\\H{o}s-R\\'enyi (ER) networks, regular random (RR) networks, ring\nlattices, and all-to-all networks. We solve analytically a neuronal network\nmodel with stochastic binary-state neurons in all the network topologies,\nexcept ring lattices. Given that apart from network structure, all four models\nare equivalent, this allows us to understand the role of network structure in\nneuronal network dynamics. Whilst ER and RR networks are characterized by\nsimilar phase diagrams, we find strikingly different phase diagrams in the\nall-to-all network. Neuronal network dynamics is not only different within\ncertain parameter ranges, but it also undergoes different bifurcations (with a\nricher repertoire of bifurcations in ER and RR compared to all-to-all\nnetworks). This suggests that local heterogeneity in the ratio between\nexcitation and inhibition plays a crucial role on emergent dynamics.\nFurthermore, we also observe one subtle discrepancy between ER and RR networks,\nnamely ER networks undergo a neuronal activity jump at lower noise levels\ncompared to RR networks, presumably due to the degree heterogeneity in ER\nnetworks that is absent in RR networks. Finally, a comparison between network\noscillations in RR networks and ring lattices shows the importance of\nsmall-world properties in sustaining stable network oscillations.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 11:22:40 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 13:26:14 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Lopes", "Marinho A.", ""], ["Goltsev", "Alexander V.", ""]]}, {"id": "1807.08220", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Creativity: Linchpin in the Quest for a Viable Theory of Cultural\n  Evolution", "comments": "13 pages; 2 tables; 1 figure; Accepted for publication in Current\n  Opinion in Behavioral Sciences", "journal-ref": "Current Opinion in Behavioral Sciences, 27, 77-83 (2019)", "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines the implications of neural-level accounts of insight, and\nmodels of the conceptual interactions that underlie creativity, for a theory of\ncultural evolution. Since elements of human culture exhibit cumulative,\nadaptive, open-ended change, it seems reasonable to view culture as an\nevolutionary process, one fueled by creativity. Associative memory models of\ncreativity and mathematical models of how concepts combine and transform\nthrough interaction with a context, support a view of creativity that is\nincompatible with a Darwinian (selectionist) framework for cultural evolution,\nbut compatible with a non-Darwinian (Self-Other Reorganization) framework. A\ntheory of cultural evolution in which creativity is centre stage could provide\nthe kind of integrative framework for the behavioral sciences that Darwin\nprovided for the life sciences.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2018 01:14:57 GMT"}, {"version": "v2", "created": "Tue, 18 Sep 2018 03:25:47 GMT"}, {"version": "v3", "created": "Wed, 13 Mar 2019 21:16:43 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1807.08476", "submitter": "R T Pramod", "authors": "R.T. Pramod, Harish Katti and S.P. Arun", "title": "Human peripheral blur is optimal for object recognition", "comments": "24 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our vision is sharpest at the center of our gaze and becomes progressively\nblurry into the periphery. It is widely believed that this high foveal\nresolution evolved at the expense of peripheral acuity. But what if this\nsampling scheme is actually optimal for object recognition? To test this\nhypothesis, we trained deep neural networks on 'foveated' images with high\nresolution near objects and increasingly sparse sampling into the periphery.\nNeural networks trained using a blur profile matching the human eye yielded the\nbest performance compared to shallower and steeper blur profiles. Even in\nhumans, categorization accuracy deteriorated only for steeper blur profiles.\nThus, our blurry peripheral vision may have evolved to optimize object\nrecognition rather than merely due to wiring constraints.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 08:25:35 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 02:55:22 GMT"}, {"version": "v3", "created": "Wed, 13 May 2020 21:06:08 GMT"}], "update_date": "2020-05-15", "authors_parsed": [["Pramod", "R. T.", ""], ["Katti", "Harish", ""], ["Arun", "S. P.", ""]]}, {"id": "1807.08686", "submitter": "Anita Mehta", "authors": "Anita Mehta", "title": "Storing and retrieving long-term memories: cooperation and competition\n  in synaptic dynamics", "comments": "34 pages, 7 figures", "journal-ref": "Advances in Physics: X, 3:1, 755-789, (2018)", "doi": "10.1080/23746149.2018.1480415", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We first review traditional approaches to memory storage and formation,\ndrawing on the literature of quantitative neuroscience as well as statistical\nphysics. These have generally focused on the fast dynamics of neurons; however,\nthere is now an increasing emphasis on the slow dynamics of synapses, whose\nweight changes are held to be responsible for memory storage. An important\nfirst step in this direction was taken in the context of Fusi's cascade model,\nwhere complex synaptic architectures were invoked, in particular, to store\nlong-term memories. No explicit synaptic dynamics were, however, invoked in\nthat work. These were recently incorporated theoretically using the techniques\nused in agent-based modelling, and subsequently, models of competing and\ncooperating synapses were formulated. It was found that the key to the storage\nof long-term memories lay in the competitive dynamics of synapses. In this\nreview, we focus on models of synaptic competition and cooperation, and look at\nthe outstanding challenges that remain.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 15:54:33 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Mehta", "Anita", ""]]}, {"id": "1807.08900", "submitter": "Hideaki Shimazaki", "authors": "Jimmy Gaudreault and Hideaki Shimazaki", "title": "State-space analysis of an Ising model reveals contributions of pairwise\n  interactions to sparseness, fluctuation, and stimulus coding of monkey V1\n  neurons", "comments": "10 pages, 4 figures, ICANN2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we analyzed the activity of monkey V1 neurons responding to\ngrating stimuli of different orientations using inference methods for a\ntime-dependent Ising model. The method provides optimal estimation of\ntime-dependent neural interactions with credible intervals according to the\nsequential Bayes estimation algorithm. Furthermore, it allows us to trace\ndynamics of macroscopic network properties such as entropy, sparseness, and\nfluctuation. Here we report that, in all examined stimulus conditions, pairwise\ninteractions contribute to increasing sparseness and fluctuation. We then\ndemonstrate that the orientation of the grating stimulus is in part encoded in\nthe pairwise interactions of the neural populations. These results demonstrate\nthe utility of the state-space Ising model in assessing contributions of neural\ninteractions during stimulus processing.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 04:12:58 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Gaudreault", "Jimmy", ""], ["Shimazaki", "Hideaki", ""]]}, {"id": "1807.08952", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison, Guillaume Hennequin, Mate Lengyel", "title": "Sampling-based probabilistic inference emerges from learning in neural\n  circuits with a cost on reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural responses in the cortex change over time both systematically, due to\nongoing plasticity and learning, and seemingly randomly, due to various sources\nof noise and variability. Most previous work considered each of these\nprocesses, learning and variability, in isolation -- here we study neural\nnetworks exhibiting both and show that their interaction leads to the emergence\nof powerful computational properties. We trained neural networks on classical\nunsupervised learning tasks, in which the objective was to represent their\ninputs in an efficient, easily decodable form, with an additional cost for\nneural reliability which we derived from basic biophysical considerations. This\ncost on reliability introduced a tradeoff between energetically cheap but\ninaccurate representations and energetically costly but accurate ones. Despite\nthe learning tasks being non-probabilistic, the networks solved this tradeoff\nby developing a probabilistic representation: neural variability represented\nsamples from statistically appropriate posterior distributions that would\nresult from performing probabilistic inference over their inputs. We provide an\nanalytical understanding of this result by revealing a connection between the\ncost of reliability, and the objective for a state-of-the-art Bayesian\ninference strategy: variational autoencoders. We show that the same cost leads\nto the emergence of increasingly accurate probabilistic representations as\nnetworks become more complex, from single-layer feed-forward, through\nmulti-layer feed-forward, to recurrent architectures. Our results provide\ninsights into why neural responses in sensory areas show signatures of\nsampling-based probabilistic representations, and may inform future deep\nlearning algorithms and their implementation in stochastic low-precision\ncomputing systems.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 08:22:11 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Aitchison", "Laurence", ""], ["Hennequin", "Guillaume", ""], ["Lengyel", "Mate", ""]]}, {"id": "1807.09194", "submitter": "Bernat Corominas-Murtra BCM", "authors": "Bernat Corominas-Murtra, Mart\\'i S\\`anchez Fibla, Sergi Valverde and\n  Ricard Sol\\'e", "title": "Chromatic transitions in the emergence of syntax networks", "comments": "8 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of syntax during childhood is a remarkable example of how\ncomplex correlations unfold in nonlinear ways through development. In\nparticular, rapid transitions seem to occur as children reach the age of two,\nwhich seems to separate a two-word, tree-like network of syntactic relations\namong words from a scale-free graphs associated to the adult, complex grammar.\nHere we explore the evolution of syntax networks through language acquisition\nusing the {\\em chromatic number}, which captures the transition and provides a\nnatural link to standard theories on syntactic structures. The data analysis is\ncompared to a null model of network growth dynamics which is shown to display\nnontrivial and sensible differences. In a more general level, we observe that\nthe chromatic classes define independent regions of the graph, and thus, can be\ninterpreted as the footprints of incompatibility relations, somewhat as opposed\nto modularity considerations.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 15:47:11 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Corominas-Murtra", "Bernat", ""], ["Fibla", "Mart\u00ed S\u00e0nchez", ""], ["Valverde", "Sergi", ""], ["Sol\u00e9", "Ricard", ""]]}, {"id": "1807.09505", "submitter": "Paola Sessa", "authors": "Paola Sessa, Arianna Schiano Lomoriello and Roy Luria", "title": "Neural measures of the causal role of observers' facial mimicry on\n  visual working memory for facial expressions", "comments": "37 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation models of facial expressions propose that sensorimotor regions may\nincrease the clarity of facial expressions representations in extrastriate\nareas. We monitored the event-related potential marker of visual working memory\n(VWM) representations, namely the sustained posterior contralateral negativity\n(SPCN), also termed contralateral delay activity (CDA), while participants\nperformed a change detection task including to-be-memorized faces with\ndifferent intensities of anger. In one condition participants could freely use\ntheir facial mimicry during the encoding/VWM maintenance of the faces, while in\na different condition, participants had their facial mimicry blocked by a gel.\nNotably, SPCN amplitude was reduced for faces in the blocked mimicry condition\nwhen compared to the free mimicry condition. This modulation interacted with\nthe empathy levels of participants such that only participants with medium-high\nempathy scores showed such reduction of the SPCN amplitude when their mimicry\nwas blocked. The SPCN amplitude was larger for full expressions when compared\nto neutral and subtle expressions, while subtle expressions elicited lower SPCN\namplitudes than neutral faces. These findings provide evidence of a functional\nlink between mimicry and VWM for faces, and further shed light on how this\nmemory system may receive feedbacks from sensorimotor regions during the\nprocessing of facial expressions.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 09:50:56 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 14:23:59 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Sessa", "Paola", ""], ["Lomoriello", "Arianna Schiano", ""], ["Luria", "Roy", ""]]}, {"id": "1807.10048", "submitter": "R. Ozgur Doruk", "authors": "Resat Ozgur Doruk", "title": "Fitting a recurrent dynamical neural network to neural spiking data:\n  Tackling with the sigmoidal gain function issues", "comments": "Submitted to Journal of Statistical Mechanics: Theory and\n  Experimentations", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a continuation of a recent study on the modeling of the information\ncoding in sensory system in the brain. The data from a sensory neurons are\navailable as discrete spike timings with no amplitude information. In the\nsimulations, these are generated from a data generator model which has certain\ndifferences from the model being estimated. The model under consideration is\nsimpler than the one used as a data generator as it has no sigmoidal gain\nfunction parameters. This choice is based on a suggestion from a recent study\nwhich states that inclusion of gain functions to the estimation algorithm\nincreases issues such as parameter confounding which leads to performance\ndegradation issues like increased or unpredictable variance changes with\ndifferent stimuli configurations. To resolve this issue we consider a more\ngeneric model that has no sigmoidal gain functions to be estimated. Like that\nof the first research, we applied a Fourier series stimulus to both data\ngenerator and the estimated network. In order to test the performance of the\nproposed scheme, we have repeated the simulations with different sample sizes,\nstimulus component counts, amplitude and base frequencies. Mean values of\nestimation are presented as tables and the statistical analysis results are\npresented in graphical forms. In addition, since we do not have any true\nparameter data (for the estimated model) we compare the firing rate responses\nof both data generator and estimated models to different stimuli. It appeared\nthat the responses of both models are almost the same.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 10:09:20 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Doruk", "Resat Ozgur", ""]]}, {"id": "1807.10137", "submitter": "Oleg  Gradov V.", "authors": "O.V. Gradov, P.A. Nasirov, A.A. Scrynnic, A.G. Jablokov", "title": "A simple device for microinjections, manipulations and measurements\n  using an electromorphological chip under microinterferometric control of the\n  interface and membrane processes at the thickness range of 5-1000 nm at\n  different angles", "comments": "in Russian", "journal-ref": "Morphologia, Vol. 11, Issue 4, pp. 7-17 (2017)", "doi": "10.26641/1997-9665.2017.4.7-17", "report-no": null, "categories": "q-bio.SC cond-mat.soft q-bio.CB q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micromanipulations, perfusions and measurements performed using glass\nmicroelectrodes filled with an electrolyte is a conventional technique for\nexperimental morphological and membrane electrophysiological studies at a\nsingle cell and membrane surface level. The typical (effective) diameter of the\nend of the glass microelectrode is from 500 up to less than 100 nm, which\nprevents one from observing it using a standard optical microscope in\naccordance with the optical resolution criteria, since the diameter less than\n500 nm is indistinguishable within the interference zone. Microprocessor\nprogramming of the puller (microforge) that provides pulling and tearing allows\nto obtain in certain regimes the adjusted diameter and shape of the\nmicropipette tip, although this result is not fully controlled due to the above\nlimitations. In this connection it is necessary to design the control devices\nfor the micropipette tips both at the preparation and operation stages\n(intracellular or extracellular insertion). This method also should provide\nvisualization of the processes occurring upon interaction of the microelectrode\ntip with the cell in real time, depending on the electrode type and state,\nwhich allows to level the artifacts arising with the systematic error frequency\nfrom the uncontrolled operation of the micropipette tip after different ways of\nthe microelectrode filling with the electrolyte. We propose an installation\nscheme that solves the above problems by means of introducing an\ninterferometric device for microscopic control of the microelectrode and\nmicromanipulator or microperfusor, for the first time for a given type of\noptical instruments combined with the interferometric optical scheme.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 12:35:57 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Gradov", "O. V.", ""], ["Nasirov", "P. A.", ""], ["Scrynnic", "A. A.", ""], ["Jablokov", "A. G.", ""]]}, {"id": "1807.10269", "submitter": "Shennan Weiss", "authors": "Zachary J. Waldman, Liliana Camarillo-Rodriguez, Inna Chervenova,\n  Brent Berry, Shoichi Shimamoto, Bahareh Elahian, Michal Kucewicz, Chaitanya\n  Ganne, Xiao-Song He, Leon A. Davis, Joel Stein, Sandhitsu Das, Richard\n  Gorniak, Ashwini D. Sharan, Robert Gross, Cory S. Inman, Bradley C. Lega,\n  Kareem Zaghloul, Barbara C. Jobst, Katheryn A. Davis, Paul Wanda, Mehraneh\n  Khadjevand, Joseph Tracy, Daniel S. Rizzuto, Gregory Worrell, Michael\n  Sperling, Shennan A. Weiss", "title": "Ripple oscillations in the left temporal neocortex are associated with\n  impaired verbal episodic memory encoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: We sought to determine if ripple oscillations (80-120Hz),\ndetected in intracranial EEG (iEEG) recordings of epilepsy patients, correlate\nwith an enhancement or disruption of verbal episodic memory encoding. Methods:\nWe defined ripple and spike events in depth iEEG recordings during list\nlearning in 107 patients with focal epilepsy. We used logistic regression\nmodels (LRMs) to investigate the relationship between the occurrence of ripple\nand spike events during word presentation and the odds of successful word\nrecall following a distractor epoch, and included the seizure onset zone (SOZ)\nas a covariate in the LRMs. Results: We detected events during 58,312 word\npresentation trials from 7,630 unique electrode sites. The probability of\nripple on spike (RonS) events was increased in the seizure onset zone (SOZ,\np<0.04). In the left temporal neocortex RonS events during word presentation\ncorresponded with a decrease in the odds ratio (OR) of successful recall,\nhowever this effect only met significance in the SOZ (OR of word recall 0.71,\n95% CI: 0.59-0.85, n=158 events, adaptive Hochberg p<0.01). Ripple on\noscillation events (RonO) that occurred in the left temporal neocortex non-SOZ\nalso correlated with decreased odds of successful recall (OR 0.52, 95% CI:\n0.34-0.80, n=140, adaptive Hochberg , p<0.01). Spikes and RonS that occurred\nduring word presentation in the left middle temporal gyrus during word\npresentation correlated with the most significant decrease in the odds of\nsuccessful recall, irrespective of the location of the SOZ (adaptive Hochberg,\np<0.01). Conclusion: Ripples and spikes generated in left temporal neocortex\nare associated with impaired verbal episodic memory encoding.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:57:14 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Waldman", "Zachary J.", ""], ["Camarillo-Rodriguez", "Liliana", ""], ["Chervenova", "Inna", ""], ["Berry", "Brent", ""], ["Shimamoto", "Shoichi", ""], ["Elahian", "Bahareh", ""], ["Kucewicz", "Michal", ""], ["Ganne", "Chaitanya", ""], ["He", "Xiao-Song", ""], ["Davis", "Leon A.", ""], ["Stein", "Joel", ""], ["Das", "Sandhitsu", ""], ["Gorniak", "Richard", ""], ["Sharan", "Ashwini D.", ""], ["Gross", "Robert", ""], ["Inman", "Cory S.", ""], ["Lega", "Bradley C.", ""], ["Zaghloul", "Kareem", ""], ["Jobst", "Barbara C.", ""], ["Davis", "Katheryn A.", ""], ["Wanda", "Paul", ""], ["Khadjevand", "Mehraneh", ""], ["Tracy", "Joseph", ""], ["Rizzuto", "Daniel S.", ""], ["Worrell", "Gregory", ""], ["Sperling", "Michael", ""], ["Weiss", "Shennan A.", ""]]}, {"id": "1807.10374", "submitter": "Leslie Valiant", "authors": "Leslie Valiant", "title": "Towards Identifying the Systems-Level Primitives of Cortex by In-Circuit\n  Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypothesis considered here is that cognition is based on a small set of\nsystems-level computational primitives that are defined at a level higher than\nsingle neurons. It is pointed out that for one such set of primitives, whose\nquantitative effectiveness has been demonstrated by analysis and computer\nsimulation, emerging technologies for stimulation and recording are making it\npossible to test directly whether cortex is capable of performing them.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 21:37:02 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Valiant", "Leslie", ""]]}, {"id": "1807.10587", "submitter": "Gabriel Kreiman", "authors": "Mengmi Zhang, Jiashi Feng, Keng Teck Ma, Joo Hwee Lim, Qi Zhao,\n  Gabriel Kreiman", "title": "Finding any Waldo: zero-shot invariant and efficient visual search", "comments": "Number of figures: 6 Number of supplementary figures: 14", "journal-ref": null, "doi": "10.1038/s41467-018-06217-x", "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searching for a target object in a cluttered scene constitutes a fundamental\nchallenge in daily vision. Visual search must be selective enough to\ndiscriminate the target from distractors, invariant to changes in the\nappearance of the target, efficient to avoid exhaustive exploration of the\nimage, and must generalize to locate novel target objects with zero-shot\ntraining. Previous work has focused on searching for perfect matches of a\ntarget after extensive category-specific training. Here we show for the first\ntime that humans can efficiently and invariantly search for natural objects in\ncomplex scenes. To gain insight into the mechanisms that guide visual search,\nwe propose a biologically inspired computational model that can locate targets\nwithout exhaustive sampling and generalize to novel objects. The model provides\nan approximation to the mechanisms integrating bottom-up and top-down signals\nduring search in natural scenes.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 01:17:34 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Zhang", "Mengmi", ""], ["Feng", "Jiashi", ""], ["Ma", "Keng Teck", ""], ["Lim", "Joo Hwee", ""], ["Zhao", "Qi", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "1807.11036", "submitter": "Sandro Sozzo", "authors": "Diederik Aerts, Massimiliano Sassoli de Bianchi, Sandro Sozzo, Tomas\n  Veloz", "title": "Modeling Human Decision-making: An Overview of the Brussels Quantum\n  Approach", "comments": "25 pages, Latex, 2 figures, published in Foundations of Science", "journal-ref": null, "doi": "10.1007/s10699-018-9559-x", "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the fundamentals of the quantum theoretical approach we have\ndeveloped in the last decade to model cognitive phenomena that resisted\nmodeling by means of classical logical and probabilistic structures, like\nBoolean, Kolmogorovian and, more generally, set theoretical structures. We\nfirstly sketch the operational-realistic foundations of conceptual entities,\ni.e. concepts, conceptual combinations, propositions, decision-making entities,\netc. Then, we briefly illustrate the application of the quantum formalism in\nHilbert space to represent combinations of natural concepts, discussing its\nsuccess in modeling a wide range of empirical data on concepts and their\nconjunction, disjunction and negation. Next, we naturally extend the quantum\ntheoretical approach to model some long-standing `fallacies of human\nreasoning', namely, the `conjunction fallacy' and the `disjunction effect'.\nFinally, we put forward an explanatory hypothesis according to which human\nreasoning is a defined superposition of `emergent reasoning' and `logical\nreasoning', where the former generally prevails over the latter. The quantum\ntheoretical approach explains human fallacies as the consequence of genuine\nquantum structures in human reasoning, i.e. `contextuality', `emergence',\n`entanglement', `interference' and `superposition'. As such, it is alternative\nto the Kahneman-Tversky research programme, which instead aims to explain human\nfallacies in terms of `individual heuristics and biases'.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 10:21:59 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Aerts", "Diederik", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1807.11819", "submitter": "Nikolaus Kriegeskorte", "authors": "Nikolaus Kriegeskorte and Pamela K. Douglas", "title": "Cognitive computational neuroscience", "comments": "31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To learn how cognition is implemented in the brain, we must build\ncomputational models that can perform cognitive tasks, and test such models\nwith brain and behavioral experiments. Cognitive science has developed\ncomputational models of human cognition, decomposing task performance into\ncomputational components. However, its algorithms still fall short of human\nintelligence and are not grounded in neurobiology. Computational neuroscience\nhas investigated how interacting neurons can implement component functions of\nbrain computation. However, it has yet to explain how those components interact\nto explain human cognition and behavior. Modern technologies enable us to\nmeasure and manipulate brain activity in unprecedentedly rich ways in animals\nand humans. However, experiments will yield theoretical insight only when\nemployed to test brain-computational models. It is time to assemble the pieces\nof the puzzle of brain computation. Here we review recent work in the\nintersection of cognitive science, computational neuroscience, and artificial\nintelligence. Computational models that mimic brain information processing\nduring perceptual, cognitive, and control tasks are beginning to be developed\nand tested with brain and behavioral data.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 13:56:16 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Kriegeskorte", "Nikolaus", ""], ["Douglas", "Pamela K.", ""]]}, {"id": "1807.11935", "submitter": "Danielle Bassett", "authors": "Danielle S. Bassett, Perry Zurn, Joshua I. Gold", "title": "Network models in neuroscience", "comments": "Under consideration as a book chapter in Cerebral Cortex 3.0, MIT\n  Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From interacting cellular components to networks of neurons and neural\nsystems, interconnected units comprise a fundamental organizing principle of\nthe nervous system. Understanding how their patterns of connections and\ninteractions give rise to the many functions of the nervous system is a primary\ngoal of neuroscience. Recently, this pursuit has begun to benefit from the\ndevelopment of new mathematical tools that can relate a system's architecture\nto its dynamics and function. These tools, which are known collectively as\nnetwork science, have been used with increasing success to build models of\nneural systems across spatial scales and species. Here we discuss the nature of\nnetwork models in neuroscience. We begin with a review of model theory from a\nphilosophical perspective to inform our view of networks as models of complex\nsystems in general, and of the brain in particular. We then summarize the types\nof models that are frequently studied in network neuroscience along three\nprimary dimensions: from data representations to first-principles theory, from\nbiophysical realism to functional phenomenology, and from elementary\ndescriptions to coarse-grained approximations. We then consider ways to\nvalidate these models, focusing on approaches that perturb a system to probe\nits function. We close with a description of important frontiers in the\nconstruction of network models and their relevance for understanding\nincreasingly complex functions of neural systems.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 17:51:16 GMT"}], "update_date": "2018-08-01", "authors_parsed": [["Bassett", "Danielle S.", ""], ["Zurn", "Perry", ""], ["Gold", "Joshua I.", ""]]}]