[{"id": "1610.00161", "submitter": "Blake Richards", "authors": "Jordan Guergiuev, Timothy P. Lillicrap and Blake A. Richards", "title": "Towards deep learning with segregated dendrites", "comments": "41 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has led to significant advances in artificial intelligence, in\npart, by adopting strategies motivated by neurophysiology. However, it is\nunclear whether deep learning could occur in the real brain. Here, we show that\na deep learning algorithm that utilizes multi-compartment neurons might help us\nto understand how the brain optimizes cost functions. Like neocortical\npyramidal neurons, neurons in our model receive sensory information and\nhigher-order feedback in electrotonically segregated compartments. Thanks to\nthis segregation, the neurons in different layers of the network can coordinate\nsynaptic weight updates. As a result, the network can learn to categorize\nimages better than a single layer network. Furthermore, we show that our\nalgorithm takes advantage of multilayer architectures to identify useful\nrepresentations---the hallmark of deep learning. This work demonstrates that\ndeep learning can be achieved using segregated dendritic compartments, which\nmay help to explain the dendritic morphology of neocortical pyramidal neurons.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 17:37:34 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 18:07:26 GMT"}, {"version": "v3", "created": "Fri, 7 Apr 2017 18:45:30 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Guergiuev", "Jordan", ""], ["Lillicrap", "Timothy P.", ""], ["Richards", "Blake A.", ""]]}, {"id": "1610.00252", "submitter": "Fabrizio Pittorino", "authors": "Fabrizio Pittorino, Miguel Ib\\'a\\~nez-Berganza, Matteo di Volo,\n  Alessandro Vezzani, Raffaella Burioni", "title": "Chaos and correlated avalanches in excitatory neural networks with\n  synaptic plasticity", "comments": "5 pages 5 figures; SI 26 pages 14 figures. Improved editing, 3\n  subsections added in SI", "journal-ref": "Phys. Rev. Lett. 118(9), 098102 (2017)", "doi": "10.1103/PhysRevLett.118.098102", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A collective chaotic phase with power law scaling of activity events is\nobserved in a disordered mean field network of purely excitatory leaky\nintegrate-and-fire neurons with short-term synaptic plasticity. The dynamical\nphase diagram exhibits two transitions from quasi-synchronous and asynchronous\nregimes to the nontrivial, collective, bursty regime with avalanches. In the\nhomogeneous case without disorder, the system synchronizes and the bursty\nbehavior is reflected into a doubling-period transition to chaos for a two\ndimensional discrete map. Numerical simulations show that the bursty chaotic\nphase with avalanches exhibits a spontaneous emergence of time correlations and\nenhanced Kolmogorov complexity. Our analysis reveals a mechanism for the\ngeneration of irregular avalanches that emerges from the combination of\ndisorder and deterministic underlying chaotic dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 09:47:46 GMT"}, {"version": "v2", "created": "Sun, 12 Feb 2017 10:45:46 GMT"}, {"version": "v3", "created": "Fri, 17 Mar 2017 08:38:48 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Pittorino", "Fabrizio", ""], ["Ib\u00e1\u00f1ez-Berganza", "Miguel", ""], ["di Volo", "Matteo", ""], ["Vezzani", "Alessandro", ""], ["Burioni", "Raffaella", ""]]}, {"id": "1610.00262", "submitter": "Yujiang Wang", "authors": "Gerold Baier, Peter N Taylor and Yujiang Wang", "title": "Understanding Epileptiform After-Discharges as Rhythmic Oscillatory\n  Transients", "comments": "http://journal.frontiersin.org/article/10.3389/fncom.2017.00025/full", "journal-ref": null, "doi": "10.3389/fncom.2017.00025", "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electro-cortical activity in patients with epilepsy may show abnormal\nrhythmic transients in response to stimulation. Even when using the same\nstimulation parameters in the same patient, wide variability in the duration of\ntransient response has been reported. These transients have long been\nconsidered important for the mapping of the excitability levels in the\nepileptic brain but their dynamic mechanism is still not well understood.\n  To understand the occurrence of abnormal transients dynamically, we use a\nthalamo-cortical neural population model of epileptic spike-wave activity and\nstudy the interaction between slow and fast subsystems.\n  In a reduced version of the thalamo-cortical model, slow wave oscillations\narise from a fold of cycles (FoC) bifurcation. This marks the onset of a region\nof bistability between a high amplitude oscillatory rhythm and the background\nstate. In vicinity of the bistability in parameter space, the model has\nexcitable dynamics, showing prolonged rhythmic transients in response to\nsuprathreshold pulse stimulation. We analyse the state space geometry of the\nbistable and excitable states, and find that the rhythmic transient arises when\nthe impending FoC bifurcation deforms the state space and creates an area of\nlocally reduced attraction to the fixed point. This area essentially allows\ntrajectories to dwell there before escaping to the stable steady state, thus\ncreating rhythmic transients. In the full thalamo-cortical model, we find a\nsimilar FoC bifurcation structure.\n  Based on the analysis, we propose an explanation of why stimulation induced\nepileptiform activity may vary between trials, and predict how the variability\ncould be related to ongoing oscillatory background activity.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 11:16:30 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 13:16:44 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Baier", "Gerold", ""], ["Taylor", "Peter N", ""], ["Wang", "Yujiang", ""]]}, {"id": "1610.00309", "submitter": "Tom Campbell", "authors": "Tom Campbell", "title": "Can Occipital Alpha Neurofeedback Influence LTRCs and Deterministic ERPs\n  without Critical Branching?", "comments": "First proof", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical branching is a theoretical interaction in-between simple units, such\nas neuronal elements of the human brain. Zhigalov, Kaplan, and Palva (2016,\nClin. Neurophysiol., 127(8), 2882-2889) revealed that neurofeedback flash\nstimulation locked to the phase of high-amplitude occipital alpha influences\nstimulus-locked occipital averages in the alpha-band. This feedback also\ninfluences the power scaling of long-range temporal correlations in alpha-band\namplitude fluctuations. Seemingly, neurofeedback influences critical branching\nalongside there being an interaction between ongoing neuronal activity and\nevoked responses. However, the causal relations between these neuronal\nlong-range temporal correlations, sustained attention, and any avalanche\ndynamics are called into question. Further, uncorrected concerns include false\ndiscovery rate and an objective mathematical error in the precedent (Palva et\nal., 2013, Proc. Nat. Acad. Sci. U.S.A., 110(9), 3585-3590). An alternative set\nof illustrative mathematical principles offers a preliminary fit to the effects\nin the data. That is, neurofeedback influences the deterministic contribution\nto the single-trial event-related potentials, which each flash evokes,\nseparately from the oscillatory alpha gain that those flashes cause.\nAccordingly, distinct principles of this neurofeedback-related exponential\noccipital oscillatory alpha gain and deterministic event-related potential\ngeneration produce micro-behaviours with macroscale consequences: neurofeedback\ncausally influences power-scaling of long-range temporal correlations without\ncritical branching.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 16:48:37 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 14:53:08 GMT"}, {"version": "v3", "created": "Thu, 29 Dec 2016 05:35:54 GMT"}, {"version": "v4", "created": "Tue, 21 Feb 2017 13:41:47 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Campbell", "Tom", ""]]}, {"id": "1610.00542", "submitter": "Cristina Zucca", "authors": "Petr Lansky, Laura Sacerdote, Cristina Zucca", "title": "The Gamma renewal process as an output of the diffusion leaky\n  integrate-and-fire neuronal model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical properties of spike trains as well as other neurophysiological\ndata suggest a number of mathematical models of neurons. These models range\nfrom entirely descriptive ones to those deduced from the properties of the real\nneurons. One of them, the diffusion leaky integrate-and-fire neuronal model,\nwhich is based on the Ornstein-Uhlenbeck stochastic process that is restricted\nby an absorbing barrier, can describe a wide range of neuronal activity in\nterms of its parameters. These parameters are readily associated with known\nphysiological mechanisms. The other model is descriptive, Gamma renewal\nprocess, and its parameters only reflect the observed experimental data or\nassumed theoretical properties. Both of these commonly used models are related\nhere. We show under which conditions the Gamma model is an output from the\ndiffusion Ornstein-Uhlenbeck model. In some cases we can see that the Gamma\ndistribution is unrealistic to be achieved for the employed parameters of the\nOrnstein-Uhlenbeck process.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 13:33:58 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Lansky", "Petr", ""], ["Sacerdote", "Laura", ""], ["Zucca", "Cristina", ""]]}, {"id": "1610.00611", "submitter": "Grzegorz Wojcik Prof.", "authors": "Dominik S. Kufel, Grzegorz M. Wojcik", "title": "Analytical modelling of temperature effects on synapses", "comments": "14 pages, 11 figures", "journal-ref": "Kufel, D. S., & Wojcik, G. M. (2018). Analytical modelling of\n  temperature effects on an AMPA-type synapse. Journal of computational\n  neuroscience, 44(3), 379-391", "doi": "10.1007/s10827-018-0684-x", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It was previously reported, that temperature may significantly influence\nneural dynamics on different levels of brain modelling. Due to this fact, while\ncreating the model in computational neuroscience we would like to make it\nscalable for wide-range of various brain temperatures. However currently,\nbecause of a lack of experimental data and an absence of analytical model\ndescribing temperature influence on synapses, it is not possible to include\ntemperature effects on multi-neuron modelling level. In this paper, we propose\nfirst step to deal with this problem: new analytical model of AMPA-type\nsynaptic conductance, which is able to include temperature effects in\nlow-frequency stimulations. It was constructed on basis of Markov model\ndescription of AMPA receptor kinetics and few simplifications motivated both\nexperimentally and from Monte Carlo simulation of synaptic transmission. The\nmodel may be used for efficient and accurate implementation of temperature\neffects on AMPA receptor conductance in large scale neural network simulations.\nThis in fact, opens wide-range of new possibilities for researching an\ninfluence of temperature on brain functioning.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 16:12:27 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Kufel", "Dominik S.", ""], ["Wojcik", "Grzegorz M.", ""]]}, {"id": "1610.01147", "submitter": "Yeldos Kozhagulov", "authors": "Z.Zh. Zhanabaev, T.Yu. Grevtseva, Y.T. Kozhagulov", "title": "Nonlinear Characteristics of Neural Signals", "comments": "Our work is dedicated to the research of nonlinear characteristics of\n  neural signals. 6 pages, 2 figures. arXiv admin note: text overlap with\n  arXiv:1610.00446", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study is devoted to definition of generalized metrical and topological\n(informational entropy) characteristics of neural signals via their well-known\ntheoretical models. We have shown that time dependence of action potential of\nneurons is scale invariant. Information and entropy of neural signals have\nconstant values in case of self-similarity and self-affinity.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 11:50:46 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Zhanabaev", "Z. Zh.", ""], ["Grevtseva", "T. Yu.", ""], ["Kozhagulov", "Y. T.", ""]]}, {"id": "1610.01217", "submitter": "Yahya Karimipanah", "authors": "Yahya Karimipanah, Zhengyu Ma and Ralf Wessel", "title": "New hallmarks of criticality in recurrent neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rigorous understanding of brain dynamics and function requires a conceptual\nbridge between multiple levels of organization, including neural spiking and\nnetwork-level population activity. Mounting evidence suggests that neural\nnetworks of cerebral cortex operate at criticality. How operating near this\nnetwork state impacts the variability of neuronal spiking is largely unknown.\nHere we show in a computational model that two prevalent features of cortical\nsingle-neuron activity, irregular spiking and the decline of response\nvariability at stimulus onset, are both emergent properties of a recurrent\nnetwork operating near criticality. Importantly, our work reveals that the\nrelation between the irregularity of spiking and the number of input\nconnections to a neuron, i.e., the in-degree, is maximized at criticality. Our\nfindings establish criticality as a unifying principle for the variability of\nsingle-neuron spiking and the collective behavior of recurrent circuits in\ncerebral cortex.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 21:49:27 GMT"}, {"version": "v2", "created": "Sat, 8 Oct 2016 05:11:51 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Karimipanah", "Yahya", ""], ["Ma", "Zhengyu", ""], ["Wessel", "Ralf", ""]]}, {"id": "1610.01563", "submitter": "Matthias K\\\"ummerer", "authors": "Matthias K\\\"ummerer, Thomas S. A. Wallis and Matthias Bethge", "title": "DeepGaze II: Reading fixations from deep features trained on object\n  recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present DeepGaze II, a model that predicts where people look in\nimages. The model uses the features from the VGG-19 deep neural network trained\nto identify objects in images. Contrary to other saliency models that use deep\nfeatures, here we use the VGG features for saliency prediction with no\nadditional fine-tuning (rather, a few readout layers are trained on top of the\nVGG features to predict saliency). The model is therefore a strong test of\ntransfer learning. After conservative cross-validation, DeepGaze II explains\nabout 87% of the explainable information gain in the patterns of fixations and\nachieves top performance in area under the curve metrics on the MIT300 hold-out\nbenchmark. These results corroborate the finding from DeepGaze I (which\nexplained 56% of the explainable information gain), that deep features trained\non object recognition provide a versatile feature space for performing related\nvisual tasks. We explore the factors that contribute to this success and\npresent several informative image examples. A web service is available to\ncompute model predictions at http://deepgaze.bethgelab.org.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 18:47:28 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["K\u00fcmmerer", "Matthias", ""], ["Wallis", "Thomas S. A.", ""], ["Bethge", "Matthias", ""]]}, {"id": "1610.01636", "submitter": "Francesca Pitolli", "authors": "Annalisa Pascarella, Francesca Pitolli", "title": "An inversion method based on random sampling for real-time MEG\n  neuroimaging", "comments": "15 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MagnetoEncephaloGraphy (MEG) has gained great interest in\nneurorehabilitation training due to its high temporal resolution. The challenge\nis to localize the active regions of the brain in a fast and accurate way. In\nthis paper we use an inversion method based on random spatial sampling to solve\nthe real-time MEG inverse problem. Several numerical tests on synthetic but\nrealistic data show that the method takes just a few hundredths of a second on\na laptop to produce an accurate map of the electric activity inside the brain.\nMoreover, it requires very little memory storage. For this reasons the random\nsampling method is particularly attractive in real-time MEG applications.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 20:33:29 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Pascarella", "Annalisa", ""], ["Pitolli", "Francesca", ""]]}, {"id": "1610.01704", "submitter": "Kieran Fox", "authors": "Kieran C. R. Fox, Manesh Girn", "title": "Neural correlates of self-generated imagery and cognition throughout the\n  sleep cycle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans have been aware for thousands of years that sleep comes in many forms,\naccompanied by different kinds of mental content. We review the first-person\nreport literature on the frequency and type of content experienced in various\nstages of sleep, showing that different sleep stages are dissociable at the\nsubjective level. We then relate these subjective differences to the growing\nliterature differentiating the various sleep stages at the neurophysiological\nlevel, including evidence from electrophysiology, neurochemistry, and\nfunctional neuroimaging. We suggest that there is emerging evidence for\nrelationships between sleep stage, neurophysiological activity, and subjective\nexperiences. Specifically, we emphasize that functional neuroimaging work\nsuggests a parallel between activation and deactivation of default network and\nvisual network brain areas and the varying frequency and intensity of imagery\nand dream mentation across sleep stages; additionally, frontoparietal control\nnetwork activity across sleep stages may parallel levels of cognitive control\nand meta-awareness. Together these findings suggest intriguing brain-mind\nisomorphisms and may serve as a first step toward a comprehensive understanding\nof the relationship between neurophysiology and psychology in sleep and\ndreaming.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 01:27:48 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Fox", "Kieran C. R.", ""], ["Girn", "Manesh", ""]]}, {"id": "1610.01849", "submitter": "Henning Dickten", "authors": "Klaus Lehnertz and Henning Dickten", "title": "Assessing directionality and strength of coupling through symbolic\n  analysis: an application to epilepsy patients", "comments": null, "journal-ref": "Phil. Trans. R. Soc. A 373, 2034 (2015)", "doi": "10.1098/rsta.2014.0094", "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring strength and direction of interactions from electroencephalographic\n(EEG) recordings is of crucial importance to improve our understanding of\ndynamical interdependencies underlying various physiologic and pathophysiologic\nconditions in the human epileptic brain. We here use approaches from symbolic\nanalysis to investigate---in a time-resolved manner---weighted and directed,\nshort- to long-ranged interactions between various brain regions constituting\nthe epileptic network. Our observations point to complex spatial-temporal\ninterdependencies underlying the epileptic process and their role in the\ngeneration of epileptic seizures, despite the massive reduction of the complex\ninformation content of multi-day, multi-channel EEG recordings through\nsymbolisation. We discuss limitations and potential future improvements of this\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 12:57:49 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Lehnertz", "Klaus", ""], ["Dickten", "Henning", ""]]}, {"id": "1610.01894", "submitter": "Christian Geier", "authors": "Christian Geier, Marie-Therese Kuhnert, Christian E. Elger, Klaus\n  Lehnertz", "title": "On the Centrality of the Focus in Human Epileptic Brain Networks", "comments": null, "journal-ref": "R. Tetzlaff and C. E. Elger and K. Lehnertz (2013), Recent\n  Advances in Predicting and Preventing Epileptic Seizures, page 175-185,\n  Singapore, World Scientific", "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is increasing evidence for specific cortical and subcortical\nlarge-scale human epileptic networks to be involved in the generation, spread,\nand termination of not only primary generalized but also focal onset seizures.\nThe complex dynamics of such networks has been studied with methods of analysis\nfrom graph theory. In addition to investigating network-specific\ncharacteristics, recent studies aim to determine the functional role of single\nnodes---such as the epileptic focus---in epileptic brain networks and their\nrelationship to ictogenesis. Utilizing the concept of betweenness centrality to\nassess the importance of network nodes, previous studies reported the epileptic\nfocus to be of highest importance prior to seizures, which would support the\nnotion of a network hub that facilitates seizure activity. We performed a\ntime-resolved analysis of various aspects of node importance in epileptic brain\nnetworks derived from long-term, multi-channel, intracranial\nelectroencephalographic recordings from an epilepsy patient. Our preliminary\nfindings indicate that the epileptic focus is not consistently the most\nimportant network node, but node importance may drastically vary over time.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 14:41:23 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Geier", "Christian", ""], ["Kuhnert", "Marie-Therese", ""], ["Elger", "Christian E.", ""], ["Lehnertz", "Klaus", ""]]}, {"id": "1610.01898", "submitter": "Christian Geier", "authors": "Christian Geier, Alexander Rothkegel, Christian E. Elger, Klaus\n  Lehnertz", "title": "Bursting and Synchrony in Networks of Model Neurons", "comments": null, "journal-ref": "R. Tetzlaff and C. E. Elger and K. Lehnertz (2013), Recent\n  Advances in Predicting and Preventing Epileptic Seizures, page 108-116,\n  Singapore, World Scientific", "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bursting neurons are considered to be a potential cause of over-excitability\nand seizure susceptibility. The functional influence of these neurons in\nextended epileptic networks is still poorly understood. There is mounting\nevidence that the dynamics of neuronal networks is influenced not only by\nneuronal and synaptic properties but also by network topology. We investigate\nnumerically the influence of different neuron dynamics on global synchrony in\nneuronal networks with complex connection topologies.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 14:52:22 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Geier", "Christian", ""], ["Rothkegel", "Alexander", ""], ["Elger", "Christian E.", ""], ["Lehnertz", "Klaus", ""]]}, {"id": "1610.02016", "submitter": "Vince Grolmusz", "authors": "Csaba Kerepesi and Balazs Szalkai and Balint Varga and Vince Grolmusz", "title": "The braingraph.org Database of High Resolution Structural Connectomes\n  and the Brain Graph Tools", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the data of the NIH-funded Human Connectome Project, we have\ncomputed structural connectomes of 426 human subjects in five different\nresolutions of 83, 129, 234, 463 and 1015 nodes and several edge weights. The\ngraphs are given in anatomically annotated GraphML format that facilitates\nbetter further processing and visualization. For 96 subjects, the anatomically\nclassified sub-graphs can also be accessed, formed from the vertices\ncorresponding to distinct lobes or even smaller regions of interests of the\nbrain. For example, one can easily download and study the connectomes,\nrestricted to the frontal lobes or just to the left precuneus of 96 subjects\nusing the data. Partially directed connectomes of 423 subjects are also\navailable for download. We also present a GitHub-deposited set of tools, called\nthe Brain Graph Tools, for several processing tasks of the connectomes on the\nsite \\url{http://braingraph.org}.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 19:44:41 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Kerepesi", "Csaba", ""], ["Szalkai", "Balazs", ""], ["Varga", "Balint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1610.02084", "submitter": "Cameron Musco", "authors": "Nancy Lynch, Cameron Musco, Merav Parter", "title": "Computational Tradeoffs in Biological Neural Networks: Self-Stabilizing\n  Winner-Take-All Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a line of investigation into biological neural networks from an\nalgorithmic perspective. We develop a simplified but biologically plausible\nmodel for distributed computation in stochastic spiking neural networks and\nstudy tradeoffs between computation time and network complexity in this model.\nOur aim is to abstract real neural networks in a way that, while not capturing\nall interesting features, preserves high-level behavior and allows us to make\nbiologically relevant conclusions.\n  In this paper, we focus on the important `winner-take-all' (WTA) problem,\nwhich is analogous to a neural leader election unit: a network consisting of\n$n$ input neurons and $n$ corresponding output neurons must converge to a state\nin which a single output corresponding to a firing input (the `winner') fires,\nwhile all other outputs remain silent. Neural circuits for WTA rely on\ninhibitory neurons, which suppress the activity of competing outputs and drive\nthe network towards a converged state with a single firing winner. We attempt\nto understand how the number of inhibitors used affects network convergence\ntime.\n  We show that it is possible to significantly outperform naive WTA\nconstructions through a more refined use of inhibition, solving the problem in\n$O(\\theta)$ rounds in expectation with just $O(\\log^{1/\\theta} n)$ inhibitors\nfor any $\\theta$. An alternative construction gives convergence in\n$O(\\log^{1/\\theta} n)$ rounds with $O(\\theta)$ inhibitors. We compliment these\nupper bounds with our main technical contribution, a nearly matching lower\nbound for networks using $\\ge \\log\\log n$ inhibitors. Our lower bound uses\nfamiliar indistinguishability and locality arguments from distributed computing\ntheory. It lets us derive a number of interesting conclusions about the\nstructure of any network solving WTA with good probability, and the use of\nrandomness and inhibition within such a network.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 21:56:38 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Lynch", "Nancy", ""], ["Musco", "Cameron", ""], ["Parter", "Merav", ""]]}, {"id": "1610.02227", "submitter": "Werner Ehm", "authors": "Werner Ehm and Jiri Wackermann", "title": "Geometric-optical illusions and Riemannian geometry", "comments": "Preprint version of journal article", "journal-ref": "Journal of Mathematical Psychology 71 (2016) 28-28", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric-optical illusions (GOI) are a subclass of a vast variety of visual\nillusions. A special class of GOIs originates from the superposition of a\nsimple geometric figure (\"target\") with an array of non-intersecting\ncurvilinear elements (\"context\") that elicits a perceptual distortion of the\ntarget element. Here we specifically deal with the case of circular targets.\nStarting from the fact that (half)circles are geodesics in a model of\nhyperbolic geometry, we conceive of the deformations of the target as resulting\nfrom a context-induced perturbation of that \"base\" geometry. We present\ncomputational methods for predicting distorted shapes of the target in\ndifferent contexts, and we report the results of a psychophysical pilot\nexperiment with eight subjects and four contexts to test the predictions.\nFinally, we propose a common scheme for modeling GOIs associated with more\ngeneral types of target curves, subsuming those studied previously.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 11:08:48 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Ehm", "Werner", ""], ["Wackermann", "Jiri", ""]]}, {"id": "1610.02249", "submitter": "Esmaeil Seraj", "authors": "Esmaeil Seraj (ECE GeorgiaTech)", "title": "Cerebral Signal Instantaneous Parameters Estimation MATLAB Toolbox -\n  User Guide Version 2.3", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document is meant to help individuals use the Cerebral Signal Phase\nAnalysis toolbox which implements different methods for estimating the\ninstantaneous phase and frequency of a signal and calculating some related\npopular quantities.The toolbox -- which is distributed under the terms of the\nGNU GENERAL PUBLIC LICENSE as a set of MATLAB routines -- can be downloaded at\nthe address http://oset.ir/category.php?dir=Tools.The purpose of this toolbox\nis to calculate the instantaneous phase and frequency sequences of cerebral\nsignals (EEG, MEG, etc.) and some related popular features and quantities in\nbrain studies and Neuroscience such as Phase Shift, Phase Resetting, Phase\nLocking Value (PLV), Phase Difference and more, to help researchers in these\nfields.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 12:27:36 GMT"}, {"version": "v2", "created": "Thu, 28 Dec 2017 13:53:44 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2018 07:00:16 GMT"}, {"version": "v4", "created": "Fri, 6 Jul 2018 01:26:42 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Seraj", "Esmaeil", "", "ECE GeorgiaTech"]]}, {"id": "1610.02308", "submitter": "Henning Dickten", "authors": "Henning Dickten and Klaus Lehnertz", "title": "Identifying delayed directional couplings with symbolic transfer entropy", "comments": null, "journal-ref": "Phys. Rev. E 90, 062706 (2014)", "doi": "10.1103/PhysRevE.90.062706", "report-no": null, "categories": "q-bio.NC nlin.CD physics.comp-ph physics.data-an physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a straightforward extension of symbolic transfer entropy to enable\nthe investigation of delayed directional relationships between coupled\ndynamical systems from time series. Analyzing time series from chaotic model\nsystems, we demonstrate the applicability and limitations of our approach. Our\nfindings obtained from applying our method to infer delayed directed\ninteractions in the human epileptic brain underline the importance of our\napproach for improving the construction of functional network structures from\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 12:56:27 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Dickten", "Henning", ""], ["Lehnertz", "Klaus", ""]]}, {"id": "1610.02309", "submitter": "Henning Dickten", "authors": "Henning Dickten, Christian E. Elger, Klaus Lehnertz", "title": "Measuring directed interactions using cellular neural networks with\n  complex connection topologies", "comments": null, "journal-ref": "R. Tetzlaff and C. E. Elger and K. Lehnertz (2013), Recent\n  Advances in Predicting and Preventing Epileptic Seizures, page 242-252,\n  Singapore, World Scientific. ISBN: 978-981-4525-34-3", "doi": null, "report-no": null, "categories": "q-bio.NC nlin.CD nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advance our approach of analyzing the dynamics of interacting complex\nsystems with the nonlinear dynamics of interacting nonlinear elements. We\nreplace the widely used lattice-like connection topology of cellular neural\nnetworks (CNN) by complex topologies that include both short- and long-ranged\nconnections. With an exemplary time-resolved analysis of asymmetric nonlinear\ninterdependences between the seizure generating area and its immediate\nsurrounding we provide first evidence for complex CNN connection topologies to\nallow for a faster network optimization together with an improved approximation\naccuracy of directed interactions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 14:33:17 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Dickten", "Henning", ""], ["Elger", "Christian E.", ""], ["Lehnertz", "Klaus", ""]]}, {"id": "1610.02395", "submitter": "Salvador Malo", "authors": "Salvador Malo", "title": "Causal-order superposition as an enabler of free will", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is often argued that bottom-up causation under a physicalist, reductionist\nworldview precludes free will in the libertarian sense. On the one hand, the\nparadigm of classical mechanics makes determinism inescapable, while on the\nother, the leading models that allow a role for quantum effects are\nnoncommittal regarding how conscious agents are supposed to translate\nindeterminacy into self-formed choice. Recent developments, however, not only\nimply that self-formed decisions are possible, but actually suggest how they\nmight come about. The cornerstone appears to be causality superposition rather\nthan quantum-state entanglement, as is usually assumed, and the natural arena\nfor applying these developments is (perhaps ironically) a framework that was\nbuilt without any consideration for quantum effects.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 00:39:25 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Malo", "Salvador", ""]]}, {"id": "1610.02471", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "The Creative Process in Musical Composition: An Introspective Account", "comments": "9 pages", "journal-ref": "In Hans-Joachim Braun (Ed.) Creativity: Technology and music (pp.\n  131-141). Frankfurt / New York: Peter Lang (2016)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter charts the creative process in the composition of a piece of\nmusic titled 'Stream not gone dry' that unfolded, while I was primarily\noccupied with other matters, over the course of nearly two decades. It avoids\ndiscussion of the technical aspects of musical composition, and it can be read\nby someone with no formal knowledge of music. The focus here is on what the\nprocess of composing this particular piece of music says about how the creative\nprocess works. My interpretation of the music-making process may be biased by\nmy academic view of creativity, but I believe that the influence works\nprimarily in the other direction, my understanding of how the creative process\nworks is derived from experiences creating. This intuitive understanding is\nshaped over time by the process of reading scholarly papers on creativity and\nworking them into my own evolving theory of creativity, but the papers that I\nresonate with and incorporate are those that are in line with my experience.\nThis chapter just makes the influence of personal experience more explicit than\nin other more scholarly writings on creativity.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 03:16:51 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1610.02475", "submitter": "Liane Gabora", "authors": "Shawn Bell and Liane Gabora", "title": "A Music-generating System Inspired by the Science of Complex Adaptive\n  Systems", "comments": "8 pages, In Proceedings of the 4th International Workshop on Musical\n  Meta-creation. Palo Alto: Association for the Advancement of Artificial\n  Intelligence (AAAI) Press. ISBN: 978-0-86491-397-5 (2016)", "journal-ref": "In Proceedings of the 4th International Workshop on Musical\n  Meta-creation (MUME 2016). Palo Alto: Association for the Advancement of\n  Artificial Intelligence (AAAI) Press. ISBN: 978-0-86491-397-5", "doi": null, "report-no": null, "categories": "cs.SD nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents NetWorks (NW), an interactive music generation system\nthat uses a hierarchically clustered scale free network to generate music that\nranges from orderly to chaotic. NW was inspired by the Honing Theory of\ncreativity, according to which human-like creativity hinges on (1) the ability\nto self-organize and maintain dynamics at the 'edge of chaos' using something\nakin to 'psychological entropy', and (2) the capacity to shift between analytic\nand associative processing modes. At the 'edge of chaos', NW generates patterns\nthat exhibit emergent complexity through coherent development at low, mid, and\nhigh levels of musical organization, and often suggests goal seeking behaviour.\nThe architecture consists of four 16-node modules: one each for pitch,\nvelocity, duration, and entry delay. The Core allows users to define how nodes\nare connected, and rules that determine when and how nodes respond to their\ninputs. The Mapping Layer allows users to map node output values to MIDI data\nthat is routed to software instruments in a digital audio workstation. By\nshifting between bottom-up and top-down NW shifts between analytic and\nassociative processing modes.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 03:42:08 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 21:07:46 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Bell", "Shawn", ""], ["Gabora", "Liane", ""]]}, {"id": "1610.02478", "submitter": "Liane Gabora", "authors": "Graeme McCaig, Steve DiPaola, and Liane Gabora", "title": "Deep Convolutional Networks as Models of Generalization and Blending\n  Within Visual Creativity", "comments": "8 pages, In Proceedings of the 7th International Conference on\n  Computational Creativity. Palo Alto: Association for the Advancement of\n  Artificial Intelligence (AAAI) Press (2016)", "journal-ref": "In Proceedings of the 7th International Conference on\n  Computational Creativity (pp. 156-163). Palo Alto, CA: Association for the\n  Advancement of Artificial Intelligence (AAAI) Press. (2016)", "doi": null, "report-no": null, "categories": "cs.NE cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine two recent artificial intelligence (AI) based deep learning\nalgorithms for visual blending in convolutional neural networks (Mordvintsev et\nal. 2015, Gatys et al. 2015). To investigate the potential value of these\nalgorithms as tools for computational creativity research, we explain and\nschematize the essential aspects of the algorithms' operation and give visual\nexamples of their output. We discuss the relationship of the two algorithms to\nhuman cognitive science theories of creativity such as conceptual blending\ntheory and honing theory, and characterize the algorithms with respect to\ngeneration of novelty and aesthetic quality.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 04:15:26 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 21:02:30 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["McCaig", "Graeme", ""], ["DiPaola", "Steve", ""], ["Gabora", "Liane", ""]]}, {"id": "1610.02484", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Honing Theory: A Complex Systems Framework for Creativity", "comments": "in press, 79 pages, 7 figures, Nonlinear Dynamics, Psychology, and\n  Life Sciences (2017)", "journal-ref": "Nonlinear Dynamics, Psychology, and Life Sciences, 21(1), 35-88\n  (2017)", "doi": null, "report-no": null, "categories": "q-bio.NC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a theory of creativity, referred to as honing theory,\nwhich posits that creativity fuels the process by which culture evolves through\ncommunal exchange amongst minds that are self-organizing, self-maintaining, and\nself-reproducing. According to honing theory, minds, like other selforganizing\nsystems, modify their contents and adapt to their environments to minimize\nentropy. Creativity begins with detection of high psychological entropy\nmaterial, which provokes uncertainty and is arousalinducing. The creative\nprocess involves recursively considering this material from new contexts until\nit is sufficiently restructured that arousal dissipates. Restructuring involves\nneural synchrony and dynamic binding, and may be facilitated by temporarily\nshifting to a more associative mode of thought. A creative work may similarly\ninduce restructuring in others, and thereby contribute to the cultural\nevolution of more nuanced worldviews. Since lines of cultural descent\nconnecting creative outputs may exhibit little continuity, it is proposed that\ncultural evolution occurs at the level of self-organizing minds, outputs\nreflect their evolutionary state. Honing theory addresses challenges not\naddressed by other theories of creativity, such as the factors that guide\nrestructuring, and in what sense creative works evolve. Evidence comes from\nempirical studies, an agent-based computational model of cultural evolution,\nand a model of concept combination.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 04:40:41 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 20:54:26 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1610.02548", "submitter": "Zhana Kuncheva", "authors": "Zhana Kuncheva, Michelle L. Krishnan and Giovanni Montana", "title": "Exploring brain transcriptomic patterns: a topological analysis using\n  spatial expression networks", "comments": "8 pages, 4 figures, 2 tables, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing the transcriptome architecture of the human brain is\nfundamental in gaining an understanding of brain function and disease. A number\nof recent studies have investigated patterns of brain gene expression obtained\nfrom an extensive anatomical coverage across the entire human brain using\nexperimental data generated by the Allen Human Brain Atlas (AHBA) project. In\nthis paper, we propose a new representation of a gene's transcription activity\nthat explicitly captures the pattern of spatial co-expression across different\nanatomical brain regions. For each gene, we define a Spatial Expression Network\n(SEN), a network quantifying co-expression patterns amongst several anatomical\nlocations. Network similarity measures are then employed to quantify the\ntopological resemblance between pairs of SENs and identify naturally occurring\nclusters. Using network-theoretical measures, three large clusters have been\ndetected featuring distinct topological properties. We then evaluate whether\ntopological diversity of the SENs reflects significant differences in\nbiological function through a gene ontology analysis. We report on evidence\nsuggesting that one of the three SEN clusters consists of genes specifically\ninvolved in the nervous system, including genes related to brain disorders,\nwhile the remaining two clusters are representative of immunity, transcription\nand translation. These findings are consistent with previous studies showing\nthat brain gene clusters are generally associated with one of these three major\nbiological processes.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 15:45:30 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Kuncheva", "Zhana", ""], ["Krishnan", "Michelle L.", ""], ["Montana", "Giovanni", ""]]}, {"id": "1610.03110", "submitter": "Guillaume Hennequin", "authors": "Guillaume Hennequin and M\\'at\\'e Lengyel", "title": "Characterizing variability in nonlinear recurrent neuronal networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we develop semi-analytical techniques to obtain the full\ncorrelational structure of a stochastic network of nonlinear neurons described\nby rate variables. Under the assumption that pairs of membrane potentials are\njointly Gaussian -- which they tend to be in large networks -- we obtain\ndeterministic equations for the temporal evolution of the mean firing rates and\nthe noise covariance matrix that can be solved straightforwardly given the\nnetwork connectivity. We also obtain spike count statistics such as Fano\nfactors and pairwise correlations, assuming doubly-stochastic action potential\nfiring. Importantly, our theory does not require fluctuations to be small, and\nworks for several biologically motivated, convex single-neuron nonlinearities.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 22:05:31 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Hennequin", "Guillaume", ""], ["Lengyel", "M\u00e1t\u00e9", ""]]}, {"id": "1610.03207", "submitter": "Fabian Soto", "authors": "Fabian A. Soto, Emily Zheng, Johnny Fonseca, F. Greg Ashby", "title": "Testing separability and independence of perceptual dimensions with\n  general recognition theory: A tutorial and new R package (grtools)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining whether perceptual properties are processed independently is an\nimportant goal in perceptual science, and tools to test independence should be\nwidely available to experimental researchers. The best analytical tools to test\nfor perceptual independence are provided by General Recognition Theory (GRT), a\nmultidimensional extension of signal detection theory. Unfortunately, there is\ncurrently a lack of software implementing GRT analyses that is ready-to-use by\nexperimental psychologists and neuroscientists with little training in\ncomputational modeling. This paper presents grtools, an R package developed\nwith the explicit aim of providing experimentalists with the ability to perform\nfull GRT analyses using only a couple of command lines. We describe the\nsoftware and provide a practical tutorial on how to perform each of the\nanalyses available in grtools. We also provide advice to researchers on best\npractices for experimental design and interpretation of results.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 06:25:30 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Soto", "Fabian A.", ""], ["Zheng", "Emily", ""], ["Fonseca", "Johnny", ""], ["Ashby", "F. Greg", ""]]}, {"id": "1610.03417", "submitter": "Alessandro Fontana", "authors": "Alessandro Fontana", "title": "Is psychosis caused by defective dissociation? An Artificial Life model\n  for schizophrenia", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both neurobiological and environmental factors are known to play a role in\nthe origin of schizophrenia, but no model has been proposed that accounts for\nboth. This work presents a functional model of schizophrenia that merges\npsychodynamic elements with ingredients borrowed from the theory of\npsychological traumas, and evidences the interplay of traumatic experiences and\ndefective mental functions in the pathogenesis of the disorder. Our model\nforesees that dissociation is a standard tool used by the mind to protect\nitself from emotional pain. In case of repeated traumas, the mind learns to\nadopt selective forms of dissociation to avoid pain without losing touch with\nexternal reality. We conjecture that this process is defective in\nschizophrenia, where dissociation is either too weak, giving rise to positive\nsymptoms, or too strong, causing negative symptoms.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 16:30:36 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 13:01:28 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Fontana", "Alessandro", ""]]}, {"id": "1610.03542", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Clinical and Educational Applications of LIVEIA: An Immersive\n  Visualization Environment", "comments": "5 pages, In Proceedings of International Psychological Applications\n  Conference and Trends (InPACT2016). Lisbon, Portugal: World Institute for\n  Advanced Research and Science (WIARS), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The association between light and psychological states has a long history and\npermeates our language. LIVEIA (Light-based Immersive Visualization Environment\nfor Imaginative Actualization) is a new immersive, interactive technology that\nuses physical light as a metaphor for visualizing peoples' inner lives and\nrelationships. This paper outlines its educational value, as a tool for\nunderstanding and explaining aspects of how people think and interact, and its\npotential therapeutic value as a form of art therapy in which the artwork has\nstraightforwardly interpretable symbolic meanings.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 04:33:58 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 22:31:23 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1610.03627", "submitter": "Stephan Krohn", "authors": "Stephan Krohn and Dirk Ostwald", "title": "Computing Integrated Information", "comments": "Revised version of the original manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrated information theory (IIT) has established itself as one of the\nleading theories for the study of consciousness. IIT essentially proposes that\nquantitative consciousness is identical to maximally integrated conceptual\ninformation, quantified by a measure called $\\Phi^{max}$, and that\nphenomenological experience corresponds to the associated set of maximally\nirreducible cause-effect repertoires of a physical system being in a certain\nstate. However, in order to ultimately apply the theory to experimental data, a\nsufficiently general formulation is needed. With the current work, we provide\nthis general formulation, which comprehensively and parsimoniously expresses\n$\\Phi^{max}$ in the language of probabilistic models. Here, the stochastic\nprocess describing a system under scrutiny corresponds to a first-order\ntime-invariant Markov process, and all necessary mathematical operations for\nthe definition of $\\Phi^{max}$ are fully specified by a system's joint\nprobability distribution over two adjacent points in discrete time. We present\na detailed constructive rule for the decomposition of a system into two\ndisjoint subsystems based on flexible marginalization and factorization of this\njoint distribution. Furthermore, we suspend the approach of interventional\ncalculus based on system perturbations, which allows us to omit undefined\nconditional distributions and virtualization. We validate our formulation in a\npreviously established discrete example system, in which we furthermore address\nthe previously unexplored theoretical issue of quale underdetermination due to\nnon-uniqueness of maximally irreducible cause-effect repertoires, which in turn\nalso entails the sensitivity of $\\Phi^{max}$ to the shape of the conceptual\nstructure in qualia space. In constructive spirit, we propose several\nmodifications of the framework in order to address some of these issues.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 07:47:28 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 11:01:11 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Krohn", "Stephan", ""], ["Ostwald", "Dirk", ""]]}, {"id": "1610.03809", "submitter": "Daniel Moyer", "authors": "Daniel Moyer, Boris A. Gutman, Joshua Faskowitz, Neda Jahanshad, Paul\n  M. Thompson", "title": "A Continuous Model of Cortical Connectivity", "comments": "Accepted at MICCAI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CE q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a continuous model for structural brain connectivity based on the\nPoisson point process. The model treats each streamline curve in a tractography\nas an observed event in connectome space, here a product space of cortical\nwhite matter boundaries. We approximate the model parameter via kernel density\nestimation. To deal with the heavy computational burden, we develop a fast\nparameter estimation method by pre-computing associated Legendre products of\nthe data, leveraging properties of the spherical heat kernel. We show how our\napproach can be used to assess the quality of cortical parcellations with\nrespect to connectivty. We further present empirical results that suggest the\ndiscrete connectomes derived from our model have substantially higher\ntest-retest reliability compared to standard methods.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 18:11:46 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 22:33:37 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Moyer", "Daniel", ""], ["Gutman", "Boris A.", ""], ["Faskowitz", "Joshua", ""], ["Jahanshad", "Neda", ""], ["Thompson", "Paul M.", ""]]}, {"id": "1610.03828", "submitter": "Gabriel Ocker", "authors": "Gabriel Koch Ocker, Kre\\v{s}imir Josi\\'c, Eric Shea-Brown, Michael A.\n  Buice", "title": "Linking structure and activity in nonlinear spiking networks", "comments": "We were recently made aware of an error in this article: in Figure\n  13, we neglected several one-loop contributions to the two-point correlation.\n  For the networks we studied here, these contributions are small (third order\n  in the coupling strength). For further discussion, please see the correction\n  note appended to the end of the article", "journal-ref": "PLoS Computational Biology 2017;13(6):e1005583", "doi": "10.1371/journal.pcbi.1005583", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental advances are producing an avalanche of data on both\nneural connectivity and neural activity. To take full advantage of these two\nemerging datasets we need a framework that links them, revealing how collective\nneural activity arises from the structure of neural connectivity and intrinsic\nneural dynamics. This problem of {\\it structure-driven activity} has drawn\nmajor interest in computational neuroscience. Existing methods for relating\nactivity and architecture in spiking networks rely on linearizing activity\naround a central operating point and thus fail to capture the nonlinear\nresponses of individual neurons that are the hallmark of neural information\nprocessing. Here, we overcome this limitation and present a new relationship\nbetween connectivity and activity in networks of nonlinear spiking neurons by\ndeveloping a diagrammatic fluctuation expansion based on statistical field\ntheory. We explicitly show how recurrent network structure produces pairwise\nand higher-order correlated activity, and how nonlinearities impact the\nnetworks' spiking activity. Our findings open new avenues to investigating how\nsingle-neuron nonlinearities---including those of different cell\ntypes---combine with connectivity to shape population activity and function.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 19:07:45 GMT"}, {"version": "v2", "created": "Fri, 10 Mar 2017 20:09:45 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 23:31:10 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Ocker", "Gabriel Koch", ""], ["Josi\u0107", "Kre\u0161imir", ""], ["Shea-Brown", "Eric", ""], ["Buice", "Michael A.", ""]]}, {"id": "1610.03914", "submitter": "Kiran Vodrahalli", "authors": "Kiran Vodrahalli, Po-Hsuan Chen, Yingyu Liang, Christopher Baldassano,\n  Janice Chen, Esther Yong, Christopher Honey, Uri Hasson, Peter Ramadge, Ken\n  Norman, Sanjeev Arora", "title": "Mapping Between fMRI Responses to Movies and their Natural Language\n  Annotations", "comments": "19 pages, 9 figures, in submission to NeuroImage. Prior version\n  presented at MLINI-2016 workshop, 2016 (arXiv:1701.01437) and ICML 2016\n  Workshop on Multi-view Representation Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several research groups have shown how to correlate fMRI responses to the\nmeanings of presented stimuli. This paper presents new methods for doing so\nwhen only a natural language annotation is available as the description of the\nstimulus. We study fMRI data gathered from subjects watching an episode of BBCs\nSherlock [1], and learn bidirectional mappings between fMRI responses and\nnatural language representations. We show how to leverage data from multiple\nsubjects watching the same movie to improve the accuracy of the mappings,\nallowing us to succeed at a scene classification task with 72% accuracy (random\nguessing would give 4%) and at a scene ranking task with average rank in the\ntop 4% (random guessing would give 50%). The key ingredients are (a) the use of\nthe Shared Response Model (SRM) and its variant SRM-ICA [2, 3] to aggregate\nfMRI data from multiple subjects, both of which are shown to be superior to\nstandard PCA in producing low-dimensional representations for the tasks in this\npaper; (b) a sentence embedding technique adapted from the natural language\nprocessing (NLP) literature [4] that produces semantic vector representation of\nthe annotations; (c) using previous timestep information in the featurization\nof the predictor data.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 02:20:45 GMT"}, {"version": "v2", "created": "Tue, 14 Mar 2017 20:29:41 GMT"}, {"version": "v3", "created": "Mon, 10 Apr 2017 08:41:51 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Vodrahalli", "Kiran", ""], ["Chen", "Po-Hsuan", ""], ["Liang", "Yingyu", ""], ["Baldassano", "Christopher", ""], ["Chen", "Janice", ""], ["Yong", "Esther", ""], ["Honey", "Christopher", ""], ["Hasson", "Uri", ""], ["Ramadge", "Peter", ""], ["Norman", "Ken", ""], ["Arora", "Sanjeev", ""]]}, {"id": "1610.04079", "submitter": "Albert Vilamala", "authors": "Albert Vilamala, Kristoffer Hougaard Madsen and Lars Kai Hansen", "title": "Towards end-to-end optimisation of functional image analysis pipelines", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of neurocognitive tasks requiring accurate localisation of activity\noften rely on functional Magnetic Resonance Imaging, a widely adopted technique\nthat makes use of a pipeline of data processing modules, each involving a\nvariety of parameters. These parameters are frequently set according to the\nlocal goal of each specific module, not accounting for the rest of the\npipeline. Given recent success of neural network research in many different\ndomains, we propose to convert the whole data pipeline into a deep neural\nnetwork, where the parameters involved are jointly optimised by the network to\nbest serve a common global goal. As a proof of concept, we develop a module\nable to adaptively apply the most suitable spatial smoothing to every brain\nvolume for each specific neuroimaging task, and we validate its results in a\nstandard brain decoding experiment.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 13:57:55 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Vilamala", "Albert", ""], ["Madsen", "Kristoffer Hougaard", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1610.04134", "submitter": "John Medaglia", "authors": "John D. Medaglia, Perry Zurn, Walter Sinnott-Armstrong, Danielle S.\n  Bassett", "title": "Mind Control as a Guide for the Mind", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain is a complex network that supports mental function. The\nnascent field of network neuroscience applies tools from mathematics to\nneuroimaging data in the hopes of shedding light on cognitive function. A\ncritical question arising from these empirical studies is how to modulate a\nhuman brain network to treat cognitive deficits or enhance mental abilities.\nWhile historically a number of tools have been employed to modulate mental\nstates (such as cognitive behavioral therapy and brain stimulation),\ntheoretical frameworks to guide these interventions - and to optimize them for\nclinical use - are fundamentally lacking. One promising and as-yet\nunderexplored approach lies in a sub-discipline of engineering known as network\ncontrol theory. Here, we posit that network control fundamentally relates to\nmind control, and that this relationship highlights important areas for future\nempirical research and opportunities to translate knowledge in practical\ndomains. We clarify the conceptual intersection between neuroanatomy,\ncognition, and control engineering in the context of network neuroscience.\nFinally, we discuss the challenges, ethics, and promises of mind control.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 15:42:13 GMT"}, {"version": "v2", "created": "Tue, 25 Apr 2017 17:49:25 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Medaglia", "John D.", ""], ["Zurn", "Perry", ""], ["Sinnott-Armstrong", "Walter", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1610.04201", "submitter": "Joseph Griffis", "authors": "Joseph C. Griffis, Rodolphe Nenert, Jane B. Allendorfer, Jerzy P.\n  Szaflarski", "title": "Parallel ICA reveals linked patterns of structural damage and fMRI\n  language task activation in chronic post-stroke aphasia", "comments": "47 pages; 4 figures; 3 Tables; 3 Supplementary Figures; 2\n  Supplementary Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural and functional MRI studies of patients with post-stroke language\ndeficits have contributed substantially to our understanding of how\ncognitive-behavioral impairments relate to the location of structural damage\nand to the activation of surviving brain regions during language processing,\nrespectively. However, very little is known about how inter-patient variability\nin language task activation relates to variability in the structures affected\nby stroke. Here, we used parallel independent component analysis (pICA) to\ncharacterize links between patterns of structural damage and patterns of\nfunctional MRI activation during semantic decisions. The pICA analysis revealed\na significant association between a lesion component featuring damage to left\nposterior temporo-parietal cortex and the underlying deep white matter and an\nfMRI component featuring (1) heightened activation in a primarily right\nhemispheric network of frontal, temporal, and parietal regions, and (2) reduced\nactivation in areas associated with the semantic network activated by healthy\ncontrols. Stronger loading parameters on both the lesion and fMRI activation\ncomponents were associated with poorer language test performance. Fiber\ntracking suggests that lesions affecting the left posterior temporo-parietal\ncortex and deep white matter may lead to the simultaneous disruption of\nmultiple long-range structural pathways connecting distal language areas.\nDamage to the left posterior temporo-parietal cortex and underlying white\nmatter may (1) impede the language task-driven recruitment of canonical left\nhemispheric language and other areas (e.g. the right anterior temporal lobe and\ndefault mode regions) that likely support residual language function after\nstroke, and (2) lead to the compensatory recruitment of right hemispheric\nfronto-temporo-parietal networks for tasks requiring semantic processing.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 19:02:53 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Griffis", "Joseph C.", ""], ["Nenert", "Rodolphe", ""], ["Allendorfer", "Jane B.", ""], ["Szaflarski", "Jerzy P.", ""]]}, {"id": "1610.04255", "submitter": "Julia Mossbridge", "authors": "Julia Mossbridge", "title": "The Influence of Streamlined Music on Cognition and Mood", "comments": "See data availability and conflict of interest statement", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in sound engineering have led to the development of so-called\nstreamlined music designed to reduce exogenous attention and improve endogenous\nattention. Although anecdotal reports suggest that streamlined music does\nindeed improve focus on daily work tasks and may improve mood, the specific\ninfluences of streamlined music on cognition and mood have yet to be examined.\nIn this paper, we report the results of a series of online experiments that\nexamined the impact of one form of streamlined music on cognition and mood. The\ntested form of streamlined music, which was tested primarily by listeners who\nfelt they benefited from this type of music, significantly outperformed plain\nmusic on measures of perceived focus, task persistence, precognition, and\ncreative thinking, with borderline effects on mood. In contrast, this same form\nof streamlined music did not significantly influence measures assessing visual\nattention, verbal memory, logical thinking, self-efficacy, perceived stress, or\nself-transcendence. We also found that improvements in perceived focus over a\n2-month period were correlated with improvements in emotional state, including\nmood. Overall the results suggest that at least for individuals who enjoy using\nstreamlined music as a focus tool, streamlined music can have a beneficial\nimpact on cognition without any obvious costs, while at the same time it may\npotentially boost mood.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 20:32:37 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Mossbridge", "Julia", ""]]}, {"id": "1610.04258", "submitter": "Kameron Harris", "authors": "Kameron Decker Harris and Tatiana Dashevskiy and Joshua Mendoza and\n  Alfredo J. Garcia III and Jan-Marino Ramirez and Eric Shea-Brown", "title": "Different roles for inhibition in the rhythm-generating respiratory\n  network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unraveling the interplay of excitation and inhibition within\nrhythm-generating networks remains a fundamental issue in neuroscience. We use\na biophysical model to investigate the different roles of local and long-range\ninhibition in the respiratory network, a key component of which is the\npre-B\\\"otzinger complex inspiratory microcircuit. Increasing inhibition within\nthe microcircuit results in a limited number of out-of-phase neurons before\nrhythmicity and synchrony degenerate. Thus, unstructured local inhibition is\ndestabilizing and cannot support the generation of more than one rhythm. A\ntwo-phase rhythm requires restructuring the network into two microcircuits\ncoupled by long-range inhibition in the manner of a half-center. In this\ncontext, inhibition leads to greater stability of the two out-of-phase rhythms.\nWe support our computational results with in vitro recordings from mouse\npre-B\\\"otzinger complex. Partial excitation block leads to increased rhythmic\nvariability, but this recovers following blockade of inhibition. Our results\nsupport the idea that local inhibition in the pre-B\\\"otzinger complex is\npresent to allow for descending control of synchrony or robustness to adverse\nconditions like hypoxia. We conclude that the balance of inhibition and\nexcitation determines the stability of rhythmogenesis, but with opposite roles\nwithin and between areas. These different inhibitory roles may apply to a\nvariety of rhythmic behaviors that emerge in widespread pattern generating\ncircuits of the nervous system.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 20:49:12 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 18:43:32 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Harris", "Kameron Decker", ""], ["Dashevskiy", "Tatiana", ""], ["Mendoza", "Joshua", ""], ["Garcia", "Alfredo J.", "III"], ["Ramirez", "Jan-Marino", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1610.04568", "submitter": "Vince Grolmusz", "authors": "Bal\\'azs Szalkai and Vince Grolmusz", "title": "The Robustness and the Doubly-Preferential Attachment Simulation of the\n  Consensus Connectome Dynamics of the Human Brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing quantity and quality of the publicly available human cerebral\ndiffusion MRI data make possible the study of the brain as it was unimaginable\nbefore. The Consensus Connectome Dynamics (CCD) is a remarkable phenomenon that\nwas discovered by continuously decreasing the minimum confidence-parameter at\nthe graphical interface of the Budapest Reference Connectome Server\n(\\url{http://connectome.pitgroup.org}). The Budapest Reference Connectome\nServer depicts the cerebral connections of $n=418$ subjects with a\nfrequency-parameter $k$: For any $k=1,2,...,n$ one can view the graph of the\nedges that are present in at least $k$ connectomes. If parameter $k$ is\ndecreased one-by-one from $k=n$ through $k=1$ then more and more edges appear\nin the graph, since the inclusion condition is relaxed. The surprising\nobservation is that the appearance of the edges is far from random: it\nresembles a growing, complex structure, like a tree or a shrub (visualized on\n\\url{https://www.youtube.com/watch?v=yxlyudPaVUE}). Here we examine the\nrobustness of the CCD phenomenon, and we show that it is almost independent of\nthe particular choice of the set of underlying individual connectomes, yielding\nthe CCD phenomenon. This result shows that the CCD phenomenon is very likely a\nbiological property of the human brain and not just a property of the data sets\nexamined. We also present a simulation that well-describes the growth of the\nCCD structure: in our random graph model a doubly-preferential attachment\ndistribution is found to mimic the CCD: a new edge appear with a probability\nproportional to the sum of the degrees of the endpoints of the new edge.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 18:18:33 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Szalkai", "Bal\u00e1zs", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1610.04579", "submitter": "Andrew Leifer", "authors": "Jeffrey P. Nguyen, Ashley N. Linder, George S. Plummer, Joshua W.\n  Shaevitz, and Andrew M. Leifer", "title": "Automatically tracking neurons in a moving and deforming brain", "comments": "33 pages, 7 figures, code available", "journal-ref": "PLoS Comput Biol 13(5): e1005517 (2017)", "doi": "10.1371/journal.pcbi.1005517", "report-no": null, "categories": "q-bio.NC cs.CV physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in optical neuroimaging techniques now allow neural activity to be\nrecorded with cellular resolution in awake and behaving animals. Brain motion\nin these recordings pose a unique challenge. The location of individual neurons\nmust be tracked in 3D over time to accurately extract single neuron activity\ntraces. Recordings from small invertebrates like C. elegans are especially\nchallenging because they undergo very large brain motion and deformation during\nanimal movement. Here we present an automated computer vision pipeline to\nreliably track populations of neurons with single neuron resolution in the\nbrain of a freely moving C. elegans undergoing large motion and deformation. 3D\nvolumetric fluorescent images of the animal's brain are straightened, aligned\nand registered, and the locations of neurons in the images are found via\nsegmentation. Each neuron is then assigned an identity using a new\ntime-independent machine-learning approach we call Neuron Registration Vector\nEncoding. In this approach, non-rigid point-set registration is used to match\neach segmented neuron in each volume with a set of reference volumes taken from\nthroughout the recording. The way each neuron matches with the references\ndefines a feature vector which is clustered to assign an identity to each\nneuron in each volume. Finally, thin-plate spline interpolation is used to\ncorrect errors in segmentation and check consistency of assigned identities.\nThe Neuron Registration Vector Encoding approach proposed here is uniquely well\nsuited for tracking neurons in brains undergoing large deformations. When\napplied to whole-brain calcium imaging recordings in freely moving C. elegans,\nthis analysis pipeline located 150 neurons for the duration of an 8 minute\nrecording and consistently found more neurons more quickly than manual or\nsemi-automated approaches.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 18:51:30 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Nguyen", "Jeffrey P.", ""], ["Linder", "Ashley N.", ""], ["Plummer", "George S.", ""], ["Shaevitz", "Joshua W.", ""], ["Leifer", "Andrew M.", ""]]}, {"id": "1610.04844", "submitter": "Alessandro Sanzeni", "authors": "Alessandro Sanzeni, Vijay Balasubramanian, Guido Tiana, Massimo\n  Vergassola", "title": "Complete coverage of space favors modularity of the grid system in the\n  brain", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevE.94.062409", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid cells in the entorhinal cortex fire when animals that are exploring a\ncertain region of space occupy the vertices of a triangular grid that spans the\nenvironment. Different neurons feature triangular grids that differ in their\nproperties of periodicity, orientation and ellipticity. Taken together, these\ngrids allow the animal to maintain an internal, mental representation of\nphysical space. Experiments show that grid cells are modular, i.e. there are\ngroups of neurons which have grids with similar periodicity, orientation and\nellipticity. We use statistical physics methods to derive a relation between\nvariability of the properties of the grids within a module and the range of\nspace that can be covered completely (i.e. without gaps) by the grid system\nwith high probability. Larger variability shrinks the range of representation,\nproviding a functional rationale for the experimentally observed co-modularity\nof grid cell periodicity, orientation and ellipticity. We obtain a scaling\nrelation between the number of neurons and the period of a module, given the\nvariability and coverage range. Specifically, we predict how many more neurons\nare required at smaller grid scales than at larger ones.\n", "versions": [{"version": "v1", "created": "Sun, 16 Oct 2016 11:34:59 GMT"}], "update_date": "2017-01-04", "authors_parsed": [["Sanzeni", "Alessandro", ""], ["Balasubramanian", "Vijay", ""], ["Tiana", "Guido", ""], ["Vergassola", "Massimo", ""]]}, {"id": "1610.04962", "submitter": "Omid Sadat Rezai", "authors": "Omid Rezai, Pinar Boyraz Jentsch, Bryan Tripp", "title": "A Rich Source of Labels for Deep Network Models of the Primate Dorsal\n  Visual Stream", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) have structures that are loosely\nrelated to that of the primate visual cortex. Surprisingly, when these networks\nare trained for object classification, the activity of their early,\nintermediate, and later layers becomes closely related to activity patterns in\ncorresponding parts of the primate ventral visual stream. The activity\nstatistics are far from identical, but perhaps remaining differences can be\nminimized in order to produce artificial networks with highly brain-like\nactivity and performance, which would provide a rich source of insight into\nprimate vision. One way to align CNN activity more closely with neural activity\nis to add cost functions that directly drive deep layers to approximate neural\nrecordings. However, suitably large datasets are particularly difficult to\nobtain for deep structures, such as the primate middle temporal area (MT). To\nwork around this barrier, we have developed a rich empirical model of activity\nin MT. The model is pixel-computable, so it can provide an arbitrarily large\n(but approximate) set of labels to better guide learning in the corresponding\nlayers of deep networks. Our model approximates a number of MT phenomena more\nclosely than previous models. Furthermore, our model approximates population\nstatistics in detail through fourteen parameter distributions that we estimated\nfrom the electrophysiology literature. In general, deep networks with internal\nrepresentations that closely approximate those of the brain may help to clarify\nthe mechanisms that produce these representations, and the roles of various\nproperties of these representations in performance of vision tasks. Although\nour empirical model inevitably differs from real neural activity, it allows\ntuning properties to be modulated independently, which may allow very detailed\nexploration of the origins and functional roles of these properties.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 03:16:58 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Rezai", "Omid", ""], ["Jentsch", "Pinar Boyraz", ""], ["Tripp", "Bryan", ""]]}, {"id": "1610.04967", "submitter": "Amin Behdad", "authors": "Amin Behdad, Amro Nour, Arash Zereshkian, Cesar Marquez Chin and Milos\n  Popovic", "title": "Identification of Intended Arm Movement Using Electrocorticographic\n  Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Brain Computer Interface (BCI) is a communication system that receives\nneurological signals from the brain and translates them into control commands\nfor electrical (e.g., computer mouse) and electromechanical (e.g., Wheelchair)\ndevices. The development of such systems was intended originally to aid\nindividuals with a condition called locked-in syndrome. Individuals with this\ncondition have lost all their voluntary muscle control but remain cognitively\nintact (i.e., mentally aware of their surroundings- can feel emotions,\nrecognize objects/people but are unable to move). This means that they are\ntrapped in their own bodies. The use of BCI may one day improve the\nindependence and quality of life of people with this disability.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 03:49:15 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Behdad", "Amin", ""], ["Nour", "Amro", ""], ["Zereshkian", "Arash", ""], ["Chin", "Cesar Marquez", ""], ["Popovic", "Milos", ""]]}, {"id": "1610.05084", "submitter": "Felix Droste", "authors": "Felix Droste and Benjamin Lindner", "title": "Exact results for power spectrum and susceptibility of a leaky\n  integrate-and-fire neuron with two-state noise", "comments": "27 pages, 5 figures", "journal-ref": "Phys. Rev. E 95, 012411 (2017)", "doi": "10.1103/PhysRevE.95.012411", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The response properties of excitable systems driven by colored noise are of\ngreat interest, but are usually mathematically only accessible via\napproximations. For this reason, dichotomous noise, a rare example of a colored\nnoise leading often to analytically tractable problems, has been extensively\nused in the study of stochastic systems. Here, we calculate exact expressions\nfor the power spectrum and the susceptibility of a leaky integrate-and-fire\nneuron driven by asymmetric dichotomous noise. While our results are in\nexcellent agreement with simulations, they also highlight a limitation of using\ndichotomous noise as a simple model for more complex fluctuations: Both power\nspectrum and susceptibility exhibit an undamped periodic structure, the origin\nof which we discuss in detail.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 12:48:28 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Droste", "Felix", ""], ["Lindner", "Benjamin", ""]]}, {"id": "1610.05561", "submitter": "Ozgur Doruk R", "authors": "R.Ozgur Doruk and Kechen Zhang", "title": "Adaptive stimulus design for dynamic recurrent neural network models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a theoretical application of an optimal experiment design (OED)\nmethodology to the development of mathematical models to describe the\nstimulus-response relationship of sensory neurons. Although there are a few\nrelated studies in the computational neuroscience literature on this topic,\nmost of them are either involving non-linear static maps or simple linear\nfilters cascaded to a static non-linearity. Although the linear filters might\nbe appropriate to demonstrate some aspects of neural processes, the high level\nof non-linearity in the nature of the stimulus-response data may render them\ninadequate. In addition, modelling by a static non-linear input - output map\nmay mask important dynamical (time-dependent) features in the response data.\nDue to all those facts a non-linear continuous time dynamic recurrent neural\nnetwork that models the excitatory and inhibitory membrane potential dynamics\nis preferred. The main goal of this research is to estimate the parametric\ndetails of this model from the available stimulus-response data. In order to\ndesign an efficient estimator an optimal experiment design scheme is proposed\nwhich computes a pre-shaped stimulus to maximize a certain measure of Fisher\nInformation Matrix. This measure depends on the estimated values of the\nparameters in the current step and the optimal stimuli are used in a maximum\nlikelihood estimation procedure to find an estimate of the network parameters.\nThis process works as a loop until a reasonable convergence occurs. The\nresponse data is discontinuous as it is composed of the neural spiking instants\nwhich is assumed to obey the Poisson statistical distribution. Thus the\nlikelihood functions depend on the Poisson statistics. In order to validate the\napproach and evaluate its performance, a comparison with another approach on\nestimation based on randomly generated stimuli is also presented.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 12:20:01 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Doruk", "R. Ozgur", ""], ["Zhang", "Kechen", ""]]}, {"id": "1610.05564", "submitter": "Laurent Perrinet", "authors": "Laurent Perrinet (INT), Rick Adams, Karl Friston", "title": "Active inference, eye movements and oculomotor delays", "comments": null, "journal-ref": "Biological Cybernetics (Modeling), Springer Verlag, 2014, 106 (8),\n  pp.777-801", "doi": "10.1007/s00422-014-0620-8", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of sensorimotor delays in the optimal\ncontrol of (smooth) eye movements under uncertainty. Specifically, we consider\ndelays in the visuo-oculomotor loop and their implications for active\ninference. Active inference uses a generalisation of Kalman filtering to\nprovide Bayes optimal estimates of hidden states and action in generalized\ncoordinates of motion. Representing hidden states in generalized coordinates\nprovides a simple way of compensating for both sensory and oculomotor delays.\nThe efficacy of this scheme is illustrated using neuronal simulations of\npursuit initiation responses, with and without compensation. We then consider\nan extension of the gener-ative model to simulate smooth pursuit eye movements\n- in which the visuo-oculomotor system believes both the target and its centre\nof gaze are attracted to a (hidden) point moving in the visual field. Finally,\nthe generative model is equipped with a hierarchical structure, so that it can\nrecognise and remember unseen (occluded) trajectories and emit anticipatory\nresponses. These simulations speak to a straightforward and neurobiologically\nplausible solution to the generic problem of integrating information from\ndifferent sources with different temporal delays and the particular\ndifficulties encountered when a system - like the oculomotor system - tries to\ncontrol its environment with delayed signals.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 12:25:00 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Perrinet", "Laurent", "", "INT"], ["Adams", "Rick", ""], ["Friston", "Karl", ""]]}, {"id": "1610.05654", "submitter": "Ramon Ferrer i Cancho", "authors": "Antoni Hern\\'andez-Fern\\'andez and Ramon Ferrer-i-Cancho", "title": "The infochemical core", "comments": "Little corrections of format and language", "journal-ref": "Journal of Quantitative Linguistics 23 (2), 133-153 (2016)", "doi": "10.1080/09296174.2016.1142323", "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vocalizations and less often gestures have been the object of linguistic\nresearch over decades. However, the development of a general theory of\ncommunication with human language as a particular case requires a clear\nunderstanding of the organization of communication through other means.\nInfochemicals are chemical compounds that carry information and are employed by\nsmall organisms that cannot emit acoustic signals of optimal frequency to\nachieve successful communication. Here the distribution of infochemicals across\nspecies is investigated when they are ranked by their degree or the number of\nspecies with which it is associated (because they produce or they are sensitive\nto it). The quality of the fit of different functions to the dependency between\ndegree and rank is evaluated with a penalty for the number of parameters of the\nfunction. Surprisingly, a double Zipf (a Zipf distribution with two regimes\nwith a different exponent each) is the model yielding the best fit although it\nis the function with the largest number of parameters. This suggests that the\nworld wide repertoire of infochemicals contains a chemical nucleus shared by\nmany species and reminiscent of the core vocabularies found for human language\nin dictionaries or large corpora.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 14:53:20 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2016 11:22:52 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Hern\u00e1ndez-Fern\u00e1ndez", "Antoni", ""], ["Ferrer-i-Cancho", "Ramon", ""]]}, {"id": "1610.05717", "submitter": "Chun-Chung Chen", "authors": "Chih-Hsu Huang, Yu-Ting Huang, Chun-Chung Chen, C.K. Chan", "title": "Propagation and synchronization of reverberatory bursts in developing\n  cultured networks", "comments": "10 pages, 8 figures", "journal-ref": "J Comput Neurosci (2017) 42: 177", "doi": "10.1007/s10827-016-0634-4", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing networks of neural systems can exhibit spontaneous, synchronous\nactivities called neural bursts, which can be important in the organization of\nfunctional neural circuits. Before the network matures, the activity level of a\nburst can reverberate in repeated rise-and-falls in periods of hundreds of\nmilliseconds following an initial wave-like propagation of spiking activity,\nwhile the burst itself lasts for seconds. To investigate the spatiotemporal\nstructure of the reverberatory bursts, we culture dissociated, rat cortical\nneurons on a high-density multi-electrode array to record the dynamics of\nneural activity over the growth and maturation of the network. We find the\nsynchrony of the spiking significantly reduced following the initial wave and\nthe activities become broadly distributed spatially. The synchrony recovers as\nthe system reverberates until the end of the burst. Using a propagation model\nwe infer the spreading speed of the spiking activity, which increases as the\nculture ages. We perform computer simulations of the system using a\nphysiological model of spiking networks in two spatial dimensions and find the\nparameters that reproduce the observed resynchronization of spiking in the\nbursts. An analysis of the simulated dynamics suggests that the depletion of\nsynaptic resources causes the resynchronization. The spatial propagation\ndynamics of the simulations match well with observations over the course of a\nburst and point to an interplay of the synaptic efficacy and the noisy neural\nself-activation in producing the morphology of the bursts.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 17:42:34 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Huang", "Chih-Hsu", ""], ["Huang", "Yu-Ting", ""], ["Chen", "Chun-Chung", ""], ["Chan", "C. K.", ""]]}, {"id": "1610.05872", "submitter": "Sergey Stavisky", "authors": "David Sussillo, Sergey D. Stavisky, Jonathan C. Kao, Stephen I. Ryu,\n  Krishna V. Shenoy", "title": "Making brain-machine interfaces robust to future neural variability", "comments": "D.S., S.D.S., and J.C.K. contributed equally to this work", "journal-ref": "Nature Communications. 7:13749 (2016)", "doi": "10.1038/ncomms13749", "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major hurdle to clinical translation of brain-machine interfaces (BMIs) is\nthat current decoders, which are trained from a small quantity of recent data,\nbecome ineffective when neural recording conditions subsequently change. We\ntested whether a decoder could be made more robust to future neural variability\nby training it to handle a variety of recording conditions sampled from months\nof previously collected data as well as synthetic training data perturbations.\nWe developed a new multiplicative recurrent neural network BMI decoder that\nsuccessfully learned a large variety of neural-to- kinematic mappings and\nbecame more robust with larger training datasets. When tested with a non-human\nprimate preclinical BMI model, this decoder was robust under conditions that\ndisabled a state-of-the-art Kalman filter based decoder. These results validate\na new BMI strategy in which accumulated data history is effectively harnessed,\nand may facilitate reliable daily BMI use by reducing decoder retraining\ndowntime.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 05:32:32 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Sussillo", "David", ""], ["Stavisky", "Sergey D.", ""], ["Kao", "Jonathan C.", ""], ["Ryu", "Stephen I.", ""], ["Shenoy", "Krishna V.", ""]]}, {"id": "1610.05982", "submitter": "Lars Rothkegel", "authors": "Lars Oliver Martin Rothkegel, Hans Arne Trukenbrod, Heiko Herbert\n  Sch\\\"utt, Felix Alexander Wichmann, Ralf Engbert", "title": "The temporal evolution of the central fixation bias in scene viewing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When watching the image of a natural scene on a computer screen, observers\ninitially move their eyes towards the center of the image --- a reliable\nexperimental finding termed central fixation bias. This systematic tendency in\neye guidance likely masks attentional selection driven by image properties and\ntop-down cognitive processes. Here we show that the central fixation bias can\nbe reduced by delaying the initial saccade relative to image onset. In four\nscene-viewing experiments we manipulated observers' initial gaze position and\ndelayed their first saccade by a specific time interval relative to the onset\nof an image. We analyzed the distance to image center over time and show that\nthe central fixation bias of initial fixations was significantly reduced after\ndelayed saccade onsets. We additionally show that selection of the initial\nsaccade target strongly depended on the first saccade latency. Processes\ninfluencing the time course of the central fixation bias were investigated by\ncomparing simulations of several dynamic and statistical models. Model\ncomparisons suggest that the central fixation bias is generated by a default\nactivation as a response to the sudden image onset and that this default\nactivation pattern decreases over time. Our results suggest that it may often\nbe preferable to use a modified version of the scene viewing paradigm that\ndecouples image onset from the start signal for scene exploration and\nexplicitly controls the central fixation bias. In general, the initial fixation\nlocation and the latency of the first saccade need to be taken into\nconsideration when investigating eye movements during scene viewing.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 12:27:30 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 13:06:38 GMT"}, {"version": "v3", "created": "Wed, 21 Jun 2017 07:58:06 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Rothkegel", "Lars Oliver Martin", ""], ["Trukenbrod", "Hans Arne", ""], ["Sch\u00fctt", "Heiko Herbert", ""], ["Wichmann", "Felix Alexander", ""], ["Engbert", "Ralf", ""]]}, {"id": "1610.06360", "submitter": "Keith Smith", "authors": "Keith Smith, Daniel Abasalo and Javier Escudero", "title": "Accounting for the Complex Hierarchical Topology of EEG Phase-Based\n  Functional Connectivity in Network Binarisation", "comments": "Accepted for publication in PLOS One, 27th September 2017", "journal-ref": "PLoS ONE12(10): e0186164 (2017)", "doi": "10.1371/journal.pone.0186164", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research into binary network analysis of brain function faces a\nmethodological challenge in selecting an appropriate threshold to binarise edge\nweights. For EEG phase-based functional connectivity, we test the hypothesis\nthat such binarisation should take into account the complex hierarchical\nstructure found in functional connectivity. We explore the density range\nsuitable for such structure and provide a comparison of state-of-the-art\nbinarisation techniques, the recently proposed Cluster-Span Threshold (CST),\nminimum spanning trees, efficiency-cost optimisation and union of shortest path\ngraphs, with arbitrary proportional thresholds and weighted networks. We test\nthese techniques on weighted complex hierarchy models by contrasting model\nrealisations with small parametric differences. We also test the robustness of\nthese techniques to random and targeted topological attacks.We find that the\nCST performs consistenty well in state-of-the-art modelling of EEG network\ntopology, robustness to topological network attacks, and in three real\ndatasets, agreeing with our hypothesis of hierarchical complexity. This\nprovides interesting new evidence into the relevance of considering a large\nnumber of edges in EEG functional connectivity research to provide\ninformational density in the topology.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 11:19:02 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 12:01:19 GMT"}, {"version": "v3", "created": "Fri, 29 Sep 2017 13:42:05 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Smith", "Keith", ""], ["Abasalo", "Daniel", ""], ["Escudero", "Javier", ""]]}, {"id": "1610.06421", "submitter": "Hao Dong", "authors": "Hao Dong, Akara Supratak, Wei Pan, Chao Wu, Paul M. Matthews and Yike\n  Guo", "title": "Mixed Neural Network Approach for Temporal Sleep Stage Classification", "comments": "THIS ARTICLE HAS BEEN PUBLISHED IN IEEE TRANSACTIONS ON NEURAL\n  SYSTEMS AND REHABILITATION ENGINEERING", "journal-ref": null, "doi": "10.1109/TNSRE.2017.2733220", "report-no": null, "categories": "q-bio.NC cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a practical approach to addressing limitations posed by\nuse of single active electrodes in applications for sleep stage classification.\nElectroencephalography (EEG)-based characterizations of sleep stage progression\ncontribute the diagnosis and monitoring of the many pathologies of sleep.\nSeveral prior reports have explored ways of automating the analysis of sleep\nEEG and of reducing the complexity of the data needed for reliable\ndiscrimination of sleep stages in order to make it possible to perform sleep\nstudies at lower cost in the home (rather than only in specialized clinical\nfacilities). However, these reports have involved recordings from electrodes\nplaced on the cranial vertex or occiput, which can be uncomfortable or\ndifficult for subjects to position. Those that have utilized single EEG\nchannels which contain less sleep information, have showed poor classification\nperformance. We have taken advantage of Rectifier Neural Network for feature\ndetection and Long Short-Term Memory (LSTM) network for sequential data\nlearning to optimize classification performance with single electrode\nrecordings. After exploring alternative electrode placements, we found a\ncomfortable configuration of a single-channel EEG on the forehead and have\nshown that it can be integrated with additional electrodes for simultaneous\nrecording of the electroocuolgram (EOG). Evaluation of data from 62 people\n(with 494 hours sleep) demonstrated better performance of our analytical\nalgorithm for automated sleep classification than existing approaches using\nvertex or occipital electrode placements. Use of this recording configuration\nwith neural network deconvolution promises to make clinically indicated home\nsleep studies practical.\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2016 18:48:00 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 17:39:53 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 15:00:48 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Dong", "Hao", ""], ["Supratak", "Akara", ""], ["Pan", "Wei", ""], ["Wu", "Chao", ""], ["Matthews", "Paul M.", ""], ["Guo", "Yike", ""]]}, {"id": "1610.06598", "submitter": "Andrea Barreiro", "authors": "Andrea K. Barreiro and Cheng Ly", "title": "When do Correlations Increase with Firing Rate?", "comments": "Previous title: \"Low-Rank Correlations in Heterogeneous Neural\n  Circuits\"", "journal-ref": "PLoS Comput Biol 13(4): e1005506, 2017", "doi": "10.1371/journal.pcbi.1005506", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central question in neuroscience is to understand how noisy firing patterns\nare used to transmit information. Because neural spiking is noisy, spiking\npatterns are often quantified via pairwise correlations, or the probability\nthat two cells will spike coincidentally, above and beyond their baseline\nfiring rate. One observation frequently made in experiments, is that\ncorrelations can increase systematically with firing rate. Theoretical studies\nhave determined that stimulus-dependent correlations that increase with firing\nrate can have beneficial effects on information coding; however, we still have\nan incomplete understanding of what circuit mechanisms do, or do not, produce\nthis correlation-firing rate relationship.\n  Here, we study the relationship between pairwise correlations and firing\nrates in recurrently coupled excitatory-inhibitory spiking networks with\nconductance-based synapses. We found that with stronger excitatory coupling, a\npositive relationship emerges between pairwise correlations and firing rates.\nTo explain these findings, we used linear response theory to predict the full\ncorrelation matrix and to decompose correlations in terms of graph motifs. We\nthen used this decomposition to explain why covariation of correlations with\nfiring rate -- a relationship previously explained in feedforward networks\ndriven by correlated input -- emerges in some recurrent networks but not in\nothers. Furthermore, when correlations covary with firing rate, this\nrelationship is reflected in low-rank structure in the correlation matrix.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 20:32:19 GMT"}, {"version": "v2", "created": "Thu, 26 Jan 2017 20:02:55 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Barreiro", "Andrea K.", ""], ["Ly", "Cheng", ""]]}, {"id": "1610.06762", "submitter": "Roos Jutten", "authors": "Roos J. Jutten, Carel F.W. Peeters, Sophie M. J. Leijdesdorff, Pieter\n  Jelle Visser, Andrea B. Maier, Caroline B. Terwee, Philip Scheltens, Sietske\n  A. M. Sikkes", "title": "Detecting functional decline from normal ageing to dementia: development\n  and validation of a short version of the Amsterdam IADL Questionnaire", "comments": "14 pages, 3 tables, 4 figures", "journal-ref": "Alzheimer's & Dementia: Diagnosis, Assessment & Disease\n  Monitoring, 8 (2017): 26-35", "doi": "10.1016/j.dadm.2017.03.002", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  INTRODUCTION: Detecting functional decline from normal ageing to dementia is\nrelevant for diagnostic and prognostic purposes. Therefore, the Amsterdam IADL\nQuestionnaire (A-IADL-Q) was developed: a 70-item proxy-based tool with good\npsychometric properties. We aimed to design a short version whilst preserving\nits psychometric quality. METHODS: Study partners of subjects (n=1355), ranging\nfrom cognitively normal to dementia subjects, completed the original A-IADL-Q.\nWe selected the short version items using a stepwise procedure combining\nmissing data, Item Response Theory and input from respondents and experts. We\ninvestigated internal consistency of the short version as well as concordance\nwith the original version. To assess its construct validity, we additionally\ninvestigated concordance between the short version and the Mini-Mental State\nExamination (MMSE) and Disability Assessment for Dementia (DAD). Lastly, we\ninvestigated differences in IADL scores between diagnostic groups across the\ndementia spectrum. RESULTS: We selected 30 items covering the entire spectrum\nof IADL functioning. Internal consistency (.98) and concordance with the\noriginal version (.97) were very high. Concordance with the MMSE (.72) and DAD\n(.87) scores was high. IADL impairment scores increased across the spectrum\nfrom normal cognition to dementia. DISCUSSION: The A-IADL-Q Short Version\n(A-IADL-Q-SV) consists of 30 items. The A-IADL-Q-SV has maintained the\npsychometric quality of the original A-IADL-Q. As such, it is a concise measure\nof functional decline.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 12:37:12 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 10:47:33 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Jutten", "Roos J.", ""], ["Peeters", "Carel F. W.", ""], ["Leijdesdorff", "Sophie M. J.", ""], ["Visser", "Pieter Jelle", ""], ["Maier", "Andrea B.", ""], ["Terwee", "Caroline B.", ""], ["Scheltens", "Philip", ""], ["Sikkes", "Sietske A. M.", ""]]}, {"id": "1610.06886", "submitter": "Adrianna Loback", "authors": "Adrianna R. Loback, Jason S. Prentice, Mark L. Ioffe, Michael J. Berry\n  II", "title": "Noise-Robust Modes of the Retinal Population Code have the Geometry of\n  \"Ridges\" and Correspond with Neuronal Communities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An appealing new principle for neural population codes is that correlations\namong neurons organize neural activity patterns into a discrete set of\nclusters, which can each be viewed as a noise-robust population \"codeword\".\nPrevious studies assumed that these codewords corresponded geometrically with\nlocal peaks in the probability landscape of neural population responses. Here,\nwe analyze multiple datasets of the responses of ~150 retinal ganglion cells\nand show that local probability peaks are absent under broad, non-repeated\nstimulus ensembles, which are characteristic of natural behavior. However, we\nfind that neural activity still forms noise-robust clusters in this regime,\nalbeit clusters with a different geometry. We start by defining a soft local\nmaximum, which is a local probability maximum when constrained to a fixed spike\ncount. Next, we show that soft local maxima are robustly present, and can\nmoreover be linked across different spike count levels in the probability\nlandscape to form a \"ridge\". We found that these ridges are comprised of\ncombinations of spiking and silence in the neural population such that all of\nthe spiking neurons are members of the same neuronal community, a notion from\nnetwork theory. We argue that a neuronal community shares many of the\nproperties of Donald Hebb's classic cell assembly, and show that a simple,\nbiologically plausible decoding algorithm can recognize the presence of a\nspecific neuronal community.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 18:25:36 GMT"}, {"version": "v2", "created": "Sun, 12 Mar 2017 15:56:11 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Loback", "Adrianna R.", ""], ["Prentice", "Jason S.", ""], ["Ioffe", "Mark L.", ""], ["Berry", "Michael J.", "II"]]}, {"id": "1610.07161", "submitter": "Mihai Alexandru Petrovici", "authors": "Mihai A. Petrovici, Johannes Bill, Ilja Bytschok, Johannes Schemmel,\n  Karlheinz Meier", "title": "Stochastic inference with spiking neurons in the high-conductance state", "comments": null, "journal-ref": "Phys. Rev. E 94, 042312 (2016)", "doi": "10.1103/PhysRevE.94.042312", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE physics.bio-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The highly variable dynamics of neocortical circuits observed in vivo have\nbeen hypothesized to represent a signature of ongoing stochastic inference but\nstand in apparent contrast to the deterministic response of neurons measured in\nvitro. Based on a propagation of the membrane autocorrelation across spike\nbursts, we provide an analytical derivation of the neural activation function\nthat holds for a large parameter space, including the high-conductance state.\nOn this basis, we show how an ensemble of leaky integrate-and-fire neurons with\nconductance-based synapses embedded in a spiking environment can attain the\ncorrect firing statistics for sampling from a well-defined target distribution.\nFor recurrent networks, we examine convergence toward stationarity in computer\nsimulations and demonstrate sample-based Bayesian inference in a mixed\ngraphical model. This points to a new computational role of high-conductance\nstates and establishes a rigorous link between deterministic neuron models and\nfunctional stochastic dynamics on the network level.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 12:27:05 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Petrovici", "Mihai A.", ""], ["Bill", "Johannes", ""], ["Bytschok", "Ilja", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1610.07181", "submitter": "Alessandro Torcini Dr", "authors": "David Angulo-Garcia, Stefano Luccioli, Simona Olmi, Alessandro Torcini", "title": "Death and rebirth of neural activity in sparse inhibitory networks", "comments": "19 pages, 10 figures, submitted to NJP", "journal-ref": "New Journal of Physics, 19 053011 (2017)", "doi": "10.1088/1367-2630/aa69ff", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we clarify the mechanisms underlying a general phenomenon\npresent in pulse-coupled heterogeneous inhibitory networks: inhibition can\ninduce not only suppression of the neural activity, as expected, but it can\nalso promote neural reactivation. In particular, for globally coupled systems,\nthe number of firing neurons monotonically reduces upon increasing the strength\nof inhibition (neurons' death). However, the random pruning of the connections\nis able to reverse the action of inhibition, i.e. in a sparse network a\nsufficiently strong synaptic strength can surprisingly promote, rather than\ndepress, the activity of the neurons (neurons' rebirth). Thus the number of\nfiring neurons reveals a minimum at some intermediate synaptic strength. We\nshow that this minimum signals a transition from a regime dominated by the\nneurons with higher firing activity to a phase where all neurons are\neffectively sub-threshold and their irregular firing is driven by current\nfluctuations. We explain the origin of the transition by deriving an analytic\nmean field formulation of the problem able to provide the fraction of active\nneurons as well as the first two moments of their firing statistics. The\nintroduction of a synaptic time scale does not modify the main aspects of the\nreported phenomenon. However, for sufficiently slow synapses the transition\nbecomes dramatic, the system passes from a perfectly regular evolution to an\nirregular bursting dynamics. In this latter regime the model provides\npredictions consistent with experimental findings for a specific class of\nneurons, namely the medium spiny neurons in the striatum.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 14:51:53 GMT"}, {"version": "v2", "created": "Sun, 12 Mar 2017 15:12:08 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Angulo-Garcia", "David", ""], ["Luccioli", "Stefano", ""], ["Olmi", "Simona", ""], ["Torcini", "Alessandro", ""]]}, {"id": "1610.07355", "submitter": "Timoth\\'ee Masquelier Dr", "authors": "Timoth\\'ee Masquelier", "title": "STDP allows close-to-optimal spatiotemporal spike pattern detection by\n  single coincidence detector neurons", "comments": "12 pages, 6 figures, 1 table", "journal-ref": "Neuroscience 2017", "doi": "10.1016/j.neuroscience.2017.06.032", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By recording multiple cells simultaneously, electrophysiologists have found\nevidence for repeating spatiotemporal spike patterns, which can carry\ninformation. How this information is extracted by downstream neurons is\nunclear. In this theoretical paper, we investigate to what extent a single cell\ncould detect a given spike pattern and what the optimal parameters to do so\nare, in particular the membrane time constant $\\tau$. Using a leaky\nintegrate-and-fire (LIF) neuron with instantaneous synapses and homogeneous\nPoisson input, we were able to compute this optimum analytically. Our results\nindicate that a relatively small $\\tau$ (at most a few tens of ms) is usually\noptimal, even when the pattern is much longer. This is somewhat counter\nintuitive as the resulting detector ignores most of the pattern, due to its\nfast memory decay. Next, we wondered if spike-timing-dependent plasticity\n(STDP) could enable a neuron to reach the theoretical optimum. We simulated a\nLIF neuron equipped with additive spike-timing-dependent potentiation and\nhomeostatic rate-based depression, and repeatedly exposed it to a given input\nspike pattern. As in previous studies, the LIF progressively became selective\nto the repeating pattern with no supervision, even when the pattern was\nembedded in Poisson activity. Here we show that, using certain STDP parameters,\nthe resulting pattern detector can be optimal. Taken together, these results\nmay explain how humans can learn repeating visual or auditory sequences. Long\nsequences could be recognized thanks to coincidence detectors working at a much\nshorter timescale. This is consistent with the fact that recognition is still\npossible if a sound sequence is compressed, played backward, or scrambled using\n10ms bins. Coincidence detection is a simple yet powerful mechanism, which\ncould be the main function of neurons in the brain.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 10:54:28 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2017 12:12:00 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Masquelier", "Timoth\u00e9e", ""]]}, {"id": "1610.07769", "submitter": "Yi-Xiang Wang", "authors": "Yao T Li, Huang Hua, Zhizheng Zhang, Puxuan Lu, Weitian Chen, Yixiang\n  J Wang", "title": "Bi-phase age-related brain gray matter magnetic resonance T1rho\n  relaxation time change", "comments": "total 31 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objectives: To investigate normative value and age-related change of brain\nmagnetic resonance T1rho relaxation at 1.5 T. Methods: 20 males (age:\n40.7+/-15.5 years, range: 22-68 years) and 22 females (age: 38.5 +/-14.8 years,\nrange: 21-62 years), were scanned at 1.5 Tesla using 3D fluid suppressed turbo\nspin echo sequence. Regions-of-interests (ROIs) were obtained by atlas-based\ntissue segmentation and T1rho was calculated by fitting the mean value to\nmonoexponential model. Correlation between T1rho relaxation of brain gray\nmatter regions and age was investigated. Results: A regional difference among\nindividual gray matter areas was noted; with hippocampus (98.37+/-5.37 msec)\nand amygdala (94.95+/-4.34 msec) have the highest measurement, while pallidum\n(83.81+/-5.49) and putamen (83.93+4.76) the lowest measurement. T1rho values\ndecreased slowly (mean slope: -0.256) and significantly (p<0.05) with age in\ngray matter for subjects younger than 40 years old, while for subjects older\nthan 40 years old there was no significant correlation between T1rho relaxation\nand age. Conclusion: T1rho relaxation demonstrates a bi-phase change with age\nin adults of 22-68 years.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 07:53:04 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Li", "Yao T", ""], ["Hua", "Huang", ""], ["Zhang", "Zhizheng", ""], ["Lu", "Puxuan", ""], ["Chen", "Weitian", ""], ["Wang", "Yixiang J", ""]]}, {"id": "1610.07986", "submitter": "Thomas Kreuz", "authors": "Thomas Kreuz, Eero Satuvuori, Martin Pofahl, Mario Mulansky", "title": "Leaders and followers: Quantifying consistency in spatio-temporal\n  propagation patterns", "comments": "18 pages; 18 figures; revised version", "journal-ref": null, "doi": "10.1088/1367-2630/aa68c3", "report-no": null, "categories": "physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repetitive spatio-temporal propagation patterns are encountered in fields as\nwide-ranging as climatology, social communication and network science. In\nneuroscience, perfectly consistent repetitions of the same global propagation\npattern are called a synfire pattern. For any recording of sequences of\ndiscrete events (in neuroscience terminology: sets of spike trains) the\nquestions arise how closely it resembles such a synfire pattern and which are\nthe spike trains that lead/follow. Here we address these questions and\nintroduce an algorithm built on two new indicators, termed SPIKE-Order and\nSpike Train Order, that define the Synfire Indicator value, which allows to\nsort multiple spike trains from leader to follower and to quantify the\nconsistency of the temporal leader-follower relationships for both the original\nand the optimized sorting. We demonstrate our new approach using artificially\ngenerated datasets before we apply it to analyze the consistency of propagation\npatterns in two real datasets from neuroscience (Giant Depolarized Potentials\nin mice slices) and climatology (El Ni~no sea surface temperature recordings).\nThe new algorithm is distinguished by conceptual and practical simplicity, low\ncomputational cost, as well as flexibility and universality.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 17:51:23 GMT"}, {"version": "v2", "created": "Wed, 26 Oct 2016 08:24:50 GMT"}, {"version": "v3", "created": "Mon, 13 Feb 2017 21:36:09 GMT"}, {"version": "v4", "created": "Wed, 22 Mar 2017 15:26:05 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Kreuz", "Thomas", ""], ["Satuvuori", "Eero", ""], ["Pofahl", "Martin", ""], ["Mulansky", "Mario", ""]]}, {"id": "1610.08192", "submitter": "Richard Spinney", "authors": "Richard E. Spinney, Mikhail Prokopenko, Joseph T. Lizier", "title": "Transfer entropy in continuous time, with applications to jump and\n  neural spiking processes", "comments": "24 pages, 2 figures", "journal-ref": "Phys. Rev. E 95, 032319 (2017)", "doi": "10.1103/PhysRevE.95.032319", "report-no": null, "categories": "cs.IT math.IT nlin.AO physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer entropy has been used to quantify the directed flow of information\nbetween source and target variables in many complex systems. While transfer\nentropy was originally formulated in discrete time, in this paper we provide a\nframework for considering transfer entropy in continuous time systems, based on\nRadon-Nikodym derivatives between measures of complete path realizations. To\ndescribe the information dynamics of individual path realizations, we introduce\nthe pathwise transfer entropy, the expectation of which is the transfer entropy\naccumulated over a finite time interval. We demonstrate that this formalism\npermits an instantaneous transfer entropy rate. These properties are analogous\nto the behavior of physical quantities defined along paths such as work and\nheat. We use this approach to produce an explicit form for the transfer entropy\nfor pure jump processes, and highlight the simplified form in the specific case\nof point processes (frequently used in neuroscience to model neural spike\ntrains). Finally, we present two synthetic spiking neuron model examples to\nexhibit the pertinent features of our formalism, namely, that the information\nflow for point processes consists of discontinuous jump contributions (at\nspikes in the target) interrupting a continuously varying contribution\n(relating to waiting times between target spikes). Numerical schemes based on\nour formalism promise significant benefits over existing strategies based on\ndiscrete time formalisms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 06:23:11 GMT"}, {"version": "v2", "created": "Sat, 1 Apr 2017 14:06:50 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Spinney", "Richard E.", ""], ["Prokopenko", "Mikhail", ""], ["Lizier", "Joseph T.", ""]]}, {"id": "1610.08465", "submitter": "Scott Linderman", "authors": "Scott W. Linderman, Ryan P. Adams, and Jonathan W. Pillow", "title": "Bayesian latent structure discovery from multi-neuron recordings", "comments": "11 pages, 5 figures, to appear in Advances in Neural Information\n  Processing Systems 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural circuits contain heterogeneous groups of neurons that differ in type,\nlocation, connectivity, and basic response properties. However, traditional\nmethods for dimensionality reduction and clustering are ill-suited to\nrecovering the structure underlying the organization of neural circuits. In\nparticular, they do not take advantage of the rich temporal dependencies in\nmulti-neuron recordings and fail to account for the noise in neural spike\ntrains. Here we describe new tools for inferring latent structure from\nsimultaneously recorded spike train data using a hierarchical extension of a\nmulti-neuron point process model commonly known as the generalized linear model\n(GLM). Our approach combines the GLM with flexible graph-theoretic priors\ngoverning the relationship between latent features and neural connectivity\npatterns. Fully Bayesian inference via P\\'olya-gamma augmentation of the\nresulting model allows us to classify neurons and infer latent dimensions of\ncircuit organization from correlated spike trains. We demonstrate the\neffectiveness of our method with applications to synthetic data and\nmulti-neuron recordings in primate retina, revealing latent patterns of neural\ntypes and locations from spike trains alone.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 19:07:59 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Linderman", "Scott W.", ""], ["Adams", "Ryan P.", ""], ["Pillow", "Jonathan W.", ""]]}, {"id": "1610.08566", "submitter": "Nat\\'alia Mota Msr", "authors": "Natalia B. Mota, Mauro Copelli, Sidarta Ribeiro", "title": "Quantifying word salad: The structural randomness of verbal reports\n  predicts negative symptoms and Schizophrenia diagnosis 6 months later", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The precise quantification of negative symptoms is necessary to\nimprove differential diagnosis and prognosis prediction in Schizophrenia. In\nchronic psychotic patients, the representation of verbal reports as word graphs\nprovides automated sorting of schizophrenia, bipolar disorder and control\ngroups based on the degree of speech connectedness. Here we aim to use machine\nlearning to verify whether speech connectedness during first clinical contact\ncan predict negative symptoms and Schizophrenia diagnosis six months later.\nMethods: PANSS scores and memory reports were collected from 21 patients\nundergoing first clinical contact for recent-onset psychosis and followed for 6\nmonths to establish DSM-IV diagnosis, and 21 healthy controls. Each report was\nrepresented as a graph in which words corresponded to nodes, and node temporal\nsuccession corresponded to edges. Three connectedness attributes were extracted\nfrom each graph, z-scores to random graph distributions were measured,\ncorrelated with the PANSS negative subscale, combined into a single\nFragmentation Index, and used for predictions. Findings: Random-like speech was\nprevalent among Schizophrenia patients (64% x 5% in Control group, p=0.0002).\nConnectedness explained 92% of the PANSS negative subscale variance (p=0.0001).\nThe Fragmentation Index classified low versus high scores of PANSS negative\nsubscale with 93% accuracy (AUC=1), predicted Schizophrenia diagnosis with 89%\naccuracy (AUC=0.89), and was validated in an independent cohort of chronic\npsychotic patients. Interpretation: The structural randomness of speech graph\nconnectedness is increased in Schizophrenia. It provides a quantitative\nmeasurement of word salad as a Fragmentation Index that tightly correlates with\nnegative symptoms and predicts Schizophrenia diagnosis during first clinical\ncontact of recent-onset psychosis.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 22:39:17 GMT"}, {"version": "v2", "created": "Sun, 30 Oct 2016 14:59:51 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Mota", "Natalia B.", ""], ["Copelli", "Mauro", ""], ["Ribeiro", "Sidarta", ""]]}, {"id": "1610.09193", "submitter": "Eugenio Urdapilleta", "authors": "Eugenio Urdapilleta", "title": "Noise-induced interspike interval correlations and spike train\n  regularization in spike-triggered adapting neurons", "comments": "7 pages, 6 figures, published in Epl", "journal-ref": "Epl 115, 68002 (2016)", "doi": "10.1209/0295-5075/115/68002", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike generation in neurons produces a temporal point process, whose\nstatistics is governed by intrinsic phenomena and the external incoming inputs\nto be coded. In particular, spike-evoked adaptation currents support a slow\ntemporal process that conditions spiking probability at the present time\naccording to past activity. In this work, we study the statistics of interspike\ninterval correlations arising in such non-renewal spike trains, for a neuron\nmodel that reproduces different spike modes in a small adaptation scenario. We\nfound that correlations are stronger as the neuron fires at a particular firing\nrate, which is defined by the adaptation process. When set in a subthreshold\nregime, the neuron may sustain this particular firing rate, and thus induce\ncorrelations, by noise. Given that, in this regime, interspike intervals are\nnegatively correlated at any lag, this effect surprisingly implies a reduction\nin the variability of the spike count statistics at a finite noise intensity.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 12:58:44 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Urdapilleta", "Eugenio", ""]]}, {"id": "1610.09294", "submitter": "Silvia Montagna", "authors": "Pantelis Samartsidis, Silvia Montagna, Thomas E. Nichols, Timothy D.\n  Johnson", "title": "The coordinate-based meta-analysis of neuroimaging data", "comments": null, "journal-ref": "Statist. Sci. Volume 32, Number 4 (2017), 580-599", "doi": "10.1214/17-STS624", "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging meta-analysis is an area of growing interest in statistics. The\nspecial characteristics of neuroimaging data render classical meta-analysis\nmethods inapplicable and therefore new methods have been developed. We review\nexisting methodologies, explaining the benefits and drawbacks of each. A\ndemonstration on a real dataset of emotion studies is included. We discuss some\nstill-open problems in the field to highlight the need for future research.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 16:12:38 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 15:31:20 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Samartsidis", "Pantelis", ""], ["Montagna", "Silvia", ""], ["Nichols", "Thomas E.", ""], ["Johnson", "Timothy D.", ""]]}, {"id": "1610.09394", "submitter": "Alice Mizrahi", "authors": "Alice Mizrahi, Tifenn Hirtzlin, Akio Fukushima, Hitoshi Kubota, Shinji\n  Yuasa, Julie Grollier and Damien Querlioz", "title": "Neural-like computing with populations of superparamagnetic basis\n  functions", "comments": "5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cond-mat.mes-hall q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neuroscience, population coding theory demonstrates that neural assemblies\ncan achieve fault-tolerant information processing. Mapped to nanoelectronics,\nthis strategy could allow for reliable computing with scaled-down, noisy,\nimperfect devices. Doing so requires that the population components form a set\nof basis functions in terms of their response functions to inputs, offering a\nphysical substrate for calculating. For this purpose, the responses of the\nnanodevices should be non-linear, and each tuned to different values of the\ninput. These strong requirements have prevented a demonstration of population\ncoding with nanodevices. Here, we show that nanoscale magnetic tunnel junctions\ncan be assembled to meet these requirements. We demonstrate experimentally that\na population of nine junctions can implement a basis set of functions,\nproviding the data to achieve, for example, the generation of cursive letters.\nWe design hybrid magnetic-CMOS systems based on interlinked populations of\njunctions and show that they can learn to realize non-linear\nvariability-resilient transformations with a low imprint area and low power.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 11:50:16 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2016 10:41:16 GMT"}, {"version": "v3", "created": "Tue, 11 Apr 2017 14:37:25 GMT"}, {"version": "v4", "created": "Sat, 21 Oct 2017 18:25:18 GMT"}, {"version": "v5", "created": "Thu, 15 Mar 2018 13:58:49 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Mizrahi", "Alice", ""], ["Hirtzlin", "Tifenn", ""], ["Fukushima", "Akio", ""], ["Kubota", "Hitoshi", ""], ["Yuasa", "Shinji", ""], ["Grollier", "Julie", ""], ["Querlioz", "Damien", ""]]}, {"id": "1610.09431", "submitter": "Omar Claflin", "authors": "Omar Claflin", "title": "Attention acts to suppress goal-based conflict under high competition", "comments": "25 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that when multiple stimuli are present, top-down attention\nselectively enhances the neural signal in the visual cortex for task-relevant\nstimuli, but this has been tested only under conditions of minimal competition\nof visual attention. Here we show during high competition, that is, two stimuli\nin a shared receptive field possessing opposing modulatory goals, top-down\nattention suppresses both task-relevant and irrelevant neural signals within\n100 ms of stimuli onset. This non-selective engagement of top-down attentional\nresources serves to reduce the feedforward signal representing irrelevant\nstimuli.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 00:21:31 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Claflin", "Omar", ""]]}, {"id": "1610.09444", "submitter": "James P. Crutchfield", "authors": "P. M. Riechers and J. P. Crutchfield", "title": "Fluctuations When Driving Between Nonequilibrium Steady States", "comments": "25 pages, 7 figures;\n  http://csc.ucdavis.edu/~cmg/compmech/pubs/ftdness.htm", "journal-ref": null, "doi": "10.1007/s10955-017-1822-y", "report-no": null, "categories": "cond-mat.stat-mech nlin.AO physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintained by environmental fluxes, biological systems are thermodynamic\nprocesses that operate far from equilibrium without detailed-balance dynamics.\nYet, they often exhibit well defined nonequilibrium steady states (NESSs). More\nimportantly, critical thermodynamic functionality arises directly from\ntransitions among their NESSs, driven by environmental switching. Here, we\nidentify constraints on excess thermodynamic quantities that ride above the\nNESS housekeeping background. We do this by extending the Crooks fluctuation\ntheorem to transitions among NESSs, without invoking an unphysical dual\ndynamics. This and corresponding integral fluctuation theorems determine how\nmuch work must be expended when controlling systems maintained far from\nequilibrium. This generalizes feedback control theory, showing that Maxwellian\nDemons can leverage mesoscopic-state information to take advantage of the\nexcess energetics in NESS transitions. Altogether, these point to universal\nthermodynamic laws that are immediately applicable to the accessible degrees of\nfreedom within the effective dynamic at any emergent level of hierarchical\norganization. By way of illustration, this readily allows analyzing a\nvoltage-gated sodium ion channel whose molecular conformational dynamics play a\ncritical functional role in propagating action potentials in mammalian neuronal\nmembranes.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 03:07:52 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Riechers", "P. M.", ""], ["Crutchfield", "J. P.", ""]]}, {"id": "1610.09536", "submitter": "Osman Kahraman", "authors": "Osman Kahraman, Yiwei Li and Christoph A. Haselwandter", "title": "Stochastic single-molecule dynamics of synaptic membrane protein domains", "comments": "Main text (7 pages, 4 figures, 1 table) and supplementary material (3\n  pages, 3 figures)", "journal-ref": "EPL, 115 (2016) 68006", "doi": "10.1209/0295-5075/115/68006", "report-no": null, "categories": "q-bio.SC physics.bio-ph q-bio.BM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by single-molecule experiments on synaptic membrane protein\ndomains, we use a stochastic lattice model to study protein reaction and\ndiffusion processes in crowded membranes. We find that the stochastic\nreaction-diffusion dynamics of synaptic proteins provide a simple physical\nmechanism for collective fluctuations in synaptic domains, the molecular\nturnover observed at synaptic domains, key features of the single-molecule\ntrajectories observed for synaptic proteins, and spatially inhomogeneous\nprotein lifetimes at the cell membrane. Our results suggest that central\naspects of the single-molecule and collective dynamics observed for membrane\nprotein domains can be understood in terms of stochastic reaction-diffusion\nprocesses at the cell membrane.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 16:09:18 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 19:25:07 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Kahraman", "Osman", ""], ["Li", "Yiwei", ""], ["Haselwandter", "Christoph A.", ""]]}, {"id": "1610.09625", "submitter": "Daniel Harari", "authors": "Shimon Ullman, Nimrod Dorfman, Daniel Harari", "title": "Discovering containment: from infants to machines", "comments": null, "journal-ref": "Cognition 183 (2019) 67-81", "doi": "10.1016/j.cognition.2018.11.001", "report-no": null, "categories": "q-bio.NC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current artificial learning systems can recognize thousands of visual\ncategories, or play Go at a champion\"s level, but cannot explain infants\nlearning, in particular the ability to learn complex concepts without guidance,\nin a specific order. A notable example is the category of 'containers' and the\nnotion of containment, one of the earliest spatial relations to be learned,\nstarting already at 2.5 months, and preceding other common relations (e.g.,\nsupport). Such spontaneous unsupervised learning stands in contrast with\ncurrent highly successful computational models, which learn in a supervised\nmanner, that is, by using large data sets of labeled examples. How can\nmeaningful concepts be learned without guidance, and what determines the\ntrajectory of infant learning, making some notions appear consistently earlier\nthan others?\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 10:26:22 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Ullman", "Shimon", ""], ["Dorfman", "Nimrod", ""], ["Harari", "Daniel", ""]]}, {"id": "1610.09733", "submitter": "Serena Bradde", "authors": "Serena Bradde and William Bialek", "title": "PCA meets RG", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": "10.1007/s10955-017-1770-6", "report-no": null, "categories": "physics.bio-ph cond-mat.stat-mech q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A system with many degrees of freedom can be characterized by a covariance\nmatrix; principal components analysis (PCA) focuses on the eigenvalues of this\nmatrix, hoping to find a lower dimensional description. But when the spectrum\nis nearly continuous, any distinction between components that we keep and those\nthat we ignore becomes arbitrary; it then is natural to ask what happens as we\nvary this arbitrary cutoff. We argue that this problem is analogous to the\nmomentum shell renormalization group (RG). Following this analogy, we can\ndefine relevant and irrelevant operators, where the role of dimensionality is\nplayed by properties of the eigenvalue density. These results also suggest an\napproach to the analysis of real data. As an example, we study neural activity\nin the vertebrate retina as it responds to naturalistic movies, and find\nevidence of behavior controlled by a nontrivial fixed point. Applied to\nfinancial data, our analysis separates modes dominated by sampling noise from a\nsmaller but still macroscopic number of modes described by a non--Gaussian\ndistribution.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 23:55:32 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Bradde", "Serena", ""], ["Bialek", "William", ""]]}, {"id": "1610.09990", "submitter": "Jannis Schuecker", "authors": "Jan Hahne, David Dahmen, Jannis Schuecker, Andreas Frommer, Matthias\n  Bolten, Moritz Helias and Markus Diesmann", "title": "Integration of continuous-time dynamics in a spiking neural network\n  simulator", "comments": null, "journal-ref": null, "doi": "10.3389/fninf.2017.00034", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary modeling approaches to the dynamics of neural networks consider\ntwo main classes of models: biologically grounded spiking neurons and\nfunctionally inspired rate-based units. The unified simulation framework\npresented here supports the combination of the two for multi-scale modeling\napproaches, the quantitative validation of mean-field approaches by spiking\nnetwork simulations, and an increase in reliability by usage of the same\nsimulation code and the same network model specifications for both model\nclasses. While most efficient spiking simulations rely on the communication of\ndiscrete events, rate models require time-continuous interactions between\nneurons. Exploiting the conceptual similarity to the inclusion of gap junctions\nin spiking network simulations, we arrive at a reference implementation of\ninstantaneous and delayed interactions between rate-based models in a spiking\nnetwork simulator. The separation of rate dynamics from the general connection\nand communication infrastructure ensures flexibility of the framework. We\nfurther demonstrate the broad applicability of the framework by considering\nvarious examples from the literature ranging from random networks to neural\nfield models. The study provides the prerequisite for interactions between\nrate-based and spiking models in a joint simulation.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 16:02:23 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Hahne", "Jan", ""], ["Dahmen", "David", ""], ["Schuecker", "Jannis", ""], ["Frommer", "Andreas", ""], ["Bolten", "Matthias", ""], ["Helias", "Moritz", ""], ["Diesmann", "Markus", ""]]}]