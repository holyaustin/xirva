[{"id": "1205.0321", "submitter": "Ramon Ferrer i Cancho", "authors": "Ramon Ferrer-i-Cancho and Brenda McCowan", "title": "The span of correlations in dolphin whistle sequences", "comments": "New Tables 3 and 4", "journal-ref": "Journal of Statistical Mechanics, P06002 (2012)", "doi": "10.1088/1742-5468/2012/06/P06002", "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-range correlations are found in symbolic sequences from human language,\nmusic and DNA. Determining the span of correlations in dolphin whistle\nsequences is crucial for shedding light on their communicative complexity.\nDolphin whistles share various statistical properties with human words, i.e.\nZipf's law for word frequencies (namely that the probability of the $i$th most\nfrequent word of a text is about $i^{-\\alpha}$) and a parallel of the tendency\nof more frequent words to have more meanings. The finding of Zipf's law for\nword frequencies in dolphin whistles has been the topic of an intense debate on\nits implications. One of the major arguments against the relevance of Zipf's\nlaw in dolphin whistles is that is not possible to distinguish the outcome of a\ndie rolling experiment from that of a linguistic or communicative source\nproducing Zipf's law for word frequencies. Here we show that statistically\nsignificant whistle-whistle correlations extend back to the 2nd previous\nwhistle in the sequence using a global randomization test and to the 4th\nprevious whistle using a local randomization test. None of these correlations\nare expected by a die rolling experiment and other simple explanation of Zipf's\nlaw for word frequencies such as Simon's model that produce sequences of\nunpredictable elements.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2012 04:49:19 GMT"}, {"version": "v2", "created": "Wed, 9 May 2012 12:29:23 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""], ["McCowan", "Brenda", ""]]}, {"id": "1205.0335", "submitter": "John Hopfield", "authors": "Filip Ponulak and John J. Hopfield", "title": "Rapid, parallel path planning by propagating wavefronts of spiking\n  neural activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient path planning and navigation is critical for animals, robotics,\nlogistics and transportation. We study a model in which spatial navigation\nproblems can rapidly be solved in the brain by parallel mental exploration of\nalternative routes using propagating waves of neural activity. A wave of\nspiking activity propagates through a hippocampus-like network, altering the\nsynaptic connectivity. The resulting vector field of synaptic change then\nguides a simulated animal to the appropriate selected target locations. We\ndemonstrate that the navigation problem can be solved using realistic, local\nsynaptic plasticity rules during a single passage of a wavefront. Our model can\nfind optimal solutions for competing possible targets or learn and navigate in\nmultiple environments. The model provides a hypothesis on the possible\ncomputational mechanisms for optimal path planning in the brain, at the same\ntime it is useful for neuromorphic implementations, where the parallelism of\ninformation processing proposed here can fully be harnessed in hardware.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2012 06:36:56 GMT"}], "update_date": "2012-05-03", "authors_parsed": [["Ponulak", "Filip", ""], ["Hopfield", "John J.", ""]]}, {"id": "1205.0528", "submitter": "Matthijs Melissen", "authors": "Matthijs Melissen", "title": "Are insight problems really different from noninsight problems?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this text, I will suggest an electroencephalogram (EEG) experiment with\nwhich it will be possible to see whether there is biological evidence for the\nfrequently made distinction between insight and noninsight problems. What is\nmeant with insight here is the 'aha'-experience, the sudden discovery of how a\nproblem works. First, I will give a summary of the research done by Auke Pols\nin his thesis 'Insight in problem solving' (Pols, 2002), an introductory text\non insight. This part of this text consists of an overview of the questions\nPols asks himself, the answers to these questions, and the methods he uses to\nfind them. Secondly, I will formulate my own research question, and propose the\nmethods with which I want to answer this question.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2012 12:15:03 GMT"}, {"version": "v2", "created": "Thu, 3 May 2012 15:46:44 GMT"}], "update_date": "2012-05-04", "authors_parsed": [["Melissen", "Matthijs", ""]]}, {"id": "1205.2012", "submitter": "Mohammadkarim Saeedghalati", "authors": "Mohammadkarim Saeedghalati, Abdolhossein Abbassian", "title": "The effect of temporal pattern of injury on disability in learning\n  networks", "comments": "Latex, 17 pages, 7 figures, 2 tables", "journal-ref": null, "doi": "10.3389/fncom.2015.00130", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How networks endure damage is a central issue in neural network research.\nThis includes temporal as well as spatial pattern of damage. Here, based on\nsome very simple models we study the difference between a slow-growing and\nacute damage and the relation between the size and rate of injury. Our result\nshows that in both a three-layer and a homeostasis model a slow-growing damage\nhas a decreasing effect on network disability as compared with a fast growing\none. This finding is in accord with clinical reports where the state of\npatients before and after the operation for slow-growing injuries is much\nbetter that those patients with acute injuries.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:19:49 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Saeedghalati", "Mohammadkarim", ""], ["Abbassian", "Abdolhossein", ""]]}, {"id": "1205.3025", "submitter": "Marc-Oliver Gewaltig", "authors": "Marc-Oliver Gewaltig and Robert Cannon", "title": "Current practice in software development for computational neuroscience\n  and how to improve it", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all research work in computational neuroscience involves software. As\nresearchers try to understand ever more complex systems, there is a continual\nneed for software with new capabilities. Because of the wide range of questions\nbeing investigated, new software is often developed rapidly by individuals or\nsmall groups. In these cases, it can be hard to demonstrate that the software\ngives the right results. Software developers are often open about the code they\nproduce and willing to share it, but there is little appreciation among\npotential users of the great diversity of software development practices and\nend results, and how this affects the suitability of software tools for use in\nresearch projects. To help clarify these issues, we have reviewed a range of\nsoftware tools and asked how the culture and practice of software development\naffects their validity and trustworthiness. We identified four key questions\nthat can be used to categorize software projects and correlate them with the\ntype of product that results. The first question addresses what is being\nproduced. The other three concern why, how, and by whom the work is done. The\nanswers to these questions show strong correlations with the nature of the\nsoftware being produced, and its suitability for particular purposes. Based on\nour findings, we suggest ways in which current software development practice in\ncomputational neuroscience can be improved and propose checklists to help\ndevelopers, reviewers and scientists to assess the quality whether particular\npieces of software are ready for use in research.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 13:48:51 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2013 08:02:32 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Gewaltig", "Marc-Oliver", ""], ["Cannon", "Robert", ""]]}, {"id": "1205.3072", "submitter": "Zachary Kilpatrick PhD", "authors": "Zachary P. Kilpatrick and Bard Ermentrout", "title": "Wandering bumps in stochastic neural fields", "comments": "40 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.PS math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effects of noise on stationary pulse solutions (bumps) in\nspatially extended neural fields. The dynamics of a neural field is described\nby an integrodifferential equation whose integral term characterizes synaptic\ninteractions between neurons in different spatial locations of the network.\nTranslationally symmetric neural fields support a continuum of stationary bump\nsolutions, which may be centered at any spatial location. Random fluctuations\nare introduced by modeling the system as a spatially extended Langevin equation\nwhose noise term we take to be multiplicative or additive. For nonzero noise,\nthese bumps are shown to wander about the domain in a purely diffusive way. We\ncan approximate the effective diffusion coefficient using a small noise\nexpansion. Upon breaking the (continuous) translation symmetry of the system\nusing a spatially heterogeneous inputs or synapses, bumps in the stochastic\nneural field can become temporarily pinned to a finite number of locations in\nthe network. In the case of spatially heterogeneous synaptic weights, as the\nmodulation frequency of this heterogeneity increases, the effective diffusion\nof bumps in the network approaches that of the network with spatially\nhomogeneous weights.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2012 16:00:32 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["Kilpatrick", "Zachary P.", ""], ["Ermentrout", "Bard", ""]]}, {"id": "1205.3747", "submitter": "Lazaros Gallos", "authors": "Lazaros K. Gallos, Mariano Sigman, Hernan A. Makse", "title": "The conundrum of functional brain networks: small-world efficiency or\n  fractal modularity", "comments": "14 pages, 8 figures", "journal-ref": "Frontiers in Fractal Physiology, 3, 123 (2012)", "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain has been studied at multiple scales, from neurons, circuits,\nareas with well defined anatomical and functional boundaries, to large-scale\nfunctional networks which mediate coherent cognition. In a recent work, we\naddressed the problem of the hierarchical organization in the brain through\nnetwork analysis. Our analysis identified functional brain modules of fractal\nstructure that were inter-connected in a small-world topology. Here, we provide\nmore details on the use of network science tools to elaborate on this behavior.\nWe indicate the importance of using percolation theory to highlight the modular\ncharacter of the functional brain network. These modules present a fractal,\nself-similar topology, identified through fractal network methods. When we\nlower the threshold of correlations to include weaker ties, the network as a\nwhole assumes a small-world character. These weak ties are organized precisely\nas predicted by theory maximizing information transfer with minimal wiring\ncosts.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 17:48:25 GMT"}], "update_date": "2012-05-17", "authors_parsed": [["Gallos", "Lazaros K.", ""], ["Sigman", "Mariano", ""], ["Makse", "Hernan A.", ""]]}, {"id": "1205.4282", "submitter": "Cesar Comin PhD", "authors": "Cesar H. Comin and Jo\\~ao B. Bunoro and Matheus P. Viana and Luciano\n  da F. Costa", "title": "The relationship between structure and function in locally observed\n  complex networks", "comments": null, "journal-ref": null, "doi": "10.1088/1367-2630/15/1/013048", "report-no": null, "categories": "physics.soc-ph cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, some studies started to unveil the wealthy of interactions that\noccur between groups of nodes when looking at the small scale of interactions\ntaking place in complex networks. Such findings claim for a new systematic\nmethodology to quantify, at node level, how a dynamics is being influenced (or\ndifferentiated) by the structure of the underlying system. Here we define a new\nmeasure that, based on dynamical characteristics obtained for a large set of\ninitial conditions, compares the dynamical behavior of the nodes present in the\nsystem. Through this measure we find that the geographic and Barab\\'asi-Albert\nmodels have high capacity for generating networks that exhibit groups of nodes\nwith distinct dynamics compared to the rest of the network. The application of\nour methodology is illustrated with respect of two real systems. In the first\nwe use the neuronal network of the nematode Caenorhabditis elegans to show that\nthe interneurons of the ventral cord of the nematode presents a very large\ndynamical differentiation when compared to the rest of the network. The second\napplication concerns the SIS epidemic model on an airport network, where we\nquantify how different the distribution of infection times of high and low\ndegree nodes can be, when compared to the expected value for the network.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2012 23:54:35 GMT"}, {"version": "v2", "created": "Fri, 22 Jul 2016 23:53:50 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Comin", "Cesar H.", ""], ["Bunoro", "Jo\u00e3o B.", ""], ["Viana", "Matheus P.", ""], ["Costa", "Luciano da F.", ""]]}, {"id": "1205.6158", "submitter": "Cedric Ginestet", "authors": "Arnaud P. Fournel, Emanuelle Reynaud, Michael J. Brammer, Andrew\n  Simmons and Cedric E. Ginestet", "title": "Group Analysis of Self-organizing Maps based on Functional MRI using\n  Restricted Frechet Means", "comments": "23 pages, 5 figures, 4 tables. Submitted to Neuroimage", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Studies of functional MRI data are increasingly concerned with the estimation\nof differences in spatio-temporal networks across groups of subjects or\nexperimental conditions. Unsupervised clustering and independent component\nanalysis (ICA) have been used to identify such spatio-temporal networks. While\nthese approaches have been useful for estimating these networks at the\nsubject-level, comparisons over groups or experimental conditions require\nfurther methodological development. In this paper, we tackle this problem by\nshowing how self-organizing maps (SOMs) can be compared within a Frechean\ninferential framework. Here, we summarize the mean SOM in each group as a\nFrechet mean with respect to a metric on the space of SOMs. We consider the use\nof different metrics, and introduce two extensions of the classical sum of\nminimum distance (SMD) between two SOMs, which take into account the\nspatio-temporal pattern of the fMRI data. The validity of these methods is\nillustrated on synthetic data. Through these simulations, we show that the\nthree metrics of interest behave as expected, in the sense that the ones\ncapturing temporal, spatial and spatio-temporal aspects of the SOMs are more\nlikely to reach significance under simulated scenarios characterized by\ntemporal, spatial and spatio-temporal differences, respectively. In addition, a\nre-analysis of a classical experiment on visually-triggered emotions\ndemonstrates the usefulness of this methodology. In this study, the\nmultivariate functional patterns typical of the subjects exposed to pleasant\nand unpleasant stimuli are found to be more similar than the ones of the\nsubjects exposed to emotionally neutral stimuli. Taken together, these results\nindicate that our proposed methods can cast new light on existing data by\nadopting a global analytical perspective on functional MRI paradigms.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2012 16:53:38 GMT"}, {"version": "v2", "created": "Mon, 13 Aug 2012 11:00:46 GMT"}], "update_date": "2012-08-14", "authors_parsed": [["Fournel", "Arnaud P.", ""], ["Reynaud", "Emanuelle", ""], ["Brammer", "Michael J.", ""], ["Simmons", "Andrew", ""], ["Ginestet", "Cedric E.", ""]]}, {"id": "1205.6438", "submitter": "Gasper Tkacik", "authors": "Einat Granot-Atedgi and Ga\\v{s}per Tka\\v{c}ik and Ronen Segev and Elad\n  Schneidman", "title": "Stimulus-dependent maximum entropy models of neural population codes", "comments": "11 pages, 7 figures", "journal-ref": "PLoS Comput Biol 9 (2013): e1002922", "doi": "10.1371/journal.pcbi.1002922", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural populations encode information about their stimulus in a collective\nfashion, by joint activity patterns of spiking and silence. A full account of\nthis mapping from stimulus to neural activity is given by the conditional\nprobability distribution over neural codewords given the sensory input. To be\nable to infer a model for this distribution from large-scale neural recordings,\nwe introduce a stimulus-dependent maximum entropy (SDME) model---a minimal\nextension of the canonical linear-nonlinear model of a single neuron, to a\npairwise-coupled neural population. The model is able to capture the\nsingle-cell response properties as well as the correlations in neural spiking\ndue to shared stimulus and due to effective neuron-to-neuron connections. Here\nwe show that in a population of 100 retinal ganglion cells in the salamander\nretina responding to temporal white-noise stimuli, dependencies between cells\nplay an important encoding role. As a result, the SDME model gives a more\naccurate account of single cell responses and in particular outperforms\nuncoupled models in reproducing the distributions of codewords emitted in\nresponse to a stimulus. We show how the SDME model, in conjunction with static\nmaximum entropy models of population vocabulary, can be used to estimate\ninformation-theoretic quantities like surprise and information transmission in\na neural population.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2012 18:03:26 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Granot-Atedgi", "Einat", ""], ["Tka\u010dik", "Ga\u0161per", ""], ["Segev", "Ronen", ""], ["Schneidman", "Elad", ""]]}, {"id": "1205.6598", "submitter": "Gasper Tkacik", "authors": "Ga\\v{s}per Tka\\v{c}ik and Einat Granot-Atedgi and Ronen Segev and Elad\n  Schneidman", "title": "Retinal metric: a stimulus distance measure derived from population\n  neural responses", "comments": "5 pages, 4 figures, to appear in Phys Rev Lett", "journal-ref": "Phys Rev Lett 110 (2013): 058104", "doi": "10.1103/PhysRevLett.110.058104", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability of the organism to distinguish between various stimuli is limited\nby the structure and noise in the population code of its sensory neurons. Here\nwe infer a distance measure on the stimulus space directly from the recorded\nactivity of 100 neurons in the salamander retina. In contrast to previously\nused measures of stimulus similarity, this \"neural metric\" tells us how\ndistinguishable a pair of stimulus clips is to the retina, given the noise in\nthe neural population response. We show that the retinal distance strongly\ndeviates from Euclidean, or any static metric, yet has a simple structure: we\nidentify the stimulus features that the neural population is jointly sensitive\nto, and show the SVM-like kernel function relating the stimulus and neural\nresponse spaces. We show that the non-Euclidean nature of the retinal distance\nhas important consequences for neural decoding.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2012 09:29:44 GMT"}, {"version": "v2", "created": "Sat, 8 Dec 2012 08:07:53 GMT"}], "update_date": "2013-06-14", "authors_parsed": [["Tka\u010dik", "Ga\u0161per", ""], ["Granot-Atedgi", "Einat", ""], ["Segev", "Ronen", ""], ["Schneidman", "Elad", ""]]}, {"id": "1205.7085", "submitter": "Alexei Koulakov", "authors": "Yi Wei and Alexei A. Koulakov", "title": "Long-term memory stabilized by noise-induced rehearsal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical networks can maintain memories for decades despite the short\nlifetime of synaptic strength. Can a neural network store long-lasting memories\nin unstable synapses? Here, we study the effects of random noise on the\nstability of memory stored in synapses of an attractor neural network. The\nmodel includes ongoing spike timing dependent plasticity (STDP). We show that\ncertain classes of STDP rules can lead to the stabilization of memory patterns\nstored in the network. The stabilization results from rehearsals induced by\nnoise. We show that unstructured neural noise, after passing through the\nrecurrent network weights, carries the imprint of all memory patterns in\ntemporal correlations. Under certain conditions, STDP combined with these\ncorrelations, can lead to reinforcement of all existing patterns, even those\nthat are never explicitly visited. Thus, unstructured neural noise can\nstabilize the existing structure of synaptic connectivity. Our findings may\nprovide the functional reason for highly irregular spiking displayed by\ncortical neurons and provide justification for models of system memory\nconsolidation. Therefore, we propose that irregular neural activity is the\nfeature that helps cortical networks maintain stable connections.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2012 19:38:08 GMT"}], "update_date": "2012-06-01", "authors_parsed": [["Wei", "Yi", ""], ["Koulakov", "Alexei A.", ""]]}]