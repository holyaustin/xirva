[{"id": "2007.00001", "submitter": "Juyang Weng", "authors": "Juyang Weng", "title": "Conscious Intelligence Requires Lifelong Autonomous Programming For\n  General Purposes", "comments": "16 pages, 6 figures. This work was submitted to Science May 27, 2020\n  and to Nature June 9, 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Universal Turing Machines [29, 10, 18] are well known in computer science but\nthey are about manual programming for general purposes. Although human children\nperform conscious learning (i.e., learning while being conscious) from infancy\n[24, 23, 14, 4], it is unknown that Universal Turing Machiness can facilitate\nnot only our understanding of Autonomous Programming For General Purposes\n(APFGP) by machines, but also enable early-age conscious learning. This work\nreports a new kind of AI---conscious learning AI from a machine's \"baby\" time.\nInstead of arguing what static tasks a conscious machine should be able to do\nduring its \"adulthood\", this work suggests that APFGP is a computationally\nclearer and necessary criterion for us to judge whether a machine is capable of\nconscious learning so that it can autonomously acquire skills along its \"career\npath\". The results here report new concepts and experimental studies for early\nvision, audition, natural language understanding, and emotion, with conscious\nlearning capabilities that are absent from traditional AI systems.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 23:52:44 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Weng", "Juyang", ""]]}, {"id": "2007.00031", "submitter": "Sacha van Albada", "authors": "Sacha Jennifer van Albada, Aitor Morales-Gregorio, Timo Dickscheid,\n  Alexandros Goulas, Rembrandt Bakker, Sebastian Bludau, G\\\"unther Palm,\n  Claus-Christian Hilgetag, Markus Diesmann", "title": "Bringing Anatomical Information into Neuronal Network Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For constructing neuronal network models computational neuroscientists have\naccess to wide-ranging anatomical data that nevertheless tend to cover only a\nfraction of the parameters to be determined. Finding and interpreting the most\nrelevant data, estimating missing values, and combining the data and estimates\nfrom various sources into a coherent whole is a daunting task. With this\nchapter we aim to provide guidance to modelers by describing the main types of\nanatomical data that may be useful for informing neuronal network models. We\nfurther discuss aspects of the underlying experimental techniques relevant to\nthe interpretation of the data, list particularly comprehensive data sets, and\ndescribe methods for filling in the gaps in the experimental data. Such methods\nof `predictive connectomics' estimate connectivity where the data are lacking\nbased on statistical relationships with known quantities. It is instructive,\nand in certain cases necessary, to use organizational principles that link the\nplethora of data within a unifying framework where regularities of brain\nstructure can be exploited to inform computational models. In addition, we\ntouch upon the most prominent features of brain organization that are likely to\ninfluence predicted neuronal network dynamics, with a focus on the mammalian\ncerebral cortex. Given the still existing need for modelers to navigate a\ncomplex data landscape full of holes and stumbling blocks, it is vital that the\nfield of neuroanatomy is moving toward increasingly systematic data collection,\nrepresentation, and publication.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 18:02:17 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2020 10:19:09 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["van Albada", "Sacha Jennifer", ""], ["Morales-Gregorio", "Aitor", ""], ["Dickscheid", "Timo", ""], ["Goulas", "Alexandros", ""], ["Bakker", "Rembrandt", ""], ["Bludau", "Sebastian", ""], ["Palm", "G\u00fcnther", ""], ["Hilgetag", "Claus-Christian", ""], ["Diesmann", "Markus", ""]]}, {"id": "2007.00079", "submitter": "Wilten Nicola", "authors": "Wilten Nicola and Sue Ann Campbell", "title": "Normalized Connectomes Show Increased Synchronizability with Age Through\n  Their Second Largest Eigenvalue", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The synchronization of different brain regions is widely observed under both\nnormal and pathological conditions such as epilepsy. However, the relationship\nbetween the dynamics of these brain regions, the connectivity between them, and\nthe ability to synchronize remains an open question. We investigated the\nproblem of inter-region synchronization in networks of Wilson-Cowan/Neural\nfield equations with homeostatic plasticity, each of which acts as a model for\nan isolated brain region. We considered arbitrary connection profiles with only\none constraint: the rows of the connection matrices are all identically\nnormalized. We found that these systems often synchronize to the solution\nobtained from a single, self-coupled neural region. We analyze the stability of\nthis solution through a straightforward modification of the Master Stability\nFunction (MSF) approach and found that synchronized solutions lose stability\nfor connectivity matrices when the second largest positive eigenvalue is\nsufficiently large, for values of the global coupling parameter that are not\ntoo large. This result was numerically confirmed for ring systems and lattices\nand was also robust to small amounts of heterogeneity in the homeostatic set\npoints in each node. Finally, we tested this result on connectomes obtained\nfrom 196 subjects over a broad age range (4-85 years) from the Human Connectome\nProject. We found that the second largest eigenvalue tended to decrease with\nage, indicating an increase in synchronizability that may be related to the\nincreased prevalence of epilepsy with old age.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 19:47:25 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Nicola", "Wilten", ""], ["Campbell", "Sue Ann", ""]]}, {"id": "2007.00126", "submitter": "Lucas Miranda", "authors": "Lucas Miranda, Riya Paul, Benno P\\\"utz, Bertram M\\\"uller-Myhsok", "title": "Functional MRI applications for psychiatric disease subtyping: a review", "comments": "16 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychiatric disorders have historically been classified using symptom\ninformation alone. With the advent of new technologies that allowed researchers\nto investigate brain mechanisms more directly, interest in the mechanistic\nrationale behind defined pathologies and aetiology redefinition has greatly\nincreased. This is particularly appealing for the field of personalised\nmedicine, which searches for data-driven approaches to improve individual\ndiagnosis, prognosis and treatment selection. Here we intend to systematically\nanalyse the usage of functional MRI on both the elucidation of psychiatric\ndisease biotypes and the interpretation of subtypes obtained via unsupervised\nlearning applied to symptom or biomarker data. We searched the existing\nliterature for functional MRI applications to the obtention or interpretation\nof psychiatric disease subtypes. The PRISMA guidelines were applied to filter\nthe retrieved studies, and the active learning framework ASReviews was applied\nfor article prioritization. From the 20 studies that met the inclusion\ncriteria, 5 used functional MRI data to interpret symptom-derived disease\nclusters, 4 used it for the interpretation of clusters derived from biomarker\ndata other than fMRI itself, and 11 applied clustering to fMRI directly. Major\ndepression disorder and schizophrenia were the two most studied pathologies,\nfollowed by ADHD, psychosis, autism disorder, and early violence. No\ntrans-diagnostic studies were retrieved. While interest in personalised\nmedicine and data-driven disease subtyping is on the rise and psychiatry is not\nthe exception, unsupervised analyses of functional MRI data are inconsistent to\ndate, and much remains to be done in terms of gathering and centralising data,\nstandardising pipelines and model validation, and method refinement. The usage\nof fMRI in the field of trans-diagnostic psychiatry remains vastly unexplored.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2020 21:50:23 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Miranda", "Lucas", ""], ["Paul", "Riya", ""], ["P\u00fctz", "Benno", ""], ["M\u00fcller-Myhsok", "Bertram", ""]]}, {"id": "2007.00212", "submitter": "Ryuta Mizutani", "authors": "Ryuta Mizutani, Rino Saiga, Yoshiro Yamamoto, Masayuki Uesugi, Akihisa\n  Takeuchi, Kentaro Uesugi, Yasuko Terada, Yoshio Suzuki, Vincent De Andrade,\n  Francesco De Carlo, Susumu Takekoshi, Chie Inomoto, Naoya Nakamura, Youta\n  Torii, Itaru Kushima, Shuji Iritani, Norio Ozaki, Kenichi Oshima, Masanari\n  Itokawa, Makoto Arai", "title": "Structural diverseness of neurons between brain areas and between cases", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cerebral cortex is composed of multiple cortical areas that exert a wide\nvariety of brain functions. Although human brain neurons are genetically and\nareally mosaic, the three-dimensional structural differences between neurons in\ndifferent brain areas or between the neurons of different individuals have not\nbeen delineated. Here, we report a nanometer-scale geometric analysis of brain\ntissues of the superior temporal gyrus of 4 schizophrenia and 4 control cases\nby using synchrotron radiation nanotomography. The results of the analysis and\na comparison with results for the anterior cingulate cortex indicated that 1)\nneuron structures are dissimilar between brain areas and that 2) the\ndissimilarity varies from case to case. The structural diverseness was mainly\nobserved in terms of the neurite curvature that inversely correlates with the\ndiameters of the neurites and spines. The analysis also revealed the geometric\ndifferences between the neurons of the schizophrenia and control cases,\nsuggesting that neuron structure is associated with brain function. The area\ndependency of the neuron structure and its diverseness between individuals\nshould represent the individuality of brain functions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 03:50:21 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Mizutani", "Ryuta", ""], ["Saiga", "Rino", ""], ["Yamamoto", "Yoshiro", ""], ["Uesugi", "Masayuki", ""], ["Takeuchi", "Akihisa", ""], ["Uesugi", "Kentaro", ""], ["Terada", "Yasuko", ""], ["Suzuki", "Yoshio", ""], ["De Andrade", "Vincent", ""], ["De Carlo", "Francesco", ""], ["Takekoshi", "Susumu", ""], ["Inomoto", "Chie", ""], ["Nakamura", "Naoya", ""], ["Torii", "Youta", ""], ["Kushima", "Itaru", ""], ["Iritani", "Shuji", ""], ["Ozaki", "Norio", ""], ["Oshima", "Kenichi", ""], ["Itokawa", "Masanari", ""], ["Arai", "Makoto", ""]]}, {"id": "2007.00469", "submitter": "Jose Gomez-Tames", "authors": "Jose Gomez-Tames, Ilkka Laakso, and Akimasa Hirata", "title": "Review on Biophysical Modelling and Simulation Studies for Transcranial\n  Magnetic Stimulation", "comments": null, "journal-ref": null, "doi": "10.1088/1361-6560/aba40d", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcranial magnetic stimulation (TMS) is a technique for noninvasively\nstimulating a brain area for therapeutic, rehabilitation treatments and\nneuroscience research. Despite our understanding of the physical principles and\nexperimental developments pertaining to TMS, it is difficult to identify the\nexact brain target as the generated dosage exhibits a non-uniform distribution\nowing to the complicated and subject-dependent brain anatomy and the lack of\nbiomarkers that can quantify the effects of TMS in most cortical areas.\nComputational dosimetry has progressed significantly and enables TMS assessment\nby computation of the induced electric field (the primary physical agent known\nto activate the brain neurons) in a digital representation of the human head.\nIn this review, TMS dosimetry studies are summarised, clarifying the importance\nof the anatomical and human biophysical parameters and computational methods.\nThis review shows that there is a high consensus on the importance of a\ndetailed cortical folding representation and an accurate modelling of the\nsurrounding cerebrospinal fluid. Recent studies have also enabled the\nprediction of individually optimised stimulation based on magnetic resonance\nimaging of the patient/subject and have attempted to understand the temporal\neffects of TMS at the cellular level by incorporating neural modelling. These\nefforts, together with the fast deployment of personalised TMS computations,\nwill permit the adoption of TMS dosimetry as a standard procedure in clinical\nprocedures.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2020 22:31:35 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Gomez-Tames", "Jose", ""], ["Laakso", "Ilkka", ""], ["Hirata", "Akimasa", ""]]}, {"id": "2007.00524", "submitter": "Petr Marsalek", "authors": "Petr Marsalek, Pavel Sanda, Zbynek Bures", "title": "On the precision of neural computation with interaural time differences\n  in the medial superior olive", "comments": "A pre-print. In preparation to be submitted into a refereed journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incoming sound is in cochlea and auditory nerve encoded into spike trains. At\nthe third neuron of the auditory pathway, spike trains of the left and right\nsides are processed in brainstem nuclei to yield sound localization\ninformation. Two different localization encoding mechanisms are employed in two\ncenters for low and high sound frequencies in the brainstem. The centers are\nsuperior olivary nuclei, medial and lateral. This paper contains analytical\nestimates of parameters needed in description of auditory coding in sound\nlocalization neural circuit. Our model spike trains are based on\nelectro-physiological recordings. We arrive to best estimates for neuronal\nsignaling with the use of just noticeable difference of the ideal observer. We\ndescribe spike timing jitter and its role in the spike train processing. All\nparameters are accompanied with detailed estimates of their values and\nvariability. Intervals bounding all the parameter from lower and higher values\nare discussed.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 14:38:40 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Marsalek", "Petr", ""], ["Sanda", "Pavel", ""], ["Bures", "Zbynek", ""]]}, {"id": "2007.00776", "submitter": "Abhronil Sengupta", "authors": "Umang Garg, Kezhou Yang, Abhronil Sengupta", "title": "Emulation of Astrocyte Induced Neural Phase Synchrony in Spin-Orbit\n  Torque Oscillator Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Astrocytes play a central role in inducing concerted phase synchronized\nneural-wave patterns inside the brain. In this letter, we demonstrate that\ninjected radio-frequency signal in underlying heavy metal layer of spin-orbit\ntorque oscillator neurons mimic the neuron phase synchronization effect\nrealized by glial cells. Potential application of such phase coupling effects\nis illustrated in the context of a temporal \"binding problem\". We also present\nthe design of a coupled neuron-synapse-astrocyte network enabled by compact\nneuromimetic devices by combining the concepts of local spike-timing dependent\nplasticity and astrocyte induced neural phase synchrony.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2020 21:36:31 GMT"}, {"version": "v2", "created": "Mon, 6 Jul 2020 20:03:32 GMT"}, {"version": "v3", "created": "Mon, 26 Oct 2020 21:22:30 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 20:30:31 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Garg", "Umang", ""], ["Yang", "Kezhou", ""], ["Sengupta", "Abhronil", ""]]}, {"id": "2007.00886", "submitter": "Qinbing Fu", "authors": "Qinbing Fu and Shigang Yue", "title": "Modelling Drosophila Motion Vision Pathways for Decoding the Direction\n  of Translating Objects Against Cluttered Moving Backgrounds", "comments": "27 pages, 13 figures, been included in a future issue of the journal\n  of Biological Cybernetics", "journal-ref": null, "doi": "10.1007/s00422-020-00841-x", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding the direction of translating objects in front of cluttered moving\nbackgrounds, accurately and efficiently, is still a challenging problem. In\nnature, lightweight and low-powered flying insects apply motion vision to\ndetect a moving target in highly variable environments during flight, which are\nexcellent paradigms to learn motion perception strategies. This paper\ninvestigates the fruit fly \\textit{Drosophila} motion vision pathways and\npresents computational modelling based on cutting-edge physiological\nresearches. The proposed visual system model features bio-plausible ON and OFF\npathways, wide-field horizontal-sensitive (HS) and vertical-sensitive (VS)\nsystems. The main contributions of this research are on two aspects: 1) the\nproposed model articulates the forming of both direction-selective (DS) and\ndirection-opponent (DO) responses, revealed as principal features of motion\nperception neural circuits, in a feed-forward manner; 2) it also shows robust\ndirection selectivity to translating objects in front of cluttered moving\nbackgrounds, via the modelling of spatiotemporal dynamics including combination\nof motion pre-filtering mechanisms and ensembles of local correlators inside\nboth the ON and OFF pathways, which works effectively to suppress irrelevant\nbackground motion or distractors, and to improve the dynamic response.\nAccordingly, the direction of translating objects is decoded as global\nresponses of both the HS and VS systems with positive or negative output\nindicating preferred-direction (PD) or null-direction (ND) translation. The\nexperiments have verified the effectiveness of the proposed neural system\nmodel, and demonstrated its responsive preference to faster-moving,\nhigher-contrast and larger-size targets embedded in cluttered moving\nbackgrounds.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 05:15:31 GMT"}], "update_date": "2020-07-03", "authors_parsed": [["Fu", "Qinbing", ""], ["Yue", "Shigang", ""]]}, {"id": "2007.00897", "submitter": "Siamak Mehrkanoon", "authors": "Ismail Alaoui Abdellaoui, Jesus Garcia Fernandez, Caner Sahinli and\n  Siamak Mehrkanoon", "title": "Deep brain state classification of MEG data", "comments": "11 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neuroimaging techniques have shown to be useful when studying the brain's\nactivity. This paper uses Magnetoencephalography (MEG) data, provided by the\nHuman Connectome Project (HCP), in combination with various deep artificial\nneural network models to perform brain decoding. More specifically, here we\ninvestigate to which extent can we infer the task performed by a subject based\non its MEG data. Three models based on compact convolution, combined\nconvolutional and long short-term architecture as well as a model based on\nmulti-view learning that aims at fusing the outputs of the two stream networks\nare proposed and examined. These models exploit the spatio-temporal MEG data\nfor learning new representations that are used to decode the relevant tasks\nacross subjects. In order to realize the most relevant features of the input\nsignals, two attention mechanisms, i.e. self and global attention, are\nincorporated in all the models. The experimental results of cross subject\nmulti-class classification on the studied MEG dataset show that the inclusion\nof attention improves the generalization of the models across subjects.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 05:51:57 GMT"}, {"version": "v2", "created": "Sat, 4 Jul 2020 19:28:11 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Abdellaoui", "Ismail Alaoui", ""], ["Fernandez", "Jesus Garcia", ""], ["Sahinli", "Caner", ""], ["Mehrkanoon", "Siamak", ""]]}, {"id": "2007.01378", "submitter": "Enzo Tagliazucchi", "authors": "Yonatan Sanz Perl, Hern\\'an Boccacio, Ignacio P\\'erez-Ipi\\~na,\n  Federico Zamberl\\'an, Helmut Laufs, Morten Kringelbach, Gustavo Deco, Enzo\n  Tagliazucchi", "title": "Generative embeddings of brain collective dynamics using variational\n  autoencoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of encoding pairwise correlations between coupled\ndynamical systems in a low-dimensional latent space based on few distinct\nobservations. We used variational autoencoders (VAE) to embed temporal\ncorrelations between coupled nonlinear oscillators that model brain states in\nthe wake-sleep cycle into a two-dimensional manifold. Training a VAE with\nsamples generated using two different parameter combinations resulted in an\nembedding that represented the whole repertoire of collective dynamics, as well\nas the topology of the underlying connectivity network. We first followed this\napproach to infer the trajectory of brain states measured from wakefulness to\ndeep sleep from the two endpoints of this trajectory; next, we showed that the\nsame architecture was capable of representing the pairwise correlations of\ngeneric Landau-Stuart oscillators coupled by complex network topology\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 20:43:52 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Perl", "Yonatan Sanz", ""], ["Boccacio", "Hern\u00e1n", ""], ["P\u00e9rez-Ipi\u00f1a", "Ignacio", ""], ["Zamberl\u00e1n", "Federico", ""], ["Laufs", "Helmut", ""], ["Kringelbach", "Morten", ""], ["Deco", "Gustavo", ""], ["Tagliazucchi", "Enzo", ""]]}, {"id": "2007.02047", "submitter": "Haiping Huang", "authors": "Zijian Jiang, Jianwen Zhou, and Haiping Huang", "title": "Relationship between manifold smoothness and adversarial vulnerability\n  in deep learning with local errors", "comments": "10 pages, 8 figures, to appear in Chin. Phys. B (2021)", "journal-ref": "Chin. Phys. B Vol. 30, No. 4 (2021) 048702", "doi": "10.1088/1674-1056/abd68e", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks can achieve impressive performances, and even\noutperform humans in some specific tasks. Nevertheless, unlike biological\nbrains, the artificial neural networks suffer from tiny perturbations in\nsensory input, under various kinds of adversarial attacks. It is therefore\nnecessary to study the origin of the adversarial vulnerability. Here, we\nestablish a fundamental relationship between geometry of hidden representations\n(manifold perspective) and the generalization capability of the deep networks.\nFor this purpose, we choose a deep neural network trained by local errors, and\nthen analyze emergent properties of trained networks through the manifold\ndimensionality, manifold smoothness, and the generalization capability. To\nexplore effects of adversarial examples, we consider independent Gaussian noise\nattacks and fast-gradient-sign-method (FGSM) attacks. Our study reveals that a\nhigh generalization accuracy requires a relatively fast power-law decay of the\neigen-spectrum of hidden representations. Under Gaussian attacks, the\nrelationship between generalization accuracy and power-law exponent is\nmonotonic, while a non-monotonic behavior is observed for FGSM attacks. Our\nempirical study provides a route towards a final mechanistic interpretation of\nadversarial vulnerability under adversarial attacks.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 08:47:51 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2020 05:27:53 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Jiang", "Zijian", ""], ["Zhou", "Jianwen", ""], ["Huang", "Haiping", ""]]}, {"id": "2007.02062", "submitter": "Manuel Beiran", "authors": "Manuel Beiran, Alexis Dubreuil, Adrian Valente, Francesca\n  Mastrogiuseppe, Srdjan Ostojic", "title": "Shaping dynamics with multiple populations in low-rank recurrent\n  networks", "comments": "29 pages, 7 figures", "journal-ref": null, "doi": "10.1162/neco_a_01381", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging paradigm proposes that neural computations can be understood at\nthe level of dynamical systems that govern low-dimensional trajectories of\ncollective neural activity. How the connectivity structure of a network\ndetermines the emergent dynamical system however remains to be clarified. Here\nwe consider a novel class of models, Gaussian-mixture low-rank recurrent\nnetworks, in which the rank of the connectivity matrix and the number of\nstatistically-defined populations are independent hyper-parameters. We show\nthat the resulting collective dynamics form a dynamical system, where the rank\nsets the dimensionality and the population structure shapes the dynamics. In\nparticular, the collective dynamics can be described in terms of a simplified\neffective circuit of interacting latent variables. While having a single,\nglobal population strongly restricts the possible dynamics, we demonstrate that\nif the number of populations is large enough, a rank-R network can approximate\nany R-dimensional dynamical system.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 10:13:04 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 08:40:09 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Beiran", "Manuel", ""], ["Dubreuil", "Alexis", ""], ["Valente", "Adrian", ""], ["Mastrogiuseppe", "Francesca", ""], ["Ostojic", "Srdjan", ""]]}, {"id": "2007.02197", "submitter": "Mar\\'ia da Fonseca", "authors": "Mar\\'ia da Fonseca and In\\'es Samengo", "title": "Statistical properties of color matching functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In trichromats, color vision entails the projection of an\ninfinite-dimensional space (the one containing all possible electromagnetic\npower spectra) onto the 3-dimensional space that modulates the activity of the\nthree types of cones. This drastic reduction in dimensionality gives rise to\nmetamerism, that is, the perceptual chromatic equivalence between two different\nlight spectra. The classes of equivalence of metamerism are revealed by\ncolor-matching experiments, in which observers adjust the intensity of three\nmonochromatic light beams of three pre-set wavelengths (the primaries) to\nproduce a mixture that is perceptually equal to a given monochromatic target\nstimulus. Here we use the linear relation between the color matching functions\nand the absorption probabilities of each type of cone to find particularly\nuseful triplets of primaries. As a second goal, we also derive an analytical\ndescription of the trial-to-trial variability and the correlations of color\nmatching functions stemming from Poissonian noise in photon capture. We analyze\nhow the statistical properties of the responses to color-matching experiments\nvary with the retinal composition and the wavelengths of peak absorption\nprobability, and compare them with experimental data on subject-to-subject\nvariability obtained previously.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 22:10:33 GMT"}, {"version": "v2", "created": "Sat, 1 May 2021 18:34:08 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["da Fonseca", "Mar\u00eda", ""], ["Samengo", "In\u00e9s", ""]]}, {"id": "2007.02198", "submitter": "Yun Zhao", "authors": "Yun Zhao, Richard Jiang, Zhenni Xu, Elmer Guzman, Paul K. Hansma,\n  Linda Petzold", "title": "Scalable Bayesian Functional Connectivity Inference for Multi-Electrode\n  Array Recordings", "comments": "in BIOKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-electrode arrays (MEAs) can record extracellular action potentials\n(also known as 'spikes') from hundreds or thousands of neurons simultaneously.\nInference of a functional network from a spike train is a fundamental and\nformidable computational task in neuroscience. With the advancement of MEA\ntechnology, it has become increasingly crucial to develop statistical tools for\nanalyzing multiple neuronal activity as a network. In this paper, we propose a\nscalable Bayesian framework for inference of functional networks from MEA data.\nOur framework makes use of the hierarchical structure of networks of neurons.\nWe split the large scale recordings into smaller local networks for network\ninference, which not only eases the computational burden from Bayesian sampling\nbut also provides useful insights on regional connections in organoids and\nbrains. We speed up the expensive Bayesian sampling process by using parallel\ncomputing. Experiments on both synthetic datasets and large-scale real-world\nMEA recordings show the effectiveness and efficiency of the scalable Bayesian\nframework. Inference of networks from controlled experiments exposing neural\ncultures to cadmium presents distinguishable results and further confirms the\nutility of our framework.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jul 2020 22:24:46 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Zhao", "Yun", ""], ["Jiang", "Richard", ""], ["Xu", "Zhenni", ""], ["Guzman", "Elmer", ""], ["Hansma", "Paul K.", ""], ["Petzold", "Linda", ""]]}, {"id": "2007.02511", "submitter": "Junhao Liang", "authors": "Junhao Liang, Sheng-Jun Wang, Changsong Zhou", "title": "Less is More: Wiring-Economical Modular Networks Support Self-Sustained\n  Firing-Economical Neural Avalanches for Efficient Processing", "comments": "19 pages, 6 figures", "journal-ref": "National Science Review, nwab102, Published: 10 June 2021", "doi": "10.1093/nsr/nwab102", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain network is remarkably cost-efficient while the fundamental physical and\ndynamical mechanisms underlying its economical optimization in network\nstructure and activity are not clear. Here we study intricate cost-efficient\ninterplay between structure and dynamics in biologically plausible spatial\nmodular neuronal network models. We find that critical avalanche states from\nexcitation-inhibition balance, under modular network topology with less wiring\ncost, can also achieve less costs in firing, but with strongly enhanced\nresponse sensitivity to stimuli. We derived mean-field equations that govern\nthe macroscopic network dynamics through a novel approximate theory. The\nmechanism of low firing cost and stronger response in the form of critical\navalanche is explained as a proximity to a Hopf bifurcation of the modules when\nincreasing their connection density. Our work reveals the generic mechanism\nunderlying the cost-efficient modular organization and critical dynamics widely\nobserved in neural systems, providing insights to brain-inspired efficient\ncomputational designs.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 03:31:52 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2020 02:22:10 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2021 06:17:20 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Liang", "Junhao", ""], ["Wang", "Sheng-Jun", ""], ["Zhou", "Changsong", ""]]}, {"id": "2007.02783", "submitter": "Maria Luisa Saggio", "authors": "Maria Luisa Saggio and Viktor Jirsa", "title": "Phenomenological Mesoscopic Models for Seizure Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter we review phenomenological models of seizure like activity.\nWe discuss dynamical mechanisms for seizure onset and offset, preictal spikes,\nspike and wave complexes and status epilepticus, highlighting the role played\nby the bifurcation structure of the model, the presence of noise and the\nemergence of multiple interacting time-scales. These models can be used to\nbuild large-scale patient specific brain network models serving as in-silico\nplatforms to test clinical hypothesis and perform virtual surgeries. They\nsuggest innovative treatment strategies, such as minimally invasive ablations\nor stimulations that fully exploit the network and dynamical properties of the\nsystem, or even modulation of variables and parameters to force the system in\nsafer regions of the bifurcation diagram. We discuss insights from\nphenomenological models that can help to foster our understanding of the\nmechanisms underlying epileptic seizures.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 14:32:43 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Saggio", "Maria Luisa", ""], ["Jirsa", "Viktor", ""]]}, {"id": "2007.03124", "submitter": "Yotam Sagiv", "authors": "Yotam Sagiv, Sebastian Musslick, Yael Niv, Jonathan D. Cohen", "title": "Efficiency of learning vs. processing: Towards a normative theory of\n  multitasking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A striking limitation of human cognition is our inability to execute some\ntasks simultaneously. Recent work suggests that such limitations can arise from\na fundamental tradeoff in network architectures that is driven by the sharing\nof representations between tasks: sharing promotes quicker learning, at the\nexpense of interference while multitasking. From this perspective, multitasking\nfailures might reflect a preference for learning efficiency over multitasking\ncapability. We explore this hypothesis by formulating an ideal Bayesian agent\nthat maximizes expected reward by learning either shared or separate\nrepresentations for a task set. We investigate the agent's behavior and show\nthat over a large space of parameters the agent sacrifices long-run optimality\n(higher multitasking capacity) for short-term reward (faster learning).\nFurthermore, we construct a general mathematical framework in which rational\nchoices between learning speed and processing efficiency can be examined for a\nvariety of different task environments.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2020 23:41:13 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Sagiv", "Yotam", ""], ["Musslick", "Sebastian", ""], ["Niv", "Yael", ""], ["Cohen", "Jonathan D.", ""]]}, {"id": "2007.03208", "submitter": "Min-Chun Wu", "authors": "Min-Chun Wu, Vladimir Itskov", "title": "A Topological Approach to Inferring the Intrinsic Dimension of Convex\n  Sensing Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AT math.CO q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a common measurement paradigm, where an unknown subset of an\naffine space is measured by unknown continuous quasi-convex functions. Given\nthe measurement data, can one determine the dimension of this space? In this\npaper, we develop a method for inferring the intrinsic dimension of the data\nfrom measurements by quasi-convex functions, under natural generic assumptions.\n  The dimension inference problem depends only on discrete data of the ordering\nof the measured points of space, induced by the sensor functions. We introduce\na construction of a filtration of Dowker complexes, associated to measurements\nby quasi-convex functions. Topological features of these complexes are then\nused to infer the intrinsic dimension. We prove convergence theorems that\nguarantee obtaining the correct intrinsic dimension in the limit of large data,\nunder natural generic assumptions. We also illustrate the usability of this\nmethod in simulations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 05:35:23 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Wu", "Min-Chun", ""], ["Itskov", "Vladimir", ""]]}, {"id": "2007.03243", "submitter": "Oleksandr Oliynyk", "authors": "Lin Ren, Alexander Oleinick (PASTEUR), Irina Svir (PASTEUR), Christian\n  Amatore (PASTEUR), Andrew Ewing", "title": "Amperometric Measurements and Dynamic Models Reveal a Mechanism for How\n  Zinc Alters Neurotransmitter Release", "comments": null, "journal-ref": "Angewandte Chemie International Edition, Wiley-VCH Verlag, 2020,\n  59 (8), pp.3083-3087", "doi": "10.1002/anie.201913184", "report-no": null, "categories": "q-bio.NC q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Zinc, a suspected potentiator of learning and memory, is shown to affect\nexocytotic release and storage in neurotransmitter-containing vesicles.\nStructural and size analysis of the vesicular dense core and halo using\ntransmission electron microscopy was combined with single-cell amperometry to\nstudy the vesicle size changes induced after zinc treatment and to compare\nthese changes to theoretical predictions based on the concept of partial\nrelease as opposed to full quantal release. This powerful combined analytical\napproach establishes the existence of an unsuspected strong link between\nvesicle structure and exocytotic dynamics which can be used to explain the\nmechanism of regulation of synaptic plasticity by Zn 2+ through modulation of\nneurotransmitter release.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 07:26:02 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Ren", "Lin", "", "PASTEUR"], ["Oleinick", "Alexander", "", "PASTEUR"], ["Svir", "Irina", "", "PASTEUR"], ["Amatore", "Christian", "", "PASTEUR"], ["Ewing", "Andrew", ""]]}, {"id": "2007.03246", "submitter": "Oleksandr Oliynyk", "authors": "Anna Larsson, Soodabeh Majdi, Alexander Oleinick (PASTEUR), Irina Svir\n  (PASTEUR), Johan Dunevall, Christian Amatore (PASTEUR), Andrew Ewing", "title": "Intracellular Electrochemical Nanomeasurements Reveal that Exocytosis of\n  Molecules at Living Neurons is Subquantal and Complex", "comments": null, "journal-ref": "Angewandte Chemie International Edition, Wiley-VCH Verlag, 2020,\n  59 (17), pp.6711-6714", "doi": "10.1002/anie.201914564", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the early work of Bernard Katz, the process of cellular chemical\ncommunication via exocytosis, quantal release, has been considered to be all or\nnone. Recent evidence has shown exocytosis to be partial or 'subquantal' at\nsingle-cell model systems, but there is a need to understand this at\ncommunicating nerve cells. Partial release allows nerve cells to control the\nsignal at the site of release during individual events, where the smaller the\nfraction released, the greater the range of regulation. Here we show that the\nfraction of the vesicular octopamine content released from a living Drosophila\nlarval neuromuscular neuron is very small. The percentage of released molecules\nwas found to be only 4.5% for simple events and 10.7% for complex (i.e.,\noscillating or flickering) events. This large content, combined with partial\nrelease controlled by fluctuations of the fusion pore, offers presynaptic\nplasticity that can be widely regulated. Two works published in 2010 suggested\nthat the Katz principle, [1] was incorrect for all-or-none release and that\nonly part of the chemical load of vesicles was released during exocytosis, at\nleast as measured as a full spike during amperometry. [2] The combination of\nelectrochemical methods to measure both release and vesicle content in 2015\nadded a wealth of information to support the concept of partial release in\nexocytosis. [3] Additionally, this has recently been supported by work with\nTIRF microscopy showing 'subquantal' release from vesicles in adrenal\nchromaffin cells and using super-resolution STED microscopy. [4] It appears\nthat the full event generally involves release of only part of the load of\nchemical messenger in single-cell model systems like adrenal chromaffin and\nPC12 cells. Is this also true at living neurons in a nervous system and to what\nextent? To answer this critical question, we quantified the number of\noctopamine molecules in the neuromuscular neurons of Drosophila larvae by\nadapting an amperometric technique developed in our\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 07:31:35 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Larsson", "Anna", "", "PASTEUR"], ["Majdi", "Soodabeh", "", "PASTEUR"], ["Oleinick", "Alexander", "", "PASTEUR"], ["Svir", "Irina", "", "PASTEUR"], ["Dunevall", "Johan", "", "PASTEUR"], ["Amatore", "Christian", "", "PASTEUR"], ["Ewing", "Andrew", ""]]}, {"id": "2007.03367", "submitter": "Franz Paul Spitzner", "authors": "F. P. Spitzner, J. Dehning, J. Wilting, A. Hagemann, J. P. Neto, J.\n  Zierenberg, V. Priesemann", "title": "MR. Estimator, a toolbox to determine intrinsic timescales from\n  subsampled spiking activity", "comments": null, "journal-ref": "PLOS ONE 16, e0249447 (2021)", "doi": "10.1371/journal.pone.0249447", "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present our Python toolbox \"MR. Estimator\" to reliably estimate the\nintrinsic timescale from electrophysiologal recordings of heavily subsampled\nsystems. Originally intended for the analysis of time series from neuronal\nspiking activity, our toolbox is applicable to a wide range of systems where\nsubsampling -- the difficulty to observe the whole system in full detail --\nlimits our capability to record. Applications range from epidemic spreading to\nany system that can be represented by an autoregressive process.\n  In the context of neuroscience, the intrinsic timescale can be thought of as\nthe duration over which any perturbation reverberates within the network; it\nhas been used as a key observable to investigate a functional hierarchy across\nthe primate cortex and serves as a measure of working memory. It is also a\nproxy for the distance to criticality and quantifies a system's dynamic working\npoint.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 11:57:31 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 18:35:11 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Spitzner", "F. P.", ""], ["Dehning", "J.", ""], ["Wilting", "J.", ""], ["Hagemann", "A.", ""], ["Neto", "J. P.", ""], ["Zierenberg", "J.", ""], ["Priesemann", "V.", ""]]}, {"id": "2007.03750", "submitter": "Jane Wang", "authors": "Matthew Botvinick, Jane X. Wang, Will Dabney, Kevin J. Miller, Zeb\n  Kurth-Nelson", "title": "Deep Reinforcement Learning and its Neuroscientific Implications", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The emergence of powerful artificial intelligence is defining new research\ndirections in neuroscience. To date, this research has focused largely on deep\nneural networks trained using supervised learning, in tasks such as image\nclassification. However, there is another area of recent AI work which has so\nfar received less attention from neuroscientists, but which may have profound\nneuroscientific implications: deep reinforcement learning. Deep RL offers a\ncomprehensive framework for studying the interplay among learning,\nrepresentation and decision-making, offering to the brain sciences a new set of\nresearch tools and a wide range of novel hypotheses. In the present review, we\nprovide a high-level introduction to deep RL, discuss some of its initial\napplications to neuroscience, and survey its wider implications for research on\nbrain and behavior, concluding with a list of opportunities for next-stage\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 19:27:54 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Botvinick", "Matthew", ""], ["Wang", "Jane X.", ""], ["Dabney", "Will", ""], ["Miller", "Kevin J.", ""], ["Kurth-Nelson", "Zeb", ""]]}, {"id": "2007.03774", "submitter": "Xin Wang", "authors": "Xin Wang", "title": "The curious case of developmental BERTology: On sparsity, transfer\n  learning, generalization and the brain", "comments": "9 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this essay, we explore a point of intersection between deep learning and\nneuroscience, through the lens of large language models, transfer learning and\nnetwork compression. Just like perceptual and cognitive neurophysiology has\ninspired effective deep neural network architectures which in turn make a\nuseful model for understanding the brain, here we explore how biological neural\ndevelopment might inspire efficient and robust optimization procedures which in\nturn serve as a useful model for the maturation and aging of the brain.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jul 2020 20:16:30 GMT"}], "update_date": "2020-07-09", "authors_parsed": [["Wang", "Xin", ""]]}, {"id": "2007.04245", "submitter": "Ka Chun Lam", "authors": "Ka Chun Lam, Francisco Pereira, Maryam Vaziri-Pashkam, Kristin\n  Woodard, Emalie McMahon", "title": "Mental representations of objects reflect the ways in which we interact\n  with them", "comments": "17 pages, 13 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to interact with objects in our environment, humans rely on an\nunderstanding of the actions that can be performed on them, as well as their\nproperties. When considering concrete motor actions, this knowledge has been\ncalled the object affordance. Can this notion be generalized to any type of\ninteraction that one can have with an object? In this paper we introduce a\nmethod to represent objects in a space where each dimension corresponds to a\nbroad mode of interaction, based on verb selectional preferences in text\ncorpora. This object embedding makes it possible to predict human judgments of\nverb applicability to objects better than a variety of alternative approaches.\nFurthermore, we show that the dimensions in this space can be used to predict\ncategorical and functional dimensions in a state-of-the-art mental\nrepresentation of objects, derived solely from human judgements of object\nsimilarity. These results suggest that interaction knowledge accounts for a\nlarge part of mental representations of objects.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2020 22:05:56 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 13:06:41 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Lam", "Ka Chun", ""], ["Pereira", "Francisco", ""], ["Vaziri-Pashkam", "Maryam", ""], ["Woodard", "Kristin", ""], ["McMahon", "Emalie", ""]]}, {"id": "2007.04370", "submitter": "Gloria Cecchini", "authors": "Lorenzo Chicchi, Gloria Cecchini, Ihusan Adam, Giuseppe de Vito,\n  Roberto Livi, Francesco Saverio Pavone, Ludovico Silvestri, Lapo Turrini,\n  Francesco Vanzi, Duccio Fanelli", "title": "Reconstruction scheme for excitatory and inhibitory dynamics with\n  quenched disorder: application to zebrafish imaging", "comments": null, "journal-ref": "Journal of Computational Neuroscience 49, 159-174 (2021)", "doi": "10.1007/s10827-020-00774-1", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An inverse procedure is developed and tested to recover functional and\nstructural information from global signals of brains activity. The method\nassumes a leaky-integrate and fire model with excitatory and inhibitory\nneurons, coupled via a directed network. Neurons are endowed with a\nheterogenous current value, which sets their associated dynamical regime. By\nmaking use of a heterogenous mean-field approximation, the method seeks to\nreconstructing from global activity patterns the distribution of in-coming\ndegrees, for both excitatory and inhibitory neurons, as well as the\ndistribution of the assigned currents. The proposed inverse scheme is first\nvalidated against synthetic data. Then, time-lapse acquisitions of a zebrafish\nlarva recorded with a two-photon light sheet microscope are used as an input to\nthe reconstruction algorithm. A power law distribution of the in-coming\nconnectivity of the excitatory neurons is found. Local degree distributions are\nalso computed by segmenting the whole brain in sub-regions traced from\nannotated atlas.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 18:58:23 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Chicchi", "Lorenzo", ""], ["Cecchini", "Gloria", ""], ["Adam", "Ihusan", ""], ["de Vito", "Giuseppe", ""], ["Livi", "Roberto", ""], ["Pavone", "Francesco Saverio", ""], ["Silvestri", "Ludovico", ""], ["Turrini", "Lapo", ""], ["Vanzi", "Francesco", ""], ["Fanelli", "Duccio", ""]]}, {"id": "2007.04500", "submitter": "Johann H. Mart\\'inez", "authors": "J. Mendoza-Ruiz, C. E. Alonso-Malaver, M. Valderrama, O. A. Rosso,\n  J.H. Mart\\'inez", "title": "Dynamics in cortical activity revealed by resting-state MEG rhythms", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": "10.1063/5.0025189", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain may be thought of as a many-body architecture with a\nspatio-temporal dynamics described by neuronal structures. The oscillatory\nnature of brain activity allows these structures (nodes) to be described as a\nset of coupled oscillators forming a network where the node dynamics, and that\nof the network topology can be studied. Quantifying its dynamics at various\nscales is an issue that claims to be explored for several brain activities,\ne.g., activity at rest. The resting-state associates the underlying brain\ndynamics of healthy subjects that are not actively compromised with sensory or\ncognitive processes. Studying its dynamics is highly non-trivial but opens the\ndoor to understand the general principles of brain functioning. We hypothesize\nabout how could be the spatio-temporal dynamics of cortical fluctuations for\nhealthy subjects at resting-state. We retrieve the alphabet that reconstructs\nthe dynamics (entropy/complexity) of magnetoencephalograpy signals. We assemble\nthe cortical connectivity to elicit the network's dynamics. We depict an order\nrelation between entropy/complexity for frequency bands. We unveiled that the\nposterior cortex conglomerates nodes with both stronger dynamics and high\nclustering for {\\alpha} band. The existence of these order relations suggests\nan emergent phenomenon of each band. Interestingly, we find that the posterior\ncortex plays a cardinal role in both the dynamics and structure regarding the\nresting-state. To the best of our knowledge, this is the first study with\nmagnetoencephalograpy involving information theory and network science to\nbetter understand the dynamics and structure of brain activity at rest for\ndifferent bands and scales.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 01:37:26 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Mendoza-Ruiz", "J.", ""], ["Alonso-Malaver", "C. E.", ""], ["Valderrama", "M.", ""], ["Rosso", "O. A.", ""], ["Mart\u00ednez", "J. H.", ""]]}, {"id": "2007.04578", "submitter": "Dongjae Kim", "authors": "Dongjae Kim and Jee Hang Lee, Jae Hoon Shin, Minsu Abel Yang, Sang Wan\n  Lee", "title": "On the Reliability and Generalizability of Brain-inspired Reinforcement\n  Learning Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although deep RL models have shown a great potential for solving various\ntypes of tasks with minimal supervision, several key challenges remain in terms\nof learning from limited experience, adapting to environmental changes, and\ngeneralizing learning from a single task. Recent evidence in decision\nneuroscience has shown that the human brain has an innate capacity to resolve\nthese issues, leading to optimism regarding the development of\nneuroscience-inspired solutions toward sample-efficient, and generalizable RL\nalgorithms. We show that the computational model combining model-based and\nmodel-free control, which we term the prefrontal RL, reliably encodes the\ninformation of high-level policy that humans learned, and this model can\ngeneralize the learned policy to a wide range of tasks. First, we trained the\nprefrontal RL, and deep RL algorithms on 82 subjects' data, collected while\nhuman participants were performing two-stage Markov decision tasks, in which we\nmanipulated the goal, state-transition uncertainty and state-space complexity.\nIn the reliability test, which includes the latent behavior profile and the\nparameter recoverability test, we showed that the prefrontal RL reliably\nlearned the latent policies of the humans, while all the other models failed.\nSecond, to test the ability to generalize what these models learned from the\noriginal task, we situated them in the context of environmental volatility.\nSpecifically, we ran large-scale simulations with 10 Markov decision tasks, in\nwhich latent context variables change over time. Our information-theoretic\nanalysis showed that the prefrontal RL showed the highest level of adaptability\nand episodic encoding efficacy. This is the first attempt to formally test the\npossibility that computational models mimicking the way the brain solves\ngeneral problems can lead to practical solutions to key challenges in machine\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2020 06:32:42 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Kim", "Dongjae", ""], ["Lee", "Jee Hang", ""], ["Shin", "Jae Hoon", ""], ["Yang", "Minsu Abel", ""], ["Lee", "Sang Wan", ""]]}, {"id": "2007.04982", "submitter": "Alexandros Arvanitakis", "authors": "Alexandros Arvanitakis", "title": "Recursion and evolution: Part II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.LO q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the question of whether it is possible for a diagonalizing system,\nto learn to use environmental reward and punishment as an information, in order\nto appropriately adapt. More specifically, we study the possiblity of such a\nsystem, to learn to use diagonalization on the basis of a rewarding function.\nRelevant phenomena regarding memory are also investigated.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2020 14:27:56 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Arvanitakis", "Alexandros", ""]]}, {"id": "2007.05112", "submitter": "William Podlaski", "authors": "William F. Podlaski, Christian K. Machens", "title": "Biological credit assignment through dynamic inversion of feedforward\n  networks", "comments": "34th Conference on Neural Information Processing Systems (NeurIPS\n  2020), Vancouver, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning depends on changes in synaptic connections deep inside the brain. In\nmultilayer networks, these changes are triggered by error signals fed back from\nthe output, generally through a stepwise inversion of the feedforward\nprocessing steps. The gold standard for this process -- backpropagation --\nworks well in artificial neural networks, but is biologically implausible.\nSeveral recent proposals have emerged to address this problem, but many of\nthese biologically-plausible schemes are based on learning an independent set\nof feedback connections. This complicates the assignment of errors to each\nsynapse by making it dependent upon a second learning problem, and by fitting\ninversions rather than guaranteeing them. Here, we show that feedforward\nnetwork transformations can be effectively inverted through dynamics. We derive\nthis dynamic inversion from the perspective of feedback control, where the\nforward transformation is reused and dynamically interacts with fixed or random\nfeedback to propagate error signals during the backward pass. Importantly, this\nscheme does not rely upon a second learning problem for feedback because\naccurate inversion is guaranteed through the network dynamics. We map these\ndynamics onto generic feedforward networks, and show that the resulting\nalgorithm performs well on several supervised and unsupervised datasets.\nFinally, we discuss potential links between dynamic inversion and second-order\noptimization. Overall, our work introduces an alternative perspective on credit\nassignment in the brain, and proposes a special role for temporal dynamics and\nfeedback control during learning.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 00:03:01 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2021 00:31:24 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Podlaski", "William F.", ""], ["Machens", "Christian K.", ""]]}, {"id": "2007.05395", "submitter": "Matteo Fraschini", "authors": "Matteo Fraschini, Simone Maurizio La Cava, Luca Didaci and Luigi\n  Barberini", "title": "On the variability of functional connectivity and network measures in\n  source-reconstructed EEG time-series", "comments": null, "journal-ref": null, "doi": "10.3390/e23010005", "report-no": null, "categories": "q-bio.NC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The idea to estimate the statistical interdependence among (interacting)\nbrain regions has motivated numerous researchers to investigate how the\nresulting connectivity patterns and networks may organize themselves under any\nconceivable scenario. Even though this idea is not at initial stages, its\npractical application is still far to be widespread. One concurrent cause may\nbe related to the proliferation of different approaches that aim to catch the\nunderlying correlation among the (interacting) units. This issue has probably\ncontributed to hinder the comparison among different studies. Not only all\nthese approaches go under the same name (functional connectivity), but they\nhave been often tested and validated using different methods, therefore, making\nit difficult to understand to what extent they are similar or not. In this\nstudy, we aim to compare a set of different approaches commonly used to\nestimate the functional connectivity on a public EEG dataset representing a\npossible realistic scenario. As expected, our results show that source-level\nEEG connectivity estimates and the derived network measures, even though\npointing to the same direction, may display substantial dependency on the\n(often arbitrary) choice of the selected connectivity metric and thresholding\napproach. In our opinion, the observed variability reflects ambiguity and\nconcern that should always be discussed when reporting findings based on any\nconnectivity metric.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jul 2020 14:01:31 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2020 18:32:50 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Fraschini", "Matteo", ""], ["La Cava", "Simone Maurizio", ""], ["Didaci", "Luca", ""], ["Barberini", "Luigi", ""]]}, {"id": "2007.05595", "submitter": "Andrey L. Shilnikov", "authors": "Marina L. Kolomiets and Andrey L. Shilnikov", "title": "Poincare return maps in neural dynamics: three examples", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding of the onset and generic mechanisms of transitions between\ndistinct patterns of activity in realistic models of individual neurons and\nneural networks presents a fundamental challenge for the theory of applied\ndynamical systems. We use three examples of slow-fast neural systems to\ndemonstrate a suite of new computational tools to study diverse neuronal\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jul 2020 20:10:59 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Kolomiets", "Marina L.", ""], ["Shilnikov", "Andrey L.", ""]]}, {"id": "2007.05800", "submitter": "Dimitrios Adamos Dr", "authors": "Nikolaos Laskaris, Dimitrios A. Adamos, Anastasios Bezerianos", "title": "A Tutorial on Graph Theory for Brain Signal Analysis", "comments": "To appear in Springer Handbook of Neuroengineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial paper refers to the use of graph-theoretic concepts for\nanalyzing brain signals. For didactic purposes it splits into two parts: theory\nand application. In the first part, we commence by introducing some basic\nelements from graph theory and stemming algorithmic tools, which can be\nemployed for data-analytic purposes. Next, we describe how these concepts are\nadapted for handling evolving connectivity and gaining insights into network\nreorganization. Finally, the notion of signals residing on a given graph is\nintroduced and elements from the emerging field of graph signal processing\n(GSP) are provided. The second part serves as a pragmatic demonstration of the\ntools and techniques described earlier. It is based on analyzing a multi-trial\ndataset containing single-trial responses from a visual ERP paradigm. The paper\nends with a brief outline of the most recent trends in graph theory that are\nabout to shape brain signal processing in the near future and a more general\ndiscussion on the relevance of graph-theoretic methodologies for analyzing\ncontinuous-mode neural recordings.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jul 2020 15:36:52 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Laskaris", "Nikolaos", ""], ["Adamos", "Dimitrios A.", ""], ["Bezerianos", "Anastasios", ""]]}, {"id": "2007.06294", "submitter": "Leonard Elia van Dyck", "authors": "Leonard E. van Dyck and Walter R. Gruber", "title": "Seeing eye-to-eye? A comparison of object recognition performance in\n  humans and deep convolutional neural networks under image manipulation", "comments": "19 pages, 7 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a considerable time, deep convolutional neural networks (DCNNs) have\nreached human benchmark performance in object recognition. On that account,\ncomputational neuroscience and the field of machine learning have started to\nattribute numerous similarities and differences to artificial and biological\nvision. This study aims towards a behavioral comparison of visual core object\nrecognition performance between humans and feedforward neural networks in a\nclassification learning paradigm on an ImageNet data set. For this purpose,\nhuman participants (n = 65) competed in an online experiment against different\nfeedforward DCNNs. The designed approach based on a typical learning process of\nseven different monkey categories included a training and validation phase with\nnatural examples, as well as a testing phase with novel, unexperienced shape\nand color manipulations. Analyses of accuracy revealed that humans not only\noutperform DCNNs on all conditions, but also display significantly greater\nrobustness towards shape and most notably color alterations. Furthermore, a\nprecise examination of behavioral patterns highlights these findings by\nrevealing independent classification errors between the groups. The obtained\nresults show that humans contrast strongly with artificial feedforward\narchitectures when it comes to visual core object recognition of manipulated\nimages. In general, these findings are in line with a growing body of\nliterature, that hints towards recurrence as a crucial factor for adequate\ngeneralization abilities.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 10:26:30 GMT"}, {"version": "v2", "created": "Sun, 13 Dec 2020 11:08:45 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["van Dyck", "Leonard E.", ""], ["Gruber", "Walter R.", ""]]}, {"id": "2007.06407", "submitter": "Marko Angjelichinoski", "authors": "Marko Angjelichinoski, Bijan Pesaran and Vahid Tarokh", "title": "Deep Cross-Subject Mapping of Neural Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective. In this paper, we consider the problem of cross-subject decoding,\nwhere neural activity data collected from the prefrontal cortex of a given\nsubject (destination) is used to decode motor intentions from the neural\nactivity of a different subject (source). Approach. We cast the problem of\nneural activity mapping in a probabilistic framework where we adopt deep\ngenerative modelling. Our proposed algorithm uses deep conditional variational\nautoencoder to infer the representation of the neural activity of the source\nsubject into an adequate feature space of the destination subject where neural\ndecoding takes place. Results. We verify our approach on an experimental data\nset in which two macaque monkeys perform memory-guided visual saccades to one\nof eight target locations. The results show a peak cross-subject decoding\nimprovement of $8\\%$ over subject-specific decoding. Conclusion. We demonstrate\nthat a neural decoder trained on neural activity signals of one subject can be\nused to robustly decode the motor intentions of a different subject with high\nreliability. This is achieved in spite of the non-stationary nature of neural\nactivity signals and the subject-specific variations of the recording\nconditions. Significance. The findings reported in this paper are an important\nstep towards the development of cross-subject brain-computer that generalize\nwell across a population.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2020 14:35:02 GMT"}, {"version": "v2", "created": "Mon, 23 Nov 2020 18:05:37 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Angjelichinoski", "Marko", ""], ["Pesaran", "Bijan", ""], ["Tarokh", "Vahid", ""]]}, {"id": "2007.06442", "submitter": "Liane Gabora", "authors": "Liane Gabora and Mike Steel", "title": "Modeling a Cognitive Transition at the Origin of Cultural Evolution\n  using Autocatalytic Networks", "comments": "46 pages; 7 figures; accepted for publication (but not yet published)\n  in Cognitive Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autocatalytic networks have been used to model the emergence of\nself-organizing structure capable of sustaining life and undergoing biological\nevolution. Here, we model the emergence of cognitive structure capable of\nundergoing cultural evolution. Mental representations of knowledge and\nexperiences play the role of catalytic molecules, and interactions amongst them\n(e.g., the forging of new associations) play the role of reactions, and result\nin representational redescription. The approach tags mental representations\nwith their source, i.e., whether they were acquired through social learning,\nindividual learning (of pre-existing information), or creative thought\n(resulting in the generation of new information). This makes it possible to\nmodel how cognitive structure emerges, and to trace lineages of cumulative\nculture step by step. We develop a formal representation of the cultural\ntransition from Oldowan to Acheulean tool technology using Reflexively\nAutocatalytifc and Food set generated (RAF) networks. Unlike more primitive\nOldowan stone tools, the Acheulean hand axe required not only the capacity to\nenvision and bring into being something that did not yet exist, but\nhierarchically structured thought and action, and the generation of new mental\nrepresentations: the concepts EDGING, THINNING, SHAPING, and a meta-concept,\nHAND AXE. We show how this constituted a key transition towards the emergence\nof semantic networks that were self-organizing, self-sustaining, and\nautocatalytic, and discuss how such networks replicated through social\ninteraction. The model provides a promising approach to unraveling one of the\ngreatest anthropological mysteries: that of why development of the Acheulean\nhand axe was followed by over a million years of cultural stasis.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jul 2020 20:19:11 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Gabora", "Liane", ""], ["Steel", "Mike", ""]]}, {"id": "2007.06706", "submitter": "Boyang Lyu", "authors": "Boyang Lyu, Thao Pham, Giles Blaney, Zachary Haga, Angelo Sassaroli,\n  Sergio Fantini, Shuchin Aeron", "title": "Domain Adaptation for Robust Workload Level Alignment Between Sessions\n  and Subjects using fNIRS", "comments": null, "journal-ref": null, "doi": "10.1117/1.JBO.26.2.022908", "report-no": null, "categories": "cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significance: We demonstrated the potential of using domain adaptation on\nfunctional Near-Infrared Spectroscopy (fNIRS) data to classify different levels\nof n-back tasks that involve working memory. Aim: Domain shift in fNIRS data is\na challenge in the workload level alignment across different experiment\nsessions and subjects. In order to address this problem, two domain adaptation\napproaches -- Gromov-Wasserstein (G-W) and Fused Gromov-Wasserstein (FG-W) were\nused. Approach: Specifically, we used labeled data from one session or one\nsubject to classify trials in another session (within the same subject) or\nanother subject. We applied G-W for session-by-session alignment and FG-W for\nsubject-by-subject alignment to fNIRS data acquired during different n-back\ntask levels. We compared these approaches with three supervised methods:\nmulti-class Support Vector Machine (SVM), Convolutional Neural Network (CNN),\nand Recurrent Neural Network (RNN). Results: In a sample of six subjects, G-W\nresulted in an alignment accuracy of 68 $\\pm$ 4 % (weighted mean $\\pm$ standard\nerror) for session-by-session alignment, FG-W resulted in an alignment accuracy\nof 55 $\\pm$ 2 % for subject-by-subject alignment. In each of these cases, 25 %\naccuracy represents chance. Alignment accuracy results from both G-W and FG-W\nare significantly greater than those from SVM, CNN and RNN. We also showed that\nremoval of motion artifacts from the fNIRS data plays an important role in\nimproving alignment performance. Conclusions: Domain adaptation has potential\nfor session-by-session and subject-by-subject alignment of mental workload by\nusing fNIRS data.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jul 2020 18:03:50 GMT"}, {"version": "v2", "created": "Mon, 30 Nov 2020 01:52:13 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Lyu", "Boyang", ""], ["Pham", "Thao", ""], ["Blaney", "Giles", ""], ["Haga", "Zachary", ""], ["Sassaroli", "Angelo", ""], ["Fantini", "Sergio", ""], ["Aeron", "Shuchin", ""]]}, {"id": "2007.07500", "submitter": "Leonardo Novelli", "authors": "Leonardo Novelli and Joseph T. Lizier", "title": "Inferring network properties from time series using transfer entropy and\n  mutual information: validation of multivariate versus bivariate approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT cs.SI math.IT physics.data-an", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Functional and effective networks inferred from time series are at the core\nof network neuroscience. Interpreting their properties requires inferred\nnetwork models to reflect key underlying structural features; however, even a\nfew spurious links can distort network measures, challenging functional\nconnectomes. We study the extent to which micro- and macroscopic properties of\nunderlying networks can be inferred by algorithms based on mutual information\nand bivariate/multivariate transfer entropy. The validation is performed on two\nmacaque connectomes and on synthetic networks with various topologies (regular\nlattice, small-world, random, scale-free, modular). Simulations are based on a\nneural mass model and on autoregressive dynamics (employing Gaussian estimators\nfor direct comparison to functional connectivity and Granger causality). We\nfind that multivariate transfer entropy captures key properties of all networks\nfor longer time series. Bivariate methods can achieve higher recall\n(sensitivity) for shorter time series but are unable to control false positives\n(lower specificity) as available data increases. This leads to overestimated\nclustering, small-world, and rich-club coefficients, underestimated shortest\npath lengths and hub centrality, and fattened degree distribution tails.\nCaution should therefore be used when interpreting network properties of\nfunctional connectomes obtained via correlation or pairwise statistical\ndependence measures, rather than more holistic (yet data-hungry) multivariate\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 06:09:02 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 03:30:28 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Novelli", "Leonardo", ""], ["Lizier", "Joseph T.", ""]]}, {"id": "2007.07643", "submitter": "Peter Taylor", "authors": "Tom W. Owen, Jane de Tisi, Sjoerd B. Vos, Gavin P. Winston, John S.\n  Duncan, Yujiang Wang, Peter N. Taylor", "title": "Multivariate white matter alterations are associated with epilepsy\n  duration", "comments": "33 pages, 6 main figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previous studies investigating associations between white matter alterations\nand duration of temporal lobe epilepsy (TLE) have shown differing results, and\nwere typically limited to univariate analyses of tracts in isolation. In this\nstudy we apply a multivariate measure (the Mahalanobis distance), to capture\nthe distinct ways white matter may differ in individual patients, and relate\nthis to epilepsy duration.\n  Diffusion MRI, from a cohort of 94 subjects (28 healthy controls, 33 left-TLE\nand 33 right-TLE), was used to assess associations between tract fractional\nanisotropy (FA) and epilepsy duration. Using ten white matter tracts, we\nanalysed associations using traditional univariate analyses (z-scores) and a\ncomplementary multivariate approach (Mahalanobis distance), incorporating\nmultiple white matter tracts into a single unified analysis.\n  In patients with right-TLE, FA was not significantly associated with epilepsy\nduration for any tract studied in isolation. In patients with left-TLE, the FA\nof two limbic tracts (ipsilateral fornix, contralateral cingulum gyrus) was\nsignificantly negatively associated with epilepsy duration (Bonferonni\ncorrected p<0.05). Using a multivariate approach we found significant\nipsilateral positive associations with duration in both left, and right-TLE\ncohorts (left-TLE: Spearman's rho=0.487, right-TLE: Spearman's rho=0.422).\nExtrapolating our multivariate results to duration equals zero (i.e. at onset)\nwe found no significant difference between patients and controls. Associations\nusing the multivariate approach were more robust than univariate methods.\n  The multivariate distance measure provides non-overlapping and more robust\nresults than traditional univariate analyses. Future studies should consider\nadopting both frameworks into their analysis in order to ascertain a more\ncomplete understanding of epilepsy progression, regardless of laterality.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 12:00:15 GMT"}], "update_date": "2020-07-16", "authors_parsed": [["Owen", "Tom W.", ""], ["de Tisi", "Jane", ""], ["Vos", "Sjoerd B.", ""], ["Winston", "Gavin P.", ""], ["Duncan", "John S.", ""], ["Wang", "Yujiang", ""], ["Taylor", "Peter N.", ""]]}, {"id": "2007.07734", "submitter": "Agnieszka Pregowska", "authors": "Agnieszka Pregowska", "title": "Signal Fluctuations and the Information Transmission Rates in Binary\n  Communication Channels", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": "10.3390/e23010092", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In nervous system information is conveyed by sequence of action potentials\n(spikes-trains). As MacKay and McCulloch proposed, spike-trains can be\nrepresented as bits sequences coming from Information Sources. Previously, we\nstudied relations between Information Transmission Rates (ITR) carried out by\nthe spikes, their correlations, and frequencies. Here, we concentrate on the\nproblem of how spikes fluctuations affect ITR. The Information Theory Method\ndeveloped by Shannon is applied. Information Sources are modeled as stationary\nstochastic processes. We assume such sources as two states Markov processes. As\na spike-trains' fluctuation measure, we consider the Standard Deviation SD,\nwhich, in fact, measures average fluctuation of spikes around the average spike\nfrequency. We found that character of ITR and signal fluctuations relation\nstrongly depends on parameter s which is a sum of transitions probabilities\nfrom no spike state to spike state and vice versa. It turned out that for\nsmaller s (s<1) the quotient ITR/SD has a maximum and can tend to zero\ndepending on transition probabilities. While for s large enough 1<s the ITR/SD\nis separated from 0 for each s. Similar behavior was observed when we replaced\nShannon entropy terms in Markov entropy formula by their approximation with\npolynomials. We also show that the ITR quotient by Variance behaves in a\ncompletely different way. We show that for large transition parameter s the\nInformation Transmission Rate by SD will never decrease to 0. Specifically, for\n1<s<1.7 the ITR will be always, independently on transition probabilities which\nform this s, above the level of fluctuations, i.e. we have SD<ITR. We conclude\nthat in a more noisy environment, to get appropriate reliability and efficiency\nof transmission, Information Sources with higher tendency of transition from\nthe state no spike to spike state and vice versa should be applied.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 15:07:04 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2020 14:11:19 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Pregowska", "Agnieszka", ""]]}, {"id": "2007.07797", "submitter": "Varun Saravanan", "authors": "Varun Saravanan, Gordon J Berman, Samuel J Sober", "title": "Application of the hierarchical bootstrap to multi-level data in\n  neuroscience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common feature in many neuroscience datasets is the presence of\nhierarchical data structures, most commonly recording the activity of multiple\nneurons in multiple animals across multiple trials. Accordingly, the\nmeasurements constituting the dataset are not independent, even though the\ntraditional statistical analyses often applied in such cases (e.g., Students\nt-test) treat them as such. The hierarchical bootstrap has been shown to be an\neffective tool to accurately analyze such data and while it has been used\nextensively in the statistical literature, its use is not widespread in\nneuroscience - despite the ubiquity of hierarchical datasets. In this paper, we\nillustrate the intuitiveness and utility of this approach to analyze\nhierarchically nested datasets. We use simulated neural data to show that\ntraditional statistical tests can result in a false positive rate of over 45%,\neven if the Type-I error rate is set at 5%. While summarizing data across\nnon-independent points (or lower levels) can potentially fix this problem, this\napproach greatly reduces the statistical power of the analysis. The\nhierarchical bootstrap, when applied sequentially over the levels of the\nhierarchical structure, keeps the Type-I error rate within the intended bound\nand retains more statistical power than summarizing methods. We conclude by\ndemonstrating the effectiveness of the method in two real-world examples, first\nanalyzing singing data in male Bengalese finches (Lonchura striata var.\ndomestica) and second quantifying changes in behavior under optogenetic control\nin flies (Drosophila melanogaster).\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2020 16:20:25 GMT"}, {"version": "v2", "created": "Thu, 16 Jul 2020 16:18:57 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Saravanan", "Varun", ""], ["Berman", "Gordon J", ""], ["Sober", "Samuel J", ""]]}, {"id": "2007.08236", "submitter": "Daniel Alejandro M\\'artin", "authors": "Daniel A. Martin, Tiago L. Ribeiro, Sergio A. Cannas, Tomas S.\n  Grigera, Dietmar Plenz and Dante R. Chialvo", "title": "Box-scaling as a proxy of finite-size correlations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scaling of correlations as a function of system size provides important\nhints to understand critical phenomena on a variety of systems. Its study in\nbiological systems offers two challenges: usually they are not of infinite\nsize, and in the majority of cases sizes can not be varied at will. Here we\ndiscuss how finite-size scaling can be approximated in an experimental system\nof fixed and relatively small size by computing correlations inside of a\nreduced field of view of various sizes (i.e., \"box-scaling\"). Numerical\nsimulations of a neuronal network are used to verify such approximation, as\nwell as the ferromagnetic 2D Ising model. The numerical results support the\nvalidity of the heuristic approach, which should be useful to characterize\nrelevant aspects of critical phenomena in biological systems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 10:13:52 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Martin", "Daniel A.", ""], ["Ribeiro", "Tiago L.", ""], ["Cannas", "Sergio A.", ""], ["Grigera", "Tomas S.", ""], ["Plenz", "Dietmar", ""], ["Chialvo", "Dante R.", ""]]}, {"id": "2007.08374", "submitter": "Markus D Schirmer", "authors": "Markus D. Schirmer, Kathleen L. Donahue, Marco J. Nardin, Adrian V.\n  Dalca, Anne-Katrin Giese, Mark R. Etherton, Steven J. T. Mocking, Elissa C.\n  McIntosh, John W. Cole, Lukas Holmegaard, Katarina Jood, Jordi Jimenez-Conde,\n  Steven J. Kittner, Robin Lemmens, James F. Meschia, Jonathan Rosand, Jaume\n  Roquer, Tatjana Rundek, Ralph L. Sacco MD, Reinhold Schmidt, Pankaj Sharma,\n  Agnieszka Slowik, Tara M. Stanne, Achala Vagal, Johan Wasselius, Daniel Woo,\n  Stephen Bevan, Laura Heitsch, Chia-Ling Phuah, Daniel Strbian MD, Turgut\n  Tatlisumak, Christopher R. Levi, John Attia, Patrick F. McArdle, Bradford B.\n  Worrall, Ona Wu, Christina Jern, Arne Lindgren, Jane Maguire, Vincent Thijs,\n  Natalia S. Rost", "title": "Brain volume: An important determinant of functional outcome after acute\n  ischemic stroke", "comments": null, "journal-ref": "Mayo Clinic Proceedings. Vol. 95. No. 5. Elsevier, 2020", "doi": "10.1016/j.mayocp.2020.01.027", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To determine whether brain volume is associated with functional\noutcome after acute ischemic stroke (AIS).\n  Methods: We analyzed cross-sectional data of the multi-site, international\nhospital-based MRI-GENetics Interface Exploration (MRI-GENIE) study (July 1,\n2014- March 16, 2019) with clinical brain magnetic resonance imaging (MRI)\nobtained on admission for index stroke and functional outcome assessment.\nPost-stroke outcome was determined using the modified Rankin Scale (mRS) score\n(0-6; 0: asymptomatic; 6 death) recorded between 60-190 days after stroke.\nDemographics and other clinical variables including acute stroke severity\n(measured as National Institutes of Health Stroke Scale score), vascular risk\nfactors, and etiologic stroke subtypes (Causative Classification of Stroke)\nwere recorded during index admission.\n  Results: Utilizing the data from 912 acute ischemic stroke (AIS) patients\n(65+/-15 years of age, 58% male, 57% history of smoking, and 65% hypertensive)\nin a generalized linear model, brain volume (per 155.1cm^3 ) was associated\nwith age (beta -0.3 (per 14.4 years)), male sex (beta 1.0) and prior stroke\n(beta -0.2). In the multivariable outcome model, brain volume was an\nindependent predictor of mRS (beta -0.233), with reduced odds of worse\nlong-term functional outcomes (OR: 0.8, 95% CI 0.7-0.9) in those with larger\nbrain volumes.\n  Conclusions: Larger brain volume quantified on clinical MRI of AIS patients\nat time of stroke purports a protective mechanism. The role of brain volume as\na prognostic, protective biomarker has the potential to forge new areas of\nresearch and advance current knowledge of mechanisms of post-stroke recovery.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 14:51:40 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Schirmer", "Markus D.", ""], ["Donahue", "Kathleen L.", ""], ["Nardin", "Marco J.", ""], ["Dalca", "Adrian V.", ""], ["Giese", "Anne-Katrin", ""], ["Etherton", "Mark R.", ""], ["Mocking", "Steven J. T.", ""], ["McIntosh", "Elissa C.", ""], ["Cole", "John W.", ""], ["Holmegaard", "Lukas", ""], ["Jood", "Katarina", ""], ["Jimenez-Conde", "Jordi", ""], ["Kittner", "Steven J.", ""], ["Lemmens", "Robin", ""], ["Meschia", "James F.", ""], ["Rosand", "Jonathan", ""], ["Roquer", "Jaume", ""], ["Rundek", "Tatjana", ""], ["MD", "Ralph L. Sacco", ""], ["Schmidt", "Reinhold", ""], ["Sharma", "Pankaj", ""], ["Slowik", "Agnieszka", ""], ["Stanne", "Tara M.", ""], ["Vagal", "Achala", ""], ["Wasselius", "Johan", ""], ["Woo", "Daniel", ""], ["Bevan", "Stephen", ""], ["Heitsch", "Laura", ""], ["Phuah", "Chia-Ling", ""], ["MD", "Daniel Strbian", ""], ["Tatlisumak", "Turgut", ""], ["Levi", "Christopher R.", ""], ["Attia", "John", ""], ["McArdle", "Patrick F.", ""], ["Worrall", "Bradford B.", ""], ["Wu", "Ona", ""], ["Jern", "Christina", ""], ["Lindgren", "Arne", ""], ["Maguire", "Jane", ""], ["Thijs", "Vincent", ""], ["Rost", "Natalia S.", ""]]}, {"id": "2007.08429", "submitter": "Camile Bahi", "authors": "Camile Bahi", "title": "5-HT2A mediated plasticity as a target in major depression: a narrative\n  review connecting the dots from neurobiology to cognition and psychology", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the world's first primary morbidity factor, depression has a considerable\nimpact on both an individual as well as a societal level. despite their\ndiscovery several decades ago, classical antidepressants have been shown to\nprovide limited benefits against this condition. However, substances such as\nketamine and psychedelics have recently shown promising results and even\nreceived the grade of Breakthrough therapy for this indication. The accurate\nmechanisms of action underlying the efficacy of these substances are still to\nbe defined, but some similarities appear to be shared on different levels\nacross these substances. These include their structural, functional and\nbehavioral plasticity promoting abilities, as well as their capacity to promote\nBrain-Derived Neurotrophic Factor overexpression, which seems to constitute a\nkey element underlying their immediate and long-lasting action. From this\nobservation, the present review aims to examine and connect the pharmacological\npathways involved in these therapies to the neurobiological, cognitive and\npsychological responses that could be shared by both 5-HT2AR agonists and NMDA\nantagonists. It is suggested that BDNF overexpression resulting from mTOR\nactivation mediates both structural and functional plasticity, resulting in\nconnectivity changes among high-level cognitive networks such as the Default\nMode Network, finally leading to an increased and long-lasting psychological\nflexibility. Connecting these pieces of evidence could provide insights about\ntheir precise mechanisms of action and help researchers to develop biomarkers\nfor antidepressant response. If the hypotheses suggested in this review are\nverified by further trials, they could also constitute a starting point to\ndeveloping safer and more efficient antidepressants, as well as provide\ninformation about the interactions that exist between different\nneurotransmitters systems.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2020 16:09:32 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Bahi", "Camile", ""]]}, {"id": "2007.08855", "submitter": "Wenjie Chen", "authors": "Wenjie Chen, Fengtong Du, Ye Wang, Lihong Cao", "title": "A Biologically Plausible Audio-Visual Integration Model for Continual\n  Learning", "comments": "Accepted by 2021 International Joint Conference on Neural Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of catastrophic forgetting has a history of more than 30 years\nand has not been completely solved yet. Since the human brain has natural\nability to perform continual lifelong learning, learning from the brain may\nprovide solutions to this problem. In this paper, we propose a novel\nbiologically plausible audio-visual integration model (AVIM) based on the\nassumption that the integration of audio and visual perceptual information in\nthe medial temporal lobe during learning is crucial to form concepts and make\ncontinual learning possible. Specifically, we use multi-compartment\nHodgkin-Huxley neurons to build the model and adopt the calcium-based synaptic\ntagging and capture as the model's learning rule. Furthermore, we define a new\ncontinual learning paradigm to simulate the possible continual learning process\nin the human brain. We then test our model under this new paradigm. Our\nexperimental results show that the proposed AVIM can achieve state-of-the-art\ncontinual learning performance compared with other advanced methods such as\nOWM, iCaRL and GEM. Moreover, it can generate stable representations of objects\nduring learning. These results support our assumption that concept formation is\nessential for continuous lifelong learning and suggest the proposed AVIM is a\npossible concept formation mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 09:30:41 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 09:21:16 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Chen", "Wenjie", ""], ["Du", "Fengtong", ""], ["Wang", "Ye", ""], ["Cao", "Lihong", ""]]}, {"id": "2007.09260", "submitter": "Felipe Meneguzzi", "authors": "Laura Tomaz Da Silva and Nathalia Bianchini Esper and Duncan D. Ruiz\n  and Felipe Meneguzzi and Augusto Buchweitz", "title": "Visual Explanation for Identification of the Brain Bases for Dyslexia on\n  fMRI Data", "comments": "19 pages, 7 Figures, submitted to Journal of Visualization", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain imaging of mental health, neurodevelopmental and learning disorders has\ncoupled with machine learning to identify patients based only on their brain\nactivation, and ultimately identify features that generalize from smaller\nsamples of data to larger ones. However, the success of machine learning\nclassification algorithms on neurofunctional data has been limited to more\nhomogeneous data sets of dozens of participants. More recently, larger brain\nimaging data sets have allowed for the application of deep learning techniques\nto classify brain states and clinical groups solely from neurofunctional\nfeatures. Deep learning techniques provide helpful tools for classification in\nhealthcare applications, including classification of structural 3D brain\nimages. Recent approaches improved classification performance of larger\nfunctional brain imaging data sets, but they fail to provide diagnostic\ninsights about the underlying conditions or provide an explanation from the\nneural features that informed the classification. We address this challenge by\nleveraging a number of network visualization techniques to show that, using\nsuch techniques in convolutional neural network layers responsible for learning\nhigh-level features, we are able to provide meaningful images for expert-backed\ninsights into the condition being classified. Our results show not only\naccurate classification of developmental dyslexia from the brain imaging alone,\nbut also provide automatic visualizations of the features involved that match\ncontemporary neuroscientific knowledge, indicating that the visual explanations\ndo help in unveiling the neurological bases of the disorder being classified.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2020 22:11:30 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Da Silva", "Laura Tomaz", ""], ["Esper", "Nathalia Bianchini", ""], ["Ruiz", "Duncan D.", ""], ["Meneguzzi", "Felipe", ""], ["Buchweitz", "Augusto", ""]]}, {"id": "2007.09291", "submitter": "In\\^es Hip\\'olito", "authors": "Maxwell Ramstead, Karl Friston, Ines Hipolito", "title": "Is the free-energy principle a formal theory of semantics? From\n  variational density dynamics to neural and phenotypic representations", "comments": "35 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is twofold: (1) to assess whether the construct of\nneural representations plays an explanatory role under the variational\nfree-energy principle and its corollary process theory, active inference; and\n(2) if so, to assess which philosophical stance - in relation to the\nontological and epistemological status of representations - is most\nappropriate. We focus on non-realist (deflationary and\nfictionalist-instrumentalist) approaches. We consider a deflationary account of\nmental representation, according to which the explanatorily relevant contents\nof neural representations are mathematical, rather than cognitive, and a\nfictionalist or instrumentalist account, according to which representations are\nscientifically useful fictions that serve explanatory (and other) aims. After\nreviewing the free-energy principle and active inference, we argue that the\nmodel of adaptive phenotypes under the free-energy principle can be used to\nfurnish a formal semantics, enabling us to assign semantic content to specific\nphenotypic states (the internal states of a Markovian system that exists far\nfrom equilibrium). We propose a modified fictionalist account: an\norganism-centered fictionalism or instrumentalism. We argue that, under the\nfree-energy principle, pursuing even a deflationary account of the content of\nneural representations licenses the appeal to the kind of semantic content\ninvolved in the aboutness or intentionality of cognitive systems; our position\nis thus coherent with, but rests on distinct assumptions from, the realist\nposition. We argue that the free-energy principle thereby explains the\naboutness or intentionality in living systems and hence their capacity to parse\ntheir sensory stream using an ontology or set of semantic factors.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 00:51:57 GMT"}, {"version": "v2", "created": "Sat, 25 Jul 2020 03:40:06 GMT"}, {"version": "v3", "created": "Sat, 8 Aug 2020 02:03:23 GMT"}], "update_date": "2020-08-11", "authors_parsed": [["Ramstead", "Maxwell", ""], ["Friston", "Karl", ""], ["Hipolito", "Ines", ""]]}, {"id": "2007.09297", "submitter": "Alvaro Ovalle", "authors": "Alvaro Ovalle and Simon M. Lucas", "title": "Modulation of viability signals for self-regulatory control", "comments": "Accepted at the International Workshop on Active Inference 2020\n  (camera-ready version). Extended from 6 to 13 pages to include appendices and\n  a more comprehensive reference list", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We revisit the role of instrumental value as a driver of adaptive behavior.\nIn active inference, instrumental or extrinsic value is quantified by the\ninformation-theoretic surprisal of a set of observations measuring the extent\nto which those observations conform to prior beliefs or preferences. That is,\nan agent is expected to seek the type of evidence that is consistent with its\nown model of the world. For reinforcement learning tasks, the distribution of\npreferences replaces the notion of reward. We explore a scenario in which the\nagent learns this distribution in a self-supervised manner. In particular, we\nhighlight the distinction between observations induced by the environment and\nthose pertaining more directly to the continuity of an agent in time. We\nevaluate our methodology in a dynamic environment with discrete time and\nactions. First with a surprisal minimizing model-free agent (in the RL sense)\nand then expanding to the model-based case to minimize the expected free\nenergy.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 01:11:51 GMT"}, {"version": "v2", "created": "Tue, 13 Oct 2020 11:57:40 GMT"}], "update_date": "2020-10-14", "authors_parsed": [["Ovalle", "Alvaro", ""], ["Lucas", "Simon M.", ""]]}, {"id": "2007.09341", "submitter": "Milad Haghani", "authors": "Milad Haghani, Michiel C. J. Bliemer, Bilal Farooq, Inhi Kim, Zhibin\n  Li, Cheol Oh, Zahra Shahhoseini, Hamish MacDougall", "title": "Applications of brain imaging methods in driving behaviour research", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications of neuroimaging methods have substantially contributed to the\nscientific understanding of human factors during driving by providing a deeper\ninsight into the neuro-cognitive aspects of driver brain. This has been\nachieved by conducting simulated (and occasionally, field) driving experiments\nwhile collecting driver brain signals of certain types. Here, this sector of\nstudies is comprehensively reviewed at both macro and micro scales. Different\nthemes of neuroimaging driving behaviour research are identified and the\nfindings within each theme are synthesised. The surveyed literature has\nreported on applications of four major brain imaging methods. These include\nFunctional Magnetic Resonance Imaging (fMRI), Electroencephalography (EEG),\nFunctional Near-Infrared Spectroscopy (fNIRS) and Magnetoencephalography (MEG),\nwith the first two being the most common methods in this domain. While\ncollecting driver fMRI signal has been particularly instrumental in studying\nneural correlates of intoxicated driving (e.g. alcohol or cannabis) or\ndistracted driving, the EEG method has been predominantly utilised in relation\nto the efforts aiming at development of automatic fatigue/drowsiness detection\nsystems, a topic to which the literature on neuro-ergonomics of driving\nparticularly has shown a spike of interest within the last few years. The\nsurvey also reveals that topics such as driver brain activity in semi-automated\nsettings or the brain activity of drivers with brain injuries or chronic\nneurological conditions have by contrast been investigated to a very limited\nextent. Further, potential topics in relation to driving behaviour are\nidentified that could benefit from the adoption of neuroimaging methods in\nfuture studies.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 06:31:16 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Haghani", "Milad", ""], ["Bliemer", "Michiel C. J.", ""], ["Farooq", "Bilal", ""], ["Kim", "Inhi", ""], ["Li", "Zhibin", ""], ["Oh", "Cheol", ""], ["Shahhoseini", "Zahra", ""], ["MacDougall", "Hamish", ""]]}, {"id": "2007.09466", "submitter": "Sergio L\\'opez Bernal", "authors": "Sergio L\\'opez Bernal, Alberto Huertas Celdr\\'an, Lorenzo Fern\\'andez\n  Maim\\'o, Michael Taynnan Barros, Sasitharan Balasubramaniam, Gregorio\n  Mart\\'inez P\\'erez", "title": "Cyberattacks on Miniature Brain Implants to Disrupt Spontaneous Neural\n  Signaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Brain-Computer Interfaces (BCI) arose as systems that merge computing systems\nwith the human brain to facilitate recording, stimulation, and inhibition of\nneural activity. Over the years, the development of BCI technologies has\nshifted towards miniaturization of devices that can be seamlessly embedded into\nthe brain and can target single neuron or small population sensing and control.\nWe present a motivating example highlighting vulnerabilities of two promising\nmicron-scale BCI technologies, demonstrating the lack of security and privacy\nprinciples in existing solutions. This situation opens the door to a novel\nfamily of cyberattacks, called neuronal cyberattacks, affecting neuronal\nsignaling. This paper defines the first two neural cyberattacks, Neuronal\nFlooding (FLO) and Neuronal Scanning (SCA), where each threat can affect the\nnatural activity of neurons. This work implements these attacks in a neuronal\nsimulator to determine their impact over the spontaneous neuronal behavior,\ndefining three metrics: number of spikes, percentage of shifts, and dispersion\nof spikes. Several experiments demonstrate that both cyberattacks produce a\nreduction of spikes compared to spontaneous behavior, generating a rise in\ntemporal shifts and a dispersion increase. Mainly, SCA presents a higher impact\nthan FLO in the metrics focused on the number of spikes and dispersion, where\nFLO is slightly more damaging, considering the percentage of shifts.\nNevertheless, the intrinsic behavior of each attack generates a differentiation\non how they alter neuronal signaling. FLO is adequate to generate an immediate\nimpact on the neuronal activity, whereas SCA presents higher effectiveness for\ndamages to the neural signaling in the long-term.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 16:25:46 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2020 14:55:42 GMT"}], "update_date": "2020-09-11", "authors_parsed": [["Bernal", "Sergio L\u00f3pez", ""], ["Celdr\u00e1n", "Alberto Huertas", ""], ["Maim\u00f3", "Lorenzo Fern\u00e1ndez", ""], ["Barros", "Michael Taynnan", ""], ["Balasubramaniam", "Sasitharan", ""], ["P\u00e9rez", "Gregorio Mart\u00ednez", ""]]}, {"id": "2007.09560", "submitter": "Erik Hoel", "authors": "Erik Hoel", "title": "The Overfitted Brain: Dreams evolved to assist generalization", "comments": "18 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding of the evolved biological function of sleep has advanced\nconsiderably in the past decade. However, no equivalent understanding of dreams\nhas emerged. Contemporary neuroscientific theories generally view dreams as\nepiphenomena, and the few proposals for their biological function are\ncontradicted by the phenomenology of dreams themselves. Now, the recent advent\nof deep neural networks (DNNs) has finally provided the novel conceptual\nframework within which to understand the evolved function of dreams. Notably,\nall DNNs face the issue of overfitting as they learn, which is when performance\non one data set increases but the network's performance fails to generalize\n(often measured by the divergence of performance on training vs. testing data\nsets). This ubiquitous problem in DNNs is often solved by modelers via \"noise\ninjections\" in the form of noisy or corrupted inputs. The goal of this paper is\nto argue that the brain faces a similar challenge of overfitting, and that\nnightly dreams evolved to combat the brain's overfitting during its daily\nlearning. That is, dreams are a biological mechanism for increasing\ngeneralizability via the creation of corrupted sensory inputs from stochastic\nactivity across the hierarchy of neural structures. Sleep loss, specifically\ndream loss, leads to an overfitted brain that can still memorize and learn but\nfails to generalize appropriately. Herein this \"overfitted brain hypothesis\" is\nexplicitly developed and then compared and contrasted with existing\ncontemporary neuroscientific theories of dreams. Existing evidence for the\nhypothesis is surveyed within both neuroscience and deep learning, and a set of\ntestable predictions are put forward that can be pursued both in vivo and in\nsilico.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 02:17:52 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2020 15:33:47 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Hoel", "Erik", ""]]}, {"id": "2007.09704", "submitter": "Adeel Razi", "authors": "Karl J. Friston, Erik D. Fagerholm, Tahereh S. Zarghami, Thomas Parr,\n  In\\^es Hip\\'olito, Lo\\\"ic Magrou, Adeel Razi", "title": "Parcels and particles: Markov blankets in the brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  At the inception of human brain mapping, two principles of functional anatomy\nunderwrote most conceptions - and analyses - of distributed brain responses:\nnamely functional segregation and integration. There are currently two main\napproaches to characterising functional integration. The first is a mechanistic\nmodelling of connectomics in terms of directed effective connectivity that\nmediates neuronal message passing and dynamics on neuronal circuits. The second\nphenomenological approach usually characterises undirected functional\nconnectivity (i.e., measurable correlations), in terms of intrinsic brain\nnetworks, self-organised criticality, dynamical instability, etc. This paper\ndescribes a treatment of effective connectivity that speaks to the emergence of\nintrinsic brain networks and critical dynamics. It is predicated on the notion\nof Markov blankets that play a fundamental role in the self-organisation of far\nfrom equilibrium systems. Using the apparatus of the renormalisation group, we\nshow that much of the phenomenology found in network neuroscience is an\nemergent property of a particular partition of neuronal states, over\nprogressively larger scales. As such, it offers a way of linking dynamics on\ndirected graphs to the phenomenology of intrinsic brain networks.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2020 16:18:41 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Friston", "Karl J.", ""], ["Fagerholm", "Erik D.", ""], ["Zarghami", "Tahereh S.", ""], ["Parr", "Thomas", ""], ["Hip\u00f3lito", "In\u00eas", ""], ["Magrou", "Lo\u00efc", ""], ["Razi", "Adeel", ""]]}, {"id": "2007.11151", "submitter": "Luke Hallum", "authors": "Luke E Hallum, Shaun L Cloherty", "title": "Liquid-crystal display (LCD) of achromatic, mean-modulated flicker in\n  clinical assessment and experimental studies of visual systems", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0248180", "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Achromatic, mean-modulated flicker (wherein luminance increments and\ndecrements of equal magnitude are applied, over time, to a test field) is\ncommonly used in both clinical assessment of vision and experimental studies of\nvisual systems. However, presenting flicker on computer-controlled displays is\nproblematic; displays typically introduce luminance artifacts at high flicker\nfrequency or contrast, potentially interfering with the validity of findings.\nHere, we present a battery of tests used to weigh the relative merits of two\ndisplays for presenting achromatic, mean-modulated flicker. These tests\nrevealed marked differences between a new high-performance liquid-crystal\ndisplay (LCD; EIZO ColorEdge CG247X) and a new consumer-grade LCD (Dell\nU2415b), despite displays' vendor-supplied specifications being almost\nidentical. We measured displayed luminance using a spot meter and a linearized\nphotodiode. We derived several measures, including spatial uniformity, the\neffect of viewing angle, response times, Fourier amplitude spectra, and\ncycle-averaged luminance. We presented paired luminance pulses to quantify the\ndisplays' nonlinear dynamics. The CG247X showed relatively good spatial\nuniformity (e.g., at moderate luminance, standard deviation 2.8% versus\nU2415b's 5.3%). Fourier transformation of nominally static test patches\nrevealed spectra free of artifacts, with the exception of a frame response. The\nCG247X's rise and fall times depended on both the luminance from which, and to\nwhich, it responded, as is to be generally expected from LCDs. Despite this\nnonlinear behaviour, we were able to define a contrast and frequency range\nwherein the CG247X appeared largely artifact-free; the relationship between\nnominal luminance and displayed luminance was accurately modelled using a\ncausal, linear time-invariant system. This range included contrasts up to 80%,\nand flicker frequencies up to 30 Hz.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 01:10:16 GMT"}, {"version": "v2", "created": "Tue, 17 Nov 2020 04:12:01 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Hallum", "Luke E", ""], ["Cloherty", "Shaun L", ""]]}, {"id": "2007.11674", "submitter": "Jorge Gaxiola", "authors": "J.A. Gaxiola-Tirado", "title": "Using EEG-based brain connectivity for the study of brain dynamics in\n  brain-computer interfaces", "comments": "in Spanish", "journal-ref": "Revista Doctorado UMH, 2020", "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of brain connectivity aims to understand the emergence of\nfunctional networks into the brain. This information can be used in the process\nof electroencephalographic (EEG) signal analysis and classification for a\nbraincomputer interface (BCI). These systems provide an alternative channel of\ncommunication and control to people with motor impairments. In this article,\nfour strategies for using the brain connectivity in a BCI environment as a tool\nto obtain a deeper understanding of the cerebral mechanisms are proposed, with\nthe principal aim of developing a scheme oriented to neuro-rehabilitation of\ngait in combination with different neurotechnologies and exoskeletons. This\nscheme would allow improving current schemes and/or to design new control\nstrategies, as well as rehabilitation approaches.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jul 2020 18:05:14 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Gaxiola-Tirado", "J. A.", ""]]}, {"id": "2007.11698", "submitter": "Vittorio Lippi", "authors": "V. Lippi, L. Assl\\\"ander, E. Akcay, and T. Mergner", "title": "Body sway responses to pseudorandom support surface translations of\n  vestibular loss subjects resemble those of vestibular able subjects", "comments": null, "journal-ref": null, "doi": "10.1016/j.neulet.2020.135271", "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Body sway responses evoked by a horizontal acceleration of a level and firm\nsupport surface are particular in that the vestibular information on body-space\nangle BS resembles the proprioceptive information on body-foot angle BF. We\ncompared corresponding eyes-closed responses of vestibular-able (VA) and\nvestibular-loss (VL) subjects, postulating a close correspondence. In\ncontradistinction to previous studies, we used an unpredictable (pseudorandom)\nstimulus and found that the eyes-closed and eyes-open responses of the VA\nclosely resembled those of the VL subjects, as expected. We further conclude\nthat the vestibular signals coding head linear translation in VA subjects has\nin this case too little functional relevance to cause a notable difference\nbetween the subject groups.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2020 22:04:44 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Lippi", "V.", ""], ["Assl\u00e4nder", "L.", ""], ["Akcay", "E.", ""], ["Mergner", "T.", ""]]}, {"id": "2007.11968", "submitter": "Justyna Signerska-Rynkowska", "authors": "Jonathan Rubin, Justyna Signerska-Rynkowska, Jonathan D. Touboul", "title": "Type III Responses to Transient Inputs in Hybrid Nonlinear Neuron Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental characterization of neuronal dynamics involves recording both of\nspontaneous activity patterns and of responses to transient and sustained\ninputs. While much theoretical attention has been devoted to the spontaneous\nactivity of neurons, less is known about the dynamic mechanisms shaping their\nresponses to transient inputs, although these bear significant physiological\nrelevance. Here, we study responses to transient inputs in a widely used class\nof neuron models (nonlinear adaptive hybrid models) well-known to reproduce a\nnumber of biologically realistic behaviors. We focus on responses to transient\ninputs that have been previously associated with Type III neurons, arguably the\nleast studied category in Hodgkin's classification, which are those neurons\nthat never exhibit continuous firing in response to sustained excitatory\ncurrents. The two phenomena that we study are post-inhibitory facilitation, in\nwhich an otherwise subthreshold excitatory input can induce a spike if it is\napplied with proper timing after an inhibitory pulse, and slope detection, in\nwhich a neuron spikes to a transient input only when the input's rate of change\nis in a specific, bounded range. We analyze the origin of these phenomena in\nnonlinear hybrid models and provide a geometric characterization of dynamical\nstructures associated with PIF in the system and an analytical study of slope\ndetection for tent inputs. While the necessary and sufficient conditions for\nthese behaviors are easily satisfied in neurons with Type III excitability, our\nproofs are quite general and valid for neurons that do not exhibit Type III\nexcitability as well. This study therefore provides a framework for the\nmathematical analysis of these responses to transient inputs associated with\nType III neurons in other systems and for advancing our understanding of these\nsystems' computational properties.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jul 2020 12:32:51 GMT"}], "update_date": "2020-07-24", "authors_parsed": [["Rubin", "Jonathan", ""], ["Signerska-Rynkowska", "Justyna", ""], ["Touboul", "Jonathan D.", ""]]}, {"id": "2007.12584", "submitter": "Francesca Schonsberg", "authors": "Francesca Sch\\\"onsberg, Yasser Roudi, Alessandro Treves", "title": "Efficiency of local learning rules in threshold-linear associative\n  networks", "comments": null, "journal-ref": "Phys. Rev. Lett. 126, 018301 (2021)", "doi": "10.1103/PhysRevLett.126.018301", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the Gardner storage capacity for associative networks of threshold\nlinear units, and show that with Hebbian learning they can operate closer to\nsuch Gardner bound than binary networks, and even surpass it. This is largely\nachieved through a sparsification of the retrieved patterns, which we analyze\nfor theoretical and empirical distributions of activity. As reaching the\noptimal capacity via non-local learning rules like backpropagation requires\nslow and neurally implausible training procedures, our results indicate that\none-shot self-organized Hebbian learning can be just as efficient.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 15:35:24 GMT"}, {"version": "v2", "created": "Fri, 25 Dec 2020 09:08:15 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Sch\u00f6nsberg", "Francesca", ""], ["Roudi", "Yasser", ""], ["Treves", "Alessandro", ""]]}, {"id": "2007.12764", "submitter": "Shadrokh Samavi", "authors": "Ghazale Ghorbanzade, Zahra Nabizadeh-ShahreBabak, Shadrokh Samavi,\n  Nader Karimi, Ali Emami, Pejman Khadivi", "title": "Selection of Proper EEG Channels for Subject Intention Classification\n  Using Deep Learning", "comments": "10 pages 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain signals could be used to control devices to assist individuals with\ndisabilities. Signals such as electroencephalograms are complicated and hard to\ninterpret. A set of signals are collected and should be classified to identify\nthe intention of the subject. Different approaches have tried to reduce the\nnumber of channels before sending them to a classifier. We are proposing a deep\nlearning-based method for selecting an informative subset of channels that\nproduce high classification accuracy. The proposed network could be trained for\nan individual subject for the selection of an appropriate set of channels.\nReduction of the number of channels could reduce the complexity of\nbrain-computer-interface devices. Our method could find a subset of channels.\nThe accuracy of our approach is comparable with a model trained on all\nchannels. Hence, our model's temporal and power costs are low, while its\naccuracy is kept high.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 20:40:10 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 19:27:53 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Ghorbanzade", "Ghazale", ""], ["Nabizadeh-ShahreBabak", "Zahra", ""], ["Samavi", "Shadrokh", ""], ["Karimi", "Nader", ""], ["Emami", "Ali", ""], ["Khadivi", "Pejman", ""]]}, {"id": "2007.12843", "submitter": "Jorge Gaxiola", "authors": "Jorge Antonio Gaxiola Tirado", "title": "Preliminary Assessment of hands motor imagery in theta- and beta-bands\n  for Brain-Machine-Interfaces using functional connectivity analysis", "comments": "Article accepted and presented at IGS2019- YOUR BRAIN ON ART", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of time- and frequency-based features has proven effective in the\nprocess of classifying mental tasks in Brain Computer Interfaces (BCIs). Still,\nmost of those methods provide little insight about the underlying brain\nactivity and functions. Thus, a better understanding of the mechanisms and\ndynamics of brain activity, is necessary in order to obtain useful and\ninformative features for BCIs. In the present study, the objective is to\ninvestigate the differences in functional connectivity of two motor imagery\ntasks, through a partial directed coherence (PDC) analysis, which is a\nfrequency-domain metric that provides information about directionality in the\ninteraction between signals recorded at different channels. Four healthy\nsubjects participated in this study, two mental tasks were evaluated:\nImagination of the movement of the right hand or left hand. We carry out the\ndifferentiation of these tasks through two different approaches: on one hand,\nthe traditional one based on spectral power; on the other hand, an approach\nbased on PDC. The results showed that EEG-based PDC analysis provides\nadditional information and it can potentially improve the feature selection\nmainly in the beta frequency band.\n", "versions": [{"version": "v1", "created": "Sat, 25 Jul 2020 03:18:02 GMT"}], "update_date": "2020-08-04", "authors_parsed": [["Tirado", "Jorge Antonio Gaxiola", ""]]}, {"id": "2007.13462", "submitter": "Aaron Voelker", "authors": "Aaron R. Voelker", "title": "A short letter on the dot product between rotated Fourier transforms", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial Semantic Pointers (SSPs) have recently emerged as a powerful tool for\nrepresenting and transforming continuous space, with numerous applications to\ncognitive modelling and deep learning. Fundamental to SSPs is the notion of\n\"similarity\" between vectors representing different points in $n$-dimensional\nspace -- typically the dot product or cosine similarity between vectors with\nrotated unit-length complex coefficients in the Fourier domain. The similarity\nmeasure has previously been conjectured to be a Gaussian function of Euclidean\ndistance. Contrary to this conjecture, we derive a simple trigonometric formula\nrelating spatial displacement to similarity, and prove that, in the case where\nthe Fourier coefficients are uniform i.i.d., the expected similarity is a\nproduct of normalized sinc functions: $\\prod_{k=1}^{n} \\operatorname{sinc}\n\\left( a_k \\right)$, where $\\mathbf{a} \\in \\mathbb{R}^n$ is the spatial\ndisplacement between the two $n$-dimensional points. This establishes a direct\nlink between space and the similarity of SSPs, which in turn helps bolster a\nuseful mathematical framework for architecting neural networks that manipulate\nspatial structures.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2020 13:53:04 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Voelker", "Aaron R.", ""]]}, {"id": "2007.13813", "submitter": "Tawan Carvalho", "authors": "Tawan T. A. Carvalho, Antonio J. Fontenele, Mauricio Girardi-Schappo,\n  Thais Feliciano, Leandro A. A. Aguiar, Thais P. L. Silva, Nivaldo A. P. de\n  Vasconcelos, Pedro V. Carelli, and Mauro Copelli", "title": "Subsampled directed-percolation models explain scaling relations\n  experimentally observed in the brain", "comments": "15 pages, 9 figures, submitted to Frontiers Neural Circuits", "journal-ref": "Front. Neural Circuits 14, 83 (2021)", "doi": "10.3389/fncir.2020.576727", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech nlin.AO physics.bio-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent experimental results on spike avalanches measured in the\nurethane-anesthetized rat cortex have revealed scaling relations that indicate\na phase transition at a specific level of cortical firing rate variability. The\nscaling relations point to critical exponents whose values differ from those of\na branching process, which has been the canonical model employed to understand\nbrain criticality. This suggested that a different model, with a different\nphase transition, might be required to explain the data. Here we show that this\nis not necessarily the case. By employing two different models belonging to the\nsame universality class as the branching process (mean-field directed\npercolation) and treating the simulation data exactly like experimental data,\nwe reproduce most of the experimental results. We find that subsampling the\nmodel and adjusting the time bin used to define avalanches (as done with\nexperimental data) are sufficient ingredients to change the apparent exponents\nof the critical point. Moreover, experimental data is only reproduced within a\nvery narrow range in parameter space around the phase transition.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 18:59:46 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Carvalho", "Tawan T. A.", ""], ["Fontenele", "Antonio J.", ""], ["Girardi-Schappo", "Mauricio", ""], ["Feliciano", "Thais", ""], ["Aguiar", "Leandro A. A.", ""], ["Silva", "Thais P. L.", ""], ["de Vasconcelos", "Nivaldo A. P.", ""], ["Carelli", "Pedro V.", ""], ["Copelli", "Mauro", ""]]}, {"id": "2007.13911", "submitter": "Anne Watson Draelos", "authors": "Anne Draelos, Eva A. Naumann, John M. Pearson", "title": "Online neural connectivity estimation with ensemble stimulation", "comments": "Revised and expanded version of the work that appeared in NeurIPS\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary goals of systems neuroscience is to relate the structure\nof neural circuits to their function, yet patterns of connectivity are\ndifficult to establish when recording from large populations in behaving\norganisms. Many previous approaches have attempted to estimate functional\nconnectivity between neurons using statistical modeling of observational data,\nbut these approaches rely heavily on parametric assumptions and are purely\ncorrelational. Recently, however, holographic photostimulation techniques have\nmade it possible to precisely target selected ensembles of neurons, offering\nthe possibility of establishing direct causal links. Here, we propose a method\nbased on noisy group testing that drastically increases the efficiency of this\nprocess in sparse networks. By stimulating small ensembles of neurons, we show\nthat it is possible to recover binarized network connectivity with a number of\ntests that grows only logarithmically with population size under minimal\nstatistical assumptions. Moreover, we prove that our approach, which reduces to\nan efficiently solvable convex optimization problem, can be related to\nVariational Bayesian inference on the binary connection weights, and we derive\nrigorous bounds on the posterior marginals. This allows us to extend our method\nto the streaming setting, where continuously updated posteriors allow for\noptional stopping, and we demonstrate the feasibility of inferring connectivity\nfor networks of up to tens of thousands of neurons online. Finally, we show how\nour work can be theoretically linked to compressed sensing approaches, and\ncompare results for connectivity inference in different settings.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2020 23:47:03 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 16:26:54 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Draelos", "Anne", ""], ["Naumann", "Eva A.", ""], ["Pearson", "John M.", ""]]}, {"id": "2007.14127", "submitter": "Gabi Socolovsky", "authors": "Gabi Socolovsky (1) and Maoz Shamir (1) ((1) Ben-Gurion University of\n  the Negev)", "title": "Robust Rhythmogenesis in the Gamma Band via Spike Timing Dependent\n  Plasticity", "comments": "9 pages with 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rhythmic activity in the gamma band (30-100Hz) has been observed in numerous\nanimal species ranging from insects to humans, and in relation to a wide range\nof cognitive tasks. Various experimental and theoretical studies have\ninvestigated this rhythmic activity. The theoretical efforts have mainly been\nfocused on the neuronal dynamics, under the assumption that network\nconnectivity satisfies certain fine-tuning conditions required to generate\ngamma oscillations. However, it remains unclear how this fine tuning is\nachieved.\n  Here we investigated the hypothesis that spike timing dependent plasticity\n(STDP) can provide the underlying mechanism for tuning synaptic connectivity to\ngenerate rhythmic activity in the gamma band. We addressed this question in a\nmodeling study. We examined STDP dynamics in the framework of a network of\nexcitatory and inhibitory neuronal populations that has been suggested to\nunderlie the generation of gamma. Mean field Fokker Planck equations for the\nsynaptic weights dynamics are derived in the limit of slow learning. We drew on\nthis approximation to determine which types of STDP rules drive the system to\nexhibit gamma oscillations, and demonstrate how the parameters that\ncharacterize the plasticity rule govern the rhythmic activity. Finally, we\npropose a novel mechanism that can ensure the robustness of self-developing\nprocesses, in general and for rhythmogenesis in particular.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 11:15:53 GMT"}], "update_date": "2020-07-29", "authors_parsed": [["Socolovsky", "Gabi", ""], ["Shamir", "Maoz", ""]]}, {"id": "2007.14236", "submitter": "Bruno Golosio", "authors": "Bruno Golosio, Gianmarco Tiddia, Chiara De Luca, Elena Pastorelli,\n  Francesco Simula, Pier Stanislao Paolucci", "title": "Fast simulations of highly-connected spiking cortical models using GPUs", "comments": null, "journal-ref": "Front. Comput. Neurosci. 15:627620 2021", "doi": "10.3389/fncom.2021.627620", "report-no": null, "categories": "q-bio.NC cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past decade there has been a growing interest in the development of\nparallel hardware systems for simulating large-scale networks of spiking\nneurons. Compared to other highly-parallel systems, GPU-accelerated solutions\nhave the advantage of a relatively low cost and a great versatility, thanks\nalso to the possibility of using the CUDA-C/C++ programming languages.\nNeuronGPU is a GPU library for large-scale simulations of spiking neural\nnetwork models, written in the C++ and CUDA-C++ programming languages, based on\na novel spike-delivery algorithm. This library includes simple LIF\n(leaky-integrate-and-fire) neuron models as well as several multisynapse AdEx\n(adaptive-exponential-integrate-and-fire) neuron models with current or\nconductance based synapses, user definable models and different devices. The\nnumerical solution of the differential equations of the dynamics of the AdEx\nmodels is performed through a parallel implementation, written in CUDA-C++, of\nthe fifth-order Runge-Kutta method with adaptive step-size control. In this\nwork we evaluate the performance of this library on the simulation of a\ncortical microcircuit model, based on LIF neurons and current-based synapses,\nand on a balanced network of excitatory and inhibitory neurons, using AdEx\nneurons and conductance-based synapses. On these models, we will show that the\nproposed library achieves state-of-the-art performance in terms of simulation\ntime per second of biological activity. In particular, using a single NVIDIA\nGeForce RTX 2080 Ti GPU board, the full-scale cortical-microcircuit model,\nwhich includes about 77,000 neurons and $3 \\cdot 10^8$ connections, can be\nsimulated at a speed very close to real time, while the simulation time of a\nbalanced network of 1,000,000 AdEx neurons with 1,000 connections per neuron\nwas about 70 s per second of biological activity.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 13:58:50 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2020 15:43:02 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2020 17:13:33 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Golosio", "Bruno", ""], ["Tiddia", "Gianmarco", ""], ["De Luca", "Chiara", ""], ["Pastorelli", "Elena", ""], ["Simula", "Francesco", ""], ["Paolucci", "Pier Stanislao", ""]]}, {"id": "2007.14823", "submitter": "Kamesh Krishnamurthy", "authors": "Kamesh Krishnamurthy, Tankut Can and David J. Schwab", "title": "Theory of gating in recurrent neural networks", "comments": "11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG nlin.CD q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recurrent neural networks (RNNs) are powerful dynamical models, widely used\nin machine learning (ML) for processing sequential data, and in neuroscience,\nto understand the emergent properties of networks of real neurons. Prior\ntheoretical work in understanding the properties of RNNs has focused on\nnetworks with additive interactions. However, gating -- i.e. multiplicative --\ninteractions are ubiquitous in real neurons, and gating is also the central\nfeature of the best-performing RNNs in ML. Here, we study the consequences of\ngating for the dynamical behavior of RNNs. We show that gating leads to slow\nmodes and a novel, marginally-stable state. The network in this\nmarginally-stable state can function as a robust integrator, and unlike\nprevious approaches, gating permits this function without parameter fine-tuning\nor special symmetries. We study the long-time behavior of the gated network\nusing its Lyapunov spectrum, and provide a novel relation between the maximum\nLyapunov exponent and the relaxation time of the dynamics. Gating is also shown\nto give rise to a novel, discontinuous transition to chaos, where the\nproliferation of critical points (topological complexity) is decoupled from the\nappearance of chaotic dynamics (dynamical complexity), in contrast to a seminal\nresult for additive RNNs. The rich dynamical behavior is summarized in a phase\ndiagram indicating critical surfaces and regions of marginal stability -- thus,\nproviding a map for principled parameter choices to ML practitioners. Finally,\nwe develop a field theory for gradients that arise in training, by combining\nthe adjoint formalism from control theory with the dynamical mean-field theory.\nThis paves the way for the use of powerful field theoretic techniques to study\ntraining and gradients in large RNNs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 13:20:58 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 21:48:52 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 20:02:16 GMT"}, {"version": "v4", "created": "Thu, 21 Jan 2021 03:03:56 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Krishnamurthy", "Kamesh", ""], ["Can", "Tankut", ""], ["Schwab", "David J.", ""]]}, {"id": "2007.14941", "submitter": "Sitabhra Sinha", "authors": "Anand Pathak, Shakti N. Menon and Sitabhra Sinha", "title": "Mesoscopic architecture enhances communication across the Macaque\n  connectome revealing structure-function correspondence in the brain", "comments": "13 pages, 3 figures + 27 pages Supplementary Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analyzing the brain in terms of organizational structures at intermediate\nscales provides an approach to negotiate the complexity arising from\ninteractions between its large number of components. Focusing on a wiring\ndiagram that spans the cortex, basal ganglia and thalamus of the Macaque brain,\nwe provide a mesoscopic-level description of the topological architecture of\none of the most well-studied mammalian connectomes. The robust modules we\nidentify each comprise densely inter-connected cortical and sub-cortical areas\nthat play complementary roles in executing specific cognitive functions. We\nfind that physical proximity between areas is insufficient to explain the\nmodular organization, as similar mesoscopic structures can be obtained even\nafter factoring out the effect of distance constraints on the connectivity. We\nobserve that the distribution profile of brain areas, classified in terms of\ntheir intra- and inter-modular connectivity, is conserved across the principal\ncortical subdivisions, as well as, sub-cortical structures. In particular\nprovincial hubs, which have significantly higher number of connections with\nmembers of their module, but relatively less well-connected to other modules,\nare the only class that exhibits homophily, i.e., a discernible preference to\nconnect to each other. By considering a process of diffusive propagation we\ndemonstrate that this architecture, instead of localizing the activity,\nfacilitates rapid communication across the connectome. By supplementing the\ntopological information about the Macaque connectome with physical locations,\nvolumes and functions of the constituent areas and analyzing this augmented\ndataset, we reveal a counter-intuitive role played by the modular architecture\nof the brain in promoting global interaction.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 16:34:47 GMT"}], "update_date": "2020-07-30", "authors_parsed": [["Pathak", "Anand", ""], ["Menon", "Shakti N.", ""], ["Sinha", "Sitabhra", ""]]}, {"id": "2007.15092", "submitter": "Steve Mehrkanoon", "authors": "Steve Mehrkanoon", "title": "Macroscopic cortical dynamics: Spatially uncorrelated but temporally\n  coherent rich-club organisations in source-space resting-state EEG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronous oscillations of neuronal populations support resting-state\ncortical activity. Recent studies indicate that resting-state functional\nconnectivity is not static, but exhibits complex dynamics. The mechanisms\nunderlying the complex dynamics of cortical activity have not been well\ncharacterised. Here, we directly apply singular value decomposition (SVD) in\nsource-reconstructed electroencephalography (EEG) in order to characterise the\ndynamics of spatiotemporal patterns of resting-state functional connectivity.\nWe found that changes in resting-state functional connectivity were associated\nwith distinct complex topological features, \"Rich-Club organisation\", of the\ndefault mode network, salience network, and motor network. Rich-club topology\nof the salience network revealed greater functional connectivity between\nventrolateral prefrontal cortex and anterior insula, whereas Rich-club\ntopologies of the default mode networks revealed bilateral functional\nconnectivity between fronto-parietal and posterior cortices. Spectral analysis\nof the dynamics underlying Rich-club organisations of these source-space\nnetwork patterns revealed that resting-state cortical activity exhibit distinct\ndynamical regimes whose intrinsic expressions contain fast oscillations in the\nalpha-beta band and with the envelope-signal in the timescale of $<0.1$ Hz. Our\nfindings thus demonstrated that multivariate eigen-decomposition of\nsource-reconstructed EEG is a reliable computational technique to explore how\ndynamics of spatiotemporal features of the resting-state cortical activity\noccur that oscillate at distinct frequencies.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2020 07:51:55 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Mehrkanoon", "Steve", ""]]}, {"id": "2007.15101", "submitter": "Emily Toomey", "authors": "Emily Toomey, Ken Segall, Matteo Castellani, Marco Colangelo, Nancy\n  Lynch, and Karl K. Berggren", "title": "A superconducting nanowire spiking element for neural networks", "comments": "5 main figures; 7 supplemental figures", "journal-ref": null, "doi": "10.1021/acs.nanolett.0c03057", "report-no": null, "categories": "q-bio.NC cond-mat.supr-con cs.ET cs.NE physics.app-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the limits of traditional von Neumann computing come into view, the\nbrain's ability to communicate vast quantities of information using low-power\nspikes has become an increasing source of inspiration for alternative\narchitectures. Key to the success of these largescale neural networks is a\npower-efficient spiking element that is scalable and easily interfaced with\ntraditional control electronics. In this work, we present a spiking element\nfabricated from superconducting nanowires that has pulse energies on the order\nof ~10 aJ. We demonstrate that the device reproduces essential characteristics\nof biological neurons, such as a refractory period and a firing threshold.\nThrough simulations using experimentally measured device parameters, we show\nhow nanowire-based networks may be used for inference in image recognition, and\nthat the probabilistic nature of nanowire switching may be exploited for\nmodeling biological processes and for applications that rely on stochasticity.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2020 20:48:36 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Toomey", "Emily", ""], ["Segall", "Ken", ""], ["Castellani", "Matteo", ""], ["Colangelo", "Marco", ""], ["Lynch", "Nancy", ""], ["Berggren", "Karl K.", ""]]}, {"id": "2007.15205", "submitter": "Ines Hipolito", "authors": "Ines Hipolito, Maxwell Ramstead, Axel Constant, Karl Friston", "title": "Cognition coming about: self-organisation and free-energy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wright and Bourkes compelling article rightly points out that existing models\nof embryogenesis fail to explain the mechanisms and functional significance of\nthe dynamic connections among neurons. We pursue their account of Dynamic Logic\nby appealing to the Markov blanket formalism that underwrites the Free Energy\nPrinciple. We submit that this allows one to model embryogenesis as\nself-organisation in a dynamical system that minimises free-energy. The ensuing\nformalism may be extended to also explain the autonomous emergence of\ncognition, specifically in the brain, as a dynamic self-assembling process.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 03:09:34 GMT"}], "update_date": "2020-07-31", "authors_parsed": [["Hipolito", "Ines", ""], ["Ramstead", "Maxwell", ""], ["Constant", "Axel", ""], ["Friston", "Karl", ""]]}, {"id": "2007.15728", "submitter": "Jeremi K. Ochab", "authors": "Ignacio Cifre, Maria T. Miller Flores, Jeremi K. Ochab, Dante R.\n  Chialvo", "title": "Revisiting non-linear functional brain co-activations: directed, dynamic\n  and delayed", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The center stage of neuro-imaging is currently occupied by studies of\nfunctional correlations between brain regions. These correlations define the\nbrain functional networks, which are the most frequently used framework to\nrepresent and interpret a variety of experimental findings. In previous work we\nfirst demonstrated that the relatively stronger BOLD activations contain most\nof the information relevant to understand functional connectivity and\nsubsequent work confirmed that a large compression of the original signals can\nbe obtained without significant loss of information. In this work we revisit\nthe correlation properties of these epochs to define a measure of nonlinear\ndynamic directed functional connectivity (nldFC) across regions of interest. We\nshow that the proposed metric provides at once, without extensive numerical\ncomplications, directed information of the functional correlations, as well as\na measure of temporal lags across regions, overall offering a different\nperspective in the analysis of brain co-activation patterns. In this paper we\nprovide for a proof of concept, based on replicating and completing existing\nresults on an Autism database, to discuss the main features and advantages of\nthe proposed strategy for the study of brain functional correlations. These\nresults show new interpretations of the correlations found on this sample.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2020 20:31:59 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Cifre", "Ignacio", ""], ["Flores", "Maria T. Miller", ""], ["Ochab", "Jeremi K.", ""], ["Chialvo", "Dante R.", ""]]}, {"id": "2007.16018", "submitter": "Daniele Marinazzo", "authors": "Sebastiano Stramaglia, Tomas Scagliarini, Bryan C. Daniels, and\n  Daniele Marinazzo", "title": "Quantifying dynamical high-order interdependencies from the\n  O-information: an application to neural spiking dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address the problem of efficiently and informatively quantifying how\nmultiplets of variables carry information about the future of the dynamical\nsystem they belong to. In particular we want to identify groups of variables\ncarrying redundant or synergistic information, and track how the size and the\ncomposition of these multiplets changes as the collective behavior of the\nsystem evolves. In order to afford a parsimonious expansion of shared\ninformation, and at the same time control for lagged interactions and common\neffect, we develop a dynamical, conditioned version of the O-information, a\nframework recently proposed to quantify high-order interdependencies via\nmultivariate extension of the mutual information. We thus obtain an expansion\nof the transfer entropy in which synergistic and redundant effects are\nseparated. We apply this framework to a dataset of spiking neurons from a\nmonkey performing a perceptual discrimination task. The method identifies\nsynergistic multiplets that include neurons previously categorized as\ncontaining little relevant information individually.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 12:34:19 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Stramaglia", "Sebastiano", ""], ["Scagliarini", "Tomas", ""], ["Daniels", "Bryan C.", ""], ["Marinazzo", "Daniele", ""]]}, {"id": "2007.16104", "submitter": "Hubert Banville", "authors": "Hubert Banville, Omar Chehab, Aapo Hyv\\\"arinen, Denis-Alexander\n  Engemann, Alexandre Gramfort", "title": "Uncovering the structure of clinical EEG signals with self-supervised\n  learning", "comments": "32 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG eess.SP q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective. Supervised learning paradigms are often limited by the amount of\nlabeled data that is available. This phenomenon is particularly problematic in\nclinically-relevant data, such as electroencephalography (EEG), where labeling\ncan be costly in terms of specialized expertise and human processing time.\nConsequently, deep learning architectures designed to learn on EEG data have\nyielded relatively shallow models and performances at best similar to those of\ntraditional feature-based approaches. However, in most situations, unlabeled\ndata is available in abundance. By extracting information from this unlabeled\ndata, it might be possible to reach competitive performance with deep neural\nnetworks despite limited access to labels. Approach. We investigated\nself-supervised learning (SSL), a promising technique for discovering structure\nin unlabeled data, to learn representations of EEG signals. Specifically, we\nexplored two tasks based on temporal context prediction as well as contrastive\npredictive coding on two clinically-relevant problems: EEG-based sleep staging\nand pathology detection. We conducted experiments on two large public datasets\nwith thousands of recordings and performed baseline comparisons with purely\nsupervised and hand-engineered approaches. Main results. Linear classifiers\ntrained on SSL-learned features consistently outperformed purely supervised\ndeep neural networks in low-labeled data regimes while reaching competitive\nperformance when all labels were available. Additionally, the embeddings\nlearned with each method revealed clear latent structures related to\nphysiological and clinical phenomena, such as age effects. Significance. We\ndemonstrate the benefit of self-supervised learning approaches on EEG data. Our\nresults suggest that SSL may pave the way to a wider use of deep learning\nmodels on EEG data.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 14:34:47 GMT"}], "update_date": "2020-08-03", "authors_parsed": [["Banville", "Hubert", ""], ["Chehab", "Omar", ""], ["Hyv\u00e4rinen", "Aapo", ""], ["Engemann", "Denis-Alexander", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "2007.16121", "submitter": "Maike Klingel", "authors": "Maike Klingel (1, 2 and 3), Norbert Kopco (3) and Bernhard Laback (1)\n  ((1) Acoustics Research Institute, Austrian Academy of Sciences, (2)\n  Department of Cognition, Emotion, and Methods in Psychology, Faculty of\n  Psychology, University of Vienna, (3) Institute of Computer Science, Faculty\n  of Science, P. J. Safarik University in Kosice)", "title": "Reweighting of Binaural Localization Cues Induced by Lateralization\n  Training", "comments": null, "journal-ref": null, "doi": "10.1007/s10162-021-00800-8", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Normal-hearing listeners adapt to alterations in sound localization cues.\nThis adaptation can result from the establishment of a new spatial map of the\naltered cues or from a stronger relative weighting of unaltered compared to\naltered cues. Such reweighting has been shown for monaural vs. binaural cues.\nHowever, studies attempting to reweight the two binaural cues, interaural\ndifferences in time and level, yielded inconclusive results. In this study we\ninvestigated whether binaural cue reweighting can be induced by a\nlateralization training in a virtual audio-visual environment. 20\nnormal-hearing participants, divided into two groups, completed the experiment\nconsisting of a seven-day lateralization training in a virtual audio-visual\nenvironment, preceded and followed by a test measuring the binaural cue\nweights. During testing, the participants task was to lateralize 500-ms\nbandpass-filtered (2-4 kHz) noise bursts containing various combinations of\nspatially consistent and inconsistent ITDs and ILDs. During training, the task\nwas extended by visual cues reinforcing ITDs in one group and ILDs in the other\ngroup as well as manipulating the azimuthal ranges of the two cues. In both\ngroups, the weight given to the reinforced cue increased significantly from\npre- to posttest, suggesting that participants reweighted the binaural cues in\nthe expected direction. This reweighting occurred predominantly within the\nfirst training session. The present results are relevant as binaural cue\nreweighting is, for example, likely to occur when normal-hearing listeners\nadapt to new acoustic environments. Similarly, binaural cue reweighting might\nbe a factor underlying the low contribution of ITDs to sound localization of\ncochlear-implant listeners as they typically do not experience reliable ITD\ncues with their clinical devices.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 15:05:35 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Klingel", "Maike", "", "1, 2 and 3"], ["Kopco", "Norbert", ""], ["Laback", "Bernhard", ""]]}, {"id": "2007.16138", "submitter": "Quanlong Wang", "authors": "Camilo Miguel Signorelli, Quanlong Wang, Ilyas Khan", "title": "A Compositional Model of Consciousness based on Consciousness-Only", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific studies of consciousness rely on objects whose existence is\nassumed to be independent of any consciousness. On the contrary, we assume\nconsciousness to be fundamental, and that one of the main features of\nconsciousness is characterized as being other-dependent. We set up a framework\nwhich naturally subsumes this feature by defining a compact closed category\nwhere morphisms represent conscious processes. These morphisms are a\ncomposition of a set of generators, each being specified by their relations\nwith other generators, and therefore co-dependent. The framework is general\nenough and fits well into a compositional model of consciousness.\nInterestingly, we also show how our proposal may become a step towards avoiding\nthe hard problem of consciousness, and thereby address the combination problem\nof conscious experiences.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2020 15:35:50 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 17:49:21 GMT"}, {"version": "v3", "created": "Thu, 25 Feb 2021 00:00:14 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Signorelli", "Camilo Miguel", ""], ["Wang", "Quanlong", ""], ["Khan", "Ilyas", ""]]}]