[{"id": "1909.01012", "submitter": "Tom Tetzlaff", "authors": "Claudia Bachmann, Tom Tetzlaff, Renato Duarte, Abigail Morrison", "title": "Firing rate homeostasis counteracts changes in stability of recurrent\n  neural networks caused by synapse loss in Alzheimer's disease", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1007790", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impairment of cognitive function in Alzheimer's is clearly correlated to\nsynapse loss. However, the mechanisms underlying this correlation are only\npoorly understood. Here, we investigate how the loss of excitatory synapses in\nsparsely connected random networks of spiking excitatory and inhibitory neurons\nalters their dynamical characteristics. Beyond the effects on the network's\nactivity statistics, we find that the loss of excitatory synapses on excitatory\nneurons shifts the network dynamic towards the stable regime. The decrease in\nsensitivity to small perturbations to time varying input can be considered as\nan indication of a reduction of computational capacity. A full recovery of the\nnetwork performance can be achieved by firing rate homeostasis, here\nimplemented by an up-scaling of the remaining excitatory-excitatory synapses.\nBy analysing the stability of the linearized network dynamics, we explain how\nhomeostasis can simultaneously maintain the network's firing rate and\nsensitivity to small perturbations.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 09:18:28 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Bachmann", "Claudia", ""], ["Tetzlaff", "Tom", ""], ["Duarte", "Renato", ""], ["Morrison", "Abigail", ""]]}, {"id": "1909.01401", "submitter": "Pengfei Sun", "authors": "Pengfei Sun and Gopala K. Anumanchipalli and Edward F. Chang", "title": "Brain2Char: A Deep Architecture for Decoding Text from Brain Recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding language representations directly from the brain can enable new\nBrain-Computer Interfaces (BCI) for high bandwidth human-human and\nhuman-machine communication. Clinically, such technologies can restore\ncommunication in people with neurological conditions affecting their ability to\nspeak. In this study, we propose a novel deep network architecture Brain2Char,\nfor directly decoding text (specifically character sequences) from direct brain\nrecordings (called Electrocorticography, ECoG). Brain2Char framework combines\nstate-of-the-art deep learning modules --- 3D Inception layers for multiband\nspatiotemporal feature extraction from neural data and bidirectional recurrent\nlayers, dilated convolution layers followed by language model weighted beam\nsearch to decode character sequences, optimizing a connectionist temporal\nclassification (CTC) loss. Additionally, given the highly non-linear\ntransformations that underlie the conversion of cortical function to character\nsequences, we perform regularizations on the network's latent representations\nmotivated by insights into cortical encoding of speech production and\nartifactual aspects specific to ECoG data acquisition. To do this, we impose\nauxiliary losses on latent representations for articulatory movements, speech\nacoustics and session specific non-linearities. In 3 participants tested here,\nBrain2Char achieves 10.6\\%, 8.5\\% and 7.0\\% Word Error Rates (WER) respectively\non vocabulary sizes ranging from 1200 to 1900 words. Brain2Char also performs\nwell when 2 participants silently mimed sentences. These results set a new\nstate-of-the-art on decoding text from brain and demonstrate the potential of\nBrain2Char as a high-performance communication BCI.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 18:54:43 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Sun", "Pengfei", ""], ["Anumanchipalli", "Gopala K.", ""], ["Chang", "Edward F.", ""]]}, {"id": "1909.01437", "submitter": "Rodrigo A. Garc\\'ia", "authors": "Rodrigo A. Garc\\'ia, Arturo C. Mart\\'i, Cecilia Cabeza and Nicol\\'as\n  Rubido", "title": "Small-worldness favours network inference", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": "10.13140/RG.2.2.30449.84329", "report-no": null, "categories": "cond-mat.dis-nn physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A main goal in the analysis of a complex system is to infer its underlying\nnetwork structure from time-series observations of its behaviour. The inference\nprocess is often done by using bi-variate similarity measures, such as the\ncross-correlation (CC), however, the main factors favouring or hindering its\nsuccess are still puzzling. Here, we use synthetic neuron models in order to\nreveal the main topological properties that frustrate or facilitate inferring\nthe underlying network from CC measurements. Specifically, we use pulse-coupled\nIzhikevich neurons connected as in the Caenorhabditis elegans neural networks\nas well as in networks with similar randomness and small-worldness. We analyse\nthe effectiveness and robustness of the inference process under different\nobservations and collective dynamics, contrasting the results obtained from\nusing membrane potentials and inter-spike interval time-series. We find that\noverall, small-worldness favours network inference and degree heterogeneity\nhinders it. In particular, success rates in C. elegans networks -- that combine\nsmall-world properties with degree heterogeneity -- are closer to success rates\nin Erd\\\"os-R\\'enyi network models rather than those in Watts-Strogatz network\nmodels. These results are relevant to understand better the relationship\nbetween topological properties and function in different neural networks.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2019 20:28:50 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Garc\u00eda", "Rodrigo A.", ""], ["Mart\u00ed", "Arturo C.", ""], ["Cabeza", "Cecilia", ""], ["Rubido", "Nicol\u00e1s", ""]]}, {"id": "1909.01561", "submitter": "Dileep George", "authors": "Dileep George", "title": "What can the brain teach us about building artificial intelligence?", "comments": null, "journal-ref": "Behavioral and Brain Sciences, volume 40, 2017", "doi": "10.1017/S0140525X17000140", "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is the preprint of an invited commentary on Lake et al's\nBehavioral and Brain Sciences article titled \"Building machines that learn and\nthink like people\". Lake et al's paper offers a timely critique on the recent\naccomplishments in artificial intelligence from the vantage point of human\nintelligence, and provides insightful suggestions about research directions for\nbuilding more human-like intelligence. Since we agree with most of the points\nraised in that paper, we will offer a few points that are complementary.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 05:49:59 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["George", "Dileep", ""]]}, {"id": "1909.01689", "submitter": "Marconi Barbosa Dr", "authors": "Marconi Barbosa and Ted Maddess", "title": "Symmetry and the salience of textures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the role of symmetry in visual stimuli designed\nto probe human sensitivity to image statistics. Our starting point is a\nrecently published parameter space, a point in which defines a family of binary\ntexture images displaying a prescribed content of \\nth{1}- to \\nth{4}-order\ncorrelations among pixels in 2x2 patches. We show that this parameter space can\nbe represented by fewer variables, namely the \\emph{orbit invariants} obtained\nby exploiting texture symmetry. Next we show how a class of locally countable\ntexture statistics, the Minkowski functionals -- recently shown to be a proxy\nfor human performance in texture discrimination tasks - can be written as a\nlinear combination of the dihedral orbit invariants. Furthermore, by recasting\nthese functionals as a combination of dihedral invariants, a generalization of\nthese functionals can be obtained for textures of any number of grey-levels,\npatch sizes, or lattice types -- greatly reducing the number of\ndimensions/parameters needed to characterize the generated images. Orbit\ninvariants may therefore provide a clue on the discrimination of these richer\ntextures, as the ordinary Minkowski functionals do for binary textures.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 10:47:16 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["Barbosa", "Marconi", ""], ["Maddess", "Ted", ""]]}, {"id": "1909.01908", "submitter": "Alexander Van Meegen", "authors": "Alexander van Meegen, Sacha J. van Albada", "title": "A Microscopic Theory of Intrinsic Timescales in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A complex interplay of single-neuron properties and the recurrent network\nstructure shapes the activity of individual cortical neurons, which differs in\ngeneral from the respective population activity. We develop a theory that makes\nit possible to investigate the influence of both network structure and\nsingle-neuron properties on the single-neuron statistics in block-structured\nsparse random networks of spiking neurons. In particular, the theory predicts\nthe neuron-level autocorrelation times, also known as intrinsic timescales, of\nthe neuronal activity. The theory is based on a postulated extension of dynamic\nmean-field theory from rate networks to spiking networks, which is validated\nvia simulations. It accounts for both static variability, e.g. due to a\ndistributed number of incoming synapses per neuron, and dynamical fluctuations\nof the input. To illustrate the theory, we apply it to a balanced random\nnetwork of leaky integrate-and-fire neurons, a balanced random network of\ngeneralized linear model neurons, and a biologically constrained network of\nleaky integrate-and-fire neurons. For the generalized linear model network, an\nanalytical solution to the colored noise problem allows us to obtain\nself-consistent firing rate distributions, single-neuron power spectra, and\nintrinsic timescales. For the leaky integrate-and-fire networks, we obtain the\nsame quantities by means of a novel analytical approximation of the colored\nnoise problem that is valid in the fluctuation-driven regime. Our results\nprovide a further step towards an understanding of the dynamics in recurrent\nspiking cortical networks.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 16:02:05 GMT"}], "update_date": "2019-09-05", "authors_parsed": [["van Meegen", "Alexander", ""], ["van Albada", "Sacha J.", ""]]}, {"id": "1909.01915", "submitter": "Mark Dubbelman", "authors": "Mark A. Dubbelman, Merike Verrijp, David Facal, Gonzalo\n  S\\'anchez-Benavides, Laura J.E. Brown, Wiesje M. van der Flier, Hanna\n  Jokinen, Athene Lee, Iracema Leroi, Cristina Lojo-Seoane, Vuk Milosevic,\n  Jos\\'e Lu\\'is Molinuevo, Arturo X. Pereiro Rozas, Craig Ritchie, Stephen\n  Salloway, Gemma Stringer, Stelios Zygouris, Bruno Dubois, St\\'ephane\n  Epelbaum, Philip Scheltens, Sietske A.M. Sikkes", "title": "The influence of diversity on the measurement of functional impairment:\n  An international validation of the Amsterdam IADL Questionnaire in 8\n  countries", "comments": null, "journal-ref": null, "doi": "10.1002/dad2.12021", "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  INTRODUCTION: To understand the potential influence of diversity on the\nmeasurement of functional impairment in dementia, we aimed to investigate\npossible bias caused by age, gender, education, and cultural differences.\nMETHODS: 3,571 individuals (67.1 {\\pm} 9.5 years old, 44.7% female) from the\nNetherlands, Spain, France, United States, United Kingdom, Greece, Serbia and\nFinland were included. Functional impairment was measured using the Amsterdam\nIADL Questionnaire. Item bias was assessed using differential item functioning\n(DIF) analysis. RESULTS: There were some differences in activity endorsement. A\nfew items showed statistically significant DIF. However, there was no evidence\nof meaningful item bias: effect sizes were low ({\\Delta}R2 range 0-0.03).\nImpact on total scores was minimal. DISCUSSION: The results imply a limited\nbias for age, gender, education and culture in the measurement of functional\nimpairment. This study provides an important step in recognizing the potential\ninfluence of diversity on primary outcomes in dementia research.\n", "versions": [{"version": "v1", "created": "Wed, 4 Sep 2019 16:08:14 GMT"}, {"version": "v2", "created": "Wed, 29 Jan 2020 07:48:06 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Dubbelman", "Mark A.", ""], ["Verrijp", "Merike", ""], ["Facal", "David", ""], ["S\u00e1nchez-Benavides", "Gonzalo", ""], ["Brown", "Laura J. E.", ""], ["van der Flier", "Wiesje M.", ""], ["Jokinen", "Hanna", ""], ["Lee", "Athene", ""], ["Leroi", "Iracema", ""], ["Lojo-Seoane", "Cristina", ""], ["Milosevic", "Vuk", ""], ["Molinuevo", "Jos\u00e9 Lu\u00eds", ""], ["Rozas", "Arturo X. Pereiro", ""], ["Ritchie", "Craig", ""], ["Salloway", "Stephen", ""], ["Stringer", "Gemma", ""], ["Zygouris", "Stelios", ""], ["Dubois", "Bruno", ""], ["Epelbaum", "St\u00e9phane", ""], ["Scheltens", "Philip", ""], ["Sikkes", "Sietske A. M.", ""]]}, {"id": "1909.02199", "submitter": "Alessandro Fontana", "authors": "Alessandro Fontana", "title": "Towards a general model for psychopathology", "comments": "40 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The DSM-1 was published in 1952, contains 128 diagnostic categories,\ndescribed in 132 pages. The DSM-5 appeared in 2013, contains 541 diagnostic\ncategories, described in 947 pages. The field of psychology is characterised by\na steady proliferation of diagnostic models and subcategories, that seems to be\ninspired by the principle of \"divide and inflate\". This approach is in contrast\nwith experimental evidence, which suggests on one hand that traumas of various\nkind are often present in the anamnesis of patients and, on the other, that the\ngene variants implicated are shared across a wide range of diagnoses. In this\nwork I propose a holistic approach, built with tools borrowed from the field of\nArtificial Intelligence. My model is based on two pillars. The first one is\ntrauma, which represents the attack to the mind, is psychological in nature and\nhas its origin in the environment. The second pillar is dissociation, which\nrepresents the mind defence in both physiological and pathological conditions,\nand incorporates all other defence mechanisms. Damages to dissociation can be\nconsidered as another category of attacks, that are neurobiological in nature\nand can be of genetic or environmental origin. They include, among other\nfactors, synaptic over-pruning, abuse of drugs and inflammation. These factors\nconcur to weaken the defence, represented by the neural networks that implement\nthe dissociation mechanism in the brain. The model is subsequently used to\ninterpret five mental conditions: PTSD, complex PTSD, dissociative identity\ndisorder, schizophrenia and bipolar disorder. Ideally, this is a first step\ntowards building a model that aims to explain a wider range of\npsychopathological affections with a single theoretical framework. The last\npart is dedicated to sketching a new psychotherapy for psychological trauma.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 03:38:03 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Fontana", "Alessandro", ""]]}, {"id": "1909.02295", "submitter": "Filipe Gama", "authors": "Filipe Gama and Matej Hoffmann", "title": "The homunculus for proprioception: Toward learning the representation of\n  a humanoid robot's joint space using self-organizing maps", "comments": "2 pages, 2 figures, ICDL-Epirob 2019 conference", "journal-ref": "Proceedings of the 2019 Joint IEEE 9th International Conference on\n  Development and Learning and Epigenetic Robotics (ICDL-EpiRob), Engineer's\n  House Conference Centre, Oslo, Norway, August 19-22, 2019, pp. 113-114", "doi": null, "report-no": null, "categories": "cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In primate brains, tactile and proprioceptive inputs are relayed to the\nsomatosensory cortex which is known for somatotopic representations, or,\n\"homunculi\". Our research centers on understanding the mechanisms of the\nformation of these and more higher-level body representations (body schema) by\nusing humanoid robots and neural networks to construct models. We specifically\nfocus on how spatial representation of the body may be learned from\nsomatosensory information in self-touch configurations. In this work, we target\nthe representation of proprioceptive inputs, which we take to be joint angles\nin the robot. The inputs collected in different body postures serve as inputs\nto a Self-Organizing Map (SOM) with a 2D lattice on the output. With\nunrestricted, all-to-all connections, the map is not capable of representing\nthe input space while preserving the topological relationships, because the\nintrinsic dimensionality of the body posture space is too large. Hence, we use\na method we developed previously for tactile inputs (Hoffmann, Straka et al.\n2018) called MRF-SOM, where the Maximum Receptive Field of output neurons is\nrestricted so they only learn to represent specific parts of the input space.\nThis is in line with the receptive fields of neurons in somatosensory areas\nrepresenting proprioception that often respond to combination of few joints\n(e.g. wrist and elbow).\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 10:07:37 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Gama", "Filipe", ""], ["Hoffmann", "Matej", ""]]}, {"id": "1909.02297", "submitter": "Pedro Mediano", "authors": "Pedro A.M. Mediano, Fernando Rosas, Robin L. Carhart-Harris, Anil K.\n  Seth, Adam B. Barrett", "title": "Beyond integrated information: A taxonomy of information dynamics\n  phenomena", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most information dynamics and statistical causal analysis frameworks rely on\nthe common intuition that causal interactions are intrinsically pairwise --\nevery 'cause' variable has an associated 'effect' variable, so that a 'causal\narrow' can be drawn between them. However, analyses that depict\ninterdependencies as directed graphs fail to discriminate the rich variety of\nmodes of information flow that can coexist within a system. This, in turn,\ncreates problems with attempts to operationalise the concepts of 'dynamical\ncomplexity' or `integrated information.' To address this shortcoming, we\ncombine concepts of partial information decomposition and integrated\ninformation, and obtain what we call Integrated Information Decomposition, or\n$\\Phi$ID. We show how $\\Phi$ID paves the way for more detailed analyses of\ninterdependencies in multivariate time series, and sheds light on collective\nmodes of information dynamics that have not been reported before. Additionally,\n$\\Phi$ID reveals that what is typically referred to as 'integration' is\nactually an aggregate of several heterogeneous phenomena. Furthermore, $\\Phi$ID\ncan be used to formulate new, tailored measures of integrated information, as\nwell as to understand and alleviate the limitations of existing measures.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 10:11:00 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Mediano", "Pedro A. M.", ""], ["Rosas", "Fernando", ""], ["Carhart-Harris", "Robin L.", ""], ["Seth", "Anil K.", ""], ["Barrett", "Adam B.", ""]]}, {"id": "1909.02603", "submitter": "Kameron Harris", "authors": "Kameron Decker Harris", "title": "Additive function approximation in the brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many biological learning systems such as the mushroom body, hippocampus, and\ncerebellum are built from sparsely connected networks of neurons. For a new\nunderstanding of such networks, we study the function spaces induced by sparse\nrandom features and characterize what functions may and may not be learned. A\nnetwork with $d$ inputs per neuron is found to be equivalent to an additive\nmodel of order $d$, whereas with a degree distribution the network combines\nadditive terms of different orders. We identify three specific advantages of\nsparsity: additive function approximation is a powerful inductive bias that\nlimits the curse of dimensionality, sparse networks are stable to outlier noise\nin the inputs, and sparse random features are scalable. Thus, even simple brain\narchitectures can be powerful function approximators. Finally, we hope that\nthis work helps popularize kernel theories of networks among computational\nneuroscientists.\n", "versions": [{"version": "v1", "created": "Thu, 5 Sep 2019 19:07:33 GMT"}, {"version": "v2", "created": "Fri, 13 Sep 2019 21:41:07 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Harris", "Kameron Decker", ""]]}, {"id": "1909.02833", "submitter": "Michael Taynnan Barros", "authors": "Geoflly L. Adonias, Anastasia Yastrebova, Michael Taynnan Barros,\n  Yevgeni Koucheryavy, Frances Cleary, Sasitharan Balasubramaniam", "title": "Utilizing Neurons for Digital Logic Circuits: A Molecular Communications\n  Analysis", "comments": "Submitted for journal publication", "journal-ref": "IEEE Transactions on NanoBioscience,2020", "doi": "10.1109/TNB.2020.2975942", "report-no": null, "categories": "q-bio.NC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of synthetic biology, several new tools have been\nconceptualized over the years as alternative treatments for current medical\nprocedures. Most of those applications are applied to various chronic diseases.\nThis work investigates how synthetically engineered neurons can operate as\ndigital logic gates that can be used towards bio-computing for the brain. We\nquantify the accuracy of logic gates under high firing rates amid a network of\nneurons and by how much it can smooth out uncontrolled neuronal firings. To\ntest the efficacy of our method, simulations composed of computational models\nof neurons connected in a structure that represents a logic gate are performed.\nThe simulations demonstrated the accuracy of performing the correct logic\noperation, and how specific properties such as the firing rate can play an\nimportant role in the accuracy. As part of the analysis, the Mean squared error\nis used to quantify the quality of our proposed model and predicting the\naccurate operation of a gate based on different sampling frequencies. As an\napplication, the logic gates were used to trap epileptic seizures in a neuronal\nnetwork, where the results demonstrated the effectiveness of reducing the\nfiring rate. Our proposed system has the potential for computing numerous\nneurological conditions of the brain.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 11:50:55 GMT"}, {"version": "v2", "created": "Wed, 18 Sep 2019 14:27:07 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Adonias", "Geoflly L.", ""], ["Yastrebova", "Anastasia", ""], ["Barros", "Michael Taynnan", ""], ["Koucheryavy", "Yevgeni", ""], ["Cleary", "Frances", ""], ["Balasubramaniam", "Sasitharan", ""]]}, {"id": "1909.02931", "submitter": "Oleg Kanakov", "authors": "Oleg Kanakov, Susanna Gordleeva, Alexey Zaikin", "title": "Integrated Information in the Spiking-Bursting Stochastic Model", "comments": null, "journal-ref": null, "doi": "10.3390/e22121334", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents a comprehensive analytic description in terms of the\nempirical \"whole minus sum\" version of Integrated Information in comparison to\nthe \"decoder based\" version for the \"spiking-bursting\" discrete-time,\ndiscrete-state stochastic model, which was recently introduced to describe a\nspecific type of dynamics in a neuron-astrocyte network. The \"whole minus sum\"\ninformation may change sign, and an interpretation of this transition in terms\nof \"net synergy\" is available in the literature. This motivates our particular\ninterest to the sign of the \"whole minus sum\" information in our analytical\nconsideration. The behavior of the \"whole minus sum\" and \"decoder based\"\ninformation measures are found to bear a lot of similarity, showing their\nmutual asymptotic convergence as time-uncorrelated activity is increased, with\nthe sign transition of the \"whole minus sum\" information associated to a rapid\ngrowth in the \"decoder based\" information. The study aims at creating a\ntheoretical base for using the spiking-bursting model as a well understood\nreference point for applying Integrated Information concepts to systems\nexhibiting similar bursting behavior (in particular, to neuron-astrocyte\nnetworks). The model can also be of interest as a new discrete-state test bench\nfor different formulations of Integrated Information.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 14:31:54 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Kanakov", "Oleg", ""], ["Gordleeva", "Susanna", ""], ["Zaikin", "Alexey", ""]]}, {"id": "1909.02944", "submitter": "Nataliya Stankevich", "authors": "Nataliya Stankevich and Aneta Koseska", "title": "Cooperative regulation of cellular identity in systems with\n  intercellular communication defects", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": "10.1063/1.5127107", "report-no": null, "categories": "q-bio.CB nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cooperative dynamics of cellular populations emerging from the underlying\ninteractions determines cellular functions, and thereby their identity in\ntissues. Global deviations from this dynamics on the other hand reflects\npathological conditions. However, how these conditions are stabilized from\ndis-regulation on the level of the single entities is still unclear. Here we\ntackle this question using generic Hodgkin-Huxley type of models that describe\nphysiological bursting dynamics of pancreatic beta-cells, and introduce channel\ndis-function to mimic pathological silent dynamics. The probability for\npathological behavior in beta-cell populations is $\\sim100\\%$ when all cell\nhave these defects, despite the negligible size of the silent state basin of\nattraction for single cells. In stark contrast, in a more realistic scenario\nfor a heterogeneous population, stabilization of the pathological state depends\non the size of the sub-population which acquired the defects. However, the\nprobability to exhibit stable pathological dynamics in this case is less than\n$\\sim10\\%$. These results therefore suggest that the physiological bursting\ndynamics of a population of beta-cells is cooperatively regulated, even under\nintercellular communication defects induced by dis-functional channels of\nsingle-cells.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 16:28:00 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 17:35:10 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Stankevich", "Nataliya", ""], ["Koseska", "Aneta", ""]]}, {"id": "1909.02947", "submitter": "Carina Curto", "authors": "Carina Curto, Jesse Geneson, Katherine Morrison", "title": "Stable fixed points of combinatorial threshold-linear networks", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial threshold-linear networks (CTLNs) are a special class of neural\nnetworks whose dynamics are tightly controlled by an underlying directed graph.\nIn prior work, we showed that target-free cliques of the graph correspond to\nstable fixed points of the dynamics, and we conjectured that these are the only\nstable fixed points allowed. In this paper we prove that the conjecture holds\nin a variety of special cases, including for graphs with very strong inhibition\nand graphs of size $n \\leq 4$. We also provide further evidence for the\nconjecture by showing that sparse graphs and graphs that are nearly cliques can\nnever support stable fixed points. Finally, we translate some results from\nextremal combinatorics to upper bound the number of stable fixed points of\nCTLNs in cases where the conjecture holds.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 06:36:01 GMT"}], "update_date": "2019-09-09", "authors_parsed": [["Curto", "Carina", ""], ["Geneson", "Jesse", ""], ["Morrison", "Katherine", ""]]}, {"id": "1909.03083", "submitter": "Ed Lein", "authors": "Rafael Yuste, Michael Hawrylycz, Nadia Aalling, Detlev Arendt, Ruben\n  Armananzas, Giorgio Ascoli, Concha Bielza, Vahid Bokharaie, Tobias Bergmann,\n  Irina Bystron, Marco Capogna, Yoonjeung Chang, Ann Clemens, Christiaan de\n  Kock, Javier DeFelipe, Sandra Dos Santos, Keagan Dunville, Dirk Feldmeyer,\n  Richard Fiath, Gordon Fishell, Angelica Foggetti, Xuefan Gao, Parviz Ghaderi,\n  Onur Gunturkun, Vanessa Jane Hall, Moritz Helmstaedter, Suzana\n  Herculano-Houzel, Markus Hilscher, Hajime Hirase, Jens Hjerling-Leffler,\n  Rebecca Hodge, Z. Josh Huang, Rafiq Huda, Yuan Juan, Konstantin Khodosevich,\n  Ole Kiehn, Henner Koch, Eric Kuebler, Malte Kuhnemund, Pedro Larranaga,\n  Boudewijn Lelieveldt, Emma Louise Louth, Jan Lui, Huibert Mansvelder, Oscar\n  Marin, Julio Mart\\'inez-Trujillo, Homeira Moradi, Natalia Goriounova, Alok\n  Mohapatra, Maiken Nedergaard, Pavel N\\v{e}mec, Netanel Ofer, Ulrich\n  Pfisterer, Samuel Pontes, William Redmond, Jean Rossier, Joshua Sanes,\n  Richard Scheuermann, Esther Serrano Saiz, Peter Somogyi, G\\'abor Tam\\'as,\n  Andreas Tolias, Maria Tosches, Miguel Turrero Garcia, Argel Aguilar-Valles,\n  Hermany Munguba, Christian Wozny, Thomas Wuttke, Liu Yong, Hongkui Zeng, Ed\n  S. Lein", "title": "A community-based transcriptomics classification and nomenclature of\n  neocortical cell types", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To understand the function of cortical circuits it is necessary to classify\ntheir underlying cellular diversity. Traditional attempts based on comparing\nanatomical or physiological features of neurons and glia, while productive,\nhave not resulted in a unified taxonomy of neural cell types. The recent\ndevelopment of single-cell transcriptomics has enabled, for the first time,\nsystematic high-throughput profiling of large numbers of cortical cells and the\ngeneration of datasets that hold the promise of being complete, accurate and\npermanent. Statistical analyses of these data have revealed the existence of\nclear clusters, many of which correspond to cell types defined by traditional\ncriteria, and which are conserved across cortical areas and species. To\ncapitalize on these innovations and advance the field, we, the Copenhagen\nConvention Group, propose the community adopts a transcriptome-based taxonomy\nof the cell types in the adult mammalian neocortex. This core classification\nshould be ontological, hierarchical and use a standardized nomenclature. It\nshould be configured to flexibly incorporate new data from multiple approaches,\ndevelopmental stages and a growing number of species, enabling improvement and\nrevision of the classification. This community-based strategy could serve as a\ncommon foundation for future detailed analysis and reverse engineering of\ncortical circuits and serve as an example for cell type classification in other\nparts of the nervous system and other organs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 18:12:50 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Yuste", "Rafael", ""], ["Hawrylycz", "Michael", ""], ["Aalling", "Nadia", ""], ["Arendt", "Detlev", ""], ["Armananzas", "Ruben", ""], ["Ascoli", "Giorgio", ""], ["Bielza", "Concha", ""], ["Bokharaie", "Vahid", ""], ["Bergmann", "Tobias", ""], ["Bystron", "Irina", ""], ["Capogna", "Marco", ""], ["Chang", "Yoonjeung", ""], ["Clemens", "Ann", ""], ["de Kock", "Christiaan", ""], ["DeFelipe", "Javier", ""], ["Santos", "Sandra Dos", ""], ["Dunville", "Keagan", ""], ["Feldmeyer", "Dirk", ""], ["Fiath", "Richard", ""], ["Fishell", "Gordon", ""], ["Foggetti", "Angelica", ""], ["Gao", "Xuefan", ""], ["Ghaderi", "Parviz", ""], ["Gunturkun", "Onur", ""], ["Hall", "Vanessa Jane", ""], ["Helmstaedter", "Moritz", ""], ["Herculano-Houzel", "Suzana", ""], ["Hilscher", "Markus", ""], ["Hirase", "Hajime", ""], ["Hjerling-Leffler", "Jens", ""], ["Hodge", "Rebecca", ""], ["Huang", "Z. Josh", ""], ["Huda", "Rafiq", ""], ["Juan", "Yuan", ""], ["Khodosevich", "Konstantin", ""], ["Kiehn", "Ole", ""], ["Koch", "Henner", ""], ["Kuebler", "Eric", ""], ["Kuhnemund", "Malte", ""], ["Larranaga", "Pedro", ""], ["Lelieveldt", "Boudewijn", ""], ["Louth", "Emma Louise", ""], ["Lui", "Jan", ""], ["Mansvelder", "Huibert", ""], ["Marin", "Oscar", ""], ["Mart\u00ednez-Trujillo", "Julio", ""], ["Moradi", "Homeira", ""], ["Goriounova", "Natalia", ""], ["Mohapatra", "Alok", ""], ["Nedergaard", "Maiken", ""], ["N\u011bmec", "Pavel", ""], ["Ofer", "Netanel", ""], ["Pfisterer", "Ulrich", ""], ["Pontes", "Samuel", ""], ["Redmond", "William", ""], ["Rossier", "Jean", ""], ["Sanes", "Joshua", ""], ["Scheuermann", "Richard", ""], ["Saiz", "Esther Serrano", ""], ["Somogyi", "Peter", ""], ["Tam\u00e1s", "G\u00e1bor", ""], ["Tolias", "Andreas", ""], ["Tosches", "Maria", ""], ["Garcia", "Miguel Turrero", ""], ["Aguilar-Valles", "Argel", ""], ["Munguba", "Hermany", ""], ["Wozny", "Christian", ""], ["Wuttke", "Thomas", ""], ["Yong", "Liu", ""], ["Zeng", "Hongkui", ""], ["Lein", "Ed S.", ""]]}, {"id": "1909.03091", "submitter": "Behnaz Akbarian", "authors": "Behnaz Akbarian, Abbas Erfanian", "title": "A framework for seizure detection using effective connectivity, graph\n  theory and deep modular neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective\n  The electrical characteristics of the EEG signals can be used for seizure\ndetection. Statistical independence between different brain regions is measured\nby functional brain connectivity (FBC). Specific directional effects can't\nconsider by FBC and thus effective brain connectivity (EBC) is used to measure\ncausal intervention between one neuronal region and the rest of the neuronal\nregions. Our main purpose is to provide a reliable automatic seizure detection\napproach.\n  Methods\n  In this study, three new methods are provided. Deep modular neural network\n(DMNN) is developed based on a combination of various EBC classification\nresults in the different frequencies. Another method is named \"modular\neffective neural networks (MENN)\". This method combines the classification\nresults of the three different EBC in the specific frequency. \"Modular\nfrequency neural networks (MFNN)\" is another method that combines the\nclassification results of the specific EBC in the seven different frequencies.\n  Results\n  The mean accuracy of the MFNN are 97.14%, 98.53%, and 97.91% using directed\ntransfer function, directed coherence, and generalized partial directed\ncoherence, respectively. Using the MENN, the highest mean accuracy is 98.34%.\nFinally, DMNN has the highest mean accuracy which is equal to 99.43. To our\nbest knowledge, the proposed method is a new method that provides the high\naccuracy in comparison to other studies which used MIT-CHB database.\n  Conclusion and significance\n  The knowledge of structure-function relationships between different areas of\nthe brain is necessary for characterizing the underlying dynamics. Hence,\nfeatures based on EBC can provide a reliable automatic seizure detection\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:01:08 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Akbarian", "Behnaz", ""], ["Erfanian", "Abbas", ""]]}, {"id": "1909.03109", "submitter": "Qiongge Li", "authors": "Qiongge Li, Luca Pasquini, Gino Del Ferraro, Madeleine Gene, Kyung K.\n  Peck, Hern\\'an A. Makse and Andrei I. Holodny", "title": "Monolingual and bilingual language networks in healthy subjects using\n  functional MRI and graph theory", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph physics.data-an physics.med-ph physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-surgical language mapping with functional magnetic resonance imaging\n(fMRI) is routinely conducted to assist the neurosurgeon in preventing damage\nto brain regions responsible for language. Functional differences exist between\nthe monolingual versus the bilingual brain, whereas clinical fMRI tasks are\ntypically conducted in a single language. The presence of secondary language\nprocessing mechanisms is a potential source of error in the inferred language\nmap. From fMRI data of healthy bilingual and monolingual subjects we obtain\nlanguage maps as functional networks. Our results show a sub-network \"core\"\narchitecture consisting of the Broca's, pre-supplementary motor, and premotor\nareas present across all subjects. Wernicke's Area was found to connect to the\n\"core\" to a different extent across groups. The $k$ core centrality measure\nshows \"core\" areas belong to the maximum core while WA and other fROIs vary\nacross groups. The results may provide a benchmark to preserve equal treatment\noutcomes for bilingual patients.\n", "versions": [{"version": "v1", "created": "Fri, 6 Sep 2019 19:59:04 GMT"}, {"version": "v2", "created": "Mon, 15 Jun 2020 16:27:18 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Li", "Qiongge", ""], ["Pasquini", "Luca", ""], ["Del Ferraro", "Gino", ""], ["Gene", "Madeleine", ""], ["Peck", "Kyung K.", ""], ["Makse", "Hern\u00e1n A.", ""], ["Holodny", "Andrei I.", ""]]}, {"id": "1909.03153", "submitter": "Jacob George", "authors": "Michael D. Paskett, Nathaniel R. Olsen, Jacob A. George, David T.\n  Kluger, Mark R. Brinton, Tyler S. Davis, Christopher C. Duncan, and Gregory\n  A. Clark", "title": "A Modular Transradial Bypass Socket for Surface Myoelectric Prosthetic\n  Control in Non-Amputees", "comments": "8 pages, 5 figures", "journal-ref": "IEEE Trans. Neural Syst. Rehabil. Eng. (2019)", "doi": "10.1109/TNSRE.2019.2941109", "report-no": null, "categories": "cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bypass sockets allow researchers to perform tests of prosthetic systems from\nthe prosthetic user's perspective. We designed a modular upper-limb bypass\nsocket with 3D-printed components that can be easily modified for use with a\nvariety of terminal devices. Our bypass socket preserves access to forearm\nmusculature and the hand, which are necessary for surface electromyography and\nto provide substituted sensory feedback. Our bypass socket allows a sufficient\nrange of motion to complete tasks in the frontal working area, as measured on\nnon-amputee participants. We examined the performance of non-amputee\nparticipants using the bypass socket on the original and modified Box and Block\nTests. Participants moved 11.3 +/- 2.7 and 11.7 +/- 2.4 blocks in the original\nand modified Box and Block Tests (mean +/- SD), respectively, within the range\nof reported scores using amputee participants. Range-of-motion for users\nwearing the bypass socket meets or exceeds most reported range-of-motion\nrequirements for activities of daily living. The bypass socket was originally\ndesigned with a freely rotating wrist; we found that adding elastic resistance\nto user wrist rotation while wearing the bypass socket had no significant\neffect on motor decode performance. We have open-sourced the design files and\nan assembly manual for the bypass socket. We anticipate that the bypass socket\nwill be a useful tool to evaluate and develop sensorized myoelectric prosthesis\ntechnology.\n", "versions": [{"version": "v1", "created": "Sat, 7 Sep 2019 00:20:10 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 17:16:29 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Paskett", "Michael D.", ""], ["Olsen", "Nathaniel R.", ""], ["George", "Jacob A.", ""], ["Kluger", "David T.", ""], ["Brinton", "Mark R.", ""], ["Davis", "Tyler S.", ""], ["Duncan", "Christopher C.", ""], ["Clark", "Gregory A.", ""]]}, {"id": "1909.04358", "submitter": "Friedrich Schuessler", "authors": "Friedrich Schuessler, Alexis Dubreuil, Francesca Mastrogiuseppe,\n  Srdjan Ostojic, Omri Barak", "title": "Dynamics of random recurrent networks with correlated low-rank structure", "comments": "18 pages, 7 figures", "journal-ref": "Phys. Rev. Research 2, 013111 (2020)", "doi": "10.1103/PhysRevResearch.2.013111", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A given neural network in the brain is involved in many different tasks. This\nimplies that, when considering a specific task, the network's connectivity\ncontains a component which is related to the task and another component which\ncan be considered random. Understanding the interplay between the structured\nand random components, and their effect on network dynamics and functionality\nis an important open question. Recent studies addressed the co-existence of\nrandom and structured connectivity, but considered the two parts to be\nuncorrelated. This constraint limits the dynamics and leaves the random\nconnectivity non-functional. Algorithms that train networks to perform specific\ntasks typically generate correlations between structure and random\nconnectivity. Here we study nonlinear networks with correlated structured and\nrandom components, assuming the structure to have a low rank. We develop an\nanalytic framework to establish the precise effect of the correlations on the\neigenvalue spectrum of the joint connectivity. We find that the spectrum\nconsists of a bulk and multiple outliers, whose location is predicted by our\ntheory. Using mean-field theory, we show that these outliers directly determine\nboth the fixed points of the system and their stability. Taken together, our\nanalysis elucidates how correlations allow structured and random connectivity\nto synergistically extend the range of computations available to networks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 09:01:33 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 12:51:14 GMT"}, {"version": "v3", "created": "Mon, 23 Dec 2019 23:57:33 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Schuessler", "Friedrich", ""], ["Dubreuil", "Alexis", ""], ["Mastrogiuseppe", "Francesca", ""], ["Ostojic", "Srdjan", ""], ["Barak", "Omri", ""]]}, {"id": "1909.04390", "submitter": "Alex Frid", "authors": "Alex Frid, Larry M. Manevitz, Norberto Eiji Nawa", "title": "Classifying the Valence of Autobiographical Memories from fMRI Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that fMRI analysis using machine learning tools are sufficient to\ndistinguish valence (i.e., positive or negative) of freely retrieved\nautobiographical memories in a cross-participant setting. Our methodology uses\nfeature selection (ReliefF) in combination with boosting methods, both applied\ndirectly to data represented in voxel space. In previous work using the same\ndata set, Nawa and Ando showed that whole-brain based classification could\nachieve above-chance classification accuracy only when both training and\ntesting data came from the same individual. In a cross-participant setting,\nclassification results were not statistically significant. Additionally, on\naverage the classification accuracy obtained when using ReliefF is\nsubstantially higher than previous results - 81% for the within-participant\nclassification, and 62% for the cross-participant classification. Furthermore,\nsince features are defined in voxel space, it is possible to show brain maps\nindicating the regions of that are most relevant in determining the results of\nthe classification. Interestingly, the voxels that were selected using the\nproposed computational pipeline seem to be consistent with current\nneurophysiological theories regarding the brain regions actively involved in\nautobiographical memory processes.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:24:44 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2020 06:24:34 GMT"}], "update_date": "2020-07-27", "authors_parsed": [["Frid", "Alex", ""], ["Manevitz", "Larry M.", ""], ["Nawa", "Norberto Eiji", ""]]}, {"id": "1909.04400", "submitter": "Micha Heilbron", "authors": "Micha Heilbron, Benedikt Ehinger, Peter Hagoort, Floris P. de Lange", "title": "Tracking Naturalistic Linguistic Predictions with Deep Neural Language\n  Models", "comments": "4 pages, 3 figures, accepted at the 2019 Conference on Cognitive\n  Computational Neuroscience", "journal-ref": "2019 Conference on Cognitive Computational Neuroscience", "doi": "10.32470/CCN.2019.1096-0", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction in language has traditionally been studied using simple designs in\nwhich neural responses to expected and unexpected words are compared in a\ncategorical fashion. However, these designs have been contested as being\n`prediction encouraging', potentially exaggerating the importance of prediction\nin language understanding. A few recent studies have begun to address these\nworries by using model-based approaches to probe the effects of linguistic\npredictability in naturalistic stimuli (e.g. continuous narrative). However,\nthese studies so far only looked at very local forms of prediction, using\nmodels that take no more than the prior two words into account when computing a\nword's predictability. Here, we extend this approach using a state-of-the-art\nneural language model that can take roughly 500 times longer linguistic\ncontexts into account. Predictability estimates from the neural network offer a\nmuch better fit to EEG data from subjects listening to naturalistic narrative\nthan simpler models, and reveal strong surprise responses akin to the P200 and\nN400. These results show that predictability effects in language are not a\nside-effect of simple designs, and demonstrate the practical use of recent\nadvances in AI for the cognitive neuroscience of language.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 10:50:04 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Heilbron", "Micha", ""], ["Ehinger", "Benedikt", ""], ["Hagoort", "Peter", ""], ["de Lange", "Floris P.", ""]]}, {"id": "1909.04586", "submitter": "Prashant Raju", "authors": "Prashant C. Raju", "title": "A Theory on Formatting Sensory Input for Cognition", "comments": "I am moving in a completely different direction", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over the last few decades, a lot of progress has been made in understanding\ndifferent aspects of the brain's ability to form abstract representations, but\na specific mechanism for how they are created and used remains to emerge. Here,\nwe review recent findings on the subject and we propose a mechanism for the\ndynamics of forming abstract representations, where the formation of local\nconnectivity in neural networks determines the of search terms between the\nprefrontal cortex and the hippocampus, as well as the amount of detail that is\ntranscribed into abstract representations.\n", "versions": [{"version": "v1", "created": "Sun, 8 Sep 2019 20:00:55 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 13:48:08 GMT"}, {"version": "v3", "created": "Mon, 2 Dec 2019 15:22:02 GMT"}, {"version": "v4", "created": "Sat, 4 Jan 2020 16:38:30 GMT"}, {"version": "v5", "created": "Fri, 28 Feb 2020 00:22:09 GMT"}], "update_date": "2020-03-02", "authors_parsed": [["Raju", "Prashant C.", ""]]}, {"id": "1909.05660", "submitter": "Juan Miguel Valverde", "authors": "Juan Miguel Valverde, Vandad Imani, John D. Lewis, Jussi Tohka", "title": "Predicting intelligence based on cortical WM/GM contrast, cortical\n  thickness and volumetry", "comments": "Submission to the ABCD Neurocognitive Prediction Challenge at MICCAI\n  2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a four-layer fully-connected neural network (FNN) for predicting\nfluid intelligence scores from T1-weighted MR images for the ABCD-challenge. In\naddition to the volumes of brain structures, the FNN uses cortical WM/GM\ncontrast and cortical thickness at 78 cortical regions. These last two\nmeasurements were derived from the T1-weighted MR images using cortical\nsurfaces produced by the CIVET pipeline. The age and gender of the subjects and\nthe scanner manufacturer are also used as features for the learning algorithm.\nThis yielded 283 features provided to the FNN with two hidden layers of 20 and\n15 nodes. The method was applied to the data from the ABCD study. Trained with\na training set of 3736 subjects, the proposed method achieved a MSE of 71.596\nand a correlation of 0.151 in the validation set of 415 subjects. For the final\nsubmission, the model was trained with 3568 subjects and it achieved a MSE of\n94.0270 in the test set comprised of 4383 subjects.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 11:53:19 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Valverde", "Juan Miguel", ""], ["Imani", "Vandad", ""], ["Lewis", "John D.", ""], ["Tohka", "Jussi", ""]]}, {"id": "1909.05691", "submitter": "Alejandro Tabas", "authors": "Alejandro Tabas and Katharina von Kriegstein", "title": "Neural modelling of the encoding of fast frequency modulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Frequency modulation (FM) is a basic constituent of vocalisation in many\nanimals as well as in humans. In human speech, short rising and falling\nFM-sweeps called formant transitions characterise individual speech sounds.\nThere are two representations of FM in the ascending auditory pathway: a\nspectral representation, holding the instantaneous frequency of the stimuli;\nand a sweep representation, consisting of neurons that respond selectively to\nFM direction. To-date computational models use feedforward mechanisms to\nexplain FM encoding. However, from neuroanatomy we know that there are massive\nfeedback projections in the auditory pathway. Here, we found that a classical\nFM-sweep perceptual effect, the sweep pitch shift, cannot be explained by\nstandard feedforward processing models. We hypothesised that the sweep pitch\nshift is caused by a predictive interaction between the sweep and the spectral\nrepresentation. To test this hypothesis, we developed a novel model of FM\nencoding incorporating a predictive feedback mechanism. The model fully\naccounted for experimental data that we acquired in a perceptual experiment\nwith human participants as well as previously published experimental results.\nWe also designed a new family of stimuli for a second perceptual experiment to\nfurther validate the model. Combined, our results indicate that predictive\ninteraction between different frequency encoding and direction encoding neural\nrepresentations plays an important role in the neural processing of FM. In the\nbrain, this mechanism is likely to occur at early stages of the processing\nhierarchy.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 14:04:47 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 11:18:20 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Tabas", "Alejandro", ""], ["von Kriegstein", "Katharina", ""]]}, {"id": "1909.05764", "submitter": "Vadim Zotev", "authors": "Vadim Zotev, Ahmad Mayeli, Masaya Misaki, Jerzy Bodurka", "title": "Emotion self-regulation training in major depressive disorder using\n  simultaneous real-time fMRI and EEG neurofeedback", "comments": "20 figures, 6 tables, to appear in NeuroImage: Clinical", "journal-ref": "NeuroImage: Clinical 27 (2020) 102331", "doi": "10.1016/j.nicl.2020.102331", "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous real-time fMRI and EEG neurofeedback (rtfMRI-EEG-nf) is an\nemerging neuromodulation approach, that enables simultaneous volitional\nregulation of both hemodynamic (BOLD fMRI) and electrophysiological (EEG) brain\nactivities. Here we report the first application of rtfMRI-EEG-nf for emotion\nself-regulation training in patients with major depressive disorder (MDD). In\nthis proof-of-concept study, MDD patients in the experimental group (n=16) used\nrtfMRI-EEG-nf during a happy emotion induction task to simultaneously\nupregulate two fMRI and two EEG activity measures relevant to MDD. The target\nmeasures included BOLD activities of the left amygdala (LA) and left rostral\nanterior cingulate cortex (rACC), and frontal EEG asymmetries in the alpha band\n(FAA, [7.5-12.5] Hz) and high-beta band (FBA, [21-30] Hz). MDD patients in the\ncontrol group (n=8) were provided with sham feedback signals. An advanced\nprocedure for improved real-time EEG-fMRI artifact correction was implemented.\nThe experimental group participants demonstrated significant upregulation of\nthe LA BOLD activity, FAA, and FBA during the rtfMRI-EEG-nf task, as well as\nsignificant enhancement in fMRI connectivity between the LA and left rACC.\nAverage individual FAA changes during the rtfMRI-EEG-nf task positively\ncorrelated with depression and anhedonia severities, and negatively correlated\nwith after-vs-before changes in depressed mood ratings. Temporal correlations\nbetween the FAA and FBA time courses and the LA BOLD activity were\nsignificantly enhanced during the rtfMRI-EEG-nf task. The experimental group\nparticipants reported significant mood improvements after the training. Our\nresults suggest that the rtfMRI-EEG-nf may have potential for treatment of MDD.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 15:47:46 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2020 15:30:32 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Zotev", "Vadim", ""], ["Mayeli", "Ahmad", ""], ["Misaki", "Masaya", ""], ["Bodurka", "Jerzy", ""]]}, {"id": "1909.05908", "submitter": "Jahan Schad", "authors": "Jahan N. Schad", "title": "Neurological Nature of Vision and Thought and Mechanisms of Perception\n  Experiences", "comments": "3 pages", "journal-ref": "J Neurol Stroke. 2016, 4(5)", "doi": "10.15406/jnsk.2016.04.00152", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding of the phenomena of vision and thought require clarification of\nthe general mechanism of perception. So far, philosophical inquiries and\nscientific investigations have not been able to address clearly the mysteries\nsurrounding them. The present work is an attempt to unravel the essences of\nthese phenomenal based on the presumption of computational brain. Within this\ncontext, the natures of thought is clarified, and the basis of the experience\nof perception is established. And by drawing from the successes of the\ndeveloped tactile vision substitution systems (TVSS), which render some measure\nof vision,in vision handicapped persons, early or congenital blinds, the true\nnature of vision as cutaneous sensations is also divulged. The mechanism of\nperception involves sensing of the stimuli, and autonomous engagement of brain\nneuronal complexity resolution patterns; that is the brain implicit embedded\ncomputational instructions. Upon commencement of the triggers, brain\ncomputations, which aso involve engaging body's biophysical feedback system,\nare performed; and the results are outputted as motor signals that render the\nrealization of perception. However, this requires deployment of a perception\nmedium; an interface. Given the nature of efferent signals, there must be a\n(known) bio-mechanical system interface, other than the body muscle and\nskeletal system, which performs the needed function: Considering the fact that\nthe vocal system performs such task for verbalization of brain's synthesis of\nlanguage, the possibility of its further role in the experience of thought and\nvision, in the form of mostly quiet (inaudible) recital of the related motor\nsignals, is suggested.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:13:41 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Schad", "Jahan N.", ""]]}, {"id": "1909.05909", "submitter": "Jahan Schad", "authors": "Jahan N. Schad", "title": "Mental Stress: Source of Neurological Degeneration; Case of MS", "comments": null, "journal-ref": "J Neurol Stroke 2014, 1(4)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental stress is a vague though familiar concept that accounts for an agency\nof the good, the bad and the ugly, that operates in the brains of animated\nbeings, in response to environmental stressors. In this work, we provide\nevidence for correlation of stressors with afflictions of MS throughout the\nworld, and put forward arguments in support of the fact that stressors can\nrender disruptions in the normal computational processes of the brain, defining\nthe innards of the mental stress, which in turn may lead to the onset of\nphysiologic adversities in the biologic systems, possibly rendering various\ndiseases, even one as MS. While the real cause of the disease is still not\nknown, major focus is put on the treatment of MS symptoms, aiming to slow down\nits progress and to reduce the frequency of attacks. In this effort we\nestablish the link between MS and mental stress, through analyses of various\naspects of statistics of prevalence and incidence, available in the literature\n[3-5], which lends itself to opening up of additional treatment possibilities\nthat could be used separate of, or conjunctively with, the medical approaches.\nOn a grander scale, publicizing the adverse workings of the mental stress and\nits evils can attain statistical gains, in the incidence reduction.\n", "versions": [{"version": "v1", "created": "Mon, 9 Sep 2019 18:12:56 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Schad", "Jahan N.", ""]]}, {"id": "1909.05910", "submitter": "Jahan Schad", "authors": "Jahan N. Schad", "title": "Brain Neurological Constructs: The Neuronal Computational Schemes for\n  Resolution of Life's Complexities", "comments": "5 Pages", "journal-ref": "J Neurol Neurophysiol 2016, 7:1", "doi": "10.4172/2155-9562.1000356", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For complex life to evolve, a sophisticated nervous system for handling its\ncomplexities was fundamental. The demand resulted in the emergence of brain's\ncomputational facility, the neuronal network. This facet of the brain is\nattested solidly by its inspired scientific computational neural nets which\n(mathematically) resolve and solve many complex problems. The presumptive\ngeneral semblance of the computational operation between the two systems allows\nfor the inference that the process in brain's neural domain also renders\ncomplexities for solution, as sets of parametric equations, like the basic\nimplicit algorithmic formalisms underlying the operations of the scientific\nneural nets. This parallel is based on the fact that such devices resolve\ncomplex problems for which no declarative logical formulation is deployed. The\nmathematically resolved neural net problem formalism also resembled that of any\ntheoretically known and formulated complexities which are algorithmized, in\ntheir discretized solution domains, within the context of initial and boundary\nvalue problems for direct or iterative solution by computers. The brain\nneuronal net algorithmization of complexities delineate the governing equations\nof life and living, solutions of which are achieved by trial and error\nlearning, deploying rest of the nervous system and other faculties of living\nbeings. The computational operations of the brain delineate two mental states:\nconsciousness and the unconscious; the aware and unaware states which describes\nthe interactive living processes involved in charting life's path.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2019 18:58:24 GMT"}], "update_date": "2019-09-16", "authors_parsed": [["Schad", "Jahan N.", ""]]}, {"id": "1909.06161", "submitter": "Jonas Kubilius", "authors": "Jonas Kubilius, Martin Schrimpf, Kohitij Kar, Ha Hong, Najib J. Majaj,\n  Rishi Rajalingham, Elias B. Issa, Pouya Bashivan, Jonathan Prescott-Roy,\n  Kailyn Schmidt, Aran Nayebi, Daniel Bear, Daniel L. K. Yamins, and James J.\n  DiCarlo", "title": "Brain-Like Object Recognition with High-Performing Shallow Recurrent\n  ANNs", "comments": "NeurIPS 2019 (Oral). Code available at\n  https://github.com/dicarlolab/neurips2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional artificial neural networks (ANNs) are the leading class of\ncandidate models of the mechanisms of visual processing in the primate ventral\nstream. While initially inspired by brain anatomy, over the past years, these\nANNs have evolved from a simple eight-layer architecture in AlexNet to\nextremely deep and branching architectures, demonstrating increasingly better\nobject categorization performance, yet bringing into question how brain-like\nthey still are. In particular, typical deep models from the machine learning\ncommunity are often hard to map onto the brain's anatomy due to their vast\nnumber of layers and missing biologically-important connections, such as\nrecurrence. Here we demonstrate that better anatomical alignment to the brain\nand high performance on machine learning as well as neuroscience measures do\nnot have to be in contradiction. We developed CORnet-S, a shallow ANN with four\nanatomically mapped areas and recurrent connectivity, guided by Brain-Score, a\nnew large-scale composite of neural and behavioral benchmarks for quantifying\nthe functional fidelity of models of the primate ventral visual stream. Despite\nbeing significantly shallower than most models, CORnet-S is the top model on\nBrain-Score and outperforms similarly compact models on ImageNet. Moreover, our\nextensive analyses of CORnet-S circuitry variants reveal that recurrence is the\nmain predictive factor of both Brain-Score and ImageNet top-1 performance.\nFinally, we report that the temporal evolution of the CORnet-S \"IT\" neural\npopulation resembles the actual monkey IT population dynamics. Taken together,\nthese results establish CORnet-S, a compact, recurrent ANN, as the current best\nmodel of the primate ventral visual stream.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2019 12:09:34 GMT"}, {"version": "v2", "created": "Mon, 28 Oct 2019 07:30:42 GMT"}], "update_date": "2019-10-29", "authors_parsed": [["Kubilius", "Jonas", ""], ["Schrimpf", "Martin", ""], ["Kar", "Kohitij", ""], ["Hong", "Ha", ""], ["Majaj", "Najib J.", ""], ["Rajalingham", "Rishi", ""], ["Issa", "Elias B.", ""], ["Bashivan", "Pouya", ""], ["Prescott-Roy", "Jonathan", ""], ["Schmidt", "Kailyn", ""], ["Nayebi", "Aran", ""], ["Bear", "Daniel", ""], ["Yamins", "Daniel L. K.", ""], ["DiCarlo", "James J.", ""]]}, {"id": "1909.06683", "submitter": "Peter Taylor", "authors": "Sriharsha Ramaraju, Simon Reichert, Yujiang Wang, Rob Forsyth, Peter N\n  Taylor", "title": "Carbogen inhalation during Non-Convulsive Status Epilepticus: A\n  quantitative analysis of EEG recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective: To quantify the effect of inhaled 5% carbon-dioxide/95% oxygen on\nEEG recordings from patients in non-convulsive status epilepticus (NCSE).\nMethods: Five children of mixed aetiology in NCSE were given high flow of\ninhaled carbogen (5% carbon dioxide/95% oxygen) using a face mask for maximum\n120s. EEG was recorded concurrently in all patients. The effects of inhaled\ncarbogen on patient EEG recordings were investigated using band-power,\nfunctional connectivity and graph theory measures. Carbogen effect was\nquantified by measuring effect size (Cohen's d) between \"before\", \"during\" and\n\"after\" carbogen delivery states. Results: Carbogen's apparent effect on EEG\nband-power and network metrics across all patients for \"before-during\" and\n\"before-after\" inhalation comparisons was inconsistent across the five\npatients. Conclusion: The changes in different measures suggest a potentially\nnon-homogeneous effect of carbogen on the patients' EEG. Different aetiology\nand duration of the inhalation may underlie these non-homogeneous effects.\nTuning the carbogen parameters (such as ratio between CO2 and O2, duration of\ninhalation) on a personalised basis may improve seizure suppression in future.\n", "versions": [{"version": "v1", "created": "Sat, 14 Sep 2019 21:49:06 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Ramaraju", "Sriharsha", ""], ["Reichert", "Simon", ""], ["Wang", "Yujiang", ""], ["Forsyth", "Rob", ""], ["Taylor", "Peter N", ""]]}, {"id": "1909.06711", "submitter": "Joseph Monaco", "authors": "Joseph D. Monaco, Grace M. Hwang, Kevin M. Schultz, Kechen Zhang", "title": "Cognitive swarming in complex environments with attractor dynamics and\n  oscillatory computing", "comments": "16 pages, 7 figures", "journal-ref": "Biol Cybern 114, 269-284 (2020)", "doi": "10.1007/s00422-020-00823-z", "report-no": null, "categories": "cs.MA cs.NE cs.RO nlin.AO q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neurobiological theories of spatial cognition developed with respect to\nrecording data from relatively small and/or simplistic environments compared to\nanimals' natural habitats. It has been unclear how to extend theoretical models\nto large or complex spaces. Complementarily, in autonomous systems technology,\napplications have been growing for distributed control methods that scale to\nlarge numbers of low-footprint mobile platforms. Animals and many-robot groups\nmust solve common problems of navigating complex and uncertain environments.\nHere, we introduce the 'NeuroSwarms' control framework to investigate whether\nadaptive, autonomous swarm control of minimal artificial agents can be achieved\nby direct analogy to neural circuits of rodent spatial cognition. NeuroSwarms\nanalogizes agents to neurons and swarming groups to recurrent networks. We\nimplemented neuron-like agent interactions in which mutually visible agents\noperate as if they were reciprocally-connected place cells in an attractor\nnetwork. We attributed a phase state to agents to enable patterns of\noscillatory synchronization similar to hippocampal models of theta-rhythmic\n(5-12 Hz) sequence generation. We demonstrate that multi-agent swarming and\nreward-approach dynamics can be expressed as a mobile form of Hebbian learning\nand that NeuroSwarms supports a single-entity paradigm that directly informs\ntheoretical models of animal cognition. We present emergent behaviors including\nphase-organized rings and trajectory sequences that interact with environmental\ncues and geometry in large, fragmented mazes. Thus, NeuroSwarms is a model\nartificial spatial system that integrates autonomous control and theoretical\nneuroscience to potentially uncover common principles to advance both domains.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 02:02:22 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Monaco", "Joseph D.", ""], ["Hwang", "Grace M.", ""], ["Schultz", "Kevin M.", ""], ["Zhang", "Kechen", ""]]}, {"id": "1909.06813", "submitter": "Sakib Matin", "authors": "Sakib Matin, Thomas Tenzin, W. Klein", "title": "Scaling of causal neural avalanches in a neutral model", "comments": null, "journal-ref": "Phys. Rev. Research 3, 013107 (2021)", "doi": "10.1103/PhysRevResearch.3.013107", "report-no": null, "categories": "physics.bio-ph nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural avalanches are collective firings of neurons that exhibit emergent\nscale-free behavior. Understanding the nature and distribution of these\navalanches is an important element in understanding how the brain functions. We\nstudy a model of neural avalanches for which the dynamics are governed by\nneutral theory. The neural avalanches are defined using causal connections\nbetween the firing neurons. We analyze the scaling of causal neural avalanches\nas the critical point is approached from the absorbing phase. By using cluster\nanalysis tools from percolation theory, we characterize the critical properties\nof the neural avalanches. We identify the tuning parameters consistent with\nexperiments. The scaling hypothesis provides a unified explanation of the power\nlaws which characterize the critical point. The critical exponents\ncharacterizing the avalanche distributions and divergence of the response\nfunctions are consistent with the predictions of the scaling hypothesis. We use\na universal scaling function for the avalanche profile to find that the firing\nrates for avalanches of different durations show data collapse after\nappropriate rescaling. We also find data collapse for the avalanche\ndistribution functions, which is stronger evidence of criticality than just the\nexistence of power laws. Critical slowing-down and power law relaxation of\navalanches is observed as the system is tuned to its critical point. We discuss\nhow our results motivate future empirical studies of criticality in the brain.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 15:12:44 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 19:02:03 GMT"}, {"version": "v3", "created": "Sun, 14 Jun 2020 05:04:54 GMT"}, {"version": "v4", "created": "Mon, 2 Nov 2020 19:16:00 GMT"}, {"version": "v5", "created": "Fri, 15 Jan 2021 00:26:02 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Matin", "Sakib", ""], ["Tenzin", "Thomas", ""], ["Klein", "W.", ""]]}, {"id": "1909.06845", "submitter": "Diederik Aerts", "authors": "Diederik Aerts and Lester Beltran", "title": "Quantum Structure in Cognition: Human Language as a Boson Gas of\n  Entangled Words", "comments": "45 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We model a piece of text of human language telling a story by means of the\nquantum structure describing a Bose gas in a state close to a Bose-Einstein\ncondensate near absolute zero temperature. For this we introduce energy levels\nfor the words (concepts) used in the story and we also introduce the new notion\nof 'cogniton' as the quantum of human thought. Words (concepts) are then\ncognitons in different energy states as it is the case for photons in different\nenergy states, or states of different radiative frequency, when the considered\nboson gas is that of the quanta of the electromagnetic field. We show that\nBose-Einstein statistics delivers a very good model for these pieces of texts\ntelling stories, both for short stories and for long stories of the size of\nnovels. We analyze an unexpected connection with Zipf's law in human language,\nthe Zipf ranking relating to the energy levels of the words, and the\nBose-Einstein graph coinciding with the Zipf graph. We investigate the issue of\n'identity and indistinguishability' from this new perspective and conjecture\nthat the way one can easily understand how two of 'the same concepts' are\n'absolutely identical and indistinguishable' in human language is also the way\nin which quantum particles are absolutely identical and indistinguishable in\nphysical reality, providing in this way new evidence for our conceptuality\ninterpretation of quantum theory.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 17:40:57 GMT"}, {"version": "v2", "created": "Sat, 5 Oct 2019 17:15:59 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Aerts", "Diederik", ""], ["Beltran", "Lester", ""]]}, {"id": "1909.06904", "submitter": "Steve DiPaola", "authors": "Vanessa Utz and Steve DiPaola", "title": "Using an AI creativity system to explore how aesthetic experiences are\n  processed along the brains perceptual neural pathways", "comments": null, "journal-ref": "Cognitive Systems Research, 2019", "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased sophistication of AI techniques, the application of these\nsystems has been expanding to ever newer fields. Increasingly, these systems\nare being used in modeling of human aesthetics and creativity, e.g. how humans\ncreate artworks and design products. Our lab has developed one such AI\ncreativity deep learning system that can be used to create artworks in the form\nof images and videos. In this paper, we describe this system and its use in\nstudying the human visual system and the formation of aesthetic experiences.\nSpecifically, we show how time-based AI created media can be used to explore\nthe nature of the dual-pathway neuro-architecture of the human visual system\nand how this relates to higher cognitive judgments such as aesthetic\nexperiences that rely on these divergent information streams. We propose a\ntheoretical framework for how the movement within percepts such as video clips,\ncauses the engagement of reflexive attention and a subsequent focus on visual\ninformation that are primarily processed via the dorsal stream, thereby\nmodulating aesthetic experiences that rely on information relayed via the\nventral stream. We outline our recent study in support of our proposed\nframework, which serves as the first study that investigates the relationship\nbetween the two visual streams and aesthetic experiences.\n", "versions": [{"version": "v1", "created": "Sun, 15 Sep 2019 22:49:41 GMT"}], "update_date": "2019-09-17", "authors_parsed": [["Utz", "Vanessa", ""], ["DiPaola", "Steve", ""]]}, {"id": "1909.07186", "submitter": "Christopher Lynn", "authors": "Christopher W. Lynn and Danielle S. Bassett", "title": "How humans learn and represent networks", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph physics.app-ph physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans communicate, receive, and store information using sequences of items\n-- from words in a sentence or notes in music to abstract concepts in lectures\nand books. The networks formed by these items (nodes) and the sequential\ntransitions between them (edges) encode important structural features of human\ncommunication and knowledge. But how do humans learn the networks of\nprobabilistic transitions that underlie sequences of items? Moreover, what do\npeople's internal maps of these networks look like? Here, we introduce graph\nlearning, a growing and interdisciplinary field focused on studying how humans\nlearn and represent networks in the world around them. We begin by describing\nestablished results from statistical learning showing that humans are adept at\ndetecting differences in the transition probabilities between items in a\nsequence. We next present recent experiments that directly control for\ndifferences in transition probabilities, demonstrating that human behavior also\ndepends critically on the abstract network structure of transitions. Finally,\nwe present computational models that researchers have proposed to explain the\neffects of network structure on human behavior and cognition. Throughout, we\nhighlight a number of exciting open questions in the study of graph learning\nthat will require creative insights from cognitive scientists and network\nscientists alike.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 13:25:57 GMT"}, {"version": "v2", "created": "Wed, 25 Mar 2020 17:52:48 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Lynn", "Christopher W.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1909.07469", "submitter": "Tugba Suzek", "authors": "Abdulahad Bayraktar, Tugba Onal-Suzek, Baris Ethem Suzek, Omur Baysal", "title": "Meta-analysis of Gene Expression in Neurodegenerative Diseases Reveals\n  Patterns in GABA Synthesis and Heat Stress Pathways", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurodegenerative diseases are characterized as the progressive loss of\nneural cells, e.g. neurons, glial cells. Ageing, monogenic variations, viral\ninfections, and many other factors are determined and speculated as causes for\nthem. While many individual genes, such as APP for Alzheimer disease and HTT\nfor Huntington disease, and biological pathways are studied for\nneurodegenerative diseases, system-wide pathogenesis studies are limited. In\nthis study, we carried out a meta-analysis of RNA-Seq studies for three\nneurodegenerative diseases, namely Alzheimer's disease, Parkinson's disease and\nAmyotrophic Lateral Sclerosis (ALS) to minimize the batch effect derived\ndifferences and identify the similarly altered factors among studies. Our main\nassumption is that these three diseases share some pathological pathway\npattern. For this purpose, we downloaded publicly available Alzheimer's disease\n(84 patients + 33 controls = 117 individuals), Parkinson's disease (28 patients\n+ 43 controls = 71 individuals) and ALS (2 studies: 46 patients + 25 control =\n71 individuals) RNA-Seq data from Sequence Read Archive (SRA) database. The\nsignificantly differentially expressed genes common to these studies were first\nidentified and analyzed for the patterns in their pathways and variations. Our\nmeta-analysis revealed the shared nature of differential gene expression and\nmutation load of the cellular heat stress response and GABA synthesis in\nneurodegenerative diseases. The downregulated GABA synthesis-related genes\n(e.g. GAD1 and GAD2) and the upregulated cellular heat stress response-related\ngenes (e.g. DNAJB6 and HSP90AA1), in addition to their expression patterns,\ncontain unique variations in samples from patients with neurodegenerative\ndiseases. The significance of genes and pathways we identified in this study\ncorroborated by the recent literature on neurodegenerative diseases.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2019 20:31:38 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Bayraktar", "Abdulahad", ""], ["Onal-Suzek", "Tugba", ""], ["Suzek", "Baris Ethem", ""], ["Baysal", "Omur", ""]]}, {"id": "1909.07536", "submitter": "Yuri A. Dabaghian", "authors": "Yuri Dabaghian", "title": "From topological analyses to functional modeling: the case of\n  hippocampus", "comments": "21 page, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological data analyses are rapidly turning into key tools for quantifying\nlarge volumes of neurobiological data, e.g., for organizing the spiking outputs\nof large neuronal ensembles and thus gaining insights into the information\nproduced by various networks. Below we discuss a case in which several\nconvergent topological analyses not only provide a description of the data\nstructure, but also produce insights into how these data may be processed in\nthe hippocampus---a brain part that plays a key role in learning and memory.\nThe resulting functional model provides a unifying framework for integrating\nspiking information at different timescales and understanding the course of\nspatial learning at different levels of spatiotemporal granularity. In\nparticular, the model allows quantifying contributions of various physiological\nphenomena---brain waves, synaptic strengths, synaptic architectures, etc., into\nspatial cognition.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 00:59:02 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Dabaghian", "Yuri", ""]]}, {"id": "1909.07540", "submitter": "Yuri A. Dabaghian", "authors": "Yuri Dabaghian", "title": "Topological stability of the hippocampal spatial map and synaptic\n  transience", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial awareness in mammals is based on internalized representations of the\nenvironment---cognitive maps---encoded by networks of spiking neurons. Although\nbehavioral studies suggest that these maps can remain stable for long periods,\nit is also well-known that the underlying networks of synaptic connections\nconstantly change their architecture due to various forms of neuronal\nplasticity. This raises a principal question: how can a dynamic network encode\na stable map of space? In the following, we discuss some recent results\nobtained in this direction using an algebro-topological modeling approach,\nwhich demonstrate that emergence of stable cognitive maps produced by networks\nwith transient architectures is not only possible, but may be a generic\nphenomenon.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 01:17:22 GMT"}], "update_date": "2019-09-18", "authors_parsed": [["Dabaghian", "Yuri", ""]]}, {"id": "1909.07932", "submitter": "Peter Taylor", "authors": "Yujiang Wang, Nishant Sinha, Gabrielle M. Schroeder, Sriharsha\n  Ramaraju, Andrew W. McEvoy, Anna Miserocchi, Jane de Tisi, Fahmida A.\n  Chowdhury, Beate Diehl, John S. Duncan, Peter N. Taylor", "title": "Interictal intracranial EEG for predicting surgical success: the\n  importance of space and time", "comments": null, "journal-ref": "Epilepsia 61 (2020) 1417-1426", "doi": "10.1111/epi.16580", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Predicting post-operative seizure freedom using functional correlation\nnetworks derived from interictal intracranial EEG has shown some success.\nHowever, there are important challenges to consider. 1: electrodes physically\ncloser to each other naturally tend to be more correlated causing a spatial\nbias. 2: implantation location and number of electrodes differ between\npatients, making cross-subject comparisons difficult. 3: functional correlation\nnetworks can vary over time but are currently assumed as static. In this study\nwe address these three substantial challenges using intracranial EEG data from\n55 patients with intractable focal epilepsy. Patients additionally underwent\npreoperative MR imaging, intra-operative CT, and post-operative MRI allowing\naccurate localisation of electrodes and delineation of removed tissue. We show\nthat normalising for spatial proximity between nearby electrodes improves\nprediction of post-surgery seizure outcomes. Moreover, patients with more\nextensive electrode coverage were more likely to have their outcome predicted\ncorrectly (ROC-AUC >0.9, p<<0.05), but not necessarily more likely to have a\nbetter outcome. Finally, our predictions are robust regardless of the time\nsegment. Future studies should account for the spatial proximity of electrodes\nin functional network construction to improve prediction of post-surgical\nseizure outcomes. Greater coverage of both removed and spared tissue allows for\npredictions with higher accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 17:00:18 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Wang", "Yujiang", ""], ["Sinha", "Nishant", ""], ["Schroeder", "Gabrielle M.", ""], ["Ramaraju", "Sriharsha", ""], ["McEvoy", "Andrew W.", ""], ["Miserocchi", "Anna", ""], ["de Tisi", "Jane", ""], ["Chowdhury", "Fahmida A.", ""], ["Diehl", "Beate", ""], ["Duncan", "John S.", ""], ["Taylor", "Peter N.", ""]]}, {"id": "1909.08018", "submitter": "Zihan Pan", "authors": "Zihan Pan, Jibin Wu, Yansong Chua, Malu Zhang, and Haizhou Li", "title": "Neural Population Coding for Effective Temporal Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural encoding plays an important role in faithfully describing the\ntemporally rich patterns, whose instances include human speech and\nenvironmental sounds. For tasks that involve classifying such spatio-temporal\npatterns with the Spiking Neural Networks (SNNs), how these patterns are\nencoded directly influence the difficulty of the task. In this paper, we\ncompare several existing temporal and population coding schemes and evaluate\nthem on both speech (TIDIGITS) and sound (RWCP) datasets. We show that, with\npopulation neural codings, the encoded patterns are linearly separable using\nthe Support Vector Machine (SVM). We note that the population neural codings\neffectively project the temporal information onto the spatial domain, thus\nimproving linear separability in the spatial dimension, achieving an accuracy\nof 95\\% and 100\\% for TIDIGITS and RWCP datasets classified using the SVM,\nrespectively. This observation suggests that an effective neural coding scheme\ngreatly simplifies the classification problem such that a simple linear\nclassifier would suffice. The above datasets are then classified using the\nTempotron, an SNN-based classifier. SNN classification results agree with the\nSVM findings that population neural codings help to improve classification\naccuracy. Hence, other than the learning algorithm, effective neural encoding\nis just as important as an SNN designed to recognize spatio-temporal patterns.\nIt is an often neglected but powerful abstraction that deserves further study.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2019 08:46:50 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 03:26:20 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Pan", "Zihan", ""], ["Wu", "Jibin", ""], ["Chua", "Yansong", ""], ["Zhang", "Malu", ""], ["Li", "Haizhou", ""]]}, {"id": "1909.08071", "submitter": "Ai Wern Chung", "authors": "Ai Wern Chung, Rebekah Mannix, Henry A. Feldman, P. Ellen Grant, Kiho\n  Im", "title": "Longitudinal structural connectomic and rich-club analysis in adolescent\n  mTBI reveals persistent, distributed brain alterations acutely through to one\n  year post-injury", "comments": "22 pages, 4 figures, 1 table. Preprint manuscript", "journal-ref": "Sci Rep 9, 18833 (2019)", "doi": "10.1038/s41598-019-54950-0", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The diffused nature of mild traumatic brain injury (mTBI) impacts brain\nwhite-matter pathways with potentially long-term consequences, even after\ninitial symptoms have resolved. To understand post-mTBI recovery in\nadolescents, longitudinal studies are needed to determine the interplay between\nhighly individualised recovery trajectories and ongoing development. To capture\nthe distributed nature of mTBI and recovery, we employ connectomes to probe the\nbrain's structural organisation. We present a diffusion MRI study on adolescent\nmTBI subjects scanned one day, two weeks and one year after injury with\ncontrols. Longitudinal global network changes over time suggests an altered and\nmore 'diffuse' network topology post-injury (specifically lower transitivity\nand global efficiency). Stratifying the connectome by its back-bone, known as\nthe 'rich-club', these network changes were driven by the 'peripheral' local\nsubnetwork by way of increased network density, fractional anisotropy and\ndecreased diffusivities. This increased structural integrity of the local\nsubnetwork may be to compensate for an injured network, or it may be robust to\nmTBI and is exhibiting a normal developmental trend. The rich-club also\nrevealed lower diffusivities over time with controls, potentially indicative of\nlonger-term structural ramifications. Our results show evolving, diffuse\nalterations in adolescent mTBI connectomes beginning acutely and continuing to\none year.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 20:06:40 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Chung", "Ai Wern", ""], ["Mannix", "Rebekah", ""], ["Feldman", "Henry A.", ""], ["Grant", "P. Ellen", ""], ["Im", "Kiho", ""]]}, {"id": "1909.08158", "submitter": "Takahiro Homma", "authors": "Takahiro Homma", "title": "Generation mechanism of cell assembly to store information about hand\n  recognition", "comments": null, "journal-ref": "Heliyon Volume 6, Issue 11, November 2020, e05347", "doi": "10.1016/j.heliyon.2020.e05347", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A specific memory is stored in a cell assembly that is activated during fear\nlearning in mice; however, research regarding cell assemblies associated with\nprocedural and habit learning processes is lacking. In modeling studies,\nsimulations of the learning process for hand regard, which is a type of\nprocedural learning, resulted in the formation of cell assemblies. However, the\nmechanisms through which the cell assemblies form and the information stored in\nthese cell assemblies remain unknown. In this paper, the relationship between\nhand movements and weight changes during the simulated learning process for\nhand regard was used to elucidate the mechanism through which inhibitory\nweights are generated, which plays an important role in the formation of cell\nassemblies. During the early training phase, trial and error attempts to bring\nthe hand into the field of view caused the generation of inhibitory weights,\nand the cell assemblies self-organized from these inhibitory weights. The\ninformation stored in the cell assemblies was estimated by examining the\ncontributions of the cell assemblies outputs to hand movements. During\nsustained hand regard, the outputs from these cell assemblies moved the hand\ninto the field of view, using hand-related inputs almost exclusively.\nTherefore, infants are likely able to select the inputs associated with their\nhand (that is, distinguish between their hand and others), based on the\ninformation stored in the cell assembly, and move their hands into the field of\nview during sustained hand regard.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 01:19:55 GMT"}, {"version": "v2", "created": "Thu, 16 Apr 2020 08:07:12 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Homma", "Takahiro", ""]]}, {"id": "1909.08341", "submitter": "Zhi-Hua Zhou", "authors": "Shao-Qun Zhang and Zhao-Yu Zhang and Zhi-Hua Zhou", "title": "Bifurcation Spiking Neural Network", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNNs) has attracted much attention due to its great\npotential of modeling time-dependent signals. The firing rate of spiking\nneurons is decided by control rate which is fixed manually in advance, and\nthus, whether the firing rate is adequate for modeling actual time series\nrelies on fortune. Though it is demanded to have an adaptive control rate, it\nis a non-trivial task because the control rate and the connection weights\nlearned during the training process are usually entangled. In this paper, we\nshow that the firing rate is related to the eigenvalue of the spike generation\nfunction. Inspired by this insight, by enabling the spike generation function\nto have adaptable eigenvalues rather than parametric control rates, we develop\nthe Bifurcation Spiking Neural Network (BSNN), which has an adaptive firing\nrate and is insensitive to the setting of control rates. Experiments validate\nthe effectiveness of BSNN on a broad range of tasks, showing that BSNN achieves\nsuperior performance to existing SNNs and is robust to the setting of control\nrates.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 10:34:59 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2020 09:06:18 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 14:13:12 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Zhang", "Shao-Qun", ""], ["Zhang", "Zhao-Yu", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1909.08466", "submitter": "Danielle J. Harper", "authors": "Danielle J. Harper, Marco Augustin, Antonia Lichtenegger, Johanna\n  Gesperger, Tanja Himmel, Martina Muck, Conrad W. Merkle, Pablo Eugui, Stefan\n  Kummer, Adelheid Woehrer, Martin Gl\\\"osmann, Bernhard Baumann", "title": "Retinal analysis of a mouse model of Alzheimer's disease with\n  multi-contrast optical coherence tomography", "comments": null, "journal-ref": "Neurophotonics 7.1 (2020): 015006", "doi": "10.1117/1.NPh.7.1.015006", "report-no": null, "categories": "physics.med-ph q-bio.NC q-bio.TO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent Alzheimer's disease (AD) patient studies have focused on retinal\nanalysis, as the retina is the only part of the central nervous system which\ncan be imaged non-invasively by optical methods. However as this is a\nrelatively new approach, the occurrence and role of pathological features such\nas retinal layer thinning, extracellular amyloid beta (A$\\beta$) accumulation\nand vascular changes is still debated. Animal models of AD are therefore often\nused in attempts to understand the disease. In this work, both eyes of 24\nAPP/PS1 transgenic mice (age: 45-104 weeks) and 15 age-matched wildtype\nlittermates were imaged by a custom-built multi-contrast optical coherence\ntomography (OCT) system. The system provided a combination of standard\nreflectivity data, polarization-sensitive data and OCT angiograms. This\ntri-fold contrast provided qualitative and quantitative information on retinal\nlayer thickness and structure, presence of hyper-reflective foci, phase\nretardation abnormalities and retinal vasculature. While abnormal structural\nproperties and phase retardation signals were observed in the retinas, the\nobservations were very similar in transgenic and control mice. At the end of\nthe experiment, retinas and brains were harvested from a subset of the mice (14\ntransgenic, 7 age-matched control) in order to compare the in vivo results to\nhistological analysis, and to quantify the cortical A$\\beta$ plaque load.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 14:17:51 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 16:54:26 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Harper", "Danielle J.", ""], ["Augustin", "Marco", ""], ["Lichtenegger", "Antonia", ""], ["Gesperger", "Johanna", ""], ["Himmel", "Tanja", ""], ["Muck", "Martina", ""], ["Merkle", "Conrad W.", ""], ["Eugui", "Pablo", ""], ["Kummer", "Stefan", ""], ["Woehrer", "Adelheid", ""], ["Gl\u00f6smann", "Martin", ""], ["Baumann", "Bernhard", ""]]}, {"id": "1909.08509", "submitter": "Erik Fagerholm", "authors": "Erik D. Fagerholm, Rosalyn J. Moran, Ines R. Violante, Robert Leech,\n  Karl J. Friston", "title": "Dynamic causal modelling of phase-amplitude interactions", "comments": "arXiv admin note: text overlap with arXiv:1812.06315", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models of coupled oscillators are used to describe a wide variety of\nphenomena in neuroimaging. These models typically rest on the premise that\noscillator dynamics do not evolve beyond their respective limit cycles, and\nhence that interactions can be described purely in terms of phase differences.\nWhilst mathematically convenient, the restrictive nature of phase-only models\ncan limit their explanatory power. We therefore propose a generalisation of\ndynamic causal modelling that incorporates both phase and amplitude. This\nallows for the separate quantifications of phase and amplitude contributions to\nthe connectivity between neural regions. We establish, using model-generated\ndata and simulations of coupled pendula, that phase-only models perform well\nonly under weak coupling conditions. We also show that, despite their higher\ncomplexity, phase-amplitude models can describe strongly coupled systems more\neffectively than their phase-only counterparts. We relate our findings to four\nmetrics commonly used in neuroimaging: the Kuramoto order parameter,\ncross-correlation, phase-lag index, and spectral entropy. We find that, with\nthe exception of spectral entropy, the phase-amplitude model is able to capture\nall metrics more effectively than the phase-only model. We then demonstrate,\nusing local field potential recordings in rodents and functional magnetic\nresonance imaging in macaque monkeys, that amplitudes in oscillator models play\nan important role in describing neural dynamics in anaesthetised brain states.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2019 14:28:42 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Fagerholm", "Erik D.", ""], ["Moran", "Rosalyn J.", ""], ["Violante", "Ines R.", ""], ["Leech", "Robert", ""], ["Friston", "Karl J.", ""]]}, {"id": "1909.08553", "submitter": "Asohan Amarasingham", "authors": "Jonathan Platkiewicz, Zachary Saccomano, Sam McKenzie, Daniel English\n  and Asohan Amarasingham", "title": "Monosynaptic inference via finely-timed spikes", "comments": "45 pages, 11 figures", "journal-ref": "J Comput Neurosci (2021)", "doi": "10.1007/s10827-020-00770-5", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observations of finely-timed spike relationships in population recordings\nhave been used to support partial reconstruction of neural microcircuit\ndiagrams. In this approach, fine-timescale components of paired spike train\ninteractions are isolated and subsequently attributed to synaptic parameters.\nRecent perturbation studies strengthen the case for such an inference, yet the\ncomplete set of measurements needed to calibrate statistical models are\nunavailable. To address this gap, we study features of pairwise spiking in a\nlarge-scale in vivo dataset where presynaptic neurons were explicitly decoupled\nfrom network activity by juxtacellular stimulation. We then construct\nbiophysical models of paired spike trains to reproduce the observed\nphenomenology of in vivo monosynaptic interactions, including both\nfine-timescale spike-spike correlations and firing irregularity. A key\ncharacteristic of these models is that the paired neurons are coupled by\nrapidly-fluctuating background inputs. We quantify a monosynapse's causal\neffect by comparing the postsynaptic train with its counterfactual, when the\nmonosynapse is removed. Subsequently, we develop statistical techniques for\nestimating this causal effect from the pre- and post-synaptic spike trains. A\nparticular focus is the justification and application of a nonparametric\nseparation of timescale principle to implement synaptic inference. Using\nsimulated data generated from the biophysical models, we characterize the\nregimes in which the estimators accurately identify the monosynaptic effect. A\nsecondary goal is to initiate a critical exploration of neurostatistical\nassumptions in terms of biophysical mechanisms, particularly with regards to\nthe challenging but arguably fundamental issue of fast, unobservable\nnonstationarities in background dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 16:22:38 GMT"}, {"version": "v2", "created": "Sat, 5 Sep 2020 23:55:40 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Platkiewicz", "Jonathan", ""], ["Saccomano", "Zachary", ""], ["McKenzie", "Sam", ""], ["English", "Daniel", ""], ["Amarasingham", "Asohan", ""]]}, {"id": "1909.08601", "submitter": "Quanying Liu", "authors": "Yorie Nakahira, Quanying Liu, Terrence J. Sejnowski, John C. Doyle", "title": "Diversity-enabled sweet spots in layered architectures and\n  speed-accuracy trade-offs in sensorimotor control", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.IT cs.SY eess.SY math.IT q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Nervous systems sense, communicate, compute and actuate movement using\ndistributed components with severe trade-offs in speed, accuracy, sparsity,\nnoise and saturation. Nevertheless, brains achieve remarkably fast, accurate,\nand robust control performance due to a highly effective layered control\narchitecture. Here we introduce a driving task to study how a mountain biker\nmitigates the immediate disturbance of trail bumps and responds to changes in\ntrail direction. We manipulated the time delays and accuracy of the control\ninput from the wheel as a surrogate for manipulating the characteristics of\nneurons in the control loop. The observed speed-accuracy trade-offs (SATs)\nmotivated a theoretical framework consisting of layers of control loops with\ncomponents having diverse speeds and accuracies within each physical level,\nsuch as nerve bundles containing axons with a wide range of sizes. Our model\nexplains why the errors from two control loops -- one fast but inaccurate\nreflexive layer that corrects for bumps, and a planning layer that is slow but\naccurate -- are additive, and show how the errors in each control loop can be\ndecomposed into the errors caused by the limited speeds and accuracies of the\ncomponents. These results demonstrate that an appropriate diversity in the\nproperties of neurons across layers helps to create \"diversity-enabled sweet\nspots\" (DESSs) so that both fast and accurate control is achieved using slow or\ninaccurate components.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 17:44:57 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 08:33:46 GMT"}, {"version": "v3", "created": "Sun, 2 May 2021 17:25:48 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Nakahira", "Yorie", ""], ["Liu", "Quanying", ""], ["Sejnowski", "Terrence J.", ""], ["Doyle", "John C.", ""]]}, {"id": "1909.08665", "submitter": "Oliver Rhodes Dr", "authors": "Oliver Rhodes, Luca Peres, Andrew G. D. Rowley, Andrew Gait, Luis A.\n  Plana, Christian Brenninkmeijer, and Steve B. Furber", "title": "Real-Time Cortical Simulation on Neuromorphic Hardware", "comments": "Paper submitted to Royal Society Philosophical Transactions A", "journal-ref": null, "doi": "10.1098/rsta.2019.0160", "report-no": null, "categories": "cs.ET q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time simulation of a large-scale biologically representative spiking\nneural network is presented, through the use of a heterogeneous parallelisation\nscheme and SpiNNaker neuromorphic hardware. A published cortical microcircuit\nmodel is used as a benchmark test case, representing approx. 1 square mm of\nearly sensory cortex, containing 77k neurons and 0.3 billion synapses. This is\nthe first true real-time simulation of this model, with 10 s of biological\nsimulation time executed in 10 s wall-clock time. This surpasses best published\nefforts on HPC neural simulators (3x slowdown) and GPUs running optimised SNN\nlibraries (2x slowdown). Furthermore, the presented approach indicates that\nreal-time processing can be maintained with increasing SNN size, breaking the\ncommunication barrier incurred by traditional computing machinery. Model\nresults are compared to an established HPC simulator baseline to verify\nsimulation correctness, comparing well across a range of statistical measures.\nEnergy to solution, and energy per synaptic event are also reported,\ndemonstrating that the relatively low-tech SpiNNaker processors achieve a 10x\nreduction in energy relative to modern HPC systems, and comparable energy\nconsumption to modern GPUs. Finally, system robustness is demonstrated through\nmultiple 12 h simulations of the cortical microcircuit, each simulating 12 h of\nbiological time, and demonstrating the potential of neuromorphic hardware as a\nneuroscience research tool for studying complex spiking neural networks over\nextended time periods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Sep 2019 19:17:00 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Rhodes", "Oliver", ""], ["Peres", "Luca", ""], ["Rowley", "Andrew G. D.", ""], ["Gait", "Andrew", ""], ["Plana", "Luis A.", ""], ["Brenninkmeijer", "Christian", ""], ["Furber", "Steve B.", ""]]}, {"id": "1909.09004", "submitter": "Kaitlyn Phillipson", "authors": "Sarah Ayman Goldrup and Kaitlyn Phillipson", "title": "Classification of Open and Closed Convex Codes on Five Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural codes, represented as collections of binary strings, encode neural\nactivity and show relationships among stimuli. Certain neurons, called place\ncells, have been shown experimentally to fire in convex regions in space. A\nnatural question to ask is: Which neural codes can arise as intersection\npatterns of convex sets? While past research has established several criteria,\ncomplete conditions for convexity are not yet known for codes with more than\nfour neurons. We classify all neural codes with five neurons as\nconvex/non-convex codes. Furthermore, we investigate which of these codes can\nbe represented by open versus closed convex sets. Interestingly, we find a code\nwhich is an open but not closed convex code and demonstrate a minimal example\nfor this phenomenon.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2019 14:02:38 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Goldrup", "Sarah Ayman", ""], ["Phillipson", "Kaitlyn", ""]]}, {"id": "1909.09847", "submitter": "Hyodong Lee", "authors": "Hyodong Lee, James J. DiCarlo", "title": "Topographic Deep Artificial Neural Networks (TDANNs) predict face\n  selectivity topography in primate inferior temporal (IT) cortex", "comments": "2018 Conference on Cognitive Computational Neuroscience", "journal-ref": null, "doi": "10.32470/CCN.2018.1085-0", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks are biologically driven models that\nresemble the hierarchical structure of primate visual cortex and are the\ncurrent best predictors of the neural responses measured along the ventral\nstream. However, the networks lack topographic properties that are present in\nthe visual cortex, such as orientation maps in primary visual cortex and\ncategory-selective maps in inferior temporal (IT) cortex. In this work, the\nminimum wiring cost constraint was approximated as an additional learning rule\nin order to generate topographic maps of the networks. We found that our\ntopographic deep artificial neural networks (ANNs) can reproduce the category\nselectivity maps of the primate IT cortex.\n", "versions": [{"version": "v1", "created": "Sat, 21 Sep 2019 15:53:24 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Lee", "Hyodong", ""], ["DiCarlo", "James J.", ""]]}, {"id": "1909.10007", "submitter": "Tilo Schwalger", "authors": "Tilo Schwalger and Anton V. Chizhov", "title": "Mind the Last Spike -- Firing Rate Models for Mesoscopic Populations of\n  Spiking Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant modeling framework for understanding cortical computations are\nheuristic firing rate models. Despite their success, these models fall short to\ncapture spike synchronization effects, to link to biophysical parameters and to\ndescribe finite-size fluctuations. In this opinion article, we propose that the\nrefractory density method (RDM), also known as age-structured population\ndynamics or quasi-renewal theory, yields a powerful theoretical framework to\nbuild rate-based models for mesoscopic neural populations from realistic neuron\ndynamics at the microscopic level. We review recent advances achieved by the\nRDM to obtain efficient population density equations for networks of\ngeneralized integrate-and-fire (GIF) neurons -- a class of neuron models that\nhas been successfully fitted to various cell types. The theory not only\npredicts the nonstationary dynamics of large populations of neurons but also\npermits an extension to finite-size populations and a systematic reduction to\nlow-dimensional rate dynamics. The new types of rate models will allow a\nre-examination of models of cortical computations under biological constraints.\n", "versions": [{"version": "v1", "created": "Sun, 22 Sep 2019 13:57:44 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Schwalger", "Tilo", ""], ["Chizhov", "Anton V.", ""]]}, {"id": "1909.10116", "submitter": "Audrey Sederberg", "authors": "Audrey J. Sederberg, Ilya Nemenman", "title": "Randomly connected networks generate emergent selectivity and predict\n  decoding properties of large populations of neurons", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1007875", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in neural recording methods enable sampling from populations of\nthousands of neurons during the performance of behavioral tasks, raising the\nquestion of how recorded activity relates to the theoretical models of\ncomputations underlying performance. In the context of decision making in\nrodents, patterns of functional connectivity between choice-selective cortical\nneurons, as well as broadly distributed choice information in both excitatory\nand inhibitory populations, were recently reported [1]. The straightforward\ninterpretation of these data suggests a mechanism relying on specific patterns\nof anatomical connectivity to achieve selective pools of inhibitory as well as\nexcitatory neurons. We investigate an alternative mechanism for the emergence\nof these experimental observations using a computational approach. We find that\na randomly connected network of excitatory and inhibitory neurons generates\nsingle-cell selectivity, patterns of pairwise correlations, and\nindistinguishable excitatory and inhibitory readout weight distributions, as\nobserved in recorded neural populations. Further, we make the readily\nverifiable experimental predictions that, for this type of evidence\naccumulation task, there are no anatomically defined sub-populations of neurons\nrepresenting choice, and that choice preference of a particular neuron changes\nwith the details of the task. This work suggests that distributed stimulus\nselectivity and patterns of functional organization in population codes could\nbe emergent properties of randomly connected networks.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 01:26:02 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Sederberg", "Audrey J.", ""], ["Nemenman", "Ilya", ""]]}, {"id": "1909.10340", "submitter": "Gideon Kowadlo", "authors": "Gideon Kowadlo, Abdelrahman Ahmed, and David Rawlinson", "title": "AHA! an 'Artificial Hippocampal Algorithm' for Episodic Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of ML research concerns slow, statistical learning of i.i.d.\nsamples from large, labelled datasets. Animals do not learn this way. An\nenviable characteristic of animal learning is `episodic' learning - the ability\nto memorise a specific experience as a composition of existing concepts, after\njust one experience, without provided labels. The new knowledge can then be\nused to distinguish between similar experiences, to generalise between classes,\nand to selectively consolidate to long-term memory. The Hippocampus is known to\nbe vital to these abilities. AHA is a biologically-plausible computational\nmodel of the Hippocampus. Unlike most machine learning models, AHA is trained\nwithout external labels and uses only local credit assignment. We demonstrate\nAHA in a superset of the Omniglot one-shot classification benchmark. The\nextended benchmark covers a wider range of known hippocampal functions by\ntesting pattern separation, completion, and recall of original input. These\nfunctions are all performed within a single configuration of the computational\nmodel. Despite these constraints, image classification results are comparable\nto conventional deep convolutional ANNs.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 12:49:47 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 15:47:27 GMT"}, {"version": "v3", "created": "Fri, 1 Nov 2019 06:00:38 GMT"}, {"version": "v4", "created": "Fri, 8 Nov 2019 01:56:18 GMT"}, {"version": "v5", "created": "Wed, 25 Mar 2020 04:08:34 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Kowadlo", "Gideon", ""], ["Ahmed", "Abdelrahman", ""], ["Rawlinson", "David", ""]]}, {"id": "1909.10831", "submitter": "Romuald A. Janik", "authors": "Romuald A. Janik", "title": "Entropy from Machine Learning", "comments": "10 pages, 2 figures; v2: reference added, minor notational\n  improvement; v3: reference added, general comments in section 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.LG hep-lat q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We translate the problem of calculating the entropy of a set of binary\nconfigurations/signals into a sequence of supervised classification tasks.\nSubsequently, one can use virtually any machine learning classification\nalgorithm for computing entropy. This procedure can be used to compute entropy,\nand consequently the free energy directly from a set of Monte Carlo\nconfigurations at a given temperature. As a test of the proposed method, using\nan off-the-shelf machine learning classifier we reproduce the entropy and free\nenergy of the 2D Ising model from Monte Carlo configurations at various\ntemperatures throughout its phase diagram. Other potential applications include\ncomputing the entropy of spiking neurons or any other multidimensional binary\nsignals.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 12:12:42 GMT"}, {"version": "v2", "created": "Mon, 7 Oct 2019 13:13:32 GMT"}, {"version": "v3", "created": "Thu, 24 Oct 2019 08:44:48 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["Janik", "Romuald A.", ""]]}, {"id": "1909.10965", "submitter": "Farzad Farkhooi", "authors": "Carl van Vreeswijk and Farzad Farkhooi", "title": "Fredholm theory for the mean first-passage time of integrate-and-fire\n  oscillators with colored noise input", "comments": "5 pages, 4 figures", "journal-ref": "Phys. Rev. E 100, 060402 (2019)", "doi": "10.1103/PhysRevE.100.060402", "report-no": null, "categories": "physics.bio-ph cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method to investigate the effect of noise timescales on the\nfirst-passage time of nonlinear oscillators. Using Fredholm theory, we derive\nan exact integral equation for the mean event rate of a\nleaky-integrate-and-fire oscillator that receives constant input and temporally\ncorrelated noise. Furthermore, we show that Fredholm theory provides a unified\nframework to determine system scaling behavior for small and large noise\ntimescales. In this framework, the leading order and higher-order asymptotic\ncorrections for slow and fast noise are naturally emerging. We show the scaling\nbehavior in the both limits are not reciprocal. We discuss further how this\napproach can be extended to study the first-passage time in a general class of\nnonlinear oscillators driven by colored noise at arbitrary timescales.\n", "versions": [{"version": "v1", "created": "Tue, 24 Sep 2019 14:47:38 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 12:32:39 GMT"}, {"version": "v3", "created": "Tue, 17 Dec 2019 19:57:33 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["van Vreeswijk", "Carl", ""], ["Farkhooi", "Farzad", ""]]}, {"id": "1909.11269", "submitter": "Sibaek Seong", "authors": "Si-Baek Seong and Hae-Jeong Park", "title": "Automated identification of neural cells in the multi-photon images\n  using deep-neural networks", "comments": "8 pages, 4 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG cs.SY eess.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advancement of the neuroscientific imaging techniques has produced an\nunprecedented size of neural cell imaging data, which calls for automated\nprocessing. In particular, identification of cells from two photon images\ndemands segmentation of neural cells out of various materials and\nclassification of the segmented cells according to their cell types. To\nautomatically segment neural cells, we used U-Net model, followed by\nclassification of excitatory and inhibitory neurons and glia cells using a\ntransfer learning technique. For transfer learning, we tested three public\nmodels of resnet18, resnet50 and inceptionv3, after replacing the fully\nconnected layer with that for three classes. The best classification\nperformance was found for the model with inceptionv3. The proposed application\nof deep learning technique is expected to provide a critical way to cell\nidentification in the era of big neuroscience data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 03:30:50 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Seong", "Si-Baek", ""], ["Park", "Hae-Jeong", ""]]}, {"id": "1909.11447", "submitter": "Aina Oll\\'e Vila", "authors": "Aina Oll\\'e-Vila, Lu\\'is F. Seoane, Ricard Sol\\'e", "title": "Aging, computation, and the evolution of neural regeneration processes", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metazoans are capable of gathering information from their environments and\nrespond in predictable ways. These computational tasks are achieved by means of\nmore or less complex networks of neurons. Task performance must be reliable\nover an individual's lifetime and must deal robustly with the finite lifespan\nof cells or with connection failure - rendering aging a relevant feature in\nthis context. How do computations degrade over an organism's lifespan? How\nreliable can computations remain throughout? In order to answer these\nquestions, here we approach the problem under a multiobjective (Pareto)\noptimization approach. We consider a population of digital organisms equipped\nwith a neural network that must solve a given computational task reliably. We\ndemand that they remain functional (as reliable as possible) for an extended\nlifespan. Neural connections are costly (as an associated metabolism in living\nbeings) and degrade over time. They can also be regenerated at some expense. We\ninvestigate the simultaneous minimization of the metabolic burden (due to\nconnections and regeneration costs) and the computational error and the\ntradeoffs emerging thereof. We show that Pareto optimal designs display a broad\nrange of potential solutions: from small networks with high regeneration rate,\nto larger and redundant circuits that regenerate slowly. The organism's\nlifespan and the external damage rates are found to act as an evolutionary\npressure that improve the exploration of the space of solutions and poses\ntighter optimality conditions. We also find that large damage rates to the\ncircuits can constrain the space of the possible and pose organisms to commit\nto unique strategies for neural systems maintenance.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:44:07 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Oll\u00e9-Vila", "Aina", ""], ["Seoane", "Lu\u00eds F.", ""], ["Sol\u00e9", "Ricard", ""]]}, {"id": "1909.11451", "submitter": "Geoffrey Iwata", "authors": "Geoffrey Z. Iwata, Yinan Hu, Tilmann Sander, Muthuraman Muthuraman,\n  Venkata Chaitanya Chirumamilla, Sergiu Groppa, Dmitry Budker, and Arne\n  Wickenbrock", "title": "Biomagnetic signals recorded during transcranial magnetic stimulation\n  (TMS)-evoked peripheral muscular activity", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.SP physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: We present magnetomyograms (MMG) of TMS-evoked movement in a human\nhand, together with a simultaneous surface electromyograph (EMG) and\nelectroencephalograph (EEG) data. Approach: We combined TMS with non-contact\nmagnetic detection of TMS-evoked muscle activity in peripheral limbs to explore\na new diagnostic modality that enhances the utility of TMS as a clinical tool\nby leveraging technological advances in magnetometry. We recorded measurements\nin a regular hospital room using an array of optically pumped magnetometers\n(OPM) inside a portable shield that encompasses only the forearm and hand of\nthe subject. Main Results: The biomagnetic signals recorded in the MMG provide\ndetailed spatial and temporal information that is complementary to that of the\nelectric signal channels. Moreover, we identify features in the magnetic\nrecording beyond those of the EMG. Significance: These results validate the\nviability of MMG recording with a compact OPM based setup in small-sized\nmagnetic shielding, and provide proof-of-principle for a non-contact data\nchannel for detection and analysis of TMS-evoked muscle activity from\nperipheral limbs.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 12:46:27 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 15:03:40 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Iwata", "Geoffrey Z.", ""], ["Hu", "Yinan", ""], ["Sander", "Tilmann", ""], ["Muthuraman", "Muthuraman", ""], ["Chirumamilla", "Venkata Chaitanya", ""], ["Groppa", "Sergiu", ""], ["Budker", "Dmitry", ""], ["Wickenbrock", "Arne", ""]]}, {"id": "1909.11483", "submitter": "Jordan Ott", "authors": "Jordan Ott, Erik Linstead, Nicholas LaHaye, Pierre Baldi", "title": "Learning in the Machine: To Share or Not to Share?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Weight-sharing is one of the pillars behind Convolutional Neural Networks and\ntheir successes. However, in physical neural systems such as the brain,\nweight-sharing is implausible. This discrepancy raises the fundamental question\nof whether weight-sharing is necessary. If so, to which degree of precision? If\nnot, what are the alternatives? The goal of this study is to investigate these\nquestions, primarily through simulations where the weight-sharing assumption is\nrelaxed. Taking inspiration from neural circuitry, we explore the use of Free\nConvolutional Networks and neurons with variable connection patterns. Using\nFree Convolutional Networks, we show that while weight-sharing is a pragmatic\noptimization approach, it is not a necessity in computer vision applications.\nFurthermore, Free Convolutional Networks match the performance observed in\nstandard architectures when trained using properly translated data (akin to\nvideo). Under the assumption of translationally augmented data, Free\nConvolutional Networks learn translationally invariant representations that\nyield an approximate form of weight sharing.\n", "versions": [{"version": "v1", "created": "Mon, 23 Sep 2019 20:10:50 GMT"}, {"version": "v2", "created": "Fri, 4 Oct 2019 19:58:04 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Ott", "Jordan", ""], ["Linstead", "Erik", ""], ["LaHaye", "Nicholas", ""], ["Baldi", "Pierre", ""]]}, {"id": "1909.11894", "submitter": "Mason A. Porter", "authors": "Elisa C. Baek, Mason A. Porter, and Carolyn Parkinson", "title": "Social Network Analysis for Social Neuroscientists", "comments": "the revision includes new tables that summarize (1) key network terms\n  and (2) limitations and challenges", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although social neuroscience is concerned with understanding how the brain\ninteracts with its social environment, prevailing research in the field has\nprimarily considered the human brain in isolation, deprived of its rich social\ncontext. Emerging work in social neuroscience that leverages tools from network\nanalysis has begun to pursue this issue, advancing knowledge of how the human\nbrain influences and is influenced by the structures of its social environment.\nIn this paper, we provide an overview of key theory and methods in network\nanalysis (especially for social systems) as an introduction for social\nneuroscientists who are interested in relating individual cognition to the\nstructures of an individual's social environments. We also highlight some\nexciting new work as examples of how to productively use these tools to\ninvestigate questions of relevance to social neuroscientists. We include\ntutorials to help with practical implementation of the concepts that we\ndiscuss. We conclude by highlighting a broad range of exciting research\nopportunities for social neuroscientists who are interested in using network\nanalysis to study social systems.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 04:57:29 GMT"}, {"version": "v2", "created": "Wed, 12 Feb 2020 03:01:02 GMT"}], "update_date": "2020-02-13", "authors_parsed": [["Baek", "Elisa C.", ""], ["Porter", "Mason A.", ""], ["Parkinson", "Carolyn", ""]]}, {"id": "1909.11899", "submitter": "Po-Ya Hsu", "authors": "Po-Ya Hsu", "title": "Dynamic Parameter Estimation of Brain Mechanisms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CE math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demystifying effective connectivity among neuronal populations has become the\ntrend to understand the brain mechanisms of Parkinson's disease, schizophrenia,\nmild traumatic brain injury, and many other unlisted neurological diseases.\nDynamic modeling is a state-of-the-art approach to explore various\nconnectivities among neuronal populations corresponding to different\nelectrophysiological responses. Through estimating the parameters in the\ndynamic models, including the strengths and propagation delays of the\nelectrophysiological signals, the discovery of the underlying connectivities\ncan lead to the elucidation of functional brain mechanisms. In this report, we\nsurvey six dynamic models that describe the intrinsic function of a single\nneuronal/subneuronal population and three effective network estimation methods\nthat can trace the connections among the neuronal/subneuronal populations. The\nsix dynamic models are event related potential, local field potential,\nconductance-based neural mass model, mean field model, neural field model, and\ncanonical micro-circuits; the three effective network estimation approaches are\ndynamic causal modeling, structural causal model, and vector autoregression.\nSubsequently, we discuss dynamic parameter estimation methods including\nvariational Bayesian, particle filtering, Metropolis-Hastings algorithm,\nGauss-Newton algorithm, collocation method, and constrained optimization. We\nsummarize the merits and drawbacks of each model, network estimation approach,\nand parameter estimation method. In addition, we demonstrate an exemplary\neffective network estimation problem statement. Last, we identify possible\nfuture work and challenges to develop an elevated package.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 05:28:40 GMT"}], "update_date": "2019-09-27", "authors_parsed": [["Hsu", "Po-Ya", ""]]}, {"id": "1909.12154", "submitter": "Michael Rosenblum", "authors": "Dmitriy Krylov, Dmitry V. Dylov, and Michael Rosenblum", "title": "Reinforcement learning for suppression of collective activity in\n  oscillatory ensembles", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": "10.1063/1.5128909", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a use of modern data-based machine learning approaches to suppress\nself-sustained collective oscillations typically signaled by ensembles of\ndegenerative neurons in the brain. The proposed hybrid model relies on two\nmajor components: an environment of oscillators and a policy-based\nreinforcement learning block. We report a model-agnostic synchrony control\nbased on proximal policy optimization and two artificial neural networks in an\nActor-Critic configuration. A class of physically meaningful reward functions\nenabling the suppression of collective oscillatory mode is proposed. The\nsynchrony suppression is demonstrated for two models of neuronal populations --\nfor the ensembles of globally coupled limit-cycle Bonhoeffer-van der Pol\noscillators and for the bursting Hindmarsh--Rose neurons.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2019 09:43:29 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2020 19:47:17 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Krylov", "Dmitriy", ""], ["Dylov", "Dmitry V.", ""], ["Rosenblum", "Michael", ""]]}, {"id": "1909.12299", "submitter": "Subba Reddy Oota", "authors": "Subba Reddy Oota and Naresh Manwani and Raju S. Bapi", "title": "Expert2Coder: Capturing Divergent Brain Regions Using Mixture of\n  Regression Experts", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  fMRI semantic category understanding using linguistic encoding models\nattempts to learn a forward mapping that relates stimuli to the corresponding\nbrain activation. State-of-the-art encoding models use a single global model\n(linear or non-linear) to predict brain activation given the stimulus. However,\nthe critical assumption in these methods is that a priori different brain\nregions respond the same way to all the stimuli, that is, there is no\nmodularity or specialization assumed for any region. This goes against the\nmodularity theory, supported by many cognitive neuroscience investigations\nsuggesting that there are functionally specialized regions in the brain. In\nthis paper, we achieve this by clustering similar regions together and for\nevery cluster we learn a different linear regression model using a mixture of\nlinear experts model. The key idea here is that each linear expert captures the\nbehaviour of similar brain regions. Given a new stimulus, the utility of the\nproposed model is twofold (i) predicts the brain activation as a weighted\nlinear combination of the activations of multiple linear experts and (ii) to\nlearn multiple experts corresponding to different brain regions. We argue that\neach expert captures activity patterns related to a particular region of\ninterest (ROI) in the human brain. This study helps in understanding the brain\nregions that are activated together given different kinds of stimuli.\nImportantly, we suggest that the mixture of regression experts (MoRE) framework\nsuccessfully combines the two principles of organization of function in the\nbrain, namely that of specialization and integration. Experiments on fMRI data\nfrom paradigm 1 [1]where participants view linguistic stimuli show that the\nproposed MoRE model has better prediction accuracy compared to that of\nconventional models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2019 17:59:33 GMT"}, {"version": "v2", "created": "Fri, 29 May 2020 19:45:25 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Oota", "Subba Reddy", ""], ["Manwani", "Naresh", ""], ["Bapi", "Raju S.", ""]]}, {"id": "1909.12537", "submitter": "Hugo Richard", "authors": "Hugo Richard, Lucas Martin, Ana Lu{\\i}sa Pinho, Jonathan Pillow,\n  Bertrand Thirion", "title": "Fast shared response model for fMRI data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The shared response model provides a simple but effective framework to\nanalyse fMRI data of subjects exposed to naturalistic stimuli. However when the\nnumber of subjects or runs is large, fitting the model requires a large amount\nof memory and computational power, which limits its use in practice. In this\nwork, we introduce the FastSRM algorithm that relies on an intermediate\natlas-based representation. It provides considerable speed-up in time and\nmemory usage, hence it allows easy and fast large-scale analysis of\nnaturalistic-stimulus fMRI data. Using four different datasets, we show that\nour method matches the performance of the original SRM algorithm while being\nabout 5x faster and 20x to 40x more memory efficient. Based on this\ncontribution, we use FastSRM to predict age from movie watching data on the\nCamCAN sample. Besides delivering accurate predictions (mean absolute error of\n7.5 years), FastSRM extracts topographic patterns that are predictive of age,\ndemonstrating that brain activity during free perception reflects age.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2019 07:46:28 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 16:20:24 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Richard", "Hugo", ""], ["Martin", "Lucas", ""], ["Pinho", "Ana Lu\u0131sa", ""], ["Pillow", "Jonathan", ""], ["Thirion", "Bertrand", ""]]}, {"id": "1909.13045", "submitter": "Acer Chang Yu-Chan", "authors": "Acer Y.C. Chang, Martin Biehl, Yen Yu, Ryota Kanai", "title": "Information Closure Theory of Consciousness", "comments": null, "journal-ref": null, "doi": "10.3389/fpsyg.2020.01504", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Information processing in neural systems can be described and analysed at\nmultiple spatiotemporal scales. Generally, information at lower levels is more\nfine-grained and can be coarse-grained in higher levels. However, information\nprocessed only at specific levels seems to be available for conscious\nawareness. We do not have direct experience of information available at the\nlevel of individual neurons, which is noisy and highly stochastic. Neither do\nwe have experience of more macro-level interactions such as interpersonal\ncommunications. Neurophysiological evidence suggests that conscious experiences\nco-vary with information encoded in coarse-grained neural states such as the\nfiring pattern of a population of neurons. In this article, we introduce a new\ninformational theory of consciousness: Information Closure Theory of\nConsciousness (ICT). We hypothesise that conscious processes are processes\nwhich form non-trivial informational closure (NTIC) with respect to the\nenvironment at certain coarse-grained levels. This hypothesis implies that\nconscious experience is confined due to informational closure from conscious\nprocessing to other coarse-grained levels. ICT proposes new quantitative\ndefinitions of both conscious content and conscious level. With the\nparsimonious definitions and a hypothesise, ICT provides explanations and\npredictions of various phenomena associated with consciousness. The\nimplications of ICT naturally reconciles issues in many existing theories of\nconsciousness and provides explanations for many of our intuitions about\nconsciousness. Most importantly, ICT demonstrates that information can be the\ncommon language between consciousness and physical reality.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 08:05:06 GMT"}, {"version": "v2", "created": "Thu, 11 Jun 2020 14:57:03 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Chang", "Acer Y. C.", ""], ["Biehl", "Martin", ""], ["Yu", "Yen", ""], ["Kanai", "Ryota", ""]]}, {"id": "1909.13868", "submitter": "Alexander  Mathis", "authors": "Mackenzie W. Mathis and Alexander Mathis", "title": "Deep learning tools for the measurement of animal behavior in\n  neuroscience", "comments": "11 pages, 3 figures, review", "journal-ref": "Current Opinion in Neurobiology Volume 60, February 2020, Pages\n  1-11", "doi": "10.1016/j.conb.2019.10.008", "report-no": null, "categories": "cs.CV q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in computer vision have made accurate, fast and robust\nmeasurement of animal behavior a reality. In the past years powerful tools\nspecifically designed to aid the measurement of behavior have come to fruition.\nHere we discuss how capturing the postures of animals - pose estimation - has\nbeen rapidly advancing with new deep learning methods. While challenges still\nremain, we envision that the fast-paced development of new deep learning tools\nwill rapidly change the landscape of realizable real-world neuroscience.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 17:50:48 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 17:40:30 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Mathis", "Mackenzie W.", ""], ["Mathis", "Alexander", ""]]}]