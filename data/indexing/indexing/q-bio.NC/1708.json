[{"id": "1708.00138", "submitter": "Richard Granger", "authors": "Antonio M Rodriguez, Richard Granger", "title": "The differential geometry of perceptual similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human similarity judgments are inconsistent with Euclidean, Hamming,\nMahalanobis, and the majority of measures used in the extensive literatures on\nsimilarity and dissimilarity. From intrinsic properties of brain circuitry, we\nderive principles of perceptual metrics, showing their conformance to\nRiemannian geometry. As a demonstration of their utility, the perceptual\nmetrics are shown to outperform JPEG compression. Unlike machine-learning\napproaches, the outperformance uses no statistics, and no learning. Beyond the\nincidental application to compression, the metrics offer broad explanatory\naccounts of empirical perceptual findings such as Tverskys triangle inequality\nviolations, contradictory human judgments of identical stimuli such as speech\nsounds, and a broad range of other phenomena on percepts and concepts that may\ninitially appear unrelated. The findings constitute a set of fundamental\nprinciples underlying perceptual similarity.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 02:39:02 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 01:09:13 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Rodriguez", "Antonio M", ""], ["Granger", "Richard", ""]]}, {"id": "1708.00525", "submitter": "Milena Korostenskaja", "authors": "Milena Korostenskaja, Christoph Kapeller, Ki H Lee, Christoph Guger,\n  James Baumgartner, Eduardo M. Castillo", "title": "Characterization of cortical motor function and imagery-related cortical\n  activity: Potential application for prehabilitation", "comments": "6 pages, 3 figures; IEEE SMC 2017: IEEE International Conference on\n  Systems, Man, and Cybernetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To minimize functional morbidity associated with brain surgery, new\npreventive approaches (also referred to as \"prehabilitation\") by using\nmotor-imagery-based computer interfaces (MI-BCIs) can be utilized. To achieve\nsuccessful MI-BCI performance for prehabilitation purposes, the characteristics\nof an electrocorticographic (ECoG) signal that is associated with overt motor\nfunction (\"real movement\" - RM) versus covert motor function (\"motor imagery\" -\nMI) need to be determined. In our current study, 5 patients with\npharmacoresistant epilepsy (2 males, average age 25 years, SD 15), undergoing\nevaluation for epilepsy surgery participated in both RM and MI tasks. Although\nthe RM- and MI- related ECoG changes had some common features, they also\ndiffered in a number of ways, such as location, frequency ranges, signal\nsynchronization and desynchronization. These similarities and differences are\ndiscussed in a view of other neuroimaging studies, including\nmagnetoencephalography (MEG) and functional magnetic resonance imaging (fMRI).\nWe emphasize the need for inclusion of a broad spectrum of frequencies in ECoG\nanalysis, when RM- and MI- related activities are concerned.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 21:29:46 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Korostenskaja", "Milena", ""], ["Kapeller", "Christoph", ""], ["Lee", "Ki H", ""], ["Guger", "Christoph", ""], ["Baumgartner", "James", ""], ["Castillo", "Eduardo M.", ""]]}, {"id": "1708.00534", "submitter": "Maurizio De Pitt\\`a", "authors": "Maurizio De Pitt\\`a", "title": "Myelin and saltatory conduction", "comments": "14 pages. Submitted as contributed section to the chapter on\n  \"Neurophysiology\" of the book \"Da\\~no cerebral\" (Brain damage), JC\n  Arango-Asprilla \\& L Olabarrieta-Landa eds. Manual Moderno Editions", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Essential tutorial on myelin, oligodendrocytes and their functional relevance\nin the pathophysiology of the brain.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 21:58:34 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["De Pitt\u00e0", "Maurizio", ""]]}, {"id": "1708.00540", "submitter": "Gergely Marton PhD", "authors": "Gergely Marton, Peter Baracskay, Barbara Cseri, Bela Plosz, Gabor\n  Juhasz, Zoltan Fekete, Anita Pongracz", "title": "A silicon-based microelectrode array with a microdrive for monitoring\n  brainstem regions of freely moving rats", "comments": null, "journal-ref": "J Neural Eng. 2016 Apr;13(2):026025. doi:\n  10.1088/1741-2560/13/2/026025. Epub 2016 Feb 29", "doi": "10.1088/1741-2560/13/2/026025", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective. Exploring neural activity behind synchronization and time locking\nin brain circuits is one of the most important tasks in neuroscience. Our goal\nwas to design and characterize a microelectrode array (MEA) system specifically\nfor obtaining in vivo extracellular recordings from three deep-brain areas of\nfreely moving rats, simultaneously. The target areas, the deep mesencephalic\nreticular-, pedunculopontine tegmental- and pontine reticular nuclei are\nrelated to the regulation of sleep-wake cycles. Approach. The three targeted\nnuclei are collinear, therefore a single-shank MEA was designed in order to\ncontact them. The silicon-based device was equipped with 3*4 recording sites,\nlocated according to the geometry of the brain regions. Furthermore, a\nmicrodrive was developed to allow fine actuation and post-implantation\nrelocation of the probe. The probe was attached to a rigid printed circuit\nboard, which was fastened to the microdrive. A flexible cable was designed in\norder to provide not only electronic connection between the probe and the\namplifier system, but sufficient freedom for the movements of the probe as\nwell. Main results. The microdrive was stable enough to allow precise electrode\ntargeting into the tissue via a single track. The microelectrodes on the probe\nwere suitable for recording neural activity from the three targeted brainstem\nareas. Significance. The system offers a robust solution to provide long-term\ninterface between an array of precisely defined microelectrodes and deep-brain\nareas of a behaving rodent. The microdrive allowed us to fine-tune the probe\nlocation and easily scan through the regions of interest.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 22:42:32 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Marton", "Gergely", ""], ["Baracskay", "Peter", ""], ["Cseri", "Barbara", ""], ["Plosz", "Bela", ""], ["Juhasz", "Gabor", ""], ["Fekete", "Zoltan", ""], ["Pongracz", "Anita", ""]]}, {"id": "1708.00556", "submitter": "Andy Zhou", "authors": "Andy Zhou, Samantha R. Santacruz, Benjamin C. Johnson, George\n  Alexandrov, Ali Moin, Fred L. Burghardt, Jan M. Rabaey, Jose M. Carmena,\n  Rikky Muller", "title": "WAND: A 128-channel, closed-loop, wireless artifact-free neuromodulation\n  device", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Closed-loop neuromodulation systems aim to treat a variety of neurological\nconditions by dynamically delivering and adjusting therapeutic electrical\nstimulation in response to a patient's neural state, recorded in real-time.\nExisting systems are limited by low channel counts, lack of algorithmic\nflexibility, and distortion of recorded signals from large, persistent\nstimulation artifacts. Here, we describe a device that enables new research\napplications requiring high-throughput data streaming, low-latency biosignal\nprocessing, and truly simultaneous sensing and stimulation. The Wireless\nArtifact-free Neuromodulation Device (WAND) is a miniaturized, wireless neural\ninterface capable of recording and stimulating on 128 channels with on-board\nprocessing to fully cancel stimulation artifacts, detect neural biomarkers, and\nautomatically adjust stimulation parameters in a closed-loop fashion. It\ncombines custom application specific integrated circuits (ASICs), an on-board\nFPGA, and a low-power bidirectional radio. We validate wireless, long-term\nrecordings of local field potentials (LFP) and real-time cancellation of\nstimulation artifacts in a behaving nonhuman primate (NHP). We use WAND to\ndemonstrate a closed-loop stimulation paradigm to disrupt movement preparatory\nactivity during a delayed-reach task in a NHP in vivo. This wireless device,\nleveraging custom ASICs for both neural recording and electrical stimulation\nmodalities, makes possible a neural interface platform technology to\nsignificantly advance both neuroscientific discovery and preclinical\ninvestigations of stimulation-based therapeutic interventions.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 00:12:05 GMT"}, {"version": "v2", "created": "Sun, 3 Dec 2017 07:49:35 GMT"}, {"version": "v3", "created": "Tue, 29 May 2018 16:54:34 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Zhou", "Andy", ""], ["Santacruz", "Samantha R.", ""], ["Johnson", "Benjamin C.", ""], ["Alexandrov", "George", ""], ["Moin", "Ali", ""], ["Burghardt", "Fred L.", ""], ["Rabaey", "Jan M.", ""], ["Carmena", "Jose M.", ""], ["Muller", "Rikky", ""]]}, {"id": "1708.00731", "submitter": "Maurizio De Pitt\\`a", "authors": "Maurizio De Pitt\\`a", "title": "Glia", "comments": "13 pages. Submitted as contributed section to the chapter on\n  \"Neurophysiology\" of the book \"Da\\~no cerebral\" (Brain damage), JC\n  Arango-Asprilla \\& L Olabarrieta-Landa eds. Manual Moderno Editions", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Essential introduction to glial cells with emphasis on astrocytes, microglia\nand their interplay in reactive astrogliosis.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 13:01:08 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["De Pitt\u00e0", "Maurizio", ""]]}, {"id": "1708.00779", "submitter": "Daniel Pouzzner", "authors": "Daniel Pouzzner", "title": "Control of Functional Connectivity in Cerebral Cortex by Basal Ganglia\n  Mediated Synchronization", "comments": "Expanded comparison to cerebellum (13.1); Discuss resonant\n  frequencies of cortico-subcortical loops (1.8, 3.2, 13.1.7); Expanded\n  treatment of neural noise and criticality (5.2, 11.4, 11.6, 12.7, 14.3.9);\n  Minor clarifications, expansions, and reorganization for readability\n  throughout; 306 new references", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since the earliest electroencephalography experiments, large scale\noscillations have been observed in the mammalian brain. More recently, they\nhave been identified not only in the cerebral cortex and thalamus, but\npervasively in the healthy basal ganglia. The basal ganglia mediated\nsynchronization model, introduced here, implicates these oscillations in the\ncombination of cortical association mechanisms with stimulus-response and\nreinforcement mechanisms in the basal ganglia. In the core mechanism of the\nmodel, oscillatory patterns in cortex are selected by and routed through the\nbasal ganglia to the thalamus phase-coherently, then circulated back to widely\nseparated areas of cortex, synchronizing those areas and functionally\nconnecting them. Corticostriatal and striatonigral conduction delays are\ncrucial to this mechanism, and evidence suggests that these delays are\nunusually long, and unusually varied, in arrangements that might facilitate\nlearning of useful time alignments and associated resonant frequencies. Other\nstructural arrangements in the basal ganglia show further specialization for\nthis role, with convergence in the inputs from cortex, and divergence in many\nof the return paths to cortex, that systematically reflect corticocortical\nanatomical connectivity. The basal ganglia also target the dopaminergic,\ncholinergic, and serotonergic centers of the brainstem and basal forebrain, and\nthe reticular nucleus of the thalamus, structures broadly implicated in the\nmodulation of oscillatory network activity and expressions of plasticity. By\nlearning to coordinate these various output channels, the basal ganglia are\npositioned to facilitate and synchronize activity in selected areas of cortex,\nbroadly impart selective receptivity, attenuate and disconnect interfering\nactivity, and recurrently process the resulting patterns of activity,\nchanneling cognition and promoting goal [...]\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 20:44:26 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 17:13:49 GMT"}], "update_date": "2020-04-13", "authors_parsed": [["Pouzzner", "Daniel", ""]]}, {"id": "1708.00909", "submitter": "Joshua Glaser", "authors": "Joshua I. Glaser, Ari S. Benjamin, Raeed H. Chowdhury, Matthew G.\n  Perich, Lee E. Miller, Konrad P. Kording", "title": "Machine learning for neural decoding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Despite rapid advances in machine learning tools, the majority of neural\ndecoding approaches still use traditional methods. Modern machine learning\ntools, which are versatile and easy to use, have the potential to significantly\nimprove decoding performance. This tutorial describes how to effectively apply\nthese algorithms for typical decoding problems. We provide descriptions, best\npractices, and code for applying common machine learning methods, including\nneural networks and gradient boosting. We also provide detailed comparisons of\nthe performance of various methods at the task of decoding spiking activity in\nmotor cortex, somatosensory cortex, and hippocampus. Modern methods,\nparticularly neural networks and ensembles, significantly outperform\ntraditional approaches, such as Wiener and Kalman filters. Improving the\nperformance of neural decoding algorithms allows neuroscientists to better\nunderstand the information contained in a neural population and can help\nadvance engineering applications such as brain machine interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 19:53:22 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 16:58:31 GMT"}, {"version": "v3", "created": "Fri, 20 Sep 2019 02:46:47 GMT"}, {"version": "v4", "created": "Fri, 3 Jul 2020 15:25:31 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Glaser", "Joshua I.", ""], ["Benjamin", "Ari S.", ""], ["Chowdhury", "Raeed H.", ""], ["Perich", "Matthew G.", ""], ["Miller", "Lee E.", ""], ["Kording", "Konrad P.", ""]]}, {"id": "1708.01273", "submitter": "Hector Vasquez", "authors": "Hector Vasquez and Giovanni Zocchi", "title": "Coincidences with the Artificial Axon", "comments": null, "journal-ref": null, "doi": "10.1209/0295-5075/119/48003", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The artificial axon is an excitable node built with the basic biomolecular\ncomponents and supporting action potentials. Here we demonstrate coincidence\nfiring (the AND operation) and other basic electrophysiology features such as\nincreasing firing rates for increasing input currents. We construct the basic\nunit for a network by connecting two such excitable nodes through an electronic\nsynapse, producing pre/post synaptic behavior in which one axon induces firing\nin another. We show that the system is well described by the Hodgkin-Huxley\nmodel of nerve excitability, and conclude with a brief outlook for realizing\nlarge networks of such low voltage \"ionics\".\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 18:36:28 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Vasquez", "Hector", ""], ["Zocchi", "Giovanni", ""]]}, {"id": "1708.01444", "submitter": "Shohei Hidaka", "authors": "Shohei Hidaka and Masafumi Oizumi", "title": "Fast and exact search for the partition with minimal information loss", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0201126", "report-no": null, "categories": "cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In analysis of multi-component complex systems, such as neural systems,\nidentifying groups of units that share similar functionality will aid\nunderstanding of the underlying structures of the system. To find such a\ngrouping, it is useful to evaluate to what extent the units of the system are\nseparable. Separability or inseparability can be evaluated by quantifying how\nmuch information would be lost if the system were partitioned into subsystems,\nand the interactions between the subsystems were hypothetically removed. A\nsystem of two independent subsystems are completely separable without any loss\nof information while a system of strongly interacted subsystems cannot be\nseparated without a large loss of information. Among all the possible\npartitions of a system, the partition that minimizes the loss of information,\ncalled the Minimum Information Partition (MIP), can be considered as the\noptimal partition for characterizing the underlying structures of the system.\nAlthough the MIP would reveal novel characteristics of the neural system, an\nexhaustive search for the MIP is numerically intractable due to the\ncombinatorial explosion of possible partitions. Here, we propose a\ncomputationally efficient search to precisely identify the MIP among all\npossible partitions by exploiting the submodularity of the measure of\ninformation loss. Mutual information is one such submodular information loss\nfunctions, and is a natural choice for measuring the degree of statistical\ndependence between paired sets of random variables. By using mutual information\nas a loss function, we show that the search for MIP can be performed in a\npractical order of computational time for a reasonably large system. We also\ndemonstrate that MIP search allows for the detection of underlying global\nstructures in a network of nonlinear oscillators.\n", "versions": [{"version": "v1", "created": "Fri, 4 Aug 2017 10:33:21 GMT"}, {"version": "v2", "created": "Wed, 29 Nov 2017 00:48:40 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 12:42:07 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Hidaka", "Shohei", ""], ["Oizumi", "Masafumi", ""]]}, {"id": "1708.01888", "submitter": "Ildefons Magrans de Abril", "authors": "Ildefons Magrans de Abril, Junichiro Yoshimoto and Kenji Doya", "title": "Connectivity Inference from Neural Recording Data: Challenges,\n  Mathematical Bases and Research Directions", "comments": "52 pages, 2 figures, 3 tables, survey paper under review in Neural\n  Networks Journal - Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a review of computational methods for connectivity\ninference from neural activity data derived from multi-electrode recordings or\nfluorescence imaging. We first identify biophysical and technical challenges in\nconnectivity inference along the data processing pipeline. We then review\nconnectivity inference methods based on two major mathematical foundations,\nnamely, descriptive model-free approaches and generative model-based\napproaches. We investigate representative studies in both categories and\nclarify which challenges have been addressed by which method. We further\nidentify critical open issues and possible research directions.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 13:19:57 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 04:16:27 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["de Abril", "Ildefons Magrans", ""], ["Yoshimoto", "Junichiro", ""], ["Doya", "Kenji", ""]]}, {"id": "1708.02204", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley", "title": "Curvature sensing by vision and touch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain representations of curvature may be formed on the basis of either\nvision or touch. Experimental and theoretical work by the author and her\ncolleagues has shown that the processing underlying such representations\ndirectly depends on specific two-dimensional geometric properties of the curved\nobject, and on the symmetry of curvature. Virtual representations of curves\nwith mirror symmetry were displayed in 2D on a computer screen to sighted\nobservers for visual scaling. For tactile (haptic) scaling, the physical\ncounterparts of these curves were placed in the two hands of sighted observers,\nwho were blindfolded during the sensing experiment, and of congenitally blind\nobservers, who never had any visual experience. All results clearly show that\ncurvature, whether haptically or visually sensed, is statistically linked to\nthe same curve properties. Sensation is expressed psychophysically as a power\nfunction of any symmetrical curve's aspect ratio, a scale invariant geometric\nproperty of physical objects. The results of the author's work support\nbiologically motivated models of sensory integration for curvature processing.\nThey also promote the idea of a universal power law for adaptive brain control\nand balancing of motor responses to environmental stimuli across sensory\nmodalities.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 17:02:51 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Dresp-Langley", "Birgitta", ""]]}, {"id": "1708.02423", "submitter": "Jonathan Schiefer", "authors": "Jonathan Schiefer, Alexander Niederb\\\"uhl, Volker Pernice, Carolin\n  Lennartz, Pierre LeVan, J\\\"urgen Henning and Stefan Rotter", "title": "From Correlation to Causation: Estimation of Effective Connectivity from\n  Continuous Brain Signals based on Zero-Lag Covariance", "comments": "18 pages, 10 figures", "journal-ref": "PLoS Comput Biol 14(3): e1006056 (2018)", "doi": "10.1371/journal.pcbi.1006056", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing brain connectivity is of great importance both in basic research and\nfor clinical applications. We are proposing a method to infer directed\nconnectivity from zero-lag covariances of neuronal activity recorded at\nmultiple sites. This allows us to identify causal relations that are reflected\nin neuronal population activity. To derive our strategy, we assume a generic\nlinear model of interacting continuous variables, the components of which\nrepresent the activity of local neuronal populations. The suggested method for\ninferring connectivity from recorded signals exploits the fact that the\ncovariance matrix derived from the observed activity contains information about\nthe existence, the direction and the sign of connections. Assuming a sparsely\ncoupled network, we disambiguate the underlying causal structure via\n$L^1$-minimization. In general, this method is suited to infer effective\nconnectivity from resting state data of various types. We show that our method\nis applicable over a broad range of structural parameters regarding network\nsize and connection probability of the network. We also explored parameters\naffecting its activity dynamics, like the eigenvalue spectrum. Also, based on\nthe simulation of suitable Ornstein-Uhlenbeck processes to model BOLD dynamics,\nwe show that with our method it is possible to estimate directed connectivity\nfrom zero-lag covariances derived from such signals. In this study, we consider\nmeasurement noise and unobserved nodes as additional confounding factors.\nFurthermore, we investigate the amount of data required for a reliable\nestimate. Additionally, we apply the proposed method on a fMRI dataset. The\nresulting network exhibits a tendency for close-by areas being connected as\nwell as inter-hemispheric connections between corresponding areas. Also, we\nfound that a large fraction of identified connections were inhibitory.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 09:33:35 GMT"}, {"version": "v2", "created": "Wed, 13 Sep 2017 09:10:32 GMT"}, {"version": "v3", "created": "Fri, 19 Jan 2018 09:51:56 GMT"}, {"version": "v4", "created": "Mon, 9 Apr 2018 09:02:57 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Schiefer", "Jonathan", ""], ["Niederb\u00fchl", "Alexander", ""], ["Pernice", "Volker", ""], ["Lennartz", "Carolin", ""], ["LeVan", "Pierre", ""], ["Henning", "J\u00fcrgen", ""], ["Rotter", "Stefan", ""]]}, {"id": "1708.02554", "submitter": "Matjaz Perc", "authors": "Daqing Guo, Matjaz Perc, Yangsong Zhang, Peng Xu, Dezhong Yao", "title": "Frequency-difference-dependent stochastic resonance in neural systems", "comments": "6 two-column pages, 7 figures; accepted for publication in Physical\n  Review E", "journal-ref": "Phys. Rev. E 96 (2017) 022415", "doi": "10.1103/PhysRevE.96.022415", "report-no": null, "categories": "q-bio.NC nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological neurons receive multiple noisy oscillatory signals, and their\ndynamical response to the superposition of these signals is of fundamental\nimportance for information processing in the brain. Here we study the response\nof neural systems to the weak envelope modulation signal, which is superimposed\nby two periodic signals with different frequencies. We show that stochastic\nresonance occurs at the beat frequency in neural systems at the single-neuron\nas well as the population level. The performance of this\nfrequency-difference-dependent stochastic resonance is influenced by both the\nbeat frequency and the two forcing frequencies. Compared to a single neuron, a\npopulation of neurons is more efficient in detecting the information carried by\nthe weak envelope modulation signal at the beat frequency. Furthermore, an\nappropriate fine-tuning of the excitation-inhibition balance can further\noptimize the response of a neural ensemble to the superimposed signal. Our\nresults thus introduce and provide insights into the generation and modulation\nmechanism of the frequency-difference-dependent stochastic resonance in neural\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 16:42:52 GMT"}, {"version": "v2", "created": "Fri, 25 Aug 2017 14:52:02 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Guo", "Daqing", ""], ["Perc", "Matjaz", ""], ["Zhang", "Yangsong", ""], ["Xu", "Peng", ""], ["Yao", "Dezhong", ""]]}, {"id": "1708.02603", "submitter": "Tae Seung Kang", "authors": "Tae Seung Kang and Arunava Banerjee", "title": "Learning Feedforward and Recurrent Deterministic Spiking Neuron Network\n  Feedback Controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of learning feedback control where the controller is a\nnetwork constructed solely of deterministic spiking neurons. In contrast to\nprevious investigations that were based on a spike rate model of the neuron,\nthe control signal here is determined by the precise temporal positions of\nspikes generated by the output neurons of the network. We model the problem\nformally as a hybrid dynamical system comprised of a closed loop between a\nplant and a spiking neuron network. We derive a novel synaptic weight update\nrule via which the spiking neuron network controller learns to hold process\nvariables at desired set points. The controller achieves its learning objective\nbased solely on access to the plant's process variables and their derivatives\nwith respect to changing control signals; in particular, it requires no\ninternal model of the plant. We demonstrate the efficacy of the rule by\napplying it to the classical control problem of the cart-pole (inverted\npendulum) and a model of fish locomotion. Experiments show that the proposed\ncontroller has a stability region comparable to a traditional PID controller,\nits trajectories differ qualitatively from those of a PID controller, and in\nmany instances the controller achieves its objective using very sparse spike\ntrain outputs.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 18:42:17 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2018 22:54:29 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Kang", "Tae Seung", ""], ["Banerjee", "Arunava", ""]]}, {"id": "1708.02638", "submitter": "Milad Makkie", "authors": "Milad Makkie, Xiang Li, Binbin Lin, Jieping Ye, Mojtaba Sedigh Fazli,\n  Tianming Liu, Shannon Quinn", "title": "Distributed rank-1 dictionary learning: Towards fast and scalable\n  solutions for fMRI big data analytics", "comments": "One of the authors name, Mojtaba Sedigh Fazli, has been mistakenly\n  missed from this paper presented at the IEEE Big Data confrence. In result we\n  are submitting this verison to correct the authors' names", "journal-ref": null, "doi": "10.1109/BigData.2016.7841000", "report-no": null, "categories": "cs.DS cs.DC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of functional brain imaging for research and diagnosis has benefitted\ngreatly from the recent advancements in neuroimaging technologies, as well as\nthe explosive growth in size and availability of fMRI data. While it has been\nshown in literature that using multiple and large scale fMRI datasets can\nimprove reproducibility and lead to new discoveries, the computational and\ninformatics systems supporting the analysis and visualization of such fMRI big\ndata are extremely limited and largely under-discussed. We propose to address\nthese shortcomings in this work, based on previous success in using dictionary\nlearning method for functional network decomposition studies on fMRI data. We\npresented a distributed dictionary learning framework based on rank-1 matrix\ndecomposition with sparseness constraint (D-r1DL framework). The framework was\nimplemented using the Spark distributed computing engine and deployed on three\ndifferent processing units: an in-house server, in-house high performance\nclusters, and the Amazon Elastic Compute Cloud (EC2) service. The whole\nanalysis pipeline was integrated with our neuroinformatics system for data\nmanagement, user input/output, and real-time visualization. Performance and\naccuracy of D-r1DL on both individual and group-wise fMRI Human Connectome\nProject (HCP) dataset shows that the proposed framework is highly scalable. The\nresulting group-wise functional network decompositions are highly accurate, and\nthe fast processing time confirm this claim. In addition, D-r1DL can provide\nreal-time user feedback and results visualization which are vital for\nlarge-scale data analysis.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 20:11:35 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Makkie", "Milad", ""], ["Li", "Xiang", ""], ["Lin", "Binbin", ""], ["Ye", "Jieping", ""], ["Fazli", "Mojtaba Sedigh", ""], ["Liu", "Tianming", ""], ["Quinn", "Shannon", ""]]}, {"id": "1708.02918", "submitter": "Volker Tresp", "authors": "Volker Tresp and Yunpu Ma", "title": "The Tensor Memory Hypothesis", "comments": "Presented at MLINI-2016 workshop, 2016 (arXiv:1701.01437) Report-no:\n  MLINI/2016/06", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss memory models which are based on tensor decompositions using\nlatent representations of entities and events. We show how episodic memory and\nsemantic memory can be realized and discuss how new memory traces can be\ngenerated from sensory input: Existing memories are the basis for perception\nand new memories are generated via perception. We relate our mathematical\napproach to the hippocampal memory indexing theory. We describe the first\ndetailed mathematical models for the complete processing pipeline from sensory\ninput and its semantic decoding, i.e., perception, to the formation of episodic\nand semantic memories and their declarative semantic decodings. Our main\nhypothesis is that perception includes an active semantic decoding process,\nwhich relies on latent representations of entities and predicates, and that\nepisodic and semantic memories depend on the same decoding process. We\ncontribute to the debate between the leading memory consolidation theories,\ni.e., the standard consolidation theory (SCT) and the multiple trace theory\n(MTT). The latter is closely related to the complementary learning systems\n(CLS) framework. In particular, we show explicitly how episodic memory can\nteach the neocortex to form a semantic memory, which is a core issue in MTT and\nCLS.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 17:22:18 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 14:20:57 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Tresp", "Volker", ""], ["Ma", "Yunpu", ""]]}, {"id": "1708.02966", "submitter": "Meena Jagadeesan", "authors": "Meena Jagadeesan", "title": "Simple Analysis of Sparse, Sign-Consistent JL", "comments": "Appeared at RANDOM 2019; this is the full version with some\n  additional appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allen-Zhu, Gelashvili, Micali, and Shavit construct a sparse, sign-consistent\nJohnson-Lindenstrauss distribution, and prove that this distribution yields an\nessentially optimal dimension for the correct choice of sparsity. However,\ntheir analysis of the upper bound on the dimension and sparsity requires a\ncomplicated combinatorial graph-based argument similar to Kane and Nelson's\nanalysis of sparse JL. We present a simple, combinatorics-free analysis of\nsparse, sign-consistent JL that yields the same dimension and sparsity upper\nbounds as the original analysis. Our analysis also yields dimension/sparsity\ntradeoffs, which were not previously known.\n  As with previous proofs in this area, our analysis is based on applying\nMarkov's inequality to the pth moment of an error term that can be expressed as\na quadratic form of Rademacher variables. Interestingly, we show that, unlike\nin previous work in the area, the traditionally used Hanson-Wright bound is not\nstrong enough to yield our desired result. Indeed, although the Hanson-Wright\nbound is known to be optimal for gaussian degree-2 chaos, it was already shown\nto be suboptimal for Rademachers. Surprisingly, we are able to show a simple\nmoment bound for quadratic forms of Rademachers that is sufficiently tight to\nachieve our desired result, which given the ubiquity of moment and tail bounds\nin theoretical computer science, is likely to be of broader interest.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 18:32:42 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 02:57:29 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Jagadeesan", "Meena", ""]]}, {"id": "1708.02967", "submitter": "Daniel Toker", "authors": "Daniel Toker and Friedrich T. Sommer", "title": "Information Integration In Large Brain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An outstanding problem in neuroscience is to understand how information is\nintegrated across the many modules of the brain. While classic\ninformation-theoretic measures have transformed our understanding of\nfeedforward information processing in the brain's sensory periphery, comparable\nmeasures for information flow in the massively recurrent networks of the rest\nof the brain have been lacking. To address this, recent work in information\ntheory has produced a sound measure of network-wide \"integrated information,\"\nwhich can be estimated from time-series data. But, a computational hurdle has\nstymied attempts to measure large-scale information integration in real brains.\nSpecifically, the measurement of integrated information involves a\ncombinatorial search for the informational \"weakest link\" of a network, a\nprocess whose computation time explodes super-exponentially with network size.\nHere, we show that spectral clustering, applied on the correlation matrix of\ntime-series data, provides an approximate but robust solution to the search for\nthe the informational weakest link of large networks. This reduces the\ncomputation time for integrated information in large systems from longer than\nthe lifespan of the universe to just minutes. We evaluate this solution in\nbrain-like systems of coupled oscillators as well as in high-density\nelectrocortigraphy data from two macaque monkeys, and show that the\ninformational \"weakest link\" of the monkey cortex splits posterior sensory\nareas from anterior association areas. Finally, we use our solution to provide\nevidence in support of the long-standing hypothesis that information\nintegration is maximized by networks with a high global efficiency, and that\nmodular network structures promote the segregation of information.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 18:37:54 GMT"}, {"version": "v2", "created": "Tue, 23 Jan 2018 21:26:58 GMT"}, {"version": "v3", "created": "Fri, 8 Feb 2019 21:16:03 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Toker", "Daniel", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "1708.03263", "submitter": "Giovanni Petri", "authors": "Giovanni Petri, Sebastian Musslick, Biswadip Dey, Kayhan Ozcimder,\n  David Turner, Nesreen K. Ahmed, Theodore Willke and Jonathan D. Cohen", "title": "Topological limits to parallel processing capability of network\n  architectures", "comments": "version 4. Added SIs, 33 pages total, 4 figures + 14 figures in SI,\n  major edits to text", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to learn new tasks and generalize performance to others is one of\nthe most remarkable characteristics of the human brain and of recent AI\nsystems. The ability to perform multiple tasks simultaneously is also a\nsignature characteristic of large-scale parallel architectures, that is evident\nin the human brain, and has been exploited effectively more traditional,\nmassively parallel computational architectures. Here, we show that these two\ncharacteristics are in tension, reflecting a fundamental tradeoff between\ninteractive parallelism that supports learning and generalization, and\nindependent parallelism that supports processing efficiency through concurrent\nmultitasking. We formally show that, while the maximum number of tasks that can\nbe performed simultaneously grows linearly with network size, under realistic\nscenarios (e.g. in an unpredictable environment), the expected number that can\nbe performed concurrently grows radically sub-linearly with network size.\nHence, even modest reliance on shared representation strictly constrains the\nnumber of tasks that can be performed simultaneously, implying profound\nconsequences for the development of artificial intelligence that optimally\nmanages the tradeoff between learning and processing, and for understanding the\nhuman brains remarkably puzzling mix of sequential and parallel capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 15:37:29 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 09:12:46 GMT"}, {"version": "v3", "created": "Wed, 18 Mar 2020 21:11:16 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2020 18:03:26 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Petri", "Giovanni", ""], ["Musslick", "Sebastian", ""], ["Dey", "Biswadip", ""], ["Ozcimder", "Kayhan", ""], ["Turner", "David", ""], ["Ahmed", "Nesreen K.", ""], ["Willke", "Theodore", ""], ["Cohen", "Jonathan D.", ""]]}, {"id": "1708.03666", "submitter": "Sarah Sauv\\'e", "authors": "Sarah A. Sauv\\'e and Marcus T. Pearce", "title": "Attention but not musical training affects auditory streaming", "comments": "36 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While musicians generally perform better than non-musicians in various\nauditory discrimination tasks, effects of specific instrumental training have\nreceived little attention. The effects of instrument-specific musical training\non auditory grouping in the context of stream segregation are investigated here\nin three experiments. In Experiment 1a, participants listened to sequences of\nABA tones and indicated when they heard a change in rhythm. This change is\ncaused by the manipulation of the B tones' timbre and indexes a change in\nperception from integration to segregation, or vice versa. While it was\nexpected that musicians would detect a change in rhythm earlier when their own\ninstrument was involved, no such pattern was observed. In Experiment 1b,\ndesigned to control for potential expectation effects in Experiment 1a,\nparticipants heard sequences of static ABA tones and reported their initial\nperceptions, whether the sequence was integrated or segregated. Results show\nthat participants tend to initially perceive these static sequences as\nsegregated, and that perception is influenced by similarity between the timbres\ninvolved. Finally, in Experiment 2 violinists and flautists located mistuned\nnotes in an interleaved melody paradigm containing a violin and a flute melody.\nPerformance did not depend on the instrument the participant played but rather\nwhich melody their attention was directed to. Taken together, results from the\nthree experiments suggest that the specific instrument one practices does not\nhave an influence on auditory grouping, but attentional mechanisms are\nnecessary for processing auditory scenes.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 19:12:46 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Sauv\u00e9", "Sarah A.", ""], ["Pearce", "Marcus T.", ""]]}, {"id": "1708.03687", "submitter": "Sarah Sauv\\'e", "authors": "Sarah A. Sauv\\'e, Aminah Sayed, Roger T. Dean and Marcus T. Pearce", "title": "Effects of pitch and timing expectancy on musical emotion", "comments": "53 pages, 5 figures; Submitted to Psychomusicology", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pitch and timing information work hand in hand to create a coherent piece of\nmusic; but what happens when this information goes against the norm?\nRelationships between musical expectancy and emotional responses were\ninvestigated in a study conducted with 40 participants: 20 musicians and 20\nnon-musicians. Participants took part in one of two behavioural paradigms\nmeasuring continuous expectancy or emotional responses (arousal and valence)\nwhile listening to folk melodies that exhibited either high or low pitch\npredictability and high or low onset predictability. The causal influence of\npitch predictability was investigated in an additional condition where pitch\nwas artificially manipulated and a comparison conducted between original and\nmanipulated forms; the dynamic correlative influence of pitch and timing\ninformation and its perception on emotional change during listening was\nevaluated using cross-sectional time series analysis. The results indicate that\npitch and onset predictability are consistent predictors of perceived\nexpectancy and emotional response, with onset carrying more weight than pitch.\nIn addition, musicians and non-musicians do not differ in their responses,\npossibly due to shared cultural background and knowledge. The results\ndemonstrate in a controlled lab-based setting a precise, quantitative\nrelationship between the predictability of musical structure, expectation and\nemotional response.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 20:00:07 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Sauv\u00e9", "Sarah A.", ""], ["Sayed", "Aminah", ""], ["Dean", "Roger T.", ""], ["Pearce", "Marcus T.", ""]]}, {"id": "1708.03845", "submitter": "Daniel Chicharro", "authors": "Daniel Chicharro", "title": "Quantifying multivariate redundancy with maximum entropy decompositions\n  of mutual information", "comments": "New Section 4A formalizes the maximum entropy decomposition\n  assumptions, showing for the multivariate case that the maximum entropy\n  measures provide bounds or match the actual synergy, unique, and redundancy\n  measures(proofs in new Appendix). New Section 5 addresses the decomposition\n  interpretability when some assumptions are not fulfilled, e.g. if a\n  nonnegative decomposition cannot be constructed", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Williams and Beer (2010) proposed a nonnegative mutual information\ndecomposition, based on the construction of redundancy lattices, which allows\nseparating the information that a set of variables contains about a target\nvariable into nonnegative components interpretable as the unique information of\nsome variables not provided by others as well as redundant and synergistic\ncomponents. However, the definition of multivariate measures of redundancy that\ncomply with nonnegativity and conform to certain axioms that capture\nconceptually desirable properties of redundancy has proven to be elusive. We\nhere present a procedure to determine nonnegative multivariate redundancy\nmeasures, within the maximum entropy framework. In particular, we generalize\nexisting bivariate maximum entropy measures of redundancy and unique\ninformation, defining measures of the redundant information that a group of\nvariables has about a target, and of the unique redundant information that a\ngroup of variables has about a target that is not redundant with information\nfrom another group. The two key ingredients for this approach are: First, the\nidentification of a type of constraints on entropy maximization that allows\nisolating components of redundancy and unique redundancy by mirroring them to\nsynergy components. Second, the construction of rooted tree-based\ndecompositions of the mutual information, which conform to the axioms of the\nredundancy lattice by the local implementation at each tree node of binary\nunfoldings of the information using hierarchically related maximum entropy\nconstraints. Altogether, the proposed measures quantify the different\nmultivariate redundancy contributions of a nonnegative mutual information\ndecomposition consistent with the redundancy lattice.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 03:29:57 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2018 18:14:23 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Chicharro", "Daniel", ""]]}, {"id": "1708.04020", "submitter": "Natalia Bielczyk Ms", "authors": "Natalia Z. Bielczyk, Sebo Uithol, Tim van Mourik, Paul Anderson,\n  Jeffrey C. Glennon, Jan K. Buitelaar", "title": "Disentangling causal webs in the brain using functional Magnetic\n  Resonance Imaging: A review of current approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past two decades, functional Magnetic Resonance Imaging has been used\nto relate neuronal network activity to cognitive processing and behaviour.\nRecently this approach has been augmented by algorithms that allow us to infer\ncausal links between component populations of neuronal networks. Multiple\ninference procedures have been proposed to approach this research question but\nso far, each method has limitations when it comes to establishing whole-brain\nconnectivity patterns. In this work, we discuss eight ways to infer causality\nin fMRI research: Bayesian Nets, Dynamical Causal Modelling, Granger Causality,\nLikelihood Ratios, LiNGAM, Patel's Tau, Structural Equation Modelling, and\nTransfer Entropy. We finish with formulating some recommendations for the\nfuture directions in this area.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 07:13:17 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 21:56:26 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 11:38:13 GMT"}, {"version": "v4", "created": "Thu, 30 May 2019 09:03:45 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Bielczyk", "Natalia Z.", ""], ["Uithol", "Sebo", ""], ["van Mourik", "Tim", ""], ["Anderson", "Paul", ""], ["Glennon", "Jeffrey C.", ""], ["Buitelaar", "Jan K.", ""]]}, {"id": "1708.04168", "submitter": "Karlis Kanders", "authors": "Karlis Kanders, Tom Lorimer, Yoko Uwate, Willi-Hans Steeb and Ruedi\n  Stoop", "title": "Robust transformations of firing patterns for neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a promising computational paradigm, occurrence of critical states in\nartificial and biological neural networks has attracted wide-spread attention.\nAn often-made explicit or implicit assumption is that one single critical state\nis responsible for two separate notions of criticality (avalanche criticality\nand dynamical edge of chaos criticality). Previously, we provided an isolated\ncounter-example for co-occurrence. Here, we reveal a persistent paradigm of\nstructural transitions that such networks undergo, as the overall connectivity\nstrength is varied over its biologically meaningful range. Among these\ntransitions, only one avalanche critical point emerges, with edge of chaos\nfailing to co-occur. Our observations are based on ensembles of networks\nobtained from variations of network configuration and their neurons. This\nsuggests that not only non-coincidence of criticality, but also the persistent\nparadigm of network structural changes in function of the overall connectivity\nstrength, could be generic features of a large class of biological neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 15:11:04 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Kanders", "Karlis", ""], ["Lorimer", "Tom", ""], ["Uwate", "Yoko", ""], ["Steeb", "Willi-Hans", ""], ["Stoop", "Ruedi", ""]]}, {"id": "1708.04232", "submitter": "Arash Rahnama", "authors": "Arash Rahnama, Abdullah Alchihabi, Vijay Gupta, Panos Antsaklis, Fatos\n  T. Yarman Vural", "title": "Encoding Multi-Resolution Brain Networks Using Unsupervised Deep\n  Learning", "comments": "6 pages, 3 figures, submitted to The 17th annual IEEE International\n  Conference on BioInformatics and BioEngineering", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this study is to extract a set of brain networks in multiple\ntime-resolutions to analyze the connectivity patterns among the anatomic\nregions for a given cognitive task. We suggest a deep architecture which learns\nthe natural groupings of the connectivity patterns of human brain in multiple\ntime-resolutions. The suggested architecture is tested on task data set of\nHuman Connectome Project (HCP) where we extract multi-resolution networks, each\nof which corresponds to a cognitive task. At the first level of this\narchitecture, we decompose the fMRI signal into multiple sub-bands using\nwavelet decompositions. At the second level, for each sub-band, we estimate a\nbrain network extracted from short time windows of the fMRI signal. At the\nthird level, we feed the adjacency matrices of each mesh network at each\ntime-resolution into an unsupervised deep learning algorithm, namely, a Stacked\nDe- noising Auto-Encoder (SDAE). The outputs of the SDAE provide a compact\nconnectivity representation for each time window at each sub-band of the fMRI\nsignal. We concatenate the learned representations of all sub-bands at each\nwindow and cluster them by a hierarchical algorithm to find the natural\ngroupings among the windows. We observe that each cluster represents a\ncognitive task with a performance of 93% Rand Index and 71% Adjusted Rand\nIndex. We visualize the mean values and the precisions of the networks at each\ncomponent of the cluster mixture. The mean brain networks at cluster centers\nshow the variations among cognitive tasks and the precision of each cluster\nshows the within cluster variability of networks, across the subjects.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 01:43:11 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Rahnama", "Arash", ""], ["Alchihabi", "Abdullah", ""], ["Gupta", "Vijay", ""], ["Antsaklis", "Panos", ""], ["Vural", "Fatos T. Yarman", ""]]}, {"id": "1708.04392", "submitter": "Pedro Mediano", "authors": "Pedro A.M. Mediano and Murray Shanahan", "title": "Balanced Information Storage and Transfer in Modular Spiking Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While information processing in complex systems can be described in abstract,\ngeneral terms, there are cases in which the relation between these computations\nand the physical substrate of the underlying system is itself of interest.\nProminently, the brain is one such case. With the aim of relating information\nand dynamics in biological neural systems, we study a model network of spiking\nneurons with different coupling configurations, and explore the relation\nbetween its informational, dynamical, and topological properties. We find that\ninformation transfer and storage peak at two separate points for different\nvalues of the coupling parameter, and are balanced at an intermediate point. In\nthis configuration, avalanches in the network follow a long-tailed, power\nlaw-like distribution. Furthermore, the avalanche statistics at this point\nreproduce empirical findings in the biological brain.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 04:16:54 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Mediano", "Pedro A. M.", ""], ["Shanahan", "Murray", ""]]}, {"id": "1708.04543", "submitter": "Sang-Yoon  Kim", "authors": "Sang-Yoon Kim and Woochang Lim", "title": "Effect of Spike-Timing-Dependent Plasticity on Stochastic Burst\n  Synchronization in A Scale-Free Neuronal Network", "comments": "arXiv admin note: substantial text overlap with arXiv:1704.03150", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider an excitatory population of subthreshold Izhikevich neurons which\ncannot fire spontaneously without noise. As the coupling strength passes a\nthreshold, individual neurons exhibit noise-induced burstings. This neuronal\npopulation has adaptive dynamic synaptic strengths governed by the\nspike-timing-dependent plasticity (STDP). In the absence of STDP, stochastic\nburst synchronization (SBS) between noise-induced burstings of subthreshold\nneurons was previously found to occur over a large range of intermediate noise\nintensities. Here, we study the effect of additive STDP on the SBS by varying\nthe noise intensity $D$ in the Barab\\'asi-Albert scale-free network (SFN) for\nthe case of symmetric preferential attachment. This type of SFN exhibits a\npower-law degree distribution, and hence it becomes an inhomogeneous one with a\nfew \"hubs\" (i.e., super-connected nodes). Occurrence of a \"Matthew\" effect in\nsynaptic plasticity is found to occur due to a positive feedback process. Good\nburst synchronization gets better via long-term potentiation (LTP) of synaptic\nstrengths, while bad burst synchronization gets worse via long-term depression\n(LTD). Consequently, a step-like rapid transition to SBS occurs by changing\n$D$, in contrast to a relatively smooth transition in the absence of STDP. In\nthe presence of additive STDP, we also investigate the effects of network\narchitecture on the SBS for a fixed $D$. Emergences of LTP and LTD of synaptic\nstrengths are investigated in details via microscopic studies based on both the\ndistributions of time delays between the burst onset times of the pre- and the\npost-synaptic neurons and the pair-correlations between the pre- and the\npost-synaptic IIBRs (instantaneous individual burst rates). Finally, a\nmultiplicative STDP case (depending on states) is also investigated in\ncomparison with the additive STDP case (independent of states).\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 04:19:25 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 07:39:28 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Kim", "Sang-Yoon", ""], ["Lim", "Woochang", ""]]}, {"id": "1708.04657", "submitter": "Dimitri Van De Ville", "authors": "Dimitri Van De Ville, Robin Demesmaeker, Maria Giulia Preti", "title": "Guiding Network Analysis using Graph Slepians: An Illustration for the\n  C. Elegans Connectome", "comments": "7 pages, 2 figures, Proceedings of the SPIE Wavelets & Sparsity XVII\n  (August 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral approaches of network analysis heavily rely upon the\neigendecomposition of the graph Laplacian. For instance, in graph signal\nprocessing, the Laplacian eigendecomposition is used to define the graph\nFourier transform and then transpose signal processing operations to graphs by\nimplementing them in the spectral domain. Here, we build on recent work that\ngeneralized Slepian functions to the graph setting. In particular, graph\nSlepians are band-limited graph signals with maximal energy concentration in a\ngiven subgraph. We show how this approach can be used to guide network\nanalysis; i.e., we propose a visualization that reveals network organization of\na subgraph, but while striking a balance with global network structure. These\ndevelopments are illustrated for the structural connectome of the C. Elegans.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 19:26:56 GMT"}, {"version": "v2", "created": "Fri, 18 Aug 2017 11:03:53 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Van De Ville", "Dimitri", ""], ["Demesmaeker", "Robin", ""], ["Preti", "Maria Giulia", ""]]}, {"id": "1708.04860", "submitter": "Ruben Van Bergen", "authors": "R.S. van Bergen, J.F.M. Jehee", "title": "Modeling correlated noise is necessary to decode uncertainty", "comments": null, "journal-ref": null, "doi": "10.1016/j.neuroimage.2017.08.015", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain decoding algorithms form an important part of the arsenal of analysis\ntools available to neuroscientists, allowing for a more detailed study of the\nkind of information represented in patterns of cortical activity. While most\ncurrent decoding algorithms focus on estimating a single, most likely stimulus\nfrom the pattern of noisy fMRI responses, the presence of noise causes this\nestimate to be uncertain. This uncertainty in stimulus estimates is a\npotentially highly relevant aspect of cortical stimulus processing, and\nfeatures prominently in Bayesian or probabilistic models of neural coding.\nHere, we focus on sensory uncertainty and how best to extract this information\nwith fMRI. We first demonstrate in simulations that decoding algorithms that\ntake into account correlated noise between fMRI voxels better recover the\namount of uncertainty (quantified as the width of a probability distribution\nover possible stimuli) associated with the decoded estimate. Furthermore, we\nshow that not all correlated variability should be treated equally, as modeling\ntuning-dependent correlations has the greatest impact on decoding performance.\nNext, we examine actual noise correlations in human visual cortex, and find\nthat shared variability in areas V1-V3 depends on the tuning properties of fMRI\nvoxels. In line with our simulations, accounting for this shared noise between\nsimilarly tuned voxels produces important benefits in decoding. Our findings\nunderscore the importance of accurate noise models in fMRI decoding approaches,\nand suggest a statistically feasible method to incorporate the most relevant\nforms of shared noise.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 12:41:34 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["van Bergen", "R. S.", ""], ["Jehee", "J. F. M.", ""]]}, {"id": "1708.05206", "submitter": "Mina Rezaei", "authors": "Mina Rezaei, Haojin Yang and Christoph Meinel", "title": "Brain Abnormality Detection by Deep Convolutional Neural Network", "comments": "Accepted for presenting in ACM-womENcourage_2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe our method for classification of brain magnetic\nresonance (MR) images into different abnormalities and healthy classes based on\nthe deep neural network. We propose our method to detect high and low-grade\nglioma, multiple sclerosis, and Alzheimer diseases as well as healthy cases.\nOur network architecture has ten learning layers that include seven\nconvolutional layers and three fully connected layers. We have achieved a\npromising result in five categories of brain images (classification task) with\n95.7% accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 11:24:58 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Rezaei", "Mina", ""], ["Yang", "Haojin", ""], ["Meinel", "Christoph", ""]]}, {"id": "1708.05282", "submitter": "Lara Escuain-Poole", "authors": "Lara Escuain-Poole, Jordi Garcia-Ojalvo, Antonio J. Pons", "title": "Extracranial estimation of neural mass model parameters using the\n  Unscented Kalman Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data assimilation, defined as the fusion of data with preexisting knowledge,\nis particularly suited to elucidating underlying phenomena from\nnoisy/insufficient observations. Although this approach has been widely used in\ndiverse fields, only recently have efforts been directed to problems in\nneuroscience, using mainly intracranial data and thus limiting its\napplicability to invasive measurements involving electrode implants. Here we\nintend to apply data assimilation to non-invasive electroencephalography (EEG)\nmeasurements to infer brain states and their characteristics. For this purpose,\nwe use Kalman filtering to combine synthetic EEG data with a coupled\nneural-mass model together with Ary's model of the head, which projects\nintracranial signals onto the scalp. Our results show that using several\nextracranial electrodes allows to successfully estimate the state and\nparameters of the neural masses and their interactions, whereas one single\nelectrode provides only a very partial and insufficient view of the system. The\nsuperiority of using multiple extracranial electrodes over using only one, be\nit intra- or extracranial, is shown over a wide variety of dynamical\nbehaviours. Our results show potential towards future clinical applications of\nthe method.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 17:33:58 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Escuain-Poole", "Lara", ""], ["Garcia-Ojalvo", "Jordi", ""], ["Pons", "Antonio J.", ""]]}, {"id": "1708.05614", "submitter": "Denis Boyer", "authors": "Andrea Falc\\'on-Cort\\'es, Denis Boyer, Luca Giuggioli, Satya N.\n  Majumdar", "title": "Localization transition induced by learning in random searches", "comments": "5 pages, 5 figures + 4 pages of Supplemental Information. Accepted in\n  Physical Review Letters", "journal-ref": "Phys. Rev. Lett. 119, 140603 (2017)", "doi": "10.1103/PhysRevLett.119.140603", "report-no": null, "categories": "cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We solve an adaptive search model where a random walker or L\\'evy flight\nstochastically resets to previously visited sites on a $d$-dimensional lattice\ncontaining one trapping site. Due to reinforcement, a phase transition occurs\nwhen the resetting rate crosses a threshold above which non-diffusive\nstationary states emerge, localized around the inhomogeneity. The threshold\ndepends on the trapping strength and on the walker's return probability in the\nmemoryless case. The transition belongs to the same class as the\nself-consistent theory of Anderson localization. These results show that\nsimilarly to many living organisms and unlike the well-studied Markovian walks,\nnon-Markov movement processes can allow agents to learn about their environment\nand promise to bring adaptive solutions in search tasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 13:56:02 GMT"}, {"version": "v2", "created": "Mon, 11 Sep 2017 17:02:06 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Falc\u00f3n-Cort\u00e9s", "Andrea", ""], ["Boyer", "Denis", ""], ["Giuggioli", "Luca", ""], ["Majumdar", "Satya N.", ""]]}, {"id": "1708.05774", "submitter": "Daniel Kepple", "authors": "Daniel Kepple and Alexei Koulakov", "title": "Constructing an olfactory perceptual space and predicting percepts from\n  molecular structure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the structure of a novel molecule, there is still no one who can\nreliably predict what odor percept that molecule will evoke. The challenge\ncomes from both the difficulty in quantitatively characterizing molecular\nstructure, and the inadequacy of language to fully characterize olfactory\nperception. Here, we present a novel approach to both problems.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 21:56:53 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 20:50:17 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Kepple", "Daniel", ""], ["Koulakov", "Alexei", ""]]}, {"id": "1708.05931", "submitter": "Roberto D. Pascual-Marqui", "authors": "Roberto D. Pascual-Marqui, Rolando J. Biscay, Jorge Bosch-Bayard,\n  Pascal Faber, Toshihiko Kinoshita, Kieko Kochi, Patricia Milz, Keiichiro\n  Nishida, Masafumi Yoshimura", "title": "Innovations orthogonalization: a solution to the major pitfalls of\n  EEG/MEG \"leakage correction\"", "comments": "preprint, technical report, under license\n  \"Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND\n  4.0)\", https://creativecommons.org/licenses/by-nc-nd/4.0/", "journal-ref": null, "doi": "10.1101/178657", "report-no": null, "categories": "stat.ME q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The problem of interest here is the study of brain functional and effective\nconnectivity based on non-invasive EEG-MEG inverse solution time series. These\nsignals generally have low spatial resolution, such that an estimated signal at\nany one site is an instantaneous linear mixture of the true, actual, unobserved\nsignals across all cortical sites. False connectivity can result from analysis\nof these low-resolution signals. Recent efforts toward \"unmixing\" have been\ndeveloped, under the name of \"leakage correction\". One recent noteworthy\napproach is that by Colclough et al (2015 NeuroImage, 117:439-448), which\nforces the inverse solution signals to have zero cross-correlation at lag zero.\nOne goal is to show that Colclough's method produces false human connectomes\nunder very broad conditions. The second major goal is to develop a new\nsolution, that appropriately \"unmixes\" the inverse solution signals, based on\ninnovations orthogonalization. The new method first fits a multivariate\nautoregression to the inverse solution signals, giving the mixed innovations.\nSecond, the mixed innovations are orthogonalized. Third, the mixed and\northogonalized innovations allow the estimation of the \"unmixing\" matrix, which\nis then finally used to \"unmix\" the inverse solution signals. It is shown that\nunder very broad conditions, the new method produces proper human connectomes,\neven when the signals are not generated by an autoregressive model.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 04:15:13 GMT"}, {"version": "v2", "created": "Wed, 23 Aug 2017 04:59:52 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Pascual-Marqui", "Roberto D.", ""], ["Biscay", "Rolando J.", ""], ["Bosch-Bayard", "Jorge", ""], ["Faber", "Pascal", ""], ["Kinoshita", "Toshihiko", ""], ["Kochi", "Kieko", ""], ["Milz", "Patricia", ""], ["Nishida", "Keiichiro", ""], ["Yoshimura", "Masafumi", ""]]}, {"id": "1708.06158", "submitter": "M\\\"ursel Karadas", "authors": "M\\\"ursel Karadas, Adam M. Wojciechowski, Alexander Huck, Nils Ole\n  Dalby, Ulrik Lund Andersen, Axel Thielscher", "title": "Opto-magnetic imaging of neural network activity in brain slices at high\n  resolution using color centers in diamond", "comments": "28 pages, 8 figures; SI 11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.med-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We suggest a novel approach for wide-field imaging of the neural network\ndynamics of brain slices that uses highly sensitivity magnetometry based on\nnitrogen-vacancy (NV) centers in diamond. In-vitro recordings in brain slices\nis a proven method for the characterization of electrical neural activity and\nhas strongly contributed to our understanding of the mechanisms that govern\nneural information processing. However, traditional recordings can only acquire\nsignals from a few positions simultaneously, which severely limits their\nability to characterize the dynamics of the underlying neural networks. We\nsuggest to radically extend the scope of this method using the wide-field\nimaging of the neural magnetic fields across the slice by means of NV\nmagnetometry. Employing comprehensive computational simulations and theoretical\nanalyses, we characterize the spatiotemporal characteristics of the neural\nmagnetic fields and derive the required key performance parameters of an\nimaging setup based on NV magnetometry. In particular, we determine how the\ntechnical parameters determine the achievable spatial resolution for an optimal\nreconstruction of the neural currents from the measured field distributions.\nFinally, we compare the imaging of neural slice activity with that of a single\nplanar pyramidal cell. Our results suggest that imaging of neural slice\nactivity will be possible with the upcoming generation of NV magnetic field\nsensors, while imaging of the activity of a single planar cell remains more\nchallenging.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 11:36:54 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Karadas", "M\u00fcrsel", ""], ["Wojciechowski", "Adam M.", ""], ["Huck", "Alexander", ""], ["Dalby", "Nils Ole", ""], ["Andersen", "Ulrik Lund", ""], ["Thielscher", "Axel", ""]]}, {"id": "1708.06544", "submitter": "Zurab Silagadze", "authors": "Mariam M. Morchiladze, Tamila K. Silagadze, Zurab K. Silagadze", "title": "Visceral theory of sleep and origins of mental disorders", "comments": "19 pages, 1 figure, published version", "journal-ref": "Medical Hypotheses 120 (2018), 22-27", "doi": "10.1016/j.mehy.2018.07.023", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visceral theory of sleep states that the same brain neurons, which process\nexternal information in wakefulness, during sleep switch to the processing of\ninternal information coming from various visceral systems. Here we hypothesize\nthat a failure in the commutation of exteroceptive and interoceptive\ninformation flows in the brain can manifest itself as a mental illness.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 09:05:14 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 08:41:02 GMT"}], "update_date": "2018-08-23", "authors_parsed": [["Morchiladze", "Mariam M.", ""], ["Silagadze", "Tamila K.", ""], ["Silagadze", "Zurab K.", ""]]}, {"id": "1708.06578", "submitter": "Dalin Zhang", "authors": "Dalin Zhang, Lina Yao, Xiang Zhang, Sen Wang, Weitong Chen, Robert\n  Boots", "title": "Cascade and Parallel Convolutional Recurrent Neural Networks on\n  EEG-based Intention Recognition for Brain Computer Interface", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-Computer Interface (BCI) is a system empowering humans to communicate\nwith or control the outside world with exclusively brain intentions.\nElectroencephalography (EEG) based BCIs are promising solutions due to their\nconvenient and portable instruments. Motor imagery EEG (MI-EEG) is a kind of\nmost widely focused EEG signals, which reveals a subjects movement intentions\nwithout actual actions. Despite the extensive research of MI-EEG in recent\nyears, it is still challenging to interpret EEG signals effectively due to the\nmassive noises in EEG signals (e.g., low signal noise ratio and incomplete EEG\nsignals), and difficulties in capturing the inconspicuous relationships between\nEEG signals and certain brain activities. Most existing works either only\nconsider EEG as chain-like sequences neglecting complex dependencies between\nadjacent signals or performing simple temporal averaging over EEG sequences. In\nthis paper, we introduce both cascade and parallel convolutional recurrent\nneural network models for precisely identifying human intended movements by\neffectively learning compositional spatio-temporal representations of raw EEG\nstreams. The proposed models grasp the spatial correlations between physically\nneighboring EEG signals by converting the chain like EEG sequences into a 2D\nmesh like hierarchy. An LSTM based recurrent network is able to extract the\nsubtle temporal dependencies of EEG data streams. Extensive experiments on a\nlarge-scale MI-EEG dataset (108 subjects, 3,145,160 EEG records) have\ndemonstrated that both models achieve high accuracy near 98.3% and outperform a\nset of baseline methods and most recent deep learning based EEG recognition\nmodels, yielding a significant accuracy increase of 18% in the cross-subject\nvalidation scenario.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 12:21:21 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 14:42:54 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Zhang", "Dalin", ""], ["Yao", "Lina", ""], ["Zhang", "Xiang", ""], ["Wang", "Sen", ""], ["Chen", "Weitong", ""], ["Boots", "Robert", ""]]}, {"id": "1708.06597", "submitter": "Antonio Bianconi Prof.", "authors": "Michael Di Gioacchino, Gaetano Campi, Nicola Poccia, Antonio Bianconi", "title": "Correlated disorder in myelinated axons orientational geometry and\n  structure", "comments": "9 pages, 4 figures", "journal-ref": "Condens. Matter 2(3), 29 (2017)", "doi": "10.3390/condmat2030029", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the ultrastructure of the myelin has been considered to be a\nquasi-crystalline stable system, nowadays its multiscale complex dynamics\nappears to play a key role for its functionality, degeneration and repair\nprocesses following neurological diseases and trauma. In this work, we have\ninvestigated the axons interactions associated to the nerve functionality,\nmeasuring the spatial distribution of the orientational fluctuations of axons\nin a Xenopus Laevis sciatic nerve. At this aim, we have used Scanning micro\nX-ray Diffraction (SmXRD), a non-invasive already applied to other\nheterogeneous systems presenting complex geometries from microscale to\nnanoscale. We have found that the orientational spatial fluctuations of fresh\naxons show a correlated disorder described by Levy flight distribution. Thus,\nwe have studied how this correlated disorder evolves during the degeneration of\nthe nerve. Our results show that the spatial distribution of axons\norientational fluctuations in unfresh, aged nerve loose the correlated disorder\nassuming a randomly disordered behaviour. This work allows a deeper\nunderstanding of nerve states and paves the way to study other materials and\nbiomaterials with the same technique to detect and to characterize their states\nand supramolecular structure, associated with dynamic structural changes at the\nnanoscale and mesoscale.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 13:33:00 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 06:15:49 GMT"}], "update_date": "2017-09-20", "authors_parsed": [["Di Gioacchino", "Michael", ""], ["Campi", "Gaetano", ""], ["Poccia", "Nicola", ""], ["Bianconi", "Antonio", ""]]}, {"id": "1708.06641", "submitter": "Adam Noel", "authors": "Adam Noel, Dimitrios Makrakis, Andrew W. Eckford", "title": "Distortion Distribution of Neural Spike Train Sequence Matching with\n  Optogenetics", "comments": "13 pages, 10 figures. To appear in IEEE Transactions on Biomedical\n  Engineering. A conference version, which was presented at 2017 IEEE Globecom,\n  can be found at arXiv:1704.04795", "journal-ref": null, "doi": "10.1109/TBME.2018.2819200", "report-no": null, "categories": "q-bio.NC cs.IT math.IT physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses a simple optogenetic model to compare the timing distortion\nbetween a randomly-generated target spike sequence and an externally-stimulated\nneuron spike sequence. Optogenetics is an emerging field of neuroscience where\nneurons are genetically modified to express light-sensitive receptors that\nenable external control over when the neurons fire. Given the prominence of\nneuronal signaling within the brain and throughout the body, optogenetics has\nsignificant potential to improve the understanding of the nervous system and to\ndevelop treatments for neurological diseases. This paper primarily considers\ntwo different distortion measures. The first measure is the delay in\nexternally-stimulated spikes. The second measure is the root mean square error\nbetween the filtered outputs of the target and stimulated spike sequences. The\nmean and the distribution of the distortion is derived in closed form when the\ntarget sequence generation rate is sufficiently low. All derived results are\nsupported with simulations. This work is a step towards an analytical model to\npredict whether different spike trains were observed from the same stimulus,\nand the broader goal of understanding the quantity and reliability of\ninformation that can be carried by neurons.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 14:30:13 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 10:09:18 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Noel", "Adam", ""], ["Makrakis", "Dimitrios", ""], ["Eckford", "Andrew W.", ""]]}, {"id": "1708.07046", "submitter": "Diego Garlaschelli", "authors": "Assaf Almog, Ori Roethler, Renate Buijink, Stephan Michel, Johanna H\n  Meijer, Jos H. T. Rohling, and Diego Garlaschelli", "title": "Uncovering functional brain signature via random matrix theory", "comments": null, "journal-ref": "PLoS Computational Biology 15(5): e1006934 (2019)", "doi": "10.1371/journal.pcbi.1006934", "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain is organized in a modular way, serving multiple functionalities.\nThis multiplicity requires that both positive (e.g. excitatory, phase-coherent)\nand negative (e.g. inhibitory, phase-opposing) interactions take place across\nbrain modules. Unfortunately, most methods to detect modules from time series\neither neglect or convert to positive any measured negative correlation. This\nmay leave a significant part of the sign-dependent functional structure\nundetected. Here we present a novel method, based on random matrix theory, for\nthe identification of sign-dependent modules in the brain. Our method filters\nout the joint effects of local (unit-specific) noise and global (system-wide)\ndependencies that empirically obfuscate such structure. The method is\nguaranteed to identify an optimally contrasted functional `signature', i.e. a\npartition into modules that are positively correlated internally and negatively\ncorrelated across. The method is purely data-driven, does not use any arbitrary\nthreshold or network projection, and outputs only statistically significant\nstructure. In measurements of neuronal gene expression in the biological clock\nof mice, the method systematically uncovers two otherwise undetectable,\nnegatively correlated modules whose relative size and mutual interaction\nstrength are found to depend on photoperiod. The neurons alternating between\nthe two modules define a candidate region of functional plasticity for\ncircadian modulation.\n", "versions": [{"version": "v1", "created": "Sat, 5 Aug 2017 05:50:45 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 09:41:30 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Almog", "Assaf", ""], ["Roethler", "Ori", ""], ["Buijink", "Renate", ""], ["Michel", "Stephan", ""], ["Meijer", "Johanna H", ""], ["Rohling", "Jos H. T.", ""], ["Garlaschelli", "Diego", ""]]}, {"id": "1708.07508", "submitter": "Eero Satuvuori", "authors": "Eero Satuvuori and Thomas Kreuz", "title": "Which spike train distance is most suitable for distinguishing rate and\n  temporal coding?", "comments": "14 pages, 6 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: It is commonly assumed in neuronal coding that repeated\npresentations of a stimulus to a coding neuron elicit similar responses. One\ncommon way to assess similarity are spike train distances. These can be divided\ninto spike-resolved, such as the Victor-Purpura and the van Rossum distance,\nand time-resolved, e.g. the ISI-, the SPIKE- and the RI-SPIKE-distance.\n  New Method: We use independent steady-rate Poisson processes as surrogates\nfor spike trains with fixed rate and no timing information to address two basic\nquestions: How does the sensitivity of the different spike train distances to\ntemporal coding depend on the rates of the two processes and how do the\ndistances deal with very low rates?\n  Results: Spike-resolved distances always contain rate information even for\nparameters indicating time coding. This is an issue for reasonably high rates\nbut beneficial for very low rates. In contrast, the operational range for\ndetecting time coding of time-resolved distances is superior at normal rates,\nbut these measures produce artefacts at very low rates. The RI-SPIKE-distance\nis the only measure that is sensitive to timing information only.\n  Comparison with Existing Methods: While our results on rate-dependent\nexpectation values for the spike-resolved distances agree with\n\\citet{Chicharro11}, we here go one step further and specifically investigate\napplicability for very low rates.\n  Conclusions: The most appropriate measure depends on the rates of the data\nbeing analysed. Accordingly, we summarize our results in one table that allows\nan easy selection of the preferred measure for any kind of data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 21:53:15 GMT"}, {"version": "v2", "created": "Tue, 7 Nov 2017 18:14:38 GMT"}, {"version": "v3", "created": "Wed, 21 Feb 2018 08:29:15 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Satuvuori", "Eero", ""], ["Kreuz", "Thomas", ""]]}, {"id": "1708.07958", "submitter": "Richard Betzel", "authors": "Richard F. Betzel, Danielle S. Bassett", "title": "Generative Models for Network Neuroscience: Prospects and Promise", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network neuroscience is the emerging discipline concerned with investigating\nthe complex patterns of interconnections found in neural systems, and to\nidentify principles with which to understand them. Within this discipline, one\nparticularly powerful approach is network generative modeling, in which wiring\nrules are algorithmically implemented to produce synthetic network\narchitectures with the same properties as observed in empirical network data.\nSuccessful models can highlight the principles by which a network is organized\nand potentially uncover the mechanisms by which it grows and develops. Here we\nreview the prospects and promise of generative models for network neuroscience.\nWe begin with a primer on network generative models, with a discussion of\ncompressibility and predictability, utility in intuiting mechanisms, and a\nshort history on their use in network science broadly. We then discuss\ngenerative models in practice and application, paying particular attention to\nthe critical need for cross-validation. Next, we review generative models of\nbiological neural networks, both at the cellular and large-scale level, and\nacross a variety of species including \\emph{C. elegans}, \\emph{Drosophila},\nmouse, rat, cat, macaque, and human. We offer a careful treatment of a few\nrelevant distinctions, including differences between generative models and null\nmodels, sufficiency and redundancy, inferring and claiming mechanism, and\nfunctional and structural connectivity. We close with a discussion of future\ndirections, outlining exciting frontiers both in empirical data collection\nefforts as well as in method and theory development that, together, further the\nutility of the generative network modeling approach for network neuroscience.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 11:30:35 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Betzel", "Richard F.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1708.08006", "submitter": "Gwyneth Rolph", "authors": "Gwyneth Wesley Rolph", "title": "Effects of mindfulness on perceived stress levels and heart rate\n  variability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mindfulness has become increasingly popular as a method for building\nresilience against stress in both clinical and healthy populations. This study\nsought to investigate the effects of mindfulness training on perceived levels\nof stress and heart rate variability in students.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 18:29:50 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Rolph", "Gwyneth Wesley", ""]]}, {"id": "1708.08133", "submitter": "Aaron Voelker", "authors": "Aaron R. Voelker and Chris Eliasmith", "title": "Methods for applying the Neural Engineering Framework to neuromorphic\n  hardware", "comments": "11 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.SY math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review our current software tools and theoretical methods for applying the\nNeural Engineering Framework to state-of-the-art neuromorphic hardware. These\nmethods can be used to implement linear and nonlinear dynamical systems that\nexploit axonal transmission time-delays, and to fully account for nonideal\nmixed-analog-digital synapses that exhibit higher-order dynamics with\nheterogeneous time-constants. This summarizes earlier versions of these methods\nthat have been discussed in a more biological context (Voelker & Eliasmith,\n2017) or regarding a specific neuromorphic architecture (Voelker et al., 2017).\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 20:27:01 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Voelker", "Aaron R.", ""], ["Eliasmith", "Chris", ""]]}, {"id": "1708.08672", "submitter": "Ernest Montbrio", "authors": "Jose M. Esnaola-Acebes, Alex Roxin, Daniele Avitabile, Ernest\n  Montbri\\'o", "title": "Synchrony-induced modes of oscillation of a neural field model", "comments": null, "journal-ref": "Phys. Rev. E 96, 052407 (2017)", "doi": "10.1103/PhysRevE.96.052407", "report-no": null, "categories": "q-bio.NC nlin.CD nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the modes of oscillation of heterogeneous ring-networks of\nquadratic integrate-and-fire neurons with non-local, space-dependent coupling.\nPerturbations of the equilibrium state with a particular wave number produce\ntransient standing waves with a specific frequency, analogous to those in a\ntense string. In the neuronal network, the equilibrium corresponds to a\nspatially homogeneous, asynchronous state. Perturbations of this state excite\nthe network's oscillatory modes, which reflect the interplay of episodes of\nsynchronous spiking with the excitatory-inhibitory spatial interactions. In the\nthermodynamic limit, an exact low-dimensional neural field model describing the\nmacroscopic dynamics of the network is derived. This allows us to obtain\nformulas for the Turing eigenvalues of the spatially-homogeneous state, and\nhence to obtain its stability boundary. We find that the frequency of each\nTuring mode depends on the corresponding Fourier coefficient of the synaptic\npattern of connectivity. The decay rate instead, is identical for all\noscillation modes as a consequence of the heterogeneity-induced\ndesynchronization of the neurons. Finally, we numerically compute the spectrum\nof spatially-inhomogeneous solutions branching from the Turing bifurcation,\nshowing that similar oscillatory modes operate in neural bump states, and are\nmaintained away from onset.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 09:59:14 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Esnaola-Acebes", "Jose M.", ""], ["Roxin", "Alex", ""], ["Avitabile", "Daniele", ""], ["Montbri\u00f3", "Ernest", ""]]}, {"id": "1708.08755", "submitter": "Daniel Lopez Martinez", "authors": "Daniel Lopez-Martinez, Rosalind Picard", "title": "Multi-task Neural Networks for Personalized Pain Recognition from\n  Physiological Signals", "comments": "2017 Seventh International Conference on Affective Computing and\n  Intelligent Interaction Workshops and Demos (ACIIW), 1st Workshop on Tools\n  and Algorithms for Mental Health and Wellbeing, Pain, and Distress (MHWPD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pain is a complex and subjective experience that poses a number of\nmeasurement challenges. While self-report by the patient is viewed as the gold\nstandard of pain assessment, this approach fails when patients cannot verbally\ncommunicate pain intensity or lack normal mental abilities. Here, we present a\npain intensity measurement method based on physiological signals. Specifically,\nwe implement a multi-task learning approach based on neural networks that\naccounts for individual differences in pain responses while still leveraging\ndata from across the population. We test our method in a dataset containing\nmulti-modal physiological responses to nociceptive pain.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 05:38:56 GMT"}, {"version": "v2", "created": "Mon, 4 Sep 2017 19:23:11 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Lopez-Martinez", "Daniel", ""], ["Picard", "Rosalind", ""]]}, {"id": "1708.08887", "submitter": "Parisa Zarkeshian", "authors": "Parisa Zarkeshian, Sourabh Kumar, Jack Tuszynski, Paul Barclay,\n  Christoph Simon", "title": "Are there optical communication channels in the brain?", "comments": "13 pages, 5 figures, review of arXiv:1607.02969 for Frontiers in\n  Bioscience, updated figures, new references on existence of opsins in the\n  brain and experimental effects of light on neurons", "journal-ref": "Front Biosci (Landmark Ed), 23, 1407-1421 (2018)", "doi": "10.2741/4652", "report-no": null, "categories": "physics.bio-ph physics.optics q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite great progress in neuroscience, there are still fundamental\nunanswered questions about the brain, including the origin of subjective\nexperience and consciousness. Some answers might rely on new physical\nmechanisms. Given that biophotons have been discovered in the brain, it is\ninteresting to explore if neurons use photonic communication in addition to the\nwell-studied electro-chemical signals. Such photonic communication in the brain\nwould require waveguides. Here we review recent work [S. Kumar, K. Boone, J.\nTuszynski, P. Barclay, and C. Simon, Scientific Reports 6, 36508 (2016)]\nsuggesting that myelinated axons could serve as photonic waveguides. The light\ntransmission in the myelinated axon was modeled, taking into account its\nrealistic imperfections, and experiments were proposed both in-vivo and\nin-vitro to test this hypothesis. Potential implications for quantum biology\nare discussed.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 22:54:52 GMT"}], "update_date": "2021-04-19", "authors_parsed": [["Zarkeshian", "Parisa", ""], ["Kumar", "Sourabh", ""], ["Tuszynski", "Jack", ""], ["Barclay", "Paul", ""], ["Simon", "Christoph", ""]]}, {"id": "1708.09042", "submitter": "Fabrizio Lombardi", "authors": "Fabrizio Lombardi, Hans J. Herrmann, Lucilla de Arcangelis", "title": "Balance of excitation and inhibition determines 1/f power spectrum in\n  neuronal networks", "comments": null, "journal-ref": "Chaos 27, 047402 (2017)", "doi": "10.1063/1.4979043", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The $1/f$-like decay observed in the power spectrum of electro-physiological\nsignals, along with scale-free statistics of the so-called neuronal avalanches,\nconstitute evidences of criticality in neuronal systems. Recent in vitro\nstudies have shown that avalanche dynamics at criticality corresponds to some\nspecific balance of excitation and inhibition, thus suggesting that this is a\nbasic feature of the critical state of neuronal networks. In particular, a lack\nof inhibition significantly alters the temporal structure of the spontaneous\navalanche activity and leads to an anomalous abundance of large avalanches.\nHere we study the relationship between network inhibition and the scaling\nexponent $\\beta$ of the power spectral density (PSD) of avalanche activity in a\nneuronal network model inspired in Self-Organized Criticality (SOC). We find\nthat this scaling exponent depends on the percentage of inhibitory synapses and\ntends to the value $\\beta = 1$ for a percentage of about 30%. More\nspecifically, $\\beta$ is close to $2$, namely brownian noise, for purely\nexcitatory networks and decreases towards values in the interval $[1,1.4]$ as\nthe percentage of inhibitory synapses ranges between 20 and 30%, in agreement\nwith experimental findings. These results indicate that the level of inhibition\naffects the frequency spectrum of resting brain activity and suggest the\nanalysis of the PSD scaling behavior as a possible tool to study pathological\nconditions.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 21:54:17 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Lombardi", "Fabrizio", ""], ["Herrmann", "Hans J.", ""], ["de Arcangelis", "Lucilla", ""]]}, {"id": "1708.09072", "submitter": "Toby Lightheart", "authors": "Toby Lightheart, Steven Grainger, Tien-Fu Lu", "title": "Continual One-Shot Learning of Hidden Spike-Patterns with Neural Network\n  Simulation Expansion and STDP Convergence Predictions", "comments": "41 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a constructive algorithm that achieves successful\none-shot learning of hidden spike-patterns in a competitive detection task. It\nhas previously been shown (Masquelier et al., 2008) that spike-timing-dependent\nplasticity (STDP) and lateral inhibition can result in neurons competitively\ntuned to repeating spike-patterns concealed in high rates of overall\npresynaptic activity. One-shot construction of neurons with synapse weights\ncalculated as estimates of converged STDP outcomes results in immediate\nselective detection of hidden spike-patterns. The capability of continual\nlearning is demonstrated through the successful one-shot detection of new sets\nof spike-patterns introduced after long intervals in the simulation time.\nSimulation expansion (Lightheart et al., 2013) has been proposed as an approach\nto the development of constructive algorithms that are compatible with\nsimulations of biological neural networks. A simulation of a biological neural\nnetwork may have orders of magnitude fewer neurons and connections than the\nrelated biological neural systems; therefore, simulated neural networks can be\nassumed to be a subset of a larger neural system. The constructive algorithm is\ndeveloped using simulation expansion concepts to perform an operation\nequivalent to the exchange of neurons between the simulation and the larger\nhypothetical neural system. The dynamic selection of neurons to simulate within\na larger neural system (hypothetical or stored in memory) may be a starting\npoint for a wide range of developments and applications in machine learning and\nthe simulation of biology.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 01:07:18 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Lightheart", "Toby", ""], ["Grainger", "Steven", ""], ["Lu", "Tien-Fu", ""]]}]