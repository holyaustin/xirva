[{"id": "1711.00193", "submitter": "Eli Shlizerman", "authors": "Hexuan Liu, Jimin Kim and Eli Shlizerman", "title": "Functional Connectomics from Data: Probabilistic Graphical Models for\n  Neuronal Network of C. elegans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a data-driven approach to represent neuronal network dynamics as a\nProbabilistic Graphical Model (PGM). Our approach learns the PGM structure by\nemploying dimension reduction to network response dynamics evoked by stimuli\napplied to each neuron separately. The outcome model captures how stimuli\npropagate through the network and thus represents functional dependencies\nbetween neurons, i.e., functional connectome. The benefit of using a PGM as the\nfunctional connectome is that posterior inference can be done efficiently and\ncircumvent the complexities in direct inference of response pathways in dynamic\nneuronal networks. In particular, posterior inference reveals the relations\nbetween known stimuli and downstream neurons or allows to query which stimuli\nare associated with downstream neurons. For validation and as an example for\nour approach we apply our methodology to a model of Caenorhabiditis elegans\nnervous system which structure and dynamics are well-studied. From its\ndynamical model we collect time series of the network response and use singular\nvalue decomposition to obtain a low-dimensional projection of the time series\ndata. We then extract dominant patterns in each data matrix to get pairwise\ndependency information and create a graphical model for the full somatic\nnervous system. The PGM enables us to obtain and verify underlying neuronal\npathways dominant for known behavioral scenarios and to detect possible\npathways for novel scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 03:43:52 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Liu", "Hexuan", ""], ["Kim", "Jimin", ""], ["Shlizerman", "Eli", ""]]}, {"id": "1711.00418", "submitter": "Ehtibar Dzhafarov", "authors": "Victor H. Cervantes and Ehtibar N. Dzhafarov", "title": "Snow Queen is Evil and Beautiful: Experimental Evidence for\n  Probabilistic Contextuality in Human Choices", "comments": "To be published in Decision. 12 pp., 6 figures, 4 tables; Version 8\n  is the proofread-for-pubpication version", "journal-ref": "Decision 5, 193-204, 2018", "doi": null, "report-no": null, "categories": "q-bio.NC math.PR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present unambiguous experimental evidence for (quantum-like) probabilistic\ncontextuality in psychology. All previous attempts to find contextuality in a\npsychological experiment were unsuccessful because of the gross violations of\nmarginal selectivity in behavioral data, making the traditional mathematical\ntests developed in quantum mechanics inapplicable. In our crowdsourcing\nexperiment respondents were making two simple choices: of one of two characters\nin a story (The Snow Queen by Hans Christian Andersen), and of one of two\ncharacteristics, such as Kind and Evil, so that the character and the\ncharacteristic chosen matched the story line. The formal structure of the\nexperiment imitated that of the Einstein-Podolsky-Rosen paradigm in the\nBohm-Bell version. Marginal selectivity was violated, indicating that the two\nchoices were directly influencing each other, but the application of a\nmathematical test developed in the Contextuality-by-Default theory, extending\nthe traditional quantum-mechanical test, indicated a strong presence of\ncontextuality proper, not reducible to direct influences.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 16:16:39 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 14:46:06 GMT"}, {"version": "v3", "created": "Thu, 9 Nov 2017 03:23:22 GMT"}, {"version": "v4", "created": "Mon, 13 Nov 2017 16:47:37 GMT"}, {"version": "v5", "created": "Mon, 18 Dec 2017 09:59:14 GMT"}, {"version": "v6", "created": "Fri, 29 Dec 2017 04:54:56 GMT"}, {"version": "v7", "created": "Thu, 18 Jan 2018 22:49:23 GMT"}, {"version": "v8", "created": "Wed, 21 Mar 2018 02:50:45 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Cervantes", "Victor H.", ""], ["Dzhafarov", "Ehtibar N.", ""]]}, {"id": "1711.00526", "submitter": "Jesus Malo", "authors": "Marina Martinez-Garcia, Praveen Cyriac, Thomas Batard, Marcelo\n  Bertalmio and Jesus Malo", "title": "Derivatives and Inverse of Cascaded Linear+Nonlinear Neural Models", "comments": "Reproducible results: associated Matlab toolbox available at\n  http://isp.uv.es/docs/BioMultiLayer_L_NL.zip", "journal-ref": null, "doi": "10.1371/journal.pone.0201326", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vision science, cascades of Linear+Nonlinear transforms are very\nsuccessful in modeling a number of perceptual experiences [Carandini&Heeger12].\nHowever, the conventional literature is usually too focused on only describing\nthe input->output transform.\n  Instead, here we present the maths of such cascades beyond the forward\ntransform, namely the Jacobians and the inverse. The fundamental reason for\nthis analytical treatment is that it offers useful insight into the\npsychophysics, the physiology, and the function of the visual system. For\ninstance, we show how the trends of the sensitivity (discrimination regions)\nand the adaptation of the receptive fields can be seen in the expression of the\nJacobian wrt the stimulus. This matrix also tells us which regions of the\nstimulus space are encoded more efficiently in multi-information terms. The\nJacobian wrt the parameters shows which aspects of the model have bigger impact\nin the response, and hence bigger relevance. The analytic inverse implies\nconditions for the response and the model to ensure decoding. From an applied\nperspective, (a) the Jacobian wrt the stimulus is necessary in new experimental\nmethods based on the synthesis of visual stimuli with interesting geometry, (b)\nthe Jacobian matrices wrt the parameters are convenient to learn the model from\nclassical experiments or alternative optimization goals, and (c) the inverse is\na model-based alternative to blind machine-learning neural decoding that does\nnot include meaningful biological information.\n  The theory is checked by building a derivable and invertible vision model\nthat actually follows the modular program suggested by Carandini&Heeger. To\nstress the generality of this modular setting we show examples where some of\nthe canonical Divisive Normalization layers are substituted by equivalent\nlayers such as the Wilson-Cowan model at V1, or a tone-mapping model at the\nretina.\n", "versions": [{"version": "v1", "created": "Wed, 1 Nov 2017 20:07:37 GMT"}, {"version": "v2", "created": "Sun, 26 Nov 2017 19:01:15 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 12:06:41 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Martinez-Garcia", "Marina", ""], ["Cyriac", "Praveen", ""], ["Batard", "Thomas", ""], ["Bertalmio", "Marcelo", ""], ["Malo", "Jesus", ""]]}, {"id": "1711.00629", "submitter": "Xin Zhang", "authors": "Xin Zhang, Weixuan Kou, Eric I-Chao Chang, He Gao, Yubo Fan and Yan Xu", "title": "Sleep Stage Classification Based on Multi-level Feature Learning and\n  Recurrent Neural Networks via Wearable Device", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a practical approach for automatic sleep stage\nclassification based on a multi-level feature learning framework and Recurrent\nNeural Network (RNN) classifier using heart rate and wrist actigraphy derived\nfrom a wearable device. The feature learning framework is designed to extract\nlow- and mid-level features. Low-level features capture temporal and frequency\ndomain properties and mid-level features learn compositions and structural\ninformation of signals. Since sleep staging is a sequential problem with\nlong-term dependencies, we take advantage of RNNs with Bidirectional Long\nShort-Term Memory (BLSTM) architectures for sequence data learning. To simulate\nthe actual situation of daily sleep, experiments are conducted with a resting\ngroup in which sleep is recorded in resting state, and a comprehensive group in\nwhich both resting sleep and non-resting sleep are included.We evaluate the\nalgorithm based on an eight-fold cross validation to classify five sleep stages\n(W, N1, N2, N3, and REM). The proposed algorithm achieves weighted precision,\nrecall and F1 score of 58.0%, 60.3%, and 58.2% in the resting group and 58.5%,\n61.1%, and 58.5% in the comprehensive group, respectively. Various comparison\nexperiments demonstrate the effectiveness of feature learning and BLSTM. We\nfurther explore the influence of depth and width of RNNs on performance. Our\nmethod is specially proposed for wearable devices and is expected to be\napplicable for long-term sleep monitoring at home. Without using too much prior\ndomain knowledge, our method has the potential to generalize sleep disorder\ndetection.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 06:28:45 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Zhang", "Xin", ""], ["Kou", "Weixuan", ""], ["Chang", "Eric I-Chao", ""], ["Gao", "He", ""], ["Fan", "Yubo", ""], ["Xu", "Yan", ""]]}, {"id": "1711.00698", "submitter": "Benoit Girard", "authors": "Guillaume Viejo (ISIR), Beno\\^it Girard (ISIR), Emmanuel Procyk, Mehdi\n  Khamassi (ISIR)", "title": "Adaptive coordination of working-memory and reinforcement learning in\n  non-human primates performing a trial-and-error problem solving task", "comments": "Behavioural Brain Research, Elsevier, 2017", "journal-ref": null, "doi": "10.1016/j.bbr.2017.09.030", "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accumulating evidence suggest that human behavior in trial-and-error learning\ntasks based on decisions between discrete actions may involve a combination of\nreinforcement learning (RL) and working-memory (WM). While the understanding of\nbrain activity at stake in this type of tasks often involve the comparison with\nnon-human primate neurophysiological results, it is not clear whether monkeys\nuse similar combined RL and WM processes to solve these tasks. Here we analyzed\nthe behavior of five monkeys with computational models combining RL and WM. Our\nmodel-based analysis approach enables to not only fit trial-by-trial choices\nbut also transient slowdowns in reaction times, indicative of WM use. We found\nthat the behavior of the five monkeys was better explained in terms of a\ncombination of RL and WM despite inter-individual differences. The same\ncoordination dynamics we used in a previous study in humans best explained the\nbehavior of some monkeys while the behavior of others showed the opposite\npattern, revealing a possible different dynamics of WM process. We further\nanalyzed different variants of the tested models to open a discussion on how\nthe long pretraining in these tasks may have favored particular coordination\ndynamics between RL and WM. This points towards either inter-species\ndifferences or protocol differences which could be further tested in humans.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 11:53:54 GMT"}], "update_date": "2019-04-30", "authors_parsed": [["Viejo", "Guillaume", "", "ISIR"], ["Girard", "Beno\u00eet", "", "ISIR"], ["Procyk", "Emmanuel", "", "ISIR"], ["Khamassi", "Mehdi", "", "ISIR"]]}, {"id": "1711.00747", "submitter": "Takahiro Wada", "authors": "Takahiro Wada, Satoru Fujisawa, Shunichi Doi", "title": "Analysis of Driver's Head Tilt Using a Mathematical Model of Motion\n  Sickness", "comments": null, "journal-ref": "International Journal of Industrial Ergonomics, 2017", "doi": "10.1016/j.ergon.2016.11.003", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that car drivers tilt their head toward the center of a curve. In\naddition, drivers are generally less susceptible to carsickness than are the\npassengers. This paper uses a mathematical model to investigate the effect of\nthe head-tilt strategy on motion sickness. It is shown that tilting the head in\nthe centripetal direction reduces the estimated motion sickness incidence\n(MSI), defined as the percentage of subjects who vomited. In addition, the head\nmovements of both drivers and passengers were measured in a real car. It is\nalso shown that the estimated MSI of the drivers is smaller than that of the\npassengers. Experimental results presented in previous studies demonstrated\nthat the severity of motion sickness was reduced when passengers imitated the\nhead tilt of the driver. These results strongly suggest that the driver's head\ntilt reduces motion sickness, and this can be understood as a subjective\nvertical conflict.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 14:00:21 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Wada", "Takahiro", ""], ["Fujisawa", "Satoru", ""], ["Doi", "Shunichi", ""]]}, {"id": "1711.00773", "submitter": "Takahiro Wada", "authors": "Takahiro Wada, Keigo Yoshida", "title": "Effect of passengers' active head tilt and opening/closure of eyes on\n  motion sickness in lateral acceleration environment of cars", "comments": null, "journal-ref": "Ergonomics, 2016", "doi": "10.1080/00140139.2015.1109713", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study examined the effect of passengers' active head-tilt and\neyes-open/closed conditions on the severity of motion sickness in the lateral\nacceleration environment of cars. In the centrifugal head-tilt condition,\nparticipants intentionally tilted their heads towards the centrifugal force,\nwhereas in the centripetal head-tilt condition, the participants tilted their\nheads against the centrifugal acceleration. The eyes-open and eyes-closed cases\nwere investigated for each head-tilt condition. In the experimental runs, the\nsickness rating in the centripetal head-tilt condition was significantly lower\nthan that in the centrifugal head-tilt condition. Moreover, the sickness rating\nin the eyes-open condition was significantly lower than that in the eyes-closed\ncondition. The results suggest that an active head-tilt motion against the\ncentrifugal acceleration reduces the severity of motion sickness both in the\neyes-open and eyes-closed conditions. They also demonstrate that the eyes-open\ncondition significantly reduces the motion sickness even when the head-tilt\nstrategy is used.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 15:01:01 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Wada", "Takahiro", ""], ["Yoshida", "Keigo", ""]]}, {"id": "1711.00928", "submitter": "Francisco Valero-Cuevas", "authors": "Kian Jalaleddini, Akira Nagamori, Christopher M Laine, Mahsa A.\n  Golkar, RObert E. Kearney, Francisco J. Valero-Cuevas", "title": "Physiological Tremor Increases when Skeletal Muscle is Shortened:\n  Implications for Fusimotor Control", "comments": null, "journal-ref": "NCBI, 2017", "doi": "10.1113/JP274899", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The involuntary force fluctuations associated with physiological (as distinct\nfrom pathological) tremor are an unavoidable component of human motor control.\nWhile the origins of the physiological tremor are known to depend on muscle\nafferentation, it is possible that the mechanical properties of muscle-tendon\nsystems also affect its generation, amplification and maintenance. In this\npaper, we investigated the dependence of physiological tremor during tonic,\nisometric plantarflextion torque at 30% of maximum at three ankle angles. The\namplitude of physiological tremor increased as calf muscles shortened in\ncontrast to the stretch reflex whose amplitude decreases as muscle shortens. We\nused a closed-loop simulation model of afferented muscle to explore the\nmechanisms responsible for this behavior. We demonstrate that changing muscle\nlengths does not suffice to explain our experimental findings. Rather, the\nmodel consistently required the modulation of gamme-static fusimotor drive to\nproduce increases in physiological tremor with muscle shortening--while\nsuccessfully replicating the concomitant reduction in stretch reflex amplitude.\nThis need to control gamma-static fusimotor drive explicitly as a function of\nmuscle length has important implication. First, it permits the amplitudes of\nphysiological tremor and stretch reflex to be decoupled. Second, it postulates\nneuromechanical interaction that require length-dependent gamma drive\nmodulation to be independent from alpha drive to the parent muscle. Lastly, it\nsuggests that physiological tremor can be used as a simple, non-invasive\nmeasure of the afferent mechanisms underlying healthy motor function, and their\ndisruption in neurological conditions.\n", "versions": [{"version": "v1", "created": "Thu, 2 Nov 2017 20:45:07 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Jalaleddini", "Kian", ""], ["Nagamori", "Akira", ""], ["Laine", "Christopher M", ""], ["Golkar", "Mahsa A.", ""], ["Kearney", "RObert E.", ""], ["Valero-Cuevas", "Francisco J.", ""]]}, {"id": "1711.01096", "submitter": "Ekkehard Ullner", "authors": "Ekkehard Ullner, Antonio Politi and Alessandro Torcini", "title": "Ubiquity of collective irregular dynamics in balanced networks of\n  spiking neurons", "comments": "5 pages, 4 figures", "journal-ref": "Chaos 28, 081106 (2018)", "doi": "10.1063/1.5049902", "report-no": null, "categories": "nlin.AO cond-mat.dis-nn nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the dynamics of a prototypical model of balanced activity in\nnetworks of spiking neutrons. A detailed investigation of the thermodynamic\nlimit for fixed density of connections (massive coupling) shows that, when\ninhibition prevails, the asymptotic regime is not asynchronous but rather\ncharacterized by a self-sustained irregular, macroscopic (collective) dynamics.\nSo long as the connectivity is massive, this regime is found in many different\nsetups: leaky as well as quadratic integrate-and-fire neurons; large and small\ncoupling strength; weak and strong external currents.\n", "versions": [{"version": "v1", "created": "Fri, 3 Nov 2017 10:34:58 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 15:34:03 GMT"}, {"version": "v3", "created": "Thu, 9 Aug 2018 21:36:36 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Ullner", "Ekkehard", ""], ["Politi", "Antonio", ""], ["Torcini", "Alessandro", ""]]}, {"id": "1711.01421", "submitter": "I\\'nigo Arandia-Romero", "authors": "I\\~nigo Arandia-Romero, Seiji Tanabe, Jan Drugowitsch, Adam Kohn,\n  Rub\\'en Moreno-Bote", "title": "Multiplicative and additive modulation of neuronal tuning with\n  population activity affects encoded information", "comments": "Main text: 34 pages, 7 figures. Supplementary information: 13 pages,\n  7 figures", "journal-ref": "Neuron, 2016 , Volume 89 , Issue 6 , 1305 - 1316", "doi": "10.1016/j.neuron.2016.01.044", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous studies have shown that neuronal responses are modulated by stimulus\nproperties, and also by the state of the local network. However, little is\nknown about how activity fluctuations of neuronal populations modulate the\nsensory tuning of cells and affect their encoded information. We found that\nfluctuations in ongoing and stimulus-evoked population activity in primate\nvisual cortex modulate the tuning of neurons in a multiplicative and additive\nmanner. While distributed on a continuum, neurons with stronger multiplicative\neffects tended to have less additive modulation, and vice versa. The\ninformation encoded by multiplicatively-modulated neurons increased with\ngreater population activity, while that of additively-modulated neurons\ndecreased. These effects offset each other, so that population activity had\nlittle effect on total information. Our results thus suggest that intrinsic\nactivity fluctuations may act as a \"traffic light\" that determines which subset\nof neurons are most informative.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 10:41:34 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Arandia-Romero", "I\u00f1igo", ""], ["Tanabe", "Seiji", ""], ["Drugowitsch", "Jan", ""], ["Kohn", "Adam", ""], ["Moreno-Bote", "Rub\u00e9n", ""]]}, {"id": "1711.01423", "submitter": "I\\'nigo Arandia-Romero", "authors": "I\\~nigo Arandia-Romero, Ramon Nogueira, Gabriela Mochol, Rub\\'en\n  Moreno-Bote", "title": "What can neuronal populations tell us about cognition?", "comments": "21 pages, 4 figures", "journal-ref": "Current Opinion in Neurobiology, Volume 46, October 2017, Pages\n  48-57", "doi": "10.1016/j.conb.2017.07.008", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, it is possible to record the activity of hundreds of cells at the\nsame time in behaving animals. However, these data are often treated and\nanalyzed as if they consisted of many independently recorded neurons. How can\nneuronal populations be uniquely used to learn about cognition? We describe\nrecent work that shows that populations of simultaneously recorded neurons are\nfundamental to understand the basis of decision-making, including processes\nsuch as ongoing deliberations and decision confidence, which generally fall\noutside the reach of single-cell analysis. Thus, neuronal population data allow\naddressing novel questions, but they also come with so far unsolved challenges.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 10:45:14 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Arandia-Romero", "I\u00f1igo", ""], ["Nogueira", "Ramon", ""], ["Mochol", "Gabriela", ""], ["Moreno-Bote", "Rub\u00e9n", ""]]}, {"id": "1711.01487", "submitter": "Yao Li", "authors": "Yao Li, Logan Chariker, Lai-Sang Young", "title": "How well do reduced models capture the dynamics in models of interacting\n  neurons ?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a class of stochastic models of interacting neurons\nwith emergent dynamics similar to those seen in local cortical populations, and\ncompares them to very simple reduced models driven by the same mean excitatory\nand inhibitory currents. Discrepancies in firing rates between network and\nreduced models were investigated, and mechanisms leading to these discrepancies\nwere identified. Chief among them is correlations in spiking, or partial\nsynchronization, working in concert with \"nonlinearities\" in the time evolution\nof membrane potentials. Additionally, simple random walk models and their first\npassage times were shown to reproduce well fluctuations in neuronal membrane\npotentials and interspike times.\n", "versions": [{"version": "v1", "created": "Sat, 4 Nov 2017 20:05:09 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Li", "Yao", ""], ["Chariker", "Logan", ""], ["Young", "Lai-Sang", ""]]}, {"id": "1711.01629", "submitter": "Rakesh Malladi", "authors": "Rakesh Malladi, Don H Johnson, Giridhar P Kalamangalam, Nitin Tandon\n  and Behnaam Aazhang", "title": "Mutual Information in Frequency and its Application to Measure\n  Cross-Frequency Coupling in Epilepsy", "comments": "This paper is accepted for publication in IEEE Transactions on Signal\n  Processing and contains 15 pages, 9 figures and 1 table", "journal-ref": null, "doi": "10.1109/TSP.2018.2821627", "report-no": null, "categories": "q-bio.NC cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a metric, mutual information in frequency (MI-in-frequency), to\ndetect and quantify the statistical dependence between different frequency\ncomponents in the data, referred to as cross-frequency coupling and apply it to\nelectrophysiological recordings from the brain to infer cross-frequency\ncoupling. The current metrics used to quantify the cross-frequency coupling in\nneuroscience cannot detect if two frequency components in non-Gaussian brain\nrecordings are statistically independent or not. Our MI-in-frequency metric,\nbased on Shannon's mutual information between the Cramer's representation of\nstochastic processes, overcomes this shortcoming and can detect statistical\ndependence in frequency between non-Gaussian signals. We then describe two\ndata-driven estimators of MI-in-frequency: one based on kernel density\nestimation and the other based on the nearest neighbor algorithm and validate\ntheir performance on simulated data. We then use MI-in-frequency to estimate\nmutual information between two data streams that are dependent across time,\nwithout making any parametric model assumptions. Finally, we use the MI-in-\nfrequency metric to investigate the cross-frequency coupling in seizure onset\nzone from electrocorticographic recordings during seizures. The inferred\ncross-frequency coupling characteristics are essential to optimize the spatial\nand spectral parameters of electrical stimulation based treatments of epilepsy.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 18:16:06 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 05:47:37 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Malladi", "Rakesh", ""], ["Johnson", "Don H", ""], ["Kalamangalam", "Giridhar P", ""], ["Tandon", "Nitin", ""], ["Aazhang", "Behnaam", ""]]}, {"id": "1711.01767", "submitter": "Wlodzislaw Duch", "authors": "W{\\l}odzis{\\l}aw Duch", "title": "Kurt Lewin, psychological constructs and sources of brain cognitive\n  activity", "comments": "10 pages, conference paper: XXVI Psychology Colloqium, Polish Academy\n  of Science \"Brain-behavior relations in psychology\", June 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding mind-brain-environment relations is one of the key topics in\npsychology. Kurt Lewin, inspired by theoretical physics, tried to establish\ntopological and vector psychology analyzing patterns of interaction between the\nindividual and her/his environment. The time is ripe to reformulate his\nambitious goals, searching for ways to interpret objectively measured brain\nprocesses in terms of suitable psychological constructs. Connecting cognitive\nand social psychology constructs to neurophenomics, as it is done now in\npsychiatry, should ground them in physical reality.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 07:58:14 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Duch", "W\u0142odzis\u0142aw", ""]]}, {"id": "1711.01846", "submitter": "Artur Speiser", "authors": "Artur Speiser, Jinyao Yan, Evan Archer, Lars Buesing, Srinivas C.\n  Turaga, Jakob H. Macke", "title": "Fast amortized inference of neural activity from calcium imaging data\n  with variational autoencoders", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calcium imaging permits optical measurement of neural activity. Since\nintracellular calcium concentration is an indirect measurement of neural\nactivity, computational tools are necessary to infer the true underlying\nspiking activity from fluorescence measurements. Bayesian model inversion can\nbe used to solve this problem, but typically requires either computationally\nexpensive MCMC sampling, or faster but approximate maximum-a-posteriori\noptimization. Here, we introduce a flexible algorithmic framework for fast,\nefficient and accurate extraction of neural spikes from imaging data. Using the\nframework of variational autoencoders, we propose to amortize inference by\ntraining a deep neural network to perform model inversion efficiently. The\nrecognition network is trained to produce samples from the posterior\ndistribution over spike trains. Once trained, performing inference amounts to a\nfast single forward pass through the network, without the need for iterative\noptimization or sampling. We show that amortization can be applied flexibly to\na wide range of nonlinear generative models and significantly improves upon the\nstate of the art in computation time, while achieving competitive accuracy. Our\nframework is also able to represent posterior distributions over spike-trains.\nWe demonstrate the generality of our method by proposing the first\nprobabilistic approach for separating backpropagating action potentials from\nputative synaptic inputs in calcium imaging of dendritic spines.\n", "versions": [{"version": "v1", "created": "Mon, 6 Nov 2017 11:57:54 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Speiser", "Artur", ""], ["Yan", "Jinyao", ""], ["Archer", "Evan", ""], ["Buesing", "Lars", ""], ["Turaga", "Srinivas C.", ""], ["Macke", "Jakob H.", ""]]}, {"id": "1711.02177", "submitter": "Chenfei Hu", "authors": "Chenfei Hu, Richard Sam, Mingguang Shan, Viorel Nastasa, Minqi Wang,\n  Taewoo Kim, Martha Gillette, Parijat Sengupta, and Gabriel Popescu", "title": "Optical excitation and detection of neuronal activity", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": "10.1002/jbio.201800269", "report-no": null, "categories": "physics.bio-ph physics.optics q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optogenetics has emerged as an exciting tool for manipulating neural\nactivity, which in turn, can modulate behavior in live organisms. However,\ndetecting the response to the optical stimulation requires electrophysiology\nwith physical contact or fluorescent imaging at target locations, which is\noften limited by photobleaching and phototoxicity. In this paper, we show that\nphase imaging can report the intracellular transport induced by optogenetic\nstimulation. We developed a multimodal instrument that can both stimulate cells\nwith high spatial resolution and detect optical pathlength changes with\nnanometer scale sensitivity. We found that optical pathlength fluctuations\nfollowing stimulation are consistent with active organelle transport.\nFurthermore, the results indicate a broadening in the transport velocity\ndistribution, which is significantly higher in stimulated cells compared to\noptogenetically inactive cells. It is likely that this label-free, contactless\nmeasurement of optogenetic response will provide an enabling approach to\nneuroscience.\n", "versions": [{"version": "v1", "created": "Fri, 27 Oct 2017 14:08:26 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 14:58:03 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Hu", "Chenfei", ""], ["Sam", "Richard", ""], ["Shan", "Mingguang", ""], ["Nastasa", "Viorel", ""], ["Wang", "Minqi", ""], ["Kim", "Taewoo", ""], ["Gillette", "Martha", ""], ["Sengupta", "Parijat", ""], ["Popescu", "Gabriel", ""]]}, {"id": "1711.02448", "submitter": "Rui Ponte Costa", "authors": "Rui Ponte Costa, Yannis M. Assael, Brendan Shillingford, Nando de\n  Freitas and Tim P. Vogels", "title": "Cortical microcircuits as gated-recurrent neural networks", "comments": "To appear in Advances in Neural Information Processing Systems 30\n  (NIPS 2017). 13 pages, 2 figures (and 1 supp. figure)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical circuits exhibit intricate recurrent architectures that are\nremarkably similar across different brain areas. Such stereotyped structure\nsuggests the existence of common computational principles. However, such\nprinciples have remained largely elusive. Inspired by gated-memory networks,\nnamely long short-term memory networks (LSTMs), we introduce a recurrent neural\nnetwork in which information is gated through inhibitory cells that are\nsubtractive (subLSTM). We propose a natural mapping of subLSTMs onto known\ncanonical excitatory-inhibitory cortical microcircuits. Our empirical\nevaluation across sequential image classification and language modelling tasks\nshows that subLSTM units can achieve similar performance to LSTM units. These\nresults suggest that cortical circuits can be optimised to solve complex\ncontextual problems and proposes a novel view on their computational function.\nOverall our work provides a step towards unifying recurrent networks as used in\nmachine learning with their biological counterparts.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 13:03:35 GMT"}, {"version": "v2", "created": "Wed, 3 Jan 2018 17:29:28 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Costa", "Rui Ponte", ""], ["Assael", "Yannis M.", ""], ["Shillingford", "Brendan", ""], ["de Freitas", "Nando", ""], ["Vogels", "Tim P.", ""]]}, {"id": "1711.02653", "submitter": "David Klindt", "authors": "David A. Klindt, Alexander S. Ecker, Thomas Euler, Matthias Bethge", "title": "Neural system identification for large populations separating \"what\" and\n  \"where\"", "comments": "NIPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscientists classify neurons into different types that perform similar\ncomputations at different locations in the visual field. Traditional methods\nfor neural system identification do not capitalize on this separation of 'what'\nand 'where'. Learning deep convolutional feature spaces that are shared among\nmany neurons provides an exciting path forward, but the architectural design\nneeds to account for data limitations: While new experimental techniques enable\nrecordings from thousands of neurons, experimental time is limited so that one\ncan sample only a small fraction of each neuron's response space. Here, we show\nthat a major bottleneck for fitting convolutional neural networks (CNNs) to\nneural data is the estimation of the individual receptive field locations, a\nproblem that has been scratched only at the surface thus far. We propose a CNN\narchitecture with a sparse readout layer factorizing the spatial (where) and\nfeature (what) dimensions. Our network scales well to thousands of neurons and\nshort recordings and can be trained end-to-end. We evaluate this architecture\non ground-truth data to explore the challenges and limitations of CNN-based\nsystem identification. Moreover, we show that our network model outperforms\ncurrent state-of-the art system identification models of mouse primary visual\ncortex.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 18:33:02 GMT"}, {"version": "v2", "created": "Mon, 29 Jan 2018 12:56:18 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Klindt", "David A.", ""], ["Ecker", "Alexander S.", ""], ["Euler", "Thomas", ""], ["Bethge", "Matthias", ""]]}, {"id": "1711.02704", "submitter": "Julie Grollier", "authors": "Miguel Romera, Philippe Talatchian, Sumito Tsunegi, Flavio Abreu\n  Araujo, Vincent Cros, Paolo Bortolotti, Juan Trastoy, Kay Yakushiji, Akio\n  Fukushima, Hitoshi Kubota, Shinji Yuasa, Maxence Ernoult, Damir\n  Vodenicarevic, Tifenn Hirtzlin, Nicolas Locatelli, Damien Querlioz, Julie\n  Grollier", "title": "Vowel recognition with four coupled spin-torque nano-oscillators", "comments": null, "journal-ref": null, "doi": "10.1038/s41586-018-0632-y", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Substantial evidence indicates that the brain uses principles of non-linear\ndynamics in neural processes, providing inspiration for computing with\nnanoelectronic devices. However, training neural networks composed of dynamical\nnanodevices requires finely controlling and tuning their coupled oscillations.\nIn this work, we show that the outstanding tunability of spintronic\nnano-oscillators can solve this challenge. We successfully train a hardware\nnetwork of four spin-torque nano-oscillators to recognize spoken vowels by\ntuning their frequencies according to an automatic real-time learning rule. We\nshow that the high experimental recognition rates stem from the high frequency\ntunability of the oscillators and their mutual coupling. Our results\ndemonstrate that non-trivial pattern classification tasks can be achieved with\nsmall hardware neural networks by endowing them with non-linear dynamical\nfeatures: here, oscillations and synchronization. This demonstration is a\nmilestone for spintronics-based neuromorphic computing.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 16:38:23 GMT"}, {"version": "v2", "created": "Wed, 21 Feb 2018 18:32:54 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 13:41:28 GMT"}, {"version": "v4", "created": "Thu, 18 Oct 2018 09:02:08 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Romera", "Miguel", ""], ["Talatchian", "Philippe", ""], ["Tsunegi", "Sumito", ""], ["Araujo", "Flavio Abreu", ""], ["Cros", "Vincent", ""], ["Bortolotti", "Paolo", ""], ["Trastoy", "Juan", ""], ["Yakushiji", "Kay", ""], ["Fukushima", "Akio", ""], ["Kubota", "Hitoshi", ""], ["Yuasa", "Shinji", ""], ["Ernoult", "Maxence", ""], ["Vodenicarevic", "Damir", ""], ["Hirtzlin", "Tifenn", ""], ["Locatelli", "Nicolas", ""], ["Querlioz", "Damien", ""], ["Grollier", "Julie", ""]]}, {"id": "1711.02837", "submitter": "Qi Yan", "authors": "Qi Yan, Zhaofei Yu, Feng Chen and Jian K. Liu", "title": "Revealing structure components of the retina by deep learning networks", "comments": "Presented at NIPS 2017 Symposium on Interpretable Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) have demonstrated impressive\nperformance on visual object classification tasks. In addition, it is a useful\nmodel for predication of neuronal responses recorded in visual system. However,\nthere is still no clear understanding of what CNNs learn in terms of visual\nneuronal circuits. Visualizing CNN's features to obtain possible connections to\nneuronscience underpinnings is not easy due to highly complex circuits from the\nretina to higher visual cortex. Here we address this issue by focusing on\nsingle retinal ganglion cells with a simple model and electrophysiological\nrecordings from salamanders. By training CNNs with white noise images to\npredicate neural responses, we found that convolutional filters learned in the\nend are resembling to biological components of the retinal circuit. Features\nrepresented by these filters tile the space of conventional receptive field of\nretinal ganglion cells. These results suggest that CNN could be used to reveal\nstructure components of neuronal circuits.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 05:35:27 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Yan", "Qi", ""], ["Yu", "Zhaofei", ""], ["Chen", "Feng", ""], ["Liu", "Jian K.", ""]]}, {"id": "1711.03000", "submitter": "Wutu Lin", "authors": "Tiger w. Lin, Giri P. Krishnan, Maxim Bazhenov, Terrence J. Sejnowski", "title": "Differential covariance: A new method to estimate functional\n  connectivity in fMRI", "comments": "arXiv admin note: text overlap with arXiv:1706.02451", "journal-ref": null, "doi": "10.1101/2020.06.16.155630", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring functional connectivity from fMRI is important in understanding\nprocessing in cortical networks. However, because brain's connection pattern is\ncomplex, currently used methods are prone to produce false connections. We\nintroduce here a new method that uses derivative for estimating functional\nconnectivity. Using simulations, we benchmarked our method with other commonly\nused methods. Our method achieves better results in complex network\nsimulations. This new method provides an alternative way to estimate functional\nconnectivity.\n", "versions": [{"version": "v1", "created": "Tue, 7 Nov 2017 05:30:45 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Lin", "Tiger w.", ""], ["Krishnan", "Giri P.", ""], ["Bazhenov", "Maxim", ""], ["Sejnowski", "Terrence J.", ""]]}, {"id": "1711.03058", "submitter": "Michael Shvartsman", "authors": "Michael Shvartsman, Narayanan Sundaram, Mikio C. Aoi, Adam Charles,\n  Theodore C. Wilke, Jonathan D. Cohen", "title": "Matrix-normal models for fMRI analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate analysis of fMRI data has benefited substantially from advances\nin machine learning. Most recently, a range of probabilistic latent variable\nmodels applied to fMRI data have been successful in a variety of tasks,\nincluding identifying similarity patterns in neural data (Representational\nSimilarity Analysis and its empirical Bayes variant, RSA and BRSA; Intersubject\nFunctional Connectivity, ISFC), combining multi-subject datasets (Shared\nResponse Mapping; SRM), and mapping between brain and behavior (Joint\nModeling). Although these methods share some underpinnings, they have been\ndeveloped as distinct methods, with distinct algorithms and software tools. We\nshow how the matrix-variate normal (MN) formalism can unify some of these\nmethods into a single framework. In doing so, we gain the ability to reuse\nnoise modeling assumptions, algorithms, and code across models. Our primary\ntheoretical contribution shows how some of these methods can be written as\ninstantiations of the same model, allowing us to generalize them to flexibly\nmodeling structured noise covariances. Our formalism permits novel model\nvariants and improved estimation strategies: in contrast to SRM, the number of\nparameters for MN-SRM does not scale with the number of voxels or subjects; in\ncontrast to BRSA, the number of parameters for MN-RSA scales additively rather\nthan multiplicatively in the number of voxels. We empirically demonstrate\nadvantages of two new methods derived in the formalism: for MN-RSA, we show up\nto 10x improvement in runtime, up to 6x improvement in RMSE, and more\nconservative behavior under the null. For MN-SRM, our method grants a modest\nimprovement to out-of-sample reconstruction while relaxing an orthonormality\nconstraint of SRM. We also provide a software prototyping tool for MN models\nthat can flexibly reuse noise covariance assumptions and algorithms across\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 8 Nov 2017 17:22:51 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 04:20:54 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Shvartsman", "Michael", ""], ["Sundaram", "Narayanan", ""], ["Aoi", "Mikio C.", ""], ["Charles", "Adam", ""], ["Wilke", "Theodore C.", ""], ["Cohen", "Jonathan D.", ""]]}, {"id": "1711.03303", "submitter": "Taishi Iwasaki", "authors": "Taishi Iwasaki, Hideitsu Hino, Masami Tatsuno, Shotaro Akaho and\n  Noboru Murata", "title": "Estimation of neural connections from partially observed neural spikes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plasticity is one of the most important properties of the nervous system,\nwhich enables animals to adjust their behavior to the ever-changing external\nenvironment. Changes in synaptic efficacy between neurons constitute one of the\nmajor mechanisms of plasticity. Therefore, estimation of neural connections is\ncrucial for investigating information processing in the brain. Although many\nanalysis methods have been proposed for this purpose, most of them suffer from\none or all the following mathematical difficulties: (1) only partially observed\nneural activity is available; (2) correlations can include both direct and\nindirect pseudo-interactions; and (3) biological evidence that a neuron\ntypically has only one type of connection (excitatory or inhibitory) should be\nconsidered. To overcome these difficulties, a novel probabilistic framework for\nestimating neural connections from partially observed spikes is proposed in\nthis paper. First, based on the property of a sum of random variables, the\nproposed method estimates the influence of unobserved neurons on observed\nneurons and extracts only the correlations among observed neurons. Second, the\nrelationship between pseudo-correlations and target connections is modeled by\nneural propagation in a multiplicative manner. Third, a novel\ninformation-theoretic framework is proposed for estimating neuron types. The\nproposed method was validated using spike data generated by artificial neural\nnetworks. In addition, it was applied to multi-unit data recorded from the CA1\narea of a rat's hippocampus. The results confirmed that our estimates are\nconsistent with previous reports. These findings indicate that the proposed\nmethod is useful for extracting crucial interactions in neural signals as well\nas in other multi-probed point process data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 09:25:23 GMT"}, {"version": "v2", "created": "Sun, 21 Jan 2018 23:39:24 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Iwasaki", "Taishi", ""], ["Hino", "Hideitsu", ""], ["Tatsuno", "Masami", ""], ["Akaho", "Shotaro", ""], ["Murata", "Noboru", ""]]}, {"id": "1711.03332", "submitter": "Alberto Sorrentino", "authors": "Sara Sommariva and Alberto Sorrentino and Michele Piana and Vittorio\n  Pizzella and Laura Marzetti", "title": "A comparative study of the robustness of frequency--domain connectivity\n  measures to finite data length", "comments": "32 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.NA q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we use numerical simulation to investigate how the temporal\nlength of the data affects the reliability of the estimates of brain\nconnectivity from EEG time--series. We assume that the neural sources follow a\nstable MultiVariate AutoRegressive model, and consider three connectivity\nmetrics: Imaginary part of Coherency (IC), generalized Partial Directed\nCoherence (gPDC) and frequency--domain Granger Causality (fGC). In order to\nassess the statistical significance of the estimated values, we use the\nsurrogate data test by generating phase--randomized and autoregressive\nsurrogate data. We first consider the ideal case where we know the source time\ncourses exactly. Here we show how, expectedly, even exact knowledge of the\nsource time courses is not sufficient to provide reliable estimates of the\nconnectivity when the number of samples gets small; however, while gPDC and fGC\ntend to provide a larger number of false positives, the IC becomes less\nsensitive to the presence of connectivity. Then we proceed with more realistic\nsimulations, where the source time courses are estimated using eLORETA, and the\nEEG signal is affected by biological noise of increasing intensity. Using the\nideal case as a reference, we show that the impact of biological noise on IC\nestimates is qualitatively different from the impact on gPDC and fGC.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 11:25:29 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Sommariva", "Sara", ""], ["Sorrentino", "Alberto", ""], ["Piana", "Michele", ""], ["Pizzella", "Vittorio", ""], ["Marzetti", "Laura", ""]]}, {"id": "1711.03383", "submitter": "Andreas Neef", "authors": "Elinor Lazarov, Melanie Dannemeyer, Barbara Feulner, J\\\"org Enderlein,\n  Michael J. Gutnick, Fred Wolf and Andreas Neef", "title": "An axon initial segment is required for temporal precision in action\n  potential encoding by neuronal populations", "comments": "Title adjusted, no other changes", "journal-ref": "Science Advances Vol. 4, no. 11, eaau8621; 28 Nov 2018", "doi": "10.1126/sciadv.aau8621", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central neurons initiate action potentials (APs) in the axon initial segment\n(AIS), a compartment characterized by a high concentration of voltage-dependent\nion channels and specialized cytoskeletal anchoring proteins arranged in a\nregular nanoscale pattern. Although the AIS was a key evolutionary innovation\nin neurons, the functional benefits it confers are not clear. Using a mutation\nof the AIS cytoskeletal protein \\beta IV-spectrin, we here establish an in\nvitro model of neurons with a perturbed AIS architecture that retains nanoscale\norder but loses the ability to maintain a high NaV density. Combining\nexperiments and simulations we show that a high NaV density in the AIS is not\nrequired for axonal AP initiation; it is however crucial for a high bandwidth\nof information encoding and AP timing precision. Our results provide the first\nexperimental demonstration of axonal AP initiation without high axonal channel\ndensity and suggest that increasing the bandwidth of the neuronal code and\nhence the computational efficiency of network function was a major benefit of\nthe evolution of the AIS.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 14:21:24 GMT"}, {"version": "v2", "created": "Wed, 17 Oct 2018 23:10:01 GMT"}, {"version": "v3", "created": "Fri, 19 Oct 2018 07:38:56 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Lazarov", "Elinor", ""], ["Dannemeyer", "Melanie", ""], ["Feulner", "Barbara", ""], ["Enderlein", "J\u00f6rg", ""], ["Gutnick", "Michael J.", ""], ["Wolf", "Fred", ""], ["Neef", "Andreas", ""]]}, {"id": "1711.03809", "submitter": "Richard Betzel", "authors": "Richard F. Betzel, Danielle S. Bassett", "title": "The specificity and robustness of long-distance connections in weighted,\n  interareal connectomes", "comments": "18 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain areas' functional repertoires are shaped by their incoming and outgoing\nstructural connections. In empirically measured networks, most connections are\nshort, reflecting spatial and energetic constraints. Nonetheless, a small\nnumber of connections span long distances, consistent with the notion that the\nfunctionality of these connections must outweigh their cost. While the precise\nfunction of these long-distance connections is not known, the leading\nhypothesis is that they act to reduce the topological distance between brain\nareas and facilitate efficient interareal communication. However, this\nhypothesis implies a non-specificity of long-distance connections that we\ncontend is unlikely. Instead, we propose that long-distance connections serve\nto diversify brain areas' inputs and outputs, thereby promoting complex\ndynamics. Through analysis of five interareal network datasets, we show that\nlong-distance connections play only minor roles in reducing average interareal\ntopological distance. In contrast, areas' long-distance and short-range\nneighbors exhibit marked differences in their connectivity profiles, suggesting\nthat long-distance connections enhance dissimilarity between regional inputs\nand outputs. Next, we show that -- in isolation -- areas' long-distance\nconnectivity profiles exhibit non-random levels of similarity, suggesting that\nthe communication pathways formed by long connections exhibit redundancies that\nmay serve to promote robustness. Finally, we use a linearization of\nWilson-Cowan dynamics to simulate the covariance structure of neural activity\nand show that in the absence of long-distance connections, a common measure of\nfunctional diversity decreases. Collectively, our findings suggest that\nlong-distance connections are necessary for supporting diverse and complex\nbrain dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 10 Nov 2017 13:23:09 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Betzel", "Richard F.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1711.03834", "submitter": "Eve Armstrong", "authors": "Eve Armstrong", "title": "Statistical data assimilation for estimating electrophysiology\n  simultaneously with connectivity within a biological neuronal network", "comments": "15 pages and 7 figures (without appendices). arXiv admin note: text\n  overlap with arXiv:1706.03296", "journal-ref": "Phys. Rev. E 101, 012415 (2020)", "doi": "10.1103/PhysRevE.101.012415", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A method of data assimilation (DA) is employed to estimate\nelectrophysiological parameters of neurons simultaneously with their synaptic\nconnectivity in a small model biological network. The DA procedure is cast as\nan optimization, with a cost function consisting of both a measurement error\nand a model error term. An iterative reweighting of these terms permits a\nsystematic method to identify the lowest minimum, within a local region of\nstate space, on the surface of a non-convex cost function. In the model, two\nsets of parameter values are associated with two particular functional modes of\nnetwork activity: simultaneous firing of all neurons, and a pattern-generating\nmode wherein the neurons burst in sequence. The DA procedure is able to recover\nthese modes if: i) the stimulating electrical currents have chaotic waveforms,\nand ii) the measurements consist of the membrane voltages of all neurons in the\ncircuit. Further, this method is able to prune a model of unnecessarily high\ndimensionality to a representation that contains the maximum dimensionality\nrequired to reproduce the provided measurements. This paper offers a\nproof-of-concept that DA has the potential to inform laboratory designs for\nestimating properties in small and isolatable functional circuits.\n", "versions": [{"version": "v1", "created": "Thu, 9 Nov 2017 18:33:03 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 23:59:07 GMT"}, {"version": "v3", "created": "Mon, 4 Dec 2017 00:38:20 GMT"}, {"version": "v4", "created": "Mon, 11 Dec 2017 20:44:51 GMT"}, {"version": "v5", "created": "Tue, 4 Sep 2018 17:48:11 GMT"}, {"version": "v6", "created": "Fri, 10 May 2019 19:05:50 GMT"}, {"version": "v7", "created": "Fri, 22 Nov 2019 19:22:04 GMT"}, {"version": "v8", "created": "Mon, 2 Dec 2019 23:23:14 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Armstrong", "Eve", ""]]}, {"id": "1711.04203", "submitter": "Robert Mok", "authors": "Nikolaus Kriegeskorte and Robert M. Mok", "title": "Building machines that adapt and compute like brains", "comments": "Commentary on: Lake BM, Ullman TD, Tenenbaum JB, Gershman SJ. (2017)\n  Building machines that learn and think like people. Behavioral and Brain\n  Sciences, 40", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building machines that learn and think like humans is essential not only for\ncognitive science, but also for computational neuroscience, whose ultimate goal\nis to understand how cognition is implemented in biological brains. A new\ncognitive computational neuroscience should build cognitive-level and neural-\nlevel models, understand their relationships, and test both types of models\nwith both brain and behavioral data.\n", "versions": [{"version": "v1", "created": "Sat, 11 Nov 2017 22:02:52 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Kriegeskorte", "Nikolaus", ""], ["Mok", "Robert M.", ""]]}, {"id": "1711.04377", "submitter": "James Hope Mr", "authors": "J. Hope, F. Vanholsbeeck, A. McDaid", "title": "A model of electrical impedance tomography on peripheral nerves for a\n  neural-prosthetic control interface", "comments": "13 pages, 9 figures", "journal-ref": "Hope, J., Vanholsbeeck, F., McDaid, A., A model of electrical\n  impedance tomography implemented in nerve-cuff for neural-prosthetics\n  control. Physiological Measurement, 2018", "doi": "10.1088/1361-6579/aab73a", "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: A model is presented to evaluate the viability of using electrical\nimpedance tomography (EIT) with a nerve cuff to record neural activity in\nperipheral nerves. Approach: Established modelling approaches in neural-EIT are\nexpanded on to be used, for the first time, on myelinated fibres which are\nabundant in mammalian peripheral nerves and transmit motor commands. Main\nresults: Fibre impedance models indicate activity in unmyelinated fibres can be\nscreened out using operating frequencies above 100 Hz. At 1 kHz and 10 mm\nelectrode spacing, impedance magnitude of inactive intra-fascicle tissue and\nthe fraction changes during neural activity are estimated to be 1,142\n{\\Omega}.cm and -8.8x10-4, respectively, with a transverse current, and 328\n{\\Omega}.cm & -0.30, respectively with a longitudinal current. We show that a\nnovel EIT drive and measurement electrode pattern which utilises longitudinal\ncurrent and longitudinal differential boundary voltage measurements could\ndistinguish activity in different fascicles of a three-fascicle mammalian nerve\nusing pseudo-experimental data synthesised to replicate real operating\nconditions. Significance: The results of this study provide an estimate of the\ntransient change in impedance of intra-fascicle tissue during neural activity\nin mammalian nerve, and present a viable EIT electrode pattern, both of which\nare critical steps towards implementing EIT in a nerve cuff for neural\nprosthetics interfaces.\n", "versions": [{"version": "v1", "created": "Sun, 12 Nov 2017 22:52:48 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Hope", "J.", ""], ["Vanholsbeeck", "F.", ""], ["McDaid", "A.", ""]]}, {"id": "1711.04950", "submitter": "Jeroen Van Boxtel", "authors": "Jeroen J.A. van Boxtel", "title": "Modelling stochastic resonance in humans: the influence of lapse rate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adding noise to a sensory signal generally decreases human performance.\nHowever noise can improve performance too, due to a process called stochastic\nresonance (SR). This paradoxical effect may be exploited in psychophysical\nexperiments, to provide additional insights into how the sensory system deals\nwith noise. Here, I develop a model for stochastic resonance to study the\ninfluence of noise on human perception, in which the biological parameter of\n`lapse rate' was included. I show that the inclusion of lapse rate allows for\nthe occurrence of stochastic resonance in terms of the performance metric d'.\nAt the same time, I show that high levels of lapse rate cause stochastic\nresonance to disappear. It is also shown that noise generated in the brain\n(i.e., internal noise) may obscure any effect of stochastic resonance in\nexperimental settings. I further relate the model to a standard equivalent\nnoise model, the linear amplifier model, and show that the lapse rate can\nfunction to scale the threshold versus noise (TvN) curve, similar to the\nefficiency parameter in equivalent noise (EN) models. Therefore, lapse rate\nprovides a psychophysical explanation for reduced efficiency in EN paradigms.\nFurthermore, I note that ignoring lapse rate may lead to an overestimation of\ninternal noise in equivalent noise paradigms. Overall, describing stochastic\nresonance in terms of signal detection theory, with the inclusion of lapse\nrate, may provide valuable new insights into how human performance depends on\ninternal and external noise.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 04:50:23 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["van Boxtel", "Jeroen J. A.", ""]]}, {"id": "1711.05042", "submitter": "Jingjing Xu", "authors": "Shengyong Xu and Jingjing Xu", "title": "A memory mechanism based on two dimensional code of neurosome pattern", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have recognized that 2D codes, i.e., a group of strongly connected\nneurosomes that can be simultaneously excited, are the basic data carriers for\nmemory in a brain. An echoing mechanism between two neighboring layers of\nneurosomes is assumed to establish temporary memory, and repeating processes\nenhance the formation of long-term memory. Creation and degradation of memory\ninformation are statistically. The maximum capacity of memory storage in a\nhuman brain is estimated to be one billion of 2D codes. By triggering one or\nmore neurosomes in a neurosome-based 2D code, the whole strongly connected\nneurosome network is capable of exciting simultaneously and projecting its\nexcitation onto an analysis layer of neurons in cortex, thus retrieving the\nstored memory data. The capability of comparing two 2D codes in the analysis\nlayer is one of the major brain functions.\n", "versions": [{"version": "v1", "created": "Tue, 14 Nov 2017 10:22:10 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Xu", "Shengyong", ""], ["Xu", "Jingjing", ""]]}, {"id": "1711.05517", "submitter": "Alfred Anwander", "authors": "Christa M\\\"uller-Axt, Alfred Anwander, Katharina von Kriegstein", "title": "Altered structural connectivity of the left visual thalamus in\n  developmental dyslexia", "comments": "31 pages, 5 figures, 2 tables", "journal-ref": "Current Biology (2017)", "doi": "10.1016/j.cub.2017.10.034", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Developmental dyslexia is characterized by persistent reading and spelling\ndeficits. Partly due to technical challenges with investigating subcortical\nsensory structures, current research on dyslexia in humans by-and-large focuses\non the cerebral cortex. These studies found that dyslexia is typically\nassociated with functional and structural alterations of a distributed\nleft-hemispheric cerebral cortex network. However, findings from animal models\nand post-mortem studies in humans suggest that developmental dyslexia might\nalso be associated with structural alterations in subcortical sensory pathways.\nWhether these alterations also exist in developmental dyslexia in-vivo and how\nthey relate to dyslexia symptoms is currently unknown. Here we used ultra-high\nresolution structural magnetic resonance imaging (MRI), diffusion MRI and\nprobabilistic tractography to investigate the structural connections of the\nvisual sensory pathway in dyslexia in-vivo. We discovered that individuals with\ndevelopmental dyslexia have reduced structural connections in the direct\npathway between the left visual thalamus (LGN) and left middle temporal area\nV5/MT, but not between the left LGN and left primary visual cortex (V1). In\naddition, left V5/MT-LGN connectivity strength correlated with rapid naming\nabilities - a key deficit in dyslexia [14]. These findings provide the first\nevidence of specific structural alterations in the connections between the\nsensory thalamus and cortex in developmental dyslexia. The results challenge\ncurrent standard models and provide novel evidence for the importance of\ncortico-thalamic interactions in explaining dyslexia.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 12:21:22 GMT"}, {"version": "v2", "created": "Thu, 16 Nov 2017 23:56:00 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["M\u00fcller-Axt", "Christa", ""], ["Anwander", "Alfred", ""], ["von Kriegstein", "Katharina", ""]]}, {"id": "1711.05596", "submitter": "Rolf Bader", "authors": "Rolf Bader", "title": "Pitch and timbre discrimination at wave-to-spike transition in the\n  cochlea", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new definition of musical pitch is proposed. A Finite-Difference Time\nDomain (FDTM) model of the cochlea is used to calculate spike trains caused by\ntone complexes and by a recorded classical guitar tone. All harmonic tone\ncomplexes, musical notes, show a narrow-band Interspike Interval (ISI) pattern\nat the respective fundamental frequency of the tone complex. Still this\nfundamental frequency is not only present at the bark band holding the\nrespective best frequency of this fundamental frequency, but rather at all bark\nbands driven by the tone complex partials. This is caused by drop-outs in the\nbasically regular, periodic spike train in the respective bands. These\ndrop-outs are caused by the energy distribution in the wave form, where time\nspans of low energy are not able to drive spikes. The presence of the\nfundamental periodicity in all bark bands can be interpreted as pitch. Contrary\nto pitch, timbre is represented as a wide distribution of different ISIs over\nbark bands. The definition of pitch is shown to also works with residue\npitches. The spike drop-outs in times of low energy of the wave form also cause\nundertones, integer multiple subdivisions in periodicity, but in no case\novertones can appear. This might explain the musical minor scale, which was\nproposed to be caused by undertones already in 1880 by Hugo Riemann, still\nuntil now without knowledge about any physical realization of such undertones.\n", "versions": [{"version": "v1", "created": "Wed, 15 Nov 2017 14:44:27 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Bader", "Rolf", ""]]}, {"id": "1711.06435", "submitter": "G Ambika", "authors": "Kunal Mozumdar and G. Ambika", "title": "Frequency locking and travelling burst sequences in community structured\n  network of inhibitory neurons with differing time-scales", "comments": "10 pages, 7 figures, submitted to Communications in Nonlinear Science\n  and Numerical Simulation", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report the emergent dynamics of a community structured modular network of\nchaotic Hindmarsh-Rose (HR) neurons with inhibitory synapses. We find the\ninhibitory coupling between the neuronal modules lead to complete\nsynchronization of neurons in a module, and also pushes modules into\ninteresting sequences of travelling burst patterns. When dynamical time-scales\nvary for neurons in different modules, hence breaking the symmetry among them,\nwe see specific sequences of travelling burst patterns that are characteristic\nof the time-scale mismatch and coupling strengths. Thus for a modular network\nwith two time-scales, the neuronal communities enter into synchronized\nfrequency locked clusters with the bursting sequences having recurring\npatterns. Our study provides a complete characterization of the spatio-temporal\nregularity in terms of frequency locking for temporal order and burst sequence\npatterns for spatial order in the collective dynamics of the neuronal clusters.\nOur results have significance in the process of information coding in terms of\nfrequency of firing dynamics among neurons and in selective communication based\non the sequences of bursts.\n", "versions": [{"version": "v1", "created": "Fri, 17 Nov 2017 07:19:12 GMT"}, {"version": "v2", "created": "Sun, 11 Mar 2018 10:36:14 GMT"}, {"version": "v3", "created": "Thu, 22 Mar 2018 09:10:03 GMT"}], "update_date": "2018-03-23", "authors_parsed": [["Mozumdar", "Kunal", ""], ["Ambika", "G.", ""]]}, {"id": "1711.06967", "submitter": "Kyongsik Yun", "authors": "Kyongsik Yun, Saeran Doh, Elisa Carrus, Daw-An Wu, Shinsuke Shimojo", "title": "Neural correlates of flow using auditory evoked potential suppression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Flow\" is a hyper-engaged state of consciousness most commonly described in\nathletics, popularly termed \"being in the zone.\" Quantitative research into\nflow has been hampered by the disruptive nature of gathering subjective\nreports. Here we show that a passive probe (suppression of Auditory Evoked\nPotential in EEG) that allowed our participants to remain engaged in a\nfirst-person shooting game while we continually tracked the depth of their\nimmersion corresponded with the participants' subjective experiences, and with\ntheir objective performance levels. Comparing this time-varying record of flow\nagainst the overall EEG record, we identified neural correlates of flow in the\nanterior cingulate cortex and the temporal pole. These areas displayed\nincreased beta band activity, mutual connectivity, and feedback connectivity\nwith primary motor cortex. These results corroborate the notion that the flow\nstate is an objective and quantifiable state of consciousness, which we\nidentify and characterize across subjective, behavioral and neural measures.\n", "versions": [{"version": "v1", "created": "Sun, 19 Nov 2017 04:37:58 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 07:38:57 GMT"}, {"version": "v3", "created": "Wed, 22 Nov 2017 08:10:53 GMT"}, {"version": "v4", "created": "Fri, 24 Nov 2017 22:30:51 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Yun", "Kyongsik", ""], ["Doh", "Saeran", ""], ["Carrus", "Elisa", ""], ["Wu", "Daw-An", ""], ["Shimojo", "Shinsuke", ""]]}, {"id": "1711.07205", "submitter": "Erik Rybakken", "authors": "Erik Rybakken, Nils Baas, Benjamin Dunn", "title": "Decoding of neural data using cohomological feature extraction", "comments": "17 pages. This is the author's final version, and the article has\n  been accepted for publication in Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel data-driven approach to discover and decode features in\nthe neural code coming from large population neural recordings with minimal\nassumptions, using cohomological feature extraction. We apply our approach to\nneural recordings of mice moving freely in a box, where we find a circular\nfeature. We then observe that the decoded value corresponds well to the head\ndirection of the mouse. Thus we capture head direction cells and decode the\nhead direction from the neural population activity without having to process\nthe behaviour of the mouse. Interestingly, the decoded values convey more\ninformation about the neural activity than the tracked head direction does,\nwith differences that have some spatial organization. Finally, we note that the\nresidual population activity, after the head direction has been accounted for,\nretains some low-dimensional structure which is correlated with the speed of\nthe mouse.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 08:56:10 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 10:39:12 GMT"}, {"version": "v3", "created": "Wed, 22 Nov 2017 09:59:06 GMT"}, {"version": "v4", "created": "Thu, 8 Mar 2018 21:11:42 GMT"}, {"version": "v5", "created": "Mon, 10 Sep 2018 09:59:32 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Rybakken", "Erik", ""], ["Baas", "Nils", ""], ["Dunn", "Benjamin", ""]]}, {"id": "1711.07258", "submitter": "Marie-Constance Corsi", "authors": "Marie-Constance Corsi, Mario Chavez, Denis Schwartz, Laurent\n  Hugueville, Ankit N. Khambhati, Danielle S. Bassett, Fabrizio De Vico Fallani", "title": "Integrating EEG and MEG signals to improve motor imagery classification\n  in brain-computer interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a fusion approach that combines features from simultaneously\nrecorded electroencephalographic (EEG) and magnetoencephalographic (MEG)\nsignals to improve classification performances in motor imagery-based\nbrain-computer interfaces (BCIs). We applied our approach to a group of 15\nhealthy subjects and found a significant classification performance enhancement\nas compared to standard single-modality approaches in the alpha and beta bands.\nTaken together, our findings demonstrate the advantage of considering\nmultimodal approaches as complementary tools for improving the impact of\nnon-invasive BCIs.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 11:30:15 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 13:27:13 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Corsi", "Marie-Constance", ""], ["Chavez", "Mario", ""], ["Schwartz", "Denis", ""], ["Hugueville", "Laurent", ""], ["Khambhati", "Ankit N.", ""], ["Bassett", "Danielle S.", ""], ["Fallani", "Fabrizio De Vico", ""]]}, {"id": "1711.07425", "submitter": "Kevin Feigelis", "authors": "Kevin T. Feigelis, Blue Sheffer, Daniel L. K. Yamins", "title": "Modular Continual Learning in a Unified Visual Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core aspect of human intelligence is the ability to learn new tasks quickly\nand switch between them flexibly. Here, we describe a modular continual\nreinforcement learning paradigm inspired by these abilities. We first introduce\na visual interaction environment that allows many types of tasks to be unified\nin a single framework. We then describe a reward map prediction scheme that\nlearns new tasks robustly in the very large state and action spaces required by\nsuch an environment. We investigate how properties of module architecture\ninfluence efficiency of task learning, showing that a module motif\nincorporating specific design principles (e.g. early bottlenecks, low-order\npolynomial nonlinearities, and symmetry) significantly outperforms more\nstandard neural network motifs, needing fewer training examples and fewer\nneurons to achieve high levels of performance. Finally, we present a\nmeta-controller architecture for task switching based on a dynamic neural\nvoting scheme, which allows new modules to use information learned from\npreviously-seen tasks to substantially improve their own learning efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 17:31:12 GMT"}, {"version": "v2", "created": "Tue, 12 Dec 2017 04:31:00 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Feigelis", "Kevin T.", ""], ["Sheffer", "Blue", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "1711.07462", "submitter": "Reza Abiri", "authors": "Reza Abiri, Soheil Borhani, Xiaopeng Zhao, Yang Jiang", "title": "Real-time brain machine interaction via social robot gesture control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-Machine Interaction (BMI) system motivates interesting and promising\nresults in forward/feedback control consistent with human intention. It holds\ngreat promise for advancements in patient care and applications to\nneurorehabilitation. Here, we propose a novel neurofeedback-based BCI robotic\nplatform using a personalized social robot in order to assist patients having\ncognitive deficits through bilateral rehabilitation and mental training. For\ninitial testing of the platform, electroencephalography (EEG) brainwaves of a\nhuman user were collected in real time during tasks of imaginary movements.\nFirst, the brainwaves associated with imagined body kinematics parameters were\ndecoded to control a cursor on a computer screen in training protocol. Then,\nthe experienced subject was able to interact with a social robot via our\nreal-time BMI robotic platform. Corresponding to subject's imagery performance,\nhe/she received specific gesture movements and eye color changes as\nneural-based feedback from the robot. This hands-free neurofeedback interaction\nnot only can be used for mind control of a social robot's movements, but also\nsets the stage for application to enhancing and recovering mental abilities\nsuch as attention via training in humans by providing real-time neurofeedback\nfrom a social robot.\n", "versions": [{"version": "v1", "created": "Mon, 20 Nov 2017 18:54:42 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["Abiri", "Reza", ""], ["Borhani", "Soheil", ""], ["Zhao", "Xiaopeng", ""], ["Jiang", "Yang", ""]]}, {"id": "1711.07792", "submitter": "Kay Gregor Hartmann", "authors": "Kay Gregor Hartmann, Robin Tibor Schirrmeister, Tonio Ball", "title": "Hierarchical internal representation of spectral features in deep\n  convolutional networks trained for EEG decoding", "comments": "6 pages, 7 figures, The 6th International Winter Conference on\n  Brain-Computer Interface", "journal-ref": null, "doi": "10.1109/IWW-BCI.2018.8311493", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there is increasing interest and research on the interpretability\nof machine learning models, for example how they transform and internally\nrepresent EEG signals in Brain-Computer Interface (BCI) applications. This can\nhelp to understand the limits of the model and how it may be improved, in\naddition to possibly provide insight about the data itself. Schirrmeister et\nal. (2017) have recently reported promising results for EEG decoding with deep\nconvolutional neural networks (ConvNets) trained in an end-to-end manner and,\nwith a causal visualization approach, showed that they learn to use spectral\namplitude changes in the input. In this study, we investigate how ConvNets\nrepresent spectral features through the sequence of intermediate stages of the\nnetwork. We show higher sensitivity to EEG phase features at earlier stages and\nhigher sensitivity to EEG amplitude features at later stages. Intriguingly, we\nobserved a specialization of individual stages of the network to the classical\nEEG frequency bands alpha, beta, and high gamma. Furthermore, we find first\nevidence that particularly in the last convolutional layer, the network learns\nto detect more complex oscillatory patterns beyond spectral phase and\namplitude, reminiscent of the representation of complex visual features in\nlater layers of ConvNets in computer vision tasks. Our findings thus provide\ninsights into how ConvNets hierarchically represent spectral EEG features in\ntheir intermediate layers and suggest that ConvNets can exploit and might help\nto better understand the compositional structure of EEG time series.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 14:05:25 GMT"}, {"version": "v2", "created": "Thu, 23 Nov 2017 18:12:03 GMT"}, {"version": "v3", "created": "Fri, 15 Dec 2017 16:29:12 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Hartmann", "Kay Gregor", ""], ["Schirrmeister", "Robin Tibor", ""], ["Ball", "Tonio", ""]]}, {"id": "1711.07894", "submitter": "Kun ho Kim", "authors": "Yanan Sui, Kun ho Kim, Joel W. Burdick", "title": "Quantifying Performance of Bipedal Standing with Multi-channel EMG", "comments": null, "journal-ref": "IROS 2017", "doi": null, "report-no": null, "categories": "stat.ML cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spinal cord stimulation has enabled humans with motor complete spinal cord\ninjury (SCI) to independently stand and recover some lost autonomic function.\nQuantifying the quality of bipedal standing under spinal stimulation is\nimportant for spinal rehabilitation therapies and for new strategies that seek\nto combine spinal stimulation and rehabilitative robots (such as exoskeletons)\nin real time feedback. To study the potential for automated electromyography\n(EMG) analysis in SCI, we evaluated the standing quality of paralyzed patients\nundergoing electrical spinal cord stimulation using both video and\nmulti-channel surface EMG recordings during spinal stimulation therapy\nsessions. The quality of standing under different stimulation settings was\nquantified manually by experienced clinicians. By correlating features of the\nrecorded EMG activity with the expert evaluations, we show that multi-channel\nEMG recording can provide accurate, fast, and robust estimation for the quality\nof bipedal standing in spinally stimulated SCI patients. Moreover, our analysis\nshows that the total number of EMG channels needed to effectively predict\nstanding quality can be reduced while maintaining high estimation accuracy,\nwhich provides more flexibility for rehabilitation robotic systems to\nincorporate EMG recordings.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 16:40:26 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Sui", "Yanan", ""], ["Kim", "Kun ho", ""], ["Burdick", "Joel W.", ""]]}, {"id": "1711.08032", "submitter": "Alexander Seeholzer", "authors": "Alexander Seeholzer, Moritz Deger, Wulfram Gerstner", "title": "Efficient low-dimensional approximation of continuous attractor networks", "comments": "23 pages, 6 figures, 3 tables. A previous version of this article was\n  published as a thesis chapter of the first author", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continuous \"bump\" attractors are an established model of cortical working\nmemory for continuous variables and can be implemented using various neuron and\nnetwork models. Here, we develop a generalizable approach for the approximation\nof bump states of continuous attractor networks implemented in networks of both\nrate-based and spiking neurons. The method relies on a low-dimensional\nparametrization of the spatial shape of firing rates, allowing to apply\nefficient numerical optimization methods. Using our theory, we can establish a\nmapping between network structure and attractor properties that allows the\nprediction of the effects of network parameters on the steady state firing rate\nprofile and the existence of bumps, and vice-versa, to fine-tune a network to\nproduce bumps of a given shape.\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 20:47:18 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Seeholzer", "Alexander", ""], ["Deger", "Moritz", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1711.08063", "submitter": "Shatrunjai Singh", "authors": "Shatrunjai P. Singh, Candi L. LaSarge, Amen An, John J. McAuliffe and\n  Steve C. Danzer", "title": "Clonal analysis of newborn hippocampal dentate granule cell\n  proliferation and development in temporal lobe epilepsy", "comments": "44 pages, 6 figures", "journal-ref": "eNeuro. 2015;2(6):ENEURO.0087-15.2015.\n  doi:10.1523/ENEURO.0087-15.2015", "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hippocampal dentate granule cells are among the few neuronal cell types\ngenerated throughout adult life in mammals. In the normal brain, new granule\ncells are generated from progenitors in the subgranular zone and integrate in a\ntypical fashion. During the development of epilepsy, granule cell integration\nis profoundly altered. The new cells migrate to ectopic locations and develop\nmisoriented basal dendrites. Although it has been established that these\nabnormal cells are newly generated, it is not known whether they arise\nubiquitously throughout the progenitor cell pool or are derived from a smaller\nnumber of bad actor progenitors. To explore this question, we conducted a\nclonal analysis study in mice expressing the Brainbow fluorescent protein\nreporter construct in dentate granule cell progenitors. Mice were examined 2\nmonths after pilocarpine-induced status epilepticus, a treatment that leads to\nthe development of epilepsy. Brain sections were rendered translucent so that\nentire hippocampi could be reconstructed and all fluorescently labeled cells\nidentified. Our findings reveal that a small number of progenitors produce the\nmajority of ectopic cells following status epilepticus, indicating that either\nthe affected progenitors or their local microenvironments have become\npathological. By contrast, granule cells with basal dendrites were equally\ndistributed among clonal groups. This indicates that these progenitors can\nproduce normal cells and suggests that global factors sporadically disrupt the\ndendritic development of some new cells. Together, these findings strongly\npredict that distinct mechanisms regulate different aspects\n", "versions": [{"version": "v1", "created": "Tue, 21 Nov 2017 22:00:01 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Singh", "Shatrunjai P.", ""], ["LaSarge", "Candi L.", ""], ["An", "Amen", ""], ["McAuliffe", "John J.", ""], ["Danzer", "Steve C.", ""]]}, {"id": "1711.08309", "submitter": "Maria Masoliver", "authors": "Maria Masoliver and Cristina Masoller", "title": "Subthreshold signal encoding in coupled FitzHugh-Nagumo neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite intensive research, the mechanisms underlying how neurons encode\nexternal inputs remain poorly understood. Recent work has focused on the\nresponse of a single neuron to a weak, subthreshold periodic signal. By\nsimulating the FitzHugh-Nagumo stochastic model and then using a symbolic\nmethod to analyze the firing activity of the neuron, preferred and infrequent\nspike patterns (defined by the relative timing of the spikes) were detected,\nwhose probabilities encode information about the signal. As not individual\nneurons in isolation but neuronal populations are responsible for the emergence\nof complex behaviors, a relevant question is whether this coding mechanism is\nrobust when the neuron is not isolated. We study how a second neuron, which\ndoes not perceive the subthreshold signal, affects the detection and the\nencoding of the signal, done by the first neuron. Through simulations of two\ncoupled FitzHugh-Nagumo neurons we show that the coding mechanism is indeed\nrobust, as the neuron that perceives the signal fires a spike train that has\nsymbolic patterns whose probabilities depend on the features of the signal.\nMoreover, we show that the second neuron facilitates the detection of the\nsignal, by lowering the firing threshold of the first neuron. This in turn\ndecreases the internal noise level need to fire the spikes that encode the\nsignal. We also show that the probabilities of the symbolic patterns achieve\nmaximum or minimum values when the period of the external signal is close to\n(or is half of) the mean firing period of the neuron.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 14:55:33 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Masoliver", "Maria", ""], ["Masoller", "Cristina", ""]]}, {"id": "1711.08359", "submitter": "Wolfgang Fr\\\"uhwirt", "authors": "Wolfgang Fruehwirt, Matthias Gerstgrasser, Pengfei Zhang, Leonard\n  Weydemann, Markus Waser, Reinhold Schmidt, Thomas Benke, Peter Dal-Bianco,\n  Gerhard Ransmayr, Dieter Grossegger, Heinrich Garn, Gareth W. Peters, Stephen\n  Roberts, Georg Dorffner", "title": "Riemannian tangent space mapping and elastic net regularization for\n  cost-effective EEG markers of brain atrophy in Alzheimer's disease", "comments": "Presented at NIPS 2017 Workshop on Machine Learning for Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diagnosis of Alzheimer's disease (AD) in routine clinical practice is\nmost commonly based on subjective clinical interpretations. Quantitative\nelectroencephalography (QEEG) measures have been shown to reflect\nneurodegenerative processes in AD and might qualify as affordable and thereby\nwidely available markers to facilitate the objectivization of AD assessment.\nHere, we present a novel framework combining Riemannian tangent space mapping\nand elastic net regression for the development of brain atrophy markers. While\nmost AD QEEG studies are based on small sample sizes and psychological test\nscores as outcome measures, here we train and test our models using data of one\nof the largest prospective EEG AD trials ever conducted, including MRI\nbiomarkers of brain atrophy.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 16:00:04 GMT"}], "update_date": "2017-11-24", "authors_parsed": [["Fruehwirt", "Wolfgang", ""], ["Gerstgrasser", "Matthias", ""], ["Zhang", "Pengfei", ""], ["Weydemann", "Leonard", ""], ["Waser", "Markus", ""], ["Schmidt", "Reinhold", ""], ["Benke", "Thomas", ""], ["Dal-Bianco", "Peter", ""], ["Ransmayr", "Gerhard", ""], ["Grossegger", "Dieter", ""], ["Garn", "Heinrich", ""], ["Peters", "Gareth W.", ""], ["Roberts", "Stephen", ""], ["Dorffner", "Georg", ""]]}, {"id": "1711.08533", "submitter": "Connor Brennan", "authors": "Connor Brennan and Alex Proekt", "title": "Universality of macroscopic neuronal dynamics in Caenorhabditis elegans", "comments": "23 pages of main text, 5 main figures, 34 page supplementary with 19\n  supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recordings of whole brain activity with single neuron resolution are now\nfeasible in simple organisms. Yet, it is still challenging to appropriately\nsimplify such complex, noisy, and multivariate data in order to reveal general\nprinciples of nervous system function. Here, we develop a method that allows us\nto extract global brain dynamics from pan-neuronal imaging. Success of this\nmethod is rooted in a surprising mathematical connection between dimensionality\nreduction and a general class of thermodynamic systems. Application of this\ntheoretical framework to the nervous system of C. elegans reveals the manifold\nthat sculpts global brain dynamics. This manifold allows us to predict switches\nbetween worm behaviors across individuals, implying that macroscopic dynamics\nembodied by the manifold are universal. In contrast, activation of individual\nneurons differs consistently between worms. These findings suggest that brains\nof genetically identical individuals express distinct microscopic neuronal\nconfigurations which nonetheless yield equivalent macroscopic dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 22 Nov 2017 22:59:52 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Brennan", "Connor", ""], ["Proekt", "Alex", ""]]}, {"id": "1711.08856", "submitter": "Alessandro Achille", "authors": "Alessandro Achille, Matteo Rovere, Stefano Soatto", "title": "Critical Learning Periods in Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "UCLA-TR-170017", "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similar to humans and animals, deep artificial neural networks exhibit\ncritical periods during which a temporary stimulus deficit can impair the\ndevelopment of a skill. The extent of the impairment depends on the onset and\nlength of the deficit window, as in animal models, and on the size of the\nneural network. Deficits that do not affect low-level statistics, such as\nvertical flipping of the images, have no lasting effect on performance and can\nbe overcome with further training. To better understand this phenomenon, we use\nthe Fisher Information of the weights to measure the effective connectivity\nbetween layers of a network during training. Counterintuitively, information\nrises rapidly in the early phases of training, and then decreases, preventing\nredistribution of information resources in a phenomenon we refer to as a loss\nof \"Information Plasticity\". Our analysis suggests that the first few epochs\nare critical for the creation of strong connections that are optimal relative\nto the input data distribution. Once such strong connections are created, they\ndo not appear to change during additional training. These findings suggest that\nthe initial learning transient, under-scrutinized compared to asymptotic\nbehavior, plays a key role in determining the outcome of the training process.\nOur findings, combined with recent theoretical results in the literature, also\nsuggest that forgetting (decrease of information in the weights) is critical to\nachieving invariance and disentanglement in representation learning. Finally,\ncritical periods are not restricted to biological systems, but can emerge\nnaturally in learning systems, whether biological or artificial, due to\nfundamental constrains arising from learning dynamics and information\nprocessing.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 01:58:54 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 13:52:02 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 11:08:56 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Achille", "Alessandro", ""], ["Rovere", "Matteo", ""], ["Soatto", "Stefano", ""]]}, {"id": "1711.08941", "submitter": "Marta Diaz Ms", "authors": "Marta Diaz-delCastillo, David P.D. Woldbye, Anne Marie Heegaard", "title": "Neuropeptide Y and its involvement in chronic pain", "comments": "18 pages, 1 figure. In press", "journal-ref": "2017,Neuroscience", "doi": "10.1016/j.neuroscience.2017.08.050", "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chronic pain is a serious condition that significantly impairs the quality of\nlife, affecting an estimate of 1.5 billion people worldwide. Despite the\nphysiological, emotional and financial burden of chronic pain, there is still a\nlack of efficient treatments. Neuropeptide Y (NPY) is a highly conserved\nendogenous peptide in the central and peripheral nervous system of all mammals,\nwhich has been implicated in both pro- and antinociceptive effects. NPY is\nexpressed in the superficial laminae of the dorsal horn of the spinal cord,\nwhere it appears to mediate its antinociceptive actions via the Y1 and Y2\nreceptors. Intrathecal administration of NPY in animal models of neuropathic,\ninflammatory or post-operative pain has been shown to cause analgesia, even\nthough its exact mechanisms are still unclear. It remains to be seen whether\nthese promising central antinociceptive effects of NPY can be transferred into\na future treatment for chronic pain.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 12:30:48 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Diaz-delCastillo", "Marta", ""], ["Woldbye", "David P. D.", ""], ["Heegaard", "Anne Marie", ""]]}, {"id": "1711.09133", "submitter": "Michael Deem", "authors": "Qiuhai Yue, Randi Martin, Simon Fischer-Baum, Aurora I. Ramos-Nu\\~nez,\n  Fengdan Ye, and Michael W. Deem", "title": "Brain Modularity Mediates the Relation between Task Complexity and\n  Performance", "comments": "47 pages; 4 figures", "journal-ref": "J. Cog. Neurosci. 29 (2017) 1532-1546", "doi": "10.1162/jocn_a_01142", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work in cognitive neuroscience has focused on analyzing the brain as a\nnetwork, rather than as a collection of independent regions. Prior studies\ntaking this approach have found that individual differences in the degree of\nmodularity of the brain network relate to performance on cognitive tasks.\nHowever, inconsistent results concerning the direction of this relationship\nhave been obtained, with some tasks showing better performance as modularity\nincreases and other tasks showing worse performance. A recent theoretical model\n(Chen & Deem, 2015) suggests that these inconsistencies may be explained on the\ngrounds that high-modularity networks favor performance on simple tasks whereas\nlow-modularity networks favor performance on more complex tasks. The current\nstudy tests these predictions by relating modularity from resting-state fMRI to\nperformance on a set of simple and complex behavioral tasks. Complex and simple\ntasks were defined on the basis of whether they did or did not draw on\nexecutive attention. Consistent with predictions, we found a negative\ncorrelation between individuals' modularity and their performance on a\ncomposite measure combining scores from the complex tasks but a positive\ncorrelation with performance on a composite measure combining scores from the\nsimple tasks. These results and theory presented here provide a framework for\nlinking measures of whole brain organization from network neuroscience to\ncognitive processing.\n", "versions": [{"version": "v1", "created": "Fri, 24 Nov 2017 20:50:59 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Yue", "Qiuhai", ""], ["Martin", "Randi", ""], ["Fischer-Baum", "Simon", ""], ["Ramos-Nu\u00f1ez", "Aurora I.", ""], ["Ye", "Fengdan", ""], ["Deem", "Michael W.", ""]]}, {"id": "1711.09199", "submitter": "Bruno. Cessac", "authors": "Dora Matzakou-Karvouniari, Lionel Gil, Elaine Orendorff, Olivier\n  Marre, Serge Picaud, Bruno Cessac", "title": "A biophysical model explains the spontaneous bursting behavior in the\n  developing retina", "comments": "25 pages, 13 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During early development, waves of activity propagate across the retina and\nplay a key role in the proper wiring of the early visual system. During the\nstage II these waves are triggered by a transient network of neurons, called\nStarburst Amacrine Cells (SACs), showing a bursting activity which disappears\nupon further maturation. While several models have attempted to reproduce\nretinal waves, none of them is able to mimic the rhythmic autonomous bursting\nof individual SACs and reveal how these cells change their intrinsic properties\nduring development. Here, we introduce a mathematical model, grounded on\nbiophysics, which enables us to reproduce the bursting activity of SACs and to\npropose a plausible, generic and robust, mechanism that generates it. The core\nparameters controlling repetitive firing are fast depolarizing $V$-gated\ncalcium channels and hyperpolarizing $V$-gated potassium channels. The\nquiescent phase of bursting is controlled by a slow after hyperpolarization\n(sAHP), mediated by calcium-dependent potassium channels. Based on a\nbifurcation analysis we show how biophysical parameters, regulating calcium and\npotassium activity, control the spontaneously occurring fast oscillatory\nactivity followed by long refractory periods in individual SACs. We make a\ntestable experimental prediction on the role of voltage-dependent potassium\nchannels on the excitability properties of SACs and on the evolution of this\nexcitability along development. We also propose an explanation on how SACs can\nexhibit a large variability in their bursting periods, as observed\nexperimentally within a SACs network as well as across different species, yet\nbased on a simple, unique, mechanism. As we discuss, these observations at the\ncellular level have a deep impact on the retinal waves description.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 06:23:35 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 14:10:39 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 07:19:16 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Matzakou-Karvouniari", "Dora", ""], ["Gil", "Lionel", ""], ["Orendorff", "Elaine", ""], ["Marre", "Olivier", ""], ["Picaud", "Serge", ""], ["Cessac", "Bruno", ""]]}, {"id": "1711.09273", "submitter": "Stuart Hagler", "authors": "Stuart Hagler", "title": "A General Optimal Control Model of Human Movement Patterns II: Rapid,\n  Targeted Hand Movements (Fitts Law)", "comments": "25 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid, targeted hand movements exhibit a regular movement pattern described\nby Fitts law. We develop a model of these movements in which this movement\npattern results from an optimal control model describing rapid hand movements\nand a utility model describing the speed/accuracy trade-off between moving the\nhand rapidly to the target and hitting the target accurately. The optimal\ncontrol model is constructed using principled approach in which we forbid the\nmuscle forces to exhibit any discontinuities and require the cost to be\nexpressed in terms of a psychophysical representation of the movement. This\nyields a yank-control or jerk-control model of the movement which exhibits two\nconstants of the motion that are closely related to the energy and momentum in\nclassical mechanics. We force the optimal control model to obey Fitts law by\nrequiring a particular relationship hold between the constants of the motion\nand the size of the target and show that the resulting model compares well to a\nstandard expression of Fitts law obtained empirically using observations of\ncomputer mouse movements. We then proceed to further show how this relationship\nmay be obtained as the result of a simple models of the movement accuracy and\nthe speed/accuracy trade-off. We use the movement accuracy model to analyze\nobserved differences in computer mouse movement patterns between older adults\nwith mild cognitive impairment and intact older adults. We conclude by looking\nat how a subject might carry out in practice the optimization implicit in\nresolving the speed/accuracy trade-off in our model.\n", "versions": [{"version": "v1", "created": "Sat, 25 Nov 2017 18:59:40 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2018 20:46:51 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Hagler", "Stuart", ""]]}, {"id": "1711.09536", "submitter": "Shatrunjai Singh", "authors": "Shatrunjai P. Singh and Swagata Karkare", "title": "Stress, Depression and Neuroplasticity", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modifications of signaling pathways and synapses owing to changing behaviors,\nenvironments, numerous neural modulation as well as brain-tissue injuries is\ndefined as neuroplasticity in developmental neurology. The central purpose of\nthe review is to gain a better understanding of the relation between stress,\ndepression and neuroplasticity and explore potential therapeutic interventions\nfor enhancing neural resilience. We have also reviewed the role of different\nfactors like age, stress and sex on inducing neuroplasticity within various\nbrain regions.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 04:57:02 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Singh", "Shatrunjai P.", ""], ["Karkare", "Swagata", ""]]}, {"id": "1711.09672", "submitter": "Francesca Mastrogiuseppe", "authors": "Francesca Mastrogiuseppe and Srdjan Ostojic", "title": "Linking connectivity, dynamics and computations in low-rank recurrent\n  neural networks", "comments": null, "journal-ref": "Neuron Volume 99, Issue 3, 8 August 2018, Pages 609-623.e29", "doi": "10.1016/j.neuron.2018.07.003", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale neural recordings have established that the transformation of\nsensory stimuli into motor outputs relies on low-dimensional dynamics at the\npopulation level, while individual neurons exhibit complex selectivity.\nUnderstanding how low-dimensional computations on mixed, distributed\nrepresentations emerge from the structure of the recurrent connectivity and\ninputs to cortical networks is a major challenge. Here, we study a class of\nrecurrent network models in which the connectivity is a sum of a random part\nand a minimal, low-dimensional structure. We show that, in such networks, the\ndynamics are low dimensional and can be directly inferred from connectivity\nusing a geometrical approach. We exploit this understanding to determine\nminimal connectivity required to implement specific computations, and find that\nthe dynamical range and computational capacity quickly increase with the\ndimensionality of the connectivity structure. This framework produces testable\nexperimental predictions for the relationship between connectivity,\nlow-dimensional dynamics and computational features of recorded neurons.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 13:21:09 GMT"}, {"version": "v2", "created": "Tue, 28 Aug 2018 16:09:40 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Mastrogiuseppe", "Francesca", ""], ["Ostojic", "Srdjan", ""]]}, {"id": "1711.09841", "submitter": "Michael Deem", "authors": "Aurora I. Ramos-Nu\\~nez, Simon Fischer-Baum, Randi Martin, Qiuhai Yue,\n  Fengdan Ye, and Michael W. Deem", "title": "Static and dynamic measures of human brain connectivity predict\n  complementary aspects of human cognitive performance", "comments": "37 pages; 7 figures", "journal-ref": "Frontiers in Human Neuroscience (2017)", "doi": "10.3389/fnhum.2017.00420", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cognitive network neuroscience, the connectivity and community structure\nof the brain network is related to cognition. Much of this research has focused\non two measures of connectivity - modularity and flexibility - which frequently\nhave been examined in isolation. By using resting state fMRI data from 52 young\nadults, we investigate the relationship between modularity, flexibility and\nperformance on cognitive tasks. We show that flexibility and modularity are\nhighly negatively correlated. However, we also demonstrate that flexibility and\nmodularity make unique contributions to explain task performance, with\nmodularity predicting performance for simple tasks and flexibility predicting\nperformance on complex tasks that require cognitive control and executive\nfunctioning. The theory and results presented here allow for stronger links\nbetween measures of brain network connectivity and cognitive processes.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 17:29:55 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Ramos-Nu\u00f1ez", "Aurora I.", ""], ["Fischer-Baum", "Simon", ""], ["Martin", "Randi", ""], ["Yue", "Qiuhai", ""], ["Ye", "Fengdan", ""], ["Deem", "Michael W.", ""]]}, {"id": "1711.09876", "submitter": "James Aimone", "authors": "James B. Aimone and William M. Severa", "title": "Context-modulation of hippocampal dynamics and deep convolutional\n  networks", "comments": "4 pages; short paper accepted to 2017 NIPS Cognitively Informed AI\n  Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex architectures of biological neural circuits, such as parallel\nprocessing pathways, has been behaviorally implicated in many cognitive\nstudies. However, the theoretical consequences of circuit complexity on neural\ncomputation have only been explored in limited cases. Here, we introduce a\nmechanism by which direct and indirect pathways from cortex to the CA3 region\nof the hippocampus can balance both contextual gating of memory formation and\ndriving network activity. We implement this concept in a deep artificial neural\nnetwork by enabling a context-sensitive bias. The motivation for this is to\nimprove performance of a size-constrained network. Using direct knowledge of\nthe superclass information in the CIFAR-100 and Fashion-MNIST datasets, we show\na dramatic increase in performance without an increase in network size.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 18:47:21 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Aimone", "James B.", ""], ["Severa", "William M.", ""]]}, {"id": "1711.10376", "submitter": "Shimin Cai Dr", "authors": "Shi-Min Cai, Wei Chen, Dong-Bai Liu, Ming Tang, Xun Chen", "title": "Complex network analysis of brain functional connectivity under a\n  multi-step cognitive task", "comments": "18 pages 6 figures", "journal-ref": "Physica A 466, 663 (2017)", "doi": "10.1016/j.physa.2016.09.058", "report-no": null, "categories": "q-bio.NC physics.bio-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional brain network has been widely studied to understand the\nrelationship between brain organization and behavior. In this paper, we aim to\nexplore the functional connectivity of brain network under a \\emph{multi-step}\ncognitive task involving with consecutive behaviors, and further understand the\neffect of behaviors on the brain organization. The functional brain networks\nare constructed base on a high spatial and temporal resolution fMRI dataset and\nanalyzed via complex network based approach. We find that at voxel level the\nfunctional brain network shows robust small-worldness and scale-free\ncharacteristics, while its assortativity and rich-club organization are\nslightly restricted to order of behaviors performed. More interestingly, the\nfunctional connectivity of brain network in activated ROIs strongly correlates\nwith behaviors and behaves obvious differences restricted to order of behaviors\nperformed. These empirical results suggest that the brain organization has the\ngeneric properties of small-worldness and scale-free characteristics, and its\ndiverse function connectivity emerging from activated ROIs is strongly driven\nby these behavioral activities via the plasticity of brain.\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 16:16:33 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Cai", "Shi-Min", ""], ["Chen", "Wei", ""], ["Liu", "Dong-Bai", ""], ["Tang", "Ming", ""], ["Chen", "Xun", ""]]}, {"id": "1711.10586", "submitter": "Vicent Sanchis Jurado", "authors": "Vicent Sanchis-Jurado, Sophie Triantaphillidou, Edward Fry, Alvaro\n  Pons", "title": "Effect of fixation target on the contrast sensitivity in the foveal and\n  parafoveal area", "comments": "12 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose\n  To determine the influence on the contrast sensitivity when the stimulus\ncontains a fixation target in two retinal locations, foveal and parafoveal.\n  Methods\n  Four young adults with 0.0 logMar acuity participated in this study. The\nstimulus was based on vertical sinusoidal gratings masked by a circular (for\nfoveal area) or a ring (for parafoveal area). To increase the luminance\nresolution of the display a bit-stealing technique was used. Four different\nsets of stimuli were generated, two for exploring the foveal sensitivity and\ntwo for the parafoveal area. The difference between the sets designed for the\nsame area was the presence, or absence, of a fixation target (a white cross) in\nthe centre of the stimulus. A modified staircase method was implemented.\n  Results\n  The results show a drop in the contrast sensitivity when the fixation target\nwas present on the stimulus for frequencies smaller than 4 cycles per degree.\n  Conclusions\n  The presence of fixation targets diminishes the contrast sensitivity for low\nto mid frequencies over different concentric areas of the retina. This could be\ndue to the fixational eye movements, different patterns of eye movements were\nfound using an eye tracker. The relationship between the sensitivity in the\nfoveal area and the parafoveal agrees with those reported by other authors\nusing different designs confirming that the new stimulus design is suitable to\nmeasure the contrast sensitivity outside the foveal area.\n", "versions": [{"version": "v1", "created": "Mon, 27 Nov 2017 15:43:53 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Sanchis-Jurado", "Vicent", ""], ["Triantaphillidou", "Sophie", ""], ["Fry", "Edward", ""], ["Pons", "Alvaro", ""]]}, {"id": "1711.10814", "submitter": "Hiroshi Tsukimoto", "authors": "Hiroshi Tsukimoto and Takefumi Matsubara", "title": "A new fMRI data analysis method using cross validation: Negative BOLD\n  responses may be the deactivations of interneurons", "comments": "23 pages, 2 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although functional magnetic resonance imaging (fMRI) is widely used for the\nstudy of brain functions, the blood oxygenation level dependent (BOLD) effect\nis incompletely understood. Particularly, negative BOLD responses(NBRs) is\ncontroversial. This paper presents a new fMRI data analysis method, which is\nmore accurate than the typical conventional method. The authors conducted the\nexperiments of simple repetition, and analyzed the data by the new method. The\nresults strongly suggest that the deactivations(NBRs) detected by the new\nmethod are the deactivations of interneurons, because the deactivation ratios\nobtained by the new method approximately equals the deactivation ratios of\ninterneurons obtained by the study of interneurons. The (de)activations\ndetected by the new method are largely different from those detected by the\nconventional method. The new method is more accurate than the conventional\nmethod, and therefore the (de)activations detected by the new method may be\ncorrect and the (de)activations detected by the conventional method may be\nincorrect. A large portion of the deactivations of inhibitory interneurons is\nalso considered to be activations. Therefore, the right-tailed t-test, which is\nusually performed in the conventional method, does not detect the whole\nactivation, because the right-tailed t-test only detects the activations of\nexcitatory neurons, and neglect the deactivations of inhibitory interneurons. A\nlot of fMRI studies so far by the conventional method should be re-examined by\nthe new method, and many results obtained so far will be modified.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 12:32:51 GMT"}, {"version": "v2", "created": "Sun, 10 Dec 2017 08:43:26 GMT"}], "update_date": "2017-12-12", "authors_parsed": [["Tsukimoto", "Hiroshi", ""], ["Matsubara", "Takefumi", ""]]}, {"id": "1711.10930", "submitter": "David Dahmen", "authors": "David Dahmen, Sonja Gr\\\"un, Markus Diesmann, Moritz Helias", "title": "Two types of criticality in the brain", "comments": null, "journal-ref": "PNAS 116 (26) 13051-13060 (2019)", "doi": "10.1073/pnas.1818972116", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks with equal excitatory and inhibitory feedback show high\ncomputational performance. They operate close to a critical point characterized\nby the joint activation of large populations of neurons. Yet, in macaque motor\ncortex we observe very different dynamics with weak fluctuations on the\npopulation level. This suggests that motor cortex operates in a sub-optimal\nregime. Here we show the opposite: the large dispersion of correlations across\nneurons is a signature of a rich dynamical repertoire, hidden from macroscopic\nbrain signals, but essential for high performance in such concepts as reservoir\ncomputing. Our findings suggest a refinement of the view on criticality in\nneural systems: network topology and heterogeneity endow the brain with two\ncomplementary substrates for critical dynamics of largely different\ncomplexities.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 16:01:00 GMT"}, {"version": "v2", "created": "Mon, 19 Mar 2018 12:08:38 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Dahmen", "David", ""], ["Gr\u00fcn", "Sonja", ""], ["Diesmann", "Markus", ""], ["Helias", "Moritz", ""]]}, {"id": "1711.10991", "submitter": "Alejandro Tabas", "authors": "Alejandro Tabas, Martin Andermann, Valeria Sebold, Helmut Riedel,\n  Emili Balaguer-Ballester and Andr\\'e Rupp", "title": "Early processing of consonance and dissonance in human auditory cortex", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pitch is the perceptual correlate of sound's periodicity and a fundamental\nproperty of the auditory sensation. The interaction of two or more pitches\ngives rise to a sensation that can be characterized by its degree of consonance\nor dissonance. In the current study, we investigated the neuromagnetic\nrepresentations of consonant and dissonant musical dyads using a new model of\ncortical activity, in an effort to assess the possible involvement of\npitch-specific neural mechanisms in consonance processing at early cortical\nstages.\n  In the first step of the study, we developed a novel model of cortical pitch\nprocessing designed to explain the morphology of the pitch onset response\n(POR), a pitch-specific subcomponent of the auditory evoked N100 component in\nthe human auditory cortex. The model explains the neural mechanisms underlying\nthe generation of the POR and quantitatively accounts for the relation between\nits peak latency and the perceived pitch.\n  Next, we applied magnetoencephalography (MEG) to record the POR as elicited\nby six consonant and dissonant dyads. The peak latency of the POR was strongly\nmodulated by the degree of consonance within the stimuli; specifically, the\nmost dissonant dyad exhibited a POR with a latency that was about 30ms longer\nthan that of the most consonant dyad, an effect that greatly exceeds the\nexpected latency difference induced by a single pitch sound.\n  Our model was able to predict the POR latency pattern observed in the\nneuromagnetic data, and to generalize this prediction to additional dyads.\nThese results indicate that the neural mechanisms responsible for pitch\nprocessing exhibit an intrinsic differential response to concurrent consonant\nand dissonant pitch combinations, suggesting that the perception of consonance\nand dissonance might be an emergent property of the pitch processing system in\nhuman auditory cortex.\n", "versions": [{"version": "v1", "created": "Wed, 29 Nov 2017 18:10:29 GMT"}, {"version": "v2", "created": "Thu, 30 Nov 2017 13:26:37 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Tabas", "Alejandro", ""], ["Andermann", "Martin", ""], ["Sebold", "Valeria", ""], ["Riedel", "Helmut", ""], ["Balaguer-Ballester", "Emili", ""], ["Rupp", "Andr\u00e9", ""]]}, {"id": "1711.11314", "submitter": "Vince Grolmusz", "authors": "Mate Fellner and Balint Varga and Vince Grolmusz", "title": "The Frequent Subgraphs of the Connectome of the Human Brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mapping the human structural connectome, we are in a very fortunate\nsituation: one can compute and compare graphs, describing the cerebral\nconnections between the very same, anatomically identified small regions of the\ngray matter among hundreds of human subjects. The comparison of these graphs\nhas led to numerous recent results, as the (i) discovery that women's\nconnectomes have deeper and richer connectivity-related graph parameters like\nthose of men, or (ii) the description of more and less conservatively connected\nlobes and cerebral regions, and (iii) the discovery of the phenomenon of the\nConsensus Connectome Dynamics.\n  Today one of the greatest challenges of brain science is the description and\nmodeling of the circuitry of the human brain. For this goal, we need to\nidentify sub-circuits that are present in almost all human subjects and those,\nwhich are much less frequent: the former sub-circuits most probably have\nfunctions with general importance, the latter sub-circuits are probably related\nto the individual variability of the brain structure and functions. The present\ncontribution describes the frequent connected subgraphs (instead of\nsub-circuits) of at most 6 edges in the human brain. We analyze these frequent\ngraphs and also examine sex differences in these graphs: we demonstrate\nnumerous connected sub-graphs that are more frequent in female or the male\nconnectome. While our results describe subgraphs, instead of sub-circuits, we\nneed to note that all macroscopic sub-circuits correspond to an underlying\nconnected subgraph.\n  Our data source is the public release of the Human Connectome Project, and we\nare applying the data of 426 human subjects in this study.\n", "versions": [{"version": "v1", "created": "Thu, 30 Nov 2017 10:45:43 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Fellner", "Mate", ""], ["Varga", "Balint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1711.11408", "submitter": "Daniel Chicharro", "authors": "Daniel Chicharro, Giuseppe Pica, Stefano Panzeri", "title": "The identity of information: how deterministic dependencies constrain\n  information synergy and redundancy", "comments": null, "journal-ref": null, "doi": "10.3390/e20030169", "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding how different information sources together transmit information\nis crucial in many domains. For example, understanding the neural code requires\ncharacterizing how different neurons contribute unique, redundant, or\nsynergistic pieces of information about sensory or behavioral variables.\nWilliams and Beer (2010) proposed a partial information decomposition (PID)\nwhich separates the mutual information that a set of sources contains about a\nset of targets into nonnegative terms interpretable as these pieces.\nQuantifying redundancy requires assigning an identity to different information\npieces, to assess when information is common across sources. Harder et al.\n(2013) proposed an identity axiom stating that there cannot be redundancy\nbetween two independent sources about a copy of themselves. However,\nBertschinger et al. (2012) showed that with a deterministically related\nsources-target copy this axiom is incompatible with ensuring PID nonnegativity.\nHere we study systematically the effect of deterministic target-sources\ndependencies. We introduce two synergy stochasticity axioms that generalize the\nidentity axiom, and we derive general expressions separating stochastic and\ndeterministic PID components. Our analysis identifies how negative terms can\noriginate from deterministic dependencies and shows how different assumptions\non information identity, implicit in the stochasticity and identity axioms,\ndetermine the PID structure. The implications for studying neural coding are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Mon, 13 Nov 2017 12:27:42 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Chicharro", "Daniel", ""], ["Pica", "Giuseppe", ""], ["Panzeri", "Stefano", ""]]}]