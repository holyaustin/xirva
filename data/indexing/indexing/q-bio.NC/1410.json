[{"id": "1410.0446", "submitter": "Arash Mahyari", "authors": "Arash Golibagh Mahyari, Selin Aviyente", "title": "Identification of Dynamic functional brain network states Through Tensor\n  Decomposition", "comments": "2014 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP)", "journal-ref": null, "doi": "10.1109/ICASSP.2014.6853969", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advances in high resolution neuroimaging, there has been a growing\ninterest in the detection of functional brain connectivity. Complex network\ntheory has been proposed as an attractive mathematical representation of\nfunctional brain networks. However, most of the current studies of functional\nbrain networks have focused on the computation of graph theoretic indices for\nstatic networks, i.e. long-time averages of connectivity networks. It is\nwell-known that functional connectivity is a dynamic process and the\nconstruction and reorganization of the networks is key to understanding human\ncognition. Therefore, there is a growing need to track dynamic functional brain\nnetworks and identify time intervals over which the network is\nquasi-stationary. In this paper, we present a tensor decomposition based method\nto identify temporally invariant 'network states' and find a common topographic\nrepresentation for each state. The proposed methods are applied to\nelectroencephalogram (EEG) data during the study of error-related negativity\n(ERN).\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 03:41:53 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Mahyari", "Arash Golibagh", ""], ["Aviyente", "Selin", ""]]}, {"id": "1410.0507", "submitter": "Claudius Gros", "authors": "Rodrigo Echeveste and Claudius Gros", "title": "Generating functionals for computational intelligence: the Fisher\n  information as an objective function for self-limiting Hebbian learning rules", "comments": null, "journal-ref": "Frontiers in Robotics and AI 1, 1 (2014)", "doi": "10.3389/frobt.2014.00001", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating functionals may guide the evolution of a dynamical system and\nconstitute a possible route for handling the complexity of neural networks as\nrelevant for computational intelligence. We propose and explore a new objective\nfunction, which allows to obtain plasticity rules for the afferent synaptic\nweights. The adaption rules are Hebbian, self-limiting, and result from the\nminimization of the Fisher information with respect to the synaptic flux. We\nperform a series of simulations examining the behavior of the new learning\nrules in various circumstances. The vector of synaptic weights aligns with the\nprincipal direction of input activities, whenever one is present. A linear\ndiscrimination is performed when there are two or more principal directions;\ndirections having bimodal firing-rate distributions, being characterized by a\nnegative excess kurtosis, are preferred. We find robust performance and full\nhomeostatic adaption of the synaptic weights results as a by-product of the\nsynaptic flux minimization. This self-limiting behavior allows for stable\nonline learning for arbitrary durations. The neuron acquires new information\nwhen the statistics of input activities is changed at a certain point of the\nsimulation, showing however, a distinct resilience to unlearn previously\nacquired knowledge. Learning is fast when starting with randomly drawn synaptic\nweights and substantially slower when the synaptic weights are already fully\nadapted.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 10:52:49 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Echeveste", "Rodrigo", ""], ["Gros", "Claudius", ""]]}, {"id": "1410.0557", "submitter": "Rodrigo Echeveste", "authors": "Rodrigo Echeveste and Claudius Gros", "title": "Two-trace model for spike-timing-dependent synaptic plasticity", "comments": "Neural Computation (in press)", "journal-ref": "Neural Computation 2015, 27(3), 672-698", "doi": "10.1162/NECO_a_00707", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an effective model for timing-dependent synaptic plasticity (STDP)\nin terms of two interacting traces, corresponding to the fraction of activated\nNMDA receptors and the Ca2+ concentration in the dendritic spine of the\npostsynaptic neuron. This model intends to bridge the worlds of existing\nsimplistic phenomenological rules and highly detailed models, constituting thus\na practical tool for the study of the interplay between neural activity and\nsynaptic plasticity in extended spiking neural networks. For isolated pairs of\npre- and postsynaptic spikes the standard pairwise STDP rule is reproduced,\nwith appropriate parameters determining the respective weights and time scales\nfor the causal and the anti-causal contributions. The model contains otherwise\nonly three free parameters which can be adjusted to reproduce triplet\nnonlinearities in both hippocampal culture and cortical slices. We also\ninvestigate the transition from time-dependent to rate-dependent plasticity\noccurring for both correlated and uncorrelated spike patterns.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 14:11:20 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Echeveste", "Rodrigo", ""], ["Gros", "Claudius", ""]]}, {"id": "1410.0818", "submitter": "Junhua Li", "authors": "Junhua Li, Zbigniew Struzik, Liqing Zhang, Andrzej Cichocki", "title": "Feature Learning from Incomplete EEG with Denoising Autoencoder", "comments": "The paper was accepted for publication by Neurocomputing", "journal-ref": "Neurocomputing, 2015, 165: 23-31", "doi": "10.1016/j.neucom.2014.08.092", "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An alternative pathway for the human brain to communicate with the outside\nworld is by means of a brain computer interface (BCI). A BCI can decode\nelectroencephalogram (EEG) signals of brain activities, and then send a command\nor an intent to an external interactive device, such as a wheelchair. The\neffectiveness of the BCI depends on the performance in decoding the EEG.\nUsually, the EEG is contaminated by different kinds of artefacts (e.g.,\nelectromyogram (EMG), background activity), which leads to a low decoding\nperformance. A number of filtering methods can be utilized to remove or weaken\nthe effects of artefacts, but they generally fail when the EEG contains extreme\nartefacts. In such cases, the most common approach is to discard the whole data\nsegment containing extreme artefacts. This causes the fatal drawback that the\nBCI cannot output decoding results during that time. In order to solve this\nproblem, we employ the Lomb-Scargle periodogram to estimate the spectral power\nfrom incomplete EEG (after removing only parts contaminated by artefacts), and\nDenoising Autoencoder (DAE) for learning. The proposed method is evaluated with\nmotor imagery EEG data. The results show that our method can successfully\ndecode incomplete EEG to good effect.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 11:12:47 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Li", "Junhua", ""], ["Struzik", "Zbigniew", ""], ["Zhang", "Liqing", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1410.1025", "submitter": "Oscar Sotolongo-Grau", "authors": "Oscar Sotolongo-Costa, L. M. Gaggero-Sager, J. T. Becker, F. Maest\\'u,\n  O. Sotolongo-Grau", "title": "A physical model for dementia", "comments": "12 pages, 4 figures. submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aging associated brain decline often result in some kind of dementia. Even\nwhen this is a complex brain disorder a physical model can be used in order to\ndescribe its general behavior. This model is based in first principles. A\nprobabilistic model for the development of dementia is obtained and fitted to\nsome experimental data obtained from the Alzheimer's Disease Neuroimaging\nInitiative. It is explained how dementia appears as a consequence of aging and\nwhy it is irreversible.\n", "versions": [{"version": "v1", "created": "Sat, 4 Oct 2014 07:18:08 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2015 09:50:41 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2015 07:48:50 GMT"}, {"version": "v4", "created": "Tue, 10 May 2016 12:07:52 GMT"}, {"version": "v5", "created": "Thu, 21 Jul 2016 15:40:06 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Sotolongo-Costa", "Oscar", ""], ["Gaggero-Sager", "L. M.", ""], ["Becker", "J. T.", ""], ["Maest\u00fa", "F.", ""], ["Sotolongo-Grau", "O.", ""]]}, {"id": "1410.1029", "submitter": "Laurence Aitchison", "authors": "Laurence Aitchison, Jannes Jegminat, Jorge Aurelio Menendez,\n  Jean-Pascal Pfister, Alex Pouget and Peter E. Latham", "title": "Synaptic plasticity as Bayesian inference", "comments": "Published in Nature Neuroscience:\n  https://www.nature.com/articles/s41593-021-00809-5", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning, especially rapid learning, is critical for survival. However,\nlearning is hard: a large number of synaptic weights must be set based on\nnoisy, often ambiguous, sensory information. In such a high-noise regime,\nkeeping track of probability distributions over weights is the optimal\nstrategy. Here we hypothesize that synapses take that strategy; in essence,\nwhen they estimate weights, they include error bars. They then use that\nuncertainty to adjust their learning rates, with more uncertain weights having\nhigher learning rates. We also make a second, independent, hypothesis: synapses\ncommunicate their uncertainty by linking it to variability in PSP size, with\nmore uncertainty leading to more variability. These two hypotheses cast\nsynaptic plasticity as a problem of Bayesian inference, and thus provide a\nnormative view of learning. They generalize known learning rules, offer an\nexplanation for the large variability in the size of post-synaptic potentials,\nand make falsifiable experimental predictions.\n", "versions": [{"version": "v1", "created": "Sat, 4 Oct 2014 09:13:22 GMT"}, {"version": "v2", "created": "Fri, 10 Oct 2014 08:03:22 GMT"}, {"version": "v3", "created": "Wed, 26 Apr 2017 10:51:39 GMT"}, {"version": "v4", "created": "Fri, 19 Mar 2021 11:44:11 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Aitchison", "Laurence", ""], ["Jegminat", "Jannes", ""], ["Menendez", "Jorge Aurelio", ""], ["Pfister", "Jean-Pascal", ""], ["Pouget", "Alex", ""], ["Latham", "Peter E.", ""]]}, {"id": "1410.1093", "submitter": "Emin Orhan", "authors": "A. Emin Orhan, Wei Ji Ma", "title": "Neural Population Coding of Multiple Stimuli", "comments": "43 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural scenes, objects generally appear together with other objects. Yet,\ntheoretical studies of neural population coding typically focus on the encoding\nof single objects in isolation. Experimental studies suggest that neural\nresponses to multiple objects are well described by linear or nonlinear\ncombinations of the responses to constituent objects, a phenomenon we call\nstimulus mixing. Here, we present a theoretical analysis of the consequences of\ncommon forms of stimulus mixing observed in cortical responses. We show that\nsome of these mixing rules can severely compromise the brain's ability to\ndecode the individual objects. This cost is usually greater than the cost\nincurred by even large reductions in the gain or large increases in neural\nvariability, explaining why the benefits of attention can be understood\nprimarily in terms of a stimulus selection, or demixing, mechanism rather than\npurely as a gain increase or noise reduction mechanism. The cost of stimulus\nmixing becomes even higher when the number of encoded objects increases,\nsuggesting a novel mechanism that might contribute to set size effects observed\nin myriad psychophysical tasks. We further show that a specific form of neural\ncorrelation and heterogeneity in stimulus mixing among the neurons can\npartially alleviate the harmful effects of stimulus mixing. Finally, we derive\nsimple conditions that must be satisfied for unharmful mixing of stimuli.\n", "versions": [{"version": "v1", "created": "Sat, 4 Oct 2014 20:45:34 GMT"}, {"version": "v2", "created": "Wed, 31 Dec 2014 17:01:18 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Orhan", "A. Emin", ""], ["Ma", "Wei Ji", ""]]}, {"id": "1410.1115", "submitter": "Andrew Sornborger", "authors": "Andrew T. Sornborger and Louis Tao", "title": "Exact, Dynamically Routable Current Propagation in Pulse-Gated Synfire\n  Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural oscillations can enhance feature recognition, modulate interactions\nbetween neurons, and improve learning and memory. Simulational studies have\nshown that coherent oscillations give rise to windows in time during which\ninformation transfer can be enhanced in neuronal networks. Unanswered questions\nare: 1) What is the transfer mechanism? And 2) how well can a transfer be\nexecuted? Here, we present a pulse-based mechanism by which graded current\namplitudes may be exactly propagated from one neuronal population to another.\nThe mechanism relies on the downstream gating of mean synaptic current\namplitude from one population of neurons to another via a pulse. Because\ntransfer is pulse-based, information may be dynamically routed through a neural\ncircuit. We demonstrate the amplitude transfer mechanism in a realistic network\nof spiking neurons and show that it is robust to noise in the form of pulse\ntiming inaccuracies, random synaptic strengths and finite size effects. In\nfinding an exact, analytical solution to a fundamental problem of information\ncoding in the brain, graded information transfer, we have isolated a basic\nmechanism that may be used as a building block for fast, complex information\nprocessing in neural circuits.\n", "versions": [{"version": "v1", "created": "Sun, 5 Oct 2014 05:41:10 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Sornborger", "Andrew T.", ""], ["Tao", "Louis", ""]]}, {"id": "1410.1116", "submitter": "Andrew Sornborger", "authors": "Andrew T. Sornborger and Louis Tao", "title": "A Unified Framework for Information Coding: Oscillations, Memory, and\n  Zombie Modes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronous neural activity can improve neural processing and is believed to\nmediate neuronal interaction by providing temporal windows during which\ninformation is more easily transferred. We demonstrate a pulse gating mechanism\nin a feedforward network that can exactly propagate graded information through\na multilayer circuit. Based on this mechanism, we present a unified framework\nwherein neural information coding and processing can be considered as a product\nof linear maps under the active control of a pulse generator. Distinct control\nand processing components combine to form the basis for the binding,\npropagation, and processing of dynamically routed information within neural\npathways. Using our framework, we construct example neural circuits to 1)\nmaintain a short-term memory, 2) compute time-windowed Fourier transforms, and\n3) perform spatial rotations. We postulate that such circuits, with stereotyped\ncontrol and processing of information, are the neural correlates of Crick and\nKoch's zombie modes.\n", "versions": [{"version": "v1", "created": "Sun, 5 Oct 2014 05:49:38 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Sornborger", "Andrew T.", ""], ["Tao", "Louis", ""]]}, {"id": "1410.1475", "submitter": "Zachary Kilpatrick PhD", "authors": "Paul C. Bressloff and Zachary P. Kilpatrick", "title": "Nonlinear Langevin equations for wandering patterns in stochastic neural\n  fields", "comments": "28 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the effects of additive, spatially extended noise on\nspatiotemporal patterns in continuum neural fields. Our main focus is how\nfluctuations impact patterns when they are weakly coupled to an external\nstimulus or another equivalent pattern. Showing the generality of our approach,\nwe study both propagating fronts and stationary bumps. Using a separation of\ntime scales, we represent the effects of noise in terms of a phase-shift of a\npattern from its uniformly translating position at long time scales, and\nfluctuations in the pattern profile around its instantaneous position at short\ntime scales. In the case of a stimulus-locked front, we show that the\nphase-shift satisfies a nonlinear Langevin equation (SDE) whose deterministic\npart has a unique stable fixed point. Using a linear-noise approximation, we\nthus establish that wandering of the front about the stimulus-locked state is\ngiven by an Ornstein-Uhlenbeck (OU) process. Analogous results hold for the\nrelative phase-shift between a pair of mutually coupled fronts, provided that\nthe coupling is excitatory. On the other hand, if the mutual coupling is given\nby a Mexican hat function (difference of exponentials), then the linear-noise\napproximation breaks down due to the co-existence of stable and unstable\nphase-locked states in the deterministic limit. Similarly, the stochastic\nmotion of mutually coupled bumps can be described by a system of nonlinearly\ncoupled SDEs, which can be linearized to yield a multivariate OU process. As in\nthe case of fronts, large deviations can cause bumps to temporarily decouple,\nleading to a phase-slip in the bump positions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 17:49:00 GMT"}, {"version": "v2", "created": "Wed, 7 Jan 2015 03:29:00 GMT"}], "update_date": "2015-01-08", "authors_parsed": [["Bressloff", "Paul C.", ""], ["Kilpatrick", "Zachary P.", ""]]}, {"id": "1410.1836", "submitter": "Stuart Kauffman", "authors": "Stuart Kauffman", "title": "A Holistic, Non-algorithmic View of Cultural Evolution: Commentary on\n  Review Article by Prof. Liane Gabora", "comments": "3 pages", "journal-ref": "Physics of Life Reviews, 10(2), 154-155", "doi": "10.1016/j.plrev.2013.05.005", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is surely some truth to the notion that culture evolves, but the\nDarwinian view of culture is trivial. Gabora does two things in this paper.\nFirst, she levels a reasoned and devastating attack on the adequacy of a\nDarwinian theory of cultural evolution, showing that cultural evolution\nviolates virtually all prerequisites to be encompassed by Darwin's standard\ntheory. Second, she advances the central concept that it is whole world views\nthat evolve. A world view emerges when the capacity of memories to evoke one\nanother surpasses a phase transition yielding a richly interconnected\nconceptual web, a world view. She proposes that cultural evolves not through a\nDarwinian process such as meme theory, but through communal exchange of facets\nof world views. Each section of her argument is completely convincing.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2014 18:25:05 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Kauffman", "Stuart", ""]]}, {"id": "1410.2098", "submitter": "Philippe Terrier PhD", "authors": "Philippe Terrier and Fabienne Reynard", "title": "Effect of age on the variability and stability of gait: a\n  cross-sectional treadmill study in healthy individuals between 20 and 69\n  years of age", "comments": "Author's version of an article published in Gait & Posture (2014)", "journal-ref": null, "doi": "10.1016/j.gaitpost.2014.09.024", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Falls during walking are a major health issue in the elderly population.\nOlder individuals are usually more cautious, work more slowly, take shorter\nsteps, and exhibit increased step-to-step variability. They often have impaired\ndynamic balance, which explains their increased falling risk. Those locomotor\ncharacteristics might be the result of the neurological/musculoskeletal\ndegenerative processes typical of advanced age or of a decline that began\nearlier in life. In order to help determine between the two possibilities, we\nanalyzed the relationship between age and gait features among 100 individuals\naged 20-69. Trunk acceleration was measured during 5-min treadmill session\nusing a 3D accelerometer. The following dependent variables were assessed:\npreferred walking speed, walk ratio (step length normalized by step frequency),\ngait instability (local dynamic stability, Lyapunov exponent method), and\nacceleration variability (root mean square (RMS)). Using age as a predictor,\nlinear regressions were performed for each dependent variable. The results\nindicated that walking speed, walk ratio and trunk acceleration variability\nwere not dependent on age (R2<2%). However, there was a significant quadratic\nassociation between age and gait instability in the mediolateral direction\n(R2=15%). We concluded that most of the typical gait features of older age do\nnot result from a slow evolution over the life course. On the other hand, gait\ninstability likely begins to increase at an accelerated rate as early as age\n40-50. This finding support the premise that local dynamic stability is likely\na relevant early indicator of falling risk.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2014 07:27:17 GMT"}, {"version": "v2", "created": "Fri, 10 Oct 2014 13:06:50 GMT"}], "update_date": "2014-10-13", "authors_parsed": [["Terrier", "Philippe", ""], ["Reynard", "Fabienne", ""]]}, {"id": "1410.2152", "submitter": "Olivier Faugeras", "authors": "Paul Bressloff, Olivier Faugeras (NEUROMATHCOMP)", "title": "On the Hamiltonian structure of large deviations in stochastic hybrid\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-bio.MN q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop the connection between large deviation theory and more applied\napproaches to stochastic hybrid systems by highlighting a common underlying\nHamiltonian structure. A stochastic hybrid system involves the coupling between\na piecewise deterministic dynamical system in $R^d$ and a time-homogeneous\nMarkov chain on some discrete space $\\Gamma$. We assume that the Markov chain\non $\\Gamma$ is ergodic, and that the discrete dynamics is much faster than the\npiecewise deterministic dynamics (separation of time-scales). Using the\nPerron-Frobenius theorem and the calculus-of-variations, we evaluate the rate\nfunction of a large deviation principle in terms of a classical action, whose\nHamiltonian is given by the Perron eigenvalue of a $|\\Gamma|$-dimensional\nlinear equation. The corresponding linear operator depends on the transition\nrates of the Markov chain and the nonlinear functions of the piecewise\ndeterministic system. The resulting Hamiltonian is identical to one derived\nusing path-integrals and WKB methods. We illustrate the theory by considering\nthe example of stochastic ion channels.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2014 18:19:43 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 17:16:34 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Bressloff", "Paul", "", "NEUROMATHCOMP"], ["Faugeras", "Olivier", "", "NEUROMATHCOMP"]]}, {"id": "1410.2610", "submitter": "Nima Dehghani", "authors": "Nima Dehghani, Adrien Peyrache, Bartosz Telenczuk, Michel Le Van\n  Quyen, Eric Halgren, Sydney S. Cash, Nicholas G. Hatsopoulos, Alain Destexhe", "title": "Dynamic Balance of Excitation and Inhibition in Human and Monkey\n  Neocortex", "comments": "Sci. Rep. 6, 23176", "journal-ref": null, "doi": "10.1038/srep23176", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Balance of excitation and inhibition is a fundamental feature of in vivo\nnetwork activity and is important for its computations. However, its presence\nin the neocortex of higher mammals is not well established. We investigated the\ndynamics of excitation and inhibition using dense multielectrode recordings in\nhumans and monkeys. We found that in all states of the wake-sleep cycle,\nexcitatory and inhibitory ensembles are well balanced, and co-fluctuate with\nslight instantaneous deviations from perfect balance, mostly in slow-wave\nsleep. Remarkably, these correlated fluctuations are seen for many different\ntemporal scales. The similarity of these computational features with a network\nmodel of self-generated balanced states suggests that such balanced activity is\nessentially generated by recurrent activity in the local network and is not due\nto external inputs. Finally, we find that this balance breaks down during\nseizures, where the temporal correlation of excitatory and inhibitory\npopulations is disrupted. These results show that balanced activity is a\nfeature of normal brain activity, and break down of the balance could be an\nimportant factor to define pathological states.\n", "versions": [{"version": "v1", "created": "Thu, 9 Oct 2014 20:25:24 GMT"}, {"version": "v2", "created": "Thu, 30 Oct 2014 18:42:12 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2015 22:46:10 GMT"}, {"version": "v4", "created": "Fri, 4 Mar 2016 15:24:23 GMT"}, {"version": "v5", "created": "Mon, 14 Mar 2016 01:32:33 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Dehghani", "Nima", ""], ["Peyrache", "Adrien", ""], ["Telenczuk", "Bartosz", ""], ["Van Quyen", "Michel Le", ""], ["Halgren", "Eric", ""], ["Cash", "Sydney S.", ""], ["Hatsopoulos", "Nicholas G.", ""], ["Destexhe", "Alain", ""]]}, {"id": "1410.3111", "submitter": "Mijung Park", "authors": "Mijung Park and Jakob H. Macke", "title": "Hierarchical models for neural population dynamics in the presence of\n  non-stationarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural population activity often exhibits rich variability and temporal\nstructure. This variability is thought to arise from single-neuron\nstochasticity, neural dynamics on short time-scales, as well as from\nmodulations of neural firing properties on long time-scales, often referred to\nas \"non-stationarity\". To better understand the nature of co-variability in\nneural circuits and their impact on cortical information processing, we need\nstatistical models that are able to capture multiple sources of variability on\ndifferent time-scales. Here, we introduce a hierarchical statistical model of\nneural population activity which models both neural population dynamics as well\nas inter-trial modulations in firing rates. In addition, we extend the model to\nallow us to capture non-stationarities in the population dynamics itself (i.e.,\ncorrelations across neurons).\n  We develop variational inference methods for learning model parameters, and\ndemonstrate that the method can recover non-stationarities in both average\nfiring rates and correlation structure. Applied to neural population recordings\nfrom anesthetized macaque primary visual cortex, our models provide a better\naccount of the structure of neural firing than stationary dynamics models.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 16:07:22 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Park", "Mijung", ""], ["Macke", "Jakob H.", ""]]}, {"id": "1410.3961", "submitter": "Peter beim Graben", "authors": "Reinhard Blutner and Peter beim Graben", "title": "Descriptive and Foundational Aspects of Quantum Cognition", "comments": "54 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum mechanics emerged as the result of a successful resolution of\nstringent empirical and profound conceptual conflicts within the development of\natomic physics at the beginning of the last century. At first glance, it seems\nto be bizarre and even ridiculous to apply ideas of quantum physics in order to\nimprove current psychological and linguistic or semantic ideas. However, a\ncloser look shows that there are some parallels in the development of quantum\nphysics and advanced theories of cognitive science. In psychology, geometric\nmodels of meaning have a long tradition. However, they suffer from many\nshortcomings which are illustrated by discussing several puzzles of bounded\nrationality. In the first part of this article, we argue that the present\naccount of quantum cognition - taking quantum probabilities rather than\nclassical probabilities - can give a more systematic description of these\npuzzles than the alternate and rather eclectic treatments in the traditional\nframework of bounded rationality. Unfortunately, the quantum probabilistic\ntreatment does not always and does not automatically provide a deeper\nunderstanding and a true explanation of these puzzles. In the second part of\nthis article, we explain the foundational issue from the perspective of Piron,\nFoulis, Randall, and others, and we apply it to the foundation of quantum\ncognition. In this connection, we show that quantum probabilities are of\n(virtual) conceptual necessity if grounded in an abstract algebraic framework\nof orthomodular lattices. This framework is motivated by assuming partial\nBoolean algebras (describing particular perspectives) that are combined into a\nuniform system while considering certain capacity restrictions. It is at this\npoint that one important aspect of the whole idea of bounded rationality\ndirectly enters the theoretical scenery of quantum cognition: resource\nlimitation.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 08:26:01 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Blutner", "Reinhard", ""], ["Graben", "Peter beim", ""]]}, {"id": "1410.3992", "submitter": "Joaquin Torres", "authors": "Joaquin J. Torres and Irene Elices and J. Marro", "title": "Efficient transmission of subthreshold signals in complex networks of\n  spiking neurons", "comments": "31 pages, 13 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0121156", "report-no": null, "categories": "physics.bio-ph cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the efficient transmission and processing of weak,\nsubthreshold signals in a realistic neural medium in the presence of different\nlevels of the underlying noise. Assuming Hebbian weights for maximal synaptic\nconductances -- that naturally balances the network with excitatory and\ninhibitory synapses -- and considering short-term synaptic plasticity affecting\nsuch conductances, we found different dynamic phases in the system. This\nincludes a memory phase where population of neurons remain synchronized, an\noscillatory phase where transitions between different synchronized populations\nof neurons appears and an asynchronous or noisy phase. When a weak stimulus\ninput is applied to each neuron, increasing the level of noise in the medium we\nfound an efficient transmission of such stimuli around the transition and\ncritical points separating different phases for well-defined different levels\nof stochasticity in the system. We proved that this intriguing phenomenon is\nquite robust, as it occurs in different situations including several types of\nsynaptic plasticity, different type and number of stored patterns and diverse\nnetwork topologies, namely, diluted networks and complex topologies such as\nscale-free and small-world networks. We conclude that the robustness of the\nphenomenon in different realistic scenarios, including spiking neurons,\nshort-term synaptic plasticity and complex networks topologies, make very\nlikely that it could also occur in actual neural systems as recent\npsycho-physical experiments suggest.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 09:58:55 GMT"}, {"version": "v2", "created": "Thu, 29 Jan 2015 09:55:05 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Torres", "Joaquin J.", ""], ["Elices", "Irene", ""], ["Marro", "J.", ""]]}, {"id": "1410.4072", "submitter": "Jonathan Touboul", "authors": "Philippe Robert and Jonathan D. Touboul", "title": "On the dynamics of random neuronal networks", "comments": "37 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the mean-field limit and stationary distributions of a pulse-coupled\nnetwork modeling the dynamics of a large neuronal assemblies. Our model takes\ninto account explicitly the intrinsic randomness of firing times, contrasting\nwith the classical integrate-and-fire model. The ergodicity properties of the\nMarkov process associated to finite networks are investigated. We derive the\nlimit in distribution of the sample path of the state of a neuron of the\nnetwork when its size gets large. The invariant distributions of this limiting\nstochastic process are analyzed as well as their stability properties. We show\nthat the system undergoes transitions as a function of the averaged\nconnectivity parameter, and can support trivial states (where the network\nactivity dies out, which is also the unique stationary state of finite networks\nin some cases) and self-sustained activity when connectivity level is\nsufficiently large, both being possibly stable.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 14:26:44 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2015 08:08:05 GMT"}, {"version": "v3", "created": "Mon, 16 Mar 2015 14:11:54 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Robert", "Philippe", ""], ["Touboul", "Jonathan D.", ""]]}, {"id": "1410.4122", "submitter": "Anna Broniec Dr", "authors": "Anna Broniec", "title": "Analysis of EEG signal by Flicker Noise Spectroscopy: Identification of\n  right/left hand movement imagination", "comments": "16 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flicker Noise Spectroscopy (FNS) has been used for the analysis of\nelectroencephalography (EEG) signal related to the movement imagination. The\nanalysis of sensorimotor rhythms in time-frequency maps reveals the\nevent-related desynchronization (ERD) and the post-movement event-related\nsynchronization (ERS), observed mainly in the contralateral hemisphere to the\nhand moved for the motor imagery. The signal has been parameterized in\naccordance with FNS method. The significant changes of the FNS parameters, at\nthe time when the subject imagines the movement, have been observed. The\nanalysis of these parameters allows to distinguish between imagination of right\nand left hands movement. Our study shows that the flicker-noise spectroscopy\ncan be an alternative method of analyzing EEG signal related to the imagination\nof movement in terms of a potential application in the brain-computer interface\n(BCI).\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 14:35:28 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Broniec", "Anna", ""]]}, {"id": "1410.4237", "submitter": "Sergei Gepshtein", "authors": "Sergey Savel'ev and Sergei Gepshtein", "title": "Interference of Neural Waves in Distributed Inhibition-stabilized\n  Networks", "comments": "35 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To gain insight into the neural events responsible for visual perception of\nstatic and dynamic optical patterns, we study how neural activation spreads in\narrays of inhibition-stabilized neural networks with nearest-neighbor coupling.\nThe activation generated in such networks by local stimuli propagates between\nlocations, forming spatiotemporal waves that affect the dynamics of activation\ngenerated by stimuli separated spatially and temporally, and by stimuli with\ncomplex spatiotemporal structure. These interactions form characteristic\ninterference patterns that make the network intrinsically selective for certain\nstimuli, such as modulations of luminance at specific spatial and temporal\nfrequencies and specific velocities of visual motion. Due to the inherent\nnonlinearity of the network, its intrinsic tuning depends on stimulus intensity\nand contrast. The interference patterns have multiple features of \"lateral\"\ninteractions between stimuli, well known in physiological and behavioral\nstudies of visual systems. The diverse phenomena have been previously\nattributed to distinct neural circuits. Our results demonstrate how the\ncanonical circuit can perform the diverse operations in a manner predicted by\nneural-wave interference.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 21:35:23 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2016 22:44:32 GMT"}, {"version": "v3", "created": "Thu, 1 Sep 2016 00:02:46 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Savel'ev", "Sergey", ""], ["Gepshtein", "Sergei", ""]]}, {"id": "1410.5099", "submitter": "Shubhanshu Shekhar", "authors": "Shubhanshu Shekhar, Kaushik Majumdar", "title": "Identifying features in spike trains using binless similarity measures", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the central nervous system communicate with each other with the\nhelp of series of Action Potentials, or spike trains. Various studies have\nshown that neurons encode information in different features of spike trains,\nsuch as the fine temporal structure, mean firing rate, synchrony etc. An\nimportant step in understanding the encoding of information by neurons, is to\nobtain a reliable measure of correlation between different spike trains. In\nthis paper, two new binless similarity measures for spike trains are proposed.\nThe performance of the new measures are compared with some existing measures in\ntheir ability to detect important features of spike trains, such as their\nfiring rate, sensitivity to bursts and common periods of silence and detecting\nsynchronous activity.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2014 17:50:43 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Shekhar", "Shubhanshu", ""], ["Majumdar", "Kaushik", ""]]}, {"id": "1410.5123", "submitter": "Giovanni Punzi", "authors": "Maria Michela Del Viva, Giovanni Punzi", "title": "The brain as a trigger system", "comments": "Presented by M. Del Viva at the Conference \"Technology and\n  Instrumentation in Particle Physics 2014\" (TIPP 2014), June 2-6, 2014,\n  Amsterdam, The Netherlands", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are significant analogies between the issues related to real-time event\nselection in HEP, and the issues faced by the human visual system. In fact, the\nvisual system needs to extract rapidly the most important elements of the\nexternal world from a large flux of information, for survival purposes. A rapid\nand reliable detection of visual stimuli is essential for triggering autonomic\nresponses to emotive stimuli, for initiating adaptive behaviors and for\norienting towards potentially interesting/ dangerous stimuli. The speed of\nvisual processing can be as fast as 20 ms, about only 20 times the duration of\nthe elementary information exchanges by the action potential. The limitations\nto the brain capacity to process visual information, imposed by intrinsic\nenergetic costs of neuronal activity, and ecological limits to the size of the\nskull, require a strong data reduction at an early stage, by creating a compact\nsummary of relevant information, the so called \"primal sketch\", to be handled\nby further levels of processing. This is quite similar to the problem of\nexperimental HEP of providing fast data reduction at a reasonable monetary\ncost, and with a practical device size. As a result of a joint effort of HEP\nphysicists and practicing vision scientists, we recently proposed that not only\nthe problems are similar, but the solutions adopted in the two cases also have\nstrong similarities, and their parallel study can actually shed light on each\nother. Modeling the visual system as a trigger processor leads to a deeper\nunderstanding, and even very specific predictions of its functionality.\nConversely, the insights gained from this new approach to vision, can lead to\nnew ideas for enhancing the capabilities of artificial vision systems, and HEP\ntrigger systems as well.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2014 23:03:57 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Del Viva", "Maria Michela", ""], ["Punzi", "Giovanni", ""]]}, {"id": "1410.5212", "submitter": "Dimitri Probst", "authors": "Dimitri Probst, Mihai A. Petrovici, Ilja Bytschok, Johannes Bill,\n  Dejan Pecevski, Johannes Schemmel and Karlheinz Meier", "title": "Probabilistic inference in discrete spaces can be implemented into\n  networks of LIF neurons", "comments": null, "journal-ref": "Front. Comput. Neurosci. 9:13 (2015)", "doi": "10.3389/fncom.2015.00013", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The means by which cortical neural networks are able to efficiently solve\ninference problems remains an open question in computational neuroscience.\nRecently, abstract models of Bayesian computation in neural circuits have been\nproposed, but they lack a mechanistic interpretation at the single-cell level.\nIn this article, we describe a complete theoretical framework for building\nnetworks of leaky integrate-and-fire neurons that can sample from arbitrary\nprobability distributions over binary random variables. We test our framework\nfor a model inference task based on a psychophysical phenomenon (the\nKnill-Kersten optical illusion) and further assess its performance when applied\nto randomly generated distributions. As the local computations performed by the\nnetwork strongly depend on the interaction between neurons, we compare several\ntypes of couplings mediated by either single synapses or interneuron chains.\nDue to its robustness to substrate imperfections such as parameter noise and\nbackground noise correlations, our model is particularly interesting for\nimplementation on novel, neuro-inspired computing architectures, which can\nthereby serve as a fast, low-power substrate for solving real-world inference\nproblems.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 09:57:35 GMT"}, {"version": "v2", "created": "Sun, 22 Feb 2015 21:37:18 GMT"}], "update_date": "2015-02-24", "authors_parsed": [["Probst", "Dimitri", ""], ["Petrovici", "Mihai A.", ""], ["Bytschok", "Ilja", ""], ["Bill", "Johannes", ""], ["Pecevski", "Dejan", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1410.5362", "submitter": "Saptarshi Das", "authors": "Wasifa Jamal, Saptarshi Das, Ioana-Anastasia Oprescu, Koushik\n  Maharatna", "title": "Prediction of Synchrostate Transitions in EEG Signals Using Markov Chain\n  Models", "comments": "5 pages, 5 figures", "journal-ref": "Signal Processing Letters, IEEE, Volume 22, Issue 2, Pages 149 -\n  152, Feb. 2015", "doi": "10.1109/LSP.2014.2352251", "report-no": null, "categories": "q-bio.NC physics.med-ph stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a stochastic model using the concept of Markov chains for\nthe inter-state transitions of the millisecond order quasi-stable phase\nsynchronized patterns or synchrostates, found in multi-channel\nElectroencephalogram (EEG) signals. First and second order transition\nprobability matrices are estimated for Markov chain modelling from 100 trials\nof 128-channel EEG signals during two different face perception tasks.\nPrediction accuracies with such finite Markov chain models for synchrostate\ntransition are also compared, under a data-partitioning based cross-validation\nscheme.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 17:28:13 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Jamal", "Wasifa", ""], ["Das", "Saptarshi", ""], ["Oprescu", "Ioana-Anastasia", ""], ["Maharatna", "Koushik", ""]]}, {"id": "1410.5580", "submitter": "Peter beim Graben", "authors": "Peter beim Graben and Axel Hutt", "title": "Detecting event-related recurrences by symbolic analysis: Applications\n  to human language processing", "comments": "24 pages, 6 figures. Draft version to appear in Proc Royal Soc A", "journal-ref": null, "doi": "10.1098/rsta.2014.0089", "report-no": null, "categories": "nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quasistationarity is ubiquitous in complex dynamical systems. In brain\ndynamics there is ample evidence that event-related potentials reflect such\nquasistationary states. In order to detect them from time series, several\nsegmentation techniques have been proposed. In this study we elaborate a recent\napproach for detecting quasistationary states as recurrence domains by means of\nrecurrence analysis and subsequent symbolisation methods. As a result,\nrecurrence domains are obtained as partition cells that can be further aligned\nand unified for different realisations. We address two pertinent problems of\ncontemporary recurrence analysis and present possible solutions for them.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 09:07:07 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Graben", "Peter beim", ""], ["Hutt", "Axel", ""]]}, {"id": "1410.5610", "submitter": "Gabriele Scheler", "authors": "Gabriele Scheler", "title": "Logarithmic distributions prove that intrinsic learning is Hebbian", "comments": null, "journal-ref": "Scheler G. Logarithmic distributions prove that intrinsic learning\n  is Hebbian [version 2; referees: 2 approved]. F1000Research 2017, 6:1222", "doi": "10.12688/f1000research.12130.2", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present data for the lognormal distributions of spike\nrates, synaptic weights and intrinsic excitability (gain) for neurons in\nvarious brain areas, such as auditory or visual cortex, hippocampus,\ncerebellum, striatum, midbrain nuclei. We find a remarkable consistency of\nheavy-tailed, specifically lognormal, distributions for rates, weights and\ngains in all brain areas examined. The difference between strongly recurrent\nand feed-forward connectivity (cortex vs. striatum and cerebellum),\nneurotransmitter (GABA (striatum) or glutamate (cortex)) or the level of\nactivation (low in cortex, high in Purkinje cells and midbrain nuclei) turns\nout to be irrelevant for this feature. Logarithmic scale distribution of\nweights and gains appears to be a general, functional property in all cases\nanalyzed. We then created a generic neural model to investigate adaptive\nlearning rules that create and maintain lognormal distributions. We\nconclusively demonstrate that not only weights, but also intrinsic gains, need\nto have strong Hebbian learning in order to produce and maintain the\nexperimentally attested distributions. This provides a solution to the\nlong-standing question about the type of plasticity exhibited by intrinsic\nexcitability.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 10:32:31 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 04:41:14 GMT"}, {"version": "v3", "created": "Wed, 13 Dec 2017 15:00:09 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Scheler", "Gabriele", ""]]}, {"id": "1410.5914", "submitter": "Margaret Henderson", "authors": "Margaret Henderson, Vadim Pinskiy, Alexander Tolpygo, Stephen Savoia,\n  Pascal Grange, Partha Mitra", "title": "Automated placement of stereotactic injections using a laser scan of the\n  skull", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stereotactic targeting is a commonly used technique for performing injections\nin the brains of mice and other animals. The most common method for targeting\nstereoscopic injections uses the skull indentations bregma and lambda as\nreference points and is limited in its precision by factors such as skull\ncurvature and individual variation, as well as an incomplete correspondence\nbetween skull landmarks and brain locations. In this software tool, a 3D laser\nscan of the mouse skull is taken in vitro and registered onto a reference skull\nusing a point cloud matching algorithm, and the parameters of the\ntransformation are used to position a glass pipette to place tracer injections.\nThe software was capable of registering sample skulls with less than 100 micron\nerror, and was able to target an injection in a mouse with error of roughly 500\nmicrons. These results indicate that using skull scan registration has the\npotential to be widely applicable in automating stereotactic targeting of\ntracer injections.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 04:39:08 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Henderson", "Margaret", ""], ["Pinskiy", "Vadim", ""], ["Tolpygo", "Alexander", ""], ["Savoia", "Stephen", ""], ["Grange", "Pascal", ""], ["Mitra", "Partha", ""]]}, {"id": "1410.5930", "submitter": "Marco Brigham", "authors": "Marco Brigham and Alain Destexhe", "title": "Non-stationary filtered shot noise processes and applications to\n  neuronal membranes", "comments": "18 pages, 13 figures", "journal-ref": "Physical Review E 91: 062102, 2015", "doi": "10.1103/PhysRevE.91.062102", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filtered shot noise processes have proven to be very effective in modelling\nthe evolution of systems exposed to stochastic shot noise sources, and have\nbeen applied to a wide variety of fields ranging from electronics through\nbiology. In particular, they can model the membrane potential Vm of neurons\ndriven by stochastic input, where these filtered processes are able to capture\nthe non-stationary characteristics of Vm fluctuations in response to\npre-synaptic input with variable rate. In this paper, we apply the general\nframework of Poisson Point Processes transformations to analyse these systems\nin the general case of variable input rate. We obtain exact analytic\nexpressions, and very accurate approximations, for the joint cumulants of\nfiltered shot noise processes with multiplicative noise. These general results\nare then applied to a model of neuronal membranes subject to conductance shot\nnoise with continuously variable rate of pre-synaptic spikes. We propose very\neffective approximations for the time evolution of Vm distribution and simple\nmethod to estimate the pre-synaptic rate from a small number of Vm traces. This\nwork opens the perspective of obtaining analytic access to important\nstatistical properties of conductance-based neuronal models such as the the\nfirst passage time.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 07:45:17 GMT"}, {"version": "v2", "created": "Fri, 20 Feb 2015 09:56:46 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2015 13:48:58 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Brigham", "Marco", ""], ["Destexhe", "Alain", ""]]}, {"id": "1410.6031", "submitter": "Dmitry Kobak", "authors": "Dmitry Kobak, Wieland Brendel, Christos Constantinidis, Claudia E.\n  Feierstein, Adam Kepecs, Zachary F. Mainen, Ranulfo Romo, Xue-Lian Qi,\n  Naoshige Uchida, Christian K. Machens", "title": "Demixed principal component analysis of population activity in higher\n  cortical areas reveals independent representation of task parameters", "comments": "23 pages, 6 figures + supplementary information (21 pages, 15\n  figures)", "journal-ref": "Elife 5, 2016", "doi": "10.7554/eLife.10989", "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in higher cortical areas, such as the prefrontal cortex, are known to\nbe tuned to a variety of sensory and motor variables. The resulting diversity\nof neural tuning often obscures the represented information. Here we introduce\na novel dimensionality reduction technique, demixed principal component\nanalysis (dPCA), which automatically discovers and highlights the essential\nfeatures in complex population activities. We reanalyze population data from\nthe prefrontal areas of rats and monkeys performing a variety of working memory\nand decision-making tasks. In each case, dPCA summarizes the relevant features\nof the population response in a single figure. The population activity is\ndecomposed into a few demixed components that capture most of the variance in\nthe data and that highlight dynamic tuning of the population to various task\nparameters, such as stimuli, decisions, rewards, etc. Moreover, dPCA reveals\nstrong, condition-independent components of the population activity that remain\nunnoticed with conventional approaches.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 13:21:04 GMT"}], "update_date": "2019-02-18", "authors_parsed": [["Kobak", "Dmitry", ""], ["Brendel", "Wieland", ""], ["Constantinidis", "Christos", ""], ["Feierstein", "Claudia E.", ""], ["Kepecs", "Adam", ""], ["Mainen", "Zachary F.", ""], ["Romo", "Ranulfo", ""], ["Qi", "Xue-Lian", ""], ["Uchida", "Naoshige", ""], ["Machens", "Christian K.", ""]]}, {"id": "1410.6049", "submitter": "Dmitry Kobak", "authors": "Luke Bashford, Dmitry Kobak, Carsten Mehring", "title": "Motor skill learning by increasing the movement planning horizon", "comments": "45 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated motor skill learning using a path tracking task, where human\nsubjects had to track various curved paths as fast as possible, in the absence\nof any external perturbations. Subjects became better with practice, producing\nfaster and smoother movements even when tracking novel untrained paths. Using a\n\"searchlight\" paradigm, where only a short segment of the path ahead of the\ncursor was shown, we found that subjects with a higher tracking skill took a\nlonger chunk of the future path into account when computing the control policy\nfor the upcoming movement segment. We observed the same effects in a second\nexperiment where tracking speed was fixed and subjects were practicing to\nincrease their accuracy. These findings demonstrate that human subjects\nincrease their planning horizon when acquiring a motor skill.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 14:21:05 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2015 21:14:22 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Bashford", "Luke", ""], ["Kobak", "Dmitry", ""], ["Mehring", "Carsten", ""]]}, {"id": "1410.6086", "submitter": "Guilherme Ost", "authors": "Aline Duarte and Guilherme Ost", "title": "A model for neural activity in the absence of external stimuli", "comments": null, "journal-ref": "Markov Processes And Related Fields, 2016, volume 22, number 1,\n  37:52", "doi": null, "report-no": null, "categories": "math.PR q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a stochastic process describing the continuous time evolution of the\nmembrane potentials of finite system of neurons in the absence of external\nstimuli. The values of the membrane potentials evolve under the effect of {\\it\nchemical synapses}, {\\it electrical synapses} and a \\textit{leak current}. The\nevolution of the process can be informally described as follows. Each neuron\nspikes randomly following a point process with rate depending on its membrane\npotential. When a neuron spikes, its membrane potential is immediately reset to\na resting value. Simultaneously, the membrane potential of the neurons which\nare influenced by it receive an additional positive value. Furthermore, between\nconsecutive spikes, the system follows a deterministic motion due both to\nelectrical synapses and the leak current. Electrical synapses push the system\ntowards its average potential, while the leak current attracts the membrane\npotential of each neuron to the resting value.\n  We show that in the absence leakage the process converges exponentially fast\nto an unique invariant measure, whenever the initial configuration is non null.\nMore interesting, when leakage is present, we proved the system stops spiking\nafter a finite amount of time almost surely. This implies that the unique\ninvariant measure is supported only by the null configuration.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 15:55:56 GMT"}, {"version": "v2", "created": "Fri, 7 Nov 2014 23:58:48 GMT"}, {"version": "v3", "created": "Tue, 18 Nov 2014 18:39:29 GMT"}, {"version": "v4", "created": "Wed, 28 Jan 2015 22:16:52 GMT"}, {"version": "v5", "created": "Wed, 16 Nov 2016 11:02:55 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Duarte", "Aline", ""], ["Ost", "Guilherme", ""]]}, {"id": "1410.6752", "submitter": "Pouyan R. Fard", "authors": "Pouyan R. Fard, Moritz Grosse-Wentrup", "title": "The Influence of Decoding Accuracy on Perceived Control: A Simulated BCI\n  Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the relationship between the decoding accuracy of a\nbrain-computer interface (BCI) and a subject's subjective feeling of control is\nimportant for determining a lower limit on decoding accuracy for a BCI that is\nto be deployed outside a laboratory environment. We investigated this\nrelationship by systematically varying the level of control in a simulated BCI\ntask. We find that a binary decoding accuracy of 65% is required for users to\nreport more often than not that they are feeling in control of the system.\nDecoding accuracies above 75%, on the other hand, added little in terms of the\nlevel of perceived control. We further find that the probability of perceived\ncontrol does not only depend on the actual decoding accuracy, but is also in\ninfluenced by whether subjects successfully complete the given task in the\nallotted time frame.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 17:51:12 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Fard", "Pouyan R.", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1410.6769", "submitter": "Thierry Mora", "authors": "Thierry Mora, St\\'ephane Deny and Olivier Marre", "title": "Dynamical criticality in the collective activity of a population of\n  retinal neurons", "comments": null, "journal-ref": "Phys. Rev. Lett. 114, 078105 (2015)", "doi": "10.1103/PhysRevLett.114.078105", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental results based on multi-electrode and imaging techniques\nhave reinvigorated the idea that large neural networks operate near a critical\npoint, between order and disorder. However, evidence for criticality has relied\non the definition of arbitrary order parameters, or on models that do not\naddress the dynamical nature of network activity. Here we introduce a novel\napproach to assess criticality that overcomes these limitations, while\nencompassing and generalizing previous criteria. We find a simple model to\ndescribe the global activity of large populations of ganglion cells in the rat\nretina, and show that their statistics are poised near a critical point. Taking\ninto account the temporal dynamics of the activity greatly enhances the\nevidence for criticality, revealing it where previous methods would not. The\napproach is general and could be used in other biological networks.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 18:23:03 GMT"}, {"version": "v2", "created": "Sat, 31 Jan 2015 17:59:34 GMT"}], "update_date": "2015-03-05", "authors_parsed": [["Mora", "Thierry", ""], ["Deny", "St\u00e9phane", ""], ["Marre", "Olivier", ""]]}, {"id": "1410.6910", "submitter": "Thomas Kreuz", "authors": "Thomas Kreuz and Mario Mulansky and Nebojsa Bozanic", "title": "SPIKY: A graphical user interface for monitoring spike train synchrony", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.MS cs.SE physics.bio-ph physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Techniques for recording large-scale neuronal spiking activity are developing\nvery fast. This leads to an increasing demand for algorithms capable of\nanalyzing large amounts of experimental spike train data. One of the most\ncrucial and demanding tasks is the identification of similarity patterns with a\nvery high temporal resolution and across different spatial scales. To address\nthis task, in recent years three time-resolved measures of spike train\nsynchrony have been proposed, the ISI-distance, the SPIKE-distance, and event\nsynchronization. The Matlab source codes for calculating and visualizing these\nmeasures have been made publicly available. However, due to the many different\npossible representations of the results the use of these codes is rather\ncomplicated and their application requires some basic knowledge of Matlab. Thus\nit became desirable to provide a more user-friendly and interactive interface.\nHere we address this need and present SPIKY, a graphical user interface which\nfacilitates the application of time-resolved measures of spike train synchrony\nto both simulated and real data. SPIKY includes implementations of the\nISI-distance, the SPIKE-distance and SPIKE-synchronization (an improved and\nsimplified extension of event synchronization) which have been optimized with\nrespect to computation speed and memory demand. It also comprises a spike train\ngenerator and an event detector which makes it capable of analyzing continuous\ndata. Finally, the SPIKY package includes additional complementary programs\naimed at the analysis of large numbers of datasets and the estimation of\nsignificance levels.\n", "versions": [{"version": "v1", "created": "Sat, 25 Oct 2014 11:02:26 GMT"}, {"version": "v2", "created": "Sat, 24 Jan 2015 22:29:28 GMT"}, {"version": "v3", "created": "Wed, 15 Apr 2015 16:40:11 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Kreuz", "Thomas", ""], ["Mulansky", "Mario", ""], ["Bozanic", "Nebojsa", ""]]}, {"id": "1410.7100", "submitter": "Harris Georgiou", "authors": "Harris V. Georgiou", "title": "Estimating the intrinsic dimension in fMRI space via dataset fractal\n  analysis - Counting the `cpu cores' of the human brain", "comments": "27 pages, 10 figures, 2 tables, 47 references", "journal-ref": null, "doi": null, "report-no": "HG/AI.1014.27v1 (draft/preprint)", "categories": "cs.AI cs.CV q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Functional Magnetic Resonance Imaging (fMRI) is a powerful non-invasive tool\nfor localizing and analyzing brain activity. This study focuses on one very\nimportant aspect of the functional properties of human brain, specifically the\nestimation of the level of parallelism when performing complex cognitive tasks.\nUsing fMRI as the main modality, the human brain activity is investigated\nthrough a purely data-driven signal processing and dimensionality analysis\napproach. Specifically, the fMRI signal is treated as a multi-dimensional data\nspace and its intrinsic `complexity' is studied via dataset fractal analysis\nand blind-source separation (BSS) methods. One simulated and two real fMRI\ndatasets are used in combination with Independent Component Analysis (ICA) and\nfractal analysis for estimating the intrinsic (true) dimensionality, in order\nto provide data-driven experimental evidence on the number of independent brain\nprocesses that run in parallel when visual or visuo-motor tasks are performed.\nAlthough this number is can not be defined as a strict threshold but rather as\na continuous range, when a specific activation level is defined, a\ncorresponding number of parallel processes or the casual equivalent of `cpu\ncores' can be detected in normal human brain activity.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 00:25:24 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Georgiou", "Harris V.", ""]]}, {"id": "1410.7881", "submitter": "Shibani Santurkar", "authors": "Shibani Santurkar and Bipin Rajendran", "title": "A neural circuit for navigation inspired by C. elegans Chemotaxis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an artificial neural circuit for contour tracking and navigation\ninspired by the chemotaxis of the nematode Caenorhabditis elegans. In order to\nharness the computational advantages spiking neural networks promise over their\nnon-spiking counterparts, we develop a network comprising 7-spiking neurons\nwith non-plastic synapses which we show is extremely robust in tracking a range\nof concentrations. Our worm uses information regarding local temporal gradients\nin sodium chloride concentration to decide the instantaneous path for foraging,\nexploration and tracking. A key neuron pair in the C. elegans chemotaxis\nnetwork is the ASEL & ASER neuron pair, which capture the gradient of\nconcentration sensed by the worm in their graded membrane potentials. The\nprimary sensory neurons for our network are a pair of artificial spiking\nneurons that function as gradient detectors whose design is adapted from a\ncomputational model of the ASE neuron pair in C. elegans. Simulations show that\nour worm is able to detect the set-point with approximately four times higher\nprobability than the optimal memoryless Levy foraging model. We also show that\nour spiking neural network is much more efficient and noise-resilient while\nnavigating and tracking a contour, as compared to an equivalent non-spiking\nnetwork. We demonstrate that our model is extremely robust to noise and with\nslight modifications can be used for other practical applications such as\nobstacle avoidance. Our network model could also be extended for use in\nthree-dimensional contour tracking or obstacle avoidance.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 05:54:22 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Santurkar", "Shibani", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1410.7883", "submitter": "Shibani Santurkar", "authors": "Shibani Santurkar and Bipin Rajendran", "title": "Sub-threshold CMOS Spiking Neuron Circuit Design for Navigation Inspired\n  by C. elegans Chemotaxis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a spiking neural network for navigation motivated by the\nchemotaxis network of Caenorhabditis elegans. Our network uses information\nregarding temporal gradients in the tracking variable's concentration to make\nnavigational decisions. The gradient information is determined by mimicking the\nunderlying mechanisms of the ASE neurons of C. elegans. Simulations show that\nour model is able to forage and track a target set-point in extremely noisy\nenvironments. We develop a VLSI implementation for the main gradient detector\nneurons, which could be integrated with standard comparator circuitry to\ndevelop a robust circuit for navigation and contour tracking.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 05:56:00 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Santurkar", "Shibani", ""], ["Rajendran", "Bipin", ""]]}, {"id": "1410.7959", "submitter": "Sebastiano Stramaglia", "authors": "Ibai Diez, Paolo Bonifazi, I\\~naki Escudero, Beatriz Mateos, Miguel A.\n  Mu\\~noz, Sebastiano Stramaglia and Jesus M. Cortes", "title": "A novel brain partition highlights the modular skeleton shared by\n  structure and function", "comments": "Accepted in Nature Scientific Reports. 56 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elucidating the intricate relationship between brain structure and function,\nboth in healthy and pathological conditions, is a key challenge for modern\nneuroscience. Recent technical and methodological progress in neuroimaging has\nhelped advance our understanding of this important issue, with diffusion\nweighted images providing information about structural connectivity (SC) and\nfunctional magnetic resonance imaging shedding light on resting state\nfunctional connectivity (rsFC). However, comparing these two distinct datasets,\neach of which can be encoded into a different complex network, is by no means\ntrivial as pairwise link-to-link comparisons represent a relatively restricted\nperspective and provide only limited information. Thus, we have adopted a more\nintegrative systems approach, exploiting theoretical graph analyses to study\nboth SC and rsFC datasets gathered independently from healthy human subjects.\nThe aim is to find the main architectural traits shared by the structural and\nfunctional networks by paying special attention to their common hierarchical\nmodular organization. This approach allows us to identify a common skeleton\nfrom which a new, optimal, brain partition can be extracted, with modules\nsharing both structure and function. We describe these emerging common\nstructure-function modules (SFMs) in detail. In addition, we compare SFMs with\nthe classical Resting State Networks derived from independent component\nanalysis of rs-fMRI functional activity, as well as with anatomical\nparcellations in the Automated Anatomical Labeling atlas and with the Broadmann\npartition, highlighting their similitude and differences. The unveiling of SFMs\nbrings to light the strong correspondence between brain structure and\nresting-state dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 12:53:35 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2015 17:10:37 GMT"}], "update_date": "2015-05-01", "authors_parsed": [["Diez", "Ibai", ""], ["Bonifazi", "Paolo", ""], ["Escudero", "I\u00f1aki", ""], ["Mateos", "Beatriz", ""], ["Mu\u00f1oz", "Miguel A.", ""], ["Stramaglia", "Sebastiano", ""], ["Cortes", "Jesus M.", ""]]}, {"id": "1410.7998", "submitter": "Liane Gabora", "authors": "Liane Gabora and Stefan Leijnen", "title": "The Relationship between Creativity, Imitation, and Cultural Diversity", "comments": "13 pages. arXiv admin note: substantial text overlap with\n  arXiv:0911.2390, arXiv:1005.1516, arXiv:1310.3781, arXiv:1310.0522,\n  arXiv:0811.2551", "journal-ref": "International Journal of Software and Informatics, 7(4), 615-627\n  2013", "doi": null, "report-no": null, "categories": "q-bio.NC cs.CY cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are both benefits and drawbacks to cultural diversity. It can lead to\nfriction and exacerbate differences. However, as with biological diversity,\ncultural diversity is valuable in times of upheaval; if a previously effective\nsolution no longer works, it is good to have alternatives available. What\nfactors give rise to cultural diversity? This paper describes a preliminary\ninvestigation of this question using a computational model of cultural\nevolution. The model is composed of neural network based agents that evolve\nfitter ideas for actions by (1) inventing new ideas through modification of\nexisting ones, and (2) imitating neighbors' ideas. Numerical simulations\nindicate that the diversity of ideas in a population is positively correlated\nwith both the proportion of creators to imitators in the population, and the\nrate at which creators create. This is the case for both minimum and peak\ndiversity of actions over the duration of a run.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 02:57:14 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Gabora", "Liane", ""], ["Leijnen", "Stefan", ""]]}, {"id": "1410.8497", "submitter": "Jaan Aru", "authors": "Kristjan Korjus, Andero Uusberg, Helen Uibo, Nele Kuldkepp, Kairi\n  Kreegipuu, J\\\"uri Allik, Raul Vicente, Jaan Aru", "title": "Personality cannot be predicted from the power of resting state EEG", "comments": "14 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present study we asked whether it is possible to decode personality\ntraits from resting state EEG data. EEG was recorded from a large sample of\nsubjects (N = 309) who had answered questionnaires measuring personality trait\nscores of the 5 dimensions as well as the 10 subordinate aspects of the Big\nFive. Machine learning algorithms were used to build a classifier to predict\neach personality trait from power spectra of the resting state EEG data. The\nresults indicate that the five dimensions as well as their subordinate aspects\ncould not be predicted from the resting state EEG data. Finally, to demonstrate\nthat this result is not due to systematic algorithmic or implementation\nmistakes the same methods were used to successfully classify whether the\nsubject had eyes open or eyes closed and whether the subject was male or\nfemale. These results indicate that the extraction of personality traits from\nthe power spectra of resting state EEG is extremely noisy, if possible at all.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 18:59:13 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Korjus", "Kristjan", ""], ["Uusberg", "Andero", ""], ["Uibo", "Helen", ""], ["Kuldkepp", "Nele", ""], ["Kreegipuu", "Kairi", ""], ["Allik", "J\u00fcri", ""], ["Vicente", "Raul", ""], ["Aru", "Jaan", ""]]}, {"id": "1410.8580", "submitter": "Matthew Lawlor", "authors": "Matthew Lawlor and Steven Zucker", "title": "An Online Algorithm for Learning Selectivity to Mixture Means", "comments": "Extended technical companion to a presentation at NIPS 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a biologically-plausible learning rule called Triplet BCM that\nprovably converges to the class means of general mixture models. This rule\ngeneralizes the classical BCM neural rule, and provides a novel interpretation\nof classical BCM as performing a kind of tensor decomposition. It achieves a\nsubstantial generalization over classical BCM by incorporating triplets of\nsamples from the mixtures, which provides a novel information processing\ninterpretation to spike-timing-dependent plasticity. We provide complete proofs\nof convergence of this learning rule, and an extended discussion of the\nconnection between BCM and tensor learning.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 22:37:41 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Lawlor", "Matthew", ""], ["Zucker", "Steven", ""]]}, {"id": "1410.8799", "submitter": "Jannis Schuecker", "authors": "Jannis Schuecker, Markus Diesmann and Moritz Helias", "title": "Reduction of colored noise in excitable systems to white noise and\n  dynamic boundary conditions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent study on the effect of colored driving noise on the escape from a\nmetastable state derives an analytic expression of the transfer function of the\nleaky integrate-and-fire neuron model subject to colored noise. Here we present\nan alternative derivation of the results, taking into account time-dependent\nboundary conditions explicitly. This systematic approach may facilitate future\nextensions beyond first order perturbation theory. The analogy of the quantum\nharmonic oscillator to the LIF neuron model subject to white noise enables a\nderivation of the well known transfer function simpler than the original\napproach. We offer a pedagogical presentation including all intermediate steps\nof the calculations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Oct 2014 12:40:42 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2015 14:16:23 GMT"}, {"version": "v3", "created": "Tue, 13 Oct 2015 11:50:55 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Schuecker", "Jannis", ""], ["Diesmann", "Markus", ""], ["Helias", "Moritz", ""]]}, {"id": "1410.8826", "submitter": "Adam Marblestone", "authors": "Gary F. Marcus and Adam H. Marblestone and Thomas L. Dean", "title": "Frequently Asked Questions for: The Atoms of Neural Computation", "comments": "Frequently Asked Questions (FAQ) for Marcus, Marblestone and Dean.\n  \"The Atoms of Neural Computation\". Science. 31 OCTOBER 2014. VOL 346 ISSUE\n  6209", "journal-ref": null, "doi": "10.1126/science.1261661", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on a survey of the literature, we attempt to answer Frequently Asked\nQuestions on issues of cortical uniformity vs. non-uniformity, the neural\nmechanisms of symbolic variable binding, and other issues highlighted in\n(Marcus, Marblestone and Dean. \"The Atoms of Neural Computation\". Science. 31\nOctober 2014. Vol 346. Issue 6209).\n", "versions": [{"version": "v1", "created": "Fri, 31 Oct 2014 17:38:34 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Marcus", "Gary F.", ""], ["Marblestone", "Adam H.", ""], ["Dean", "Thomas L.", ""]]}]