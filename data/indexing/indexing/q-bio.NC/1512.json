[{"id": "1512.00033", "submitter": "Jose Acacio de Barros", "authors": "J. Acacio de Barros and Gary Oas", "title": "Some Examples of Contextuality in Physics: Implications to Quantum\n  Cognition", "comments": "24 pages, 3 figures. Paper presented at the 2014 Winer Memorial\n  Lectures at Purdue University. To appear in Contextuality from Quantum\n  Physics to Psychology, edited by E. Dzhafarov, R. Zhang, S. Jordan", "journal-ref": null, "doi": "10.1142/9789814730617_0008", "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextuality, the impossibility of assigning a single random variable to\nrepresent the outcomes of the same measurement procedure under different\nexperimental conditions, is a central aspect of quantum mechanics. Thus\ndefined, it appears in well-known cases in quantum mechanics, such as the\ndouble-slit experiment, the Bell-EPR experiment, and the Kochen-Specker\ntheorem. Here we examine contextuality in such cases, and discuss how each of\nthem bring different conceptual issues when applied to quantum cognition. We\nthen focus on the shortcomings of using quantum probabilities to describe\nsocial systems, and explain how negative quasi-probability distributions may\naddress such limitations.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 23:55:42 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["de Barros", "J. Acacio", ""], ["Oas", "Gary", ""]]}, {"id": "1512.00035", "submitter": "Benoit Girard", "authors": "Jean Li\\'enard (ISIR), Beno\\^it Girard (ISIR)", "title": "A biologically constrained model of the whole basal ganglia addressing\n  the paradoxes of connections and selection", "comments": "\\&lt;http://link.springer.com/article/10.1007%2Fs10827-013-0476-2\\&gt;.\n  \\&lt;10.1007/s10827-013-0476-2\\&gt", "journal-ref": "Journal of Computational Neuroscience, Springer Verlag (Germany),\n  2014, 36 (3), pp.445-468", "doi": "10.1007/s10827-013-0476-2", "report-no": null, "categories": "q-bio.NC cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The basal ganglia nuclei form a complex network of nuclei often assumed to\nperform selection, yet their individual roles and how they influence each other\nis still largely unclear. In particular, the ties between the external and\ninternal parts of the globus pallidus are paradoxical, as anatomical data\nsuggest a potent inhibitory projection between them while electrophys-iological\nrecordings indicate that they have similar activities. Here we introduce a\ntheoretical study that reconciles both views on the intra-pallidal projection,\nby providing a plausible characterization of the relationship between the\nexternal and internal globus pallidus. Specifically, we developed a mean-field\nmodel of the whole basal ganglia, whose parameterization is optimized to\nrespect best a collection of numerous anatomical and electrophysiological data.\nWe first obtained models respecting all our constraints, hence anatomical and\nelectrophysiological data on the intrapallidal projection are globally\nconsistent. This model furthermore predicts that both aforementioned views\nabout the intra-pallidal projection may be reconciled when this projection is\nweakly inhibitory, thus making it possible to support similar neural activity\nin both nuclei and for the entire basal ganglia to select between actions.\nSecond, we predicts that afferent projections are substantially unbalanced\ntowards the external segment, as it receives the strongest excitation from STN\nand the weakest inhibition from the striatum. Finally, our study strongly\nsuggest that the intrapallidal connection pattern is not focused but diffuse,\nas this latter pattern is more efficient for the overall selection performed in\nthe basal ganglia.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 07:45:55 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Li\u00e9nard", "Jean", "", "ISIR"], ["Girard", "Beno\u00eet", "", "ISIR"]]}, {"id": "1512.00036", "submitter": "James  Peters Ph.D.", "authors": "A. Tozzi and J.F. Peters", "title": "Brain activity on a hypersphere", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current advances in neurosciences deal with the functional architecture of\nthe central nervous system, paving the way for holistic theories that improve\nour understanding of brain activity. From topology, a strong concept comes into\nplay in the understanding of brain signals, namely, continuous mapping of the\nsignals onto a hyper-sphere, a 4-dimensional space equipped with a\ndoughnut-like shape that is not detected by observers living in a 3-dimensional\nworld. We evaluate the features of the imperceptible 4th dimension based on\nresting state functional magnetic resonance imaging series. In particular, we\nlooked for simultaneous activation of antipodal signals on the surface of a\ncortical hyper-sphere. In this article, we demonstrate that spontaneous brain\nactivity displays the typical features which reveal the existence of a\nfunctional hyper-sphere. The suggestion here is that the brain is embedded in a\nhyper-sphere, which helps solve long-standing mysteries concerning our\npsychological activities such mind-wandering and memory retrieval or the\nability to connect, pasts and future events.\n", "versions": [{"version": "v1", "created": "Sun, 4 Oct 2015 12:39:25 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Tozzi", "A.", ""], ["Peters", "J. F.", ""]]}, {"id": "1512.00037", "submitter": "Weiyu Huang", "authors": "Weiyu Huang, Leah Goldsberry, Nicholas F. Wymbs, Scott T. Grafton,\n  Danielle S. Bassett and Alejandro Ribeiro", "title": "Graph Frequency Analysis of Brain Signals", "comments": null, "journal-ref": null, "doi": "10.1109/JSTSP.2016.2600859", "report-no": null, "categories": "q-bio.NC cs.CE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents methods to analyze functional brain networks and signals\nfrom graph spectral perspectives. The notion of frequency and filters\ntraditionally defined for signals supported on regular domains such as discrete\ntime and image grids has been recently generalized to irregular graph domains,\nand defines brain graph frequencies associated with different levels of spatial\nsmoothness across the brain regions. Brain network frequency also enables the\ndecomposition of brain signals into pieces corresponding to smooth or rapid\nvariations. We relate graph frequency with principal component analysis when\nthe networks of interest denote functional connectivity. The methods are\nutilized to analyze brain networks and signals as subjects master a simple\nmotor skill. We observe that brain signals corresponding to different graph\nfrequencies exhibit different levels of adaptability throughout learning.\nFurther, we notice a strong association between graph spectral properties of\nbrain networks and the level of exposure to tasks performed, and recognize the\nmost contributing and important frequency signatures at different task\nfamiliarity.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 19:25:39 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 16:00:32 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Huang", "Weiyu", ""], ["Goldsberry", "Leah", ""], ["Wymbs", "Nicholas F.", ""], ["Grafton", "Scott T.", ""], ["Bassett", "Danielle S.", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1512.00058", "submitter": "Sundeep Teki", "authors": "Sundeep Teki", "title": "Observations on recent progress in the field of timing and time\n  perception", "comments": "23 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time is an important dimension of brain function, but little is still known\nabout the underlying cognitive principles and neurobiological mechanisms. The\nfield of timing and time perception has witnessed rapid growth and\nmultidisciplinary interest in the recent years with the advent of modern\nneuroimaging, neurophysiological and optogenetic tools. In this article, I\nreview the literature from the last ten years (2005-2015) using a data mining\napproach and highlight the most significant empirical as well as review\narticles based on the number of citations (a minimum of 100 citations). Such\nanalysis provides a unique perspective on the current state-of-the-art in the\nfield and highlights subtopics in the field that have received considerable\nattention, and those that have not. The objective of the article is to present\nan objective summary of the current progress in the field of timing and time\nperception and provide a valuable and accessible resource summarizing the most\ncited articles for new as well current investigators in the field.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 21:51:05 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Teki", "Sundeep", ""]]}, {"id": "1512.00296", "submitter": "Vinay Jayaram", "authors": "Vinay Jayaram, Morteza Alamgir, Yasemin Altun, Bernhard Sch\\\"olkopf,\n  Moritz Grosse-Wentrup", "title": "Transfer Learning in Brain-Computer Interfaces", "comments": "To be published in IEEE Computational Intelligence Magazine, special\n  BCI issue on January 15th online", "journal-ref": null, "doi": "10.1109/MCI.2015.2501545", "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of brain-computer interfaces (BCIs) improves with the amount\nof available training data, the statistical distribution of this data, however,\nvaries across subjects as well as across sessions within individual subjects,\nlimiting the transferability of training data or trained models between them.\nIn this article, we review current transfer learning techniques in BCIs that\nexploit shared structure between training data of multiple subjects and/or\nsessions to increase performance. We then present a framework for transfer\nlearning in the context of BCIs that can be applied to any arbitrary feature\nspace, as well as a novel regression estimation method that is specifically\ndesigned for the structure of a system based on the electroencephalogram (EEG).\nWe demonstrate the utility of our framework and method on subject-to-subject\ntransfer in a motor-imagery paradigm as well as on session-to-session transfer\nin one patient diagnosed with amyotrophic lateral sclerosis (ALS), showing that\nit is able to outperform other comparable methods on an identical dataset.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 15:33:24 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Jayaram", "Vinay", ""], ["Alamgir", "Morteza", ""], ["Altun", "Yasemin", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1512.00520", "submitter": "Andrew Sornborger", "authors": "Cong Wang, Zhuocheng Xiao, Zhou Wang, Andrew T. Sornborger, Louis Tao", "title": "A Fokker-Planck approach to graded information propagation in\n  pulse-gated feedforward neuronal networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information transmission is a key element for information processing in the\nbrain. A number of mechanisms have been proposed for transferring volleys of\nspikes between layers of a feedforward neural circuit. Many of these mechanisms\nuse synchronous activity to provide windows in time when spikes may be\ntransferred more easily from layer to layer. Recently, we have demonstrated\nthat a pulse-gating mechanism can transfer graded information between layers in\na feedforward neuronal network. Our transfer mechanism resulted in a\ntime-translationally invariant firing rate and synaptic current waveforms of\narbitrary amplitude, thus providing exact, graded information transfer between\nlayers. In this paper, we apply a Fokker-Planck approach to understand how this\ntranslational invariance manifests itself in a high-dimensional, non-linear\nfeedforward integrate-and-fire network. We show that there is good\ncorrespondence in spiking probabilities between the Fokker-Planck solutions and\nour previous mean-field solutions. We identify an approximate line attractor in\nstate space as the essential structure underlying the time-translational\ninvariance of our solutions. This approach has enabled us to better understand\nthe role played by the synaptic coupling, gating pulse and the membrane\npotential probability density function in information transfer.\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2015 23:33:18 GMT"}], "update_date": "2015-12-03", "authors_parsed": [["Wang", "Cong", ""], ["Xiao", "Zhuocheng", ""], ["Wang", "Zhou", ""], ["Sornborger", "Andrew T.", ""], ["Tao", "Louis", ""]]}, {"id": "1512.00810", "submitter": "Carsten Allefeld", "authors": "Carsten Allefeld, Kai G\\\"orgen, John-Dylan Haynes", "title": "Valid population inference for information-based imaging: From the\n  second-level $t$-test to prevalence inference", "comments": "manuscript accepted by NeuroImage, plus minor fixes and a note added\n  after publication", "journal-ref": "NeuroImage 141: 378-392, 2016", "doi": "10.1016/j.neuroimage.2016.07.040", "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multivariate pattern analysis of neuroimaging data, 'second-level'\ninference is often performed by entering classification accuracies into a\n$t$-test vs chance level across subjects. We argue that while the\nrandom-effects analysis implemented by the $t$-test does provide population\ninference if applied to activation differences, it fails to do so in the case\nof classification accuracy or other 'information-like' measures, because the\ntrue value of such measures can never be below chance level. This constraint\nchanges the meaning of the population-level null hypothesis being tested, which\nbecomes equivalent to the global null hypothesis that there is no effect in any\nsubject in the population. Consequently, rejecting it only allows to infer that\nthere are some subjects in which there is an information effect, but not that\nit generalizes, rendering it effectively equivalent to fixed-effects analysis.\nThis statement is supported by theoretical arguments as well as simulations. We\nreview possible alternative approaches to population inference for\ninformation-based imaging, converging on the idea that it should not target the\nmean, but the prevalence of the effect in the population. One method to do so,\n'permutation-based information prevalence inference using the minimum\nstatistic', is described in detail and applied to empirical data.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 18:59:46 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2016 19:46:45 GMT"}, {"version": "v3", "created": "Wed, 10 Aug 2016 17:00:26 GMT"}], "update_date": "2016-08-11", "authors_parsed": [["Allefeld", "Carsten", ""], ["G\u00f6rgen", "Kai", ""], ["Haynes", "John-Dylan", ""]]}, {"id": "1512.00897", "submitter": "Carina Curto", "authors": "Carina Curto and Katherine Morrison", "title": "Pattern completion in symmetric threshold-linear networks", "comments": "25 pages, 4 figures. Minor changes in response to reviewer comments.\n  To appear in Neural Computation", "journal-ref": "Neural Computation, Vol 28, pp. 2825-2852, 2016", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threshold-linear networks are a common class of firing rate models that\ndescribe recurrent interactions among neurons. Unlike their linear\ncounterparts, these networks generically possess multiple stable fixed points\n(steady states), making them viable candidates for memory encoding and\nretrieval. In this work, we characterize stable fixed points of general\nthreshold-linear networks with constant external drive, and discover\nconstraints on the co-existence of fixed points involving different subsets of\nactive neurons. In the case of symmetric networks, we prove the following\nantichain property: if a set of neurons $\\tau$ is the support of a stable fixed\npoint, then no proper subset or superset of $\\tau$ can support a stable fixed\npoint. Symmetric threshold-linear networks thus appear to be well suited for\npattern completion, since the dynamics are guaranteed not to get \"stuck\" in a\nsubset or superset of a stored pattern. We also show that for any graph G, we\ncan construct a network whose stable fixed points correspond precisely to the\nmaximal cliques of G. As an application, we design network decoders for place\nfield codes, and demonstrate their efficacy for error correction and pattern\ncompletion. The proofs of our main results build on the theory of permitted\nsets in threshold-linear networks, including recently-developed connections to\nclassical distance geometry.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2015 22:56:38 GMT"}, {"version": "v2", "created": "Sat, 7 May 2016 21:56:10 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Curto", "Carina", ""], ["Morrison", "Katherine", ""]]}, {"id": "1512.01073", "submitter": "David Dahmen", "authors": "David Dahmen, Hannah Bos, Moritz Helias", "title": "Correlated fluctuations in strongly-coupled binary networks beyond\n  equilibrium", "comments": null, "journal-ref": "Phys. Rev. X 6, 031024 (2016)", "doi": "10.1103/PhysRevX.6.031024", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomly coupled Ising spins constitute the classical model of collective\nphenomena in disordered systems, with applications covering ferromagnetism,\ncombinatorial optimization, protein folding, stock market dynamics, and social\ndynamics. The phase diagram of these systems is obtained in the thermodynamic\nlimit by averaging over the quenched randomness of the couplings. However, many\napplications require the statistics of activity for a single realization of the\npossibly asymmetric couplings in finite-sized networks. Examples include\nreconstruction of couplings from the observed dynamics, learning in the central\nnervous system by correlation-sensitive synaptic plasticity, and representation\nof probability distributions for sampling-based inference. The systematic\ncumulant expansion for kinetic binary (Ising) threshold units with strong,\nrandom and asymmetric couplings presented here goes beyond mean-field theory\nand is applicable outside thermodynamic equilibrium; a system of approximate\nnon-linear equations predicts average activities and pairwise covariances in\nquantitative agreement with full simulations down to hundreds of units. The\nlinearized theory yields an expansion of the correlation- and response\nfunctions in collective eigenmodes, leads to an efficient algorithm solving the\ninverse problem, and shows that correlations are invariant under scaling of the\ninteraction strengths.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 13:33:34 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Dahmen", "David", ""], ["Bos", "Hannah", ""], ["Helias", "Moritz", ""]]}, {"id": "1512.01156", "submitter": "Vince Grolmusz", "authors": "Bal\\'azs Szalkai, B\\'alint Varga, Vince Grolmusz", "title": "The Advantage is at the Ladies: Brain Size Bias-Compensated\n  Graph-Theoretical Parameters are Also Better in Women's Connectomes", "comments": "arXiv admin note: substantial text overlap with arXiv:1501.00727", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our previous study we have shown that the female connectomes have\nsignificantly better, deep graph-theoretical parameters, related to superior\n\"connectivity\", than the connectome of the males. Since the average female\nbrain is smaller than the average male brain, one cannot rule out that the\nsignificant advantages are due to the size- and not to the sex-differences in\nthe data. To filter out the possible brain-volume related artifacts, we have\nchosen 36 small male and 36 large female brains such that all the brains in the\nfemale set are larger than all the brains in the male set. For the sets, we\nhave computed the corresponding braingraphs and computed numerous\ngraph-theoretical parameters. We have found that (i) the small male brains lack\nthe better connectivity advantages shown in our previous study for female\nbrains in general; (ii) in numerous parameters, the connectomes computed from\nthe large-brain females, still have the significant, deep connectivity\nadvantages, demonstrated in our previous study.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 16:50:32 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Szalkai", "Bal\u00e1zs", ""], ["Varga", "B\u00e1lint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1512.01197", "submitter": "Geza Odor", "authors": "Michael T. Gastner and G\\'eza \\'Odor", "title": "The topology of large Open Connectome networks for the human brain", "comments": "14 pages, 6 figures, accepted version in Scientific Reports", "journal-ref": "Scientific Reports 6 (2016) 27249", "doi": "10.1038/srep27249", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structural human connectome (i.e.\\ the network of fiber connections in\nthe brain) can be analyzed at ever finer spatial resolution thanks to advances\nin neuroimaging. Here we analyze several large data sets for the human brain\nnetwork made available by the Open Connectome Project. We apply statistical\nmodel selection to characterize the degree distributions of graphs containing\nup to $\\simeq 10^6$ nodes and $\\simeq 10^8$ edges. A three-parameter\ngeneralized Weibull (also known as a stretched exponential) distribution is a\ngood fit to most of the observed degree distributions. For almost all networks,\nsimple power laws cannot fit the data, but in some cases there is statistical\nsupport for power laws with an exponential cutoff. We also calculate the\ntopological (graph) dimension $D$ and the small-world coefficient $\\sigma$ of\nthese networks. While $\\sigma$ suggests a small-world topology, we found that\n$D < 4$ showing that long-distance connections provide only a small correction\nto the topology of the embedding three-dimensional space.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 19:13:54 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 12:42:43 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Gastner", "Michael T.", ""], ["\u00d3dor", "G\u00e9za", ""]]}, {"id": "1512.01213", "submitter": "Alireza Alemi", "authors": "Alireza Alemi", "title": "An attractor neural network architecture with an ultra high information\n  capacity: numerical results", "comments": "8 pages, 1 figure, minor revision of the text for clarification,\n  figure updated for including more data, unchanged results", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attractor neural network is an important theoretical scenario for modeling\nmemory function in the hippocampus and in the cortex. In these models, memories\nare stored in the plastic recurrent connections of neural populations in the\nform of \"attractor states\". The maximal information capacity for conventional\nabstract attractor networks with unconstrained connections is 2 bits/synapse.\nHowever, an unconstrained synapse has the capacity to store infinite amount of\nbits in a noiseless theoretical scenario: a capacity that conventional\nattractor networks cannot achieve. Here, I propose a hierarchical attractor\nnetwork that can achieve an ultra high information capacity. The network has\ntwo layers: a visible layer with $N_v$ neurons, and a hidden layer with $N_h$\nneurons. The visible-to-hidden connections are set at random and kept fixed\nduring the training phase, in which the memory patterns are stored as\nfixed-points of the network dynamics. The hidden-to-visible connections,\ninitially normally distributed, are learned via a local, online learning rule\ncalled the Three-Threshold Learning Rule and there is no within-layer\nconnections. The results of simulations suggested that the maximal information\ncapacity grows exponentially with the expansion ratio $N_h/N_v$. As a first\norder approximation to understand the mechanism providing the high capacity, I\nsimulated a naive mean-field approximation (nMFA) of the network. The\nexponential increase was captured by the nMFA, revealing that a key underlying\nfactor is the correlation between the hidden and the visible units.\nAdditionally, it was observed that, at maximal capacity, the degree of symmetry\nof the connectivity between the hidden and the visible neurons increases with\nthe expansion ratio. These results highlight the role of hierarchical\narchitecture in remarkably increasing the performance of information storage in\nattractor networks.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 20:06:46 GMT"}, {"version": "v2", "created": "Sun, 10 Jan 2016 22:57:54 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Alemi", "Alireza", ""]]}, {"id": "1512.01255", "submitter": "Sebastian Weichwald", "authors": "Sebastian Weichwald, Moritz Grosse-Wentrup, Arthur Gretton", "title": "MERLiN: Mixture Effect Recovery in Linear Networks", "comments": null, "journal-ref": "IEEE Journal of Selected Topics in Signal Processing, 10(7),\n  1254-1266, 2016", "doi": "10.1109/JSTSP.2016.2601144", "report-no": null, "categories": "stat.ME q-bio.NC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal inference concerns the identification of cause-effect relationships\nbetween variables, e.g. establishing whether a stimulus affects activity in a\ncertain brain region. The observed variables themselves often do not constitute\nmeaningful causal variables, however, and linear combinations need to be\nconsidered. In electroencephalographic studies, for example, one is not\ninterested in establishing cause-effect relationships between electrode signals\n(the observed variables), but rather between cortical signals (the causal\nvariables) which can be recovered as linear combinations of electrode signals.\n  We introduce MERLiN (Mixture Effect Recovery in Linear Networks), a family of\ncausal inference algorithms that implement a novel means of constructing causal\nvariables from non-causal variables. We demonstrate through application to EEG\ndata how the basic MERLiN algorithm can be extended for application to\ndifferent (neuroimaging) data modalities. Given an observed linear mixture, the\nalgorithms can recover a causal variable that is a linear effect of another\ngiven variable. That is, MERLiN allows us to recover a cortical signal that is\naffected by activity in a certain brain region, while not being a direct effect\nof the stimulus. The Python/Matlab implementation for all presented algorithms\nis available on https://github.com/sweichwald/MERLiN\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 21:29:30 GMT"}, {"version": "v2", "created": "Fri, 8 Jul 2016 17:43:18 GMT"}, {"version": "v3", "created": "Tue, 27 Sep 2016 21:27:57 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Weichwald", "Sebastian", ""], ["Grosse-Wentrup", "Moritz", ""], ["Gretton", "Arthur", ""]]}, {"id": "1512.01408", "submitter": "John Pearson", "authors": "Xin (Cindy) Chen, Jeffrey M Beck and John M Pearson", "title": "Neuron's Eye View: Inferring Features of Complex Stimuli from Neural\n  Responses", "comments": "Updated author list and added new results", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments that study neural encoding of stimuli at the level of individual\nneurons typically choose a small set of features present in the world ---\ncontrast and luminance for vision, pitch and intensity for sound --- and\nassemble a stimulus set that systematically varies along these dimensions.\nSubsequent analysis of neural responses to these stimuli typically focuses on\nregression models, with experimenter-controlled features as predictors and\nspike counts or firing rates as responses. Unfortunately, this approach\nrequires knowledge in advance about the relevant features coded by a given\npopulation of neurons. For domains as complex as social interaction or natural\nmovement, however, the relevant feature space is poorly understood, and an\narbitrary \\emph{a priori} choice of features may give rise to confirmation\nbias. Here, we present a Bayesian model for exploratory data analysis that is\ncapable of automatically identifying the features present in unstructured\nstimuli based solely on neuronal responses. Our approach is unique within the\nclass of latent state space models of neural activity in that it assumes that\nfiring rates of neurons are sensitive to multiple discrete time-varying\nfeatures tied to the \\emph{stimulus}, each of which has Markov (or semi-Markov)\ndynamics. That is, we are modeling neural activity as driven by multiple\nsimultaneous stimulus features rather than intrinsic neural dynamics. We derive\na fast variational Bayesian inference algorithm and show that it correctly\nrecovers hidden features in synthetic data, as well as ground-truth stimulus\nfeatures in a prototypical neural dataset. To demonstrate the utility of the\nalgorithm, we also apply it to cluster neural responses and demonstrate\nsuccessful recovery of features corresponding to monkeys and faces in the image\nset.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2015 14:00:43 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 20:19:50 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Xin", "", "", "Cindy"], ["Chen", "", ""], ["Beck", "Jeffrey M", ""], ["Pearson", "John M", ""]]}, {"id": "1512.01464", "submitter": "Dmytro Bielievtsov", "authors": "Dmytro Bielievtsov, Josef Ladenbauer, Klaus Obermayer", "title": "Controlling Statistical Moments of Stochastic Dynamical Networks", "comments": "12 pages, 9 eps figures", "journal-ref": "Phys. Rev. E 94, 012306 (2016)", "doi": "10.1103/PhysRevE.94.012306", "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a general class of stochastic networks and ask which network\nnodes need to be controlled, and how, to stabilize and switch between desired\nmetastable (target) states in terms of the first and second statistical moments\nof the system. We first show that it is sufficient to directly interfere with a\nsubset of nodes which can be identified using information about the graph of\nthe network only. Then, we develop a suitable method for feedback control which\nacts on that subset of nodes and preserves the covariance structure of the\ndesired target state. Finally, we demonstrate our theoretical results using a\nstochastic Hopfield network and a global brain model. Our results are\napplicable to a variety of (model) networks, and further our understanding of\nthe relationship between network structure and collective dynamics for the\nbenefit of effective control.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2015 16:11:30 GMT"}, {"version": "v2", "created": "Mon, 21 Dec 2015 21:21:08 GMT"}, {"version": "v3", "created": "Fri, 17 Jun 2016 14:37:26 GMT"}, {"version": "v4", "created": "Mon, 20 Jun 2016 00:33:16 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Bielievtsov", "Dmytro", ""], ["Ladenbauer", "Josef", ""], ["Obermayer", "Klaus", ""]]}, {"id": "1512.01536", "submitter": "Justus Kromer", "authors": "Justus A. Kromer, Lutz Schimansky-Geier, and Alexander B. Neiman", "title": "Emergence and coherence of oscillations in star networks of stochastic\n  excitable elements", "comments": "24 pages, 7 figures", "journal-ref": "Phys. Rev. E 93, 042406 (2016)", "doi": "10.1103/PhysRevE.93.042406", "report-no": null, "categories": "physics.bio-ph nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the emergence and coherence of stochastic oscillations in star\nnetworks of excitable elements in which peripheral nodes receive independent\nrandom inputs. A biophysical model of a distal branch of sensory neuron in\nwhich peripheral nodes of Ranvier are coupled to a central node by myelinated\ncable segments is used along with a generic model of networked stochastic\nactive rotators. We show that coherent oscillations can emerge due to\nstochastic synchronization of peripheral nodes and that the degree of coherence\ncan be maximized by tuning the coupling strength and the size of the network.\nAnalytical results are obtained for the strong coupling regime of the active\nrotator network. In particular, we show that in the strong coupling regime the\nnetwork dynamics can be described by an effective single active rotator with\nrescaled parameters and noise.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2015 20:41:50 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Kromer", "Justus A.", ""], ["Schimansky-Geier", "Lutz", ""], ["Neiman", "Alexander B.", ""]]}, {"id": "1512.01622", "submitter": "Christian Fink", "authors": "Stephen V. Gliske, Eugene Lim, Katherine A. Holman, William C. Stacey,\n  Christian G. Fink", "title": "Narrowband oscillations from asynchronous neural activity", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the possibility that narrowband oscillations may emerge from\ncompletely asynchronous, independent neural firing. We find that a population\nof asynchronous neurons may produce narrowband oscillations if each neuron\nfires quasi-periodically, and we deduce bounds on the degree of variability in\nneural spike-timing which will permit the emergence of such oscillations. These\nresults suggest a novel mechanism of neural rhythmogenesis, and they help to\nexplain recent experimental reports of large-amplitude local field potential\noscillations in the absence of neural spike-timing synchrony. Simply put,\nalthough synchrony can produce oscillations, oscillations do not always imply\nthe existence of synchrony.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 04:15:57 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Gliske", "Stephen V.", ""], ["Lim", "Eugene", ""], ["Holman", "Katherine A.", ""], ["Stacey", "William C.", ""], ["Fink", "Christian G.", ""]]}, {"id": "1512.01834", "submitter": "SueYeon Chung", "authors": "SueYeon Chung, Daniel D. Lee, Haim Sompolinsky", "title": "Linear Readout of Object Manifolds", "comments": "5 pages, 3 figures, accepted in Physical Review E as Rapid\n  Communication on 14th May. 2016", "journal-ref": "Phys. Rev. E 93, 060301 (R) (2016)", "doi": "10.1103/PhysRevE.93.060301", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objects are represented in sensory systems by continuous manifolds due to\nsensitivity of neuronal responses to changes in physical features such as\nlocation, orientation, and intensity. What makes certain sensory\nrepresentations better suited for invariant decoding of objects by downstream\nnetworks? We present a theory that characterizes the ability of a linear\nreadout network, the perceptron, to classify objects from variable neural\nresponses. We show how the readout perceptron capacity depends on the\ndimensionality, size, and shape of the object manifolds in its input neural\nrepresentation.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2015 21:00:02 GMT"}, {"version": "v2", "created": "Sun, 21 Aug 2016 05:50:13 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Chung", "SueYeon", ""], ["Lee", "Daniel D.", ""], ["Sompolinsky", "Haim", ""]]}, {"id": "1512.01922", "submitter": "Junghyo Jo", "authors": "Jin Xu, Dong-Ho Park, and Junghyo Jo", "title": "Controllable Synchronization of Hierarchically Networked Oscillators", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The controllability of synchronization is an intriguing question in complex\nsystems, in which hiearchically-organized heterogeneous elements have\nasymmetric and activity-dependent couplings. In this study, we introduce a\nsimple and effective way to control synchronization in such a complex system by\nchanging the complexity of subsystems. We consider three Stuart-Landau\noscillators as a minimal subsystem for generating various complexity, and\nhiearchically connect the subsystems through a mean field of their activities.\nDepending on the coupling signs between three oscillators, subsystems can\ngenerate ample dynamics, in which the number of attractors specify their\ncomplexity. The degree of synchronization between subsystems is then\ncontrollable by changing the complexity of subsystems. This controllable\nsynchronization can be applied to understand the synchronization behavior of\ncomplex biological networks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 06:07:31 GMT"}], "update_date": "2015-12-08", "authors_parsed": [["Xu", "Jin", ""], ["Park", "Dong-Ho", ""], ["Jo", "Junghyo", ""]]}, {"id": "1512.02574", "submitter": "Andreas Daffertshofer", "authors": "Robert Ton, Gustavo Deco, Morten L Kringelbach, Mark Woolrich, and\n  Andreas Daffertshofer", "title": "Distinct criticality of phase and amplitude dynamics in the resting\n  brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Converging research suggests that the resting brain operates at the cusp of\ndynamic instability signified by scale-free temporal correlations. We asked if\nthe scaling properties of these correlations differ between amplitude and phase\nfluctuations, which may reflect different aspects of cortical functioning.\nUsing source-reconstructed magneto-encephalographic signals, we found power-law\nscaling for the collective amplitude and for phase synchronization, both\ncapturing whole-brain activity. The temporal changes of the amplitude comprise\nslow, persistent memory processes, whereas phase synchronization exhibits less\ntemporally structured and more complex correlations, indicating a fast and\nflexible coding. This distinct temporal scaling supports the idea of different\nroles of amplitude and phase in cortical functioning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2015 18:28:06 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Ton", "Robert", ""], ["Deco", "Gustavo", ""], ["Kringelbach", "Morten L", ""], ["Woolrich", "Mark", ""], ["Daffertshofer", "Andreas", ""]]}, {"id": "1512.02602", "submitter": "Sergio Pequito", "authors": "Cassiano O. Becker, Sergio Pequito, George J. Pappas, Michael B.\n  Miller, Scott T. Grafton, Danielle S. Bassett and Victor M. Preciado", "title": "Accurately Predicting Functional Connectivity from Diffusion Imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the relationship between the dynamics of neural processes and\nthe anatomical substrate of the brain is a central question in neuroscience. On\nthe one hand, modern neuroimaging technologies, such as diffusion tensor\nimaging, can be used to construct structural graphs representing the\narchitecture of white matter streamlines linking cortical and subcortical\nstructures. On the other hand, temporal patterns of neural activity can be used\nto construct functional graphs representing temporal correlations between brain\nregions. Although some studies provide evidence that whole-brain functional\nconnectivity is shaped by the underlying anatomy, the observed relationship\nbetween function and structure is weak, and the rules by which anatomy\nconstrains brain dynamics remain elusive. In this article, we introduce a\nmethodology to predict with high accuracy the functional connectivity of a\nsubject at rest from his or her structural graph. Using our methodology, we are\nable to systematically unveil the role of structural paths in the formation of\nfunctional correlations. Furthermore, in our empirical evaluations, we observe\nthat the eigen-modes of the predicted functional connectivity are aligned with\nactivity patterns associated with different cognitive systems. Our work offers\nthe potential to infer properties of brain dynamics in clinical or\ndevelopmental populations with low tolerance for functional neuroimaging.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2015 19:53:53 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2015 00:34:56 GMT"}, {"version": "v3", "created": "Wed, 20 Apr 2016 17:36:08 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Becker", "Cassiano O.", ""], ["Pequito", "Sergio", ""], ["Pappas", "George J.", ""], ["Miller", "Michael B.", ""], ["Grafton", "Scott T.", ""], ["Bassett", "Danielle S.", ""], ["Preciado", "Victor M.", ""]]}, {"id": "1512.02603", "submitter": "Sergey Komech Mr", "authors": "Elena Zhizhina and Sergey Komech and Xavier Descombes", "title": "Modelling axon growing using CTRW", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal of this study is to propose a mathematical model describing\npaths of the axon growth cones and differences in the behavior of normal and\nmutant axons. We introduce a probabilistic model for axon growing, such that\neach family of axons is described as an ensemble of trajectories of a\ncontinuous time random walk (CTRW) model under different parameters in the case\nof normal and mutant axons. We describe different regimes in the model and\nconclude how the behavior of axons depends on the parameters of the model.\nBiological observations of the axonal growth process say us that the guiding\ndevelopment of axons to their targets is operated by chemical signals from the\ncellular environment. To simulate this control mechanism we propose the CTRW\nmodel, where a random waiting time reflects a reaction time of the growth cones\non the neighboring chemical environment.\n", "versions": [{"version": "v1", "created": "Sat, 5 Dec 2015 22:05:22 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Zhizhina", "Elena", ""], ["Komech", "Sergey", ""], ["Descombes", "Xavier", ""]]}, {"id": "1512.02930", "submitter": "Hesham Mostafa", "authors": "Hesham Mostafa, Giacomo Indiveri", "title": "Stochastic Interpretation of Quasi-periodic Event-based Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many networks used in machine learning and as models of biological neural\nnetworks make use of stochastic neurons or neuron-like units. We show that\nstochastic artificial neurons can be realized on silicon chips by exploiting\nthe quasi-periodic behavior of mismatched analog oscillators to approximate the\nneuron's stochastic activation function. We represent neurons by finite state\nmachines (FSMs) that communicate using digital events and whose transitions are\nevent-triggered. The event generation times of each neuron are controlled by an\nanalog oscillator internal to that neuron/FSM and the frequencies of the\noscillators in different FSMs are incommensurable. We show that within this\nquasi-periodic system, the transition graph of a FSM can be interpreted as the\ntransition graph of a Markov chain and we show that by using different FSMs, we\ncan obtain approximations of different stochastic activation functions. We\ninvestigate the quality of the stochastic interpretation of such a\ndeterministic system and we use the system to realize and sample from a\nrestricted Boltzmann machine. We implemented the quasi-periodic event-based\nsystem on a custom silicon chip and we show that the chip behavior can be used\nto closely approximate a stochastic sampling task.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2015 16:31:59 GMT"}], "update_date": "2015-12-10", "authors_parsed": [["Mostafa", "Hesham", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "1512.03561", "submitter": "Vladimir Klinshov", "authors": "Vladimir Klinshov and Igor Franovic", "title": "Mean-field dynamics of a random neural network with noise", "comments": null, "journal-ref": "Physical Review E 92, 062813 (2015)", "doi": "10.1103/PhysRevE.92.062813", "report-no": null, "categories": "nlin.CD math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a network of randomly coupled rate-based neurons influenced by\nexternal and internal noise. We derive a second-order stochastic mean-field\nmodel for the network dynamics and use it to analyze the stability and\nbifurcations in the thermodynamic limit, as well as to study the fluctuations\ndue to the finite-size effect. It is demonstrated that the two types of noise\nhave substantially different impact on the network dynamics. While both sources\nof noise give rise to stochastic fluctuations in the case of the finite-size\nnetwork, only the external noise affects the stationary activity levels of the\nnetwork in the thermodynamic limit.We compare the theoretical predictions with\nthe direct simulation results and show that they agree for large enough network\nsizes and for parameter domains sufficiently away from bifurcations.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2015 09:23:06 GMT"}], "update_date": "2015-12-14", "authors_parsed": [["Klinshov", "Vladimir", ""], ["Franovic", "Igor", ""]]}, {"id": "1512.03784", "submitter": "Hao Yu", "authors": "Chenxia Gu, Shaotong Wang, Hao Yu", "title": "A Chessboard Model of Human Brain and One Application on Memory Capacity", "comments": "21 pages, 7 figures, 1 tabel", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The famous claim that we only use about 10% of the brain capacity has\nrecently been challenged. Researchers argue that we are likely to use the whole\nbrain, against the 10% claim. Some evidence and results from relevant studies\nand experiments related to memory in the field of neuroscience leads to the\nconclusion that if the rest 90% of the brain is not used, then many neural\npathways would degenerate. What is memory? How does the brain function? What\nwould be the limit of memory capacity? This article provides a model\nestablished upon the physiological and neurological characteristics of the\nhuman brain, which could give some theoretical support and scientific\nexplanation to explain some phenomena. It may not only have theoretically\nsignificance in neuroscience, but could also be practically useful to fill in\nthe gap between the natural and machine intelligence.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2015 09:02:32 GMT"}, {"version": "v2", "created": "Fri, 29 Jan 2016 11:06:34 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Gu", "Chenxia", ""], ["Wang", "Shaotong", ""], ["Yu", "Hao", ""]]}, {"id": "1512.03785", "submitter": "Carmen Oana Tarniceriu", "authors": "Gr\\'egory Dumont, Jacques Henry, Carmen Oana Tarniceriu", "title": "Noisy threshold in neuronal models: connections with the noisy leaky\n  integrate-and-fire model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing an analytical treatment to the stochastic feature of neurons'\ndynamics is one of the current biggest challenges in mathematical biology. The\nnoisy leaky integrate-and-fire model and its associated Fokker-Planck equation\nare probably the most popular way to deal with neural variability. Another\nwell-known formalism is the escape-rate model: a model giving the probability\nthat a neuron fires at a certain time knowing the time elapsed since its last\naction potential. This model leads to a so-called age-structured system, a\npartial differential equation with non-local boundary condition famous in the\nfield of population dynamics, where the {\\it age} of a neuron is the amount of\ntime passed by since its previous spike. In this theoretical paper, we\ninvestigate the mathematical connection between the two formalisms. We shall\nderive an integral transform of the solution to the age-structured model into\nthe solution of the Fokker-Planck equation. This integral transform highlights\nthe link between the two stochastic processes. As far as we know, an explicit\nmathematical correspondence between the two solutions has not been introduced\nuntil now.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2015 18:49:36 GMT"}], "update_date": "2015-12-14", "authors_parsed": [["Dumont", "Gr\u00e9gory", ""], ["Henry", "Jacques", ""], ["Tarniceriu", "Carmen Oana", ""]]}, {"id": "1512.03850", "submitter": "Junghyo Jo", "authors": "Marissa Pastor and Juyong Song and Danh-Tai Hoang and Junghyo Jo", "title": "Minimal Perceptrons for Memorizing Complex Patterns", "comments": "14 pages, 5 figures", "journal-ref": "Physica A 462:31-37 (2016)", "doi": "10.1016/j.physa.2016.06.025", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedforward neural networks have been investigated to understand learning and\nmemory, as well as applied to numerous practical problems in pattern\nclassification. It is a rule of thumb that more complex tasks require larger\nnetworks. However, the design of optimal network architectures for specific\ntasks is still an unsolved fundamental problem. In this study, we consider\nthree-layered neural networks for memorizing binary patterns. We developed a\nnew complexity measure of binary patterns, and estimated the minimal network\nsize for memorizing them as a function of their complexity. We formulated the\nminimal network size for regular, random, and complex patterns. In particular,\nthe minimal size for complex patterns, which are neither ordered nor\ndisordered, was predicted by measuring their Hamming distances from known\nordered patterns. Our predictions agreed with simulations based on the\nback-propagation algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2015 00:08:27 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Pastor", "Marissa", ""], ["Song", "Juyong", ""], ["Hoang", "Danh-Tai", ""], ["Jo", "Junghyo", ""]]}, {"id": "1512.03955", "submitter": "Rui Li", "authors": "Rui Li, Robert Perneczky, Alexander Drzezga, Stefan Kramer (for the\n  Alzheimer's Disease Neuroimaging Initiative)", "title": "Survival analysis, the infinite Gaussian mixture model, FDG-PET and\n  non-imaging data in the prediction of progression from mild cognitive\n  impairment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to discover interesting brain regions in [18F]\nfluorodeoxyglucose positron emission tomography (PET) scans, showing also the\nbenefits when PET scans are in combined use with non-imaging variables. The\ndiscriminative brain regions facilitate a better understanding of Alzheimer's\ndisease (AD) progression, and they can also be used for predicting conversion\nfrom mild cognitive impairment (MCI) to AD. A survival analysis(Cox regression)\nand infinite Gaussian mixture model (IGMM) are introduced to identify the\ninformative brain regions, which can be further used to make a prediction of\nconversion (in two years) from MCI to AD using only the baseline PET scan.\nFurther, the predictive accuracy can be enhanced when non-imaging variables are\nused together with identified informative brain voxels. The results suggest\nthat PET scan imaging data is more predictive than other non-imaging data,\nrevealing even better performance when both imaging and non-imaging data are\ncombined.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2015 20:01:57 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Li", "Rui", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Perneczky", "Robert", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Drzezga", "Alexander", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Kramer", "Stefan", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"]]}, {"id": "1512.04247", "submitter": "Gabriele Lohmann", "authors": "Gabriele Lohmann, Johannes Stelzer, Verena Zuber, Tilo Buschmann,\n  Daniel Margulies, Andreas Bartels, Klaus Scheffler", "title": "Task-related edge density (TED) - a new method for revealing large-scale\n  network formation in fMRI data of the human brain", "comments": "21 pages, 11 figures", "journal-ref": "PLoS ONE 11(6): e0158185 (2016)", "doi": "10.1371/journal.pone.0158185", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formation of transient networks in response to external stimuli or as a\nreflection of internal cognitive processes is a hallmark of human brain\nfunction. However, its identification in fMRI data of the human brain is\nnotoriously difficult. Here we propose a new method of fMRI data analysis that\ntackles this problem by considering large-scale, task-related synchronisation\nnetworks. Networks consist of nodes and edges connecting them, where nodes\ncorrespond to voxels in fMRI data, and the weight of an edge is determined via\ntask-related changes in dynamic synchronisation between their respective times\nseries. Based on these definitions, we developed a new data analysis algorithm\nthat identifies edges in a brain network that differentially respond in unison\nto a task onset and that occur in dense packs with similar characteristics.\nHence, we call this approach \"Task-related Edge Density\" (TED). TED proved to\nbe a very strong marker for dynamic network formation that easily lends itself\nto statistical analysis using large scale statistical inference. A major\nadvantage of TED compared to other methods is that it does not depend on any\nspecific hemodynamic response model, and it also does not require a\npresegmentation of the data for dimensionality reduction as it can handle large\nnetworks consisting of tens of thousands of voxels. We applied TED to fMRI data\nof a fingertapping task provided by the Human Connectome Project. TED revealed\nnetwork-based involvement of a large number of brain areas that evaded\ndetection using traditional GLM-based analysis. We show that our proposed\nmethod provides an entirely new window into the immense complexity of human\nbrain function.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 10:31:50 GMT"}], "update_date": "2016-12-05", "authors_parsed": [["Lohmann", "Gabriele", ""], ["Stelzer", "Johannes", ""], ["Zuber", "Verena", ""], ["Buschmann", "Tilo", ""], ["Margulies", "Daniel", ""], ["Bartels", "Andreas", ""], ["Scheffler", "Klaus", ""]]}, {"id": "1512.04274", "submitter": "Sebastian Weichwald", "authors": "Sebastian Weichwald, Timm Meyer, Bernhard Sch\\\"olkopf, Tonio Ball,\n  Moritz Grosse-Wentrup", "title": "Decoding index finger position from EEG using random forests", "comments": "accepted manuscript", "journal-ref": "Cognitive Information Processing (CIP), 2014 4th International\n  Workshop on, 1-6, 2014", "doi": "10.1109/CIP.2014.6844513", "report-no": null, "categories": "stat.ML q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While invasively recorded brain activity is known to provide detailed\ninformation on motor commands, it is an open question at what level of detail\ninformation about positions of body parts can be decoded from non-invasively\nacquired signals. In this work it is shown that index finger positions can be\ndifferentiated from non-invasive electroencephalographic (EEG) recordings in\nhealthy human subjects. Using a leave-one-subject-out cross-validation\nprocedure, a random forest distinguished different index finger positions on a\nnumerical keyboard above chance-level accuracy. Among the different spectral\nfeatures investigated, high $\\beta$-power (20-30 Hz) over contralateral\nsensorimotor cortex carried most information about finger position. Thus, these\nfindings indicate that finger position is in principle decodable from\nnon-invasive features of brain activity that generalize across individuals.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 12:19:31 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Weichwald", "Sebastian", ""], ["Meyer", "Timm", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Ball", "Tonio", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1512.04293", "submitter": "Torbj{\\o}rn V Ness", "authors": "Torbj{\\o}rn V Ness, Michiel W H Remme, Gaute T Einevoll", "title": "Active subthreshold dendritic conductances shape the local field\n  potential", "comments": null, "journal-ref": "J Physiol 2016, 594 (13)", "doi": "10.1113/JP272022", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution to the local field potential (LFP) is thought to stem\nfrom synaptic input to neurons and the ensuing subthreshold dendritic\nprocessing. The role of active dendritic conductances in shaping the LFP has\nreceived little attention, even though such ion channels are known to affect\nthe subthreshold neuron dynamics. Here we used a modeling approach to\ninvestigate the effects of subthreshold dendritic conductances on the LFP.\nUsing a biophysically detailed, experimentally constrained model of a cortical\npyramidal neuron, we identified conditions under which subthreshold active\nconductances are a major factor in shaping the LFP. We found that particularly\nthe hyperpolarization-activated inward current, I$_{\\rm h}$, can have a sizable\neffect and cause a resonance in the LFP power spectral density. To get a\ngeneral, qualitative understanding of how any subthreshold active dendritic\nconductance and its cellular distribution can affect the LFP, we next performed\na systematic study with a simplified model. We found that the effect on the LFP\nis most pronounced when (1) the synaptic drive to the cell is asymmetrically\ndistributed (i.e., either basal or apical), (2) the active conductances are\ndistributed non-uniformly with the highest channel densities near the synaptic\ninput, and (3) when the LFP is measured at the opposite pole of the cell\nrelative to the synaptic input. In summary, we show that subthreshold active\nconductances can be strongly reflected in LFP signals, opening up the\npossibility that the LFP can be used to characterize the properties and\ncellular distributions of active conductances.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 13:02:56 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Ness", "Torbj\u00f8rn V", ""], ["Remme", "Michiel W H", ""], ["Einevoll", "Gaute T", ""]]}, {"id": "1512.04426", "submitter": "Piotr S{\\l}owi\\'nski", "authors": "Piotr S{\\l}owi\\'nski, Krasimira Tsaneva-Atanasova and Bernd Krauskopf", "title": "Effects of time-delay in a model of intra- and inter-personal motor\n  coordination", "comments": null, "journal-ref": "Eur. Phys. J. Special Topics 225, 2591-2600 (2016)", "doi": "10.1140/epjst/e2015-50327-6", "report-no": null, "categories": "math.DS nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motor coordination is an important feature of intra- and inter-personal\ninteractions, and several scenarios --- from finger tapping to human-computer\ninterfaces --- have been investigated experimentally. In the 1980, Haken, Kelso\nand Bunz formulated a coupled nonlinear two-oscillator model, which has been\nshown to describe many observed aspects of coordination tasks. We present here\na bifurcation study of this model, where we consider a delay in the coupling.\nThe delay is shown to have a significant effect on the observed dynamics. In\nparticular, we find a much larger degree of bistablility between in-phase and\nanti-phase oscillations in the presence of a frequency detuning.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2015 17:46:29 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["S\u0142owi\u0144ski", "Piotr", ""], ["Tsaneva-Atanasova", "Krasimira", ""], ["Krauskopf", "Bernd", ""]]}, {"id": "1512.04808", "submitter": "Sebastian Weichwald", "authors": "Sebastian Weichwald, Bernhard Sch\\\"olkopf, Tonio Ball, Moritz\n  Grosse-Wentrup", "title": "Causal and anti-causal learning in pattern recognition for neuroimaging", "comments": "accepted manuscript", "journal-ref": "Pattern Recognition in Neuroimaging, 2014 International Workshop\n  on, 1-4, 2014", "doi": "10.1109/PRNI.2014.6858551", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern recognition in neuroimaging distinguishes between two types of\nmodels: encoding- and decoding models. This distinction is based on the insight\nthat brain state features, that are found to be relevant in an experimental\nparadigm, carry a different meaning in encoding- than in decoding models. In\nthis paper, we argue that this distinction is not sufficient: Relevant features\nin encoding- and decoding models carry a different meaning depending on whether\nthey represent causal- or anti-causal relations. We provide a theoretical\njustification for this argument and conclude that causal inference is essential\nfor interpretation in neuroimaging.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 15:05:00 GMT"}], "update_date": "2015-12-16", "authors_parsed": [["Weichwald", "Sebastian", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Ball", "Tonio", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1512.05007", "submitter": "Anca Radulescu", "authors": "Anca Radulescu, Rachel Marra", "title": "A mathematical model of reward and executive circuitry in obsessive\n  compulsive disorde", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neuronal circuit that controls obsessive and compulsive behaviors\ninvolves a complex network of brain regions (some with known involvement in\nreward processing). Among these are cortical regions, the striatum and the\nthalamus (which compose the CSTC pathway), limbic areas such as the amygdala\nand the hippocampus, and well as dopamine pathways. Abnormal dynamic behavior\nin this brain network is a hallmark feature of patients with increased anxiety\nand motor activity, like the ones affected by OCD. There is currently no clear\nunderstanding of precisely what mechanisms generates these behaviors.\n  We attempt to investigate a collection of connectivity hypotheses of OCD by\nmeans of a computational model of the brain circuitry that governs reward and\nmotion execution. Mathematically, we use methods from ordinary differential\nequations and continuous time dynamical systems. We use classical analytical\nmethods as well as computational approaches to study phenomena in the phase\nplane (e.g., behavior of the system's solutions when given certain initial\nconditions) and in the parameter space (e.g., sensitive dependence of initial\nconditions).\n  We find that different obsessive-compulsive subtypes may correspond to\ndifferent abnormalities in the network connectivity profiles. We suggest that\nit is combinations of parameters (connectivity strengths between regions),\nrather the than the value of any one parameter taken independently, that\nprovides the best basis for predicting behavior, and for understanding the\nheterogeneity of the illness.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2015 23:17:55 GMT"}], "update_date": "2015-12-17", "authors_parsed": [["Radulescu", "Anca", ""], ["Marra", "Rachel", ""]]}, {"id": "1512.05220", "submitter": "Luke Bashford", "authors": "Luke Bashford and Carsten Mehring", "title": "Ownership and Agency of an Independent Supernumerary Hand Induced by an\n  Imitation Brain-Computer Interface", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0156591", "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To study body ownership and control, illusions that elicit these feelings in\nnon-body objects are widely used. Classically introduced with the Rubber Hand\nIllusion, these illusions have been replicated more recently in virtual reality\nand by using brain-computer interfaces. Traditionally these illusions\ninvestigate the replacement of a body part by an artificial counterpart,\nhowever as brain-computer interface research develops it offers us the\npossibility to explore the case where non-body objects are controlled in\naddition to movements of our own limbs. Therefore we propose a new illusion\ndesigned to test the feeling of ownership and control of an independent\nsupernumerary hand. Subjects are under the impression they control a virtual\nreality hand via a brain-computer interface, but in reality there is no causal\nconnection between brain activity and virtual hand movement but correct\nmovements are observed with 80% probability. These imitation brain-computer\ninterface trials are interspersed with movements in both the subjects' real\nhands, which are in view throughout the experiment. We show that subjects\ndevelop strong feelings of ownership and control over the third hand, despite\nonly receiving visual feedback with no causal link to the actual brain signals.\nOur illusion is crucially different from previously reported studies as we\ndemonstrate independent ownership and control of the third hand without loss of\nownership in the real hands.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 15:55:14 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 14:47:34 GMT"}], "update_date": "2016-06-17", "authors_parsed": [["Bashford", "Luke", ""], ["Mehring", "Carsten", ""]]}, {"id": "1512.05245", "submitter": "Fergal Byrne", "authors": "Fergal Byrne", "title": "Symphony from Synapses: Neocortex as a Universal Dynamical Systems\n  Modeller using Hierarchical Temporal Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Reverse engineering the brain is proving difficult, perhaps impossible. While\nmany believe that this is just a matter of time and effort, a different\napproach might help. Here, we describe a very simple idea which explains the\npower of the brain as well as its structure, exploiting complex dynamics rather\nthan abstracting it away. Just as a Turing Machine is a Universal Digital\nComputer operating in a world of symbols, we propose that the brain is a\nUniversal Dynamical Systems Modeller, evolved bottom-up (itself using nested\nnetworks of interconnected, self-organised dynamical systems) to prosper in a\nworld of dynamical systems.\n  Recent progress in Applied Mathematics has produced startling evidence of\nwhat happens when abstract Dynamical Systems interact. Key latent information\ndescribing system A can be extracted by system B from very simple signals, and\nsignals can be used by one system to control and manipulate others. Using these\nfacts, we show how a region of the neocortex uses its dynamics to intrinsically\n\"compute\" about the external and internal world.\n  Building on an existing \"static\" model of cortical computation (Hawkins'\nHierarchical Temporal Memory - HTM), we describe how a region of neocortex can\nbe viewed as a network of components which together form a Dynamical Systems\nmodelling module, connected via sensory and motor pathways to the external\nworld, and forming part of a larger dynamical network in the brain.\n  Empirical modelling and simulations of Dynamical HTM are possible with simple\nextensions and combinations of currently existing open source software. We list\na number of relevant projects.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 16:58:06 GMT"}], "update_date": "2015-12-17", "authors_parsed": [["Byrne", "Fergal", ""]]}, {"id": "1512.05264", "submitter": "Pier Stanislao Paolucci", "authors": "Elena Pastorelli, Pier Stanislao Paolucci, Roberto Ammendola, Andrea\n  Biagioni, Ottorino Frezza, Francesca Lo Cicero, Alessandro Lonardo, Michele\n  Martinelli, Francesco Simula, Piero Vicini", "title": "Impact of exponential long range and Gaussian short range lateral\n  connectivity on the distributed simulation of neural networks including up to\n  30 billion synapses", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental neuroscience studies are pointing out the role of\nlong-range intra-areal connectivity that can be modeled by a distance dependent\nexponential decay of the synaptic probability distribution. This short report\nprovides a preliminary measure of the impact of exponentially decaying lateral\nconnectivity compared to that of shorter-range Gaussian decays on the scaling\nbehaviour and memory occupation of a distributed spiking neural network\nsimulator (DPSNN). Two-dimensional grids of cortical columns composed by\npoint-like spiking neurons have been connected by up to 30 billion synapses\nusing exponential and Gaussian connectivity models. Up to 1024 hardware cores,\nhosted on a 64 nodes server platform, executed the MPI processes composing the\ndistributed simulator. The hardware platform was a cluster of IBM NX360 M5\n16-core compute nodes, each one containing two Intel Xeon Haswell 8-core\nE5-2630 v3 processors, with a clock of 2.40GHz, interconnected through an\nInfiniBand network. This study is conducted in the framework of the CORTICONIC\nFET project, also in view of the next -to-start activities foreseen as part of\nthe Human Brain Project (HBP), SubProject 3 Cognitive and Systems Neuroscience,\nWaveScalES work-package.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 18:03:20 GMT"}], "update_date": "2015-12-17", "authors_parsed": [["Pastorelli", "Elena", ""], ["Paolucci", "Pier Stanislao", ""], ["Ammendola", "Roberto", ""], ["Biagioni", "Andrea", ""], ["Frezza", "Ottorino", ""], ["Cicero", "Francesca Lo", ""], ["Lonardo", "Alessandro", ""], ["Martinelli", "Michele", ""], ["Simula", "Francesco", ""], ["Vicini", "Piero", ""]]}, {"id": "1512.05340", "submitter": "\\\"Ozkan Karabacak Mr.", "authors": "Neslihan Serap \\c{S}eng\\\"or and \\\"Ozkan Karabacak", "title": "A computational model revealing the effect of dopamine on action\n  selection", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to reveal the effect of nigrostriatal dopamine system on action\nselection, first a computational model of the cortex-basal ganglia-thalamus\nloop is proposed and based on this model a simple compound model realizing the\nStroop effect is established. Even though Stroop task is mostly used to examine\nselective attention, the main objective of this work is to investigate the\neffect of action selection on Stroop task. The computational model of the\ncortex-basal ganglia-thalamus loop is a non-linear dynamical system which is\nnot only capable of revealing the action selection property of basal ganglia\nbut also capable of modelling the effect of dopamine on action selection. While\nthe interpretation of action selection is based on the solutions of the\nnon-linear dynamical system, the effect of dopamine is modelled by a parameter\nof the model. The inhibiting effect of dopamine on the habitual behaviour which\ncorresponds to word reading in Stroop task and letting the novel one occur\ncorresponding to colour naming is investigated using the compound computational\nmodel established in this work.\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 10:32:11 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["\u015eeng\u00f6r", "Neslihan Serap", ""], ["Karabacak", "\u00d6zkan", ""]]}, {"id": "1512.05386", "submitter": "Andrei Khrennikov Yu", "authors": "Andrei Khrennikov", "title": "\"Social Laser\": Action Amplification by Stimulated Emission of Social\n  Energy", "comments": null, "journal-ref": "Phil. Trans. Royal Soc. 374, N 2054, 20150094 (2016)", "doi": "10.1098/rsta.2015.0094", "report-no": null, "categories": "physics.soc-ph q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of the \"explanation\" of recent social explosions, especially in\nthe Middle East, but also in Southern Europe and the USA, have been debated\nactively in the social and political literature. We can mention the\ncontributions of P. Mason, F. Fukuyama, E. Schmidt and J. Cohen, I. Krastev to\nthis debate. We point out that the diversity of opinions and conclusions is\nreally amazing. At the moment, there is no consistent and commonly acceptable\ntheory of these phenomena. We present a model of social explosions based on a\nnovel approach for the description of social processes, namely, the\nquantum-like approach. Here quantum theory is treated simply as an operational\nformalism - without any direct relation to physics. We explore the quantum-like\nlaser model to describe the possibility of Action Amplification by Stimulated\nEmission of Social Energy (ASE).\n", "versions": [{"version": "v1", "created": "Wed, 16 Dec 2015 21:41:28 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Khrennikov", "Andrei", ""]]}, {"id": "1512.05463", "submitter": "Subutai Ahmad", "authors": "Yuwei Cui, Subutai Ahmad, and Jeff Hawkins", "title": "Continuous online sequence learning with an unsupervised neural network\n  model", "comments": "Preprint of journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to recognize and predict temporal sequences of sensory inputs is\nvital for survival in natural environments. Based on many known properties of\ncortical neurons, hierarchical temporal memory (HTM) sequence memory is\nrecently proposed as a theoretical framework for sequence learning in the\ncortex. In this paper, we analyze properties of HTM sequence memory and apply\nit to sequence learning and prediction problems with streaming data. We show\nthe model is able to continuously learn a large number of variable-order\ntemporal sequences using an unsupervised Hebbian-like learning rule. The sparse\ntemporal codes formed by the model can robustly handle branching temporal\nsequences by maintaining multiple predictions until there is sufficient\ndisambiguating evidence. We compare the HTM sequence memory with other sequence\nlearning algorithms, including statistical methods: autoregressive integrated\nmoving average (ARIMA), feedforward neural networks: online sequential extreme\nlearning machine (ELM), and recurrent neural networks: long short-term memory\n(LSTM) and echo-state networks (ESN), on sequence prediction problems with both\nartificial and real-world data. The HTM model achieves comparable accuracy to\nother state-of-the-art algorithms. The model also exhibits properties that are\ncritical for sequence learning, including continuous online learning, the\nability to handle multiple predictions and branching sequences with high order\nstatistics, robustness to sensor noise and fault tolerance, and good\nperformance without task-specific hyper- parameters tuning. Therefore the HTM\nsequence memory not only advances our understanding of how the brain may solve\nthe sequence learning problem, but is also applicable to a wide range of\nreal-world problems such as discrete and continuous sequence prediction,\nanomaly detection, and sequence classification.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 04:45:31 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2016 21:00:52 GMT"}], "update_date": "2016-05-02", "authors_parsed": [["Cui", "Yuwei", ""], ["Ahmad", "Subutai", ""], ["Hawkins", "Jeff", ""]]}, {"id": "1512.05478", "submitter": "Ariel Amir", "authors": "Ariel Amir, Naomichi Hatano and David R. Nelson", "title": "Non-Hermitian Localization in Biological Networks", "comments": null, "journal-ref": "Phys. Rev. E 93, 042310 (2016)", "doi": "10.1103/PhysRevE.93.042310", "report-no": null, "categories": "cond-mat.dis-nn math-ph math.MP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the spectra and localization properties of the N-site banded\none-dimensional non-Hermitian random matrices that arise naturally in sparse\nneural networks. Approximately equal numbers of random excitatory and\ninhibitory connections lead to spatially localized eigenfunctions, and an\nintricate eigenvalue spectrum in the complex plane that controls the\nspontaneous activity and induced response. A finite fraction of the eigenvalues\ncondense onto the real or imaginary axes. For large N, the spectrum has\nremarkable symmetries not only with respect to reflections across the real and\nimaginary axes, but also with respect to 90 degree rotations, with an unusual\nanisotropic divergence in the localization length near the origin. When chains\nwith periodic boundary conditions become directed, with a systematic\ndirectional bias superimposed on the randomness, a hole centered on the origin\nopens up in the density-of-states in the complex plane. All states are extended\non the rim of this hole, while the localized eigenvalues outside the hole are\nunchanged. The bias dependent shape of this hole tracks the bias independent\ncontours of constant localization length. We treat the large-N limit by a\ncombination of direct numerical diagonalization and using transfer matrices, an\napproach that allows us to exploit an electrostatic analogy connecting the\n\"charges\" embodied in the eigenvalue distribution with the contours of constant\nlocalization length. We show that similar results are obtained for more\nrealistic neural networks that obey \"Dale's Law\" (each site is purely\nexcitatory or inhibitory), and conclude with perturbation theory results that\ndescribe the limit of large bias g, when all states are extended. Related\nproblems arise in random ecological networks and in chains of artificial cells\nwith randomly coupled gene expression patterns.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 06:44:27 GMT"}, {"version": "v2", "created": "Mon, 4 Jan 2016 21:56:09 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Amir", "Ariel", ""], ["Hatano", "Naomichi", ""], ["Nelson", "David R.", ""]]}, {"id": "1512.05497", "submitter": "Per B{\\ae}kgaard", "authors": "Per B{\\ae}kgaard, Michael Kai Petersen, Jakob Eg Larsen", "title": "Assessing Levels of Attention using Low Cost Eye Tracking", "comments": "12 pages, 6 figures, 2 tables. The final publication will be\n  available at Springer via http://dx.doi.org/DOIxxx, when published as part of\n  the HCI International 2016 Conference Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of mobile eye trackers embedded in next generation smartphones\nor VR displays will make it possible to trace not only what objects we look at\nbut also the level of attention in a given situation. Exploring whether we can\nquantify the engagement of a user interacting with a laptop, we apply mobile\neye tracking in an in-depth study over 2 weeks with nearly 10.000 observations\nto assess pupil size changes, related to attentional aspects of alertness,\norientation and conflict resolution. Visually presenting conflicting cues and\ntargets we hypothesize that it's feasible to measure the allocated effort when\nresponding to confusing stimuli. Although such experiments are normally carried\nout in a lab, we are able to differentiate between sustained alertness and\ncomplex decision making even with low cost eye tracking \"in the wild\". From a\nquantified self perspective of individual behavioral adaptation, the\ncorrelations between the pupil size and the task dependent reaction time and\nerror rates may longer term provide a foundation for modifying smartphone\ncontent and interaction to the users perceived level of attention.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 09:04:50 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2016 11:24:06 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["B\u00e6kgaard", "Per", ""], ["Petersen", "Michael Kai", ""], ["Larsen", "Jakob Eg", ""]]}, {"id": "1512.05619", "submitter": "Francesco Alderisio", "authors": "Chao Zhai, Francesco Alderisio, Piotr Slowinski, Krasimira\n  Tsaneva-Atanasova, Mario di Bernardo", "title": "Modeling Joint Improvisation between Human and Virtual Players in the\n  Mirror Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Joint improvisation is observed to emerge spontaneously among humans\nperforming joint action tasks, and has been associated with high levels of\nmovement synchrony and enhanced sense of social bonding. Exploring the\nunderlying cognitive and neural mechanisms behind the emergence of joint\nimprovisation is an open research challenge. This paper investigates the\nemergence of jointly improvised movements between two participants in the\nmirror game, a paradigmatic joint task example. A theoretical model based on\nobservations and analysis of experimental data is proposed to capture the main\nfeatures of their interaction. A set of experiments is carried out to test and\nvalidate the model ability to reproduce the experimental observations. Then,\nthe model is used to drive a computer avatar able to improvise joint motion\nwith a human participant in real time. Finally, a convergence analysis of the\nproposed model is carried out to confirm its ability to reproduce the emergence\nof joint movement between the participants.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2015 15:02:36 GMT"}], "update_date": "2015-12-18", "authors_parsed": [["Zhai", "Chao", ""], ["Alderisio", "Francesco", ""], ["Slowinski", "Piotr", ""], ["Tsaneva-Atanasova", "Krasimira", ""], ["di Bernardo", "Mario", ""]]}, {"id": "1512.05875", "submitter": "Alessandro Fontana", "authors": "Alessandro Fontana", "title": "Quadripolar Relational Model: a framework for the description of\n  borderline and narcissistic personality disorders", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Borderline personality disorder and narcissistic personality disorder are\nimportant nosographic entities and have been subject of intensive\ninvestigations. The currently prevailing psychodynamic theory for mental\ndisorders is based on the repertoire of defense mechanisms employed. Another\nline of research is concerned with the study of psychological traumas and\ndissociation as a defensive response. Both theories can be used to shed light\non some aspects of pathological mental functioning, and have many points of\ncontact. This work merges these two psychological theories, and builds a model\nof mental function in a relational context called Quadripolar Relational Model.\nThe model, which is enriched with ideas borrowed from the field of computer\nscience, leads to a new therapeutic proposal for psychological traumas and\npersonality disorders.\n", "versions": [{"version": "v1", "created": "Fri, 18 Dec 2015 09:08:49 GMT"}, {"version": "v2", "created": "Wed, 6 Jan 2016 10:54:11 GMT"}, {"version": "v3", "created": "Wed, 10 Aug 2016 09:01:18 GMT"}, {"version": "v4", "created": "Tue, 25 Oct 2016 07:07:23 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Fontana", "Alessandro", ""]]}, {"id": "1512.06248", "submitter": "Julija Krupic", "authors": "Julija Krupic, Neil Burgess and John O'Keefe", "title": "Spatially Periodic Cells Are Neither Formed From Grids Nor Poor\n  Isolation", "comments": "20 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid cells recorded in the parahippocampal formation of freely moving rodents\nprovide a strikingly periodic representation of self-location whose underlying\nmechanism has been the subject of intense interest. Our previous work(1) showed\nthat grid cells represent the most stable subset of a larger continuum of\nspatially periodic cells (SPCs) which deviate from the hexagonal symmetry\nobserved in grid cells. Recently Navratilova et al(2) suggested that our\nfindings reflected poor isolation of the spikes from multiple grid cells,\nrather than the existence of actual non-grid SPCs. Here we refute this\nsuggestion by showing that: (i) most SPCs cannot be formed from hexagonal\ngrids; (ii) all standard cluster isolation measures are similar between\nrecorded grid cells and non-grid SPCs, and are comparable to those reported in\nother laboratories; (iii) the spikes from different fields of band-like SPCs do\nnot differ. Thus the theoretical implications of the presence of cells with\nspatially periodic firing patterns that diverge from perfect hexagonality need\nto be taken seriously, rather than explained away on the basis of hopeful but\nunjustified assumptions.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2015 13:26:20 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Krupic", "Julija", ""], ["Burgess", "Neil", ""], ["O'Keefe", "John", ""]]}, {"id": "1512.06557", "submitter": "Gunther Schauberger", "authors": "C. Wu, J. Liu, P. Zhao, M. Piringer, G. Schauberger", "title": "Conversion of the chemical concentration of odorous mixtures into odour\n  concentration and odour intensity: a comparison of methods", "comments": "accepted for publication on Dec. 20, 2015, Atmospheric Environment\n  (2016)", "journal-ref": null, "doi": "10.1016/j.atmosenv.2015.12.051", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous odour measurements both of emissions as well as ambient\nconcentrations are seldom realised, mainly because of their high costs. They\nare therefore often substituted by concentration measurements of odorous\nsubstances. Then a conversion of the chemical concentrations C (mg m-3) into\nodour concentrations COD (ouE m-3) and odour intensities OI is necessary. Four\nmethods to convert the concentrations of single substances to the odour\nconcentrations and odour intensities of an odorous mixture are investigated:\n(1) direct use of measured concentrations, (2) the sum of the odour activity\nvalue SOAV, (3) the sum of the odour intensities SOI, and (4) the equivalent\nodour concentration EOC, as a new method. The methods are evaluated with\nolfactometric measurements of seven substances as well as their mixtures. The\nresults indicate that the SOI and EOC conversion methods deliver reliable\nvalues. These methods use not only the odour threshold concentration but also\nthe slope of the Weber-Fechner law to include the sensitivity of the odour\nperception of the individual substances. They fulfil the criteria of an\nobjective conversion without the need of a further calibration by additional\nolfactometric measurements.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 10:00:39 GMT"}], "update_date": "2015-12-28", "authors_parsed": [["Wu", "C.", ""], ["Liu", "J.", ""], ["Zhao", "P.", ""], ["Piringer", "M.", ""], ["Schauberger", "G.", ""]]}, {"id": "1512.06830", "submitter": "Daniel Takahashi", "authors": "Andr\\'e Fujita, Daniel Yasumasa Takahashi, Joana Bisol Balardin and\n  Jo\\~ao Ricardo Sato", "title": "Correlation between graphs with an application to brain networks\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global functional brain network (graph) is more suitable for\ncharacterizing brain states than local analysis of the connectivity of brain\nregions. Therefore, graph-theoretic approaches are the natural methods to study\nthe brain. However, conventional graph theoretical analyses are limited due to\nthe lack of formal statistical methods for estimation and inference for random\ngraphs. For example, the concept of correlation between two vectors of graphs\nis yet not defined. The aim of this article to introduce a notion of\ncorrelation between graphs. In order to develop a framework to infer\ncorrelation between graphs, we assume that they are generated by mathematical\nmodels and that the parameters of the models are our random variables. Then, we\ndefine that two vectors of graphs are independent whether their parameters are\nindependent. The problem is that, in real world, the model is rarely known, and\nconsequently, the parameters cannot be estimated. By analyzing the graph\nspectrum, we showed that the spectral radius is highly associated with the\nparameters of the graph model. Based on it, we constructed a framework for\ncorrelation inference between graphs and illustrate our approach in a\nfunctional magnetic resonance imaging data composed of 814 subjects comprising\n529 controls and 285 individuals diagnosed with autism spectrum disorder (ASD).\nResults show that correlations between default-mode and control, default-mode\nand somatomotor, and default-mode and visual sub-networks are higher ($p<0.05$)\nin ASD than in controls.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2015 20:54:52 GMT"}], "update_date": "2015-12-22", "authors_parsed": [["Fujita", "Andr\u00e9", ""], ["Takahashi", "Daniel Yasumasa", ""], ["Balardin", "Joana Bisol", ""], ["Sato", "Jo\u00e3o Ricardo", ""]]}, {"id": "1512.06999", "submitter": "Gael Varoquaux", "authors": "Ga\\\"el Varoquaux (PARIETAL), Michael Eickenberg (PARIETAL), Elvis\n  Dohmatob (PARIETAL), Bertand Thirion (PARIETAL)", "title": "FAASTA: A fast solver for total-variation regularization of\n  ill-conditioned problems with application to brain imaging", "comments": null, "journal-ref": "Colloque GRETSI, Sep 2015, Lyon, France. Gretsi, 2015,\n  http://www.gretsi.fr/colloque2015/myGretsi/programme.php", "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The total variation (TV) penalty, as many other analysis-sparsity problems,\ndoes not lead to separable factors or a proximal operatorwith a closed-form\nexpression, such as soft thresholding for the $\\ell\\_1$ penalty. As a result,\nin a variational formulation of an inverse problem or statisticallearning\nestimation, it leads to challenging non-smooth optimization problemsthat are\noften solved with elaborate single-step first-order methods. When thedata-fit\nterm arises from empirical measurements, as in brain imaging, it isoften very\nill-conditioned and without simple structure. In this situation, in proximal\nsplitting methods, the computation cost of thegradient step can easily dominate\neach iteration. Thus it is beneficialto minimize the number of gradient\nsteps.We present fAASTA, a variant of FISTA, that relies on an internal solver\nforthe TV proximal operator, and refines its tolerance to balance\ncomputationalcost of the gradient and the proximal steps. We give benchmarks\nandillustrations on \"brain decoding\": recovering brain maps from\nnoisymeasurements to predict observed behavior. The algorithm as well as\ntheempirical study of convergence speed are valuable for any non-exact\nproximaloperator, in particular analysis-sparsity problems.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2015 09:35:55 GMT"}], "update_date": "2015-12-23", "authors_parsed": [["Varoquaux", "Ga\u00ebl", "", "PARIETAL"], ["Eickenberg", "Michael", "", "PARIETAL"], ["Dohmatob", "Elvis", "", "PARIETAL"], ["Thirion", "Bertand", "", "PARIETAL"]]}, {"id": "1512.07404", "submitter": "Demian Wassermann", "authors": "Demian Wassermann (ATHENA, HMS, PNL), Makris Nikos (CMA, HMS), Yogesh\n  Rathi (PNL, HMS), Shenton Martha (HMS, PNL), Ron Kikinis (HMS), Marek Kubicki\n  (HMS, PNL), Carl-Fredrik Westin (HMS)", "title": "The White Matter Query Language: A Novel Approach for Describing Human\n  White Matter Anatomy", "comments": "Brain Structure and Function, Springer Verlag, 2016", "journal-ref": null, "doi": "10.1007/s00429-015-1179-4", "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed a novel method to describe human white matter anatomy using\nan approach that is both intuitive and simple to use, and which automatically\nextracts white matter tracts from diffusion MRI volumes. Further, our method\nsimplifies the quantification and statistical analysis of white matter tracts\non large diffusion MRI databases. This work reflects the careful syntactical\ndefinition of major white matter fiber tracts in the human brain based on a\nneuroanatomist's expert knowledge. The framework is based on a novel query\nlanguage with a near-to-English textual syntax. This query language makes it\npossible to construct a dictionary of anatomical definitions that describe\nwhite matter tracts. The definitions include adjacent gray and white matter\nregions, and rules for spatial relations. This novel method makes it possible\nto automatically label white matter anatomy across subjects. After describing\nthis method, we provide an example of its implementation where we encode\nanatomical knowledge in human white matter for 10 association and 15 projection\ntracts per hemisphere, along with 7 commissural tracts. Importantly, this novel\nmethod is comparable in accuracy to manual labeling. Finally, we present\nresults applying this method to create a white matter atlas from 77 healthy\nsubjects, and we use this atlas in a small proof-of-concept study to detect\nchanges in association tracts that characterize schizophrenia.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 09:25:13 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Wassermann", "Demian", "", "ATHENA, HMS, PNL"], ["Nikos", "Makris", "", "CMA, HMS"], ["Rathi", "Yogesh", "", "PNL, HMS"], ["Martha", "Shenton", "", "HMS, PNL"], ["Kikinis", "Ron", "", "HMS"], ["Kubicki", "Marek", "", "HMS, PNL"], ["Westin", "Carl-Fredrik", "", "HMS"]]}, {"id": "1512.07563", "submitter": "Didier Fass", "authors": "Didier Fass (MOSEL)", "title": "Affordances and Safe Design of Assistance Wearable Virtual Environment\n  of Gesture", "comments": null, "journal-ref": "Tared Ahram, Waldemar Karwowski, Dylan Schmorrow. Human Factors\n  and Egonomics (AHFE 2015), Jul 2015, Las Vegas, United States. Elsivier,\n  Procedia Manufacturing, pp.8, 2015, 6th International Conference on Applied\n  Human Factors and Ergonomics (AHFE 2015) and the Affiliated Conferences, AHFE\n  2015", "doi": "10.1016/j.promfg.2015.07.343", "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Safety and reliability are the main issues for designing assistance wearable\nvirtual environment of technical gesture in aerospace, or health application\ndomains. That needs the integration in the same isomorphic engineering\nframework of human requirements, systems requirements and the rationale of\ntheir relation to the natural and artifactual environment.To explore coupling\nintegration and design functional organization of support technical gesture\nsystems, firstly ecological psychologyprovides usa heuristicconcept: the\naffordance. On the other hand mathematical theory of integrative physiology\nprovides us scientific concepts: the stabilizing auto-association principle and\nfunctional interaction.After demonstrating the epistemological consistence of\nthese concepts, we define an isomorphic framework to describe and model human\nsystems integration dedicated to human in-the-loop system engineering.We\npresent an experimental approach of safe design of assistance wearable virtual\nenvironment of gesture based in laboratory and parabolic flights. On the\nresults, we discuss the relevance of our conceptual approach and the\napplications to future assistance of gesture wearable systems engineering.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 17:57:23 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Fass", "Didier", "", "MOSEL"]]}, {"id": "1512.07596", "submitter": "Danielle Bassett", "authors": "Zitong Zhang, Qawi K. Telesford, Chad Giusti, Kelvin O. Lim, Danielle\n  S. Bassett", "title": "Choosing Wavelet Methods, Filters, and Lengths for Functional Brain\n  Network Construction", "comments": "working paper", "journal-ref": null, "doi": "10.1371/journal.pone.0157243", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wavelet methods are widely used to decompose fMRI, EEG, or MEG signals into\ntime series representing neurophysiological activity in fixed frequency bands.\nUsing these time series, one can estimate frequency-band specific functional\nconnectivity between sensors or regions of interest, and thereby construct\nfunctional brain networks that can be examined from a graph theoretic\nperspective. Despite their common use, however, practical guidelines for the\nchoice of wavelet method, filter, and length have remained largely\nundelineated. Here, we explicitly explore the effects of wavelet method (MODWT\nvs. DWT), wavelet filter (Daubechies Extremal Phase, Daubechies Least\nAsymmetric, and Coiflet families), and wavelet length (2 to 24) - each\nessential parameters in wavelet-based methods - on the estimated values of\nnetwork diagnostics and in their sensitivity to alterations in psychiatric\ndisease. We observe that the MODWT method produces less variable estimates than\nthe DWT method. We also observe that the length of the wavelet filter chosen\nhas a greater impact on the estimated values of network diagnostics than the\ntype of wavelet chosen. Furthermore, wavelet length impacts the sensitivity of\nthe method to detect differences between health and disease and tunes\nclassification accuracy. Collectively, our results suggest that the choice of\nwavelet method and length significantly alters the reliability and sensitivity\nof these methods in estimating values of network diagnostics drawn from graph\ntheory. They furthermore demonstrate the importance of reporting the choices\nutilized in neuroimaging studies and support the utility of exploring wavelet\nparameters to maximize classification accuracy in the development of biomarkers\nof psychiatric disease and neurological disorders.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2015 19:25:08 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Zhang", "Zitong", ""], ["Telesford", "Qawi K.", ""], ["Giusti", "Chad", ""], ["Lim", "Kelvin O.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1512.07855", "submitter": "Hideaki Shimazaki", "authors": "Hideaki Shimazaki", "title": "Neurons as an Information-theoretic Engine", "comments": "16 pages, 4 figures; corrected four typos in the original submission", "journal-ref": "An extended edition is published as a book chapter. Shimazaki H.\n  (2018) Neural Engine Hypothesis. In Chen Z. and Sarma S.V. (Eds.), Dynamic\n  Neuroscience. Springer", "doi": "10.1007/978-3-319-71976-4", "report-no": null, "categories": "q-bio.NC physics.bio-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that dynamical gain modulation of neurons' stimulus response is\ndescribed as an information-theoretic cycle that generates entropy associated\nwith the stimulus-related activity from entropy produced by the modulation. To\narticulate this theory, we describe stimulus-evoked activity of a neural\npopulation based on the maximum entropy principle with constraints on two types\nof overlapping activities, one that is controlled by stimulus conditions and\nthe other, termed internal activity, that is regulated internally in an\norganism. We demonstrate that modulation of the internal activity realises gain\ncontrol of stimulus response, and controls stimulus information. A cycle of\nneural dynamics is then introduced to model information processing by the\nneurons during which the stimulus information is dynamically enhanced by the\ninternal gain-modulation mechanism. Based on the conservation law for entropy\nproduction, we demonstrate that the cycle generates entropy ascribed to the\nstimulus-related activity using entropy supplied by the internal mechanism,\nanalogously to a heat engine that produces work from heat. We provide an\nefficient cycle that achieves the highest entropic efficiency to retain the\nstimulus information. The theory allows us to quantify efficiency of the\ninternal computation and its theoretical limit.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2015 16:40:01 GMT"}, {"version": "v2", "created": "Wed, 27 Dec 2017 12:47:30 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Shimazaki", "Hideaki", ""]]}, {"id": "1512.08309", "submitter": "Rakesh Malladi", "authors": "Rakesh Malladi, Giridhar Kalamangalam, Nitin Tandon and Behnaam\n  Aazhang", "title": "Identifying Seizure Onset Zone from the Causal Connectivity Inferred\n  Using Directed Information", "comments": "This paper is accepted for publication in IEEE Journal of Selected\n  Topics in Signal Processing, special issue on Advanced Signal Processing in\n  Brain Networks, October 2016. 16 pages, 11 figures and 2 tables", "journal-ref": null, "doi": "10.1109/JSTSP.2016.2601485", "report-no": null, "categories": "q-bio.NC cs.IT math.IT stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we developed a model-based and a data-driven estimator for\ndirected information (DI) to infer the causal connectivity graph between\nelectrocorticographic (ECoG) signals recorded from brain and to identify the\nseizure onset zone (SOZ) in epileptic patients. Directed information, an\ninformation theoretic quantity, is a general metric to infer causal\nconnectivity between time-series and is not restricted to a particular class of\nmodels unlike the popular metrics based on Granger causality or transfer\nentropy. The proposed estimators are shown to be almost surely convergent.\nCausal connectivity between ECoG electrodes in five epileptic patients is\ninferred using the proposed DI estimators, after validating their performance\non simulated data. We then proposed a model-based and a data-driven SOZ\nidentification algorithm to identify SOZ from the causal connectivity inferred\nusing model-based and data-driven DI estimators respectively. The data-driven\nSOZ identification outperforms the model-based SOZ identification algorithm\nwhen benchmarked against visual analysis by neurologist, the current clinical\ngold standard. The causal connectivity analysis presented here is the first\nstep towards developing novel non-surgical treatments for epilepsy.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 02:53:24 GMT"}, {"version": "v2", "created": "Tue, 16 Aug 2016 19:21:32 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Malladi", "Rakesh", ""], ["Kalamangalam", "Giridhar", ""], ["Tandon", "Nitin", ""], ["Aazhang", "Behnaam", ""]]}, {"id": "1512.08339", "submitter": "Dongmei Shi", "authors": "Dongmei Shi, Chitin Shih, Yenjen Lin, Chungchuan Lo, and Annshyn\n  Chiang", "title": "Detecting local processing unit in drosophila brain by using network\n  theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection method in network theory was applied to the neuron\nnetwork constructed from the image overlapping between neuron pairs to detect\nthe Local Processing Unit (LPU) automatically in Drosophila brain. 26\ncommunities consistent with the known LPUs, and 13 subdivisions were found.\nBesides, 45 tracts were detected and could be discriminated from the LPUs by\nanalyzing the distribution of participation coefficient P. Furthermore, layer\nstructures in fan-shaped body (FB) were observed which coincided with the\nimages shot by the optical devices, and a total of 13 communities were proven\nclosely related to FB. The method proposed in this work was proven effective to\nidentify the LPU structure in Drosophila brain irrespectively of any subjective\naspect, and could be applied to the relevant areas extensively.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 08:00:27 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Shi", "Dongmei", ""], ["Shih", "Chitin", ""], ["Lin", "Yenjen", ""], ["Lo", "Chungchuan", ""], ["Chiang", "Annshyn", ""]]}, {"id": "1512.08457", "submitter": "Joel Leibo", "authors": "Joel Z. Leibo, Julien Cornebise, Sergio G\\'omez, Demis Hassabis", "title": "Approximate Hubel-Wiesel Modules and the Data Structures of Neural\n  Computation", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a framework for modeling the interface between\nperception and memory on the algorithmic level of analysis. It is consistent\nwith phenomena associated with many different brain regions. These include\nview-dependence (and invariance) effects in visual psychophysics and\ninferotemporal cortex physiology, as well as episodic memory recall\ninterference effects associated with the medial temporal lobe. The perspective\ndeveloped here relies on a novel interpretation of Hubel and Wiesel's\nconjecture for how receptive fields tuned to complex objects, and invariant to\ndetails, could be achieved. It complements existing accounts of two-speed\nlearning systems in neocortex and hippocampus (e.g., McClelland et al. 1995)\nwhile significantly expanding their scope to encompass a unified view of the\nentire pathway from V1 to hippocampus.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 16:53:35 GMT"}], "update_date": "2015-12-29", "authors_parsed": [["Leibo", "Joel Z.", ""], ["Cornebise", "Julien", ""], ["G\u00f3mez", "Sergio", ""], ["Hassabis", "Demis", ""]]}, {"id": "1512.08538", "submitter": "Chris Antonopoulos Dr", "authors": "Chris G. Antonopoulos", "title": "Dynamic Range in the C.elegans Brain Network", "comments": "9 pages, 6 figures, accepted for publication in Chaos: An\n  Interdisciplinary Journal of Nonlinear Science", "journal-ref": null, "doi": "10.1063/1.4939837", "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study external, electrical perturbations and their responses in the brain\ndynamic network of the \\textit{Caenorhabditis elegans} soil worm, given by the\nconnectome of its large somatic nervous system. Our analysis is inspired by a\nrealistic experiment where one stimulates externally specific parts of the\nbrain and studies the persistent neural activity triggered in other cortical\nregions. In this work, we perturb groups of neurons that form communities,\nidentified by the walktrap community detection method, by trains of\nstereotypical electrical Poissonian impulses and study the propagation of\nneural activity to other communities by measuring the corresponding dynamic\nranges and Steven law exponents. We show that when one perturbs specific\ncommunities, keeping the rest unperturbed, the external stimulations are able\nto propagate to some of them but not to all. There are also perturbations that\ndo not trigger any response. We found that this depends on the initially\nperturbed community. Finally, we relate our findings for the former cases with\nlow neural synchronization, self-criticality and large information flow\ncapacity, and interpret them as the ability of the brain network to respond to\nexternal perturbations when it works at criticality and its information flow\ncapacity becomes maximal.\n", "versions": [{"version": "v1", "created": "Mon, 28 Dec 2015 21:50:24 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Antonopoulos", "Chris G.", ""]]}, {"id": "1512.09133", "submitter": "Tomas Ros", "authors": "Tomas Ros, Paul Frewen, Jean Theberge, Rosemarie Kluetsch, Andreas\n  Mueller, Gian Candrian, Rakesh Jetly, Patrik Vuilleumier, Ruth Lanius", "title": "Neurofeedback Tunes Scale-Free Dynamics in Spontaneous Brain Activity", "comments": null, "journal-ref": "Cerebral Cortex (2016)", "doi": "10.1093/cercor/bhw285", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain oscillations exhibit long-range temporal correlations (LRTCs), which\nreflect the regularity of their fluctuations: low values representing more\nrandom (decorrelated) while high values more persistent (correlated) dynamics.\nLRTCs constitute supporting evidence that the brain operates near criticality,\na state where neuronal activities are balanced between order and randomness.\nHere, healthy adults used closed-loop brain training (neurofeedback, NFB) to\nreduce the amplitude of alpha oscillations, producing a significant increase in\nspontaneous LRTCs post-training. This effect was reproduced in patients with\npost-traumatic stress disorder, where abnormally random dynamics were reversed\nby NFB, correlating with significant improvements in hyperarousal. Notably,\nregions manifesting abnormally low LRTCs (i.e., excessive randomness)\nnormalized toward healthy population levels, consistent with theoretical\npredictions about self-organized criticality. Hence, when exposed to\nappropriate training, spontaneous cortical activity reveals a residual capacity\nfor \"self-tuning\" its own temporal complexity, despite manifesting the abnormal\ndynamics seen in individuals with psychiatric disorder. Lastly, we observed an\ninverse-U relationship between strength of LRTC and oscillation amplitude,\nsuggesting a breakdown of long-range dependence at high/low synchronization\nextremes, in line with recent computational models. Together, our findings\noffer a broader mechanistic framework for motivating research and clinical\napplications of NFB, encompassing disorders with perturbed LRTCs.\n", "versions": [{"version": "v1", "created": "Wed, 30 Dec 2015 20:58:03 GMT"}, {"version": "v2", "created": "Thu, 17 Mar 2016 09:16:18 GMT"}, {"version": "v3", "created": "Fri, 2 Feb 2018 10:18:50 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Ros", "Tomas", ""], ["Frewen", "Paul", ""], ["Theberge", "Jean", ""], ["Kluetsch", "Rosemarie", ""], ["Mueller", "Andreas", ""], ["Candrian", "Gian", ""], ["Jetly", "Rakesh", ""], ["Vuilleumier", "Patrik", ""], ["Lanius", "Ruth", ""]]}]