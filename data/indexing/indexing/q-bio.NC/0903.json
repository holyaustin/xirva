[{"id": "0903.0127", "submitter": "Alain Destexhe", "authors": "Olivier Marre, Sami El Boustani, Yves Fregnac and Alain Destexhe", "title": "Prediction of spatio-temporal patterns of neural activity from pairwise\n  correlations", "comments": "Physical Preview Letters (in press, 2009)", "journal-ref": "Physical Review Letters 102: 138101, 2009.", "doi": "10.1103/PhysRevLett.102.138101", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We designed a model-based analysis to predict the occurrence of population\npatterns in distributed spiking activity. Using a maximum entropy principle\nwith a Markovian assumption, we obtain a model that accounts for both spatial\nand temporal pairwise correlations among neurons. This model is tested on data\ngenerated with a Glauber spin-glass system and is shown to correctly predict\nthe occurrence probabilities of spatio-temporal patterns significantly better\nthan Ising models taking into account only pairwise correlations. This increase\nof predictability was also observed on experimental data recorded in parietal\ncortex during slow-wave sleep. This approach can also be used to generate\nsurrogates that reproduce the spatial and temporal correlations of a given data\nset.\n", "versions": [{"version": "v1", "created": "Sun, 1 Mar 2009 07:59:09 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Marre", "Olivier", ""], ["Boustani", "Sami El", ""], ["Fregnac", "Yves", ""], ["Destexhe", "Alain", ""]]}, {"id": "0903.0800", "submitter": "Markus Dahlem", "authors": "Markus A. Dahlem, Rudolf Graf, Anthony J. Strong, Jens P. Dreier,\n  Yuliya A. Dahlem, Michaela Sieber, Wolfgang Hanke, Klaus Podoll, Eckehard\n  Schoell", "title": "Two-dimensional wave patterns of spreading depolarization: retracting,\n  re-entrant, and stationary waves", "comments": null, "journal-ref": null, "doi": "10.1016/j.physd.2009.08.009", "report-no": null, "categories": "nlin.PS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present spatio-temporal characteristics of spreading depolarizations (SD)\nin two experimental systems: retracting SD wave segments observed with\nintrinsic optical signals in chicken retina, and spontaneously occurring\nre-entrant SD waves that repeatedly spread across gyrencephalic feline cortex\nobserved by laser speckle flowmetry. A mathematical framework of\nreaction-diffusion systems with augmented transmission capabilities is\ndeveloped to explain the emergence and transitions between these patterns. Our\nprediction is that the observed patterns are reaction-diffusion patterns\ncontrolled and modulated by weak nonlocal coupling. The described\nspatio-temporal characteristics of SD are of important clinical relevance under\nconditions of migraine and stroke. In stroke, the emergence of re-entrant SD\nwaves is believed to worsen outcome. In migraine, retracting SD wave segments\ncause neurological symptoms and transitions to stationary SD wave patterns may\ncause persistent symptoms without evidence from noninvasive imaging of\ninfarction.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2009 16:23:33 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Dahlem", "Markus A.", ""], ["Graf", "Rudolf", ""], ["Strong", "Anthony J.", ""], ["Dreier", "Jens P.", ""], ["Dahlem", "Yuliya A.", ""], ["Sieber", "Michaela", ""], ["Hanke", "Wolfgang", ""], ["Podoll", "Klaus", ""], ["Schoell", "Eckehard", ""]]}, {"id": "0903.0859", "submitter": "Chih-Yuan Tseng", "authors": "Hung-I Pai, Chih-Yuan Tseng and H.C. Lee", "title": "Data Processing Approach for Localizing Bio-magnetic Sources in the\n  Brain", "comments": "11 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetoencephalography (MEG) provides dynamic spatial-temporal insight of\nneural activities in the cortex. Because the number of possible sources is far\ngreater than the number of MEG detectors, the proposition to localize sources\ndirectly from MEG data is notoriously ill-posed. Here we develop an approach\nbased on data processing procedures including clustering, forward and backward\nfiltering, and the method of maximum entropy. We show that taking as a starting\npoint the assumption that the sources lie in the general area of the auditory\ncortex (an area of about 40 mm by 15 mm), our approach is capable of achieving\nreasonable success in pinpointing active sources concentrated in an area of a\nfew mm's across, while limiting the spatial distribution and number of false\npositives.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2009 21:10:15 GMT"}], "update_date": "2009-03-06", "authors_parsed": [["Pai", "Hung-I", ""], ["Tseng", "Chih-Yuan", ""], ["Lee", "H. C.", ""]]}, {"id": "0903.1012", "submitter": "Nail Khusnutdinov Mr", "authors": "F. Gafarov, N. Khusnutdinov, and F. Galimyanov", "title": "The simulation of the activity dependent neural network growth", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": "10.1142/S0219635209002058", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is currently accepted that cortical maps are dynamic constructions that\nare altered in response to external input. Experience-dependent structural\nchanges in cortical microcurcuts lead to changes of activity, i.e. to changes\nin information encoded. Specific patterns of external stimulation can lead to\ncreation of new synaptic connections between neurons. The calcium influxes\ncontrolled by neuronal activity regulate the processes of neurotrophic factors\nreleased by neurons, growth cones movement and synapse differentiation in\ndeveloping neural systems. We propose a model for description and investigation\nof the activity dependent development of neural networks. The dynamics of the\nnetwork parameters (activity, diffusion of axon guidance chemicals, growth cone\nposition) is described by a closed set of differential equations. The model\npresented here describes the development of neural networks under the\nassumption of activity dependent axon guidance molecules. Numerical simulation\nshows that morpholess neurons compromise the development of cortical\nconnectivity.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2009 14:48:10 GMT"}], "update_date": "2013-02-26", "authors_parsed": [["Gafarov", "F.", ""], ["Khusnutdinov", "N.", ""], ["Galimyanov", "F.", ""]]}, {"id": "0903.1025", "submitter": "Aushra Abouzeid", "authors": "Aushra Abouzeid and Bard Ermentrout", "title": "The type II phase resetting curve is optimal for stochastic synchrony", "comments": "10 pages, 4 figures, submitted to Physical Review E", "journal-ref": null, "doi": "10.1103/PhysRevE.80.011911", "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The phase-resetting curve (PRC) describes the response of a neural oscillator\nto small perturbations in membrane potential. Its usefulness for predicting the\ndynamics of weakly coupled deterministic networks has been well characterized.\nHowever, the inputs to real neurons may often be more accurately described as\nbarrages of synaptic noise. Effective connectivity between cells may thus arise\nin the form of correlations between the noisy input streams. We use constrained\noptimization and perturbation methods to prove that PRC shape determines\nsusceptibility to synchrony among otherwise uncoupled noise-driven neural\noscillators. PRCs can be placed into two general categories: Type I PRCs are\nnon-negative while Type II PRCs have a large negative region. Here we show that\noscillators with Type II PRCs receiving common noisy input sychronize more\nreadily than those with Type I PRCs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2009 16:19:14 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Abouzeid", "Aushra", ""], ["Ermentrout", "Bard", ""]]}, {"id": "0903.1850", "submitter": "Burzin Bhavnagri", "authors": "Burzin Bhavnagri", "title": "Free actions and Grassmanian variety", "comments": "fixed matrices lost in latex and numbered equations", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AG cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An algebraic notion of representational consistency is defined. A theorem\nrelating it to free actions is proved. A metrizability problem of the quotient\n(a shape space) is discussed. This leads to a new algebraic variety with a\nmetrizability result. A concrete example is given from stereo vision.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2009 06:52:53 GMT"}], "update_date": "2009-03-18", "authors_parsed": [["Bhavnagri", "Burzin", ""]]}, {"id": "0903.1856", "submitter": "Lester Ingber", "authors": "Lester Ingber", "title": "Quantum calcium-ion interactions with EEG", "comments": "published in Sci", "journal-ref": "Sci 1 (7), 1-21 (2018)", "doi": "10.3390/sci1010020", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous papers have developed a statistical mechanics of neocortical\ninteractions (SMNI) fit to short-term memory and EEG data. Adaptive Simulated\nAnnealing (ASA) has been developed to perform fits to such nonlinear stochastic\nsystems. An N-dimensional path-integral algorithm for quantum systems,\nqPATHINT, has been developed from classical PATHINT. Both fold short-time\npropagators (distributions or wave functions) over long times. Previous papers\napplied qPATHINT to two systems, in neocortical interactions and financial\noptions. \\textbf{Objective}: In this paper the quantum path-integral for\nCalcium ions is used to derive a closed-form analytic solution at arbitrary\ntime that is used to calculate interactions with classical-physics SMNI\ninteractions among scales. Using fits of this SMNI model to EEG data, including\nthese effects, will help determine if this is a reasonable approach.\n\\textbf{Method}: Methods of mathematical-physics for optimization and for path\nintegrals in classical and quantum spaces are used for this project. Studies\nusing supercomputer resources tested various dimensions for their scaling\nlimits. In this paper the quantum path-integral is used to derive a closed-form\nanalytic solution at arbitrary time that is used to calculate interactions with\nclassical-physics SMNI interactions among scales. \\textbf{Results}: The\nmathematical-physics and computer parts of the study are successful, in that\nthere is modest improvement of cost/objective functions used to fit EEG data\nusing these models. \\textbf{Conclusion}: This project points to directions for\nmore detailed calculations using more EEG data and qPATHINT at each time slice\nto propagate quantum calcium waves, synchronized with PATHINT propagation of\nclassical SMNI.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2009 13:44:05 GMT"}, {"version": "v2", "created": "Sun, 18 Oct 2009 23:39:15 GMT"}, {"version": "v3", "created": "Sat, 23 Nov 2019 21:30:43 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Ingber", "Lester", ""]]}, {"id": "0903.1867", "submitter": "Alessandro Torcini", "authors": "Massimo Calamai, Antonio Politi, Alessandro Torcini", "title": "Stability of splay states in globally coupled rotators", "comments": "7.7 pages - 16 Figures - Submitted to Physical Review E", "journal-ref": "Phys. Rev. E 80, 036209 (2009)", "doi": "10.1103/PhysRevE.80.036209", "report-no": null, "categories": "cond-mat.dis-nn nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The stability of dynamical states characterized by a uniform firing rate\n({\\it splay states}) is analyzed in a network of $N$ globally pulse-coupled\nrotators (neurons) subject to a generic velocity field. In particular, we\nanalyse short-wavelength modes that were known to be marginally stable in the\ninfinite $N$ limit and show that the corresponding Floquet exponent scale as\n$1/N^2$. Moreover, we find that the sign, and thereby the stability, of this\nspectral component is determined by the sign of the average derivative of the\nvelocity field. For leaky-integrate-and-fire neurons, an analytic expression\nfor the whole spectrum is obtained. In the intermediate case of continuous\nvelocity fields, the Floquet exponents scale faster than $1/N^2$ (namely, as\n$1/N^4$) and we even find strictly neutral directions in a wider class than the\nsinusoidal velocity fields considered by Watanabe and Strogatz in {\\it Physica\nD 74 (1994) 197-253}.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2009 21:36:47 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2009 12:57:05 GMT"}], "update_date": "2009-09-24", "authors_parsed": [["Calamai", "Massimo", ""], ["Politi", "Antonio", ""], ["Torcini", "Alessandro", ""]]}, {"id": "0903.1915", "submitter": "Tatsuya Uezu", "authors": "T. Uezu, K. Abe, S. Miyoshi and M. Okada", "title": "Statistical Mechanical Study on a Neural Network Model with Time\n  Dependent Interactions", "comments": "19 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a neural network model in which both neurons and synaptic\ninteractions evolve in time simultaneously. The time evolution of synaptic\ninteractions is described by a Langevin equation including a Hebbian learning\nterm, and a bias term which is the interactions of the Hopfield model. We\nassume that synaptic interactions change much slower than neurons and study the\nstationary states of synaptic interactions by the replica method. We find that\nthe order of the phase transition changes from the second to the first and that\nthe existence regions of the Hopfield attractor and mixed states increase as\nthe coefficient of the learning term increases. We also study the AT stability\nof solutions and find that the temperature region in which the Hopfield\nattractor is stable increases as the learning coefficient increases.\nTheoretical results are confirmed by the direct numerical integration of the\nLangevin equation. Further, we study the characteristics of the resultant\nsynaptic interactions by partial annealing and find that the stability of the\nattractor which emerges after partial annealing is enhanced and those of the\ncoexistent attractors are reduced.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2009 07:05:12 GMT"}], "update_date": "2009-03-12", "authors_parsed": [["Uezu", "T.", ""], ["Abe", "K.", ""], ["Miyoshi", "S.", ""], ["Okada", "M.", ""]]}, {"id": "0903.1979", "submitter": "Claudius Gros", "authors": "C. Gros, G. Kaczor", "title": "Semantic learning in autonomously active recurrent neural networks", "comments": "Journal of Algorithms in Cognition, Informatics and Logic, special\n  issue on `Perspectives and Challenges for Recurrent Neural Networks', in\n  press", "journal-ref": "Logic Journal of the IGPL, Vol. 18, 686 (2010)", "doi": "10.1093/jigpal/jzp045", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain is autonomously active, being characterized by a\nself-sustained neural activity which would be present even in the absence of\nexternal sensory stimuli. Here we study the interrelation between the\nself-sustained activity in autonomously active recurrent neural nets and\nexternal sensory stimuli.\n  There is no a priori semantical relation between the influx of external\nstimuli and the patterns generated internally by the autonomous and ongoing\nbrain dynamics. The question then arises when and how are semantic correlations\nbetween internal and external dynamical processes learned and built up?\n  We study this problem within the paradigm of transient state dynamics for the\nneural activity in recurrent neural nets, i.e. for an autonomous neural\nactivity characterized by an infinite time-series of transiently stable\nattractor states. We propose that external stimuli will be relevant during the\nsensitive periods, {\\it viz} the transition period between one transient state\nand the subsequent semi-stable attractor. A diffusive learning signal is\ngenerated unsupervised whenever the stimulus influences the internal dynamics\nqualitatively.\n  For testing we have presented to the model system stimuli corresponding to\nthe bars and stripes problem. We found that the system performs a non-linear\nindependent component analysis on its own, being continuously and autonomously\nactive. This emergent cognitive capability results here from a general\nprinciple for the neural dynamics, the competition between neural ensembles.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2009 14:14:51 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Gros", "C.", ""], ["Kaczor", "G.", ""]]}, {"id": "0903.2210", "submitter": "Mark Kramer", "authors": "Mark A. Kramer, Uri T. Eden, Sydney S. Cash, Eric D. Kolaczyk", "title": "Network inference - with confidence - from multivariate time series", "comments": "12 pages, 7 figures (low resolution), submitted", "journal-ref": null, "doi": "10.1103/PhysRevE.79.061916", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks - collections of interacting elements or nodes - abound in the\nnatural and manmade worlds. For many networks, complex spatiotemporal dynamics\nstem from patterns of physical interactions unknown to us. To infer these\ninteractions, it is common to include edges between those nodes whose time\nseries exhibit sufficient functional connectivity, typically defined as a\nmeasure of coupling exceeding a pre-determined threshold. However, when\nuncertainty exists in the original network measurements, uncertainty in the\ninferred network is likely, and hence a statistical propagation-of-error is\nneeded. In this manuscript, we describe a principled and systematic procedure\nfor the inference of functional connectivity networks from multivariate time\nseries data. Our procedure yields as output both the inferred network and a\nquantification of uncertainty of the most fundamental interest: uncertainty in\nthe number of edges. To illustrate this approach, we apply our procedure to\nsimulated data and electrocorticogram data recorded from a human subject during\nan epileptic seizure. We demonstrate that the procedure is accurate and robust\nin both the determination of edges and the reporting of uncertainty associated\nwith that determination.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2009 16:25:38 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Kramer", "Mark A.", ""], ["Eden", "Uri T.", ""], ["Cash", "Sydney S.", ""], ["Kolaczyk", "Eric D.", ""]]}, {"id": "0903.2569", "submitter": "Matthew Caudill", "authors": "M. S. Caudill, S. F. Brandt, Z. Nussinov, R. Wessel", "title": "Equivalent Dynamics from Disparate Synaptic Weights in a Prevalent\n  Visual Circuit", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural feedback-triads consisting of two feedback loops with a non-reciprocal\nlateral connection from one loop to the other are ubiquitous in the brain. We\nshow analytically that the dynamics of this network topology are determined by\ntwo algebraic combinations of its five synaptic weights. Thus different weight\nsettings can generate equivalent network dynamics. Exploration of network\nactivity over the two-dimensional parameter space demonstrates the importance\nof the non-reciprocal lateral connection and reveals intricate behavior\ninvolving continuous transitions between qualitatively different activity\nstates. In addition, we show that the response to periodic inputs is narrowly\ntuned around a center frequency determined by the two effective synaptic\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2009 18:49:04 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2009 16:34:10 GMT"}], "update_date": "2009-03-17", "authors_parsed": [["Caudill", "M. S.", ""], ["Brandt", "S. F.", ""], ["Nussinov", "Z.", ""], ["Wessel", "R.", ""]]}, {"id": "0903.2641", "submitter": "Constantinos Siettos", "authors": "Konstantinos G. Spiliotis and Constantinos I. Siettos", "title": "Multiscale Computations on Neural Networks: From the Individual Neuron\n  Interactions to the Macroscopic-Level Analysis", "comments": null, "journal-ref": "Int. J. Bifurcation and Chaos 20 (1) 121-134 (2010)", "doi": "10.1142/S0218127410025442", "report-no": null, "categories": "cs.CE cs.NA q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how the Equation-Free approach for multi-scale computations can be\nexploited to systematically study the dynamics of neural interactions on a\nrandom regular connected graph under a pairwise representation perspective.\nUsing an individual-based microscopic simulator as a black box coarse-grained\ntimestepper and with the aid of simulated annealing we compute the\ncoarse-grained equilibrium bifurcation diagram and analyze the stability of the\nstationary states sidestepping the necessity of obtaining explicit closures at\nthe macroscopic level. We also exploit the scheme to perform a rare-events\nanalysis by estimating an effective Fokker-Planck describing the evolving\nprobability density function of the corresponding coarse-grained observables.\n", "versions": [{"version": "v1", "created": "Sun, 15 Mar 2009 16:27:55 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Spiliotis", "Konstantinos G.", ""], ["Siettos", "Constantinos I.", ""]]}, {"id": "0903.2987", "submitter": "Christian Meisel", "authors": "Christian Meisel and Thilo Gross", "title": "Adaptive self-organization in a realistic neural network model", "comments": "6 pages, 4 figures", "journal-ref": "Phys. Rev. E 80, 061917 (2009)", "doi": "10.1103/PhysRevE.80.061917", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information processing in complex systems is often found to be maximally\nefficient close to critical states associated with phase transitions. It is\ntherefore conceivable that also neural information processing operates close to\ncriticality. This is further supported by the observation of power-law\ndistributions, which are a hallmark of phase transitions. An important open\nquestion is how neural networks could remain close to a critical point while\nundergoing a continual change in the course of development, adaptation,\nlearning, and more. An influential contribution was made by Bornholdt and\nRohlf, introducing a generic mechanism of robust self-organized criticality in\nadaptive networks. Here, we address the question whether this mechanism is\nrelevant for real neural networks. We show in a realistic model that\nspike-time-dependent synaptic plasticity can self-organize neural networks\nrobustly toward criticality. Our model reproduces several empirical\nobservations and makes testable predictions on the distribution of synaptic\nstrength, relating them to the critical state of the network. These results\nsuggest that the interplay between dynamics and topology may be essential for\nneural information processing.\n", "versions": [{"version": "v1", "created": "Tue, 17 Mar 2009 15:51:05 GMT"}, {"version": "v2", "created": "Wed, 26 May 2010 08:55:11 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Meisel", "Christian", ""], ["Gross", "Thilo", ""]]}, {"id": "0903.3083", "submitter": "Thomas Kreuz", "authors": "T. Kreuz, D. Chicharro, R.G. Andrzejak, J.S. Haas, H.D.I. Abarbanel", "title": "Measuring multiple spike train synchrony", "comments": "15 pages, 17 figures, 30 references Changes: Abstract corrected, one\n  Figure and one Section in Appendix added, plus some minor corrections (Final\n  Version)", "journal-ref": "J Neurosci Methods 183, 287 (2009)", "doi": "10.1016/j.jneumeth.2009.06.039", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measures of multiple spike train synchrony are essential in order to study\nissues such as spike timing reliability, network synchronization, and neuronal\ncoding. These measures can broadly be divided in multivariate measures and\naverages over bivariate measures. One of the most recent bivariate approaches,\nthe ISI-distance, employs the ratio of instantaneous interspike intervals. In\nthis study we propose two extensions of the ISI-distance, the straightforward\naveraged bivariate ISI-distance and the multivariate ISI-diversity based on the\ncoefficient of variation. Like the original measure these extensions combine\nmany properties desirable in applications to real data. In particular, they are\nparameter free, time scale independent, and easy to visualize in a\ntime-resolved manner, as we illustrate with in vitro recordings from a cortical\nneuron. Using a simulated network of Hindemarsh-Rose neurons as a controlled\nconfiguration we compare the performance of our methods in distinguishing\ndifferent levels of multi-neuron spike train synchrony to the performance of\nsix other previously published measures. We show and explain why the averaged\nbivariate measures perform better than the multivariate ones and why the\nmultivariate ISI-diversity is the best performer among the multivariate\nmethods. Finally, in a comparison against standard methods that rely on moving\nwindow estimates, we use single-unit monkey data to demonstrate the advantages\nof the instantaneous nature of our methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2009 03:59:05 GMT"}, {"version": "v2", "created": "Thu, 2 Jul 2009 17:10:41 GMT"}], "update_date": "2012-12-11", "authors_parsed": [["Kreuz", "T.", ""], ["Chicharro", "D.", ""], ["Andrzejak", "R. G.", ""], ["Haas", "J. S.", ""], ["Abarbanel", "H. D. I.", ""]]}, {"id": "0903.3451", "submitter": "Jun Kitazono", "authors": "Jun Kitazono, Toshiaki Omori, Masato Okada", "title": "Neural network model with discrete and continuous information\n  representation", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": "10.1143/JPSJ.78.114801", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An associative memory model and a neural network model with a Mexican-hat\ntype interaction are the two most typical attractor networks used in the\nartificial neural network models. The associative memory model has discretely\ndistributed fixed-point attractors, and achieves a discrete information\nrepresentation. On the other hand, a neural network model with a Mexican-hat\ntype interaction uses a line attractor to achieves a continuous information\nrepresentation, which can be seen in the working memory in the prefrontal\ncortex and columnar activity in the visual cortex. In the present study, we\npropose a neural network model that achieves discrete and continuous\ninformation representation. We use a statistical-mechanical analysis to find\nthat a localized retrieval phase exists in the proposed model, where the memory\npattern is retrieved in the localized subpopulation of the network. In the\nlocalized retrieval phase, the discrete and continuous information\nrepresentation is achieved by using the orthogonality of the memory patterns\nand the neutral stability of fixed points along the positions of the localized\nretrieval. The obtained phase diagram suggests that the antiferromagnetic\ninteraction and the external field are important for generating the localized\nretrieval phase.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2009 05:17:39 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Kitazono", "Jun", ""], ["Omori", "Toshiaki", ""], ["Okada", "Masato", ""]]}, {"id": "0903.3498", "submitter": "Bruno. Cessac", "authors": "Bruno Cessac, H\\'el\\`ene Paugam-Moisy, Thierry Vi\\'eville", "title": "Indisputable facts when implementing spiking neuron networks", "comments": "29 pages, 11 figures, submitted", "journal-ref": "J. Physiol., Paris, 104, (1-2), 5-18, (2010)", "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, our wish is to demystify some aspects of coding with\nspike-timing, through a simple review of well-understood technical facts\nregarding spike coding. The goal is to help better understanding to which\nextend computing and modelling with spiking neuron networks can be biologically\nplausible and computationally efficient. We intentionally restrict ourselves to\na deterministic dynamics, in this review, and we consider that the dynamics of\nthe network is defined by a non-stochastic mapping. This allows us to stay in a\nrather simple framework and to propose a review with concrete numerical values,\nresults and formula on (i) general time constraints, (ii) links between\ncontinuous signals and spike trains, (iii) spiking networks parameter\nadjustments. When implementing spiking neuron networks, for computational or\nbiological simulation purposes, it is important to take into account the\nindisputable facts here reviewed. This precaution could prevent from\nimplementing mechanisms meaningless with regards to obvious time constraints,\nor from introducing spikes artificially, when continuous calculations would be\nsufficient and simpler. It is also pointed out that implementing a spiking\nneuron network is finally a simple task, unless complex neural codes are\nconsidered.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2009 12:14:35 GMT"}], "update_date": "2010-03-02", "authors_parsed": [["Cessac", "Bruno", ""], ["Paugam-Moisy", "H\u00e9l\u00e8ne", ""], ["Vi\u00e9ville", "Thierry", ""]]}, {"id": "0903.3535", "submitter": "Ivan Yu. Tyukin", "authors": "Erik Steur, Ivan Tyukin, and Henk Nijmeijer", "title": "Semi-passivity and synchronization of diffusively coupled neuronal\n  oscillators", "comments": null, "journal-ref": null, "doi": "10.1016/j.physd.2009.08.007", "report-no": null, "categories": "nlin.PS nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss synchronization in networks of neuronal oscillators which are\ninterconnected via diffusive coupling, i.e. linearly coupled via gap junctions.\nIn particular, we present sufficient conditions for synchronization in these\nnetworks using the theory of semi-passive and passive systems. We show that the\nconductance-based neuronal models of Hodgkin-Huxley, Morris-Lecar, and the\npopular reduced models of FitzHugh-Nagumo and Hindmarsh-Rose all satisfy a\nsemi-passivity property, i.e. that is the state trajectories of such a model\nremain oscillatory but bounded provided that the supplied (electrical) energy\nis bounded. As a result, for a wide range of coupling configurations, networks\nof these oscillators are guaranteed to possess ultimately bounded solutions.\nMoreover, we demonstrate that when the coupling is strong enough the\noscillators become synchronized. Our theoretical conclusions are confirmed by\ncomputer simulations with coupled \\HR and \\ML oscillators. Finally we discuss\npossible \"instabilities\" in networks of oscillators induced by the diffusive\ncoupling.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2009 15:09:54 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Steur", "Erik", ""], ["Tyukin", "Ivan", ""], ["Nijmeijer", "Henk", ""]]}, {"id": "0903.4168", "submitter": "Satoru Hayasaka", "authors": "Satoru Hayasaka, Paul J. Laurienti", "title": "Degree distributions in mesoscopic and macroscopic functional brain\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated the degree distribution of brain networks extracted from\nfunctional magnetic resonance imaging of the human brain. In particular, the\ndistributions are compared between macroscopic brain networks using\nregion-based nodes and mesoscopic brain networks using voxel-based nodes. We\nfound that the distribution from these networks follow the same family of\ndistributions and represent a continuum of exponentially truncated power law\ndistributions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2009 19:42:36 GMT"}], "update_date": "2009-03-25", "authors_parsed": [["Hayasaka", "Satoru", ""], ["Laurienti", "Paul J.", ""]]}, {"id": "0903.4416", "submitter": "Rom\\`an R. Zapatrin", "authors": "Christopher Altman, Rom\\`an R. Zapatrin", "title": "Backpropagation training in adaptive quantum networks", "comments": "Talk presented at \"Quantum Structures - 2008\", Gdansk, Poland", "journal-ref": "International Journal of Theoretical Physics, 49, 2991 (2010)", "doi": "10.1007/s10773-009-0103-1", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a robust, error-tolerant adaptive training algorithm for\ngeneralized learning paradigms in high-dimensional superposed quantum networks,\nor \\emph{adaptive quantum networks}. The formalized procedure applies standard\nbackpropagation training across a coherent ensemble of discrete topological\nconfigurations of individual neural networks, each of which is formally merged\ninto appropriate linear superposition within a predefined, decoherence-free\nsubspace. Quantum parallelism facilitates simultaneous training and revision of\nthe system within this coherent state space, resulting in accelerated\nconvergence to a stable network attractor under consequent iteration of the\nimplemented backpropagation algorithm. Parallel evolution of linear superposed\nnetworks incorporating backpropagation training provides quantitative,\nnumerical indications for optimization of both single-neuron activation\nfunctions and optimal reconfiguration of whole-network quantum structure.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2009 18:22:19 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Altman", "Christopher", ""], ["Zapatrin", "Rom\u00e0n R.", ""]]}, {"id": "0903.4664", "submitter": "Tobias H. Jaeger", "authors": "T. Jaeger", "title": "Neuronal Coding of pacemaker neurons - A random dynamical systems\n  approach", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behaviour of neurons under the influence of periodic external input has\nbeen modelled very successfully by circle maps. The aim of this note is to\nextend certain aspects of this analysis to a much more general class of forcing\nprocesses. We apply results on the fibred rotation number of randomly forced\ncircle maps to show the uniqueness of the asymptotic firing frequency of\nergodically forced pacemaker neurons. The details of the analysis are carried\nout for the forced leaky integrate-and-fire model, but the results should also\nremain valid for a large class of further models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2009 18:23:27 GMT"}], "update_date": "2009-03-27", "authors_parsed": [["Jaeger", "T.", ""]]}, {"id": "0903.5021", "submitter": "David Hsu", "authors": "David Hsu, Murielle Hsu", "title": "Zwanzig-Mori projection operators and EEG dynamics: deriving a simple\n  equation of motion", "comments": "Revised, e-published Jul 13, 2009", "journal-ref": "PMC Biophysics 2009; 2:6", "doi": "10.1186/1757-5036-2-6", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a macroscopic theory of electroencephalogram (EEG) dynamics based\non the laws of motion that govern atomic and molecular motion. The theory is an\napplication of Zwanzig-Mori projection operators. The result is a simple\nequation of motion that has the form of a generalized Langevin equation (GLE),\nwhich requires knowledge only of macroscopic properties. The macroscopic\nproperties can be extracted from experimental data by one of two possible\nvariational principles. These variational principles are our principal\ncontribution to the formalism. Potential applications are discussed, including\napplications to the theory of critical phenomena in the brain, Granger\ncausality and Kalman filters.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2009 04:11:05 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2009 17:00:30 GMT"}], "update_date": "2009-07-14", "authors_parsed": [["Hsu", "David", ""], ["Hsu", "Murielle", ""]]}]