[{"id": "1007.0210", "submitter": "Sergei Gepshtein", "authors": "Sergei Gepshtein and Ivan Tyukin", "title": "Uncertainty of visual measurement and efficient allocation of sensory\n  resources", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the reasoning underlying two approaches to combination of sensory\nuncertainties. First approach is noncommittal, making no assumptions about\nproperties of uncertainty or parameters of stimulation. Then we explain the\nrelationship between this approach and the one commonly used in modeling\n\"higher level\" aspects of sensory systems, such as in visual cue integration,\nwhere assumptions are made about properties of stimulation. The two approaches\nfollow similar logic, except in one case maximal uncertainty is minimized, and\nin the other minimal certainty is maximized. Then we demonstrate how optimal\nsolutions are found to the problem of resource allocation under uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2010 16:37:34 GMT"}, {"version": "v2", "created": "Sat, 3 May 2014 00:57:19 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Gepshtein", "Sergei", ""], ["Tyukin", "Ivan", ""]]}, {"id": "1007.0394", "submitter": "Dimitris Kugiumtzis", "authors": "Ioannis Vlachos and Dimitris Kugiumtzis", "title": "Non-uniform state space reconstruction and coupling detection", "comments": "21 pages, 11 figures, to be published in Physical Review E", "journal-ref": null, "doi": "10.1103/PhysRevE.82.016207", "report-no": null, "categories": "nlin.CD cs.IT math.IT physics.data-an q-bio.NC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the state space reconstruction from multiple time series\nderived from continuous and discrete systems and propose a method for building\nembedding vectors progressively using information measure criteria regarding\npast, current and future states. The embedding scheme can be adapted for\ndifferent purposes, such as mixed modelling, cross-prediction and Granger\ncausality. In particular we apply this method in order to detect and evaluate\ninformation transfer in coupled systems. As a practical application, we\ninvestigate in records of scalp epileptic EEG the information flow across brain\nareas.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2010 16:41:37 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Vlachos", "Ioannis", ""], ["Kugiumtzis", "Dimitris", ""]]}, {"id": "1007.0728", "submitter": "Robert Burger PhD", "authors": "John Robert Burger", "title": "Artificial Learning in Artificial Memories", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory refinements are designed below to detect those sequences of actions\nthat have been repeated a given number n. Subsequently such sequences are\npermitted to run without CPU involvement. This mimics human learning. Actions\nare rehearsed and once learned, they are performed automatically without\nconscious involvement.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2010 17:22:06 GMT"}, {"version": "v2", "created": "Sun, 5 Sep 2010 21:06:55 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Burger", "John Robert", ""]]}, {"id": "1007.0858", "submitter": "Christophe Magnani", "authors": "Christophe Magnani and L.E.Moore", "title": "Quadratic Sinusoidal Analysis of Neurons in Voltage Clamp", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear biophysical properties of individual neurons are known to play a\nmajor role in the nervous system. Earlier electrophysiological studies have\nmade use of piecewise linear characterization of voltage clamped neurons, which\nconsists of a sequence of linear admittances computed at different voltage\nlevels. In this paper, the linear approach is extended to a piecewise quadratic\ncharacterization in two different ways. First, an analytical model is derived\nwith power series following the work pionneered by Fitzhugh. Second, matrix\ncalculus is developed to provide a novel quantitative analysis not dependent on\ndifferential equations. This method provides an assessment of quadratic\nresponses for both data recorded from individual neurons and their\ncorresponding models.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2010 10:45:10 GMT"}], "update_date": "2010-07-07", "authors_parsed": [["Magnani", "Christophe", ""], ["Moore", "L. E.", ""]]}, {"id": "1007.1234", "submitter": "Georgi Medvedev S.", "authors": "Georgi S. Medvedev", "title": "Stochastic stability of continuous time consensus protocols", "comments": "SIAM Journal on Control and Optimization, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.SY nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A unified approach to studying convergence and stochastic stability of\ncontinuous time consensus protocols (CPs) is presented in this work. Our method\napplies to networks with directed information flow; both cooperative and\nnoncooperative interactions; networks under weak stochastic forcing; and those\nwhose topology and strength of connections may vary in time. The graph\ntheoretic interpretation of the analytical results is emphasized. We show how\nthe spectral properties, such as algebraic connectivity and total effective\nresistance, as well as the geometric properties, such the dimension and the\nstructure of the cycle subspace of the underlying graph, shape stability of the\ncorresponding CPs. In addition, we explore certain implications of the spectral\ngraph theory to CP design. In particular, we point out that expanders, sparse\nhighly connected graphs, generate CPs whose performance remains uniformly high\nwhen the size of the network grows unboundedly. Similarly, we highlight the\nbenefits of using random versus regular network topologies for CP design. We\nillustrate these observations with numerical examples and refer to the relevant\ngraph-theoretic results.\n  Keywords: consensus protocol, dynamical network, synchronization, robustness\nto noise, algebraic connectivity, effective resistance, expander, random graph\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2010 19:59:16 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2011 00:06:59 GMT"}, {"version": "v3", "created": "Sat, 2 Jun 2012 14:02:26 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Medvedev", "Georgi S.", ""]]}, {"id": "1007.1395", "submitter": "Davide Barbieri", "authors": "Davide Barbieri, Giovanna Citti, Gonzalo Sanguinetti, Alessandro Sarti", "title": "An uncertainty principle underlying the pinwheel structure in the\n  primary visual cortex", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.MP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The visual information in V1 is processed by an array of modules called\norientation preference columns. In some species including humans, orientation\ncolumns are radially arranged around singular points like the spokes of a\nwheel, that are called pinwheels. The pinwheel structure has been observed\nfirst with optical imaging techniques and more recently by in vivo two-photon\nimaging proving their organization with single cell precision. In this research\nwe provide evidence that pinwheels are de facto optimal distributions for\ncoding at the best angular position and momentum. In the last years many\nauthors have recognized that the functional architecture of V1 is locally\ninvariant with respect to the symmetry group of rotations and translations\nSE(2). In the present study we show that the orientation cortical maps used to\nconstruct pinwheels can be modeled as coherent states, i.e. the configurations\nbest localized both in angular position and angular momentum. The theory we\nadopt is based on the well known uncertainty principle, introduced by\nHeisenberg in quantum mechanics and later extended to many other groups of\ninvariance. Here we state a corresponding principle in the cortical geometry\nwith SE(2) symmetry, and by computing its minimizers we obtain a model of\norientation activity maps in the cortex. As it is well known the pinwheels\nconfiguration is directly constructed from these activity maps, and we will be\nable to formally reproduce their structure starting from the group symmetries\nof the functional architecture of the visual cortex. The primary visual cortex\nis then modeled as an integrated system in which the set of simple cells\nimplements the SE(2) group, the horizontal connectivity implements its Lie\nalgebra and the pinwheels implement its minimal uncertainty states.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2010 15:01:35 GMT"}], "update_date": "2010-07-09", "authors_parsed": [["Barbieri", "Davide", ""], ["Citti", "Giovanna", ""], ["Sanguinetti", "Gonzalo", ""], ["Sarti", "Alessandro", ""]]}, {"id": "1007.2345", "submitter": "Farzad Farkhooi", "authors": "Farzad Farkhooi, Eilif Muller, Martin P. Nawrot", "title": "Sequential Sparsening by Successive Adaptation in Neural Populations", "comments": "5 pages, 2 figures, This manuscript was submitted for review to the\n  Eighteenth Annual Computational Neuroscience Meeting CNS*2009 in Berlin and\n  accepted for oral presentation at the meeting", "journal-ref": "Supplement to Farkhooi, F., Muller, E. & Nawrot, M. Sequential\n  sparsing by successive adapting neural populations. BMC Neuroscience 10, O10\n  (2009)", "doi": "10.1186/1471-2202-10-S1-O10", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the principal cells of the insect mushroom body, the Kenyon cells (KC),\nolfactory information is represented by a spatially and temporally sparse code.\nEach odor stimulus will activate only a small portion of neurons and each\nstimulus leads to only a short phasic response following stimulus onset\nirrespective of the actual duration of a constant stimulus. The mechanisms\nresponsible for the sparse code in the KCs are yet unresolved.\n  Here, we explore the role of the neuron-intrinsic mechanism of\nspike-frequency adaptation (SFA) in producing temporally sparse responses to\nsensory stimulation in higher processing stages. Our single neuron model is\ndefined through a conductance-based integrate-and-fire neuron with\nspike-frequency adaptation [1]. We study a fully connected feed-forward network\narchitecture in coarse analogy to the insect olfactory pathway. A first layer\nof ten neurons represents the projection neurons (PNs) of the antenna lobe. All\nPNs receive a step-like input from the olfactory receptor neurons, which was\nrealized by independent Poisson processes. The second layer represents 100 KCs\nwhich converge onto ten neurons in the output layer which represents the\npopulation of mushroom body extrinsic neurons (ENs).\n  Our simulation result matches with the experimental observations. In\nparticular, intracellular recordings of PNs show a clear phasic-tonic response\nthat outlasts the stimulus [2] while extracellular recordings from KCs in the\nlocust express sharp transient responses [3]. We conclude that the\nneuron-intrinsic mechanism is can explain a progressive temporal response\nsparsening in the insect olfactory system. Further experimental work is needed\nto test this hypothesis empirically.\n  [1] Muller et. al., Neural Comput, 19(11):2958-3010, 2007. [2] Assisi et.\nal., Nat Neurosci, 10(9):1176-1184, 2007. [3] Krofczik et. al. Front. Comput.\nNeurosci., 2(9), 2009.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2010 14:29:22 GMT"}], "update_date": "2010-07-21", "authors_parsed": [["Farkhooi", "Farzad", ""], ["Muller", "Eilif", ""], ["Nawrot", "Martin P.", ""]]}, {"id": "1007.2420", "submitter": "Didier Sornette", "authors": "Didier Sornette and Ivan Osorio", "title": "Prediction", "comments": "44 pages with 16 figures and 167 references, chapter in \"Epilepsy:\n  The Intersection of Neurosciences, Mathematics, and Engineering\",Taylor &\n  Francis Group, Ivan Osorio, Mark G. Frei, Hitten Zaveri, Susan Arthurs, eds\n  (2010)", "journal-ref": "chapter in \"Epilepsy: The Intersection of Neurosciences, Biology,\n  Mathematics, Physics and Engineering'', Editors: Osorio I., Zaveri H.P., Frei\n  M.G., Arthurs S., CRC Press, Taylor & Francis Group, pp. 203-237 (2010)", "doi": null, "report-no": null, "categories": "physics.geo-ph nlin.AO physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter first presents a rather personal view of some different aspects\nof predictability, going in crescendo from simple linear systems to\nhigh-dimensional nonlinear systems with stochastic forcing, which exhibit\nemergent properties such as phase transitions and regime shifts. Then, a\ndetailed correspondence between the phenomenology of earthquakes, financial\ncrashes and epileptic seizures is offered. The presented statistical evidence\nprovides the substance of a general phase diagram for understanding the many\nfacets of the spatio-temporal organization of these systems. A key insight is\nto organize the evidence and mechanisms in terms of two summarizing measures:\n(i) amplitude of disorder or heterogeneity in the system and (ii) level of\ncoupling or interaction strength among the system's components. On the basis of\nthe recently identified remarkable correspondence between earthquakes and\nseizures, we present detailed information on a class of stochastic point\nprocesses that has been found to be particularly powerful in describing\nearthquake phenomenology and which, we think, has a promising future in\nepileptology. The so-called self-exciting Hawkes point processes capture\nparsimoniously the idea that events can trigger other events, and their\ncascades of interactions and mutual influence are essential to understand the\nbehavior of these systems.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2010 20:03:37 GMT"}], "update_date": "2014-08-26", "authors_parsed": [["Sornette", "Didier", ""], ["Osorio", "Ivan", ""]]}, {"id": "1007.2493", "submitter": "Romain Veltz M", "authors": "Romain Veltz, Olivier Faugeras", "title": "Illusions in the Ring Model of visual orientation selectivity", "comments": "33 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Ring Model of orientation tuning is a dynamical model of a hypercolumn of\nvisual area V1 in the human neocortex that has been designed to account for the\nexperimentally observed orientation tuning curves by local, i.e.,\ncortico-cortical computations. The tuning curves are stationary, i.e. time\nindependent, solutions of this dynamical model. One important assumption\nunderlying the Ring Model is that the LGN input to V1 is weakly tuned to the\nretinal orientation and that it is the local computations in V1 that sharpen\nthis tuning. Because the equations that describe the Ring Model have built-in\nequivariance properties in the synaptic weight distribution with respect to a\nparticular group acting on the retinal orientation of the stimulus, the model\nin effect encodes an infinite number of tuning curves that are arbitrarily\ntranslated with respect to each other. By using the Orbit Space Reduction\ntechnique we rewrite the model equations in canonical form as functions of\npolynomials that are invariant with respect to the action of this group. This\nallows us to combine equivariant bifurcation theory with an efficient numerical\ncontinuation method in order to compute the tuning curves predicted by the Ring\nModel. Surprisingly some of these tuning curves are not tuned to the stimulus.\nWe interpret them as neural illusions and show numerically how they can be\ninduced by simple dynamical stimuli. These neural illusions are important\nbiological predictions of the model. If they could be observed experimentally\nthis would be a strong point in favour of the Ring Model. We also show how our\ntheoretical analysis allows to very simply specify the ranges of the model\nparameters by comparing the model predictions with published experimental\nobservations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2010 07:47:42 GMT"}], "update_date": "2010-07-16", "authors_parsed": [["Veltz", "Romain", ""], ["Faugeras", "Olivier", ""]]}, {"id": "1007.2787", "submitter": "Jason Prentice", "authors": "Jason S. Prentice, Jan Homann, Kristina D. Simmons, Ga\\v{s}per\n  Tka\\v{c}ik, Vijay Balasubramanian, and Philip C. Nelson", "title": "Fast, scalable, Bayesian spike identification for multi-electrode arrays", "comments": null, "journal-ref": "PLoS ONE 6: e19884 (2011)", "doi": "10.1371/journal.pone.0019884", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm to identify individual neural spikes observed on\nhigh-density multi-electrode arrays (MEAs). Our method can distinguish large\nnumbers of distinct neural units, even when spikes overlap, and accounts for\nintrinsic variability of spikes from each unit. As MEAs grow larger, it is\nimportant to find spike-identification methods that are scalable, that is, the\ncomputational cost of spike fitting should scale well with the number of units\nobserved. Our algorithm accomplishes this goal, and is fast, because it\nexploits the spatial locality of each unit and the basic biophysics of\nextracellular signal propagation. Human intervention is minimized and\nstreamlined via a graphical interface. We illustrate our method on data from a\nmammalian retina preparation and document its performance on simulated data\nconsisting of spikes added to experimentally measured background noise. The\nalgorithm is highly accurate.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2010 14:57:07 GMT"}], "update_date": "2013-08-01", "authors_parsed": [["Prentice", "Jason S.", ""], ["Homann", "Jan", ""], ["Simmons", "Kristina D.", ""], ["Tka\u010dik", "Ga\u0161per", ""], ["Balasubramanian", "Vijay", ""], ["Nelson", "Philip C.", ""]]}, {"id": "1007.3122", "submitter": "Samuel Johnson", "authors": "Samuel Johnson, J. Marro, and Joaqu\\'in J. Torres", "title": "Robust short-term memory without synaptic learning", "comments": "20 pages, 9 figures. Amended to include section on spiking neurons,\n  with general rewrite", "journal-ref": "Johnson S, Marro J, Torres JJ (2013) Robust Short-Term Memory\n  without Synaptic Learning. PLoS ONE 8(1): e50276", "doi": "10.1371/journal.pone.0050276", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term memory in the brain cannot in general be explained the way\nlong-term memory can -- as a gradual modification of synaptic weights -- since\nit takes place too quickly. Theories based on some form of cellular\nbistability, however, do not seem able to account for the fact that noisy\nneurons can collectively store information in a robust manner. We show how a\nsufficiently clustered network of simple model neurons can be instantly induced\ninto metastable states capable of retaining information for a short time (a few\nseconds). The mechanism is robust to different network topologies and kinds of\nneural model. This could constitute a viable means available to the brain for\nsensory and/or short-term memory with no need of synaptic learning. Relevant\nphenomena described by neurobiology and psychology, such as local\nsynchronization of synaptic inputs and power-law statistics of forgetting\navalanches, emerge naturally from this mechanism, and we suggest possible\nexperiments to test its viability in more biological settings.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 11:11:48 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2013 19:34:49 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Johnson", "Samuel", ""], ["Marro", "J.", ""], ["Torres", "Joaqu\u00edn J.", ""]]}, {"id": "1007.3230", "submitter": "Sean Simpson", "authors": "Sean L. Simpson, Satoru Hayasaka, and Paul J. Laurienti", "title": "Exponential Random Graph Modeling for Complex Brain Networks", "comments": null, "journal-ref": "PLoS ONE 2011: 6(5), e20039 (doi:10.1371/journal.pone.0020039)", "doi": "10.1371/journal.pone.0020039", "report-no": null, "categories": "stat.AP q-bio.NC q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exponential random graph models (ERGMs), also known as p* models, have been\nutilized extensively in the social science literature to study complex networks\nand how their global structure depends on underlying structural components.\nHowever, the literature on their use in biological networks (especially brain\nnetworks) has remained sparse. Descriptive models based on a specific feature\nof the graph (clustering coefficient, degree distribution, etc.) have dominated\nconnectivity research in neuroscience. Corresponding generative models have\nbeen developed to reproduce one of these features. However, the complexity\ninherent in whole-brain network data necessitates the development and use of\ntools that allow the systematic exploration of several features simultaneously\nand how they interact to form the global network architecture. ERGMs provide a\nstatistically principled approach to the assessment of how a set of interacting\nlocal brain network features gives rise to the global structure. We illustrate\nthe utility of ERGMs for modeling, analyzing, and simulating complex\nwhole-brain networks with network data from normal subjects. We also provide a\nfoundation for the selection of important local features through the\nimplementation and assessment of three selection approaches: a traditional\np-value based backward selection approach, an information criterion approach\n(AIC), and a graphical goodness of fit (GOF) approach. The graphical GOF\napproach serves as the best method given the scientific interest in being able\nto capture and reproduce the structure of fitted brain networks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2010 18:16:26 GMT"}, {"version": "v2", "created": "Wed, 1 Jun 2011 20:31:29 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Simpson", "Sean L.", ""], ["Hayasaka", "Satoru", ""], ["Laurienti", "Paul J.", ""]]}, {"id": "1007.3490", "submitter": "Farzad Farkhooi", "authors": "Farzad Farkhooi and Eilif Muller and Martin P. Nawrot", "title": "Adaptation Reduces Variability of the Neuronal Population Code", "comments": "4 pages, 2 figures", "journal-ref": "Phys. Rev. E 83, 050905 (2011)", "doi": "10.1103/PhysRevE.83.050905", "report-no": null, "categories": "physics.bio-ph math.PR q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequences of events in noise-driven excitable systems with slow variables\noften show serial correlations among their intervals of events. Here, we employ\na master equation for general non-renewal processes to calculate the interval\nand count statistics of superimposed processes governed by a slow adaptation\nvariable. For an ensemble of spike-frequency adapting neurons this results in\nthe regularization of the population activity and an enhanced post-synaptic\nsignal decoding. We confirm our theoretical results in a population of cortical\nneurons.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2010 19:42:34 GMT"}, {"version": "v2", "created": "Mon, 7 Feb 2011 16:29:14 GMT"}], "update_date": "2011-05-23", "authors_parsed": [["Farkhooi", "Farzad", ""], ["Muller", "Eilif", ""], ["Nawrot", "Martin P.", ""]]}, {"id": "1007.3556", "submitter": "Jorge F. Mejias", "authors": "Jorge F. Mejias, Hilbert J. Kappen and Joaquin J. Torres", "title": "Irregular dynamics in up and down cortical states", "comments": "23 pages, 8 figues", "journal-ref": null, "doi": "10.1371/journal.pone.0013651", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex coherent dynamics is present in a wide variety of neural systems. A\ntypical example is the voltage transitions between up and down states observed\nin cortical areas in the brain. In this work, we study this phenomenon via a\nbiologically motivated stochastic model of up and down transitions. The model\nis constituted by a simple bistable rate model, where the synaptic current is\nmodulated by short-term synaptic processes which introduce stochasticity and\ntemporal correlations. A complete analysis of our model, both with mean-field\napproaches and numerical simulations, shows the appearance of complex\ntransitions between high (up) and low (down) neural activity states, driven by\nthe synaptic noise, with permanence times in the up state distributed according\nto a power-law. We show that the experimentally observed large fluctuation in\nup and down permanence times can be explained as the result of sufficiently\nnoisy dynamical synapses with sufficiently large recovery times. Static\nsynapses cannot account for this behavior, nor can dynamical synapses in the\nabsence of noise.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2010 03:58:44 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Mejias", "Jorge F.", ""], ["Kappen", "Hilbert J.", ""], ["Torres", "Joaquin J.", ""]]}, {"id": "1007.5016", "submitter": "Tsvi Tlusty", "authors": "Jordi Soriano, Ilan Breskin, Elisha Moses and Tsvi Tlusty", "title": "Percolation Approach to Study Connectivity in Living Neural Networks", "comments": "Keywords: neural networks, graphs, connectivity, percolation, giant\n  component PACS: 87.18.Sn, 87.19.La, 64.60.Ak\n  http://www.weizmann.ac.il/complex/tlusty/papers/AIP2006.pdf", "journal-ref": "9th Granada Seminar 2006 - Cooperative Behavior in Neural Systems\n  AIP, eds Garrido PL, Marro J, & Torres JJ (AIP, Granada, SPAIN), Vol 887, pp\n  96-106", "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study neural connectivity in cultures of rat hippocampal neurons. We\nmeasure the neurons' response to an electric stimulation for gradual lower\nconnectivity, and characterize the size of the giant cluster in the network.\nThe connectivity undergoes a percolation transition described by the critical\nexponent $\\beta \\simeq 0.65$. We use a theoretic approach based on\nbond.percolation on a graph to describe the process of disintegration of the\nnetwork and extract its statistical properties. Together with numerical\nsimulations we show that the connectivity in the neural culture is local,\ncharacterized by a gaussian degree distribution and not a power law on\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2010 15:58:03 GMT"}], "update_date": "2010-07-30", "authors_parsed": [["Soriano", "Jordi", ""], ["Breskin", "Ilan", ""], ["Moses", "Elisha", ""], ["Tlusty", "Tsvi", ""]]}, {"id": "1007.5022", "submitter": "Tsvi Tlusty", "authors": "Ilan Breskin, Jordi Soriano, Elisha Moses, and Tsvi Tlusty", "title": "Percolation in living neural networks", "comments": "PACS numbers: 87.18.Sn, 87.19.La, 64.60.Ak\n  http://www.weizmann.ac.il/complex/tlusty/papers/PhysRevLett2006.pdf", "journal-ref": "Breskin I Soriano J Moses E & Tlusty T Percolation in Living\n  Neural Networks Phys Rev Lett 97 188102-4 (2006)", "doi": "10.1103/PhysRevLett.97.188102", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study living neural networks by measuring the neurons' response to a\nglobal electrical stimulation. Neural connectivity is lowered by reducing the\nsynaptic strength, chemically blocking neurotransmitter receptors. We use a\ngraph-theoretic approach to show that the connectivity undergoes a percolation\ntransition. This occurs as the giant component disintegrates, characterized by\na power law with critical exponent $\\beta \\simeq 0.65$ is independent of the\nbalance between excitatory and inhibitory neurons and indicates that the degree\ndistribution is gaussian rather than scale free\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2010 16:12:39 GMT"}], "update_date": "2010-07-30", "authors_parsed": [["Breskin", "Ilan", ""], ["Soriano", "Jordi", ""], ["Moses", "Elisha", ""], ["Tlusty", "Tsvi", ""]]}, {"id": "1007.5143", "submitter": "Tsvi Tlusty", "authors": "Or Cohen, Anna Keselman, Elisha Moses, Mar\\'ia Rodr\\'iguez Mart\\'inez,\n  Jordi Soriano and Tsvi Tlusty", "title": "Quorum Percolation in Living Neural Networks", "comments": "87.19.L-: Neuroscience 87.19.ll: Models of single neurons and\n  networks 64.60.ah: Percolation http://iopscience.iop.org/0295-5075/89/1/18008\n  http://www.weizmann.ac.il/complex/tlusty/papers/EuroPhysLett2010.pdf", "journal-ref": "O. Cohen et al 2010 EPL 89 18008", "doi": "10.1209/0295-5075/89/18008", "report-no": null, "categories": "cond-mat.dis-nn physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative effects in neural networks appear because a neuron fires only if\na minimal number $m$ of its inputs are excited. The multiple inputs requirement\nleads to a percolation model termed {\\it quorum percolation}. The connectivity\nundergoes a phase transition as $m$ grows, from a network--spanning cluster at\nlow $m$ to a set of disconnected clusters above a critical $m$. Both numerical\nsimulations and the model reproduce the experimental results well. This allows\na robust quantification of biologically relevant quantities such as the average\nconnectivity $\\kbar$ and the distribution of connections $p_k$\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2010 08:22:57 GMT"}], "update_date": "2010-07-30", "authors_parsed": [["Cohen", "Or", ""], ["Keselman", "Anna", ""], ["Moses", "Elisha", ""], ["Mart\u00ednez", "Mar\u00eda Rodr\u00edguez", ""], ["Soriano", "Jordi", ""], ["Tlusty", "Tsvi", ""]]}, {"id": "1007.5465", "submitter": "Tsvi Tlusty", "authors": "Jean-Pierre Eckmann, Ofer Feinerman, Leor Gruendlinger, Elisha Moses,\n  Jordi Soriano, Tsvi Tlusty", "title": "The Physics of Living Neural Networks", "comments": "PACS: 87.18.Sn, 87.19.La, 87.80.-y, 87.80.Xa, 64.60.Ak Keywords:\n  complex systems, neuroscience, neural networks, transport of information,\n  neural connectivity, percolation\n  http://www.weizmann.ac.il/complex/tlusty/papers/PhysRep2007.pdf\n  http://www.weizmann.ac.il/complex/EMoses/pdf/PhysRep-448-56.pdf", "journal-ref": "Physics Reports Volume 449, Issues 1-3, September 2007, Pages\n  54-76", "doi": "10.1016/j.physrep.2007.02.014", "report-no": null, "categories": "cond-mat.dis-nn physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improvements in technique in conjunction with an evolution of the theoretical\nand conceptual approach to neuronal networks provide a new perspective on\nliving neurons in culture. Organization and connectivity are being measured\nquantitatively along with other physical quantities such as information, and\nare being related to function. In this review we first discuss some of these\nadvances, which enable elucidation of structural aspects. We then discuss two\nrecent experimental models that yield some conceptual simplicity. A\none-dimensional network enables precise quantitative comparison to analytic\nmodels, for example of propagation and information transport. A two-dimensional\npercolating network gives quantitative information on connectivity of cultured\nneurons. The physical quantities that emerge as essential characteristics of\nthe network in vitro are propagation speeds, synaptic transmission, information\ncreation and capacity. Potential application to neuronal devices is discussed.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jul 2010 14:48:05 GMT"}], "update_date": "2010-08-02", "authors_parsed": [["Eckmann", "Jean-Pierre", ""], ["Feinerman", "Ofer", ""], ["Gruendlinger", "Leor", ""], ["Moses", "Elisha", ""], ["Soriano", "Jordi", ""], ["Tlusty", "Tsvi", ""]]}, {"id": "1007.5471", "submitter": "Pablo Barttfeld", "authors": "Pablo Barttfeld, Bruno Wicker, Sebasti\\'an Cukier, Silvana Navarta,\n  Sergio Lew and Mariano Sigman", "title": "A big-world network in ASD: Dynamical connectivity analysis reflects a\n  deficit in long-range connections and an excess of short-range connections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years, increasing evidence has fuelled the hypothesis that\nAutism Spectrum Disorder (ASD) is a condition of altered brain functional\nconnectivity. The great majority of these empirical studies rely on functional\nmagnetic resonance imaging (fMRI) which has a relatively poor temporal\nresolution. Only a handful of studies have examined networks emerging from\ndynamic coherence at the millisecond resolution and there are no investigations\nof coherence at the lowest frequencies in the power spectrum - which has\nrecently been shown to reflect long-range cortico-cortical connections. Here we\nused electroencephalography (EEG) to assess dynamic brain connectivity in ASD\nfocusing in the low-frequency (delta) range. We found that connectivity\npatterns were distinct in ASD and control populations and reflected a double\ndissociation: ASD subjects lacked long-range connections, with a most prominent\ndeficit in fronto-occipital connections. Conversely, individuals with ASD\nshowed increased short-range connections in lateral-frontal electrodes. This\neffect between categories showed a consistent parametric dependency: as ASD\nseverity increased, short-range coherence was more pronounced and long-range\ncoherence decreased. Theoretical arguments have been proposed arguing that\ndistinct patterns of connectivity may result in networks with different\nefficiency in transmission of information. We show that the networks in ASD\nsubjects have less Clustering coefficient, greater Characteristic Path Length\nthan controls -indicating that the topology of the network departs from\nsmall-world behaviour- and greater modularity. Together these results show that\ndelta-band coherence reveal qualitative and quantitative aspects associated\nwith ASD pathology.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jul 2010 15:09:12 GMT"}], "update_date": "2010-08-02", "authors_parsed": [["Barttfeld", "Pablo", ""], ["Wicker", "Bruno", ""], ["Cukier", "Sebasti\u00e1n", ""], ["Navarta", "Silvana", ""], ["Lew", "Sergio", ""], ["Sigman", "Mariano", ""]]}]