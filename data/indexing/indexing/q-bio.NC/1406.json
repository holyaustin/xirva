[{"id": "1406.0139", "submitter": "Sadra Sadeh", "authors": "Sadra Sadeh and Stefan Rotter", "title": "Distribution of Orientation Selectivity in Recurrent Networks of Spiking\n  Neurons with Different Random Topologies", "comments": "12 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0114237", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the primary visual cortex are more or less selective for the\norientation of a light bar used for stimulation. A broad distribution of\nindividual grades of orientation selectivity has in fact been reported in all\nspecies. A possible reason for emergence of broad distributions is the\nrecurrent network within which the stimulus is being processed. Here we compute\nthe distribution of orientation selectivity in randomly connected model\nnetworks that are equipped with different spatial patterns of connectivity. We\nshow that, for a wide variety of connectivity patterns, a linear theory based\non firing rates accurately approximates the outcome of direct numerical\nsimulations of networks of spiking neurons. Distance dependent connectivity in\nnetworks with a more biologically realistic structure does not compromise our\nlinear analysis, as long as the linearized dynamics, and hence the uniform\nasynchronous irregular activity state, remain stable. We conclude that linear\nmechanisms of stimulus processing are indeed responsible for the emergence of\norientation selectivity and its distribution in recurrent networks with\nfunctionally heterogeneous synaptic connectivity.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jun 2014 07:43:30 GMT"}, {"version": "v2", "created": "Sat, 8 Nov 2014 00:30:26 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Sadeh", "Sadra", ""], ["Rotter", "Stefan", ""]]}, {"id": "1406.0243", "submitter": "Ehtibar Dzhafarov", "authors": "Janne V. Kujala and Ehtibar N. Dzhafarov", "title": "Probabilistic Contextuality in EPR/Bohm-type Systems with Signaling\n  Allowed", "comments": "a chapter (pp. 287-308) in \"Contextuality from Quantum Physics to\n  Psychology\", edited by E. Dzhafarov, S. Jordan, R. Zhang, and V. Cervantes.\n  New Jersey: World Scientific, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this chapter, we review a principled way of defining and measuring\ncontextuality in systems with deterministic inputs and random outputs, recently\nproposed and developed in \\citep{KujalaDzhafarovLarsson2015,DKL2015FooP}.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 04:59:19 GMT"}, {"version": "v2", "created": "Thu, 12 Jun 2014 00:25:24 GMT"}, {"version": "v3", "created": "Fri, 27 Jun 2014 11:43:31 GMT"}, {"version": "v4", "created": "Thu, 10 Jul 2014 18:01:19 GMT"}, {"version": "v5", "created": "Thu, 17 Jul 2014 20:24:47 GMT"}, {"version": "v6", "created": "Tue, 27 Jan 2015 21:26:32 GMT"}, {"version": "v7", "created": "Mon, 27 Jul 2015 14:03:11 GMT"}, {"version": "v8", "created": "Mon, 30 Nov 2015 21:48:59 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Kujala", "Janne V.", ""], ["Dzhafarov", "Ehtibar N.", ""]]}, {"id": "1406.0476", "submitter": "Julien Chevallier", "authors": "Julien Chevallier (JAD), Thomas Lalo\\\"e (JAD)", "title": "Detection of dependence patterns with delay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Unitary Events (UE) method is a popular and efficient method used this\nlast decade to detect dependence patterns of joint spike activity among\nsimultaneously recorded neurons. The first introduced method is based on binned\ncoincidence count \\citep{Grun1996} and can be applied on two or more\nsimultaneously recorded neurons. Among the improvements of the methods, a\ntransposition to the continuous framework has recently been proposed in\n\\citep{muino2014frequent} and fully investigated in \\citep{MTGAUE} for two\nneurons. The goal of the present paper is to extend this study to more than two\nneurons. The main result is the determination of the limit distribution of the\ncoincidence count. This leads to the construction of an independence test\nbetween $L\\geq 2$ neurons. Finally we propose a multiple test procedure via a\nBenjamini and Hochberg approach \\citep{Benjamini1995}. All the theoretical\nresults are illustrated by a simulation study, and compared to the UE method\nproposed in \\citep{Grun2002}. Furthermore our method is applied on real data.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jun 2014 18:55:17 GMT"}, {"version": "v2", "created": "Fri, 22 May 2015 13:22:20 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2015 08:48:35 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Chevallier", "Julien", "", "JAD"], ["Lalo\u00eb", "Thomas", "", "JAD"]]}, {"id": "1406.1265", "submitter": "Jackie Shen", "authors": "Yoon Mo Jung and Jianhong Jackie Shen", "title": "Illusory Shapes via Phase Transition", "comments": "New Work", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new variational illusory shape (VIS) model via phase fields and\nphase transitions. It is inspired by the first-order variational illusory\ncontour (VIC) model proposed by Jung and Shen [{\\em J. Visual Comm. Image\nRepres.}, {\\bf 19}:42-55, 2008]. Under the new VIS model, illusory shapes are\nrepresented by phase values close to 1 while the rest by values close to 0. The\n0-1 transition is achieved by an elliptic energy with a double-well potential,\nas in the theory of $\\Gamma$-convergence. The VIS model is non-convex, with the\nzero field as its trivial global optimum. To seek visually meaningful local\noptima that can induce illusory shapes, an iterative algorithm is designed and\nits convergence behavior is closely studied. Several generic numerical examples\nconfirm the versatility of the model and the algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jun 2014 04:40:31 GMT"}], "update_date": "2014-06-06", "authors_parsed": [["Jung", "Yoon Mo", ""], ["Shen", "Jianhong Jackie", ""]]}, {"id": "1406.1391", "submitter": "Donald Forsdyke Dr.", "authors": "Donald R. Forsdyke", "title": "'A Vehicle of Symbols and Nothing More.' George Romanes, Theory of Mind,\n  Information, and Samuel Butler", "comments": "Accepted for publication in History of Psychiatry. 31 pages including\n  3 footnotes. Based on a lecture given at Santa Clara University, February\n  28th 2014, at a Bannan Institute Symposium on 'Science and Seeking:\n  Rethinking the God Question in the Lab, Cosmos, and Classroom.' - See more at\n  either http://www.youtube.com/watch?v=a3yNbTUCPd4 or\n  http://www.youtube.com/watch?v=ezcdIrR9r-w", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's 'theory of mind' (ToM) concept is rooted in the distinction of\nnineteenth century philosopher William Clifford between 'objects' that can be\ndirectly perceived, and 'ejects,' such as the mind of another person, which are\ninferred from one's subjective knowledge of one's own mind. A founder, with\nCharles Darwin, of the discipline of comparative psychology, George Romanes\nconsidered the minds of animals as ejects, an idea that could be generalized to\n'society as eject' and, ultimately, 'the world as an eject' - mind in the\nuniverse. Yet, Romanes and Clifford only vaguely connected mind with the\nabstraction we call 'information,' which needs 'a vehicle of symbols' - a\nmaterial transporting medium. However, Samuel Butler was able to address, in\ninformational terms depleted of theological trappings, both organic evolution\nand mind in the universe. This view harmonizes with insights arising from\nmodern DNA research, the relative immortality of 'selfish' genes, and some\nstartling recent developments in brain research.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jun 2014 03:04:49 GMT"}, {"version": "v2", "created": "Thu, 13 Nov 2014 22:19:37 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Forsdyke", "Donald R.", ""]]}, {"id": "1406.1537", "submitter": "Sungwoo Ahn", "authors": "Leonid L Rubchinsky, Sungwoo Ahn, and Choongseok Park", "title": "Dynamics of desynchronized episodes in intermittent synchronization", "comments": "12 pages, 2 figures. Accepted to Frontiers in Physics", "journal-ref": "Front. Phys. 2:38, 2014", "doi": "10.3389/fphy.2014.00038", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intermittent synchronization is observed in a variety of different\nexperimental settings in physics and beyond and is an established research\ntopic in nonlinear dynamics. When coupled oscillators exhibit relatively weak,\nintermittent synchrony, the trajectory in the phase space spends a substantial\nfraction of time away from a vicinity of a synchronized state. Thus to describe\nand understand the observed dynamics one may consider both synchronized\nepisodes and desynchronized episodes (the episodes when oscillators are not\nsynchronous). This mini-review discusses recent developments in this area. We\nexplain how one can consider variation in synchrony on the very short\ntime-scales, provided that there is some degree of overall synchrony. We show\nhow to implement this approach in the case of intermittent phase locking,\nreview several recent examples of the application of these ideas to\nexperimental data and modeling systems, and discuss when and why these methods\nmay be useful.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jun 2014 22:20:25 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Rubchinsky", "Leonid L", ""], ["Ahn", "Sungwoo", ""], ["Park", "Choongseok", ""]]}, {"id": "1406.1603", "submitter": "Robert Prevedel", "authors": "Tina Schr\\\"odel, Robert Prevedel, Karin Aumayr, Manuel Zimmer and\n  Alipasha Vaziri", "title": "Brain-wide 3D imaging of neuronal activity in Caenorhabditis elegans\n  with sculpted light", "comments": "28 pages, 5 figures, plus Supplementary Information (24 pages, 10\n  figures)", "journal-ref": "Nature Methods 10, 1013-1020 (2013)", "doi": "10.1038/nmeth.2637", "report-no": null, "categories": "q-bio.NC physics.bio-ph physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent efforts in neuroscience research seek to obtain detailed anatomical\nneuronal wiring maps as well as information on how neurons in these networks\nengage in dynamic activities. Although the entire connectivity map of the\nnervous system of C. elegans has been known for more than 25 years, this\nknowledge has not been sufficient to predict all functional connections\nunderlying behavior. To approach this goal, we developed a two-photon technique\nfor brain-wide calcium imaging in C. elegans using wide-field temporal focusing\n(WF-TEFO). Pivotal to our results was the use of a nuclear-localized,\ngenetically encoded calcium indicator (NLS-GCaMP5K) that permits unambiguous\ndiscrimination of individual neurons within the densely-packed head ganglia of\nC. elegans. We demonstrate near-simultaneous recording of activity of up to 70%\nof all head neurons. In combination with a lab-on-a-chip device for stimulus\ndelivery, this method provides an enabling platform for establishing functional\nmaps of neuronal networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 07:46:02 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Schr\u00f6del", "Tina", ""], ["Prevedel", "Robert", ""], ["Aumayr", "Karin", ""], ["Zimmer", "Manuel", ""], ["Vaziri", "Alipasha", ""]]}, {"id": "1406.1770", "submitter": "Tomaso Poggio", "authors": "Tomaso Poggio, Jim Mutch, Leyla Isik", "title": "Computational role of eccentricity dependent cortical magnification", "comments": null, "journal-ref": null, "doi": null, "report-no": "CBMM memo 17", "categories": "cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a sampling extension of M-theory focused on invariance to scale\nand translation. Quite surprisingly, the theory predicts an architecture of\nearly vision with increasing receptive field sizes and a high resolution fovea\n-- in agreement with data about the cortical magnification factor, V1 and the\nretina. From the slope of the inverse of the magnification factor, M-theory\npredicts a cortical \"fovea\" in V1 in the order of $40$ by $40$ basic units at\neach receptive field size -- corresponding to a foveola of size around $26$\nminutes of arc at the highest resolution, $\\approx 6$ degrees at the lowest\nresolution. It also predicts uniform scale invariance over a fixed range of\nscales independently of eccentricity, while translation invariance should\ndepend linearly on spatial frequency. Bouma's law of crowding follows in the\ntheory as an effect of cortical area-by-cortical area pooling; the Bouma\nconstant is the value expected if the signature responsible for recognition in\nthe crowding experiments originates in V2. From a broader perspective, the\nemerging picture suggests that visual recognition under natural conditions\ntakes place by composing information from a set of fixations, with each\nfixation providing recognition from a space-scale image fragment -- that is an\nimage patch represented at a set of increasing sizes and decreasing\nresolutions.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 18:49:56 GMT"}], "update_date": "2014-06-09", "authors_parsed": [["Poggio", "Tomaso", ""], ["Mutch", "Jim", ""], ["Isik", "Leyla", ""]]}, {"id": "1406.1975", "submitter": "Wenlian Lu", "authors": "Xiaohong Gong, Wenlian Lu, Keith M. Kendrick, Weidan Pu, Chu Wang, Li\n  Jin, Guangmin Lu, Zhening Liu, Haihong Liu, Jianfeng Feng", "title": "A brain-wide association study of DISC1 genetic variants reveals a\n  relationship with the structure and functional connectivity of the precuneus\n  in schizophrenia", "comments": "43 pages, 8 figures, 3 tables", "journal-ref": null, "doi": "10.1002/hbm.22560", "report-no": null, "categories": "q-bio.NC q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Disrupted in Schizophrenia Gene 1 (DISC1) plays a role in both neural\nsignalling and development and is associated with schizophrenia, although its\nlinks to altered brain structure and function in this disorder are not fully\nestablished. Here we have used structural and functional MRI to investigate\nlinks with six DISC1 single nucleotide polymorphisms (SNPs). We employed a\nbrain-wide association analysis (BWAS) together with a Jacknife internal\nvalidation approach in 46 schizophrenia patients and 24 matched healthy control\nsubjects. Results from structural MRI showed significant associations between\nall six DISC1 variants and gray matter volume in the precuneus, post-central\ngyrus and middle cingulate gyrus. Associations with specific SNPs were found\nfor rs2738880 in the left precuneus and right post-central gyrus, and rs1535530\nin the right precuneus and middle cingulate gyrus. Using regions showing\nstructural associations as seeds a resting-state functional connectivity\nanalysis revealed significant associations between all 6 SNPS and connectivity\nbetween the right precuneus and inferior frontal gyrus. The connection between\nthe right precuneus and inferior frontal gyrus was also specifically associated\nwith rs821617. Importantly schizophrenia patients showed positive correlations\nbetween the six DISC-1 SNPs associated gray matter volume in the left precuneus\nand right post-central gyrus and negative symptom severity. No correlations\nwith illness duration were found. Our results provide the first evidence\nsuggesting a key role for structural and functional connectivity associations\nbetween DISC1 polymorphisms and the precuneus in schizophrenia.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jun 2014 11:56:14 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Gong", "Xiaohong", ""], ["Lu", "Wenlian", ""], ["Kendrick", "Keith M.", ""], ["Pu", "Weidan", ""], ["Wang", "Chu", ""], ["Jin", "Li", ""], ["Lu", "Guangmin", ""], ["Liu", "Zhening", ""], ["Liu", "Haihong", ""], ["Feng", "Jianfeng", ""]]}, {"id": "1406.1976", "submitter": "Wenlian Lu", "authors": "Y. Yao, W. L. Lu, B. Xu, C. B. Li, C. P. Lin, D. Waxman, J. F. Feng", "title": "The Increase of the Functional Entropy of the Human Brain with Age", "comments": "8 pages, 5 figures", "journal-ref": "Scientific Reports, 3:2853, 2013", "doi": "10.1038/srep02853", "report-no": null, "categories": "q-bio.QM physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use entropy to characterize intrinsic ageing properties of the human\nbrain. Analysis of fMRI data from a large dataset of individuals, using resting\nstate BOLD signals, demonstrated that a functional entropy associated with\nbrain activity increases with age. During an average lifespan, the entropy,\nwhich was calculated from a population of individuals, increased by\napproximately 0.1 bits, due to correlations in BOLD activity becoming more\nwidely distributed. We attribute this to the number of excitatory neurons and\nthe excitatory conductance decreasing with age. Incorporating these properties\ninto a computational model leads to quantitatively similar results to the fMRI\ndata. Our dataset involved males and females and we found significant\ndifferences between them. The entropy of males at birth was lower than that of\nfemales. However, the entropies of the two sexes increase at different rates,\nand intersect at approximately 50 years; after this age, males have a larger\nentropy.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jun 2014 12:03:11 GMT"}], "update_date": "2014-06-10", "authors_parsed": [["Yao", "Y.", ""], ["Lu", "W. L.", ""], ["Xu", "B.", ""], ["Li", "C. B.", ""], ["Lin", "C. P.", ""], ["Waxman", "D.", ""], ["Feng", "J. F.", ""]]}, {"id": "1406.2358", "submitter": "Sandro Sozzo", "authors": "Sandro Sozzo", "title": "Conjunction and Negation of Natural Concepts: A Quantum-theoretic\n  Modeling", "comments": "32 pages, standard latex, no figures, 16 tables. arXiv admin note:\n  text overlap with arXiv:1311.6050; and text overlap with arXiv:0805.3850 by\n  other authors", "journal-ref": "Journal of Mathematical Psychology 66, 83-102 (2015)", "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform two experiments with the aim to investigate the effects of\nnegation on the combination of natural concepts. In the first experiment, we\ntest the membership weights of a list of exemplars with respect to two\nconcepts, e.g., {\\it Fruits} and {\\it Vegetables}, and their conjunction {\\it\nFruits And Vegetables}. In the second experiment, we test the membership\nweights of the same list of exemplars with respect to the same two concepts,\nbut negating the second, e.g., {\\it Fruits} and {\\it Not Vegetables}, and again\ntheir conjunction {\\it Fruits And Not Vegetables}. The collected data confirm\nexisting results on conceptual combination, namely, they show dramatic\ndeviations from the predictions of classical (fuzzy set) logic and probability\ntheory. More precisely, they exhibit conceptual vagueness, gradeness of\nmembership, overextension and double overextension of membership weights with\nrespect to the given conjunctions. Then, we show that the quantum probability\nmodel in Fock space recently elaborated to model Hampton's data on concept\nconjunction (Hampton, 1988a) and disjunction (Hampton, 1988b) faithfully\naccords with the collected data. Our quantum-theoretic modeling enables to\ndescribe these non-classical effects in terms of genuine quantum effects,\nnamely `contextuality', `superposition', `interference' and `emergence'. The\nobtained results confirm and strenghten the analysis in Aerts (2009a) and Sozzo\n(2014) on the identification of quantum aspects in experiments on conceptual\nvagueness. Our results can be inserted within the general research on the\nidentification of quantum structures in cognitive and decision processes.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jun 2014 19:20:25 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Sozzo", "Sandro", ""]]}, {"id": "1406.2914", "submitter": "Jay Newby", "authors": "Jay Newby", "title": "Spontaneous excitability in the Morris--Lecar model with ion channel\n  noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.CB cond-mat.stat-mech math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise induced excitability is studied in type I and II Morris-Lecar neurons\nsubject to constant sub threshold input, where fluctuations arise from sodium\nand potassium ion channels. Ion channels open and close randomly, creating\ncurrent fluctuations that can induce spontaneous firing of action potentials.\nBoth noise sources are assumed to be weak so that spontaneous action potentials\noccur on a longer timescale than ion channel fluctuations. Asymptotic\napproximations of the stationary density function and most probable paths are\ndeveloped to understand the role of channel noise in spontaneous excitability.\nEven though the deterministic dynamical behavior of type I and II action\npotentials differ, results show that a single mechanism explains how ion\nchannel noise generates spontaneous action potentials.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jun 2014 14:25:26 GMT"}, {"version": "v2", "created": "Fri, 5 Sep 2014 16:07:27 GMT"}], "update_date": "2014-09-08", "authors_parsed": [["Newby", "Jay", ""]]}, {"id": "1406.3185", "submitter": "Karthik Shankar", "authors": "Karthik H. Shankar", "title": "Generic construction of scale-invariantly coarse grained memory", "comments": null, "journal-ref": "Lecture Notes in Artificial Intelligence, vol: 8955, pp: 175-184,\n  2015", "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.AI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Encoding temporal information from the recent past as spatially distributed\nactivations is essential in order for the entire recent past to be\nsimultaneously accessible. Any biological or synthetic agent that relies on the\npast to predict/plan the future, would be endowed with such a spatially\ndistributed temporal memory. Simplistically, we would expect that resource\nlimitations would demand the memory system to store only the most useful\ninformation for future prediction. For natural signals in real world which show\nscale free temporal fluctuations, the predictive information encoded in memory\nis maximal if the past information is scale invariantly coarse grained. Here we\nexamine the general mechanism to construct a scale invariantly coarse grained\nmemory system. Remarkably, the generic construction is equivalent to encoding\nthe linear combinations of Laplace transform of the past information and their\napproximated inverses. This reveals a fundamental construction constraint on\nmemory networks that attempt to maximize predictive information storage\nrelevant to the natural world.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2014 10:32:42 GMT"}, {"version": "v2", "created": "Fri, 2 Jan 2015 16:54:13 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Shankar", "Karthik H.", ""]]}, {"id": "1406.3284", "submitter": "Charles Cadieu", "authors": "Charles F. Cadieu, Ha Hong, Daniel L. K. Yamins, Nicolas Pinto, Diego\n  Ardila, Ethan A. Solomon, Najib J. Majaj, James J. DiCarlo", "title": "Deep Neural Networks Rival the Representation of Primate IT Cortex for\n  Core Visual Object Recognition", "comments": "35 pages, 12 figures, extends and expands upon arXiv:1301.3530", "journal-ref": null, "doi": "10.1371/journal.pcbi.1003963", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primate visual system achieves remarkable visual object recognition\nperformance even in brief presentations and under changes to object exemplar,\ngeometric transformations, and background variation (a.k.a. core visual object\nrecognition). This remarkable performance is mediated by the representation\nformed in inferior temporal (IT) cortex. In parallel, recent advances in\nmachine learning have led to ever higher performing models of object\nrecognition using artificial deep neural networks (DNNs). It remains unclear,\nhowever, whether the representational performance of DNNs rivals that of the\nbrain. To accurately produce such a comparison, a major difficulty has been a\nunifying metric that accounts for experimental limitations such as the amount\nof noise, the number of neural recording sites, and the number trials, and\ncomputational limitations such as the complexity of the decoding classifier and\nthe number of classifier training examples. In this work we perform a direct\ncomparison that corrects for these experimental limitations and computational\nconsiderations. As part of our methodology, we propose an extension of \"kernel\nanalysis\" that measures the generalization accuracy as a function of\nrepresentational complexity. Our evaluations show that, unlike previous\nbio-inspired models, the latest DNNs rival the representational performance of\nIT cortex on this visual object recognition task. Furthermore, we show that\nmodels that perform well on measures of representational performance also\nperform well on measures of representational similarity to IT and on measures\nof predicting individual IT multi-unit responses. Whether these DNNs rely on\ncomputational mechanisms similar to the primate visual system is yet to be\ndetermined, but, unlike all previous bio-inspired models, that possibility\ncannot be ruled out merely on representational performance grounds.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2014 16:38:07 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Cadieu", "Charles F.", ""], ["Hong", "Ha", ""], ["Yamins", "Daniel L. K.", ""], ["Pinto", "Nicolas", ""], ["Ardila", "Diego", ""], ["Solomon", "Ethan A.", ""], ["Majaj", "Najib J.", ""], ["DiCarlo", "James J.", ""]]}, {"id": "1406.3793", "submitter": "Cheston Tan", "authors": "Cheston Tan, Tomaso Poggio", "title": "Neural tuning size is a key factor underlying holistic face processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faces are a class of visual stimuli with unique significance, for a variety\nof reasons. They are ubiquitous throughout the course of a person's life, and\nface recognition is crucial for daily social interaction. Faces are also unlike\nany other stimulus class in terms of certain physical stimulus characteristics.\nFurthermore, faces have been empirically found to elicit certain characteristic\nbehavioral phenomena, which are widely held to be evidence of \"holistic\"\nprocessing of faces. However, little is known about the neural mechanisms\nunderlying such holistic face processing. In other words, for the processing of\nfaces by the primate visual system, the input and output characteristics are\nrelatively well known, but the internal neural computations are not. The main\naim of this work is to further the fundamental understanding of what causes the\nvisual processing of faces to be different from that of objects. In this\ncomputational modeling work, we show that a single factor - \"neural tuning\nsize\" - is able to account for three key phenomena that are characteristic of\nface processing, namely the Composite Face Effect (CFE), Face Inversion Effect\n(FIE) and Whole-Part Effect (WPE). Our computational proof-of-principle\nprovides specific neural tuning properties that correspond to the\npoorly-understood notion of holistic face processing, and connects these neural\nproperties to psychophysical behavior. Overall, our work provides a unified and\nparsimonious theoretical account for the disparate empirical data on\nface-specific processing, deepening the fundamental understanding of face\nprocessing.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jun 2014 03:05:07 GMT"}], "update_date": "2014-06-17", "authors_parsed": [["Tan", "Cheston", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1406.4006", "submitter": "Javier Buldu", "authors": "D. Papo, M. Zanin, J.A. Pineda-Pardo, S. Boccaletti and J.M. Buld\\'u", "title": "Functional brain networks: great expectations, hard times, and the big\n  leap forward", "comments": "12 pages, no figures. Philosophical Transactions of the Royal Society\n  B, in press", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many physical and biological systems can be studied using complex network\ntheory, a new statistical physics understanding of graph theory. The recent\napplication of complex network theory to the study of functional brain networks\ngenerated great enthusiasm as it allows addressing hitherto non-standard issues\nin the field, such as efficiency of brain functioning or vulnerability to\ndamage. However, in spite of its high degree of generality, the theory was\noriginally designed to describe systems profoundly different from the brain. We\ndiscuss some important caveats in the wholesale application of existing tools\nand concepts to a field they were not originally designed to describe. At the\nsame time, we argue that complex network theory has not yet been taken full\nadvantage of, as many of its important aspects are yet to make their appearance\nin the neuroscience literature. Finally, we propose that, rather than simply\nborrowing from an existing theory, functional neural networks can inspire a\nfundamental reformulation of complex network theory, to account for its\nexquisitely complex functioning mode.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jun 2014 13:19:38 GMT"}], "update_date": "2014-06-17", "authors_parsed": [["Papo", "D.", ""], ["Zanin", "M.", ""], ["Pineda-Pardo", "J. A.", ""], ["Boccaletti", "S.", ""], ["Buld\u00fa", "J. M.", ""]]}, {"id": "1406.4818", "submitter": "Sang-Yoon  Kim", "authors": "Sang-Yoon Kim and Woochang Lim", "title": "Noise-Induced Burst and Spike Synchronizations in An Inhibitory\n  Small-World Network of Subthreshold Bursting Neurons", "comments": "arXiv admin note: substantial text overlap with arXiv:1403.3994", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For modeling complex synaptic connectivity, we consider the Watts-Strogatz\nsmall-world network which interpolates between regular lattice and random\nnetwork via rewiring, and investigate the effect of small-world connectivity on\nemergence of noise-induced population synchronization in an inhibitory\npopulation of subthreshold bursting Hindmarsh-Rose neurons. Thus, noise-induced\nslow burst synchronization and fasg spike synchronization are found to appear\nin a synchronized region of the $J-D$ plane. As the rewiring probability $p$ is\ndecreased from 1 (random network) to 0 (regular lattice), the region of spike\nsynchronization shrinks rapidly in the $J-D$ plane, while the region of the\nburst synchronization decreases slowly. Population synchronization may be well\nvisualized in the raster plot of neural spikes which can be obtained in\nexperiments. Instantaneous population firing rate, $R(t)$, which is directly\nobtained from the raster plot of spikes, is a realistic population quantity\nexhibiting collective behaviors with both the slow bursting and the fast\nspiking timescales. Through frequency filtering, we separate $R(t)$ into\n$R_b(t)$ (describing the slow bursting behavior) and $R_s(t)$ (describing the\nfast intraburst spiking behavior). Then, we develop thermodynamic order\nparameters and statistical-mechanical measures, based on $R_b (t)$ and $R_s\n(t)$, for characterization of the burst and spike synchronizations of the\nbursting neurons and show their usefulness in explicit examples. With increase\nin $p$, both the degrees of the burst and spike synchronizations are found to\nincrease because more long-range connections appear. However, they become\nsaturated for some maximal values of $p$ because long-range short-cuts which\nappear up to the maximal values of $p$ play sufficient role to get maximal\ndegrees of the burst and spike synchronizations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jun 2014 00:55:39 GMT"}, {"version": "v2", "created": "Thu, 10 Jul 2014 05:53:34 GMT"}], "update_date": "2014-07-11", "authors_parsed": [["Kim", "Sang-Yoon", ""], ["Lim", "Woochang", ""]]}, {"id": "1406.5096", "submitter": "Anca Radulescu", "authors": "Anca Radulescu, Sergio Verduzco-Flores", "title": "Nonlinear network dynamics under perturbations of the underlying graph", "comments": "22 pages, 12 figures", "journal-ref": null, "doi": "10.1063/1.4906213", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many natural systems are organized as networks, in which the nodes (be they\ncells, individuals or populations) interact in a time-dependent fashion. The\ndynamic behavior of these networks depends on how these nodes are connected,\nwhich can be understood in terms of an adjacency matrix, and connection\nstrengths. The object of our study is to relate connectivity to temporal\nbehavior in networks of coupled nonlinear oscillators. We investigate the\nrelationship between classes of system architectures and classes of their\npossible dynamics, when the nodes are coupled according to a connectivity\nscheme that obeys certain constrains, but also incorporates random aspects.\n  We illustrate how the phase space dynamics and bifurcations of the system\nchange when perturbing the underlying adjacency graph. We differentiate between\nthe effects on dynamics of the following operations that directly modulate\nnetwork connectivity: (1) increasing/decreasing edge weights, (2)\nincreasing/decreasing edge density, (3) altering edge configuration by adding,\ndeleting or moving edges.\n  We discuss the significance of our results in the context of real life\nnetworks. Some interpretations lead us to draw conclusions that may apply to\nbrain networks, synaptic restructuring and neural dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jun 2014 16:10:44 GMT"}, {"version": "v2", "created": "Tue, 14 Oct 2014 20:29:14 GMT"}, {"version": "v3", "created": "Thu, 15 Jan 2015 01:21:08 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Radulescu", "Anca", ""], ["Verduzco-Flores", "Sergio", ""]]}, {"id": "1406.5115", "submitter": "Michael Paulin", "authors": "Michael G. Paulin, Andre van Schaik", "title": "Bayesian Inference with Spiking Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans and other animals behave as if we perform fast Bayesian inference\nunderlying decisions and movement control given uncertain sense data. Here we\nshow that a biophysically realistic model of the subthreshold membrane\npotential of a single neuron can exactly compute the numerator in Bayes rule\nfor inferring the Poisson parameter of a sensory spike train. A simple network\nof spiking neurons can construct and represent the Bayesian posterior density\nof a parameter of an external cause that affects the Poisson parameter,\naccurately and in real time.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jun 2014 17:09:11 GMT"}], "update_date": "2014-06-20", "authors_parsed": [["Paulin", "Michael G.", ""], ["van Schaik", "Andre", ""]]}, {"id": "1406.5197", "submitter": "Danielle Bassett", "authors": "Shi Gu, Fabio Pasqualetti, Matthew Cieslak, Scott T. Grafton, Danielle\n  S. Bassett", "title": "Controllability of Brain Networks", "comments": "14 pages, 4 figures, supplementary materials", "journal-ref": null, "doi": "10.1038/ncomms9414", "report-no": null, "categories": "q-bio.NC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive function is driven by dynamic interactions between large-scale\nneural circuits or networks, enabling behavior. Fundamental principles\nconstraining these dynamic network processes have remained elusive. Here we use\nnetwork control theory to offer a mechanistic explanation for how the brain\nmoves between cognitive states drawn from the network organization of white\nmatter microstructure. Our results suggest that densely connected areas,\nparticularly in the default mode system, facilitate the movement of the brain\nto many easily-reachable states. Weakly connected areas, particularly in\ncognitive control systems, facilitate the movement of the brain to\ndifficult-to-reach states. Areas located on the boundary between network\ncommunities, particularly in attentional control systems, facilitate the\nintegration or segregation of diverse cognitive systems. Our results suggest\nthat structural network differences between the cognitive circuits dictate\ntheir distinct roles in controlling dynamic trajectories of brain network\nfunction.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jun 2014 20:05:48 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Gu", "Shi", ""], ["Pasqualetti", "Fabio", ""], ["Cieslak", "Matthew", ""], ["Grafton", "Scott T.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1406.5807", "submitter": "Peilei Liu", "authors": "Peilei Liu and Ting Wang", "title": "A Unified Quantitative Model of Vision and Audition", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have put forwards a unified quantitative framework of vision and audition,\nbased on existing data and theories. According to this model, the retina is a\nfeedforward network self-adaptive to inputs in a specific period. After fully\ngrown, cells become specialized detectors based on statistics of stimulus\nhistory. This model has provided explanations for perception mechanisms of\ncolour, shape, depth and motion. Moreover, based on this ground we have put\nforwards a bold conjecture that single ear can detect sound direction. This is\ncomplementary to existing theories and has provided better explanations for\nsound localization.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jun 2014 05:00:31 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Liu", "Peilei", ""], ["Wang", "Ting", ""]]}, {"id": "1406.6045", "submitter": "Emanuel Diamant", "authors": "Emanuel Diamant", "title": "Cognitive Surveillance: Why does it never appear among the AVSS\n  Conferences topics?", "comments": "The paper was submitted to the 11th IEEE International Conference on\n  Advanced Video Signal-Based Surveillance (AVSS2014, August 26-29, 2014,\n  Seoul, Korea) and has not been accepted for presentation at the conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video Surveillance is a fast evolving field of research and development (R&D)\ndriven by the urgent need for public security and safety (due to the growing\nthreats of terrorism, vandalism, and anti-social behavior). Traditionally,\nsurveillance systems are comprised of two components - video cameras\ndistributed over the guarded area and human observer watching and analyzing the\nincoming video. Explosive growth of installed cameras and limited human\noperator's ability to process the delivered video content raise an urgent\ndemand for developing surveillance systems with human like cognitive\ncapabilities, that is - Cognitive surveillance systems. The growing interest in\nthis issue is testified by the tens of workshops, symposiums and conferences\nheld over the world each year. The IEEE International Conference on Advanced\nVideo and Signal-Based Surveillance (AVSS) is certainly one of them. However,\nfor unknown reasons, the term Cognitive Surveillance does never appear among\nits topics. As to me, the explanation for this is simple - the complexity and\nthe indefinable nature of the term \"Cognition\". In this paper, I am trying to\nresolve the problem providing a novel definition of cognition equally suitable\nfor biological as well as technological applications. I hope my humble efforts\nwill be helpful.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jun 2014 14:14:13 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Diamant", "Emanuel", ""]]}, {"id": "1406.6453", "submitter": "Peilei Liu", "authors": "Peilei Liu and Ting Wang", "title": "A Quantitative Neural Coding Model of Sensory Memory", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The coding mechanism of sensory memory on the neuron scale is one of the most\nimportant questions in neuroscience. We have put forward a quantitative neural\nnetwork model, which is self organized, self similar, and self adaptive, just\nlike an ecosystem following Darwin theory. According to this model, neural\ncoding is a mult to one mapping from objects to neurons. And the whole cerebrum\nis a real-time statistical Turing Machine, with powerful representing and\nlearning ability. This model can reconcile some important disputations, such\nas: temporal coding versus rate based coding, grandmother cell versus\npopulation coding, and decay theory versus interference theory. And it has also\nprovided explanations for some key questions such as memory consolidation,\nepisodic memory, consciousness, and sentiment. Philosophical significance is\nindicated at last.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jun 2014 04:17:21 GMT"}], "update_date": "2014-06-26", "authors_parsed": [["Liu", "Peilei", ""], ["Wang", "Ting", ""]]}, {"id": "1406.6901", "submitter": "Alexey Redozubov", "authors": "Alexey Redozubov", "title": "Pattern-wave model of brain. Mechanisms of information processing,\n  memory organization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The structure of the axon-dendrite connections of neurons of the brain\ncreates a rich spatial structure in which provided various combinations of\nsignals surrounding neurons. Structure of dendritic trees and shape of\ndendritic spines allow repeatedly increase combinatorial component through\ncross synapses influence neighboring neurons. In this paper it is shown that\nthe diffuse spreading of neurotransmitters allows neurons to detect and\nremember significant set of environmental activity patterns. As a core element\nfixation described extrasynaptic metabotropic receptive clusters. The described\nmechanism leads to the appearance of wave processes, based on the propagation\nof the front-line areas of spontaneous activity. In the proposed model, any\ncompact pattern of neural activity is seen as a source emitting a diverging\nwave endogenous spikes. It is shown that the spike pattern of the wave front is\nstrictly unique and uniquely defined pattern that started the wave. The\npropagation of waves with a unique pattern allows anywhere in nature undergoing\nbrain wave patterns there to judge the whole brain processes information. In\nthese assumptions naturally described mechanism of projection information\nbetween regions of the cortex. Performed computer simulations show the high\neffectiveness of such information model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jun 2014 14:38:38 GMT"}, {"version": "v2", "created": "Thu, 24 Jul 2014 09:00:07 GMT"}], "update_date": "2014-07-25", "authors_parsed": [["Redozubov", "Alexey", ""]]}, {"id": "1406.7179", "submitter": "Alex Susemihl", "authors": "Alex Susemihl, Ron Meir, Manfred Opper", "title": "Optimal Population Codes for Control and Estimation", "comments": "9 Pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents acting in the natural world aim at selecting appropriate actions based\non noisy and partial sensory observations. Many behaviors leading to decision\nmak- ing and action selection in a closed loop setting are naturally phrased\nwithin a control theoretic framework. Within the framework of optimal Control\nTheory, one is usually given a cost function which is minimized by selecting a\ncontrol law based on the observations. While in standard control settings the\nsensors are assumed fixed, biological systems often gain from the extra\nflexibility of optimiz- ing the sensors themselves. However, this sensory\nadaptation is geared towards control rather than perception, as is often\nassumed. In this work we show that sen- sory adaptation for control differs\nfrom sensory adaptation for perception, even for simple control setups. This\nimplies, consistently with recent experimental results, that when studying\nsensory adaptation, it is essential to account for the task being performed.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jun 2014 13:46:05 GMT"}], "update_date": "2014-06-30", "authors_parsed": [["Susemihl", "Alex", ""], ["Meir", "Ron", ""], ["Opper", "Manfred", ""]]}, {"id": "1406.7185", "submitter": "Marijn van Dongen", "authors": "M.N. van Dongen and F.E. Hoebeek and S.K.E. Koekkoek and C.I. De Zeeuw\n  and W.A. Serdijn", "title": "Efficacy of high frequency switched-mode stimulation in activating\n  Purkinje cells", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the efficacy of high frequency switched-mode neural\nstimulation. Instead of using a constant stimulation amplitude, the stimulus is\nswitched on and off repeatedly with a high frequency (up to 100kHz) duty cycled\nsignal. By means of tissue modeling that includes the dynamic properties of\nboth the tissue material as well as the axon membrane, it is first shown that\nswitched-mode stimulation depolarizes the cell membrane in a similar way as\nclassical constant amplitude stimulation. These findings are subsequently\nverified using in vitro experiments in which the response of a Purkinje cell is\nmeasured due to a stimulation signal in the molecular layer of the cerebellum\nof a mouse. For this purpose a stimulator circuit is developed that is able to\nproduce a monophasic high frequency switched-mode stimulation signal. The\nresults confirm the modeling by showing that switched-mode stimulation is able\nto induce similar responses in the Purkinje cell as classical stimulation using\na constant current source. This conclusion opens up possibilities for novel\nstimulation designs that can improve the performance of the stimulator\ncircuitry. Care has to be taken to avoid losses in the system due to the higher\noperating frequency.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jun 2014 14:04:03 GMT"}], "update_date": "2014-06-30", "authors_parsed": [["van Dongen", "M. N.", ""], ["Hoebeek", "F. E.", ""], ["Koekkoek", "S. K. E.", ""], ["De Zeeuw", "C. I.", ""], ["Serdijn", "W. A.", ""]]}, {"id": "1406.7391", "submitter": "Fabrizio De Vico Fallani", "authors": "Fabrizio De Vico Fallani, Jonas Richiardi, Mario Chavez, Sophie Achard", "title": "Graph analysis of functional brain networks: practical issues in\n  translational neuroscience", "comments": null, "journal-ref": null, "doi": "10.1098/rstb.2013.0521", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain can be regarded as a network: a connected system where nodes, or\nunits, represent different specialized regions and links, or connections,\nrepresent communication pathways. From a functional perspective communication\nis coded by temporal dependence between the activities of different brain\nareas. In the last decade, the abstract representation of the brain as a graph\nhas allowed to visualize functional brain networks and describe their\nnon-trivial topological properties in a compact and objective way. Nowadays,\nthe use of graph analysis in translational neuroscience has become essential to\nquantify brain dysfunctions in terms of aberrant reconfiguration of functional\nbrain networks. Despite its evident impact, graph analysis of functional brain\nnetworks is not a simple toolbox that can be blindly applied to brain signals.\nOn the one hand, it requires a know-how of all the methodological steps of the\nprocessing pipeline that manipulates the input brain signals and extract the\nfunctional network properties. On the other hand, a knowledge of the neural\nphenomenon under study is required to perform physiological-relevant analysis.\nThe aim of this review is to provide practical indications to make sense of\nbrain network analysis and contrast counterproductive attitudes.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jun 2014 11:51:07 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Fallani", "Fabrizio De Vico", ""], ["Richiardi", "Jonas", ""], ["Chavez", "Mario", ""], ["Achard", "Sophie", ""]]}]