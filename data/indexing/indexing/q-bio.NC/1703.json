[{"id": "1703.00091", "submitter": "Jean Daunizeau", "authors": "Jean Daunizeau", "title": "Semi-analytical approximations to statistical moments of sigmoid and\n  softmax mappings of normal variables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note is concerned with accurate and computationally efficient\napproximations of moments of Gaussian random variables passed through sigmoid\nor softmax mappings. These approximations are semi-analytical (i.e. they\ninvolve the numerical adjustment of parametric forms) and highly accurate (they\nyield 5% error at most). We also highlight a few niche applications of these\napproximations, which arise in the context of, e.g., drift-diffusion models of\ndecision making or non-parametric data clustering approaches. We provide these\nas examples of efficient alternatives to more tedious derivations that would be\nneeded if one was to approach the underlying mathematical issues in a more\nformal way. We hope that this technical note will be helpful to modellers\nfacing similar mathematical issues, although maybe stemming from different\nacademic prospects.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 00:01:04 GMT"}, {"version": "v2", "created": "Fri, 3 Mar 2017 08:55:29 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Daunizeau", "Jean", ""]]}, {"id": "1703.00223", "submitter": "Nithin Nagaraj", "authors": "Indranil Mukhopadhyay, Nithin Nagaraj, Sisir Roy", "title": "New Empirical Evidence on Disjunction Effect and Cultural Dependence", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We perform new experiment using almost the same sample size considered by\nTversky and Shafir to test the validity of classical probability theory in\ndecision making. The results clearly indicate that the disjunction effect\ndepends also on culture and more specifically on gender (females rather than\nmales). We did more statistical analysis rather that putting the actual values\ndone by previous authors. We propose different kind of disjunction effect i.e.\nstrong and weak based on our statistical analysis.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 10:48:45 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Mukhopadhyay", "Indranil", ""], ["Nagaraj", "Nithin", ""], ["Roy", "Sisir", ""]]}, {"id": "1703.00698", "submitter": "Alain Destexhe", "authors": "Yann Zerlaut and Alain Destexhe", "title": "A mean-field model for conductance-based networks of adaptive\n  exponential integrate-and-fire neurons", "comments": "21 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voltage-sensitive dye imaging (VSDi) has revealed fundamental properties of\nneocortical processing at mesoscopic scales. Since VSDi signals report the\naverage membrane potential, it seems natural to use a mean-field formalism to\nmodel such signals. Here, we investigate a mean-field model of networks of\nAdaptive Exponential (AdEx) integrate-and-fire neurons, with conductance-based\nsynaptic interactions. The AdEx model can capture the spiking response of\ndifferent cell types, such as regular-spiking (RS) excitatory neurons and\nfast-spiking (FS) inhibitory neurons. We use a Master Equation formalism,\ntogether with a semi-analytic approach to the transfer function of AdEx\nneurons. We compare the predictions of this mean-field model to simulated\nnetworks of RS-FS cells, first at the level of the spontaneous activity of the\nnetwork, which is well predicted by the mean-field model. Second, we\ninvestigate the response of the network to time-varying external input, and\nshow that the mean-field model accurately predicts the response time course of\nthe population. One notable exception was that the \"tail\" of the response at\nlong times was not well predicted, because the mean-field does not include\nadaptation mechanisms. We conclude that the Master Equation formalism can yield\nmean-field models that predict well the behavior of nonlinear networks with\nconductance-based interactions and various electrophysiolgical properties, and\nshould be a good candidate to model VSDi signals where both excitatory and\ninhibitory neurons contribute.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 10:19:17 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Zerlaut", "Yann", ""], ["Destexhe", "Alain", ""]]}, {"id": "1703.00981", "submitter": "Daniel Moyer", "authors": "Daniel Moyer, Boris A Gutman, Neda Jahanshad, Paul M. Thompson", "title": "A Restaurant Process Mixture Model for Connectivity Based Parcellation\n  of the Cortex", "comments": "In the Proceedings of Information Processing in Medical Imaging 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CE cs.CV q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the primary objectives of human brain mapping is the division of the\ncortical surface into functionally distinct regions, i.e. parcellation. While\nit is generally agreed that at macro-scale different regions of the cortex have\ndifferent functions, the exact number and configuration of these regions is not\nknown. Methods for the discovery of these regions are thus important,\nparticularly as the volume of available information grows. Towards this end, we\npresent a parcellation method based on a Bayesian non-parametric mixture model\nof cortical connectivity.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 23:03:56 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Moyer", "Daniel", ""], ["Gutman", "Boris A", ""], ["Jahanshad", "Neda", ""], ["Thompson", "Paul M.", ""]]}, {"id": "1703.01357", "submitter": "Peter Helfer", "authors": "Peter Helfer and Thomas R. Shultz", "title": "A Computational Model of Systems Memory Consolidation and\n  Reconsolidation", "comments": null, "journal-ref": "Hippocampus, 30, (2020) 659-677", "doi": "10.1002/hipo.23187", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the mammalian brain, newly acquired memories depend on the hippocampus for\nmaintenance and recall, but over time the neocortex takes over these functions,\nrendering memories hippocampus-independent. The process responsible for this\ntransformation is called systems memory consolidation. However, reactivation of\na well-consolidated memory can trigger a temporary return to a\nhippocampus-dependent state, a phenomenon known as systems memory\nreconsolidation. The neural mechanisms underlying systems memory consolidation\nand reconsolidation are not well understood. Here, we propose a neural model\nbased on well-documented mechanisms of synaptic plasticity and stability and\ndescribe a computational implementation that demonstrates the model's ability\nto account for a range of findings from the systems consolidation and\nreconsolidation literature. We derive several predictions from the\ncomputational model and suggest experiments that may test its validity.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 23:21:23 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 18:22:45 GMT"}, {"version": "v3", "created": "Sat, 12 Aug 2017 22:06:35 GMT"}, {"version": "v4", "created": "Thu, 28 Mar 2019 15:14:41 GMT"}, {"version": "v5", "created": "Fri, 7 Jun 2019 21:14:08 GMT"}, {"version": "v6", "created": "Wed, 17 Jul 2019 17:24:50 GMT"}, {"version": "v7", "created": "Fri, 27 Sep 2019 21:22:14 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Helfer", "Peter", ""], ["Shultz", "Thomas R.", ""]]}, {"id": "1703.01842", "submitter": "Mathilde M\\'enoret", "authors": "Mathilde M\\'enoret, Nicolas Farrugia, Bastien Pasdeloup and Vincent\n  Gripon", "title": "Evaluating Graph Signal Processing for Neuroimaging Through\n  Classification and Dimensionality Reduction", "comments": "5 pages, GlobalSIP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Signal Processing (GSP) is a promising framework to analyze\nmulti-dimensional neuroimaging datasets, while taking into account both the\nspatial and functional dependencies between brain signals. In the present work,\nwe apply dimensionality reduction techniques based on graph representations of\nthe brain to decode brain activity from real and simulated fMRI datasets. We\nintroduce seven graphs obtained from a) geometric structure and/or b)\nfunctional connectivity between brain areas at rest, and compare them when\nperforming dimension reduction for classification. We show that mixed graphs\nusing both a) and b) offer the best performance. We also show that graph\nsampling methods perform better than classical dimension reduction including\nPrincipal Component Analysis (PCA) and Independent Component Analysis (ICA).\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 12:45:39 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 08:40:56 GMT"}, {"version": "v3", "created": "Mon, 28 Aug 2017 12:41:28 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["M\u00e9noret", "Mathilde", ""], ["Farrugia", "Nicolas", ""], ["Pasdeloup", "Bastien", ""], ["Gripon", "Vincent", ""]]}, {"id": "1703.01999", "submitter": "Quico Spaen", "authors": "Quico Spaen, Dorit S. Hochbaum, Roberto As\\'in-Ach\\'a", "title": "HNCcorr: A Novel Combinatorial Approach for Cell Identification in\n  Calcium-Imaging Movies", "comments": null, "journal-ref": null, "doi": "10.1523/ENEURO.0304-18.2019", "report-no": null, "categories": "q-bio.QM math.OC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calcium imaging has emerged as a workhorse method in neuroscience to\ninvestigate patterns of neuronal activity. Instrumentation to acquire calcium\nimaging movies has rapidly progressed and has become standard across labs.\nStill, algorithms to automatically detect and extract activity signals from\ncalcium imaging movies are highly variable from~lab~to~lab and more advanced\nalgorithms are continuously being developed. Here we present HNCcorr, a novel\nalgorithm for cell identification in calcium imaging movies based on\ncombinatorial optimization. The algorithm identifies cells by finding distinct\ngroups of highly similar pixels in correlation space, where a pixel is\nrepresented by the vector of correlations to a set of other pixels. The HNCcorr\nalgorithm achieves the best known results for the cell identification benchmark\nof Neurofinder, and guarantees an optimal solution to the underlying\ndeterministic optimization model resulting in a transparent mapping from input\ndata to outcome.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 17:42:25 GMT"}], "update_date": "2019-06-03", "authors_parsed": [["Spaen", "Quico", ""], ["Hochbaum", "Dorit S.", ""], ["As\u00edn-Ach\u00e1", "Roberto", ""]]}, {"id": "1703.02036", "submitter": "Jakob Wasserthal", "authors": "Jakob Wasserthal, Peter F. Neher, Fabian Isensee, Klaus H. Maier-Hein", "title": "Direct White Matter Bundle Segmentation using Stacked U-Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art method for automatically segmenting white matter bundles\nin diffusion-weighted MRI is tractography in conjunction with streamline\ncluster selection. This process involves long chains of processing steps which\nare not only computationally expensive but also complex to setup and tedious\nwith respect to quality control. Direct bundle segmentation methods treat the\ntask as a traditional image segmentation problem. While they so far did not\ndeliver competitive results, they can potentially mitigate many of the\nmentioned issues. We present a novel supervised approach for direct tract\nsegmentation that shows major performance gains. It builds upon a stacked U-Net\narchitecture which is trained on manual bundle segmentations from Human\nConnectome Project subjects. We evaluate our approach \\textit{in vivo} as well\nas \\textit{in silico} using the ISMRM 2015 Tractography Challenge phantom\ndataset. We achieve human segmentation performance and a major performance gain\nover previous pipelines. We show how the learned spatial priors efficiently\nguide the segmentation even at lower image qualities with little quality loss.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 14:21:49 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Wasserthal", "Jakob", ""], ["Neher", "Peter F.", ""], ["Isensee", "Fabian", ""], ["Maier-Hein", "Klaus H.", ""]]}, {"id": "1703.02089", "submitter": "Jean Daunizeau", "authors": "Jean Daunizeau", "title": "The variational Laplace approach to approximate Bayesian inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational approaches to approximate Bayesian inference provide very\nefficient means of performing parameter estimation and model selection. Among\nthese, so-called variational-Laplace or VL schemes rely on Gaussian\napproximations to posterior densities on model parameters. In this note, we\nreview the main variants of VL approaches, that follow from considering\nnonlinear models of continuous and/or categorical data. En passant, we also\nderive a few novel theoretical results that complete the portfolio of existing\nanalyses of variational Bayesian approaches, including investigations of their\nasymptotic convergence. We also suggest practical ways of extending existing VL\napproaches to hierarchical generative models that include (e.g., precision)\nhyperparameters.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 11:02:22 GMT"}, {"version": "v2", "created": "Tue, 16 Jan 2018 17:45:14 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Daunizeau", "Jean", ""]]}, {"id": "1703.02245", "submitter": "Nima Dehghani", "authors": "Nima Dehghani", "title": "Design of the Artificial: lessons from the biological roots of general\n  intelligence", "comments": "Theoretical perspective on AGI (Artificial General Intelligence)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our desire and fascination with intelligent machines dates back to the\nantiquity's mythical automaton Talos, Aristotle's mode of mechanical thought\n(syllogism) and Heron of Alexandria's mechanical machines and automata.\nHowever, the quest for Artificial General Intelligence (AGI) is troubled with\nrepeated failures of strategies and approaches throughout the history. This\ndecade has seen a shift in interest towards bio-inspired software and hardware,\nwith the assumption that such mimicry entails intelligence. Though these steps\nare fruitful in certain directions and have advanced automation, their singular\ndesign focus renders them highly inefficient in achieving AGI. Which set of\nrequirements have to be met in the design of AGI? What are the limits in the\ndesign of the artificial? Here, a careful examination of computation in\nbiological systems hints that evolutionary tinkering of contextual processing\nof information enabled by a hierarchical architecture is the key to build AGI.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 07:20:30 GMT"}, {"version": "v2", "created": "Wed, 8 Mar 2017 15:29:05 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Dehghani", "Nima", ""]]}, {"id": "1703.02386", "submitter": "Wen Jiang", "authors": "Zichang He and Wen Jiang", "title": "A quantum dynamic belief decision making model", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sure thing principle and the law of total probability are basic laws in\nclassic probability theory. A disjunction fallacy leads to the violation of\nthese two classical probability laws. In this paper, a new quantum dynamic\nbelief decision making model based on quantum dynamic modelling and\nDempster-Shafer (D-S) evidence theory is proposed to address this issue and\nmodel the real human decision-making process. Some mathematical techniques are\nborrowed from quantum mathematics. Generally, belief and action are two parts\nin a decision making process. The uncertainty in belief part is represented by\na superposition of certain states. The uncertainty in actions is represented as\nan extra uncertainty state. The interference effect is produced due to the\nentanglement between beliefs and actions. Basic probability assignment (BPA) of\ndecisions is generated by quantum dynamic modelling. Then BPA of the extra\nuncertain state and an entanglement degree defined by an entropy function named\nDeng entropy are used to measure the interference effect. Compared the existing\nmodel, the number of free parameters is less in our model. Finally, a classical\ncategorization decision-making experiment is illustrated to show the\neffectiveness of our model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 15:30:08 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["He", "Zichang", ""], ["Jiang", "Wen", ""]]}, {"id": "1703.02564", "submitter": "Pablo Piedrahita", "authors": "P. Piedrahita, J.J. Mazo, L.M. Flor\\'ia, Y. Moreno", "title": "Pulse-coupled model of excitable elements on heterogeneous sparse\n  networks", "comments": "Working paper, 13 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a pulse-coupled dynamics of excitable elements in uncorrelated\nscale-free networks. Regimes of self-sustained activity are found for\nhomogeneous and inhomogeneous couplings, in which the system displays a wide\nvariety of behaviors, including periodic and irregular global spiking signals,\nas well as coherent oscillations, an unexpected form of synchronization. Our\nnumerical results also show that the properties of the population firing rate\ndepend on the size of the system, particularly its structure and average value\nover time. However, a few straightforward dynamical and topological strategies\ncan be introduced to enhance or hinder these global behaviors, rendering a\nscenario where signal control is attainable, which incorporates a basic\nmechanism to turn off the dynamics permanently. As our main result, here we\npresent a framework to estimate, in the stationary state, the mean firing rate\nover a long time window and to decompose the global dynamics into average\nvalues of the inter-spike-interval of each connectivity group. Our approach\nprovides accurate predictions of these average quantities when the network\nexhibits high heterogeneity, a remarkable finding that is not restricted\nexclusively to the scale-free topology.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 19:30:05 GMT"}, {"version": "v2", "created": "Thu, 9 Mar 2017 17:29:23 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Piedrahita", "P.", ""], ["Mazo", "J. J.", ""], ["Flor\u00eda", "L. M.", ""], ["Moreno", "Y.", ""]]}, {"id": "1703.03030", "submitter": "Gustav Markkula", "authors": "Gustav Markkula, Erwin Boer, Richard Romano, Natasha Merat", "title": "Sustained sensorimotor control as intermittent decisions about\n  prediction errors: Computational framework and application to ground vehicle\n  steering", "comments": null, "journal-ref": null, "doi": "10.1007/s00422-017-0743-9", "report-no": null, "categories": "q-bio.NC cs.CE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A conceptual and computational framework is proposed for modelling of human\nsensorimotor control, and is exemplified for the sensorimotor task of steering\na car. The framework emphasises control intermittency, and extends on existing\nmodels by suggesting that the nervous system implements intermittent control\nusing a combination of (1) motor primitives, (2) prediction of sensory outcomes\nof motor actions, and (3) evidence accumulation of prediction errors. It is\nshown that approximate but useful sensory predictions in the intermittent\ncontrol context can be constructed without detailed forward models, as a\nsuperposition of simple prediction primitives, resembling neurobiologically\nobserved corollary discharges. The proposed mathematical framework allows\nstraightforward extension to intermittent behaviour from existing\none-dimensional continuous models in the linear control and ecological\npsychology traditions. Empirical observations from a driving simulator provide\nsupport for some of the framework assumptions: It is shown that human steering\ncontrol, in routine lane-keeping and in a demanding near-limit task, is better\ndescribed as a sequence of discrete stepwise steering adjustments, than as\ncontinuous control. Furthermore, the amplitudes of individual steering\nadjustments are well predicted by a compound visual cue signalling steering\nerror, and even better so if also adjusting for predictions of how the same cue\nis affected by previous control. Finally, evidence accumulation is shown to\nexplain observed covariability between inter-adjustment durations and\nadjustment amplitudes, seemingly better so than the type of threshold\nmechanisms that are typically assumed in existing models of intermittent\ncontrol.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 20:56:04 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Markkula", "Gustav", ""], ["Boer", "Erwin", ""], ["Romano", "Richard", ""], ["Merat", "Natasha", ""]]}, {"id": "1703.03065", "submitter": "Elad Schneidman", "authors": "Roy Harpaz, Ga\\v{s}per Tka\\v{c}ik, Elad Schneidman", "title": "Discrete modes of social information processing predict individual\n  behavior of fish in a group", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individual computations and social interactions underlying collective\nbehavior in groups of animals are of great ethological, behavioral, and\ntheoretical interest. While complex individual behaviors have successfully been\nparsed into small dictionaries of stereotyped behavioral modes, studies of\ncollective behavior largely ignored these findings; instead, their focus was on\ninferring single, mode-independent social interaction rules that reproduced\nmacroscopic and often qualitative features of group behavior. Here we bring\nthese two approaches together to predict individual swimming patterns of adult\nzebrafish in a group. We show that fish alternate between an active mode in\nwhich they are sensitive to the swimming patterns of conspecifics, and a\npassive mode where they ignore them. Using a model that accounts for these two\nmodes explicitly, we predict behaviors of individual fish with high accuracy,\noutperforming previous approaches that assumed a single continuous computation\nby individuals and simple metric or topological weighing of neighbors behavior.\nAt the group level, switching between active and passive modes is uncorrelated\namong fish, yet correlated directional swimming behavior still emerges. Our\nquantitative approach for studying complex, multi-modal individual behavior\njointly with emergent group behavior is readily extensible to additional\nbehavioral modes and their neural correlates, as well as to other species.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 22:55:45 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Harpaz", "Roy", ""], ["Tka\u010dik", "Ga\u0161per", ""], ["Schneidman", "Elad", ""]]}, {"id": "1703.03132", "submitter": "Gabriel Ocker", "authors": "Gabriel Koch Ocker and Yu Hu, Michael A. Buice, Brent Doiron,\n  Kre\\v{s}imir Josi\\'c, Robert Rosenbaum, Eric Shea-Brown", "title": "From the statistics of connectivity to the statistics of spike times in\n  neuronal networks", "comments": "review article", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential step toward understanding neural circuits is linking their\nstructure and their dynamics. In general, this relationship can be almost\narbitrarily complex. Recent theoretical work has, however, begun to identify\nsome broad principles underlying collective spiking activity in neural\ncircuits. The first is that local features of network connectivity can be\nsurprisingly effective in predicting global statistics of activity across a\nnetwork. The second is that, for the important case of large networks with\nexcitatory-inhibitory balance, correlated spiking persists or vanishes\ndepending on the spatial scales of recurrent and feedforward connectivity. We\nclose by showing how these ideas, together with plasticity rules, can help to\nclose the loop between network structure and activity statistics.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 04:47:45 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Ocker", "Gabriel Koch", ""], ["Hu", "Yu", ""], ["Buice", "Michael A.", ""], ["Doiron", "Brent", ""], ["Josi\u0107", "Kre\u0161imir", ""], ["Rosenbaum", "Robert", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1703.03442", "submitter": "Vanessa Ferdinand PhD", "authors": "Vanessa Ferdinand, Simon Kirby, Kenny Smith", "title": "The cognitive roots of regularization in language", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regularization occurs when the output a learner produces is less variable\nthan the linguistic data they observed. In an artificial language learning\nexperiment, we show that there exist at least two independent sources of\nregularization bias in cognition: a domain-general source based on cognitive\nload and a domain-specific source triggered by linguistic stimuli. Both of\nthese factors modulate how frequency information is encoded and produced, but\nonly the production-side modulations result in regularization (i.e. cause\nlearners to eliminate variation from the observed input). We formalize the\ndefinition of regularization as the reduction of entropy and find that entropy\nmeasures are better at identifying regularization behavior than frequency-based\nanalyses. Using our experimental data and a model of cultural transmission, we\ngenerate predictions for the amount of regularity that would develop in each\nexperimental condition if the artificial language were transmitted over several\ngenerations of learners. Here we find that the effect of cognitive constraints\ncan become more complex when put into the context of cultural evolution:\nalthough learning biases certainly carry information about the course of\nlanguage evolution, we should not expect a one-to-one correspondence between\nthe micro-level processes that regularize linguistic datasets and the\nmacro-level evolution of linguistic regularity.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 19:50:00 GMT"}, {"version": "v2", "created": "Thu, 18 Oct 2018 21:33:46 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Ferdinand", "Vanessa", ""], ["Kirby", "Simon", ""], ["Smith", "Kenny", ""]]}, {"id": "1703.03444", "submitter": "Fernanda Matias", "authors": "Fernanda S. Matias, Pedro V. Carelli, Claudio R. Mirasso, Mauro\n  Copelli", "title": "Anticipated synchronization in neuronal circuits unveiled by a\n  phase-resetting curve analysis", "comments": null, "journal-ref": "Phys. Rev. E 95, 052410 (2017)", "doi": "10.1103/PhysRevE.95.052410", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anticipated synchronization (AS) is a counter intuitive behavior that has\nbeen observed in several systems. When AS establishes in a sender-receiver\nconfiguration, the latter can predict the future dynamics of the former for\ncertain parameter values. In particular, in neuroscience AS was proposed to\nexplain the apparent discrepancy between information flow and time lag in the\ncortical activity recorded in monkeys. Despite its success, a clear\nunderstanding on the mechanisms yielding AS in neuronal circuits is still\nmissing. Here we use the well-known phase-resetting-curve (PRC) approach to\nstudy the prototypical sender-receiver-interneuron neuronal motif. Our aim is\nto better understand how the transitions between delayed to anticipated\nsynchronization and anticipated synchronization to phase-drift regimes occur.\nWe construct a map based on the PRC method to predict the phase-locking regimes\nand their stability. We find that a PRC function of two variables, accounting\nsimultaneously for the inputs from sender and interneuron into the receiver, is\nessential to reproduce the numerical results obtained using a Hodgkin-Huxley\nmodel for the neurons. On the contrary, the typical approximation that\nconsiders a sum of two independent single-variable PRCs fails for intermediate\nto high values of the inhibitory connectivity between interneuron. In\nparticular, it looses the delayed-synchronization to\nanticipated-synchronization transition.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 19:58:42 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Matias", "Fernanda S.", ""], ["Carelli", "Pedro V.", ""], ["Mirasso", "Claudio R.", ""], ["Copelli", "Mauro", ""]]}, {"id": "1703.03560", "submitter": "Wenyuan Li", "authors": "Wenyuan Li, Igor V. Ovchinnikov, Honglin Chen, Zhe Wang, Albert Lee,\n  Hochul Lee, Carlos Cepeda, Robert N. Schwartz, Karlheinz Meier and Kang L.\n  Wang", "title": "A neuronal dynamics study on a neuromorphic chip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal firing activities have attracted a lot of attention since a large\npopulation of spatiotemporal patterns in the brain is the basis for adaptive\nbehavior and can also reveal the signs for various neurological disorders\nincluding Alzheimer's, schizophrenia, epilepsy and others. Here, we study the\ndynamics of a simple neuronal network using different sets of settings on a\nneuromorphic chip. We observed three different types of collective neuronal\nfiring activities, which agree with the clinical data taken from the brain. We\nconstructed a brain phase diagram and showed that within the weak noise region,\nthe brain is operating in an expected noise-induced phase (N-phase) rather than\nat a so-called self-organized critical boundary. The significance of this study\nis twofold: first, the deviation of neuronal activities from the normal brain\ncould be symptomatic of diseases of the central nervous system, thus paving the\nway for new diagnostics and treatments; second, the normal brain states in the\nN-phase are optimal for computation and information processing. The latter may\nprovide a way to establish powerful new computing paradigm using collective\nbehavior of networks of spiking neurons.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 07:24:01 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Li", "Wenyuan", ""], ["Ovchinnikov", "Igor V.", ""], ["Chen", "Honglin", ""], ["Wang", "Zhe", ""], ["Lee", "Albert", ""], ["Lee", "Hochul", ""], ["Cepeda", "Carlos", ""], ["Schwartz", "Robert N.", ""], ["Meier", "Karlheinz", ""], ["Wang", "Kang L.", ""]]}, {"id": "1703.03777", "submitter": "Wieland Brendel", "authors": "Wieland Brendel, Ralph Bourdoukan, Pietro Vertechi, Christian K.\n  Machens, Sophie Den\\'eve", "title": "Learning to represent signals spike by spike", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key question in neuroscience is at which level functional meaning emerges\nfrom biophysical phenomena. In most vertebrate systems, precise functions are\nassigned at the level of neural populations, while single-neurons are deemed\nunreliable and redundant. Here we challenge this view and show that many\nsingle-neuron quantities, including voltages, firing thresholds, excitation,\ninhibition, and spikes, acquire precise functional meaning whenever a network\nlearns to transmit information parsimoniously and precisely to the next layer.\nBased on the hypothesis that neural circuits generate precise population codes\nunder severe constraints on metabolic costs, we derive synaptic plasticity\nrules that allow a network to represent its time-varying inputs with maximal\naccuracy. We provide exact solutions to the learnt optimal states, and we\npredict the properties of an entire network from its input distribution and the\ncost of activity. Single-neuron variability and tuning curves as typically\nobserved in cortex emerge over the course of learning, but paradoxically\ncoincide with a precise, non-redundant spike-based population code. Our work\nsuggests that neural circuits operate far more accurately than previously\nthought, and that no spike is fired in vain.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 17:41:36 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 15:59:59 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Brendel", "Wieland", ""], ["Bourdoukan", "Ralph", ""], ["Vertechi", "Pietro", ""], ["Machens", "Christian K.", ""], ["Den\u00e9ve", "Sophie", ""]]}, {"id": "1703.04056", "submitter": "Phebe Kemmer", "authors": "Phebe Brenne Kemmer, F. DuBois Bowman, Helen Mayberg, Ying Guo", "title": "Quantifying the strength of structural connectivity underlying\n  functional brain networks", "comments": "25 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, there has been strong interest in neuroscience studies to\ninvestigate brain organization through networks of brain regions that\ndemonstrate strong functional connectivity (FC). These networks are extracted\nfrom observed fMRI using data-driven analytic methods such as independent\ncomponent analysis (ICA). A notable limitation of these FC methods is that they\ndo not provide any information on the underlying structural connectivity (SC),\nwhich is believed to serve as the basis for interregional interactions in brain\nactivity. We propose a new statistical measure of the strength of SC (sSC)\nunderlying FC networks obtained from data-driven methods. The sSC measure is\ndeveloped using information from diffusion tensor imaging (DTI) data, and can\nbe applied to compare the strength of SC across different FC networks.\nFurthermore, we propose a reliability index for data-driven FC networks to\nmeasure the reproducibility of the networks through re-sampling the observed\ndata. To perform statistical inference such as hypothesis testing on the sSC,\nwe develop a formal variance estimator of sSC based a spatial semivariogram\nmodel with a novel distance metric. We demonstrate the performance of the sSC\nmeasure and its estimation and inference methods with simulation studies. For\nreal data analysis, we apply our methods to a multimodal imaging study with\nresting-state fMRI and DTI data from 20 healthy controls and 20 subjects with\nmajor depressive disorder. Results show that well-known resting state networks\nall demonstrate higher SC within the network as compared to the average\nstructural connections across the brain. We also found that sSC is positively\nassociated with the reliability index, indicating that the FC networks that\nhave stronger underlying SC are more reproducible across samples.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 02:07:37 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Kemmer", "Phebe Brenne", ""], ["Bowman", "F. DuBois", ""], ["Mayberg", "Helen", ""], ["Guo", "Ying", ""]]}, {"id": "1703.04117", "submitter": "Duccio Fanelli", "authors": "Clement Zankoc, Duccio Fanelli, Francesco Ginelli, Roberto Livi", "title": "Intertangled stochastic motifs in networks of excitatory-inhibitory\n  units", "comments": "Movies of the stochastic dynamics are made available upon request", "journal-ref": "Phys. Rev. E 96, 022308 (2017)", "doi": "10.1103/PhysRevE.96.022308", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stochastic model of excitatory and inhibitory interactions which bears\nuniversality traits is introduced and studied. The endogenous component of\nnoise, stemming from finite size corrections, drives robust inter-nodes\ncorrelations, that persist at large large distances. Anti-phase synchrony at\nsmall frequencies is resolved on adjacent nodes and found to promote the\nspontaneous generation of long-ranged stochastic patterns, that invade the\nnetwork as a whole. These patterns are lacking under the idealized\ndeterministic scenario, and could provide novel hints on how living systems\nimplement and handle a large gallery of delicate computational tasks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 13:38:16 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Zankoc", "Clement", ""], ["Fanelli", "Duccio", ""], ["Ginelli", "Francesco", ""], ["Livi", "Roberto", ""]]}, {"id": "1703.04145", "submitter": "Mihai Alexandru Petrovici", "authors": "Mihai A. Petrovici, Anna Schroeder, Oliver Breitwieser, Andreas\n  Gr\\\"ubl, Johannes Schemmel, Karlheinz Meier", "title": "Robustness from structure: Inference with hierarchical spiking networks\n  on analog neuromorphic hardware", "comments": "accepted at IJCNN 2017", "journal-ref": "International Joint Conference on Neural Networks (IJCNN), 2017", "doi": "10.1109/IJCNN.2017.7966123", "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How spiking networks are able to perform probabilistic inference is an\nintriguing question, not only for understanding information processing in the\nbrain, but also for transferring these computational principles to neuromorphic\nsilicon circuits. A number of computationally powerful spiking network models\nhave been proposed, but most of them have only been tested, under ideal\nconditions, in software simulations. Any implementation in an analog, physical\nsystem, be it in vivo or in silico, will generally lead to distorted dynamics\ndue to the physical properties of the underlying substrate. In this paper, we\ndiscuss several such distortive effects that are difficult or impossible to\nremove by classical calibration routines or parameter training. We then argue\nthat hierarchical networks of leaky integrate-and-fire neurons can offer the\nrequired robustness for physical implementation and demonstrate this with both\nsoftware simulations and emulation on an accelerated analog neuromorphic\ndevice.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 17:29:11 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Petrovici", "Mihai A.", ""], ["Schroeder", "Anna", ""], ["Breitwieser", "Oliver", ""], ["Gr\u00fcbl", "Andreas", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1703.04176", "submitter": "Satohiro Tajima", "authors": "Satohiro Tajima, Takeshi Mita, Douglas J. Bakkum, Hirokazu Takahashi,\n  Taro Toyoizumi", "title": "Locally embedded presages of global network bursts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spontaneous, synchronous bursting of neural population is a widely observed\nphenomenon in nervous networks, which is considered important for functions and\ndysfunctions of the brain. However, how the global synchrony across a large\nnumber of neurons emerges from an initially non-bursting network state is not\nfully understood. In this study, we develop a new state-space reconstruction\nmethod combined with high-resolution recordings of cultured neurons. This\nmethod extracts deterministic signatures of upcoming global bursts in \"local\"\ndynamics of individual neurons during non-bursting periods. We find that local\ninformation within a single-cell time series can compare with or even\noutperform the global mean field activity for predicting future global bursts.\nMoreover, the inter-cell variability in the burst predictability is found to\nreflect the network structure realized in the non-bursting periods. These\nfindings demonstrate the deterministic mechanisms underlying the locally\nconcentrated early-warnings of the global state transition in self-organized\nnetworks.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 21:04:39 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Tajima", "Satohiro", ""], ["Mita", "Takeshi", ""], ["Bakkum", "Douglas J.", ""], ["Takahashi", "Hirokazu", ""], ["Toyoizumi", "Taro", ""]]}, {"id": "1703.04182", "submitter": "Alexander Vasilyev", "authors": "Alexander Yurievich Vasilyev", "title": "Optimal control of eye-movements during visual search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of optimal oculomotor control during the execution of\nvisual search tasks. We introduce a computational model of human eye movements,\nwhich takes into account various constraints of the human visual and oculomotor\nsystems. In the model, the choice of the subsequent fixation location is posed\nas a problem of stochastic optimal control, which relies on reinforcement\nlearning methods. We show that if biological constraints are taken into\naccount, the trajectories simulated under learned policy share both basic\nstatistical properties and scaling behaviour with human eye movements. We\nvalidated our model simulations with human psychophysical eye-tracking\nexperiments\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 21:56:29 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 10:23:08 GMT"}, {"version": "v3", "created": "Sun, 19 Mar 2017 16:59:39 GMT"}, {"version": "v4", "created": "Thu, 13 Apr 2017 14:50:03 GMT"}, {"version": "v5", "created": "Thu, 14 Sep 2017 21:39:50 GMT"}, {"version": "v6", "created": "Wed, 4 Apr 2018 14:24:03 GMT"}, {"version": "v7", "created": "Tue, 28 Aug 2018 20:42:53 GMT"}], "update_date": "2018-08-30", "authors_parsed": [["Vasilyev", "Alexander Yurievich", ""]]}, {"id": "1703.04200", "submitter": "Ben Poole", "authors": "Friedemann Zenke, Ben Poole, Surya Ganguli", "title": "Continual Learning Through Synaptic Intelligence", "comments": "ICML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep learning has led to remarkable advances across diverse\napplications, it struggles in domains where the data distribution changes over\nthe course of learning. In stark contrast, biological neural networks\ncontinually adapt to changing domains, possibly by leveraging complex molecular\nmachinery to solve many tasks simultaneously. In this study, we introduce\nintelligent synapses that bring some of this biological complexity into\nartificial neural networks. Each synapse accumulates task relevant information\nover time, and exploits this information to rapidly store new memories without\nforgetting old ones. We evaluate our approach on continual learning of\nclassification tasks, and show that it dramatically reduces forgetting while\nmaintaining computational efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 00:02:48 GMT"}, {"version": "v2", "created": "Mon, 10 Apr 2017 17:54:57 GMT"}, {"version": "v3", "created": "Mon, 12 Jun 2017 19:57:42 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Zenke", "Friedemann", ""], ["Poole", "Ben", ""], ["Ganguli", "Surya", ""]]}, {"id": "1703.04500", "submitter": "Alessandro Torcini Dr", "authors": "Simona Olmi, David Angulo-Garcia, Alberto Imparato, Alessandro Torcini", "title": "Exact firing time statistics of neurons driven by discrete inhibitory\n  noise", "comments": "20 pages, 8 Figures, submitted to Scientific Reports", "journal-ref": "Scientific Reports 7, Article number: 1577 (2017)", "doi": "10.1038/s41598-017-01658-8", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the intact brain receive a continuous and irregular synaptic\nbombardment from excitatory and inhibitory pre-synaptic neurons, which\ndetermines the firing activity of the stimulated neuron. In order to\ninvestigate the influence of inhibitory stimulation on the firing time\nstatistics, we consider Leaky Integrate-and-Fire neurons subject to inhibitory\ninstantaneous post-synaptic potentials. In particular, we report exact results\nfor the firing rate, the coefficient of variation and the spike train spectrum\nfor various synaptic weight distributions. Our results are not limited to\nstimulations of infinitesimal amplitude, but they apply as well to finite\namplitude post-synaptic potentials, thus being able to capture the effect of\nrare and large spikes. The developed methods are able to reproduce also the\naverage firing properties of heterogeneous neuronal populations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 17:36:22 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Olmi", "Simona", ""], ["Angulo-Garcia", "David", ""], ["Imparato", "Alberto", ""], ["Torcini", "Alessandro", ""]]}, {"id": "1703.04647", "submitter": "Liane Gabora", "authors": "Liane Gabora and Kirsty Kitto", "title": "Toward a Quantum Theory of Humor", "comments": null, "journal-ref": null, "doi": "10.3389/fphy.2016.00053", "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes that cognitive humor can be modeled using the\nmathematical framework of quantum theory. We begin with brief overviews of both\nresearch on humor, and the generalized quantum framework. We show how the\nbisociation of incongruous frames or word meanings in jokes can be modeled as a\nlinear superposition of a set of basis states, or possible interpretations, in\na complex Hilbert space. The choice of possible interpretations depends on the\ncontext provided by the set-up vs. the punchline of a joke. We apply the\napproach to a verbal pun, and consider how it might be extended to frame\nblending. An initial study of that made use of the Law of Total Probability,\ninvolving 85 participant responses to 35 jokes (as well as variants), suggests\nthat the Quantum Theory of Humor (QTH) proposed here provides a viable new\napproach to modeling humor.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 18:22:41 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Gabora", "Liane", ""], ["Kitto", "Kirsty", ""]]}, {"id": "1703.05079", "submitter": "Jorge Hidalgo", "authors": "Matteo Martinello, Jorge Hidalgo, Serena di Santo, Amos Maritan,\n  Dietmar Plenz, Miguel A. Mu\\~noz", "title": "Neutral theory and scale-free neural dynamics", "comments": "Main text: 8 pages, 3 figures. Supplementary information: 5 pages, 4\n  figures", "journal-ref": "Phys. Rev. X 7, 041071 (2017)", "doi": "10.1103/PhysRevX.7.041071", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Avalanches of electrochemical activity in brain networks have been\nempirically reported to obey scale-invariant behavior --characterized by\npower-law distributions up to some upper cut-off-- both in vitro and in vivo.\nElucidating whether such scaling laws stem from the underlying neural dynamics\noperating at the edge of a phase transition is a fascinating possibility, as\nsystems poised at criticality have been argued to exhibit a number of important\nfunctional advantages. Here we employ a well-known model for neural dynamics\nwith synaptic plasticity, to elucidate an alternative scenario in which\nneuronal avalanches can coexist, overlapping in time, but still remaining\nscale-free. Remarkably their scale-invariance does not stem from underlying\ncriticality nor self-organization at the edge of a continuous phase transition.\nInstead, it emerges from the fact that perturbations to the system exhibit a\nneutral drift --guided by demographic fluctuations-- with respect to endogenous\nspontaneous activity. Such a neutral dynamics --similar to the one in neutral\ntheories of population genetics-- implies marginal propagation of activity,\ncharacterized by power-law distributed causal avalanches. Importantly, our\nresults underline the importance of considering causal information --on which\nneuron triggers the firing of which-- to properly estimate the statistics of\navalanches of neural activity. We discuss the implications of these findings\nboth in modeling and to elucidate experimental observations, as well as its\npossible consequences for actual neural dynamics and information processing in\nactual neural networks.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 11:05:43 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Martinello", "Matteo", ""], ["Hidalgo", "Jorge", ""], ["di Santo", "Serena", ""], ["Maritan", "Amos", ""], ["Plenz", "Dietmar", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}, {"id": "1703.05205", "submitter": "Maximilian Puelma Touzel Mr.", "authors": "Maximilian Puelma Touzel, Fred Wolf", "title": "Statistical mechanics of phase-space partitioning in large-scale spiking\n  neuron circuits", "comments": "manuscript(16 pages, 5 figures)", "journal-ref": "Phys. Rev. E 99, 052402 (2019)", "doi": "10.1103/PhysRevE.99.052402", "report-no": null, "categories": "cond-mat.dis-nn nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic interactions structure the phase space of the dynamics of neural\ncircuits and constrain neural computation. Understanding how requires methods\nthat handle those discrete interactions, yet few exist. Recently, it was\ndiscovered that even random networks exhibit dynamics that partitions the phase\nspace into numerous attractor basins. Here we utilize this phenomenon to\ndevelop theory for the geometry of phase space partitioning in spiking neural\ncircuits. We find basin boundaries structuring the phase space are pre-images\nof spike-time collision events. Formulating a statistical theory of spike-time\ncollision events, we derive expressions for the rate of divergence of\nneighboring basins and for their size distribution. This theory reveals that\nthe typical basin diameter grows with inhibitory coupling strength and shrinks\nwith the rate of spike events. Our study provides an analytical and\ngeneralizable approach for dissecting how connectivity, coupling strength,\nsingle neuron dynamics and population activity shape the phase space geometry\nof spiking circuits.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 15:19:33 GMT"}, {"version": "v2", "created": "Mon, 1 May 2017 22:31:33 GMT"}], "update_date": "2019-05-15", "authors_parsed": [["Touzel", "Maximilian Puelma", ""], ["Wolf", "Fred", ""]]}, {"id": "1703.05344", "submitter": "Rita Singh", "authors": "Rita Singh, Justin Baker, Luciana Pennant, Louis-Philippe Morency", "title": "Deducing the severity of psychiatric symptoms from the human voice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychiatric illnesses are often associated with multiple symptoms, whose\nseverity must be graded for accurate diagnosis and treatment. This grading is\nusually done by trained clinicians based on human observations and judgments\nmade within doctor-patient sessions. Current research provides sufficient\nreason to expect that the human voice may carry biomarkers or signatures of\nmany, if not all, these symptoms. Based on this conjecture, we explore the\npossibility of objectively and automatically grading the symptoms of\npsychiatric illnesses with reference to various standard psychiatric rating\nscales. Using acoustic data from several clinician-patient interviews within\nhospital settings, we use non-parametric models to learn and predict the\nrelations between symptom-ratings and voice. In the process, we show that\ndifferent articulatory-phonetic units of speech are able to capture the effects\nof different symptoms differently, and use this to establish a plausible\nmethodology that could be employed for automatically grading psychiatric\nsymptoms for clinical purposes.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 18:41:37 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Singh", "Rita", ""], ["Baker", "Justin", ""], ["Pennant", "Luciana", ""], ["Morency", "Louis-Philippe", ""]]}, {"id": "1703.05406", "submitter": "Andrew Sornborger", "authors": "Yuxiu Shao, Andrew T. Sornborger, Louis Tao", "title": "A Pulse-Gated, Predictive Neural Circuit", "comments": "This invited paper was presented at the 50th Asilomar Conference on\n  Signals, Systems and Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent evidence suggests that neural information is encoded in packets and\nmay be flexibly routed from region to region. We have hypothesized that neural\ncircuits are split into sub-circuits where one sub-circuit controls information\npropagation via pulse gating and a second sub-circuit processes graded\ninformation under the control of the first sub-circuit. Using an explicit\npulse-gating mechanism, we have been able to show how information may be\nprocessed by such pulse-controlled circuits and also how, by allowing the\ninformation processing circuit to interact with the gating circuit, decisions\ncan be made. Here, we demonstrate how Hebbian plasticity may be used to\nsupplement our pulse-gated information processing framework by implementing a\nmachine learning algorithm. The resulting neural circuit has a number of\nstructures that are similar to biological neural systems, including a layered\nstructure and information propagation driven by oscillatory gating with a\ncomplex frequency spectrum.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 22:25:29 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Shao", "Yuxiu", ""], ["Sornborger", "Andrew T.", ""], ["Tao", "Louis", ""]]}, {"id": "1703.05414", "submitter": "Andrew Sornborger", "authors": "Andrew T. Sornborger and James D. Lauderdale", "title": "A Multitaper, Causal Decomposition for Stochastic, Multivariate Time\n  Series: Application to High-Frequency Calcium Imaging Data", "comments": "This invited paper was presented at the Asilomar 50th Conference on\n  Signals, Systems, and Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural data analysis has increasingly incorporated causal information to\nstudy circuit connectivity. Dimensional reduction forms the basis of most\nanalyses of large multivariate time series. Here, we present a new,\nmultitaper-based decomposition for stochastic, multivariate time series that\nacts on the covariance of the time series at all lags, $C(\\tau)$, as opposed to\nstandard methods that decompose the time series, $\\mathbf{X}(t)$, using only\ninformation at zero-lag. In both simulated and neural imaging examples, we\ndemonstrate that methods that neglect the full causal structure may be\ndiscarding important dynamical information in a time series.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 22:54:15 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Sornborger", "Andrew T.", ""], ["Lauderdale", "James D.", ""]]}, {"id": "1703.05428", "submitter": "Yu Takagi", "authors": "Yu Takagi, Yuki Sakai, Giuseppe Lisi, Noriaki Yahata, Yoshinari Abe,\n  Seiji Nishida, Takashi Nakamae, Jun Morimoto, Mitsuo Kawato, Jin Narumoto and\n  Saori C. Tanaka", "title": "A neural marker of obsessive-compulsive disorder from whole-brain\n  functional connectivity", "comments": "47 pages, 3 figures", "journal-ref": "Sci Rep. 2017 Aug 8;7(1):7538", "doi": "10.1038/s41598-017-07792-7", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obsessive-compulsive disorder (OCD) is a common psychiatric disorder with a\nlifetime prevalence of 2-3 percent. Recently, brain activity in the resting\nstate is gathering attention as a new means of exploring altered functional\nconnectivity in psychiatric disorders. Although previous resting-state\nfunctional magnetic resonance imaging studies investigated neurobiological\nabnormalities of patients with OCD, there are concerns that should be\naddressed. One concern is the validity of the hypothesis employed. Most studies\nused seed-based analysis of the fronto-striatal circuit, despite the potential\nfor abnormalities in other regions. A hypothesis-free study is a promising\napproach in such a case, while it requires researchers to handle a dataset with\nlarge dimensions. Another concern is the reliability of biomarkers derived from\na single dataset, which may be influenced by cohort-specific features. Here, by\nemploying a recently developed machine-learning algorithm to avoid these\nconcerns, we identified the first OCD biomarker that is generalized to an\nexternal dataset. We also demonstrated that the functional connectivities that\ncontributed to the classification were widely distributed rather than locally\nconstrained. Our generalizable classifier has the potential not only to deepen\nour understanding of the abnormal neural substrates of OCD but also to find use\nin clinical applications.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 23:54:37 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 16:53:09 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Takagi", "Yu", ""], ["Sakai", "Yuki", ""], ["Lisi", "Giuseppe", ""], ["Yahata", "Noriaki", ""], ["Abe", "Yoshinari", ""], ["Nishida", "Seiji", ""], ["Nakamae", "Takashi", ""], ["Morimoto", "Jun", ""], ["Kawato", "Mitsuo", ""], ["Narumoto", "Jin", ""], ["Tanaka", "Saori C.", ""]]}, {"id": "1703.05504", "submitter": "Oleg Maslennikov V", "authors": "Oleg V. Maslennikov, Dmitry S. Shchapin, Vladimir I. Nekorkin", "title": "Transient sequences in a hypernetwork generated by an adaptive network\n  of spiking neurons", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": "10.1098/rsta.2016.0288", "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a model of an adaptive network of spiking neurons that gives rise\nto a hypernetwork of its dynamic states at the upper level of description. Left\nto itself, the network exhibits a sequence of transient clustering which\nrelates to a traffic in the hypernetwork in the form of a random walk.\nReceiving inputs the system is able to generate reproducible sequences\ncorresponding to stimulus-specific paths in the hypernetwork. We illustrate\nthese basic notions by a simple network of discrete-time spiking neurons\ntogether with its FPGA realization and analyze their properties.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 08:36:43 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Maslennikov", "Oleg V.", ""], ["Shchapin", "Dmitry S.", ""], ["Nekorkin", "Vladimir I.", ""]]}, {"id": "1703.05691", "submitter": "Vyacheslav Yukalov", "authors": "V.I. Yukalov and D. Sornette", "title": "Quantum Probabilities as Behavioral Probabilities", "comments": "Latex file, 32 pages", "journal-ref": "Entropy 19 (2017) 112", "doi": "10.3390/e19030112", "report-no": null, "categories": "q-bio.NC physics.soc-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate that behavioral probabilities of human decision makers share\nmany common features with quantum probabilities. This does not imply that\nhumans are some quantum objects, but just shows that the mathematics of quantum\ntheory is applicable to the description of human decision making. The\napplicability of quantum rules for describing decision making is connected with\nthe nontrivial process of making decisions in the case of composite prospects\nunder uncertainty. Such a process involves deliberations of a decision maker\nwhen making a choice. In addition to the evaluation of the utilities of\nconsidered prospects, real decision makers also appreciate their respective\nattractiveness. Therefore, human choice is not based solely on the utility of\nprospects, but includes the necessity of resolving the utility-attraction\nduality. In order to justify that human consciousness really functions\nsimilarly to the rules of quantum theory, we develop an approach defining human\nbehavioral probabilities as the probabilities determined by quantum rules. We\nshow that quantum behavioral probabilities of humans not merely explain\nqualitatively how human decisions are made, but they predict quantitative\nvalues of the behavioral probabilities. Analyzing a large set of empirical\ndata, we find good quantitative agreement between theoretical predictions and\nobserved experimental data.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 16:04:45 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Yukalov", "V. I.", ""], ["Sornette", "D.", ""]]}, {"id": "1703.05917", "submitter": "Mike Steel Prof.", "authors": "Liane Gabora and Mike Steel", "title": "Autocatalytic networks in cognition and the origin of culture", "comments": "28 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been proposed that cultural evolution was made possible by a cognitive\ntransition brought about by onset of the capacity for self-triggered recall and\nrehearsal. Here we develop a novel idea that models of collectively\nautocatalytic networks, developed for understanding the origin and organization\nof life, may also help explain the origin of the kind of cognitive structure\nthat makes cultural evolution possible. In our setting, mental representations\n(for example, memories, concepts, ideas) play the role of 'molecules', and\n'reactions' involve the evoking of one representation by another through\nremindings, associations, and stimuli. In the 'episodic mind', representations\nare so coarse-grained (encode too few properties) that such reactions are\ncatalyzed only by external stimuli. As cranial capacity increased,\nrepresentations became more fine-grained (encoded more features), allowing them\nto act as catalysts, leading to streams of thought. At this point, the mind\ncould combine representations and adapt them to specific needs and situations,\nand thereby contribute to cultural evolution. In this paper, we propose and\nstudy a simple and explicit cognitive model that gives rise naturally to\nautocatylatic networks, and thereby provides a possible mechanism for the\ntransition from a pre-cultural episodic mind to a mimetic mind.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 08:00:15 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 06:24:57 GMT"}, {"version": "v3", "created": "Mon, 7 Aug 2017 21:59:34 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Gabora", "Liane", ""], ["Steel", "Mike", ""]]}, {"id": "1703.06043", "submitter": "Mihai Alexandru Petrovici", "authors": "Mihai A. Petrovici, Sebastian Schmitt, Johann Kl\\\"ahn, David\n  St\\\"ockel, Anna Schroeder, Guillaume Bellec, Johannes Bill, Oliver\n  Breitwieser, Ilja Bytschok, Andreas Gr\\\"ubl, Maurice G\\\"uttler, Andreas\n  Hartel, Stephan Hartmann, Dan Husmann, Kai Husmann, Sebastian Jeltsch, Vitali\n  Karasenko, Mitja Kleider, Christoph Koke, Alexander Kononov, Christian Mauch,\n  Eric M\\\"uller, Paul M\\\"uller, Johannes Partzsch, Thomas Pfeil, Stefan\n  Schiefer, Stefan Scholze, Anand Subramoney, Vasilis Thanasoulis, Bernhard\n  Vogginger, Robert Legenstein, Wolfgang Maass, Ren\\'e Sch\\\"uffny, Christian\n  Mayr, Johannes Schemmel, Karlheinz Meier", "title": "Pattern representation and recognition with accelerated analog\n  neuromorphic systems", "comments": "accepted at ISCAS 2017", "journal-ref": "Circuits and Systems (ISCAS), 2017 IEEE International Symposium on", "doi": "10.1109/ISCAS.2017.8050530", "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite being originally inspired by the central nervous system, artificial\nneural networks have diverged from their biological archetypes as they have\nbeen remodeled to fit particular tasks. In this paper, we review several\npossibilites to reverse map these architectures to biologically more realistic\nspiking networks with the aim of emulating them on fast, low-power neuromorphic\nhardware. Since many of these devices employ analog components, which cannot be\nperfectly controlled, finding ways to compensate for the resulting effects\nrepresents a key challenge. Here, we discuss three different strategies to\naddress this problem: the addition of auxiliary network components for\nstabilizing activity, the utilization of inherently robust architectures and a\ntraining method for hardware-emulated networks that functions without perfect\nknowledge of the system's dynamics and parameters. For all three scenarios, we\ncorroborate our theoretical considerations with experimental results on\naccelerated analog neuromorphic platforms.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 14:59:17 GMT"}, {"version": "v2", "created": "Mon, 3 Jul 2017 15:16:43 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Petrovici", "Mihai A.", ""], ["Schmitt", "Sebastian", ""], ["Kl\u00e4hn", "Johann", ""], ["St\u00f6ckel", "David", ""], ["Schroeder", "Anna", ""], ["Bellec", "Guillaume", ""], ["Bill", "Johannes", ""], ["Breitwieser", "Oliver", ""], ["Bytschok", "Ilja", ""], ["Gr\u00fcbl", "Andreas", ""], ["G\u00fcttler", "Maurice", ""], ["Hartel", "Andreas", ""], ["Hartmann", "Stephan", ""], ["Husmann", "Dan", ""], ["Husmann", "Kai", ""], ["Jeltsch", "Sebastian", ""], ["Karasenko", "Vitali", ""], ["Kleider", "Mitja", ""], ["Koke", "Christoph", ""], ["Kononov", "Alexander", ""], ["Mauch", "Christian", ""], ["M\u00fcller", "Eric", ""], ["M\u00fcller", "Paul", ""], ["Partzsch", "Johannes", ""], ["Pfeil", "Thomas", ""], ["Schiefer", "Stefan", ""], ["Scholze", "Stefan", ""], ["Subramoney", "Anand", ""], ["Thanasoulis", "Vasilis", ""], ["Vogginger", "Bernhard", ""], ["Legenstein", "Robert", ""], ["Maass", "Wolfgang", ""], ["Sch\u00fcffny", "Ren\u00e9", ""], ["Mayr", "Christian", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1703.06091", "submitter": "Javier Buldu", "authors": "Javier M. Buld\\'u and Mason A. Porter", "title": "Frequency-based brain networks: From a multiplex framework to a full\n  multilayer description", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.CO physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore how to study dynamical interactions between brain regions using\nfunctional multilayer networks whose layers represent the different frequency\nbands at which a brain operates. Specifically, we investigate the consequences\nof considering the brain as a multilayer network in which all brain regions can\ninteract with each other at different frequency bands, instead of as a\nmultiplex network, in which interactions between different frequency bands are\nonly allowed within each brain region and not between them. We study the second\nsmallest eigenvalue of the combinatorial supra-Laplacian matrix of the\nmultilayer network in detail, and we thereby show that the heterogeneity of\ninterlayer edges and, especially, the fraction of missing edges crucially\nmodify the spectral properties of the multilayer network. We illustrate our\nresults with both synthetic network models and real data sets obtained from\nresting state magnetoencephalography. Our work demonstrates an important issue\nin the construction of frequency-based multilayer brain networks.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 16:44:24 GMT"}, {"version": "v2", "created": "Thu, 14 Sep 2017 14:05:41 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Buld\u00fa", "Javier M.", ""], ["Porter", "Mason A.", ""]]}, {"id": "1703.06264", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Magdalena Fuchs, Victoria Beneder and Radu Grosu", "title": "Non-Associative Learning Representation in the Nervous System of the\n  Nematode Caenorhabditis elegans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Caenorhabditis elegans (C. elegans) illustrated remarkable behavioral\nplasticities including complex non-associative and associative learning\nrepresentations. Understanding the principles of such mechanisms presumably\nleads to constructive inspirations for the design of efficient learning\nalgorithms. In the present study, we postulate a novel approach on modeling\nsingle neurons and synapses to study the mechanisms underlying learning in the\nC. elegans nervous system. In this regard, we construct a precise mathematical\nmodel of sensory neurons where we include multi-scale details from genes, ion\nchannels and ion pumps, together with a dynamic model of synapses comprised of\nneurotransmitters and receptors kinetics. We recapitulate mechanosensory\nhabituation mechanism, a non-associative learning process, in which elements of\nthe neural network tune their parameters as a result of repeated input stimuli.\nAccordingly, we quantitatively demonstrate the roots of such plasticity in the\nneuronal and synaptic-level representations. Our findings can potentially give\nrise to the development of new bio-inspired learning algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 07:45:51 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 15:55:30 GMT"}, {"version": "v3", "created": "Sat, 25 Mar 2017 13:24:29 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Fuchs", "Magdalena", ""], ["Beneder", "Victoria", ""], ["Grosu", "Radu", ""]]}, {"id": "1703.06270", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Victoria Beneder, Magdalena Fuchs, David Lung and\n  Radu Grosu", "title": "SIM-CE: An Advanced Simulink Platform for Studying the Brain of\n  Caenorhabditis elegans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SIM-CE, an advanced, user-friendly modeling and simulation\nenvironment in Simulink for performing multi-scale behavioral analysis of the\nnervous system of Caenorhabditis elegans (C. elegans). SIM-CE contains an\nimplementation of the mathematical models of C. elegans's neurons and synapses,\nin Simulink, which can be easily extended and particularized by the user. The\nSimulink model is able to capture both complex dynamics of ion channels and\nadditional biophysical detail such as intracellular calcium concentration. We\ndemonstrate the performance of SIM-CE by carrying out neuronal, synaptic and\nneural-circuit-level behavioral simulations. Such environment enables the user\nto capture unknown properties of the neural circuits, test hypotheses and\ndetermine the origin of many behavioral plasticities exhibited by the worm.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 08:27:42 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 15:49:11 GMT"}, {"version": "v3", "created": "Sat, 25 Mar 2017 13:19:14 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Beneder", "Victoria", ""], ["Fuchs", "Magdalena", ""], ["Lung", "David", ""], ["Grosu", "Radu", ""]]}, {"id": "1703.06290", "submitter": "Johannes Thiele", "authors": "Johannes Thiele, Peter Diehl, Matthew Cook", "title": "A wake-sleep algorithm for recurrent, spiking neural networks", "comments": "Presented at the NIPS 2016 workshop \"Computing with Spikes\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a recently proposed model for cortical computation which\nperforms relational inference. It consists of several interconnected,\nstructurally equivalent populations of leaky integrate-and-fire (LIF) neurons,\nwhich are trained in a self-organized fashion with spike-timing dependent\nplasticity (STDP). Despite its robust learning dynamics, the model is\nsusceptible to a problem typical for recurrent networks which use a correlation\nbased (Hebbian) learning rule: if trained with high learning rates, the\nrecurrent connections can cause strong feedback loops in the network dynamics,\nwhich lead to the emergence of attractor states. This causes a strong reduction\nin the number of representable patterns and a decay in the inference ability of\nthe network. As a solution, we introduce a conceptually very simple\n\"wake-sleep\" algorithm: during the wake phase, training is executed normally,\nwhile during the sleep phase, the network \"dreams\" samples from its generative\nmodel, which are induced by random input. This process allows us to activate\nthe attractor states in the network, which can then be unlearned effectively by\nan anti-Hebbian mechanism. The algorithm allows us to increase learning rates\nup to a factor of ten while avoiding clustering, which allows the network to\nlearn several times faster. Also for low learning rates, where clustering is\nnot an issue, it improves convergence speed and reduces the final inference\nerror.\n", "versions": [{"version": "v1", "created": "Sat, 18 Mar 2017 12:29:16 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Thiele", "Johannes", ""], ["Diehl", "Peter", ""], ["Cook", "Matthew", ""]]}, {"id": "1703.06491", "submitter": "Shankha Sanyal", "authors": "Shankha Sanyal, Archi Banerjee, Souparno Roy, Sourya Sengupta, Sayan\n  Biswas, Sayan Nag, Ranjan Sengupta and Dipak Ghosh", "title": "Gestalt Phenomenon in Music? A Neurocognitive Physics Study with EEG", "comments": "14 Pages, 5 Figures, Presented in International Conference on\n  Creativity and Cognition in Art and Design, NIMHANS, Bangalore; 19-21\n  January, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term gestalt has been widely used in the field of psychology which\ndefined the perception of human mind to group any object not in part but as a\nunified whole. Music in general is polytonic i.e. a combination of a number of\npure tones (frequencies) mixed together in a manner that sounds harmonius. The\nstudy of human brain response due to different frequency groups of acoustic\nsignal can give us an excellent insight regarding the neural and functional\narchitecture of brain functions. In this work we have tried to analyze the\neffect of different frequency bands of music on the various frequency rhythms\nof human brain obtained from EEG data of 5 participants. Four (4) widely\npopular Rabindrasangeet clips were subjected to Wavelet Transform method for\nextracting five resonant frequency bands from the original music signal. These\nresonant frequency bands were presented to the subjects as auditory stimulus\nand EEG signals recorded simultaneously in 19 different locations of the brain.\nThe recorded EEG signals were noise cleaned and subjected to Multifractal\nDetrended Fluctuation Analysis (MFDFA) technique on the alpha, theta and gamma\nfrequency range. Thus, we obtained the complexity values (in the form of\nmultifractal spectral width) in alpha, theta and gamma EEG rhythms\ncorresponding to different frequency bands of music. We obtain frequency\nspecific arousal based response in different lobes of brain as well as in\nspecific EEG bands corresponding to musical stimuli. This revelation can be of\nimmense importance when it comes to the field of cognitive music therapy.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 19:10:27 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Sanyal", "Shankha", ""], ["Banerjee", "Archi", ""], ["Roy", "Souparno", ""], ["Sengupta", "Sourya", ""], ["Biswas", "Sayan", ""], ["Nag", "Sayan", ""], ["Sengupta", "Ranjan", ""], ["Ghosh", "Dipak", ""]]}, {"id": "1703.06670", "submitter": "Kai G\\\"orgen", "authors": "Kai G\\\"orgen (1), Martin N. Hebart (2 and 3), Carsten Allefeld (1 and\n  6), John-Dylan Haynes (1 and 4 and 5 and 6) ((1) Charite, FU, HU, BIH, BCCN,\n  BCAN, Neurocure, Berlin, (2) University Medical Center Hamburg-Eppendorf, (3)\n  NIMH, Bethesda, (4) Mind and Brain, HU Berlin, (5) TU Dresden, (6) Equal\n  contribution)", "title": "The Same Analysis Approach: Practical protection against the pitfalls of\n  novel neuroimaging analysis methods", "comments": "Manuscript [29 pages, 7 Figures] + Supplemental Information [21\n  pages, 13 Figures], published in NeuroImage as: G\\\"orgen, K., Hebart, M. N.,\n  Allefeld, C., & Haynes, J.-D. (2018). The same analysis approach: Practical\n  protection against the pitfalls of novel neuroimaging analysis methods.\n  NeuroImage 180, 19-30. doi:10.1016/j.neuroimage.2017.12.083", "journal-ref": null, "doi": "10.1016/j.neuroimage.2017.12.083", "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard neuroimaging data analysis based on traditional principles of\nexperimental design, modelling, and statistical inference is increasingly\ncomplemented by novel analysis methods, driven e.g. by machine learning\nmethods. While these novel approaches provide new insights into neuroimaging\ndata, they often have unexpected properties, generating a growing literature on\npossible pitfalls. We propose to meet this challenge by adopting a habit of\nsystematic testing of experimental design, analysis procedures, and statistical\ninference. Specifically, we suggest to apply the analysis method used for\nexperimental data also to aspects of the experimental design, simulated\nconfounds, simulated null data, and control data. We stress the importance of\nkeeping the analysis method the same in main and test analyses, because only\nthis way possible confounds and unexpected properties can be reliably detected\nand avoided. We describe and discuss this Same Analysis Approach in detail, and\ndemonstrate it in two worked examples using multivariate decoding. With these\nexamples, we reveal two sources of error: A mismatch between counterbalancing\n(crossover designs) and cross-validation which leads to systematic below-chance\naccuracies, and linear decoding of a nonlinear effect, a difference in\nvariance.\n  Highlights: 1. Traditional design principles can be unsuitable when combined\nwith cross-validation; 2. This can explain both inflated accuracies and\nbelow-chance accuracies; 3. We propose the novel \"same analysis approach\" (SAA)\nfor checking analysis pipelines; 4. The principle of SAA is to perform\nadditional analyses using the same analysis; 5. SAA analysis should be\nperformed on design variables, control data, and simulations\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 11:01:15 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 17:19:46 GMT"}, {"version": "v3", "created": "Wed, 5 Jul 2017 15:38:21 GMT"}, {"version": "v4", "created": "Thu, 31 Aug 2017 17:25:27 GMT"}, {"version": "v5", "created": "Mon, 5 Feb 2018 15:11:47 GMT"}, {"version": "v6", "created": "Wed, 26 Sep 2018 10:10:29 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["G\u00f6rgen", "Kai", "", "2 and 3"], ["Hebart", "Martin N.", "", "2 and 3"], ["Allefeld", "Carsten", "", "1 and\n  6"], ["Haynes", "John-Dylan", "", "1 and 4 and 5 and 6"]]}, {"id": "1703.06946", "submitter": "Ashley Petersen", "authors": "Ashley Petersen, Noah Simon, Daniela Witten", "title": "SCALPEL: Extracting Neurons from Calcium Imaging Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, new technologies in the field of neuroscience have\nmade it possible to simultaneously image activity in large populations of\nneurons at cellular resolution in behaving animals. In mid-2016, a huge\nrepository of this so-called \"calcium imaging\" data was made\npublicly-available. The availability of this large-scale data resource opens\nthe door to a host of scientific questions, for which new statistical methods\nmust be developed.\n  In this paper, we consider the first step in the analysis of calcium imaging\ndata: namely, identifying the neurons in a calcium imaging video. We propose a\ndictionary learning approach for this task. First, we perform image\nsegmentation to develop a dictionary containing a huge number of candidate\nneurons. Next, we refine the dictionary using clustering. Finally, we apply the\ndictionary in order to select neurons and estimate their corresponding activity\nover time, using a sparse group lasso optimization problem. We apply our\nproposal to three calcium imaging data sets.\n  Our proposed approach is implemented in the R package scalpel, which is\navailable on CRAN.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 19:45:39 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Petersen", "Ashley", ""], ["Simon", "Noah", ""], ["Witten", "Daniela", ""]]}, {"id": "1703.07168", "submitter": "Jean Daunizeau", "authors": "Jean Daunizeau", "title": "On parameters transformations for emulating sparse priors using\n  variational-Laplace inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  So-called sparse estimators arise in the context of model fitting, when one a\npriori assumes that only a few (unknown) model parameters deviate from zero.\nSparsity constraints can be useful when the estimation problem is\nunder-determined, i.e. when number of model parameters is much higher than the\nnumber of data points. Typically, such constraints are enforced by minimizing\nthe L1 norm, which yields the so-called LASSO estimator. In this work, we\npropose a simple parameter transform that emulates sparse priors without\nsacrificing the simplicity and robustness of L2-norm regularization schemes. We\nshow how L1 regularization can be obtained with a \"sparsify\" remapping of\nparameters under normal Bayesian priors, and we demonstrate the ensuing\nvariational Laplace approach using Monte-Carlo simulations.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 16:40:15 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Daunizeau", "Jean", ""]]}, {"id": "1703.07633", "submitter": "Shay Ohayon", "authors": "Shay Ohayon, Antonio Miguel Caravaca-Aguirre, Rafael Piestun, James J.\n  DiCarlo", "title": "Deep brain fluorescence imaging with minimally invasive ultra-thin\n  optical fibers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph physics.med-ph physics.optics q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major open challenge in neuroscience is the ability to measure and perturb\nneural activity in vivo from well-defined neural sub-populations at cellular\nresolution anywhere in the brain. However, limitations posed by scattering and\nabsorption prohibit non-invasive (surface) multiphoton approaches for deep\n(>2mm) structures, while Gradient Refreactive Index (GRIN) endoscopes are thick\nand cause significant damage upon insertion. Here, we demonstrate a novel\nmicroendoscope to image neural activity at arbitrary depths via an ultrathin\nmultimode optical fiber (MMF) probe that is 5-10X thinner than commercially\navailable microendoscopes. We demonstrate micron-scale resolution,\nmultispectral and volumetric imaging. In contrast to previous approaches, we\nshow that this method has an improved acquisition speed that is sufficient to\ncapture rapid neuronal dynamics in-vivo in rodents expressing a genetically\nencoded calcium indicator. Our results emphasize the potential of this\ntechnology in neuroscience applications and open up possibilities for cellular\nresolution imaging in previously unreachable brain regions.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 20:40:52 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 16:42:25 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Ohayon", "Shay", ""], ["Caravaca-Aguirre", "Antonio Miguel", ""], ["Piestun", "Rafael", ""], ["DiCarlo", "James J.", ""]]}, {"id": "1703.07639", "submitter": "Eugen Tarnow", "authors": "Regina Ershova and Eugen Tarnow", "title": "Working memory capacity and gender", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The working memory capacity (WMC) of 400 Russian college students was\nmeasured using the Tarnow Unchunkable Test [2] which tests WMC alone without\nrequiring explicit working memory operations. We found small-sized WMC\ndifferences by gender and the possibility that the male/female ratio increases\nfor low and high WMC creating a u-shaped curve. The gender proportion in each\nacademic fields was a strong determinant of the average WMC (r2=0.2 for the\n3-item test and r2=0.5 for the 4-item test), associating \"academic female\"\n(law, history) with holistic thinking and \"academic male\" with reductive\nthinking (physics, computer science, math). Within academic fields there were\nno WMC gender differences. The male/female ratios for the different fields are\nstrongly amplified from the WMC male/female ratios, by factors of 12-14.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 12:58:46 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Ershova", "Regina", ""], ["Tarnow", "Eugen", ""]]}, {"id": "1703.07654", "submitter": "Roberto D. Pascual-Marqui", "authors": "RD Pascual-Marqui, P Faber, S Ikeda, R Ishii, T Kinoshita, Y Kitaura,\n  K Kochi, P Milz, K Nishida, M Yoshimura", "title": "The cross-frequency mediation mechanism of intracortical information\n  transactions", "comments": "https://doi.org/10.1101/119362 licensed as CC-BY-NC-ND 4.0\n  International license: http://creativecommons.org/licenses/by-nc-nd/4.0/", "journal-ref": null, "doi": "10.1101/119362", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In a seminal paper by von Stein and Sarnthein (2000), it was hypothesized\nthat \"bottom-up\" information processing of \"content\" elicits local, high\nfrequency (beta-gamma) oscillations, whereas \"top-down\" processing is\n\"contextual\", characterized by large scale integration spanning distant\ncortical regions, and implemented by slower frequency (theta-alpha)\noscillations. This corresponds to a mechanism of cortical information\ntransactions, where synchronization of beta-gamma oscillations between distant\ncortical regions is mediated by widespread theta-alpha oscillations. It is the\naim of this paper to express this hypothesis quantitatively, in terms of a\nmodel that will allow testing this type of information transaction mechanism.\nThe basic methodology used here corresponds to statistical mediation analysis,\noriginally developed by (Baron and Kenny 1986). We generalize the classical\nmediator model to the case of multivariate complex-valued data, consisting of\nthe discrete Fourier transform coefficients of signals of electric neuronal\nactivity, at different frequencies, and at different cortical locations. The\n\"mediation effect\" is quantified here in a novel way, as the product of \"dual\nfrequency RV-coupling coefficients\", that were introduced in (Pascual-Marqui et\nal 2016, http://arxiv.org/abs/1603.05343). Relevant statistical procedures are\npresented for testing the cross-frequency mediation mechanism in general, and\nin particular for testing the von Stein & Sarnthein hypothesis.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 13:47:00 GMT"}, {"version": "v2", "created": "Mon, 27 Mar 2017 23:10:16 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Pascual-Marqui", "RD", ""], ["Faber", "P", ""], ["Ikeda", "S", ""], ["Ishii", "R", ""], ["Kinoshita", "T", ""], ["Kitaura", "Y", ""], ["Kochi", "K", ""], ["Milz", "P", ""], ["Nishida", "K", ""], ["Yoshimura", "M", ""]]}, {"id": "1703.07738", "submitter": "Wilma Bainbridge", "authors": "Wilma A. Bainbridge", "title": "The Resiliency of Memorability: A Predictor of Memory Separate from\n  Attention and Priming", "comments": "37 pages, 9 figures", "journal-ref": null, "doi": "10.1016/j.neuropsychologia.2020.107408", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we encounter a new person or place, we may easily encode it into our\nmemories, or we may quickly forget it. Recent work finds that this likelihood\nof encoding a given entity - memorability - is highly consistent across viewers\nand intrinsic to an image; people tend to remember and forget the same images.\nHowever, several forces influence our memories beyond the memorability of the\nstimulus itself - for example, how attention-grabbing the stimulus is, how much\nattentional resources we dedicate to the task, or how primed we are for that\nstimulus. How does memorability interact with these various phenomena, and\ncould any of them explain the effects of memorability found in prior work? This\nstudy uses five psychophysical experiments to explore the link between\nmemorability and three attention-related phenomena: 1) bottom-up attention\n(through testing spatial cueing and visual search), 2) top-down attention\n(through testing cognitive control and depth of encoding), and 3) priming.\nThese experiments find that memorability remains resilient to all of these\nphenomena - none are able to explain memorability effects or overcome the\nstrong effects memorability has on determining memory performance. Thus,\nmemorability is truly an independent, intrinsic attribute of an image that\nworks in conjunction with these phenomena to determine if an event will\nultimately be remembered.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 16:35:04 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Bainbridge", "Wilma A.", ""]]}, {"id": "1703.07914", "submitter": "Cengiz Pehlevan", "authors": "Cengiz Pehlevan, Anirvan Sengupta, Dmitri B. Chklovskii", "title": "Why do similarity matching objectives lead to Hebbian/anti-Hebbian\n  networks?", "comments": "Accepted for publication in Neural Computation", "journal-ref": null, "doi": "10.1162/neco_a_01018", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling self-organization of neural networks for unsupervised learning using\nHebbian and anti-Hebbian plasticity has a long history in neuroscience. Yet,\nderivations of single-layer networks with such local learning rules from\nprincipled optimization objectives became possible only recently, with the\nintroduction of similarity matching objectives. What explains the success of\nsimilarity matching objectives in deriving neural networks with local learning\nrules? Here, using dimensionality reduction as an example, we introduce several\nvariable substitutions that illuminate the success of similarity matching. We\nshow that the full network objective may be optimized separately for each\nsynapse using local learning rules both in the offline and online settings. We\nformalize the long-standing intuition of the rivalry between Hebbian and\nanti-Hebbian rules by formulating a min-max optimization problem. We introduce\na novel dimensionality reduction objective using fractional matrix exponents.\nTo illustrate the generality of our approach, we apply it to a novel\nformulation of dimensionality reduction combined with whitening. We confirm\nnumerically that the networks with learning rules derived from principled\nobjectives perform better than those with heuristic learning rules.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 03:16:19 GMT"}, {"version": "v2", "created": "Tue, 11 Jul 2017 23:02:09 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Pehlevan", "Cengiz", ""], ["Sengupta", "Anirvan", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1703.07943", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Role of zero synapses in unsupervised feature learning", "comments": "6 pages, 4 figures, to appear in J. Phys A as a LETTER", "journal-ref": null, "doi": "10.1088/1751-8121/aaa631", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synapses in real neural circuits can take discrete values, including zero\n(silent or potential) synapses. The computational role of zero synapses in\nunsupervised feature learning of unlabeled noisy data is still unclear, thus it\nis important to understand how the sparseness of synaptic activity is shaped\nduring learning and its relationship with receptive field formation. Here, we\nformulate this kind of sparse feature learning by a statistical mechanics\napproach. We find that learning decreases the fraction of zero synapses, and\nwhen the fraction decreases rapidly around a critical data size, an\nintrinsically structured receptive field starts to develop. Further increasing\nthe data size refines the receptive field, while a very small fraction of zero\nsynapses remain to act as contour detectors. This phenomenon is discovered not\nonly in learning a handwritten digits dataset, but also in learning retinal\nneural activity measured in a natural-movie-stimuli experiment.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 06:19:47 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 08:07:52 GMT"}, {"version": "v3", "created": "Wed, 12 Jul 2017 05:13:42 GMT"}, {"version": "v4", "created": "Wed, 10 Jan 2018 06:57:00 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1703.08513", "submitter": "Stefan Heinrich", "authors": "Stefan Heinrich and Stefan Wermter", "title": "Interactive Natural Language Acquisition in a Multi-modal Recurrent\n  Neural Architecture", "comments": "Received 25 June 2016; Accepted 1 February 2017", "journal-ref": "Connection Science, vol 30, No 1, pp. 99-133, 2017", "doi": "10.1080/09540091.2017.1318357", "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the complex human brain that enables us to communicate in natural\nlanguage, we gathered good understandings of principles underlying language\nacquisition and processing, knowledge about socio-cultural conditions, and\ninsights about activity patterns in the brain. However, we were not yet able to\nunderstand the behavioural and mechanistic characteristics for natural language\nand how mechanisms in the brain allow to acquire and process language. In\nbridging the insights from behavioural psychology and neuroscience, the goal of\nthis paper is to contribute a computational understanding of appropriate\ncharacteristics that favour language acquisition. Accordingly, we provide\nconcepts and refinements in cognitive modelling regarding principles and\nmechanisms in the brain and propose a neurocognitively plausible model for\nembodied language acquisition from real world interaction of a humanoid robot\nwith its environment. In particular, the architecture consists of a continuous\ntime recurrent neural network, where parts have different leakage\ncharacteristics and thus operate on multiple timescales for every modality and\nthe association of the higher level nodes of all modalities into cell\nassemblies. The model is capable of learning language production grounded in\nboth, temporal dynamic somatosensation and vision, and features hierarchical\nconcept abstraction, concept decomposition, multi-modal integration, and\nself-organisation of latent representations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 17:13:08 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 16:08:05 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Heinrich", "Stefan", ""], ["Wermter", "Stefan", ""]]}, {"id": "1703.08644", "submitter": "Sean Jewell", "authors": "Sean Jewell and Daniela Witten", "title": "Exact Spike Train Inference Via $\\ell_0$ Optimization", "comments": "28 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, new technologies in neuroscience have made it possible to\nmeasure the activities of large numbers of neurons simultaneously in behaving\nanimals. For each neuron, a fluorescence trace is measured; this can be seen as\na first-order approximation of the neuron's activity over time. Determining the\nexact time at which a neuron spikes on the basis of its fluorescence trace is\nan important open problem in the field of computational neuroscience.\n  Recently, a convex optimization problem involving an $\\ell_1$ penalty was\nproposed for this task. In this paper, we slightly modify that recent proposal\nby replacing the $\\ell_1$ penalty with an $\\ell_0$ penalty. In stark contrast\nto the conventional wisdom that $\\ell_0$ optimization problems are\ncomputationally intractable, we show that the resulting optimization problem\ncan be efficiently solved for the global optimum using an extremely simple and\nefficient dynamic programming algorithm. Our R-language implementation of the\nproposed algorithm runs in a few minutes on fluorescence traces of $100,000$\ntimesteps. Furthermore, our proposal leads to substantial improvements over the\nprevious $\\ell_1$ proposal, in simulations as well as on two calcium imaging\ndata sets.\n  R-language software for our proposal is available on CRAN in the package\nLZeroSpikeInference. Instructions for running this software in python can be\nfound at https://github.com/jewellsean/LZeroSpikeInference.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 03:44:05 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 22:35:01 GMT"}, {"version": "v3", "created": "Sun, 12 Nov 2017 17:46:48 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Jewell", "Sean", ""], ["Witten", "Daniela", ""]]}, {"id": "1703.09202", "submitter": "Aran Nayebi", "authors": "Aran Nayebi, Surya Ganguli", "title": "Biologically inspired protection of deep networks from adversarial\n  attacks", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by biophysical principles underlying nonlinear dendritic computation\nin neural circuits, we develop a scheme to train deep neural networks to make\nthem robust to adversarial attacks. Our scheme generates highly nonlinear,\nsaturated neural networks that achieve state of the art performance on gradient\nbased adversarial examples on MNIST, despite never being exposed to\nadversarially chosen examples during training. Moreover, these networks exhibit\nunprecedented robustness to targeted, iterative schemes for generating\nadversarial examples, including second-order methods. We further identify\nprinciples governing how these networks achieve their robustness, drawing on\nmethods from information geometry. We find these networks progressively create\nhighly flat and compressed internal representations that are sensitive to very\nfew input dimensions, while still solving the task. Moreover, they employ\nhighly kurtotic weight distributions, also found in the brain, and we\ndemonstrate how such kurtosis can protect even linear classifiers from\nadversarial attack.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 17:45:07 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Nayebi", "Aran", ""], ["Ganguli", "Surya", ""]]}, {"id": "1703.09347", "submitter": "Keith Hayton", "authors": "Keith Hayton, Dimitrios Moirogiannis, Marcelo Magnasco", "title": "Adaptive Scales of Spatial Integration and Response Latencies in a\n  Critically-Balanced Model of the Primary Visual Cortex", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0196566", "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain processes visual inputs having structure over a large range of\nspatial scales. The precise mechanisms or algorithms used by the brain to\nachieve this feat are largely unknown and an open problem in visual\nneuroscience. In particular, the spatial extent in visual space over which\nprimary visual cortex (V1) performs evidence integration has been shown to\nchange as a function of contrast and other visual parameters, thus adapting\nscale in visual space in an input-dependent manner. We demonstrate that a\nsimple dynamical mechanism---dynamical criticality---can simultaneously account\nfor the well-documented input-dependence characteristics of three properties of\nV1: scales of integration in visuotopic space, extents of lateral integration\non the cortical surface, and response latencies.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 23:42:54 GMT"}, {"version": "v2", "created": "Wed, 26 Jul 2017 21:46:24 GMT"}, {"version": "v3", "created": "Wed, 21 Mar 2018 11:35:37 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Hayton", "Keith", ""], ["Moirogiannis", "Dimitrios", ""], ["Magnasco", "Marcelo", ""]]}, {"id": "1703.09488", "submitter": "Michael Denker", "authors": "Michael Denker, Lyuba Zehl, Bj{\\o}rg E. Kilavik, Markus Diesmann,\n  Thomas Brochier, Alexa Riehle, Sonja Gr\\\"un", "title": "LFP beta amplitude is predictive of mesoscopic spatio-temporal phase\n  patterns", "comments": null, "journal-ref": "Scientific Reports 8:5200 (2018)", "doi": "10.1038/s41598-018-22990-7", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beta oscillations observed in motor cortical local field potentials (LFPs)\nrecorded on separate electrodes of a multi-electrode array have been shown to\nexhibit non-zero phase shifts that organize into a planar wave propagation.\nHere, we generalize this concept by introducing additional classes of patterns\nthat fully describe the spatial organization of beta oscillations. During a\ndelayed reach-to-grasp task in monkey primary motor and dorsal premotor\ncortices we distinguish planar, synchronized, random, circular, and radial\nphase patterns. We observe that specific patterns correlate with the beta\namplitude (envelope). In particular, wave propagation accelerates with growing\namplitude, and culminates at maximum amplitude in a synchronized pattern.\nFurthermore, the occurrence probability of a particular pattern is modulated\nwith behavioral epochs: Planar waves and synchronized patterns are more present\nduring movement preparation where beta amplitudes are large, whereas random\nphase patterns are dominant during movement execution where beta amplitudes are\nsmall.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 10:06:27 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Denker", "Michael", ""], ["Zehl", "Lyuba", ""], ["Kilavik", "Bj\u00f8rg E.", ""], ["Diesmann", "Markus", ""], ["Brochier", "Thomas", ""], ["Riehle", "Alexa", ""], ["Gr\u00fcn", "Sonja", ""]]}, {"id": "1703.09637", "submitter": "Joshua D. Salvi", "authors": "Joshua D. Salvi, Daibhid O Maoileidigh, Brian A. Fabella, Melanie\n  Tobin, and A. J. Hudspeth", "title": "Control of a hair bundle's mechanosensory function by its mechanical\n  load", "comments": null, "journal-ref": "Proc Natl Acad Sci U S A. 2015 Mar 3;112(9):E1000-9", "doi": "10.1073/pnas.1501453112", "report-no": null, "categories": "q-bio.NC physics.bio-ph q-bio.CB", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Hair cells, the sensory receptors of the internal ear, subserve different\nfunctions in various receptor organs: they detect oscillatory stimuli in the\nauditory system, but transduce constant and step stimuli in the vestibular and\nlateral-line systems. We show that a hair cell's function can be controlled\nexperimentally by adjusting its mechanical load. By making bundles from a\nsingle organ operate as any of four distinct types of signal detector, we\ndemonstrate that altering only a few key parameters can fundamentally change a\nsensory cell's role. The motions of a single hair bundle can resemble those of\na bundle from the amphibian vestibular system, the reptilian auditory system,\nor the mammalian auditory system, demonstrating an essential similarity of\nbundles across species and receptor organs.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 15:41:21 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Salvi", "Joshua D.", ""], ["Maoileidigh", "Daibhid O", ""], ["Fabella", "Brian A.", ""], ["Tobin", "Melanie", ""], ["Hudspeth", "A. J.", ""]]}, {"id": "1703.09990", "submitter": "Saeed Reza Kheradpisheh", "authors": "Matin N. Ashtiani, Saeed Reza Kheradpisheh, Timoth\\'ee Masquelier,\n  Mohammad Ganjtabesh", "title": "Object categorization in finer levels requires higher spatial\n  frequencies, and therefore takes longer", "comments": null, "journal-ref": "Frontiers in Psychology 2017", "doi": "10.3389/fpsyg.2017.01261", "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human visual system contains a hierarchical sequence of modules that take\npart in visual perception at different levels of abstraction, i.e.,\nsuperordinate, basic, and subordinate levels. One important question is to\nidentify the \"entry\" level at which the visual representation is commenced in\nthe process of object recognition. For a long time, it was believed that the\nbasic level had advantage over two others; a claim that has been challenged\nrecently. Here we used a series of psychophysics experiments, based on a rapid\npresentation paradigm, as well as two computational models, with bandpass\nfiltered images to study the processing order of the categorization levels. In\nthese experiments, we investigated the type of visual information required for\ncategorizing objects in each level by varying the spatial frequency bands of\nthe input image. The results of our psychophysics experiments and computational\nmodels are consistent. They indicate that the different spatial frequency\ninformation had different effects on object categorization in each level. In\nthe absence of high frequency information, subordinate and basic level\ncategorization are performed inaccurately, while superordinate level is\nperformed well. This means that, low frequency information is sufficient for\nsuperordinate level, but not for the basic and subordinate levels. These finer\nlevels require high frequency information, which appears to take longer to be\nprocessed, leading to longer reaction times. Finally, to avoid the ceiling\neffect, we evaluated the robustness of the results by adding different amounts\nof noise to the input images and repeating the experiments. As expected, the\ncategorization accuracy decreased and the reaction time increased\nsignificantly, but the trends were the same.This shows that our results are not\ndue to a ceiling effect.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 12:03:21 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Ashtiani", "Matin N.", ""], ["Kheradpisheh", "Saeed Reza", ""], ["Masquelier", "Timoth\u00e9e", ""], ["Ganjtabesh", "Mohammad", ""]]}, {"id": "1703.10062", "submitter": "Sofia Ira Ktena", "authors": "Sofia Ira Ktena, Salim Arslan, Sarah Parisot, Daniel Rueckert", "title": "Exploring Heritability of Functional Brain Networks with Inexact Graph\n  Matching", "comments": "accepted at ISBI 2017: International Symposium on Biomedical Imaging,\n  Apr 2017, Melbourne, Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven brain parcellations aim to provide a more accurate representation\nof an individual's functional connectivity, since they are able to capture\nindividual variability that arises due to development or disease. This renders\ncomparisons between the emerging brain connectivity networks more challenging,\nsince correspondences between their elements are not preserved. Unveiling these\ncorrespondences is of major importance to keep track of local functional\nconnectivity changes. We propose a novel method based on graph edit distance\nfor the comparison of brain graphs directly in their domain, that can\naccurately reflect similarities between individual networks while providing the\nnetwork element correspondences. This method is validated on a dataset of 116\ntwin subjects provided by the Human Connectome Project.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 14:24:52 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Ktena", "Sofia Ira", ""], ["Arslan", "Salim", ""], ["Parisot", "Sarah", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1703.10363", "submitter": "Mattia  Zorzi", "authors": "Giulia Prando, Mattia Zorzi, Alessandra Bertoldo and Alessandro Chiuso", "title": "Estimating effective connectivity in linear brain network models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary neuroscience has embraced network science to study the complex\nand self-organized structure of the human brain; one of the main outstanding\nissues is that of inferring from measure data, chiefly functional Magnetic\nResonance Imaging (fMRI), the so-called effective connectivity in brain\nnetworks, that is the existing interactions among neuronal populations. This\ninverse problem is complicated by the fact that the BOLD (Blood Oxygenation\nLevel Dependent) signal measured by fMRI represent a dynamic and nonlinear\ntransformation (the hemodynamic response) of neuronal activity. In this paper,\nwe consider resting state (rs) fMRI data; building upon a linear population\nmodel of the BOLD signal and a stochastic linear DCM model, the model\nparameters are estimated through an EM-type iterative procedure, which\nalternately estimates the neuronal activity by means of the Rauch-Tung-Striebel\n(RTS) smoother, updates the connections among neuronal states and refines the\nparameters of the hemodynamic model; sparsity in the interconnection structure\nis favoured using an iteratively reweighting scheme. Experimental results using\nrs-fMRI data are shown demonstrating the effectiveness of our approach and\ncomparison with state of the art routines (SPM12 toolbox) is provided.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 08:50:26 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Prando", "Giulia", ""], ["Zorzi", "Mattia", ""], ["Bertoldo", "Alessandra", ""], ["Chiuso", "Alessandro", ""]]}, {"id": "1703.10449", "submitter": "Eve Armstrong", "authors": "Eve Armstrong", "title": "A Neural Networks Approach to Predicting How Things Might Have Turned\n  Out Had I Mustered the Nerve to Ask Barry Cottonfield to the Junior Prom Back\n  in 1997", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.pop-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a feed-forward artificial neural network with back-propagation through\na single hidden layer to predict Barry Cottonfield's likely reply to this\nauthor's invitation to the \"Once Upon a Daydream\" junior prom at the Conard\nHigh School gymnasium back in 1997. To examine the network's ability to\ngeneralize to such a situation beyond specific training scenarios, we use a L2\nregularization term in the cost function and examine performance over a range\nof regularization strengths. In addition, we examine the nonsensical\ndecision-making strategies that emerge in Barry at times when he has recently\nengaged in a fight with his annoying kid sister Janice. To simulate Barry's\ninability to learn efficiently from large mistakes (an observation well\ndocumented by his algebra teacher during sophomore year), we choose a simple\nquadratic form for the cost function, so that the weight update magnitude is\nnot necessary correlated with the magnitude of output error.\n  Network performance on test data indicates that this author would have\nreceived an 87.2 (1)% chance of \"Yes\" given a particular set of environmental\ninput parameters. Most critically, the optimal method of question delivery is\nfound to be Secret Note rather than Verbal Speech. There also exists mild\nevidence that wearing a burgundy mini-dress might have helped. The network\nperforms comparably for all values of regularization strength, which suggests\nthat the nature of noise in a high school hallway during passing time does not\naffect much of anything. We comment on possible biases inherent in the output,\nimplications regarding the functionality of a real biological network, and\nfuture directions. Over-training is also discussed, although the linear algebra\nteacher assures us that in Barry's case this is not possible.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 12:59:42 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Armstrong", "Eve", ""]]}, {"id": "1703.10621", "submitter": "Takashi Nishikawa", "authors": "Liyue Zhang, Adilson E. Motter, Takashi Nishikawa", "title": "Incoherence-Mediated Remote Synchronization", "comments": "5 pages, 4 figures, Supplemental Material (7 pages, 9 figures);\n  missing links added to the network in Fig. 2(a)", "journal-ref": "Phys. Rev. Lett. 118, 174102 (2017)", "doi": "10.1103/PhysRevLett.118.174102", "report-no": null, "categories": "nlin.AO cond-mat.dis-nn physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previously identified forms of remote synchronization between two nodes,\nthe intermediate portion of the network connecting the two nodes is not\nsynchronized with them but generally exhibits some coherent dynamics. Here we\nreport on a network phenomenon we call incoherence-mediated remote\nsynchronization (IMRS), in which two non-contiguous parts of the network are\nidentically synchronized while the dynamics of the intermediate part is\nstatistically and information-theoretically incoherent. We identify mirror\nsymmetry in the network structure as a mechanism allowing for such behavior,\nand show that IMRS is robust against dynamical noise as well as against\nparameter changes. IMRS may underlie neuronal information processing and\npotentially lead to network solutions for encryption key distribution and\nsecure communication.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 18:08:37 GMT"}, {"version": "v2", "created": "Mon, 1 May 2017 22:57:08 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 22:00:59 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Zhang", "Liyue", ""], ["Motter", "Adilson E.", ""], ["Nishikawa", "Takashi", ""]]}, {"id": "1703.10627", "submitter": "Mans Henningson", "authors": "M{\\aa}ns Henningson and Sebastian Illes", "title": "Analysis and Modelling of Subthreshold Neural Multi-electrode Array Data\n  by Statistical Field Theory", "comments": "27 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-electrode arrays (MEA) are increasingly used to investigate spontaneous\nneuronal network activity. The recorded signals comprise several distinct\ncomponents: Apart from artefacts without biological significance, one can\ndistinguish between spikes (action potentials) and subthreshold fluctuations\n(local fields potentials). Here we aim to develop a theoretical model that\nallows for a compact and robust characterization of subthreshold fluctuations\nin terms of a Gaussian statistical field theory in two spatial and one temporal\ndimension. What is usually referred to as the driving noise in the context of\nstatistical physics is here interpreted as a representation of the neural\nactivity. Spatial and temporal correlations of this activity give valuable\ninformation about the connectivity in the neural tissue. We apply our methods\non a dataset obtained from MEA-measurements in an acute hippocampal brain slice\nfrom a rat. Our main finding is that the empirical correlation functions indeed\nobey the logarithmic behaviour that is a general feature of theoretical models\nof this kind. We also find a clear correlation between the activity and the\noccurence of spikes. Another important insight is the importance of correcly\nseparating out certain artefacts from the data before proceeding with the\nanalysis.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 18:21:30 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Henningson", "M\u00e5ns", ""], ["Illes", "Sebastian", ""]]}, {"id": "1703.10643", "submitter": "Ann Sizemore", "authors": "Ann E. Sizemore and Danielle S. Bassett", "title": "Dynamic Graph Metrics: Tutorial, Toolbox, and Tale", "comments": "21 pages, 5 figures. Toolbox not yet publicly available", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The central nervous system is composed of many individual units -- from cells\nto areas -- that are connected with one another in a complex pattern of\nfunctional interactions that supports perception, action, and cognition. One\nnatural and parsimonious representation of such a system is a graph in which\nnodes (units) are connected by edges (interactions). While applicable across\nspatiotemporal scales, species, and cohorts, the traditional graph approach is\nunable to address the complexity of time-varying connectivity patterns that may\nbe critically important for an understanding of emotional and cognitive state,\ntask-switching, adaptation and development, or aging and disease progression.\nHere we survey a set of tools from applied mathematics that offer measures to\ncharacterize dynamic graphs. Along with this survey, we offer suggestions for\nvisualization and a publicly-available MATLAB toolbox to facilitate the\napplication of these metrics to existing or yet-to-be acquired neuroimaging\ndata. We illustrate the toolbox by applying it to a previously published data\nset of time-varying functional graphs, but note that the tools can also be\napplied to time-varying structural graphs or to other sorts of relational data\nentirely. Our aim is to provide the neuroimaging community with a useful set of\ntools, and an intuition regarding how to use them, for addressing emerging\nquestions that hinge on accurate and creative analyses of dynamic graphs.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 19:16:33 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Sizemore", "Ann E.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1703.10677", "submitter": "Yang Chen", "authors": "Yang Chen, Dong-Jie Zhao, Chao Song, Wei-He Liu, Zi-Yang Wang,\n  Zhong-Yi Wang, Guiliang Tang, and Lan Huang", "title": "Detecting causality in Plant electrical signal by a hybrid causal\n  analysis approach", "comments": "12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  At present, multi-electrode array (MEA) approach and optical recording allow\nus to acquire plant electrical activity with higher spatio-temporal resolution.\nTo understand the dynamic information flow of the electrical signaling system\nand estimate the effective connectivity, we proposed a solution to combine the\ntwo casualty analysis approaches, i.e. Granger causality and transfer entropy,\nwhich they complement each other to measure dynamics effective connectivity of\nthe complex system. Our findings in three qualitatively different levels of\nplant bioelectrical activities revealed direction of information flow and\ndynamic complex causal connectives by using the two causal analysis approaches,\nespecially indicated that the direction of information flow is not only along\nthe longitudinal section but also spreading in transection.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 02:11:45 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Chen", "Yang", ""], ["Zhao", "Dong-Jie", ""], ["Song", "Chao", ""], ["Liu", "Wei-He", ""], ["Wang", "Zi-Yang", ""], ["Wang", "Zhong-Yi", ""], ["Tang", "Guiliang", ""], ["Huang", "Lan", ""]]}, {"id": "1703.10683", "submitter": "Kieran Fox", "authors": "Kieran C.R. Fox", "title": "Neural origins of self-generated thought: Insights from intracranial\n  electrical stimulation and recordings in humans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional magnetic resonance imaging (fMRI) has begun to narrow down the\nneural correlates of self-generated forms of thought, with current evidence\npointing toward central roles for the default, frontoparietal, and visual\nnetworks. Recent work has linked the arising of thoughts more specifically to\ndefault network activity, but the limited temporal resolution of fMRI has\nprecluded more detailed conclusions about where in the brain self-created\nmental content is generated and how this is achieved. Here I argue that the\nunparalleled spatiotemporal resolution of intracranial electrophysiology (iEEG)\nin human epilepsy patients can begin to provide answers to questions about the\nspecific neural origins of self-generated thought. I review the extensive body\nof literature from iEEG studies over the past few decades and show that many\nstudies involving passive recording or direct electrical stimulation throughout\nthe brain all point to the medial temporal lobe as a key site of\nthought-generation. At the same time, null effects from other brain regions\nsuggest that various other default network hubs, such as the posterior\ncingulate cortex and inferior parietal lobule, might have only a marginal role\n(if any) in the self-generation or initiation of mental content like dreams,\nvisual imagery, memories, and prospective simulations. Ultimately, combining a\nvariety of neuroscientific methods that compensate for each other's weaknesses\nand complement each other's strengths may prove to be the most effective way to\nunderstand the brain's remarkable ability to decouple from the immediate\nenvironment and generate its own experiences.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 21:08:29 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Fox", "Kieran C. R.", ""]]}, {"id": "1703.10713", "submitter": "Jiancheng Zhuang", "authors": "Jiancheng Zhuang", "title": "Detecting Resting-state Neural Connectivity Using Dynamic Network\n  Analysis on Multiband fMRI Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an approach of using dynamic Structural Equation\nModeling (SEM) analysis to estimate the connectivity networks from\nresting-state fMRI data measured by a multiband EPI sequence. Two structural\nequation models were estimated at each voxel with respect to the sensory-motor\nnetwork and default-mode network. The resulting connectivity maps indicate that\nsupplementary motor area has significant connections to left/right primary\nmotor areas, and medial prefrontal cortex link significantly with posterior\ncingulate cortex and inferior parietal lobules. The results imply that high\ntemporal resolution images obtained with multiband fMRI data can provide\ndynamic and directional information on the neural connectivity.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 23:38:20 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Zhuang", "Jiancheng", ""]]}]