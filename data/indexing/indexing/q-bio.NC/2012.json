[{"id": "2012.00104", "submitter": "Hui Wei Dr.", "authors": "Hui Wei", "title": "A Neural Dynamic Model based on Activation Diffusion and a\n  Micro-Explanation for Cognitive Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The neural mechanism of memory has a very close relation with the problem of\nrepresentation in artificial intelligence. In this paper a computational model\nwas proposed to simulate the network of neurons in brain and how they process\ninformation. The model refers to morphological and electrophysiological\ncharacteristics of neural information processing, and is based on the\nassumption that neurons encode their firing sequence. The network structure,\nfunctions for neural encoding at different stages, the representation of\nstimuli in memory, and an algorithm to form a memory were presented. It also\nanalyzed the stability and recall rate for learning and the capacity of memory.\nBecause neural dynamic processes, one succeeding another, achieve a\nneuron-level and coherent form by which information is represented and\nprocessed, it may facilitate examination of various branches of Artificial\nIntelligence, such as inference, problem solving, pattern recognition, natural\nlanguage processing and learning. The processes of cognitive manipulation\noccurring in intelligent behavior have a consistent representation while all\nbeing modeled from the perspective of computational neuroscience. Thus, the\ndynamics of neurons make it possible to explain the inner mechanisms of\ndifferent intelligent behaviors by a unified model of cognitive architecture at\na micro-level.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 01:34:08 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Wei", "Hui", ""]]}, {"id": "2012.00667", "submitter": "Krzysztof Kotowski", "authors": "W. Sommer, K. Stapor, G. Konczak, K. Kotowski, P. Fabian, J. Ochab, A.\n  Beres, G. Slusarczyk", "title": "Single trial ERP amplitudes reveal the time course of acquiring\n  representations of novel faces in individual participants", "comments": "36 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The neural correlates of face individuation - the acquisition of memory\nrepresentations for novel faces - have been studied only in coarse detail and\ndisregarding individual differences between learners. In their seminal study,\n(Tanaka, Curran, Porterfield, & Collins, 2006) required the identification of a\nparticular novel face across 70 trials and found that the N250 component in the\nERP became more negative from the first to the second half of the experiment,\nwhere it reached a similar amplitude as a well-known face. We were unable to\ndirectly replicate this finding in our study when we used the original split of\ntrials. However, when we applied a different split of trials we observed very\nsimilar changes in N250 amplitude. Then, we developed and applied a new\ntwo-step explorative-confirmative non-parametric method based on permutation\ntesting to determine the time course of face individuation in individual\nparticipants based on single-trial N250 amplitudes. We show that the assumption\nof a steep initial increase of N250 amplitude across multiple presentations of\nthe target face, followed by a plateau, yields plausible results in fitting\nlinear trends for most participants. The transition point from initial\nacquisition to the plateau phase differed strongly between participants and\ntended to be earlier when performance in target face recognition was better.\nHence, face individuation may be accounted for by a biphasic process of early,\nfast acquisition, followed by a slower, asymptotic consolidation or maintenance\nphase. The current approach might be fruitfully applied to further\ninvestigations into face individuation and their neural correlates\n", "versions": [{"version": "v1", "created": "Tue, 1 Dec 2020 17:39:40 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Sommer", "W.", ""], ["Stapor", "K.", ""], ["Konczak", "G.", ""], ["Kotowski", "K.", ""], ["Fabian", "P.", ""], ["Ochab", "J.", ""], ["Beres", "A.", ""], ["Slusarczyk", "G.", ""]]}, {"id": "2012.00675", "submitter": "Tananun Songdechakraiwut", "authors": "Tananun Songdechakraiwut and Moo K. Chung", "title": "Topological Learning for Brain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel topological learning framework that can integrate\nbrain networks of different sizes and topology through persistent homology.\nThis is possible through the introduction of a new topological loss function\nthat enables such challenging task. The use of the proposed loss function\nbypasses the intrinsic computational bottleneck associated with matching\nnetworks. We validate the method in extensive statistical simulations with\nground truth to assess the effectiveness of the topological loss in\ndiscriminating networks with different topology. The method is further applied\nto a twin brain imaging study in determining if the brain network is\ngenetically heritable. The challenge is in overlaying the topologically\ndifferent functional brain networks obtained from the resting-state functional\nMRI (fMRI) onto the template structural brain network obtained through the\ndiffusion MRI (dMRI).\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 18:46:36 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2020 05:51:52 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Songdechakraiwut", "Tananun", ""], ["Chung", "Moo K.", ""]]}, {"id": "2012.00695", "submitter": "Janusz Jacak", "authors": "W. A. Jacak, J. E. Jacak", "title": "The topological non-local braid-group concept of information processing\n  in brain, the different role of the gray and white matter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The velocity of the action potential transduction along myelinated axons in\nthe peripheral nervous system or in the white matter of brain and spinal cord\nreaches hundreds of meters per second to assure proper functioning of the body,\nwhich exceeds the ability of diffusive ion conduction. We propose the new model\nof the saltatory conduction based on a plasmon-polariton kinetics in myelinated\naxons, which excludes, however, the white matter form the information storage\nand its identification in the brain via e-m response. We propose a nonlocal\ntopological approach to information processing in the cortex of brain in\nconsistence with the ion electricity of the gray matter and a supplementary\nonly communication role of the white matter.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 07:47:09 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Jacak", "W. A.", ""], ["Jacak", "J. E.", ""]]}, {"id": "2012.01074", "submitter": "Giulia Cisotto", "authors": "Giulia Cisotto, Alessio Zanga, Joanna Chlebus, Italo Zoppis, Sara\n  Manzoni, and Urszula Markowska-Kaczmar", "title": "Comparison of Attention-based Deep Learning Models for EEG\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To evaluate the impact on Electroencephalography (EEG)\nclassification of different kinds of attention mechanisms in Deep Learning (DL)\nmodels. Methods: We compared three attention-enhanced DL models, the brand-new\nInstaGATs, an LSTM with attention and a CNN with attention. We used these\nmodels to classify normal and abnormal (i.e., artifactual or pathological) EEG\npatterns. Results: We achieved the state of the art in all classification\nproblems, regardless the large variability of the datasets and the simple\narchitecture of the attention-enhanced models. We could also prove that,\ndepending on how the attention mechanism is applied and where the attention\nlayer is located in the model, we can alternatively leverage the information\ncontained in the time, frequency or space domain of the dataset. Conclusions:\nwith this work, we shed light over the role of different attention mechanisms\nin the classification of normal and abnormal EEG patterns. Moreover, we\ndiscussed how they can exploit the intrinsic relationships in the temporal,\nfrequency and spatial domains of our brain activity. Significance: Attention\nrepresents a promising strategy to evaluate the quality of the EEG information,\nand its relevance, in different real-world scenarios. Moreover, it can make it\neasier to parallelize the computation and, thus, to speed up the analysis of\nbig electrophysiological (e.g., EEG) datasets.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 10:43:41 GMT"}], "update_date": "2020-12-03", "authors_parsed": [["Cisotto", "Giulia", ""], ["Zanga", "Alessio", ""], ["Chlebus", "Joanna", ""], ["Zoppis", "Italo", ""], ["Manzoni", "Sara", ""], ["Markowska-Kaczmar", "Urszula", ""]]}, {"id": "2012.01328", "submitter": "Justin Jude", "authors": "Justin Jude and Matthias H. Hennig", "title": "Hippocampal representations emerge when training recurrent neural\n  networks on a memory dependent maze navigation task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Can neural networks learn goal-directed behaviour using similar strategies to\nthe brain, by combining the relationships between the current state of the\norganism and the consequences of future actions? Recent work has shown that\nrecurrent neural networks trained on goal based tasks can develop\nrepresentations resembling those found in the brain, entorhinal cortex grid\ncells, for instance. Here we explore the evolution of the dynamics of their\ninternal representations and compare this with experimental data. We observe\nthat once a recurrent network is trained to learn the structure of its\nenvironment solely based on sensory prediction, an attractor based landscape\nforms in the network's representation, which parallels hippocampal place cells\nin structure and function. Next, we extend the predictive objective to include\nQ-learning for a reward task, where rewarding actions are dependent on delayed\ncue modulation. Mirroring experimental findings in hippocampus recordings in\nrodents performing the same task, this training paradigm causes nonlocal neural\nactivity to sweep forward in space at decision points, anticipating the future\npath to a rewarded location. Moreover, prevalent choice and cue-selective\nneurons form in this network, again recapitulating experimental findings.\nTogether, these results indicate that combining predictive, unsupervised\nlearning of the structure of an environment with reinforcement learning can\nhelp understand the formation of hippocampus-like representations containing\nboth spatial and task-relevant information.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 16:55:02 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 17:36:54 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Jude", "Justin", ""], ["Hennig", "Matthias H.", ""]]}, {"id": "2012.01501", "submitter": "Olha Shchur", "authors": "Alexander Vidybida and Olha Shchur", "title": "Moment-generating function of output stream of leaky integrate-and-fire\n  neuron", "comments": "10 pages, 3 figures, manuscript accepted by Ukrainian Journal of\n  Physics", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistics of the output activity of a neuron during its stimulation by\nthe stream of input impulses that forms the stochastic Poisson process is\nstudied. The leaky integrate-and-fire neuron is considered as a neuron model. A\nnew representation of the probability distribution function of the output\ninterspike interval durations is found. Based on it, the moment-generating\nfunction of the probability distribution is calculated explicitly. The latter,\naccording to Curtiss theorem, completely determines the distribution itself. In\nparticular, explicit expressions are derived from the moment-generating\nfunction for the moments of all orders. The first moment coincides with the one\nfound earlier. Formulas for the second and third moments have been checked\nnumerically by direct modeling of the stochastic dynamics of a neuron with\nspecific physical parameters.\n", "versions": [{"version": "v1", "created": "Wed, 2 Dec 2020 20:07:39 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Vidybida", "Alexander", ""], ["Shchur", "Olha", ""]]}, {"id": "2012.01637", "submitter": "Hermann Riecke", "authors": "Xize Xu and Hermann Riecke", "title": "Paradoxical phase response of gamma rhythms facilitates their\n  entrainment in heterogeneous networks", "comments": "24 pages, 7 Figs, 3 Supp Figs", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The synchronization of different $\\gamma$-rhythms arising in different brain\nareas has been implicated in various cognitive functions. Here, we focus on the\neffect of the ubiquitous neuronal heterogeneity on the synchronization of PING\n(pyramidal-interneuronal network gamma) and ING (interneuronal network gamma)\nrhythms. The synchronization properties of rhythms depends on the response of\ntheir collective phase to external input. We therefore determined the\nmacroscopic phase-response curve for finite-amplitude perturbations (fmPRC),\nusing numerical simulation of all-to-all coupled networks of integrate-and-fire\n(IF) neurons exhibiting either PING or ING rhythms. We show that the intrinsic\nneuronal heterogeneity can qualitatively modify the fmPRC. While the\nphase-response curve for the individual IF-neurons is strictly positive (type\nI), the fmPRC can be biphasic and exhibit both signs (type II). Thus, for PING\nrhythms, an external excitation to the excitatory cells can, in fact, delay the\ncollective oscillation of the network, even though the same excitation would\nlead to an advance when applied to uncoupled neurons. This paradoxical delay\narises when the external excitation modifies the internal dynamics of the\nnetwork by causing additional spikes of inhibitory neurons, whose delaying\nwithin-network inhibition outweighs the immediate advance caused by the\nexternal excitation. These results explain how intrinsic heterogeneity allows\nthe PING rhythm to become synchronized with a periodic forcing or another PING\nrhythm for a wider range in the mismatch of their frequencies. We demonstrate a\nsimilar mechanism for the synchronization of ING rhythms. Our results identify\na potential function of neuronal heterogeneity in the synchronization of\ncoupled $\\gamma$-rhythms, which may play a role in neural information transfer\nvia communication through coherence.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 01:58:35 GMT"}], "update_date": "2020-12-04", "authors_parsed": [["Xu", "Xize", ""], ["Riecke", "Hermann", ""]]}, {"id": "2012.02246", "submitter": "Gabriel Schamberg", "authors": "Gabriel Schamberg, Sourish Chakravarty, Taylor E. Baum, Emery N. Brown", "title": "Inferring neural dynamics during burst suppression using a\n  neurophysiology-inspired switching state-space model", "comments": "To appear in the proceedings of the 2020 IEEE Asilomar Conference on\n  Signals, Systems, and Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Burst suppression is an electroencephalography (EEG) pattern associated with\nprofoundly inactivated brain states characterized by cerebral metabolic\ndepression. Its distinctive feature is alternation between short temporal\nsegments of near-isoelectric inactivity (suppressions) and relatively\nhigh-voltage activity (bursts). Prior modeling studies suggest that\nburst-suppression EEG is a manifestation of two alternating brain states\nassociated with consumption (during a burst) and production (during a\nsuppression) of adenosine triphosphate (ATP). This finding motivates us to\ninfer latent states characterizing alternating brain states and underlying ATP\nkinetics from instantaneous power of multichannel EEG using a switching\nstate-space model. Our model assumes Gaussian distributed data as a broadcast\nnetwork manifestation of one of two global brain states. The two brain states\nare allowed to stochastically alternate with transition probabilities that\ndepend on the instantaneous ATP level, which evolves according to first-order\nkinetics. The rate constants governing the ATP kinetics are allowed to vary as\nfirst-order autoregressive processes. Our latent state estimates are determined\nfrom data using a sequential Monte Carlo algorithm. Our\nneurophysiology-informed model not only provides unsupervised segmentation of\nmulti-channel burst-suppression EEG but can also generate additional insights\non the level of brain inactivation during anesthesia.\n", "versions": [{"version": "v1", "created": "Thu, 3 Dec 2020 20:30:46 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Schamberg", "Gabriel", ""], ["Chakravarty", "Sourish", ""], ["Baum", "Taylor E.", ""], ["Brown", "Emery N.", ""]]}, {"id": "2012.02361", "submitter": "Storm Slivkoff", "authors": "Storm Slivkoff, Jack L. Gallant", "title": "Design of Complex Experiments Using Mixed Integer Linear Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few decades, neuroscience experiments have become increasingly\ncomplex and naturalistic. Experimental design has in turn become more\nchallenging, as experiments must conform to an ever-increasing diversity of\ndesign constraints. In this article we demonstrate how this design process can\nbe greatly assisted using an optimization tool known as Mixed Integer Linear\nProgramming (MILP). MILP provides a rich framework for incorporating many types\nof real-world design constraints into a neuroimaging experiment. We introduce\nthe mathematical foundations of MILP, compare MILP to other experimental design\ntechniques, and provide four case studies of how MILP can be used to solve\ncomplex experimental design challenges.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 01:49:43 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Slivkoff", "Storm", ""], ["Gallant", "Jack L.", ""]]}, {"id": "2012.02867", "submitter": "Richard Granger", "authors": "A Rodriguez, R Granger", "title": "On the contrast-dependence of crowding", "comments": "Journal of Vision, in press", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual clutter affects our ability to see: objects that would be identifiable\non their own, may become unrecognizable when presented close together\n(\"crowding\") -- but the psychophysical characteristics of crowding have\nresisted simplification. Image properties initially thought to produce crowding\nhave paradoxically yielded unexpected results, e.g., adding flanking objects\ncan ameliorate crowding (Manassi, Sayim et al., 2012; Herzog, Sayim et al.,\n2015; Pachai, Doerig et al., 2016). The resulting theory revisions have been\nsufficiently complex and specialized as to make it difficult to discern what\nprinciples may underlie the observed phenomena. A generalized formulation of\nsimple visual contrast energy is presented, arising from straightforward\nanalyses of center and surround neurons in the early visual stream. Extant\ncontrast measures, such as RMS contrast, are easily shown to fall out as\nreduced special cases. The new generalized contrast energy metric surprisingly\npredicts the principal findings of a broad range of crowding studies. These\nearly crowding phenomena may thus be said to arise predominantly from contrast,\nor are, at least, severely confounded by contrast effects. (These findings may\nbe distinct from accounts of other, likely downstream, \"configural\" or\n\"semantic\" instances of crowding, suggesting at least two separate forms of\ncrowding that may resist unification.) The new fundamental contrast energy\nformulation provides a candidate explanatory framework that addresses multiple\npsychophysical phenomena beyond crowding.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 21:53:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Rodriguez", "A", ""], ["Granger", "R", ""]]}, {"id": "2012.03240", "submitter": "George F. R. Ellis", "authors": "George Ellis and Carole Bloch", "title": "Neuroscience and Literacy: An Integrative View", "comments": "Main text 42 pages, 6 figures. Published version: Transactions of the\n  Royal Society of South Africa (14 May 2021), DOI:\n  10.1080/0035919X.2021.1912848", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Significant challenges exist globally regarding literacy teaching and\nlearning. To address these challenges, key features of how the brain works\nshould be taken into account. First, perception is an active process based in\ndetection of errors in hierarchical predictions of sensory data and action\noutcomes. Reading is a particular case of this non-linear predictive process.\nSecond, emotions play a key role in underlying cognitive functioning, including\noral and written language. Negative emotions undermine motivation to learn.\nThird, there is not the fundamental difference between listening/speaking and\nreading/writing often alleged on the basis of evolutionary arguments. Both are\nsocio-cultural practices that are driven through the communication imperative\nof the social brain. Fourth, both listening and reading are contextually\noccurring pyscho-social practices of understanding, shaped by current knowledge\nand cutlural contexts and practices. Fifth, the natural operation of the brain\nis not rule-based, as is supposed in the standard view of linguistics: it is\nprediction, based on statistical pattern recognition. This all calls into\nquestion narrow interpretations of the widely quoted \"Simple View of Reading\",\nwhich argues that explict decoding is the necessary route to comprehension. One\nof the two neural routes to reading does not involve such explicit decoding\nprocesses, and can be activated from the earliest years. An integrated view of\nbrain function reflecting the non-linear contextual nature of the reading\nprocess implies that an ongoing focus on personal meaning and understanding\nfrom the very beginning provides positive conditions for learning all aspects\nof reading and writing.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 11:28:48 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 13:41:28 GMT"}, {"version": "v3", "created": "Thu, 25 Mar 2021 09:52:56 GMT"}, {"version": "v4", "created": "Sun, 23 May 2021 19:00:12 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Ellis", "George", ""], ["Bloch", "Carole", ""]]}, {"id": "2012.03303", "submitter": "Shixin Xu", "authors": "Yi Zhu, Shixin Xu, Robert S. Eisenberg, and Huaxiong Huang", "title": "A Tridomain Model for Potassium Clearance in Optic Nerve of Necturus", "comments": "35 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph math.AP q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The accumulation of potassium in the narrow space outside nerve cells is a\nclassical subject of biophysics that has received much attention recently. It\nmay be involved in potassium accumulation \\textcolor{black}{including}\nspreading depression, perhaps migraine and some kinds of epilepsy, even\n(speculatively) learning. Quantitative analysis is likely to help evaluate the\nrole of potassium clearance from the extracellular space after a train of\naction potentials. Clearance involves three structures that extend down the\nlength of the nerve: glia, extracellular space, and axon and so need to be\ndescribed as systems distributed in space in the tradition used for electrical\npotential in the `cable equations' of nerve since the work of Hodgkin in 1937.\nA three-compartment model is proposed here for the optic nerve and is used to\nstudy the accumulation of potassium and its clearance. The model allows the\nconvection, diffusion, and electrical migration of water and ions. We depend on\nthe data of Orkand et al to ensure the relevance of our model and align its\nparameters with the anatomy and properties of membranes, channels, and\ntransporters: our model fits their experimental data quite well. The aligned\nmodel shows that glia has an important role in buffering potassium, as\nexpected. The model shows that potassium is cleared mostly by convective flow\nthrough the syncytia of glia driven by osmotic pressure differences. A\nsimplified model might be possible, but it must involve flow down the length of\nthe optic nerve. It is easy for compartment models to neglect this flow. Our\nmodel can be used for structures quite different from the optic nerve that\nmight have different distributions of channels and transporters in its three\ncompartments. It can be generalized to include a fourth (distributed)\ncompartment representing blood vessels to deal with the glymphatic flow into\nthe circulatory system.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 16:12:33 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 13:04:17 GMT"}, {"version": "v3", "created": "Sun, 16 May 2021 15:29:09 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhu", "Yi", ""], ["Xu", "Shixin", ""], ["Eisenberg", "Robert S.", ""], ["Huang", "Huaxiong", ""]]}, {"id": "2012.03378", "submitter": "Rajesh Rao", "authors": "Rajesh P. N. Rao", "title": "Brain Co-Processors: Using AI to Restore and Augment Brain Function", "comments": "arXiv admin note: text overlap with arXiv:1811.11876", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE nlin.AO q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Brain-computer interfaces (BCIs) use decoding algorithms to control\nprosthetic devices based on brain signals for restoration of lost function.\nComputer-brain interfaces (CBIs), on the other hand, use encoding algorithms to\ntransform external sensory signals into neural stimulation patterns for\nrestoring sensation or providing sensory feedback for closed-loop prosthetic\ncontrol. In this article, we introduce brain co-processors, devices that\ncombine decoding and encoding in a unified framework using artificial\nintelligence (AI) to supplement or augment brain function. Brain co-processors\ncan be used for a range of applications, from inducing Hebbian plasticity for\nrehabilitation after brain injury to reanimating paralyzed limbs and enhancing\nmemory. A key challenge is simultaneous multi-channel neural decoding and\nencoding for optimization of external behavioral or task-related goals. We\ndescribe a new framework for developing brain co-processors based on artificial\nneural networks, deep learning and reinforcement learning. These \"neural\nco-processors\" allow joint optimization of cost functions with the nervous\nsystem to achieve desired behaviors. By coupling artificial neural networks\nwith their biological counterparts, neural co-processors offer a new way of\nrestoring and augmenting the brain, as well as a new scientific tool for brain\nresearch. We conclude by discussing the potential applications and ethical\nimplications of brain co-processors.\n", "versions": [{"version": "v1", "created": "Sun, 6 Dec 2020 21:06:28 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Rao", "Rajesh P. N.", ""]]}, {"id": "2012.03671", "submitter": "Cailey Kerley", "authors": "Cailey I. Kerley, Leon Y. Cai, Chang Yu, Logan M. Crawford, Jason M.\n  Elenberger, Eden S. Singh, Kurt G. Schilling, Katherine S. Aboud, Bennett A.\n  Landman, Tonia S. Rex", "title": "Joint analysis of structural connectivity and cortical surface features:\n  correlates with mild traumatic brain injury", "comments": "To be published in Proc SPIE Int Soc Opt Eng. 2021 Feb", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mild traumatic brain injury (mTBI) is a complex syndrome that affects up to\n600 per 100,000 individuals, with a particular concentration among military\npersonnel. About half of all mTBI patients experience a diverse array of\nchronic symptoms which persist long after the acute injury. Hence, there is an\nurgent need for better understanding of the white matter and gray matter\npathologies associated with mTBI to map which specific brain systems are\nimpacted and identify courses of intervention. Previous works have linked mTBI\nto disruptions in white matter pathways and cortical surface abnormalities.\nHerein, we examine these hypothesized links in an exploratory study of joint\nstructural connectivity and cortical surface changes associated with mTBI and\nits chronic symptoms. Briefly, we consider a cohort of 12 mTBI and 26 control\nsubjects. A set of 588 cortical surface metrics and 4,753 structural\nconnectivity metrics were extracted from cortical surface regions and diffusion\nweighted magnetic resonance imaging in each subject. Principal component\nanalysis (PCA) was used to reduce the dimensionality of each metric set. We\nthen applied independent component analysis (ICA) both to each PCA space\nindividually and together in a joint ICA approach. We identified a stable\nindependent component across the connectivity-only and joint ICAs which\npresented significant group differences in subject loadings (p<0.05,\ncorrected). Additionally, we found that two mTBI symptoms, slowed thinking and\nforgetfulness, were significantly correlated (p<0.05, corrected) with mTBI\nsubject loadings in a surface-only ICA. These surface-only loadings captured an\nincrease in bilateral cortical thickness.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 19:39:55 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 16:16:50 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Kerley", "Cailey I.", ""], ["Cai", "Leon Y.", ""], ["Yu", "Chang", ""], ["Crawford", "Logan M.", ""], ["Elenberger", "Jason M.", ""], ["Singh", "Eden S.", ""], ["Schilling", "Kurt G.", ""], ["Aboud", "Katherine S.", ""], ["Landman", "Bennett A.", ""], ["Rex", "Tonia S.", ""]]}, {"id": "2012.03849", "submitter": "Simone Palazzo", "authors": "Simone Palazzo, Concetto Spampinato, Joseph Schmidt, Isaak Kavasidis,\n  Daniela Giordano, Mubarak Shah", "title": "Correct block-design experiments mitigate temporal correlation bias in\n  EEG classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is argued in [1] that [2] was able to classify EEG responses to visual\nstimuli solely because of the temporal correlation that exists in all EEG data\nand the use of a block design. We here show that the main claim in [1] is\ndrastically overstated and their other analyses are seriously flawed by wrong\nmethodological choices. To validate our counter-claims, we evaluate the\nperformance of state-of-the-art methods on the dataset in [2] reaching about\n50% classification accuracy over 40 classes, lower than in [2], but still\nsignificant. We then investigate the influence of EEG temporal correlation on\nclassification accuracy by testing the same models in two additional\nexperimental settings: one that replicates [1]'s rapid-design experiment, and\nanother one that examines the data between blocks while subjects are shown a\nblank screen. In both cases, classification accuracy is at or near chance, in\ncontrast to what [1] reports, indicating a negligible contribution of temporal\ncorrelation to classification accuracy. We, instead, are able to replicate the\nresults in [1] only when intentionally contaminating our data by inducing a\ntemporal correlation. This suggests that what Li et al. [1] demonstrate is that\ntheir data are strongly contaminated by temporal correlation and low\nsignal-to-noise ratio. We argue that the reason why Li et al. [1] observe such\nhigh correlation in EEG data is their unconventional experimental design and\nsettings that violate the basic cognitive neuroscience design recommendations,\nfirst and foremost the one of limiting the experiments' duration, as instead\ndone in [2]. Our analyses in this paper refute the claims of the \"perils and\npitfalls of block-design\" in [1]. Finally, we conclude the paper by examining a\nnumber of other oversimplistic statements, inconsistencies, misinterpretation\nof machine learning concepts, speculations and misleading claims in [1].\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 22:25:21 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Palazzo", "Simone", ""], ["Spampinato", "Concetto", ""], ["Schmidt", "Joseph", ""], ["Kavasidis", "Isaak", ""], ["Giordano", "Daniela", ""], ["Shah", "Mubarak", ""]]}, {"id": "2012.04132", "submitter": "Neehar Kondapaneni", "authors": "Neehar Kondapaneni, Pietro Perona", "title": "A Number Sense as an Emergent Property of the Manipulating Brain", "comments": "15 pages, 6 figures, 8 supplemental figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ability to understand and manipulate numbers and quantities emerges\nduring childhood, but the mechanism through which this ability is developed is\nstill poorly understood. In particular, it is not known whether acquiring such\na {\\em number sense} is possible without supervision from a teacher.\n  To explore this question, we propose a model in which spontaneous and\nundirected manipulation of small objects trains perception to predict the\nresulting scene changes. We find that, from this task, an image representation\nemerges that exhibits regularities that foreshadow numbers and quantity. These\ninclude distinct categories for zero and the first few natural numbers, a\nnotion of order, and a signal that correlates with numerical quantity. As a\nresult, our model acquires the ability to estimate the number of objects in the\nscene, as well as {\\em subitization}, i.e. the ability to recognize at a glance\nthe exact number of objects in small scenes. We conclude that important aspects\nof a facility with numbers and quantities may be learned without explicit\nteacher supervision.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 00:37:35 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 09:51:43 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Kondapaneni", "Neehar", ""], ["Perona", "Pietro", ""]]}, {"id": "2012.04217", "submitter": "Yuzhen Qin", "authors": "Yuzhen Qin, Tommaso Menara, Danielle S. Bassett, Fabio Pasqualetti", "title": "Phase-Amplitude Coupling in Neuronal Oscillator Networks", "comments": "6 pages, 5 figures", "journal-ref": "Phys. Rev. Research 3, 023218 (2021)", "doi": "10.1103/PhysRevResearch.3.023218", "report-no": null, "categories": "q-bio.NC math.DS nlin.AO nlin.PS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Phase-amplitude coupling (PAC) describes the phenomenon where the power of a\nhigh-frequency oscillation evolves with the phase of a low-frequency one. We\npropose a model that explains the emergence of PAC in two commonly-accepted\narchitectures in the brain, namely, a high-frequency neural oscillation driven\nby an external low-frequency input and two interacting local oscillations with\ndistinct, locally-generated frequencies. We further propose an interconnection\nstructure for brain regions and demonstrate that low-frequency phase synchrony\ncan integrate high-frequency activities regulated by local PAC and control the\ndirection of information flow across distant regions.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 05:02:08 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Qin", "Yuzhen", ""], ["Menara", "Tommaso", ""], ["Bassett", "Danielle S.", ""], ["Pasqualetti", "Fabio", ""]]}, {"id": "2012.04728", "submitter": "Daniel Kunin", "authors": "Daniel Kunin, Javier Sagastuy-Brena, Surya Ganguli, Daniel L.K.\n  Yamins, Hidenori Tanaka", "title": "Neural Mechanics: Symmetry and Broken Conservation Laws in Deep Learning\n  Dynamics", "comments": "30 pages, 17 figures, ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the dynamics of neural network parameters during training is\none of the key challenges in building a theoretical foundation for deep\nlearning. A central obstacle is that the motion of a network in\nhigh-dimensional parameter space undergoes discrete finite steps along complex\nstochastic gradients derived from real-world datasets. We circumvent this\nobstacle through a unifying theoretical framework based on intrinsic symmetries\nembedded in a network's architecture that are present for any dataset. We show\nthat any such symmetry imposes stringent geometric constraints on gradients and\nHessians, leading to an associated conservation law in the continuous-time\nlimit of stochastic gradient descent (SGD), akin to Noether's theorem in\nphysics. We further show that finite learning rates used in practice can\nactually break these symmetry induced conservation laws. We apply tools from\nfinite difference methods to derive modified gradient flow, a differential\nequation that better approximates the numerical trajectory taken by SGD at\nfinite learning rates. We combine modified gradient flow with our framework of\nsymmetries to derive exact integral expressions for the dynamics of certain\nparameter combinations. We empirically validate our analytic expressions for\nlearning dynamics on VGG-16 trained on Tiny ImageNet. Overall, by exploiting\nsymmetry, our work demonstrates that we can analytically describe the learning\ndynamics of various parameter combinations at finite learning rates and batch\nsizes for state of the art architectures trained on any dataset.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 20:33:30 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 16:02:08 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Kunin", "Daniel", ""], ["Sagastuy-Brena", "Javier", ""], ["Ganguli", "Surya", ""], ["Yamins", "Daniel L. K.", ""], ["Tanaka", "Hidenori", ""]]}, {"id": "2012.04761", "submitter": "Justin Faber", "authors": "Justin Faber, Hancheng Li, Dolores Bozovic", "title": "Chaos stabilizes synchronization in systems of coupled inner-ear hair\n  cells", "comments": null, "journal-ref": "Phys. Rev. Research 3, 013266 (2021)", "doi": "10.1103/PhysRevResearch.3.013266", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hair cells of the auditory and vestibular systems display astonishing\nsensitivity, frequency selectivity, and temporal resolution to external\nsignals. These specialized cells utilize an internal active amplifier to\nachieve highly sensitive mechanical detection. One of the manifestations of\nthis active process is the occurrence of spontaneous limit-cycle motion of the\nhair cell bundle. As hair bundles under in vivo conditions are typically\ncoupled to each other by overlying structures, we explore the role of this\ncoupling on the dynamics of the system, using a combination of theoretical and\nexperimental approaches. Our numerical model suggests that the presence of\nchaotic dynamics in the response of individual bundles enhances their ability\nto synchronize when coupled, resulting in significant improvement in the\nsystem's ability to detect weak signals. This synchronization persists even for\na large frequency dispersion and a large number of oscillators comprising the\nsystem. Further, the amplitude and coherence of the active motion is not\nreduced upon increasing the number of oscillators. Using artificial membranes,\nwe impose mechanical coupling on groups of live and functional hair bundles,\nselected from in vitro preparations of the sensory epithelium, allowing us to\nexplore the role of coupling experimentally. Consistent with the numerical\nsimulations of the chaotic system, synchronization occurs even for large\nfrequency dispersion and a large number of hair cells. Further, the amplitude\nand coherence of the spontaneous oscillations are independent of the number of\nhair cells in the network. We therefore propose that hair cells utilize their\nchaotic dynamics to stabilize the synchronized state and avoid the amplitude\ndeath regime, resulting in collective coherent motion that could play a role in\ngenerating spontaneous otoacoustic emissions and an enhanced ability to detect\nweak signals.\n", "versions": [{"version": "v1", "created": "Tue, 8 Dec 2020 21:59:51 GMT"}], "update_date": "2021-03-31", "authors_parsed": [["Faber", "Justin", ""], ["Li", "Hancheng", ""], ["Bozovic", "Dolores", ""]]}, {"id": "2012.05038", "submitter": "Zhengjia Dai", "authors": "Junji Ma, Jinbo Zhang, Ying Lin and Zhengjia Dai", "title": "Cost-efficiency trade-offs of the human brain network revealed by a\n  multiobjective evolutionary algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  It is widely believed that the formation of brain network structure is under\nthe pressure of optimal trade-off between reducing wiring cost and promoting\ncommunication efficiency. However, the question of whether this trade-off\nexists in empirical human brain networks and, if so, how it takes effect is\nstill not well understood. Here, we employed a multiobjective evolutionary\nalgorithm to directly and quantitatively explore the cost-efficiency trade-off\nin human brain networks. Using this algorithm, we generated a population of\nsynthetic networks with optimal but diverse cost-efficiency trade-offs. It was\nfound that these synthetic networks could not only reproduce a large portion of\nconnections in the empirical brain networks but also embed a resembling\nsmall-world structure. Moreover, the synthetic and empirical brain networks\nwere found similar in terms of the spatial arrangement of hub regions and the\nmodular structure, which are two important topological features widely assumed\nto be outcomes of cost-efficiency trade-offs. The synthetic networks had high\nrobustness against random attack as the empirical brain networks did.\nAdditionally, we also revealed some differences of the synthetic networks from\nthe empirical brain networks, including lower segregated processing capacity\nand weaker robustness against targeted attack. These findings provide direct\nand quantitative evidence that the structure of human brain networks is indeed\nlargely influenced by optimal cost-efficiency trade-offs. We also suggest that\nsome additional factors (e.g., segregated processing capacity) might jointly\ndetermine the network organization with cost and efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 13:37:05 GMT"}], "update_date": "2020-12-10", "authors_parsed": [["Ma", "Junji", ""], ["Zhang", "Jinbo", ""], ["Lin", "Ying", ""], ["Dai", "Zhengjia", ""]]}, {"id": "2012.05454", "submitter": "Adrian Joseph Alva", "authors": "Adrian Joseph Alva and Harjinder Singh", "title": "A minimal model for synaptic integration in simple neurons", "comments": "25 pages, 8 figures", "journal-ref": "Physica D 426 (2021) 132988", "doi": "10.1016/j.physd.2021.132988", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic integration is a prominent aspect of neuronal information\nprocessing. The detailed mechanisms that modulate synaptic inputs determine the\ncomputational properties of any given neuron. We study a simple model for the\nsummation of excitatory inputs from synapses and illustrate its use by\ncharacterizing some functional properties of postsynaptic neurons. In this\nregard, we study the response of postsynaptic neurons as defined by the model\nto two well known noise driven processes: stochastic and coherence resonance.\nThe model requires a small number of parameters and is especially useful to\nisolate the role of integration mechanisms that rely on summation of inputs\nwith little dendritic processing.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 05:03:07 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 13:54:48 GMT"}, {"version": "v3", "created": "Wed, 14 Jul 2021 06:14:20 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Alva", "Adrian Joseph", ""], ["Singh", "Harjinder", ""]]}, {"id": "2012.05501", "submitter": "Bruno. Cessac", "authors": "Bruno Cessac", "title": "The Retina as a Dynamical System", "comments": "Review paper, submitted as a chapter of the \"Book in honour of Prof.\n  Miguel A.F. Sanju\\'an on his 60th Birthday\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the retina as a high dimensional, non autonomous, dynamical\nsystem, layered and structured, with non stationary and spatially inhomogeneous\nentries (visual scenes), we present several examples where dynamical systems-,\nbifurcations-, and ergodic-theory provide useful insights on retinal behaviour\nand dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 08:03:29 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Cessac", "Bruno", ""]]}, {"id": "2012.05549", "submitter": "Laurent Bonnasse-Gahot", "authors": "Laurent Bonnasse-Gahot and Jean-Pierre Nadal", "title": "Categorical Perception: A Groundwork for Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification is one of the major tasks that deep learning is successfully\ntackling. Categorization is also a fundamental cognitive ability. A well-known\nperceptual consequence of categorization in humans and other animals, called\ncategorical perception, is characterized by a within-category compression and a\nbetween-category separation: two items, close in input space, are perceived\ncloser if they belong to the same category than if they belong to different\ncategories. Elaborating on experimental and theoretical results in cognitive\nscience, here we study categorical effects in artificial neural networks. Our\nformal and numerical analysis provides insights into the geometry of the neural\nrepresentation in deep layers, with expansion of space near category boundaries\nand contraction far from category boundaries. We investigate categorical\nrepresentation by using two complementary approaches: one mimics experiments in\npsychophysics and cognitive neuroscience by means of morphed continua between\nstimuli of different categories, while the other introduces a categoricality\nindex that quantifies the separability of the classes at the population level\n(a given layer in the neural network). We show on both shallow and deep neural\nnetworks that category learning automatically induces categorical perception.\nWe further show that the deeper a layer, the stronger the categorical effects.\nAn important outcome of our analysis is to provide a coherent and unifying view\nof the efficacy of different heuristic practices of the dropout regularization\ntechnique. Our views, which find echoes in the neuroscience literature, insist\non the differential role of noise as a function of the level of representation\nand in the course of learning: noise injected in the hidden layers gets\nstructured according to the organization of the categories, more variability\nbeing allowed within a category than across classes.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 09:41:38 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Bonnasse-Gahot", "Laurent", ""], ["Nadal", "Jean-Pierre", ""]]}, {"id": "2012.05950", "submitter": "Ryan Blything", "authors": "Ryan Blything, Valerio Biscione, Jeffrey Bowers", "title": "A case for robust translation tolerance in humans and CNNs. A commentary\n  on Han et al", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Han et al. (2020) reported a behavioral experiment that assessed the extent\nto which the human visual system can identify novel images at unseen retinal\nlocations (what the authors call \"intrinsic translation invariance\") and\ndeveloped a novel convolutional neural network model (an Eccentricity Dependent\nNetwork or ENN) to capture key aspects of the behavioral results. Here we show\nthat their analysis of behavioral data used inappropriate baseline conditions,\nleading them to underestimate intrinsic translation invariance. When the data\nare correctly interpreted they show near complete translation tolerance\nextending to 14{\\deg} in some conditions, consistent with earlier work (Bowers\net al., 2016) and more recent work Blything et al. (in press). We describe a\nsimpler model that provides a better account of translation invariance.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 20:12:14 GMT"}, {"version": "v2", "created": "Mon, 14 Dec 2020 14:59:56 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Blything", "Ryan", ""], ["Biscione", "Valerio", ""], ["Bowers", "Jeffrey", ""]]}, {"id": "2012.05965", "submitter": "Corey Maley", "authors": "Corey J. Maley", "title": "Analog Computation and Representation", "comments": "To be published in British Journal for the Philosophy of Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GL q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Relative to digital computation, analog computation has been neglected in the\nphilosophical literature. To the extent that attention has been paid to analog\ncomputation, it has been misunderstood. The received view -- that analog\ncomputation has to do essentially with continuity -- is simply wrong, as shown\nby careful attention to historical examples of discontinuous, discrete analog\ncomputers. Instead of the received view, I develop an account of analog\ncomputation in terms of a particular type of analog representation that allows\nfor discontinuity. This account thus characterizes all types of analog\ncomputation, whether continuous or discrete. Furthermore, the structure of this\naccount can be generalized to other types of computation: analog computation\nessentially involves analog representation, whereas digital computation\nessentially involves digital representation. Besides being a necessary\ncomponent of a complete philosophical understanding of computation in general,\nunderstanding analog computation is important for computational explanation in\ncontemporary neuroscience and cognitive science.\n", "versions": [{"version": "v1", "created": "Thu, 10 Dec 2020 20:44:48 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Maley", "Corey J.", ""]]}, {"id": "2012.06075", "submitter": "Tonatiuh Hern\\'andez-Del-Toro M.Sc.", "authors": "Tonatiuh Hern\\'andez-Del-Toro, Carlos A. Reyes-Garc\\'ia", "title": "An algorithm for onset detection of linguistic segments in continuous\n  electroencephalogram signals", "comments": null, "journal-ref": "Proceedings of the 11th Models and Analysis of Vocal Emissions for\n  Biomedical Applications (MAVEBA), pages 249-252, Florence, Italy, 2019.\n  Firenze University Press", "doi": "10.36253/978-88-6453-961-4", "report-no": null, "categories": "eess.SP cs.CL cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Brain Computer Interface based on imagined words can decode the word a\nsubject is thinking on through brain signals to control an external device. In\norder to build a fully asynchronous Brain Computer Interface based on imagined\nwords in electroencephalogram signals as source, we need to solve the problem\nof detecting the onset of the imagined words. Although there has been some\nresearch in this field, the problem has not been fully solved. In this paper we\npresent an approach to solve this problem by using values from statistics,\ninformation theory and chaos theory as features to correctly identify the onset\nof imagined words in a continuous signal. On detecting the onsets of imagined\nwords, the highest True Positive Rate achieved by our approach was obtained\nusing features based on the generalized Hurst exponent, this True Positive Rate\nwas 0.69 and 0.77 with a timing error tolerance region of 3 and 4 seconds\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 01:38:06 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Hern\u00e1ndez-Del-Toro", "Tonatiuh", ""], ["Reyes-Garc\u00eda", "Carlos A.", ""]]}, {"id": "2012.06112", "submitter": "Swapna Sasi Mrs", "authors": "Pranav Mahajan, Advait Rane, Swapna Sasi, Basabdatta Sen Bhattacharya", "title": "Quantifying Synchronization in a Biologically Inspired Neural Network", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a collated set of algorithms to obtain objective measures of\nsynchronisation in brain time-series data. The algorithms are implemented in\nMATLAB; we refer to our collated set of 'tools' as SyncBox. Our motivation for\nSyncBox is to understand the underlying dynamics in an existing population\nneural network, commonly referred to as neural mass models, that mimic Local\nField Potentials of the visual thalamic tissue. Specifically, we aim to measure\nthe phase synchronisation objectively in the model response to periodic\nstimuli; this is to mimic the condition of\nSteady-state-visually-evoked-potentials (SSVEP), which are scalp\nElectroencephalograph (EEG) corresponding to periodic stimuli. We showcase the\nuse of SyncBox on our existing neural mass model of the visual thalamus.\nFollowing our successful testing of SyncBox, it is currently being used for\nfurther research on understanding the underlying dynamics in enhanced neural\nnetworks of the visual pathway\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 04:08:15 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Mahajan", "Pranav", ""], ["Rane", "Advait", ""], ["Sasi", "Swapna", ""], ["Bhattacharya", "Basabdatta Sen", ""]]}, {"id": "2012.06537", "submitter": "William Winlow Professor", "authors": "Andrew Simon Johnson and William Winlow", "title": "Does the brain function as a quantum phase computer using phase ternary\n  computation?", "comments": "16 pages, 7 figures. Key Words: Plasticity; Action potential; Timing;\n  Error redaction; Synchronization; Quantum phase computation; Phase ternary\n  computation; Retinal model", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Here we provide evidence that the fundamental basis of nervous communication\nis derived from a pressure pulse/soliton capable of computation with sufficient\ntemporal precision to overcome any processing errors. Signalling and computing\nwithin the nervous system are complex and different phenomena. Action\npotentials are plastic and this makes the action potential peak an\ninappropriate fixed point for neural computation, but the action potential\nthreshold is suitable for this purpose. Furthermore, neural models timed by\nspiking neurons operate below the rate necessary to overcome processing error.\nUsing retinal processing as our example, we demonstrate that the contemporary\ntheory of nerve conduction based on cable theory is inappropriate to account\nfor the short computational time necessary for the full functioning of the\nretina and by implication the rest of the brain. Moreover, cable theory cannot\nbe instrumental in the propagation of the action potential because at the\nactivation-threshold there is insufficient charge at the activation site for\nsuccessive ion channels to be electrostatically opened. Deconstruction of the\nbrain neural network suggests that it is a member of a group of Quantum phase\ncomputers of which the Turing machine is the simplest: the brain is another\nbased upon phase ternary computation. However, attempts to use Turing based\nmechanisms cannot resolve the coding of the retina or the computation of\nintelligence, as the technology of Turing based computers is fundamentally\ndifferent. We demonstrate that that coding in the brain neural network is\nquantum based, where the quanta have a temporal variable and a phase-base\nvariable enabling phase ternary computation as previously demonstrated in the\nretina.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 08:00:23 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Johnson", "Andrew Simon", ""], ["Winlow", "William", ""]]}, {"id": "2012.06608", "submitter": "Jesus Malo", "authors": "Jose Juan Esteve-Taboada, Guillermo Aguilar, Marianne Maertens, Felix\n  A. Wichmann, Jesus Malo", "title": "Psychophysical Estimation of Early and Late Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In psychophysics (without access to physiological measurements at retina and\nthe behaviourally relevant stages within the visual system), early and late\nnoise in within the visual system seem hard to tell apart because\ndiscrimination depends on the inner noise or effective noise which is a\nnon-trivial combination of early and late noises. In this work we analyze this\ncombination in detail in nonlinear vision models and propose a purely\npsychophysical methodology to quantify the early noise and the late noise. Our\nanalysis generalizes classical results from linear systems (Burgess and\nColborne, 1988) by combining the theory of noise propagation through a\nnonlinear network (Ahumada, 1987) with the expressions to obtain the perceptual\nmetric along the nonlinear network (Malo and Simoncelli, 2006; Laparra,\nMu\\~noz, and Malo, 2010). The proposed method shows that the scale of the late\nnoise can only be determined if the experiments include substantial noise in\nthe input. This means that knowing the magnitude of early noise is necessary as\nit is needed as a scaling factor for the late noise. Moreover, it suggests that\nthe use of external noise in the experiments may be helpful as an extra\nreference. Therefore, we propose to use accurate measurements of pattern\ndiscrimination in external noise, where the spectrum of this external noise was\nwell controlled (Henning, Bird, and Wichmann, 2002). Our psychophysical\nestimate of early noise (assuming a conventional cascade of linear+nonlinear\nstages) is discussed in light of the noise in cone photocurrents computed via\naccurate models of retinal physiology (Brainard and Wandell, 2020). Finally, in\nline with Maximum Differentiation (Wang and Simoncelli, 2008), we discuss how\nto the proposed method may be used to design stimuli to decide between\nalternative vision models.\n", "versions": [{"version": "v1", "created": "Fri, 11 Dec 2020 19:25:46 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Esteve-Taboada", "Jose Juan", ""], ["Aguilar", "Guillermo", ""], ["Maertens", "Marianne", ""], ["Wichmann", "Felix A.", ""], ["Malo", "Jesus", ""]]}, {"id": "2012.06720", "submitter": "Huachuan Wang", "authors": "Huachuan Wang and James Ting-Ho Lo", "title": "Low-Order Model of Biological Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A biologically plausible low-order model (LOM) of biological neural networks\nis a recurrent hierarchical network of dendritic nodes/trees,\nspiking/nonspiking neurons, unsupervised/ supervised covariance/accumulative\nlearning mechanisms, feedback connections, and a scheme for maximal\ngeneralization. These component models are motivated and necessitated by making\nLOM learn and retrieve easily without differentiation, optimization, or\niteration, and cluster, detect and recognize multiple/hierarchical corrupted,\ndistorted, and occluded temporal and spatial patterns.\n", "versions": [{"version": "v1", "created": "Sat, 12 Dec 2020 04:22:09 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Wang", "Huachuan", ""], ["Lo", "James Ting-Ho", ""]]}, {"id": "2012.07105", "submitter": "Christoforos Papasavvas", "authors": "Mariella Panagiotopoulou, Christoforos Papasavvas, Gabrielle M\n  Schroeder, Peter Taylor, Yujiang Wang", "title": "Fluctuations in EEG band power at subject-specific timescales over\n  minutes to days are associated with changes in seizure dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is recognised as a dynamic disease, where susceptibility to seizures\nand seizure characteristics change over time. Specifically, we recently found\nvariable seizure dynamics within individual patients. Additionally, the\nvariability appeared to follow subject-specific circadian or longer timescale\nmodulations. However, whether signatures of these modulations over different\ntimescales can be captured on continuous (interictal) EEG remains unclear.\n  In this work, we analyse continuous interictal intracranial\nelectroencephalographic (iEEG) recordings from video-telemetry units and find\nfluctuations in iEEG band power over different timescales ranging from minutes\nup to twelve days.\n  We find that all subjects show not only an approximately-circadian\nfluctuation in their EEG band power, but also many other fluctuations on\nsubject-specific timescales. Importantly, we find that a combination of\nfluctuations on different timescales can explain changes in seizure network\nevolution in a regression model in most subjects above chance level.\n  These results suggest that subject-specific fluctuations in iEEG band power\nover timescales of minutes to days are associated with how seizures are\nmodulated over time. Future work is needed to link the detected fluctuations to\nthe exact biological time-varying processes. Understanding seizure modulating\nfactors enables development of novel treatment strategies that minimise the\nseizure spread, duration, or severity and therefore clinical impact of\nseizures.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 17:17:38 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 20:07:47 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Panagiotopoulou", "Mariella", ""], ["Papasavvas", "Christoforos", ""], ["Schroeder", "Gabrielle M", ""], ["Taylor", "Peter", ""], ["Wang", "Yujiang", ""]]}, {"id": "2012.07691", "submitter": "Thiago B. Burghi", "authors": "Thiago B. Burghi, Maarten Schoukens, Rodolphe Sepulchre", "title": "System identification of biophysical neuronal models", "comments": "Slightly extended pre-print of the paper to be presented at the 59th\n  Conference on Decision and Control, held remotely between December 14-18,\n  2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After sixty years of quantitative biophysical modeling of neurons, the\nidentification of neuronal dynamics from input-output data remains a\nchallenging problem, primarily due to the inherently nonlinear nature of\nexcitable behaviors. By reformulating the problem in terms of the\nidentification of an operator with fading memory, we explore a simple approach\nbased on a parametrization given by a series interconnection of Generalized\nOrthonormal Basis Functions (GOBFs) and static Artificial Neural Networks. We\nshow that GOBFs are particularly well-suited to tackle the identification\nproblem, and provide a heuristic for selecting GOBF poles which addresses the\nultra-sensitivity of neuronal behaviors. The method is illustrated on the\nidentification of a bursting model from the crab stomatogastric ganglion.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 16:41:27 GMT"}], "update_date": "2020-12-15", "authors_parsed": [["Burghi", "Thiago B.", ""], ["Schoukens", "Maarten", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "2012.07836", "submitter": "Danko Georgiev", "authors": "Danko D. Georgiev", "title": "Quantum information theoretic approach to the mind-brain problem", "comments": "27 pages, 6 figures", "journal-ref": "Progress in Biophysics and Molecular Biology 2020; 158: 16-32", "doi": "10.1016/j.pbiomolbio.2020.08.002", "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain is composed of electrically excitable neuronal networks regulated\nby the activity of voltage-gated ion channels. Further portraying the molecular\ncomposition of the brain, however, will not reveal anything remotely\nreminiscent of a feeling, a sensation or a conscious experience. In classical\nphysics, addressing the mind-brain problem is a formidable task because no\nphysical mechanism is able to explain how the brain generates the unobservable,\ninner psychological world of conscious experiences and how in turn those\nconscious experiences steer the underlying brain processes toward desired\nbehavior. Yet, this setback does not establish that consciousness is\nnon-physical. Modern quantum physics affirms the interplay between two types of\nphysical entities in Hilbert space: unobservable quantum states, which are\nvectors describing what exists in the physical world, and quantum observables,\nwhich are operators describing what can be observed in quantum measurements.\nQuantum no-go theorems further provide a framework for studying quantum brain\ndynamics, which has to be governed by a physically admissible Hamiltonian.\nComprising consciousness of unobservable quantum information integrated in\nquantum brain states explains the origin of the inner privacy of conscious\nexperiences and revisits the dynamic timescale of conscious processes to\npicosecond conformational transitions of neural biomolecules. The observable\nbrain is then an objective construction created from classical bits of\ninformation, which are bound by Holevo's theorem, and obtained through the\nmeasurement of quantum brain observables. Thus, quantum information theory\nclarifies the distinction between the unobservable mind and the observable\nbrain, and supports a solid physical foundation for consciousness research.\n", "versions": [{"version": "v1", "created": "Sun, 13 Dec 2020 09:07:33 GMT"}], "update_date": "2020-12-16", "authors_parsed": [["Georgiev", "Danko D.", ""]]}, {"id": "2012.08655", "submitter": "Elian Malkin", "authors": "Elian Malkin, Arturo Deza, Tomaso Poggio", "title": "CUDA-Optimized real-time rendering of a Foveated Visual System", "comments": "16 pages, 13 figures, presented at the Shared Visual Representations\n  in Human and Machine Intelligence Workshop (SVRHM NeurIPS 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spatially-varying field of the human visual system has recently received\na resurgence of interest with the development of virtual reality (VR) and\nneural networks. The computational demands of high resolution rendering desired\nfor VR can be offset by savings in the periphery, while neural networks trained\nwith foveated input have shown perceptual gains in i.i.d and o.o.d\ngeneralization. In this paper, we present a technique that exploits the CUDA\nGPU architecture to efficiently generate Gaussian-based foveated images at high\ndefinition (1920x1080 px) in real-time (165 Hz), with a larger number of\npooling regions than previous Gaussian-based foveation algorithms by several\norders of magnitude, producing a smoothly foveated image that requires no\nfurther blending or stitching, and that can be well fit for any contrast\nsensitivity function. The approach described can be adapted from Gaussian\nblurring to any eccentricity-dependent image processing and our algorithm can\nmeet demand for experimentation to evaluate the role of spatially-varying\nprocessing across biological and artificial agents, so that foveation can be\nadded easily on top of existing systems rather than forcing their redesign\n(emulated foveated renderer). Altogether, this paper demonstrates how a GPU,\nwith a CUDA block-wise architecture, can be employed for radially-variant\nrendering, with opportunities for more complex post-processing to ensure a\nmetameric foveation scheme. Code is provided.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 22:43:04 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Malkin", "Elian", ""], ["Deza", "Arturo", ""], ["Poggio", "Tomaso", ""]]}, {"id": "2012.08667", "submitter": "Luca Faes", "authors": "Gorana Mijatovic, Yuri Antonacci, Tatjana Loncar-Turukalo, Ludovico\n  Minati and Luca Faes", "title": "An information-theoretic framework to measure the dynamic interaction\n  between neural spike trains", "comments": "12 pages, 7 figures; supplementary material at\n  www.lucafaes.net/TEMI.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding the interaction patterns among simultaneous recordings of spike\ntrains from multiple neuronal units is a key topic in neuroscience. However, an\noptimal approach of assessing these interactions has not been established, as\nexisting methods either do not consider the inherent point process nature of\nspike trains or are based on parametric assumptions that may lead to wrong\ninferences if not met. This work presents a framework, grounded in the field of\ninformation dynamics, for the model-free, continuous-time estimation of both\nundirected (symmetric) and directed (causal) interactions between pairs of\nspike trains. The framework decomposes the overall information exchanged\ndynamically between two point processes X and Y as the sum of the dynamic\nmutual information (dMI) between the histories of X and Y, plus the transfer\nentropy (TE) along the directions X->Y and Y->X. Building on recent work which\nderived theoretical expressions and consistent estimators for the TE in\ncontinuous time, we develop algorithms for estimating efficiently all measures\nin our framework through nearest neighbor statistics. These algorithms are\nvalidated in simulations of independent and coupled spike train processes,\nshowing the accuracy of dMI and TE in the assessment of undirected and directed\ninteractions even for weakly coupled and short realizations, and proving the\nsuperiority of the continuous-time estimator over the discrete-time method.\nThen, the usefulness of the framework is illustrated in a real data scenario of\nrecordings from in-vitro preparations of spontaneously-growing cultures of\ncortical neurons, where we show the ability of dMI and TE to identify how the\nnetworks of undirected and directed spike train interactions change their\ntopology through maturation of the neuronal cultures.\n", "versions": [{"version": "v1", "created": "Tue, 15 Dec 2020 23:27:24 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Mijatovic", "Gorana", ""], ["Antonacci", "Yuri", ""], ["Loncar-Turukalo", "Tatjana", ""], ["Minati", "Ludovico", ""], ["Faes", "Luca", ""]]}, {"id": "2012.09027", "submitter": "Radu Horaud P", "authors": "Miles Hansard and Radu Horaud", "title": "A Differential Model of the Complex Cell", "comments": null, "journal-ref": "Neural Computation, 23(9), 2011", "doi": "10.1162/NECO_a_00163", "report-no": null, "categories": "q-bio.NC cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The receptive fields of simple cells in the visual cortex can be understood\nas linear filters. These filters can be modelled by Gabor functions, or by\nGaussian derivatives. Gabor functions can also be combined in an `energy model'\nof the complex cell response. This paper proposes an alternative model of the\ncomplex cell, based on Gaussian derivatives. It is most important to account\nfor the insensitivity of the complex response to small shifts of the image. The\nnew model uses a linear combination of the first few derivative filters, at a\nsingle position, to approximate the first derivative filter, at a series of\nadjacent positions. The maximum response, over all positions, gives a signal\nthat is insensitive to small shifts of the image. This model, unlike previous\napproaches, is based on the scale space theory of visual processing. In\nparticular, the complex cell is built from filters that respond to the \\twod\\\ndifferential structure of the image. The computational aspects of the new model\nare studied in one and two dimensions, using the steerability of the Gaussian\nderivatives. The response of the model to basic images, such as edges and\ngratings, is derived formally. The response to natural images is also\nevaluated, using statistical measures of shift insensitivity. The relevance of\nthe new model to the cortical image representation is discussed.\n", "versions": [{"version": "v1", "created": "Wed, 9 Dec 2020 10:23:23 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Hansard", "Miles", ""], ["Horaud", "Radu", ""]]}, {"id": "2012.09660", "submitter": "Giuseppe de Vito", "authors": "Giuseppe de Vito, Lapo Turrini, Caroline M\\\"ullenbroich, Pietro Ricci,\n  Giuseppe Sancataldo, Giacomo Mazzamuto, Natascia Tiso, Leonardo Sacconi,\n  Duccio Fanelli, Ludovico Silvestri, Francesco Vanzi, Francesco Saverio Pavone", "title": "Fast whole-brain imaging of seizures in zebrafish larvae by two-photon\n  light sheet microscopy", "comments": "Replacement: revised version of the manuscript. -------- 25 pages, 9\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Light-sheet fluorescence microscopy (LSFM) enables real-time whole-brain\nfunctional imaging in zebrafish larvae. Conventional one photon LSFM can\nhowever induce undesirable visual stimulation due to the use of visible\nexcitation light. The use of two-photon (2P) excitation, employing\nnear-infrared invisible light, provides unbiased investigation of neuronal\ncircuit dynamics. However, due to the low efficiency of the 2P absorption\nprocess, the imaging speed of this technique is typically limited by the\nsignal-to-noise-ratio. Here, we describe a 2P LSFM setup designed for\nnon-invasive imaging that enables quintuplicating state-of-the-art volumetric\nacquisition rate of the larval zebrafish brain (5 Hz) while keeping low the\nlaser intensity on the specimen. We applied our system to the study of\npharmacologically-induced acute seizures, characterizing the spatial-temporal\ndynamics of pathological activity and describing for the first time the\nappearance of caudo-rostral ictal waves (CRIWs).\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 15:19:00 GMT"}, {"version": "v2", "created": "Fri, 1 Jan 2021 23:13:09 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 22:21:55 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["de Vito", "Giuseppe", ""], ["Turrini", "Lapo", ""], ["M\u00fcllenbroich", "Caroline", ""], ["Ricci", "Pietro", ""], ["Sancataldo", "Giuseppe", ""], ["Mazzamuto", "Giacomo", ""], ["Tiso", "Natascia", ""], ["Sacconi", "Leonardo", ""], ["Fanelli", "Duccio", ""], ["Silvestri", "Ludovico", ""], ["Vanzi", "Francesco", ""], ["Pavone", "Francesco Saverio", ""]]}, {"id": "2012.09723", "submitter": "Hsin-Yu Lai", "authors": "Hsin-Yu Lai, Gladynel Saavedra-Pena, Charles G. Sodini, Thomas Heldt,\n  Vivienne Sze", "title": "App-based saccade latency and error determination across the adult age\n  spectrum", "comments": "11 pages, 16 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.IV eess.SP q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We aid in neurocognitive monitoring outside the hospital environment by\nenabling app-based measurements of visual reaction time (saccade latency) and\nerror rate in a cohort of subjects spanning the adult age spectrum. Methods: We\ndeveloped an iOS app to record subjects with the frontal camera during pro- and\nanti-saccade tasks. We further developed automated algorithms for measuring\nsaccade latency and error rate that take into account the possibility that it\nmight not always be possible to determine the eye movement from app-based\nrecordings. Results: To measure saccade latency on a tablet, we ensured that\nthe absolute timing error between on-screen task presentation and the camera\nrecording is within 5 ms. We collected over 235,000 eye movements in 80\nsubjects ranging in age from 20 to 92 years, with 96% of recorded eye movements\neither declared good or directional errors. Our error detection code achieved a\nsensitivity of 0.97 and a specificity of 0.97. Confirming prior reports, we\nobserved a positive correlation between saccade latency and age while the\nrelationship between error rate and age was not significant. Finally, we\nobserved significant intra- and inter-subject variations in saccade latency and\nerror rate distributions, which highlights the importance of individualized\ntracking of these visual digital biomarkers. Conclusion and Significance: Our\nsystem and algorithms allow ubiquitous tracking of saccade latency and error\nrate, which opens up the possibility of quantifying patient state on a finer\ntimescale in a broader population than previously possible.\n", "versions": [{"version": "v1", "created": "Mon, 14 Dec 2020 02:02:02 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Lai", "Hsin-Yu", ""], ["Saavedra-Pena", "Gladynel", ""], ["Sodini", "Charles G.", ""], ["Heldt", "Thomas", ""], ["Sze", "Vivienne", ""]]}, {"id": "2012.09930", "submitter": "Linli Shi", "authors": "Linli Shi (1), Ying Jiang (2), Fernando R. Fernandez (2,5,6), Lu Lan\n  (3), Guo Chen (3), Heng-ye Man (4,5), John A. White (2,5,6), Ji-Xin Cheng\n  (2,3), Chen Yang (1, 3) ((1) Department of Chemistry, Boston University,\n  Boston, USA, (2) Department of Biomedical Engineering, Boston University,\n  Boston, USA, (3) Department of Electrical and Computer Engineering, Boston,\n  USA, (4) Department of Biology, Boston University, Boston, USA, (5) Center\n  for Systems Neuroscience, Boston University, Boston, USA, (6) Neurophotonics\n  Center, Photonics Center, Boston University, Boston, USA)", "title": "Non-genetic acoustic stimulation of single neurons by a tapered fiber\n  optoacoustic emitter", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an emerging technology, transcranial focused ultrasound has been\ndemonstrated to successfully evoke motor responses in mice, rabbits, and\nsensory/motor responses in humans. Yet, the spatial resolution of ultrasound\ndoes not allow for high-precision stimulation. Here, we developed a tapered\nfiber optoacoustic emitter (TFOE) for optoacoustic stimulation of neurons with\nan unprecedented spatial resolution of 20 microns, enabling selective\nactivation of single neurons or subcellular structures, such as axons and\ndendrites. A single acoustic pulse of 1 microsecond converted by the TFOE from\na single laser pulse of 3 nanoseconds is shown as the shortest acoustic stimuli\nso far for successful neuron activation. The highly localized ultrasound\ngenerated by the TFOE made it possible to integrate the optoacoustic\nstimulation and highly stable patch clamp recording on single neurons. Direct\nmeasurements of electrical response of single neurons to acoustic stimulation,\nwhich is difficult for conventional ultrasound stimulation, have been\ndemonstrated for the first time. By coupling TFOE with ex vivo brain slice\nelectrophysiology, we unveil cell-type-specific response of excitatory and\ninhibitory neurons to acoustic stimulation. These results demonstrate that TFOE\nis a non-genetic single-cell and sub-cellular modulation technology, which\ncould shed new insights into the mechanism of neurostimulation.\n", "versions": [{"version": "v1", "created": "Thu, 17 Dec 2020 20:50:19 GMT"}], "update_date": "2020-12-21", "authors_parsed": [["Shi", "Linli", ""], ["Jiang", "Ying", ""], ["Fernandez", "Fernando R.", ""], ["Lan", "Lu", ""], ["Chen", "Guo", ""], ["Man", "Heng-ye", ""], ["White", "John A.", ""], ["Cheng", "Ji-Xin", ""], ["Yang", "Chen", ""]]}, {"id": "2012.10390", "submitter": "Rufin VanRullen", "authors": "Rufin VanRullen and Ryota Kanai", "title": "Deep Learning and the Global Workspace Theory", "comments": "This version with improved text and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep learning have allowed Artificial Intelligence (AI) to\nreach near human-level performance in many sensory, perceptual, linguistic or\ncognitive tasks. There is a growing need, however, for novel, brain-inspired\ncognitive architectures. The Global Workspace theory refers to a large-scale\nsystem integrating and distributing information among networks of specialized\nmodules to create higher-level forms of cognition and awareness. We argue that\nthe time is ripe to consider explicit implementations of this theory using deep\nlearning techniques. We propose a roadmap based on unsupervised neural\ntranslation between multiple latent spaces (neural networks trained for\ndistinct tasks, on distinct sensory inputs and/or modalities) to create a\nunique, amodal global latent workspace (GLW). Potential functional advantages\nof GLW are reviewed, along with neuroscientific implications.\n", "versions": [{"version": "v1", "created": "Fri, 4 Dec 2020 11:36:01 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 00:33:38 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["VanRullen", "Rufin", ""], ["Kanai", "Ryota", ""]]}, {"id": "2012.10677", "submitter": "Selma Mehyaoui", "authors": "Selma Mehyaoui", "title": "How does neural activity encode spontaneous motor behavior in zebrafish\n  larvae ?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The origins of spontaneous movements have been investigated in human as well\nas in other vertebrates. Studies have reported an increase in neuronal activity\none second before the onset of a given movement: this is known as readiness\npotential. The mechanisms underlying this increase are still unclear. Zebrafish\nlarva is an ideal animal model to study the neuronal basis of spontaneous\nmovements. Because of its small size and transparency, this vertebrate is an\nideal candidate to apply optical recording methods. In order to understand what\nneuronal activity causes the execution of a specific tail movement at a given\ntime, we will mainly use a prediction approach.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 13:04:29 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Mehyaoui", "Selma", ""]]}, {"id": "2012.10785", "submitter": "Enzo Tagliazucchi", "authors": "Sofia Morena del Pozo, Helmut Laufs, Vincent Bonhomme, Steven Laureys,\n  Pablo Balenzuela, Enzo Tagliazucchi", "title": "Unconsciousness reconfigures modular brain network dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The dynamic core hypothesis posits that consciousness is correlated with\nsimultaneously integrated and differentiated assemblies of transiently\nsynchronized brain regions. We represented time-dependent functional\ninteractions using dynamic brain networks, and assessed the integrityof the\ndynamic core by means of the flexibility and largest multilayer module of these\nnetworks. As a first step, we constrained parameter selection using a newly\ndeveloped benchmark for module detection in heterogeneous temporal networks.\nNext, we applied a multilayer modularity maximization algorithm to dynamic\nbrain networks computed from functional magnetic resonance imaging (fMRI) data\nacquired during deep sleep and under propofol anesthesia. We found that\nunconsciousness reconfigured network flexibility and reduced the size of the\nlargest spatiotemporal module, which we identified with the dynamic core. Our\nresults present a first characterization of modular brain network dynamics\nduring states of unconsciousness measured with fMRI, adding support to the\ndynamic core hypothesis of human consciousness.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 21:29:34 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["del Pozo", "Sofia Morena", ""], ["Laufs", "Helmut", ""], ["Bonhomme", "Vincent", ""], ["Laureys", "Steven", ""], ["Balenzuela", "Pablo", ""], ["Tagliazucchi", "Enzo", ""]]}, {"id": "2012.10792", "submitter": "Enzo Tagliazucchi", "authors": "Yonatan Sanz Perl, Hernan Bocaccio, Ignacio Perez-Ipina, Steven\n  Laureys, Helmut Laufs, Morten Kringelbach, Gustavo Deco, Enzo Tagliazucchi", "title": "Non-equilibrium brain dynamics as a signature of consciousness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The cognitive functions of human and non-human primates rely on the dynamic\ninterplay of distributed neural assemblies. As such, it seems unlikely that\ncognition can be supported by macroscopic brain dynamics at the proximity of\nthermodynamic equilibrium. We confirmed this hypothesis by investigating\nelectrocorticography data from non human primates undergoing different states\nof unconsciousness (sleep, and anesthesia with propofol, ketamine, and ketamine\nplus medetomidine), and funcional magnetic resonance imaging data from humans,\nboth during deep sleep and under propofol anesthesia. Systematically, all\nstates of reduced consciousness unfolded at higher proximity to equilibrium\ndynamics than conscious wakefulness, as demonstrated by entropy production and\nthe curl of probability flux in phase space. Our results establish\nnon-equilibrium macroscopic brain dynamics as a robust signature of\nconsciousness, opening the way for the characterization of cognition and\nawareness using tools from statistical mechanics.\n", "versions": [{"version": "v1", "created": "Sat, 19 Dec 2020 21:58:26 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Perl", "Yonatan Sanz", ""], ["Bocaccio", "Hernan", ""], ["Perez-Ipina", "Ignacio", ""], ["Laureys", "Steven", ""], ["Laufs", "Helmut", ""], ["Kringelbach", "Morten", ""], ["Deco", "Gustavo", ""], ["Tagliazucchi", "Enzo", ""]]}, {"id": "2012.11240", "submitter": "Tiziana Cattai", "authors": "Tiziana Cattai, Gaetano Scarano, Marie-Constance Corsi, Danielle S.\n  Bassett, Fabrizio De Vico Fallani, Stefania Colonnese", "title": "Improving J-divergence of brain connectivity states by graph Laplacian\n  denoising", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional connectivity (FC) can be represented as a network, and is\nfrequently used to better understand the neural underpinnings of complex tasks\nsuch as motor imagery (MI) detection in brain-computer interfaces (BCIs).\nHowever, errors in the estimation of connectivity can affect the detection\nperformances. In this work, we address the problem of denoising common\nconnectivity estimates to improve the detectability of different connectivity\nstates. Specifically, we propose a denoising algorithm that acts on the network\ngraph Laplacian, which leverages recent graph signal processing results.\nFurther, we derive a novel formulation of the Jensen divergence for the\ndenoised Laplacian under different states. Numerical simulations on synthetic\ndata show that the denoising method improves the Jensen divergence of\nconnectivity patterns corresponding to different task conditions. Furthermore,\nwe apply the Laplacian denoising technique to brain networks estimated from\nreal EEG data recorded during MI-BCI experiments. Using our novel formulation\nof the J-divergence, we are able to quantify the distance between the FC\nnetworks in the motor imagery and resting states, as well as to understand the\ncontribution of each Laplacian variable to the total J-divergence between two\nstates. Experimental results on real MI-BCI EEG data demonstrate that the\nLaplacian denoising improves the separation of motor imagery and resting mental\nstates, and shortens the time interval required for connectivity estimation. We\nconclude that the approach shows promise for the robust detection of\nconnectivity states while being appealing for implementation in real-time BCI\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 21 Dec 2020 10:43:50 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 11:23:07 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Cattai", "Tiziana", ""], ["Scarano", "Gaetano", ""], ["Corsi", "Marie-Constance", ""], ["Bassett", "Danielle S.", ""], ["Fallani", "Fabrizio De Vico", ""], ["Colonnese", "Stefania", ""]]}, {"id": "2012.12351", "submitter": "Erfan Nozari", "authors": "Erfan Nozari, Jennifer Stiso, Lorenzo Caciagli, Eli J. Cornblath,\n  Xiaosong He, Maxwell A. Bertolero, Arun S. Mahadevan, George J. Pappas, and\n  Danielle S. Bassett", "title": "Is the brain macroscopically linear? A system identification of resting\n  state dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central challenge in the computational modeling of neural dynamics is the\ntrade-off between accuracy and simplicity. At the level of individual neurons,\nnonlinear dynamics are both experimentally established and essential for\nneuronal functioning. An implicit assumption has thus formed that an accurate\ncomputational model of whole-brain dynamics must also be highly nonlinear,\nwhereas linear models may provide a first-order approximation. Here, we provide\na rigorous and data-driven investigation of this hypothesis at the level of\nwhole-brain blood-oxygen-level-dependent (BOLD) and macroscopic field potential\ndynamics by leveraging the theory of system identification. Using functional\nMRI (fMRI) and intracranial EEG (iEEG), we model the resting state activity of\n700 subjects in the Human Connectome Project (HCP) and 122 subjects from the\nRestoring Active Memory (RAM) project using state-of-the-art linear and\nnonlinear model families. We assess relative model fit using predictive power,\ncomputational complexity, and the extent of residual dynamics unexplained by\nthe model. Contrary to our expectations, linear auto-regressive models achieve\nthe best measures across all three metrics, eliminating the trade-off between\naccuracy and simplicity. To understand and explain this linearity, we highlight\nfour properties of macroscopic neurodynamics which can counteract or mask\nmicroscopic nonlinear dynamics: averaging over space, averaging over time,\nobservation noise, and limited data samples. Whereas the latter two are\ntechnological limitations and can improve in the future, the former two are\ninherent to aggregated macroscopic brain activity. Our results, together with\nthe unparalleled interpretability of linear models, can greatly facilitate our\nunderstanding of macroscopic neural dynamics and the principled design of\nmodel-based interventions for the treatment of neuropsychiatric disorders.\n", "versions": [{"version": "v1", "created": "Tue, 22 Dec 2020 20:51:42 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Nozari", "Erfan", ""], ["Stiso", "Jennifer", ""], ["Caciagli", "Lorenzo", ""], ["Cornblath", "Eli J.", ""], ["He", "Xiaosong", ""], ["Bertolero", "Maxwell A.", ""], ["Mahadevan", "Arun S.", ""], ["Pappas", "George J.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "2012.12486", "submitter": "Valentin Slepukhin", "authors": "Valentin M. Slepukhin (1), Sufyan Ashhad (2), Jack L. Feldman (2),\n  Alex J. Levine (1,3 and 4) ((1) Department of Physics and Astronomy, UCLA,\n  (2) Systems Neurobiology Laboratory, Department of Neurobiology, David Geffen\n  School of Medicine, UCLA, (3) Department of Chemistry and Biochemistry, UCLA,\n  (4), Department of Biomathematics, UCLA)", "title": "Microcircuit synchronization and heavy tailed synaptic weight\n  distribution in preB\\\"otzinger Complex contribute to generation of breathing\n  rhythm", "comments": "47 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The preB\\\"otzinger Complex, the mammalian inspiratory rhythm generator,\nencodes inspiratory time as motor pattern. Spike synchronization throughout\nthis sparsely connected network generates inspiratory bursts albeit with\nvariable latencies after preinspiratory activity onset in each breathing cycle.\nUsing preB\\\"otC rhythmogenic microcircuit minimal models, we examined the\nvariability in probability and latency to burst, mimicking experiments. Among\nvarious physiologically plausible graphs of 1000 point neurons with\nexperimentally determined neuronal and synaptic parameters, directed\nErd\\H{o}s-R\\'enyi graphs best captured the experimentally observed dynamics.\nMechanistically, preB\\\"otC (de)synchronization and oscillatory dynamics are\nregulated by the efferent connectivity of spiking neurons that gates the\namplification of modest preinspiratory activity through input convergence.\nFurthermore, to replicate experiments, a lognormal distribution of synaptic\nweights was necessary to augment the efficacy of convergent coincident inputs.\nThese mechanisms enable exceptionally robust yet flexible preB\\\"otC attractor\ndynamics that, we postulate, represent universal temporal-processing and\ndecision-making computational motifs throughout the brain.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 05:01:06 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Slepukhin", "Valentin M.", "", "1,3 and 4"], ["Ashhad", "Sufyan", "", "1,3 and 4"], ["Feldman", "Jack L.", "", "1,3 and 4"], ["Levine", "Alex J.", "", "1,3 and 4"]]}, {"id": "2012.12583", "submitter": "Pedro Cardoso-Leite", "authors": "Aur\\'elien Defossez, Morteza Ansarinia, Brice Clocher, Emmanuel\n  Schm\\\"uck, Paul Schrater and Pedro Cardoso-Leite", "title": "The structure of behavioral data", "comments": "12 pages, 1 table, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For more than a century, scientists have been collecting behavioral data--an\nincreasing fraction of which is now being publicly shared so other researchers\ncan reuse them to replicate, integrate or extend past results. Although\nbehavioral data is fundamental to many scientific fields, there is currently no\nwidely adopted standard for formatting, naming, organizing, describing or\nsharing such data. This lack of standardization is a major bottleneck for\nscientific progress. Not only does it prevent the effective reuse of data, it\nalso affects how behavioral data in general are processed, as non-standard data\ncalls for custom-made data analysis code and prevents the development of\nefficient tools. To address this problem, we develop the Behaverse Data Model\n(BDM), a standard for structuring behavioral data. Here we focus on major\nconcepts in behavioral data, leaving further details and developments to the\nproject's website (https://behaverse.github.io/data-model/).\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 10:22:00 GMT"}], "update_date": "2020-12-24", "authors_parsed": [["Defossez", "Aur\u00e9lien", ""], ["Ansarinia", "Morteza", ""], ["Clocher", "Brice", ""], ["Schm\u00fcck", "Emmanuel", ""], ["Schrater", "Paul", ""], ["Cardoso-Leite", "Pedro", ""]]}, {"id": "2012.12963", "submitter": "Gr\\'egoire Sergeant-Perthuis", "authors": "D. Rudrauf, G. Sergeant-Perthuis, O. Belli, Y. Tisserand, G. Di Marzo\n  Serugendo", "title": "The role of consciousness in biological cybernetics: emergent adaptive\n  and maladaptive behaviours in artificial agents governed by the projective\n  consciousness model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The role of consciousness in biological cybernetics remains an essential yet\nopen question. We applied the principles of the Projective Consciousness Model\n(PCM) to derive a model of appraisal and social-affective perspective taking,\nand their role in the motivation of action, based on the concept of Field of\nConsciousness, central to the PCM. We show how these principles can account for\nknown relationships between appraisal and distance as an inverse distance law,\nand how it can be generalised to implement Theory of Mind. We used simulations\nof artificial agents based on psychological rationale to demonstrate how\ndifferent model parameters could generate a variety of emergent adaptive and\nmaladaptive behaviours: the ability to be resilient in the face of obstacles\nthrough imaginary projections, the emergence of social approach and joint\nattention behaviours, the ability to take advantage of false beliefs attributed\nto others, the emergence of avoidance behaviours as observed in social anxiety\ndisorders, the presence of restricted interests as observed in autism spectrum\ndisorders. The simulation of agents was applied to a specific robotic context,\nand agents' behaviours were demonstrated by controlling the corresponding\nrobots. The approach opens new paths towards a science of consciousness, and\napplications, from clinical assessment and training to the design of artificial\n(virtual and robotic) agents.\n", "versions": [{"version": "v1", "created": "Wed, 23 Dec 2020 20:38:37 GMT"}, {"version": "v2", "created": "Sun, 21 Mar 2021 12:39:52 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Rudrauf", "D.", ""], ["Sergeant-Perthuis", "G.", ""], ["Belli", "O.", ""], ["Tisserand", "Y.", ""], ["Serugendo", "G. Di Marzo", ""]]}, {"id": "2012.13252", "submitter": "Kevin S. Chen", "authors": "Kevin S. Chen", "title": "Nonequilibrium thermodynamics of input-driven networks", "comments": "8 pages, 7 figures, first draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural dynamics of energy-based models are governed by energy minimization\nand the patterns stored in the network are retrieved when the system reaches\nequilibrium. However, when the system is driven by time-varying external input,\nthe nonequilibrium process of such physical system has not been well\ncharacterized. Here, we study attractor neural networks, specifically the\nHopfield network, driven by time-varying external input and measure\nthermodynamic quantities along trajectories between two collective states. The\noverlap between distribution of the forward and reversal work along the\nnonequilibrium trajectories agrees with the equilibrium free energy difference\nbetween two states, following the prediction of Crooks fluctuation theorem. We\nstudy conditions with different stimulation protocol and neural network\nconstraints. We further discuss how biologically plausible synaptic connections\nand information processing may play a role in this nonequilibrium framework.\nThese results demonstrate how nonequilibrium thermodynamics can be relevant for\nneural computation and connect to recent systems neuroscience studies with\nclosed-loop dynamic perturbations.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 13:50:42 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Chen", "Kevin S.", ""]]}, {"id": "2012.13289", "submitter": "Mieke Massink", "authors": "Gina Belmonte and Giovanna Broccia and Vincenzo Ciancia and Diego\n  Latella and Mieke Massink", "title": "Using Spatial Logic and Model Checking for Nevus Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO eess.IV q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spatial and spatio-temporal model checking techniques have a wide range of\napplication domains, among which large scale distributed systems and signal and\nimage analysis. In the latter domain, automatic and semi-automatic contouring\nin Medical Imaging has shown to be a very promising and versatile application\nthat can greatly facilitate the work of professionals in this domain, while\nsupporting explainability, easy replicability and exchange of medical image\nanalysis methods. In recent work we have applied this model-checking technique\nto the (3D) contouring of tumours and related oedema in magnetic resonance\nimages of the brain. In the current work we address the contouring of (2D)\nimages of nevi. One of the challenges of treating nevi images is their\nconsiderable inhomogeneity in shape, colour, texture and size. To deal with\nthis challenge we use a texture similarity operator, in combination with\nspatial logic operators. We apply our technique on images of a large public\ndatabase and compare the results with associated ground truth segmentation\nprovided by domain experts.\n", "versions": [{"version": "v1", "created": "Thu, 24 Dec 2020 15:17:35 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Belmonte", "Gina", ""], ["Broccia", "Giovanna", ""], ["Ciancia", "Vincenzo", ""], ["Latella", "Diego", ""], ["Massink", "Mieke", ""]]}, {"id": "2012.13467", "submitter": "Zhijie Charles Chen", "authors": "Zhijie Charles Chen, Bing-Yi Wang, Daniel Palanker", "title": "Real-Time Optimization of the Current Steering for Visual Prosthesis", "comments": "5 pages, 2 figures, submitted to IEEE EMBS NER'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph eess.IV q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Current steering on a multi-electrode array is commonly used to shape the\nelectric field in the neural tissue in order to improve selectivity and\nefficacy of stimulation. Previously, simulations of the electric field in\ntissue required separate computation for each set of the stimulation\nparameters. Not only is this approach to modeling time-consuming and very\ndifficult with a large number of electrodes, it is incompatible with real-time\noptimization of the current steering for practical applications. We present a\nframework for efficient computation of the electric field in the neural tissue\nbased on superposition of the fields from a pre-calculated basis. Such linear\nalgebraic framework enables optimization of the current steering for any\ntargeted electric field in real time. For applications to retinal prosthetics,\nwe demonstrate how the stimulation depth can be optimized for each patient\nbased on the retinal thickness and separation from the array, while maximizing\nthe lateral confinement of the electric field essential for spatial resolution.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 00:04:27 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Chen", "Zhijie Charles", ""], ["Wang", "Bing-Yi", ""], ["Palanker", "Daniel", ""]]}, {"id": "2012.13779", "submitter": "Ismael Tito Freire Gonz\\'alez", "authors": "Ismael T. Freire, Adri\\'an F. Amil, Vasiliki Vouloutsi, Paul F.M.J.\n  Verschure", "title": "Towards sample-efficient episodic control with DAC-ML", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sample-inefficiency problem in Artificial Intelligence refers to the\ninability of current Deep Reinforcement Learning models to optimize action\npolicies within a small number of episodes. Recent studies have tried to\novercome this limitation by adding memory systems and architectural biases to\nimprove learning speed, such as in Episodic Reinforcement Learning. However,\ndespite achieving incremental improvements, their performance is still not\ncomparable to how humans learn behavioral policies. In this paper, we\ncapitalize on the design principles of the Distributed Adaptive Control (DAC)\ntheory of mind and brain to build a novel cognitive architecture (DAC-ML) that,\nby incorporating a hippocampus-inspired sequential memory system, can rapidly\nconverge to effective action policies that maximize reward acquisition in a\nchallenging foraging task.\n", "versions": [{"version": "v1", "created": "Sat, 26 Dec 2020 16:38:08 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Freire", "Ismael T.", ""], ["Amil", "Adri\u00e1n F.", ""], ["Vouloutsi", "Vasiliki", ""], ["Verschure", "Paul F. M. J.", ""]]}, {"id": "2012.14559", "submitter": "Bhav Jain", "authors": "Bhav Jain, Sean Elliott", "title": "Correlation Across Environments Encoded by Hippocampal Place Cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The hippocampus is often attributed to episodic memory formation and storage\nin the mammalian brain; in particular, Alme et al. showed that hippocampal area\nCA3 forms statistically independent representations across a large number of\nenvironments, even if the environments share highly similar features. This lack\nof overlap between spatial maps indicates the large capacity of the CA3\ncircuitry. In this paper, we support the argument for the large capacity of the\nCA3 network. To do so, we replicate the key findings of Alme et al. and extend\nthe results by perturbing the neural activity encodings with noise and\nconducting representation similarity analysis (RSA). We find that the\ncorrelations between firing rates are partially resistant to noise, and that\nthe spatial representations across cells show similar patterns, even across\ndifferent environments. Finally, we discuss some theoretical and practical\nimplications of our results.\n", "versions": [{"version": "v1", "created": "Tue, 29 Dec 2020 01:41:31 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Jain", "Bhav", ""], ["Elliott", "Sean", ""]]}, {"id": "2012.15681", "submitter": "William Bialek", "authors": "Vasyl Alba, Gordon J. Berman, William Bialek, and Joshua W. Shaevitz", "title": "Exploring a strongly non-Markovian animal behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A freely walking fly visits roughly 100 stereotyped states in a strongly\nnon-Markovian sequence. To explore these dynamics, we develop a generalization\nof the information bottleneck method, compressing the large number of\nbehavioral states into a more compact description that maximally preserves the\ncorrelations between successive states. Surprisingly, preserving these short\ntime correlations with a compression into just two states captures the long\nranged correlations seen in the raw data. Having reduced the behavior to a\nbinary sequence, we describe the distribution of these sequences by an Ising\nmodel with pairwise interactions, which is the maximum entropy model that\nmatches the two-point correlations. Matching the correlation function at longer\nand longer times drives the resulting model toward the Ising model with inverse\nsquare interactions and near zero magnetic field. The emergence of this\nstatistical physics problem from the analysis real data on animal behavior is\nunexpected.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 16:02:44 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Alba", "Vasyl", ""], ["Berman", "Gordon J.", ""], ["Bialek", "William", ""], ["Shaevitz", "Joshua W.", ""]]}, {"id": "2012.15750", "submitter": "Samiya Alkhairy", "authors": "Samiya A Alkhairy, Christopher A Shera", "title": "An analytic physically motivated model of the mammalian cochlea", "comments": "17 pages, 12 figures. Published in JASA", "journal-ref": "The Journal of the Acoustical Society of America, 145(1), 45-60\n  (2019)", "doi": "10.1121/1.5084042", "report-no": null, "categories": "q-bio.TO cs.SD eess.AS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an analytic model of the mammalian cochlea. We use a mixed\nphysical-phenomenological approach by utilizing existing work on the physics of\nclassical box-representations of the cochlea, and behavior of recent\ndata-derived wavenumber estimates. Spatial variation is incorporated through a\nsingle independent variable that combines space and frequency. We arrive at\nclosed-form expressions for the organ of Corti velocity, its impedance, the\npressure difference across the organ of Corti, and its wavenumber. We perform\nmodel tests using real and imaginary parts of chinchilla data from multiple\nlocations and for multiple variables. The model also predicts impedances that\nare qualitatively consistent with current literature. For implementation, the\nmodel can leverage existing efforts for both filter bank and filter cascade\nmodels that target improved algorithmic or analog circuit efficiencies. The\nsimplicity of the cochlear model, its small number of model constants, its\nability to capture the variation of tuning, its closed-form expressions for\nphysically-interrelated variables, and the form of these expressions that\nallows for easily determining one variable from another make the model\nappropriate for analytic and digital auditory filter implementations as\ndiscussed here, as well as for extracting macromechanical insights regarding\nhow the cochlea works.\n", "versions": [{"version": "v1", "created": "Fri, 25 Dec 2020 00:26:22 GMT"}], "update_date": "2021-01-29", "authors_parsed": [["Alkhairy", "Samiya A", ""], ["Shera", "Christopher A", ""]]}, {"id": "2012.15854", "submitter": "Sitabhra Sinha", "authors": "Anand Pathak, Shakti N. Menon and Sitabhra Sinha", "title": "Uncovering the invariant structural organization of the human connectome", "comments": "16 pages, 7 figures + 5 pages Supplementary Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to understand the complex cognitive functions of the human brain, it\nis essential to study the structural connectome, i.e., the wiring of different\nbrain regions to each other through axonal pathways. However, the high degree\nof plasticity and cross-population variability in human brains makes it\ndifficult to relate structure to function, motivating a search for invariant\npatterns in the connectivity. At the same time, variability within a population\ncan provide information about generative mechanisms. In this paper we analyze\nthe connection topology and link-weight distribution of human structural\nconnectomes obtained from a database comprising 196 subjects. By demonstrating\na correspondence between the occurrence frequency of individual links and their\naverage weight across the population, we show that the process by which the\nbrain is wired is not independent of the process by which the link weights of\nthe connectome are determined. Furthermore, using the specific distribution of\nthe weights associated with each link over the entire population, we show that\na single parameter that is specific to a link can account for its frequency of\noccurrence, as well as, the variation in its weight across different subjects.\nThis parameter provides a basis for ``rescaling'' the link weights in each\nconnectome, allowing us to obtain a generic network representative of the human\nbrain, distinct from a simple average over the connectomes. We obtain\nfunctional connectomes by implementing a neural mass model on each of the\nvertices of the corresponding structural connectomes. By comparing with the\nempirical functional brain networks, we demonstrate that the rescaling\nprocedure yields a closer structure-function correspondence. Finally, we show\nthat the representative network can be decomposed into a basal component that\nis stable across the population and a highly variable superstructure.\n", "versions": [{"version": "v1", "created": "Thu, 31 Dec 2020 18:58:33 GMT"}], "update_date": "2021-01-25", "authors_parsed": [["Pathak", "Anand", ""], ["Menon", "Shakti N.", ""], ["Sinha", "Sitabhra", ""]]}]