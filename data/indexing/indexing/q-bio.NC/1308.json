[{"id": "1308.0486", "submitter": "Jean-Pierre Francoise", "authors": "Marion Lahutte-Auboin, Robert Costalat, Jean-Pierre Fran\\c{c}oise and\n  Remy Guillevin", "title": "Dip and Buffering in a fast-slow system associated to Brain Lactacte\n  Kinetics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-dimensional compartmental dynamical systems have been introduced to\nmodel brain metabolism. In this article, an approach is proposed to their\nmathematical analysis. Reductions of these models are obtained by replacing\nseveral compartments by a control term. The analysis focuses here on lactate\nkinetics. A mathematical analysis of the initial dip of lactacte, observed\nunder stimulation, and of the periodic buffering, underlying the re- sponse to\na repetitive sequence of identical stimuli, can be proposed. This mathematical\nanalysis relies on asymptotics techniques of time multi-scaled dynamical\nsystems such as averaging along slow manifolds.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2013 12:58:55 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Lahutte-Auboin", "Marion", ""], ["Costalat", "Robert", ""], ["Fran\u00e7oise", "Jean-Pierre", ""], ["Guillevin", "Remy", ""]]}, {"id": "1308.0668", "submitter": "David Lusseau", "authors": "David Lusseau", "title": "Quantum-like perception entanglement leads to advantageous collective\n  decisions", "comments": "8 pages, 3 figures, paper presented at the XXXIII International\n  Ethological Congress, 8 August 2013, Newcastle-upon-Tyne, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social animals have to make collective decisions on a daily basis. In most\ninstances, these decisions are taken by consensus, when the group does what the\nmajority of individuals want. Individuals have to base these decisions on the\ninformation they perceive from their socioecological landscape. The perception\nmechanisms they use can influence the cost of collective decisions. Here I show\nthat when group-living individuals perceive their environment concurrently for\nthe same decisions, a quantum-like perception entanglement process can confer\nless costly collective decisions than when individuals collect their\ninformation independently. This highlights a mechanism that can help explain\nwhat may seem to be irrational group-living behavior and opens avenues to\ndevelop empirical tests for quantum decision theory.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2013 07:54:08 GMT"}], "update_date": "2013-08-06", "authors_parsed": [["Lusseau", "David", ""]]}, {"id": "1308.0695", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Reply to Commentaries on 'An Evolutionary Framework for Cultural Change:\n  Selectionism versus Communal Exchange'", "comments": "8 pages; this is a reply to commentaries on q-bio.PE/0773336", "journal-ref": "Physics of Life Reviews, 10(2), 162-167 (2013)", "doi": "10.1016/j.plrev.2013.05.007", "report-no": null, "categories": "q-bio.PE nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The commentators have brought a wealth of new perspectives to the question of\nhow culture evolves. Each of their diverse disciplines--ranging from psychology\nto biology to anthropology to economics to engineering--has a valuable\ncontribution to make to our understanding of this complex, multifaceted topic.\nThough the vast majority of their comments were supportive of my approach, it\nis natural that a reply such as this focus on points where my views differ from\nthat of the commentators. ... I conclude by saying that I am grateful to the\ncommentators for their diverse perspectives and insights, their overall support\nfor the project, and provocative ideas for where to go from here. Clearly there\nare many fascinating avenues to explore as we move forward on our quest to\nunderstand how culture evolves.\n", "versions": [{"version": "v1", "created": "Sat, 3 Aug 2013 13:44:11 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 01:56:10 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1308.0821", "submitter": "Ivan Lazarevich", "authors": "Ivan A. Lazarevich and Victor B. Kazantsev", "title": "Dendritic signal transmission induced by intracellular charge\n  inhomogeneities", "comments": null, "journal-ref": "Phys. Rev. E 88, 062718 (2013)", "doi": "10.1103/PhysRevE.88.062718", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signal propagation in neuronal dendrites represents the basis for interneuron\ncommunication and information processing in the brain. Here we take into\naccount charge inhomogeneities arising in the vicinity of ion channels in\ncytoplasm and obtained a modified cable equation. We show that the charge\ninhomogeneities acting on the millisecond time scale can lead to the appearance\nof propagating waves with wavelengths of hundreds of micrometers. They\ncorrespond to a certain frequency band predicting the appearance of resonant\nproperties in brain neuron signalling.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2013 16:09:56 GMT"}], "update_date": "2013-12-25", "authors_parsed": [["Lazarevich", "Ivan A.", ""], ["Kazantsev", "Victor B.", ""]]}, {"id": "1308.0879", "submitter": "Takanobu Yamanobe", "authors": "Takanobu Yamanobe", "title": "Global Dynamics of a Stochastic Neuronal Oscillator", "comments": "45 pages, 9 figures, authors homepage\n  http://niseiri.med.hokudai.ac.jp/yamanobe/indexeng.html", "journal-ref": null, "doi": "10.1103/PhysRevE.88.052709", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear oscillators have been used to model neurons that fire periodically\nin the absence of input. These oscillators, which are called neuronal\noscillator, share some common response structures with other biological\noscillations. In this study, we analyze the dependence of the global dynamics\nof an impulse-driven stochastic neuronal oscillator on the relaxation rate to\nthe limit cycle, the strength of the intrinsic noise, and the impulsive input\nparameters. To do this, we use a Markov operator that both reflects the density\nevolution of the oscillator and is an extension of the phase transition curve,\nwhich describes the phase shift due to a single isolated impulse. Previously,\nwe derived the Markov operator for the finite relaxation rate that describes\nthe dynamics of the entire phase plane. Here, we construct a Markov operator\nfor the infinite relaxation rate that describes the stochastic dynamics\nrestricted to the limit cycle. In both cases, the response of the stochastic\nneuronal oscillator to time-varying impulses is described by a product of\nMarkov operators. Furthermore, we calculate the number of spikes between two\nconsecutive impulses to relate the dynamics of the oscillator to the number of\nspikes per unit time and the interspike interval density. Specifically, we\nanalyze the dynamics of the number of spikes per unit time based on the\nproperties of the Markov operators. Each Markov operator can be decomposed into\nstationary and transient components based on the properties of the eigenvalues\nand eigenfunctions. This allows us to evaluate the difference in the number of\nspikes per unit time between the stationary and transient responses of the\noscillator, which we show to be based on the dependence of the oscillator on\npast activity. Our analysis shows how the duration of the past neuronal\nactivity depends on the relaxation rate, the noise strength and the input\nparameters.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2013 03:42:36 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Yamanobe", "Takanobu", ""]]}, {"id": "1308.1252", "submitter": "Marc de Lussanet H.E.", "authors": "Marc H.E. de Lussanet", "title": "The human and mammalian cerebrum scale by computational power and\n  information resistance", "comments": "15 pages, 2 figures; 3 supplements", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cerebrum of mammals spans a vast range of sizes and yet has a very\nregular structure. The amount of folding of the cortical surface and the\nproportion of white matter gradually increase with size, but the underlying\nmechanisms remain elusive. Here, two laws are derived to fully explain these\ncerebral scaling relations. The first law holds that the long-range information\nflow in the cerebrum is determined by the total cortical surface (i.e., the\nnumber of neurons) and the increasing information resistance of long-range\nconnections. Despite having just one free parameter, the first law fits the\nmammalian cerebrum better than any existing function, both across species and\nwithin humans. According to the second law, the white matter volume scales,\nwith a few minor corrections, to the cortical surface area. It follows from the\nfirst law that large cerebrums have much local processing and little global\ninformation flow. Moreover, paradoxically, a further increase in long-range\nconnections would decrease the efficiency of information flow.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 12:13:18 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["de Lussanet", "Marc H. E.", ""]]}, {"id": "1308.1352", "submitter": "Paul Gribble", "authors": "Jeremy D Wong, Elizabeth T Wilson, Dinant A Kistemaker, Paul L Gribble", "title": "Bimanual proprioception: are two hands better than one?", "comments": null, "journal-ref": "J Neurophysiol. 2014 Mar;111(6):1362-8", "doi": "10.1152/jn.00537.2013", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information about the position of an object that is held in both hands, such\nas a golf club or a tennis racquet, is transmitted to the human central nervous\nsystem from peripheral sensors in both left and right arms. How does the brain\ncombine these two sources of information? Using a robot to move participant's\npassive limbs, we performed psychophysical estimates of proprioceptive function\nfor each limb independently, and again when subjects grasped the robot handle\nwith both arms. We compared empirical estimates of bimanual proprioception to\nseveral models from the sensory integration literature: some that propose a\ncombination of signals from the left and right arms (such as a Bayesian\nmaximum-likelihood estimate), and some that propose using unimanual signals\nalone. Our results are consistent with the hypothesis that the nervous system\nboth has knowledge of, and uses the limb with the best proprioceptive acuity\nfor bimanual proprioception. Surprisingly, a Bayesian model that postulates\noptimal combination of sensory signals could not predict empirically observed\nbimanual acuity. These findings suggest that while the central nervous system\nseems to have information about the relative sensory acuity of each limb, it\nuses this information in a rather rudimentary fashion, essentially ignoring\ninformation from the less reliable limb.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2013 17:18:53 GMT"}], "update_date": "2014-04-10", "authors_parsed": [["Wong", "Jeremy D", ""], ["Wilson", "Elizabeth T", ""], ["Kistemaker", "Dinant A", ""], ["Gribble", "Paul L", ""]]}, {"id": "1308.1522", "submitter": "Asha  Gopinathan", "authors": "Asha Gopinathan and Joseph Mathew", "title": "Solving Hodgkin-Huxley equations using the compact difference scheme -\n  somadendrite", "comments": "12 pages, 4 figures, 4 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dendrites have voltage-gated ion channels which aid in production of action\npotentials. Thus dendrites are not just passive conductors of information, but\nactively act on the incoming input. Here we assume Hodgkin-Huxley formulations\nof voltage-gated ion channels on the dendrite. These equations are normally\nsolved by some form of central difference scheme or the spectral methods. We\nuse a compact finite-difference scheme to solve these equations. This scheme\ngives spectral-like spatial resolution while being easier to solve than\nspectral methods. The scheme has shown to be able to reproduce the results from\nspectral methods. In this paper cylindrical dendrites are described. It may\nalso be noted that the compact difference scheme can be used to solve any other\nPDE both in biological as well as non biological systems. It is increasingly\nused in studying turbulence in airflow.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2013 09:50:43 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2013 18:03:14 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Gopinathan", "Asha", ""], ["Mathew", "Joseph", ""]]}, {"id": "1308.1788", "submitter": "Asha  Gopinathan", "authors": "Asha Gopinathan and Joseph Mathew", "title": "Solving Hodgkin-Huxley equations using the compact difference scheme\n  -tapering dendrite", "comments": "10 pages, 3 Figures, 3 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dendritic processing is now considered to be important in pre-processing of\nsignals coming into a cell. Dendrites are involved in both propagation and\nbackpropagation of signals. In a cylindrical dendrite, signals moving in either\ndirection will be similar. However, if the dendrites taper, then this is not\nthe case any more. The picture gets more complex if the ion channel\ndistribution along the dendrite is also non-uniform. These equations have been\nsolved using the Chebyshev pseudo-spectral method. Here we look at non-uniform\ndendritic voltage gated channels in both cylindrical and tapering dendrites.\nFor back-propagating signals, the signal is accentuated in the case of tapering\ndendrites. We assume a Hodgkin-Huxley formulation of ion channels and solve\nthese equations with the compact finite-difference scheme. The scheme gives\nspectral-like spatial resolution while being easier to solve than spectral\nmethods. We show that the scheme is able to reproduce the results obtained from\nspectral methods. The compact difference scheme is widely used to study\nturbulence in airflow, however it is being used for the first time in our\nlaboratory to solve the equations involving transmission of signals in the\nbrain.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2013 09:02:42 GMT"}, {"version": "v2", "created": "Fri, 27 Sep 2013 06:51:53 GMT"}], "update_date": "2013-09-30", "authors_parsed": [["Gopinathan", "Asha", ""], ["Mathew", "Joseph", ""]]}, {"id": "1308.2350", "submitter": "Bonny Banerjee", "authors": "Jayanta K. Dutta, Bonny Banerjee", "title": "Learning Features and their Transformations by Spatial and Temporal\n  Spherical Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning features invariant to arbitrary transformations in the data is a\nrequirement for any recognition system, biological or artificial. It is now\nwidely accepted that simple cells in the primary visual cortex respond to\nfeatures while the complex cells respond to features invariant to different\ntransformations. We present a novel two-layered feedforward neural model that\nlearns features in the first layer by spatial spherical clustering and\ninvariance to transformations in the second layer by temporal spherical\nclustering. Learning occurs in an online and unsupervised manner following the\nHebbian rule. When exposed to natural videos acquired by a camera mounted on a\ncat's head, the first and second layer neurons in our model develop simple and\ncomplex cell-like receptive field properties. The model can predict by learning\nlateral connections among the first layer neurons. A topographic map to their\nspatial features emerges by exponentially decaying the flow of activation with\ndistance from one neuron to another in the first layer that fire in close\ntemporal proximity, thereby minimizing the pooling length in an online manner\nsimultaneously with feature learning.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2013 22:56:26 GMT"}], "update_date": "2020-12-14", "authors_parsed": [["Dutta", "Jayanta K.", ""], ["Banerjee", "Bonny", ""]]}, {"id": "1308.2577", "submitter": "Cedric Ginestet", "authors": "Cedric E. Ginestet, Arnaud P. Fournel and Andrew Simmons", "title": "Statistical Network Analysis for Functional MRI: Summary Networks and\n  Group Comparisons", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Comparing weighted networks in neuroscience is hard, because the topological\nproperties of a given network are necessarily dependent on the number of edges\nof that network. This problem arises in the analysis of both weighted and\nunweighted networks. The term density is often used in this context, in order\nto refer to the mean edge weight of a weighted network, or to the number of\nedges in an unweighted one. Comparing families of networks is therefore\nstatistically difficult because differences in topology are necessarily\nassociated with differences in density. In this review paper, we consider this\nproblem from two different perspectives, which include (i) the construction of\nsummary networks, such as how to compute and visualize the mean network from a\nsample of network-valued data points; and (ii) how to test for topological\ndifferences, when two families of networks also exhibit significant differences\nin density. In the first instance, we show that the issue of summarizing a\nfamily of networks can be conducted by adopting a mass-univariate approach,\nwhich produces a statistical parametric network (SPN). In the second part of\nthis review, we then highlight the inherent problems associated with the\ncomparison of topological functions of families of networks that differ in\ndensity. In particular, we show that a wide range of topological summaries,\nsuch as global efficiency and network modularity are highly sensitive to\ndifferences in density. Moreover, these problems are not restricted to\nunweighted metrics, as we demonstrate that the same issues remain present when\nconsidering the weighted versions of these metrics. We conclude by encouraging\ncaution, when reporting such statistical comparisons, and by emphasizing the\nimportance of constructing summary networks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 14:26:38 GMT"}, {"version": "v2", "created": "Thu, 27 Mar 2014 06:09:45 GMT"}], "update_date": "2014-03-28", "authors_parsed": [["Ginestet", "Cedric E.", ""], ["Fournel", "Arnaud P.", ""], ["Simmons", "Andrew", ""]]}, {"id": "1308.2630", "submitter": "Tomasz Rutkowski", "authors": "Yohann Lelievre and Tomasz M. Rutkowski", "title": "Novel Virtual Moving Sound-based Spatial Auditory Brain-Computer\n  Interface Paradigm", "comments": "4 pages (in conference proceedings original version); 6 figures,\n  accepted at 6th International IEEE EMBS Conference on Neural Engineering,\n  November 6-8, 2013, Sheraton San Diego Hotel & Marina, San Diego, CA; paper\n  ID 465; to be available at IEEE Xplore; IEEE Copyright 2013", "journal-ref": "Neural Engineering (NER), 2013 6th International IEEE/EMBS\n  Conference on. IEEE Engineering in Medicine and Biology Society; 2013. p.\n  9-12", "doi": "10.1109/NER.2013.6695858", "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on a study in which a novel virtual moving sound-based\nspatial auditory brain-computer interface (BCI) paradigm is developed. Classic\nauditory BCIs rely on spatially static stimuli, which are often boring and\ndifficult to perceive when subjects have non-uniform spatial hearing perception\ncharacteristics. The concept of moving sound proposed and tested in the paper\nallows for the creation of a P300 oddball paradigm of necessary target and\nnon-target auditory stimuli, which are more interesting and easier to\ndistinguish. We present a report of our study of seven healthy subjects, which\nproves the concept of moving sound stimuli usability for a novel BCI. We\ncompare online BCI classification results in static and moving sound paradigms\nyielding similar accuracy results. The subject preference reports suggest that\nthe proposed moving sound protocol is more comfortable and easier to\ndiscriminate with the online BCI.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2013 17:26:14 GMT"}, {"version": "v2", "created": "Wed, 14 Aug 2013 08:41:04 GMT"}], "update_date": "2014-01-08", "authors_parsed": [["Lelievre", "Yohann", ""], ["Rutkowski", "Tomasz M.", ""]]}, {"id": "1308.3362", "submitter": "Sven Jahnke", "authors": "Sven Jahnke, Marc Timme, Raoul-Martin Memmesheimer", "title": "Guiding synchrony through random networks", "comments": null, "journal-ref": "Phys. Rev. X 2, 041016 (2012)", "doi": "10.1103/PhysRevX.2.041016", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Sparse random networks contain structures that can be considered as diluted\nfeed-forward networks. Modeling of cortical circuits has shown that\nfeed-forward structures, if strongly pronounced compared to the embedding\nrandom network, enable reliable signal transmission by propagating localized\n(sub-network) synchrony. This assumed prominence, however, is not\nexperimentally observed in local cortical circuits. Here we show that nonlinear\ndendritic interactions as discovered in recent single neuron experiments,\nnaturally enable guided synchrony propagation already in random recurrent\nneural networks exhibiting mildly enhanced, biologically plausible\nsub-structures.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 11:27:57 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Jahnke", "Sven", ""], ["Timme", "Marc", ""], ["Memmesheimer", "Raoul-Martin", ""]]}, {"id": "1308.3363", "submitter": "Sven Jahnke", "authors": "Sven Jahnke, Raoul-Martin Memmesheimer, Marc Timme", "title": "How Chaotic is the Balanced State?", "comments": null, "journal-ref": "Front. Comput. Neurosci. (2009) 3:13", "doi": "10.3389/neuro.10.013.2009", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Large sparse circuits of spiking neurons exhibit a balanced state of highly\nirregular activity under a wide range of conditions. It occurs likewise in\nsparsely connected random networks that receive excitatory external inputs and\nrecurrent inhibition as well as in networks with mixed recurrent inhibition and\nexcitation. Here we analytically investigate this irregular dynamics in finite\nnetworks keeping track of all individual spike times and the identities of\nindividual neurons. For delayed, purely inhibitory interactions we show that\nthe irregular dynamics is not chaotic but in fact stable. Moreover, we\ndemonstrate that after long transients the dynamics converges towards periodic\norbits and that every generic periodic orbit of these dynamical systems is\nstable. We investigate the collective irregular dynamics upon increasing the\ntime scale of synaptic responses and upon iteratively replacing inhibitory by\nexcitatory interactions. Whereas for small and moderate time scales as well as\nfor few excitatory interactions, the dynamics stays stable, there is a smooth\ntransition to chaos if the synaptic response becomes sufficiently slow (even in\npurely inhibitory networks) or the number of excitatory interactions becomes\ntoo large. These results indicate that chaotic and stable dynamics are equally\ncapable of generating the irregular neuronal activity. More generally, chaos\napparently is not essential for generating high irregularity of balanced\nactivity, and we suggest that a mechanism different from chaos and\nstochasticity significantly contributes to irregular activity in cortical\ncircuits.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2013 11:30:56 GMT"}], "update_date": "2013-08-16", "authors_parsed": [["Jahnke", "Sven", ""], ["Memmesheimer", "Raoul-Martin", ""], ["Timme", "Marc", ""]]}, {"id": "1308.3542", "submitter": "Ross Williamson", "authors": "Ross S. Williamson, Maneesh Sahani, Jonathan W. Pillow", "title": "The equivalence of information-theoretic and likelihood-based methods\n  for neural dimensionality reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stimulus dimensionality-reduction methods in neuroscience seek to identify a\nlow-dimensional space of stimulus features that affect a neuron's probability\nof spiking. One popular method, known as maximally informative dimensions\n(MID), uses an information-theoretic quantity known as \"single-spike\ninformation\" to identify this space. Here we examine MID from a model-based\nperspective. We show that MID is a maximum-likelihood estimator for the\nparameters of a linear-nonlinear-Poisson (LNP) model, and that the empirical\nsingle-spike information corresponds to the normalized log-likelihood under a\nPoisson model. This equivalence implies that MID does not necessarily find\nmaximally informative stimulus dimensions when spiking is not well described as\nPoisson. We provide several examples to illustrate this shortcoming, and derive\na lower bound on the information lost when spiking is Bernoulli in discrete\ntime bins. To overcome this limitation, we introduce model-based dimensionality\nreduction methods for neurons with non-Poisson firing statistics, and show that\nthey can be framed equivalently in likelihood-based or information-theoretic\nterms. Finally, we show how to overcome practical limitations on the number of\nstimulus dimensions that MID can estimate by constraining the form of the\nnon-parametric nonlinearity in an LNP model. We illustrate these methods with\nsimulations and data from primate visual cortex.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2013 03:47:19 GMT"}, {"version": "v2", "created": "Tue, 24 Feb 2015 22:29:56 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Williamson", "Ross S.", ""], ["Sahani", "Maneesh", ""], ["Pillow", "Jonathan W.", ""]]}, {"id": "1308.3552", "submitter": "Markus Dahlem", "authors": "Markus A. Dahlem, Sebastian Rode, Arne May, Naoya Fujiwara, Yoshito\n  Hirata, Kazuyuki Aihara, and J\\\"urgen Kurths", "title": "Towards dynamical network biomarkers in neuromodulation of episodic\n  migraine", "comments": "13 pages, 5 figures", "journal-ref": null, "doi": "10.2478/s13380-013-0127-0", "report-no": null, "categories": "q-bio.NC nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational methods have complemented experimental and clinical\nneursciences and led to improvements in our understanding of the nervous\nsystems in health and disease. In parallel, neuromodulation in form of electric\nand magnetic stimulation is gaining increasing acceptance in chronic and\nintractable diseases. In this paper, we firstly explore the relevant state of\nthe art in fusion of both developments towards translational computational\nneuroscience. Then, we propose a strategy to employ the new theoretical concept\nof dynamical network biomarkers (DNB) in episodic manifestations of chronic\ndisorders. In particular, as a first example, we introduce the use of\ncomputational models in migraine and illustrate on the basis of this example\nthe potential of DNB as early-warning signals for neuromodulation in episodic\nmigraine.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2013 04:48:56 GMT"}], "update_date": "2014-08-13", "authors_parsed": [["Dahlem", "Markus A.", ""], ["Rode", "Sebastian", ""], ["May", "Arne", ""], ["Fujiwara", "Naoya", ""], ["Hirata", "Yoshito", ""], ["Aihara", "Kazuyuki", ""], ["Kurths", "J\u00fcrgen", ""]]}, {"id": "1308.4017", "submitter": "Berdakh Abibullaev", "authors": "Berdakh Abibullaev, Jinung An, Seung-Hyun Lee and Jeon-Il Moon", "title": "A Study on Stroke Rehabilitation through Task-Oriented Control of a\n  Haptic Device via Near-Infrared Spectroscopy-Based BCI", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a study in task-oriented approach to stroke\nrehabilitation by controlling a haptic device via near-infrared\nspectroscopy-based brain-computer interface (BCI). The task is to command the\nhaptic device to move in opposing directions of leftward and rightward\nmovement. Our study consists of data acquisition, signal preprocessing, and\nclassification. In data acquisition, we conduct experiments based on two\ndifferent mental tasks: one on pure motor imagery, and another on combined\nmotor imagery and action observation. The experiments were conducted in both\noffline and online modes. In the signal preprocessing, we use localization\nmethod to eliminate channels that are irrelevant to the mental task, as well as\nperform feature extraction for subsequent classification. We propose multiple\nsupport vector machine classifiers with a majority-voting scheme for improved\nclassification results. And lastly, we present test results to demonstrate the\nefficacy of our proposed approach to possible stroke rehabilitation practice.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 13:31:34 GMT"}, {"version": "v2", "created": "Wed, 9 Oct 2013 09:32:52 GMT"}, {"version": "v3", "created": "Mon, 14 Apr 2014 08:06:07 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Abibullaev", "Berdakh", ""], ["An", "Jinung", ""], ["Lee", "Seung-Hyun", ""], ["Moon", "Jeon-Il", ""]]}, {"id": "1308.4102", "submitter": "Inti  Pedroso", "authors": "Inti Pedroso", "title": "Gene and Gene-Set Analysis for Genome-Wide Association Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN q-bio.MN q-bio.NC q-bio.PE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Genome-wide association studies (GWAS) have identified hundreds of loci at\nvery stringent levels of statistical significance across many different human\ntraits. However, it is now clear that very large samples (n~10^4-10^5) are\nneeded to find the majority of genetic variants underlying risk for most human\ndiseases. Therefore, the field has engaged itself in a race to increase study\nsample sizes with some studies yielding very successful results but also\nstudies which provide little or no new insights. This project started early on\nin this new wave of studies and I decided to use an alternative approach that\nuses prior biological knowledge to improve both interpretation and power of\nGWAS. The project aimed to a) implement and develop new gene-based methods to\nderive gene-level statistics to use GWAS in well established system biology\ntools; b) use of these gene-level statistics in networks and gene-set analyses\nof GWAS data; c) mine GWAS of neuropsychiatric disorders using gene, gene-sets\nand integrative biology analyses with gene-expression studies; and d) explore\nthe ability of these methods to improve the analysis GWAS on disease\nsub-phenotypes which usually suffer of very small sample sizes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2013 19:20:12 GMT"}], "update_date": "2013-08-20", "authors_parsed": [["Pedroso", "Inti", ""]]}, {"id": "1308.4122", "submitter": "Lianchun Yu", "authors": "Lianchun Yu and Liwei Liu", "title": "The Optimal Size of Stochastic Hodgkin-Huxley Neuronal Systems for\n  Maximal Energy Efficiency in Coding of Pulse Signals", "comments": "22 pages, 10 figures", "journal-ref": "Phys. Rev. E 89, 032725 (2014)", "doi": "10.1103/PhysRevE.89.032725", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generation and conduction of action potentials represents a fundamental\nmeans of communication in the nervous system, and is a metabolically expensive\nprocess. In this paper, we investigate the energy efficiency of neural systems\nin a process of transfer pulse signals with action potentials. By computer\nsimulation of a stochastic version of Hodgkin-Huxley model with detailed\ndescription of ion channel random gating, and analytically solve a bistable\nneuron model that mimic the action potential generation with a particle\ncrossing the barrier of a double well, we find optimal number of ion channels\nthat maximize energy efficiency for a neuron. We also investigate the energy\nefficiency of neuron population in which input pulse signals are represented\nwith synchronized spikes and read out with a downstream coincidence detector\nneuron. We find an optimal combination of the number of neurons in neuron\npopulation and the number of ion channels in each neuron that maximize the\nenergy efficiency. The energy efficiency depends on the characters of the input\nsignals, e.g., the pulse strength and the inter-pulse intervals. We argue that\ntrade-off between reliability of signal transmission and energy cost may\ninfluence the size of the neural systems if energy use is constrained.\n", "versions": [{"version": "v1", "created": "Sat, 17 Aug 2013 05:13:14 GMT"}], "update_date": "2014-04-23", "authors_parsed": [["Yu", "Lianchun", ""], ["Liu", "Liwei", ""]]}, {"id": "1308.4241", "submitter": "Liane Gabora", "authors": "Liane Gabora and Adam Saab", "title": "Creative Interference and States of Potentiality in Analogy Problem\n  Solving", "comments": "7 pages", "journal-ref": "Proceedings of the 33rd Annual Meeting of the Cognitive Science\n  Society (pp. 3506-3511). Austin, TX: Cognitive Science Society. (2011)", "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creative processes are widely believed to involve the generation of multiple,\ndiscrete, well-defined possibilities followed by exploration and selection. An\nalternative, inspired by parallel distributed processing models of associative\nmemory, is that creativity involves the merging and interference of memory\nitems resulting in a single cognitive structure that is ill-defined, and can\nthus be said to exist in a state of potentiality. We tested this hypothesis in\nan experiment in which participants were interrupted midway through solving an\nanalogy problem and asked what they were thinking in terms of a solution. Naive\njudges categorized their responses as AP if there was evidence of merging\nsolution sources from memory resulting in an ill-defined idea, and SM if there\nwas no evidence of this. Data from frequency counts and mean number of SM\nversus AP judgments supported the hypothesis that midway through creative\nprocessing an idea is in a potentiality state.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 07:25:12 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 20:33:47 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 19:54:21 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Gabora", "Liane", ""], ["Saab", "Adam", ""]]}, {"id": "1308.4245", "submitter": "Liane Gabora", "authors": "Sean N. Riley and Liane Gabora", "title": "Evidence that Threatening Situations Enhance Creativity", "comments": null, "journal-ref": "Proceedings of the 34th Annual Meeting of the Cognitive Science\n  Society (pp. 2234-2239). Austin, TX: Cognitive Science Society. (2012)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tested the hypothesis that threatening situations enhance creativity. 60\nparticipants viewed a series of photographs and rated them on level of threat.\nThey then wrote two short stories: one based on the photograph they rated as\nmost threatening, and the other based on the photograph they rated as least\nthreatening. The stories were rated for level of creativity. Paired samples\nt-tests revealed that stories based on threatening pictures produced a higher\ndegree of creativity than those based on non-threatening pictures. Theoretical\nframeworks consistent with these findings are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 07:37:49 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 20:30:21 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 19:53:30 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Riley", "Sean N.", ""], ["Gabora", "Liane", ""]]}, {"id": "1308.4385", "submitter": "Gael Varoquaux", "authors": "P. Ciuciu (LNAO), G. Varoquaux, P. Abry, S. Sadaghiani, A.\n  Kleinschmidt", "title": "Scale-Free and Multifractal Time Dynamics of fMRI Signals during Rest\n  and Task", "comments": null, "journal-ref": "Frontiers in Physiology 3, 1 (2012) 186", "doi": "10.3389/fphys.2012.00186", "report-no": null, "categories": "math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scaling temporal dynamics in functional MRI (fMRI) signals have been\nevidenced for a decade as intrinsic characteristics of ongoing brain activity\n(Zarahn et al., 1997). Recently, scaling properties were shown to fluctuate\nacross brain networks and to be modulated between rest and task (He, 2011):\nnotably, Hurst exponent, quantifying long memory, decreases under task in\nactivating and deactivating brain regions. In most cases, such results were\nobtained: First, from univariate (voxelwise or regionwise) analysis, hence\nfocusing on specific cognitive systems such as Resting-State Networks (RSNs)\nand raising the issue of the specificity of this scale-free dynamics modulation\nin RSNs. Second, using analysis tools designed to measure a single scaling\nexponent related to the second order statistics of the data, thus relying on\nmodels that either implicitly or explicitly assume Gaussianity and (asymptotic)\nself-similarity, while fMRI signals may significantly depart from those either\nof those two assumptions (Ciuciu et al., 2008; Wink et al., 2008). To address\nthese issues, the present contribution elaborates on the analysis of the\nscaling properties of fMRI temporal dynamics by proposing two significant\nvariations. First, scaling properties are technically investigated using the\nrecently introduced Wavelet Leader-based Multifractal formalism (WLMF; Wendt et\nal., 2007). This measures a collection of scaling exponents, thus enables a\nricher and more versatile description of scale invariance (beyond correlation\nand Gaussianity), referred to as multifractality. Also, it benefits from\nimproved estimation performance compared to tools previously used in the\nliterature. Second, scaling properties are investigated in both RSN and non-RSN\nstructures (e.g., artifacts), at a broader spatial scale than the voxel one,\nusing a multivariate approach, namely the Multi-Subject Dictionary Learning\n(MSDL) algorithm (Varoquaux et al., 2011) that produces a set of spatial\ncomponents that appear more sparse than their Independent Component Analysis\n(ICA) counterpart. These tools are combined and applied to a fMRI dataset\ncomprising 12 subjects with resting-state and activation runs (Sadaghiani et\nal., 2009). Results stemming from those analysis confirm the already reported\ntask-related decrease of long memory in functional networks, but also show that\nit occurs in artifacts, thus making this feature not specific to functional\nnetworks. Further, results indicate that most fMRI signals appear multifractal\nat rest except in non-cortical regions. Task-related modulation of\nmultifractality appears only significant in functional networks and thus can be\nconsidered as the key property disentangling functional networks from\nartifacts. These finding are discussed in the light of the recent literature\nreporting scaling dynamics of EEG microstate sequences at rest and addressing\nnon-stationarity issues in temporally independent fMRI modes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 19:21:53 GMT"}], "update_date": "2013-08-21", "authors_parsed": [["Ciuciu", "P.", "", "LNAO"], ["Varoquaux", "G.", ""], ["Abry", "P.", ""], ["Sadaghiani", "S.", ""], ["Kleinschmidt", "A.", ""]]}, {"id": "1308.4706", "submitter": "Liane Gabora", "authors": "Apara Ranjan, Liane Gabora, and Brian O'Connor", "title": "The Cross-Domain Re-interpretation of Artistic Ideas", "comments": "6 pages", "journal-ref": "Proceedings 35th Annual Meeting of the Cognitive Science Society\n  (pp. 3251-3256). Austin, TX: Cognitive Science Society. (2013)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this study was to investigate the translation of creative works\ninto other domains. We tested whether people were able to recognize which works\nof art were inspired by which pieces of music. Three expert painters created\nfour paintings, each of which was the artist's interpretation of one of four\ndifferent pieces of instrumental music. Participants were able to identify\nwhich paintings were inspired by which pieces of music at statistically\nsignificant above chance levels. The findings support the hypothesis that\ncreative ideas can exist in an at least somewhat domain independent state of\npotentiality and become more well defined as they are actualized in accordance\nwith the constraints of a particular domain.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 06:58:32 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 20:43:32 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 19:51:48 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Ranjan", "Apara", ""], ["Gabora", "Liane", ""], ["O'Connor", "Brian", ""]]}, {"id": "1308.4707", "submitter": "Liane Gabora", "authors": "Madeleine Henderson and Liane Gabora", "title": "The Recognizability of Authenticity", "comments": "6 pages", "journal-ref": "Proceedings of the 35th Annual Meeting of the Cognitive Science\n  Society (pp. 2524-2529). Austin, TX: Cognitive Science Society. (2013)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goals of this research were to (1) determine if there is agreement both\namongst viewers, and between viewers and the performer, about the extent to\nwhich performances are authentic, and (2) ascertain whether or not performers\nand/or viewers can distinguish between authenticity and skill. An authentic\nperformance is one that is natural or genuine, while an inauthentic performance\nfeels faked, forced, or imitative. Study participants were asked to rate the\nauthenticity and skill level of a series of videotaped performances by dancers\nand stand-up comedians. Performers also rated their own performances.\nAuthenticity ratings amongst viewers were significantly positively correlated.\nRatings between viewers and performers were not significant but all positive. A\nhigher correlation between ratings of both authenticity and skill of\nperformances for viewers than for performers suggests that viewers make less of\na distinction between authenticity and skill than performers. The relationship\nbetween authenticity and creativity is discussed.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2013 07:02:20 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 20:41:41 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 19:50:53 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Henderson", "Madeleine", ""], ["Gabora", "Liane", ""]]}, {"id": "1308.5032", "submitter": "Liane Gabora", "authors": "Liane Gabora and Steve DiPaola", "title": "How Did Humans Become So Creative? A Computational Approach", "comments": "8 pages", "journal-ref": "Proceedings of the Third International Conference on Computational\n  Creativity (pp. 203-210). May 31 - June 1, 2012, Dublin, Ireland", "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.MA q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes efforts to computationally model two transitions in the\nevolution of human creativity: its origins about two million years ago, and the\n'big bang' of creativity about 50,000 years ago. Using a computational model of\ncultural evolution in which neural network based agents evolve ideas for\nactions through invention and imitation, we tested the hypothesis that human\ncreativity began with onset of the capacity for recursive recall. We compared\nruns in which agents were limited to single-step actions to runs in which they\nused recursive recall to chain simple actions into complex ones. Chaining\nresulted in higher diversity, open-ended novelty, no ceiling on the mean\nfitness of actions, and greater ability to make use of learning. Using a\ncomputational model of portrait painting, we tested the hypothesis that the\nexplosion of creativity in the Middle/Upper Paleolithic was due to onset of\ncon-textual focus: the capacity to shift between associative and analytic\nthought. This resulted in faster convergence on portraits that resembled the\nsitter, employed painterly techniques, and were rated as preferable. We\nconclude that recursive recall and contextual focus provide a computationally\nplausible explanation of how humans evolved the means to transform this planet.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 03:05:28 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 02:03:19 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 19:24:32 GMT"}, {"version": "v4", "created": "Tue, 9 Jul 2019 19:50:17 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Gabora", "Liane", ""], ["DiPaola", "Steve", ""]]}, {"id": "1308.5034", "submitter": "Liane Gabora", "authors": "Liane Gabora and Anne Russon", "title": "The Evolution of Intelligence", "comments": "25 pages. arXiv admin note: substantial text overlap with\n  arXiv:1106.3386", "journal-ref": "In R. Sternberg & S. Kaufman (Eds.), The Cambridge handbook of\n  intelligence, (pp. 328-350). Cambridge UK: Cambridge University Press (2011)", "doi": "10.1017/CBO9780511977244.018", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How did the human species evolve the capacity not just to communicate complex\nideas to one another but to hold such conversations from across the globe,\nusing remote devices constructed from substances that do not exist in the\nnatural world, the raw materials for which may have been hauled up from the\nbowels of the earth? How did we come to be so intelligent? Research at the\ninterface of psychology, biology, anthropology, archaeology, and cognitive\nscience is culminating in an increasingly sophisticated understanding of how\nhuman intelligence evolved. Studies of the brains of living humans and great\napes and the intellectual abilities they support are enabling us to assess what\nis unique about human intelligence and what we share with our primate\nrelatives. Examining the habitats and skeletons of our ancestors gives cues as\nto environmental, social, and anatomical factors that both constrain and enable\nthe evolution of human intelligence. Relics of the past also have much to tell\nus about the thoughts, beliefs, and abilities of the individuals who invented\nand used them.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 03:14:31 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 02:05:55 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 22:00:50 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Gabora", "Liane", ""], ["Russon", "Anne", ""]]}, {"id": "1308.5037", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Revenge of the 'Neurds': Characterizing Creative Thought in terms of the\n  Structure and Dynamics of Memory", "comments": "25 pages including 3 figures. arXiv admin note: substantial text\n  overlap with arXiv:1106.3600", "journal-ref": "Creativity Research Journal, 22(1), 1-13 (2010)", "doi": "10.1080/10400410903579494", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is cognitive, neurological, and computational support for the\nhypothesis that defocusing attention results in divergent or associative\nthought, conducive to insight and finding unusual connections, while focusing\nattention results in convergent or analytic thought, conducive to rule-based\noperations. Creativity appears to involve both. It is widely believed that it\nis possible to escape mental fixation by spontaneously and temporarily engaging\nin a more associative mode of thought. The resulting insight (if found) may be\nrefined in a more analytic mode of thought. The questions addressed here are:\n(1) how does the architecture of memory support these two modes of thought, and\n(2) what is happening at the neural level when one shifts between them? Recent\nadvances in neuroscience shed light on this. Activated cell assemblies are\ncomposed of multiple neural cliques, groups of neurons that respond\ndifferentially to general or context-specific aspects of a situation. I refer\nto neural cliques that would not be included in the assembly if one were in an\nanalytic mode, but would be if one were in an associative mode, as neurds. It\nis posited that the shift to a more associative mode of thought is accomplished\nby recruiting neurds that respond to abstract or atypical microfeatures of the\nproblem or task. Since memory is distributed and content-addressable, this\nfosters the forging of associations to potentially relevant items previously\nencoded in those neurons. Thus it is proposed that creative thought not by\nsearching a space of predefined alternatives and blindly tweaking those that\nhold promise, but by evoking remotely associated items through the recruitment\nof neurds in a distributed, content-addressable memory.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 03:32:15 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 02:10:08 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1308.5050", "submitter": "Zachary Kilpatrick PhD", "authors": "Sam Carroll, Kresimir Josic, and Zachary P Kilpatrick", "title": "Encoding certainty in bump attractors", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent activity in neuronal populations has been shown to represent the\nspatial position of remembered stimuli. Networks that support bump attractors\nare often used to model such persistent activity. Such models usually exhibit\ntranslational symmetry. Thus activity bumps are neutrally stable, and\nperturbations in position do not decay away. We extend previous work on bump\nattractors by constructing model networks capable of encoding the certainty or\nsalience of a stimulus stored in memory. Such networks support bumps that are\nnot only neutrally stable to perturbations in position, but also perturbations\nin amplitude. Possible bump solutions then lie on a two-dimensional attractor,\ndetermined by a continuum of positions and amplitudes. Such an attractor\nrequires precisely balancing the strength of recurrent synaptic connections.\nThe amplitude of activity bumps represents certainty, and is determined by the\ninitial input to the system. Moreover, bumps with larger amplitudes are more\nrobust to noise, and over time provide a more faithful representation of the\nstored stimulus. In networks with separate excitatory and inhibitory\npopulations, generating bumps with a continuum of possible amplitudes, requires\ntuning the strength of inhibition to precisely cancel background excitation.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2013 05:20:22 GMT"}], "update_date": "2013-08-26", "authors_parsed": [["Carroll", "Sam", ""], ["Josic", "Kresimir", ""], ["Kilpatrick", "Zachary P", ""]]}, {"id": "1308.5458", "submitter": "Juan Manuel Romero", "authors": "Juan M. Romero, Carlos Trenado, Berenice Aguilar and Miriam\n  Tirradentro", "title": "Relativistic conformal symmetry of neural field propagation in the brain", "comments": "No figures, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-th q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address a neural field equation that characterizes\nspatio-temporal propagation of a neural population pulse. Due that the human\nbrain is a complex system whose constituents interaction give rise to\nfundamental states of consciousness and behavior, it is crucial to gain insight\ninto its functioning even at relativistic scales. To this end, we study the\naction of the relativistic conformal group on the accounted neural field\npropagation equation. In particular, we obtain an exact solution for the field\npropagation equation when the space-time is 3 or 4 dimensional. Furthermore, in\nthe 4 dimensional case and the large distance limit, it is shown that the\nneural population pulse becomes a Yukawa potential.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2013 22:31:10 GMT"}], "update_date": "2013-08-27", "authors_parsed": [["Romero", "Juan M.", ""], ["Trenado", "Carlos", ""], ["Aguilar", "Berenice", ""], ["Tirradentro", "Miriam", ""]]}, {"id": "1308.5668", "submitter": "Richard Naud", "authors": "Richard Naud", "title": "An Integral Equation Approach to the Dynamics of L2-3 Cortical Neurons", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How do neuronal populations encode time-dependent stimuli in their population\nfiring rate? To address this question, I consider the quasi-renewal equation\nand the event-based expansion, two theoretical approximations proposed\nrecently, and test these against peri-stimulus time histograms from L2-3\npyramidal cells in vitro. Parameters are optimized by gradient descent to best\nmatch the firing rate output given the current input. The fitting method can\nestimate single-neuron parameters that are normally obtained either with\nintracellular recordings or with individual spike trains. I find that\nquasi-renewal theory predicts the adapting firing rate with good precision but\nnot the event-based expansion. Quasi-renewal predictions are equal in quality\nwith state-of-the-art spike timing prediction methods, and does so without\nresorting to the indiviual spike times or the membrane potential responses.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2013 19:55:20 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2013 03:31:29 GMT"}], "update_date": "2013-12-04", "authors_parsed": [["Naud", "Richard", ""]]}, {"id": "1308.6014", "submitter": "Robert Rosenbaum", "authors": "Robert Rosenbaum and Brent Doiron", "title": "Balanced networks of spiking neurons with spatially dependent recurrent\n  connections", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevX.4.021039", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks of model neurons with balanced recurrent excitation and inhibition\nproduce irregular and asynchronous spiking activity. We extend the analysis of\nbalanced networks to include the known dependence of connection probability on\nthe spatial separation between neurons. In the continuum limit we derive that\nstable, balanced firing rate solutions require that the spatial spread of\nexternal inputs be broader than that of recurrent excitation, which in turn\nmust be broader than or equal to that of recurrent inhibition. For finite size\nnetworks we investigate the pattern forming dynamics arising when balanced\nconditions are not satisfied. The spatiotemporal dynamics of balanced networks\noffer new challenges in the statistical mechanics of complex systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2013 23:39:34 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2013 18:14:06 GMT"}], "update_date": "2014-06-02", "authors_parsed": [["Rosenbaum", "Robert", ""], ["Doiron", "Brent", ""]]}, {"id": "1308.6140", "submitter": "Fumito Mori", "authors": "Fumito Mori and Hiroshi Kori", "title": "Inference Methods for Interaction and Noise Intensities Using Only\n  Spike-time Data on Coupled Oscillators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose theoretical methods to infer coupling strength and noise intensity\nsimultaneously through an observation of spike timing in two well-synchronized\nnoisy oscillators. A phase oscillator model is applied to derive formulae\nrelating each of the parameters to some statistics from spike-time data. Using\nthese formulae, each parameter is inferred from a specific set of statistics.\nWe demonstrate the methods with the FitzHugh-Nagumo model as well as the phase\nmodel. Our methods do not require any external perturbation and thus are ready\nfor application to various experimental systems.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2013 12:17:58 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 09:42:23 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Mori", "Fumito", ""], ["Kori", "Hiroshi", ""]]}, {"id": "1308.6636", "submitter": "Roman Beletskiy", "authors": "Roman V. Beletskiy", "title": "Imaging electrical activity of neurons with metamaterial nanosensors", "comments": "10 pages Research Proposal Supplementary Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph cond-mat.mtrl-sci physics.optics q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A technology for recording electrical activity of large neuron populations at\narbitrary depth in brain tissues with less than cell spatial and millisecond\ntemporal resolutions was the most craving dream of neuroscientists and a long\npursued goal of engineers for decades. Even though many imaging techniques have\nbeen devised up to date, none of them is capable to deliver either\nquantitatively valid data nor able to meet contradictory requirements posed for\nsensors to be safe, non-invasive and reliably working either within cultured\ncell populations or during chronic implantations in vivo. In my research\nproject, I design and justify a novel nanobiosensors, capable to detect and\noptically report the electric fields across cellular membrane and investigate\nproperties of that specially engineered plasmonic nanoantennas. In the\nfollowing literature survey, I observe the current state of electrophysiology\nmethods and after recalling the basics of fluorescence, discuss benefits and\ndrawbacks of today's voltage sensitive labelling and electric fields imaging\nmethods. This review is wrapped up by a brief outlook of prospective\napplications of this technology.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 02:11:22 GMT"}], "update_date": "2013-09-02", "authors_parsed": [["Beletskiy", "Roman V.", ""]]}, {"id": "1308.6661", "submitter": "Paolo Moretti", "authors": "Paolo Moretti, Miguel A. Mu\\~noz", "title": "Griffiths phases and the stretching of criticality in brain networks", "comments": "Final version. A misprint in Equation (2) was corrected.\n  Supplementary Information included", "journal-ref": "Nature Communications 4, 2521 (2013)", "doi": "10.1038/ncomms3521", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hallmarks of criticality, such as power-laws and scale invariance, have been\nempirically found in cortical networks and it has been conjectured that\noperating at criticality entails functional advantages, such as optimal\ncomputational capabilities, memory, and large dynamical ranges. As critical\nbehavior requires a high degree of fine tuning to emerge, some type of\nself-tuning mechanism needs to be invoked. Here we show that, taking into\naccount the complex hierarchical-modular architecture of cortical networks, the\nsingular critical point is replaced by an extended critical-like region which\ncorresponds --in the jargon of statistical mechanics-- to a Griffiths phase.\nUsing computational and analytical approaches, we find Griffiths phases in\nsynthetic hierarchical networks and also in empirical brain networks such as\nthe human connectome and the caenorhabditis elegans one. Stretched critical\nregions, stemming from structural disorder, yield enhanced functionality in a\ngeneric way, facilitating the task of self-organizing, adaptive, and\nevolutionary mechanisms selecting for criticality.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2013 07:10:53 GMT"}, {"version": "v2", "created": "Wed, 12 Nov 2014 18:57:54 GMT"}], "update_date": "2014-11-13", "authors_parsed": [["Moretti", "Paolo", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}]