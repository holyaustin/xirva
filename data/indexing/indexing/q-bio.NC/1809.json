[{"id": "1809.00358", "submitter": "Taposh Banerjee", "authors": "Taposh Banerjee, Stephen Allsop, Kay M. Tye, Demba Ba and Vahid Tarokh", "title": "Sequential Detection of Regime Changes in Neural Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting changes in firing patterns in neural data is\nstudied. The problem is formulated as a quickest change detection problem.\nImportant algorithms from the literature are reviewed. A new algorithmic\ntechnique is discussed to detect deviations from learned baseline behavior. The\nalgorithms studied can be applied to both spike and local field potential data.\nThe algorithms are applied to mice spike data to verify the presence of\nbehavioral learning.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 15:31:14 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Banerjee", "Taposh", ""], ["Allsop", "Stephen", ""], ["Tye", "Kay M.", ""], ["Ba", "Demba", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1809.00395", "submitter": "Alborz Rezazadeh Sereshkeh", "authors": "Alborz Rezazadeh Sereshkeh, Rozhin Yousefi, Andrew T Wong, Tom Chau", "title": "Online classification of imagined speech using functional near-infrared\n  spectroscopy signals", "comments": null, "journal-ref": null, "doi": "10.1088/1741-2552/aae4b9", "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most brain-computer interfaces (BCIs) based on functional near-infrared\nspectroscopy (fNIRS) require that users perform mental tasks such as motor\nimagery, mental arithmetic, or music imagery to convey a message or to answer\nsimple yes or no questions. These cognitive tasks usually have no direct\nassociation with the communicative intent, which makes them difficult for users\nto perform. In this paper, a 3-class intuitive BCI is presented which enables\nusers to directly answer yes or no questions by covertly rehearsing the word\n'yes' or 'no' for 15 s. The BCI also admits an equivalent duration of\nunconstrained rest which constitutes the third discernable task. Twelve\nparticipants each completed one offline block and six online blocks over the\ncourse of 2 sessions. The mean value of the change in oxygenated hemoglobin\nconcentration during a trial was calculated for each channel and used to train\na regularized linear discriminant analysis (RLDA) classifier. By the final\nonline block, 9 out of 12 participants were performing above chance (p<0.001),\nwith a 3-class accuracy of 83.8+9.4%. Even when considering all participants,\nthe average online 3-class accuracy over the last 3 blocks was 64.1+20.6%, with\nonly 3 participants scoring below chance (p<0.001). For most participants,\nchannels in the left temporal and temporoparietal cortex provided the most\ndiscriminative information. To our knowledge, this is the first report of an\nonline fNIRS 3-class imagined speech BCI. Our findings suggest that imagined\nspeech can be used as a reliable activation task for selected users for the\ndevelopment of more intuitive BCIs for communication.\n", "versions": [{"version": "v1", "created": "Sun, 2 Sep 2018 21:27:19 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Sereshkeh", "Alborz Rezazadeh", ""], ["Yousefi", "Rozhin", ""], ["Wong", "Andrew T", ""], ["Chau", "Tom", ""]]}, {"id": "1809.00607", "submitter": "Federico Devalle", "authors": "Federico Devalle, Ernest Montbri\\'o, Diego Paz\\'o", "title": "Dynamics of a large system of spiking neurons with synaptic delay", "comments": null, "journal-ref": "Phys. Rev. E 98, 042214 (2018)", "doi": "10.1103/PhysRevE.98.042214", "report-no": null, "categories": "nlin.AO nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a large system of heterogeneous quadratic integrate-and-fire (QIF)\nneurons with time delayed, all-to-all synaptic coupling. The model is exactly\nreduced to a system of firing rate equations that is exploited to investigate\nthe existence, stability and bifurcations of fully synchronous, partially\nsynchronous, and incoherent states. In conjunction with this analysis we\nperform extensive numerical simulations of the original network of QIF neurons,\nand determine the relation between the macroscopic and microscopic states for\npartially synchronous states. The results are summarized in two phase diagrams,\nfor homogeneous and heterogeneous populations, which are obtained analytically\nto a large extent. For excitatory coupling, the phase diagram is remarkably\nsimilar to that of the Kuramoto model with time delays, although here the\nstability boundaries extend to regions in parameter space where the neurons are\nnot self-sustained oscillators. In contrast, the structure of the boundaries\nfor inhibitory coupling is different, and already for homogeneous networks\nunveils the presence of various partially synchronized states not present in\nthe Kuramoto model: Collective chaos, quasiperiodic partial synchronization\n(QPS), and a novel state which we call modulated-QPS (M-QPS). In the presence\nof heterogeneity partially synchronized states reminiscent to collective chaos,\nQPS and M-QPS persist. In addition, the presence of heterogeneity greatly\namplifies the differences between the incoherence stability boundaries of\nexcitation and inhibition. Finally, we compare our results with those of a\ntraditional (Wilson Cowan-type) firing rate model with time delays. The\noscillatory instabilities of the traditional firing rate model qualitatively\nagree with our results only for the case of inhibitory coupling with strong\nheterogeneity.\n", "versions": [{"version": "v1", "created": "Mon, 3 Sep 2018 14:05:23 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 10:50:58 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Devalle", "Federico", ""], ["Montbri\u00f3", "Ernest", ""], ["Paz\u00f3", "Diego", ""]]}, {"id": "1809.00895", "submitter": "Marta Diaz Ms", "authors": "Marta Diaz-delCastillo, Soren H. Christiansen, Camilla K. Appel, Sarah\n  Falka, David P. D. Woldbye and Anne-Marie Heegaarda", "title": "Neuropeptide Y is up-regulated and induces antinociception in\n  cancer-induced bone pain", "comments": "23 pages, 4 figures", "journal-ref": "Neuroscience. 2018 Aug 1;384:111-119. Epub 2018 May 29. PMID:\n  29852245", "doi": "10.1016/j.neuroscience.2018.05.025", "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pain remains a major concern in patients suffering from metastatic cancer to\nthe bone and more knowledge of the condition, as well as novel treatment\navenues, are called for. Neuropeptide Y (NPY) is a highly conserved peptide\nthat appears to play a central role in nociceptive signaling in inflammatory\nand neuropathic pain. However, little is known about the peptide in\ncancer-induced bone pain. Here, we evaluate the role of spinal NPY in the\nMRMT-1 rat model of cancer-induced bone pain. Our studies revealed an\nup-regulation of NPY-immunoreactivity in the dorsal horn of cancer-bearing rats\n17 days after inoculation, which could be a compensatory antinociceptive\nresponse. Consistent with this interpretation, intrathecal administration of\nNPY to rats with cancer-induced bone pain caused a reduction in nociceptive\nbehaviors that lasted up to 150 min. This effect was diminished by both Y1\n(BIBO3304) and Y2 (BIIE0246) receptor antagonists, indicating that both\nreceptors participate in mediating the antinociceptive effect of NPY. Y1 and Y2\nreceptor binding in the spinal cord was unchanged in the cancer state as\ncompared to sham-operated rats, consistent with the notion that increased NPY\nresults in a net antinociceptive effect in the MRMT-1 model. In conclusion, the\ndata indicate that NPY is involved in the spinal nociceptive signaling of\ncancer-induced bone pain and could be a new therapeutic target for patients\nwith this condition.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 11:28:34 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Diaz-delCastillo", "Marta", ""], ["Christiansen", "Soren H.", ""], ["Appel", "Camilla K.", ""], ["Falka", "Sarah", ""], ["Woldbye", "David P. D.", ""], ["Heegaarda", "Anne-Marie", ""]]}, {"id": "1809.01020", "submitter": "Kelly Iarosz", "authors": "Fernando Borges, Paulo Protachevicz, Rodrigo Pena, Ewandson Lameu,\n  Guilherme Higa, Fernanda Matias, Alexandre Kihara, Chris Antonopoulos,\n  Roberto de Pasquale, Antonio Roque, Kelly Iarosz, Peng Ji, Antonio Batista", "title": "Self-sustained activity of low firing rate in balanced networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-sustained activity in the brain is observed in the absence of external\nstimuli and contributes to signal propagation, neural coding, and dynamic\nstability. It also plays an important role in cognitive processes. In this\nwork, by means of studying intracellular recordings from CA1 neurons in rats\nand results from numerical simulations, we demonstrate that self-sustained\nactivity presents high variability of patterns, such as low neural firing rates\nand activity in the form of small-bursts in distinct neurons. In our numerical\nsimulations, we consider random networks composed of coupled, adaptive\nexponential integrate-and-fire neurons. The neural dynamics in the random\nnetworks simulate regular spiking (excitatory) and fast-spiking (inhibitory)\nneurons. We show that both the connection probability and network size are\nfundamental properties that give rise to self-sustained activity in qualitative\nagreement with our experimental results. Finally, we provide a more detailed\ndescription of the self-sustained activity in terms of lifetime distributions,\nsynaptic conductances, and synaptic currents.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 14:25:17 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 20:46:20 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 19:26:48 GMT"}], "update_date": "2019-10-01", "authors_parsed": [["Borges", "Fernando", ""], ["Protachevicz", "Paulo", ""], ["Pena", "Rodrigo", ""], ["Lameu", "Ewandson", ""], ["Higa", "Guilherme", ""], ["Matias", "Fernanda", ""], ["Kihara", "Alexandre", ""], ["Antonopoulos", "Chris", ""], ["de Pasquale", "Roberto", ""], ["Roque", "Antonio", ""], ["Iarosz", "Kelly", ""], ["Ji", "Peng", ""], ["Batista", "Antonio", ""]]}, {"id": "1809.01051", "submitter": "Matthias Hennig", "authors": "Matthias H. Hennig, Cole Hurwitz and Martino Sorbaro", "title": "Scaling Spike Detection and Sorting for Next Generation\n  Electrophysiology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable spike detection and sorting, the process of assigning each detected\nspike to its originating neuron, is an essential step in the analysis of\nextracellular electrical recordings from neurons. The volume and complexity of\nthe data from recently developed large scale, high density microelectrode\narrays and probes, which allow recording from thousands of channels\nsimultaneously, substantially complicate this task conceptually and\ncomputationally. This chapter provides a summary and discussion of recently\ndeveloped methods to tackle these challenges, and discuss the important aspect\nof algorithm validation, and assessment of detection and sorting quality.\n", "versions": [{"version": "v1", "created": "Tue, 4 Sep 2018 15:42:00 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Hennig", "Matthias H.", ""], ["Hurwitz", "Cole", ""], ["Sorbaro", "Martino", ""]]}, {"id": "1809.01281", "submitter": "Nadine Chang", "authors": "Nadine Chang, John A. Pyles, Abhinav Gupta, Michael J. Tarr, Elissa M.\n  Aminoff", "title": "BOLD5000: A public fMRI dataset of 5000 images", "comments": "Currently in submission to Scientific Data", "journal-ref": null, "doi": "10.1038/s41597-019-0052-3", "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Vision science, particularly machine vision, has been revolutionized by\nintroducing large-scale image datasets and statistical learning approaches.\nYet, human neuroimaging studies of visual perception still rely on small\nnumbers of images (around 100) due to time-constrained experimental procedures.\nTo apply statistical learning approaches that integrate neuroscience, the\nnumber of images used in neuroimaging must be significantly increased. We\npresent BOLD5000, a human functional MRI (fMRI) study that includes almost\n5,000 distinct images depicting real-world scenes. Beyond dramatically\nincreasing image dataset size relative to prior fMRI studies, BOLD5000 also\naccounts for image diversity, overlapping with standard computer vision\ndatasets by incorporating images from the Scene UNderstanding (SUN), Common\nObjects in Context (COCO), and ImageNet datasets. The scale and diversity of\nthese image datasets, combined with a slow event-related fMRI design, enable\nfine-grained exploration into the neural representation of a wide range of\nvisual features, categories, and semantics. Concurrently, BOLD5000 brings us\ncloser to realizing Marr's dream of a singular vision science - the intertwined\nstudy of biological and computer vision.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 00:50:34 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Chang", "Nadine", ""], ["Pyles", "John A.", ""], ["Gupta", "Abhinav", ""], ["Tarr", "Michael J.", ""], ["Aminoff", "Elissa M.", ""]]}, {"id": "1809.01524", "submitter": "Christopher Bates", "authors": "Christopher J. Bates and Ilker Yildirim and Joshua B. Tenenbaum and\n  Peter Battaglia", "title": "Modeling human intuitions about liquid flow with particle-based\n  simulation", "comments": "Under review at PLOS Computational Biology", "journal-ref": null, "doi": "10.1371/journal.pcbi.1007210", "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can easily describe, imagine, and, crucially, predict a wide variety\nof behaviors of liquids--splashing, squirting, gushing, sloshing, soaking,\ndripping, draining, trickling, pooling, and pouring--despite tremendous\nvariability in their material and dynamical properties. Here we propose and\ntest a computational model of how people perceive and predict these liquid\ndynamics, based on coarse approximate simulations of fluids as collections of\ninteracting particles. Our model is analogous to a \"game engine in the head\",\ndrawing on techniques for interactive simulations (as in video games) that\noptimize for efficiency and natural appearance rather than physical accuracy.\nIn two behavioral experiments, we found that the model accurately captured\npeople's predictions about how liquids flow among complex solid obstacles, and\nwas significantly better than two alternatives based on simple heuristics and\ndeep neural networks. Our model was also able to explain how people's\npredictions varied as a function of the liquids' properties (e.g., viscosity\nand stickiness). Together, the model and empirical results extend the recent\nproposal that human physical scene understanding for the dynamics of rigid,\nsolid objects can be supported by approximate probabilistic simulation, to the\nmore complex and unexplored domain of fluid dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 14:03:32 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Bates", "Christopher J.", ""], ["Yildirim", "Ilker", ""], ["Tenenbaum", "Joshua B.", ""], ["Battaglia", "Peter", ""]]}, {"id": "1809.01646", "submitter": "Uwe C. T\\\"auber", "authors": "Jacob Carroll, Ada Warren, and Uwe C. T\\\"auber (Virginia Tech)", "title": "The effects of inhibitory and excitatory neurons on the dynamics and\n  control of avalanching neural networks", "comments": "14 pages, 10 figures", "journal-ref": "Phys. Rev. E 99, 052407 (2019)", "doi": "10.1103/PhysRevE.99.052407", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The statistical analysis of the collective neural activity known as\navalanches provides insight into the proper behavior of brains across many\nspecies. We consider a neural network model based on the work of Lombardi,\nHerrmann, De Arcangelis et al. that captures the relevant dynamics of neural\navalanches, and we show how tuning the fraction of inhibitory neurons in this\nmodel alters the connectivity of the network over time, removes exponential\ncut-offs present in the distributions of avalanche strength and duration, and\ntransitions the power spectral density of the network into an `epileptic'\nregime. We propose that the brain operates away from this power law regime of\nlow inhibitory fraction to protect itself from the dominating avalanches\npresent in these extended distributions. We present control strategies that\ncurtail these power law distributions through either random or, more\neffectively, targeted disabling of excitatory neurons.\n", "versions": [{"version": "v1", "created": "Wed, 5 Sep 2018 17:49:19 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 21:19:28 GMT"}], "update_date": "2019-05-22", "authors_parsed": [["Carroll", "Jacob", "", "Virginia Tech"], ["Warren", "Ada", "", "Virginia Tech"], ["T\u00e4uber", "Uwe C.", "", "Virginia Tech"]]}, {"id": "1809.01851", "submitter": "Richa Phogat", "authors": "Richa Phogat and P. Parmananda", "title": "Provoking Predetermined Aperiodic Patterns in Human Brainwaves", "comments": "This is the final manuscript after peer review. 8 pages and 10\n  figures in main text, 3 pages and 6 figures in supplementary text, all\n  combined in a single pdf document", "journal-ref": "Chaos 28, 121105 (2018)", "doi": "10.1063/1.5080971", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work, electroencephalographic recordings of healthy human\nparticipants were performed to study the entrainment of brainwaves using a\nvariety of stimulus. First, periodic entrainment of the brainwaves was studied\nusing two different stimuli in the form of periodic auditory and visual\nsignals. The entrainment with the periodic visual stimulation was consistently\nobserved, whereas the auditory entrainment was inconclusive. Hence, a photic\n(Visual) stimulus, where two frequencies were presented to the subject\nsimultaneously was used to further explore the bifrequency entrainment of human\nbrainwaves. Subsequently, the evolution of brainwaves as a result of an\naperiodic stimulation was explored, wherein an entrainment to the predetermined\naperiodic pattern was observed. These results suggest that aperiodic\nentrainment could be used as a tool for guided modification of brainwaves. This\ncould find possible applications in processes such as epilepsy suppression and\nbiofeedback.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 07:26:06 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 09:32:57 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Phogat", "Richa", ""], ["Parmananda", "P.", ""]]}, {"id": "1809.01926", "submitter": "Alessio Burrello", "authors": "Alessio Burrello, Kaspar Schindler, Luca Benini, Abbas Rahimi", "title": "One-shot Learning for iEEG Seizure Detection Using End-to-end Binary\n  Operations: Local Binary Patterns with Hyperdimensional Computing", "comments": "Published as a conference paper at the IEEE BioCAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an efficient binarized algorithm for both learning and\nclassification of human epileptic seizures from intracranial\nelectroencephalography (iEEG). The algorithm combines local binary patterns\nwith brain-inspired hyperdimensional computing to enable end-to-end learning\nand inference with binary operations. The algorithm first transforms iEEG time\nseries from each electrode into local binary pattern codes. Then atomic\nhigh-dimensional binary vectors are used to construct composite representations\nof seizures across all electrodes. For the majority of our patients (10 out of\n16), the algorithm quickly learns from one or two seizures (i.e., one-/few-shot\nlearning) and perfectly generalizes on 27 further seizures. For other patients,\nthe algorithm requires three to six seizures for learning. Overall, our\nalgorithm surpasses the state-of-the-art methods for detecting 65 novel\nseizures with higher specificity and sensitivity, and lower memory footprint.\n", "versions": [{"version": "v1", "created": "Thu, 6 Sep 2018 11:39:12 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Burrello", "Alessio", ""], ["Schindler", "Kaspar", ""], ["Benini", "Luca", ""], ["Rahimi", "Abbas", ""]]}, {"id": "1809.02386", "submitter": "Francesca Mastrogiuseppe", "authors": "Francesca Mastrogiuseppe and Srdjan Ostojic", "title": "A geometrical analysis of global stability in trained feedback networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have been extensively studied in the context of\nneuroscience and machine learning due to their ability to implement complex\ncomputations. While substantial progress in designing effective learning\nalgorithms has been achieved in the last years, a full understanding of trained\nrecurrent networks is still lacking. Specifically, the mechanisms that allow\ncomputations to emerge from the underlying recurrent dynamics are largely\nunknown. Here we focus on a simple, yet underexplored computational setup: a\nfeedback architecture trained to associate a stationary output to a stationary\ninput. As a starting point, we derive an approximate analytical description of\nglobal dynamics in trained networks which assumes uncorrelated connectivity\nweights in the feedback and in the random bulk. The resulting mean-field theory\nsuggests that the task admits several classes of solutions, which imply\ndifferent stability properties. Different classes are characterized in terms of\nthe geometrical arrangement of the readout with respect to the input vectors,\ndefined in the high-dimensional space spanned by the network population. We\nfind that such approximate theoretical approach can be used to understand how\nstandard training techniques implement the input-output task in finite-size\nfeedback networks. In particular, our simplified description captures the local\nand the global stability properties of the target solution, and thus predicts\ntraining performance.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 10:08:01 GMT"}, {"version": "v2", "created": "Fri, 18 Jan 2019 14:11:56 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Mastrogiuseppe", "Francesca", ""], ["Ostojic", "Srdjan", ""]]}, {"id": "1809.02440", "submitter": "Hugo Richard", "authors": "Hugo Richard (PARIETAL), Ana Pinho (NEUROSPIN), Bertrand Thirion\n  (PARIETAL), Guillaume Charpiat (TAU)", "title": "Optimizing deep video representation to match brain activity", "comments": null, "journal-ref": "2018 Conference on Cognitive Computational Neuroscience, Sep 2018,\n  Philadelphia, United States", "doi": null, "report-no": null, "categories": "cs.NE cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The comparison of observed brain activity with the statistics generated by\nartificial intelligence systems is useful to probe brain functional\norganization under ecological conditions. Here we study fMRI activity in ten\nsubjects watching color natural movies and compute deep representations of\nthese movies with an architecture that relies on optical flow and image\ncontent. The association of activity in visual areas with the different layers\nof the deep architecture displays complexity-related contrasts across visual\nareas and reveals a striking foveal/peripheral dichotomy.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 12:37:50 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Richard", "Hugo", "", "PARIETAL"], ["Pinho", "Ana", "", "NEUROSPIN"], ["Thirion", "Bertrand", "", "PARIETAL"], ["Charpiat", "Guillaume", "", "TAU"]]}, {"id": "1809.02511", "submitter": "\\'Aine Byrne", "authors": "\\'Aine Byrne, Daniele Avitabile, Stephen Coombes", "title": "A next generation neural field model: The evolution of synchrony within\n  patterns and waves", "comments": null, "journal-ref": "Phys. Rev. E 99, 012313 (2019)", "doi": "10.1103/PhysRevE.99.012313", "report-no": null, "categories": "q-bio.NC math.DS nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural field models are commonly used to describe wave propagation and bump\nattractors at a tissue level in the brain. Although motivated by biology, these\nmodels are phenomenological in nature. They are built on the assumption that\nthe neural tissue operates in a near synchronous regime, and hence, cannot\naccount for changes in the underlying synchrony of patterns. It is customary to\nuse spiking neural network models when examining within population\nsynchronisation. Unfortunately, these high dimensional models are notoriously\nhard to obtain insight from. In this paper, we consider a network of\n$\\theta$-neurons, which has recently been shown to admit an exact mean-field\ndescription in the absence of a spatial component. We show that the inclusion\nof space and a realistic synapse model leads to a reduced model that has many\nof the features of a standard neural field model coupled to a further dynamical\nequation that describes the evolution of network synchrony. Both Turing\ninstability analysis and numerical continuation software are used to explore\nthe existence and stability of spatio-temporal patterns in the system. In\nparticular, we show that this new model can support states above and beyond\nthose seen in a standard neural field model. These states are typified by\nstructures within bumps and waves showing the dynamic evolution of population\nsynchrony.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 14:39:34 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Byrne", "\u00c1ine", ""], ["Avitabile", "Daniele", ""], ["Coombes", "Stephen", ""]]}, {"id": "1809.02572", "submitter": "Jeffrey Shainline", "authors": "Jeffrey M. Shainline", "title": "The largest cognitive systems will be optoelectronic", "comments": "10 pages, 5 figures, ICRC 2018 conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.NE physics.app-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrons and photons offer complementary strengths for information\nprocessing. Photons are excellent for communication, while electrons are\nsuperior for computation and memory. Cognition requires distributed computation\nto be communicated across the system for information integration. We present\nreasoning from neuroscience, network theory, and device physics supporting the\nconjecture that large-scale cognitive systems will benefit from electronic\ndevices performing synaptic, dendritic, and neuronal information processing\noperating in conjunction with photonic communication. On the chip scale,\nintegrated dielectric waveguides enable fan-out to thousands of connections. On\nthe system scale, fiber and free-space optics can be employed. The largest\ncognitive systems will be limited by the distance light can travel during the\nperiod of a network oscillation. We calculate that optoelectronic networks the\narea of a large data center ($10^5$\\,m$^2$) will be capable of system-wide\ninformation integration at $1$\\,MHz. At frequencies of cortex-wide integration\nin the human brain ($4$\\,Hz, theta band), optoelectronic systems could\nintegrate information across the surface of the earth.\n", "versions": [{"version": "v1", "created": "Fri, 7 Sep 2018 16:45:38 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Shainline", "Jeffrey M.", ""]]}, {"id": "1809.02849", "submitter": "Eli Cornblath", "authors": "Eli J. Cornblath, Arian Ashourvan, Jason Z. Kim, Richard F. Betzel,\n  Rastko Ciric, Azeez Adebimpe, Graham L. Baum, Xiaosong He, Kosha Ruparel,\n  Tyler M. Moore, Ruben C. Gur, Raquel E. Gur, Russell T. Shinohara, David R.\n  Roalf, Theodore D. Satterthwaite, and Danielle S. Bassett", "title": "Temporal sequences of brain activity at rest are constrained by white\n  matter structure and modulated by cognitive demands", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A diverse white matter network and finely tuned neuronal membrane properties\nallow the brain to transition seamlessly between cognitive states. However, it\nremains unclear how static structural connections guide the temporal\nprogression of large-scale brain activity patterns in different cognitive\nstates. Here, we analyze the brain's trajectories through a high-dimensional\nactivity space at the level of single time point activity patterns from\nfunctional magnetic resonance imaging data acquired during passive visual\nfixation (rest) and an n-back working memory task. We find that specific state\nspace trajectories, which represent temporal sequences of brain activity, are\nmodulated by cognitive load and related to task performance. Using\ndiffusion-weighted imaging acquired from the same subjects, we use tools from\nnetwork control theory to show that linear spread of activity along white\nmatter connections constrains the brain's state space trajectories at rest.\nAdditionally, accounting for stimulus-driven visual inputs explains the\ndifferent trajectories taken during the n-back task. We also used models of\nnetwork rewiring to show that these findings are the result of non-trivial\ngeometric and topological properties of white matter architecture. Finally, we\nexamine associations between age and time-resolved brain state dynamics,\nrevealing new insights into functional changes in the default mode and\nexecutive control networks. Overall, these results elucidate the structural\nunderpinnings of cognitively and developmentally relevant spatiotemporal brain\ndynamics.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 18:14:29 GMT"}, {"version": "v2", "created": "Mon, 30 Sep 2019 23:14:02 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Cornblath", "Eli J.", ""], ["Ashourvan", "Arian", ""], ["Kim", "Jason Z.", ""], ["Betzel", "Richard F.", ""], ["Ciric", "Rastko", ""], ["Adebimpe", "Azeez", ""], ["Baum", "Graham L.", ""], ["He", "Xiaosong", ""], ["Ruparel", "Kosha", ""], ["Moore", "Tyler M.", ""], ["Gur", "Ruben C.", ""], ["Gur", "Raquel E.", ""], ["Shinohara", "Russell T.", ""], ["Roalf", "David R.", ""], ["Satterthwaite", "Theodore D.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1809.02910", "submitter": "Tsang-Kai Chang", "authors": "Tsang-Kai Chang, Shengkang Chen, and Ankur Mehta", "title": "Localization Algorithm with Circular Representation in 2D and its\n  Similarity to Mammalian Brains", "comments": "8 pages, 2 figures, submitted to the IEEE Robotics and Automation\n  Letters (RA-L) journal with the option for presentation at RSS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extended Kalman filter (EKF) does not guarantee consistent mean and\ncovariance under linearization, even though it is the main framework for\nrobotic localization. While Lie group improves the modeling of the state space\nin localization, the EKF on Lie group still relies on the arbitrary Gaussian\nassumption in face of nonlinear models. We instead use von Mises filter for\norientation estimation together with the conventional Kalman filter for\nposition estimation, and thus we are able to characterize the first two moments\nof the state estimates. Since the proposed algorithm holds a solid\nprobabilistic basis, it is fundamentally relieved from the inconsistency\nproblem. Furthermore, we extend the localization algorithm to fully circular\nrepresentation even for position, which is similar to grid patterns found in\nmammalian brains and in recurrent neural networks. The applicability of the\nproposed algorithms is substantiated not only by strong mathematical foundation\nbut also by the comparison against other common localization methods.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 01:54:21 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 03:56:57 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Chang", "Tsang-Kai", ""], ["Chen", "Shengkang", ""], ["Mehta", "Ankur", ""]]}, {"id": "1809.03142", "submitter": "Seongsik Park", "authors": "Seongsik Park, Seijoon Kim, Hyeokjun Choe, Sungroh Yoon", "title": "Fast and Efficient Information Transmission with Burst Spikes in Deep\n  Spiking Neural Networks", "comments": "Accepted to DAC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spiking neural networks (SNNs) are considered as one of the most\npromising artificial neural networks due to their energy efficient computing\ncapability. Recently, conversion of a trained deep neural network to an SNN has\nimproved the accuracy of deep SNNs. However, most of the previous studies have\nnot achieved satisfactory results in terms of inference speed and energy\nefficiency. In this paper, we propose a fast and energy-efficient information\ntransmission method with burst spikes and hybrid neural coding scheme in deep\nSNNs. Our experimental results showed the proposed methods can improve\ninference energy efficiency and shorten the latency.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 05:42:18 GMT"}, {"version": "v2", "created": "Sun, 10 Feb 2019 12:16:19 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Park", "Seongsik", ""], ["Kim", "Seijoon", ""], ["Choe", "Hyeokjun", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1809.03300", "submitter": "Giulia Cisotto", "authors": "Giulia Cisotto, Anna V. Guglielmi, Leonardo Badia, Andrea Zanella", "title": "Classification of grasping tasks based on EEG-EMG coherence", "comments": null, "journal-ref": "2018 IEEE 20th International Conference on e-Health Networking,\n  Applications and Services (Healthcom)", "doi": "10.1109/HealthCom.2018.8531140", "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an innovative application of the well-known concept of\ncortico-muscular coherence for the classification of various motor tasks, i.e.,\ngrasps of different kinds of objects. Our approach can classify objects with\ndifferent weights (motor-related features) and different surface frictions\n(haptics-related features) with high accuracy (over 0:8). The outcomes\npresented here provide information about the synchronization existing between\nthe brain and the muscles during specific activities; thus, this may represent\na new effective way to perform activity recognition.\n", "versions": [{"version": "v1", "created": "Mon, 10 Sep 2018 13:34:10 GMT"}], "update_date": "2020-09-01", "authors_parsed": [["Cisotto", "Giulia", ""], ["Guglielmi", "Anna V.", ""], ["Badia", "Leonardo", ""], ["Zanella", "Andrea", ""]]}, {"id": "1809.03490", "submitter": "Christoph Simon", "authors": "Christoph Simon", "title": "Can quantum physics help solve the hard problem of consciousness? A\n  hypothesis based on entangled spins and photons", "comments": "12 pages, ca. 5000 words", "journal-ref": "Journal of Consciousness Studies 26, 204 (2019)", "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hard problem of consciousness is the question how subjective experience\narises from brain matter. I suggest exploring the possibility that quantum\nphysics could be part of the answer. The simultaneous unity and complexity of\nsubjective experience is difficult to understand from a classical physics\nperspective. In contrast, quantum entanglement is naturally both complex and\nunified. Moreover the concept of matter is much more subtle in quantum physics\ncompared to classical physics, and quantum computing shows that quantum effects\ncan be useful for information processing. Building on recent progress in\nquantum technology and neuroscience, I propose a concrete hypothesis as a basis\nfor further investigation, namely that subjective experience is related to the\ndynamics of a complex entangled state of spins, which is continuously generated\nand updated through the exchange of photons. Spins in condensed matter systems\nat room or body temperature can have coherence times in the relevant range for\nsubjective experience (milliseconds to seconds). Photons are well suited for\ndistributing entanglement over macroscopic distances. Neurons emit photons,\nreactive oxygen species in the mitochondria being likely sources. Opsins,\nlight-sensitive proteins that are plausible single-photon detectors, exist in\nthe brain and are evolutionarily conserved, suggesting that they serve a\nfunction. We have recently shown by detailed numerical modeling that axons can\nplausibly act as photonic waveguides. The oxygen molecule, which has non-zero\nelectronic spin and emits photons, might serve as an interface between photons\nand spins. The achievable photon rates seem to be more than sufficient to\nsupport the bandwidth of subjective experience. The proposed hypothesis raises\nmany interesting experimental and theoretical questions in neuroscience,\nquantum physics, evolutionary biology, psychophysics, and philosophy.\n", "versions": [{"version": "v1", "created": "Sat, 8 Sep 2018 20:04:22 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Simon", "Christoph", ""]]}, {"id": "1809.03878", "submitter": "Moo K. Chung", "authors": "Moo K. Chung, Hyekyoung Lee, Andrey Gritsenko, Alex DiChristofano,\n  Dustin Pluta, Hernando Ombao, Victor Solo", "title": "Topological Brain Network Distances", "comments": "arXiv admin note: text overlap with arXiv:1701.04171", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing brain network distances are often based on matrix norms. The\nelement-wise differences in the existing matrix norms may fail to capture\nunderlying topological differences. Further, matrix norms are sensitive to\noutliers. A major disadvantage to element-wise distance calculations is that it\ncould be severely affected even by a small number of extreme edge weights. Thus\nit is necessary to develop network distances that recognize topology. In this\npaper, we provide a survey of bottleneck, Gromov-Hausdorff (GH) and\nKolmogorov-Smirnov (KS) distances that are adapted for brain networks, and\ncompare them against matrix-norm based network distances. Bottleneck and\nGH-distances are often used in persistent homology. However, they were rarely\nutilized to measure similarity between brain networks. KS-distance is recently\nintroduced to measure the similarity between networks across different\nfiltration values. The performance analysis was conducted using the random\nnetwork simulations with the ground truths. Using a twin imaging study, which\nprovides biological ground truth, we demonstrate that the KS distance has the\nability to determine heritability.\n", "versions": [{"version": "v1", "created": "Sun, 9 Sep 2018 10:47:58 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Chung", "Moo K.", ""], ["Lee", "Hyekyoung", ""], ["Gritsenko", "Andrey", ""], ["DiChristofano", "Alex", ""], ["Pluta", "Dustin", ""], ["Ombao", "Hernando", ""], ["Solo", "Victor", ""]]}, {"id": "1809.03930", "submitter": "Tomasz Piotrowski", "authors": "Tomasz Piotrowski and Jan Nikadon", "title": "Localization of Brain Activity from EEG/MEG Using MV-PURE Framework", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of localization of sources of brain electrical\nactivity from electroencephalographic (EEG) and magnetoencephalographic (MEG)\nmeasurements using spatial filtering techniques. We propose novel reduced-rank\nactivity indices based on the minimum-variance pseudo-unbiased reduced-rank\nestimation (MV-PURE) framework. The main results of this paper establish the\nkey unbiasedness property of the proposed indices and their higher spatial\nresolution compared with full-rank indices in challenging task of localizing\nclosely positioned and possibly highly correlated sources, especially in low\nsignal-to-noise regime. A numerical example is provided to illustrate the\npractical applicability of the proposed activity indices. Simulations presented\nin this paper use open-source EEG/MEG spatial filtering framework freely\navailable at https://github.com/IS-UMK/supFunSim.git.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 14:32:43 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Piotrowski", "Tomasz", ""], ["Nikadon", "Jan", ""]]}, {"id": "1809.03934", "submitter": "Pranav Reddy", "authors": "Pranav G. Reddy, Richard F. Betzel, Ankit N. Khambhati, Preya Shah,\n  Lohith Kini, Brian Litt, Thomas H. Lucas, Kathryn A. Davis, Danielle S.\n  Bassett", "title": "Genetic and Neuroanatomical Support for Functional Brain Network\n  Dynamics in Epilepsy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Focal epilepsy is a devastating neurological disorder that affects an\noverwhelming number of patients worldwide, many of whom prove resistant to\nmedication. The efficacy of current innovative technologies for the treatment\nof these patients has been stalled by the lack of accurate and effective\nmethods to fuse multimodal neuroimaging data to map anatomical targets driving\nseizure dynamics. Here we propose a parsimonious model that explains how\nlarge-scale anatomical networks and shared genetic constraints shape\ninter-regional communication in focal epilepsy. In extensive ECoG recordings\nacquired from a group of patients with medically refractory focal-onset\nepilepsy, we find that ictal and preictal functional brain network dynamics can\nbe accurately predicted from features of brain anatomy and geometry, patterns\nof white matter connectivity, and constraints complicit in patterns of gene\ncoexpression, all of which are conserved across healthy adult populations.\nMoreover, we uncover evidence that markers of non-conserved architecture,\npotentially driven by idiosyncratic pathology of single subjects, are most\nprevalent in high frequency ictal dynamics and low frequency preictal dynamics.\nFinally, we find that ictal dynamics are better predicted by white matter\nfeatures and more poorly predicted by geometry and genetic constraints than\npreictal dynamics, suggesting that the functional brain network dynamics\nmanifest in seizures rely on - and may directly propagate along - underlying\nwhite matter structure that is largely conserved across humans. Broadly, our\nwork offers insights into the generic architectural principles of the human\nbrain that impact seizure dynamics, and could be extended to further our\nunderstanding, models, and predictions of subject-level pathology and response\nto intervention.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 14:37:44 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Reddy", "Pranav G.", ""], ["Betzel", "Richard F.", ""], ["Khambhati", "Ankit N.", ""], ["Shah", "Preya", ""], ["Kini", "Lohith", ""], ["Litt", "Brian", ""], ["Lucas", "Thomas H.", ""], ["Davis", "Kathryn A.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1809.04166", "submitter": "C. Daniel Greenidge", "authors": "C. Daniel Greenidge, Noam Miller, and Kenneth A. Norman", "title": "Leabra7: a Python package for modeling recurrent, biologically-realistic\n  neural networks", "comments": "Fix minor typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergent is a software package that uses the AdEx neural dynamics model and\nLEABRA learning algorithm to simulate and train arbitrary recurrent neural\nnetwork architectures in a biologically-realistic manner. We present Leabra7, a\ncomplementary Python library that implements these same algorithms. Leabra7 is\ndeveloped and distributed using modern software development principles, and\nintegrates tightly with Python's scientific stack. We demonstrate recurrent\nLeabra7 networks using traditional pattern-association tasks and a standard\nmachine learning task, classifying the IRIS dataset.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 21:09:25 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 23:17:17 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Greenidge", "C. Daniel", ""], ["Miller", "Noam", ""], ["Norman", "Kenneth A.", ""]]}, {"id": "1809.04414", "submitter": "David Rudrauf", "authors": "David Rudrauf, Daniel Bennequin, Kenneth Williford", "title": "The Moon Illusion explained by the Projective Consciousness Model", "comments": "Main 10 pages, 3 figures, Supplement 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Moon often appears larger near the perceptual horizon and smaller high in\nthe sky though the visual angle subtended is invariant. We show how this\nillusion results from the optimization of a projective geometrical frame for\nconscious perception through free energy minimization, as articulated in the\nProjective Consciousness Model. The model accounts for all documented\nmodulations of the illusion without anomalies (e.g., the size-distance\nparadox), surpasses other theories in explanatory power, makes sense of inter-\nand intra-subjective variability vis-a-vis the illusion, and yields new\nquantitative and qualitative predictions.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 12:59:06 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Rudrauf", "David", ""], ["Bennequin", "Daniel", ""], ["Williford", "Kenneth", ""]]}, {"id": "1809.04429", "submitter": "Muhammad Yousefnezhad", "authors": "Xiaoliang Sheng, Muhammad Yousefnezhad, Tonglin Xu, Ning Yuan,\n  Daoqiang Zhang", "title": "Gradient-based Representational Similarity Analysis with Searchlight for\n  Analyzing fMRI Data", "comments": "Conference: Chinese Conference on Pattern Recognition and Computer\n  Vision 2018 (PRCV18), 23-26/Nov, Guangzhou, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representational Similarity Analysis (RSA) aims to explore similarities\nbetween neural activities of different stimuli. Classical RSA techniques employ\nthe inverse of the covariance matrix to explore a linear model between the\nneural activities and task events. However, calculating the inverse of a\nlarge-scale covariance matrix is time-consuming and can reduce the stability\nand robustness of the final analysis. Notably, it becomes severe when the\nnumber of samples is too large. For facing this shortcoming, this paper\nproposes a novel RSA method called gradient-based RSA (GRSA). Moreover, the\nproposed method is not restricted to a linear model. In fact, there is a\ngrowing interest in finding more effective ways of using multi-subject and\nwhole-brain fMRI data. Searchlight technique can extend RSA from the localized\nbrain regions to the whole-brain regions with smaller memory footprint in each\nprocess. Based on Searchlight, we propose a new method called Spatiotemporal\nSearchlight GRSA (SSL-GRSA) that generalizes our ROI-based GRSA algorithm to\nthe whole-brain data. Further, our approach can handle some computational\nchallenges while dealing with large-scale, multi-subject fMRI data.\nExperimental studies on multi-subject datasets confirm that both proposed\napproaches achieve superior performance to other state-of-the-art RSA\nalgorithms.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 13:40:59 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Sheng", "Xiaoliang", ""], ["Yousefnezhad", "Muhammad", ""], ["Xu", "Tonglin", ""], ["Yuan", "Ning", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1809.04877", "submitter": "Fereshteh Lagzi", "authors": "Fereshteh Lagzi, Fatihcan M. Atay, Stefan Rotter", "title": "Bifurcation analysis of the dynamics of interacting populations of\n  spiking networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the collective dynamics of hierarchically structured networks of\ndensely connected spiking neurons. These networks of sub-networks may represent\ninteractions between cell assemblies or different nuclei in the brain. The\ndynamical activity pattern that results from these interactions depends on the\nstrength of synaptic coupling between them. Importantly, the overall dynamics\nof a brain region in the absence of external input, so called ongoing brain\nactivity, has been attributed to the dynamics of such interactions. In our\nstudy, two different network scenarios are considered: a system with one\ninhibitory and two excitatory sub-networks, and a network representation with\nthree inhibitory sub-networks. To study the effect of synaptic strength on the\nglobal dynamics of the network, two parameters for relative couplings between\nthese sub-networks are considered. For each case, a co-dimension two\nbifurcation analysis is performed and the results have been compared to\nlarge-scale network simulations. Our analysis shows that Generalized\nLotka-Volterra (GLV) equations, well-known in predator-prey studies, yield a\nmeaningful population-level description for the collective behavior of spiking\nneuronal interaction, which have a hierarchical structure. In particular, we\nobserved a striking equivalence between the bifurcation diagrams of spiking\nneuronal networks and their corresponding GLV equations. This study gives new\ninsight on the behavior of neuronal assemblies, and can potentially suggest new\nmechanisms for altering the dynamical patterns of spiking networks based on\nchanging the synaptic strength between some groups of neurons.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 10:29:29 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Lagzi", "Fereshteh", ""], ["Atay", "Fatihcan M.", ""], ["Rotter", "Stefan", ""]]}, {"id": "1809.04953", "submitter": "Sang-Yoon  Kim", "authors": "Sang-Yoon Kim and Woochang Lim", "title": "Cluster Burst Synchronization in A Scale-Free Network of Inhibitory\n  Bursting Neurons", "comments": "arXiv admin note: text overlap with arXiv:1803.07256,\n  arXiv:1708.04543", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a scale-free network of inhibitory Hindmarsh-Rose (HR) bursting\nneurons, and investigate coupling-induced cluster burst synchronization by\nvarying the average coupling strength $J_0$. For sufficiently small $J_0$,\nnon-cluster desynchronized states exist. However, when passing a critical point\n$J^*_c~(\\simeq 0.16)$, the whole population is segregated into 3 clusters via a\nconstructive role of synaptic inhibition to stimulate dynamical clustering\nbetween individual burstings, and thus 3-cluster desynchronized states appear.\nAs $J_0$ is further increased and passes a lower threshold $J^*_l~(\\simeq\n0.78)$, a transition to 3-cluster burst synchronization occurs due to another\nconstructive role of synaptic inhibition to favor population synchronization.\nIn this case, HR neurons in each cluster exhibit burst synchronization.\nHowever, as $J_0$ passes an intermediate threshold $J^*_m~(\\simeq 5.2)$, HR\nneurons begin to make intermittent hoppings between the 3 clusters. Due to the\nintermittent intercluster hoppings, the 3 clusters are integrated into a single\none. In spite of break-up of the 3 clusters, (non-cluster) burst\nsynchronization persists in the whole population, which is well visualized in\nthe raster plot of burst onset times where bursting stripes (composed of burst\nonset times and indicating burst synchronization) appear successively. With\nfurther increase in $J_0$, intercluster hoppings are intensified, and bursting\nstripes also become smeared more and more due to a destructive role of synaptic\ninhibition to spoil the burst synchronization. Eventually, when passing a\nhigher threshold $J^*_h~(\\simeq 17.8)$ a transition to desynchronization occurs\nvia complete overlap between the bursting stripes. Finally, we also investigate\nthe effects of stochastic noise on both 3-cluster burst synchronization and\nintercluster hoppings.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 00:40:18 GMT"}, {"version": "v2", "created": "Mon, 1 Apr 2019 13:51:14 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Kim", "Sang-Yoon", ""], ["Lim", "Woochang", ""]]}, {"id": "1809.05023", "submitter": "Jacob Davidson", "authors": "Jacob D. Davidson and Ahmed El Hady", "title": "Foraging as an evidence accumulation process", "comments": null, "journal-ref": "PLOS Computational Biology 2019", "doi": "10.1371/journal.pcbi.1007060", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A canonical foraging task is the patch-leaving problem, in which a forager\nmust decide to leave a current resource in search for another. Theoretical work\nhas derived optimal strategies for when to leave a patch, and experiments have\ntested for conditions where animals do or do not follow an optimal strategy.\nNevertheless, models of patch-leaving decisions do not consider the imperfect\nand noisy sampling process through which an animal gathers information, and how\nthis process is constrained by neurobiological mechanisms. In this theoretical\nstudy, we formulate an evidence accumulation model of patch-leaving decisions\nwhere the animal averages over noisy measurements to estimate the state of the\ncurrent patch and the overall environment. Evidence accumulation models belong\nto the class of drift diffusion processes and have been used to model decision\nmaking in different contexts. We solve the model for conditions where foraging\ndecisions are optimal and equivalent to the marginal value theorem, and perform\nsimulations to analyze deviations from optimal when these conditions are not\nmet. By adjusting the drift rate and decision threshold, the model can\nrepresent different strategies, for example an increment-decrement or counting\nstrategy. These strategies yield identical decisions in the limiting case but\ndiffer in how patch residence times adapt when the foraging environment is\nuncertain. To account for sub-optimal decisions, we introduce an\nenergy-dependent utility function that predicts longer than optimal patch\nresidence times when food is plentiful. Our model provides a quantitative\nconnection between ecological models of foraging behavior and evidence\naccumulation models of decision making. Moreover, it provides a theoretical\nframework for potential experiments which seek to identify neural circuits\nunderlying patch leaving decisions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 15:51:31 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Davidson", "Jacob D.", ""], ["Hady", "Ahmed El", ""]]}, {"id": "1809.05196", "submitter": "Anna Miller", "authors": "Anna Miller, Dawei Li, Jason Platt, Arij Daou, Daniel Margoliash,\n  Henry Abarbanel", "title": "Statistical Data Assimilation: Formulation and Examples from\n  Neurobiology", "comments": "28 pages, 13 figuress", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  For the Research Topic Data Assimilation and Control: Theory and Applications\nin Life Sciences we first review the formulation of statistical data\nassimilation (SDA) and discuss algorithms for exploring variational\napproximations to the conditional expected values of biophysical aspects of\nfunctional neural circuits. Then we report on the application of SDA to (1) the\nexploration of properties of individual neurons in the HVC nucleus of the avian\nsong system, and (2) characterizing individual neurons formulated as very large\nscale integration (VLSI) analog circuits with a goal of building functional,\nbiophysically realistic, VLSI representations of functional nervous systems.\nNetworks of neurons pose a substantially greater challenge, and we comment on\nformulating experiments to probe the properties, especially the functional\nconnectivity, in song command circuits within HVC.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 22:27:24 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Miller", "Anna", ""], ["Li", "Dawei", ""], ["Platt", "Jason", ""], ["Daou", "Arij", ""], ["Margoliash", "Daniel", ""], ["Abarbanel", "Henry", ""]]}, {"id": "1809.05254", "submitter": "Tatsuya Haga", "authors": "Tatsuya Haga, Tomoki Fukai", "title": "Extended temporal association memory by inhibitory Hebbian learning", "comments": "4 pages, 4 figures", "journal-ref": "Phys. Rev. Lett. 123, 078101 (2019)", "doi": "10.1103/PhysRevLett.123.078101", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hebbian learning of excitatory synapses plays a central role in storing\nactivity patterns in associative memory models. Furthermore, interstimulus\nHebbian learning associates multiple items in the brain by converting temporal\ncorrelation to spatial correlation between attractors. However, growing\nexperimental evidence suggests that learning of inhibitory synapses creates\n\"inhibitory engrams\", which presumably balance with the patterns encoded in the\nexcitatory network. Controlling inhibitory engrams may modify the behavior of\nassociative memory in neural networks, but the consequence of such control has\nnot been theoretically understood. Noting that Hebbian learning of inhibitory\nsynapses yields an anti-Hebbian effect, we show that the combination of Hebbian\nand anti-Hebbian learning can increase the span of temporal association between\nthe correlated attractors. The balance of targetted and global inhibition\nregulates this span of association in the network. Our results suggest a\nnontrivial role of anti-Hebbian learning and inhibitory engrams in associative\nmemory.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 04:57:16 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Haga", "Tatsuya", ""], ["Fukai", "Tomoki", ""]]}, {"id": "1809.05336", "submitter": "Richa Tripathi", "authors": "Richa Tripathi, Dyutiman Mukhopadhyay, Chakresh Kumar Singh, Krishna\n  Prasad Miyapuram and Shivakumar Jolad", "title": "Characterizing functional brain networks and emotional centers based on\n  Rasa theory of Indian aesthetics", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": "10.1007/978-3-030-36683-4_68", "report-no": "Complex Networks and Their Applications VIII pp 854-867", "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Indian history of arts, Rasas are the aesthetics associated with any\nauditory, visual, literary or musical piece of art that evokes highly\norchestrated emotional states. In this work, we study the functional response\nof the brain to movie clippings meant to evoke the Rasas through network\nanalysis. We extract functional brain networks using coherence measures on EEG\nrecordings of film clips from popular Indian Bollywood movies representing nine\nRasas in the Indian Natyasastra. Structural and functional network measures\nwere computed for these brain networks, averaging over a range of significant\nedge weights, in different brainwave frequency bands. We identify segregation\nof neuronal wiring in the brain into modules using a community detection\nalgorithm. Further, using mutual information measure, we compare and contrast\nthe modular organizations of brain network corresponding to different Rasas.\nHubs identified using centrality measure reveal the network nodes that are\ncentral to information propagation across all Rasas. We also observe that the\nfunctional connectivity is suppressed when high-frequency waves such as beta\nand gamma are dominant in the brain. The significant links causing differences\nbetween the Rasa pairs are extracted statistically.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 10:15:54 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Tripathi", "Richa", ""], ["Mukhopadhyay", "Dyutiman", ""], ["Singh", "Chakresh Kumar", ""], ["Miyapuram", "Krishna Prasad", ""], ["Jolad", "Shivakumar", ""]]}, {"id": "1809.05560", "submitter": "Hongming Li", "authors": "Hongming Li, Yong Fan", "title": "Identification of temporal transition of functional states using\n  recurrent neural networks from functional MRI", "comments": "Accepted by MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic functional connectivity analysis provides valuable information for\nunderstanding brain functional activity underlying different cognitive\nprocesses. Besides sliding window based approaches, a variety of methods have\nbeen developed to automatically split the entire functional MRI scan into\nsegments by detecting change points of functional signals to facilitate better\ncharacterization of temporally dynamic functional connectivity patterns.\nHowever, these methods are based on certain assumptions for the functional\nsignals, such as Gaussian distribution, which are not necessarily suitable for\nthe fMRI data. In this study, we develop a deep learning based framework for\nadaptively detecting temporally dynamic functional state transitions in a\ndata-driven way without any explicit modeling assumptions, by leveraging recent\nadvances in recurrent neural networks (RNNs) for sequence modeling.\nParticularly, we solve this problem in an anomaly detection framework with an\nassumption that the functional profile of one single time point could be\nreliably predicted based on its preceding profiles within stable functional\nstate, while large prediction errors would occur around change points of\nfunctional states. We evaluate the proposed method using both task and\nresting-state fMRI data obtained from the human connectome project and\nexperimental results have demonstrated that the proposed change point detection\nmethod could effectively identify change points between different task events\nand split the resting-state fMRI into segments with distinct functional\nconnectivity patterns.\n", "versions": [{"version": "v1", "created": "Fri, 14 Sep 2018 18:59:32 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Li", "Hongming", ""], ["Fan", "Yong", ""]]}, {"id": "1809.05743", "submitter": "Netta Haroush", "authors": "Netta Haroush and Shimon Marom", "title": "Inhibition in Random Neuronal Networks Enhances Response Variability and\n  Disrupts Stimulus Discrimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inhibition is considered to shape neural activity, and broaden its pattern\nrepertoire. In the sensory organs, where the anatomy of neural circuits is\nhighly structured, lateral inhibition sharpens contrast among stimulus\nproperties. The impact of inhibition on stimulus processing and the involvement\nof lateral inhibition is less clear when activity propagates to the\nless-structured relay stations. Here we take a synthetic approach to\ndisentangle the impacts of inhibition from that of specialized anatomy on the\nrepertoire of evoked activity patterns, and as a result, the network capacity\nto uniquely represent different stimuli. To this aim, we blocked inhibition in\nrandomly rewired networks of cortical neurons in-vitro, and quantified response\nvariability and stimulus discrimination among stimuli provided at different\nspatial loci, before and after the blockade. We show that blocking inhibition\nquenches variability of responses evoked by repeated stimuli through any\nspatial source; for all tested response features. Despite the sharpening role\nof inhibition in the highly structured sensory organs, in these random networks\nwe find that blocking inhibition enhances stimulus discrimination between\nspatial sources of stimulation, when based on response features that emphasize\nthe relation among spike times recorded through different electrodes. We\nfurther show that under intact inhibition, responses to a given stimulus are a\nnoisy version of those revealed by blocking inhibition; such that intact\ninhibition disrupts an otherwise coherent, wave propagation of activity.\n", "versions": [{"version": "v1", "created": "Sat, 15 Sep 2018 16:57:13 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Haroush", "Netta", ""], ["Marom", "Shimon", ""]]}, {"id": "1809.05880", "submitter": "Markus D Schirmer", "authors": "Markus D. Schirmer and Ai Wern Chung", "title": "Structural subnetwork evolution across the life-span: rich-club, feeder,\n  seeder", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-00755-3_15", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of developmental and aging processes on brain connectivity and the\nconnectome has been widely studied. Network theoretical measures and certain\ntopological principles are computed from the entire brain, however there is a\nneed to separate and understand the underlying subnetworks which contribute\ntowards these observed holistic connectomic alterations. One organizational\nprinciple is the rich-club - a core subnetwork of brain regions that are\nstrongly connected, forming a high-cost, high-capacity backbone that is\ncritical for effective communication in the network. Investigations primarily\nfocus on its alterations with disease and age. Here, we present a systematic\nanalysis of not only the rich-club, but also other subnetworks derived from\nthis backbone - namely feeder and seeder subnetworks. Our analysis is applied\nto structural connectomes in a normal cohort from a large, publicly available\nlifespan study. We demonstrate changes in rich-club membership with age\nalongside a shift in importance from 'peripheral' seeder to feeder subnetworks.\nOur results show a refinement within the rich-club structure (increase in\ntransitivity and betweenness centrality), as well as increased efficiency in\nthe feeder subnetwork and decreased measures of network integration and\nsegregation in the seeder subnetwork. These results demonstrate the different\ndevelopmental patterns when analyzing the connectome stratified according to\nits rich-club and the potential of utilizing this subnetwork analysis to reveal\nthe evolution of brain architectural alterations across the life-span.\n", "versions": [{"version": "v1", "created": "Sun, 16 Sep 2018 14:19:59 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Schirmer", "Markus D.", ""], ["Chung", "Ai Wern", ""]]}, {"id": "1809.06139", "submitter": "Mathis Fleury", "authors": "Mathis Fleury (VisAGeS), Pierre Maurel (VisAGeS), Marsel Mano\n  (VisAGeS), Elise Bannier (VisAGeS), Christian Barillot (VisAGeS)", "title": "Automatic Electrodes Detection during simultaneous EEG/fMRI acquisition", "comments": "ISMRM, Jun 2018, Paris, France. 2018, https://www.ismrm.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneous EEG/fMRI acquisition allows to measure brain activity at high\nspatial-temporal resolution. The localisation of EEG sources depends on several\nparameters including the position of the electrodes on the scalp. The position\nof the MR electrodes during its acquisitions is obtained with the use of the\nUTE sequence allowing their visualisation. The retrieval of the electrodes\nconsists in obtaining the volume where the electrodes are located by applying a\nsphere detection algorithm. We detect around 90% of electrodes for each\nsubject, and our UTE-based electrode detection showed an average position error\nof 3.7mm for all subjects.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 11:37:49 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Fleury", "Mathis", "", "VisAGeS"], ["Maurel", "Pierre", "", "VisAGeS"], ["Mano", "Marsel", "", "VisAGeS"], ["Bannier", "Elise", "", "VisAGeS"], ["Barillot", "Christian", "", "VisAGeS"]]}, {"id": "1809.06199", "submitter": "Amirhossein Hajiaghajani", "authors": "Soheil Hashemi, Amirhossein Hajiaghajani, and Ali Abdolali", "title": "Noninvasive Blockade of Action Potential by Electromagnetic Induction", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.SP q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional anesthesia methods such as injective anesthetic agents may cause\nvarious side effects such as injuries, allergies, and infections. We aim to\ninvestigate a noninvasive scheme of an electromagnetic radiator system to block\naction potential (AP) in neuron fibers. We achieved a high-gradient and\nunipolar tangential electric field by designing circular geometric coils on an\nelectric rectifier filter layer. An asymmetric sawtooth pulse shape supplied\nthe coils in order to create an effective blockage. The entire setup was placed\n5 cm above 50 motor and sensory neurons of the spinal cord. A validated\ntime-domain full-wave analysis code Based on cable model of the neurons and the\nelectric and magnetic potentials is used to simulate and investigate the\nproposed scheme. We observed action potential blockage on both motor and\nsensory neurons. In addition, the introduced approach shows promising potential\nfor AP manipulation in the spinal cord.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2018 06:42:41 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Hashemi", "Soheil", ""], ["Hajiaghajani", "Amirhossein", ""], ["Abdolali", "Ali", ""]]}, {"id": "1809.06216", "submitter": "Diego Alvarez-Estevez", "authors": "Diego Alvarez-Estevez, Isaac Fern\\'andez-Varela", "title": "Large-scale validation of an automatic EEG arousal detection algorithm\n  using different heterogeneous databases", "comments": "13 pages, 1 figure, 7 tables; typos corrected; format improved", "journal-ref": null, "doi": "10.1016/j.sleep.2019.01.025", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  $\\textbf{Objective}$: To assess the validity of an automatic EEG arousal\ndetection algorithm using large patient samples and different heterogeneous\ndatabases\n  $\\textbf{Methods}$: Automatic scorings were confronted with results from\nhuman expert scorers on a total of 2768 full-night PSG recordings obtained from\ntwo different databases. Of them, 472 recordings were obtained during clinical\nroutine at our sleep center and were subdivided into two subgroups of 220\n(HMC-S) and 252 (HMC-M) recordings each, attending to the procedure followed by\nthe clinical expert during the visual review (semi-automatic or purely manual,\nrespectively). In addition, 2296 recordings from the public SHHS-2 database\nwere evaluated against the respective manual expert scorings.\n  $\\textbf{Results}$: Event-by-event epoch-based validation resulted in an\noverall Cohen kappa agreement K = 0.600 (HMC-S), 0.559 (HMC-M), and 0.573\n(SHHS-2). Estimated inter-scorer variability on the datasets was, respectively,\nK = 0.594, 0.561 and 0.543. Analyses of the corresponding Arousal Index scores\nshowed associated automatic-human repeatability indices ranging in 0.693-0.771\n(HMC-S), 0.646-0.791 (HMC-M), and 0.759-0.791 (SHHS-2).\n  $\\textbf{Conclusions}$: Large-scale validation of our automatic EEG arousal\ndetector on different databases has shown robust performance and good\ngeneralization results comparable to the expected levels of human agreement.\nSpecial emphasis has been put on allowing reproducibility of the results and\nimplementation of our method has been made accessible online as open source\ncode\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 09:55:42 GMT"}, {"version": "v2", "created": "Fri, 9 Nov 2018 08:26:24 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Alvarez-Estevez", "Diego", ""], ["Fern\u00e1ndez-Varela", "Isaac", ""]]}, {"id": "1809.06221", "submitter": "Mustafa Radha", "authors": "Mustafa Radha, Pedro Fonseca, Marco Ross, Andreas Cerny, Peter\n  Anderer, Ronald M. Aarts", "title": "LSTM knowledge transfer for HRV-based sleep staging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated sleep stage classification using heart-rate variability is an\nactive field of research. In this work limitations of the current\nstate-of-the-art are addressed through the use of deep learning techniques and\ntheir efficacy is demonstrated. First, a temporal model is proposed for the\ninference of sleep stages from electrocardiography using a deep long- and\nshort-term (LSTM) classifier and it is shown that this model outperforms\nprevious approaches which were often limited to non-temporal or Markovian\nclassifiers on a comprehensive benchmark data set (292 participants, 541214\nsamples) comprising a wide range of ages and pathological profiles, achieving a\nCohen's $\\kappa$ of $0.61\\pm0.16$ and accuracy of $76.30\\pm10.17$ annotated\naccording to the Rechtschaffen & Kales annotation standard.\n  Subsequently, it is demonstrated how knowledge learned on this large\nbenchmark data set can be re-used through transfer learning for the\nclassification of photoplethysmography (PPG) data. This is done using a smaller\ndata set (60 participants, 91479 samples) that is annotated with the more\nrecent American Association of Sleep Medicine annotation standard, achieving a\nCohen's $\\kappa$ of $0.63\\pm0.13$ and accuracy of $74.65\\pm8.63$ for\nwrist-mounted PPG-based sleep stage classification, higher than any previously\nreported performance using this sensor modality. This demonstrates the\nfeasibility of knowledge transfer in sleep staging to adapt models for new\nsensor modalities as well as different annotation strategies.\n", "versions": [{"version": "v1", "created": "Wed, 12 Sep 2018 10:01:38 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Radha", "Mustafa", ""], ["Fonseca", "Pedro", ""], ["Ross", "Marco", ""], ["Cerny", "Andreas", ""], ["Anderer", "Peter", ""], ["Aarts", "Ronald M.", ""]]}, {"id": "1809.06303", "submitter": "Daniel Durstewitz", "authors": "Daniel Durstewitz, Quentin J.M. Huys, Georgia Koppe", "title": "Psychiatric Illnesses as Disorders of Network Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This review provides a dynamical systems perspective on psychiatric symptoms\nand disease, and discusses its potential implications for diagnosis, prognosis,\nand treatment. After a brief introduction into the theory of dynamical systems,\nwe will focus on the idea that cognitive and emotional functions are\nimplemented in terms of dynamical systems phenomena in the brain, a common\nassumption in theoretical and computational neuroscience. Specific\ncomputational models, anchored in biophysics, for generating different types of\nnetwork dynamics, and with a relation to psychiatric symptoms, will be briefly\nreviewed, as well as methodological approaches for reconstructing the system\ndynamics from observed time series (like fMRI or EEG recordings). We then\nattempt to outline how psychiatric phenomena, associated with schizophrenia,\ndepression, PTSD, ADHD, phantom pain, and others, could be understood in\ndynamical systems terms. Most importantly, we will try to convey that the\ndynamical systems level may provide a central, hub-like level of convergence\nwhich unifies and links multiple biophysical and behavioral phenomena, in the\nsense that diverse biophysical changes can give rise to the same dynamical\nphenomena and, vice versa, similar changes in dynamics may yield different\nbehavioral symptoms depending on the brain area where these changes manifest.\nIf this assessment is correct, it may have profound implications for the\ndiagnosis, prognosis, and treatment of psychiatric conditions, as it puts the\nfocus on dynamics. We therefore argue that consideration of dynamics should\nplay an important role in the choice and target of interventions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 16:14:37 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Durstewitz", "Daniel", ""], ["Huys", "Quentin J. M.", ""], ["Koppe", "Georgia", ""]]}, {"id": "1809.06441", "submitter": "Christopher Lynn", "authors": "Christopher W. Lynn and Danielle S. Bassett", "title": "The physics of brain network structure, function, and control", "comments": null, "journal-ref": "Nat Rev Phys 1, 318-332 (2019)", "doi": "10.1038/s42254-019-0040-8", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain is a complex organ characterized by heterogeneous patterns of\nstructural connections supporting unparalleled feats of cognition and a wide\nrange of behaviors. New noninvasive imaging techniques now allow these patterns\nto be carefully and comprehensively mapped in individual humans and animals.\nYet, it remains a fundamental challenge to understand how the brain's\nstructural wiring supports cognitive processes, with major implications for the\npersonalized treatment of mental health disorders. Here, we review recent\nefforts to meet this challenge that draw on intuitions, models, and theories\nfrom physics, spanning the domains of statistical mechanics, information\ntheory, and dynamical systems and control. We begin by considering the\norganizing principles of brain network architecture instantiated in structural\nwiring under constraints of symmetry, spatial embedding, and energy\nminimization. We next consider models of brain network function that stipulate\nhow neural activity propagates along these structural connections, producing\nthe long-range interactions and collective dynamics that support a rich\nrepertoire of system functions. Finally, we consider perturbative experiments\nand models for brain network control, which leverage the physics of signal\ntransmission along structural wires to infer intrinsic control processes that\nsupport goal-directed behavior and to inform stimulation-based therapies for\nneurological disease and psychiatric disorders. Throughout, we highlight\nseveral open questions in the physics of brain network structure, function, and\ncontrol that will require creative efforts from physicists willing to brave the\ncomplexities of living matter.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 20:55:18 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 14:26:50 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2019 16:30:50 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Lynn", "Christopher W.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1809.06521", "submitter": "Liane Gabora", "authors": "V. Scotney, S. Weissmeyer, L. Gabora", "title": "Cross-Domain Influences on Creative Processes and Products", "comments": "6 pages, 2 tables", "journal-ref": "Scotney, V., Weissmeyer, S., & Gabora, L. 2018. In C. Kalish, M.\n  Rau, J. Zhu and T. Rogers, Eds. Proc 40th Ann Mtng Cognitive Science Society,\n  pp. 2452-2457. Austin TX: Cog Sci Soc", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the honing theory of creativity, the iterative process\nculminating in a creative work is made possible by the self-organizing nature\nof a conceptual network, or worldview, and its innate holistic tendency to\nminimize inconsistency. As such, the creative process is not limited to the\nproblem domain, and influences on creativity from domains other than that of\nthe final product are predicted to be widespread. We conducted a study in which\nparticipants with varying levels of creative experience listed their creative\noutputs, as well as influences (sources of inspiration) on these outputs. Of\nthe 758 creative influences, 13% were within-domain narrow, 13% within-domain\nbroad, 67% cross-domain, and 6% unclear. These findings support the hypothesis\nthat to trace the inspirational sources or 'conceptual parents' of a creative\noutput, and thus track its cultural lineage, one must look beyond the problem\ndomain to the creators' self-organizing, inconsistency-minimizing worldview at\nlarge.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 03:51:31 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Scotney", "V.", ""], ["Weissmeyer", "S.", ""], ["Gabora", "L.", ""]]}, {"id": "1809.06534", "submitter": "Zehong Cao Dr.", "authors": "Zehong Cao, Chun-Hsiang Chuang, Jung-Kai King, Chin-Teng Lin", "title": "Multi-channel EEG recordings during a sustained-attention driving task", "comments": "This manuscript is submitting to Nature: Scientific Data", "journal-ref": "Scientific Data (volume 6, Article number: 19) (2019)", "doi": "10.1038/s41597-019-0027-4", "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We described driver behaviour and brain dynamics acquired from a 90-minute\nsustained-attention task in an immersive driving simulator. The data include 62\ncopies of 32 channel electroencephalography (EEG) data for 27 subjects that\ndrove on a four lane highway and were asked to keep the car cruising in the\ncentre of the lane. Lane departure events were randomly induced to make the car\ndrift from the original cruising lane towards the left or right lane. A\ncomplete trial includes events with deviation onset, response onset, and\nresponse offset. The next trial, in which the subject has to drive back to the\noriginal cruising lane, occurs from 5 to 10 seconds after finishing the current\ntrial. We hope that this dataset will lead to the development of novel neural\nprocessing assays that can be used to index brain cortical dynamics and detect\ndriving fatigue and drowsiness. This publicly available dataset is beneficial\nto the neuroscientific and brain computer interface communities.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 05:09:26 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Cao", "Zehong", ""], ["Chuang", "Chun-Hsiang", ""], ["King", "Jung-Kai", ""], ["Lin", "Chin-Teng", ""]]}, {"id": "1809.06676", "submitter": "Zehong Cao Dr.", "authors": "Fali Li, Chanlin Yi, Yuanyuan Liao, Yuanling Jiang, Yajing Si, Limeng\n  Song, Tao Zhang, Dezhong Yao, Yangsong Zhang, Zehong Cao and Peng Xu", "title": "Reconfiguration of Brain Network between Resting-state and Oddball\n  Paradigm", "comments": "This manuscript is submitting to IEEE Transactions on Cognitive and\n  Developmental Systems", "journal-ref": null, "doi": "10.1109/TCDS.2020.2965135", "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The oddball paradigm is widely applied to the investigation of multiple\ncognitive functions. Prior studies have explored the cortical oscillation and\npower spectral differing from the resting-state conduction to oddball paradigm,\nbut whether brain networks existing the significant difference is still\nunclear. Our study addressed how the brain reconfigures its architecture from a\nresting-state condition (i.e., baseline) to P300 stimulus task in the visual\noddball paradigm. In this study, electroencephalogram (EEG) datasets were\ncollected from 24 postgraduate students, who were required to only mentally\ncount the number of target stimulus; afterwards the functional EEG networks\nconstructed in different frequency bands were compared between baseline and\noddball task conditions to evaluate the reconfiguration of functional network\nin the brain. Compared to the baseline, our results showed the significantly (p\n< 0.05) enhanced delta/theta EEG connectivity and decreased alpha default mode\nnetwork in the progress of brain reconfiguration to the P300 task. Furthermore,\nthe reconfigured coupling strengths were demonstrated to relate to P300\namplitudes, which were then regarded as input features to train a classifier to\ndifferentiate the high and low P300 amplitudes groups with an accuracy of\n77.78%. The findings of our study help us to understand the changes of\nfunctional brain connectivity from resting-state to oddball stimulus task, and\nthe reconfigured network pattern has the potential for the selection of good\nsubjects for P300-based brain- computer interface.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 12:57:47 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Li", "Fali", ""], ["Yi", "Chanlin", ""], ["Liao", "Yuanyuan", ""], ["Jiang", "Yuanling", ""], ["Si", "Yajing", ""], ["Song", "Limeng", ""], ["Zhang", "Tao", ""], ["Yao", "Dezhong", ""], ["Zhang", "Yangsong", ""], ["Cao", "Zehong", ""], ["Xu", "Peng", ""]]}, {"id": "1809.06697", "submitter": "Luis Alfredo Moctezuma", "authors": "Luis Alfredo Moctezuma and Marta Molinas", "title": "EEG-based Subjects Identification based on Biometrics of Imagined Speech\n  using EMD", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When brain activity is translated into commands for real applications, the\npotential for human capacities augmentation is promising. In this paper, EMD is\nused to decompose EEG signals during Imagined Speech in order to use it as a\nbiometric marker for creating a Biometric Recognition System. For each EEG\nchannel, the most relevant Intrinsic Mode Functions (IMFs) are decided based on\nthe Minkowski distance, and for each IMF 4 features are computed: Instantaneous\nand Teager energy distribution and Higuchi and Petrosian Fractal Dimension. To\ntest the proposed method, a dataset with 20 subjects who imagined 30\nrepetitions of 5 words in Spanish, is used. Four classifiers are used for this\ntask - random forest, SVM, naive Bayes, and k-NN - and their performances are\ncompared. The accuracy obtained (up to 0.92 using Linear SVM) after 10-folds\ncross-validation suggest that the proposed method based on EMD can be valuable\nfor creating EEG-based biometrics of imagined speech for Subjects\nidentification.\n", "versions": [{"version": "v1", "created": "Thu, 13 Sep 2018 14:17:08 GMT"}], "update_date": "2018-09-19", "authors_parsed": [["Moctezuma", "Luis Alfredo", ""], ["Molinas", "Marta", ""]]}, {"id": "1809.06899", "submitter": "Ru Zhang", "authors": "Ru Zhang and Cheng-Ta Yang and Janne V. Kujala", "title": "Testing Selective Influence Directly Using Trackball Movement Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems factorial technology (SFT; Townsend & Nozawa, 1995) is regarded as a\nuseful tool to diagnose if features (or dimensions) of the investigated\nstimulus are processed in a parallel or serial fashion. In order to use SFT,\none has to assume the speed to process each feature is influenced by that\nfeature only, termed as selective influence (Sternberg, 1969). This assumption\nis usually untestable as the processing time for a stimulus feature is not\nobservable. Stochastic dominance is traditionally used as an indirect evidence\nfor selective influence (e.g., Townsend & Fifi\\'c, 2004). However, one should\nkeep in mind that selective influence may be violated even when stochastic\ndominance holds. The current study proposes a trackball movement paradigm for a\ndirect test of selective influence. The participants were shown a reference\nstimulus and a test stimulus simultaneously on a computer screen. They were\nasked to use the trackball to adjust the test stimulus until it appeared to\nmatch the position or shape of the reference stimulus. We recorded the reaction\ntime, the parameters defined the reference stimulus (denoted as \\alpha and\n\\beta ), and the parameters defined the test stimulus (denoted as A and B). We\ntested selective influence of \\alpha and \\beta on the amount of time to adjust\nA and B through testing selective influence of \\alpha and \\beta on the values\nof A and B using the linear feasibility test (Dzhafarov & Kujala, 2010). We\nfound that when the test was passed and stochastic dominance held, the inferred\narchitecture was as expected, which was further confirmed by the trajectory of\nA and B observed in each trial. However, with stochastic dominance only SFT can\nsuggest a prohibited architecture. Our results indicate the proposed method is\nmore reliable for testing selective influence on the processing speed than\nexamining stochastic dominance only.\n", "versions": [{"version": "v1", "created": "Tue, 18 Sep 2018 19:27:30 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Zhang", "Ru", ""], ["Yang", "Cheng-Ta", ""], ["Kujala", "Janne V.", ""]]}, {"id": "1809.07550", "submitter": "Jens Wilting", "authors": "Jens Wilting, Jonas Dehning, Joao Pinheiro Neto, Lucas Rudelt, Michael\n  Wibral, Johannes Zierenberg, Viola Priesemann", "title": "Dynamic Adaptive Computation: Tuning network states to task requirements", "comments": "6 pages + references, 2 figures", "journal-ref": "Frontiers in systems neuroscience 12 (2018)", "doi": "10.3389/fnsys.2018.00055", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Neural circuits are able to perform computations under very diverse\nconditions and requirements. The required computations impose clear constraints\non their fine-tuning: a rapid and maximally informative response to stimuli in\ngeneral requires decorrelated baseline neural activity. Such network dynamics\nis known as asynchronous-irregular. In contrast, spatio-temporal integration of\ninformation requires maintenance and transfer of stimulus information over\nextended time periods. This can be realized at criticality, a phase transition\nwhere correlations, sensitivity and integration time diverge. Being able to\nflexibly switch, or even combine the above properties in a task-dependent\nmanner would present a clear functional advantage. We propose that cortex\noperates in a \"reverberating regime\" because it is particularly favorable for\nready adaptation of computational properties to context and task. This\nreverberating regime enables cortical networks to interpolate between the\nasynchronous-irregular and the critical state by small changes in effective\nsynaptic strength or excitation-inhibition ratio. These changes directly adapt\ncomputational properties, including sensitivity, amplification, integration\ntime and correlation length within the local network. We review recent\nconverging evidence that cortex in vivo operates in the reverberating regime,\nand that various cortical areas have adapted their integration times to\nprocessing requirements. In addition, we propose that neuromodulation enables a\nfine-tuning of the network, so that local circuits can either decorrelate or\nintegrate, and quench or maintain their input depending on task. We argue that\nthis task-dependent tuning, which we call \"dynamic adaptive computation\",\npresents a central organization principle of cortical networks and discuss\nfirst experimental evidence.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 10:00:18 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Wilting", "Jens", ""], ["Dehning", "Jonas", ""], ["Neto", "Joao Pinheiro", ""], ["Rudelt", "Lucas", ""], ["Wibral", "Michael", ""], ["Zierenberg", "Johannes", ""], ["Priesemann", "Viola", ""]]}, {"id": "1809.07656", "submitter": "Alexander Gorban", "authors": "A.N. Gorban, V.A. Makarov, I.Y. Tyukin", "title": "The unreasonable effectiveness of small neural ensembles in\n  high-dimensional brain", "comments": "Review paper, accepted in Physics of Life Reviews; minor corrections", "journal-ref": null, "doi": "10.1016/j.plrev.2018.09.005", "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite the widely-spread consensus on the brain complexity, sprouts of the\nsingle neuron revolution emerged in neuroscience in the 1970s. They brought\nmany unexpected discoveries, including grandmother or concept cells and sparse\ncoding of information in the brain.\n  In machine learning for a long time, the famous curse of dimensionality\nseemed to be an unsolvable problem. Nevertheless, the idea of the blessing of\ndimensionality becomes gradually more and more popular. Ensembles of\nnon-interacting or weakly interacting simple units prove to be an effective\ntool for solving essentially multidimensional problems. This approach is\nespecially useful for one-shot (non-iterative) correction of errors in large\nlegacy artificial intelligence systems.\n  These simplicity revolutions in the era of complexity have deep fundamental\nreasons grounded in geometry of multidimensional data spaces. To explore and\nunderstand these reasons we revisit the background ideas of statistical\nphysics. In the course of the 20th century they were developed into the\nconcentration of measure theory. New stochastic separation theorems reveal the\nfine structure of the data clouds.\n  We review and analyse biological, physical, and mathematical problems at the\ncore of the fundamental question: how can high-dimensional brain organise\nreliable and fast learning in high-dimensional world of data by simple tools?\n  Two critical applications are reviewed to exemplify the approach: one-shot\ncorrection of errors in intellectual systems and emergence of static and\nassociative memories in ensembles of single neurons.\n", "versions": [{"version": "v1", "created": "Thu, 20 Sep 2018 14:53:11 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 10:57:11 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Gorban", "A. N.", ""], ["Makarov", "V. A.", ""], ["Tyukin", "I. Y.", ""]]}, {"id": "1809.08045", "submitter": "Dominik Dold", "authors": "Dominik Dold, Ilja Bytschok, Akos F. Kungl, Andreas Baumbach, Oliver\n  Breitwieser, Walter Senn, Johannes Schemmel, Karlheinz Meier, Mihai A.\n  Petrovici", "title": "Stochasticity from function -- why the Bayesian brain may need no noise", "comments": null, "journal-ref": "Neural Networks 119C (2019) pp. 200-213", "doi": "10.1016/j.neunet.2019.08.002", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE physics.bio-ph stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An increasing body of evidence suggests that the trial-to-trial variability\nof spiking activity in the brain is not mere noise, but rather the reflection\nof a sampling-based encoding scheme for probabilistic computing. Since the\nprecise statistical properties of neural activity are important in this\ncontext, many models assume an ad-hoc source of well-behaved, explicit noise,\neither on the input or on the output side of single neuron dynamics, most often\nassuming an independent Poisson process in either case. However, these\nassumptions are somewhat problematic: neighboring neurons tend to share\nreceptive fields, rendering both their input and their output correlated; at\nthe same time, neurons are known to behave largely deterministically, as a\nfunction of their membrane potential and conductance. We suggest that spiking\nneural networks may, in fact, have no need for noise to perform sampling-based\nBayesian inference. We study analytically the effect of auto- and\ncross-correlations in functionally Bayesian spiking networks and demonstrate\nhow their effect translates to synaptic interaction strengths, rendering them\ncontrollable through synaptic plasticity. This allows even small ensembles of\ninterconnected deterministic spiking networks to simultaneously and\nco-dependently shape their output activity through learning, enabling them to\nperform complex Bayesian computation without any need for noise, which we\ndemonstrate in silico, both in classical simulation and in neuromorphic\nemulation. These results close a gap between the abstract models and the\nbiology of functionally Bayesian spiking networks, effectively reducing the\narchitectural constraints imposed on physical neural substrates required to\nperform probabilistic computing, be they biological or artificial.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 11:37:14 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 15:53:49 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 12:58:19 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Dold", "Dominik", ""], ["Bytschok", "Ilja", ""], ["Kungl", "Akos F.", ""], ["Baumbach", "Andreas", ""], ["Breitwieser", "Oliver", ""], ["Senn", "Walter", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""], ["Petrovici", "Mihai A.", ""]]}, {"id": "1809.08203", "submitter": "Michael Hasselmo PhD", "authors": "Michael E. Hasselmo", "title": "A model of cortical cognitive function using hierarchical interactions\n  of gating matrices in internal agents coding relational representations", "comments": "6 figures, version 2 simplifies notation and changes notation from\n  row vector to column vector for clarity in the equations, and fixes some\n  typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flexible cognition requires the ability to rapidly detect systematic\nfunctions of variables and guide future behavior based on predictions. The\nmodel described here proposes a potential framework for patterns of neural\nactivity to detect systematic functions and relations between components of\nsensory input and apply them in a predictive manner. This model includes\nmultiple internal gating agents that operate within the state space of neural\nactivity, in analogy to external agents behaving in the external environment.\nThe multiple internal gating agents represent patterns of neural activity that\ndetect and gate patterns of matrix connectivity representing the relations\nbetween different neural populations. The patterns of gating matrix\nconnectivity represent functions that can be used to predict future components\nof a series of sensory inputs or the relationship between different features of\na static sensory stimulus. The model is applied to the prediction of dynamical\ntrajectories, the internal relationship between features of different sensory\nstimuli and to the prediction of affine transformations that could be useful\nfor solving cognitive tasks such as the Ravens progressive matrices task.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 16:46:33 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 18:21:46 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Hasselmo", "Michael E.", ""]]}, {"id": "1809.08273", "submitter": "Ayoub Hajlaoui", "authors": "Ayoub Hajlaoui, Mohamed Chetouani, Slim Essid", "title": "EEG-based Inter-Subject Correlation Schemes in a Stimuli-Shared\n  Framework: Interplay with Valence and Arousal", "comments": "9 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affective computing is confronted to high inter-subject variability, in both\nemotional and physiological responses to a given stimulus. In a stimuli-shared\nframework, that is to say for different subjects who watch the same stimuli,\nInter-Subject Correlation (ISC) measured from Electroencephalographic (EEG)\nrecordings characterize the correlations between the respective signals at the\ndifferent EEG channels. In order to investigate the interplay between ISC and\nemotion, we propose to study the effect of valence and arousal on the ISC\nscore. To this end, we exploited various computational schemes corresponding to\ndifferent subsets of the dataset: all the data, stimulus-wise, subject\npairwise, and both stimulus-wise and subject pairwise. We thus applied these\nschemes to the HCI MAHNOB and DEAP databases. Our results suggest that the ISC\nscore decreases with valence and increases with arousal, as already shown by\nprevious results on functional MRI.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 10:01:17 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Hajlaoui", "Ayoub", ""], ["Chetouani", "Mohamed", ""], ["Essid", "Slim", ""]]}, {"id": "1809.08291", "submitter": "Simon DeDeo", "authors": "Christina Boyce-Jacino and Simon DeDeo", "title": "Opacity, Obscurity, and the Geometry of Question-Asking", "comments": "24 pages, 7 tables, 4 figures. Comments welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asking questions is a pervasive human activity, but little is understood\nabout what makes them difficult to answer. An analysis of a pair of large\ndatabases, of New York Times crosswords and questions from the quiz-show\nJeopardy, establishes two orthogonal dimensions of question difficulty:\nobscurity (the rarity of the answer) and opacity (the indirectness of question\ncues, operationalized with word2vec). The importance of opacity, and the role\nof synergistic information in resolving it, suggests that accounts of\ndifficulty in terms of prior expectations captures only a part of the\nquestion-asking process. A further regression analysis shows the presence of\nadditional dimensions to question-asking: question complexity, the answer's\nlocal network density, cue intersection, and the presence of signal words. Our\nwork shows how question-askers can help their interlocutors by using contextual\ncues, or, conversely, how a particular kind of unfamiliarity with the domain in\nquestion can make it harder for individuals to learn from others. Taken\ntogether, these results suggest how Bayesian models of question difficulty can\nbe supplemented by process models and accounts of the heuristics individuals\nuse to navigate conceptual spaces.\n", "versions": [{"version": "v1", "created": "Fri, 21 Sep 2018 20:01:30 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Boyce-Jacino", "Christina", ""], ["DeDeo", "Simon", ""]]}, {"id": "1809.08461", "submitter": "Leenoy Meshulam", "authors": "Leenoy Meshulam, Jeffrey L. Gauthier, Carlos D. Brody, David W. Tank\n  and William Bialek", "title": "Coarse--graining, fixed points, and scaling in a large population of\n  neurons", "comments": null, "journal-ref": "Phys. Rev. Lett. 123, 178103 (2019)", "doi": "10.1103/PhysRevLett.123.178103", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a phenomenological coarse--graining procedure for activity in a\nlarge network of neurons, and apply this to recordings from a population of\n1000+ cells in the hippocampus. Distributions of coarse--grained variables seem\nto approach a fixed non--Gaussian form, and we see evidence of scaling in both\nstatic and dynamic quantities. These results suggest that the collective\nbehavior of the network is described by a non--trivial fixed point.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 18:00:10 GMT"}], "update_date": "2019-10-30", "authors_parsed": [["Meshulam", "Leenoy", ""], ["Gauthier", "Jeffrey L.", ""], ["Brody", "Carlos D.", ""], ["Tank", "David W.", ""], ["Bialek", "William", ""]]}, {"id": "1809.08504", "submitter": "Mason A. Porter", "authors": "Bernadette J. Stolz, Tegan Emerson, Satu Nahkuri, Mason A. Porter, and\n  Heather A. Harrington", "title": "Topological Data Analysis of Task-Based fMRI Data from Experiments on\n  Schizophrenia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cond-mat.dis-nn math.AT nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use methods from computational algebraic topology to study functional\nbrain networks, in which nodes represent brain regions and weighted edges\nencode the similarity of fMRI time series from each region. With these tools,\nwhich allow one to characterize topological invariants such as loops in\nhigh-dimensional data, we are able to gain understanding into low-dimensional\nstructures in networks in a way that complements traditional approaches that\nare based on pairwise interactions. In the present paper, we use persistent\nhomology to analyze networks that we construct from task-based fMRI data from\nschizophrenia patients, healthy controls, and healthy siblings of schizophrenia\npatients. We thereby explore the persistence of topological structures such as\nloops at different scales in these networks. We use persistence landscapes and\npersistence images to create output summaries from our persistent-homology\ncalculations, and we study the persistence landscapes and images using\n$k$-means clustering and community detection. Based on our analysis of\npersistence landscapes, we find that the members of the sibling cohort have\ntopological features (specifically, their 1-dimensional loops) that are\ndistinct from the other two cohorts. From the persistence images, we are able\nto distinguish all three subject groups and to determine the brain regions in\nthe loops (with four or more edges) that allow us to make these distinctions.\n", "versions": [{"version": "v1", "created": "Sat, 22 Sep 2018 23:52:57 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 00:53:46 GMT"}, {"version": "v3", "created": "Tue, 2 Jun 2020 05:30:39 GMT"}, {"version": "v4", "created": "Tue, 25 Aug 2020 22:25:23 GMT"}], "update_date": "2020-08-27", "authors_parsed": [["Stolz", "Bernadette J.", ""], ["Emerson", "Tegan", ""], ["Nahkuri", "Satu", ""], ["Porter", "Mason A.", ""], ["Harrington", "Heather A.", ""]]}, {"id": "1809.08632", "submitter": "Linxing Jiang", "authors": "Linxing Preston Jiang, Andrea Stocco, Darby M. Losey, Justin A.\n  Abernethy, Chantel S. Prat, Rajesh P. N. Rao", "title": "BrainNet: A Multi-Person Brain-to-Brain Interface for Direct\n  Collaboration Between Brains", "comments": null, "journal-ref": null, "doi": "10.1038/s41598-019-41895-7", "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present BrainNet which, to our knowledge, is the first multi-person\nnon-invasive direct brain-to-brain interface for collaborative problem solving.\nThe interface combines electroencephalography (EEG) to record brain signals and\ntranscranial magnetic stimulation (TMS) to deliver information noninvasively to\nthe brain. The interface allows three human subjects to collaborate and solve a\ntask using direct brain-to-brain communication. Two of the three subjects are\n\"Senders\" whose brain signals are decoded using real-time EEG data analysis to\nextract decisions about whether to rotate a block in a Tetris-like game before\nit is dropped to fill a line. The Senders' decisions are transmitted via the\nInternet to the brain of a third subject, the \"Receiver,\" who cannot see the\ngame screen. The decisions are delivered to the Receiver's brain via magnetic\nstimulation of the occipital cortex. The Receiver integrates the information\nreceived and makes a decision using an EEG interface about either turning the\nblock or keeping it in the same position. A second round of the game gives the\nSenders one more chance to validate and provide feedback to the Receiver's\naction. We evaluated the performance of BrainNet in terms of (1) Group-level\nperformance during the game; (2) True/False positive rates of subjects'\ndecisions; (3) Mutual information between subjects. Five groups of three\nsubjects successfully used BrainNet to perform the Tetris task, with an average\naccuracy of 0.813. Furthermore, by varying the information reliability of the\nSenders by artificially injecting noise into one Sender's signal, we found that\nReceivers are able to learn which Sender is more reliable based solely on the\ninformation transmitted to their brains. Our results raise the possibility of\nfuture brain-to-brain interfaces that enable cooperative problem solving by\nhumans using a \"social network\" of connected brains.\n", "versions": [{"version": "v1", "created": "Sun, 23 Sep 2018 16:59:55 GMT"}, {"version": "v2", "created": "Thu, 21 Mar 2019 23:10:22 GMT"}, {"version": "v3", "created": "Wed, 22 May 2019 20:14:47 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Jiang", "Linxing Preston", ""], ["Stocco", "Andrea", ""], ["Losey", "Darby M.", ""], ["Abernethy", "Justin A.", ""], ["Prat", "Chantel S.", ""], ["Rao", "Rajesh P. N.", ""]]}, {"id": "1809.08704", "submitter": "Denis Boyer", "authors": "Denis Boyer and Gabriel Ramos-Fernandez", "title": "Contribution of social network analysis and collective phenomena to\n  understanding social complexity and cognition", "comments": "In: Di Paolo L., Di Vincenzo F., De Petrillo F. (eds) Evolution of\n  Primate Social Cognition. Interdisciplinary Evolution Research. Springer,\n  Cham (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The social brain hypothesis postulates the increasing complexity of social\ninteractions as a driving force for the evolution of cognitive abilities.\nWhereas dyadic and triadic relations play a basic role in defining social\nbehaviours and pose many challenges for the social brain, individuals in animal\nsocieties typically belong to relatively large networks. How the structure and\ndynamics of these networks also contribute to the evolution of cognition, and\nvice versa, is less understood. Here we review how collective phenomena can\noccur in systems where social agents do not require sophisticated cognitive\nskills, and how complex networks can grow from simple probabilistic rules, or\neven emerge from the interaction between agents and their environment, without\nexplicit social factors. We further show that the analysis of social networks\ncan be used to develop good indicators of social complexity beyond the\nindividual or dyadic level. We also discuss the types of challenges that the\nsocial brain must cope with in structured groups, such as higher information\nfluxes, originating from individuals playing different roles in the network, or\ndyadic contacts of widely varying durations and frequencies. We discuss the\nrelevance of these ideas for primates and other animals societies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 00:07:48 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Boyer", "Denis", ""], ["Ramos-Fernandez", "Gabriel", ""]]}, {"id": "1809.08959", "submitter": "Joaquin Goni", "authors": "Sumra Bari, Enrico Amico, Nicole Vike, Thomas M. Talavage, Joaqu\\'in\n  Go\\~ni", "title": "Uncovering Multi-Site Identifiability Based on Resting-State Functional\n  Connectomes", "comments": "28 pages, 11 figures in main text, 5 figures in supplementary", "journal-ref": "NeuroImage, 2019, Vol 202, 115967", "doi": "10.1016/j.neuroimage.2019.06.045", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-site studies are becoming important to increase statistical power,\nenhance generalizability, and to improve the likelihood of pooling relevant\nsubgroups together activities. Even with harmonized imaging sequences,\nsite-dependent variability can mask the advantages of these multi-site studies.\nThe aim of this study was to assess multi-site reproducibility in resting-state\nfunctional connectivity fingerprints, and to improve identifiability of\nfunctional connectomes. The individual fingerprinting of functional\nconnectivity profiles is promising due to its potential as a robust\nneuroimaging biomarker. We evaluated, on two independent multi-site datasets,\nindividual fingerprints in test-retest visit pairs within and across two sites\nand present a generalized framework based on principal component analysis to\nimprove identifiability. Those components that maximized differential\nidentifiability of a training dataset were used as an orthogonal connectivity\nbasis to reconstruct the functional connectomes of training and validation\nsets. The optimally reconstructed functional connectomes showed a substantial\nimprovement in individual fingerprinting within and across the two sites\nrelative to the original data. A notable increase in ICC values for functional\nedges and resting-state networks was also observed. Improvements in\nidentifiability were not found to be affected by global signal regression.\nPost-hoc analyses assessed the effect of the number of fMRI volumes on\nidentifiability and showed that multi-site differential identifiability was for\nall cases maximized after optimal reconstruction. The generalizability of the\noptimal set of orthogonal basis of each dataset was evaluated through a\nleave-one-out procedure. Overall, results demonstrate that the framework\npresented in this study systematically improves identifiability in\nresting-state functional connectomes in multi-site studies.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 14:14:32 GMT"}, {"version": "v2", "created": "Tue, 23 Apr 2019 19:06:42 GMT"}], "update_date": "2019-09-11", "authors_parsed": [["Bari", "Sumra", ""], ["Amico", "Enrico", ""], ["Vike", "Nicole", ""], ["Talavage", "Thomas M.", ""], ["Go\u00f1i", "Joaqu\u00edn", ""]]}, {"id": "1809.09321", "submitter": "Bryan Daniels", "authors": "Bryan C. Daniels, William S. Ryu, and Ilya Nemenman", "title": "Automated, predictive, and interpretable inference of C. elegans escape\n  dynamics", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": "10.1073/pnas.1816531116", "report-no": null, "categories": "q-bio.NC q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The roundworm C. elegans exhibits robust escape behavior in response to\nrapidly rising temperature. The behavior lasts for a few seconds, shows history\ndependence, involves both sensory and motor systems, and is too complicated to\nmodel mechanistically using currently available knowledge. Instead we model the\nprocess phenomenologically, and we use the Sir Isaac dynamical inference\nplatform to infer the model in a fully automated fashion directly from\nexperimental data. The inferred model requires incorporation of an unobserved\ndynamical variable, and is biologically interpretable. The model makes accurate\npredictions about the dynamics of the worm behavior, and it can be used to\ncharacterize the functional logic of the dynamical system underlying the escape\nresponse. This work illustrates the power of modern artificial intelligence to\naid in discovery of accurate and interpretable models of complex natural\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 05:15:40 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Daniels", "Bryan C.", ""], ["Ryu", "William S.", ""], ["Nemenman", "Ilya", ""]]}, {"id": "1809.09700", "submitter": "Audrey Wong-Kee-You MA", "authors": "Audrey M. B. Wong-Kee-You, John K. Tsotsos, and Scott A. Adler", "title": "Development of spatial suppression surrounding the focus of visual\n  attention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The capacity to filter out irrelevant information from our environment is\ncritical to efficient processing. Yet, during development, when building a\nknowledge base of the world is occurring, the ability to selectively allocate\nattentional resources is limited (e.g., Amso & Scerif, 2015). In adulthood,\nresearch has demonstrated that surrounding the spatial location of attentional\nfocus is a suppressive field, resulting from top-down attention promoting the\nprocessing of relevant stimuli and inhibiting surrounding distractors (e.g.,\nHopf et al., 2006). It is not fully known, however, whether this phenomenon\nmanifests in development. In the current study, we examined whether spatial\nsuppression surrounding the focus of visual attention is exhibited in\ndevelopmental age groups. Participants between 12 and 27 years of age exhibited\nspatial suppression surrounding their focus of visual attention. Their accuracy\nincreased as a function of the separation distance between a spatially cued\n(and attended) target and a second target, suggesting that a ring of\nsuppression surrounded the attended target. When a central cue was instead\npresented and therefore attention was no longer spatially cued, surround\nsuppression was not observed, indicating that our initial findings of\nsuppression were indeed related to the focus of attention. Attentional surround\nsuppression was not observed in 8- to 11-years-olds, even with a longer spatial\ncue presentation time, demonstrating that the lack of the effect at these ages\nis not due to slowed attentional feedback processes. Our findings demonstrate\nthat top-down attentional processes are still immature until approximately 12\nyears of age, and that they continue to be refined throughout adolescence,\nconverging well with previous research on attentional development.\n", "versions": [{"version": "v1", "created": "Mon, 17 Sep 2018 01:35:56 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Wong-Kee-You", "Audrey M. B.", ""], ["Tsotsos", "John K.", ""], ["Adler", "Scott A.", ""]]}, {"id": "1809.09707", "submitter": "Doo Seok Jeong", "authors": "Doo Seok Jeong", "title": "Tutorial: Neuromorphic spiking neural networks for temporal learning", "comments": "40 pages, 10 figures", "journal-ref": null, "doi": "10.1063/1.5042243", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks (SNN) as time-dependent hypotheses consisting of\nspiking nodes (neurons) and directed edges (synapses) are believed to offer\nunique solutions to reward prediction tasks and the related feedback that are\nclassified as reinforcement learning. Generally, temporal difference (TD)\nlearning renders it possible to optimize a model network to predict the delayed\nreward in an ad hoc manner. Neuromorphic SNNs--networks built using dedicated\nhardware--particularly leverage such TD learning for not only reward prediction\nbut also temporal sequence prediction in a physical time domain. In this\ntutorial, such learning in a physical time domain is referred to as temporal\nlearning to distinguish it from conventional TD learning-based methods that\ngenerally involve algorithmic (rather than physical) time. This tutorial\naddresses neuromorphic SNNs for temporal learning from the scratch. It first\nconcerns general characteristics of SNNs including spiking neurons and\ninformation coding schemes and then moves on to temporal learning including its\ngeneral concept, feasible algorithms, and their association with\nneurophysiological learning rules that have intensively been enriched for the\nlast few decades.\n", "versions": [{"version": "v1", "created": "Tue, 11 Sep 2018 06:32:42 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Jeong", "Doo Seok", ""]]}, {"id": "1809.09757", "submitter": "Joaquin Goni", "authors": "Diana O. Svaldi, Joaqu\\'in Go\\~ni, Apoorva Bharthur Sanjay, Enrico\n  Amico, Shannon L. Risacher, John D. West, Mario Dzemidzic, Andrew Saykin,\n  Liana Apostolova", "title": "Towards Subject and Diagnostic Identifiability in the Alzheimer's\n  Disease Spectrum based on Functional Connectomes", "comments": "8 pages, 3 tables, 3 figures", "journal-ref": "In: Stoyanov D. et al. (eds) Graphs in Biomedical Image Analysis\n  and Integrating Medical Imaging and Non-Imaging Modalities. GRAIL 2018,\n  Beyond MIC 2018. Lecture Notes in Computer Science, vol 11044. Springer, Cham", "doi": "10.1007/978-3-030-00689-1_8", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease (AD) is the only major cause of mortality in the world\nwithout an effective disease modifying treatment. Evidence supporting the so\ncalled disconnection hypothesis suggests that functional connectivity\nbiomarkers may have clinical potential for early detection of AD. However,\nknown issues with low test-retest reliability and signal to noise in functional\nconnectivity may prevent accuracy and subsequent predictive capacity. We\nvalidate the utility of a novel principal component based diagnostic\nidentifiability framework to increase separation in functional connectivity\nacross the Alzheimer's spectrum by identifying and reconstructing FC using only\nAD sensitive components or connectivity modes. We show that this framework (1)\nincreases test-retest correspondence and (2) allows for better separation, in\nfunctional connectivity, of diagnostic groups both at the whole brain and\nindividual resting state network level. Finally, we evaluate a posteriori the\nassociation between connectivity mode weights with longitudinal neurocognitive\noutcomes.\n", "versions": [{"version": "v1", "created": "Tue, 25 Sep 2018 23:28:32 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Svaldi", "Diana O.", ""], ["Go\u00f1i", "Joaqu\u00edn", ""], ["Sanjay", "Apoorva Bharthur", ""], ["Amico", "Enrico", ""], ["Risacher", "Shannon L.", ""], ["West", "John D.", ""], ["Dzemidzic", "Mario", ""], ["Saykin", "Andrew", ""], ["Apostolova", "Liana", ""]]}, {"id": "1809.09943", "submitter": "Paulo Aguiar", "authors": "Kristine Heiney, Jos\\'e Mateus, C\\'atia Lopes, Estrela Neto, Meriem\n  Lamghari, Paulo Aguiar", "title": "{\\mu}SpikeHunter: An advanced computational tool for the analysis of\n  neuronal communication and action potential propagation in microfluidic\n  platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding neuronal communication is fundamental in neuroscience but there\nare few methodologies offering detailed analysis for well-controlled\nconditions. By interfacing microElectrode arrays with microFluidics ({\\mu}EF\ndevices), it is possible to compartmentalize neuronal cultures with a specified\nalignment of axons and microelectrodes. This setup allows extracellular\nrecordings of spike propagation with high signal-to-noise ratio over the course\nof several weeks. Addressing these {\\mu}EF systems we developed an advanced,\nyet easy-to-use, open-source computational tool, {\\mu}SpikeHunter, which\nprovides detailed quantification of several communication-related properties\nsuch as propagation velocity, conduction failure, spike timings, and coding\nmechanisms. The combination of {\\mu}EF devices and {\\mu}SpikeHunter can be used\nin the context of standard neuronal cultures or with co-culture configurations\nwhere, for example, communication between sensory neurons and other cell types\nis monitored and assessed. The ability to analyze axonal signals (in a\nuser-friendly, time-efficient, high-throughput manner) opens doors to new\napproaches to studies of peripheral innervation, neural coding, and\nneuroregeneration approaches, among many others. We demonstrate the use of\n{\\mu}SpikeHunter in dorsal root ganglion neurons where we analyze the presence\nof anterograde signals in {\\mu}EF devices.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 12:42:26 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Heiney", "Kristine", ""], ["Mateus", "Jos\u00e9", ""], ["Lopes", "C\u00e1tia", ""], ["Neto", "Estrela", ""], ["Lamghari", "Meriem", ""], ["Aguiar", "Paulo", ""]]}, {"id": "1809.10024", "submitter": "Russell Poldrack", "authors": "Russell A. Poldrack, Krzysztof J. Gorgolewski, and Gael Varoquaux", "title": "Computational and informatics advances for reproducible data analysis in\n  neuroimaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reproducibility of scientific research has become a point of critical\nconcern. We argue that openness and transparency are critical for\nreproducibility, and we outline an ecosystem for open and transparent science\nthat has emerged within the human neuroimaging community. We discuss the range\nof open data sharing resources that have been developed for neuroimaging data,\nand the role of data standards (particularly the Brain Imaging Data Structure)\nin enabling the automated sharing, processing, and reuse of large neuroimaging\ndatasets. We outline how the open-source Python language has provided the basis\nfor a data science platform that enables reproducible data analysis and\nvisualization. We also discuss how new advances in software engineering, such\nas containerization, provide the basis for greater reproducibility in data\nanalysis. The emergence of this new ecosystem provides an example for many\nareas of science that are currently struggling with reproducibility.\n", "versions": [{"version": "v1", "created": "Mon, 24 Sep 2018 19:23:28 GMT"}], "update_date": "2018-09-27", "authors_parsed": [["Poldrack", "Russell A.", ""], ["Gorgolewski", "Krzysztof J.", ""], ["Varoquaux", "Gael", ""]]}, {"id": "1809.10301", "submitter": "Aline Amabile Viol Barbosa", "authors": "A. Viol, Fernanda Palhano-Fontes, Heloisa Onias, Draulio B. de Araujo,\n  Philipp H\\\"ovel and G. M. Viswanathan", "title": "Characterizing complex networks using Entropy-degree diagrams: unveiling\n  changes in functional brain connectivity induced by Ayahuasca", "comments": null, "journal-ref": null, "doi": "10.3390/e21020128", "report-no": null, "categories": "q-bio.NC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open problems abound in the theory of complex networks, which has found\nsuccessful application to diverse fields of science. With the aim of further\nadvancing the understanding of the brain's functional connectivity, we propose\nto evaluate a network metric which we term the geodesic entropy. This entropy,\nin a way that can be made precise, quantifies the Shannon entropy of the\ndistance distribution to a specific node from all other nodes. Measurements of\ngeodesic entropy allow for the characterization of the structural information\nof a network that takes into account the distinct role of each node into the\nnetwork topology. The measurement and characterization of this structural\ninformation has the potential to greatly improve our understanding of sustained\nactivity and other emergent behaviors in networks, such as self-organized\ncriticality sometimes seen in such contexts. We apply these concepts and\nmethods to study the effects of how the psychedelic Ayahuasca affects the\nfunctional connectivity of the human brain. We show that the geodesic entropy\nis able to differentiate the functional networks of the human brain in two\ndifferent states of consciousness in the resting state: (i) the ordinary waking\nstate and (ii) a state altered by ingestion of the Ayahuasca. The entropy of\nthe nodes of brain networks from subjects under the influence of Ayahuasca\ndiverge significantly from those of the ordinary waking state. The functional\nbrain networks from subjects in the altered state have, on average, a larger\ngeodesic entropy compared to the ordinary state. We conclude that geodesic\nentropy is a useful tool for analyzing complex networks and discuss how and why\nit may bring even further valuable insights into the study of the human brain\nand other empirical networks.\n", "versions": [{"version": "v1", "created": "Wed, 26 Sep 2018 07:04:50 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Viol", "A.", ""], ["Palhano-Fontes", "Fernanda", ""], ["Onias", "Heloisa", ""], ["de Araujo", "Draulio B.", ""], ["H\u00f6vel", "Philipp", ""], ["Viswanathan", "G. M.", ""]]}, {"id": "1809.10504", "submitter": "Alexander Ecker", "authors": "Alexander S. Ecker, Fabian H. Sinz, Emmanouil Froudarakis, Paul G.\n  Fahey, Santiago A. Cadena, Edgar Y. Walker, Erick Cobos, Jacob Reimer,\n  Andreas S. Tolias, Matthias Bethge", "title": "A rotation-equivariant convolutional neural network model of primary\n  visual cortex", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical models describe primary visual cortex (V1) as a filter bank of\norientation-selective linear-nonlinear (LN) or energy models, but these models\nfail to predict neural responses to natural stimuli accurately. Recent work\nshows that models based on convolutional neural networks (CNNs) lead to much\nmore accurate predictions, but it remains unclear which features are extracted\nby V1 neurons beyond orientation selectivity and phase invariance. Here we work\ntowards systematically studying V1 computations by categorizing neurons into\ngroups that perform similar computations. We present a framework to identify\ncommon features independent of individual neurons' orientation selectivity by\nusing a rotation-equivariant convolutional neural network, which automatically\nextracts every feature at multiple different orientations. We fit this model to\nresponses of a population of 6000 neurons to natural images recorded in mouse\nprimary visual cortex using two-photon imaging. We show that our\nrotation-equivariant network not only outperforms a regular CNN with the same\nnumber of feature maps, but also reveals a number of common features shared by\nmany V1 neurons, which deviate from the typical textbook idea of V1 as a bank\nof Gabor filters. Our findings are a first step towards a powerful new tool to\nstudy the nonlinear computations in V1.\n", "versions": [{"version": "v1", "created": "Thu, 27 Sep 2018 13:16:37 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Ecker", "Alexander S.", ""], ["Sinz", "Fabian H.", ""], ["Froudarakis", "Emmanouil", ""], ["Fahey", "Paul G.", ""], ["Cadena", "Santiago A.", ""], ["Walker", "Edgar Y.", ""], ["Cobos", "Erick", ""], ["Reimer", "Jacob", ""], ["Tolias", "Andreas S.", ""], ["Bethge", "Matthias", ""]]}, {"id": "1809.11098", "submitter": "Ixavier Higgins", "authors": "Ixavier A Higgins, Ying Guo, Suprateek Kundu, Ki Sueng Choi, Helen\n  Mayberg", "title": "A Differential Degree Test for Comparing Brain Networks", "comments": "35 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, graph theory has become a popular method for characterizing brain\nfunctional organization. One important goal in graph theoretical analysis of\nbrain networks is to identify network differences across disease types or\nconditions. Typical approaches include massive univariate testing of each edge\nor comparisons of local and/or global network metrics to identify deviations in\ntopological organization. Some limitations of these methods include low\nstatistical power due to the large number of comparisons and difficulty\nattributing overall differences in networks to local variations in brain\nfunction. We propose a novel differential degree test (DDT) to identify brain\nregions incident to a large number of differentially weighted edges across two\npopulations. The proposed test could help detect key brain locations involved\nin diseases by demonstrating significantly altered neural connections. We\nachieve this by generating an appropriate set of null networks which are\nmatched on the first and second moments of the observed difference network\nusing the Hirschberger-Qi-Steuer (HQS) algorithm. This formulation permits\nseparation of the network's true topology from the nuisance topology which is\ninduced by the correlation measure and may drive inter-regional connectivity in\nways unrelated to the brain function. Simulations indicate that the proposed\napproach routinely outperforms competing methods in detecting differentially\nconnected regions of interest. Furthermore, we propose a data-adaptive\nthreshold selection procedure which is able to detect differentially weighted\nedges and is shown to outperform competing methods that perform edge-wise\ncomparisons controlling for the error rate. An application of our method to a\nmajor depressive disorder dataset leads to the identification of brain regions\nin the default mode network commonly implicated in this ruminative disorder.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 15:43:49 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Higgins", "Ixavier A", ""], ["Guo", "Ying", ""], ["Kundu", "Suprateek", ""], ["Choi", "Ki Sueng", ""], ["Mayberg", "Helen", ""]]}, {"id": "1809.11167", "submitter": "Weishun Zhong", "authors": "Weishun Zhong, Zhiyue Lu, David J Schwab, Arvind Murugan", "title": "Non-equilibrium statistical mechanics of continuous attractors", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous attractors have been used to understand recent neuroscience\nexperiments where persistent activity patterns encode internal representations\nof external attributes like head direction or spatial location. However, the\nconditions under which the emergent bump of neural activity in such networks\ncan be manipulated by space and time-dependent external sensory or motor\nsignals are not understood. Here, we find fundamental limits on how rapidly\ninternal representations encoded along continuous attractors can be updated by\nan external signal. We apply these results to place cell networks to derive a\nvelocity-dependent non-equilibrium memory capacity in neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2018 17:56:42 GMT"}, {"version": "v2", "created": "Sun, 30 Dec 2018 17:21:56 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Zhong", "Weishun", ""], ["Lu", "Zhiyue", ""], ["Schwab", "David J", ""], ["Murugan", "Arvind", ""]]}]