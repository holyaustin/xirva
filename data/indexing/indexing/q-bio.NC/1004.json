[{"id": "1004.0973", "submitter": "Lech S. Borkowski", "authors": "L. S. Borkowski", "title": "Response of a Hodgkin-Huxley neuron to a high-frequency input", "comments": "7 pages, 11 figures", "journal-ref": "Physical Review E 80, 051914 (2009)", "doi": "10.1103/PhysRevE.80.051914", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the response of a Hodgkin-Huxley neuron stimulated by a periodic\nsequence of conductance pulses arriving through the synapse in the high\nfrequency regime. In addition to the usual excitation threshold there is a\nsmooth crossover from the firing to the silent regime for increasing pulse\namplitude $g_{syn}$. The amplitude of the voltage spikes decreases\napproximately linearly with $g_{syn}$. In some regions of parameter space the\nresponse is irregular, probably chaotic. In the chaotic regime between the\nmode-locked regions 3:1 and 2:1 near the lower excitation threshold the output\ninterspike interval histogram (ISIH) undergoes a sharp transition. If the\ndriving period is below the critical value, $T_i < T^*$, the output histogram\ncontains only odd multiples of $T_i$. For $T_i > T^*$ even multiples of $T_i$\nalso appear in the histogram, starting from the largest values. Near $T^*$ the\nISIH scales logarithmically on both sides of the transition. The coefficient of\nvariation of ISIH has a cusp singularity at $T^*$. The average response period\nhas a maximum slightly above $T^*$. Near the excitation threshold in the\nchaotic regime the average firing rate rises sublinearly from frequencies of\norder 1 Hz.\n", "versions": [{"version": "v1", "created": "Tue, 6 Apr 2010 21:00:57 GMT"}], "update_date": "2010-04-08", "authors_parsed": [["Borkowski", "L. S.", ""]]}, {"id": "1004.2009", "submitter": "Suhita Nadkarni", "authors": "Suhita Nadkarni, Thomas Bartol, Terrence Sejnowski and Herbert Levine", "title": "Spatial and Temporal Correlates of Vesicular Release at Hippocampal\n  Synapses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a spatially explicit biophysical model of the hippocampal CA3-CA1\npresynaptic bouton to study local calcium dynamics leading to vesicle fusion. A\nkinetic model with two calcium sensors is formulated specifically for the\nCA3-CA1 synapse. The model includes a sensor for fast synchronous release that\nlasts a few tens of milliseconds and a sensor for slow asynchronous release\nthat lasts a few hundred milliseconds. We show that a variety of extant data on\nCA3-CA1 synapse can be accounted for consistently only when a refractory period\nof the order of few milliseconds between releases is introduced. Including a\nsecond sensor for asynchronous release that has a slow unbinding site and\ntherefore an embedded long memory, is shown to play a role in short-term\nplasticity by facilitating release. For synchronous release mediated by\nSynaptotagmin II a third time scale is revealed in addition to the fast and\nslow release. This third time scale corresponds to \"stimulus-correlated\nsuper-fast\" neurotransmitter release. Our detailed spatial simulation indicates\nthat all three-time scales of neurotransmitter release are an emergent property\nof the calcium sensor and independent of synaptic ultrastructure. Furthermore,\nit allows us to identify features of synaptic transmission that are universal\nand those that are modulated by structure.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2010 17:23:43 GMT"}], "update_date": "2010-05-02", "authors_parsed": [["Nadkarni", "Suhita", ""], ["Bartol", "Thomas", ""], ["Sejnowski", "Terrence", ""], ["Levine", "Herbert", ""]]}, {"id": "1004.2072", "submitter": "Vadas Gintautas", "authors": "Michael I. Ham, Vadas Gintautas, Guenter W. Gross", "title": "Spontaneous coordinated activity in cultured networks: Analysis of\n  multiple ignition sites, primary circuits, burst phase delay distributions\n  and functional structures", "comments": "4 pages, 3 figures. Presented at 6th International Meeting on\n  Substrate-Integrated Micro Electrode Arrays in Reutlingen in July 2008.", "journal-ref": "Published in 6th International Meeting on Substrate-Integrated\n  Micro Electrode Arrays, 2008.", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All higher order central nervous systems exhibit spontaneous neural activity,\nthough the purpose and mechanistic origin of such activity remains poorly\nunderstood. We explore the ignition and spread of collective spontaneous\nelectrophysiological burst activity in networks of cultured cortical neurons\ngrowing on microelectrode arrays using information theory and\nfirst-spike-in-burst analysis methods. We show the presence of burst leader\nneurons, which form a mono-synaptically connected primary circuit, and initiate\na majority of network bursts. Leader/follower firing delay times form\ntemporally stable positively skewed distributions. Blocking inhibitory synapses\nusually results in shorter delay times with reduced variance. These\ndistributions are generalized characterizations of internal network dynamics\nand provide estimates of pair-wise synaptic distances. We show that mutual\ninformation between neural nodes is a function of distance, which is maintained\nunder disinhibition. The resulting analysis produces specific quantitative\nconstraints and insights into the activation patterns of collective neuronal\nactivity in self-organized cortical networks, which may prove useful for models\nemulating spontaneously active systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Apr 2010 22:23:15 GMT"}], "update_date": "2010-04-14", "authors_parsed": [["Ham", "Michael I.", ""], ["Gintautas", "Vadas", ""], ["Gross", "Guenter W.", ""]]}, {"id": "1004.2280", "submitter": "Robert Burger PhD", "authors": "John Robert Burger", "title": "XOR at a Single Vertex -- Artificial Dendrites", "comments": "Edited for clarity; added Kandel reference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New to neuroscience with implications for AI, the exclusive OR, or any other\nBoolean gate may be biologically accomplished within a single region where\nactive dendrites merge. This is demonstrated below using dynamic circuit\nanalysis. Medical knowledge aside, this observation points to the possibility\nof specially coated conductors to accomplish artificial dendrites.\n", "versions": [{"version": "v1", "created": "Tue, 13 Apr 2010 22:12:22 GMT"}, {"version": "v2", "created": "Thu, 23 Sep 2010 16:27:39 GMT"}], "update_date": "2010-09-24", "authors_parsed": [["Burger", "John Robert", ""]]}, {"id": "1004.2515", "submitter": "Paul Williams", "authors": "Paul L. Williams and Randall D. Beer", "title": "Nonnegative Decomposition of Multivariate Information", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math-ph math.IT math.MP physics.bio-ph physics.data-an q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Of the various attempts to generalize information theory to multiple\nvariables, the most widely utilized, interaction information, suffers from the\nproblem that it is sometimes negative. Here we reconsider from first principles\nthe general structure of the information that a set of sources provides about a\ngiven variable. We begin with a new definition of redundancy as the minimum\ninformation that any source provides about each possible outcome of the\nvariable, averaged over all possible outcomes. We then show how this measure of\nredundancy induces a lattice over sets of sources that clarifies the general\nstructure of multivariate information. Finally, we use this redundancy lattice\nto propose a definition of partial information atoms that exhaustively\ndecompose the Shannon information in a multivariate system in terms of the\nredundancy between synergies of subsets of the sources. Unlike interaction\ninformation, the atoms of our partial information decomposition are never\nnegative and always support a clear interpretation as informational quantities.\nOur analysis also demonstrates how the negativity of interaction information\ncan be explained by its confounding of redundancy and synergy.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2010 22:12:52 GMT"}], "update_date": "2010-04-16", "authors_parsed": [["Williams", "Paul L.", ""], ["Beer", "Randall D.", ""]]}, {"id": "1004.2787", "submitter": "Cyrille Zbinden", "authors": "Cyrille Zbinden", "title": "Leader neurons in leaky integrate and fire neural network simulations", "comments": "25 pages, 13 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several experimental studies show the existence of leader neurons in\npopulation bursts of 2D living neural networks. A leader neuron is, basically,\na neuron which fires at the beginning of a burst (respectively network spike)\nmore often that we expect by looking at its whole mean neural activity. This\nmeans that leader neurons have some burst triggering power beyond a simple\nstatistical effect. In this study, we characterize these leader neuron\nproperties. This naturally leads us to simulate neural 2D networks. To build\nour simulations, we choose the leaky integrate and fire (lIF) neuron model. Our\nlIF model has got stable leader neurons in the burst population that we\nsimulate. These leader neurons are excitatory neurons and have a low membrane\npotential firing threshold. Except for these two first properties, the\nconditions required for a neuron to be a leader neuron are difficult to\nidentify and seem to depend on several parameters involved in the simulations\nthemself. However, a detailed linear analysis shows a trend of the properties\nrequired for a neuron to be a leader neuron. Our main finding is: A leader\nneuron sends a signal to many excitatory neurons as well as to a few inhibitory\nneurons and a leader neuron receives only a few signals from other excitatory\nneurons. Our linear analysis exhibits five essential properties for leader\nneurons with relative importance. This means that considering a given neural\nnetwork with a fixed mean number of connections per neuron, our analysis gives\nus a way of predicting which neuron can be a good leader neuron and which\ncannot. Our prediction formula gives us a good statistical prediction even if,\nconsidering a single given neuron, the success rate does not reach hundred\npercent.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2010 08:48:40 GMT"}], "update_date": "2010-04-19", "authors_parsed": [["Zbinden", "Cyrille", ""]]}, {"id": "1004.3476", "submitter": "Cosma Rohilla Shalizi", "authors": "Shinsuke Koyama, Lucia Castellanos P\\'erez-Bolde, Cosma Rohilla\n  Shalizi, Robert E. Kass", "title": "Approximate Methods for State-Space Models", "comments": "31 pages, 4 figures. Different pagination from journal version due to\n  incompatible style files but same content; the supplemental file for the\n  journal appears here as appendices B--E.", "journal-ref": "Journal of the American Statistical Association, volume 105, 2010,\n  pp. 170--180", "doi": "10.1198/jasa.2009.tm08326", "report-no": null, "categories": "stat.ME physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-space models provide an important body of techniques for analyzing\ntime-series, but their use requires estimating unobserved states. The optimal\nestimate of the state is its conditional expectation given the observation\nhistories, and computing this expectation is hard when there are\nnonlinearities. Existing filtering methods, including sequential Monte Carlo,\ntend to be either inaccurate or slow. In this paper, we study a nonlinear\nfilter for nonlinear/non-Gaussian state-space models, which uses Laplace's\nmethod, an asymptotic series expansion, to approximate the state's conditional\nmean and variance, together with a Gaussian conditional distribution. This {\\em\nLaplace-Gaussian filter} (LGF) gives fast, recursive, deterministic state\nestimates, with an error which is set by the stochastic characteristics of the\nmodel and is, we show, stable over time. We illustrate the estimation ability\nof the LGF by applying it to the problem of neural decoding and compare it to\nsequential Monte Carlo both in simulations and with real data. We find that the\nLGF can deliver superior results in a small fraction of the computing time.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2010 15:19:45 GMT"}], "update_date": "2010-04-21", "authors_parsed": [["Koyama", "Shinsuke", ""], ["P\u00e9rez-Bolde", "Lucia Castellanos", ""], ["Shalizi", "Cosma Rohilla", ""], ["Kass", "Robert E.", ""]]}, {"id": "1004.3598", "submitter": "Mikhail Simkin", "authors": "M.V. Simkin and V.P. Roychowdhury", "title": "An explanation of the distribution of inter-seizure intervals", "comments": null, "journal-ref": "EPL 91 (2010) 58005", "doi": "10.1209/0295-5075/91/58005", "report-no": null, "categories": "q-bio.NC math.PR physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Osorio et al (Eur. J. Neurosci., 30 (2009) 1554) reported that\nprobability distribution of intervals between successive epileptic seizures\nfollows a power law with exponent 1.5. We theoretically explain this finding by\nmodeling epileptic activity as a branching process, which we in turn\napproximate by a random walk. We confirm the theoretical conclusion by\nnumerical simulation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2010 23:22:56 GMT"}, {"version": "v2", "created": "Thu, 23 Sep 2010 18:34:15 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Simkin", "M. V.", ""], ["Roychowdhury", "V. P.", ""]]}, {"id": "1004.4031", "submitter": "Rhonda Dzakpasu", "authors": "Xin Chen and Rhonda Dzakpasu", "title": "Observed network dynamics from altering the balance between excitatory\n  and inhibitory neurons in cultured networks", "comments": null, "journal-ref": "Phys Rev E, 82, 031907 (2010)", "doi": "10.1103/PhysRevE.82.031907", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complexity in the temporal organization of neural systems may be a reflection\nof the diversity of its neural constituents. These constituents, excitatory and\ninhibitory neurons, comprise an invariant ratio in vivo and form the substrate\nfor rhythmic oscillatory activity. To begin to elucidate the dynamical\nmechanisms that underlie this balance, we construct novel neural circuits not\nordinarily found in nature. We culture several networks of neurons composed of\nexcitatory and inhibitory cells and use a multi-electrode array to study their\ntemporal dynamics as the balance is modulated. We use the electrode burst as\nthe temporal imprimatur to signify the presence of network activity. Burst\ndurations, inter-burst intervals, and the number of spikes participating within\na burst are used to illustrate the vivid dynamical differences between the\nvarious cultured networks. When the network consists largely of excitatory\nneurons, no network temporal structure is apparent. However, the addition of\ninhibitory neurons evokes a temporal order. Calculation of the temporal\nautocorrelation shows that when the number of inhibitory neurons is a major\nfraction of the network, a striking network pattern materializes when none was\npreviously present.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2010 00:21:19 GMT"}, {"version": "v2", "created": "Wed, 8 Sep 2010 02:13:27 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Chen", "Xin", ""], ["Dzakpasu", "Rhonda", ""]]}, {"id": "1004.4322", "submitter": "Lester Ingber", "authors": "Lester Ingber and Paul L. Nunez", "title": "Neocortical Dynamics at Multiple Scales: EEG Standing Waves, Statistical\n  Mechanics, and Physical Analogs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamic behavior of scalp potentials (EEG) is apparently due to some\ncombination of global and local processes with important top-down and bottom-up\ninteractions across spatial scales. In treating global mechanisms, we stress\nthe importance of myelinated axon propagation delays and periodic boundary\nconditions in the cortical-white matter system, which is topologically close to\na spherical shell. By contrast, the proposed local mechanisms are multiscale\ninteractions between cortical columns via short-ranged non-myelinated fibers. A\nmechanical model consisting of a stretched string with attached nonlinear\nsprings demonstrates the general idea. The string produces standing waves\nanalogous to large-scale coherence EEG observed in some brain states. The\nattached springs are analogous to the smaller (mesoscopic) scale columnar\ndynamics. Generally, we expect string displacement and EEG at all scales to\nresult from both global and local phenomena. A statistical mechanics of\nneocortical interactions (SMNI) calculates oscillatory behavior consistent with\ntypical EEG, within columns, between neighboring columns via short-ranged\nnon-myelinated fibers, across cortical regions via myelinated fibers, and also\nderive a string equation consistent with the global EEG model.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2010 03:54:00 GMT"}], "update_date": "2010-04-27", "authors_parsed": [["Ingber", "Lester", ""], ["Nunez", "Paul L.", ""]]}, {"id": "1004.5060", "submitter": "Areejit Samal", "authors": "Quansheng Ren, Kiran M. Kolwankar, Areejit Samal, J\\\"urgen Jost", "title": "STDP-driven networks and the \\emph{C. elegans} neuronal network", "comments": "16 pages, 14 figures", "journal-ref": null, "doi": "10.1016/j.physa.2010.05.018", "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the dynamics of the structure of a formal neural network wherein the\nstrengths of the synapses are governed by spike-timing-dependent plasticity\n(STDP). For properly chosen input signals, there exists a steady state with a\nresidual network. We compare the motif profile of such a network with that of a\nreal neural network of \\emph{C. elegans} and identify robust qualitative\nsimilarities. In particular, our extensive numerical simulations show that this\nSTDP-driven resulting network is robust under variations of the model\nparameters.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2010 15:21:37 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Ren", "Quansheng", ""], ["Kolwankar", "Kiran M.", ""], ["Samal", "Areejit", ""], ["Jost", "J\u00fcrgen", ""]]}]