[{"id": "0804.0008", "submitter": "Dante Chialvo", "authors": "Dante R. Chialvo", "title": "Emergent complexity: what uphill analysis or downhill invention can not\n  do", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In these notes we review emergent phenomena in complex systems, emphasizing\nways to identify potential underlying universal mechanisms that generates\ncomplexity. The discussion is centered around the emergence of collective\nbehavior in dynamical systems when they are poised near a critical point of a\nphase transition, either by tuning or by self-organization. We then argue the\nrationale for our proposal that the brain is naturally poised near criticality\nreviewing recent results as well as the implications of this view of the\nfunctioning brain.\n", "versions": [{"version": "v1", "created": "Mon, 31 Mar 2008 20:00:54 GMT"}], "update_date": "2008-04-02", "authors_parsed": [["Chialvo", "Dante R.", ""]]}, {"id": "0804.0032", "submitter": "Dante Chialvo", "authors": "Dante R. Chialvo, Pablo Balenzuela, Daniel Fraiman", "title": "The brain: What is critical about it?", "comments": "Proceedings of BIOCOMP2007 - Collective Dynamics: Topics on\n  Competition and Cooperation in the Biosciences. Vietri sul Mare, Italy (2007)", "journal-ref": null, "doi": "10.1063/1.2965095", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review the recent proposal that the most fascinating brain properties are\nrelated to the fact that it always stays close to a second order phase\ntransition. In such conditions, the collective of neuronal groups can reliably\ngenerate robust and flexible behavior, because it is known that at the critical\npoint there is the largest abundance of metastable states to choose from. Here\nwe review the motivation, arguments and recent results, as well as further\nimplications of this view of the functioning brain.\n", "versions": [{"version": "v1", "created": "Mon, 31 Mar 2008 21:36:51 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Chialvo", "Dante R.", ""], ["Balenzuela", "Pablo", ""], ["Fraiman", "Daniel", ""]]}, {"id": "0804.0190", "submitter": "Usha Devi A. R.", "authors": "Ramakrishna Chakravarthi, A. K. Rajagopal and A. R. Usha Devi", "title": "Quantum Mechanical Basis of Vision", "comments": "5 pages, no figures; submitted for publication in the Proceedings of\n  the India-US Workshop on Science and Technology at the Nabo-Bio Interface,\n  Bhubaneswar, India held during February 19-22, 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two striking components of retina, i.e., the light sensitive neural layer\nin the eye, by which it responds to light are (the three types of) color\nsensitive Cones and color insensitive Rods (which outnumber the cones 20:1).\nThe interaction between electromagnetic radiation and these photoreceptors\n(causing transitions between cis- and trans- states of rhodopsin molecules in\nthe latter) offers a prime example of physical processes at the nano-bio\ninterface. After a brief review of the basic facts about vision, we propose a\nquantum mechanical model (paralleling the Jaynes-Cummings model (JCM) of\ninteraction of light with matter) of early vision describing the interaction of\nlight with the two states of rhodopsin mentioned above. Here we model the early\nessential steps in vision incorporating, separately, the two well-known\nfeatures of retinal transduction (converting light to neural signals): small\nnumbers of cones respond to bright light (large number of photons) and large\nnumbers of rods respond to faint light (small number of photons) with an\namplification scheme. An outline of the method of solution of these respective\nmodels based on quantum density matrix is also indicated. This includes a brief\noverview of the theory, based on JCM, of signal amplification required for the\nperception of faint light. We envision this methodology, which brings a novel\nquantum approach to modeling neural activity, to be a useful paradigm in\ndeveloping a better understanding of key visual processes than is possible with\ncurrently available models that completely ignore quantum effects at the\nrelevant neural level.\n", "versions": [{"version": "v1", "created": "Tue, 1 Apr 2008 14:55:34 GMT"}], "update_date": "2008-04-02", "authors_parsed": [["Chakravarthi", "Ramakrishna", ""], ["Rajagopal", "A. K.", ""], ["Devi", "A. R. Usha", ""]]}, {"id": "0804.0759", "submitter": "Matthias Keil", "authors": "Matthias S. Keil", "title": "Does Face Image Statistics Predict a Preferred Spatial Frequency for\n  Human Face Processing?", "comments": "6 pages, 11 figures, submitted to a peer-reviewed journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Psychophysical experiments suggested a relative importance of a narrow band\nof spatial frequencies for recognition of face identity in humans. There\nexists, however, no conclusive evidence of why it is that such frequencies are\npreferred. To address this question, I examined the amplitude spectra of a\nlarge number of face images, and observed that face spectra generally fall off\nsteeper with spatial frequency compared to ordinary natural images. When\nexternal face features (like hair) are suppressed, then whitening of the\ncorresponding mean amplitude spectra revealed higher response amplitudes at\nthose spatial frequencies which are deemed important for processing face\nidentity. The results presented here therefore provide support for that face\nprocessing characteristics match corresponding stimulus properties.\n", "versions": [{"version": "v1", "created": "Fri, 4 Apr 2008 15:33:48 GMT"}], "update_date": "2008-04-07", "authors_parsed": [["Keil", "Matthias S.", ""]]}, {"id": "0804.0829", "submitter": "Jozsi Jalics", "authors": "Jozsi Jalics, Martin Krupa, Horacio G. Rotstein", "title": "A novel canard-based mechanism for mixed-mode oscillations in a neuronal\n  model", "comments": "46 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a biophysical model of a neuron from the entorhinal cortex that\nincludes persistent sodium and slow potassium as non-standard currents using\nreduction of dimension and dynamical systems techniques to determine the\nmechanisms for the generation of mixed-mode oscillations. We have found that\nthe standard spiking currents (sodium and potassium) play a critical role in\nthe analysis of the interspike interval. To study the mixed-mode oscillations,\nthe six dimensional model has been reduced to a three dimensional model for the\nsubthreshold regime. Additional transformations and a truncation have led to a\nsimplified model system with three timescales that retains many properties of\nthe original equations, and we employ this system to elucidate the underlying\nstructure and explain a novel mechanism for the generation of mixed-mode\noscillations based on the canard phenomenon. In particular, we prove the\nexistence of a special solution, a singular primary canard, that serves as a\ntransition between mixed-mode oscillations and spiking in the singular limit by\nemploying appropriate rescalings, center manifold reductions, and energy\narguments. Additionally, we conjecture that the singular canard solution is the\nlimit of a family of canards and provide numerical evidence for the conjecture.\n", "versions": [{"version": "v1", "created": "Sat, 5 Apr 2008 01:40:45 GMT"}], "update_date": "2008-04-08", "authors_parsed": [["Jalics", "Jozsi", ""], ["Krupa", "Martin", ""], ["Rotstein", "Horacio G.", ""]]}, {"id": "0804.0838", "submitter": "Dmitry Tsigankov", "authors": "Dmitry Tsigankov and Alexei Koulakov", "title": "Optimal axonal and dendritic branching strategies during the development\n  of neural circuitry", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In developing brain, axons and dendrites are capable of connecting to each\nother with high precision. Recent advances in imaging have allowed for the\nmonitoring of axonal, dendritic, and synapse dynamics in vivo. It is observed\nthat the majority of axonal and dendritic branches are formed 'in error', only\nto be retracted later. The functional significance of the overproduction of\nbranches is not clear. In this study, we use a computational model to\ninvestigate the speed and efficiency of different branching strategies. We show\nthat branching itself allows for substantial acceleration in the identification\nof appropriate targets through the use of a parallel search. We also show that\nthe formation of new branches in the vicinity of existing synapses leads to the\nformation of target connectivity with a decreased number of erroneous branches.\nThis finding allows us to explain the high correlation between the branch\npoints and synapses observed in the Xenopus laevis retinotectal system. We also\nsuggest that the most efficient branching rule is different for axons and\ndendrites. The optimal axonal strategy is to form new branches in the vicinity\nof existing synapses, whereas the optimal rule for dendrites is to form new\nbranches preferentially in the vicinity of synapses with correlated pre- and\npostsynaptic electric activity. Thus, our studies suggest that the developing\nneural system employs a set of sophisticated computational strategies that\nfacilitate the formation of required circuitry, so that it may proceed in the\nfastest and most frugal way.\n", "versions": [{"version": "v1", "created": "Sat, 5 Apr 2008 05:02:29 GMT"}], "update_date": "2008-04-08", "authors_parsed": [["Tsigankov", "Dmitry", ""], ["Koulakov", "Alexei", ""]]}, {"id": "0804.1306", "submitter": "Claudius Gros", "authors": "Claudius Gros and Gregor Kaczor", "title": "Learning in cognitive systems with autonomous dynamics", "comments": null, "journal-ref": "Proceedings of the 2008 International Conference on Cognitive\n  Systems, Karlsruhe", "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The activity patterns of highly developed cognitive systems like the human\nbrain are dominated by autonomous dynamical processes, that is by a\nself-sustained activity which would be present even in the absence of external\nsensory stimuli.\n  During normal operation the continuous influx of external stimuli could\ntherefore be completely unrelated to the patterns generated internally by the\nautonomous dynamical process. Learning of spurious correlations between\nexternal stimuli and autonomously generated internal activity states needs\ntherefore to be avoided.\n  We study this problem within the paradigm of transient state dynamics for the\ninternal activity, that is for an autonomous activity characterized by a\ninfinite time-series of transiently stable attractor states. We propose that\nexternal stimuli will be relevant during the sensitive periods, the transition\nperiod between one transient state and the subsequent semi-stable attractor. A\ndiffusive learning signal is generated unsupervised whenever the stimulus\ninfluences the internal dynamics qualitatively.\n  For testing we have presented to the model system stimuli corresponding to\nthe bar-stripes problem and found it capable to perform the required\nindependent-component analysis on its own, all the time being continuously and\nautonomously active.\n", "versions": [{"version": "v1", "created": "Tue, 8 Apr 2008 15:53:00 GMT"}], "update_date": "2008-04-14", "authors_parsed": [["Gros", "Claudius", ""], ["Kaczor", "Gregor", ""]]}, {"id": "0804.2162", "submitter": "Andrew G. White", "authors": "Sonja Kleinlogel and Andrew G. White", "title": "The secret world of shrimps: polarisation vision at its best", "comments": "10 pages, 6 figures, 2 tables", "journal-ref": "PLoS ONE 3, e2190 (2008)", "doi": "10.1371/journal.pone.0002190", "report-no": null, "categories": "physics.bio-ph physics.optics q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animal vision spans a great range of complexity, with systems evolving to\ndetect variations in optical intensity, distribution, colour, and polarisation.\nPolarisation vision systems studied to date detect one to four channels of\nlinear polarisation, combining them in opponent pairs to provide\nintensity-independent operation. Circular polarisation vision has never been\nseen, and is widely believed to play no part in animal vision. Polarisation is\nfully measured via Stokes' parameters--obtained by combined linear and circular\npolarisation measurements. Optimal polarisation vision is the ability to see\nStokes' parameters: here we show that the crustacean \\emph{Gonodactylus\nsmithii} measures the exact components required. This vision provides optimal\ncontrast-enhancement, and precise determination of polarisation with no\nconfusion-states or neutral-points--significant advantages. We emphasise that\nlinear and circular polarisation vision are not different modalities--both are\nnecessary for optimal polarisation vision, regardless of the presence of\nstrongly linear or circularly polarised features in the animal's environment.\n", "versions": [{"version": "v1", "created": "Mon, 14 Apr 2008 07:14:16 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["Kleinlogel", "Sonja", ""], ["White", "Andrew G.", ""]]}, {"id": "0804.3176", "submitter": "Andras Lorincz", "authors": "Andras Lorincz, Melinda Kiszlinger, and Gabor Szirtes", "title": "Model of the hippocampal formation explains the coexistence of grid\n  cells and place cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we explain the strikingly regular activity of the 'grid' cells\nin rodent dorsal medial entorhinal cortex (dMEC) and the spatially localized\nactivity of the hippocampal place cells in CA3 and CA1 by assuming that the\nhippocampal region is constructed to support an internal dynamical model of the\nsensory information. The functioning of the different areas of the\nhippocampal-entorhinal loop and their interaction are derived from a set of\ninformation theoretical principles. We demonstrate through simple\ntransformations of the stimulus representations that the double form of space\nrepresentation (i.e. place field and regular grid tiling) can be seen as a\ncomputational 'by-product' of the circuit. In contrast to other theoretical or\ncomputational models we can also explain how place and grid activity may emerge\nat the respective areas simultaneously. In accord with recent views, our\nresults point toward a close relation between the formation of episodic memory\nand spatial navigation.\n", "versions": [{"version": "v1", "created": "Sun, 20 Apr 2008 11:08:50 GMT"}], "update_date": "2008-04-22", "authors_parsed": [["Lorincz", "Andras", ""], ["Kiszlinger", "Melinda", ""], ["Szirtes", "Gabor", ""]]}, {"id": "0804.3234", "submitter": "Jorge Leandro", "authors": "J. J. G. Leandro (1), R. M. Cesar Jr (1) and L. da F. Costa (2) ((1)\n  Institute of Mathematics and Statistics - USP - Brazil, (2) Instituto de\n  F\\'isica de S\\~ao Carlos - USP - Brazil)", "title": "Technical Report - Automatic Contour Extraction from 2D Neuron Images", "comments": "40 pages, 22 figures and 02 tables. Typos corrected, references\n  added, figures added, new experiments added. Submitted to Elsevier-Journal of\n  Neuronscience Methods. For associated video demonstration of the system, see\n  http://www.vision.ime.usp.br/creativision/demos/branch/alfa-bta-bscea-fast.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work describes a novel methodology for automatic contour extraction from\n2D images of 3D neurons (e.g. camera lucida images and other types of 2D\nmicroscopy). Most contour-based shape analysis methods can not be used to\ncharacterize such cells because of overlaps between neuronal processes. The\nproposed framework is specifically aimed at the problem of contour following\neven in presence of multiple overlaps. First, the input image is preprocessed\nin order to obtain an 8-connected skeleton with one-pixel-wide branches, as\nwell as a set of critical regions (i.e., bifurcations and crossings). Next, for\neach subtree, the tracking stage iteratively labels all valid pixel of\nbranches, up to a critical region, where it determines the suitable direction\nto proceed. Finally, the labeled skeleton segments are followed in order to\nyield the parametric contour of the neuronal shape under analysis. The reported\nsystem was successfully tested with respect to several images and the results\nfrom a set of three neuron images are presented here, each pertaining to a\ndifferent class, i.e. alpha, delta and epsilon ganglion cells, containing a\ntotal of 34 crossings. The algorithms successfully got across all these\noverlaps. The method has also been found to exhibit robustness even for images\nwith close parallel segments. The proposed method is robust and may be\nimplemented in an efficient manner. The introduction of this approach should\npave the way for more systematic application of contour-based shape analysis\nmethods in neuronal morphology.\n", "versions": [{"version": "v1", "created": "Mon, 21 Apr 2008 04:03:48 GMT"}, {"version": "v2", "created": "Fri, 24 Oct 2008 16:02:03 GMT"}], "update_date": "2008-10-24", "authors_parsed": [["Leandro", "J. J. G.", ""], ["Cesar", "R. M.", "Jr"], ["Costa", "L. da F.", ""]]}, {"id": "0804.4237", "submitter": "Robert Burger PhD", "authors": "John Robert Burger", "title": "Explaining the Logical Nature of Electrical Solitons in Neural Circuits", "comments": "13 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons are modeled electrically based on ferroelectric membranes thin enough\nto permit charge transfer, conjectured to be the tunneling result of thermally\nenergetic ions and random electrons. These membranes can be triggered to\nproduce electrical solitons, the main signals for brain associative memory and\nlogical processing. Dendritic circuits are modeled, and electrical solitons are\nsimulated to demonstrate the nature of soliton propagation, soliton reflection,\nthe collision of solitons, as well as soliton OR gates, AND gates, XOR gates\nand NOT gates.\n", "versions": [{"version": "v1", "created": "Sat, 26 Apr 2008 16:55:59 GMT"}], "update_date": "2008-04-30", "authors_parsed": [["Burger", "John Robert", ""]]}, {"id": "0804.4830", "submitter": "Laurent Perrinet", "authors": "Laurent Perrinet (INCM)", "title": "Sparse Spike Coding : applications of Neuroscience to the processing of\n  natural images", "comments": "http://incm.cnrs-mrs.fr/LaurentPerrinet/Publications/Perrinet08spie", "journal-ref": "SPIE Photonics Europe, Strasbourg : France (2008)", "doi": "10.1117/12.787076", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  If modern computers are sometimes superior to humans in some specialized\ntasks such as playing chess or browsing a large database, they can't beat the\nefficiency of biological vision for such simple tasks as recognizing and\nfollowing an object in a complex cluttered background. We present in this paper\nour attempt at outlining the dynamical, parallel and event-based representation\nfor vision in the architecture of the central nervous system. We will\nillustrate this on static natural images by showing that in a signal matching\nframework, a L/LN (linear/non-linear) cascade may efficiently transform a\nsensory signal into a neural spiking signal and we will apply this framework to\na model retina. However, this code gets redundant when using an over-complete\nbasis as is necessary for modeling the primary visual cortex: we therefore\noptimize the efficiency cost by increasing the sparseness of the code. This is\nimplemented by propagating and canceling redundant information using lateral\ninteractions. We compare the efficiency of this representation in terms of\ncompression as the reconstruction quality as a function of the coding length.\nThis will correspond to a modification of the Matching Pursuit algorithm where\nthe ArgMax function is optimized for competition, or Competition Optimized\nMatching Pursuit (COMP). We will in particular focus on bridging neuroscience\nand image processing and on the advantages of such an interdisciplinary\napproach.\n", "versions": [{"version": "v1", "created": "Wed, 30 Apr 2008 15:15:32 GMT"}, {"version": "v2", "created": "Thu, 22 Jan 2009 12:02:33 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Perrinet", "Laurent", "", "INCM"]]}]