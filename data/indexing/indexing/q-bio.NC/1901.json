[{"id": "1901.00258", "submitter": "Wenpo Yao", "authors": "Yao Wen-po, Yao wen-li, Dai Jia-fei, Wang Jun", "title": "Time irreversibility and its application in epileptic brain electrical\n  activities", "comments": "The results in the original paper might be misleading and need\n  further consideration. Therefore, we would like to withdraw this manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time irreversibility (temporal asymmetry) is one of fundamental properties\nthat characterize the nonlinearity of complex dynamical processes, and our\nbrain is a typical complex dynamical system manifested with nonlinearity. Two\nsubtraction-based parameters, Ys and X2, are employed to measure the\nprobabilistic differences of permutations instead of raw vectors for the\nsimplified quantification of time irreversibility, which is validated by\nchaotic and reversible processes and the surrogate data. We show that it is\nequivalent to quantify time irreversibility by measuring probabilistic\ndifference between the forward and its backward processes and between the\nsymmetric permutations. And we detect time irreversibility of two groups of\nepileptic EEGs, from the Nanjing General Hospital (NJGH) and from the public\nBonn epileptic database. In our contribution, NJGH epileptic EEGs during\nseizure-free intervals of have lower time irreversibility than the control data\nwhile those of the Bonn data sets have higher nonlinearity than the healthy\nbrain electrical activities. For the inconsistent results, we conduct\nmulti-scale analysis and elucidate from the circadian rhythms in epileptic\nnonlinearity, however, more targeted researches are needed to verify our\nassumptions or to determine if there are other reasons leading to the\ninconsistency.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2019 03:55:20 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 09:02:41 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Wen-po", "Yao", ""], ["wen-li", "Yao", ""], ["Jia-fei", "Dai", ""], ["Jun", "Wang", ""]]}, {"id": "1901.00449", "submitter": "Youngjun Cho", "authors": "Youngjun Cho, Simon J. Julier, Nadia Bianchi-Berthouze", "title": "Instant Automated Inference of Perceived Mental Stress through\n  Smartphone PPG and Thermal Imaging", "comments": "Accepted by Journal of Medical Internet Research (JMIR) Mental Health\n  - Special Issue on Computing and Mental Health (2018)", "journal-ref": null, "doi": "10.2196/10140", "report-no": null, "categories": "physics.med-ph cs.CV cs.HC q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background: A smartphone is a promising tool for daily cardiovascular\nmeasurement and mental stress monitoring. A smartphone camera-based\nPhotoPlethysmoGraphy (PPG) and a low-cost thermal camera can be used to create\ncheap, convenient and mobile monitoring systems. However, to ensure reliable\nmonitoring results, a person has to remain still for several minutes while a\nmeasurement is being taken. This is very cumbersome and makes its use in\nreal-life mobile situations quite impractical.\n  Objective: We propose a system which combines PPG and thermography with the\naim of improving cardiovascular signal quality and capturing stress responses\nquickly.\n  Methods: Using a smartphone camera with a low cost thermal camera added on,\nwe built a novel system which continuously and reliably measures two different\ntypes of cardiovascular events: i) blood volume pulse and ii)\nvasoconstriction/dilation-induced temperature changes of the nose tip. 17\nhealthy participants, involved in a series of stress-inducing mental workload\ntasks, measured their physiological responses to stressors over a short window\nof time (20 seconds) immediately after each task. Participants reported their\nlevel of perceived mental stress using a 10-cm Visual Analogue Scale (VAS). We\nused normalized K-means clustering to reduce interpersonal differences in the\nself-reported ratings. For the instant stress inference task, we built novel\nlow-level feature sets representing variability of cardiovascular patterns. We\nthen used the automatic feature learning capability of artificial Neural\nNetworks (NN) to improve the mapping between the extracted set of features and\nthe self-reported ratings. We compared our proposed method with existing\nhand-engineered features-based machine learning methods.\n  Results, Conclusions: ... due to limited space here, we refer to our\nmanuscript.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2018 00:49:11 GMT"}], "update_date": "2019-01-03", "authors_parsed": [["Cho", "Youngjun", ""], ["Julier", "Simon J.", ""], ["Bianchi-Berthouze", "Nadia", ""]]}, {"id": "1901.00708", "submitter": "Nur Ahmadi", "authors": "Nur Ahmadi, Timothy G. Constandinou and Christos-Savvas Bouganis", "title": "Decoding Hand Kinematics from Local Field Potentials Using Long\n  Short-Term Memory (LSTM) Network", "comments": "Accepted for the 9th International IEEE EMBS Conference on Neural\n  Engineering (NER 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local field potential (LFP) has gained increasing interest as an alternative\ninput signal for brain-machine interfaces (BMIs) due to its informative\nfeatures, long-term stability, and low frequency content. However, despite\nthese interesting properties, LFP-based BMIs have been reported to yield low\ndecoding performances compared to spike-based BMIs. In this paper, we propose a\nnew decoder based on long short-term memory (LSTM) network which aims to\nimprove the decoding performance of LFP-based BMIs. We compare offline decoding\nperformance of the proposed LSTM decoder to a commonly used Kalman filter (KF)\ndecoder on hand kinematics prediction tasks from multichannel LFPs. We also\nbenchmark the performance of LFP-driven LSTM decoder against KF decoder driven\nby two types of spike signals: single-unit activity (SUA) and multi-unit\nactivity (MUA). Our results show that LFP-driven LSTM decoder achieves\nsignificantly better decoding performance than LFP-, SUA-, and MUA-driven KF\ndecoders. This suggests that LFPs coupled with LSTM decoder could provide high\ndecoding performance, robust, and low power BMIs.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 13:17:19 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Ahmadi", "Nur", ""], ["Constandinou", "Timothy G.", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1901.00945", "submitter": "Stephane Deny", "authors": "Jack Lindsey, Samuel A. Ocko, Surya Ganguli, Stephane Deny", "title": "A Unified Theory of Early Visual Representations from Retina to Cortex\n  through Anatomically Constrained Deep CNNs", "comments": null, "journal-ref": "International Conference on Learning Representations, 2019\n  https://openreview.net/forum?id=S1xq3oR5tQ", "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The visual system is hierarchically organized to process visual information\nin successive stages. Neural representations vary drastically across the first\nstages of visual processing: at the output of the retina, ganglion cell\nreceptive fields (RFs) exhibit a clear antagonistic center-surround structure,\nwhereas in the primary visual cortex, typical RFs are sharply tuned to a\nprecise orientation. There is currently no unified theory explaining these\ndifferences in representations across layers. Here, using a deep convolutional\nneural network trained on image recognition as a model of the visual system, we\nshow that such differences in representation can emerge as a direct consequence\nof different neural resource constraints on the retinal and cortical networks,\nand we find a single model from which both geometries spontaneously emerge at\nthe appropriate stages of visual processing. The key constraint is a reduced\nnumber of neurons at the retinal output, consistent with the anatomy of the\noptic nerve as a stringent bottleneck. Second, we find that, for simple\ncortical networks, visual representations at the retinal output emerge as\nnonlinear and lossy feature detectors, whereas they emerge as linear and\nfaithful encoders of the visual scene for more complex cortices. This result\npredicts that the retinas of small vertebrates should perform sophisticated\nnonlinear computations, extracting features directly relevant to behavior,\nwhereas retinas of large animals such as primates should mostly encode the\nvisual scene linearly and respond to a much broader range of stimuli. These\npredictions could reconcile the two seemingly incompatible views of the retina\nas either performing feature extraction or efficient coding of natural scenes,\nby suggesting that all vertebrates lie on a spectrum between these two\nobjectives, depending on the degree of neural resources allocated to their\nvisual system.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 23:51:38 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Lindsey", "Jack", ""], ["Ocko", "Samuel A.", ""], ["Ganguli", "Surya", ""], ["Deny", "Stephane", ""]]}, {"id": "1901.01024", "submitter": "Peter Taylor", "authors": "Yujiang Wang, Gabrielle Marie Schroeder, Nishant Sinha, Peter Neal\n  Taylor", "title": "Personalised network modelling in epilepsy", "comments": "18 pages, 1 figure, book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epilepsy is a disorder characterised by spontaneous, recurrent seizures. Both\nlocal and network abnormalities have been associated with epilepsy, and the\nexact processes generating seizures are thought to be heterogeneous and\npatient-specific. Due to the heterogeneity, treatments such as surgery and\nmedication are not always effective in achieving full seizure control and\nchoosing the best treatment for the individual patient can be challenging.\nPredictive models constrained by the patient's own data therefore offer the\npotential to assist in clinical decision making. In this chapter, we describe\nhow personalised patient-derived networks from structural or functional\nconnectivity can be incorporated into predictive models. We focus specifically\non dynamical systems models which are composed of differential equations\ncapable of simulating brain activity over time. Here we review recent studies\nwhich have used these models, constrained by patient data, to make personalised\npatient-specific predictions about seizure features (such as propagation\npatterns) or treatment outcomes (such as the success of surgical resection).\nFinally, we suggest future research directions for patient-specific network\nmodels in epilepsy, including their application to integrate information from\nmultiple modalities, to predict long-term disease evolution, and to account for\nwithin-subject variability for treatment.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 09:04:55 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Wang", "Yujiang", ""], ["Schroeder", "Gabrielle Marie", ""], ["Sinha", "Nishant", ""], ["Taylor", "Peter Neal", ""]]}, {"id": "1901.01309", "submitter": "Mireille Broucke", "authors": "Mireille E. Broucke", "title": "Adaptive Internal Models: Explaining the Oculomotor System and the\n  Cerebellum", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new model of the oculomotor system, particularly the\nvestibulo-ocular reflex, gaze fixation, and smooth pursuit. Our key insight is\nto exploit recent developments on adaptive internal models. The outcome is a\nsimple model that includes the interactions between the brainstem and the\ncerebellum and that recovers behaviors from more than 15 oculomotor\nexperiments. In addition, we put forward a thesis that the cerebellum embodies\ninternal models of all persistent, exogenous reference and disturbance signals\nacting on the body and observable through the error signals it receives.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 20:55:38 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 20:38:42 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Broucke", "Mireille E.", ""]]}, {"id": "1901.01362", "submitter": "Lucas Roitman", "authors": "Lucas Agudiez Roitman, Poppy Crum", "title": "Hacking the Brain: Triggering Neuroplasticity for Enhancing Musical\n  Talent: A study on Monkey and Human behavior after Exposure to Videogames and\n  Visual/Auditory Stimuli to Increase Musical Abilities through Neuroplasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we analyze the cognitive improvements that can be achieved\nthrough hacking the brain through the use of multiple methods to enhance\nneuroplasticity. Exposure to gaming, for example, has proven conducive for\nlearning real-world abilities through auditory and visual stimuli. We will\ndiscuss cortical magnification and receptive field sizes, as well as\ntopographic brain maps in the context of neuroplasticity. We finally propose\nmore studies to be performed to improve musical talent and musical abilities.\n", "versions": [{"version": "v1", "created": "Sat, 5 Jan 2019 04:03:48 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 13:52:57 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Roitman", "Lucas Agudiez", ""], ["Crum", "Poppy", ""]]}, {"id": "1901.02068", "submitter": "James Hope Mr", "authors": "J. Hope, K. Aristovich, C. A. R. Chapman, A. Volschenk, F.\n  Vanholsbeeck, A. McDaid", "title": "Extracting impedance changes from a frequency multiplexed signal during\n  neural activity in sciatic nerve of rat: preliminary study in-vitro", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": "10.1088/1361-6579/ab0c24", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Establish suitable frequency spacing and demodulation steps to use\nwhen extracting impedance changes from frequency division multiplexed (FDM)\ncarrier signals in peripheral nerve. Approach: Experiments were performed\nin-vitro on cadavers immediately following euthanasia. Neural activity was\nevoked via stimulation of nerves in the hind paw, while carrier signals were\ninjected, and recordings obtained, with a dual ring nerve cuff implanted on the\nsciatic nerve. Frequency analysis of recorded compound action potentials (CAPs)\nand extracted impedance changes, with the latter obtained using established\ndemodulation methods, were used to determine suitable frequency spacing of\ncarrier signals, and bandpass filter (BPF) bandwidth and order, for a frequency\nmultiplexed signal. Main results: CAPs and impedance changes were dominant in\nthe frequency band 200 to 500 Hz and 100 to 200 Hz, respectively. A Tukey\nwindow was introduced to remove ringing from Gibbs phenomena. A +/- 750 Hz BPF\nbandwidth was selected to encompass 99.99 % of the frequency power of the\nimpedance change. Modelling predicted a minimum BPF order of 16 for 2 kHz\nspacing, and 10 for 4 kHz spacing, were required to avoid ringing from the\nneighbouring carrier signal, while FDM experiments verified BPF orders of 12\nand 8, respectively, were required. With a notch filter centred on the\nneighbouring signal, a BPF order of at least 6 or 4 was required for 2 and 4\nkHz, respectively. Significance: The results establish drive frequency spacing\nand demodulation settings for use in FDM electrical impedance tomography (EIT)\nexperiments, as well as a framework for their selection, and, for the first\ntime, demonstrates the viability of FDM-EIT of neural activity on peripheral\nnerve, which will be a central aspect of future real-time neural-EIT systems\nand EIT-based neural prosthetics interfaces.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2019 21:18:50 GMT"}], "update_date": "2019-06-28", "authors_parsed": [["Hope", "J.", ""], ["Aristovich", "K.", ""], ["Chapman", "C. A. R.", ""], ["Volschenk", "A.", ""], ["Vanholsbeeck", "F.", ""], ["McDaid", "A.", ""]]}, {"id": "1901.02270", "submitter": "Peter Helfer", "authors": "Peter Helfer, Thomas R. Shultz", "title": "Neural-network simulations of memory consolidation and reconsolidation", "comments": "arXiv admin note: substantial text overlap with arXiv:1703.01357", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the mammalian brain newly acquired memories depend on the hippocampus for\nmaintenance and recall, but over time these functions are taken over by the\nneocortex through a process called systems consolidation. However, reactivation\nof a consolidated memory can induce a brief period of temporary\nhippocampus-dependence, followed by return to hippocampus-independence. Here we\npresent a computational model that uses simulation of recently described\nmechanisms of synaptic plasticity to account for findings from the systems\nconsolidation/reconsolidation literature and to make predictions for future\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 12:02:56 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 19:48:42 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 15:30:41 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Helfer", "Peter", ""], ["Shultz", "Thomas R.", ""]]}, {"id": "1901.02478", "submitter": "Andrew Jaegle", "authors": "Andrew Jaegle, Vahid Mehrpour, Nicole Rust", "title": "Visual novelty, curiosity, and intrinsic reward in machine learning and\n  the brain", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A strong preference for novelty emerges in infancy and is prevalent across\nthe animal kingdom. When incorporated into reinforcement-based machine learning\nalgorithms, visual novelty can act as an intrinsic reward signal that vastly\nincreases the efficiency of exploration and expedites learning, particularly in\nsituations where external rewards are difficult to obtain. Here we review\nparallels between recent developments in novelty-driven machine learning\nalgorithms and our understanding of how visual novelty is computed and signaled\nin the primate brain. We propose that in the visual system, novelty\nrepresentations are not configured with the principal goal of detecting novel\nobjects, but rather with the broader goal of flexibly generalizing novelty\ninformation across different states in the service of driving novelty-based\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 19:34:44 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Jaegle", "Andrew", ""], ["Mehrpour", "Vahid", ""], ["Rust", "Nicole", ""]]}, {"id": "1901.02874", "submitter": "Johannes Vorwerk", "authors": "Sophie Schrader, Andreas Westhoff, Maria Carla Piastra, Tuuli\n  Miinalainen, Sampsa Pursiainen, Johannes Vorwerk, Heinrich Brinck, Carsten H.\n  Wolters, Christian Engwer", "title": "DUNEuro -- A software toolbox for forward modeling in\n  bioelectromagnetism", "comments": null, "journal-ref": "PLoS ONE 16.6 (2021): e0252431", "doi": "10.1371/journal.pone.0252431", "report-no": null, "categories": "cs.MS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and efficient source analysis in electro- and magnetoencephalography\nusing sophisticated realistic head geometries requires advanced numerical\napproaches. This paper presents DUNEuro, a free and open source C++ software\ntoolbox for forward modeling in bioelectromagnetism. Building upon the DUNE\nframework, it provides implementations of modern fitted and unfitted finite\nelement methods to efficiently solve the forward problems in electro- and\nmagnetoencephalography. The user can choose between a variety of different\nsource models that are implemented. The software's aim is to provide interfaces\nthat are extendible and easy-to-use. In order to enable a closer integration\ninto existing analysis pipelines, interfaces to Python and Matlab are provided.\nThe practical use is demonstrated by a source analysis example of somatosensory\nevoked potentials using a realistic six compartment head model.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 18:52:01 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 12:13:53 GMT"}, {"version": "v3", "created": "Sat, 19 Jan 2019 12:06:16 GMT"}, {"version": "v4", "created": "Thu, 14 Jan 2021 17:46:20 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Schrader", "Sophie", ""], ["Westhoff", "Andreas", ""], ["Piastra", "Maria Carla", ""], ["Miinalainen", "Tuuli", ""], ["Pursiainen", "Sampsa", ""], ["Vorwerk", "Johannes", ""], ["Brinck", "Heinrich", ""], ["Wolters", "Carsten H.", ""], ["Engwer", "Christian", ""]]}, {"id": "1901.02915", "submitter": "Charles Zheng", "authors": "Charles Y. Zheng, Francisco Pereira, Chris I. Baker, Martin N. Hebart", "title": "Revealing interpretable object representations from human behavior", "comments": "Accepted in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To study how mental object representations are related to behavior, we\nestimated sparse, non-negative representations of objects using human\nbehavioral judgments on images representative of 1,854 object categories. These\nrepresentations predicted a latent similarity structure between objects, which\ncaptured most of the explainable variance in human behavioral judgments.\nIndividual dimensions in the low-dimensional embedding were found to be highly\nreproducible and interpretable as conveying degrees of taxonomic membership,\nfunctionality, and perceptual attributes. We further demonstrated the\npredictive power of the embeddings for explaining other forms of human\nbehavior, including categorization, typicality judgments, and feature ratings,\nsuggesting that the dimensions reflect human conceptual representations of\nobjects beyond the specific task.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jan 2019 20:04:42 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Zheng", "Charles Y.", ""], ["Pereira", "Francisco", ""], ["Baker", "Chris I.", ""], ["Hebart", "Martin N.", ""]]}, {"id": "1901.02943", "submitter": "Amirmasoud Ahmadi", "authors": "Amirmasoud Ahmadi, Sepideh Farakhor Seghinsara, Mohammad Reza Daliri,\n  Vahid Shalchyan", "title": "Brain Electrical Stimulation for Animal Navigation", "comments": "in Farsi", "journal-ref": "Iranian Journal of Biomedical Engineering, 11(1), pp. 83-100", "doi": "10.22041/IJBME.2017.72949.1276", "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain stimulation and its widespread use is one of the most important\nsubjects in studies of neurophysiology. In brain electrical stimulation\nmethods, following the surgery and electrode implantation, electrodes send\nelectrical impulses to the specific targets in the brain. The use of this\nstimulation method is provided therapeutic benefits for treatment chronic pain,\nessential tremor, Parkinsons disease, major depression, and neurological\nmovement disorder syndrome (dystonia). One area in which advancements have been\nrecently made is in controlling the movement and navigation of animals in a\nspecific pathway. It is important to identify brain targets in order to\nstimulate appropriate brain regions for all the applications listed above. An\nanimal navigation system based on brain electrical stimulation is used to\ndevelop new behavioral models for the aim of creating a platform for\ninteracting with the animal nervous system in the spatial learning task. In the\ncontext of animal navigation the electrical stimulation has been used either as\ncreating virtual sensation for movement guidance or virtual reward for movement\nmotivation. In this paper, different approaches and techniques of brain\nelectrical stimulation for this application has been reviewed.\n  Keywords: Rat Robot, Brain Computer Interface, Electrical Stimulation, Cyborg\nIntelligence, Brain to Brain Interface\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2018 13:56:40 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Ahmadi", "Amirmasoud", ""], ["Seghinsara", "Sepideh Farakhor", ""], ["Daliri", "Mohammad Reza", ""], ["Shalchyan", "Vahid", ""]]}, {"id": "1901.03299", "submitter": "Nitzan Shalom Artzi", "authors": "Nitzan S. Artzi, Oren Shriki", "title": "An Analysis of the Accuracy of the P300 BCI", "comments": null, "journal-ref": null, "doi": "10.1080/2326263X.2018.1552357", "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The P300 Brain-Computer Interface (BCI) is a well-established communication\nchannel for severely disabled people. The P300 event-related potential is\nmostly characterized by its amplitude or its area, which correlate with the\nspelling accuracy of the P300 speller. Here, we introduce a novel approach for\nestimating the efficiency of this BCI by considering the P300 signal-to-noise\nratio (SNR), a parameter that estimates the spatial and temporal noise levels\nand has a significantly stronger correlation with spelling accuracy.\nFurthermore, we suggest a Gaussian noise model, which utilizes the P300\nevent-related potential SNR to predict spelling accuracy under various\nconditions for LDA-based classification. We demonstrate the utility of this\nanalysis using real data and discuss its potential applications, such as\nspeeding up the process of electrode selection.\n", "versions": [{"version": "v1", "created": "Tue, 11 Dec 2018 11:34:11 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Artzi", "Nitzan S.", ""], ["Shriki", "Oren", ""]]}, {"id": "1901.03442", "submitter": "Mathias Baumert", "authors": "Simanto Saha, Khondaker A. Mamun, Khawza Ahmed, Raqibul Mostafa,\n  Ganesh R. Naik, Ahsan Khandoker, Sam Darvishi, Mathias Baumert", "title": "Progress in Brain Computer Interfaces: Challenges and Trends", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain computer interfaces (BCI) provide a direct communication link between\nthe brain and a computer or other external devices. They offer an extended\ndegree of freedom either by strengthening or by substituting human peripheral\nworking capacity and have potential applications in various fields such as\nrehabilitation, affective computing, robotics, gaming and artificial\nintelligence. Significant research efforts on a global scale have delivered\ncommon platforms for technology standardization and help tackle highly complex\nand nonlinear brain dynamics and related feature extraction and classification\nchallenges. Psycho-neurophysiological phenomena and their impact on brain\nsignals impose another challenge for BCI researchers to transform the\ntechnology from laboratory experiments to plug-and-play daily life. This review\nsummarizes progress in BCI field and highlights critical challenges.\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 00:57:05 GMT"}], "update_date": "2019-01-14", "authors_parsed": [["Saha", "Simanto", ""], ["Mamun", "Khondaker A.", ""], ["Ahmed", "Khawza", ""], ["Mostafa", "Raqibul", ""], ["Naik", "Ganesh R.", ""], ["Khandoker", "Ahsan", ""], ["Darvishi", "Sam", ""], ["Baumert", "Mathias", ""]]}, {"id": "1901.03553", "submitter": "Razvan Marinescu", "authors": "Razvan V. Marinescu, Arman Eshaghi, Marco Lorenzi, Alexandra L. Young,\n  Neil P. Oxtoby, Sara Garbarino, Sebastian J. Crutch, Daniel C. Alexander (for\n  the Alzheimer's Disease Neuroimaging Initiative)", "title": "DIVE: A spatiotemporal progression model of brain pathology in\n  neurodegenerative disorders", "comments": "24 pages, 5 figures, 2 tables, 1 algorithm", "journal-ref": "NeuroImage, Volume 192, 15 May 2019, Pages 166-177", "doi": "10.1016/j.neuroimage.2019.02.053", "report-no": null, "categories": "cs.CV cs.LG q-bio.NC q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Here we present DIVE: Data-driven Inference of Vertexwise Evolution. DIVE is\nan image-based disease progression model with single-vertex resolution,\ndesigned to reconstruct long-term patterns of brain pathology from short-term\nlongitudinal data sets. DIVE clusters vertex-wise biomarker measurements on the\ncortical surface that have similar temporal dynamics across a patient\npopulation, and concurrently estimates an average trajectory of vertex\nmeasurements in each cluster. DIVE uniquely outputs a parcellation of the\ncortex into areas with common progression patterns, leading to a new signature\nfor individual diseases. DIVE further estimates the disease stage and\nprogression speed for every visit of every subject, potentially enhancing\nstratification for clinical trials or management. On simulated data, DIVE can\nrecover ground truth clusters and their underlying trajectory, provided the\naverage trajectories are sufficiently different between clusters. We\ndemonstrate DIVE on data from two cohorts: the Alzheimer's Disease Neuroimaging\nInitiative (ADNI) and the Dementia Research Centre (DRC), UK, containing\npatients with Posterior Cortical Atrophy (PCA) as well as typical Alzheimer's\ndisease (tAD). DIVE finds similar spatial patterns of atrophy for tAD subjects\nin the two independent datasets (ADNI and DRC), and further reveals distinct\npatterns of pathology in different diseases (tAD vs PCA) and for distinct types\nof biomarker data: cortical thickness from Magnetic Resonance Imaging (MRI) vs\namyloid load from Positron Emission Tomography (PET). Finally, DIVE can be used\nto estimate a fine-grained spatial distribution of pathology in the brain using\nany kind of voxelwise or vertexwise measures including Jacobian compression\nmaps, fractional anisotropy (FA) maps from diffusion imaging or other PET\nmeasures. DIVE source code is available online:\nhttps://github.com/mrazvan22/dive\n", "versions": [{"version": "v1", "created": "Fri, 11 Jan 2019 11:13:44 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Marinescu", "Razvan V.", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Eshaghi", "Arman", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Lorenzi", "Marco", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Young", "Alexandra L.", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Oxtoby", "Neil P.", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Garbarino", "Sara", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Crutch", "Sebastian J.", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"], ["Alexander", "Daniel C.", "", "for\n  the Alzheimer's Disease Neuroimaging Initiative"]]}, {"id": "1901.03990", "submitter": "Robert Baumgartner", "authors": "Piotr Majdak, Robert Baumgartner, Claudia Jenny", "title": "Formation of three-dimensional auditory space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Human listeners need to permanently interact with their three-dimensional\n(3-D) environment. To this end, they require efficient perceptual mechanisms to\nform a sufficiently accurate 3-D auditory space. In this chapter, we discuss\nthe formation of the 3-D auditory space from various perspectives. The aim is\nto show the link between cognition, acoustics, neurophysiology, and\npsychophysics, when it comes to spatial hearing. First, we present recent\ncognitive concepts for creating internal models of the complex auditory\nenvironment. Second, we describe the acoustic signals available at our ears and\ndiscuss the spatial information they convey. Third, we look into\nneurophysiology, seeking for the neural substrates of the 3-D auditory space.\nFinally, we elaborate on psychophysical spatial tasks and percepts that are\npossible just because of the formation of the auditory space.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2019 14:22:37 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Majdak", "Piotr", ""], ["Baumgartner", "Robert", ""], ["Jenny", "Claudia", ""]]}, {"id": "1901.04094", "submitter": "Yuval Harel", "authors": "Yuval Harel, Ron Meir, Manfred Opper", "title": "Optimal decoding of dynamic stimuli encoded by heterogeneous populations\n  of spiking neurons - a closed form approximation", "comments": "This is an extended version of arXiv:1507.07813 and arXiv:1609.03519.\n  Additions relative to the version presented in NIPS (arXiv:1507.07813) are\n  outlined in the introduction", "journal-ref": "Neural Computation 2018, Vol. 30, 2056-2112", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural decoding may be formulated as dynamic state estimation (filtering)\nbased on point process observations, a generally intractable problem. Numerical\nsampling techniques are often practically useful for the decoding of real\nneural data. However, they are less useful as theoretical tools for modeling\nand understanding sensory neural systems, since they lead to limited conceptual\ninsight about optimal encoding and decoding strategies. We consider sensory\nneural populations characterized by a distribution over neuron parameters. We\ndevelop an analytically tractable Bayesian approximation to optimal filtering\nbased on the observation of spiking activity, that greatly facilitates the\nanalysis of optimal encoding in situations deviating from common assumptions of\nuniform coding. Continuous distributions are used to approximate large\npopulations with few parameters, resulting in a filter whose complexity does\nnot grow with the population size, and allowing optimization of population\nparameters rather than individual tuning functions. Numerical comparison with\nparticle filtering demonstrates the quality of the approximation. The analytic\nframework leads to insights which are difficult to obtain from numerical\nalgorithms, and is consistent with biological observations about the\ndistribution of sensory cells' preferred stimuli.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 00:07:53 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Harel", "Yuval", ""], ["Meir", "Ron", ""], ["Opper", "Manfred", ""]]}, {"id": "1901.04399", "submitter": "Janina Hesse", "authors": "Janina Hesse, Susanne Schreiber", "title": "How to correctly quantify neuronal phase-response curves from noisy\n  recordings", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the level of individual neurons, various coding properties can be inferred\nfrom the input-output relationship of a cell. For small inputs, this relation\nis captured by the phase-response curve (PRC), which measures the effect of a\nsmall perturbation on the timing of the subsequent spike. Experimentally,\nhowever, an accurate experimental estimation of PRCs is challenging. Despite\nelaborate measurement efforts, experimental PRC estimates often cannot be\nrelated to those from modeling studies. In particular, experimental PRCs rarely\nresemble the generic PRC expected close to spike initiation, which is\nindicative of the underlying spike-onset bifurcation. Here, we show for\nconductance-based model neurons that the correspondence between theoretical and\nmeasured phase-response curve is lost when the stimuli used for the estimation\nare too large. In this case, the derived phase-response curve is distorted\nbeyond recognition and takes on a generic shape that reflects the measurement\nprotocol, but not the real neuronal dynamics. We discuss how to identify\nappropriate stimulus strengths for perturbation and noise-stimulation methods,\nwhich permit to estimate PRCs that reliably reflect the spike-onset bifurcation\n-- a task that is particularly difficult if a lower bound for the stimulus\namplitude is dictated by prominent intrinsic neuronal noise.\n", "versions": [{"version": "v1", "created": "Mon, 14 Jan 2019 16:58:10 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Hesse", "Janina", ""], ["Schreiber", "Susanne", ""]]}, {"id": "1901.04908", "submitter": "Iuliia Kotseruba", "authors": "John K. Tsotsos, Iuliia Kotseruba, Calden Wloka", "title": "Rapid Visual Categorization is not Guided by Early Salience-Based\n  Selection", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0224306", "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current dominant visual processing paradigm in both human and machine\nresearch is the feedforward, layered hierarchy of neural-like processing\nelements. Within this paradigm, visual saliency is seen by many to have a\nspecific role, namely that of early selection. Early selection is thought to\nenable very fast visual performance by limiting processing to only the most\nsalient candidate portions of an image. This strategy has led to a plethora of\nsaliency algorithms that have indeed improved processing time efficiency in\nmachine algorithms, which in turn have strengthened the suggestion that human\nvision also employs a similar early selection strategy. However, at least one\nset of critical tests of this idea has never been performed with respect to the\nrole of early selection in human vision. How would the best of the current\nsaliency models perform on the stimuli used by experimentalists who first\nprovided evidence for this visual processing paradigm? Would the algorithms\nreally provide correct candidate sub-images to enable fast categorization on\nthose same images? Do humans really need this early selection for their\nimpressive performance? Here, we report on a new series of tests of these\nquestions whose results suggest that it is quite unlikely that such an early\nselection process has any role in human rapid visual categorization.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2019 16:22:24 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 14:43:38 GMT"}, {"version": "v3", "created": "Thu, 30 Jan 2020 20:58:35 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Tsotsos", "John K.", ""], ["Kotseruba", "Iuliia", ""], ["Wloka", "Calden", ""]]}, {"id": "1901.05913", "submitter": "Li Xiao", "authors": "Li Xiao, Julia M. Stephen, Tony W. Wilson, Vince D. Calhoun, and\n  Yu-Ping Wang", "title": "A Manifold Regularized Multi-Task Learning Model for IQ Prediction from\n  Multiple fMRI Paradigms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modal brain functional connectivity (FC) data have shown great\npotential for providing insights into individual variations in behavioral and\ncognitive traits. The joint learning of multi-modal imaging data can utilize\nthe intrinsic association, and thus can boost the learning performance.\nAlthough several multi-task based learning models have already been proposed by\nviewing the feature learning on each modality as one task, most of them ignore\nthe geometric structure information inherent in the modalities, which may play\nan important role in extracting discriminative features. In this paper, we\npropose a new manifold regularized multi-task learning model by simultaneously\nconsidering between-subject and between-modality relationships. Besides\nemploying a group-sparsity regularizer to jointly select a few common features\nacross multiple tasks (modalities), we design a novel manifold regularizer to\npreserve the structure information both within and between modalities in our\nmodel. This will make our model more adaptive for realistic data analysis. Our\nmodel is then validated on the Philadelphia Neurodevelopmental Cohort dataset,\nwhere we regard our modalities as functional MRI (fMRI) data collected under\ntwo paradigms. Specifically, we conduct experimental studies on fMRI based FC\nnetwork data in two task conditions for intelligence quotient (IQ) prediction.\nThe results demonstrate that our proposed model can not only achieve improved\nprediction performance, but also yield a set of IQ-relevant biomarkers.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 17:30:13 GMT"}], "update_date": "2019-01-18", "authors_parsed": [["Xiao", "Li", ""], ["Stephen", "Julia M.", ""], ["Wilson", "Tony W.", ""], ["Calhoun", "Vince D.", ""], ["Wang", "Yu-Ping", ""]]}, {"id": "1901.06552", "submitter": "Andrew Murphy", "authors": "Andrew C. Murphy, Maxwell A. Bertolero, Lia Papadopoulos, David M.\n  Lydon-Staley, Danielle S. Bassett", "title": "Multiscale and multimodal network dynamics underpinning working memory", "comments": null, "journal-ref": null, "doi": "10.1038/s41467-020-15541-0", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working memory (WM) allows information to be stored and manipulated over\nshort time scales. Performance on WM tasks is thought to be supported by the\nfrontoparietal system (FPS), the default mode system (DMS), and interactions\nbetween them. Yet little is known about how these systems and their\ninteractions relate to individual differences in WM performance. We address\nthis gap in knowledge using functional MRI data acquired during the performance\nof a 2-back WM task, as well as diffusion tensor imaging data collected in the\nsame individuals. We show that the strength of functional interactions between\nthe FPS and DMS during task engagement is inversely correlated with WM\nperformance, and that this strength is modulated by the activation of FPS\nregions but not DMS regions. Next, we use a clustering algorithm to identify\ntwo distinct subnetworks of the FPS, and find that these subnetworks display\ndistinguishable patterns of gene expression. Activity in one subnetwork is\npositively associated with the strength of FPS-DMS functional interactions,\nwhile activity in the second subnetwork is negatively associated. Further, the\npattern of structural linkages of these subnetworks explains their differential\ncapacity to influence the strength of FPS-DMS functional interactions. To\ndetermine whether these observations could provide a mechanistic account of\nlarge-scale neural underpinnings of WM, we build a computational model of the\nsystem composed of coupled oscillators. Modulating the amplitude of the\nsubnetworks in the model causes the expected change in the strength of FPS-DMS\nfunctional interactions, thereby offering support for a mechanism in which\nsubnetwork activity tunes functional interactions. Broadly, our study presents\na holistic account of how regional activity, functional interactions, and\nstructural linkages together support individual differences in WM in humans.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 16:41:31 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Murphy", "Andrew C.", ""], ["Bertolero", "Maxwell A.", ""], ["Papadopoulos", "Lia", ""], ["Lydon-Staley", "David M.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1901.07274", "submitter": "Andras Jakab", "authors": "Eliane Meuwly, Maria Feldmann, Walter Knirsch, Michael von Rhein,\n  Kelly Payette, Hitendu Dave, Ruth Tuura, Raimund Kottke, Cornelia Hagmann,\n  Beatrice Latal, Andras Jakab", "title": "Postoperative brain volumes are associated with one-year\n  neurodevelopmental outcome in children with severe congenital heart disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Children with congenital heart disease (CHD) remain at risk for\nneurodevelopmental impairment despite improved peri- and intraoperative care.\nOur prospective cohort study aimed to determine the relationship between\nperioperative brain volumes and neurodevelopmental outcome in neonates with\nsevere CHD. Pre- and postoperative cerebral MRI was acquired in term born\nneonates with CHD undergoing neonatal cardiopulmonary bypass surgery. Brain\nvolumes were measured using an atlas prior based automated method. One-year\noutcome was assessed with the Bayley-III. CHD infants (n=77) had lower pre- and\npostoper-ative total and regional brain volumes compared to controls (n=44, all\np<0.01). CHD infants had poorer cognitive and motor outcome (p<=0.0001) and a\ntrend towards lower language composite score compared to controls (p=0.06). The\ntotal and selected regional postoperative brain volumes predicted cognitive and\nlanguage outcome (all p<0.04). This association was independent of length of\nintensive care unit stay for total, cortical, temporal, frontal and cerebellar\nvolumes. In CHD neonates undergoing cardiopulmonary bypass surgery, pre- and\npostoperative brain volumes are reduced, and postoperative brain volumes\npredict cognitive and language outcome at one year. Reduced cerebral volumes in\nCHD patients could serve as a biomarker for im-paired outcome.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 11:55:59 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Meuwly", "Eliane", ""], ["Feldmann", "Maria", ""], ["Knirsch", "Walter", ""], ["von Rhein", "Michael", ""], ["Payette", "Kelly", ""], ["Dave", "Hitendu", ""], ["Tuura", "Ruth", ""], ["Kottke", "Raimund", ""], ["Hagmann", "Cornelia", ""], ["Latal", "Beatrice", ""], ["Jakab", "Andras", ""]]}, {"id": "1901.07298", "submitter": "Jimmy Gaudreault", "authors": "Jimmy Gaudreault, Arunabh Saxena and Hideaki Shimazaki", "title": "Online Estimation of Multiple Dynamic Graphs in Pattern Sequences", "comments": "8 pages, 4 figures v2: IJCNN 2019, results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequences of correlated binary patterns can represent many time-series data\nincluding text, movies, and biological signals. These patterns may be described\nby weighted combinations of a few dominant structures that underpin specific\ninteractions among the binary elements. To extract the dominant correlation\nstructures and their contributions to generating data in a time-dependent\nmanner, we model the dynamics of binary patterns using the state-space model of\nan Ising-type network that is composed of multiple undirected graphs. We\nprovide a sequential Bayes algorithm to estimate the dynamics of weights on the\ngraphs while gaining the graph structures online. This model can uncover\noverlapping graphs underlying the data better than a traditional orthogonal\ndecomposition method, and outperforms an original time-dependent Ising model.\nWe assess the performance of the method by simulated data, and demonstrate that\nspontaneous activity of cultured hippocampal neurons is represented by dynamics\nof multiple graphs.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 14:05:53 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 03:38:11 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Gaudreault", "Jimmy", ""], ["Saxena", "Arunabh", ""], ["Shimazaki", "Hideaki", ""]]}, {"id": "1901.07454", "submitter": "Alexander Peyser", "authors": "Nora Abi Akar, Ben Cumming, Vasileios Karakasis, Anne K\\\"usters,\n  Wouter Klijn, Alexander Peyser, Stuart Yates", "title": "Arbor -- a morphologically-detailed neural network simulation library\n  for contemporary high-performance computing architectures", "comments": "PDP 2019 27th Euromicro International Conference on Parallel,\n  Distributed and Network-based Processing", "journal-ref": "2019 27th Euromicro International Conference on Parallel,\n  Distributed and Network-Based Processing (PDP), Pavia, Italy, 2019, pp.\n  274-282", "doi": "10.1109/EMPDP.2019.8671560", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Arbor, a performance portable library for simulation of large\nnetworks of multi-compartment neurons on HPC systems. Arbor is open source\nsoftware, developed under the auspices of the HBP. The performance portability\nis by virtue of back-end specific optimizations for x86 multicore, Intel KNL,\nand NVIDIA GPUs. When coupled with low memory overheads, these optimizations\nmake Arbor an order of magnitude faster than the most widely-used comparable\nsimulation software. The single-node performance can be scaled out to run very\nlarge models at extreme scale with efficient weak scaling.\n  HPC, GPU, neuroscience, neuron, software\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2019 07:44:39 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Akar", "Nora Abi", ""], ["Cumming", "Ben", ""], ["Karakasis", "Vasileios", ""], ["K\u00fcsters", "Anne", ""], ["Klijn", "Wouter", ""], ["Peyser", "Alexander", ""], ["Yates", "Stuart", ""]]}, {"id": "1901.07536", "submitter": "Evelyn Tang", "authors": "Evelyn Tang, Harang Ju, Graham L. Baum, David R. Roalf, Theodore D.\n  Satterthwaite, Fabio Pasqualetti and Danielle S. Bassett", "title": "The control of brain network dynamics across diverse scales of space and\n  time", "comments": "12 pages, 7 figures. arXiv admin note: text overlap with\n  arXiv:1607.01010", "journal-ref": "Phys. Rev. E 101, 062301 (2020)", "doi": "10.1103/PhysRevE.101.062301", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain is composed of distinct regions that are each associated with\nparticular functions and distinct propensities for the control of neural\ndynamics. However, the relation between these functions and control profiles is\npoorly understood, as is the variation in this relation across diverse scales\nof space and time. Here we probe the relation between control and dynamics in\nbrain networks constructed from diffusion tensor imaging data in a large\ncommunity based sample of young adults. Specifically, we probe the control\nproperties of each brain region and investigate their relationship with\ndynamics across various spatial scales using the Laplacian eigenspectrum. In\naddition, through analysis of regional modal controllability and partitioning\nof modes, we determine whether the associated dynamics are fast or slow, as\nwell as whether they are alternating or monotone. We find that brain regions\nthat facilitate the control of energetically easy transitions are associated\nwith activity on short length scales and slow time scales. Conversely, brain\nregions that facilitate control of difficult transitions are associated with\nactivity on long length scales and fast time scales. Built on linear dynamical\nmodels, our results offer parsimonious explanations for the activity\npropagation and network control profiles supported by regions of differing\nneuroanatomical structure.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2019 13:22:19 GMT"}, {"version": "v2", "created": "Thu, 2 May 2019 08:11:43 GMT"}, {"version": "v3", "created": "Mon, 1 Jun 2020 15:42:13 GMT"}], "update_date": "2020-06-02", "authors_parsed": [["Tang", "Evelyn", ""], ["Ju", "Harang", ""], ["Baum", "Graham L.", ""], ["Roalf", "David R.", ""], ["Satterthwaite", "Theodore D.", ""], ["Pasqualetti", "Fabio", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1901.07589", "submitter": "Christoph Adami", "authors": "Ali Tehrani-Saleh and Christoph Adami (Michigan State University)", "title": "Can Transfer Entropy Infer Information Flow in Neuronal Circuits for\n  Cognitive Processing?", "comments": "16 pages, 7 figures. Significantly changed version including new\n  results. Title changed", "journal-ref": null, "doi": "10.3390/e22040385", "report-no": null, "categories": "cs.NE nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To infer information flow in any network of agents, it is important first and\nforemost to establish causal temporal relations between the nodes. Practical\nand automated methods that can infer causality are difficult to find, and the\nsubject of ongoing research. While Shannon information only detects\ncorrelation, there are several information-theoretic notions of \"directed\ninformation\" that have successfully detected causality in some systems, in\nparticular in the neuroscience community. However, recent work has shown that\nsome directed information measures can sometimes inadequately estimate the\nextent of causal relations, or even fail to identify existing cause-effect\nrelations between components of systems, especially if neurons contribute in a\ncryptographic manner to influence the effector neuron. Here, we test how often\ncryptographic logic emerges in an evolutionary process that generates\nartificial neural circuits for two fundamental cognitive tasks: motion\ndetection and sound localization. We also test whether activity time-series\nrecorded from behaving digital brains can infer information flow using the\ntransfer entropy concept, when compared to a ground-truth model of causal\ninfluence constructed from connectivity and circuit logic. Our results suggest\nthat transfer entropy will sometimes fail to infer causality when it exists,\nand sometimes suggest a causal connection when there is none. However, the\nextent of incorrect inference strongly depends on the cognitive task\nconsidered. These results emphasize the importance of understanding the\nfundamental logic processes that contribute to information flow in cognitive\nprocessing, and quantifying their relevance in any given nervous system.\n", "versions": [{"version": "v1", "created": "Tue, 22 Jan 2019 19:19:11 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2019 04:20:26 GMT"}], "update_date": "2020-04-22", "authors_parsed": [["Tehrani-Saleh", "Ali", "", "Michigan State University"], ["Adami", "Christoph", "", "Michigan State University"]]}, {"id": "1901.07945", "submitter": "Samuel Gershman", "authors": "Samuel J. Gershman", "title": "What does the free energy principle tell us about the brain?", "comments": "Accepted for publication in Neurons, Behavior, Data Analysis, and\n  Theory", "journal-ref": "Neurons, Behavior, Data Analysis, and Theory, 2019", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The free energy principle has been proposed as a unifying account of brain\nfunction. It is closely related, and in some cases subsumes, earlier unifying\nideas such as Bayesian inference, predictive coding, and active learning. This\narticle clarifies these connections, teasing apart distinctive and shared\npredictions.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 15:23:00 GMT"}, {"version": "v2", "created": "Sun, 7 Jul 2019 16:31:46 GMT"}, {"version": "v3", "created": "Tue, 3 Sep 2019 15:30:20 GMT"}, {"version": "v4", "created": "Wed, 4 Sep 2019 08:16:30 GMT"}, {"version": "v5", "created": "Wed, 2 Oct 2019 13:59:13 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Gershman", "Samuel J.", ""]]}, {"id": "1901.08093", "submitter": "Gal Chechik", "authors": "Ohad Felsenstein, Idan Tal, Michal Ben-Shachar, Moshe Abeles, Gal\n  Chechik", "title": "Decoding multimodal behavior using time differences of MEG events", "comments": "25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal behavior involves multiple processing stations distributed across\ndistant brain regions, but our understanding of how such distributed processing\nis coordinated in the brain is limited. Here we take a decoding approach to\nthis problem, aiming to quantify how temporal aspects of brain-wide neural\nactivity may be used to infer specific multimodal behaviors. Using high\ntemporal resolution measurements by MEG, we detect bursts of activity from\nhundreds of locations across the surface of the brain at millisecond\nresolution. We then compare decoding using three characteristics of neural\nactivity bursts, decoding with event counts, with latencies and with time\ndifferences between pairs of events. Training decoders in this regime is\nparticularly challenging because the number of samples is smaller by orders of\nmagnitude than the input dimensionality. We develop a new decoding approach for\nthis regime that combines non-parametric modelling with aggressive feature\nselection. Surprisingly, we find that decoding using time-differences, based on\nthousands of region pairs, is significantly more accurate than using other\nactivity characteristics, reaching 90% accuracy consistently across subjects.\nThese results suggest that relevant information about multimodal brain function\nis provided by subtle time differences across remote brain areas.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 19:29:27 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Felsenstein", "Ohad", ""], ["Tal", "Idan", ""], ["Ben-Shachar", "Michal", ""], ["Abeles", "Moshe", ""], ["Chechik", "Gal", ""]]}, {"id": "1901.08114", "submitter": "Yanlu Xie", "authors": "Yanlu Xie, Yue Chen, Man Li", "title": "Convolution Forgetting Curve Model for Repeated Learning", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of mathematic forgetting curve models fit well with the forgetting data\nunder the learning condition of one time rather than repeated. In the paper, a\nconvolution model of forgetting curve is proposed to simulate the memory\nprocess during learning. In this model, the memory ability (i.e. the central\nprocedure in the working memory model) and learning material (i.e. the input in\nthe working memory model) is regarded as the system function and the input\nfunction, respectively. The status of forgetting (i.e. the output in the\nworking memory model) is regarded as output function or the convolution result\nof the memory ability and learning material. The model is applied to simulate\nthe forgetting curves in different situations. The results show that the model\nis able to simulate the forgetting curves not only in one time learning\ncondition but also in multi-times condition. The model is further verified in\nthe experiments of Mandarin tone learning for Japanese learners. And the\npredicted curve fits well on the test points.\n", "versions": [{"version": "v1", "created": "Sat, 19 Jan 2019 08:09:58 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Xie", "Yanlu", ""], ["Chen", "Yue", ""], ["Li", "Man", ""]]}, {"id": "1901.08355", "submitter": "Victor Buendia", "authors": "Victor Buend\\'ia, Pablo Villegas, Serena di Santo, Alessandro Vezzani,\n  Raffaella Burioni and Miguel A. Mu\\~noz", "title": "Jensen's force and the statistical mechanics of cortical asynchronous\n  states", "comments": null, "journal-ref": "Sci. Rep. 9, 15183 (2019)", "doi": "10.1038/s41598-019-51520-2", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cortex exhibits self-sustained highly-irregular activity even under\nresting conditions, whose origin and function need to be fully understood. It\nis believed that this can be described as an \"asynchronous state\" stemming from\nthe balance between excitation and inhibition, with important consequences for\ninformation-processing, though a competing hypothesis claims it stems from\ncritical dynamics. By analyzing a parsimonious neural-network model with\nexcitatory and inhibitory interactions, we elucidate a noise-induced mechanism\ncalled \"Jensen's force\" responsible for the emergence of a novel phase of\narbitrarily-low but self-sustained activity, which reproduces all the\nexperimental features of asynchronous states. The simplicity of our framework\nallows for a deep understanding of asynchronous states from a broad\nstatistical-mechanics perspective and of the phase transitions to other\nstandard phases it exhibits, opening the door to reconcile, asynchronous-state\nand critical-state hypotheses. We argue that Jensen's forces are measurable\nexperimentally and might be relevant in contexts beyond neuroscience.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 11:24:14 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Buend\u00eda", "Victor", ""], ["Villegas", "Pablo", ""], ["di Santo", "Serena", ""], ["Vezzani", "Alessandro", ""], ["Burioni", "Raffaella", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}, {"id": "1901.08521", "submitter": "Andrea Gabrielli", "authors": "Rossana Mastrandrea, Fabrizio Piras, Andrea Gabrielli, Nerisa Banaj,\n  Guido Caldarelli, Gianfranco Spalletta, Tommaso Gili", "title": "The unbalanced reorganization of weaker functional connections induces\n  the altered brain network topology in schizophrenia", "comments": "37 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network neuroscience shed some light on the functional and structural\nmodifications occurring to the brain associated with the phenomenology of\nschizophrenia. In particular, resting-state functional networks have helped our\nunderstanding of the illness by highlighting the global and local alterations\nwithin the cerebral organization. We investigated the robustness of the brain\nfunctional architecture in forty-four medicated schizophrenic patients and\nforty healthy comparators through an advanced network analysis of resting-state\nfunctional magnetic resonance imaging data. The networks in patients showed\nmore resistance to disconnection than in healthy controls, with an evident\ndiscrepancy between the two groups in the node degree distribution computed\nalong a percolation process. Despite a substantial similarity of the basal\nfunctional organization between the two groups, the expected hierarchy of\nhealthy brains modular organization is crumbled in schizophrenia, showing a\npeculiar arrangement of the functional connections, characterized by several\ntopologically equivalent backbones.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 17:33:14 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 10:18:19 GMT"}, {"version": "v3", "created": "Thu, 29 Apr 2021 11:17:17 GMT"}], "update_date": "2021-04-30", "authors_parsed": [["Mastrandrea", "Rossana", ""], ["Piras", "Fabrizio", ""], ["Gabrielli", "Andrea", ""], ["Banaj", "Nerisa", ""], ["Caldarelli", "Guido", ""], ["Spalletta", "Gianfranco", ""], ["Gili", "Tommaso", ""]]}, {"id": "1901.08644", "submitter": "Richard Meyes", "authors": "Richard Meyes, Melanie Lu, Constantin Waubert de Puiseau, Tobias\n  Meisen", "title": "Ablation Studies in Artificial Neural Networks", "comments": "19 pages, 23 figures, intention to submit as a conference publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ablation studies have been widely used in the field of neuroscience to tackle\ncomplex biological systems such as the extensively studied Drosophila central\nnervous system, the vertebrate brain and more interestingly and most\ndelicately, the human brain. In the past, these kinds of studies were utilized\nto uncover structure and organization in the brain, i.e. a mapping of features\ninherent to external stimuli onto different areas of the neocortex. considering\nthe growth in size and complexity of state-of-the-art artificial neural\nnetworks (ANNs) and the corresponding growth in complexity of the tasks that\nare tackled by these networks, the question arises whether ablation studies may\nbe used to investigate these networks for a similar organization of their inner\nrepresentations. In this paper, we address this question and performed two\nablation studies in two fundamentally different ANNs to investigate their inner\nrepresentations of two well-known benchmark datasets from the computer vision\ndomain. We found that features distinct to the local and global structure of\nthe data are selectively represented in specific parts of the network.\nFurthermore, some of these representations are redundant, awarding the network\na certain robustness to structural damages. We further determined the\nimportance of specific parts of the network for the classification task solely\nbased on the weight structure of single units. Finally, we examined the ability\nof damaged networks to recover from the consequences of ablations by means of\nrecovery training. We argue that ablations studies are a feasible method to\ninvestigate knowledge representations in ANNs and are especially helpful to\nexamine a networks robustness to structural damages, a feature of ANNs that\nwill become increasingly important for future safety-critical applications.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 21:11:59 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 09:39:19 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Meyes", "Richard", ""], ["Lu", "Melanie", ""], ["de Puiseau", "Constantin Waubert", ""], ["Meisen", "Tobias", ""]]}, {"id": "1901.08743", "submitter": "Liam Hanlon Mr", "authors": "Liam Hanlon, Vini Gautam, James D. A. Wood, Prithvi Reddy, Michael\n  S.J. Barson, Marika Niihori, Alexander R.J. Silalahi, Ben Corry, Joerg\n  Wrachtrup, Matthew J. Sellars, Vincent R. Daria, Patrick Maletinsky, Gregory\n  J. Stuart, Marcus W. Doherty", "title": "Diamond nano-pillar arrays for quantum microscopy of neuronal signals", "comments": "18 pages including supplementary and references, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cond-mat.mes-hall q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neuroscience is currently limited in its capacity to perform long\nterm, wide-field measurements of neuron electromagnetics with nanoscale\nresolution. Quantum microscopy using the nitrogen vacancy centre (NV) can\nprovide a potential solution to this problem with electric and magnetic field\nsensing at nano-scale resolution and good biocompatibility. However, the\nperformance of existing NV sensing technology does not allow for studies of\nsmall mammalian neurons yet. In this paper, we propose a solution to this\nproblem by engineering NV quantum sensors in diamond nanopillar arrays. The\npillars improve light collection efficiency by guiding excitation/emission\nlight, which improves sensitivity. More importantly, they also improve the size\nof the signal at the NV by removing screening charges as well as coordinating\nthe neuron growth to the tips of the pillars where the NV is located. Here, we\nprovide a growth study to demonstrate coordinated neuron growth as well as the\nfirst simulation of nano-scopic neuron electric and magnetic fields to assess\nthe enhancement provided by the nanopillar geometry.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2019 05:16:33 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Hanlon", "Liam", ""], ["Gautam", "Vini", ""], ["Wood", "James D. A.", ""], ["Reddy", "Prithvi", ""], ["Barson", "Michael S. J.", ""], ["Niihori", "Marika", ""], ["Silalahi", "Alexander R. J.", ""], ["Corry", "Ben", ""], ["Wrachtrup", "Joerg", ""], ["Sellars", "Matthew J.", ""], ["Daria", "Vincent R.", ""], ["Maletinsky", "Patrick", ""], ["Stuart", "Gregory J.", ""], ["Doherty", "Marcus W.", ""]]}, {"id": "1901.09948", "submitter": "Emre Neftci", "authors": "Emre O. Neftci, Hesham Mostafa, Friedemann Zenke", "title": "Surrogate Gradient Learning in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural networks are nature's versatile solution to fault-tolerant and\nenergy efficient signal processing. To translate these benefits into hardware,\na growing number of neuromorphic spiking neural network processors attempt to\nemulate biological neural networks. These developments have created an imminent\nneed for methods and tools to enable such systems to solve real-world signal\nprocessing problems. Like conventional neural networks, spiking neural networks\ncan be trained on real, domain specific data. However, their training requires\novercoming a number of challenges linked to their binary and dynamical nature.\nThis article elucidates step-by-step the problems typically encountered when\ntraining spiking neural networks, and guides the reader through the key\nconcepts of synaptic plasticity and data-driven learning in the spiking\nsetting. To that end, it gives an overview of existing approaches and provides\nan introduction to surrogate gradient methods, specifically, as a particularly\nflexible and efficient method to overcome the aforementioned challenges.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:13:55 GMT"}, {"version": "v2", "created": "Fri, 3 May 2019 16:24:45 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Neftci", "Emre O.", ""], ["Mostafa", "Hesham", ""], ["Zenke", "Friedemann", ""]]}, {"id": "1901.09975", "submitter": "Farouk Nathoo", "authors": "Yunlong Nie, Eugene Opoku, Laila Yasmin, Yin Song, Jie Wang, Sidi Wu,\n  Vanessa Scarapicchia, Jodie Gawryluk, Liangliang Wang, Jiguo Cao, Farouk S.\n  Nathoo", "title": "Spectral Dynamic Causal Modelling of Resting-State fMRI: Relating\n  Effective Brain Connectivity in the Default Mode Network to Genetics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conduct an imaging genetics study to explore how effective brain\nconnectivity in the default mode network (DMN) may be related to genetics\nwithin the context of Alzheimer's disease and mild cognitive impairment. We\ndevelop an analysis of longitudinal resting-state functional magnetic resonance\nimaging (rs-fMRI) and genetic data obtained from a sample of 111 subjects with\na total of 319 rs-fMRI scans from the Alzheimer's Disease Neuroimaging\nInitiative (ADNI) database. A Dynamic Causal Model (DCM) is fit to the rs-fMRI\nscans to estimate effective brain connectivity within the DMN and related to a\nset of single nucleotide polymorphisms (SNPs) contained in an empirical\ndisease-constrained set which is obtained out-of-sample from 663 ADNI subjects\nhaving only genome-wide data.\n  We examine longitudinal data in both a 4-region and an 6-region network and\nrelate longitudinal effective brain connectivity networks estimated using\nspectral DCM to SNPs using both linear mixed effect (LME) models as well as\nfunction-on-scalar regression (FSR). In the former case we implement a\nparametric bootstrap for testing SNP coefficients and make comparisons with\np-values obtained from the chi-squared null distribution. We also implement a\nparametric bootstrap approach for testing regression functions in FSR and we\nmake comparisons between p-values obtained from the parametric bootstrap to\np-values obtained using the F-distribution with degrees-of-freedom based on\nSatterthwaite's approximation.\n  In both networks we report on exploratory patterns of associations with\nrelatively high ranks that exhibit stability to the differing assumptions made\nby both FSR and LME.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2019 19:58:32 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2019 21:14:29 GMT"}, {"version": "v3", "created": "Sat, 4 May 2019 03:33:14 GMT"}, {"version": "v4", "created": "Wed, 8 May 2019 18:39:55 GMT"}, {"version": "v5", "created": "Fri, 10 May 2019 07:53:07 GMT"}, {"version": "v6", "created": "Wed, 21 Aug 2019 20:54:57 GMT"}, {"version": "v7", "created": "Sat, 16 Nov 2019 23:32:35 GMT"}, {"version": "v8", "created": "Tue, 2 Jun 2020 05:35:39 GMT"}], "update_date": "2020-06-03", "authors_parsed": [["Nie", "Yunlong", ""], ["Opoku", "Eugene", ""], ["Yasmin", "Laila", ""], ["Song", "Yin", ""], ["Wang", "Jie", ""], ["Wu", "Sidi", ""], ["Scarapicchia", "Vanessa", ""], ["Gawryluk", "Jodie", ""], ["Wang", "Liangliang", ""], ["Cao", "Jiguo", ""], ["Nathoo", "Farouk S.", ""]]}, {"id": "1901.10397", "submitter": "Marko Angjelichinoski", "authors": "Marko Angjelichinoski, Taposh Banerjee, John Choi, Bijan Pesaran,\n  Vahid Tarokh", "title": "Minimax-optimal decoding of movement goals from local field potentials\n  using complex spectral features", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of predicting eye movement goals from local field\npotentials (LFP) recorded through a multielectrode array in the macaque\nprefrontal cortex. The monkey is tasked with performing memory-guided saccades\nto one of eight targets during which LFP activity is recorded and used to train\na decoder. Previous reports have mainly relied on the spectral amplitude of the\nLFPs as a feature in the decoding step to limited success, while neglecting the\nphase without proper theoretical justification. This paper formulates the\nproblem of decoding eye movement intentions in a statistically optimal\nframework and uses Gaussian sequence modeling and Pinsker's theorem to generate\nminimax-optimal estimates of the LFP signals which are later used as features\nin the decoding step. The approach is shown to act as a low-pass filter and\neach LFP in the feature space is represented via its complex Fourier\ncoefficients after appropriate shrinking such that higher frequency components\nare attenuated; this way, the phase information inherently present in the LFP\nsignal is naturally embedded into the feature space. The proposed complex\nspectrum-based decoder achieves prediction accuracy of up to $94\\%$ at\nsuperficial electrode depths near the surface of the prefrontal cortex, which\nmarks a significant performance improvement over conventional power\nspectrum-based decoders.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2019 17:08:25 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Angjelichinoski", "Marko", ""], ["Banerjee", "Taposh", ""], ["Choi", "John", ""], ["Pesaran", "Bijan", ""], ["Tarokh", "Vahid", ""]]}, {"id": "1901.10962", "submitter": "Joaquin Goni", "authors": "Duy Duong-Tran, Kausar Abbas, Enrico Amico, Bernat Corominas-Murtra,\n  Mario Dzemidzic, David Kareken, Mario Ventresca and Joaqu\\'in Go\\~ni", "title": "A morphospace of functional configuration to assess configural breadth\n  based on brain functional networks", "comments": "main article: 24 pages, 8 figures, 2 tables. supporting information:\n  11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The best approach to quantify human brain functional reconfigurations in\nresponse to varying cognitive demands remains an unresolved topic in network\nneuroscience. We propose that such functional reconfigurations may be\ncategorized into three different types: i) Network Configural Breadth, ii)\nTask-to-Task transitional reconfiguration, and iii) Within-Task\nreconfiguration. In order to quantify these reconfigurations, we propose a\nmesoscopic framework focused on functional networks (FNs) or communities. To do\nso, we introduce a 2D network morphospace that relies on two novel mesoscopic\nmetrics, Trapping Efficiency (TE) and Exit Entropy (EE), which capture topology\nand integration of information within and between a reference set of FNs. In\nthis study, we use this framework to quantify the Network Configural Breadth\nacross different tasks. We show that the metrics defining this morphospace can\ndifferentiate FNs, cognitive tasks and subjects. We also show that network\nconfigural breadth significantly predicts behavioral measures, such as episodic\nmemory, verbal episodic memory, fluid intelligence and general intelligence. In\nessence, we put forth a framework to explore the cognitive space in a\ncomprehensive manner, for each individual separately, and at different levels\nof granularity. This tool that can also quantify the FN reconfigurations that\nresult from the brain switching between mental states.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 17:27:28 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 19:09:28 GMT"}, {"version": "v3", "created": "Fri, 3 Jan 2020 18:54:36 GMT"}, {"version": "v4", "created": "Fri, 6 Nov 2020 16:34:52 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Duong-Tran", "Duy", ""], ["Abbas", "Kausar", ""], ["Amico", "Enrico", ""], ["Corominas-Murtra", "Bernat", ""], ["Dzemidzic", "Mario", ""], ["Kareken", "David", ""], ["Ventresca", "Mario", ""], ["Go\u00f1i", "Joaqu\u00edn", ""]]}, {"id": "1901.10975", "submitter": "Pramod Kumbhar", "authors": "Pramod Kumbhar, Michael Hines, Jeremy Fouriaux, Aleksandr Ovcharenko,\n  James King, Fabien Delalondre, Felix Sch\\\"urmann", "title": "CoreNEURON : An Optimized Compute Engine for the NEURON Simulator", "comments": "Corresponding author: Felix Sch\\\"urman", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NEURON simulator has been developed over the past three decades and is\nwidely used by neuroscientists to model the electrical activity of neuronal\nnetworks. Large network simulation projects using NEURON have supercomputer\nallocations that individually measure in the millions of core hours.\nSupercomputer centers are transitioning to next generation architectures and\nthe work accomplished per core hour for these simulations could be improved by\nan order of magnitude if NEURON was able to better utilize those new hardware\ncapabilities. In order to adapt NEURON to evolving computer architectures, the\ncompute engine of the NEURON simulator has been extracted and has been\noptimized as a library called CoreNEURON. This paper presents the design,\nimplementation and optimizations of CoreNEURON. We describe how CoreNEURON can\nbe used as a library with NEURON and then compare performance of different\nnetwork models on multiple architectures including IBM BlueGene/Q, Intel\nSkylake, Intel MIC and NVIDIA GPU. We show how CoreNEURON can simulate existing\nNEURON network models with 4-7x less memory usage and 2-7x less execution time\nwhile maintaining binary result compatibility with NEURON.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 18:05:56 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Kumbhar", "Pramod", ""], ["Hines", "Michael", ""], ["Fouriaux", "Jeremy", ""], ["Ovcharenko", "Aleksandr", ""], ["King", "James", ""], ["Delalondre", "Fabien", ""], ["Sch\u00fcrmann", "Felix", ""]]}, {"id": "1901.11085", "submitter": "Daniel Rubinstein", "authors": "D. Rubinstein, L. Camarillo-Rodriguez, ZJ Waldman, I. Orosz, J. Stein,\n  S. Das, R. Gorniak, AD Sharan, R. Gross, BC Lega, K. Zaghloul, BC Jobst, KA\n  Davis, PA Wanda, G. Worrell, MR Sperling, SA Weiss", "title": "High gamma and beta band oscillations in left ventral posterior parietal\n  cortex are regionally dissociated during verbal episodic encoding and recall", "comments": "methodological flaws/concerns of scientific validity, and lack of\n  agreement among co-authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The posterior parietal cortex (PPC) has a unique role in memory retrieval:\nfMRI and electrocorticography studies suggest that within the ventral PPC (VPC)\nspecifically, there is an anterior-posterior functional divergence between\nexternally-oriented and internally-oriented attention to memory (AtoM).\nHowever, the role of VPC during verbal episodic encoding, and the relationship\nbetween encoding- and retrieval-related activity, is less understood. Here we\nshow that activation within a subregion of VPC is doubly dissociated between\nits anterior and posterior parts, during encoding compared to recall in a free\nrecall task. We found that regional activation defined by increased high gamma\npower and decreased beta power oscillations during encoding and recall\ncorrelated with recall success. During word encoding, iEEG sites that showed\nthis correlation were located anterior to those that showed deactivation.\nConversely, during word recall, sites that showed stronger correlations between\nactivity and number of words recalled were located more posteriorly. Our\nresults demonstrate the significance of high gamma and beta oscillations\nsuggesting a push-pull relationship between attention to external stimuli and\ninternal memories within left ventral PPC. Knowledge of this divergence of\nfunction along the anterior-posterior axis within left ventral PPC may prove\nuseful for guiding brain stimulation strategies.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 20:24:48 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2019 20:30:30 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Rubinstein", "D.", ""], ["Camarillo-Rodriguez", "L.", ""], ["Waldman", "ZJ", ""], ["Orosz", "I.", ""], ["Stein", "J.", ""], ["Das", "S.", ""], ["Gorniak", "R.", ""], ["Sharan", "AD", ""], ["Gross", "R.", ""], ["Lega", "BC", ""], ["Zaghloul", "K.", ""], ["Jobst", "BC", ""], ["Davis", "KA", ""], ["Wanda", "PA", ""], ["Worrell", "G.", ""], ["Sperling", "MR", ""], ["Weiss", "SA", ""]]}, {"id": "1901.11110", "submitter": "Stefan Seelig", "authors": "Stefan A. Seelig, Maximilian M. Rabe, Noa Malem-Shinitski, Sarah\n  Risse, Sebastian Reich, Ralf Engbert", "title": "Bayesian parameter estimation for the SWIFT model of eye-movement\n  control during reading", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process-oriented theories of cognition must be evaluated against time-ordered\nobservations. Here we present a representative example for data assimilation of\nthe SWIFT model, a dynamical model of the control of spatial fixation position\nand fixation duration during reading. First, we develop and test an approximate\nlikelihood function of the model, which is a combination of a pseudo-marginal\nspatial likelihood and an approximate temporal likelihood function. Second, we\nuse a Bayesian approach to parameter inference using an adapative Markov chain\nMonte Carlo procedure. Our results indicate that model parameters can be\nestimated reliably for individual subjects. We conclude that approximative\nBayesian inference represents a considerable step forward for the area of\neye-movement modeling, where modelling of individual data on the basis of\nprocess-based dynamic models has not been possible before.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 21:36:53 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 16:39:54 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2019 14:43:01 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Seelig", "Stefan A.", ""], ["Rabe", "Maximilian M.", ""], ["Malem-Shinitski", "Noa", ""], ["Risse", "Sarah", ""], ["Reich", "Sebastian", ""], ["Engbert", "Ralf", ""]]}, {"id": "1901.11418", "submitter": "Weisi Guo", "authors": "Zhuangkun Wei, Bin Li, Weisi Guo, Wenxiu Hu, Chenglin Zhao", "title": "Sequential Bayesian Detection of Spike Activities from Fluorescence\n  Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting and detecting spike activities from the fluorescence observations\nis an important step in understanding how neuron systems work. The main\nchallenge lies in that the combination of the ambient noise with dynamic\nbaseline fluctuation, often contaminates the observations, thereby\ndeteriorating the reliability of spike detection. This may be even worse in the\nface of the nonlinear biological process, the coupling interactions between\nspikes and baseline, and the unknown critical parameters of an underlying\nphysiological model, in which erroneous estimations of parameters will affect\nthe detection of spikes causing further error propagation. In this paper, we\npropose a random finite set (RFS) based Bayesian approach. The dynamic\nbehaviors of spike sequence, fluctuated baseline and unknown parameters are\nformulated as one RFS. This RFS state is capable of distinguishing the hidden\nactive/silent states induced by spike and non-spike activities respectively,\nthereby \\emph{negating the interaction role} played by spikes and other\nfactors. Then, premised on the RFS states, a Bayesian inference scheme is\ndesigned to simultaneously estimate the model parameters, baseline, and crucial\nspike activities. Our results demonstrate that the proposed scheme can gain an\nextra $12\\%$ detection accuracy in comparison with the state-of-the-art MLSpike\nmethod.\n", "versions": [{"version": "v1", "created": "Thu, 31 Jan 2019 15:14:28 GMT"}], "update_date": "2019-02-01", "authors_parsed": [["Wei", "Zhuangkun", ""], ["Li", "Bin", ""], ["Guo", "Weisi", ""], ["Hu", "Wenxiu", ""], ["Zhao", "Chenglin", ""]]}]