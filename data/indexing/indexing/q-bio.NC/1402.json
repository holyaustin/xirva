[{"id": "1402.0530", "submitter": "Jonathan Touboul", "authors": "Gr\\'egory Faye and Jonathan Touboul", "title": "Pulsatile localized dynamics in delayed neural-field equations in\n  arbitrary dimension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS nlin.PS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural field equations are integro-differential systems describing the\nmacroscopic activity of spatially extended pieces of cortex. In such cortical\nassemblies, the propagation of information and the transmission machinery\ninduce communication delays, due to the transport of information (propagation\ndelays) and to the synaptic machinery (constant delays). We investigate the\nrole of these delays on the formation of structured spatiotemporal patterns for\nthese systems in arbitrary dimensions. We focus on localized activity, either\ninduced by the presence of a localized stimulus (pulses) or by transitions\nbetween two levels of activity (fronts). Linear stability analysis allows to\nreveal the existence of Hopf bifurcation curves induced by the delays, along\ndifferent modes that may be symmetric or asymmetric. We show that instabilities\nstrongly depend on the dimension, and in particular may exhibit transversal\ninstabilities along invariant directions. These instabilities yield pulsatile\nlocalized activity, and depending on the symmetry of the destabilized modes,\neither produce spatiotemporal breathing or sloshing patterns.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 21:38:18 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Faye", "Gr\u00e9gory", ""], ["Touboul", "Jonathan", ""]]}, {"id": "1402.0710", "submitter": "Andrea Soltoggio", "authors": "Andrea Soltoggio", "title": "Short-term plasticity as cause-effect hypothesis testing in distal\n  reward learning", "comments": "Biological Cybernetics, September 2014", "journal-ref": null, "doi": "10.1007/s00422-014-0628-0", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asynchrony, overlaps and delays in sensory-motor signals introduce ambiguity\nas to which stimuli, actions, and rewards are causally related. Only the\nrepetition of reward episodes helps distinguish true cause-effect relationships\nfrom coincidental occurrences. In the model proposed here, a novel plasticity\nrule employs short and long-term changes to evaluate hypotheses on cause-effect\nrelationships. Transient weights represent hypotheses that are consolidated in\nlong-term memory only when they consistently predict or cause future rewards.\nThe main objective of the model is to preserve existing network topologies when\nlearning with ambiguous information flows. Learning is also improved by biasing\nthe exploration of the stimulus-response space towards actions that in the past\noccurred before rewards. The model indicates under which conditions beliefs can\nbe consolidated in long-term memory, it suggests a solution to the\nplasticity-stability dilemma, and proposes an interpretation of the role of\nshort-term plasticity.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 12:37:20 GMT"}, {"version": "v2", "created": "Mon, 9 Jun 2014 14:22:29 GMT"}, {"version": "v3", "created": "Fri, 11 Jul 2014 13:06:49 GMT"}, {"version": "v4", "created": "Mon, 11 Aug 2014 13:37:45 GMT"}, {"version": "v5", "created": "Tue, 9 Sep 2014 15:42:23 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Soltoggio", "Andrea", ""]]}, {"id": "1402.0836", "submitter": "Sakyasingha Dasgupta", "authors": "Sakyasingha Dasgupta", "title": "Cognitive Aging as Interplay between Hebbian Learning and Criticality", "comments": "Concise version of MSc thesis, Neural Models of the Ageing Brain,\n  University of Edinburgh, 2010. Supervisor Dr. J. Michael Herrmann. 64 pages,\n  20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive ageing seems to be a story of global degradation. As one ages there\nare a number of physical, chemical and biological changes that take place.\nTherefore it is logical to assume that the brain is no exception to this\nphenomenon. The principle purpose of this project is to use models of neural\ndynamics and learning based on the underlying principle of self-organised\ncriticality, to account for the age related cognitive effects. In this regard\nlearning in neural networks can serve as a model for the acquisition of skills\nand knowledge in early development stages i.e. the ageing process and\ncriticality in the network serves as the optimum state of cognitive abilities.\nPossible candidate mechanisms for ageing in a neural network are loss of\nconnectivity and neurons, increase in the level of noise, reduction in white\nmatter or more interestingly longer learning history and the competition among\nseveral optimization objectives. In this paper we are primarily interested in\nthe affect of the longer learning history on memory and thus the optimality in\nthe brain. Hence it is hypothesized that prolonged learning in the form of\nassociative memory patterns can destroy the state of criticality in the\nnetwork. We base our model on Tsodyks and Markrams [49] model of dynamic\nsynapses, in the process to explore the effect of combining standard Hebbian\nlearning with the phenomenon of Self-organised criticality. The project mainly\nconsists of evaluations and simulations of networks of integrate and\nfire-neurons that have been subjected to various combinations of neural-level\nageing effects, with the aim of establishing the primary hypothesis and\nunderstanding the decline of cognitive abilities due to ageing, using one of\nits important characteristics, a longer learning history.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 19:16:34 GMT"}], "update_date": "2014-08-07", "authors_parsed": [["Dasgupta", "Sakyasingha", ""]]}, {"id": "1402.0863", "submitter": "Sergiusz  Wesolowski", "authors": "Sergiusz Wesolowski, Alexandre A. Nikonov, Robert J. Contreras, Wei Wu", "title": "A comparison of Euclidean metrics and their application in statistical\n  inferences in the spike train space", "comments": "Withdrawn, new, extended results sumbmitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistical analysis and inferences on spike trains are one of the central\ntopics in neural coding. It is of great interest to understand the underlying\ndistribution and geometric structure of given spike train data. However, a\nfundamental obstacle is that the space of all spike trains is not an Euclidean\nspace, and non-Euclidean metrics have been commonly used in the literature to\ncharacterize the variability and pattern in neural observations. Over the past\nfew years, two Euclidean-like metrics were independently developed to measure\ndistance in the spike train space. An important benefit of these metrics is\nthat the spike train space will be suitable for embedding in Euclidean spaces\ndue to their Euclidean properties. In this paper, we systematically compare\nthese two metrics on theory, properties, and applications. Because of its\nEuclidean properties, one of these metrics has been further used in defining\nsummary statistics (i.e. mean and variance) and conducting statistical\ninferences in the spike train space. Here we provide equivalent definitions\nusing the other metric and show that consistent statistical inferences can be\nconducted. We then apply both inference frameworks in a neural coding problem\nfor a recording in geniculate ganglion stimulated by different tastes. It is\nfound that both frameworks achieve desirable results and provide useful new\ntools in statistical inferences in neural spike train space.\n", "versions": [{"version": "v1", "created": "Mon, 3 Feb 2014 22:14:51 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2015 03:16:45 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Wesolowski", "Sergiusz", ""], ["Nikonov", "Alexandre A.", ""], ["Contreras", "Robert J.", ""], ["Wu", "Wei", ""]]}, {"id": "1402.1959", "submitter": "Chun-Chung Chen", "authors": "Hao Song, Chun-Chung Chen, Jyh-Jang Sun, Pik-Yin Lai, and C. K. Chan", "title": "Reconstruction of network structures from repeating spike patterns in\n  simulated bursting dynamics", "comments": "9 pages, 9 figures", "journal-ref": "Phys. Rev. E 90, 012703 (2014)", "doi": "10.1103/PhysRevE.90.012703", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repeating patterns of spike sequences from a neuronal network have been\nproposed to be useful in the reconstruction of the network topology.\nReverberations in a physiologically realistic model with various physical\nconnection topologies (from random to scale-free) have been simulated to study\nthe effectiveness of the pattern-matching method in the reconstruction of\nnetwork topology from network dynamics. Simulation results show that functional\nnetworks reconstructed from repeating spike patterns can be quite different\nfrom the original physical networks; even global properties, such as the degree\ndistribution, cannot always be recovered. However, the pattern-matching method\ncan be effective in identifying hubs in the network. Since the form of\nreverberations are quite different for networks with and without hubs, the form\nof reverberations together with the reconstruction by repeating spike patterns\nmight provide a reliable method to detect hubs in neuronal cultures.\n", "versions": [{"version": "v1", "created": "Sun, 9 Feb 2014 15:51:00 GMT"}, {"version": "v2", "created": "Sat, 12 Jul 2014 16:11:37 GMT"}], "update_date": "2014-07-15", "authors_parsed": [["Song", "Hao", ""], ["Chen", "Chun-Chung", ""], ["Sun", "Jyh-Jang", ""], ["Lai", "Pik-Yin", ""], ["Chan", "C. K.", ""]]}, {"id": "1402.2196", "submitter": "Karin Vadovi\\v{c}ov\\'a", "authors": "Karin Vadovi\\v{c}ov\\'a", "title": "Affective and cognitive prefrontal cortex projections to the lateral\n  habenula in humans", "comments": "I renamed the medioventral part of the anterior thalamus via which\n  the PFC to LHb fibre tracts from ventral anterior (AV) to medial anterior\n  thalamic region. Apologies for that. My co-author decided to remove his name", "journal-ref": null, "doi": "10.3389/fnhum.2014.00819", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anterior insula (AI) and dACC are known to process information about pain,\nloss, adversities, bad, harmful or suboptimal choices and consequences that\nthreaten survival or well-being. Pain and loss activate also pregenual ACC\n(pgACC), linked to sad thoughts, hurt and regrets. The lateral habenula (LHb)\nis stimulated by predicted and received pain, discomfort, aversive outcome,\nloss. Its chronic stimulation makes us feel worse/low and gradually stops us\nchoosing and moving for suboptimal, hurtful or punished choices, by direct and\nindirect (via RMTg) inhibition of DRN and VTA/SNc. Response selectivity of LHb\nneurons suggests their cortical input from affective and cognitive evaluative\nregions that make expectations about bad or suboptimal outcomes. Based on these\nfacts I predicted direct corticohabenular projections from the dACC, pgACC and\nAI, as part of the adversity processing circuit that learns to avoid bad\noutcomes by suppressing dopamine and serotonin signal. Using DTI I found dACC,\npgACC, AI, adjacent caudolateral and lateral OFC projections to LHb. I\npredicted no corticohabenular projections from the reward processing regions:\nmedial OFC and vACC because both respond most strongly to good, high value\nstimuli and outcomes, inducing serotonin and dopamine release respectively.\nThis lack of LHb projections was confirmed for vACC and likely for mOFC. The\nsurprising findings were the corticohabenular projections from the cognitive\nprefrontal cortex regions, known for flexible reasoning, planning and combining\nwhatever information are relevant for reaching current goals. I propose that\nprefrontohabenular projections provide a teaching signal for value-based choice\nbehaviour, to learn to deselect, avoid or inhibit the potentially harmful, low\nvalued or wrong choices, goals, strategies, predictions, models and ways of\ndoing things, to prevent bad or suboptimal consequences.\n", "versions": [{"version": "v1", "created": "Mon, 10 Feb 2014 16:13:53 GMT"}, {"version": "v2", "created": "Fri, 28 Mar 2014 19:33:07 GMT"}, {"version": "v3", "created": "Sat, 26 Apr 2014 21:06:29 GMT"}, {"version": "v4", "created": "Sat, 3 May 2014 07:07:12 GMT"}, {"version": "v5", "created": "Sat, 24 May 2014 13:52:39 GMT"}, {"version": "v6", "created": "Fri, 20 Jun 2014 08:41:29 GMT"}, {"version": "v7", "created": "Fri, 1 Aug 2014 09:54:09 GMT"}, {"version": "v8", "created": "Tue, 30 Sep 2014 07:55:11 GMT"}, {"version": "v9", "created": "Mon, 13 Oct 2014 20:08:06 GMT"}], "update_date": "2014-10-15", "authors_parsed": [["Vadovi\u010dov\u00e1", "Karin", ""]]}, {"id": "1402.2584", "submitter": "Peter Thomas PhD", "authors": "David F. Anderson and Bard Ermentrout and Peter J. Thomas", "title": "Stochastic Representations of Ion Channel Kinetics and Exact Stochastic\n  Simulation of Neuronal Dynamics", "comments": "39 pages, 6 figures, appendix with XPP and Matlab code", "journal-ref": "Journal of Computational Neuroscience: Volume 38, Issue 1 (2015),\n  Page 67-82", "doi": "10.1007/s10827-014-0528-2", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we provide two representations for stochastic ion channel\nkinetics, and compare the performance of exact simulation with a commonly used\nnumerical approximation strategy. The first representation we present is a\nrandom time change representation, popularized by Thomas Kurtz, with the second\nbeing analogous to a \"Gillespie\" representation. Exact stochastic algorithms\nare provided for the different representations, which are preferable to either\n(a) fixed time step or (b) piecewise constant propensity algorithms, which\nstill appear in the literature. As examples, we provide versions of the exact\nalgorithms for the Morris-Lecar conductance based model, and detail the error\ninduced, both in a weak and a strong sense, by the use of approximate\nalgorithms on this model. We include ready-to-use implementations of the random\ntime change algorithm in both XPP and Matlab. Finally, through the\nconsideration of parametric sensitivity analysis, we show how the\nrepresentations presented here are useful in the development of further\ncomputational methods. The general representations and simulation strategies\nprovided here are known in other parts of the sciences, but less so in the\npresent setting.\n", "versions": [{"version": "v1", "created": "Tue, 11 Feb 2014 18:05:25 GMT"}, {"version": "v2", "created": "Wed, 3 Sep 2014 04:08:23 GMT"}, {"version": "v3", "created": "Tue, 11 Nov 2014 21:37:42 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Anderson", "David F.", ""], ["Ermentrout", "Bard", ""], ["Thomas", "Peter J.", ""]]}, {"id": "1402.2820", "submitter": "Pascal Grange", "authors": "Pascal Grange, Jason W. Bohland, Benjamin Okaty, Ken Sugino, Hemant\n  Bokil, Sacha Nelson, Lydia Ng, Michael Hawrylycz and Partha P. Mitra", "title": "Cell-type-specific transcriptomes and the Allen Atlas (II): discussion\n  of the linear model of brain-wide densities of cell types", "comments": "178 pages, 207 figures, 7 tables; v2: typos corrected; v3: more typos\n  corrected, missing pseudo-code in section 3.5 written, image attachment\n  changed in Figure 6, misuse of notation $r^{signal}$ corrected, conclusions\n  unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The voxelized Allen Atlas of the adult mouse brain (at a resolution of 200\nmicrons) has been used in [arXiv:1303.0013] to estimate the region-specificity\nof 64 cell types whose transcriptional profile in the mouse brain has been\nmeasured in microarray experiments. In particular, the model yields estimates\nfor the brain-wide density of each of these cell types. We conduct numerical\nexperiments to estimate the errors in the estimated density profiles. First of\nall, we check that a simulated thalamic profile based on 200 well-chosen genes\ncan transfer signal from cerebellar Purkinje cells to the thalamus. This\ninspires us to sub-sample the atlas of genes by repeatedly drawing random sets\nof 200 genes and refitting the model. This results in a random distribution of\ndensity profiles, that can be compared to the predictions of the model. This\nresults in a ranking of cell types by the overlap between the original and\nsub-sampled density profiles. Cell types with high rank include medium spiny\nneurons, several samples of cortical pyramidal neurons, hippocampal pyramidal\nneurons, granule cells and cholinergic neurons from the brain stem. In some\ncases with lower rank, the average sub-sample can have better contrast\nproperties than the original model (this is the case for amygdalar neurons and\ndopaminergic neurons from the ventral midbrain). Finally, we add some noise to\nthe cell-type-specific transcriptomes by mixing them using a scalar parameter\nweighing a random matrix. After refitting the model, we observe than a mixing\nparameter of $5\\%$ leads to modifications of density profiles that span the\nsame interval as the ones resulting from sub-sampling.\n", "versions": [{"version": "v1", "created": "Wed, 12 Feb 2014 13:49:44 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2014 11:34:33 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2014 13:05:31 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Grange", "Pascal", ""], ["Bohland", "Jason W.", ""], ["Okaty", "Benjamin", ""], ["Sugino", "Ken", ""], ["Bokil", "Hemant", ""], ["Nelson", "Sacha", ""], ["Ng", "Lydia", ""], ["Hawrylycz", "Michael", ""], ["Mitra", "Partha P.", ""]]}, {"id": "1402.3022", "submitter": "Arkady Zgonnikov", "authors": "Arkady Zgonnikov, Ihor Lubashevsky, Shigeru Kanemoto, Toru Miyazawa,\n  Takashi Suzuki", "title": "To react or not to react? Intrinsic stochasticity of human control in\n  virtual stick balancing", "comments": "18 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph cs.SY nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how humans control unstable systems is central to many research\nproblems, with applications ranging from quiet standing to aircraft landing.\nIncreasingly much evidence appears in favor of event-driven control hypothesis:\nhuman operators only start actively controlling the system when the discrepancy\nbetween the current and desired system states becomes large enough. The\nevent-driven models based on the concept of threshold can explain many features\nof the experimentally observed dynamics. However, much still remains unclear\nabout the dynamics of human-controlled systems, which likely indicates that\nhumans employ more intricate control mechanisms. The present paper argues that\ncontrol activation in humans may be not threshold-driven, but instead\nintrinsically stochastic, noise-driven. Specifically, we suggest that control\nactivation stems from stochastic interplay between the operator's need to keep\nthe controlled system near the goal state on one hand and the tendency to\npostpone interrupting the system dynamics on the other hand. We propose a model\ncapturing this interplay and show that it matches the experimental data on\nhuman balancing of virtual overdamped stick. Our results illuminate that the\nnoise-driven activation mechanism plays a crucial role at least in the\nconsidered task, and, hypothetically, in a broad range of human-controlled\nprocesses.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 02:42:49 GMT"}, {"version": "v2", "created": "Mon, 9 Jun 2014 14:11:59 GMT"}, {"version": "v3", "created": "Mon, 16 Jun 2014 01:49:52 GMT"}], "update_date": "2014-06-17", "authors_parsed": [["Zgonnikov", "Arkady", ""], ["Lubashevsky", "Ihor", ""], ["Kanemoto", "Shigeru", ""], ["Miyazawa", "Toru", ""], ["Suzuki", "Takashi", ""]]}, {"id": "1402.3344", "submitter": "Zhang Chong", "authors": "Chong Zhang, Yu Zhao, Jochen Triesch and Bertram E. Shi", "title": "Intrinsically Motivated Learning of Visual Motion Perception and Smooth\n  Pursuit", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We extend the framework of efficient coding, which has been used to model the\ndevelopment of sensory processing in isolation, to model the development of the\nperception/action cycle. Our extension combines sparse coding and reinforcement\nlearning so that sensory processing and behavior co-develop to optimize a\nshared intrinsic motivational signal: the fidelity of the neural encoding of\nthe sensory input under resource constraints. Applying this framework to a\nmodel system consisting of an active eye behaving in a time varying\nenvironment, we find that this generic principle leads to the simultaneous\ndevelopment of both smooth pursuit behavior and model neurons whose properties\nare similar to those of primary visual cortical neurons selective for different\ndirections of visual motion. We suggest that this general principle may form\nthe basis for a unified and integrated explanation of many perception/action\nloops.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 01:27:41 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2014 03:00:00 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Zhang", "Chong", ""], ["Zhao", "Yu", ""], ["Triesch", "Jochen", ""], ["Shi", "Bertram E.", ""]]}, {"id": "1402.3375", "submitter": "Thaddeus Cybulski R", "authors": "Thaddeus R. Cybulski, Joshua I. Glaser, Adam H. Marblestone, Bradley\n  M. Zamft, Edward S. Boyden, George M. Church, Konrad P. Kording", "title": "Spatial Information in Large-Scale Neural Recordings", "comments": "38 pages, 7 figures", "journal-ref": null, "doi": "10.3389/fncom.2014.00172", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central issue in neural recording is that of distinguishing the activities\nof many neurons. Here, we develop a framework, based on Fisher information, to\nquantify how separable a neuron's activity is from the activities of nearby\nneurons. We (1) apply this framework to model information flow and spatial\ndistinguishability for several electrical and optical neural recording methods,\n(2) provide analytic expressions for information content, and (3) demonstrate\npotential applications of the approach. This method generalizes to many\nrecording devices that resolve objects in space and thus may be useful in the\ndesign of next-generation scalable neural recording systems.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 06:28:06 GMT"}, {"version": "v2", "created": "Fri, 17 Oct 2014 14:41:10 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Cybulski", "Thaddeus R.", ""], ["Glaser", "Joshua I.", ""], ["Marblestone", "Adam H.", ""], ["Zamft", "Bradley M.", ""], ["Boyden", "Edward S.", ""], ["Church", "George M.", ""], ["Kording", "Konrad P.", ""]]}, {"id": "1402.3563", "submitter": "Mathieu Galtier", "authors": "Mathieu Galtier", "title": "Ideomotor feedback control in a recurrent neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The architecture of a neural network controlling an unknown environment is\npresented. It is based on a randomly connected recurrent neural network from\nwhich both perception and action are simultaneously read and fed back. There\nare two concurrent learning rules implementing a sort of ideomotor control: (i)\nperception is learned along the principle that the network should predict\nreliably its incoming stimuli; (ii) action is learned along the principle that\nthe prediction of the network should match a target time series. The coherent\nbehavior of the neural network in its environment is a consequence of the\ninteraction between the two principles. Numerical simulations show the\npromising performance of the approach, which can be turned into a local, and\nthus \"biologically plausible\", algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 14 Feb 2014 19:57:21 GMT"}, {"version": "v2", "created": "Mon, 17 Feb 2014 17:20:03 GMT"}, {"version": "v3", "created": "Sun, 23 Feb 2014 09:23:43 GMT"}, {"version": "v4", "created": "Sun, 18 Jan 2015 22:02:17 GMT"}], "update_date": "2015-01-20", "authors_parsed": [["Galtier", "Mathieu", ""]]}, {"id": "1402.4058", "submitter": "Ihor Lubashevsky", "authors": "Ihor Lubashevsky and Bohdan Datsko", "title": "Fractional Dynamics and Multi-Slide Model of Human Memory", "comments": "Submitted to 36th Annual Conference of the Cognitive Science Society,\n  Quebec City, Canada, July 23-26 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a single chunk model of long-term memory that combines the basic\nfeatures of the ACT-R theory and the multiple trace memory architecture. The\npivot point of the developed theory is a mathematical description of the\ncreation of new memory traces caused by learning a certain fragment of\ninformation pattern and affected by the fragments of this pattern already\nretained by the current moment of time. Using the available psychological and\nphysiological data these constructions are justified. The final equation\ngoverning the learning and forgetting processes is constructed in the form of\nthe differential equation with the Caputo type fractional time derivative.\nSeveral characteristic situations of the learning (continuous and\ndiscontinuous) and forgetting processes are studied numerically. In particular,\nit is demonstrated that, first, the \"learning\" and \"forgetting\" exponents of\nthe corresponding power laws of the memory fractional dynamics should be\nregarded as independent system parameters. Second, as far as the spacing\neffects are concerned, the longer the discontinuous learning process, the\nlonger the time interval within which a subject remembers the information\nwithout its considerable lost. Besides, the latter relationship is a linear\nproportionality.\n", "versions": [{"version": "v1", "created": "Thu, 13 Feb 2014 05:06:43 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Lubashevsky", "Ihor", ""], ["Datsko", "Bohdan", ""]]}, {"id": "1402.4579", "submitter": "Venkatakrishnan Ramaswamy", "authors": "Venkatakrishnan Ramaswamy, Arunava Banerjee", "title": "Connectomic Constraints on Computation in Feedforward Networks of\n  Spiking Neurons", "comments": "Accepted at the Journal of Computational Neuroscience", "journal-ref": null, "doi": "10.1007/s10827-014-0497-5", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several efforts are currently underway to decipher the connectome or parts\nthereof in a variety of organisms. Ascertaining the detailed physiological\nproperties of all the neurons in these connectomes, however, is out of the\nscope of such projects. It is therefore unclear to what extent knowledge of the\nconnectome alone will advance a mechanistic understanding of computation\noccurring in these neural circuits, especially when the high-level function of\nthe said circuit is unknown. We consider, here, the question of how the wiring\ndiagram of neurons imposes constraints on what neural circuits can compute,\nwhen we cannot assume detailed information on the physiological response\nproperties of the neurons. We call such constraints -- that arise by virtue of\nthe connectome -- connectomic constraints on computation. For feedforward\nnetworks equipped with neurons that obey a deterministic spiking neuron model\nwhich satisfies a small number of properties, we ask if just by knowing the\narchitecture of a network, we can rule out computations that it could be doing,\nno matter what response properties each of its neurons may have. We show\nresults of this form, for certain classes of network architectures. On the\nother hand, we also prove that with the limited set of properties assumed for\nour model neurons, there are fundamental limits to the constraints imposed by\nnetwork structure. Thus, our theory suggests that while connectomic constraints\nmight restrict the computational ability of certain classes of network\narchitectures, we may require more elaborate information on the properties of\nneurons in the network, before we can discern such results for other classes of\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 08:07:40 GMT"}], "update_date": "2014-04-03", "authors_parsed": [["Ramaswamy", "Venkatakrishnan", ""], ["Banerjee", "Arunava", ""]]}, {"id": "1402.4648", "submitter": "Wiktor Mlynarski", "authors": "Wiktor M{\\l}ynarski and J\\\"urgen Jost", "title": "Natural statistics of binaural sounds", "comments": "29 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Binaural sound localization is usually considered a discrimination task,\nwhere interaural time (ITD) and level (ILD) disparities at pure frequency\nchannels are utilized to identify a position of a sound source. In natural\nconditions binaural circuits are exposed to a stimulation by sound waves\noriginating from multiple, often moving and overlapping sources. Therefore\nstatistics of binaural cues depend on acoustic properties and the spatial\nconfiguration of the environment. In order to process binaural sounds\nefficiently, the auditory system should be adapted to naturally encountered cue\ndistributions. Statistics of cues encountered naturally and their dependence on\nthe physical properties of an auditory scene have not been studied before.\nHere, we performed binaural recordings of three auditory scenes with varying\nspatial properties. We have analyzed empirical cue distributions from each\nscene by fitting them with parametric probability density functions which\nallowed for an easy comparison of different scenes. Higher order statistics of\nbinaural waveforms were analyzed by performing Independent Component Analysis\n(ICA) and studying properties of learned basis functions. Obtained results can\nbe related to known neuronal mechanisms and suggest how binaural hearing can be\nunderstood in terms of adaptation to the natural signal statistics.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 12:47:05 GMT"}, {"version": "v2", "created": "Sat, 1 Mar 2014 01:32:16 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["M\u0142ynarski", "Wiktor", ""], ["Jost", "J\u00fcrgen", ""]]}, {"id": "1402.4802", "submitter": "Lu\\'is F.  Seoane MSc", "authors": "Ricard V. Sol\\'e and Lu\\'is F. Seoane", "title": "Ambiguity in language networks", "comments": "19 pages, 5 figures, review and book chapter", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human language defines the most complex outcomes of evolution. The emergence\nof such an elaborated form of communication allowed humans to create extremely\nstructured societies and manage symbols at different levels including, among\nothers, semantics. All linguistic levels have to deal with an astronomic\ncombinatorial potential that stems from the recursive nature of languages. This\nrecursiveness is indeed a key defining trait. However, not all words are\nequally combined nor frequent. In breaking the symmetry between less and more\noften used and between less and more meaning-bearing units, universal scaling\nlaws arise. Such laws, common to all human languages, appear on different\nstages from word inventories to networks of interacting words. Among these\nseemingly universal traits exhibited by language networks, ambiguity appears to\nbe a specially relevant component. Ambiguity is avoided in most computational\napproaches to language processing, and yet it seems to be a crucial element of\nlanguage architecture. Here we review the evidence both from language network\narchitecture and from theoretical reasonings based on a least effort argument.\nAmbiguity is shown to play an essential role in providing a source of language\nefficiency, and is likely to be an inevitable byproduct of network growth.\n", "versions": [{"version": "v1", "created": "Tue, 18 Feb 2014 09:26:17 GMT"}, {"version": "v2", "created": "Thu, 13 Mar 2014 15:10:40 GMT"}], "update_date": "2014-03-14", "authors_parsed": [["Sol\u00e9", "Ricard V.", ""], ["Seoane", "Lu\u00eds F.", ""]]}, {"id": "1402.4824", "submitter": "Sergio G\\'omez", "authors": "Sara Teller, Clara Granell, Manlio De Domenico, Jordi Soriano, Sergio\n  Gomez, Alex Arenas", "title": "Emergence of assortative mixing between clusters of cultured neurons", "comments": "33 pages, 10 figures", "journal-ref": "PLOS Comput. Biol. 10(9) (2014) e1003796", "doi": "10.1371/journal.pcbi.1003796", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the activity of neuronal cultures is considered to be a good\nproxy of the functional connectivity of in vivo neuronal tissues. Thus, the\nfunctional complex network inferred from activity patterns is a promising way\nto unravel the interplay between structure and functionality of neuronal\nsystems. Here, we monitor the spontaneous self-sustained dynamics in neuronal\ncultures formed by interconnected aggregates of neurons (clusters). Dynamics is\ncharacterized by the fast activation of groups of clusters in sequences termed\nbursts. The analysis of the time delays between clusters' activations within\nthe bursts allows the reconstruction of the directed functional connectivity of\nthe network. We propose a method to statistically infer this connectivity and\nanalyze the resulting properties of the associated complex networks.\nSurprisingly enough, in contrast to what has been reported for many biological\nnetworks, the clustered neuronal cultures present assortative mixing\nconnectivity values, as well as a rich--club core, meaning that there is a\npreference for clusters to link to other clusters that share similar functional\nconnectivity, which shapes a `connectivity backbone' in the network. These\nresults point out that the grouping of neurons and the assortative connectivity\nbetween clusters are intrinsic survival mechanisms of the culture.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 21:05:25 GMT"}, {"version": "v2", "created": "Mon, 7 Jul 2014 19:13:46 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Teller", "Sara", ""], ["Granell", "Clara", ""], ["De Domenico", "Manlio", ""], ["Soriano", "Jordi", ""], ["Gomez", "Sergio", ""], ["Arenas", "Alex", ""]]}, {"id": "1402.5289", "submitter": "Paolo Moretti", "authors": "Pablo Villegas, Paolo Moretti, Miguel A. Mu\\~noz", "title": "Frustrated hierarchical synchronization and emergent complexity in the\n  human connectome network", "comments": "4 Figures", "journal-ref": "Scientific reports 4 (2014) 5990", "doi": "10.1038/srep05990", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spontaneous emergence of coherent behavior through synchronization plays\na key role in neural function, and its anomalies often lie at the basis of\npathologies. Here we employ a parsimonious (mesoscopic) approach to study\nanalytically and computationally the synchronization (Kuramoto) dynamics on the\nactual human-brain connectome network. We elucidate the existence of a\nso-far-uncovered intermediate phase, placed between the standard synchronous\nand asynchronous phases, i.e. between order and disorder. This novel phase\nstems from the hierarchical modular organization of the connectome. Where one\nwould expect a hierarchical synchronization process, we show that the interplay\nbetween structural bottlenecks and quenched intrinsic frequency heterogeneities\nat many different scales, gives rise to frustrated synchronization,\nmetastability, and chimera-like states, resulting in a very rich and complex\nphenomenology. We uncover the origin of the dynamic freezing behind these\nfeatures by using spectral graph theory and discuss how the emerging complex\nsynchronization patterns relate to the need for the brain to access --in a\nrobust though flexible way-- a large variety of functional attractors and\ndynamical repertoires without ad hoc fine-tuning to a critical point.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 13:17:15 GMT"}, {"version": "v2", "created": "Thu, 3 Jul 2014 15:07:31 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Villegas", "Pablo", ""], ["Moretti", "Paolo", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}, {"id": "1402.5332", "submitter": "Danko Nikolic", "authors": "Danko Nikoli\\'c", "title": "Practopoiesis: Or how life fosters a mind", "comments": "Revised version in response to reviewer comments", "journal-ref": "(2015) Journal of Theoretical Biology Volume 373, 21 May 2015,\n  Pages 40-61", "doi": "10.1016/j.jtbi.2015.03.003", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mind is a biological phenomenon. Thus, biological principles of\norganization should also be the principles underlying mental operations.\nPractopoiesis states that the key for achieving intelligence through adaptation\nis an arrangement in which mechanisms laying a lower level of organization, by\ntheir operations and interaction with the environment, enable creation of\nmechanisms lying at a higher level of organization. When such an organizational\nadvance of a system occurs, it is called a traverse. A case of traverse is when\nplasticity mechanisms (at a lower level of organization), by their operations,\ncreate a neural network anatomy (at a higher level of organization). Another\ncase is the actual production of behavior by that network, whereby the\nmechanisms of neuronal activity operate to create motor actions. Practopoietic\ntheory explains why the adaptability of a system increases with each increase\nin the number of traverses. With a larger number of traverses, a system can be\nrelatively small and yet, produce a higher degree of adaptive/intelligent\nbehavior than a system with a lower number of traverses. The present analyses\nindicate that the two well-known traverses-neural plasticity and neural\nactivity-are not sufficient to explain human mental capabilities. At least one\nadditional traverse is needed, which is named anapoiesis for its contribution\nin reconstructing knowledge e.g., from long-term memory into working memory.\nThe conclusions bear implications for brain theory, the mind-body explanatory\ngap, and developments of artificial intelligence technologies.\n", "versions": [{"version": "v1", "created": "Thu, 20 Feb 2014 09:17:32 GMT"}, {"version": "v2", "created": "Mon, 24 Feb 2014 18:45:27 GMT"}, {"version": "v3", "created": "Wed, 26 Feb 2014 21:20:58 GMT"}, {"version": "v4", "created": "Fri, 4 Apr 2014 18:22:35 GMT"}, {"version": "v5", "created": "Wed, 17 Dec 2014 18:21:51 GMT"}], "update_date": "2015-05-11", "authors_parsed": [["Nikoli\u0107", "Danko", ""]]}, {"id": "1402.5702", "submitter": "Mustafa Mert Ankarali", "authors": "Noah J. Cowan, Mustafa Mert Ankarali, Jonathan P. Dyhr, Manu S.\n  Madhav, Eatai Roth, Shahin Sefati, Simon Sponberg, Sarah A. Stamper, Eric S.\n  Fortune and Thomas L. Daniel", "title": "Feedback Control as a Framework for Understanding Tradeoffs in Biology", "comments": "Submitted to Integr Comp Biol", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control theory arose from a need to control synthetic systems. From\nregulating steam engines to tuning radios to devices capable of autonomous\nmovement, it provided a formal mathematical basis for understanding the role of\nfeedback in the stability (or change) of dynamical systems. It provides a\nframework for understanding any system with feedback regulation, including\nbiological ones such as regulatory gene networks, cellular metabolic systems,\nsensorimotor dynamics of moving animals, and even ecological or evolutionary\ndynamics of organisms and populations. Here we focus on four case studies of\nthe sensorimotor dynamics of animals, each of which involves the application of\nprinciples from control theory to probe stability and feedback in an organism's\nresponse to perturbations. We use examples from aquatic (electric fish station\nkeeping and jamming avoidance), terrestrial (cockroach wall following) and\naerial environments (flight control in moths) to highlight how one can use\ncontrol theory to understand how feedback mechanisms interact with the physical\ndynamics of animals to determine their stability and response to sensory inputs\nand perturbations. Each case study is cast as a control problem with sensory\ninput, neural processing, and motor dynamics, the output of which feeds back to\nthe sensory inputs. Collectively, the interaction of these systems in a closed\nloop determines the behavior of the entire system.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 01:49:49 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Cowan", "Noah J.", ""], ["Ankarali", "Mustafa Mert", ""], ["Dyhr", "Jonathan P.", ""], ["Madhav", "Manu S.", ""], ["Roth", "Eatai", ""], ["Sefati", "Shahin", ""], ["Sponberg", "Simon", ""], ["Stamper", "Sarah A.", ""], ["Fortune", "Eric S.", ""], ["Daniel", "Thomas L.", ""]]}, {"id": "1402.5708", "submitter": "Lavdim Kurtaj", "authors": "Lavdim Kurtaj, Ilir Limani, Vjosa Shatri and Avni Skeja", "title": "The Cerebellum: New Computational Model that Reveals its Primary\n  Function to Calculate Multibody Dynamics Conform to Lagrange-Euler\n  Formulation", "comments": "18 pages, 4 figures", "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 10,\n  Issue 5, No 2, September 2013", "doi": null, "report-no": null, "categories": "cs.NE cs.CE cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cerebellum is part of the brain that occupies only 10% of the brain volume,\nbut it contains about 80% of total number of brain neurons. New cerebellar\nfunction model is developed that sets cerebellar circuits in context of\nmultibody dynamics model computations, as important step in controlling balance\nand movement coordination, functions performed by two oldest parts of the\ncerebellum. Model gives new functional interpretation for granule cells-Golgi\ncell circuit, including distinct function for upper and lower Golgi cell\ndendritc trees, and resolves issue of sharing Granule cells between Purkinje\ncells. Sets new function for basket cells, and for stellate cells according to\nposition in molecular layer. New model enables easily and direct integration of\nsensory information from vestibular system and cutaneous mechanoreceptors, for\nbalance, movement and interaction with environments. Model gives explanation of\nPurkinje cells convergence on deep-cerebellar nuclei.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 02:40:05 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Kurtaj", "Lavdim", ""], ["Limani", "Ilir", ""], ["Shatri", "Vjosa", ""], ["Skeja", "Avni", ""]]}, {"id": "1402.5956", "submitter": "Henrik Jeldtoft Jensen", "authors": "Xiaogeng Wan, Bjorn Cruts and Henrik Jeldtoft Jensen", "title": "The causal inference of cortical neural networks during music\n  improvisations", "comments": "22 pages, 9 figures. The version was a revised in accordance with\n  referee's comments. The language was also improved", "journal-ref": null, "doi": "10.1371/journal.pone.0112776", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an EEG study of two music improvisation\nexperiments. Professional musicians with high level of improvisation skills\nwere asked to perform music either according to notes (composed music) or in\nimprovisation. Each piece of music was performed in two different modes: strict\nmode and \"let-go\" mode. Synchronized EEG data was measured from both musicians\nand listeners. We used one of the most reliable causality measures: conditional\nmutual information from mixed embedding (MIME), to analyze directed\ncorrelations between different EEG channels, which was combined with network\ntheory to construct both intra-brain and cross-brain neural networks.\nDifferences were identified in intra-brain neural networks between composed\nmusic and improvisation and between strict mode and \"let-go\" mode. Particular\nbrain regions such as frontal, parietal and temporal regions were found to play\na key role in differentiating the brain activities between different playing\nconditions. By comparing the level of degree centralities in intra-brain neural\nnetworks, we found musicians responding differently to listeners when playing\nmusic in different conditions.\n", "versions": [{"version": "v1", "created": "Mon, 24 Feb 2014 17:13:07 GMT"}, {"version": "v2", "created": "Thu, 24 Jul 2014 15:06:18 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Wan", "Xiaogeng", ""], ["Cruts", "Bjorn", ""], ["Jensen", "Henrik Jeldtoft", ""]]}, {"id": "1402.5996", "submitter": "Po T. Wang", "authors": "Po T. Wang, Christine E. King, Andrew Schombs, Jack J. Lin, Mona\n  Sazgar, Frank P. K. Hsu, Susan J. Shaw, David E. Millett, Charles Y. Liu,\n  Luis A. Chui, Zoran Nenadic, An H. Do", "title": "Electrocorticogram encoding of upper extremity movement trajectories", "comments": "Preliminary report. We have not completed full analyses", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrocorticogram (ECoG)-based brain computer interfaces (BCI) can\npotentially control upper extremity prostheses to restore independent function\nto paralyzed individuals. However, current research is mostly restricted to the\noffline decoding of finger or 2D arm movement trajectories, and these results\nare modest. This study seeks to improve the fundamental understanding of the\nECoG signal features underlying upper extremity movements to guide better BCI\ndesign. Subjects undergoing ECoG electrode implantation performed a series of\nelementary upper extremity movements in an intermittent flexion and extension\nmanner. It was found that movement velocity, $\\dot\\theta$, had a high positive\n(negative) correlation with the instantaneous power of the ECoG high-$\\gamma$\nband (80-160 Hz) during flexion (extension). Also, the correlation was low\nduring idling epochs. Visual inspection of the ECoG high-$\\gamma$ band revealed\npower bursts during flexion/extension events that have a waveform that strongly\nresembles the corresponding flexion/extension event as seen on $\\dot\\theta$.\nThese high-$\\gamma$ bursts were present in all elementary movements, and were\nspatially distributed in a somatotopic fashion. Thus, it can be concluded that\nthe high-$\\gamma$ power of ECoG strongly encodes for movement trajectories, and\ncan be used as an input feature in future BCIs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Feb 2014 20:43:35 GMT"}], "update_date": "2014-02-26", "authors_parsed": [["Wang", "Po T.", ""], ["King", "Christine E.", ""], ["Schombs", "Andrew", ""], ["Lin", "Jack J.", ""], ["Sazgar", "Mona", ""], ["Hsu", "Frank P. K.", ""], ["Shaw", "Susan J.", ""], ["Millett", "David E.", ""], ["Liu", "Charles Y.", ""], ["Chui", "Luis A.", ""], ["Nenadic", "Zoran", ""], ["Do", "An H.", ""]]}, {"id": "1402.6465", "submitter": "Sylvie Costrel De Corainville", "authors": "St\\'ephane Mottin (LHC), Bruno Montcel (CREATIS), Hugues Guillet De\n  Chatellus (LIPhy), St\\'ephane Ramstein (LHC), Cl\\'ementine Vignal (ENES)", "title": "Time-resolved and spectral-resolved optical imaging to study brain\n  hemodynamics in songbirds", "comments": null, "journal-ref": "Diffuse Optical Imaging III. Edited by Hielscher 8088 (2011) 8", "doi": "10.1117/12.889799", "report-no": null, "categories": "q-bio.NC physics.optics q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrary to the intense debate about brain oxygen dynamics and its uncoupling\nin mammals, very little is known in birds. In zebra finches, picosecond optical\ntomography (POT) with a white laser and a streak camera can measure in vivo\noxy-hemoglobin (HbO2) and deoxy-hemoglobin (Hb) concentration changes following\nphysiological stimulation (familiar calls and songs). POT demonstrated\nsufficient sub-micromolar sensitivity to resolve the fast changes in\nhippocampus and auditory forebrain areas with 250 \\mu m resolution. The\ntime-course is composed of (i) an early 2s-long event with a significant\ndecrease in Hb and HbO2, respectively -0.7 \\mu Moles/L and -0.9 \\mu Moles/L\n(ii) a subsequent increase in blood oxygen availability with a plateau of HbO2\n(+0.3 \\mu Moles/L) and (iii) pronounced vasodilatation events immediately\nfollowing the end of the stimulus. One of the findings of our work is the\ndirect link between the blood oxygen level-dependent (BOLD) signals previously\npublished in birds and our results. Furthermore, the early vasoconstriction\nevent and post-stimulus ringing seem to be more pronounced in birds than in\nmammals. These results in bird, a tachymetabolic vertebrate with a long\nlifespan, can potentially yield new insights for example in brain aging.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 09:20:36 GMT"}], "update_date": "2014-02-27", "authors_parsed": [["Mottin", "St\u00e9phane", "", "LHC"], ["Montcel", "Bruno", "", "CREATIS"], ["De Chatellus", "Hugues Guillet", "", "LIPhy"], ["Ramstein", "St\u00e9phane", "", "LHC"], ["Vignal", "Cl\u00e9mentine", "", "ENES"]]}, {"id": "1402.6752", "submitter": "Alexander Goltsev", "authors": "M. A. Lopes, K.-E. Lee, A. V. Goltsev, and J. F. F. Mendes", "title": "Noise-enhanced nonlinear response and the role of modular structure for\n  signal detection in neuronal networks", "comments": "10 pages, 8 figures", "journal-ref": "Phys Rev E 90, 052709 (2014)", "doi": "10.1103/PhysRevE.90.052709", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find that sensory noise delivered together with a weak periodic signal not\nonly enhances nonlinear response of neuronal networks, but also improves the\nsynchronization of the response to the signal. We reveal this phenomenon in\nneuronal networks that are in a dynamical state near a saddle-node bifurcation\ncorresponding to appearance of sustained network oscillations. In this state,\neven a weak periodic signal can evoke sharp nonlinear oscillations of neuronal\nactivity. These sharp network oscillations have a deterministic form and\namplitude determined by nonlinear dynamical equations. The signal-to-noise\nratio reaches a maximum at an optimum level of sensory noise, manifesting\nstochastic resonance (SR) at the population level. We demonstrate SR by use of\nsimulations and numerical integration of rate equations in a cortical model\nwith stochastic neurons. Using this model, we mimic the experiments of Gluckman\net al. [B. J. Gluckman et al, Phys. Rev. Lett., v. 77, 4098 (1996)] that have\ngiven evidence of SR in mammalian brain. We also study neuronal networks in\nwhich neurons are grouped in modules and every module works in the regime of\nSR. We find that even a few modules can strongly enhance the reliability of\nsignal detection in comparison with the case when a modular organization is\nabsent.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 00:42:07 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Lopes", "M. A.", ""], ["Lee", "K. -E.", ""], ["Goltsev", "A. V.", ""], ["Mendes", "J. F. F.", ""]]}, {"id": "1402.6951", "submitter": "Drausin Wulsin", "authors": "Drausin F. Wulsin, Emily B. Fox, Brian Litt", "title": "Modeling the Complex Dynamics and Changing Correlations of Epileptic\n  Events", "comments": null, "journal-ref": null, "doi": "10.1016/j.artint.2014.05.006", "report-no": null, "categories": "stat.ML q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Patients with epilepsy can manifest short, sub-clinical epileptic \"bursts\" in\naddition to full-blown clinical seizures. We believe the relationship between\nthese two classes of events---something not previously studied\nquantitatively---could yield important insights into the nature and intrinsic\ndynamics of seizures. A goal of our work is to parse these complex epileptic\nevents into distinct dynamic regimes. A challenge posed by the intracranial EEG\n(iEEG) data we study is the fact that the number and placement of electrodes\ncan vary between patients. We develop a Bayesian nonparametric Markov switching\nprocess that allows for (i) shared dynamic regimes between a variable number of\nchannels, (ii) asynchronous regime-switching, and (iii) an unknown dictionary\nof dynamic regimes. We encode a sparse and changing set of dependencies between\nthe channels using a Markov-switching Gaussian graphical model for the\ninnovations process driving the channel dynamics and demonstrate the importance\nof this model in parsing and out-of-sample predictions of iEEG data. We show\nthat our model produces intuitive state assignments that can help automate\nclinical analysis of seizures and enable the comparison of sub-clinical bursts\nand full clinical seizures.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2014 16:09:09 GMT"}, {"version": "v2", "created": "Mon, 14 Jul 2014 01:37:35 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Wulsin", "Drausin F.", ""], ["Fox", "Emily B.", ""], ["Litt", "Brian", ""]]}, {"id": "1402.7038", "submitter": "Vahid Ramezani", "authors": "Vahid R. Ramezani", "title": "Causal Event Networks: Cognition, Complexity and Physical Laws", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information flow framed in a computational and complexity context is relevant\nto the understanding of cognitive processes and awareness. In this paper, we\nbegin with analyzing an information theory framework developed in recent years\nunder Information and Integration Theory (IIT) based on interactions among\npartitions of cognitive information sets. We discuss the scope and limitations\nof these ideas, introducing a related measure for partitioning information\nsets. We introduce a set of postulates describing cognition as a partially\nordered set of events in space and time. We consider the relevant sequential\nand concurrent computational concepts in an idealized minimal cognitive device.\nThe concept of fundamental cognitive chain formalizes temporal limits of\ncognition.\n", "versions": [{"version": "v1", "created": "Wed, 26 Feb 2014 20:29:43 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Ramezani", "Vahid R.", ""]]}]