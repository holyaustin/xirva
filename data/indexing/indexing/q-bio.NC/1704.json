[{"id": "1704.00494", "submitter": "Jiancheng Zhuang", "authors": "Jiancheng Zhuang", "title": "The eddy current distortion in the multiband diffusion images: diagnosis\n  and correction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diffusion weighted images acquired with the multiband sequence or the\nLifespan protocols shows a type of slice distortion artifact. We find that this\nartifact is caused by the eddy currents, which can be induced by the diffusion\ngradient associated with either current DW image or the previous DW images. The\nartifact can be corrected by further tuning the compensation circuit in the MR\nhardware, or by a correction algorithm which includes the diffusion gradients\nfrom the current and previous DW images.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 09:37:02 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Zhuang", "Jiancheng", ""]]}, {"id": "1704.00646", "submitter": "Sebastian Seung", "authors": "H. Sebastian Seung and Jonathan Zung", "title": "A correlation game for unsupervised learning yields computational\n  interpretations of Hebbian excitation, anti-Hebbian inhibition, and synapse\n  elimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much has been learned about plasticity of biological synapses from empirical\nstudies. Hebbian plasticity is driven by correlated activity of presynaptic and\npostsynaptic neurons. Synapses that converge onto the same neuron often behave\nas if they compete for a fixed resource; some survive the competition while\nothers are eliminated. To provide computational interpretations of these\naspects of synaptic plasticity, we formulate unsupervised learning as a\nzero-sum game between Hebbian excitation and anti-Hebbian inhibition in a\nneural network model. The game formalizes the intuition that Hebbian excitation\ntries to maximize correlations of neurons with their inputs, while anti-Hebbian\ninhibition tries to decorrelate neurons from each other. We further include a\nmodel of synaptic competition, which enables a neuron to eliminate all\nconnections except those from its most strongly correlated inputs. Through\nempirical studies, we show that this facilitates the learning of sensory\nfeatures that resemble parts of objects.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 15:39:19 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Seung", "H. Sebastian", ""], ["Zung", "Jonathan", ""]]}, {"id": "1704.00793", "submitter": "Jinghao Lu", "authors": "Jinghao Lu, Chunyuan Li, Fan Wang", "title": "Seeds Cleansing CNMF for Spatiotemporal Neural Signals Extraction of\n  Miniscope Imaging Data", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Miniscope calcium imaging is increasingly being used to monitor large\npopulations of neuronal activities in freely behaving animals. However, due to\nthe high background and low signal-to-noise ratio of the single-photon based\nimaging used in this technique, extraction of neural signals from the large\nnumbers of imaged cells automatically has remained challenging. Here we\ndescribe a highly accurate framework for automatically identifying activated\nneurons and extracting calcium signals from the miniscope imaging data, seeds\ncleansing Constrained Nonnegative Matrix Factorization (sc-CNMF). This sc-CNMF\nextends the conventional CNMF with two new modules: i) a neural enhancing\nmodule to overcome miniscope-specific limitations, and ii) a seeds cleansing\nmodule combining LSTM to rigorously select and cleanse the set of seeds for\ndetecting regions-of-interest. Our sc-CNMF yields highly stable and superior\nperformance in analyzing miniscope calcium imaging data compared to existing\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 20:10:00 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Lu", "Jinghao", ""], ["Li", "Chunyuan", ""], ["Wang", "Fan", ""]]}, {"id": "1704.01039", "submitter": "Naho Ichikawa", "authors": "Naho Ichikawa, Giuseppe Lisi, Noriaki Yahata, Go Okada, Masahiro\n  Takamura, Makiko Yamada, Tetsuya Suhara, Ryu-ichiro Hashimoto, Takashi\n  Yamada, Yujiro Yoshihara, Hidehiko Takahashi, Kiyoto Kasai, Nobumasa Kato,\n  Shigeto Yamawaki, Mitsuo Kawato, Jun Morimoto, Yasumasa Okamoto", "title": "Identifying melancholic depression biomarker using whole-brain\n  functional connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By focusing on melancholic features with biological homogeneity, this study\naimed to identify a small number of critical functional connections (FCs) that\nwere specific only to the melancholic type of MDD. On the resting-state fMRI\ndata, classifiers were developed to differentiate MDD patients from healthy\ncontrols (HCs). The classification accuracy was improved from 50 % (93 MDD and\n93 HCs) to 70% (66 melancholic MDD and 66 HCs), when we specifically focused on\nthe melancholic MDD with moderate or severer level of depressive symptoms. It\nshowed 65% accuracy for the independent validation cohort. The biomarker score\ndistribution showed improvements with escitalopram treatments, and also showed\nsignificant correlations with depression symptom scores. This classifier was\nspecific to melancholic MDD, and it did not generalize in other mental\ndisorders including autism spectrum disorder (ASD, 54% accuracy) and\nschizophrenia spectrum disorder (SSD, 45% accuracy). Among the identified 12\nFCs from 9,316 FCs between whole brain anatomical node pairs, the left DLPFC /\nIFG region, which has most commonly been targeted for depression treatments,\nand its functional connections between Precuneus / PCC, and between right DLPFC\n/ SMA areas had the highest contributions. Given the heterogeneity of the MDD,\nfocusing on the melancholic features is the key to achieve high classification\naccuracy. The identified FCs specifically predicted the melancholic MDD and\nassociated with subjective depressive symptoms. These results suggested key FCs\nof melancholic depression, and open doors to novel treatments targeting these\nregions in the future.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 15:05:59 GMT"}, {"version": "v2", "created": "Tue, 18 Apr 2017 05:50:40 GMT"}, {"version": "v3", "created": "Sun, 14 May 2017 20:09:58 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Ichikawa", "Naho", ""], ["Lisi", "Giuseppe", ""], ["Yahata", "Noriaki", ""], ["Okada", "Go", ""], ["Takamura", "Masahiro", ""], ["Yamada", "Makiko", ""], ["Suhara", "Tetsuya", ""], ["Hashimoto", "Ryu-ichiro", ""], ["Yamada", "Takashi", ""], ["Yoshihara", "Yujiro", ""], ["Takahashi", "Hidehiko", ""], ["Kasai", "Kiyoto", ""], ["Kato", "Nobumasa", ""], ["Yamawaki", "Shigeto", ""], ["Kawato", "Mitsuo", ""], ["Morimoto", "Jun", ""], ["Okamoto", "Yasumasa", ""]]}, {"id": "1704.01148", "submitter": "T.R. Leffler", "authors": "T.R. Leffler", "title": "The Hard Problem of Consciousness: A Mathematical Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can potentially make progress on the hard problem of consciousness\n(Chalmers, 1995), the seemingly intractable problem of explaining how qualia\narise from certain physical systems, via the mathematically tractable problem\nof explaining how objectively unmeasurable aspects (identified with qualia)\ncould arise from certain physical systems that are otherwise objectively\nmeasurable. In short, it is proposed that qualia may correspond to\nnon-divergent singularities in the mathematical descriptions of certain aspects\nof certain complex physical systems. This proposal may have been foreshadowed\nby Srinivasa Ramanujan. It could have significant implications for the\nprospects of the experimental verification of consciousness in physical systems\nand for the prospects of the generation of artificial consciousness (AC).\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 18:32:58 GMT"}, {"version": "v2", "created": "Fri, 14 Jul 2017 04:58:27 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 18:58:53 GMT"}, {"version": "v4", "created": "Sun, 25 Aug 2019 19:57:45 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Leffler", "T. R.", ""]]}, {"id": "1704.01350", "submitter": "Mitsuo Kawato", "authors": "Takashi Yamada, Ryu-ichiro Hashimoto, Noriaki Yahata, Naho Ichikawa,\n  Yujiro Yoshihara, Yasumasa Okamoto, Nobumasa Kato, Hidehiko Takahashi, Mitsuo\n  Kawato", "title": "Resting-state functional connectivity-based biomarkers and functional\n  MRI-based neurofeedback for psychiatric disorders: a challenge for developing\n  theranostic biomarkers", "comments": "46 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychiatric research has been hampered by an explanatory gap between\npsychiatric symptoms and their neural underpinnings, which has resulted in poor\ntreatment outcomes. This situation has prompted us to shift from symptom-based\ndiagnosis to data-driven diagnosis, aiming to redefine psychiatric disorders as\ndisorders of neural circuitry. Promising candidates for data-driven diagnosis\ninclude resting-state functional connectivity MRI (rs-fcMRI)-based biomarkers.\nAlthough biomarkers have been developed with the aim of diagnosing patients and\npredicting the efficacy of therapy, the focus has shifted to the identification\nof biomarkers that represent therapeutic targets, which would allow for more\npersonalized treatment approaches. This type of biomarker (i.e., theranostic\nbiomarker) is expected to elucidate the disease mechanism of psychiatric\nconditions and to offer an individualized neural circuit-based therapeutic\ntarget based on the neural cause of a condition. To this end, researchers have\ndeveloped rs-fcMRI-based biomarkers and investigated a causal relationship\nbetween potential biomarkers and disease-specific behavior using functional MRI\n(fMRI)-based neurofeedback on functional connectivity. In this review, we\nintroduce recent approach for creating a theranostic biomarker, which consists\nmainly of two parts: (i) developing an rs-fcMRI-based biomarker that can\npredict diagnosis and/or symptoms with high accuracy, and (ii) the introduction\nof a proof-of-concept study investigating the relationship between normalizing\nthe biomarker and symptom changes using fMRI-based neurofeedback. In parallel\nwith the introduction of recent studies, we review rs-fcMRI-based biomarker and\nfMRI-based neurofeedback, focusing on the technological improvements and\nlimitations associated with clinical use.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 10:15:37 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 01:18:16 GMT"}, {"version": "v3", "created": "Mon, 10 Apr 2017 04:07:01 GMT"}, {"version": "v4", "created": "Fri, 18 Aug 2017 04:42:15 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Yamada", "Takashi", ""], ["Hashimoto", "Ryu-ichiro", ""], ["Yahata", "Noriaki", ""], ["Ichikawa", "Naho", ""], ["Yoshihara", "Yujiro", ""], ["Okamoto", "Yasumasa", ""], ["Kato", "Nobumasa", ""], ["Takahashi", "Hidehiko", ""], ["Kawato", "Mitsuo", ""]]}, {"id": "1704.01547", "submitter": "Wieland Brendel", "authors": "Wieland Brendel, Matthias Bethge", "title": "Comment on \"Biologically inspired protection of deep networks from\n  adversarial attacks\"", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent paper suggests that Deep Neural Networks can be protected from\ngradient-based adversarial perturbations by driving the network activations\ninto a highly saturated regime. Here we analyse such saturated networks and\nshow that the attacks fail due to numerical limitations in the gradient\ncomputations. A simple stabilisation of the gradient estimates enables\nsuccessful and efficient attacks. Thus, it has yet to be shown that the\nrobustness observed in highly saturated networks is not simply due to numerical\nlimitations.\n", "versions": [{"version": "v1", "created": "Wed, 5 Apr 2017 17:47:25 GMT"}], "update_date": "2017-04-06", "authors_parsed": [["Brendel", "Wieland", ""], ["Bethge", "Matthias", ""]]}, {"id": "1704.01761", "submitter": "Hans Trukenbrod", "authors": "Hans A. Trukenbrod, Simon Barthelm\\'e, Felix A. Wichmann and Ralf\n  Engbert", "title": "Spatial statistics for gaze patterns in scene viewing: Effects of\n  repeated viewing", "comments": "27 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene viewing is used to study attentional selection in complex but still\ncontrolled environments. One of the main observations on eye movements during\nscene viewing is the inhomogeneous distribution of fixation locations: While\nsome parts of an image are fixated by almost all observers and are inspected\nrepeatedly by the same observer, other image parts remain unfixated by\nobservers even after long exploration intervals. Here, we apply spatial point\nprocess methods to investigate the relationship between pairs of fixations.\nMore precisely, we use the pair correlation function (PCF), a powerful\nstatistical tool, to evaluate dependencies between fixation locations along\nindividual scanpaths. We demonstrate that aggregation of fixation locations\nwithin four degrees is stronger than expected from chance. Furthermore, the PCF\nreveals stronger aggregation of fixations when the same image is presented a\nsecond time. We use simulations of a dynamical model to show that a narrower\nspatial attentional span may explain differences in pair correlations between\nthe first and the second inspection of the same image.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 09:46:01 GMT"}, {"version": "v2", "created": "Tue, 13 Nov 2018 08:35:59 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Trukenbrod", "Hans A.", ""], ["Barthelm\u00e9", "Simon", ""], ["Wichmann", "Felix A.", ""], ["Engbert", "Ralf", ""]]}, {"id": "1704.02019", "submitter": "Rishidev Chaudhuri", "authors": "Rishidev Chaudhuri and Ila Fiete", "title": "Associative content-addressable networks with exponentially many robust\n  stable states", "comments": "42 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain must robustly store a large number of memories, corresponding to\nthe many events encountered over a lifetime. However, the number of memory\nstates in existing neural network models either grows weakly with network size\nor recall fails catastrophically with vanishingly little noise. We construct an\nassociative content-addressable memory with exponentially many stable states\nand robust error-correction. The network possesses expander graph connectivity\non a restricted Boltzmann machine architecture. The expansion property allows\nsimple neural network dynamics to perform at par with modern error-correcting\ncodes. Appropriate networks can be constructed with sparse random connections,\nglomerular nodes, and associative learning using low dynamic-range weights.\nThus, sparse quasi-random structures---characteristic of important\nerror-correcting codes---may provide for high-performance computation in\nartificial neural networks and the brain.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 20:46:16 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 18:30:38 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Chaudhuri", "Rishidev", ""], ["Fiete", "Ila", ""]]}, {"id": "1704.02342", "submitter": "Elizaveta Solomonova", "authors": "Elizaveta Solomonova", "title": "Sleep Paralysis: phenomenology, neurophysiology and treatment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sleep paralysis is an experience of being temporarily unable to move or talk\nduring the transitional periods between sleep and wakefulness: at sleep onset\nor upon awakening. Feeling of paralysis may be accompanied by a variety of\nvivid and intense sensory experiences, including mentation in visual, auditory,\nand tactile modalities, as well as a distinct feeling of presence. This chapter\ndiscusses a variety of sleep paralysis experiences from the perspective of\nenactive cognition and cultural neurophenomenology. Current knowledge of\nneurophysiology and associated conditions is presented, and some techniques for\ncoping with sleep paralysis are proposed. As an experience characterized by a\nhybrid state of dreaming and waking, sleep paralysis offers a unique window\ninto phenomenology of spontaneous thought in sleep.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 18:33:59 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Solomonova", "Elizaveta", ""]]}, {"id": "1704.02351", "submitter": "Brenton Maisel", "authors": "Brenton Maisel and Katja Lindenberg", "title": "Channel Noise Effects on Neural Synchronization", "comments": "7 Figures", "journal-ref": null, "doi": "10.1016/j.physa.2019.123186", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronization in neural networks is strongly tied to the implementation of\ncognitive processes, but abnormal neuronal synchronization has been linked to a\nnumber of brain disorders such as epilepsy and schizophrenia. Here we examine\nthe effects of channel noise on the synchronization of small Hodgkin-Huxley\nneuronal networks. The principal feature of a Hodgkin-Huxley neuron is the\nexistence of protein channels that transition between open and closed states\nwith voltage dependent rate constants. The Hodgkin-Huxley model assumes\ninfinitely many channels, so fluctuations in the number of open channels do not\naffect the voltage. However, real neurons have finitely many channels which\nlead to fluctuations in the membrane voltage and modify the timing of the\nspikes, which may in turn lead to large changes in the degree of\nsynchronization. We demonstrate that under mild conditions, neurons in the\nnetwork reach a steady state synchronization level that depends only on the\nnumber of neurons in the network. The channel noise only affects the time it\ntakes to reach the steady state synchronization level.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 19:26:50 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 15:29:49 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Maisel", "Brenton", ""], ["Lindenberg", "Katja", ""]]}, {"id": "1704.02533", "submitter": "Kieran Fox", "authors": "Jessica R. Andrews-Hanna, Zachary C. Irving, Kieran C.R. Fox, R.\n  Nathan Spreng, Kalina Christoff", "title": "The Neuroscience of Spontaneous Thought: An Evolving, Interdisciplinary\n  Field", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An often-overlooked characteristic of the human mind is its propensity to\nwander. Despite growing interest in the science of mind-wandering, most studies\noperationalize mind-wandering by its task-unrelated contents, which may be\northogonal to the processes constraining how thoughts are evoked and unfold\nover time. In this chapter, we emphasize the importance of incorporating such\nprocesses into current definitions of mind-wandering, and proposing that\nmind-wandering and other forms of spontaneous thought (such as dreaming and\ncreativity) are mental states that arise and transition relatively freely due\nto an absence of constraints on cognition. We review existing psychological,\nphilosophical, and neuroscientific research on spontaneous thought through the\nlens of this framework, and call for additional research into the dynamic\nproperties of the mind and brain.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 20:16:58 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Andrews-Hanna", "Jessica R.", ""], ["Irving", "Zachary C.", ""], ["Fox", "Kieran C. R.", ""], ["Spreng", "R. Nathan", ""], ["Christoff", "Kalina", ""]]}, {"id": "1704.02693", "submitter": "Jiancheng Zhuang", "authors": "Jiancheng Zhuang", "title": "Detecting neural activity and connectivity by perfusion-based fMRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes an approach to estimate the functional localization and\nconnectivity from CBF and BOLD signals simultaneously measured by ASL (arterial\nspin labeling) MRI, especially using exploratory Structural Equation Modeling\nanalysis. In a visual task experiment, the primary visual cortices were located\nby analyzing the perfusion data. In the resting state experiment, two\nstructural equation models were estimated at each voxel regarding to the\nsensory-motor network and default-mode network. The resulting connectivity maps\nindicate that supplementary motor area has significant connections to\nleft/right primary motor areas, and inferior parietal lobules link\nsignificantly with posterior cingulate cortex and medial prefrontal cortex. The\nmodel fitting results imply that BOLD signal is more directly linked to the\nunderlying cause of functional connectivity than CBF signal.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 03:23:16 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Zhuang", "Jiancheng", ""]]}, {"id": "1704.02702", "submitter": "Aaron Kucyi", "authors": "Aaron Kucyi", "title": "Pain and Spontaneous Thought", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pain is among the most salient of experiences while also, curiously, being\namong the most malleable. A large body of research has revealed that a\nmultitude of explicit strategies can be used to effectively alter the\nattention-demanding quality of acute and chronic pains and their associated\nneural correlates. However, thoughts that are spontaneous, rather than actively\ngenerated, are common in daily life, and so attention to pain can often\ntemporally fluctuate because of ongoing self-generated experiences. Classic\npain theories have largely neglected to account for unconstrained fluctuations\nin cognition, but new studies have demonstrated the behavioral-relevance,\nputative neural basis, and individual variability of interactions between pain\nand spontaneous thoughts. In this chapter, I review behavioral studies of\nongoing fluctuations in attention to pain, studies of the neural basis of\nspontaneous mind-wandering away from pain, and the clinical implications of\nthis research.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 04:04:43 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Kucyi", "Aaron", ""]]}, {"id": "1704.02741", "submitter": "Roseli Suzi Wedemann", "authors": "Maheen Siddiqui, Roseli S. Wedemann, Henrik Jensen", "title": "Avalanches and Generalized Memory Associativity in a Network Model for\n  Conscious and Unconscious Mental Functioning", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2017.08.011", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore statistical characteristics of avalanches associated with the\ndynamics of a complex-network model, where two modules corresponding to\nsensorial and symbolic memories interact, representing unconscious and\nconscious mental processes. The model illustrates Freud's ideas regarding the\nneuroses and that consciousness is related with symbolic and linguistic memory\nactivity in the brain. It incorporates the Stariolo-Tsallis generalization of\nthe Boltzmann Machine in order to model memory retrieval and associativity. In\nthe present work, we define and measure avalanche size distributions during\nmemory retrieval, in order to gain insight regarding basic aspects of the\nfunctioning of these complex networks. The avalanche sizes defined for our\nmodel should be related to the time consumed and also to the size of the\nneuronal region which is activated, during memory retrieval. This allows the\nqualitative comparison of the behaviour of the distribution of cluster sizes,\nobtained during fMRI measurements of the propagation of signals in the brain,\nwith the distribution of avalanche sizes obtained in our simulation\nexperiments. This comparison corroborates the indication that the Nonextensive\nStatistical Mechanics formalism may indeed be more well suited to model the\ncomplex networks which constitute brain and mental structure.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 07:38:28 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Siddiqui", "Maheen", ""], ["Wedemann", "Roseli S.", ""], ["Jensen", "Henrik", ""]]}, {"id": "1704.02780", "submitter": "Maurizio Mattia", "authors": "Matteo Biggio, Marco Storace, Maurizio Mattia", "title": "Equivalence between synaptic current dynamics and heterogeneous\n  propagation delays in spiking neuron networks", "comments": "14 pages, 5 figures, submitted for publication", "journal-ref": null, "doi": "10.1371/journal.pcbi.1007404", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message passing between components of a distributed physical system is\nnon-instantaneous and contributes to determine the time scales of the emerging\ncollective dynamics like an effective inertia. In biological neuron networks\nthis inertia is due in part to local synaptic filtering of exchanged spikes,\nand in part to the distribution of the axonal transmission delays. How\ndifferently these two kinds of inertia affect the network dynamics is an open\nissue not yet addressed due to the difficulties in dealing with the\nnon-Markovian nature of synaptic transmission. Here, we develop a mean-field\ndimensional reduction yielding to an effective Markovian dynamics of the\npopulation density of the neuronal membrane potential, valid under the\nhypothesis of small fluctuations of the synaptic current. The resulting theory\nallows us to prove the formal equivalence between local and distributed\ninertia, holding for any synaptic time scale, integrate-and-fire neuron model,\nspike emission regimes and for different network states even when the neuron\nnumber is finite.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 09:37:38 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Biggio", "Matteo", ""], ["Storace", "Marco", ""], ["Mattia", "Maurizio", ""]]}, {"id": "1704.03150", "submitter": "Sang-Yoon  Kim", "authors": "Sang-Yoon Kim and Woochang Lim", "title": "Stochastic Spike Synchronization in A Small-World Neural Network with\n  Spike-Timing-Dependent Plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Watts-Strogatz small-world network consisting of subthreshold\nneurons which exhibit noise-induced spikings. This neuronal network has\nadaptive dynamic synaptic strengths governed by the spike-timing-dependent\nplasticity (STDP). In previous works without STDP, stochastic spike\nsynchronization (SSS) between noise-induced spikings of subthreshold neurons\nwas found to occur in a range of intermediate noise intensities through\ncompetition between the constructive and the destructive roles of noise. Here,\nwe investigate the effect of additive STDP on the SSS by varying the noise\nintensity. Occurrence of a \"Matthew\" effect in synaptic plasticity is found due\nto a positive feedback process. As a result, good synchronization gets better\nvia long-term potentiation (LTP) of synaptic strengths, while bad\nsynchronization gets worse via long-term depression (LTD). Emergence of LTP and\nLTD of synaptic strengths are intensively investigated via microscopic studies\nbased on the pair-correlations between the pre- and the post-synaptic IISRs\n(instantaneous individual spike rates) as well as the distributions of time\ndelays between the pre- and the post-synaptic spike times. Furthermore, the\neffects of multiplicative STDP (which depends on the states) on the SSS are\nalso studied and discussed in comparison with the case of additive STDP.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 05:42:39 GMT"}, {"version": "v2", "created": "Wed, 12 Apr 2017 01:56:32 GMT"}, {"version": "v3", "created": "Thu, 13 Apr 2017 02:27:33 GMT"}, {"version": "v4", "created": "Mon, 14 Aug 2017 19:16:44 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Kim", "Sang-Yoon", ""], ["Lim", "Woochang", ""]]}, {"id": "1704.03508", "submitter": "Andreas Hula", "authors": "Andreas Hula and Iris Vilares and Peter Dayan and P.Read Montague", "title": "A Model of Risk and Mental State Shifts during Social Interaction", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1005935", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation and competition between human players in repeated microeconomic\ngames offer a powerful window onto social phenomena such as the establishment,\nbreakdown and repair of trust. This offers the prospect of particular insight\ninto populations of subjects suffering from socially-debilitating conditions\nsuch as borderline personality disorder. However, although a suitable\nfoundation for the quantitative analysis of such games exists, namely the\nInteractive Partially Observable Markov Decision Process (I-POMDP),\ncomputational considerations have hitherto limited its application. Here, we\nimprove inference in I-POMDPs in a canonical trust game, and thereby highlight\nand address two previously unmodelled phenomena: a form of social risk-aversion\nexhibited by the player who is in control of the interaction in the game, and\nirritation or anger exhibited by both players. Irritation arises when partners\napparently defect, and it causes a precipitate breakdown in cooperation.\nFailing to model one's partner's propensity for it leads to substantial\neconomic inefficiency. We illustrate these behaviours using evidence drawn from\nthe play of large cohorts of healthy volunteers and patients.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 19:39:49 GMT"}, {"version": "v2", "created": "Thu, 10 Aug 2017 15:17:31 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Hula", "Andreas", ""], ["Vilares", "Iris", ""], ["Dayan", "Peter", ""], ["Montague", "P. Read", ""]]}, {"id": "1704.03568", "submitter": "Christopher Funk", "authors": "Christopher Funk and Yanxi Liu", "title": "Beyond Planar Symmetry: Modeling human perception of reflection and\n  rotation symmetries in the wild", "comments": "To appear in the International Conference on Computer Vision (ICCV)\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans take advantage of real world symmetries for various tasks, yet\ncapturing their superb symmetry perception mechanism with a computational model\nremains elusive. Motivated by a new study demonstrating the extremely high\ninter-person accuracy of human perceived symmetries in the wild, we have\nconstructed the first deep-learning neural network for reflection and rotation\nsymmetry detection (Sym-NET), trained on photos from MS-COCO (Microsoft-Common\nObject in COntext) dataset with nearly 11K consistent symmetry-labels from more\nthan 400 human observers. We employ novel methods to convert discrete human\nlabels into symmetry heatmaps, capture symmetry densely in an image and\nquantitatively evaluate Sym-NET against multiple existing computer vision\nalgorithms. On CVPR 2013 symmetry competition testsets and unseen MS-COCO\nphotos, Sym-NET significantly outperforms all other competitors. Beyond\nmathematically well-defined symmetries on a plane, Sym-NET demonstrates\nabilities to identify viewpoint-varied 3D symmetries, partially occluded\nsymmetrical objects, and symmetries at a semantic level.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 23:25:25 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 17:11:05 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Funk", "Christopher", ""], ["Liu", "Yanxi", ""]]}, {"id": "1704.03855", "submitter": "Richard Granger", "authors": "Richard Granger", "title": "How brains are built: Principles of computational neuroscience", "comments": "http://dana.org/news/cerebrum/detail.aspx?id=30356", "journal-ref": "Cerebrum; Dana Foundation 2011", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  'If I cannot build it, I do not understand it.' So said Nobel laureate\nRichard Feynman, and by his metric, we understand a bit about physics, less\nabout chemistry, and almost nothing about biology.\n  When we fully understand a phenomenon, we can specify its entire sequence of\nevents, causes, and effects so completely that it is possible to fully simulate\nit, with all its internal mechanisms intact. Achieving that level of\nunderstanding is rare. It is commensurate with constructing a full design for a\nmachine that could serve as a stand-in for the thing being studied. To\nunderstand a phenomenon sufficiently to fully simulate it is to understand it\ncomputationally.\n  'Computation' does not refer to computers per se. Rather, it refers to the\nunderlying principles and methods that make them work. As Turing Award\nrecipient Edsger Dijkstra said, computational science 'is no more about\ncomputers than astronomy is about telescopes.' Computational science is the\nstudy of the hidden rules underlying complex phenomena from physics to\npsychology.\n  Computational neuroscience, then, has the aim of understanding brains\nsufficiently well to be able to simulate their functions, thereby subsuming the\ntwin goals of science and engineering: deeply understanding the inner workings\nof our brains, and being able to construct simulacra of them. As simple robots\ntoday substitute for human physical abilities, in settings from factories to\nhospitals, so brain engineering will construct stand-ins for our mental\nabilities, and possibly even enable us to fix our brains when they break.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 01:18:13 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Granger", "Richard", ""]]}, {"id": "1704.03941", "submitter": "Henry Tuckwell", "authors": "Henry C. Tuckwell, Ying Zhou, Nicholas J. Penington", "title": "Analysis of pacemaker activity in a two-component model of some\n  brainstem neurons", "comments": "arXiv admin note: substantial text overlap with arXiv:1508.05468", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serotonergic, noradrenergic and dopaminergic brainstem (including midbrain)\nneurons, often exhibit spontaneous and fairly regular spiking with frequencies\nof order a few Hz, though dopaminergic and noradrenergic neurons only exhibit\nsuch pacemaker-type activity in vitro or in vivo under special conditions.\n  A large number of ion channel types contribute to such spiking so that\ndetailed modeling of spike generation leads to the requirement of solving very\nlarge systems of differential equations. It is useful to have simplified\nmathematical models of spiking in such neurons so that, for example, features\nof inputs and output spike trains can be incorporated including stochastic\neffects for possible use in network models.\n  In this article we investigate a simple two-component conductance-based model\nof the Hodgkin-Huxley type. Solutions are computed numerically and with\nsuitably chosen parameters mimic features of pacemaker-type spiking in the\nabove types of neurons. The effects of varying parameters is investigated in\ndetail, it being found that there is extreme sensitivity to eight of them.\nTransitions from non-spiking to spiking are examined for two of these, the\nhalf-activation potential for an activation variable and the added\n(depolarizing) current and contrasted with the behavior of the classical\nHodgkin-Huxley system. The plateaux levels between spikes can be adjusted, by\nchanging a set of voltage parameters, to agree with experimental observations.\nExperiment has shown that in, in vivo, dopaminergic and noradrenergic neurons'\npacemaker activity can be induced by the removal of excitatory inputs or the\nintroduction of inhibitory ones. These properties are confirmed by mimicking\nopposite such changes in the model, which resulted in a change from pacemaker\nactivity to bursting-type phenomena.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 21:59:55 GMT"}, {"version": "v2", "created": "Sat, 15 Apr 2017 13:38:15 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Tuckwell", "Henry C.", ""], ["Zhou", "Ying", ""], ["Penington", "Nicholas J.", ""]]}, {"id": "1704.04199", "submitter": "Madhavun Candadai Vasu", "authors": "Madhavun Candadai Vasu, Eduardo J. Izquierdo", "title": "Evolution and Analysis of Embodied Spiking Neural Networks Reveals\n  Task-Specific Clusters of Effective Networks", "comments": "Camera ready version of accepted for GECCO'17", "journal-ref": null, "doi": "10.1145/3071178.3071336", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elucidating principles that underlie computation in neural networks is\ncurrently a major research topic of interest in neuroscience. Transfer Entropy\n(TE) is increasingly used as a tool to bridge the gap between network\nstructure, function, and behavior in fMRI studies. Computational models allow\nus to bridge the gap even further by directly associating individual neuron\nactivity with behavior. However, most computational models that have analyzed\nembodied behaviors have employed non-spiking neurons. On the other hand,\ncomputational models that employ spiking neural networks tend to be restricted\nto disembodied tasks. We show for the first time the artificial evolution and\nTE-analysis of embodied spiking neural networks to perform a\ncognitively-interesting behavior. Specifically, we evolved an agent controlled\nby an Izhikevich neural network to perform a visual categorization task. The\nsmallest networks capable of performing the task were found by repeating\nevolutionary runs with different network sizes. Informational analysis of the\nbest solution revealed task-specific TE-network clusters, suggesting that\nwithin-task homogeneity and across-task heterogeneity were key to behavioral\nsuccess. Moreover, analysis of the ensemble of solutions revealed that\ntask-specificity of TE-network clusters correlated with fitness. This provides\nan empirically testable hypothesis that links network structure to behavior.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 16:23:19 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 00:53:16 GMT"}], "update_date": "2017-06-08", "authors_parsed": [["Vasu", "Madhavun Candadai", ""], ["Izquierdo", "Eduardo J.", ""]]}, {"id": "1704.04238", "submitter": "David Kappel", "authors": "David Kappel, Robert Legenstein, Stefan Habenschuss, Michael Hsieh and\n  Wolfgang Maass", "title": "A dynamic connectome supports the emergence of stable computational\n  function of neural circuits through reward-based learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic connections between neurons in the brain are dynamic because of\ncontinuously ongoing spine dynamics, axonal sprouting, and other processes. In\nfact, it was recently shown that the spontaneous synapse-autonomous component\nof spine dynamics is at least as large as the component that depends on the\nhistory of pre- and postsynaptic neural activity. These data are inconsistent\nwith common models for network plasticity, and raise the questions how neural\ncircuits can maintain a stable computational function in spite of these\ncontinuously ongoing processes, and what functional uses these ongoing\nprocesses might have. Here, we present a rigorous theoretical framework for\nthese seemingly stochastic spine dynamics and rewiring processes in the context\nof reward-based learning tasks. We show that spontaneous synapse-autonomous\nprocesses, in combination with reward signals such as dopamine, can explain the\ncapability of networks of neurons in the brain to configure themselves for\nspecific computational tasks, and to compensate automatically for later changes\nin the network or task. Furthermore we show theoretically and through computer\nsimulations that stable computational performance is compatible with\ncontinuously ongoing synapse-autonomous changes. After reaching good\ncomputational performance it causes primarily a slow drift of network\narchitecture and dynamics in task-irrelevant dimensions, as observed for neural\nactivity in motor cortex and other areas. On the more abstract level of\nreinforcement learning the resulting model gives rise to an understanding of\nreward-driven network plasticity as continuous sampling of network\nconfigurations.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 15:52:14 GMT"}, {"version": "v2", "created": "Mon, 28 Aug 2017 10:34:44 GMT"}, {"version": "v3", "created": "Fri, 1 Sep 2017 08:11:34 GMT"}, {"version": "v4", "created": "Fri, 5 Jan 2018 12:56:42 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Kappel", "David", ""], ["Legenstein", "Robert", ""], ["Habenschuss", "Stefan", ""], ["Hsieh", "Michael", ""], ["Maass", "Wolfgang", ""]]}, {"id": "1704.04626", "submitter": "Byungjoon Min", "authors": "Flaviano Morone, Kevin Roth, Byungjoon Min, H. Eugene Stanley,\n  Hern\\'an A. Makse", "title": "Model of Brain Activation Predicts the Neural Collective Influence Map\n  of the Brain", "comments": "18 pages, 5 figures", "journal-ref": "Proc. Natl. Acad. Sci. 114 (15), 3849-3854 (2017)", "doi": null, "report-no": null, "categories": "q-bio.NC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient complex systems have a modular structure, but modularity does not\nguarantee robustness, because efficiency also requires an ingenious interplay\nof the interacting modular components. The human brain is the elemental\nparadigm of an efficient robust modular system interconnected as a network of\nnetworks (NoN). Understanding the emergence of robustness in such modular\narchitectures from the interconnections of its parts is a long-standing\nchallenge that has concerned many scientists. Current models of dependencies in\nNoN inspired by the power grid express interactions among modules with fragile\ncouplings that amplify even small shocks, thus preventing functionality.\nTherefore, we introduce a model of NoN to shape the pattern of brain\nactivations to form a modular environment that is robust. The model predicts\nthe map of neural collective influencers (NCIs) in the brain, through the\noptimization of the influence of the minimal set of essential nodes responsible\nfor broadcasting information to the whole-brain NoN. Our results suggest new\nintervention protocols to control brain activity by targeting influential\nneural nodes predicted by network theory.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 11:40:50 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Morone", "Flaviano", ""], ["Roth", "Kevin", ""], ["Min", "Byungjoon", ""], ["Stanley", "H. Eugene", ""], ["Makse", "Hern\u00e1n A.", ""]]}, {"id": "1704.04795", "submitter": "Adam Noel", "authors": "Adam Noel, Dimitrios Makrakis, Andrew W. Eckford", "title": "Root Mean Square Error of Neural Spike Train Sequence Matching with\n  Optogenetics", "comments": "6 pages, 5 figures. Will be presented at IEEE Global Communications\n  Conference (IEEE GLOBECOM 2017) in December 2017", "journal-ref": null, "doi": "10.1109/GLOCOM.2017.8255060", "report-no": null, "categories": "q-bio.NC cs.IT math.IT physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optogenetics is an emerging field of neuroscience where neurons are\ngenetically modified to express light-sensitive receptors that enable external\ncontrol over when the neurons fire. Given the prominence of neuronal signaling\nwithin the brain and throughout the body, optogenetics has significant\npotential to improve the understanding of the nervous system and to develop\ntreatments for neurological diseases. This paper uses a simple optogenetic\nmodel to compare the timing distortion between a randomly-generated target\nspike sequence and an externally-stimulated neuron spike sequence. The\ndistortion is measured by filtering each sequence and finding the root mean\nsquare error between the two filter outputs. The expected distortion is derived\nin closed form when the target sequence generation rate is sufficiently low.\nDerivations are verified via simulations.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 16:34:09 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 02:01:02 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Noel", "Adam", ""], ["Makrakis", "Dimitrios", ""], ["Eckford", "Andrew W.", ""]]}, {"id": "1704.04818", "submitter": "Liane Gabora", "authors": "Liane Gabora, Samantha Thomson, and Kirsty Kitto", "title": "A Layperson Introduction to the Quantum Approach to Humor", "comments": "11 pages; In W. Ruch (Ed.) Humor: Transdisciplinary approaches (pp.\n  317-322). Bogot\\'a Colombia: Universidad Cooperativa de Colombia Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite our familiarity with and fondness of humor, until relatively recently\nvery little was known about the underlying psychology of this complex and\nnuanced phenomenon. Recently, however, cognitive psychologists have begun\ninvestigating how people understand humor and why we find certain things funny.\nThis chapter introduces a new cognitive approach to modeling humor that we\nrefer to as the 'quantum approach', which will be explained here in intuitive,\nnon-mathematical terms later (a formal treatment can be found in Gabora &\nKitto, 2017). What makes the quantum approach a promising candidate for a\ntheory of humor is that it can be useful for representing states of ambiguity,\nand it defines states and variables with reference to a context. Contextuality\nand ambiguity both play a key role in humor, which often hangs on an ambiguous\nword, phrase, or situation that might not make sense, or even be socially\nacceptable outside the specific context of the joke. The quantum approach does\nnot attempt to explain all aspects of humor, such as the contagious quality of\nlaughter, or why children tease each other, or why people might find it funny\nwhen someone is hit in the face with a pie (and laugh even if they know it will\nhappen in advance); what it aims to do is to mathematically represent the\nunderlying cognitive process of \"getting\" a joke. After briefly overviewing the\nrelevant historical antecedents of the quantum approach and other related\napproaches in cognitive psychology, we present the theoretical basis of our\napproach, and outline a recent study that provides empirical support for it.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 20:52:41 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 22:24:36 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Gabora", "Liane", ""], ["Thomson", "Samantha", ""], ["Kitto", "Kirsty", ""]]}, {"id": "1704.04989", "submitter": "Rodolphe Sepulchre", "authors": "Rodolphe Sepulchre, Guillaume Drion, Alessio Franci", "title": "Excitable behaviors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This chapter revisits the concept of excitability, a basic system property of\nneurons. The focus is on excitable systems regarded as behaviors rather than\ndynamical systems. By this we mean open systems modulated by specific\ninterconnection properties rather than closed systems classified by their\nparameter ranges. Modeling, analysis, and synthesis questions can be formulated\nin the classical language of circuit theory. The input-output characterization\nof excitability is in terms of the local sensitivity of the current-voltage\nrelationship. It suggests the formulation of novel questions for non-linear\nsystem theory, inspired by questions from experimental neurophysiology.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 09:17:16 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Sepulchre", "Rodolphe", ""], ["Drion", "Guillaume", ""], ["Franci", "Alessio", ""]]}, {"id": "1704.05056", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "The Creative Process of Cultural Evolution", "comments": "26 pages; To appear in Leung, A., Kwan, L., & Liou, S. (Eds.)\n  Handbook of Culture and Creativity: Basic Processes and Applied Innovations.\n  Oxford: Oxford University Press", "journal-ref": "In A. Leung (Ed.) Handbook of Culture and creativity: Basic\n  processes and applied innovations (pp. 33-60). New York: Oxford University\n  Press (2018)", "doi": null, "report-no": null, "categories": "q-bio.PE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even this saying itself is a variant of a similar statement attributed to\nBernard of Chartres in the 12th Century, and inspired the title for a book by\nSteven Hawking and an album by Oasis. Creative ideas beget other creative ideas\nand, as a result, modifications accumulate, and we see an overall increase in\nthe complexity of cultural novelty over time, a phenomenon sometimes referred\nto as the ratchet effect (Tomasello, Kruger, & Ratner, 1993). Although we may\nnever meet the people or objects that creatively influence us, by assimilating\nwhat we encounter around us and bringing to bear our own insights and\nperspectives, we all contribute in our own way, however small, to a second\nevolutionary process -- the evolution of culture. This chapter explores how we\ncan better understand culture by understanding the creative processes that fuel\nit, and better understand creativity by examining it from its cultural context.\nFirst, we look at some theoretical frameworks for how culture evolves and what\nthese frameworks imply for the role of creativity. Then we will see how\nquestions about the relationship between creativity and cultural evolution have\nbeen addressed using an agent-based model. We will also discuss studies of how\ncreative outputs are influenced, in perhaps unexpected ways, by other ideas and\nindividuals, and how individual creative styles \"peek through\" cultural outputs\nin different domains.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 21:11:47 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 22:14:48 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1704.05255", "submitter": "Miguel Aguilera", "authors": "Miguel Aguilera and Manuel G. Bedia", "title": "Criticality as It Could Be: organizational invariance as self-organized\n  criticality in embodied agents", "comments": null, "journal-ref": null, "doi": "10.7551/ecal_a_009", "report-no": null, "categories": "nlin.AO cond-mat.dis-nn cond-mat.stat-mech cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper outlines a methodological approach for designing adaptive agents\ndriving themselves near points of criticality. Using a synthetic approach we\nconstruct a conceptual model that, instead of specifying mechanistic\nrequirements to generate criticality, exploits the maintenance of an\norganizational structure capable of reproducing critical behavior. Our approach\nexploits the well-known principle of universality, which classifies critical\nphenomena inside a few universality classes of systems independently of their\nspecific mechanisms or topologies. In particular, we implement an artificial\nembodied agent controlled by a neural network maintaining a correlation\nstructure randomly sampled from a lattice Ising model at a critical point. We\nevaluate the agent in two classical reinforcement learning scenarios: the\nMountain Car benchmark and the Acrobot double pendulum, finding that in both\ncases the neural controller reaches a point of criticality, which coincides\nwith a transition point between two regimes of the agent's behaviour,\nmaximizing the mutual information between neurons and sensorimotor patterns.\nFinally, we discuss the possible applications of this synthetic approach to the\ncomprehension of deeper principles connected to the pervasive presence of\ncriticality in biological and cognitive systems.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 09:53:25 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 08:31:30 GMT"}, {"version": "v3", "created": "Wed, 24 May 2017 10:51:29 GMT"}], "update_date": "2017-12-14", "authors_parsed": [["Aguilera", "Miguel", ""], ["Bedia", "Manuel G.", ""]]}, {"id": "1704.05301", "submitter": "Dibakar Ghosh Dr.", "authors": "Sarbendu Rakshit, Bidesh K. Bera, Matjaz Perc and Dibakar Ghosh", "title": "Basin stability for chimera states", "comments": "10 pages, 8 figures; accepted for publication in Scientific Reports", "journal-ref": "Sci. Rep. 7, 2412 (2017)", "doi": "10.1038/s41598-017-02409-5", "report-no": null, "categories": "nlin.CD physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chimera states, namely complex spatiotemporal patterns that consist of\ncoexisting domains of spatially coherent and incoherent dynamics, are\ninvestigated in a network of coupled identical oscillators. These intriguing\nspatiotemporal patterns were first reported in nonlocally coupled phase\noscillators, and it was shown that such mixed type behavior occurs only for\nspecific initial conditions in nonlocally and globally coupled networks. The\ninfluence of initial conditions on chimera states has remained a fundamental\nproblem since their discovery. In this report, we investigate the robustness of\nchimera states together with incoherent and coherent states in dependence on\nthe initial conditions. For this, we use the basin stability method which is\nrelated to the volume of the basin of attraction, and we consider nonlocally\nand globally coupled time-delayed Mackey-Glass oscillators as example.\nPreviously, it was shown that the existence of chimera states can be\ncharacterized by mean phase velocity and a statistical measure, such as the\nstrength of incoherence, by using well prepared initial conditions. Here we\nshow further how the coexistence of different dynamical states can be\nidentified and quantified by means of the basin stability measure over a wide\nrange of the parameter space.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 12:28:14 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Rakshit", "Sarbendu", ""], ["Bera", "Bidesh K.", ""], ["Perc", "Matjaz", ""], ["Ghosh", "Dibakar", ""]]}, {"id": "1704.05344", "submitter": "Rodrigo Cofre", "authors": "Bruno Cessac, Ignacio Ampuero and Rodrigo Cofre", "title": "Linear response for spiking neuronal networks with unbounded memory", "comments": "60 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We establish a general linear response relation for spiking neuronal\nnetworks, based on chains with unbounded memory. This relation allows us to\npredict the influence of a weak amplitude time-dependent external stimuli on\nspatio-temporal spike correlations, from the spontaneous statistics (without\nstimulus) in a general context where the memory in spike dynamics can extend\narbitrarily far in the past. Using this approach, we show how linear response\nis explicitly related to neuronal dynamics with an example, the gIF model,\nintroduced by M. Rudolph and A. Destexhe. This example illustrates the\ncollective effect of the stimuli, intrinsic neuronal dynamics, and network\nconnectivity on spike statistics. We illustrate our results with numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 14:02:15 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 14:18:59 GMT"}, {"version": "v3", "created": "Sun, 14 Oct 2018 02:10:24 GMT"}, {"version": "v4", "created": "Wed, 17 Oct 2018 01:08:36 GMT"}, {"version": "v5", "created": "Thu, 2 Apr 2020 01:48:38 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Cessac", "Bruno", ""], ["Ampuero", "Ignacio", ""], ["Cofre", "Rodrigo", ""]]}, {"id": "1704.05687", "submitter": "Sayan Nag", "authors": "Archi Banerjee, Shankha Sanyal, Souparno Roy, Sourya Sengupta, Sayan\n  Biswas, Sayan Nag, Ranjan Sengupta and Dipak Ghosh", "title": "Neural (EEG) Response during Creation and Appreciation: A Novel Study\n  with Hindustani Raga Music", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What happens inside the performers brain when he is performing and composing\na particular raga. Are there some specific regions in brain which are activated\nwhen an artist is creating or imaging a raga in his brain. Do the regions\nremain the same when the artist is listening to the same raga sung by him.\nThese are the questions that perplexed neuroscientists for a long time. In this\nstudy we strive to answer these questions by using latest state of the art\ntechniques to assess brain response. An EEG experiment was conducted for two\neminent performers of Indian classical music, when they mentally created the\nimagery of a raga Jay Jayanti in their mind, as well as when they listened to\nthe same raga. The beauty of Hindustani music lies in the fact that the\nmusician is himself the composer and recreates the imagery of the raga in his\nmind while performing, hence the scope of creative improvisations are immense.\nThe alpha and theta frequency rhythms were segregated from each of the time\nseries data and analyzed using robust non MFDXA technique to quantitatively\nassess the degree of cross-correlation of each EEG frequency rhythm in\ndifferent combination of electrodes from frontal, occipital and temporal lobes.\nA strong response was found in the occipital and fronto occipital region during\nmental improvisation of the raga, which is an interesting revelation of this\nstudy. Strong retentive features were obtained in regard to both alpha and\ntheta rhythms in musical listening in the fronto temporal and occipital\ntemporal region while the features were almost absent in the thinking part.\nFurther, other specific regions have been identified separately for the two\nseparate conditions in which the correlations among the different lobes were\nthe strongest.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 11:01:20 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Banerjee", "Archi", ""], ["Sanyal", "Shankha", ""], ["Roy", "Souparno", ""], ["Sengupta", "Sourya", ""], ["Biswas", "Sayan", ""], ["Nag", "Sayan", ""], ["Sengupta", "Ranjan", ""], ["Ghosh", "Dipak", ""]]}, {"id": "1704.05694", "submitter": "John M. O' Toole", "authors": "John M. O' Toole and Geraldine B. Boylan", "title": "NEURAL: quantitative features for newborn EEG using Matlab", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: For newborn infants in critical care, continuous monitoring of\nbrain function can help identify infants at-risk of brain injury. Quantitative\nfeatures allow a consistent and reproducible approach to EEG analysis, but only\nwhen all implementation aspects are clearly defined.\n  Methods: We detail quantitative features frequently used in neonatal EEG\nanalysis and present a Matlab software package together with exact\nimplementation details for all features. The feature set includes stationary\nfeatures that capture amplitude and frequency characteristics and features of\ninter-hemispheric connectivity. The software, a Neonatal Eeg featURe set in\nmAtLab (NEURAL), is open source and freely available. The software also\nincludes a pre-processing stage with a basic artefact removal procedure.\n  Conclusions: NEURAL provides a common platform for quantitative analysis of\nneonatal EEG. This will support reproducible research and enable comparisons\nacross independent studies. These features present summary measures of the EEG\nthat can also be used in automated methods to determine brain development and\nhealth of the newborn in critical care.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 11:20:38 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Toole", "John M. O'", ""], ["Boylan", "Geraldine B.", ""]]}, {"id": "1704.05748", "submitter": "Nicolai Pedersen", "authors": "Rasmus S. Andersen, Anders U. Eliasen, Nicolai Pedersen, Michael Riis\n  Andersen, Sofie Therese Hansen, Lars Kai Hansen", "title": "EEG source imaging assists decoding in a face recognition task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EEG based brain state decoding has numerous applications. State of the art\ndecoding is based on processing of the multivariate sensor space signal,\nhowever evidence is mounting that EEG source reconstruction can assist\ndecoding. EEG source imaging leads to high-dimensional representations and\nrather strong a priori information must be invoked. Recent work by Edelman et\nal. (2016) has demonstrated that introduction of a spatially focal source space\nrepresentation can improve decoding of motor imagery. In this work we explore\nthe generality of Edelman et al. hypothesis by considering decoding of face\nrecognition. This task concerns the differentiation of brain responses to\nimages of faces and scrambled faces and poses a rather difficult decoding\nproblem at the single trial level. We implement the pipeline using spatially\nfocused features and show that this approach is challenged and source imaging\ndoes not lead to an improved decoding. We design a distributed pipeline in\nwhich the classifier has access to brain wide features which in turn does lead\nto a 15% reduction in the error rate using source space features. Hence, our\nwork presents supporting evidence for the hypothesis that source imaging\nimproves decoding.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 10:19:16 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Andersen", "Rasmus S.", ""], ["Eliasen", "Anders U.", ""], ["Pedersen", "Nicolai", ""], ["Andersen", "Michael Riis", ""], ["Hansen", "Sofie Therese", ""], ["Hansen", "Lars Kai", ""]]}, {"id": "1704.05826", "submitter": "Arian Ashourvan", "authors": "Arian Ashourvan, Qawi K. Telesford, Timothy Verstynen, Jean M. Vettel,\n  Danielle S. Bassett", "title": "Multi-scale detection of hierarchical community architecture in\n  structural and functional brain networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection algorithms have been widely used to study the\norganization of complex systems like the brain. A principal appeal of these\ntechniques is their ability to identify a partition of brain regions (or nodes)\ninto communities, where nodes within a community are densely interconnected. In\ntheir simplest application, community detection algorithms are agnostic to the\npresence of community hierarchies, but a common characteristic of many neural\nsystems is a nested hierarchy. To address this limitation, we exercise a\nmulti-scale extension of a community detection technique known as modularity\nmaximization, and we apply the tool to both synthetic graphs and graphs derived\nfrom human structural and functional imaging data. Our multi-scale community\ndetection algorithm links a graph to copies of itself across neighboring\ntopological scales, thereby becoming sensitive to conserved community\norganization across neighboring levels of the hierarchy. We demonstrate that\nthis method allows for a better characterization of topological inhomogeneities\nof the graph's hierarchy by providing a local (node) measure of community\nstability and inter-scale reliability across topological scales. We compare the\nbrain's structural and functional network architectures and demonstrate that\nstructural graphs display a wider range of topological scales than functional\ngraphs. Finally, we build a multimodal multiplex graph that combines structural\nand functional connectivity in a single model, and we identify the topological\nscales where resting state functional connectivity and underlying structural\nconnectivity show similar versus unique hierarchical community architecture.\nTogether, our results showcase the advantages of the multi-scale community\ndetection algorithm in studying hierarchical community structure in brain\ngraphs, and they illustrate its utility in modeling multimodal neuroimaging\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 17:08:18 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Ashourvan", "Arian", ""], ["Telesford", "Qawi K.", ""], ["Verstynen", "Timothy", ""], ["Vettel", "Jean M.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1704.06014", "submitter": "Kieran Fox", "authors": "Kieran C.R. Fox, Kalina Christoff", "title": "Introduction: Toward an interdisciplinary science of spontaneous thought", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enormous questions still loom for the emerging science of spontaneous\nthought: what, exactly, is spontaneous thought? Why does our brain engage in\nspontaneous forms of thinking, and when is this most likely to occur? And\nperhaps the question most interesting and accessible from a scientific\nperspective: how does the brain generate, elaborate, and evaluate its own\nspontaneous creations? The central aim of this volume is to bring together\nviews from neuroscience, psychology, philosophy, phenomenology, history,\neducation, contemplative traditions, and clinical practice in order to begin to\naddress the ubiquitous but poorly understood mental phenomena that we\ncollectively call 'spontaneous thought.' Perhaps no other mental experience is\nso familiar to us in daily life, and yet so difficult to understand and explain\nscientifically. The present volume represents the first effort to bring such\nhighly diverse perspectives to bear on answering the what, when, why, and how\nof spontaneous thought.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 04:58:42 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Fox", "Kieran C. R.", ""], ["Christoff", "Kalina", ""]]}, {"id": "1704.06593", "submitter": "Jacek Bialowas", "authors": "Jacek Bialowas, Beata Grzyb, Pawel Poszumski", "title": "Firing Cell: An Artificial Neuron with a Simulation of\n  Long-Term-Potentiation-Related Memory", "comments": "4 pages, 3 figures", "journal-ref": "ISAROB 2006, pp.731-734", "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a computational model of neuron, called firing cell (FC),\nproperties of which cover such phenomena as attenuation of receptors for\nexternal stimuli, delay and decay of postsynaptic potentials, modification of\ninternal weights due to propagation of postsynaptic potentials through the\ndendrite, modification of properties of the analog memory for each input due to\na pattern of short-time synaptic potentiation or long-time synaptic\npotentiation (LTP), output-spike generation when the sum of all inputs exceeds\na threshold, and refraction. The cell may take one of the three forms:\nexcitatory, inhibitory, and receptory. The computer simulations showed that,\ndepending on the phase of input signals, the artificial neuron's output\nfrequency may demonstrate various chaotic behaviors.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 15:31:33 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Bialowas", "Jacek", ""], ["Grzyb", "Beata", ""], ["Poszumski", "Pawel", ""]]}, {"id": "1704.06645", "submitter": "Dylan Muir", "authors": "Dylan Richard Muir", "title": "Feed-forward approximations to dynamic recurrent network architectures", "comments": "Author's final version, accepted for publication in Neural\n  Computation", "journal-ref": null, "doi": "10.1162/neco_a_01042", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural network architectures can have useful computational\nproperties, with complex temporal dynamics and input-sensitive attractor\nstates. However, evaluation of recurrent dynamic architectures requires\nsolution of systems of differential equations, and the number of evaluations\nrequired to determine their response to a given input can vary with the input,\nor can be indeterminate altogether in the case of oscillations or instability.\nIn feed-forward networks, by contrast, only a single pass through the network\nis needed to determine the response to a given input. Modern machine-learning\nsystems are designed to operate efficiently on feed-forward architectures. We\nhypothesised that two-layer feedforward architectures with simple,\ndeterministic dynamics could approximate the responses of single-layer\nrecurrent network architectures. By identifying the fixed-point responses of a\ngiven recurrent network, we trained two-layer networks to directly approximate\nthe fixed-point response to a given input. These feed-forward networks then\nembodied useful computations, including competitive interactions, information\ntransformations and noise rejection. Our approach was able to find useful\napproximations to recurrent networks, which can then be evaluated in linear and\ndeterministic time complexity.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 17:28:47 GMT"}, {"version": "v2", "created": "Fri, 15 Sep 2017 09:53:08 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Muir", "Dylan Richard", ""]]}, {"id": "1704.07526", "submitter": "Yansong Chua", "authors": "Yansong Chua, Cheston Tan", "title": "Neurogenesis and multiple plasticity mechanisms enhance associative\n  memory retrieval in a spiking network model of the hippocampus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hippocampal CA3 is crucial for the formation of long-term associative memory.\nIt has a heavily recurrent connectivity, and memories are thought to be stored\nas memory engrams in the CA3. However, despite its importance for memory\nstorage and retrieval, spiking network models of the CA3 to date are relatively\nsmall-scale, and exist as only proof-of-concept models. Specifically, how\nneurogenesis in the dentate gyrus affects memory encoding and retrieval in the\nCA3 is not studied in such spiking models. Our work is the first to develop a\nbiologically plausible spiking neural network model of hippocampal memory\nencoding and retrieval, with at least an order-of-magnitude more neurons than\nprevious models. It is also the first to investigate the effect of neurogenesis\non CA3 memory encoding and retrieval. Using such a model, we first show that a\nrecently developed plasticity model is crucial for good encoding and retrieval.\nNext, we show how neural properties related to neurogenesis and neuronal death\nenhance storage and retrieval of associative memories in the CA3. In\nparticular, we show that without neurogenesis, increasing number of CA3 neurons\nare recruited by each new memory stimulus, resulting in a corresponding\nincrease in inhibition and poor memory retrieval as more memories are encoded.\nNeurogenesis, on the other hand, maintains the number of CA3 neurons recruited\nper stimulus, and enables the retrieval of recent memories, while forgetting\nthe older ones. Our model suggests that structural plasticity (provided by\nneurogenesis and apoptosis) is required in the hippocampus for memory encoding\nand retrieval when the network is overloaded; synaptic plasticity alone does\nnot suffice. The above results are obtained from an exhaustive study in the\ndifferent plasticity models and network parameters.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 03:30:28 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Chua", "Yansong", ""], ["Tan", "Cheston", ""]]}, {"id": "1704.07575", "submitter": "Huiguang He", "authors": "Changde Du, Changying Du, Huiguang He", "title": "Sharing deep generative representation for perceived image\n  reconstruction from human brain activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding human brain activities via functional magnetic resonance imaging\n(fMRI) has gained increasing attention in recent years. While encouraging\nresults have been reported in brain states classification tasks, reconstructing\nthe details of human visual experience still remains difficult. Two main\nchallenges that hinder the development of effective models are the perplexing\nfMRI measurement noise and the high dimensionality of limited data instances.\nExisting methods generally suffer from one or both of these issues and yield\ndissatisfactory results. In this paper, we tackle this problem by casting the\nreconstruction of visual stimulus as the Bayesian inference of missing view in\na multiview latent variable model. Sharing a common latent representation, our\njoint generative model of external stimulus and brain response is not only\n\"deep\" in extracting nonlinear features from visual images, but also powerful\nin capturing correlations among voxel activities of fMRI recordings. The\nnonlinearity and deep structure endow our model with strong representation\nability, while the correlations of voxel activities are critical for\nsuppressing noise and improving prediction. We devise an efficient variational\nBayesian method to infer the latent variables and the model parameters. To\nfurther improve the reconstruction accuracy, the latent representations of\ntesting instances are enforced to be close to that of their neighbours from the\ntraining set via posterior regularization. Experiments on three fMRI recording\ndatasets demonstrate that our approach can more accurately reconstruct visual\nstimuli.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 08:20:42 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 05:16:14 GMT"}, {"version": "v3", "created": "Tue, 11 Jul 2017 01:50:34 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Du", "Changde", ""], ["Du", "Changying", ""], ["He", "Huiguang", ""]]}, {"id": "1704.07635", "submitter": "Onerva Korhonen", "authors": "Onerva Korhonen (1,2), Heini Saarim\\\"aki (1), Enrico Glerean (1),\n  Mikko Sams (1), Jari Saram\\\"aki (2) ((1) Department of Neuroscience and\n  Biomedical Engineering, School of Science, Aalto University, Espoo, Finland,\n  (2) Department of Computer Science, School of Science, Aalto University,\n  Espoo, Finland)", "title": "Consistency of Regions of Interest as nodes of functional brain networks\n  measured by fMRI", "comments": "28 + 19 pages, 7 + 14 figures. Accepted for publication in Network\n  Neuroscience", "journal-ref": "Network Neuroscience 1(3) (2017) 254-274", "doi": "10.1162/NETN_a_00013", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The functional network approach, where fMRI BOLD time series are mapped to\nnetworks depicting functional relationships between brain areas, has opened new\ninsights into the function of the human brain. In this approach, the choice of\nnetwork nodes is of crucial importance. One option is to consider fMRI voxels\nas nodes. This results in a large number of nodes, making network analysis and\ninterpretation of results challenging. A common alternative is to use\npre-defined clusters of anatomically close voxels, Regions of Interest (ROIs).\nThis approach assumes that voxels within ROIs are functionally similar. Because\nthese two approaches result in different network structures, it is crucial to\nunderstand what happens to network connectivity when moving from the voxel\nlevel to the ROI level. We show that the consistency of ROIs, defined as the\nmean Pearson correlation coefficient between the time series of their voxels,\nvaries widely in resting-state experimental data. Therefore the assumption of\nsimilar voxel dynamics within each ROI does not generally hold. Further, the\ntime series of low-consistency ROIs may be highly correlated, resulting in\nspurious links in ROI-level networks. Based on these results, we recommend that\naveraging BOLD signals over anatomically defined ROIs should be carefully\nconsidered.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 11:23:12 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Korhonen", "Onerva", ""], ["Saarim\u00e4ki", "Heini", ""], ["Glerean", "Enrico", ""], ["Sams", "Mikko", ""], ["Saram\u00e4ki", "Jari", ""]]}, {"id": "1704.07636", "submitter": "Huu Phuoc Bui", "authors": "Huu Phuoc Bui, Satyendra Tomar, Hadrien Courtecuisse, Michel Audette,\n  St\\'ephane Cotin and St\\'ephane P.A. Bordas", "title": "Controlling the Error on Target Motion through Real-time Mesh\n  Adaptation: Applications to Deep Brain Stimulation", "comments": "21 pages, 14 figures", "journal-ref": null, "doi": "10.1002/cnm.2958", "report-no": null, "categories": "cs.CE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an error-controlled mesh refinement procedure for needle insertion\nsimulation and apply it to the simulation of electrode implantation for deep\nbrain stimulation, including brain shift. Our approach enables to control the\nerror in the computation of the displacement and stress fields around the\nneedle tip and needle shaft by suitably refining the mesh, whilst maintaining a\ncoarser mesh in other parts of the domain. We demonstrate through academic and\npractical examples that our approach increases the accuracy of the displacement\nand stress fields around the needle without increasing the computational\nexpense. This enables real-time simulations. The proposed methodology has\ndirect implications to increase the accuracy and control the computational\nexpense of the simulation of percutaneous procedures such as biopsy,\nbrachytherapy, regional anesthesia, or cryotherapy and can be essential to the\ndevelopment of robotic guidance.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 11:23:51 GMT"}, {"version": "v2", "created": "Sat, 30 Sep 2017 19:28:36 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Bui", "Huu Phuoc", ""], ["Tomar", "Satyendra", ""], ["Courtecuisse", "Hadrien", ""], ["Audette", "Michel", ""], ["Cotin", "St\u00e9phane", ""], ["Bordas", "St\u00e9phane P. A.", ""]]}, {"id": "1704.08306", "submitter": "Michael Smith", "authors": "Michael R. Smith, Aaron J. Hill, Kristofor D. Carlson, Craig M.\n  Vineyard, Jonathon Donaldson, David R. Follett, Pamela L. Follett, John H.\n  Naegle, Conrad D. James, James B. Aimone", "title": "A Digital Neuromorphic Architecture Efficiently Facilitating Complex\n  Synaptic Response Functions Applied to Liquid State Machines", "comments": "8 pages, 4 Figures, Preprint of 2017 IJCNN", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information in neural networks is represented as weighted connections, or\nsynapses, between neurons. This poses a problem as the primary computational\nbottleneck for neural networks is the vector-matrix multiply when inputs are\nmultiplied by the neural network weights. Conventional processing architectures\nare not well suited for simulating neural networks, often requiring large\namounts of energy and time. Additionally, synapses in biological neural\nnetworks are not binary connections, but exhibit a nonlinear response function\nas neurotransmitters are emitted and diffuse between neurons. Inspired by\nneuroscience principles, we present a digital neuromorphic architecture, the\nSpiking Temporal Processing Unit (STPU), capable of modeling arbitrary complex\nsynaptic response functions without requiring additional hardware components.\nWe consider the paradigm of spiking neurons with temporally coded information\nas opposed to non-spiking rate coded neurons used in most neural networks. In\nthis paradigm we examine liquid state machines applied to speech recognition\nand show how a liquid state machine with temporal dynamics maps onto the\nSTPU-demonstrating the flexibility and efficiency of the STPU for instantiating\nneural algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 16:12:31 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Smith", "Michael R.", ""], ["Hill", "Aaron J.", ""], ["Carlson", "Kristofor D.", ""], ["Vineyard", "Craig M.", ""], ["Donaldson", "Jonathon", ""], ["Follett", "David R.", ""], ["Follett", "Pamela L.", ""], ["Naegle", "John H.", ""], ["James", "Conrad D.", ""], ["Aimone", "James B.", ""]]}, {"id": "1704.08372", "submitter": "Hannah Bos", "authors": "Hannah Bos, Jannis Sch\\\"ucker, Moritz Helias", "title": "How the connectivity structure of neuronal networks influences responses\n  to oscillatory stimuli", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Propagation of oscillatory signals through the cortex and coherence is shaped\nby the connectivity structure of neuronal circuits. This study systematically\ninvestigates the network and stimulus properties that shape network responses.\nThe results show how input to a cortical column model of the primary visual\ncortex excites dynamical modes determined by the laminar pattern. Stimulating\nthe inhibitory neurons in the upper layer reproduces experimentally observed\nresonances at gamma frequency whose origin can be traced back to two anatomical\nsub-circuits. We develop this result systematically: Initially, we highlight\nthe effect of stimulus amplitude and filter properties of the neurons on their\nresponse to oscillatory stimuli. Subsequently, we analyze the amplification of\noscillatory stimuli by the effective network structure. We demonstrate that the\namplification of stimuli, as well as their visibility in different populations,\ncan be explained by specific network patterns. Inspired by experimental results\nwe ask whether the anatomical origin of oscillations can be inferred by\napplying oscillatory stimuli. We find that different network motifs can\ngenerate similar responses to oscillatory input, showing that resonances in the\nnetwork response cannot, straightforwardly, be assigned to the motifs they\nemerge from. Applying the analysis to a spiking model of a cortical column, we\ncharacterize how the dynamic mode structure, which is induced by the laminar\nconnectivity, processes external input. In particular, we show that a stimulus\napplied to specific populations typically elicits responses of several\ninteracting modes. The resulting network response is therefore composed of a\nmultitude of contributions and can therefore neither be assigned to a single\nmode nor do the observed resonances necessarily coincide with the intrinsic\nresonances of the circuit.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 22:52:24 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Bos", "Hannah", ""], ["Sch\u00fccker", "Jannis", ""], ["Helias", "Moritz", ""]]}, {"id": "1704.08585", "submitter": "G Ambika", "authors": "K. P. Harikrishnan, Rinku Jacob, R. Misra, G. Ambika", "title": "Determining the minimum embedding dimension for state space\n  reconstruction through recurrence networks", "comments": "13 pages, 8 figures, submitted to Pramana( J Phys)", "journal-ref": "Indian Academy of Sciences Conference Series (2017) 1:1", "doi": "10.29195/iascs.01.01.0004", "report-no": null, "categories": "q-bio.NC nlin.CD physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of observed time series from nonlinear systems is usually done\nby making a time-delay reconstruction to unfold the dynamics on a\nmulti-dimensional state space. An important aspect of the analysis is the\nchoice of the correct embedding dimension. The conventional procedure used for\nthis is either the method of false nearest neighbors or the saturation of some\ninvariant measure, such as, correlation dimension. Here we examine this issue\nfrom a complex network perspective and propose a recurrence network based\nmeasure to determine the acceptable minimum embedding dimension to be used for\nsuch analysis. The measure proposed here is based on the well known\nKullback-Leibler divergence commonly used in information theory. We show that\nthe measure is simple and direct to compute and give accurate result for short\ntime series. To show the significance of the measure in the analysis of\npractical data, we present the analysis of two EEG signals as examples.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 02:20:18 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Harikrishnan", "K. P.", ""], ["Jacob", "Rinku", ""], ["Misra", "R.", ""], ["Ambika", "G.", ""]]}, {"id": "1704.08669", "submitter": "Wilhelm Braun", "authors": "Wilhelm Braun, R\\\"udiger Thul, Andr\\'e Longtin", "title": "Evolution of moments and correlations in non-renewal escape-time\n  processes", "comments": "14 pages, 12 figures, 1 appendix. Accepted for publication in\n  Physical Review E", "journal-ref": null, "doi": "10.1103/PhysRevE.95.052127", "report-no": null, "categories": "q-bio.NC math.PR physics.comp-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theoretical description of non-renewal stochastic systems is a challenge.\nAnalytical results are often not available or can only be obtained under strong\nconditions, limiting their applicability. Also, numerical results have mostly\nbeen obtained by ad-hoc Monte--Carlo simulations, which are usually\ncomputationally expensive when a high degree of accuracy is needed. To gain\nquantitative insight into these systems under general conditions, we here\nintroduce a numerical iterated first-passage time approach based on solving the\ntime-dependent Fokker-Planck equation (FPE) to describe the statistics of\nnon-renewal stochastic systems. We illustrate the approach using\nspike-triggered neuronal adaptation in the leaky and perfect integrate-and-fire\nmodel, respectively. The transition to stationarity of first-passage time\nmoments and their sequential correlations occur on a non-trivial timescale that\ndepends on all system parameters. Surprisingly this is so for both single\nexponential and scale-free power-law adaptation. The method works beyond the\nsmall noise and timescale separation approximations. It shows excellent\nagreement with direct Monte Carlo simulations, which allows for the computation\nof transient and stationary distributions. We compare different methods to\ncompute the evolution of the moments and serial correlation coefficients (SCC),\nand discuss the challenge of reliably computing the SCC which we find to be\nvery sensitive to numerical inaccuracies for both the leaky and perfect\nintegrate-and-fire models. In conclusion, our methods provide a general picture\nof non-renewal dynamics in a wide range of stochastic systems exhibiting short\nand long-range correlations.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 17:33:32 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Braun", "Wilhelm", ""], ["Thul", "R\u00fcdiger", ""], ["Longtin", "Andr\u00e9", ""]]}, {"id": "1704.08851", "submitter": "Sebastian Weichwald", "authors": "Sebastian Weichwald and Moritz Grosse-Wentrup", "title": "The right tool for the right question --- beyond the encoding versus\n  decoding dichotomy", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two major questions that neuroimaging studies attempt to answer:\nFirst, how are sensory stimuli represented in the brain (which we term the\nstimulus-based setting)? And, second, how does the brain generate cognition\n(termed the response-based setting)? There has been a lively debate in the\nneuroimaging community whether encoding and decoding models can provide\ninsights into these questions. In this commentary, we construct two simple and\nanalytically tractable examples to demonstrate that while an encoding model\nanalysis helps with the former, neither model is appropriate to satisfactorily\nanswer the latter question. Consequently, we argue that if we want to\nunderstand how the brain generates cognition, we need to move beyond the\nencoding versus decoding dichotomy and instead discuss and develop tools that\nare specifically tailored to our endeavour.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 08:56:47 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Weichwald", "Sebastian", ""], ["Grosse-Wentrup", "Moritz", ""]]}]