[{"id": "1202.0836", "submitter": "Gael Varoquaux", "authors": "Ga\\\"el Varoquaux (LNAO, INRIA Saclay - Ile de France), Alexandre\n  Gramfort (LNAO, INRIA Saclay - Ile de France), Jean Baptiste Poline (LNAO,\n  INRIA Saclay - Ile de France), Bertrand Thirion (LNAO, INRIA Saclay - Ile de\n  France)", "title": "Markov models for fMRI correlation structure: is brain functional\n  connectivity small world, or decomposable into networks?", "comments": null, "journal-ref": "Journal of Physiology - Paris (2012)", "doi": "10.1016/j.jphysparis.2012.01.001", "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlations in the signal observed via functional Magnetic Resonance Imaging\n(fMRI), are expected to reveal the interactions in the underlying neural\npopulations through hemodynamic response. In particular, they highlight\ndistributed set of mutually correlated regions that correspond to brain\nnetworks related to different cognitive functions. Yet graph-theoretical\nstudies of neural connections give a different picture: that of a highly\nintegrated system with small-world properties: local clustering but with short\npathways across the complete structure. We examine the conditional independence\nproperties of the fMRI signal, i.e. its Markov structure, to find realistic\nassumptions on the connectivity structure that are required to explain the\nobserved functional connectivity. In particular we seek a decomposition of the\nMarkov structure into segregated functional networks using decomposable graphs:\na set of strongly-connected and partially overlapping cliques. We introduce a\nnew method to efficiently extract such cliques on a large, strongly-connected\ngraph. We compare methods learning different graph structures from functional\nconnectivity by testing the goodness of fit of the model they learn on new\ndata. We find that summarizing the structure as strongly-connected networks can\ngive a good description only for very large and overlapping networks. These\nresults highlight that Markov models are good tools to identify the structure\nof brain connectivity from fMRI signals, but for this purpose they must reflect\nthe small-world properties of the underlying neural systems.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2012 22:31:39 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["Varoquaux", "Ga\u00ebl", "", "LNAO, INRIA Saclay - Ile de France"], ["Gramfort", "Alexandre", "", "LNAO, INRIA Saclay - Ile de France"], ["Poline", "Jean Baptiste", "", "LNAO,\n  INRIA Saclay - Ile de France"], ["Thirion", "Bertrand", "", "LNAO, INRIA Saclay - Ile de\n  France"]]}, {"id": "1202.1189", "submitter": "Erica Lanzarini", "authors": "Maria Rosa Antognazza, Diego Ghezzi, Marco Dal Maschio, Erica\n  Lanzarini, Fabio Benfenati and Guglielmo Lanzani", "title": "A hybrid bio-organic interface for neuronal photo-activation", "comments": "about 9 pages, 3 figures", "journal-ref": "Nature Communications, 1164, 2011", "doi": "10.1038/ncomms1164", "report-no": null, "categories": "cond-mat.soft physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interfacing artificial functional materials and living neuronal tissues is at\nthe forefront of bio-nano-technology. Attempts have been so far based onto\nmicroscale processing of metals and inorganic semiconductors as electrodes or\nphotoactive layers in biased devices. More recently, also nanomaterials\nproperties have been investigated. In spite of extensive research however, the\ncommunication between biological tissues and artificial sensors is still a\nchallenge. Constraints consist in the complexity of the fabrication processes\n(i.e. metal and semiconductor lithography), the mechanical properties (e.g.\nflexibility and mechanical invasiveness) and chemical influence (e.g.\ninflammatory reactions). In addition, electrodes have fixed geometries that\nlimit the location in space of the stimulus and often electrical currents are\ndetrimental for the overall system. To this respect organic soft matter offers\na chance in terms of biological affinity and mechanical properties. In\nparticular conjugated polymers have appealing optoelectronic features which\ncould lead to a new generation of neuronal communication and photo-manipulation\ntechniques. So far conjugated polymers have being only tested as coatings of\nelectrodes for neuronal activity recording. Here we report an up-scale of their\nuse: the successful interfacing of an organic semiconductor to a network of\ncultured primary neurons, through optical excitation. This allows to a new\nparadigm for the optical stimulation of neurons which could have important\nimplications for the development of an artificial retina based on organic\nphotodetectors.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2012 16:21:21 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["Antognazza", "Maria Rosa", ""], ["Ghezzi", "Diego", ""], ["Maschio", "Marco Dal", ""], ["Lanzarini", "Erica", ""], ["Benfenati", "Fabio", ""], ["Lanzani", "Guglielmo", ""]]}, {"id": "1202.1696", "submitter": "Max Hinne", "authors": "M. Hinne, T. Heskes, M. A. J. van Gerven", "title": "Bayesian Inference of Whole-Brain Networks", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In structural brain networks the connections of interest consist of\nwhite-matter fibre bundles between spatially segregated brain regions. The\npresence, location and orientation of these white matter tracts can be derived\nusing diffusion MRI in combination with probabilistic tractography.\nUnfortunately, as of yet no approaches have been suggested that provide an\nundisputed way of inferring brain networks from tractography. In this paper, we\nprovide a computational framework which we refer to as Bayesian connectomics.\nRather than applying an arbitrary threshold to obtain a single network, we\nconsider the posterior distribution of networks that are supported by the data,\ncombined with an exponential random graph (ERGM) prior that captures a priori\nknowledge concerning the graph-theoretical properties of whole-brain networks.\nWe show that, on simulated probabilistic tractography data, our approach is\nable to reconstruct whole-brain networks. In addition, our approach directly\nsupports multi-model data fusion and group-level network inference.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2012 13:52:05 GMT"}], "update_date": "2012-02-09", "authors_parsed": [["Hinne", "M.", ""], ["Heskes", "T.", ""], ["van Gerven", "M. A. J.", ""]]}, {"id": "1202.2034", "submitter": "David Holcman", "authors": "David Holcman", "title": "The Complexity of Synaptic Transmission Revealed by a Multiscale\n  Analysis Approach From The Molecular to The Cellular Level", "comments": "This Correspondence contains remarks and comments and corrections on\n  a recent review on synaptic transmission and modeling", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synaptic Transmission is a multiscale process, revealed by various\napproaches, going from the molecular to the cellular level. This correspondence\npoints out to our recent contributions in this field. We now provide the\nphysical and mathematical foundation, leading to the rational quantification of\nthe analysis of the stochastic steps, underlying synaptic transmission.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 16:18:13 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Holcman", "David", ""]]}, {"id": "1202.2148", "submitter": "Hermann Riecke", "authors": "Siu-Fai Chow, Stuart D. Wick, Hermann Riecke", "title": "Neurogenesis Drives Stimulus Decorrelation in a Model of the Olfactory\n  Bulb", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1002398", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reshaping and decorrelation of similar activity patterns by neuronal\nnetworks can enhance their discriminability, storage, and retrieval. How can\nsuch networks learn to decorrelate new complex patterns, as they arise in the\nolfactory system? Using a computational network model for the dominant neural\npopulations of the olfactory bulb we show that fundamental aspects of the adult\nneurogenesis observed in the olfactory bulb -- the persistent addition of new\ninhibitory granule cells to the network, their activity-dependent survival, and\nthe reciprocal character of their synapses with the principal mitral cells --\nare sufficient to restructure the network and to alter its encoding of odor\nstimuli adaptively so as to reduce the correlations between the bulbar\nrepresentations of similar stimuli. The decorrelation is quite robust with\nrespect to various types of perturbations of the reciprocity. The model\nparsimoniously captures the experimentally observed role of neurogenesis in\nperceptual learning and the enhanced response of young granule cells to novel\nstimuli. Moreover, it makes specific predictions for the type of odor\nenrichment that should be effective in enhancing the ability of animals to\ndiscriminate similar odor mixtures.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2012 23:03:57 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Chow", "Siu-Fai", ""], ["Wick", "Stuart D.", ""], ["Riecke", "Hermann", ""]]}, {"id": "1202.2249", "submitter": "Ioana Sporea", "authors": "Ioana Sporea and Andr\\'e Gr\\\"uning", "title": "Supervised Learning in Multilayer Spiking Neural Networks", "comments": "38 pages, 4 figures", "journal-ref": "Neural Compuation February 2013, Vol. 25, No. 2, Pages 473-509", "doi": "10.1162/NECO_a_00396", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current article introduces a supervised learning algorithm for multilayer\nspiking neural networks. The algorithm presented here overcomes some\nlimitations of existing learning algorithms as it can be applied to neurons\nfiring multiple spikes and it can in principle be applied to any linearisable\nneuron model. The algorithm is applied successfully to various benchmarks, such\nas the XOR problem and the Iris data set, as well as complex classifications\nproblems. The simulations also show the flexibility of this supervised learning\nalgorithm which permits different encodings of the spike timing patterns,\nincluding precise spike trains encoding.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2012 12:57:34 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Sporea", "Ioana", ""], ["Gr\u00fcning", "Andr\u00e9", ""]]}, {"id": "1202.2491", "submitter": "Henry Tuckwell", "authors": "Henry C. Tuckwell, J\\\"urgen Jost", "title": "Analysis of inverse stochastic resonance and the long-term firing of\n  Hodgkin-Huxley neurons with Gaussian white noise", "comments": "27 pages, 16 figures", "journal-ref": null, "doi": "10.1016/j.physa.2012.06.019", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous articles we have investigated the firing properties of the\nstandard Hodgkin-Huxley (HH) systems of ordinary and partial differential\nequations in response to input currents composed of a drift (mean) and additive\nGaussian white noise. For certain values of the mean current, as the noise\namplitude increased from zero, the firing rate exhibited a minimum and this\nphenomenon was called inverse stochastic resonance (ISR). Here we analyse the\nunderlying transitions from a stable equilibrium point to the limit cycle and\nvice-versa. Focusing on the case of a mean input current density $\\mu=6.8$ at\nwhich repetitive firing occurs and ISR had been found to be pronounced, some of\nthe properties of the corresponding stable equilibrium point are found. A\nlinearized approximation around this point has oscillatory solutions from whose\nmaxima spikes tend to occur. A one dimensional diffusion is also constructed\nfor small noise based on the correlations between the pairs of HH variables and\nthe small magnitudes of the fluctuations in two of them.\n  Properties of the basin of attraction of the limit cycle (spike) are\ninvestigated heuristically and also the nature of distribution of spikes at\nvery small noise corresponding to trajectories which do not ever enter the\nbasin of attraction of the equilibrium point. Long term trials of duration\n500000 ms are carried out for values of the noise parameter $\\sigma$ from 0 to\n2.0, with results appearing in Section 3. The graph of mean spike count versus\n$\\sigma$ is divided into 4 regions $R_1,...,R_4,$ where $R_3$ contains the\nminimum associated with ISR.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2012 06:22:12 GMT"}], "update_date": "2015-06-04", "authors_parsed": [["Tuckwell", "Henry C.", ""], ["Jost", "J\u00fcrgen", ""]]}, {"id": "1202.3087", "submitter": "Alexander Rothkegel", "authors": "Alexander Rothkegel and Klaus Lehnertz", "title": "Multistability, local pattern formation, and global collective firing in\n  a small-world network of non-leaky integrate-and-fire neurons", "comments": null, "journal-ref": "Chaos 19, 015109 (2009)", "doi": "10.1063/1.3087432", "report-no": null, "categories": "physics.comp-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate numerically the collective dynamical behavior of pulse-coupled\nnon-leaky integrate-and-fire-neurons that are arranged on a two-dimensional\nsmall-world network. To ensure ongoing activity, we impose a probability for\nspontaneous firing for each neuron. We study network dynamics evolving from\ndifferent sets of initial conditions in dependence on coupling strength and\nrewiring probability. Beside a homogeneous equilibrium state for low coupling\nstrength, we observe different local patterns including cyclic waves, spiral\nwaves, and turbulent-like patterns, which -- depending on network parameters --\ninterfere with the global collective firing of the neurons. We attribute the\nvarious network dynamics to distinct regimes in the parameter space. For the\nsame network parameters different network dynamics can be observed depending on\nthe set of initial conditions only. Such a multistable behavior and the\ninterplay between local pattern formation and global collective firing may be\nattributable to the spatiotemporal dynamics of biological networks.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2012 17:01:20 GMT"}], "update_date": "2012-02-15", "authors_parsed": [["Rothkegel", "Alexander", ""], ["Lehnertz", "Klaus", ""]]}, {"id": "1202.3539", "submitter": "Matjaz Perc", "authors": "Qingyun Wang, Honghui Zhang, Matjaz Perc, Guanrong Chen", "title": "Multiple firing coherence resonances in excitatory and inhibitory\n  coupled neurons", "comments": "7 two-column pages, 6 figures; accepted for publication in\n  Communications in Nonlinear Science and Numerical Simulation", "journal-ref": "Commun. Nonlinear Sci. Numer. Simulat. 17 (2012) 3979-3988", "doi": "10.1016/j.cnsns.2012.02.019", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.PS physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impact of inhibitory and excitatory synapses in delay-coupled\nHodgkin--Huxley neurons that are driven by noise is studied. If both synaptic\ntypes are used for coupling, appropriately tuned delays in the inhibition\nfeedback induce multiple firing coherence resonances at sufficiently strong\ncoupling strengths, thus giving rise to tongues of coherency in the\ncorresponding delay-strength parameter plane. If only inhibitory synapses are\nused, however, appropriately tuned delays also give rise to multiresonant\nresponses, yet the successive delays warranting an optimal coherence of\nexcitations obey different relations with regards to the inherent time scales\nof neuronal dynamics. This leads to denser coherence resonance patterns in the\ndelay-strength parameter plane. The robustness of these findings to the\nintroduction of delay in the excitatory feedback, to noise, and to the number\nof coupled neurons is determined. Mechanisms underlying our observations are\nrevealed, and it is suggested that the regularity of spiking across neuronal\nnetworks can be optimized in an unexpectedly rich variety of ways, depending on\nthe type of coupling and the duration of delays.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2012 09:23:15 GMT"}], "update_date": "2012-05-01", "authors_parsed": [["Wang", "Qingyun", ""], ["Zhang", "Honghui", ""], ["Perc", "Matjaz", ""], ["Chen", "Guanrong", ""]]}, {"id": "1202.4174", "submitter": "Ahmed Mahran", "authors": "Ahmed M. Mahran", "title": "Perception Lie Paradox: Mathematically Proved Uncertainty about Humans\n  Perception Similarity", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents' judgment depends on perception and previous knowledge. Assuming that\nprevious knowledge depends on perception, we can say that judgment depends on\nperception. So, if judgment depends on perception, can agents judge that they\nhave the same perception? In few words, this is the addressed paradox through\nthis document. While illustrating on the paradox, it's found that to reach\nagreement in communication, it's not necessary for parties to have the same\nperception however the necessity is to have perception correspondence. The\nattempted solution to this paradox reveals a potential uncertainty in judging\nthe matter thus supporting the skeptical view of the problem. Moreover,\nrelating perception to intelligence, the same uncertainty is inherited by\njudging the level of intelligence of an agent compared to others not\nnecessarily from the same kind (e.g. machine intelligence compared to human\nintelligence). Using a proposed simple mathematical model for perception and\naction, a tool is developed to construct scenarios, and the problem is\naddressed mathematically such that conclusions are drawn systematically based\non mathematically defined properties. When it comes to formalization,\nphilosophical arguments and views become more visible and explicit.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2012 18:12:28 GMT"}], "update_date": "2012-02-21", "authors_parsed": [["Mahran", "Ahmed M.", ""]]}, {"id": "1202.4482", "submitter": "David Balduzzi", "authors": "David Balduzzi, Pedro A Ortega, Michel Besserve", "title": "Metabolic cost as an organizing principle for cooperative learning", "comments": "14 pages, 2 figures, to appear in Advances in Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates how neurons can use metabolic cost to facilitate\nlearning at a population level. Although decision-making by individual neurons\nhas been extensively studied, questions regarding how neurons should behave to\ncooperate effectively remain largely unaddressed. Under assumptions that\ncapture a few basic features of cortical neurons, we show that constraining\nreward maximization by metabolic cost aligns the information content of actions\nwith their expected reward. Thus, metabolic cost provides a mechanism whereby\nneurons encode expected reward into their outputs. Further, aside from reducing\nenergy expenditures, imposing a tight metabolic constraint also increases the\naccuracy of empirical estimates of rewards, increasing the robustness of\ndistributed learning. Finally, we present two implementations of metabolically\nconstrained learning that confirm our theoretical finding. These results\nsuggest that metabolic cost may be an organizing principle underlying the\nneural code, and may also provide a useful guide to the design and analysis of\nother cooperating populations.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2012 22:02:16 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2013 21:34:51 GMT"}], "update_date": "2013-02-12", "authors_parsed": [["Balduzzi", "David", ""], ["Ortega", "Pedro A", ""], ["Besserve", "Michel", ""]]}, {"id": "1202.4578", "submitter": "Anastasia Lavrova", "authors": "Anastasia I. Lavrova, Michael A. Zaks, Lutz Schimansky-Geier", "title": "Modeling rhythmic patterns in the hippocampus", "comments": "10 pages, 9 figures", "journal-ref": "Phys. Rev. E (2012) 85, 041922", "doi": "10.1103/PhysRevE.85.041922", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate different dynamical regimes of neuronal network in the CA3\narea of the hippocampus. The proposed neuronal circuit includes two fast- and\ntwo slowly-spiking cells which are interconnected by means of dynamical\nsynapses. On the individual level, each neuron is modeled by FitzHugh-Nagumo\nequations. Three basic rhythmic patterns are observed: gamma-rhythm in which\nthe fast neurons are uniformly spiking, theta-rhythm in which the individual\nspikes are separated by quiet epochs, and theta/gamma rhythm with repeated\npatches of spikes. We analyze the influence of asymmetry of synaptic strengths\non the synchronization in the network and demonstrate that strong asymmetry\nreduces the variety of available dynamical states. The model network exhibits\nmultistability; this results in occurrence of hysteresis in dependence on the\nconductances of individual connections. We show that switching between\ndifferent rhythmic patterns in the network depends on the degree of\nsynchronization between the slow cells.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2012 09:52:48 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Lavrova", "Anastasia I.", ""], ["Zaks", "Michael A.", ""], ["Schimansky-Geier", "Lutz", ""]]}, {"id": "1202.4751", "submitter": "Wonsang You", "authors": "Wonsang You, Joerg Stadler", "title": "Fractal-based Correlation Analysis for Resting State Functional\n  Connectivity of the Rat Brain in Functional MRI", "comments": "CBBS Educational Workshop on Resting State fMRI 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most studies on functional connectivity have been done by analyzing the\nbrain's hemodynamic response to a stimulation. On the other hand, the\nlow-frequency spontaneous fluctuations in the blood oxygen level dependent\n(BOLD) signals of functional MRI have been observed in the resting state.\nHowever, the BOLD signals in resting state are significantly corrupted by huge\nnoises arising from cardiac pulsation, respiration, subject motion, scanner,\nand so forth. Especially, the noise compounds are stronger in the rat brain\nthan in the human brain. To overcome such an artifact, we assumed that fractal\nbehavior in BOLD signals reflects low frequency neural activity, and applied\nthe theorem such that the wavelet correlation spectrum between long memory\nprocesses is scale-invariant over low frequency scales. Here, we report an\nexperiment that shows special correlation patterns not only in correlation of\nscaling coefficients in very low-frequency band (less than 0.0078Hz) but also\nin asymptotic wavelet correlation. In addition, we show the distribution of the\nHurst exponents in the rat brain.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2012 20:55:07 GMT"}], "update_date": "2012-02-22", "authors_parsed": [["You", "Wonsang", ""], ["Stadler", "Joerg", ""]]}, {"id": "1202.5041", "submitter": "Daniele Marinazzo", "authors": "Daniele Marinazzo, Mario Pellicoro, Guorong Wu, Leonardo Angelini,\n  Sebastiano Stramaglia", "title": "Information flow in a network model and the law of diminishing marginal\n  returns", "comments": "5 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.SI physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a simple dynamical network model which describes the limited\ncapacity of nodes to process the input information. For a suitable choice of\nthe parameters, the information flow pattern is characterized by exponential\ndistribution of the incoming information and a fat-tailed distribution of the\noutgoing information, as a signature of the law of diminishing marginal\nreturns. The analysis of a real EEG data-set shows that similar phenomena may\nbe relevant for brain signals.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2012 21:02:10 GMT"}, {"version": "v2", "created": "Wed, 18 Apr 2012 10:01:42 GMT"}], "update_date": "2012-04-19", "authors_parsed": [["Marinazzo", "Daniele", ""], ["Pellicoro", "Mario", ""], ["Wu", "Guorong", ""], ["Angelini", "Leonardo", ""], ["Stramaglia", "Sebastiano", ""]]}, {"id": "1202.5080", "submitter": "Anatoly Zlotnik", "authors": "Anatoly Zlotnik and Jr-Shin Li", "title": "Optimal Entrainment of Neural Oscillator Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive the minimum-energy periodic control that entrains an\nensemble of structurally similar neural oscillators to a desired frequency. The\nstate space representation of a nominal oscillator is reduced to a phase model\nby computing its limit cycle and phase response curve, from which the optimal\ncontrol is derived by using formal averaging and the calculus of variations. We\nfocus on the case of a 1:1 entrainment ratio, and introduce a numerical method\nfor approximating the optimal controls. The method is applied to asymptotically\ncontrol the spiking frequency of neural oscillators modeled using the\nHodgkin-Huxley equations. This illustrates the optimality of entrainment\ncontrols derived using phase models when applied to the original state space\nsystem, which is a crucial requirement for using phase models in control\nsynthesis for practical applications. The results of this work can be used to\ndesign low energy signals for deep brain stimulation therapies for\nneuropathologies, and can be generalized for optimal frequency control of\nlarge-scale complex oscillating systems with parameter uncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 03:02:49 GMT"}], "update_date": "2012-02-24", "authors_parsed": [["Zlotnik", "Anatoly", ""], ["Li", "Jr-Shin", ""]]}, {"id": "1202.5434", "submitter": "Geraldo A. Barbosa", "authors": "Geraldo A. Barbosa", "title": "Can humans see beyond intensity images?", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human's visual system detect intensity images. Quite interesting,\ndetector systems have shown the existence of different kind of images. Among\nthem, images obtained by two detectors (detector array or spatially scanning\ndetector) capturing signals within short window times may reveal a \"hidden\"\nimage not contained in either isolated detector: Information on this image\ndepend on the two detectors simultaneously. In general, they are called\n\"high-order\" images because they may depend on more than two electric fields.\nIntensity images depend on the square of magnitude of the light's electric\nfield. Can the human visual sensory system perceive high-order images as well?\nThis paper proposes a way to test this idea. A positive answer could give new\ninsights on the \"visual-conscience\" machinery, opening a new sensory channel\nfor humans. Applications could be devised, e.g., head position sensing, privacy\nin communications at visual ranges and many others.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2012 12:38:09 GMT"}], "update_date": "2012-02-27", "authors_parsed": [["Barbosa", "Geraldo A.", ""]]}, {"id": "1202.5783", "submitter": "Monica De Angelis", "authors": "M. De Angelis, P. Renno", "title": "On the Fitzhugh-Nagumo model", "comments": null, "journal-ref": "Proceedings WASCOM 2007 XIV International Conference on Waves and\n  Stability in Continuous Media World Scientific Publishing Company 2008,\n  193-198", "doi": null, "report-no": null, "categories": "q-bio.NC math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The initial value problem P0, in all of the space, for the spatio - temporal\nFitzHugh - Nagumo equations is analyzed. When the reaction kinetics of the\nmodel can be outlined by means of piecewise linear approximations, then the\nsolution of P0 is explicitly obtained. For periodic initial data are possible\ndamped travelling waves and their speed of propagation is evaluated. The\nresults imply applications also to the non linear case.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2012 17:28:02 GMT"}], "update_date": "2012-02-28", "authors_parsed": [["De Angelis", "M.", ""], ["Renno", "P.", ""]]}, {"id": "1202.6388", "submitter": "Jose Fontanari", "authors": "Jose F. Fontanari, Marie-Claude Bonniot-Cabanac, Michel Cabanac and\n  Leonid I. Perlovsky", "title": "A structural model of emotions of cognitive dissonances", "comments": null, "journal-ref": "Neural Networks 32 (2012) 57-64", "doi": "10.1016/j.neunet.2012.04.007", "report-no": null, "categories": "q-bio.NC cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive dissonance is the stress that comes from holding two conflicting\nthoughts simultaneously in the mind, usually arising when people are asked to\nchoose between two detrimental or two beneficial options. In view of the\nwell-established role of emotions in decision making, here we investigate\nwhether the conventional structural models used to represent the relationships\namong basic emotions, such as the Circumplex model of affect, can describe the\nemotions of cognitive dissonance as well. We presented a questionnaire to 34\nanonymous participants, where each question described a decision to be made\namong two conflicting motivations and asked the participants to rate\nanalogically the pleasantness and the intensity of the experienced emotion. We\nfound that the results were compatible with the predictions of the Circumplex\nmodel for basic emotions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2012 21:44:22 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Fontanari", "Jose F.", ""], ["Bonniot-Cabanac", "Marie-Claude", ""], ["Cabanac", "Michel", ""], ["Perlovsky", "Leonid I.", ""]]}, {"id": "1202.6670", "submitter": "Yashar Ahmadian", "authors": "Yashar Ahmadian, Daniel B. Rubin and Kenneth D. Miller", "title": "Analysis of the stabilized supralinear network", "comments": "45 pages, 4 figures", "journal-ref": "Neural Computation 25, 1994-2037 (2013)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a rate-model neural network composed of excitatory and inhibitory\nneurons in which neuronal input-output functions are power laws with a power\ngreater than 1, as observed in primary visual cortex. This supralinear\ninput-output function leads to supralinear summation of network responses to\nmultiple inputs for weak inputs. We show that for stronger inputs, which would\ndrive the excitatory subnetwork to instability, the network will dynamically\nstabilize provided feedback inhibition is sufficiently strong. For a wide range\nof network and stimulus parameters, this dynamic stabilization yields a\ntransition from supralinear to sublinear summation of network responses to\nmultiple inputs. We compare this to the dynamic stabilization in the \"balanced\nnetwork\", which yields only linear behavior. We more exhaustively analyze the\n2-dimensional case of 1 excitatory and 1 inhibitory population. We show that in\nthis case dynamic stabilization will occur whenever the determinant of the\nweight matrix is positive and the inhibitory time constant is sufficiently\nsmall, and analyze the conditions for \"supersaturation\", or decrease of firing\nrates with increasing stimulus contrast (which represents increasing input\nfiring rates). In work to be presented elsewhere, we have found that this\ntransition from supralinear to sublinear summation can explain a wide variety\nof nonlinearities in cerebral cortical processing.\n", "versions": [{"version": "v1", "created": "Wed, 29 Feb 2012 20:14:17 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2012 23:13:47 GMT"}, {"version": "v3", "created": "Thu, 6 Dec 2012 22:23:31 GMT"}, {"version": "v4", "created": "Sun, 5 May 2013 19:02:44 GMT"}, {"version": "v5", "created": "Tue, 28 May 2013 22:27:52 GMT"}, {"version": "v6", "created": "Mon, 1 Jul 2013 20:48:29 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Ahmadian", "Yashar", ""], ["Rubin", "Daniel B.", ""], ["Miller", "Kenneth D.", ""]]}]