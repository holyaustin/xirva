[{"id": "1907.00070", "submitter": "Rostislav Serota", "authors": "M. Dashti Moghaddam, Jiong Liu, John G. Holden and R. A. Serota", "title": "Modeling Response Time Distributions with Generalized Beta Prime", "comments": "15 pages, 11 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use Generalized Beta Prime distribution, also known as GB2, for fitting\nresponse time distributions. This distribution, characterized by one scale and\nthree shape parameters, is incredibly flexible in that it can mimic behavior of\nmany other distributions. GB2 exhibits power-law behavior at both front and\ntail ends and is a steady-state distribution of a simple stochastic\ndifferential equation. We apply GB2 in contrast studies between two distinct\ngroups -- in this case children with dyslexia and a control group -- and show\nthat it provides superior fitting. We compare aggregate response time\ndistributions of the two groups for scale and shape differences (including\nseveral scale-independent measures of variability, such as Hoover index), which\nmay in turn reflect on cognitive dynamics differences. In this approach,\nresponse time distribution of an individual can be considered as a random\nvariate of that individual's group distribution.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 20:46:21 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Moghaddam", "M. Dashti", ""], ["Liu", "Jiong", ""], ["Holden", "John G.", ""], ["Serota", "R. A.", ""]]}, {"id": "1907.00230", "submitter": "Alessandro Torcini Dr", "authors": "Hongjie Bi, Marco Segneri, Matteo di Volo, Alessandro Torcini", "title": "Coexistence of fast and slow gamma oscillations in one population of\n  inhibitory spiking neurons", "comments": "20 pages, 14 figures", "journal-ref": "Phys. Rev. Research 2, 013042 (2020)", "doi": "10.1103/PhysRevResearch.2.013042", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oscillations are a hallmark of neural population activity in various brain\nregions with a spectrum covering a wide range of frequencies. Within this\nspectrum gamma oscillations have received particular attention due to their\nubiquitous nature and to their correlation with higher brain functions.\nRecently, it has been reported that gamma oscillations in the hippocampus of\nbehaving rodents are segregated in two distinct frequency bands: slow and fast.\nThese two gamma rhythms correspond to dfferent states of the network, but their\norigin has been not yet clarified. Here, we show theoretically and numerically\nthat a single inhibitory population can give rise to coexisting slow and fast\ngamma rhythms corresponding to collective oscillations of a balanced spiking\nnetwork. The slow and fast gamma rhythms are generated via two different\nmechanisms: the fast one being driven by the coordinated tonic neural firing\nand the slow one by endogenous fluctuations due to irregular neural activity.\nWe show that almost instantaneous stimulations can switch the collective gamma\noscillations from slow to fast and vice versa. Furthermore, to make a closer\ncontact with the experimental observations, we consider the modulation of the\ngamma rhythms induced by a slower (theta) rhythm driving the network dynamics.\nIn this context, depending on the strength of the forcing, we observe\nphase-amplitude and phase-phase coupling between the fast and slow gamma\noscillations and the theta forcing. Phase-phase coupling reveals different\ntheta-phases preferences for the two coexisting gamma rhythms.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 16:09:48 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Bi", "Hongjie", ""], ["Segneri", "Marco", ""], ["di Volo", "Matteo", ""], ["Torcini", "Alessandro", ""]]}, {"id": "1907.00263", "submitter": "Emily Toomey", "authors": "Emily Toomey, Ken Segall, and Karl K. Berggren", "title": "A Power Efficient Artificial Neuron Using Superconducting Nanowires", "comments": "12 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.supr-con cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rising societal demand for more information-processing capacity with\nlower power consumption, alternative architectures inspired by the parallelism\nand robustness of the human brain have recently emerged as possible solutions.\nIn particular, spiking neural networks (SNNs) offer a bio-realistic approach,\nrelying on pulses analogous to action potentials as units of information. While\nsoftware encoded networks provide flexibility and precision, they are often\ncomputationally expensive. As a result, hardware SNNs based on the spiking\ndynamics of a device or circuit represent an increasingly appealing direction.\nHere, we propose to use superconducting nanowires as a platform for the\ndevelopment of an artificial neuron. Building on an architecture first proposed\nfor Josephson junctions, we rely on the intrinsic nonlinearity of two coupled\nnanowires to generate spiking behavior, and use electrothermal circuit\nsimulations to demonstrate that the nanowire neuron reproduces multiple\ncharacteristics of biological neurons. Furthermore, by harnessing the\nnonlinearity of the superconducting nanowire's inductance, we develop a design\nfor a variable inductive synapse capable of both excitatory and inhibitory\ncontrol. We demonstrate that this synapse design supports direct fanout, a\nfeature that has been difficult to achieve in other superconducting\narchitectures, and that the nanowire neuron's nominal energy performance is\ncompetitive with that of current technologies.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 19:28:25 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Toomey", "Emily", ""], ["Segall", "Ken", ""], ["Berggren", "Karl K.", ""]]}, {"id": "1907.00441", "submitter": "Marcio Fonseca", "authors": "Marcio Fonseca", "title": "Unsupervised predictive coding models may explain visual brain\n  representation", "comments": "4 pages, 1 figure, Algonauts Challenge", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep predictive coding networks are neuroscience-inspired unsupervised\nlearning models that learn to predict future sensory states. We build upon the\nPredNet implementation by Lotter, Kreiman, and Cox (2016) to investigate if\npredictive coding representations are useful to predict brain activity in the\nvisual cortex. We use representational similarity analysis (RSA) to compare\nPredNet representations to functional magnetic resonance imaging (fMRI) and\nmagnetoencephalography (MEG) data from the Algonauts Project. In contrast to\nprevious findings in the literature (Khaligh-Razavi &Kriegeskorte, 2014), we\nreport empirical data suggesting that unsupervised models trained to predict\nframes of videos may outperform supervised image classification baselines. Our\nbest submission achieves an average noise normalized score of 16.67% and 27.67%\non the fMRI and MEG tracks of the Algonauts Challenge.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 19:53:32 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Fonseca", "Marcio", ""]]}, {"id": "1907.00650", "submitter": "Qi She", "authors": "Qi She, Anqi Wu", "title": "Neural Dynamics Discovery via Gaussian Process Recurrent Neural Networks", "comments": "11 pages, 3 figures, 7 Tables, accepted to The Conference on\n  Uncertainty in Artificial Intelligence (UAI), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent dynamics discovery is challenging in extracting complex dynamics from\nhigh-dimensional noisy neural data. Many dimensionality reduction methods have\nbeen widely adopted to extract low-dimensional, smooth and time-evolving latent\ntrajectories. However, simple state transition structures, linear embedding\nassumptions, or inflexible inference networks impede the accurate recovery of\ndynamic portraits. In this paper, we propose a novel latent dynamic model that\nis capable of capturing nonlinear, non-Markovian, long short-term\ntime-dependent dynamics via recurrent neural networks and tackling complex\nnonlinear embedding via non-parametric Gaussian process. Due to the complexity\nand intractability of the model and its inference, we also provide a powerful\ninference network with bi-directional long short-term memory networks that\nencode both past and future information into posterior distributions. In the\nexperiment, we show that our model outperforms other state-of-the-art methods\nin reconstructing insightful latent dynamics from both simulated and\nexperimental neural datasets with either Gaussian or Poisson observations,\nespecially in the low-sample scenario. Our codes and additional materials are\navailable at https://github.com/sheqi/GP-RNN_UAI2019.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 10:51:38 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["She", "Qi", ""], ["Wu", "Anqi", ""]]}, {"id": "1907.00689", "submitter": "Soaad Hossain Mr", "authors": "Soaad Hossain", "title": "Application and Computation of Probabilistic Neural Plasticity", "comments": "10 pages, submitted to Frontiers in Human Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CE cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The discovery of neural plasticity has proved that throughout the life of a\nhuman being, the brain reorganizes itself through forming new neural\nconnections. The formation of new neural connections are achieved through the\nbrain's effort to adapt to new environments or to changes in the existing\nenvironment. Despite the realization of neural plasticity, there is a lack of\nunderstanding the probability of neural plasticity occurring given some event.\nUsing ordinary differential equations, neural firing equations and spike-train\nstatistics, we show how an additive short-term memory (STM) equation can be\nformulated to approach the computation of neural plasticity. We then show how\nthe additive STM equation can be used for probabilistic inference in computable\nneural plasticity, and the computation of probabilistic neural plasticity. We\nwill also provide a brief introduction to the theory of probabilistic neural\nplasticity and conclude with showing how it can be applied to multiple\ndisciplines such as behavioural science, machine learning, artificial\nintelligence and psychiatry.\n", "versions": [{"version": "v1", "created": "Sat, 25 May 2019 07:03:56 GMT"}, {"version": "v2", "created": "Fri, 7 Aug 2020 01:23:53 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Hossain", "Soaad", ""]]}, {"id": "1907.00694", "submitter": "Danko Nikolic", "authors": "Madeline E. Klinger, Christian A. Kell, Danko Nikolic", "title": "Quickly fading afterimages: hierarchical adaptations in human perception", "comments": "3 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Afterimages result from a prolonged exposure to still visual stimuli. They\nare best detectable when viewed against uniform backgrounds and can persist for\nmultiple seconds. Consequently, the dynamics of afterimages appears to be slow\nby their very nature. To the contrary, we report here that about 50% of an\nafterimage intensity can be erased rapidly--within less than a second. The\nprerequisite is that subjects view a rich visual content to erase the\nafterimage; fast erasure of afterimages does not occur if subjects view a blank\nscreen. Moreover, we find evidence that fast removal of afterimages is a skill\nlearned with practice as our subjects were always more effective in cleaning up\nafterimages in later parts of the experiment. These results can be explained by\na tri-level hierarchy of adaptive mechanisms, as has been proposed by the\ntheory of practopoiesis.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jun 2019 06:22:18 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Klinger", "Madeline E.", ""], ["Kell", "Christian A.", ""], ["Nikolic", "Danko", ""]]}, {"id": "1907.00703", "submitter": "Benjamin Bleier", "authors": "B.S. Bleier", "title": "Information Flow Theory (IFT) of Biologic and Machine Consciousness:\n  Implications for Artificial General Intelligence and the Technological\n  Singularity", "comments": "23 Pages, 2 Figures, 1 Table, 1 Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.ET cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subjective experience of consciousness is at once familiar and yet deeply\nmysterious. Strategies exploring the top-down mechanisms of conscious thought\nwithin the human brain have been unable to produce a generalized explanatory\ntheory that scales through evolution and can be applied to artificial systems.\nInformation Flow Theory (IFT) provides a novel framework for understanding both\nthe development and nature of consciousness in any system capable of processing\ninformation. In prioritizing the direction of information flow over information\ncomputation, IFT produces a range of unexpected predictions. The purpose of\nthis manuscript is to introduce the basic concepts of IFT and explore the\nmanifold implications regarding artificial intelligence, superhuman\nconsciousness, and our basic perception of reality.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 15:01:25 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bleier", "B. S.", ""]]}, {"id": "1907.00709", "submitter": "Guido Schillaci", "authors": "Yasmin Kim Georgie, Guido Schillaci, Verena Vanessa Hafner", "title": "An interdisciplinary overview of developmental indices and behavioral\n  measures of the minimal self", "comments": "Accepted for presentation at the 9th IEEE Joint International\n  Conference on Development and Learning and Epigenetic Robotics (IEEE\n  ICDL-EpiRob), August 2019, Oslo, Norway. To appear in the conference\n  proceedings. https://icdl-epirob2019.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this review paper we discuss the development of the minimal self in\nhumans, the behavioural measures indicating the presence of different aspects\nof the minimal self, namely, body ownership and sense of agency, and also\ndiscuss robotics research investigating and developing these concepts in\nartificial agents. We investigate possible avenues for expanding the research\nin robotics to further explore the development of an artificial minimal self.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 13:33:08 GMT"}, {"version": "v2", "created": "Tue, 2 Jul 2019 08:56:51 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Georgie", "Yasmin Kim", ""], ["Schillaci", "Guido", ""], ["Hafner", "Verena Vanessa", ""]]}, {"id": "1907.00816", "submitter": "David Hansel", "authors": "Alexandre Mahrach, Guang Chen, Nuo Li, Carl van Vreeswijk, David\n  Hansel", "title": "Mechanisms underlying the response of mouse cortical networks to\n  optogenetic manipulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GABAergic interneurons can be subdivided into three subclasses: parvalbumin\npositive (PV), somatostatin positive (SOM) and serotonin positive neurons. With\nprincipal cells (PCs) they form complex networks. We examine PCs and PV\nresponses in mouse anterior lateral motor cortex (ALM) and barrel cortex (S1)\nupon PV photostimulation in vivo. In layer 5, the PV response is paradoxical:\nphotoexcitation reduces their activity. This is not the case in ALM layer 2/3.\nWe combine analytical calculations and numerical simulations to investigate how\nthese results constrain the architecture. Two-population models cannot account\nfor the results. Networks with three inhibitory populations and V1-like\narchitecture account for the data in ALM layer 2/3. Our data in layer 5 can be\naccounted for if SOM neurons receive inputs only from PCs and PV neurons. In\nboth four-population models, the paradoxical effect implies not too strong\nrecurrent excitation. It is not evidence for stabilization by inhibition.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 14:22:03 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Mahrach", "Alexandre", ""], ["Chen", "Guang", ""], ["Li", "Nuo", ""], ["van Vreeswijk", "Carl", ""], ["Hansel", "David", ""]]}, {"id": "1907.00950", "submitter": "Romuald A. Janik", "authors": "Romuald A. Janik", "title": "Explaining the Human Visual Brain Challenge 2019 -- receptive fields and\n  surrogate features", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper I review the submission to the Explaining the Human Visual\nBrain Challenge 2019 in both the fMRI and MEG tracks. The goal was to construct\nneural network features which generate the so-called representational\ndissimilarity matrix (RDM) which is most similar to the one extracted from fMRI\nand MEG data upon viewing a set of images. I review exploring the optimal\ngranularity of the receptive field, a construction of intermediate surrogate\nfeatures using Multidimensional Scaling and modelling them using neural network\nfeatures. I also point out some peculiarities of the RDM construction which\nhave to be taken into account.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:39:48 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Janik", "Romuald A.", ""]]}, {"id": "1907.01034", "submitter": "Guy Gaziv", "authors": "Guy Gaziv", "title": "Learning to aggregate feature representations", "comments": "Report for Algonauts2019 challenge. 4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Algonauts challenge requires to construct a multi-subject encoder of\nimages to brain activity. Deep networks such as ResNet-50 and AlexNet trained\nfor image classification are known to produce feature representations along\ntheir intermediate stages which closely mimic the visual hierarchy. However the\nchallenges introduced in the Algonauts project, including combining data from\nmultiple subjects, relying on very few similarity data points, solving for\nvarious ROIs, and multi-modality, require devising a flexible framework which\ncan efficiently accommodate them. Here we build upon a recent state-of-the-art\nclassification network (SE-ResNeXt-50) and construct an adaptive combination of\nits intermediate representations. While the pretrained network serves as a\nbackbone of our model, we learn how to aggregate feature representations along\nfive stages of the network. During learning, our method enables to modulate and\nscreen outputs from each stage along the network as governed by the optimized\nobjective. We applied our method to the Algonauts2019 fMRI and MEG challenges.\nUsing the combined fMRI and MEG data, our approach was rated among the leading\nfive for both challenges. Surprisingly we find that for both the lower and\nhigher order areas (EVC and IT) the adaptive aggregation favors features\nstemming at later stages of the network.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 19:35:17 GMT"}, {"version": "v2", "created": "Wed, 3 Jul 2019 08:32:41 GMT"}, {"version": "v3", "created": "Thu, 4 Jul 2019 06:34:12 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Gaziv", "Guy", ""]]}, {"id": "1907.01062", "submitter": "Gustavo Borges Moreno E Mello", "authors": "Gustavo Borges Moreno e Mello, Vibeke Devold Valderhaug, Sidney\n  Pontes-Filho, Evi Zouganeli, Ioanna Sandvig and Stefano Nichele", "title": "DeepTEGINN: Deep Learning Based Tools to Extract Graphs from Images of\n  Neural Networks", "comments": "5 pages, 2 figures, ICDL IEEE conference 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the brain, the structure of a network of neurons defines how these neurons\nimplement the computations that underlie the mind and the behavior of animals\nand humans. Provided that we can describe the network of neurons as a graph, we\ncan employ methods from graph theory to investigate its structure or use\ncellular automata to mathematically assess its function. Although, software for\nthe analysis of graphs and cellular automata are widely available. Graph\nextraction from the image of networks of brain cells remains difficult. Nervous\ntissue is heterogeneous, and differences in anatomy may reflect relevant\ndifferences in function. Here we introduce a deep learning based toolbox to\nextracts graphs from images of brain tissue. This toolbox provides an\neasy-to-use framework allowing system neuroscientists to generate graphs based\non images of brain tissue by combining methods from image processing, deep\nlearning, and graph theory. The goals are to simplify the training and usage of\ndeep learning methods for computer vision and facilitate its integration into\ngraph extraction pipelines. In this way, the toolbox provides an alternative to\nthe required laborious manual process of tracing, sorting and classifying. We\nexpect to democratize the machine learning methods to a wider community of\nusers beyond the computer vision experts and improve the time-efficiency of\ngraph extraction from large brain image datasets, which may lead to further\nunderstanding of the human mind.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 20:33:08 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Mello", "Gustavo Borges Moreno e", ""], ["Valderhaug", "Vibeke Devold", ""], ["Pontes-Filho", "Sidney", ""], ["Zouganeli", "Evi", ""], ["Sandvig", "Ioanna", ""], ["Nichele", "Stefano", ""]]}, {"id": "1907.01288", "submitter": "Ahmed ELGazzar", "authors": "Ahmed El Gazzar, Leonardo Cerliani, Guido van Wingen, Rajat Mani\n  Thomas", "title": "Simple 1-D Convolutional Networks for Resting-State fMRI Based\n  Classification in Autism", "comments": "accepted for publication in IJCNN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning methods are increasingly being used with neuroimaging data like\nstructural and function magnetic resonance imaging (MRI) to predict the\ndiagnosis of neuropsychiatric and neurological disorders. For psychiatric\ndisorders in particular, it is believed that one of the most promising modality\nis the resting-state functional MRI (rsfMRI), which captures the intrinsic\nconnectivity between regions in the brain. Because rsfMRI data points are\ninherently high-dimensional (~1M), it is impossible to process the entire input\nin its raw form. In this paper, we propose a very simple transformation of the\nrsfMRI images that captures all of the temporal dynamics of the signal but\nsub-samples its spatial extent. As a result, we use a very simple 1-D\nconvolutional network which is fast to train, requires minimal preprocessing\nand performs at par with the state-of-the-art on the classification of Autism\nspectrum disorders.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 10:35:25 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Gazzar", "Ahmed El", ""], ["Cerliani", "Leonardo", ""], ["van Wingen", "Guido", ""], ["Thomas", "Rajat Mani", ""]]}, {"id": "1907.01355", "submitter": "Hideyoshi Yanagisawa", "authors": "Takahiro Sekoguchi, Yuki Sakai, Hideyoshi Yanagisawa", "title": "Mathematical Model of Emotional Habituation to Novelty: Modeling with\n  Bayesian Update and Information Theory", "comments": "PrePrint submitted to IEEE SMC 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Novelty is an important factor of creativity in product design. Acceptance of\nnovelty, however, depends on one's emotions. Yanagisawa, the last author, and\nhis colleagues previously developed a mathematical model of emotional\ndimensions associated with novelty such as arousal (surprise) and valence. The\nmodel formalized arousal as Bayesian information gain and valence as a function\nof arousal based on Berlyne's arousal potential theory. One becomes accustomed\nto novelty by repeated exposure. This so-called habituation to novelty is\nimportant in the design of long-term product experience. We herein propose a\nmathematical model of habituation to novelty based on the emotional dimension\nmodel. We formalized the habituation as a decrement in information gain from a\nnovel event through Bayesian update. We derived the information gained from the\nrepeated exposure of a novel stimulus as a function of three parameters:\ninitial prediction error, initial uncertainty, and noise of sensory stimulus.\nWith the proposed model, we discovered an interaction effect of the initial\nprediction error and initial uncertainty on habituation. Furthermore, we\ndemonstrate that a range of positive emotions on prediction errors shift toward\nbecoming more novel by repeated exposure.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 13:31:00 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 02:29:08 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Sekoguchi", "Takahiro", ""], ["Sakai", "Yuki", ""], ["Yanagisawa", "Hideyoshi", ""]]}, {"id": "1907.01504", "submitter": "Nikolay Koshev", "authors": "Nikolay Koshev, Nikolay Yavich, Mikhail Malovichko, Ekaterina\n  Skidchenko, Maxim Fedorov", "title": "FEM-based Scalp-to-Cortex data mapping via the solution of the Cauchy\n  problem", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach and the numerical algorithm for pre-processing of the\nelectroencephalography (EEG) data, enabling to generate an accurate mapping of\nthe potential from the measurement area - scalp - to the brain surface. The\nalgorithm based on the solution of ill-posed Cauchy problem for the Laplace's\nequation using tetrahedral finite elements linear approximation. Application of\nthe proposed algorithm sufficiently increases the spatial resolution of the EEG\ntechnique, making it comparable with much more complicated electrocorticography\n(ECoG) method.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 12:47:12 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Koshev", "Nikolay", ""], ["Yavich", "Nikolay", ""], ["Malovichko", "Mikhail", ""], ["Skidchenko", "Ekaterina", ""], ["Fedorov", "Maxim", ""]]}, {"id": "1907.01588", "submitter": "Elahe Arani", "authors": "Elahe Arani, Sofia Triantafillou and Konrad P. Kording", "title": "Reverse engineering neural networks from many partial recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of neuroscience aims at reverse engineering the brain, but we only\nrecord a small number of neurons at a time. We do not currently know if reverse\nengineering the brain requires us to simultaneously record most neurons or if\nmultiple recordings from smaller subsets suffice. This is made even more\nimportant by the development of novel techniques that allow recording from\nselected subsets of neurons, e.g. using optical techniques. To get at this\nquestion, we analyze a neural network, trained on the MNIST dataset, using only\npartial recordings and characterize the dependency of the quality of our\nreverse engineering on the number of simultaneously recorded \"neurons\". We find\nthat reverse engineering of the nonlinear neural network is meaningfully\npossible if a sufficiently large number of neurons is simultaneously recorded\nbut that this number can be considerably smaller than the number of neurons.\nMoreover, recording many times from small random subsets of neurons yields\nsurprisingly good performance. Application in neuroscience suggests to\napproximate the I/O function of an actual neural system, we need to record from\na much larger number of neurons. The kind of scaling analysis we perform here\ncan, and arguably should be used to calibrate approaches that can dramatically\nscale up the size of recorded data sets in neuroscience.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 19:15:30 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Arani", "Elahe", ""], ["Triantafillou", "Sofia", ""], ["Kording", "Konrad P.", ""]]}, {"id": "1907.01620", "submitter": "Konstantinos Michmizos", "authors": "Guangzhi Tang, Ioannis E. Polykretis, Vladimir A. Ivanov, Arpit Shah,\n  Konstantinos P. Michmizos", "title": "Introducing Astrocytes on a Neuromorphic Processor: Synchronization,\n  Local Plasticity and Edge of Chaos", "comments": "9 pages, 7 figures", "journal-ref": "ACM Proceeding NICE '19 Proceedings of the 7th Annual\n  Neuro-inspired Computational Elements Workshop, 2019", "doi": "10.1145/3320288.3320302", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there is still a lot to learn about astrocytes and their\nneuromodulatory role in the spatial and temporal integration of neuronal\nactivity, their introduction to neuromorphic hardware is timely, facilitating\ntheir computational exploration in basic science questions as well as their\nexploitation in real-world applications. Here, we present an astrocytic module\nthat enables the development of a spiking Neuronal-Astrocytic Network (SNAN)\ninto Intel's Loihi neuromorphic chip. The basis of the Loihi module is an\nend-to-end biophysically plausible compartmental model of an astrocyte that\nsimulates the intracellular activity in response to the synaptic activity in\nspace and time. To demonstrate the functional role of astrocytes in SNAN, we\ndescribe how an astrocyte may sense and induce activity-dependent neuronal\nsynchronization, switch on and off spike-time-dependent plasticity (STDP) to\nintroduce single-shot learning, and monitor the transition between ordered and\nchaotic activity at the synaptic space. Our module may serve as an extension\nfor neuromorphic hardware, by either replicating or exploring the distinct\ncomputational roles that astrocytes have in forming biological intelligence.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 20:19:25 GMT"}, {"version": "v2", "created": "Thu, 19 Sep 2019 16:19:01 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Tang", "Guangzhi", ""], ["Polykretis", "Ioannis E.", ""], ["Ivanov", "Vladimir A.", ""], ["Shah", "Arpit", ""], ["Michmizos", "Konstantinos P.", ""]]}, {"id": "1907.01827", "submitter": "Hideyoshi Yanagisawa", "authors": "Kazutaka Ueda, Yuki Sakai, Hideyoshi Yanagisawa", "title": "Quantitative evaluation of sense of discrepancy to operation response\n  using event-related potential", "comments": "Submitted to iDECON2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study aimed to develop a method to evaluate the sense of discrepancy to\nthe operation response quantitatively. We examined the availability of\nevent-related potential (P300), which is considered to reflect attention to\nstimulation, to evaluate the sense of discrepancy to the product response to\nthe user's action. In the experiment using subjective evaluation and P300 to\ninvestigate the sense of discrepancy due to the lack of operation response\n(sound and vibration) to the shutter operation of the mirrorless single-lens\ncamera, it was confirmed that P300 amplitude corresponds to the degree of the\nsubjective sense of discrepancy. Our results showed that the P300 amplitude\ncould evaluate the sense of discrepancy to the operation response.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 10:10:02 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Ueda", "Kazutaka", ""], ["Sakai", "Yuki", ""], ["Yanagisawa", "Hideyoshi", ""]]}, {"id": "1907.01934", "submitter": "Hideyoshi Yanagisawa", "authors": "Dan Nanno, Hideyoshi Yanagisawa", "title": "Effect of assistive method on the sense of fulfillment with agency:\n  Modeling with flow and attribution theory", "comments": "PrePrint submitted to ASME", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Several assistive technologies for users' operations have been recently\ndeveloped. A user's sense of agency (SoA) decreases with increasing system\nassistance, possibly resulting in a decrease in the user's sense of\nfulfillment. This study aims to provide a design guideline for an assistive\nmethod to maintain and improve the sense of fulfillment with SoA. We propose a\nmathematical model describing the mechanisms by which the assistive method\naffects SoA and SoA induces a sense of fulfillment. The experience in the flow\nstate is assumed to be a sense of fulfillment. The assistance effect on the\nskill-challenge plane in flow theory is defined as an increase in skill and\ndecrease in challenge. The factor that separates the two effects from\nattribution theory is the locus of causality, which is matched to the judgement\nof agency (JoA) from the two-step account of agency. We hypothesized that the\nassistance increases the perception of skill and sense of fulfillment is\ngreater when the locus of causality is internal, rather than external. To\nverify this hypothesis, a game task experiment was conducted with assistance\nthat varied with the ease of recognition. We hypothesized that a player's JoA\nis internal for hard-to-recognize assistance, resulting in a high sense of\nfulfillment. Experimental results supported this hypothesis.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 13:28:52 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 02:44:12 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Nanno", "Dan", ""], ["Yanagisawa", "Hideyoshi", ""]]}, {"id": "1907.02116", "submitter": "Paria Mehrani", "authors": "Paria Mehrani, Andrei Mouraviev, and John K. Tsotsos", "title": "Multiplicative modulations in hue-selective cells enhance unique hue\n  representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is still much to understand about the color processing mechanisms in\nthe brain and the transformation from cone-opponent representations to\nperceptual hues. Moreover, it is unclear which areas(s) in the brain represent\nunique hues. We propose a hierarchical model inspired by the neuronal\nmechanisms in the brain for local hue representation, which reveals the\ncontributions of each visual cortical area in hue representation. Local hue\nencoding is achieved through incrementally increasing processing nonlinearities\nbeginning with cone input. Besides employing nonlinear rectifications, we\npropose multiplicative modulations as a form of nonlinearity. Our simulation\nresults indicate that multiplicative modulations have significant contributions\nin encoding of hues along intermediate directions in the MacLeod-Boynton\ndiagram and that model V4 neurons have the capacity to encode unique hues.\nAdditionally, responses of our model neurons resemble those of biological color\ncells, suggesting that our model provides a novel formulation of the brain's\ncolor processing pathway.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 19:57:33 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Mehrani", "Paria", ""], ["Mouraviev", "Andrei", ""], ["Tsotsos", "John K.", ""]]}, {"id": "1907.02324", "submitter": "Marco Palombo Dr.", "authors": "Ioana Hill, Marco Palombo, Mathieu Santin, Francesca Branzoli,\n  Anne-Charlotte Philippe, Demian Wassermann, Marie-Stephane Aigrot, Bruno\n  Stankoff, Anne Baron-Van Evercooren, Mehdi Felfi, Dominique Langui, Hui\n  Zhang, Stephane Lehericy, Alexandra Petiet, Daniel C. Alexander, Olga\n  Ciccarelli, Ivana Drobnjak", "title": "Machine learning based white matter models with permeability: An\n  experimental study in cuprizone treated in-vivo mouse model of axonal\n  demyelination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The intra-axonal water exchange time {\\tau}i, a parameter associated with\naxonal permeability, could be an important biomarker for understanding\ndemyelinating pathologies such as Multiple Sclerosis. Diffusion-Weighted MRI is\nsensitive to changes in permeability, however, the parameter has remained\nelusive due to the intractability of the mathematical models that incorporate\nit. Machine learning based computational models can potentially be used to\nestimate such parameters, and recently, a theoretical framework using a random\nforest (RF) suggests this is a promising approach. In this study, we adopt such\nan RF approach and experimentally investigate its suitability as a biomarker\nfor demyelinating pathologies through direct comparison with histology. For\nthis, we use an in-vivo cuprizone (CPZ) mouse model of demyelination with\navailable ex-vivo electron microscopy (EM) data. We test our model on\nnoise-free simulations and find very strong correlations between the predicted\nand ground truth parameters. For realistic noise levels as in our in-vivo data,\nthe performance is affected, however, the parameters are still well estimated.\nWe apply our RF model on in-vivo data from 8 CPZ and 8 wild-type (WT) mice and\nvalidate the RF estimates using histology. We find a strong correlation between\nthe in-vivo RF estimates of {\\tau}i and the EM measurements of myelin thickness\n({\\rho_\\tau}i = 0.82), and between RF estimates and EM measurements of\nintra-axonal volume fraction ({\\rho_f} = 0.98). When comparing {\\tau}i in CPZ\nand WT mice we find a statistically significant decrease in the corpus callosum\nof the CPZ compared to the WT mice, in line with our expectations that {\\tau}i\nis lower in regions where the myelin sheath is damaged. Overall, these results\ndemonstrate the suitability of machine learning compartment models with\npermeability as a potential biomarker for demyelinating pathologies.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 10:52:01 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Hill", "Ioana", ""], ["Palombo", "Marco", ""], ["Santin", "Mathieu", ""], ["Branzoli", "Francesca", ""], ["Philippe", "Anne-Charlotte", ""], ["Wassermann", "Demian", ""], ["Aigrot", "Marie-Stephane", ""], ["Stankoff", "Bruno", ""], ["Evercooren", "Anne Baron-Van", ""], ["Felfi", "Mehdi", ""], ["Langui", "Dominique", ""], ["Zhang", "Hui", ""], ["Lehericy", "Stephane", ""], ["Petiet", "Alexandra", ""], ["Alexander", "Daniel C.", ""], ["Ciccarelli", "Olga", ""], ["Drobnjak", "Ivana", ""]]}, {"id": "1907.02339", "submitter": "Madhavun Candadai", "authors": "Madhavun Candadai and Eduardo J. Izquierdo", "title": "infotheory: A C++/Python package for multivariate information theoretic\n  analysis", "comments": "Submitted to Journal of Open Source Software (JOSS)", "journal-ref": null, "doi": "10.21105/joss.01609", "report-no": null, "categories": "cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces \\texttt{infotheory}: a package written in C++ and\nusable from Python and C++, for multivariate information theoretic analyses of\ndiscrete and continuous data. This package allows the user to study the\nrelationship between components of a complex system simply from the data\nrecorded during its operation, using the tools of information theory. It\nimplements widely used measures such as entropy and mutual information, as well\nas more recent measures that arise from multivariate extensions to information\ntheory, specifically Partial Information Decomposition. It provides an\neasy-to-use and flexible tool for use in research as well as pedgogical\npurposes to introduce students to information theory. Website:\nhttp://mcandadai.com/infotheory/ Source: https://git.io/infot\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 11:48:54 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 14:52:04 GMT"}, {"version": "v3", "created": "Sat, 27 Jul 2019 03:25:44 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Candadai", "Madhavun", ""], ["Izquierdo", "Eduardo J.", ""]]}, {"id": "1907.02351", "submitter": "Kristine Heiney", "authors": "Kristine Heiney, Vibeke Devold Valderhaug, Ioanna Sandvig, Axel\n  Sandvig, Gunnar Tufte, Hugo Lewi Hammer, Stefano Nichele", "title": "Evaluation of the criticality of in vitro neuronal networks: Toward an\n  assessment of computational capacity", "comments": "For presentation at the workshop \"Novel Substrates and Models for the\n  Emergence of Developmental, Learning and Cognitive Capabilities,\" 9th Joint\n  IEEE International Conference on Development and Learning and on Epigenetic\n  Robotics (IEEE ICDL-EPIROB 2019), Oslo, Norway. (website:\n  http://www.nichele.eu/ICDL-EPIROB_NSM/ICDL-EPIROB_SNM.html)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel computing hardwares are necessary to keep up with today's increasing\ndemand for data storage and processing power. In this research project, we turn\nto the brain for inspiration to develop novel computing substrates that are\nself-learning, scalable, energy-efficient, and fault-tolerant. The overarching\naim of this work is to develop computational models that are able to reproduce\ntarget behaviors observed in in vitro neuronal networks. These models will be\nultimately be used to aid in the realization of these behaviors in a more\nengineerable substrate: an array of nanomagnets. The target behaviors will be\nidentified by analyzing electrophysiological recordings of the neuronal\nnetworks. Preliminary analysis has been performed to identify when a network is\nin a critical state based on the size distribution of network-wide avalanches\nof activity, and the results of this analysis are reported here. This\nclassification of critical versus non-critical networks is valuable in\nidentifying networks that can be expected to perform well on computational\ntasks, as criticality is widely considered to be the state in which a system is\nbest suited for computation. This type of analysis is expected to enable the\nidentification of networks that are well-suited for computation and the\nclassification of networks as perturbed or healthy.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 12:14:30 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Heiney", "Kristine", ""], ["Valderhaug", "Vibeke Devold", ""], ["Sandvig", "Ioanna", ""], ["Sandvig", "Axel", ""], ["Tufte", "Gunnar", ""], ["Hammer", "Hugo Lewi", ""], ["Nichele", "Stefano", ""]]}, {"id": "1907.02431", "submitter": "Guy Gaziv", "authors": "Roman Beliy, Guy Gaziv, Assaf Hoogi, Francesca Strappini, Tal Golan,\n  Michal Irani", "title": "From voxels to pixels and back: Self-supervision in natural-image\n  reconstruction from fMRI", "comments": "*First two authors contributed equally. NeurIPS 2019", "journal-ref": "https://proceedings.neurips.cc/paper/2019/file/7d2be41b1bde6ff8fe45150c37488ebb-Paper.pdf", "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing observed images from fMRI brain recordings is challenging.\nUnfortunately, acquiring sufficient \"labeled\" pairs of {Image, fMRI} (i.e.,\nimages with their corresponding fMRI responses) to span the huge space of\nnatural images is prohibitive for many reasons. We present a novel approach\nwhich, in addition to the scarce labeled data (training pairs), allows to train\nfMRI-to-image reconstruction networks also on \"unlabeled\" data (i.e., images\nwithout fMRI recording, and fMRI recording without images). The proposed model\nutilizes both an Encoder network (image-to-fMRI) and a Decoder network\n(fMRI-to-image). Concatenating these two networks back-to-back (Encoder-Decoder\n& Decoder-Encoder) allows augmenting the training with both types of unlabeled\ndata. Importantly, it allows training on the unlabeled test-fMRI data. This\nself-supervision adapts the reconstruction network to the new input test-data,\ndespite its deviation from the statistics of the scarce training data.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 14:49:26 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Beliy", "Roman", ""], ["Gaziv", "Guy", ""], ["Hoogi", "Assaf", ""], ["Strappini", "Francesca", ""], ["Golan", "Tal", ""], ["Irani", "Michal", ""]]}, {"id": "1907.02557", "submitter": "Sudhakar Mishra", "authors": "Sudhakar Mishra and U.S.Tiwary", "title": "A Cognition-Affect Integrated Model of Emotion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of the efforts for defining and modelling emotion is broadly\nshifting from classical definite marker theory to statistically context\nsituated conceptual theory. However, the role of context processing and its\ninteraction with the affect is still not comprehensively explored and modelled.\nWith the help of neural decoding of functional networks, we have decoded\ncognitive functions for 12 different basic and complex emotion conditions.\nUsing transfer learning in deep neural architecture, we arrived at the\nconclusion that the core affect is unable to provide varieties of emotions\nunless coupled with cortical cognitive functions such as autobiographical\nmemory, dmn, self-referential, social, tom and salient event detection.\nFollowing our results, in this article, we present a 'cognition-affect\nintegrated model of emotion' which includes many cortical and subcortical\nregions and their interactions. Our model suggests three testable hypotheses.\nFirst, affect and physiological sensations alone are inconsequential in\ndefining or classifying emotions until integrated with the domain-general\ncognitive systems. Second, cognition and affect modulate each other throughout\nthe generation of meaningful instance which is situated in the current context.\nAnd, finally, the structural and temporal hierarchies in the brain's\norganization and anatomical projections play an important role in emotion\nresponses in terms of hierarchical activities and their durations. The model,\nalong with the analytical and anatomical support, is presented. The article\nconcludes with the future research questions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 18:24:10 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2019 17:14:18 GMT"}, {"version": "v3", "created": "Tue, 28 Apr 2020 09:53:44 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Mishra", "Sudhakar", ""], ["Tiwary", "U. S.", ""]]}, {"id": "1907.02591", "submitter": "Aakash Agrawal", "authors": "Aakash Agrawal", "title": "Dissimilarity learning via Siamese network predicts brain imaging data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The advent of deep learning has a profound effect on visual neuroscience. It\npaved the way for new models to predict neural data. Although deep\nconvolutional neural networks are explicitly trained for categorization, they\nlearn a representation similar to a biological visual system. But\ncategorization is not the only goal of the human visual system. Hence, the\nrepresentation of a classification algorithm may not completely explain the\nvisual processing stages. Here, I modified the traditional Siamese network loss\nfunction (Contrastive loss) to train them directly on neural dissimilarity.\nThis network takes image pair as input and predicts the correlation distance\nbetween their output features. For Algonauts challenge, using dissimilarity\nlearning, I fine-tuned the initial layers of Alexnet to predict MEG early\nresponse/EVC data and all the layers of VGG-16 to predict MEG late response/IT\ndata. This approach is ideal for datasets with high SNR. Therefore, my model\nachieved state-of-the-art performance on MEG dataset but not fMRI.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 16:58:39 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Agrawal", "Aakash", ""]]}, {"id": "1907.02596", "submitter": "Abderrazak Chahid Mr", "authors": "Abderrazak Chahid, Fahad Albalawi, Turky Nayef Alotaiby, Majed Hamad\n  Al-Hameed, Saleh Alshebeili, Taous-Meriem Laleg-Kirati", "title": "QuPWM: Feature Extraction Method for MEG Epileptic Spike Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is a neurological disorder classified as the second most serious\nneurological disease known to humanity, after stroke. Localization of the\nepileptogenic zone is an important step for epileptic patient treatment, which\nstarts with epileptic spike detection. The common practice for spike detection\nof brain signals is via visual scanning of the recordings, which is a\nsubjective and a very time-consuming task. Motivated by that, this paper\nfocuses on using machine learning for automatic detection of epileptic spikes\nin magnetoencephalography (MEG) signals. First, we used the Position Weight\nMatrix (PWM) method combined with a uniform quantizer to generate useful\nfeatures. Second, the extracted features are classified using a Support Vector\nMachine (SVM) for the purpose of epileptic spikes detection. The proposed\ntechnique shows great potential in improving the spike detection accuracy and\nreducing the feature vector size. Specifically, the proposed technique achieved\naverage accuracy up to 98\\% in using 5-folds cross-validation applied to a\nbalanced dataset of 3104 samples. These samples are extracted from 16 subjects\nwhere eight are healthy and eight are epileptic subjects using a sliding frame\nof size of 100 samples-points with a step-size of 2 sample-points\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:11:19 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Chahid", "Abderrazak", ""], ["Albalawi", "Fahad", ""], ["Alotaiby", "Turky Nayef", ""], ["Al-Hameed", "Majed Hamad", ""], ["Alshebeili", "Saleh", ""], ["Laleg-Kirati", "Taous-Meriem", ""]]}, {"id": "1907.02649", "submitter": "Owen Marschall", "authors": "Owen Marschall, Kyunghyun Cho, Cristina Savin", "title": "A Unified Framework of Online Learning Algorithms for Training Recurrent\n  Neural Networks", "comments": "29 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for compactly summarizing many recent results in\nefficient and/or biologically plausible online training of recurrent neural\nnetworks (RNN). The framework organizes algorithms according to several\ncriteria: (a) past vs. future facing, (b) tensor structure, (c) stochastic vs.\ndeterministic, and (d) closed form vs. numerical. These axes reveal latent\nconceptual connections among several recent advances in online learning.\nFurthermore, we provide novel mathematical intuitions for their degree of\nsuccess. Testing various algorithms on two synthetic tasks shows that\nperformances cluster according to our criteria. Although a similar clustering\nis also observed for gradient alignment, alignment with exact methods does not\nalone explain ultimate performance, especially for stochastic algorithms. This\nsuggests the need for better comparison metrics.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 01:49:45 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Marschall", "Owen", ""], ["Cho", "Kyunghyun", ""], ["Savin", "Cristina", ""]]}, {"id": "1907.02862", "submitter": "Esmaeil Seraj", "authors": "Esmaeil Seraj and Karthiga Mahalingam", "title": "Essential Motor Cortex Signal Processing: an ERP and functional\n  connectivity MATLAB toolbox -- user guide version 2.0", "comments": "37 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CE eess.IV q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this document is to help individuals use the \"Essential Motor\nCortex Signal Processing MATLAB Toolbox\". The toolbox implements various\nmethods for three major aspects of investigating human motor cortex from\nNeuroscience view point: (1) ERP estimation and quantification, (2) Cortical\nFunctional Connectivity analysis and (3) EMG quantification. The toolbox --\nwhich is distributed under the terms of the GNU GENERAL PUBLIC LICENSE as a set\nof MATLAB R routines -- can be downloaded directly at the address:\nhttp://oset.ir/category.php?dir=Tools or from the public repository on GitHub,\nat address below: https://github.com/EsiSeraj/ERP Connectivity EMG Analysis\n  The purpose of this toolbox is threefold: 1. Extract the\nevent-related-potential (ERP) from preprocessed cerebral signals (i.e. EEG,\nMEG, etc.), identify and then quantify the event-related\nsynchronization/desynchronization (ERS/ERD) events. Both time-course dynamics\nand time-frequency (TF) analyzes are included. 2. Measure, quantify and\ndemonstrate the cortical functional connectivity (CFC) across scalp electrodes.\nThese set of functions can also be applied to various types of cerebral signals\n(i.e. electric and magnetic). 3. Quantify electromyogram (EMG) recorded from\nactive muscles during performing motor tasks.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jun 2019 03:17:02 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2020 17:34:37 GMT"}], "update_date": "2020-07-23", "authors_parsed": [["Seraj", "Esmaeil", ""], ["Mahalingam", "Karthiga", ""]]}, {"id": "1907.02863", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Cognitive Functions of the Brain: Perception, Attention and Memory", "comments": "33 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a follow-up tutorial article of [17] and [16], in this paper, we will\nintroduce several important cognitive functions of the brain. Brain cognitive\nfunctions are the mental processes that allow us to receive, select, store,\ntransform, develop, and recover information that we've received from external\nstimuli. This process allows us to understand and to relate to the world more\neffectively. Cognitive functions are brain-based skills we need to carry out\nany task from the simplest to the most complex. They are related with the\nmechanisms of how we learn, remember, problem-solve, and pay attention, etc. To\nbe more specific, in this paper, we will talk about the perception, attention\nand memory functions of the human brain. Several other brain cognitive\nfunctions, e.g., arousal, decision making, natural language, motor\ncoordination, planning, problem solving and thinking, will be added to this\npaper in the later versions, respectively. Many of the materials used in this\npaper are from wikipedia and several other neuroscience introductory articles,\nwhich will be properly cited in this paper. This is the last of the three\ntutorial articles about the brain. The readers are suggested to read this paper\nafter the previous two tutorial articles on brain structure and functions [17]\nas well as the brain basic neural units [16].\n", "versions": [{"version": "v1", "created": "Thu, 30 May 2019 23:17:16 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1907.02936", "submitter": "Vasiliki Liakoni", "authors": "Vasiliki Liakoni, Alireza Modirshanechi, Wulfram Gerstner, Johanni\n  Brea", "title": "Learning in Volatile Environments with the Bayes Factor Surprise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Surprise-based learning allows agents to rapidly adapt to non-stationary\nstochastic environments characterized by sudden changes. We show that exact\nBayesian inference in a hierarchical model gives rise to a surprise-modulated\ntrade-off between forgetting old observations and integrating them with the new\nones. The modulation depends on a probability ratio, which we call \"Bayes\nFactor Surprise\", that tests the prior belief against the current belief. We\ndemonstrate that in several existing approximate algorithms the Bayes Factor\nSurprise modulates the rate of adaptation to new observations. We derive three\nnovel surprised-based algorithms, one in the family of particle filters, one in\nthe family of variational learning, and the other in the family of message\npassing, that have constant scaling in observation sequence length and\nparticularly simple update dynamics for any distribution in the exponential\nfamily. Empirical results show that these surprise-based algorithms estimate\nparameters better than alternative approximate approaches and reach levels of\nperformance comparable to computationally more expensive algorithms. The Bayes\nFactor Surprise is related to but different from Shannon Surprise. In two\nhypothetical experiments, we make testable predictions for physiological\nindicators that dissociate the Bayes Factor Surprise from Shannon Surprise. The\ntheoretical insight of casting various approaches as surprise-based learning,\nas well as the proposed online algorithms, may be applied to the analysis of\nanimal and human behavior, and to reinforcement learning in non-stationary\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 17:07:18 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2020 13:50:28 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2020 19:55:12 GMT"}], "update_date": "2020-09-25", "authors_parsed": [["Liakoni", "Vasiliki", ""], ["Modirshanechi", "Alireza", ""], ["Gerstner", "Wulfram", ""], ["Brea", "Johanni", ""]]}, {"id": "1907.03223", "submitter": "Johannes Kleiner", "authors": "Johannes Kleiner", "title": "Mathematical Models of Consciousness", "comments": null, "journal-ref": null, "doi": "10.3390/e22060609", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, promising mathematical models have been suggested which aim\nto describe conscious experience and its relation to the physical domain.\nWhereas the axioms and metaphysical ideas of these theories have been carefully\nmotivated, their mathematical formalism has not. In this article we aim to\nremedy this situation. We give an account of what warrants mathematical\nrepresentation of phenomenal experience, derive a general mathematical\nframework which takes into account consciousness' epistemic context and study\nwhich mathematical structures some of the key characteristics of conscious\nexperience imply, showing precisely where mathematical approaches allow to go\nbeyond what the standard methodology can do. The result is a general\nmathematical framework for models of consciousness that can be employed in the\ntheory-building process.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 05:35:24 GMT"}, {"version": "v2", "created": "Mon, 20 Apr 2020 10:44:33 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Kleiner", "Johannes", ""]]}, {"id": "1907.03341", "submitter": "Haozhe Shan", "authors": "Haozhe Shan, Rub\\'en Moreno-Bote, Jan Drugowitsch", "title": "Family of closed-form solutions for two-dimensional correlated diffusion\n  processes", "comments": "11 pages", "journal-ref": "Phys. Rev. E 100, 032132 (2019)", "doi": "10.1103/PhysRevE.100.032132", "report-no": null, "categories": "math.PR cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion processes with boundaries are models of transport phenomena with\nwide applicability across many fields. These processes are described by their\nprobability density functions (PDFs), which often obey Fokker-Planck equations\n(FPEs). While obtaining analytical solutions is often possible in the absence\nof boundaries, obtaining closed-form solutions to the FPE is more challenging\nonce absorbing boundaries are present. As a result, analyses of these processes\nhave largely relied on approximations or direct simulations. In this paper, we\nstudied two-dimensional, time-homogeneous, spatially-correlated diffusion with\nlinear, axis-aligned, absorbing boundaries. Our main result is the explicit\nconstruction of a full family of closed-form solutions for their PDFs using the\nmethod of images (MoI). We found that such solutions can be built if and only\nif the correlation coefficient $\\rho$ between the two diffusing processes takes\none of a numerable set of values. Using a geometric argument, we derived the\ncomplete set of $\\rho$'s where such solutions can be found. Solvable $\\rho$'s\nare given by $\\rho = - \\cos \\left( \\frac{\\pi}{k} \\right)$, where $k \\in\n\\mathbb{Z}^+ \\cup \\{ +\\infty\\}$. Solutions were validated in simulations.\nQualitative behaviors of the process appear to vary smoothly over $\\rho$,\nallowing extrapolation from our solutions to cases with unsolvable $\\rho$'s.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 20:04:33 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2019 14:19:51 GMT"}], "update_date": "2019-09-25", "authors_parsed": [["Shan", "Haozhe", ""], ["Moreno-Bote", "Rub\u00e9n", ""], ["Drugowitsch", "Jan", ""]]}, {"id": "1907.03612", "submitter": "Michael Cole", "authors": "Takuya Ito, Luke Hearne, Ravi Mill, Carrisa Cocuzza, Michael W. Cole", "title": "Discovering the Computational Relevance of Brain Network Organization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding neurocognitive computations will require not just localizing\ncognitive information distributed throughout the brain but also determining how\nthat information got there. We review recent advances in linking empirical and\nsimulated brain network organization with cognitive information processing.\nBuilding on these advances, we offer a new framework for understanding the role\nof connectivity in cognition - network coding (encoding/decoding) models. These\nmodels utilize connectivity to specify the transfer of information via neural\nactivity flow processes, successfully predicting the formation of cognitive\nrepresentations in empirical neural data. The success of these models supports\nthe possibility that localized neural functions mechanistically emerge (are\ncomputed) from distributed activity flow processes that are specified primarily\nby connectivity patterns.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 13:41:45 GMT"}, {"version": "v2", "created": "Mon, 21 Oct 2019 14:31:20 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Ito", "Takuya", ""], ["Hearne", "Luke", ""], ["Mill", "Ravi", ""], ["Cocuzza", "Carrisa", ""], ["Cole", "Michael W.", ""]]}, {"id": "1907.03929", "submitter": "Mohsen Joneidi", "authors": "Mohsen Joneidi", "title": "Functional Brain Networks Discovery Using Dictionary Learning with\n  Correlated Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP eess.IV q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of data from functional magnetic resonance imaging (fMRI) results in\nconstructing functional brain networks. Principal component analysis (PCA) and\nindependent component analysis (ICA) are widely used to generate functional\nbrain networks. Moreover, dictionary learning and sparse representation provide\nsome latent patterns that rules brain activities and they can be interpreted as\nbrain networks. However, these methods lack modeling dependencies of the\ndiscovered networks. In this study an alternative to these conventional methods\nis presented in which dependencies of the networks are considered via\ncorrelated sparsity patterns. We formulate this challenge as a new dictionary\nlearning problem and propose two approaches to solve the problem effectively.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 01:18:11 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 21:29:05 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Joneidi", "Mohsen", ""]]}, {"id": "1907.04242", "submitter": "Pierre Baudot", "authors": "Pierre Baudot and Monica Tapia and Daniel Bennequin and Jean-Marc\n  Goaillard", "title": "Topological Information Data Analysis", "comments": null, "journal-ref": null, "doi": "10.3390/e21090869", "report-no": null, "categories": "stat.OT cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents methods that quantify the structure of statistical\ninteractions within a given data set, and was first used in \\cite{Tapia2018}.\nIt establishes new results on the k-multivariate mutual-informations (I_k)\ninspired by the topological formulation of Information introduced in. In\nparticular we show that the vanishing of all I_k for 2\\leq k \\leq n of n random\nvariables is equivalent to their statistical independence. Pursuing the work of\nHu Kuo Ting and Te Sun Han, we show that information functions provide\nco-ordinates for binary variables, and that they are analytically independent\non the probability simplex for any set of finite variables. The maximal\npositive I_k identifies the variables that co-vary the most in the population,\nwhereas the minimal negative I_k identifies synergistic clusters and the\nvariables that differentiate-segregate the most the population. Finite data\nsize effects and estimation biases severely constrain the effective computation\nof the information topology on data, and we provide simple statistical tests\nfor the undersampling bias and the k-dependences following. We give an example\nof application of these methods to genetic expression and unsupervised\ncell-type classification. The methods unravel biologically relevant subtypes,\nwith a sample size of 41 genes and with few errors. It establishes generic\nbasic methods to quantify the epigenetic information storage and a unified\nepigenetic unsupervised learning formalism. We propose that higher-order\nstatistical interactions and non identically distributed variables are\nconstitutive characteristics of biological systems that should be estimated in\norder to unravel their significant statistical structure and diversity. The\ntopological information data analysis presented here allows to precisely\nestimate this higher-order structure characteristic of biological systems.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 15:04:08 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Baudot", "Pierre", ""], ["Tapia", "Monica", ""], ["Bennequin", "Daniel", ""], ["Goaillard", "Jean-Marc", ""]]}, {"id": "1907.04412", "submitter": "Ignacio Perez Ipi\\~na", "authors": "Ignacio Perez Ipi\\~na, Patricio Donnelly Kehoe, Morten Kringelbach,\n  Helmut Laufs, Agust\\'in Iba\\~nez, Gustavo Deco, Yonatan Sanz Perl, Enzo\n  Tagliazucchi", "title": "Modeling the relationship between regional activation and functional\n  connectivity during wakefulness and sleep", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global brain activity self-organizes into discrete patterns characterized by\ndistinct behavioral observables and modes of information processing. The human\nthalamocortical system is a densely connected network where local neural\nactivation reciprocally influences coordinated collective dynamics. We\nintroduce a semi-empirical model to investigate the relationship between\nregional activation and long-range functional connectivity in the different\nbrain states visited during the natural wake-sleep cycle. Our model combines\nfunctional magnetic resonance imaging (fMRI) data, in vivo estimates of\nstructural connectivity, and anatomically-informed priors that constrain the\nindependent variation of regional activation. As expected, priors based on\nfunctionally coherent networks resulted in the best fit between empirical and\nsimulated brain activity. We show that sleep progressively divided the cortex\ninto regions presenting opposite dynamical behavior: frontoparietal regions\napproached a bifurcation towards local oscillatory dynamics, while sensorimotor\nregions presented stable dynamics governed by noise. In agreement with human\nelectrophysiological experiments, sleep onset induced subcortical deactivation\nand uncoupling, which was subsequently reversed for deeper stages. Finally, we\nintroduced external forcing of variable intensity to simulate external\nperturbations, and identifiedthe key regionsespecially relevant for the\nrecovery of wakefulness from deep sleep. Our model represents sleep as a state\nwhere long-range decoupling and regional deactivation coexist with the latent\ncapacity for a rapid transition towards wakefulness. The mechanistic insights\nprovided by our simulations allow the in silico parametric exploration of such\ntransitions in terms of external perturbations, with potential applications for\nthe control of physiological and pathological brain states.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 21:00:15 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 00:03:09 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Ipi\u00f1a", "Ignacio Perez", ""], ["Kehoe", "Patricio Donnelly", ""], ["Kringelbach", "Morten", ""], ["Laufs", "Helmut", ""], ["Iba\u00f1ez", "Agust\u00edn", ""], ["Deco", "Gustavo", ""], ["Perl", "Yonatan Sanz", ""], ["Tagliazucchi", "Enzo", ""]]}, {"id": "1907.05060", "submitter": "Fabian Pallasdies", "authors": "Fabian Pallasdies, Sven Goedeke, Wilhelm Braun and Raoul-Martin\n  Memmesheimer", "title": "From Single Neurons to Behavior in the Jellyfish Aurelia aurita", "comments": null, "journal-ref": "eLife 2019;8:e50084", "doi": "10.7554/eLife.50084", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jellyfish nerve nets provide insight into the origins of nervous systems, as\nboth their taxonomic position and their evolutionary age imply that jellyfish\nresemble some of the earliest neuron-bearing, actively-swimming animals. Here\nwe develop the first neuronal network model for the nerve nets of jellyfish.\nSpecifically, we focus on the moon jelly Aurelia aurita and the control of its\nenergy-efficient swimming motion. The proposed single neuron model disentangles\nthe contributions of different currents to a spike. The network model\nidentifies factors ensuring non-pathological activity and suggests an\noptimization for the transmission of signals. After modeling the jellyfish's\nmuscle system and its bell in a hydrodynamic environment, we explore the\nswimming elicited by neural activity. We find that different delays between\nnerve net activations lead to well-controlled, differently directed movements.\nOur model bridges the scales from single neurons to behavior, allowing for a\ncomprehensive understanding of jellyfish neural control.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 08:57:27 GMT"}], "update_date": "2020-02-25", "authors_parsed": [["Pallasdies", "Fabian", ""], ["Goedeke", "Sven", ""], ["Braun", "Wilhelm", ""], ["Memmesheimer", "Raoul-Martin", ""]]}, {"id": "1907.05395", "submitter": "Prasanna Parvathaneni", "authors": "Prasanna Parvathaneni, Shunxing Bao, Vishwesh Nath, Neil D. Woodward,\n  Daniel O. Claassen, Carissa J. Cascio, David H. Zald, Yuankai Huo, Bennett A.\n  Landman, Ilwoo Lyu", "title": "Cortical Surface Parcellation using Spherical Convolutional Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.IV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present cortical surface parcellation using spherical deep convolutional\nneural networks. Traditional multi-atlas cortical surface parcellation requires\ninter-subject surface registration using geometric features with high\nprocessing time on a single subject (2-3 hours). Moreover, even optimal surface\nregistration does not necessarily produce optimal cortical parcellation as\nparcel boundaries are not fully matched to the geometric features. In this\ncontext, a choice of training features is important for accurate cortical\nparcellation. To utilize the networks efficiently, we propose cortical\nparcellation-specific input data from an irregular and complicated structure of\ncortical surfaces. To this end, we align ground-truth cortical parcel\nboundaries and use their resulting deformation fields to generate new pairs of\ndeformed geometric features and parcellation maps. To extend the capability of\nthe networks, we then smoothly morph cortical geometric features and\nparcellation maps using the intermediate deformation fields. We validate our\nmethod on 427 adult brains for 49 labels. The experimental results show that\nour method out-performs traditional multi-atlas and naive spherical U-Net\napproaches, while achieving full cortical parcellation in less than a minute.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 17:20:00 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Parvathaneni", "Prasanna", ""], ["Bao", "Shunxing", ""], ["Nath", "Vishwesh", ""], ["Woodward", "Neil D.", ""], ["Claassen", "Daniel O.", ""], ["Cascio", "Carissa J.", ""], ["Zald", "David H.", ""], ["Huo", "Yuankai", ""], ["Landman", "Bennett A.", ""], ["Lyu", "Ilwoo", ""]]}, {"id": "1907.05827", "submitter": "Ayon Borthakur Mr", "authors": "Ayon Borthakur, Thomas A. Cleland", "title": "Signal Conditioning for Learning in the Wild", "comments": "Neuro-inspired Computational Elements Workshop(NICE 19), March 26-28,\n  2019, Albany, NY, USA. ACM, New York, NY, USA, 11 pages", "journal-ref": null, "doi": "10.1145/3320288.3320293", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mammalian olfactory system learns rapidly from very few examples,\npresented in unpredictable online sequences, and then recognizes these learned\nodors under conditions of substantial interference without exhibiting\ncatastrophic forgetting. We have developed a brain-mimetic algorithm that\nreplicates these properties, provided that sensory inputs adhere to a common\nstatistical structure. However, in natural, unregulated environments, this\nconstraint cannot be assured. We here present a series of signal conditioning\nsteps, inspired by the mammalian olfactory system, that transform diverse\nsensory inputs into a regularized statistical structure to which the learning\nnetwork can be tuned. This pre-processing enables a single instantiated network\nto be applied to widely diverse classification tasks and datasets - here\nincluding gas sensor data, remote sensing from spectral characteristics, and\nmulti-label hierarchical identification of wild species - without adjusting\nnetwork hyperparameters.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 16:25:50 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Borthakur", "Ayon", ""], ["Cleland", "Thomas A.", ""]]}, {"id": "1907.06286", "submitter": "Viktor Toth", "authors": "Viktor T\\'oth, Lauri Parkkonen", "title": "Autoencoding sensory substitution", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.10576.87048", "report-no": null, "categories": "q-bio.NC cs.CV cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tens of millions of people live blind, and their number is ever increasing.\nVisual-to-auditory sensory substitution (SS) encompasses a family of cheap,\ngeneric solutions to assist the visually impaired by conveying visual\ninformation through sound. The required SS training is lengthy: months of\neffort is necessary to reach a practical level of adaptation. There are two\nreasons for the tedious training process: the elongated substituting audio\nsignal, and the disregard for the compressive characteristics of the human\nhearing system. To overcome these obstacles, we developed a novel class of SS\nmethods, by training deep recurrent autoencoders for image-to-sound conversion.\nWe successfully trained deep learning models on different datasets to execute\nvisual-to-auditory stimulus conversion. By constraining the visual space, we\ndemonstrated the viability of shortened substituting audio signals, while\nproposing mechanisms, such as the integration of computational hearing models,\nto optimally convey visual features in the substituting stimulus as\nperceptually discernible auditory components. We tested our approach in two\nseparate cases. In the first experiment, the author went blindfolded for 5\ndays, while performing SS training on hand posture discrimination. The second\nexperiment assessed the accuracy of reaching movements towards objects on a\ntable. In both test cases, above-chance-level accuracy was attained after a few\nhours of training. Our novel SS architecture broadens the horizon of\nrehabilitation methods engineered for the visually impaired. Further\nimprovements on the proposed model shall yield hastened rehabilitation of the\nblind and a wider adaptation of SS devices as a consequence.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 21:58:10 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["T\u00f3th", "Viktor", ""], ["Parkkonen", "Lauri", ""]]}, {"id": "1907.06314", "submitter": "Sandro Sozzo", "authors": "Sandro Sozzo", "title": "Representing Attitudes Towards Ambiguity in Hilbert Space: Foundations\n  and Applications", "comments": "23 pages, standard LaTeX, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide here a general mathematical framework to model attitudes towards\nambiguity which uses the formalism of quantum theory as a ``purely mathematical\nformalism, detached from any physical interpretation''. We show that the\nquantum-theoretic framework enables modelling of the \"Ellsberg paradox\", but it\nalso successfully applies to more concrete human decision-making (DM) tests\ninvolving financial, managerial and medical decisions. In particular, we\nelaborate a mathematical representation of various empirical studies which\nreveal that attitudes of managers towards uncertainty shift from \"ambiguity\nseeking\" to \"ambiguity aversion\", and viceversa, thus exhibiting \"hope effects\"\nand \"fear effects\". The present framework provides a promising direction\ntowards the development of a unified theory of decisions in the presence of\nuncertainty.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 11:32:38 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2020 11:36:18 GMT"}, {"version": "v3", "created": "Sat, 20 Jun 2020 13:31:01 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Sozzo", "Sandro", ""]]}, {"id": "1907.06374", "submitter": "Timothy Lillicrap", "authors": "Timothy P. Lillicrap and Konrad P. Kording", "title": "What does it mean to understand a neural network?", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We can define a neural network that can learn to recognize objects in less\nthan 100 lines of code. However, after training, it is characterized by\nmillions of weights that contain the knowledge about many object types across\nvisual scenes. Such networks are thus dramatically easier to understand in\nterms of the code that makes them than the resulting properties, such as tuning\nor connections. In analogy, we conjecture that rules for development and\nlearning in brains may be far easier to understand than their resulting\nproperties. The analogy suggests that neuroscience would benefit from a focus\non learning and development.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 08:58:26 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lillicrap", "Timothy P.", ""], ["Kording", "Konrad P.", ""]]}, {"id": "1907.06486", "submitter": "Pierre Baudot", "authors": "Pierre Baudot", "title": "The Poincar\\'e-Boltzmann Machine: from Statistical Physics to Machine\n  Learning and back", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the computational methods of information cohomology\napplied to genetic expression in and in the companion paper and proposes its\ninterpretations in terms of statistical physics and machine learning. In order\nto further underline the Hochschild cohomological nature af information\nfunctions and chain rules, following, the computation of the cohomology in low\ndegrees is detailed to show more directly that the $k$ multivariate\nmutual-informations (I_k) are k-coboundaries. The k-cocycles condition\ncorresponds to I_k=0, generalizing statistical independence. Hence the\ncohomology quantifies the statistical dependences and the obstruction to\nfactorization. The topological approach allows to investigate information in\nthe multivariate case without the assumptions of independent identically\ndistributed variables and without mean field approximations. We develop the\ncomputationally tractable subcase of simplicial information cohomology\nrepresented by entropy H_k and information I_k landscapes and their respective\npaths. The I_1 component defines a self-internal energy U_k, and I_k,k>1\ncomponents define the contribution to a free energy G_k (the total correlation)\nof the k-body interactions. The set of information paths in simplicial\nstructures is in bijection with the symmetric group and random processes,\nprovides a trivial topological expression of the 2nd law of thermodynamic. The\nlocal minima of free-energy, related to conditional information negativity, and\nconditional independence, characterize a minimum free energy complex. This\ncomplex formalizes the minimum free-energy principle in topology, provides a\ndefinition of a complex system, and characterizes a multiplicity of local\nminima that quantifies the diversity observed in biology. I give an\ninterpretation of this complex in terms of frustration in glass and of Van Der\nWalls k-body interactions for data points.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 18:26:19 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Baudot", "Pierre", ""]]}, {"id": "1907.06765", "submitter": "Alejandro Tlaie", "authors": "A. Tlaie, I. Leyva, I. Sendi\\~na", "title": "High-order couplings in geometric complex networks of neurons", "comments": null, "journal-ref": "Phys. Rev. E 100, 052305 (2019)", "doi": "10.1103/PhysRevE.100.052305", "report-no": null, "categories": "nlin.PS nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the consequences of introducing higher-order interactions in a\ngeometric complex network of Morris-Lecar neurons. We focus on the regime where\ntravelling synchronization waves are observed out of a first-neighbours based\ncoupling, to evaluate the changes induced when higher-order dynamical\ninteractions are included. We observe that the travelling wave phenomenon gets\nenhanced by these interactions, allowing the information to travel further in\nthe system without generating pathological full synchronization states. This\nscheme could be a step towards a simple modelization of neuroglial networks.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 21:42:13 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Tlaie", "A.", ""], ["Leyva", "I.", ""], ["Sendi\u00f1a", "I.", ""]]}, {"id": "1907.06909", "submitter": "Kevin Woods", "authors": "Kevin J P Woods, Adam Hewett, Andrea Spencer, Benjamin Morillon,\n  Psyche Loui", "title": "Modulation in background music influences sustained attention", "comments": "20 pages, 5 figures. Behavioral portion of larger planned manuscript\n  to include neuroimaging. Comments welcome (kevin@brain.fm)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background music is known to affect performance on cognitive tasks, possibly\ndue to temporal modulations in the acoustic signal, but little is known about\nhow music should be designed to aid performance. Since acoustic modulation has\nbeen shown to shape neural activity in known networks, we chose to test the\neffects of acoustic modulation on sustained attention, which requires activity\nin these networks and is a common ingredient for success across many tasks. To\nunderstand how specific aspects of background music influence sustained\nattention, we manipulated the rate and depth of amplitude modulations imposed\non otherwise identical music. This produced stimuli that were musically and\nacoustically identical except for a peak in the modulation spectrum that could\nchange intensity or shift location under manipulations of depth or rate\nrespectively. These controlled musical backgrounds were presented to\nparticipants (total N = 677) during the sustained attention to response (SART)\ntask. In two experiments, we show performance benefits due to added modulation,\nwith best performance at 16 Hz (beta band) rate and higher modulation depths;\nneighboring parameter settings did not produce this benefit. Further\nexamination of individual differences within our overall sample showed that\nthose with a high level of self-reported ADHD symptomaticity tended to perform\nbetter with more intense beta modulation. These results suggest optimal\nparameters for adding modulation to background music, which are consistent with\ntheories of oscillatory dynamics that relate auditory stimulation to behavior,\nyet demonstrate the need for a personalized approach in creating functional\nmusic for everyday use.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:33:39 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Woods", "Kevin J P", ""], ["Hewett", "Adam", ""], ["Spencer", "Andrea", ""], ["Morillon", "Benjamin", ""], ["Loui", "Psyche", ""]]}, {"id": "1907.06996", "submitter": "Alberto Testolin Dr.", "authors": "Alberto Testolin, Serena Dolfi, Mathijs Rochus and Marco Zorzi", "title": "Perception of visual numerosity in humans and machines", "comments": "27 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerosity perception is foundational to mathematical learning, but its\ncomputational bases are strongly debated. Some investigators argue that humans\nare endowed with a specialized system supporting numerical representation;\nothers argue that visual numerosity is estimated using continuous magnitudes,\nsuch as density or area, which usually co-vary with number. Here we reconcile\nthese contrasting perspectives by testing deep networks on the same numerosity\ncomparison task that was administered to humans, using a stimulus space that\nallows to measure the contribution of non-numerical features. Our model\naccurately simulated the psychophysics of numerosity perception and the\nassociated developmental changes: discrimination was driven by numerosity\ninformation, but non-numerical features had a significant impact, especially\nearly during development. Representational similarity analysis further\nhighlighted that both numerosity and continuous magnitudes were spontaneously\nencoded even when no task had to be carried out, demonstrating that numerosity\nis a major, salient property of our visual environment.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 13:45:18 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Testolin", "Alberto", ""], ["Dolfi", "Serena", ""], ["Rochus", "Mathijs", ""], ["Zorzi", "Marco", ""]]}, {"id": "1907.07821", "submitter": "Yahya Karimipanah", "authors": "Carson C. Chow and Yahya Karimipanah", "title": "Before and beyond the Wilson-Cowan equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Wilson-Cowan equations represent a landmark in the history of\ncomputational neuroscience. Among the insights Wilson and Cowan offered for\nneuroscience, they crystallized an approach to modeling neural dynamics and\nbrain function. Although their iconic equations are used in various guises\ntoday, the ideas that led to their formulation and the relationship to other\napproaches are not well known. Here, we give a little context to some of the\nbiological and theoretical concepts that lead to the Wilson-Cowan equations and\ndiscuss how to extend beyond them.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 00:26:04 GMT"}, {"version": "v2", "created": "Wed, 31 Jul 2019 16:49:27 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Chow", "Carson C.", ""], ["Karimipanah", "Yahya", ""]]}, {"id": "1907.08097", "submitter": "Matthew Turner", "authors": "Henry J. Charlesworth and Matthew S. Turner", "title": "Intrinsically motivated collective motion", "comments": "PNAS in press, SI and movies, available at\n  http://wrap.warwick.ac.uk/120002/", "journal-ref": null, "doi": "10.1073/pnas.1822069116", "report-no": null, "categories": "physics.bio-ph cond-mat.soft q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective motion is found in various animal systems, active suspensions and\nrobotic or virtual agents. This is often understood using high level models\nthat directly encode selected empirical features, such as co-alignment and\ncohesion. Can these features be shown to emerge from an underlying, low-level\nprinciple? We find that they emerge naturally under Future State Maximisation\n(FSM). Here agents perceive a visual representation of the world around them,\nsuch as might be recorded on a simple retina, and then move to maximise the\nnumber of different visual environments that they expect to be able to access\nin the future. Such a control principle may confer evolutionary fitness in an\nuncertain world by enabling agents to deal with a wide variety of future\nscenarios. The collective dynamics that spontaneously emerge under FSM resemble\nanimal systems in several qualitative aspects, including cohesion, co-alignment\nand collision suppression, none of which are explicitly encoded in the model. A\nmulti-layered neural network trained on simulated trajectories is shown to\nrepresent a heuristic mimicking FSM. Similar levels of reasoning would seem to\nbe accessible under animal cognition, demonstrating a possible route to the\nemergence of collective motion in social animals directly from the control\nprinciple underlying FSM. Such models may also be good candidates for encoding\ninto possible future realisations of artificial \"intelligent\" matter, able to\nsense light, process information and move.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 14:49:06 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Charlesworth", "Henry J.", ""], ["Turner", "Matthew S.", ""]]}, {"id": "1907.08145", "submitter": "Ganesh Chand", "authors": "Ganesh B Chand, Mohamad Habes, Sudipto Dolui, John A Detre, David A\n  Wolk, and Christos Davatzikos", "title": "Estimating regional cerebral blood flow using resting-state functional\n  MRI via machine learning", "comments": "20 pages, 6 main figures or tables, 4 supplementary figures or tables", "journal-ref": null, "doi": "10.1016/j.jneumeth.2019.108528", "report-no": null, "categories": "eess.IV eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Perfusion MRI is an important modality in many brain imaging protocols, since\nit probes cerebrovascular changes in aging and many diseases; however, it may\nnot be always available. Here we introduce a method that seeks to estimate\nregional perfusion properties using spectral information of resting-state\nfunctional MRI (rsfMRI) via machine learning. We used pairs of rsfMRI and\narterial spin labeling (ASL) images from the same elderly individuals with\nnormal cognition (NC; n = 45) and mild cognitive impairment (MCI; n = 26), and\nbuilt support vector machine models aiming to estimate regional cerebral blood\nflow (CBF) from the rsfMRI signal alone. This method demonstrated higher\nassociations between the estimated CBF and actual CBF (ASL-CBF) at the total\nlobar gray matter (r = 0.40; FDR-p = 1.9e-03), parietal lobe (r = 0.46, FDR-p =\n8e-04), and occipital lobe (r = 0.35; FDR-p = 0.01) using rsfMRI signals of\nfrequencies [0.01-0.15] Hertz compared to frequencies [0.01-0.10] Hertz and\n[0.01-0.20] Hertz, respectively. We further observed significant associations\nbetween the estimated CBF and actual CBF in 24 regions of interest (p < 0.05),\nwith the highest association observed in the superior parietal lobule (r =\n0.50, FDR-p = 0.002). Moreover, the estimated CBF at superior parietal lobule\nshowed significant correlation with the mini-mental state exam (MMSE) score (r\n= 0.27; FDR-p = 0.04) and decreased in MCI with lower MMSE score compared to NC\ngroup (FDR-p = 0.04). Overall, these results suggest that the proposed\nframework can obtain estimates of regional perfusion from rsfMRI, which can\nserve as surrogate perfusion measures in the absence of ASL.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 16:30:24 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Chand", "Ganesh B", ""], ["Habes", "Mohamad", ""], ["Dolui", "Sudipto", ""], ["Detre", "John A", ""], ["Wolk", "David A", ""], ["Davatzikos", "Christos", ""]]}, {"id": "1907.08196", "submitter": "Tanya Schmah", "authors": "Kevin Raina, Uladzimir Yahorau, Tanya Schmah", "title": "Exploiting bilateral symmetry in brain lesion segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain lesions, including stroke and tumours, have a high degree of\nvariability in terms of location, size, intensity and form, making automatic\nsegmentation difficult. We propose an improvement to existing segmentation\nmethods by exploiting the bilateral quasi-symmetry of healthy brains, which\nbreaks down when lesions are present. Specifically, we use nonlinear\nregistration of a neuroimage to a reflected version of itself (\"reflective\nregistration\") to determine for each voxel its homologous (corresponding) voxel\nin the other hemisphere. A patch around the homologous voxel is added as a set\nof new features to the segmentation algorithm. To evaluate this method, we\nimplemented two different CNN-based multimodal MRI stroke lesion segmentation\nalgorithms, and then augmented them by adding extra symmetry features using the\nreflective registration method described above. For each architecture, we\ncompared the performance with and without symmetry augmentation, on the SISS\nTraining dataset of the Ischemic Stroke Lesion Segmentation Challenge (ISLES)\n2015 challenge. Using affine reflective registration improves performance over\nbaseline, but nonlinear reflective registration gives significantly better\nresults: an improvement in Dice coefficient of 13 percentage points over\nbaseline for one architecture and 9 points for the other. We argue for the\nbroad applicability of adding symmetric features to existing segmentation\nalgorithms, specifically using nonlinear, template-free methods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 13:42:22 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Raina", "Kevin", ""], ["Yahorau", "Uladzimir", ""], ["Schmah", "Tanya", ""]]}, {"id": "1907.08549", "submitter": "Niru Maheswaranathan", "authors": "Niru Maheswaranathan, Alex H. Williams, Matthew D. Golub, Surya\n  Ganguli, David Sussillo", "title": "Universality and individuality in neural dynamics across large\n  populations of recurrent networks", "comments": "Presented at NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task-based modeling with recurrent neural networks (RNNs) has emerged as a\npopular way to infer the computational function of different brain regions.\nThese models are quantitatively assessed by comparing the low-dimensional\nneural representations of the model with the brain, for example using canonical\ncorrelation analysis (CCA). However, the nature of the detailed neurobiological\ninferences one can draw from such efforts remains elusive. For example, to what\nextent does training neural networks to solve common tasks uniquely determine\nthe network dynamics, independent of modeling architectural choices? Or\nalternatively, are the learned dynamics highly sensitive to different model\nchoices? Knowing the answer to these questions has strong implications for\nwhether and how we should use task-based RNN modeling to understand brain\ndynamics. To address these foundational questions, we study populations of\nthousands of networks, with commonly used RNN architectures, trained to solve\nneuroscientifically motivated tasks and characterize their nonlinear dynamics.\nWe find the geometry of the RNN representations can be highly sensitive to\ndifferent network architectures, yielding a cautionary tale for measures of\nsimilarity that rely representational geometry, such as CCA. Moreover, we find\nthat while the geometry of neural dynamics can vary greatly across\narchitectures, the underlying computational scaffold---the topological\nstructure of fixed points, transitions between them, limit cycles, and\nlinearized dynamics---often appears universal across all architectures.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 15:35:38 GMT"}, {"version": "v2", "created": "Wed, 4 Dec 2019 20:43:41 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Maheswaranathan", "Niru", ""], ["Williams", "Alex H.", ""], ["Golub", "Matthew D.", ""], ["Ganguli", "Surya", ""], ["Sussillo", "David", ""]]}, {"id": "1907.08705", "submitter": "Mohammad Hadi Mehdizavareh", "authors": "Mohammad Hadi Mehdizavareh, Sobhan Hemati, Hamid Soltanian-Zadeh", "title": "Enhancing performance of subject-specific models via subject-independent\n  information for SSVEP-based BCIs", "comments": "22 pages, 8 figures, 1 table, 1 appendix, published in PLOS ONE\n  journal. This is a draft version. The published version is available in the\n  following link:\n  https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0226048", "journal-ref": "PLOS ONE 15(1): e0226048 (2020)", "doi": "10.1371/journal.pone.0226048", "report-no": null, "categories": "q-bio.NC cs.HC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, brain-computer interface (BCI) systems developed based on\nsteady-state visual evoked potential (SSVEP) have attracted much attention due\nto their high information transfer rate (ITR) and increasing number of targets.\nHowever, SSVEP-based methods can be improved in terms of their accuracy and\ntarget detection time. We propose a new method based on canonical correlation\nanalysis (CCA) to integrate subject-specific models and subject-independent\ninformation and enhance BCI performance. We propose to use training data of\nother subjects to optimize hyperparameters for CCA-based model of a specific\nsubject. An ensemble version of the proposed method is also developed for a\nfair comparison with ensemble task-related component analysis (TRCA). The\nproposed method is compared with TRCA and extended CCA methods. A publicly\navailable, 35-subject SSVEP benchmark dataset is used for comparison studies\nand performance is quantified by classification accuracy and ITR. The ITR of\nthe proposed method is higher than those of TRCA and extended CCA. The proposed\nmethod outperforms extended CCA in all conditions and TRCA for time windows\ngreater than 0.3 s. The proposed method also outperforms TRCA when there are\nlimited training blocks and electrodes. This study illustrates that adding\nsubject-independent information to subject-specific models can improve\nperformance of SSVEP-based BCIs.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 21:49:39 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 20:34:28 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Mehdizavareh", "Mohammad Hadi", ""], ["Hemati", "Sobhan", ""], ["Soltanian-Zadeh", "Hamid", ""]]}, {"id": "1907.08801", "submitter": "Mauricio Barahona", "authors": "Amadeus Maes, Mauricio Barahona, Claudia Clopath", "title": "Learning spatiotemporal signals using a recurrent spiking network that\n  discretizes time", "comments": "To appear in Plos Computational Biology", "journal-ref": null, "doi": "10.1371/journal.pcbi.1007606", "report-no": null, "categories": "q-bio.NC cs.NE nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to produce spatiotemporal sequences is a common task that the brain\nhas to solve. The same neural substrate may be used by the brain to produce\ndifferent sequential behaviours. The way the brain learns and encodes such\ntasks remains unknown as current computational models do not typically use\nrealistic biologically-plausible learning. Here, we propose a model where a\nspiking recurrent network of excitatory and inhibitory biophysical neurons\ndrives a read-out layer: the dynamics of the driver recurrent network is\ntrained to encode time which is then mapped through the read-out neurons to\nencode another dimension, such as space or a phase. Different spatiotemporal\npatterns can be learned and encoded through the synaptic weights to the\nread-out neurons that follow common Hebbian learning rules. We demonstrate that\nthe model is able to learn spatiotemporal dynamics on time scales that are\nbehaviourally relevant and we show that the learned sequences are robustly\nreplayed during a regime of spontaneous activity.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 11:54:20 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 05:40:07 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Maes", "Amadeus", ""], ["Barahona", "Mauricio", ""], ["Clopath", "Claudia", ""]]}, {"id": "1907.08946", "submitter": "Misha Tsodyks", "authors": "Antonios Georgiou, Mikhail Katkov, Misha Tsodyks", "title": "Retroactive Interference Model of Power-Law Forgetting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Memory and forgetting constitute two sides of the same coin, and although the\nfirst has been rigorously investigated, the latter is often overlooked. A\nnumber of experiments under the realm of psychology and experimental\nneuroscience have described the properties of forgetting in humans and animals,\nshowing that forgetting exhibits a power-law relationship with time. These\nresults indicate a counter-intuitive property of forgetting, namely that old\nmemories are more stable than younger ones. We have devised a phenomenological\nmodel that is based on the principle of retroactive interference, driven by a\nmulti-dimensional valence measure for acquired memories. The model has only one\nfree integer parameter and can be solved analytically. We performed recognition\nexperiments with long streams of words were performed, resulting in a good\nmatch to a five-dimensional version of the model.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 09:49:23 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Georgiou", "Antonios", ""], ["Katkov", "Mikhail", ""], ["Tsodyks", "Misha", ""]]}, {"id": "1907.08977", "submitter": "Saugat Bhattacharyya", "authors": "Saugat Bhattacharyya, Mitsuhiro Hayashibe", "title": "Systematic Enhancement of Functional Connectivity in Brain-Computer\n  Interfacing using Common Spatial Patterns and Tangent Space Mapping", "comments": "Pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Functional connectivity of cognitive tasks allows researchers to analyse the\ninteraction mapping occurring between different regions of the brain using\nelectroencephalography (EEG) signals. Standard practice in functional\nconnectivity involve studying the electrode pair interactions across several\ntrials. As the cognitive task always involves the human factor, it is\ninevitable to have lower quality data from the brain signals influenced by the\nsubject concentration or other mental states which can occur anytime over the\nwhole experimental trials. The connectivity among electrodes are heavily\ninfluenced by these low quality EEG. In this paper, we aim at enhancing the\nfunctional connectivity of mental tasks by implementing a classification step\nin the process to remove those incorrect EEG trials from the available set. The\nclassification step removes the trials which were mis-classified or had a low\nprobability of occurrence to extract only reliable EEG trials. Through our\napproach, we have successfully improved the separability among graph parameters\nfor different mental tasks. We also observe an improvement in the readability\nof the connectivity by focusing only on a group of selected channels rather\nthan employing all the channels.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 14:04:33 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Bhattacharyya", "Saugat", ""], ["Hayashibe", "Mitsuhiro", ""]]}, {"id": "1907.09019", "submitter": "Eric Sun", "authors": "Eric D. Sun and Ron Dekel", "title": "ImageNet-trained deep neural network exhibits illusion-like response to\n  the Scintillating Grid", "comments": "Supplementary material at end of document", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural network (DNN) models for computer vision are now capable of\nhuman-level object recognition. Consequently, similarities in the performance\nand vulnerabilities of DNN and human vision are of great interest. Here we\ncharacterize the response of the VGG-19 DNN to images of the Scintillating Grid\nvisual illusion, in which white dots are perceived to be partially black. We\nobserved a significant deviation from the expected monotonic relation between\nVGG-19 representational dissimilarity and dot whiteness in the Scintillating\nGrid. That is, a linear increase in dot whiteness leads to a non-linear\nincrease and then, remarkably, a decrease (non-monotonicity) in\nrepresentational dissimilarity. In control images, mostly monotonic relations\nbetween representational dissimilarity and dot whiteness were observed.\nFurthermore, the dot whiteness level corresponding to the maximal\nrepresentational dissimilarity (i.e. onset of non-monotonic dissimilarity)\nmatched closely with that corresponding to the onset of illusion perception in\nhuman observers. As such, the non-monotonic response in the DNN is a potential\nmodel correlate for human illusion perception.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 19:14:47 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 02:13:38 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Sun", "Eric D.", ""], ["Dekel", "Ron", ""]]}, {"id": "1907.09209", "submitter": "Leo Cazenille Dr", "authors": "Leo Cazenille, Nicolas Bredeche, Jos\\'e Halloy", "title": "Automatic Calibration of Artificial Neural Networks for Zebrafish\n  Collective Behaviours using a Quality Diversity Algorithm", "comments": "8 pages, 4 figures, 1 table", "journal-ref": "Conference on Biomimetic and Biohybrid Systems. Springer, Cham,\n  2019", "doi": "10.1007/978-3-030-24741-6_4", "report-no": null, "categories": "cs.NE cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last two decades, various models have been proposed for fish\ncollective motion. These models are mainly developed to decipher the biological\nmechanisms of social interaction between animals. They consider very simple\nhomogeneous unbounded environments and it is not clear that they can simulate\naccurately the collective trajectories. Moreover when the models are more\naccurate, the question of their scalability to either larger groups or more\nelaborate environments remains open. This study deals with learning how to\nsimulate realistic collective motion of collective of zebrafish, using\nreal-world tracking data. The objective is to devise an agent-based model that\ncan be implemented on an artificial robotic fish that can blend into a\ncollective of real fish. We present a novel approach that uses Quality\nDiversity algorithms, a class of algorithms that emphasise exploration over\npure optimisation. In particular, we use CVT-MAP-Elites, a variant of the\nstate-of-the-art MAP-Elites algorithm for high dimensional search space.\nResults show that Quality Diversity algorithms not only outperform classic\nevolutionary reinforcement learning methods at the macroscopic level (i.e.\ngroup behaviour), but are also able to generate more realistic biomimetic\nbehaviours at the microscopic level (i.e. individual behaviour).\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 10:04:22 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Cazenille", "Leo", ""], ["Bredeche", "Nicolas", ""], ["Halloy", "Jos\u00e9", ""]]}, {"id": "1907.09270", "submitter": "Afshin Montakhab", "authors": "Mahsa Khoshkhou and Afshin Montakhab", "title": "Spike-timing-dependent plasticity with axonal delay tunes networks of\n  Izhikevich neurons to the edge of synchronization transition with scale-free\n  avalanches", "comments": "9 pages, 7 figures, 42 references", "journal-ref": "Front. Syst. Neurosci., 04 December 2019", "doi": "10.3389/fnsys.2019.00073", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Critical brain hypothesis has been intensively studied both in experimental\nand theoretical neuroscience over the past two decades. However, some important\nquestions still remain: (i) What is the critical point the brain operates at?\n(ii) What is the regulatory mechanism that brings about and maintains such a\ncritical state? (iii) The critical state is characterized by scale-invariant\nbehavior which is seemingly at odds with definitive brain oscillations? In this\nwork we consider a biologically motivated model of Izhikevich neuronal network\nwith chemical synapses interacting via spike-timingdependent plasticity (STDP)\nas well as axonal time delay. Under generic and physiologically relevant\nconditions we show that the system is organized and maintained around a\nsynchronization transition point as opposed to an activity transition point\nassociated with an absorbing state phase transition. However, such a state\nexhibits experimentally relevant signs of critical dynamics including\nscale-free avalanches with finite-size scaling as well as branching ratios.\nWhile the system displays stochastic oscillations with highly correlated\nfluctuations, it also displays dominant frequency modes seen as sharp peaks in\nthe power spectrum. The role of STDP as well as time delay is crucial in\nachieving and maintaining such critical dynamics, while the role of inhibition\nis not as crucial. In this way we provide definitive answers to all three\nquestions posed above. We also show that one can achieve supercritical or\nsubcritical dynamics if one changes the average time delay associated with\naxonal conduction.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 12:28:45 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Khoshkhou", "Mahsa", ""], ["Montakhab", "Afshin", ""]]}, {"id": "1907.09533", "submitter": "Ozan Ozdenizci", "authors": "Ozan \\\"Ozdenizci, Timm Meyer, Felix Wichmann, Jan Peters, Bernhard\n  Sch\\\"olkopf, M\\\"ujdat \\c{C}etin, Moritz Grosse-Wentrup", "title": "Neural Signatures of Motor Skill in the Resting Brain", "comments": "2019 IEEE International Conference on Systems, Man, and Cybernetics\n  (IEEE SMC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stroke-induced disturbances of large-scale cortical networks are known to be\nassociated with the extent of motor deficits. We argue that identifying brain\nnetworks representative of motor behavior in the resting brain would provide\nsignificant insights for current neurorehabilitation approaches. Particularly,\nwe aim to investigate the global configuration of brain rhythms and their\nrelation to motor skill, instead of learning performance as broadly studied. We\nempirically approach this problem by conducting a three-dimensional physical\nspace visuomotor learning experiment during electroencephalographic (EEG) data\nrecordings with thirty-seven healthy participants. We demonstrate that\nacross-subjects variations in average movement smoothness as the quantified\nmeasure of subjects' motor skills can be predicted from the global\nconfiguration of resting-state EEG alpha-rhythms (8-14 Hz) recorded prior to\nthe experiment. Importantly, this neural signature of motor skill was found to\nbe orthogonal to (independent of) task -- as well as to learning-related\nchanges in alpha-rhythms, which we interpret as an organizing principle of the\nbrain. We argue that disturbances of such configurations in the brain may\ncontribute to motor deficits in stroke, and that reconfiguring stroke patients'\nbrain rhythms by neurofeedback may enhance post-stroke neurorehabilitation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:09:13 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["\u00d6zdenizci", "Ozan", ""], ["Meyer", "Timm", ""], ["Wichmann", "Felix", ""], ["Peters", "Jan", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["\u00c7etin", "M\u00fcjdat", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1907.09586", "submitter": "Vince Grolmusz", "authors": "Mate Fellner and Balint Varga and Vince Grolmusz", "title": "Good Neighbors, Bad Neighbors: The Frequent Network Neighborhood Mapping\n  of the Hippocampus Enlightens Several Structural Factors of the Human\n  Intelligence on a 414-Subject Cohort", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human connectome has become the very frequent subject of study of\nbrain-scientists, psychologists, and imaging experts in the last decade. With\ndiffusion magnetic resonance imaging techniques, unified with advanced data\nprocessing algorithms, today we are able to compute braingraphs with several\nhundred, anatomically identified nodes and thousands of edges, corresponding to\nthe anatomical connections of the brain. The analysis of these graphs without\nrefined mathematical tools is hopeless. These tools need to address the high\nerror rate of the MRI processing workflow, and need to find structural causes\nor at least correlations of psychological properties and cerebral connections.\nUntil now, structural connectomics was only rarely able identifying such causes\nor correlations. In the present work, we study the frequent neighbor sets of\nthe most deeply investigated brain area, the hippocampus. By applying the\nFrequent Network Neighborhood mapping method, we identified frequent\nneighbor-sets of the hippocampus, which may influence numerous psychological\nparameters, including intelligence-related ones. We have found neighbor sets,\nwhich have significantly higher frequency in subjects with high-scored Penn\nMatrix tests, and with low-scored Penn Word Memory tests. Our study utilizes\nthe braingraphs, computed from the imaging data of the Human Connectome\nProject's 414 subjects, each with 463 anatomically identified nodes.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 21:30:44 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Fellner", "Mate", ""], ["Varga", "Balint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1907.10009", "submitter": "Fabrizio De Vico Fallani", "authors": "Catalina Obando, Charlotte Rosso, Joshua Siegel, Maurizio Corbetta and\n  Fabrizio De Vico Fallani", "title": "Temporal connection signatures of human brain networks after stroke", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Plasticity after stroke is a complex phenomenon initiated by the functional\nreorganization of the brain, especially in the perilesional tissue. At\nmacroscales, the reestablishment of segregation within the affected hemisphere\nand interhemispheric integration has been extensively documented in the\nreconfiguration of brain networks. However, the local connection mechanisms\ngenerating such global network changes are still largely unknown as well as\ntheir potential to better predict the outcome of patients. To address this\nquestion, time must be considered as a formal variable of the problem and not\njust a simple repeated observation. Here, we hypothesize that the temporal\nformation of basic connection blocks such as intermodule edges and intramodule\ntriangles would be sufficient to determine the large-scale brain reorganization\nafter stroke. To test our hypothesis, we adopted a statistical approach based\non temporal exponential random graph models (tERGMs). First, we validated the\noverall performance on synthetic time-varying networks simulating the\nreconfiguration process after stroke. Then, using longitudinal functional\nconnectivity measurements of resting-state brain activity, we showed that both\nthe formation of triangles within the affected hemisphere and interhemispheric\nlinks are sufficient to reproduce the longitudinal brain network changes from 2\nweeks to 1 year after the stroke. Finally, we showed that these temporal\nconnection mechanisms are over-expressed in the subacute phase as compared to\nhealthy controls and predicted the chronic language and visual outcome\nrespectively in patients with subcortical and cortical lesions, whereas static\napproaches failed to do so. Our results indicate the importance of considering\ntime-varying connection properties when modeling dynamic complex systems and\nprovide fresh insights into the network mechanisms of stroke recovery.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 17:07:50 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Obando", "Catalina", ""], ["Rosso", "Charlotte", ""], ["Siegel", "Joshua", ""], ["Corbetta", "Maurizio", ""], ["Fallani", "Fabrizio De Vico", ""]]}, {"id": "1907.10060", "submitter": "Massimiliano Zanin", "authors": "Massimiliano Zanin, Bahar G\\\"untekin, Tuba Akt\\\"urk, L\\\"utf\\\"u\n  Hano\\u{g}lu, David Papo", "title": "Time irreversibility of resting brain activity in the healthy brain and\n  pathology", "comments": "27 pages, under consideration", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterising brain activity at rest is of paramount importance to our\nunderstanding both of general principles of brain functioning and of the way\nbrain dynamics is affected in the presence of neurological or psychiatric\npathologies. We measured the time-reversal symmetry of spontaneous\nelectroencephalographic brain activity recorded from three groups of patients\nand their respective control group under two experimental conditions (eyes open\nand closed). We evaluated differences in time irreversibility in terms of\npossible underlying physical generating mechanisms. The results showed that\nresting brain activity is generically time-irreversible at sufficiently long\ntime scales, and that brain pathology is generally associated with a reduction\nin time-asymmetry, albeit with pathology-specific patterns. The significance of\nthese results and their possible dynamical aetiology are discussed. Some\nimplications of the differential modulation of time asymmetry by pathology and\nexperimental condition are examined.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 16:37:55 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Zanin", "Massimiliano", ""], ["G\u00fcntekin", "Bahar", ""], ["Akt\u00fcrk", "Tuba", ""], ["Hano\u011flu", "L\u00fctf\u00fc", ""], ["Papo", "David", ""]]}, {"id": "1907.10879", "submitter": "Pau Vilimelis Aceituno", "authors": "Pau Vilimelis Aceituno and Masud Ehsani and J\\\"urgen Jost", "title": "Synaptic Time-Dependent Plasticity Leads to Efficient Coding of\n  Predictions", "comments": "27 Pages, 5 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latency reduction of postsynaptic spikes is a well-known effect of Synaptic\nTime-Dependent Plasticity. We expand this notion for long postsynaptic spike\ntrains, showing that, for a fixed input spike train, STDP reduces the number of\npostsynaptic spikes and concentrates the remaining ones. Then we study the\nconsequences of this phenomena in terms of coding, finding that this mechanism\nimproves the neural code by increasing the signal-to-noise ratio and lowering\nthe metabolic costs of frequent stimuli. Finally, we illustrate that the\nreduction of postsynaptic latencies can lead to the emergence of predictions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 07:46:22 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Aceituno", "Pau Vilimelis", ""], ["Ehsani", "Masud", ""], ["Jost", "J\u00fcrgen", ""]]}, {"id": "1907.10944", "submitter": "Alexander Iomin", "authors": "Alexander Iomin", "title": "Richardson diffusion in neurons", "comments": null, "journal-ref": "Physical Review E 100, 010104(R) (2019)", "doi": "10.1103/PhysRevE.100.010104", "report-no": null, "categories": "physics.bio-ph cond-mat.dis-nn cond-mat.soft cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of an initial wave packed affected by random noise is considered\nin the framework of a comb model. The model is relevant to a diffusion problem\nin neurons where the transport of ions can be accelerated by an external random\nfield due to synapse fluctuations. In the present specific case, it acts as\nboundary conditions, which lead to a reaction transport equation with\nmultiplicative noise. The temporal behavior of the mean squared displacement is\nestimated analytically, and it is shown that the spreading of the initial wave\npacket corresponds to Richardson diffusion.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 10:14:13 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Iomin", "Alexander", ""]]}, {"id": "1907.11075", "submitter": "Andrew Warrington", "authors": "Andrew Warrington, Arthur Spencer, Frank Wood", "title": "The Virtual Patch Clamp: Imputing C. elegans Membrane Potentials from\n  Calcium Imaging", "comments": "Includes Supplementary Materials", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a stochastic whole-brain and body simulator of the nematode\nroundworm Caenorhabditis elegans (C. elegans) and show that it is sufficiently\nregularizing to allow imputation of latent membrane potentials from partial\ncalcium fluorescence imaging observations. This is the first attempt we know of\nto \"complete the circle,\" where an anatomically grounded whole-connectome\nsimulator is used to impute a time-varying \"brain\" state at single-cell\nfidelity from covariates that are measurable in practice. The sequential Monte\nCarlo (SMC) method we employ not only enables imputation of said latent states\nbut also presents a strategy for learning simulator parameters via variational\noptimization of the noisy model evidence approximation provided by SMC. Our\nimputation and parameter estimation experiments were conducted on distributed\nsystems using novel implementations of the aforementioned techniques applied to\nsynthetic data of dimension and type representative of that which are measured\nin laboratories currently.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:57:39 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Warrington", "Andrew", ""], ["Spencer", "Arthur", ""], ["Wood", "Frank", ""]]}, {"id": "1907.11297", "submitter": "Emma Towlson", "authors": "Emma K. Towlson and Albert-L\\'aszl\\'o Barab\\'asi", "title": "Synthetic ablations in the C. elegans nervous system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic lethality, the finding that the simultaneous knockout of two or\nmore individually non-essential genes leads to cell or organism death, has\noffered a systematic framework to explore cellular function, and also offered\ntherapeutic applications. Yet, the concept lacks its parallel in neuroscience -\na systematic knowledge base on the role of double or higher order ablations in\nthe functioning of a neural system. Here, we use the framework of network\ncontrol to systematically predict the ablation of neuron pairs and triplets. We\nfind that surprisingly small sets of 58 pairs and 46 triplets can reduce muscle\ncontrollability, and that these sets are localised in the nervous system in\ndistinct groups. Further, they lead to highly specific experimentally testable\npredictions about mechanisms of loss of control, and which muscle cells are\nexpected to experience this loss.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 20:08:15 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Towlson", "Emma K.", ""], ["Barab\u00e1si", "Albert-L\u00e1szl\u00f3", ""]]}, {"id": "1907.11403", "submitter": "Ikkyu Aihara", "authors": "Kaiichiro Ota, Ikkyu Aihara, Toshio Aoyagi", "title": "Interaction Mechanisms Quantified from Dynamical Features of Frog\n  Choruses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction mechanism in the acoustic communication of actual animals is\ninvestigated by combining mathematical modeling and empirical data. Here we use\na deterministic mathematical model (a phase oscillator model) to describe the\ninteraction mechanism underlying the choruses of male Japanese tree frogs (Hyla\njaponica) in which the male frogs attempt to avoid call overlaps with each\nother due to acoustic communication. The mathematical model with a general\ninteraction term is identified by a Bayesian approach from multiple audio\nrecordings on the choruses of three male frogs. The identified model\nqualitatively reproduces the stationary and dynamical features of the empirical\ndata, supporting the validity of the model identification. In addition, we\nquantify the magnitude of attention paid among the male frogs from the\nidentified model, and then analyze the relationship between the attention and\nbehavioral parameters by using a statistical model. The analysis demonstrates\nthe biologically valid relationship about the negative correlation between the\nattention and inter-frog distance, and also indicates the existence of a\nbehavioral strategy that the male frogs selectively pay attention towards a\nless attractive male frog so as to utilize the advantage of their\nattractiveness for effective mate attraction.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 07:10:35 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Ota", "Kaiichiro", ""], ["Aihara", "Ikkyu", ""], ["Aoyagi", "Toshio", ""]]}, {"id": "1907.11570", "submitter": "Julien Modolo", "authors": "Julien Modolo, Mahmoud Hassan, Fabrice Wendling, Pascal Benquet", "title": "Decoding the circuitry of consciousness: from local microcircuits to\n  brain-scale networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the physiological processes underlying the emergence and\nmaintenance of consciousness is one of the most fundamental problems of\nneuroscience, with implications ranging from fundamental neuroscience to the\ntreatment of patients with disorders of consciousness (DOC). One major\nchallenge is to understand how cortical circuits at drastically different\nspatial scales, from local networks to brain-scale networks, operate in concert\nto enable consciousness, and how those processes are impaired in DOC patients.\nIn this review, we attempt to relate available neurophysiological and clinical\ndata with existing theoretical models of consciousness, while linking the\nmicro- and macro-circuit levels. First, we address the relationships between\nawareness and wakefulness on the one hand, and cortico-cortical, and\nthalamo-cortical connectivity on the other hand. Second, we discuss the role of\nthree main types of GABAergic interneurons in specific circuits responsible for\nthe dynamical re-organization of functional networks. Third, we explore\nadvances in the functional role of nested oscillations for neural\nsynchronization and communication, emphasizing the importance of the balance\nbetween local (high-frequency) and distant (low-frequency) activity for\nefficient information processing. The clinical implications of these\ntheoretical considerations are presented. We propose that such cellular-scale\nmechanisms could extend current theories of consciousness.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 13:31:26 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Modolo", "Julien", ""], ["Hassan", "Mahmoud", ""], ["Wendling", "Fabrice", ""], ["Benquet", "Pascal", ""]]}, {"id": "1907.11609", "submitter": "Michele Giugliano", "authors": "Daniele Linaro, Gabriel K. Ocker, Brent Doiron, Michele Giugliano", "title": "Correlation transfer by layer 5 cortical neurons under recreated\n  synaptic inputs in vitro", "comments": "47 pages, 10 figures", "journal-ref": "Journal of Neuroscience 25 July 2019, 3169-18", "doi": "10.1523/JNEUROSCI.3169-18.2019", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlated electrical activity in neurons is a prominent characteristic of\ncortical microcircuits. Despite a growing amount of evidence concerning both\nspike-count and subthreshold membrane potential pairwise correlations, little\nis known about how different types of cortical neurons convert correlated\ninputs into correlated outputs. We studied pyramidal neurons and two classes of\nGABAergic interneurons of layer 5 in neocortical brain slices obtained from\nrats of both sexes, and we stimulated them with biophysically realistic\ncorrelated inputs, generated using dynamic clamp. We found that the\nphysiological differences between cell types manifested unique features in\ntheir capacity to transfer correlated inputs. We used linear response theory\nand computational modeling to gain clear insights into how cellular properties\ndetermine both the gain and timescale of correlation transfer, thus tying\nsingle-cell features with network interactions. Our results provide further\nground for the functionally distinct roles played by various types of neuronal\ncells in the cortical microcircuit.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 14:56:32 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Linaro", "Daniele", ""], ["Ocker", "Gabriel K.", ""], ["Doiron", "Brent", ""], ["Giugliano", "Michele", ""]]}, {"id": "1907.11885", "submitter": "Kai Qiao", "authors": "Kai Qiao, Chi Zhang, Jian Chen, Linyuan Wang, Li Tong, Bin Yan", "title": "Effective and efficient ROI-wise visual encoding using an end-to-end CNN\n  regression model and selective optimization", "comments": "under review in Computational Intelligence and Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, visual encoding based on functional magnetic resonance imaging\n(fMRI) have realized many achievements with the rapid development of deep\nnetwork computation. Visual encoding model is aimed at predicting brain\nactivity in response to presented image stimuli. Currently, visual encoding is\naccomplished mainly by firstly extracting image features through convolutional\nneural network (CNN) model pre-trained on computer vision task, and secondly\ntraining a linear regression model to map specific layer of CNN features to\neach voxel, namely voxel-wise encoding. However, the two-step manner model,\nessentially, is hard to determine which kind of well features are well linearly\nmatched for beforehand unknown fMRI data with little understanding of human\nvisual representation. Analogizing computer vision mostly related human vision,\nwe proposed the end-to-end convolution regression model (ETECRM) in the region\nof interest (ROI)-wise manner to accomplish effective and efficient visual\nencoding. The end-to-end manner was introduced to make the model automatically\nlearn better matching features to improve encoding performance. The ROI-wise\nmanner was used to improve the encoding efficiency for many voxels. In\naddition, we designed the selective optimization including self-adapting weight\nlearning and weighted correlation loss, noise regularization to avoid\ninterfering of ineffective voxels in ROI-wise encoding. Experiment demonstrated\nthat the proposed model obtained better predicting accuracy than the two-step\nmanner of encoding models. Comparative analysis implied that end-to-end manner\nand large volume of fMRI data may drive the future development of visual\nencoding.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 10:09:05 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Qiao", "Kai", ""], ["Zhang", "Chi", ""], ["Chen", "Jian", ""], ["Wang", "Linyuan", ""], ["Tong", "Li", ""], ["Yan", "Bin", ""]]}, {"id": "1907.12071", "submitter": "Xiaohan Lin", "authors": "Yuanyuan Mi, Xiaohan Lin, Xiaolong Zou, Zilong Ji, Tiejun Huang, Si Wu", "title": "Spatiotemporal Information Processing with a Reservoir Decision-making\n  Network", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal information processing is fundamental to brain functions. The\npresent study investigates a canonic neural network model for spatiotemporal\npattern recognition. Specifically, the model consists of two modules, a\nreservoir subnetwork and a decision-making subnetwork. The former projects\ncomplex spatiotemporal patterns into spatially separated neural\nrepresentations, and the latter reads out these neural representations via\nintegrating information over time; the two modules are combined together via\nsupervised-learning using known examples. We elucidate the working mechanism of\nthe model and demonstrate its feasibility for discriminating complex\nspatiotemporal patterns. Our model reproduces the phenomenon of recognizing\nlooming patterns in the neural system, and can learn to discriminate gait with\nvery few training examples. We hope this study gives us insight into\nunderstanding how spatiotemporal information is processed in the brain and\nhelps us to develop brain-inspired application algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 11:04:34 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Mi", "Yuanyuan", ""], ["Lin", "Xiaohan", ""], ["Zou", "Xiaolong", ""], ["Ji", "Zilong", ""], ["Huang", "Tiejun", ""], ["Wu", "Si", ""]]}, {"id": "1907.12309", "submitter": "Sushrut Thorat", "authors": "Sushrut Thorat, Giacomo Aldegheri, Marcel A. J. van Gerven, Marius V.\n  Peelen", "title": "Modulation of early visual processing alleviates capacity limits in\n  solving multiple tasks", "comments": "Main paper - 4 pages, 2 figures; Appendix - 2 pages, 2 figures;\n  Published at the 2019 Conference on Cognitive Computational Neuroscience", "journal-ref": null, "doi": "10.32470/CCN.2019.1229-0", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In daily life situations, we have to perform multiple tasks given a visual\nstimulus, which requires task-relevant information to be transmitted through\nour visual system. When it is not possible to transmit all the possibly\nrelevant information to higher layers, due to a bottleneck, task-based\nmodulation of early visual processing might be necessary. In this work, we\nreport how the effectiveness of modulating the early processing stage of an\nartificial neural network depends on the information bottleneck faced by the\nnetwork. The bottleneck is quantified by the number of tasks the network has to\nperform and the neural capacity of the later stage of the network. The\neffectiveness is gauged by the performance on multiple object detection tasks,\nwhere the network is trained with a recent multi-task optimization scheme. By\nassociating neural modulations with task-based switching of the state of the\nnetwork and characterizing when such switching is helpful in early processing,\nour results provide a functional perspective towards understanding why\ntask-based modulation of early neural processes might be observed in the\nprimate visual cortex\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 09:56:40 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 08:10:26 GMT"}, {"version": "v3", "created": "Mon, 23 Sep 2019 17:42:12 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Thorat", "Sushrut", ""], ["Aldegheri", "Giacomo", ""], ["van Gerven", "Marcel A. J.", ""], ["Peelen", "Marius V.", ""]]}, {"id": "1907.12430", "submitter": "Alexander V Terekhov", "authors": "Alexander V. Terekhov and J. Kevin O'Regan", "title": "Learning abstract perceptual notions: the example of space", "comments": "arXiv admin note: text overlap with arXiv:1308.2124", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are extremely swift learners. We are able to grasp highly abstract\nnotions, whether they come from art perception or pure mathematics. Current\nmachine learning techniques demonstrate astonishing results in extracting\npatterns in information. Yet the abstract notions we possess are more than just\nstatistical patterns in the incoming information. Sensorimotor theory suggests\nthat they represent functions, laws, describing how the information can be\ntransformed, or, in other words, they represent the statistics of sensorimotor\nchanges rather than sensory inputs themselves. The aim of our work is to\nsuggest a way for machine learning and sensorimotor theory to benefit from each\nother so as to pave the way toward new horizons in learning. We show in this\nstudy that a highly abstract notion, that of space, can be seen as a collection\nof laws of transformations of sensory information and that these laws could in\ntheory be learned by a naive agent. As an illustration we do a one-dimensional\nsimulation in which an agent extracts spatial knowledge in the form of\ninternalized (\"sensible\") rigid displacements. The agent uses them to encode\nits own displacements in a way which is isometrically related to external\nspace. Though the algorithm allowing acquisition of rigid displacements is\ndesigned \\emph{ad hoc}, we believe it can stimulate the development of\nunsupervised learning techniques leading to similar results.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 17:57:54 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Terekhov", "Alexander V.", ""], ["O'Regan", "J. Kevin", ""]]}, {"id": "1907.12830", "submitter": "Daniel Lopez-Martinez", "authors": "Daniel Lopez-Martinez, Ke Peng, Arielle Lee, David Borsook, and\n  Rosalind Picard", "title": "Pain Detection with fNIRS-Measured Brain Signals: A Personalized Machine\n  Learning Approach Using the Wavelet Transform and Bayesian Hierarchical\n  Modeling with Dirichlet Process Priors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently self-report pain ratings are the gold standard in clinical pain\nassessment. However, the development of objective automatic measures of pain\ncould substantially aid pain diagnosis and therapy. Recent neuroimaging studies\nhave shown the potential of functional near-infrared spectroscopy (fNIRS) for\npain detection. This is a brain-imaging technique that provides non-invasive,\nlong-term measurements of cortical hemoglobin concentration changes. In this\nstudy, we focused on fNIRS signals acquired exclusively from the prefrontal\ncortex, which can be accessed unobtrusively, and derived an algorithm for the\ndetection of the presence of pain using Bayesian hierarchical modelling with\nwavelet features. This approach allows personalization of the inference process\nby accounting for inter-participant variability in pain responses. Our work\nhighlights the importance of adopting a personalized approach and supports the\nuse of fNIRS for pain assessment.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 11:03:58 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Lopez-Martinez", "Daniel", ""], ["Peng", "Ke", ""], ["Lee", "Arielle", ""], ["Borsook", "David", ""], ["Picard", "Rosalind", ""]]}, {"id": "1907.13004", "submitter": "Alexander Gomez Villa A. Gomez-Villa", "authors": "Marcelo Bertalm\\'io, Luca Calatroni, Valentina Franceschi, Benedetta\n  Franceschiello, Alexander Gomez-Villa, Dario Prandi", "title": "Visual illusions via neural dynamics: Wilson-Cowan-type models and the\n  efficient representation principle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we have aimed to reproduce supra-threshold perception phenomena,\nspecifically visual illusions, with Wilson-Cowan-type models of neuronal\ndynamics. We have found that it is indeed possible to do so, but that the\nability to replicate visual illusions is related to how well the neural\nactivity equations comply with the efficient representation principle. Our\nfirst contribution is to show that the Wilson-Cowan equations can reproduce a\nnumber of brightness and orientation-dependent illusions, and that the latter\ntype of illusions require that the neuronal dynamics equations consider\nexplicitly the orientation, as expected. Then, we formally prove that there\ncan't be an energy functional that the Wilson-Cowan equations are minimizing,\nbut that a slight modification makes them variational and yields a model that\nis consistent with the efficient representation principle. Finally, we show\nthat this new model provides a better reproduction of visual illusions than the\noriginal Wilson-Cowan formulation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 15:15:07 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 15:41:37 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Bertalm\u00edo", "Marcelo", ""], ["Calatroni", "Luca", ""], ["Franceschi", "Valentina", ""], ["Franceschiello", "Benedetta", ""], ["Gomez-Villa", "Alexander", ""], ["Prandi", "Dario", ""]]}, {"id": "1907.13046", "submitter": "Alexander Gomez Villa A. Gomez-Villa", "authors": "Alexander Gomez-Villa, Marcelo Bertalm\\'io, Jes\\'us Malo", "title": "Visual Information flow in Wilson-Cowan networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the communication efficiency of a\npsychophysically-tuned cascade of Wilson-Cowan and Divisive Normalization\nlayers that simulate the retina-V1 pathway. This is the first analysis of\nWilson-Cowan networks in terms of multivariate total correlation. The\nparameters of the cortical model have been derived through the relation between\nthe steady state of the Wilson-Cowan model and the Divisive Normalization\nmodel.\n  The communication efficiency has been analyzed in two ways: First, we provide\nan analytical expression for the reduction of the total correlation among the\nresponses of a V1-like population after the application of the Wilson-Cowan\ninteraction. Second, we empirically study the efficiency with visual stimuli\nand statistical tools that were not available before: (1) we use a recent,\nradiometrically calibrated, set of natural scenes, and (2) we use a recent\ntechnique to estimate the multivariate total correlation in bits from sets of\nvisual responses which only involves univariate operations, thus giving better\nestimates of the redundancy.\n  The theoretical and the empirical results show that although this cascade of\nlayers was not optimized for statistical independence in any way, the\nredundancy between the responses gets substantially reduced along the neural\npathway. Specifically, we show that (1)~the efficiency of a Wilson-Cowan\nnetwork is similar to its equivalent Divisive Normalization model, (2) while\ninitial layers (Von-Kries adaptation and Weber-like brightness) contribute to\nunivariate equalization, the bigger contributions to the reduction in total\ncorrelation come from the computation of nonlinear local contrast and the\napplication of local oriented filters, and (3)~psychophysically-tuned models\nare more efficient (reduce more total correlation) in the more populated\nregions of the luminance-contrast plane.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 16:08:29 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Gomez-Villa", "Alexander", ""], ["Bertalm\u00edo", "Marcelo", ""], ["Malo", "Jes\u00fas", ""]]}, {"id": "1907.13118", "submitter": "Kristine Heiney", "authors": "Kristine Heiney, Ola Huse Ramstad, Ioanna Sandvig, Axel Sandvig,\n  Stefano Nichele", "title": "Assessment and manipulation of the computational capacity of in vitro\n  neuronal networks through criticality in neuronal avalanches", "comments": "8 pages, 3 figures, submitted to IEEE SSCI2019 ALIFE Symposium. arXiv\n  admin note: substantial text overlap with arXiv:1907.02351", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we report the preliminary analysis of the electrophysiological\nbehavior of in vitro neuronal networks to identify when the networks are in a\ncritical state based on the size distribution of network-wide avalanches of\nactivity. The results presented here demonstrate the importance of selecting\nappropriate parameters in the evaluation of the size distribution and indicate\nthat it is possible to perturb networks showing highly synchronized---or\nsupercritical---behavior into the critical state by increasing the level of\ninhibition in the network. The classification of critical versus non-critical\nnetworks is valuable in identifying networks that can be expected to perform\nwell on computational tasks, as criticality is widely considered to be the\nstate in which a system is best suited for computation. This type of analysis\nis expected to enable the identification of networks that are well-suited for\ncomputation and the classification of networks as perturbed or healthy. This\nstudy is part of a larger research project, the overarching aim of which is to\ndevelop computational models that are able to reproduce target behaviors\nobserved in in vitro neuronal networks. These models will ultimately be used to\naid in the realization of these behaviors in nanomagnet arrays to be used in\nnovel computing hardwares.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 12:33:41 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Heiney", "Kristine", ""], ["Ramstad", "Ola Huse", ""], ["Sandvig", "Ioanna", ""], ["Sandvig", "Axel", ""], ["Nichele", "Stefano", ""]]}, {"id": "1907.13223", "submitter": "Iulia Comsa", "authors": "Iulia M. Comsa, Krzysztof Potempa, Luca Versari, Thomas Fischbacher,\n  Andrea Gesmundo and Jyrki Alakuijala", "title": "Temporal Coding in Spiking Neural Networks with Alpha Synaptic Function:\n  Learning with Backpropagation", "comments": "Open-source code related to this paper is available at\n  https://github.com/google/ihmehimmeli v2: Added references and added some\n  clarifications for the methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The timing of individual neuronal spikes is essential for biological brains\nto make fast responses to sensory stimuli. However, conventional artificial\nneural networks lack the intrinsic temporal coding ability present in\nbiological networks. We propose a spiking neural network model that encodes\ninformation in the relative timing of individual neuron spikes. In\nclassification tasks, the output of the network is indicated by the first\nneuron to spike in the output layer. This temporal coding scheme allows the\nsupervised training of the network with backpropagation, using locally exact\nderivatives of the postsynaptic spike times with respect to presynaptic spike\ntimes. The network operates using a biologically-plausible alpha synaptic\ntransfer function. Additionally, we use trainable synchronisation pulses that\nprovide bias, add flexibility during training and exploit the decay part of the\nalpha function. We show that such networks can be trained successfully on noisy\nBoolean logic tasks and on the MNIST dataset encoded in time. The results show\nthat the spiking neural network outperforms comparable spiking models on MNIST\nand achieves similar quality to fully connected conventional networks with the\nsame architecture. We also find that the spiking network spontaneously\ndiscovers two operating regimes, mirroring the accuracy-speed trade-off\nobserved in human decision-making: a slow regime, where a decision is taken\nafter all hidden neurons have spiked and the accuracy is very high, and a fast\nregime, where a decision is taken very fast but the accuracy is lower. These\nresults demonstrate the computational power of spiking networks with biological\ncharacteristics that encode information in the timing of individual neurons. By\nstudying temporal coding in spiking networks, we aim to create building blocks\ntowards energy-efficient and more complex biologically-inspired neural\narchitectures.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 21:05:18 GMT"}, {"version": "v2", "created": "Fri, 30 Aug 2019 11:20:25 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 21:34:55 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Comsa", "Iulia M.", ""], ["Potempa", "Krzysztof", ""], ["Versari", "Luca", ""], ["Fischbacher", "Thomas", ""], ["Gesmundo", "Andrea", ""], ["Alakuijala", "Jyrki", ""]]}]