[{"id": "1409.0171", "submitter": "Christian Mayr", "authors": "Christian Mayr, Michael Schultz, Marko Noack, Stephan Henker, Johannes\n  Partzsch, Rene Sch\\\"uffny", "title": "OTA based 200 G{\\Omega} resistance on 700 {\\mu}m2 in 180 nm CMOS for\n  neuromorphic applications", "comments": "8 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generating an exponential decay function with a time constant on the order of\nhundreds of milliseconds is a mainstay for neuromorphic circuits. Usually,\neither subthreshold circuits or RC-decays based on transconductance amplifiers\nare used. In the latter case, transconductances in the 10 pS range are needed.\nHowever, state-of-the-art low-transconductance amplifiers still require too\nmuch circuit area to be applicable in neuromorphic circuits where >100 of these\ntime constant circuits may be required on a single chip. We present a silicon\nverified operational transconductance amplifier that achieves a gm of 5 pS in\nonly 700 {\\mu}m2, a factor of 10-100 less area than current examples. This\nallows a high-density integration of time constant circuits in target\nappliations such as synaptic learning or as driving circuit for neuromorphic\nmemristor arrays.\n", "versions": [{"version": "v1", "created": "Sun, 31 Aug 2014 00:18:08 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Mayr", "Christian", ""], ["Schultz", "Michael", ""], ["Noack", "Marko", ""], ["Henker", "Stephan", ""], ["Partzsch", "Johannes", ""], ["Sch\u00fcffny", "Rene", ""]]}, {"id": "1409.0257", "submitter": "Ralf M Haefner", "authors": "Ralf M. Haefner, Pietro Berkes and J\\'ozsef Fiser", "title": "The implications of perception as probabilistic inference for correlated\n  neural variability during behavior", "comments": "25 pages, 9 figures; improved readability, added figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses two main challenges facing systems neuroscience today:\nunderstanding the nature and function of a) cortical feedback between sensory\nareas and b) correlated variability. Starting from the old idea of perception\nas probabilistic inference, we show how to use knowledge of the psychophysical\ntask to make easily testable predictions for the impact that feedback signals\nhave on early sensory representations. Applying our framework to the\nwell-studied two-alternative forced choice task paradigm, we can explain\nmultiple empirical findings that have been hard to account for by the\ntraditional feedforward model of sensory processing, including the\ntask-dependence of neural response correlations, and the diverging time courses\nof choice probabilities and psychophysical kernels. Our model makes a number of\nnew predictions and, importantly, characterizes a component of correlated\nvariability that represents task-related information rather than\nperformance-degrading noise. It also demonstrates a normative way to integrate\nsensory and cognitive components into physiologically testable mathematical\nmodels of perceptual decision-making.\n", "versions": [{"version": "v1", "created": "Sun, 31 Aug 2014 19:32:55 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 18:33:08 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Haefner", "Ralf M.", ""], ["Berkes", "Pietro", ""], ["Fiser", "J\u00f3zsef", ""]]}, {"id": "1409.0470", "submitter": "Tom Froese", "authors": "Alexander Woodward, Tom Froese, Takashi Ikegami", "title": "Neural coordination can be enhanced by occasional interruption of normal\n  firing patterns: A self-optimizing spiking neural network model", "comments": "22 pages, 6 figures; Neural Networks, in press", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state space of a conventional Hopfield network typically exhibits many\ndifferent attractors of which only a small subset satisfy constraints between\nneurons in a globally optimal fashion. It has recently been demonstrated that\ncombining Hebbian learning with occasional alterations of normal neural states\navoids this problem by means of self-organized enlargement of the best basins\nof attraction. However, so far it is not clear to what extent this process of\nself-optimization is also operative in real brains. Here we demonstrate that it\ncan be transferred to more biologically plausible neural networks by\nimplementing a self-optimizing spiking neural network model. In addition, by\nusing this spiking neural network to emulate a Hopfield network with Hebbian\nlearning, we attempt to make a connection between rate-based and temporal\ncoding based neural systems. Although further work is required to make this\nmodel more realistic, it already suggests that the efficacy of the\nself-optimizing process is independent from the simplifying assumptions of a\nconventional Hopfield network. We also discuss natural and cultural processes\nthat could be responsible for occasional alteration of neural firing patterns\nin actual brains\n", "versions": [{"version": "v1", "created": "Mon, 1 Sep 2014 16:20:41 GMT"}], "update_date": "2014-09-02", "authors_parsed": [["Woodward", "Alexander", ""], ["Froese", "Tom", ""], ["Ikegami", "Takashi", ""]]}, {"id": "1409.0655", "submitter": "Florian Gomez", "authors": "Tom Lorimer, Florian Gomez, Ruedi Stoop", "title": "Mammalian cochlea as a physics guided evolution-optimized hearing sensor", "comments": null, "journal-ref": "Scientific Reports 5, 12492 (2015)", "doi": "10.1038/srep12492", "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonlinear physics plays an essential role in hearing, from sound signal\ngeneration to sound sensing to the processing of complex sound environments. We\ndemonstrate that the evolution of the biological hearing sensors demonstrates a\ndramatic reduction in the solution space available for hearing sensors due to\nnonlinear physics principles. More specifically, our analysis hints at that the\ndifferences between amniotic lineages hearing, could be recast into a scaleable\nand a non-scaleable arrangement of nonlinear sound detectors. The scalable\nsolution employed in mammals, as the most advanced design, provides a natural\ncontext that demands the ultimate characterization of complex sounds through\npitch.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 10:25:23 GMT"}, {"version": "v2", "created": "Tue, 18 Nov 2014 15:23:23 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Lorimer", "Tom", ""], ["Gomez", "Florian", ""], ["Stoop", "Ruedi", ""]]}, {"id": "1409.0675", "submitter": "Felix Polyakov", "authors": "Felix Polyakov", "title": "Affine differential geometry and smoothness maximization as tools for\n  identifying geometric movement primitives", "comments": "The current version of the manuscript is result of significant\n  revision. It contains novel solutions, some formulations and explanations\n  have been corrected and in many parts of the text improved. The manuscript\n  now contains discussion about performance of the compromised motor control\n  system in the framework of the theory under consideration", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscientific studies of drawing-like movements usually analyze neural\nrepresentation of either geometric (eg. direction, shape) or temporal (eg.\nspeed) features of trajectories rather than trajectory's representation as a\nwhole. This work is about empirically supported mathematical ideas behind\nsplitting and merging geometric and temporal features which characterize\nbiological movements. Movement primitives supposedly facilitate the efficiency\nof movements' representation in the brain and comply with different criteria\nfor biological movements, among them kinematic smoothness and geometric\nconstraint. Criterion for trajectories' maximal smoothness of arbitrary order\n$n$ is employed, $n = 3$ is the case of the minimum-jerk model. I derive a\nclass of differential equations obeyed by movement paths for which $n$-th order\nmaximally smooth trajectories have constant rate of accumulating geometric\nmeasurement along the drawn path. Constant rate of accumulating equi-affine arc\ncorresponds to compliance with the two-thirds power-law model. Geometric\nmeasurement is invariant under a class of geometric transformations and may be\nchosen to be an arc in certain geometry. Equations' solutions presumably serve\nas candidates for geometric movement primitives. The derived class of\ndifferential equations consists of two parts. The first part is identical for\nall geometric parameterizations of the path. The second part enforces\nconsistency with desired (geometric) parametrization of curves on solutions of\nthe first part. Equations in different geometries in plane and in space and\ntheir known solutions are presented. Connection between geometric invariance,\nmotion smoothness, compositionality and performance of the compromised motor\ncontrol system is discussed. The derived class of differential equations is a\nnovel tool for discovering candidates for geometric movement primitives.\n", "versions": [{"version": "v1", "created": "Tue, 2 Sep 2014 11:50:34 GMT"}, {"version": "v2", "created": "Thu, 16 Oct 2014 18:51:10 GMT"}, {"version": "v3", "created": "Mon, 29 Dec 2014 20:53:43 GMT"}, {"version": "v4", "created": "Wed, 27 Jan 2016 20:47:11 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Polyakov", "Felix", ""]]}, {"id": "1409.1064", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Physical Light as a Metaphor for Inner Light", "comments": "17 pages; In a special issue of Aisthesis\n  (http://www.fupress.net/index.php/aisthesis/index) on \"Giving form through\n  metaphors\"; seeking collaborators in computer graphics, visualization, and\n  optics for further development of these projects. arXiv admin note:\n  substantial text overlap with arXiv:1501.00029", "journal-ref": "Aisthesis, 7(2), 43-61 (2014)", "doi": "10.13128/Aisthesis-15289", "report-no": null, "categories": "q-bio.NC cs.CG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The metaphor between physical light and inner light has a long history that\npermeates diverse languages and cultures. This paper outlines a system for\nusing basic principles from optics to visually represent psychological states\nand processes such as ideation, enlightenment, mindfulness, and fragmentation\nversus integrity, as well as situations that occur between people involving\nphenomena such as honest versus deceptive communication, and understanding\nversus misunderstanding. The paper summarizes two ongoing projects based on\nthis system: The Light and Enlightenment art installation project, and the\nSoultracker virtual reality project. These projects enable people to depict\ntheir inner lives and external worlds including situations and relationships\nwith others, both as they are and as they could be, and explore alternative\npaths for navigating challenges and living to their fullest potential. The\nprojects aim to be of clinical value as therapeutic tools, as well as of\npedagogical value by providing a concrete language for depicting aspects of\nhuman nature that can otherwise seem elusive and intangible.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2014 12:39:00 GMT"}, {"version": "v2", "created": "Mon, 15 Sep 2014 16:16:39 GMT"}, {"version": "v3", "created": "Thu, 22 Jan 2015 17:32:58 GMT"}], "update_date": "2015-01-23", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1409.1801", "submitter": "Stephen Plaza", "authors": "Stephen M. Plaza, Toufiq Parag, Gary B. Huang, Donald J. Olbris,\n  Mathew A. Saunders, Patricia K. Rivlin", "title": "Annotating Synapses in Large EM Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing neuronal circuits at the level of synapses is a central\nproblem in neuroscience and becoming a focus of the emerging field of\nconnectomics. To date, electron microscopy (EM) is the most proven technique\nfor identifying and quantifying synaptic connections. As advances in EM make\nacquiring larger datasets possible, subsequent manual synapse identification\n({\\em i.e.}, proofreading) for deciphering a connectome becomes a major time\nbottleneck. Here we introduce a large-scale, high-throughput, and\nsemi-automated methodology to efficiently identify synapses. We successfully\napplied our methodology to the Drosophila medulla optic lobe, annotating many\nmore synapses than previous connectome efforts. Our approaches are extensible\nand will make the often complicated process of synapse identification\naccessible to a wider-community of potential proofreaders.\n", "versions": [{"version": "v1", "created": "Fri, 5 Sep 2014 13:52:47 GMT"}, {"version": "v2", "created": "Thu, 4 Dec 2014 16:18:01 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Plaza", "Stephen M.", ""], ["Parag", "Toufiq", ""], ["Huang", "Gary B.", ""], ["Olbris", "Donald J.", ""], ["Saunders", "Mathew A.", ""], ["Rivlin", "Patricia K.", ""]]}, {"id": "1409.1892", "submitter": "Ting  Zhao", "authors": "Ting Zhao, Stephen M Plaza", "title": "Automatic Neuron Type Identification by Neurite Localization in the\n  Drosophila Medulla", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mapping the connectivity of neurons in the brain (i.e., connectomics) is a\nchallenging problem due to both the number of connections in even the smallest\norganisms and the nanometer resolution required to resolve them. Because of\nthis, previous connectomes contain only hundreds of neurons, such as in the\nC.elegans connectome. Recent technological advances will unlock the mysteries\nof increasingly large connectomes (or partial connectomes). However, the value\nof these maps is limited by our ability to reason with this data and understand\nany underlying motifs. To aid connectome analysis, we introduce algorithms to\ncluster similarly-shaped neurons, where 3D neuronal shapes are represented as\nskeletons. In particular, we propose a novel location-sensitive clustering\nalgorithm. We show clustering results on neurons reconstructed from the\nDrosophila medulla that show high-accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 5 Sep 2014 18:03:03 GMT"}], "update_date": "2014-09-08", "authors_parsed": [["Zhao", "Ting", ""], ["Plaza", "Stephen M", ""]]}, {"id": "1409.1933", "submitter": "Alessandro Torcini Dr", "authors": "Stefano Luccioli, Eshel Ben-Jacob, Ari Barzilai, Paolo Bonifazi,\n  Alessandro Torcini", "title": "Clique of functional hubs orchestrates population bursts in\n  developmentally regulated neural networks", "comments": "39 pages, 15 figures, to appear in PLOS Computational Biology", "journal-ref": "PLoS Comput Biol 10(9) (2014) e1003823", "doi": "10.1371/journal.pcbi.1003823", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been discovered that single neuron stimulation can impact\nnetwork dynamics in immature and adult neuronal circuits. Here we report a\nnovel mechanism which can explain in neuronal circuits, at an early stage of\ndevelopment, the peculiar role played by a few specific neurons in\npromoting/arresting the population activity. For this purpose, we consider a\nstandard neuronal network model, with short-term synaptic plasticity, whose\npopulation activity is characterized by bursting behavior. The addition of\ndevelopmentally inspired constraints and correlations in the distribution of\nthe neuronal connectivities and excitabilities leads to the emergence of\nfunctional hub neurons, whose stimulation/deletion is critical for the network\nactivity. Functional hubs form a clique, where a precise sequential activation\nof the neurons is essential to ignite collective events without any need for a\nspecific topological architecture. Unsupervised time-lagged firings of\nsupra-threshold cells, in connection with coordinated entrainments of\nnear-threshold neurons, are the key ingredients to orchestrate\n", "versions": [{"version": "v1", "created": "Fri, 5 Sep 2014 20:11:32 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Luccioli", "Stefano", ""], ["Ben-Jacob", "Eshel", ""], ["Barzilai", "Ari", ""], ["Bonifazi", "Paolo", ""], ["Torcini", "Alessandro", ""]]}, {"id": "1409.2046", "submitter": "Vadim Zotev", "authors": "Vadim Zotev, Han Yuan, Masaya Misaki, Raquel Phillips, Kymberly D.\n  Young, Matthew T. Feldner, Jerzy Bodurka", "title": "Correlation between amygdala BOLD activity and frontal EEG asymmetry\n  during real-time fMRI neurofeedback training in patients with depression", "comments": "28 pages, 16 figures, to appear in NeuroImage: Clinical", "journal-ref": "NeuroImage: Clinical 11 (2016) 224-238", "doi": "10.1016/j.nicl.2016.02.003", "report-no": null, "categories": "physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time fMRI neurofeedback (rtfMRI-nf) is an emerging approach for studies\nand novel treatments of major depressive disorder (MDD). EEG performed\nsimultaneously with an rtfMRI-nf procedure allows an independent evaluation of\nrtfMRI-nf brain modulation effects. Frontal EEG asymmetry in the alpha band is\na widely used measure of emotion and motivation that shows profound changes in\ndepression. However, it has never been directly related to simultaneously\nacquired fMRI data. We report the first study investigating\nelectrophysiological correlates of the rtfMRI-nf procedure, by combining\nrtfMRI-nf with simultaneous and passive EEG recordings. In this pilot study,\nMDD patients in the experimental group (n=13) learned to upregulate BOLD\nactivity of the left amygdala using an rtfMRI-nf during a happy emotion\ninduction task. MDD patients in the control group (n=11) were provided with a\nsham rtfMRI-nf. Correlations between frontal EEG asymmetry in the upper alpha\nband and BOLD activity across the brain were examined. Average individual\nchanges in frontal EEG asymmetry during the rtfMRI-nf task for the experimental\ngroup showed a significant positive correlation with the MDD patients'\ndepression severity ratings, consistent with an inverse correlation between the\ndepression severity and frontal EEG asymmetry at rest. Temporal correlations\nbetween frontal EEG asymmetry and BOLD activity were significantly enhanced,\nduring the rtfMRI-nf task, for the amygdala and many regions associated with\nemotion regulation. Our findings demonstrate an important link between amygdala\nBOLD activity and frontal EEG asymmetry. Our EEG asymmetry results suggest that\nthe rtfMRI-nf training targeting the amygdala is beneficial to MDD patients,\nand that alpha-asymmetry EEG-nf would be compatible with the amygdala\nrtfMRI-nf. Combination of the two could enhance emotion regulation training and\nbenefit MDD patients.\n", "versions": [{"version": "v1", "created": "Sat, 6 Sep 2014 19:01:30 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2015 23:32:24 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2016 22:57:21 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Zotev", "Vadim", ""], ["Yuan", "Han", ""], ["Misaki", "Masaya", ""], ["Phillips", "Raquel", ""], ["Young", "Kymberly D.", ""], ["Feldner", "Matthew T.", ""], ["Bodurka", "Jerzy", ""]]}, {"id": "1409.2047", "submitter": "Christian Mayr", "authors": "Christian Mayr", "title": "Untersuchungen zur Implementierung von Bildverarbeitungsalgorithmen\n  mittels pulsgekoppelter neuronaler Netze", "comments": "Dissertation thesis, in German, with English preface", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis deals with the study of image processing algorithms which can be\nimplemented by pulse-coupled neural nets. The inspiration for this choice is\ntaken from biological image processing, which achieves with little\ncomputational effort in highly parallel processes image analysis tasks such as\nobject recognition, image segmentation, velocity and distance estimation, etc.\nConventional, serially implemented algorithms either cannot realize those tasks\nat all or will expend significantly more effort. Because the first stages of\nthe visual system comprise a sensor interface, they are comparatively\naccessible with respect to defining their transfer or processing function. Some\nof those processing functions or principles are to be used in hardware\nimplementations, with the focus on duplicating especially the highly parallel\nprocessing.\n", "versions": [{"version": "v1", "created": "Sat, 6 Sep 2014 19:05:27 GMT"}, {"version": "v2", "created": "Fri, 12 Dec 2014 08:48:35 GMT"}], "update_date": "2014-12-15", "authors_parsed": [["Mayr", "Christian", ""]]}, {"id": "1409.2071", "submitter": "Christian Mayr", "authors": "Christian Mayr", "title": "Untersuchungen zur Modellierung und Schaltungsrealisierung von\n  synaptischer Plastizitaet", "comments": "Habilitation thesis, in German, with English preface", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript deals with the analysis and VLSI implementation of adaptive\ninformation processing derived from biological measurements. Specifically,\nmodels for short term plasticity, long term plasticity and metaplasticity are\nderived from biological measurements and implemented in CMOS circuits.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 01:05:43 GMT"}, {"version": "v2", "created": "Wed, 10 Dec 2014 10:50:14 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Mayr", "Christian", ""]]}, {"id": "1409.2114", "submitter": "C.C. Alan Fung", "authors": "C. C. Alan Fung and K. Y. Michael Wong and Hongzi Mao and Si Wu", "title": "Fluctuation-response Relation Unifies Dynamical Behaviors in Neural\n  Fields", "comments": "17 pages, 9 figures", "journal-ref": "Phys. Rev. E 92, 022801 (2015)", "doi": "10.1103/PhysRevE.92.022801", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anticipation is a strategy used by neural fields to compensate for\ntransmission and processing delays during the tracking of dynamical\ninformation, and can be achieved by slow, localized, inhibitory feedback\nmechanisms such as short-term synaptic depression, spike-frequency adaptation,\nor inhibitory feedback from other layers. Based on the translational symmetry\nof the mobile network states, we derive generic fluctuation-response relations,\nproviding unified predictions that link their tracking behaviors in the\npresence of external stimuli to the intrinsic dynamics of the neural fields in\ntheir absence.\n", "versions": [{"version": "v1", "created": "Sun, 7 Sep 2014 12:56:37 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2015 04:21:17 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Fung", "C. C. Alan", ""], ["Wong", "K. Y. Michael", ""], ["Mao", "Hongzi", ""], ["Wu", "Si", ""]]}, {"id": "1409.2182", "submitter": "Garrett Evans", "authors": "Garrett N. Evans", "title": "Convolution Metric for Neuron Membrane Potential Recordings", "comments": "31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I provide a convolution metric which takes neural membrane potential\nrecordings as arguments and compares their subthreshold features along with the\ntiming and number of spikes within them--summarizing differences in these with\na single \"distance\" between the recordings. Based on van Rossum's 2001 metric\nfor spike trains, the metric relies on a convolution operation that it performs\non the input data. The kernel used for the convolution is carefully chosen such\nthat it produces a desirable frequency space response and, unlike van Rossum's\nkernel, causes the metric to be first order both in differences between nearby\nspike times and in differences between same-time membrane potential values: an\nimportant trait. 31 pages, 4 figures.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 01:27:18 GMT"}], "update_date": "2014-09-09", "authors_parsed": [["Evans", "Garrett N.", ""]]}, {"id": "1409.2207", "submitter": "Liane Gabora", "authors": "Paul Sowden, Andrew Pringle, and Liane Gabora", "title": "The Shifting Sands of Creative Thinking: Connections to Dual Process\n  Theory", "comments": "17 pages", "journal-ref": "Thinking & Reasoning, 21(1), 40-60 (2015)", "doi": "10.1080/13546783.2014.885464", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dual process models of cognition suggest there are two kinds of thought:\nrapid, automatic Type 1 processes, and effortful, controlled Type 2 processes.\nModels of creative thinking also distinguish between two sets of processes:\nthose involved in the generation of ideas, and those involved with their\nrefinement, evaluation and/or selection. Here we review dual process models in\nboth these literatures and delineate the similarities and differences. Both\ngenerative and evaluative creative processing modes involve elements that have\nbeen attributed to each of the dual processes of cognition. We explore the\nnotion that creative thinking may rest upon the nature of a shifting process\nbetween generative and evaluative modes of thought. We suggest that through a\nsynthesis application of the evidence bases on dual process models of cognition\nand from neuroimaging, together with developing chronometric approaches to\nexplore the shifting process, could assist the development of interventions to\nfacilitate creativity.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 05:04:30 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 21:51:13 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Sowden", "Paul", ""], ["Pringle", "Andrew", ""], ["Gabora", "Liane", ""]]}, {"id": "1409.2210", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Why Blind-Variation Selective-Retention is an Inappropriate Explanatory\n  Framework for Creativity", "comments": "6 pages", "journal-ref": "Physics of Life Reviews, 7(2), 182-183, 2010", "doi": "10.1016/j.plrev.2010.04.008", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simonton is attempting to salvage the Blind Variation Selective Retention\ntheory of creativity (often referred to as the Darwinian theory of creativity)\nby dissociating it from Darwinism. This is a necessary move for complex reasons\noutlined in detail elsewhere. However, whether or not one calls BVSR a\nDarwinian theory, it is still a variation-and-selection theory.\nVariation-and-selection was put forward to solve a certain kind of paradox,\nthat of how biological change accumulates (that is, over generations, species\nbecome more adapted to their environment) despite being discarded at the end of\neach generation (that is, parents don't transmit to offspring knowledge or\nbodily changes acquired during their lifetimes, e.g., you don't inherit your\nmother's ear piercings). This paradox does not exist with respect to creative\nthought. There is no discarding of acquired change when ideas are transmitted\namongst individuals; we share with others modified versions of the ideas we\nwere exposed to on a regular basis.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 05:39:08 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 21:41:09 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1409.2535", "submitter": "Merav  Stern", "authors": "Merav Stern, Haim Sompolinsky and L. F. Abbott", "title": "Dynamics of Random Neural Networks with Bistable Units", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevE.90.062710", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct and analyze a rate-based neural network model in which\nself-interacting units represent clusters of neurons with strong local\nconnectivity and random inter-unit connections reflect long-range interactions.\nWhen sufficiently strong, the self-interactions make the individual units\nbistable. Simulation results, mean-field calculations and stability analysis\nreveal the different dynamic regimes of this network and identify the locations\nin parameter space of its phase transitions. We identify an interesting\ndynamical regime exhibiting transient but long-lived chaotic activity that\ncombines features of chaotic and multiple fixed-point attractors.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 21:46:04 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Stern", "Merav", ""], ["Sompolinsky", "Haim", ""], ["Abbott", "L. F.", ""]]}, {"id": "1409.2544", "submitter": "Nora Youngs", "authors": "Nora Youngs", "title": "The neural ring: using algebraic geometry to analyze neural codes", "comments": "Doctoral dissertation, Univ Nebraska 2014. arXiv admin note: text\n  overlap with arXiv:1212.5188 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.AC math.AG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the brain represent external stimuli via neural codes. These codes\noften arise from stimulus-response maps, associating to each neuron a convex\nreceptive field. An important problem confronted by the brain is to infer\nproperties of a represented stimulus space without knowledge of the receptive\nfields, using only the intrinsic structure of the neural code. How does the\nbrain do this? To address this question, it is important to determine what\nstimulus space features can - in principle - be extracted from neural codes.\nThis motivates us to define the neural ring and a related neural ideal,\nalgebraic objects that encode the full combinatorial data of a neural code. We\nfind that these objects can be expressed in a \"canonical form\" that directly\ntranslates to a minimal description of the receptive field structure intrinsic\nto the neural code. We consider the algebraic properties of homomorphisms\nbetween neural rings, which naturally relate to maps between neural codes. We\nshow that maps between two neural codes are in bijection with ring\nhomomorphisms between the respective neural rings, and define the notion of\nneural ring homomorphism, a special restricted class of ring homomorphisms\nwhich preserve neuron structure. We also find connections to Stanley-Reisner\nrings, and use ideas similar to those in the theory of monomial ideals to\nobtain an algorithm for computing the canonical form associated to any neural\ncode, providing the groundwork for inferring stimulus space features from\nneural activity alone.\n", "versions": [{"version": "v1", "created": "Mon, 8 Sep 2014 22:53:53 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Youngs", "Nora", ""]]}, {"id": "1409.2604", "submitter": "Tatyana Sharpee", "authors": "David B. Kastner, Stephen A. Baccus, Tatyana O. Sharpee", "title": "Critical and maximally informative encoding between neural populations\n  in the retina", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1418092112", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation in the brain involves multiple types of neurons, yet the\norganizing principles for how these neurons work together remain unclear.\nInformation theory has offered explanations for how different types of neurons\ncan optimize the encoding of different stimulus features. However, recent\nexperiments indicate that separate neuronal types exist that encode the same\nstimulus features, but do so with different thresholds. Here we show that the\nemergence of these types of neurons can be quantitatively described by the\ntheory of transitions between different phases of matter. The two key\nparameters that control the separation of neurons into subclasses are the mean\nand standard deviation of noise levels among neurons in the population. The\nmean noise level plays the role of temperature in the classic theory of phase\ntransitions, whereas the standard deviation is equivalent to pressure, in the\ncase of liquid-gas transitions, or to magnetic field for magnetic transitions.\nOur results account for properties of two recently discovered types of\nsalamander OFF retinal ganglion cells, as well as the absence of multiple types\nof ON cells. We further show that, across visual stimulus contrasts, retinal\ncircuits continued to operate near the critical point whose quantitative\ncharacteristics matched those expected near a liquid-gas critical point and\ndescribed by the nearest-neighbor Ising model in three dimensions. By operating\nnear a critical point, neural circuits can optimize the trade-off between\nmaximizing information transmission in a given environment and quickly adapting\nto a new environment.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 06:01:29 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Kastner", "David B.", ""], ["Baccus", "Stephen A.", ""], ["Sharpee", "Tatyana O.", ""]]}, {"id": "1409.2676", "submitter": "Max Hinne", "authors": "Max Hinne, Alex Lenkoski, Tom Heskes and Marcel van Gerven", "title": "Efficient sampling of Gaussian graphical models using conditional Bayes\n  factors", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian estimation of Gaussian graphical models has proven to be challenging\nbecause the conjugate prior distribution on the Gaussian precision matrix, the\nG-Wishart distribution, has a doubly intractable partition function. Recent\ndevelopments provide a direct way to sample from the G-Wishart distribution,\nwhich allows for more efficient algorithms for model selection than previously\npossible. Still, estimating Gaussian graphical models with more than a handful\nof variables remains a nearly infeasible task. Here, we propose two novel\nalgorithms that use the direct sampler to more efficiently approximate the\nposterior distribution of the Gaussian graphical model. The first algorithm\nuses conditional Bayes factors to compare models in a Metropolis-Hastings\nframework. The second algorithm is based on a continuous time Markov process.\nWe show that both algorithms are substantially faster than state-of-the-art\nalternatives. Finally, we show how the algorithms may be used to simultaneously\nestimate both structural and functional connectivity between subcortical brain\nregions using resting-state fMRI.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 10:57:23 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Hinne", "Max", ""], ["Lenkoski", "Alex", ""], ["Heskes", "Tom", ""], ["van Gerven", "Marcel", ""]]}, {"id": "1409.2839", "submitter": "Fang-Cheng Yeh", "authors": "Fang-Cheng Yeh and Timothy D. Verstynen", "title": "Increasing the Analytical Accessibility of Multishell and Diffusion\n  Spectrum Imaging Data Using Generalized Q-Sampling Conversion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many diffusion MRI researchers, including the Human Connectome Project (HCP),\nacquire data using multishell (e.g., WU-Minn consortium) and diffusion spectrum\nimaging (DSI) schemes (e.g., USC-Harvard consortium). However, these data sets\nare not readily accessible to high angular resolution diffusion imaging (HARDI)\nanalysis methods that are popular in connectomics analysis. Here we introduce a\nscheme conversion approach that transforms multishell and DSI data into their\ncorresponding HARDI representations, thereby empowering HARDI-based analytical\nmethods to make use of data acquired using non-HARDI approaches. This method\nwas evaluated on both phantom and in-vivo human data sets by acquiring\nmultishell, DSI, and HARDI data simultaneously, and comparing the converted\nHARDI, from non-HARDI methods, with the original HARDI data. Analysis on the\nphantom shows that the converted HARDI from DSI and multishell data strongly\npredicts the original HARDI (correlation coefficient > 0.9). Our in-vivo study\nshows that the converted HARDI can be reconstructed by constrained spherical\ndeconvolution, and the fiber orientation distributions are consistent with\nthose from the original HARDI. We further illustrate that our scheme conversion\nmethod can be applied to HCP data, and the converted HARDI do not appear to\nsacrifice angular resolution. Thus this novel approach can benefit all\nHARDI-based analysis approaches, allowing greater analytical accessibility to\nnon-HARDI data, including data from the HCP.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 18:41:48 GMT"}], "update_date": "2014-09-10", "authors_parsed": [["Yeh", "Fang-Cheng", ""], ["Verstynen", "Timothy D.", ""]]}, {"id": "1409.2842", "submitter": "Jaan Aru", "authors": "Renate Rutiku, Jaan Aru and Talis Bachmann", "title": "General markers of conscious visual perception and their timing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the present investigation was to identify reliable markers of\nconscious visual perception and to characterize their onset latency and its\nvariability. To that end many visual stimuli from different categories were\npresented at near-threshold contrast and contrastive analyses were carried out\non 100 balanced subsets of the data. N200 and P300 were the two reliable\nmarkers of conscious perception common to all perceived stimuli and absent for\nall nonperceived stimuli. The estimated mean onset latency for both markers was\nshortly after 200 ms. However, the onset latency of both of these markers of\nconscious perception showed considerable variability depending on which subsets\nof the data were considered. Some of this variability could be attributed to\nnoise, but it was first and foremost the amplitude fluctuation in the condition\nwithout conscious perception that explained the variability in onset latencies\nof the markers of conscious perception. The present results help to understand\nwhy different studies have observed different onset times for the neural\ncorrelates of conscious perception. Moreover, the consciousness markers\nexplored here have more generality as stimulus specificity was reduced.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 18:53:56 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2015 08:31:45 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Rutiku", "Renate", ""], ["Aru", "Jaan", ""], ["Bachmann", "Talis", ""]]}, {"id": "1409.2903", "submitter": "Eftychios A. Pnevmatikakis", "authors": "Eftychios A. Pnevmatikakis, Yuanjun Gao, Daniel Soudry, David Pfau,\n  Clay Lacefield, Kira Poskanzer, Randy Bruno, Rafael Yuste, Liam Paninski", "title": "A structured matrix factorization framework for large scale calcium\n  imaging data analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a structured matrix factorization approach to analyzing calcium\nimaging recordings of large neuronal ensembles. Our goal is to simultaneously\nidentify the locations of the neurons, demix spatially overlapping components,\nand denoise and deconvolve the spiking activity of each neuron from the slow\ndynamics of the calcium indicator. The matrix factorization approach relies on\nthe observation that the spatiotemporal fluorescence activity can be expressed\nas a product of two matrices: a spatial matrix that encodes the location of\neach neuron in the optical field and a temporal matrix that characterizes the\ncalcium concentration of each neuron over time. We present a simple approach\nfor estimating the dynamics of the calcium indicator as well as the observation\nnoise statistics from the observed data. These parameters are then used to set\nup the matrix factorization problem in a constrained form that requires no\nfurther parameter tuning. We discuss initialization and post-processing\ntechniques that enhance the performance of our method, along with efficient and\nlargely parallelizable algorithms. We apply our method to {\\it in vivo} large\nscale multi-neuronal imaging data and also demonstrate how similar methods can\nbe used for the analysis of {\\it in vivo} dendritic imaging data.\n", "versions": [{"version": "v1", "created": "Tue, 9 Sep 2014 21:25:59 GMT"}], "update_date": "2014-09-11", "authors_parsed": [["Pnevmatikakis", "Eftychios A.", ""], ["Gao", "Yuanjun", ""], ["Soudry", "Daniel", ""], ["Pfau", "David", ""], ["Lacefield", "Clay", ""], ["Poskanzer", "Kira", ""], ["Bruno", "Randy", ""], ["Yuste", "Rafael", ""], ["Paninski", "Liam", ""]]}, {"id": "1409.2942", "submitter": "Gabriel Kreiman", "authors": "Hanlin Tang, Calin Buia, Joseph Madsen, William S. Anderson, Gabriel\n  Kreiman", "title": "A role for recurrent processing in object completion:\n  neurophysiological, psychophysical and computational\"evidence", "comments": null, "journal-ref": "Neuron. 2014 Aug 6;83(3):736-48", "doi": "10.1016/j.neuron.2014.06.017.", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognition of objects from partial information presents a significant\nchallenge for theories of vision because it requires spatial integration and\nextrapolation from prior knowledge. We combined neurophysiological recordings\nin human cortex with psychophysical measurements and computational modeling to\ninvestigate the mechanisms involved in object completion. We recorded\nintracranial field potentials from 1,699 electrodes in 18 epilepsy patients to\nmeasure the timing and selectivity of responses along human visual cortex to\nwhole and partial objects. Responses along the ventral visual stream remained\nselective despite showing only 9-25% of the object. However, these visually\nselective signals emerged ~100 ms later for partial versus whole objects. The\nprocessing delays were particularly pronounced in higher visual areas within\nthe ventral stream, suggesting the involvement of additional recurrent\nprocessing. In separate psychophysics experiments, disrupting this recurrent\ncomputation with a backward mask at ~75ms significantly impaired recognition of\npartial, but not whole, objects. Additionally, computational modeling shows\nthat the performance of a purely bottom-up architecture is impaired by heavy\nocclusion and that this effect can be partially rescued via the incorporation\nof top-down connections. These results provide spatiotemporal constraints on\ntheories of object recognition that involve recurrent processing to recognize\nobjects from partial information.\n", "versions": [{"version": "v1", "created": "Wed, 10 Sep 2014 02:51:01 GMT"}], "update_date": "2014-09-11", "authors_parsed": [["Tang", "Hanlin", ""], ["Buia", "Calin", ""], ["Madsen", "Joseph", ""], ["Anderson", "William S.", ""], ["Kreiman", "Gabriel", ""]]}, {"id": "1409.3909", "submitter": "Liane Gabora", "authors": "Sophie Morin, Jean-Marc Robert, and Liane Gabora", "title": "A New Course on Creativity in an Engineering Program: Foundations and\n  Issues", "comments": "10 pages, Intl Conf on Innovative Design and Manufacturing (pp.\n  270-275). Aug 13-15, Montreal. IEEE Conference Proceedings", "journal-ref": null, "doi": "10.1109/IDAM.2014.6912706", "report-no": null, "categories": "cs.CY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of innovation in the world's economy, now undeniable, draws\ngreat attention to the need to improve organizations' creative potential. In\nthe last 60 years, hundreds of books have been written on the subject and\nhundreds of webpages display information on how to be more creative and achieve\ninnovation. Several North American and European universities offer graduated\nprograms in creativity. However, building an effective and validated creativity\ntraining program is not without challenges. Because of the nature of their\nwork, engineers are often asked to be innovative. Without aiming for a degree\nin creativity, could future engineers benefit from training programs in\ncreativity? This article presents the conceptual framework and pedagogical\nelements of a new course in creativity for engineering students.\n", "versions": [{"version": "v1", "created": "Sat, 13 Sep 2014 04:40:36 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Morin", "Sophie", ""], ["Robert", "Jean-Marc", ""], ["Gabora", "Liane", ""]]}, {"id": "1409.3911", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Probing the Mind Behind the (Literal and Figurative) Lightbulb", "comments": "16 pages; requested commentary on \"Thomas Edison's creative career:\n  The Multilayered trajectory of trials, errors, failures, and triumphs\" by\n  Dean Simonton. < http://psycnet.apa.org/psycinfo/2014-32896-001/ > Both\n  target paper and commentary are in press in Psychology of Aesthetics,\n  Creativity, and the Arts", "journal-ref": "2015. Psychology of Aesthetics, Creativity, and the Arts, 9(1),\n  20-24", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After doing away with the evolutionary scaffold for BVSR, what remains is a\nnotion of \"blindness\" that does not distinguish BVSR from other theories of\ncreativity, and an assumption that creativity can be understood by treating\nideas as discrete, countable entities, as opposed to different external\nmanifestations of a singular gradually solidifying internal conception.\nUprooted from Darwinian theory, BVSR lacks a scientific framework that can be\ncalled upon to generate hypotheses and test them. In lieu of such a framework,\nhypotheses appear to be generated on the basis of previous data--they are not\ntheory-driven. The paper does not explain how the hypothesis that creativity is\nenhanced by engagement in a \"network of enterprises\" is derived from BVSR; this\nhypothesis is more compatible with competing conceptions of creativity. The\nnotion that creativity involves backtracking conflates evidence for\nbacktracking with respect to the external output with evidence for backtracking\nof the conception of the invention. The first does not imply the second; a\ncreator can set aside a creative output but cannot go back to the conception of\nthe task he/she had prior to generating that output. The notion that creativity\nentails superfluity (i.e., many ideas have \"zero usefulness\") is misguided;\nusefulness is context-dependent, moreover, the usefulness of an idea may reside\nin its being a critical stepping-stone to a subsequent idea.\n", "versions": [{"version": "v1", "created": "Sat, 13 Sep 2014 04:56:48 GMT"}, {"version": "v2", "created": "Fri, 19 Sep 2014 00:56:05 GMT"}, {"version": "v3", "created": "Wed, 24 Sep 2014 16:11:13 GMT"}, {"version": "v4", "created": "Wed, 25 Feb 2015 18:55:02 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1409.4178", "submitter": "Leonardo L. Gollo", "authors": "Leonardo L. Gollo and Michael Breakspear", "title": "The frustrated brain: From dynamics on motifs to communities and\n  networks", "comments": "17 pages, 7 figures", "journal-ref": "Phil. Trans. R. Soc. B 369: 20130532 (2014)", "doi": "10.1098/rstb.2013.0532", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.PS physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive function depends on an adaptive balance between flexible dynamics\nand integrative processes in distributed cortical networks. Patterns of\nzero-lag synchrony likely underpin numerous perceptual and cognitive functions.\nSynchronization fulfils integration by reducing entropy, whilst adaptive\nfunction mandates that a broad variety of stable states be readily accessible.\nHere, we elucidate two complementary influences on patterns of zero-lag\nsynchrony that derive from basic properties of brain networks. First, mutually\ncoupled pairs of neuronal subsystems -- resonance pairs -- promote stable\nzero-lag synchrony amongst the small motifs in which they are embedded, and\nwhose effects can propagate along connected chains. Second, frustrated\nclosed-loop motifs disrupt synchronous dynamics, enabling metastable\nconfigurations of zero-lag synchrony to coexist. We document these two\ncomplementary influences in small motifs and illustrate how these effects\nunderpin stable versus metastable phase-synchronization patterns in\nprototypical modular networks and in large-scale cortical networks of the\nmacaque (CoCoMac). We find that the variability of synchronization patterns\ndepends on the inter-node time delay, increases with the network size, and is\nmaximized for intermediate coupling strengths. We hypothesize that the\ndialectic influences of resonance versus frustration may form a dynamic\nsubstrate for flexible neuronal integration, an essential platform across\ndiverse cognitive processes.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 08:27:34 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Gollo", "Leonardo L.", ""], ["Breakspear", "Michael", ""]]}, {"id": "1409.4185", "submitter": "Jean-Marc Luck", "authors": "J. M. Luck and A. Mehta", "title": "Slow synaptic dynamics in a network: from exponential to power-law\n  forgetting", "comments": "12 pages, 8 figures. Phys. Rev. E (2014) to appear", "journal-ref": "Phys. Rev. E 90, 032709 (2014)", "doi": "10.1103/PhysRevE.90.032709", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a mean-field model of interacting synapses on a directed\nneural network. Our interest lies in the slow adaptive dynamics of synapses,\nwhich are driven by the fast dynamics of the neurons they connect. Cooperation\nis modelled from the usual Hebbian perspective, while competition is modelled\nby an original polarity-driven rule. The emergence of a critical manifold\nculminating in a tricritical point is crucially dependent on the presence of\nsynaptic competition. This leads to a universal $1/t$ power-law relaxation of\nthe mean synaptic strength along the critical manifold and an equally universal\n$1/\\sqrt{t}$ relaxation at the tricritical point, to be contrasted with the\nexponential relaxation that is otherwise generic. In turn, this leads to the\nnatural emergence of long- and short-term memory from different parts of\nparameter space in a synaptic network, which is the most novel and important\nresult of our present investigations.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 09:09:22 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Luck", "J. M.", ""], ["Mehta", "A.", ""]]}, {"id": "1409.4251", "submitter": "Stephan Porz", "authors": "Stephan Porz, Matth\\\"aus Kiel, Klaus Lehnertz", "title": "Can spurious indications for phase synchronization due to superimposed\n  signals be avoided?", "comments": null, "journal-ref": "Porz S, Kiel M, Lehnertz K, Chaos 24, 033112 (2014)", "doi": "10.1063/1.4890568", "report-no": null, "categories": "q-bio.NC nlin.CD physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the relative merit of phase-based methods---mean phase\ncoherence, unweighted and weighted phase lag index---for estimating the\nstrength of interactions between dynamical systems from empirical time series\nwhich are affected by common sources and noise. By numerically analyzing the\ninteraction dynamics of coupled model systems, we compare these methods to each\nother with respect to their ability to distinguish between different levels of\ncoupling for various simulated experimental situations. We complement our\nnumerical studies by investigating consistency and temporal variations of the\nstrength of interactions within and between brain regions using intracranial\nelectroencephalographic recordings from an epilepsy patient. Our findings\nindicate that the unweighted and weighted phase lag index are less prone to the\ninfluence of common sources but that this advantage may lead to constrictions\nlimiting the applicability of these methods.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 13:36:00 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Porz", "Stephan", ""], ["Kiel", "Matth\u00e4us", ""], ["Lehnertz", "Klaus", ""]]}, {"id": "1409.4700", "submitter": "Liane Gabora", "authors": "Liane Gabora and Apara Ranjan", "title": "Can Sol's Explanation for the Evolution of Animal Innovation Account for\n  Human Innovation?", "comments": "7 pages", "journal-ref": "In A. Kaufman & J. Kaufman (Eds.), Animal creativity and\n  innovation: Research and theory (pp. 183-188). Philadelphia PA: Elsevier.\n  (2015)", "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sol argues that innovation propensity is not a specialized adaptation\nresulting from targeted selection but an instance of exaptation because\nselection cannot act on situations that are only encountered once. In\nexaptation, a trait that originally evolved to solve one problem is co-opted to\nsolve a new problem; thus the trait or traits in question must be necessary and\nsufficient to solve the new problem. Sol claims that traits such as persistence\nand neophilia, are necessary and sufficient for animal innovation, which is a\nmatter of trial and error. We suggest that this explanation does not extend to\nhuman innovation, which involves strategy, logic, intuition, and insight, and\nrequires traits that evolved, not as a byproduct of some other function, but\nfor the purpose of coming up with adaptive responses to environmental\nvariability itself. We point to an agent based model that indicates the\nfeasibility of two such proposed traits: (1) chaining, the ability to construct\ncomplex thoughts from simple ones, and (2) contextual focus, the ability to\nshift between convergent and divergent modes of thought. We agree that there is\na sense in which innovation is exaptation--it occurs when an existing object or\nbehaviour is adapted to new needs or tastes--and refer to a mathematical model\nof biological and cultural exaltation. We conclude that much is gained by\ncomparing and contrasting animal and human innovation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Sep 2014 16:56:04 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 21:32:09 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Gabora", "Liane", ""], ["Ranjan", "Apara", ""]]}, {"id": "1409.4927", "submitter": "Alberto Romagnoni", "authors": "Alberto Romagnoni, J\\'er\\^ome Ribot, Daniel Bennequin, Jonathan D.\n  Touboul", "title": "Parsimony, exhaustivity and balanced detection in neocortex", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1004623", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One fascinating aspect of the brain is its ability to process information in\na fast and reliable manner. The functional architecture is thought to play a\ncentral role in this task, by encoding efficiently complex stimuli and\nfacilitating higher level processing. In the early visual cortex of higher\nmammals, information is processed within functional maps whose layout is\nthought to underlie visual perception. The possible principles underlying the\ntopology of the different maps, as well as the role of a specific functional\narchitecture on information processing, is however poorly understood. We\ndemonstrate mathematically here that two natural principles, local exhaustivity\nof representation and parsimony, would constrain the orientation and spatial\nfrequency maps to display co-located singularities around which the orientation\nis organized as a pinwheel and spatial frequency as a dipole. This observation\nis perfectly in line with new optical imaging data on the cat visual cortex we\nanalyze in a companion paper. Here we further focus on the theoretical\nimplications of this structure. Using a computational model, we show that this\narchitecture allows a trade-off in the local perception of orientation and\nspatial frequency, but this would occur for sharper selectivity than the tuning\nwidth reported in the literature. We therefore re-examined physiological data\nand show that indeed the spatial frequency selectivity substantially sharpens\nnear maps singularities, bringing to the prediction that the system tends to\noptimize balanced detection between different attributes. These results shed\nnew light on the principles at play in the emergence of functional architecture\nof cortical maps, as well as their potential role in processing information.\n", "versions": [{"version": "v1", "created": "Wed, 17 Sep 2014 09:50:48 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Romagnoni", "Alberto", ""], ["Ribot", "J\u00e9r\u00f4me", ""], ["Bennequin", "Daniel", ""], ["Touboul", "Jonathan D.", ""]]}, {"id": "1409.5280", "submitter": "Marcus Kaiser", "authors": "Marc-Thorsten Huett and Marcus Kaiser and Claus C. Hilgetag", "title": "Perspective: network-guided pattern formation of neural dynamics", "comments": null, "journal-ref": "Phil. Trans. R. Soc. B 20130522, 2014", "doi": "10.1098/rstb.2013.0522", "report-no": null, "categories": "q-bio.NC nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The understanding of neural activity patterns is fundamentally linked to an\nunderstanding of how the brain's network architecture shapes dynamical\nprocesses. Established approaches rely mostly on deviations of a given network\nfrom certain classes of random graphs. Hypotheses about the supposed role of\nprominent topological features (for instance, the roles of modularity, network\nmotifs, or hierarchical network organization) are derived from these\ndeviations. An alternative strategy could be to study deviations of network\narchitectures from regular graphs (rings, lattices) and consider the\nimplications of such deviations for self-organized dynamic patterns on the\nnetwork. Following this strategy, we draw on the theory of spatiotemporal\npattern formation and propose a novel perspective for analyzing dynamics on\nnetworks, by evaluating how the self-organized dynamics are confined by network\narchitecture to a small set of permissible collective states. In particular, we\ndiscuss the role of prominent topological features of brain connectivity, such\nas hubs, modules and hierarchy, in shaping activity patterns. We illustrate the\nnotion of network-guided pattern formation with numerical simulations and\noutline how it can facilitate the understanding of neural dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 12:17:16 GMT"}], "update_date": "2014-09-19", "authors_parsed": [["Huett", "Marc-Thorsten", ""], ["Kaiser", "Marcus", ""], ["Hilgetag", "Claus C.", ""]]}, {"id": "1409.5326", "submitter": "Marcus Kaiser", "authors": "Richard J. Tomsett, Matt Ainsworth, Alexander Thiele, Mehdi Sanayei,\n  Xing Chen, Alwin Gieselmann, Miles A. Whittington, Mark O. Cunningham and\n  Marcus Kaiser", "title": "Virtual Electrode Recording Tool for EXtracellular potentials (VERTEX):\n  Comparing multi-electrode recordings from simulated and biological mammalian\n  cortical tissue", "comments": "appears in Brain Struct Funct 2014", "journal-ref": null, "doi": "10.1007/s00429-014-0793-x", "report-no": null, "categories": "q-bio.NC cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local field potentials (LFPs) sampled with extracellular electrodes are\nfrequently used as a measure of population neuronal activity. However, relating\nsuch measurements to underlying neuronal behaviour and connectivity is\nnon-trivial. To help study this link, we developed the Virtual Electrode\nRecording Tool for EXtracellular potentials (VERTEX). We first identified a\nreduced neuron model that retained the spatial and frequency filtering\ncharacteristics of extracellular potentials from neocortical neurons. We then\ndeveloped VERTEX as an easy-to-use Matlab tool for simulating LFPs from large\npopulations (>100 000 neurons). A VERTEX-based simulation successfully\nreproduced features of the LFPs from an in vitro multi-electrode array\nrecording of macaque neocortical tissue. Our model, with virtual electrodes\nplaced anywhere in 3D, allows direct comparisons with the in vitro recording\nsetup. We envisage that VERTEX will stimulate experimentalists, clinicians, and\ncomputational neuroscientists to use models to understand the mechanisms\nunderlying measured brain dynamics in health and disease.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 15:04:53 GMT"}], "update_date": "2014-09-19", "authors_parsed": [["Tomsett", "Richard J.", ""], ["Ainsworth", "Matt", ""], ["Thiele", "Alexander", ""], ["Sanayei", "Mehdi", ""], ["Chen", "Xing", ""], ["Gieselmann", "Alwin", ""], ["Whittington", "Miles A.", ""], ["Cunningham", "Mark O.", ""], ["Kaiser", "Marcus", ""]]}, {"id": "1409.5352", "submitter": "Stefan Thurner", "authors": "Maximilian Sadilek and Stefan Thurner", "title": "Physiologically motivated multiplex Kuramoto model describes phase\n  diagram of cortical activity", "comments": "8 pages, 3 figures", "journal-ref": "Scientific Reports 5, 10015, (2015)", "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech nlin.CD physics.bio-ph physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive a two-layer multiplex Kuramoto model from weakly coupled\nWilson-Cowan oscillators on a cortical network with inhibitory synaptic time\ndelays. Depending on the coupling strength and a phase shift parameter, related\nto cerebral blood flow and GABA concentration, respectively, we numerically\nidentify three macroscopic phases: unsynchronized, synchronized, and chaotic\ndynamics. These correspond to physiological background-, epileptic seizure-,\nand resting-state cortical activity, respectively. We also observe frequency\nsuppression at the transition from resting-state to seizure activity.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2014 20:23:46 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Sadilek", "Maximilian", ""], ["Thurner", "Stefan", ""]]}, {"id": "1409.5353", "submitter": "Stojan Jovanovi\\\"A", "authors": "Stojan Jovanovi\\'c, John Hertz and Stefan Rotter", "title": "Cumulants of Hawkes point processes", "comments": "11 pages, 4 figures", "journal-ref": "Phys. Rev. E 91, 042802 (2015)", "doi": "10.1103/PhysRevE.91.042802", "report-no": null, "categories": "math.ST physics.bio-ph q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive explicit, closed-form expressions for the cumulant densities of a\nmultivariate, self-exciting Hawkes point process, generalizing a result of\nHawkes in his earlier work on the covariance density and Bartlett spectrum of\nsuch processes. To do this, we represent the Hawkes process in terms of a\nPoisson cluster process and show how the cumulant density formulas can be\nderived by enumerating all possible \"family trees\", representing complex\ninteractions between point events. We also consider the problem of computing\nthe integrated cumulants, characterizing the average measure of correlated\nactivity between events of different types, and derive the relevant equations.\n", "versions": [{"version": "v1", "created": "Thu, 18 Sep 2014 16:02:03 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2015 15:47:00 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Jovanovi\u0107", "Stojan", ""], ["Hertz", "John", ""], ["Rotter", "Stefan", ""]]}, {"id": "1409.5496", "submitter": "Bingni Brunton", "authors": "Bingni W. Brunton, Lise A. Johnson, Jeffrey G. Ojemann, J. Nathan Kutz", "title": "Extracting spatial-temporal coherent patterns in large-scale neural\n  recordings using dynamic mode decomposition", "comments": "5 figures, 10 pages including methods", "journal-ref": "J Neurosci Methods (2015) 258:1--15", "doi": "10.1016/j.jneumeth.2015.10.010", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a broad need in the neuroscience community to understand and\nvisualize large-scale recordings of neural activity, big data acquired by tens\nor hundreds of electrodes simultaneously recording dynamic brain activity over\nminutes to hours. Such dynamic datasets are characterized by coherent patterns\nacross both space and time, yet existing computational methods are typically\nrestricted to analysis either in space or in time separately. Here we report\nthe adaptation of dynamic mode decomposition (DMD), an algorithm originally\ndeveloped for the study of fluid physics, to large-scale neuronal recordings.\nDMD is a modal decomposition algorithm that describes high-dimensional dynamic\ndata using coupled spatial-temporal modes; the resulting analysis combines key\nfeatures of performing principal components analysis (PCA) in space and power\nspectral analysis in time. The algorithm scales easily to very large numbers of\nsimultaneously acquired measurements. We validated the DMD approach on\nsub-dural electrode array recordings from human subjects performing a known\nmotor activation task. Next, we leveraged DMD in combination with machine\nlearning to develop a novel method to extract sleep spindle networks from the\nsame subjects. We suggest that DMD is generally applicable as a powerful method\nin the analysis and understanding of large-scale recordings of neural activity.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 00:57:50 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Brunton", "Bingni W.", ""], ["Johnson", "Lise A.", ""], ["Ojemann", "Jeffrey G.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1409.5510", "submitter": "Saulo Reis", "authors": "Saulo D. S. Reis, Yanqing Hu, Andr\\'es Babino, Jos\\'e S. Andrade Jr.,\n  Santiago Canals, Mariano Sigman, and Hern\\'an A. Makse", "title": "Avoiding catastrophic failure in correlated networks of networks", "comments": "40 pages, 7 figures", "journal-ref": "Nature Physics, Vol 10, 762-767 (2014)", "doi": "10.1038/nphys3081", "report-no": null, "categories": "physics.soc-ph physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks in nature do not act in isolation but instead exchange information,\nand depend on each other to function properly. An incipient theory of Networks\nof Networks have shown that connected random networks may very easily result in\nabrupt failures. This theoretical finding bares an intrinsic paradox: If\nnatural systems organize in interconnected networks, how can they be so stable?\nHere we provide a solution to this conundrum, showing that the stability of a\nsystem of networks relies on the relation between the internal structure of a\nnetwork and its pattern of connections to other networks. Specifically, we\ndemonstrate that if network inter-connections are provided by hubs of the\nnetwork and if there is a moderate degree of convergence of inter-network\nconnection the systems of network are stable and robust to failure. We test\nthis theoretical prediction in two independent experiments of functional brain\nnetworks (in task- and resting states) which show that brain networks are\nconnected with a topology that maximizes stability according to the theory.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 03:58:10 GMT"}, {"version": "v2", "created": "Sun, 19 Oct 2014 20:46:44 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2015 16:33:15 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Reis", "Saulo D. S.", ""], ["Hu", "Yanqing", ""], ["Babino", "Andr\u00e9s", ""], ["Andrade", "Jos\u00e9 S.", "Jr."], ["Canals", "Santiago", ""], ["Sigman", "Mariano", ""], ["Makse", "Hern\u00e1n A.", ""]]}, {"id": "1409.5672", "submitter": "Rapha\\\"el Li\\'egeois", "authors": "Rapha\\\"el Li\\'egeois, Erik Ziegler, Pierre Geurts, Francisco Gomez,\n  Mohamed Ali Bahri, Christophe Phillips, Andrea Soddu, Audrey Vanhaudenhuyse,\n  Steven Laureys, Rodolphe Sepulchre", "title": "Cerebral functional connectivity periodically (de)synchronizes with\n  anatomical constraints", "comments": "11 pages, 7 figures in main text, submitted to Human Brain Mapping", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the link between resting-state functional connectivity\n(FC), measured by the correlations of the fMRI BOLD time courses, and\nstructural connectivity (SC), estimated through fiber tractography. Instead of\na static analysis based on the correlation between SC and the FC averaged over\nthe entire fMRI time series, we propose a dynamic analysis, based on the time\nevolution of the correlation between SC and a suitably windowed FC. Assessing\nthe statistical significance of the time series against random phase\npermutations, our data show a pronounced peak of significance for time window\nwidths around 20-30 TR (40-60 sec). Using the appropriate window width, we show\nthat FC patterns oscillate between phases of high modularity, primarily shaped\nby anatomy, and phases of low modularity, primarily shaped by inter-network\nconnectivity. Building upon recent results in dynamic FC, this emphasizes the\npotential role of SC as a transitory architecture between different highly\nconnected resting state FC patterns. Finally, we show that networks implied in\nconsciousness-related processes, such as the default mode network (DMN),\ncontribute more to these brain-level fluctuations compared to other networks,\nsuch as the motor or somatosensory networks. This suggests that the\nfluctuations between FC and SC are capturing mind-wandering effects.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2014 14:23:24 GMT"}], "update_date": "2014-09-22", "authors_parsed": [["Li\u00e9geois", "Rapha\u00ebl", ""], ["Ziegler", "Erik", ""], ["Geurts", "Pierre", ""], ["Gomez", "Francisco", ""], ["Bahri", "Mohamed Ali", ""], ["Phillips", "Christophe", ""], ["Soddu", "Andrea", ""], ["Vanhaudenhuyse", "Audrey", ""], ["Laureys", "Steven", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "1409.6338", "submitter": "Julie Dethier", "authors": "Julie Dethier, Guillaume Drion, Alessio Franci, Rodolphe Sepulchre", "title": "A positive feedback at the cellular level promotes robustness and\n  modulation at the circuit level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper highlights the role of a positive feedback gating mechanism at the\ncellular level in the robust- ness and modulation properties of rhythmic\nactivities at the circuit level. The results are presented in the context of\nhalf-center oscillators, which are simple rhythmic circuits composed of two\nreciprocally connected inhibitory neuronal populations. Specifically, we focus\non rhythms that rely on a particu- lar excitability property, the\npost-inhibitory rebound, an intrinsic cellular property that elicits transient\nmembrane depolarization when released from hyperpolarization. Two distinct\nionic currents can evoke this transient depolarization: a\nhyperpolarization-activated cation current and a low-threshold T-type calcium\ncurrent. The presence of a slow activation is specific to the T-type calcium\ncurrent and provides a slow-positive feedback at the cellular level that is\nabsent in the cation current. We show that this slow- positive feedback is\nnecessary and sufficient to endow the network rhythm with physiological\nmodulation and robustness properties. This study thereby identifies an\nessential cellular property to be retained at the network level in modeling\nnetwork robustness and modulation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Sep 2014 20:42:10 GMT"}, {"version": "v2", "created": "Fri, 19 Dec 2014 19:21:18 GMT"}], "update_date": "2014-12-22", "authors_parsed": [["Dethier", "Julie", ""], ["Drion", "Guillaume", ""], ["Franci", "Alessio", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "1409.6378", "submitter": "Dante Chialvo", "authors": "Enzo Tagliazucchi, Helmut Laufs, Dante R. Chialvo", "title": "A few points suffice: Efficient large-scale computation of brain\n  voxel-wise functional connectomes from a sparse spatio-temporal point-process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large efforts are currently under way to systematically map functional\nconnectivity between all pairs of millimeter-scale brain regions using big\nvolumes of neuroimaging data. Functional magnetic resonance imaging (fMRI) can\nproduce these functional connectomes, however, large amounts of data and\nlengthy computation times add important overhead to this task. Previous work\nhas demonstrated that fMRI data admits a sparse representation in the form a\ndiscrete point-process containing sufficient information for the efficient\nestimation of functional connectivity between all pairs of voxels. In this work\nwe validate this method, by replicating results obtained with standard\nwhole-brain voxel-wise linear correlation matrices in two datasets. In the\nfirst one (n=71) we study the changes in node strength (a measure of network\ncentrality) during deep sleep. The second is a large database (n=1147) of\nsubjects in which we look at the age-related reorganization of the voxel-wise\nnetwork of functional connections. In both cases it is shown that the proposed\nmethod compares well with standard techniques, despite requiring of the order\nof 1 % of the original fMRI time series. Overall, these results demonstrate\nthat the proposed approach allows efficient fMRI data compression and a\nsubsequent reduction of computation times.\n", "versions": [{"version": "v1", "created": "Tue, 23 Sep 2014 00:43:48 GMT"}], "update_date": "2014-09-24", "authors_parsed": [["Tagliazucchi", "Enzo", ""], ["Laufs", "Helmut", ""], ["Chialvo", "Dante R.", ""]]}, {"id": "1409.6744", "submitter": "Antonio Galves", "authors": "C. D. Vargas, M. L. Rangel and A. Galves", "title": "Predicting upcoming actions by observation: some facts, models and\n  challenges", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting another person's upcoming action to build an appropriate response\nis a regular occurrence in the domain of motor control. In this review we\ndiscuss conceptual and experimental approaches aiming at the neural basis of\npredicting and learning to predict upcoming movements by their observation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Sep 2014 20:22:50 GMT"}], "update_date": "2014-09-25", "authors_parsed": [["Vargas", "C. D.", ""], ["Rangel", "M. L.", ""], ["Galves", "A.", ""]]}, {"id": "1409.7086", "submitter": "Sean Simpson", "authors": "Sean L. Simpson and Paul J. Laurienti", "title": "A Two-Part Mixed-Effects Modeling Framework For Analyzing Whole-Brain\n  Network Data", "comments": null, "journal-ref": "NeuroImage 113, 310-319, 2015", "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whole-brain network analyses remain the vanguard in neuroimaging research,\ncoming to prominence within the last decade. Network science approaches have\nfacilitated these analyses and allowed examining the brain as an integrated\nsystem. However, statistical methods for modeling and comparing groups of\nnetworks have lagged behind. Fusing multivariate statistical approaches with\nnetwork science presents the best path to develop these methods. Toward this\nend, we propose a two-part mixed-effects modeling framework that allows\nmodeling both the probability of a connection (presence/absence of an edge) and\nthe strength of a connection if it exists. Models within this framework enable\nquantifying the relationship between an outcome (e.g., disease status) and\nconnectivity patterns in the brain while reducing spurious correlations through\ninclusion of confounding covariates. They also enable prediction about an\noutcome based on connectivity structure and vice versa, simulating networks to\ngain a better understanding of normal ranges of topological variability, and\nthresholding networks leveraging group information. Thus, they provide a\ncomprehensive approach to studying system level brain properties to further our\nunderstanding of normal and abnormal brain function.\n", "versions": [{"version": "v1", "created": "Wed, 24 Sep 2014 20:17:08 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Simpson", "Sean L.", ""], ["Laurienti", "Paul J.", ""]]}, {"id": "1409.7137", "submitter": "Shinsuke Koyama", "authors": "Shinsuke Koyama", "title": "On the spike train variability characterized by variance-to-mean power\n  relationship", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a statistical method for modeling the non-Poisson variability of\nspike trains observed in a wide range of brain regions. Central to our approach\nis the assumption that the variance and the mean of interspike intervals are\nrelated by a power function characterized by two parameters: the scale factor\nand exponent. It is shown that this single assumption allows the variability of\nspike trains to have an arbitrary scale and various dependencies on the firing\nrate in the spike count statistics, as well as in the interval statistics,\ndepending on the two parameters of the power function. We also propose a\nstatistical model for spike trains that exhibits the variance-to-mean power\nrelationship, and based on this a maximum likelihood method is developed for\ninferring the parameters from rate-modulated spike trains. The proposed method\nis illustrated on simulated and experimental spike trains.\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2014 02:08:58 GMT"}, {"version": "v2", "created": "Thu, 21 May 2015 07:33:11 GMT"}], "update_date": "2015-05-22", "authors_parsed": [["Koyama", "Shinsuke", ""]]}, {"id": "1409.7149", "submitter": "Zachary Kilpatrick PhD", "authors": "Zachary P. Kilpatrick", "title": "Delay stabilizes stochastic motion of bumps in layered neural fields", "comments": "21 pages, 7 figures; To appear in Physica D", "journal-ref": null, "doi": "10.1016/j.physd.2014.12.011", "report-no": null, "categories": "q-bio.NC nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effects of propagation delays on the stochastic dynamics of\nbumps in neural fields with multiple layers. In the absence of noise, each\nlayer supports a stationary bump. Using linear stability analysis, we show that\ndelayed coupling between layers causes translating perturbations of the bumps\nto decay in the noise-free system. Adding noise to the system causes bumps to\nwander as a random walk. However, coupling between layers can reduce the\nvariability of this stochastic motion by canceling noise that perturbs bumps in\nopposite directions. Delays in interlaminar coupling can further reduce\nvariability, since they couple bump positions to states from the past. We\ndemonstrate these relationships by deriving an asymptotic approximation for the\neffective motion of bumps. This yields a stochastic delay-differential equation\nwhere each delayed term arises from an interlaminar coupling. The impact of\ndelays is well approximated by using a small delay expansion, which allows us\nto compute the effective diffusion in bumps' positions, accurately matching\nresults from numerical simulations.\n", "versions": [{"version": "v1", "created": "Thu, 25 Sep 2014 04:02:22 GMT"}, {"version": "v2", "created": "Tue, 23 Dec 2014 17:31:40 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Kilpatrick", "Zachary P.", ""]]}, {"id": "1409.7686", "submitter": "Matthias K\\\"ummerer", "authors": "Matthias K\\\"ummerer, Thomas Wallis, Matthias Bethge", "title": "How close are we to understanding image-based saliency?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the set of the many complex factors driving gaze placement, the\nproperities of an image that are associated with fixations under free viewing\nconditions have been studied extensively. There is a general impression that\nthe field is close to understanding this particular association. Here we frame\nsaliency models probabilistically as point processes, allowing the calculation\nof log-likelihoods and bringing saliency evaluation into the domain of\ninformation. We compared the information gain of state-of-the-art models to a\ngold standard and find that only one third of the explainable spatial\ninformation is captured. We additionally provide a principled method to show\nwhere and how models fail to capture information in the fixations. Thus,\ncontrary to previous assertions, purely spatial saliency remains a significant\nchallenge.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2014 19:59:44 GMT"}], "update_date": "2014-09-29", "authors_parsed": [["K\u00fcmmerer", "Matthias", ""], ["Wallis", "Thomas", ""], ["Bethge", "Matthias", ""]]}, {"id": "1409.8270", "submitter": "Sayan Mukherjee Dr.", "authors": "Sayan Mukherjee, Sanjay Kumar Palit, D. K. Bhattacharya", "title": "Approximate discrete dynamics of EMG signal", "comments": null, "journal-ref": "Applied Mathematics and Computation 243 (15 September 2014)\n  879-888", "doi": "10.1016/j.amc.2014.06.059", "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximation of a continuous dynamics by discrete dynamics in the form of\nPoincare map is one of the fascinating mathematical tool, which can describe\nthe approximate behaviour of the dynamics of the dynamical system in lesser\ndimension than the embedding diemnsion. The present article considers a very\nrare biomedical signal like Electromyography (EMG) signal. It determines\nsuitable time delay and reconstruct the attractor of embedding diemnsion three.\nBy measuring its Lyapunov exponent, the attractor so reconstructed is found to\nbe chaotic. Naturally the Poincare map obtained by corresponding Poincare\nsection is to be chaotic too. This may be verified by calculation of Lyapunov\nexponent of the map. The main objective of this article is to show that\nPoincare map exists in this case as a 2D map for a suitable Poincare section\nonly. In fact, the article considers two Poincare sections of the attractor for\nconstruction of the Poincare map. It is seen that one such map is chaotic but\nthe other one is not so, both are verified by calculation of Lyapunov exponent\nof the map.\n", "versions": [{"version": "v1", "created": "Tue, 23 Sep 2014 20:06:16 GMT"}], "update_date": "2014-09-30", "authors_parsed": [["Mukherjee", "Sayan", ""], ["Palit", "Sanjay Kumar", ""], ["Bhattacharya", "D. K.", ""]]}, {"id": "1409.8275", "submitter": "William  Softky", "authors": "William Softky", "title": "Elastic Nanocomputation in an Ideal Brain (1p abstract + 36 pages + 49\n  endnotes)", "comments": "1 page abstract, 36 pages content incl. 12 figures, 49 endnotes", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This explanation of what a brain is and does rests on informational first\nprinciples, because information theory, like its parent theory thermodynamics,\nis mathematically sacrosanct, itself resting on real-valued probability.Just as\nthermodynamics has enabled hyper-potent physical technologies from the internal\ncombustion engine to the hydrogen bomb, so information theory has enabled\nhyper-persuasive technologies, from color television to addictive video games.\nOnly a theory of what a brain is and does based on those same principles makes\nlegible and transparent the mechanisms by which such hyper-persuasion works. In\ninformation-theoretic terms, a brain is a specialized real-valued real-time 3D\nprocessor detecting discontinuities in spacetime outside itself and\nreconstituting in itself a continuous reality based on them. This continuous\napproach is difficult to reconcile with any computational architecture based on\nseparate neurons, and in fact the vast discrepancy in efficiency (of order at\nleast a hundred million) between those architectures constitutes the\ncalculations of this paper. This remarkable signal-processing requires strong\nprior hypotheses embedded in 3D edge-detecting algorithms, priors which\nunfortunately also open an unpatchable security hole to automated persuasion.\nSo a 3D model of the brain is essential for understanding how and why\npersuasive technologies alter our perception of reality, and for protecting us\nagainst systemic, systematic cognitive manipulation.\n", "versions": [{"version": "v1", "created": "Sat, 27 Sep 2014 19:28:22 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Softky", "William", ""]]}, {"id": "1409.8278", "submitter": "Marcus Kaiser", "authors": "Jinseop S. Kim and Marcus Kaiser", "title": "From Caenorhabditis elegans to the Human Connectome: A Specific Modular\n  Organisation Increases Metabolic, Functional, and Developmental Efficiency", "comments": null, "journal-ref": "Phil. Trans. R. Soc. B 369: 20130529, 2014", "doi": "10.1098/rstb.2013.0529", "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connectome, or the entire connectivity of a neural system represented by\nnetwork, ranges various scales from synaptic connections between individual\nneurons to fibre tract connections between brain regions. Although the\nmodularity they commonly show has been extensively studied, it is unclear\nwhether connection specificity of such networks can already be fully explained\nby the modularity alone. To answer this question, we study two networks, the\nneuronal network of C. elegans and the fibre tract network of human brains\nyielded through diffusion spectrum imaging (DSI). We compare them to their\nrespective benchmark networks with varying modularities, which are generated by\nlink swapping to have desired modularity values but otherwise maximally random.\nWe find several network properties that are specific to the neural networks and\ncannot be fully explained by the modularity alone. First, the clustering\ncoefficient and the characteristic path length of C. elegans and human\nconnectomes are both higher than those of the benchmark networks with similar\nmodularity. High clustering coefficient indicates efficient local information\ndistribution and high characteristic path length suggests reduced global\nintegration. Second, the total wiring length is smaller than for the\nalternative configurations with similar modularity. This is due to lower\ndispersion of connections, which means each neuron in C. elegans connectome or\neach region of interest (ROI) in human connectome reaches fewer ganglia or\ncortical areas, respectively. Third, both neural networks show lower\nalgorithmic entropy compared to the alternative arrangements. This implies that\nfewer rules are needed to encode for the organisation of neural systems.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 09:17:44 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Kim", "Jinseop S.", ""], ["Kaiser", "Marcus", ""]]}, {"id": "1409.8323", "submitter": "Austin Sendek", "authors": "Austin Sendek, Henry R. Fuller, N. Robert Hayre, Rajiv R. P. Singh,\n  Daniel L. Cox", "title": "Simulated Cytoskeletal Collapse via Tau Degradation", "comments": "11 pages, 9 figures", "journal-ref": "PLoS ONE 9(8): e104965", "doi": "10.1371/journal.pone.0104965", "report-no": null, "categories": "q-bio.NC q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a coarse-grained two dimensional mechanical model for the\nmicrotubule-tau bundles in neuronal axons in which we remove taus, as can\nhappen in various neurodegenerative conditions such as Alzheimer's disease,\ntauopathies, and chronic traumatic encephalopathy. Our simplified model\nincludes (i) taus modeled as entropic springs between microtubules, (ii)\nremoval of taus from the bundles due to phosphorylation, and (iii) a possible\ndepletion force between microtubules due to these dissociated phosphorylated\ntaus. We equilibrate upon tau removal using steepest descent relaxation. In the\nabsence of the depletion force, the transverse rigidity to radial compression\nof the bundle falls to zero at about 60% tau occupancy, in agreement with\nstandard percolation theory results. However, with the attractive depletion\nforce, spring removal leads to a first order collapse of the bundles over a\nwide range of tau occupancies for physiologically realizable conditions. While\nour simplest calculations assume a constant concentration of microtubule\nintercalants to mediate the depletion force, including a dependence that is\nlinear in the detached taus yields the same collapse. Applying percolation\ntheory to removal of taus at microtubule tips, which are likely to be the\nprotective sites against dynamic instability, we argue that the microtubule\ninstability can only obtain at low tau occupancy, from 0.06-0.30 depending upon\nthe tau coordination at the microtubule tips. Hence, the collapse we discover\nis likely to be more robust over a wide range of tau occupancies than the\ndynamic instability. We suggest in vitro tests of our predicted collapse.\n", "versions": [{"version": "v1", "created": "Mon, 29 Sep 2014 20:49:56 GMT"}], "update_date": "2014-10-01", "authors_parsed": [["Sendek", "Austin", ""], ["Fuller", "Henry R.", ""], ["Hayre", "N. Robert", ""], ["Singh", "Rajiv R. P.", ""], ["Cox", "Daniel L.", ""]]}]