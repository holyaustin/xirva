[{"id": "1302.0120", "submitter": "Russell Luke", "authors": "Stephan C. Kramer, Johannes Hagemann and D. Russell Luke", "title": "Real-Time Phase Masks for Interactive Stimulation of Optogenetic Neurons", "comments": "8 pages, 5 figures, 20 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments with networks of optogenetically altered neurons require\nstimulation with high spatio-temporal selectivity. Computer-assisted holography\nis an energy-efficient method for robust and reliable addressing of single\nneurons on the millisecond-timescale inherent to biologial information\nprocessing. We show that real-time control of neurons can be achieved by a\nCUDA-based hologram computation.\n", "versions": [{"version": "v1", "created": "Fri, 1 Feb 2013 10:00:59 GMT"}], "update_date": "2013-02-04", "authors_parsed": [["Kramer", "Stephan C.", ""], ["Hagemann", "Johannes", ""], ["Luke", "D. Russell", ""]]}, {"id": "1302.0476", "submitter": "Kyle Wedgwood", "authors": "Kyle C A Wedgwood, Kevin K Lin, R\\\"udiger Thul, Stephen Coombes", "title": "Phase-amplitude descriptions of neural oscillator models", "comments": "26 pages, 11 figures", "journal-ref": "The Journal of Mathematical Neuroscience 2013, 3:2", "doi": "10.1186/2190-8567-3-2", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Phase oscillators are a common starting point for the reduced description of\nmany single neuron models that exhibit a strongly attracting limit cycle. The\nframework for analysing such models in response to weak perturbations is now\nparticularly well advanced, and has allowed for the development of a theory of\nweakly connected neural networks. However, the strong-attraction assumption may\nwell not be the natural one for many neural oscillator models. For example, the\npopular conductance based Morris-Lecar model is known to respond to periodic\npulsatile stimulation in a chaotic fashion that cannot be adequately described\nwith a phase reduction. In this paper, we generalise the phase description that\nallows one to track the evolution of distance from the cycle as well as phase\non cycle. We use a classical technique from the theory of ordinary differential\nequations that makes use of a moving coordinate system to analyse periodic\norbits. The subsequent phase-amplitude description is shown to be very well\nsuited to understanding the response of the oscillator to external stimuli\n(which are not necessarily weak). We consider a number of examples of neural\noscillator models, ranging from planar through to high dimensional models, to\nillustrate the effectiveness of this approach in providing an improvement over\nthe standard phase-reduction technique. As an explicit application of this\nphase-amplitude framework, we consider in some detail the response of a generic\nplanar model where the strong-attraction assumption does not hold, and examine\nthe response of the system to periodic pulsatile forcing. In addition, we\nexplore how the presence of dynamical shear can lead to a chaotic response.\n", "versions": [{"version": "v1", "created": "Sun, 3 Feb 2013 11:44:49 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Wedgwood", "Kyle C A", ""], ["Lin", "Kevin K", ""], ["Thul", "R\u00fcdiger", ""], ["Coombes", "Stephen", ""]]}, {"id": "1302.0984", "submitter": "Peter Ashwin", "authors": "Peter Ashwin and Claire Postlethwaite", "title": "On designing heteroclinic networks from graphs", "comments": "31 pages, 16 figures", "journal-ref": null, "doi": "10.1016/j.physd.2013.09.006", "report-no": null, "categories": "nlin.AO math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust heteroclinic networks are invariant sets that can appear as attractors\nin symmetrically coupled or otherwise constrained dynamical systems. These\nnetworks may have a very complicated structure that is poorly understood and\ndetermined to a large extent by the constraints and dimension of the system. As\nthese networks are of great interest as dynamical models of biological and\ncognitive processes, it is useful to understand how particular graphs can be\nrealised as robust heteroclinic networks that are attracting. This paper\npresents two methods of realizing arbitrarily complex directed graphs as robust\nheteroclinic networks for flows generated by ODEs---we say the ODEs {\\em\nrealise} the graphs as heteroclinic networks between equilibria that represent\nthe vertices. Suppose we have a directed graph on $n_v$ vertices with $n_e$\nedges. The \"simplex realisation\" embeds the graph as an invariant set of a flow\non an $(n_v-1)$-simplex. This method realises the graph as long as it is one-\nand two-cycle free. The \"cylinder realisation\" embeds a graph as an invariant\nset of a flow on a $(n_e+1)$-dimensional space. This method realises the graph\nas long as it is one-cycle free. In both cases we find the graph as an\ninvariant set within an attractor, and discuss some illustrative examples,\nincluding the influence of noise and parameters on the dynamics. In particular\nwe show that the resulting heteroclinic network may or may not display \"memory\"\nof the vertices visited.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 10:35:07 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2014 18:01:37 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Ashwin", "Peter", ""], ["Postlethwaite", "Claire", ""]]}, {"id": "1302.1029", "submitter": "Olivier Faugeras", "authors": "Olivier Faugeras and James MacLaurin", "title": "A large deviation principle for networks of rate neurons with correlated\n  synaptic weights", "comments": "67 pages. Changed the order of presentation. Clarified and corrected\n  several proofs. Give more details about the limit measure. Main result\n  unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the asymptotic law of a network of interacting neurons when the\nnumber of neurons becomes infinite. Given a completely connected network of\nfiring rate neurons in which the synaptic weights are Gaussian correlated\nrandom variables, we describe the asymptotic law of the network when the number\nof neurons goes to infinity. We introduce the process-level empirical measure\nof the trajectories of the solutions to the equations of the finite network of\nneurons and the averaged law (with respect to the synaptic weights) of the\ntrajectories of the solutions to the equations of the network of neurons. The\nmain result of this article is that the image law through the empirical measure\nsatisfies a large deviation principle with a good rate function which is shown\nto have a unique global minimum. Our analysis of the rate function allows us\nalso to characterize the limit measure as the image of a stationary Gaussian\nmeasure defined on a transformed set of trajectories. This is potentially very\nuseful for applications in neuroscience since the Gaussian measure can be\ncompletely characterized by its mean and spectral density. It also facilitates\nthe assessment of the probability of finite-size effects.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 13:28:19 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2013 14:27:39 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2013 16:36:31 GMT"}, {"version": "v4", "created": "Fri, 31 May 2013 14:45:35 GMT"}], "update_date": "2013-06-03", "authors_parsed": [["Faugeras", "Olivier", ""], ["MacLaurin", "James", ""]]}, {"id": "1302.1758", "submitter": "Andrey Dovzhenok", "authors": "Andrey Dovzhenok, Choongseok Park, Robert M. Worth and Leonid L.\n  Rubchinsky", "title": "Failure of Delayed Feedback Deep Brain Stimulation for Intermittent\n  Pathological Synchronization in Parkinson's Disease", "comments": "19 pages, 8 figures", "journal-ref": "PLoS ONE 8(3): e58264, 2013", "doi": "10.1371/journal.pone.0058264", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suppression of excessively synchronous beta-band oscillatory activity in the\nbrain is believed to suppress hypokinetic motor symptoms of Parkinson's\ndisease. Recently, a lot of interest has been devoted to desynchronizing\ndelayed feedback deep brain stimulation (DBS). This type of synchrony control\nwas shown to destabilize the synchronized state in networks of simple model\noscillators as well as in networks of coupled model neurons. However, the\ndynamics of the neural activity in Parkinson's disease exhibits complex\nintermittent synchronous patterns, far from the idealized synchronous dynamics\nused to study the delayed feedback stimulation. This study explores the action\nof delayed feedback stimulation on partially synchronized oscillatory dynamics,\nsimilar to what one observes experimentally in parkinsonian patients. We employ\na model of the basal ganglia networks which reproduces experimentally observed\nfine temporal structure of the synchronous dynamics. When the parameters of our\nmodel are such that the synchrony is unphysiologically strong, the feedback\nexerts a desynchronizing action. However, when the network is tuned to\nreproduce the highly variable temporal patterns observed experimentally, the\nsame kind of delayed feedback may actually increase the synchrony. As network\nparameters are changed from the range which produces complete synchrony to\nthose favoring less synchronous dynamics, desynchronizing delayed feedback may\ngradually turn into synchronizing stimulation. This suggests that delayed\nfeedback DBS in Parkinson's disease may boost rather than suppress\nsynchronization and is unlikely to be clinically successful. The study also\nindicates that delayed feedback stimulation may not necessarily exhibit a\ndesynchronization effect when acting on a physiologically realistic partially\nsynchronous dynamics, and provides an example of how to estimate the\nstimulation effect.\n", "versions": [{"version": "v1", "created": "Thu, 7 Feb 2013 14:30:52 GMT"}], "update_date": "2013-03-05", "authors_parsed": [["Dovzhenok", "Andrey", ""], ["Park", "Choongseok", ""], ["Worth", "Robert M.", ""], ["Rubchinsky", "Leonid L.", ""]]}, {"id": "1302.3261", "submitter": "Dominique Vuillaume", "authors": "O. Bichler, W. Zhao, F. Alibart, S. Pleutin, S. Lenfant, D. Vuillaume,\n  C. Gamrat", "title": "Pavlov's dog associative learning demonstrated on synaptic-like organic\n  transistors", "comments": null, "journal-ref": "Neural Computation 25(2), 549-566 (2013)", "doi": "10.1162/NECO_a_00377", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.ET cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter, we present an original demonstration of an associative\nlearning neural network inspired by the famous Pavlov's dogs experiment. A\nsingle nanoparticle organic memory field effect transistor (NOMFET) is used to\nimplement each synapse. We show how the physical properties of this dynamic\nmemristive device can be used to perform low power write operations for the\nlearning and implement short-term association using temporal coding and spike\ntiming dependent plasticity based learning. An electronic circuit was built to\nvalidate the proposed learning scheme with packaged devices, with good\nreproducibility despite the complex synaptic-like dynamic of the NOMFET in\npulse regime.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 22:18:49 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Bichler", "O.", ""], ["Zhao", "W.", ""], ["Alibart", "F.", ""], ["Pleutin", "S.", ""], ["Lenfant", "S.", ""], ["Vuillaume", "D.", ""], ["Gamrat", "C.", ""]]}, {"id": "1302.3590", "submitter": "Kathryn Blackmond Laskey", "authors": "Kathryn Blackmond Laskey, Laura Martignon", "title": "Bayesian Learning of Loglinear Models for Neural Connectivity", "comments": "Appears in Proceedings of the Twelfth Conference on Uncertainty in\n  Artificial Intelligence (UAI1996)", "journal-ref": null, "doi": null, "report-no": "UAI-P-1996-PG-373-380", "categories": "cs.LG q-bio.NC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Bayesian approach to learning the connectivity\nstructure of a group of neurons from data on configuration frequencies. A major\nobjective of the research is to provide statistical tools for detecting changes\nin firing patterns with changing stimuli. Our framework is not restricted to\nthe well-understood case of pair interactions, but generalizes the Boltzmann\nmachine model to allow for higher order interactions. The paper applies a\nMarkov Chain Monte Carlo Model Composition (MC3) algorithm to search over\nconnectivity structures and uses Laplace's method to approximate posterior\nprobabilities of structures. Performance of the methods was tested on synthetic\ndata. The models were also applied to data obtained by Vaadia on multi-unit\nrecordings of several neurons in the visual cortex of a rhesus monkey in two\ndifferent attentional states. Results confirmed the experimenters' conjecture\nthat different attentional states were associated with different interaction\nstructures.\n", "versions": [{"version": "v1", "created": "Wed, 13 Feb 2013 14:15:20 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Laskey", "Kathryn Blackmond", ""], ["Martignon", "Laura", ""]]}, {"id": "1302.3651", "submitter": "Philipp H\\\"ovel", "authors": "Vesna Vuksanovi\\'c and Philipp H\\\"ovel", "title": "Large-scale neural network model for functional networks of the human\n  cortex", "comments": "To appear in A. Pelster and G. Wunner (Editors): Proceedings of the\n  International Symposium Selforganization in Complex Systems: The Past,\n  Present, and Future of Synergetics; Hanse Institute of Advanced Studies,\n  Delmenhorst, November 13 -- 16, 2012; Springer Series Understanding Complex\n  Systems, Springer, in preparation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the influence of indirect connections, interregional distance\nand collective effects on the large-scale functional networks of the human\ncortex. We study topologies of empirically derived resting state networks\n(RSNs), extracted from fMRI data, and model dynamics on the obtained networks.\nThe RSNs are calculated from mean time-series of blood-oxygen-level-dependent\n(BOLD) activity of distinct cortical regions via Pearson correlation\ncoefficients. We compare functional-connectivity networks of simulated BOLD\nactivity as a function of coupling strength and correlation threshold. Neural\nnetwork dynamics underpinning the BOLD signal fluctuations are modelled as\nexcitable FitzHugh-Nagumo oscillators subject to uncorrelated white Gaussian\nnoise and time-delayed interactions to account for the finite speed of the\nsignal propagation along the axons. We discuss the functional connectivity of\nsimulated BOLD activity in dependence on the signal speed and correlation\nthreshold and compare it to the empirical data.\n", "versions": [{"version": "v1", "created": "Thu, 14 Feb 2013 23:52:59 GMT"}], "update_date": "2013-02-18", "authors_parsed": [["Vuksanovi\u0107", "Vesna", ""], ["H\u00f6vel", "Philipp", ""]]}, {"id": "1302.3869", "submitter": "Daniele Marinazzo", "authors": "Daniele Marinazzo, Mario Pellicoro, Guorong Wu, Leonardo Angelini,\n  Jesus M Cortes, Sebastiano Stramaglia", "title": "Information transfer of an Ising model on a brain network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement the Ising model on a structural connectivity matrix describing\nthe brain at a coarse scale. Tuning the model temperature to its critical\nvalue, i.e. at the susceptibility peak, we find a maximal amount of total\ninformation transfer between the spin variables. At this point the amount of\ninformation that can be redistributed by some nodes reaches a limit and the net\ndynamics exhibits signature of the law of diminishing marginal returns, a\nfundamental principle connected to saturated levels of production. Our results\nextend the recent analysis of dynamical oscillators models on the connectome\nstructure, taking into account lagged and directional influences, focusing only\non the nodes that are more prone to became bottlenecks of information. The\nratio between the outgoing and the incoming information at each node is related\nto the number of incoming links.\n", "versions": [{"version": "v1", "created": "Fri, 15 Feb 2013 20:32:22 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2013 20:45:14 GMT"}, {"version": "v3", "created": "Wed, 3 Jul 2013 15:39:50 GMT"}, {"version": "v4", "created": "Sun, 1 Sep 2013 14:38:18 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Marinazzo", "Daniele", ""], ["Pellicoro", "Mario", ""], ["Wu", "Guorong", ""], ["Angelini", "Leonardo", ""], ["Cortes", "Jesus M", ""], ["Stramaglia", "Sebastiano", ""]]}, {"id": "1302.3943", "submitter": "Samuel Johnson", "authors": "Samuel Johnson", "title": "Interplay between Network Topology and Dynamics in Neural Systems", "comments": "PhD thesis in physics, defended at the University of Granada in May\n  2011. Advisors: Joaqu\\'in J. Torres and Joaqu\\'in Marro. All the text is in\n  English save for the acknowledgements and a summary in Spanish", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis is a compendium of research which brings together ideas from the\nfields of Complex Networks and Computational Neuroscience to address two\nquestions regarding neural systems:\n  1) How the activity of neurons, via synaptic changes, can shape the topology\nof the network they form part of, and\n  2) How the resulting network structure, in its turn, might condition aspects\nof brain behaviour.\n  Although the emphasis is on neural networks, several theoretical findings\nwhich are relevant for complex networks in general are presented -- such as a\nmethod for studying network evolution as a stochastic process, or a theory that\nallows for ensembles of correlated networks, and sets of dynamical elements\nthereon, to be treated mathematically and computationally in a\nmodel-independent manner. Some of the results are used to explain experimental\ndata -- certain properties of brain tissue, the spontaneous emergence of\ncorrelations in all kinds of networks... -- and predictions regarding\nstatistical aspects of the central nervous system are made. The mechanism of\nCluster Reverberation is proposed to account for the near-instant storage of\nnovel information the brain is capable of.\n", "versions": [{"version": "v1", "created": "Sat, 16 Feb 2013 08:10:04 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Johnson", "Samuel", ""]]}, {"id": "1302.4051", "submitter": "Alexander E. Hramov", "authors": "Evgenia Sitnikova, Alexander E. Hramov, Alexey A. Ovchinnikov, Alexey\n  A. Koronovskii", "title": "On-off intermittency of thalamo-cortical oscillations in the\n  electroencephalogram of rats with genetic predisposition to absence epilepsy", "comments": "15 pages, 5 figures", "journal-ref": "Brain research. 1436 (2012) 147-156", "doi": "10.1016/j.brainres.2011.12.006", "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike-wave discharges (SWD) are electroencephalographic hallmarks of absence\nepilepsy. SWD are known to originate from thalamo-cortical neuronal network\nthat normally produce sleep spindle oscillations. Although both sleep spindles\nand SWD are considered as thalamo-cortical oscillations, functional\nrelationship between them is still uncertain. The present study describes\ntemporal dynamics of SWD and sleep spindles as determined in long-term EEG\nrecordings in WAG/Rij rat model of absence epilepsy. It was found that\nnon-linear dynamics of SWD fits well to the law of 'on-off intermittency'.\nTypical sleep spindles that occur during slow-wave sleep (SWS) also\ndemonstrated 'on-off intermittency' behavior, in contrast to high-voltage\nspindles during intermediate sleep stage, whose dynamics was uncertain. This\nimplies that both SWS sleep spindles and SWD are controlled by a system-level\nmechanism that is responsible for regulating circadian activity and/or\nsleep-wake transitions.\n", "versions": [{"version": "v1", "created": "Sun, 17 Feb 2013 10:17:58 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Sitnikova", "Evgenia", ""], ["Hramov", "Alexander E.", ""], ["Ovchinnikov", "Alexey A.", ""], ["Koronovskii", "Alexey A.", ""]]}, {"id": "1302.4257", "submitter": "Mayya Miftakhova", "authors": "M.B. Miftakhova, V.V Babenko", "title": "Features of the second-order visual filters sensitive to the spatial\n  frequency modulations", "comments": "3 pages, 4 figures", "journal-ref": "Miftakhova M.B., Babenko V.V. \"Features of the second-order visual\n  filters sensitive to the spatial frequency modulations\". Proceedings XVI\n  International Conference on Neurocybernetics. Rostov-on-Don: SFU-Press. Vol.1\n  P. 432-434. 2012", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated selectivity of 2nd order visual filters sensitive to the\nspatial frequency (SF) modulations to orientation and to SF of modulation. We\ncarried out psychophysical experiment using masking paradigm. It was found that\n2nd order filters are selective to SF of modulation (with bandwidth +1.5\noctaves), and do not show any selectivity to orientation of modulation. We\nsuppose receptive fields of 2nd order mechanisms have concentric form.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 13:12:05 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Miftakhova", "M. B.", ""], ["Babenko", "V. V", ""]]}, {"id": "1302.4273", "submitter": "Marco Winkler", "authors": "Marco Winkler and Sebastian Butsch and Wolfgang Kinzel", "title": "Pulsed chaos synchronization in networks with adaptive couplings", "comments": "8 pages 13 figures", "journal-ref": "Phys. Rev. E 86, 016203 (2012)", "doi": "10.1103/PhysRevE.86.016203", "report-no": null, "categories": "nlin.CD cond-mat.stat-mech nlin.AO physics.comp-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks of chaotic units with static couplings can synchronize to a common\nchaotic trajectory. The effect of dynamic adaptive couplings on the cooperative\nbehavior of chaotic networks is investigated. The couplings adjust to the\nactivities of its two units by two competing mechanisms: An exponential\ndecrease of the coupling strength is compensated by an increase due to\nde-synchronized activity. This mechanism prevents the network from reaching a\nsteady state. Numerical simulations of a coupled map lattice show chaotic\ntrajectories of de-synchronized units interrupted by pulses of mutually\nsynchronized clusters. These pulses occur on all scales, sometimes extending to\nthe entire network. Clusters of synchronized units can be triggered by a small\ngroup of synchronized units.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 13:59:25 GMT"}], "update_date": "2013-04-12", "authors_parsed": [["Winkler", "Marco", ""], ["Butsch", "Sebastian", ""], ["Kinzel", "Wolfgang", ""]]}, {"id": "1302.4559", "submitter": "Szymon {\\L}{\\ke}ski", "authors": "Szymon {\\L}\\k{e}ski, Henrik Lind\\'en, Tom Tetzlaff, Klas H. Pettersen,\n  Gaute T. Einevoll", "title": "Frequency dependence of signal power and spatial reach of the local\n  field potential", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first recording of electrical potential from brain activity was reported\nalready in 1875, but still the interpretation of the signal is debated. To take\nfull advantage of the new generation of microelectrodes with hundreds or even\nthousands of electrode contacts, an accurate quantitative link between what is\nmeasured and the underlying neural circuit activity is needed. Here we address\nthe question of how the observed frequency dependence of recorded local field\npotentials (LFPs) should be interpreted. By use of a well-established\nbiophysical modeling scheme, combined with detailed reconstructed neuronal\nmorphologies, we find that correlations in the synaptic inputs onto a\npopulation of pyramidal cells may significantly boost the low-frequency\ncomponents of the generated LFP. We further find that these low-frequency\ncomponents may be less `local' than the high-frequency LFP components in the\nsense that (1) the size of signal-generation region of the LFP recorded at an\nelectrode is larger and (2) that the LFP generated by a synaptically activated\npopulation spreads further outside the population edge due to volume\nconduction.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 09:52:38 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["\u0141\u0119ski", "Szymon", ""], ["Lind\u00e9n", "Henrik", ""], ["Tetzlaff", "Tom", ""], ["Pettersen", "Klas H.", ""], ["Einevoll", "Gaute T.", ""]]}, {"id": "1302.5007", "submitter": "Bruno. Cessac", "authors": "B. Cessac and R. Cofr\\'e", "title": "Spike train statistics and Gibbs distributions", "comments": "23 pages, submitted", "journal-ref": "J. Physiol. Paris, Volume 107, Issue 5, Pages 360-368 (November\n  2013). Special issue: Neural Coding and Natural Image Statistics", "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is based on a lecture given in the LACONEU summer school,\nValparaiso, January 2012. We introduce Gibbs distribution in a general setting,\nincluding non stationary dynamics, and present then three examples of such\nGibbs distributions, in the context of neural networks spike train statistics:\n(i) Maximum entropy model with spatio-temporal constraints; (ii) Generalized\nLinear Models; (iii) Conductance based Inte- grate and Fire model with chemical\nsynapses and gap junctions.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 15:58:32 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Cessac", "B.", ""], ["Cofr\u00e9", "R.", ""]]}, {"id": "1302.5055", "submitter": "Marcus Kaiser", "authors": "Iwo Jerzy Bohr, Eva Kenny, Andrew Blamire, John T. O'Brien, Alan J.\n  Thomas, Jonathan Richardson and Marcus Kaiser", "title": "Resting-State Functional Connectivity in Late-Life Depression: Higher\n  Global Connectivity and More Long Distance Connections", "comments": null, "journal-ref": "Front Psychiatry. 2012; 3: 116", "doi": "10.3389/fpsyt.2012.00116", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional magnetic resonance imaging recordings in the resting-state (RS)\nfrom the human brain are characterized by spontaneous low-frequency\nfluctuations in the blood oxygenation level dependent signal that reveal\nfunctional connectivity (FC) via their spatial synchronicity. This RS study\napplied network analysis to compare FC between late-life depression (LLD)\npatients and control subjects. Raw cross-correlation matrices (CM) for LLD were\ncharacterized by higher FC. We analyzed the small-world (SW) and modular\norganization of these networks consisting of 110 nodes each as well as the\nconnectivity patterns of individual nodes of the basal ganglia. Topological\nnetwork measures showed no significant differences between groups. The\ncomposition of top hubs was similar between LLD and control subjects, however\nin the LLD group posterior medial-parietal regions were more highly connected\ncompared to controls. In LLD, a number of brain regions showed connections with\nmore distant neighbors leading to an increase of the average Euclidean distance\nbetween connected regions compared to controls. In addition, right caudate\nnucleus connectivity was more diffuse in LLD. In summary, LLD was associated\nwith overall increased FC strength and changes in the average distance between\nconnected nodes, but did not lead to global changes in SW or modular\norganization.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 18:04:58 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Bohr", "Iwo Jerzy", ""], ["Kenny", "Eva", ""], ["Blamire", "Andrew", ""], ["O'Brien", "John T.", ""], ["Thomas", "Alan J.", ""], ["Richardson", "Jonathan", ""], ["Kaiser", "Marcus", ""]]}, {"id": "1302.5331", "submitter": "Jonathan Crofts", "authors": "Reuben O'Dea, Jonathan J. Crofts and Marcus Kaiser", "title": "Spreading dynamics on spatially constrained complex brain networks", "comments": null, "journal-ref": "Journal of the Royal Society Interface 2013, 10(81), 20130016", "doi": "10.1098/rsif.2013.0016", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.CG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of dynamical systems defined on complex networks provides a natural\nframework with which to investigate myriad features of neural dynamics, and has\nbeen widely undertaken. Typically, however, networks employed in theoretical\nstudies bear little relation to the spatial embedding or connectivity of the\nneural networks that they attempt to replicate. Here, we employ detailed\nneuroimaging data to define a network whose spatial embedding represents\naccurately the folded structure of the cortical surface of a rat and\ninvestigate the propagation of activity over this network under simple\nspreading and connectivity rules. By comparison with standard network models\nwith the same coarse statistics, we show that the cortical geometry influences\nprofoundly the speed propagation of activation through the network. Our\nconclusions are of high relevance to the theoretical modelling of epileptic\nseizure events, and indicate that such studies which omit physiological network\nstructure risk simplifying the dynamics in a potentially significant way.\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 16:40:14 GMT"}], "update_date": "2013-02-22", "authors_parsed": [["O'Dea", "Reuben", ""], ["Crofts", "Jonathan J.", ""], ["Kaiser", "Marcus", ""]]}, {"id": "1302.5526", "submitter": "Richard A. Blythe", "authors": "Rainer Reisenauer, Kenny Smith and Richard A. Blythe", "title": "Stochastic dynamics of lexicon learning in an uncertain and nonuniform\n  world", "comments": "7 pages, 3 figures. Version 2 contains additional discussion and will\n  appear in Phys. Rev. Lett", "journal-ref": "Phys Rev Lett (2013) 110 258701", "doi": "10.1103/PhysRevLett.110.258701", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the time taken by a language learner to correctly identify the\nmeaning of all words in a lexicon under conditions where many plausible\nmeanings can be inferred whenever a word is uttered. We show that the most\nbasic form of cross-situational learning - whereby information from multiple\nepisodes is combined to eliminate incorrect meanings - can perform badly when\nwords are learned independently and meanings are drawn from a nonuniform\ndistribution. If learners further assume that no two words share a common\nmeaning, we find a phase transition between a maximally-efficient learning\nregime, where the learning time is reduced to the shortest it can possibly be,\nand a partially-efficient regime where incorrect candidate meanings for words\npersist at late times. We obtain exact results for the word-learning process\nthrough an equivalence to a statistical mechanical problem of enumerating loops\nin the space of word-meaning mappings.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2013 09:23:50 GMT"}, {"version": "v2", "created": "Fri, 31 May 2013 08:20:34 GMT"}], "update_date": "2015-05-26", "authors_parsed": [["Reisenauer", "Rainer", ""], ["Smith", "Kenny", ""], ["Blythe", "Richard A.", ""]]}, {"id": "1302.5616", "submitter": "Martin Riedler", "authors": "Christian Kuehn and Martin G. Riedler", "title": "Large Deviations for Nonlocal Stochastic Neural Fields", "comments": "29 pages", "journal-ref": "Journal of Mathematical Neuroscience, Vol. 4, No. 1, pp. 1-33,\n  2014", "doi": "10.1186/2190-8567-4-1", "report-no": null, "categories": "math.PR math.DS physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of additive noise on integro-differential neural field\nequations. In particular, we analyze an Amari-type model driven by a $Q$-Wiener\nprocess and focus on noise-induced transitions and escape. We argue that\nproving a sharp Kramers' law for neural fields poses substanial difficulties\nbut that one may transfer techniques from stochastic partial differential\nequations to establish a large deviation principle (LDP). Then we demonstrate\nthat an efficient finite-dimensional approximation of the stochastic neural\nfield equation can be achieved using a Galerkin method and that the resulting\nfinite-dimensional rate function for the LDP can have a multi-scale structure\nin certain cases. These results form the starting point for an efficient\npractical computation of the LDP. Our approach also provides the technical\nbasis for further rigorous study of noise-induced transitions in neural fields\nbased on Galerkin approximations.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2013 15:14:20 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2013 12:05:58 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Kuehn", "Christian", ""], ["Riedler", "Martin G.", ""]]}, {"id": "1302.5721", "submitter": "Sean Simpson", "authors": "Sean L. Simpson, F. DuBois Bowman, Paul J. Laurienti", "title": "Analyzing complex functional brain networks: fusing statistics and\n  network science to understand the brain", "comments": "Statistics Surveys, In Press", "journal-ref": "Statistics Surveys (2013) 7, 1-36", "doi": "10.1214/13-SS103", "report-no": null, "categories": "stat.ME q-bio.NC q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex functional brain network analyses have exploded over the last eight\nyears, gaining traction due to their profound clinical implications. The\napplication of network science (an interdisciplinary offshoot of graph theory)\nhas facilitated these analyses and enabled examining the brain as an integrated\nsystem that produces complex behaviors. While the field of statistics has been\nintegral in advancing activation analyses and some connectivity analyses in\nfunctional neuroimaging research, it has yet to play a commensurate role in\ncomplex network analyses. Fusing novel statistical methods with network-based\nfunctional neuroimage analysis will engender powerful analytical tools that\nwill aid in our understanding of normal brain function as well as alterations\ndue to various brain disorders. Here we survey widely used statistical and\nnetwork science tools for analyzing fMRI network data and discuss the\nchallenges faced in filling some of the remaining methodological gaps. When\napplied and interpreted correctly, the fusion of network scientific and\nstatistical methods has a chance to revolutionize the understanding of brain\nfunction.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2013 21:50:37 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2013 14:02:12 GMT"}, {"version": "v3", "created": "Tue, 22 Oct 2013 20:40:21 GMT"}], "update_date": "2013-10-28", "authors_parsed": [["Simpson", "Sean L.", ""], ["Bowman", "F. DuBois", ""], ["Laurienti", "Paul J.", ""]]}, {"id": "1302.5804", "submitter": "Georgi Medvedev S.", "authors": "Georgi S. Medvedev", "title": "The nonlinear heat equation on dense graphs and graph limits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the combination of ideas and results from the theory of graph limits\nand nonlinear evolution equations to provide a rigorous mathematical\njustification for taking continuum limit for certain nonlocally coupled\nnetworks and to extend this method to cover many complex networks, for which it\nhas not been applied before. Specifically, for dynamical networks on convergent\nsequences of simple and weighted graphs, we prove convergence of solutions of\nthe initial-value problems for discrete models to those of the limiting\ncontinuous equations. In addition, for sequences of simple graphs converging to\n{0, 1}-valued graphons, it is shown that the convergence rate depends on the\nfractal dimension of the boundary of the support of the graph limit. These\nresults are then used to study the regions of continuity of chimera states and\nthe attractors of the nonlocal Kuramoto equation on certain multipartite\ngraphs. Furthermore, the analytical tools developed in this work are used in\nthe rigorous justification of the continuum limit for networks on random graphs\nthat we undertake in a companion paper (Medvedev, 2013).\n  As a by-product of the analysis of the continuum limit on deterministic and\nrandom graphs, we identify the link between this problem and the convergence\nanalysis of several classical numerical schemes: the collocation, Galerkin, and\nMonte-Carlo methods. Therefore, our results can be used to characterize\nconvergence of these approximate methods of solving initial-value problems for\nnonlinear evolution equations with nonlocal interactions.\n", "versions": [{"version": "v1", "created": "Sat, 23 Feb 2013 14:30:52 GMT"}, {"version": "v2", "created": "Sun, 15 Sep 2013 21:04:56 GMT"}, {"version": "v3", "created": "Fri, 22 Nov 2013 20:51:16 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Medvedev", "Georgi S.", ""]]}, {"id": "1302.5866", "submitter": "Sungwoo Ahn", "authors": "Sungwoo Ahn and Leonid L. Rubchinsky", "title": "Short desynchronization episodes prevail in synchronous dynamics of\n  human brain rhythms", "comments": "7 pages, 7 figures. The paper will appear in Chaos", "journal-ref": "Chaos 23(1):013138, 2013", "doi": "10.1063/1.4794793", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural synchronization is believed to be critical for many brain functions.\nIt frequently exhibits temporal variability, but it is not known if this\nvariability has a specific temporal patterning. This study explores these\nsynchronization/desynchronization patterns. We employ recently developed\ntechniques to analyze the fine temporal structure of phase-locking to study the\ntemporal patterning of synchrony of the human brain rhythms. We study neural\noscillations recorded by EEG in $\\alpha$ and $\\beta$ frequency bands in healthy\nhuman subjects at rest and during the execution of a task. While the\nphase-locking strength depends on many factors, dynamics of synchrony has a\nvery specific temporal pattern: synchronous states are interrupted by frequent,\nbut short desynchronization episodes. The probability for a desynchronization\nepisode to occur decreased with its duration. The transition matrix between\nsynchronized and desynchronized states has eigenvalues close to 0 and 1 where\neigenvalue 1 has multiplicity 1, and therefore if the stationary distribution\nbetween these states is perturbed, the system converges back to the stationary\ndistribution very fast. The qualitative similarity of this patterning across\ndifferent subjects, brain states and electrode locations suggests that this may\nbe a general type of dynamics for the brain. Earlier studies indicate that not\nall oscillatory networks have this kind of patterning of\nsynchronization/desynchronization dynamics. Thus the observed prevalence of\nshort (but potentially frequent) desynchronization events (length of one cycle\nof oscillations) may have important functional implications for the brain.\nNumerous short desynchronizations (as opposed to infrequent, but long\ndesynchronizations) may allow for a quick and efficient formation and break-up\nof functionally significant neuronal assemblies.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2013 03:49:44 GMT"}], "update_date": "2013-03-11", "authors_parsed": [["Ahn", "Sungwoo", ""], ["Rubchinsky", "Leonid L.", ""]]}, {"id": "1302.5904", "submitter": "Eleonora Catsigeras", "authors": "Eleonora Catsigeras", "title": "Dynamics of large cooperative pulsed-coupled networks", "comments": "We introduced the changes suggested by the referees. To appear in\n  Journal of Dynamics and Games\n  http://aimsciences.org/journals/home.jsp?journalID=26, Vol. 1 N. 2, aprox.\n  April 2014. Premat 2013/160 (Prepublicaciones de la Universidad de la\n  Rep\\'ublica) http://premat.fing.edu.uy/papers/2013/160.pdf", "journal-ref": "Journal of Dynamics and Games, ISSN 2164-6066, Vol.1, Nr. 2, pp.\n  225-281, 2014", "doi": "10.3934/jdg.2014.1.255", "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the deterministic dynamics of networks N composed by m non\nidentical, mutually pulse-coupled cells. We assume weighted, asymmetric and\npositive (cooperative) interactions among the cells, and arbitrarily large\nvalues of m. We consider two cases of the network's graph: the complete graph,\nand the existence of a large core (i.e. a large complete subgraph). First, we\nprove that the system periodically eventually synchronizes with a natural\n\"spiking period\" \\ p >=1, and that if the cells are mutually structurally\nidentical or similar, then the synchronization is complete (p= 1) . Second, we\nprove that the amount of information H that N generates or processes equals log\np. Therefore, if N completely synchronizes, the information is null. Finally,\nwe prove that N protects the cells from their risk of death.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2013 13:35:33 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2014 16:32:19 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Catsigeras", "Eleonora", ""]]}, {"id": "1302.5917", "submitter": "N Khusnutdinov", "authors": "Y. Suleymanov, F. Gafarov, N. Khusnutdinov", "title": "Modeling of interstitial branching of axonal networks", "comments": "12 pages, 7 figures", "journal-ref": "1. J. Integr. Neurosci. 12, 1-14, (2013)", "doi": "10.1142/S0219635213500064", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A single axon can generate branches connecting with plenty synaptic targets.\nProcess of branching is very important for making connections in central\nnervous system. The interstitial branching along primary axon shaft occurs\nduring nervous system development. Growing axon makes pause in its movement and\nleaves active points behind its terminal. The new branches appear from these\npoints. We suggest mathematical model to describe and investigate neural\nnetwork branching process. The model under consideration describes neural\nnetwork growth in which the concentration of axon guidance molecules manages\naxon's growth. We model the interstitial branching from axon shaft. Numerical\nsimulations show that in the model framework axonal networks are similar to\nneural network.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2013 15:53:19 GMT"}], "update_date": "2013-04-25", "authors_parsed": [["Suleymanov", "Y.", ""], ["Gafarov", "F.", ""], ["Khusnutdinov", "N.", ""]]}, {"id": "1302.5964", "submitter": "Il Memming Park", "authors": "Il Memming Park, Sohan Seth, Antonio R. C. Paiva, Lin Li, Jose C.\n  Principe", "title": "Kernel methods on spike train space for neuroscience: a tutorial", "comments": "12 pages, 8 figures, accepted in IEEE Signal Processing Magazine", "journal-ref": "IEEE Signal Processing Magazine 30(4), 2013", "doi": "10.1109/MSP.2013.2251072", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade several positive definite kernels have been proposed to\ntreat spike trains as objects in Hilbert space. However, for the most part,\nsuch attempts still remain a mere curiosity for both computational\nneuroscientists and signal processing experts. This tutorial illustrates why\nkernel methods can, and have already started to, change the way spike trains\nare analyzed and processed. The presentation incorporates simple mathematical\nanalogies and convincing practical examples in an attempt to show the yet\nunexplored potential of positive definite functions to quantify point\nprocesses. It also provides a detailed overview of the current state of the art\nand future challenges with the hope of engaging the readers in active\nparticipation.\n", "versions": [{"version": "v1", "created": "Sun, 24 Feb 2013 22:44:20 GMT"}], "update_date": "2013-10-16", "authors_parsed": [["Park", "Il Memming", ""], ["Seth", "Sohan", ""], ["Paiva", "Antonio R. C.", ""], ["Li", "Lin", ""], ["Principe", "Jose C.", ""]]}, {"id": "1302.6952", "submitter": "Jonathan Touboul", "authors": "Mathieu Galtier and Jonathan Touboul", "title": "Macroscopic equations governing noisy spiking neuronal populations", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0078917", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At functional scales, cortical behavior results from the complex interplay of\na large number of excitable cells operating in noisy environments. Such systems\nresist to mathematical analysis, and computational neurosciences have largely\nrelied on heuristic partial (and partially justified) macroscopic models, which\nsuccessfully reproduced a number of relevant phenomena. The relationship\nbetween these macroscopic models and the spiking noisy dynamics of the\nunderlying cells has since then been a great endeavor. Based on recent\nmean-field reductions for such spiking neurons, we present here {a principled\nreduction of large biologically plausible neuronal networks to firing-rate\nmodels, providing a rigorous} relationship between the macroscopic activity of\npopulations of spiking neurons and popular macroscopic models, under a few\nassumptions (mainly linearity of the synapses). {The reduced model we derive\nconsists of simple, low-dimensional ordinary differential equations with}\nparameters and {nonlinearities derived from} the underlying properties of the\ncells, and in particular the noise level. {These simple reduced models are\nshown to reproduce accurately the dynamics of large networks in numerical\nsimulations}. Appropriate parameters and functions are made available {online}\nfor different models of neurons: McKean, Fitzhugh-Nagumo and Hodgkin-Huxley\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 27 Feb 2013 18:33:10 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Galtier", "Mathieu", ""], ["Touboul", "Jonathan", ""]]}]