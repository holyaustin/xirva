[{"id": "0801.0011", "submitter": "Quang-Cuong Pham", "authors": "Nicolas Tabareau, Jean-Jacques Slotine, Quang-Cuong Pham", "title": "How synchronization protects from noise", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronization phenomena are pervasive in biology. In neuronal networks, the\nmechanisms of synchronization have been extensively studied from both\nphysiological and computational viewpoints. The functional role of\nsynchronization has also attracted much interest and debate. In particular,\nsynchronization may allow distant sites in the brain to communicate and\ncooperate with each other, and therefore it may play a role in temporal binding\nand in attention and sensory-motor integration mechanisms.\n  In this article, we study another role for synchronization: the so-called\n\"collective enhancement of precision.\" We argue, in a full nonlinear dynamical\ncontext, that synchronization may help protect interconnected neurons from the\ninfluence of random perturbations -- intrinsic neuronal noise -- which affect\nall neurons in the nervous system. This property may allow reliable\ncomputations to be carried out even in the presence of significant noise (as\nexperimentally found e.g., in retinal ganglion cells in primates), as\nmathematically it is key to obtaining meaningful downstream signals, whether in\nterms of precisely-timed interaction (temporal coding), population coding, or\nfrequency coding. Using stochastic contraction theory, we show how\nsynchronization of nonlinear dynamical systems helps protect these systems from\nrandom perturbations.\n  Our main contribution is a mathematical proof that, under specific quantified\nconditions, the impact of noise on each individual system and on the spatial\nmean can essentially be cancelled through synchronization. Similar concepts may\nbe applicable to questions in systems biology.\n", "versions": [{"version": "v1", "created": "Fri, 28 Dec 2007 22:28:47 GMT"}, {"version": "v2", "created": "Sun, 6 Apr 2008 16:37:38 GMT"}, {"version": "v3", "created": "Thu, 13 Nov 2008 20:56:31 GMT"}, {"version": "v4", "created": "Wed, 1 Apr 2009 04:47:34 GMT"}, {"version": "v5", "created": "Thu, 18 Jun 2009 06:07:40 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Tabareau", "Nicolas", ""], ["Slotine", "Jean-Jacques", ""], ["Pham", "Quang-Cuong", ""]]}, {"id": "0801.0250", "submitter": "Alexander K. Vidybida", "authors": "A. K. Vidybida", "title": "Information processing at single neuron level", "comments": "6 pages, 5 figures, \"Modulation of neuronal signaling: Implications\n  for visual perception\", NATO ARW, July 12-21 2000, Nida, Lithuania", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": null, "abstract": "  Based on numerical simulation of Hodgkin and Huxley type neuron stimulated\nfrom many synaptic inputs, an abstract concept of signal processing in\nindividual neuron is proposed. In the concept proposed, neuron performs binding\nof synaptic inputs into a single output event, based on the degree of temporal\ncoherence between the inputs. Inhibition serves as controlling factor of this\ntype of binding.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2007 23:17:54 GMT"}], "update_date": "2008-01-03", "authors_parsed": [["Vidybida", "A. K.", ""]]}, {"id": "0801.0253", "submitter": "William Bialek", "authors": "Greg J. Stephens and William Bialek", "title": "Toward a statistical mechanics of four letter words", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevE.81.066119", "report-no": null, "categories": "q-bio.NC cs.CL physics.data-an physics.soc-ph", "license": null, "abstract": "  We consider words as a network of interacting letters, and approximate the\nprobability distribution of states taken on by this network. Despite the\nintuition that the rules of English spelling are highly combinatorial (and\narbitrary), we find that maximum entropy models consistent with pairwise\ncorrelations among letters provide a surprisingly good approximation to the\nfull statistics of four letter words, capturing ~92% of the multi-information\namong letters and even \"discovering\" real words that were not represented in\nthe data from which the pairwise correlations were estimated. The maximum\nentropy model defines an energy landscape on the space of possible words, and\nlocal minima in this landscape account for nearly two-thirds of words used in\nwritten English.\n", "versions": [{"version": "v1", "created": "Mon, 31 Dec 2007 23:51:51 GMT"}], "update_date": "2013-05-29", "authors_parsed": [["Stephens", "Greg J.", ""], ["Bialek", "William", ""]]}, {"id": "0801.0311", "submitter": "Tatyana Sharpee", "authors": "Tatyana O. Sharpee", "title": "Comparison of objective functions for estimating linear-nonlinear models", "comments": "to appear in Advances in Neural Information Processing Systems 21\n  (NIPS, 2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": null, "abstract": "  This paper compares a family of methods for characterizing neural feature\nselectivity with natural stimuli in the framework of the linear-nonlinear\nmodel. In this model, the neural firing rate is a nonlinear function of a small\nnumber of relevant stimulus components. The relevant stimulus dimensions can be\nfound by maximizing one of the family of objective functions, Renyi divergences\nof different orders. We show that maximizing one of them, Renyi divergence of\norder 2, is equivalent to least-square fitting of the linear-nonlinear model to\nneural data. Next, we derive reconstruction errors in relevant dimensions found\nby maximizing Renyi divergences of arbitrary order in the asymptotic limit of\nlarge spike numbers. We find that the smallest rrors are obtained with Renyi\ndivergence of order 1, also known as Kullback-Leibler divergence. This\ncorresponds to finding relevant dimensions by maximizing mutual information. We\nnumerically test how these optimization schemes perform in the regime of low\nsignal-to-noise ratio (small number of spikes and increasing neural noise) for\nmodel visual neurons. We find that optimization schemes based on either least\nsquare fitting or information maximization perform well even when number of\nspikes is small. Information maximization provides slightly, but significantly,\nbetter reconstructions than least square fitting. This makes the problem of\nfinding relevant dimensions, together with the problem of lossy compression,\none of examples where information-theoretic measures are no more data limited\nthan those derived from least squares.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2008 07:13:48 GMT"}], "update_date": "2008-01-03", "authors_parsed": [["Sharpee", "Tatyana O.", ""]]}, {"id": "0801.1885", "submitter": "Takuma Tanaka", "authors": "Takuma Tanaka, Takeshi Kaneko, Toshio Aoyagi", "title": "Recurrent infomax generates cell assemblies, avalanches, and simple\n  cell-like selectivity", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": null, "abstract": "  Through evolution, animals have acquired central nervous systems (CNSs),\nwhich are extremely efficient information processing devices that improve an\nanimal's adaptability to various environments. It has been proposed that the\nprocess of information maximization (infomax), which maximizes the information\ntransmission from the input to the output of a feedforward network, may provide\nan explanation of the stimulus selectivity of neurons in CNSs. However, CNSs\ncontain not only feedforward but also recurrent synaptic connections, and\nlittle is known about information retention over time in such recurrent\nnetworks. Here, we propose a learning algorithm based on infomax in a recurrent\nnetwork, which we call \"recurrent infomax\" (RI). RI maximizes information\nretention and thereby minimizes information loss in a network. We find that\nfeeding in external inputs consisting of information obtained from photographs\nof natural scenes into an RI-based model of a recurrent network results in the\nappearance of Gabor-like selectivity quite similar tothat existing in simple\ncells of the primary visual cortex (V1). More importantly, we find that without\nexternal input, this network exhibits cell assembly-like and synfire chain-like\nspontaneous activity and a critical neuronal avalanche. RI provides a simple\nframework to explain a wide range of phenomena observed in in vivo and in vitro\nneuronal networks, and it should provide a novel understanding of experimental\nresults for multineuronal activity and plasticity from an information-theoretic\npoint of view.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2008 08:16:23 GMT"}], "update_date": "2008-01-15", "authors_parsed": [["Tanaka", "Takuma", ""], ["Kaneko", "Takeshi", ""], ["Aoyagi", "Toshio", ""]]}, {"id": "0801.1931", "submitter": "Anca Radulescu", "authors": "Anca Radulescu, Kingsley Cox, Paul Adams", "title": "Hebbian Inspecificity in the Oja Model", "comments": "42 pages (including appendices and references); 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": null, "abstract": "  Recent work on Long Term Potentiation in brain slices shows that Hebb's rule\nis not completely synapse-specific, probably due to intersynapse diffusion of\ncalcium or other factors. We extend the classical Oja unsupervised model of\nlearning by a single linear neuron to include Hebbian inspecificity, by\nintroducing an error matrix E, which expresses possible crosstalk between\nupdating at different connections. We show the modified algorithm converges to\nthe leading eigenvector of the matrix EC, where C is the input covariance\nmatrix. When there is no inspecificity, this gives the classical result of\nconvergence to the first principal component of the input distribution (PC1).\nWe then study the outcome of learning using different versions of E. In the\nmost biologically plausible case, arising when there are no intrinsically\nprivileged connections, E has diagonal elements Q and off- diagonal elements\n(1-Q)/(n-1), where Q, the quality, is expected to decrease with the number of\ninputs n. We analyze this error-onto-all case in detail, for both uncorrelated\nand correlated inputs. We study the dependence of the angle theta between PC1\nand the leading eigenvector of EC on b, n and the amount of input activity or\ncorrelation. (We do this analytically and using Matlab calculations.) We find\nthat theta increases (learning becomes gradually less useful) with increases in\nb, particularly for intermediate (i.e. biologically-realistic) correlation\nstrength, although some useful learning always occurs up to the trivial limit Q\n= 1/n. We discuss the relation of our results to Hebbian unsupervised learning\nin the brain.\n", "versions": [{"version": "v1", "created": "Sun, 13 Jan 2008 03:16:12 GMT"}], "update_date": "2008-01-15", "authors_parsed": [["Radulescu", "Anca", ""], ["Cox", "Kingsley", ""], ["Adams", "Paul", ""]]}, {"id": "0801.3056", "submitter": "Luciano da Fontoura Costa", "authors": "Luciano da Fontoura Costa", "title": "Transient and Equilibrium Synchronization in Complex Neuronal Networks", "comments": "25 pages, 26 figures. A working manuscript: comments and suggestions\n  welcomed", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": null, "abstract": "  Transient and equilibrium synchronizations in complex neuronal networks as a\nconsequence of dynamics induced by having sources placed at specific neurons\nare investigated. The basic integrate-and-fire neuron is adopted, and the\ndynamics is estimated computationally so as to obtain the activation at each\nnode along each instant of time. In the transient case, the dynamics is\nimplemented so as to conserve the total activation entering the system. In our\nequilibrium investigations, the internally stored activation is limited to the\nvalue of the respective threshold. The synchronization of the activation of the\nnetwork is then quantified in terms of its normalized entropy. The equilibrium\ninvestigations involve the application of a number of complementary\ncharacterization methods, including spectra and Principal Component Analysis,\nas well as of an equivalent model capable of reproducing both the transient and\nequilibrium dynamics. The potential of such concepts and measurements is\nexplored with respect to several theoretical models, as well as for the\nneuronal network of \\emph{C. elegans}. A series of interesting results are\nobtained and discussed, including the fact that all models led to a transient\nperiod of synchronization, whose specific features depend on the topological\nstructures of the networks. The investigations of the equilibrium dynamics\nrevealed a series of remarkable insights, including the relationship between\nspiking oscillations and the hierarchical structure of the networks and the\nidentification of twin correlation patterns between node degree and total\nactivation, implying that hubs of connectivity are also hubs of\nintegrate-and-fire activation.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2008 02:04:19 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2008 14:08:43 GMT"}], "update_date": "2008-02-18", "authors_parsed": [["Costa", "Luciano da Fontoura", ""]]}, {"id": "0801.3651", "submitter": "Matthias Kaschube", "authors": "Matthias Kaschube, Michael Schnabel and Fred Wolf", "title": "Self-organization and the selection of pinwheel density in visual\n  cortical development", "comments": "22 pages, 3 figures", "journal-ref": null, "doi": "10.1088/1367-2630/10/1/015009", "report-no": null, "categories": "q-bio.NC", "license": null, "abstract": "  Self-organization of neural circuitry is an appealing framework for\nunderstanding cortical development, yet its applicability remains unconfirmed.\nModels for the self-organization of neural circuits have been proposed, but\nexperimentally testable predictions of these models have been less clear. The\nvisual cortex contains a large number of topological point defects, called\npinwheels, which are detectable in experiments and therefore in principle well\nsuited for testing predictions of self-organization empirically. Here, we\nanalytically calculate the density of pinwheels predicted by a pattern\nformation model of visual cortical development. An important factor controlling\nthe density of pinwheels in this model appears to be the presence of non-local\nlong-range interactions, a property which distinguishes cortical circuits from\nmany nonliving systems in which self-organization has been studied. We show\nthat in the limit where the range of these interactions is infinite, the\naverage pinwheel density converges to $\\pi$. Moreover, an average pinwheel\ndensity close to this value is robustly selected even for intermediate\ninteraction ranges, a regime arguably covering interaction-ranges in a wide\nrange of different species. In conclusion, our paper provides the first direct\ntheoretical demonstration and analysis of pinwheel density selection in models\nof cortical self-organization and suggests to quantitatively probe this type of\nprediction in future high-precision experiments.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2008 19:42:06 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Kaschube", "Matthias", ""], ["Schnabel", "Michael", ""], ["Wolf", "Fred", ""]]}, {"id": "0801.3764", "submitter": "Indranil Mitra Mr", "authors": "Sisir Roy, Indranil Mitra, Rodolfo Llinas", "title": "Non Markovian Noise mediated through Anamolous Diffusion within Ion\n  Channels", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": null, "abstract": "  It is quite clear from a wide range of experiments that gating phenomena of\nion channels is inherently stochastic. It has been discussed using BD\nsimulations in a recent paper that memory effects in ion transport is\nnegligible, unless the barrier height is high. In this brief report we like to\nstate using Differential Stochastic Methods (DSM's) that the Markovian property\nof exponential dwell times do indeed give rise to a high barrier, which in turn\nindicates that memory effects need not be ignored. We have thus constructed a\nGeneralized Langevin Equation which contains a combination of Non Markovian at\ndifferent time scales & Markovian processes and develop an algorithm to\ndescribe the scheme of events. We see that the oscillatory function behaviour\nwith exponential decay is obtained in the Markovian limit and two distinct time\nscales corresponding to the processes of diffusion & drift may be obtained from\npreliminary simulation results. We propose that the results need much more\ninspection and it will be worthwhile to reproduce using MD simulations. The\nmost important idea which we like to propose in this paper is that the rise of\ntime scales and memory effects may be inherently related to the differential\nbehaviour of shear viscosity in the cytoplasm & extracellular matrix.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2008 01:52:08 GMT"}], "update_date": "2008-01-25", "authors_parsed": [["Roy", "Sisir", ""], ["Mitra", "Indranil", ""], ["Llinas", "Rodolfo", ""]]}, {"id": "0801.3832", "submitter": "Michael Schnabel", "authors": "Michael Schnabel, Matthias Kaschube and Fred Wolf", "title": "Pinwheel stability, pattern selection and the geometry of visual space", "comments": "5 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.PS physics.bio-ph", "license": null, "abstract": "  It has been proposed that the dynamical stability of topological defects in\nthe visual cortex reflects the Euclidean symmetry of the visual world. We\nanalyze defect stability and pattern selection in a generalized Swift-Hohenberg\nmodel of visual cortical development symmetric under the Euclidean group E(2).\nEuclidean symmetry strongly influences the geometry and multistability of model\nsolutions but does not directly impact on defect stability.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2008 20:42:26 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2008 23:07:20 GMT"}], "update_date": "2008-01-30", "authors_parsed": [["Schnabel", "Michael", ""], ["Kaschube", "Matthias", ""], ["Wolf", "Fred", ""]]}, {"id": "0801.3963", "submitter": "Ines Samengo", "authors": "Germ\\'an Mato and In\\'es Samengo", "title": "Type I and type II neuron models are selectively driven by differential\n  stimulus features", "comments": "25 pages and 9 figures. To appear in Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": null, "abstract": "  Neurons in the nervous system exhibit an outstanding variety of morphological\nand physiological properties. However, close to threshold, this remarkable\nrichness may be grouped succinctly into two basic types of excitability, often\nreferred to as type I and type II. The dynamical traits of these two neuron\ntypes have been extensively characterized. It would be interesting, however, to\nunderstand the information-processing consequences of their dynamical\nproperties. To that end, here we determine the differences between the stimulus\nfeatures inducing firing in type I and in type II neurons. We work both with\nrealistic conductance-based models and minimal normal forms. We conclude that\ntype I neurons fire in response to scale-free depolarizing stimuli. Type II\nneurons, instead, are most efficiently driven by input stimuli containing both\ndepolarizing and hyperpolarizing phases, with significant power in the\nfrequency band corresponding to the intrinsic frequencies of the cell.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2008 15:58:52 GMT"}], "update_date": "2008-01-28", "authors_parsed": [["Mato", "Germ\u00e1n", ""], ["Samengo", "In\u00e9s", ""]]}, {"id": "0801.4164", "submitter": "Matthias Kaschube", "authors": "Matthias Kaschube, Michael Schnabel, Siegrid L\\\"owel and Fred Wolf", "title": "Inter-areal coordination of columnar architectures during visual\n  cortical development", "comments": "30 pages, 1 table, 6 figures", "journal-ref": null, "doi": "10.1073/pnas.0901615106", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": null, "abstract": "  The occurrence of a critical period of plasticity in the visual cortex has\nlong been established, yet its function in normal development is not fully\nunderstood. Here we show that as the late phase of the critical period unfolds,\ndifferent areas of cat visual cortex develop in a coordinated manner.\nOrientation columns in areas V1 and V2 become matched in size in regions that\nare mutually connected. The same age trend is found for such regions in the\nleft and right brain hemisphere. Our results indicate that a function of\ncritical period plasticity is to progressively coordinate the functional\narchitectures of different cortical areas - even across hemispheres.\n", "versions": [{"version": "v1", "created": "Sun, 27 Jan 2008 22:48:53 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Kaschube", "Matthias", ""], ["Schnabel", "Michael", ""], ["L\u00f6wel", "Siegrid", ""], ["Wolf", "Fred", ""]]}, {"id": "0801.4269", "submitter": "Luciano da Fontoura Costa", "authors": "Luciano da Fontoura Costa", "title": "Detecting Neuronal Communities from Beginning of Activation Patterns", "comments": "9 pages, 7 figures. A working manuscript: suggestions and comments\n  welcomed", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cond-mat.dis-nn physics.comp-ph q-bio.NC", "license": null, "abstract": "  The detection of neuronal communities is addressed with basis on two\nimportant concepts from neuroscience: facilitation of neuronal firing and\nnearly simultaneous beginning of activation of sets of neurons. More\nspecifically, integrate-and-fire complex neuronal networks are activated at\neach of their nodes, and the dissemination of activation is monitored. As the\nactivation received by each neuron accumulates, its firing gets facilitated.\nThe time it takes for each neuron, other than the source, to receive the first\nnon-zero input (beginning activation time) and the time for it to produce the\nfirst spike (beginning spiking time) are identified through simulations. It is\nshown, with respect to two synthetic and a real-world (\\emph{C. elegans})\nneuronal complex networks, that the patterns of beginning activation times (and\nto a lesser extent also of the spiking times) tend to cluster into groups\ncorresponding to communities of neurons in the original complex neuronal\nnetwork. Such an effect is identified to be a direct consequence of the almost\nsimultaneous activation between the nodes inside the same community in which\nthe source of activation is placed, as well as of the respective trapping of\nactivation implied by the integration of activiation prior to firing.\nInterestingly, the accumulation of activity and thresholds inside each neuron\nwere found to be essential for constraining the initial activations within each\nrespective community during the transient activation (no clear clusters were\nobserved when using overall activation or spiking rates). In addition to its\nintrinsic value for neuroscience and structure-dynamics studies, these results\nconfirm the importance of the consideration of transient dynamics in complex\nsystems investigations.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jan 2008 13:52:57 GMT"}], "update_date": "2008-01-29", "authors_parsed": [["Costa", "Luciano da Fontoura", ""]]}, {"id": "0801.4461", "submitter": "C.C. Alan Fung", "authors": "C. C. Alan Fung, K. Y. Michael Wong, Si Wu", "title": "Dynamics of Neural Networks with Continuous Attractors", "comments": "6 pages, 7 figures with 4 captions", "journal-ref": "EPL (2008) 84: 18002", "doi": "10.1209/0295-5075/84/18002", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the dynamics of continuous attractor neural networks (CANNs).\nDue to the translational invariance of their neuronal interactions, CANNs can\nhold a continuous family of stationary states. We systematically explore how\ntheir neutral stability facilitates the tracking performance of a CANN, which\nis believed to have wide applications in brain functions. We develop a\nperturbative approach that utilizes the dominant movement of the network\nstationary states in the state space. We quantify the distortions of the bump\nshape during tracking, and study their effects on the tracking performance.\nResults are obtained on the maximum speed for a moving stimulus to be\ntrackable, and the reaction time to catch up an abrupt change in stimulus.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jan 2008 10:15:35 GMT"}, {"version": "v2", "created": "Sat, 31 Jan 2015 15:29:22 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Fung", "C. C. Alan", ""], ["Wong", "K. Y. Michael", ""], ["Wu", "Si", ""]]}, {"id": "0801.4684", "submitter": "Luciano da Fontoura Costa", "authors": "Luciano da Fontoura Costa", "title": "Communities in Neuronal Complex Networks Revealed by Activation Patterns", "comments": "11 pages, 7 figures. Comments and suggestions welcomed", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.soc-ph", "license": null, "abstract": "  Recently, it has been shown that the communities in neuronal networks of the\nintegrate-and-fire type can be identified by considering patterns containing\nthe beginning times for each cell to receive the first non-zero activation. The\nreceived activity was integrated in order to facilitate the spiking of each\nneuron and to constrain the activation inside the communities, but no time\ndecay of such activation was considered. The present article shows that, by\ntaking into account exponential decays of the stored activation, it is possible\nto identify the communities also in terms of the patterns of activation along\nthe initial steps of the transient dynamics. The potential of this method is\nillustrated with respect to complex neuronal networks involving four\ncommunities, each of a different type (Erd\\H{o}s-R\\'eny, Barab\\'asi-Albert,\nWatts-Strogatz as well as a simple geographical model). Though the\nconsideration of activation decay has been found to enhance the communities\nseparation, too intense decays tend to yield less discrimination.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2008 14:18:34 GMT"}], "update_date": "2008-01-31", "authors_parsed": [["Costa", "Luciano da Fontoura", ""]]}]