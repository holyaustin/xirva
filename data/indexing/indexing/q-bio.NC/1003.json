[{"id": "1003.0836", "submitter": "Dominique Rousie DL", "authors": "D. L. Rousie (1), J.P. Deroubaix (2), O. Joly (1), P. Salvetti (2), J.\n  Vasseur (2), A. Berthoz (1), ((1) Laboratoire de la perception et de l\n  action-College de France-Paris, (2) IFR 49 INSERM/CNRS-Orsay)", "title": "Semi-Circular Canals Anomalies//Idiopathic Scoliosis", "comments": "15 pages, 8 figures Name and adress for correspondence: Docteur\n  Rousie, 3 rue Saint Louis, 59113 Seclin France. Fax: 0033 320 32 35 44, Tel.\n  0033 320 90 12 29, mrousie@nordnet.fr", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.med-ph q-bio.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thanks to a novel modelling programme to detect anomalies in the membranous\nsemi circular canals (SSC) of idiopathic scoliosis (IS) we found severe\nanomalies mainly located in lateral SCC devoted to trunk rotation and lateral\ndeviations. We also found a specific communication between the lateral and\nposterior canal involving the utricular chamber which is also highly suspected\nin scoliosis. Key points: - Membranous semi circular canals (SCC) modelling\nbased on MRI revealed significant anomalies in IS patients compared to normal\nsubjects. - Frequent aplasias located in the lateral canal were found in IS. -\nWe also discovered a, never described, abnormal communication between lateral\nand posterior canal. - Lateral SCC is involved in trunk rotation and lateral\ndeviation: these movements are frequently abnormal in IS. Supports: Fondation\nYves Cotrel pour la recherche en pathologie rachidienne. Institut de France,\nParis. SHFJ/CEA Orsay in the frame of the cooperation through IFR 49\nINSERM/CNRS France.\n", "versions": [{"version": "v1", "created": "Wed, 3 Mar 2010 15:31:05 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Rousie", "D. L.", ""], ["Deroubaix", "J. P.", ""], ["Joly", "O.", ""], ["Salvetti", "P.", ""], ["Vasseur", "J.", ""], ["Berthoz", "A.", ""]]}, {"id": "1003.1020", "submitter": "Haiping Huang", "authors": "Haiping Huang and Haijun Zhou", "title": "Learning by random walks in the weight space of the Ising perceptron", "comments": "12 pages, 4 figures, An extensively revised version", "journal-ref": "J. Stat. Mech.: Theory Exp. P08014 (2010)", "doi": "10.1088/1742-5468/2010/08/P08014", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several variants of a stochastic local search process for constructing the\nsynaptic weights of an Ising perceptron are studied. In this process, binary\npatterns are sequentially presented to the Ising perceptron and are then\nlearned as the synaptic weight configuration is modified through a chain of\nsingle- or double-weight flips within the compatible weight configuration space\nof the earlier learned patterns. This process is able to reach a storage\ncapacity of $\\alpha \\approx 0.63$ for pattern length N = 101 and $\\alpha\n\\approx 0.41$ for N = 1001. If in addition a relearning process is exploited,\nthe learning performance is further improved to a storage capacity of $\\alpha\n\\approx 0.80$ for N = 101 and $\\alpha \\approx 0.42$ for N=1001. We found that,\nfor a given learning task, the solutions constructed by the random walk\nlearning process are separated by a typical Hamming distance, which decreases\nwith the constraint density $\\alpha$ of the learning task; at a fixed value of\n$\\alpha$, the width of the Hamming distance distributions decreases with $N$.\n", "versions": [{"version": "v1", "created": "Thu, 4 Mar 2010 11:38:33 GMT"}, {"version": "v2", "created": "Sun, 30 May 2010 03:44:54 GMT"}], "update_date": "2010-08-13", "authors_parsed": [["Huang", "Haiping", ""], ["Zhou", "Haijun", ""]]}, {"id": "1003.1196", "submitter": "Yasuhiko Igarashi", "authors": "Yasuhiko Igarashi, Masafumi Oizumi and Masato Okada", "title": "Mean Field Analysis of Stochastic Neural Network Models with Synaptic\n  Depression", "comments": "26 pages, 13 figures. Preliminary results for the present work have\n  been published elsewhere (Y Igarashi et al., 2009.\n  http://www.iop.org/EJ/abstract/1742-6596/197/1/012018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated the effects of synaptic depression on the macroscopic\nbehavior of stochastic neural networks. Dynamical mean field equations were\nderived for such networks by taking the average of two stochastic variables: a\nfiring state variable and a synaptic variable. In these equations, their\naverage product is decoupled as the product of averaged them because the two\nstochastic variables are independent. We proved the independence of these two\nstochastic variables assuming that the synaptic weight is of the order of 1/N\nwith respect to the number of neurons N. Using these equations, we derived\nmacroscopic steady state equations for a network with uniform connections and a\nring attractor network with Mexican hat type connectivity and investigated the\nstability of the steady state solutions. An oscillatory uniform state was\nobserved in the network with uniform connections due to a Hopf instability.\nWith the ring network, high-frequency perturbations were shown not to affect\nsystem stability. Two mechanisms destabilize the inhomogeneous steady state,\nleading two oscillatory states. A Turing instability leads to a rotating bump\nstate, while a Hopf instability leads to an oscillatory bump state, which was\nprevious unreported. Various oscillatory states take place in a network with\nsynaptic depression depending on the strength of the interneuron connections.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 09:25:54 GMT"}], "update_date": "2010-03-08", "authors_parsed": [["Igarashi", "Yasuhiko", ""], ["Oizumi", "Masafumi", ""], ["Okada", "Masato", ""]]}, {"id": "1003.1200", "submitter": "Lucilla de Arcangelis", "authors": "Lucilla de Arcangelis and Hans J. Herrmann", "title": "Learning as a phenomenon occurring in a critical state", "comments": "5 pages, 5 figures", "journal-ref": "PNAS 2010 vol 107 pages 3977-3981", "doi": "10.1073/pnas.0912289107", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent physiological measurements have provided clear evidence about\nscale-free avalanche brain activity and EEG spectra, feeding the classical\nenigma of how such a chaotic system can ever learn or respond in a controlled\nand reproducible way. Models for learning, like neural networks or perceptrons,\nhave traditionally avoided strong fluctuations. Conversely, we propose that\nbrain activity having features typical of systems at a critical point,\nrepresents a crucial ingredient for learning. We present here a study which\nprovides novel insights toward the understanding of the problem. Our model is\nable to reproduce quantitatively the experimentally observed critical state of\nthe brain and, at the same time, learns and remembers logical rules including\nthe exclusive OR (XOR), which has posed difficulties to several previous\nattempts. We implement the model on a network with topological properties close\nto the functionality network in real brains. Learning occurs via plastic\nadaptation of synaptic strengths and exhibits universal features. We find that\nthe learning performance and the average time required to learn are controlled\nby the strength of plastic adaptation, in a way independent of the specific\ntask assigned to the system. Even complex rules can be learned provided that\nthe plastic adaptation is sufficiently slow.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2010 07:50:49 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["de Arcangelis", "Lucilla", ""], ["Herrmann", "Hans J.", ""]]}, {"id": "1003.1872", "submitter": "Marc de Lussanet H.E.", "authors": "Marc H.E. de Lussanet and Jan W.M. Osse", "title": "An ancestral axial twist explains the contralateral forebrain and the\n  optic chiasm in vertebrates", "comments": "13 pages, 6 figures. A small correction is made (May 2014): see\n  footnote 2", "journal-ref": "Animal Biol., 62(2):193-216 (2012)", "doi": "10.1163/157075611X617102", "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the best-known facts of the brain are the contralateral visual,\nauditory, sensational, and motor mappings in the forebrain. How and why did\nthese evolve? The few theories to this question provide functional answers,\nsuch as better networks for visuomotor control. However, these theories\ncontradict the data, as discussed here. Instead we propose that a 90-deg\nleft-turn around the body-axis evolved in a common ancestor of all vertebrates.\nCompensatory migrations of the tissues during development restore body\nsymmetry. Eyes, nostrils and forebrain compensate in the direction of the turn,\nwhereas more caudal structures migrate in the opposite direction. As a result\nof these opposite migrations the forebrain becomes crossed and inverted with\nrespect to the rest of the nervous system. We show that these compensatory\nmigratory movements can indeed be observed in the zebrafish (Danio rerio) and\nthe chick (Gallus gallus). With a model we show how the axial twist hypothesis\npredicts that an optic chiasm should develop on the ventral side of the brain,\nwhereas the olfactory tract should be uncrossed. In addition, the hypothesis\nexplains the decussation of the trochlear nerve, why olfaction is non-crossed,\nwhy the cerebellar hemispheres represent the ipsilateral bodyside, why in\nsharks the forebrain halves each represent the ipsilateral eye, why the heart\nand other inner organs are asymmetric in the body. Due to the poor fossil\nrecord, the possible evolutionary scenarios remain speculative. Molecular\nevidence does support the hypothesis. The findings may throw new insight on the\nproblematic structure of the forebrain.\n", "versions": [{"version": "v1", "created": "Tue, 9 Mar 2010 13:53:19 GMT"}, {"version": "v2", "created": "Mon, 11 Jul 2011 19:28:58 GMT"}, {"version": "v3", "created": "Tue, 12 Jul 2011 07:17:50 GMT"}, {"version": "v4", "created": "Mon, 14 May 2012 07:23:39 GMT"}, {"version": "v5", "created": "Sat, 10 May 2014 13:24:05 GMT"}], "update_date": "2014-05-13", "authors_parsed": [["de Lussanet", "Marc H. E.", ""], ["Osse", "Jan W. M.", ""]]}, {"id": "1003.2111", "submitter": "Jens Christian Claussen", "authors": "Hong-Viet V. Ngo, Jan K\\\"ohler, J\\\"org Mayer, Jens Christian Claussen\n  and Heinz Georg Schuster", "title": "Triggering up states in all-to-all coupled neurons", "comments": "epl Europhysics Letters, accepted (2010)", "journal-ref": "EPL (Europhysics Letters) 89, 68002 (2010)", "doi": "10.1209/0295-5075/89/68002", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech nlin.CD physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slow-wave sleep in mammalians is characterized by a change of large-scale\ncortical activity currently paraphrased as cortical Up/Down states. A recent\nexperiment demonstrated a bistable collective behaviour in ferret slices, with\nthe remarkable property that the Up states can be switched on and off with\npulses, or excitations, of same polarity; whereby the effect of the second\npulse significantly depends on the time interval between the pulses. Here we\npresent a simple time discrete model of a neural network that exhibits this\ntype of behaviour, as well as quantitatively reproduces the time-dependence\nfound in the experiments.\n", "versions": [{"version": "v1", "created": "Wed, 10 Mar 2010 13:50:57 GMT"}], "update_date": "2012-06-12", "authors_parsed": [["Ngo", "Hong-Viet V.", ""], ["K\u00f6hler", "Jan", ""], ["Mayer", "J\u00f6rg", ""], ["Claussen", "Jens Christian", ""], ["Schuster", "Heinz Georg", ""]]}, {"id": "1003.2879", "submitter": "Nicolas Brodu", "authors": "Nicolas Brodu, Fabien Lotte, Anatole L\\'ecuyer", "title": "Exploring Two Novel Features for EEG-based Brain-Computer Interfaces:\n  Multifractal Cumulants and Predictive Complexity", "comments": "Updated with more subjects. Separated out the band-power comparisons\n  in a companion article after reviewer feedback. Source code and companion\n  article are available at\n  http://nicolas.brodu.numerimoire.net/en/recherche/publications", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce two new features for the design of\nelectroencephalography (EEG) based Brain-Computer Interfaces (BCI): one feature\nbased on multifractal cumulants, and one feature based on the predictive\ncomplexity of the EEG time series. The multifractal cumulants feature measures\nthe signal regularity, while the predictive complexity measures the difficulty\nto predict the future of the signal based on its past, hence a degree of how\ncomplex it is. We have conducted an evaluation of the performance of these two\nnovel features on EEG data corresponding to motor-imagery. We also compared\nthem to the most successful features used in the BCI field, namely the\nBand-Power features. We evaluated these three kinds of features and their\ncombinations on EEG signals from 13 subjects. Results obtained show that our\nnovel features can lead to BCI designs with improved classification\nperformance, notably when using and combining the three kinds of feature\n(band-power, multifractal cumulants, predictive complexity) together.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2010 10:20:14 GMT"}, {"version": "v2", "created": "Sat, 18 Sep 2010 15:52:09 GMT"}], "update_date": "2010-09-21", "authors_parsed": [["Brodu", "Nicolas", ""], ["Lotte", "Fabien", ""], ["L\u00e9cuyer", "Anatole", ""]]}, {"id": "1003.2950", "submitter": "Xaq Pitkow", "authors": "Xaq Pitkow", "title": "Exact feature probabilities in images with occlusion", "comments": "18 pages, 5 figures, plus 10 pages supplementary information with 7\n  figures. Keywords: natural scene statistics, dead leaves model, contours,\n  wavelets", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an q-bio.NC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  To understand the computations of our visual system, it is important to\nunderstand also the natural environment it evolved to interpret. Unfortunately,\nexisting models of the visual environment are either unrealistic or too complex\nfor mathematical description. Here we describe a naturalistic image model and\npresent a mathematical solution for the statistical relationships between the\nimage features and model variables. The world described by this model is\ncomposed of independent, opaque, textured objects which occlude each other.\nThis simple structure allows us to calculate the joint probability distribution\nof image values sampled at multiple arbitrarily located points, without\napproximation. This result can be converted into probabilistic relationships\nbetween observable image features as well as between the unobservable\nproperties that caused these features, including object boundaries and relative\ndepth. Using these results we explain the causes of a wide range of natural\nscene properties, including highly non-gaussian distributions of image features\nand causal relations between pairs of edges. We discuss the implications of\nthis description of natural scenes for the study of vision.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2010 16:13:03 GMT"}], "update_date": "2010-03-16", "authors_parsed": [["Pitkow", "Xaq", ""]]}, {"id": "1003.3036", "submitter": "Luciano da Fontoura Costa", "authors": "Krissia Zawadzki, Mauro Miazaki and Luciano da F. Costa", "title": "Investigating the Morphological Categories in the NeuroMorpho Database\n  by Using Superparamagnetic Clustering", "comments": "15 pages, 3 tables, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuing neuroscience advances, catalysed by multidisciplinary\ncollaborations between the biological, computational, physical and chemical\nareas, have implied in increasingly more complex approaches to understand and\nmodel the mammals nervous systems. One particularly important related issue\nregards the investigation of the relationship between morphology and function\nof neuronal cells, which requires the application of effective means for their\nclassification, for instance by using multivariated, pattern recognition and\nclustering methods. The current work aims at such a study while considering a\nlarge number of neuronal cells obtained from the NeuroMorpho database, which is\ncurrently the most comprehensive such a repository. Our approach applies an\nunsupervised clustering technique, known as Superparamagnetic Clustering, over\na set of morphological measurements regarding four major neuronal categories.\nIn particular, we target two important problems: (i) we investigate the\ncoherence between the obtained clusters and the original categories; and (ii)\nwe verify for eventual subclusters inside each of these categories. We report a\ngood agreement between the obtained clusters and the original categories, as\nwell as the identification of a relatively complex structure of subclusters in\nthe case of the pyramidal neuronal cells.\n", "versions": [{"version": "v1", "created": "Mon, 15 Mar 2010 21:10:04 GMT"}], "update_date": "2010-03-17", "authors_parsed": [["Zawadzki", "Krissia", ""], ["Miazaki", "Mauro", ""], ["Costa", "Luciano da F.", ""]]}, {"id": "1003.3081", "submitter": "Marcus Kaiser", "authors": "Marcus Kaiser and Claus C. Hilgetag", "title": "Optimal hierarchical modular topologies for producing limited sustained\n  activation of neural networks", "comments": "Contribution to Frontiers in Neuroinformatics special issue on\n  'Hierarchy and dynamics in neural networks'\n  (http://frontiersin.org/neuroscience/neuroinformatics/specialtopics/29/)", "journal-ref": "Kaiser M and Hilgetag CC (2010) Optimal hierarchical modular\n  topologies for producing limited sustained activation of neural networks.\n  Front. Neuroinform. 4:8", "doi": "10.3389/fninf.2010.00008", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An essential requirement for the representation of functional patterns in\ncomplex neural networks, such as the mammalian cerebral cortex, is the\nexistence of stable regimes of network activation, typically arising from a\nlimited parameter range. In this range of limited sustained activity (LSA), the\nactivity of neural populations in the network persists between the extremes of\neither quickly dying out or activating the whole network. Hierarchical modular\nnetworks were previously found to show a wider parameter range for LSA than\nrandom or small-world networks not possessing hierarchical organization or\nmultiple modules. Here we explored how variation in the number of hierarchical\nlevels and modules per level influenced network dynamics and occurrence of LSA.\nWe tested hierarchical configurations of different network sizes, approximating\nthe large-scale networks linking cortical columns in one hemisphere of the rat,\ncat, or macaque monkey brain. Scaling of the network size affected the number\nof hierarchical levels and modules in the optimal networks, also depending on\nwhether global edge density or the numbers of connections per node were kept\nconstant. For constant edge density, only few network configurations,\npossessing an intermediate number of levels and a large number of modules, led\nto a large range of LSA independent of brain size. For a constant number of\nnode connections, there was a trend for optimal configurations in larger-size\nnetworks to possess a larger number of hierarchical levels or more modules.\nThese results may help to explain the trend to greater network complexity\napparent in larger brains and may indicate that this complexity is required for\nmaintaining stable levels of neural activation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2010 05:13:41 GMT"}], "update_date": "2010-03-17", "authors_parsed": [["Kaiser", "Marcus", ""], ["Hilgetag", "Claus C.", ""]]}, {"id": "1003.3157", "submitter": "Bruno. Cessac", "authors": "J.C. Vasquez, B. Cessac, T. Vi\\'eville", "title": "Entropy-based parametric estimation of spike train statistics", "comments": "37 pages, 8 figures, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the evolution of a network of neurons, focusing on the asymptotic\nbehavior of spikes dynamics instead of membrane potential dynamics. The spike\nresponse is not sought as a deterministic response in this context, but as a\nconditional probability : \"Reading out the code\" consists of inferring such a\nprobability. This probability is computed from empirical raster plots, by using\nthe framework of thermodynamic formalism in ergodic theory. This gives us a\nparametric statistical model where the probability has the form of a Gibbs\ndistribution. In this respect, this approach generalizes the seminal and\nprofound work of Schneidman and collaborators. A minimal presentation of the\nformalism is reviewed here, while a general algorithmic estimation method is\nproposed yielding fast convergent implementations. It is also made explicit how\nseveral spike observables (entropy, rate, synchronizations, correlations) are\ngiven in closed-form from the parametric estimation. This paradigm does not\nonly allow us to estimate the spike statistics, given a design choice, but also\nto compare different models, thus answering comparative questions about the\nneural code such as : \"are correlations (or time synchrony or a given set of\nspike patterns, ..) significant with respect to rate coding only ?\" A numerical\nvalidation of the method is proposed and the perspectives regarding spike-train\ncode analysis are also discussed.\n", "versions": [{"version": "v1", "created": "Tue, 16 Mar 2010 14:38:14 GMT"}, {"version": "v2", "created": "Thu, 26 Aug 2010 11:53:35 GMT"}], "update_date": "2010-08-27", "authors_parsed": [["Vasquez", "J. C.", ""], ["Cessac", "B.", ""], ["Vi\u00e9ville", "T.", ""]]}, {"id": "1003.3682", "submitter": "Henrik Jeldtoft Jensen", "authors": "Paul Expert, Renaud Lambiotte, Dante R. Chialvo, Kim Christensen,\n  Henrik Jeldtoft Jensen, David J. Sharp and Federico Turkheimer", "title": "Self-similar correlation function in brain resting-state fMRI", "comments": "14 pages 13 figures; published online before print September 22", "journal-ref": "J. R. Soc. Interface April 6, 2011 8:472-479", "doi": "10.1098/rsif.2010.0416", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptive behavior, cognition and emotion are the result of a bewildering\nvariety of brain spatiotemporal activity patterns. An important problem in\nneuroscience is to understand the mechanism by which the human brain's 100\nbillion neurons and 100 trillion synapses manage to produce this large\nrepertoire of cortical configurations in a flexible manner. In addition, it is\nrecognized that temporal correlations across such configurations cannot be\narbitrary, but they need to meet two conflicting demands: while diverse\ncortical areas should remain functionally segregated from each other, they must\nstill perform as a collective, i.e., they are functionally integrated. Here, we\ninvestigate these large-scale dynamical properties by inspecting the character\nof the spatiotemporal correlations of brain resting-state activity. In physical\nsystems, these correlations in space and time are captured by measuring the\ncorrelation coefficient between a signal recorded at two different points in\nspace at two different times. We show that this two-point correlation function\nextracted from resting-state fMRI data exhibits self-similarity in space and\ntime. In space, self-similarity is revealed by considering three successive\nspatial coarse-graining steps while in time it is revealed by the 1/f frequency\nbehavior of the power spectrum. The uncovered dynamical self-similarity implies\nthat the brain is spontaneously at a continuously changing (in space and time)\nintermediate state between two extremes, one of excessive cortical integration\nand the other of complete segregation. This dynamical property may be seen as\nan important marker of brain well-being both in health and disease.\n", "versions": [{"version": "v1", "created": "Thu, 18 Mar 2010 21:52:00 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Expert", "Paul", ""], ["Lambiotte", "Renaud", ""], ["Chialvo", "Dante R.", ""], ["Christensen", "Kim", ""], ["Jensen", "Henrik Jeldtoft", ""], ["Sharp", "David J.", ""], ["Turkheimer", "Federico", ""]]}, {"id": "1003.3821", "submitter": "Dan Guralnik", "authors": "Dan Guralnik", "title": "A Formal Approach to Modeling the Memory of a Living Organism", "comments": "33 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a living organism as an observer of the evolution of its\nenvironment recording sensory information about the state space X of the\nenvironment in real time. Sensory information is sampled and then processed on\ntwo levels. On the biological level, the organism serves as an evaluation\nmechanism of the subjective relevance of the incoming data to the observer: the\nobserver assigns excitation values to events in X it could recognize using its\nsensory equipment. On the algorithmic level, sensory input is used for updating\na database, the memory of the observer whose purpose is to serve as a\ngeometric/combinatorial model of X, whose nodes are weighted by the excitation\nvalues produced by the evaluation mechanism. These values serve as a guidance\nsystem for deciding how the database should transform as observation data\nmounts. We define a searching problem for the proposed model and discuss the\nmodel's flexibility and its computational efficiency, as well as the\npossibility of implementing it as a dynamic network of neuron-like units. We\nshow how various easily observable properties of the human memory and thought\nprocess can be explained within the framework of this model. These include:\nreasoning (with efficiency bounds), errors, temporary and permanent loss of\ninformation. We are also able to define general learning problems in terms of\nthe new model, such as the language acquisition problem.\n", "versions": [{"version": "v1", "created": "Fri, 19 Mar 2010 15:56:37 GMT"}], "update_date": "2010-03-22", "authors_parsed": [["Guralnik", "Dan", ""]]}, {"id": "1003.3916", "submitter": "Marzena Ciszak Dr", "authors": "Marzena Ciszak", "title": "Stochastic incoherence in the response of rebound bursters", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2010.02.028", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At an optimal value of the noise intensity, the maximum variability in\nrebound burst durations is observed and referred to as a response stochastic\nincoherence. A general mechanism underlying this phenomenon is given, being\ndifferent from those reported so far in excitable systems. It is shown to be\ndetermined by (i) the monotonic reduction of the hysteresis responsible for\nbursting caused by noise and consequent transformation of responses from\nrebound bursts to single spikes, and (ii) a symmetry breaking in distributions\nof burst durations caused by the existence of the minimum response length. The\nphenomenon is studied numerically in a Morris-Lecar model for neurons and its\nmechanism is explained with the use of canonical models describing hard\nexcitation states.\n", "versions": [{"version": "v1", "created": "Sat, 20 Mar 2010 09:55:28 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Ciszak", "Marzena", ""]]}, {"id": "1003.4217", "submitter": "Sebastiano Stramaglia", "authors": "Mario Pellicoro and Sebastiano Stramaglia", "title": "Granger causality and the inverse Ising problem", "comments": "6 pages and 8 figures. Revised version in press on Physica A", "journal-ref": null, "doi": "10.1016/j.physa.2010.06.028", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Ising models for describing data and show that autoregressive\nmethods may be used to learn their connections, also in the case of asymmetric\nconnections and for multi-spin interactions. For each link the linear Granger\ncausality is two times the corresponding transfer entropy (i.e. the information\nflow on that link) in the weak coupling limit. For sparse connections and a low\nnumber of samples, the L1 regularized least squares method is used to detect\nthe interacting pairs of spins. Nonlinear Granger causality is related to\nmultispin interactions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Mar 2010 17:10:58 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2010 14:21:49 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Pellicoro", "Mario", ""], ["Stramaglia", "Sebastiano", ""]]}, {"id": "1003.4410", "submitter": "Michael Monteforte", "authors": "Michael Monteforte and Fred Wolf", "title": "Dynamical Entropy Production in Spiking Neuron Networks in the Balanced\n  State", "comments": "4 pages, 4 figures", "journal-ref": "Phys. Rev. Lett. 105, 268104 (2010)", "doi": "10.1103/PhysRevLett.105.268104", "report-no": null, "categories": "cond-mat.dis-nn nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate deterministic extensive chaos in the dynamics of large sparse\nnetworks of theta neurons in the balanced state. The analysis is based on\nnumerically exact calculations of the full spectrum of Lyapunov exponents, the\nentropy production rate and the attractor dimension. Extensive chaos is found\nin inhibitory networks and becomes more intense when an excitatory population\nis included. We find a strikingly high rate of entropy production that would\nlimit information representation in cortical spike patterns to the immediate\nstimulus response.\n", "versions": [{"version": "v1", "created": "Tue, 23 Mar 2010 13:41:29 GMT"}, {"version": "v2", "created": "Fri, 10 Dec 2010 06:46:08 GMT"}], "update_date": "2011-01-14", "authors_parsed": [["Monteforte", "Michael", ""], ["Wolf", "Fred", ""]]}, {"id": "1003.4980", "submitter": "Janaki Balakrishnan", "authors": "Nishant Malik, B. Ashok, and J. Balakrishnan", "title": "Complete synchronization in coupled Type-I neurons", "comments": "24 pages, 9 figures", "journal-ref": "Pramana - Journal of Physics, vol.74, pages 189-205 (2010)", "doi": "10.1007/s12043-010-0020-0", "report-no": null, "categories": "nlin.AO cond-mat.stat-mech physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a system of type-I neurons bidirectionally coupled through a nonlinear\nfeedback mechanism, we discuss the issue of noise-induced complete\nsynchronization (CS). For the inputs to the neurons, we point out that the rate\nof change of instantaneous frequency with the instantaneous phase of the\nstochastic inputs to each neuron matches exactly with that for the other in the\nevent of CS of their outputs. Our observation can be exploited in practical\nsituations to produce completely synchronized outputs in artificial devices.\nFor excitatory-excitatory synaptic coupling, a functional dependence for the\nsynchronization error on coupling and noise strengths is obtained. Finally we\nreport an observation of noise-induced CS between non-identical neurons coupled\nbidirectionally through random non-zero couplings in an all-to- all way in a\nlarge neuronal ensemble.\n", "versions": [{"version": "v1", "created": "Thu, 25 Mar 2010 19:43:20 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Malik", "Nishant", ""], ["Ashok", "B.", ""], ["Balakrishnan", "J.", ""]]}, {"id": "1003.5260", "submitter": "Peter Borowski", "authors": "Peter Borowski, Rachel Kuske, Yue-Xian Li, Juan Luis Cabrera", "title": "Characterizing mixed mode oscillations shaped by noise and bifurcation\n  structure", "comments": "22 pages", "journal-ref": "Chaos 20, 043117 (2010)", "doi": "10.1063/1.3489100", "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many neuronal systems and models display a certain class of mixed mode\noscillations (MMOs) consisting of periods of small amplitude oscillations\ninterspersed with spikes. Various models with different underlying mechanisms\nhave been proposed to generate this type of behavior. Stochastic versions of\nthese models can produce similarly looking time series, often with noise-driven\nmechanisms different from those of the deterministic models. We present a suite\nof measures which, when applied to the time series, serves to distinguish\nmodels and classify routes to producing MMOs, such as noise-induced\noscillations or delay bifurcation. By focusing on the subthreshold\noscillations, we analyze the interspike interval density, trends in the\namplitude and a coherence measure. We develop these measures on a biophysical\nmodel for stellate cells and a phenomenological FitzHugh-Nagumo-type model and\napply them on related models. The analysis highlights the influence of model\nparameters and reset and return mechanisms in the context of a novel approach\nusing noise level to distinguish model types and MMO mechanisms. Ultimately, we\nindicate how the suite of measures can be applied to experimental time series\nto reveal the underlying dynamical structure, while exploiting either the\nintrinsic noise of the system or tunable extrinsic noise.\n", "versions": [{"version": "v1", "created": "Sat, 27 Mar 2010 03:48:01 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Borowski", "Peter", ""], ["Kuske", "Rachel", ""], ["Li", "Yue-Xian", ""], ["Cabrera", "Juan Luis", ""]]}, {"id": "1003.5538", "submitter": "Alain Destexhe", "authors": "Nima Dehghani, Claude Bedard, Sydney S. Cash, Eric Halgren and Alain\n  Destexhe", "title": "Comparative power spectral analysis of simultaneous\n  elecroencephalographic and magnetoencephalographic recordings in humans\n  suggests non-resistive extracellular media", "comments": "Submitted to Journal of Computational Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The resistive or non-resistive nature of the extracellular space in the brain\nis still debated, and is an important issue for correctly modeling\nextracellular potentials. Here, we first show theoretically that if the medium\nis resistive, the frequency scaling should be the same for electroencephalogram\n(EEG) and magnetoencephalogram (MEG) signals at low frequencies (<10 Hz). To\ntest this prediction, we analyzed the spectrum of simultaneous EEG and MEG\nmeasurements in four human subjects. The frequency scaling of EEG displays\ncoherent variations across the brain, in general between 1/f and 1/f^2, and\ntends to be smaller in parietal/temporal regions. In a given region, although\nthe variability of the frequency scaling exponent was higher for MEG compared\nto EEG, both signals consistently scale with a different exponent. In some\ncases, the scaling was similar, but only when the signal-to-noise ratio of the\nMEG was low. Several methods of noise correction for environmental and\ninstrumental noise were tested, and they all increased the difference between\nEEG and MEG scaling. In conclusion, there is a significant difference in\nfrequency scaling between EEG and MEG, which can be explained if the\nextracellular medium (including other layers such as dura matter and skull) is\nglobally non-resistive.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 13:23:51 GMT"}, {"version": "v2", "created": "Mon, 24 May 2010 09:41:12 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Dehghani", "Nima", ""], ["Bedard", "Claude", ""], ["Cash", "Sydney S.", ""], ["Halgren", "Eric", ""], ["Destexhe", "Alain", ""]]}, {"id": "1003.5557", "submitter": "Tobias Reichenbach", "authors": "Tobias Reichenbach, A. J. Hudspeth", "title": "A ratchet mechanism for amplification in low-frequency mammalian hearing", "comments": "6 pages, 4 figures, plus Supplementary Information. Animation\n  available on the PNAS website (http://dx.doi.org/10.1073/pnas.0914345107).", "journal-ref": "Proc. Natl. Acad. Sci. U.S.A. 107, 4973-4978 (2010)", "doi": "10.1073/pnas.0914345107", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sensitivity and frequency selectivity of hearing result from tuned\namplification by an active process in the mechanoreceptive hair cells. In most\nvertebrates the active process stems from the active motility of hair bundles.\nThe mammalian cochlea exhibits an additional form of mechanical activity termed\nelectromotility: its outer hair cells (OHCs) change length upon electrical\nstimulation. The relative contributions of these two mechanisms to the active\nprocess in the mammalian inner ear is the subject of intense current debate.\nHere we show that active hair-bundle motility and electromotility can together\nimplement an efficient mechanism for amplification that functions like a\nratchet: sound-evoked forces acting on the basilar membrane are transmitted to\nthe hair bundles whereas electromotility decouples active hair-bundle forces\nfrom the basilar membrane. This unidirectional coupling can extend the hearing\nrange well below the resonant frequency of the basilar membrane. It thereby\nprovides a concept for low-frequency hearing that accounts for a variety of\nunexplained experimental observations from the cochlear apex, including the\nshape and phase behavior of apical tuning curves, their lack of significant\nnonlinearities, and the shape changes of threshold tuning curves of auditory\nnerve fibers along the cochlea. The ratchet mechanism constitutes a general\ndesign principle for implementing mechanical amplification in engineering\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 29 Mar 2010 14:51:39 GMT"}], "update_date": "2010-03-30", "authors_parsed": [["Reichenbach", "Tobias", ""], ["Hudspeth", "A. J.", ""]]}, {"id": "1003.5804", "submitter": "Raul Toral", "authors": "T. Perez, C. R. Mirasso, R. Toral and J. D. Gunton", "title": "The constructive role of diversity on the global response of coupled\n  neuron systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect that the heterogeneity present among the elements of an\nensemble of coupled excitable neurons have on the collective response of the\nsystem to an external signal. We have considered two different interaction\nscenarios, one in which the neurons are diffusively coupled and another in\nwhich the neurons interact via pulse-like signals. We found that the type of\ninteraction between the neurons has a crucial role in determining the response\nof the system to the external modulation. We develop a mean-field theory based\non an order parameter expansion that quantitatively reproduces the numerical\nresults in the case of diffusive coupling.\n", "versions": [{"version": "v1", "created": "Tue, 30 Mar 2010 12:37:03 GMT"}], "update_date": "2010-03-31", "authors_parsed": [["Perez", "T.", ""], ["Mirasso", "C. R.", ""], ["Toral", "R.", ""], ["Gunton", "J. D.", ""]]}]