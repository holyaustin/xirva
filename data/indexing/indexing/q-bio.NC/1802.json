[{"id": "1802.00056", "submitter": "Andre van Hoorn", "authors": "Christoph Heger, Andr\\'e van Hoorn, Du\\v{s}an Okanovic, Stefan Siegl,\n  Christian V\\\"ogele, Alexander Wert", "title": "diagnoseIT: Expertengest\\\"utzte automatische Diagnose von\n  Performance-Probleme in Enterprise-Anwendungen (Abschlussbericht)", "comments": "The language of the report is German", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC cs.PF q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the final report of the collaborative research project diagnoseIT on\nexpert-guided automatic diagnosis of performance problems in enterprise\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 03:34:10 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Heger", "Christoph", ""], ["van Hoorn", "Andr\u00e9", ""], ["Okanovic", "Du\u0161an", ""], ["Siegl", "Stefan", ""], ["V\u00f6gele", "Christian", ""], ["Wert", "Alexander", ""]]}, {"id": "1802.00217", "submitter": "Heidi Teppola", "authors": "H. Teppola (1 and 2), S. Okujeni (2), M.-L. Linne (1), U. Egert (2)\n  ((1) Department of Signal Processing, Tampere University of Technology,\n  Tampere, Finland, (2) Bernstein Center Freiburg & Department of Microsystems\n  Engineering, IMTEK, Albert-Ludwig University of Freiburg, Freiburg, Germany)", "title": "AMPA, NMDA and GABAA receptor mediated network burst dynamics in\n  cortical cultures in vitro", "comments": "4 pages, 3 figures, 1 table, In Proceedings of the 8th International\n  Workshop on Computational Systems Biology (WCSB2011), eds. H Koeppl, J.\n  A\\'cimovi\\'c, T. M\\\"aki-Marttunen, A. Larjo, and O. Yli-Harja (Zurich,\n  Switzerland: TICSP series), 181-184", "journal-ref": "Proc. Int. Works. Comp. Syst. Biol. TICSP series 8 (2011) 181-184", "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the excitatory AMPA, and NMDA, and inhibitory GABAA\nreceptor mediated dynamical changes in neuronal networks of neonatal rat cortex\nin vitro. Extracellular network-wide activity was recorded with 59 planar\nelectrodes simultaneously under different pharmacological conditions. We\nanalyzed the changes of overall network activity and network-wide burst\nfrequency between baseline and AMPA receptor (AMPA-R) or NMDA receptor (NMDA-R)\ndriven activity, as well as between the latter states and disinhibited\nactivity. Additionally, spatiotemporal structures of pharmacologically modified\nbursts and recruitment of electrodes during the network bursts were studied.\nOur results show that AMPA-R and NMDA-R receptors have clearly distinct roles\nin network dynamics. AMPA-Rs are in greater charge to initiate network wide\nbursts. Therefore NMDA-Rs maintain the already initiated activity. GABAA\nreceptors (GABAA-Rs) inhibit AMPA-R driven network activity more strongly than\nNMDA-R driven activity during the bursts.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 09:50:29 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Teppola", "H.", "", "1 and 2"], ["Okujeni", "S.", ""], ["Linne", "M. -L.", ""], ["Egert", "U.", ""]]}, {"id": "1802.00297", "submitter": "Ana Paula Mill\\'an Vidal", "authors": "Ana P. Mill\\'an, Joaqu\\'in J. Torres and Ginestra Bianconi", "title": "Complex Network Geometry and Frustrated Synchronization", "comments": "12 pages, 5 figures", "journal-ref": "Scientific Reports 8, 9910 (2018)", "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of networks of neuronal cultures has been recently shown to be\nstrongly dependent on the network geometry and in particular on their\ndimensionality. However, this phenomenon has been so far mostly unexplored from\nthe theoretical point of view. Here we reveal the rich interplay between\nnetwork geometry and synchronization of coupled oscillators in the context of a\nsimplicial complex model of manifolds called Complex Network Manifold. The\nnetworks generated by this model combine small world properties (infinite\nHausdorff dimension) and a high modular structure with finite and tunable\nspectral dimension. We show that the networks display frustrated\nsynchronization for a wide range of the coupling strength of the oscillators,\nand that the synchronization properties are directly affected by the spectral\ndimension of the network.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 14:24:41 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 03:45:59 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Mill\u00e1n", "Ana P.", ""], ["Torres", "Joaqu\u00edn J.", ""], ["Bianconi", "Ginestra", ""]]}, {"id": "1802.00334", "submitter": "Joaquin Goni", "authors": "Enrico Amico, Alex Arenas, Joaquin Goni", "title": "Centralized and distributed cognitive task processing in the human\n  connectome", "comments": "22 pages main, 6 pages supplementary, 6 figures, 5 supplementary\n  figures, 1 table, 1 supplementary table. arXiv admin note: text overlap with\n  arXiv:1710.02199", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key question in modern neuroscience is how cognitive changes in a human\nbrain can be quantified and captured by functional connectomes (FC) . A\nsystematic approach to measure pairwise functional distance at different brain\nstates is lacking. This would provide a straight-forward way to quantify\ndifferences in cognitive processing across tasks; also, it would help in\nrelating these differences in task-based FCs to the underlying structural\nnetwork. Here we propose a framework, based on the concept of Jensen-Shannon\ndivergence, to map the task-rest connectivity distance between tasks and\nresting-state FC. We show how this information theoretical measure allows for\nquantifying connectivity changes in distributed and centralized processing in\nfunctional networks. We study resting-state and seven tasks from the Human\nConnectome Project dataset to obtain the most distant links across tasks. We\ninvestigate how these changes are associated to different functional brain\nnetworks, and use the proposed measure to infer changes in the information\nprocessing regimes. Furthermore, we show how the FC distance from resting state\nis shaped by structural connectivity, and to what extent this relationship\ndepends on the task. This framework provides a well grounded mathematical\nquantification of connectivity changes associated to cognitive processing in\nlarge-scale brain networks.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 17:59:36 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2018 18:44:00 GMT"}, {"version": "v3", "created": "Mon, 24 Sep 2018 20:09:47 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["Amico", "Enrico", ""], ["Arenas", "Alex", ""], ["Goni", "Joaquin", ""]]}, {"id": "1802.00473", "submitter": "Kanika Bansal", "authors": "Kanika Bansal, Johan Nakuci, and Sarah Feldt Muldoon", "title": "Personalized brain network models for assessing structure-function\n  relationships", "comments": "13 pages, 3 figures, review article", "journal-ref": null, "doi": "10.1016/j.conb.2018.04.014", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent efforts in computational modeling of macro-scale brain dynamics\nhave begun to take a data-driven approach by incorporating structural and/or\nfunctional information derived from subject data. Here, we discuss recent work\nusing personalized brain network models to study structure-function\nrelationships in human brains. We describe the steps necessary to build such\nmodels and show how this computational approach can provide previously\nunobtainable information through the ability to perform virtual experiments.\nFinally, we present examples of how personalized brain network models can be\nused to gain insight into the effects of local stimulation and improve surgical\noutcomes in epilepsy.\n", "versions": [{"version": "v1", "created": "Thu, 1 Feb 2018 19:50:29 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Bansal", "Kanika", ""], ["Nakuci", "Johan", ""], ["Muldoon", "Sarah Feldt", ""]]}, {"id": "1802.00718", "submitter": "Fabian Chersi", "authors": "Chersi Fabian, Burgess Neil", "title": "Hippocampal and striatal involvement in cognitive tasks: a computational\n  model", "comments": null, "journal-ref": "Proceedings of the 6th International Conference on Memory ICOM16,\n  2016, p. 24", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The hippocampus and the striatum support episodic and procedural memory,\nrespectively, and \"place\" and \"response\" learning within spatial navigation.\nRecently this dichotomy has been linked to \"model-based\" and \"model-free\"\nreinforcement learning. Here we present a well-constrained neural model of how\nboth systems support spatial navigation, and apply the same model to more\nabstract problems such as sequential decision making. In particular, we show\nthat if a task can be transformed into a Markov Decision Process, the machinery\nprovided by the hippocampus and striatum can be utilized to solve it. These\nresults show how the hippocampal complex can represent non-spatial problems,\nincluding context, probabilities and action-dependent information, in support\nof \"model-based\" reinforcement learning to complement learning within the\nstriatum.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 15:10:05 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Fabian", "Chersi", ""], ["Neil", "Burgess", ""]]}, {"id": "1802.00753", "submitter": "Adam Steel", "authors": "Adam Steel, Cibu Thomas, Chris I Baker", "title": "Effect of time of day on reward circuitry. A discussion of Byrne et al.\n  2017", "comments": "9 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Byrne and colleagues present a paper on a timely topic with potentially\nimportant results. However, we think that issues in the design and analysis\ncomplicate the interpretation and limit the generalizability of the findings.\nSpecifically, the details of the small volume correction used in the primary\nanalysis are not adequately described and, moreover, the results do not appear\nto be corroborated by the whole-brain analysis. In addition, the follow-up\nmultilevel modeling, which is fundamental to the conclusions of the paper, is\ninherently circular thereby guaranteeing discovery of the reported effect.\nFinally, the study does not control for other factors that vary over the course\nof the day and are known to impact MRI measurements, and fails to link the\nneural results directly to any relevant behavior.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 16:20:59 GMT"}], "update_date": "2018-02-05", "authors_parsed": [["Steel", "Adam", ""], ["Thomas", "Cibu", ""], ["Baker", "Chris I", ""]]}, {"id": "1802.00840", "submitter": "Andrei Amatuni", "authors": "Andrei Amatuni, Estelle He, Elika Bergelson", "title": "Preserved Structure Across Vector Space Representations", "comments": "presented at CogSci 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Certain concepts, words, and images are intuitively more similar than others\n(dog vs. cat, dog vs. spoon), though quantifying such similarity is notoriously\ndifficult. Indeed, this kind of computation is likely a critical part of\nlearning the category boundaries for words within a given language. Here, we\nuse a set of 27 items (e.g. 'dog') that are highly common in infants' input,\nand use both image- and word-based algorithms to independently compute\nsimilarity among them. We find three key results. First, the pairwise item\nsimilarities derived within image-space and word-space are correlated,\nsuggesting preserved structure among these extremely different representational\nformats. Second, the closest 'neighbors' for each item, within each space,\nshowed significant overlap (e.g. both found 'egg' as a neighbor of 'apple').\nThird, items with the most overlapping neighbors are later-learned by infants\nand toddlers. We conclude that this approach, which does not rely on human\nratings of similarity, may nevertheless reflect stable within-class structure\nacross these two spaces. We speculate that such invariance might aid lexical\nacquisition, by serving as an informative marker of category boundaries.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 20:35:36 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 21:11:13 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Amatuni", "Andrei", ""], ["He", "Estelle", ""], ["Bergelson", "Elika", ""]]}, {"id": "1802.01008", "submitter": "Dimitrios Adamos Dr", "authors": "Dimitrios A. Adamos, Nikolaos Laskaris, Sifis Micheloyannis", "title": "Harnessing functional segregation across brain rhythms as a means to\n  detect EEG oscillatory multiplexing during music listening", "comments": "Pre-print version of the paper published in Journal of Neural\n  Engineering (2018)", "journal-ref": null, "doi": "10.1088/1741-2552/aaac36", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music, being a multifaceted stimulus evolving at multiple timescales,\nmodulates brain function in a manifold way that encompasses not only the\ndistinct stages of auditory perception but also higher cognitive processes like\nmemory and appraisal. Network theory is apparently a promising approach to\ndescribe the functional reorganization of brain oscillatory dynamics during\nmusic listening. However, the music induced changes have so far been examined\nwithin the functional boundaries of isolated brain rhythms. Using naturalistic\nmusic, we detected the functional segregation patterns associated with\ndifferent cortical rhythms, as these were reflected in the surface EEG\nmeasurements. The emerged structure was compared across frequency bands to\nquantify the interplay among rhythms. It was also contrasted against the\nstructure from the rest and noise listening conditions to reveal the specific\ncomponents stemming from music listening. Our methodology includes an efficient\ngraph-partitioning algorithm, which is further utilized for mining prototypical\nmodular patterns, and a novel algorithmic procedure for identifying switching\nnodes that consistently change module during music listening. Our results\nsuggest the multiplex character of the music-induced functional reorganization\nand particularly indicate the dependence between the networks reconstructed\nfrom the {\\delta} and {\\beta}H rhythms. This dependence is further justified\nwithin the framework of nested neural oscillations and fits perfectly within\nthe context of recently introduced cortical entrainment to music. Considering\nits computational efficiency, and in conjunction with the flexibility of in\nsitu electroencephalography, it may lead to novel assistive tools for real-life\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 3 Feb 2018 17:46:08 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Adamos", "Dimitrios A.", ""], ["Laskaris", "Nikolaos", ""], ["Micheloyannis", "Sifis", ""]]}, {"id": "1802.01287", "submitter": "Stephen Eglen", "authors": "E. Cotterill, S. J. Eglen", "title": "Burst detection methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  `Bursting', defined as periods of high frequency firing of a neuron separated\nby periods of quiescence, has been observed in various neuronal systems, both\n\\textit{in vitro} and \\textit{in vivo}. It has been associated with a range of\nneuronal processes, including efficient information transfer and the formation\nof functional networks during development, and has been shown to be sensitive\nto genetic and pharmacological manipulations. Accurate detection of periods of\nbursting activity is thus an important aspect of characterising both\nspontaneous and evoked neuronal network activity. A wide variety of\ncomputational methods have been developed to detect periods of bursting in\nspike trains recorded from neuronal networks. In this chapter, we review\nseveral of the most popular and successful of these methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Feb 2018 07:08:37 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 06:19:45 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Cotterill", "E.", ""], ["Eglen", "S. J.", ""]]}, {"id": "1802.01496", "submitter": "Konstantinos Aronis", "authors": "Konstantinos N. Aronis, Ronald D. Berger, Hugh Calkins, Jonathan\n  Chrispin, Joseph E. Marine, David D. Spragg, Susumu Tao, Harikrishna Tandri,\n  and Hiroshi Ashikaga", "title": "Is Human Atrial Fibrillation Stochastic or Deterministic?", "comments": "25 pages, 6 figures, 72 references", "journal-ref": "Chaos 28, 063130 (2018)", "doi": "10.1063/1.5023588", "report-no": null, "categories": "q-bio.TO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atrial fibrillation (AF) is the most common cardiac arrhythmia in human\nbeings, and is associated with significant morbidity and mortality. The current\nstandard of care includes interventional catheter ablation in selected\npatients, but the success rate is limited. The major limitation of the current\napproach to AF is the lack of fundamental understanding of its underlying\nmechanism. Specifically, it remains unclear whether human AF dynamics are a\ndeterministic or a stochastic process. Here we assess for determinism in human\nAF by evaluating the properties of the symbolic representation of intracardiac\nelectrical recordings obtained from patients. Specifically, we evaluate (a) the\nnumber of the missing ordinal patterns, (b) the rate of missing ordinal pattern\ndecay for increased length of the time series, and (c) the causal-entropy\ncomplexity plane of the Bandt-Pompe symbolic representation. When used\ntogether, these are powerful tools to detect determinism, even in the presence\nof experimental noise and brief time series.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 20:02:54 GMT"}, {"version": "v2", "created": "Sun, 1 Jul 2018 22:04:24 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Aronis", "Konstantinos N.", ""], ["Berger", "Ronald D.", ""], ["Calkins", "Hugh", ""], ["Chrispin", "Jonathan", ""], ["Marine", "Joseph E.", ""], ["Spragg", "David D.", ""], ["Tao", "Susumu", ""], ["Tandri", "Harikrishna", ""], ["Ashikaga", "Hiroshi", ""]]}, {"id": "1802.01569", "submitter": "Nicolas Masse", "authors": "Nicolas Y. Masse, Gregory D. Grant, David J. Freedman", "title": "Alleviating catastrophic forgetting using context-dependent gating and\n  synaptic stabilization", "comments": "Published in PNAS, https://www.pnas.org/content/115/44/E10467", "journal-ref": "Proceedings of the National Academy of Sciences, 115(44),\n  E10467-E10475", "doi": "10.1073/pnas.1803839115", "report-no": null, "categories": "cs.LG cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Humans and most animals can learn new tasks without forgetting old ones.\nHowever, training artificial neural networks (ANNs) on new tasks typically\ncause it to forget previously learned tasks. This phenomenon is the result of\n\"catastrophic forgetting\", in which training an ANN disrupts connection weights\nthat were important for solving previous tasks, degrading task performance.\nSeveral recent studies have proposed methods to stabilize connection weights of\nANNs that are deemed most important for solving a task, which helps alleviate\ncatastrophic forgetting. Here, drawing inspiration from algorithms that are\nbelieved to be implemented in vivo, we propose a complementary method: adding a\ncontext-dependent gating signal, such that only sparse, mostly non-overlapping\npatterns of units are active for any one task. This method is easy to\nimplement, requires little computational overhead, and allows ANNs to maintain\nhigh performance across large numbers of sequentially presented tasks when\ncombined with weight stabilization. This work provides another example of how\nneuroscience-inspired algorithms can benefit ANN design and capability.\n", "versions": [{"version": "v1", "created": "Fri, 2 Feb 2018 23:49:44 GMT"}, {"version": "v2", "created": "Wed, 3 Apr 2019 16:44:16 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Masse", "Nicolas Y.", ""], ["Grant", "Gregory D.", ""], ["Freedman", "David J.", ""]]}, {"id": "1802.01830", "submitter": "Akira Utsumi", "authors": "Akira Utsumi", "title": "A Neurobiologically Motivated Analysis of Distributional Semantic Models", "comments": "submitted to CogSci 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasive use of distributional semantic models or word embeddings in a\nvariety of research fields is due to their remarkable ability to represent the\nmeanings of words for both practical application and cognitive modeling.\nHowever, little has been known about what kind of information is encoded in\ntext-based word vectors. This lack of understanding is particularly problematic\nwhen word vectors are regarded as a model of semantic representation for\nabstract concepts. This paper attempts to reveal the internal information of\ndistributional word vectors by the analysis using Binder et al.'s (2016)\nbrain-based vectors, explicitly structured conceptual representations based on\nneurobiologically motivated attributes. In the analysis, the mapping from\ntext-based vectors to brain-based vectors is trained and prediction performance\nis evaluated by comparing the estimated and original brain-based vectors. The\nanalysis demonstrates that social and cognitive information is better encoded\nin text-based word vectors, but emotional information is not. This result is\ndiscussed in terms of embodied theories for abstract concepts.\n", "versions": [{"version": "v1", "created": "Tue, 6 Feb 2018 07:41:14 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Utsumi", "Akira", ""]]}, {"id": "1802.01980", "submitter": "Jingjing Xu", "authors": "Shengyong Xu, Jingjing Xu and Rujun Dai", "title": "Layered structure and leveled function of a human brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The anatomically layered structure of a human brain results in leveled\nfunctions. In all these levels of different functions, comparison, feedback and\nimitation are the universal and crucial mechanisms. Languages, symbols and\ntools play key roles in the development of human brain and entire civilization.\n", "versions": [{"version": "v1", "created": "Sun, 4 Feb 2018 05:58:42 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Xu", "Shengyong", ""], ["Xu", "Jingjing", ""], ["Dai", "Rujun", ""]]}, {"id": "1802.02523", "submitter": "Zg Ma", "authors": "John Z. G. Ma", "title": "Plasma Brain Dynamics (PBD): A Mechanism for EEG Waves Under Human\n  Consciousness", "comments": null, "journal-ref": "Cosmos and History: The Journal of Natural and Social Philosophy,\n  Vol 13, No 2 (2017)", "doi": null, "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  EEG signals are records of nonlinear solitary waves in human brains. The\nwaves have several types (e.g., a, b, g, q, d) in response to different levels\nof consciousness. They are classified into two groups: Group-1 consists of\ncomplex storm-like waves (a, b, and g); Group-2 is composed of simple\nquasilinear waves (q and d). In order to elucidate the mechanism of EEG wave\nformation and propagation, this paper extends the Vlasov-Maxwell equations of\nPlasma Brain Dynamics (PBD) to a set of two-fluid, self-similar, nonlinear\nsolitary wave equations. Numerical simulations are performed for different EEG\nsignals. Main results include: (1) The excitation and propagation of the EEG\nwave packets are dependent of electric and magnetic fields, brain aqua-ions,\nelectron and ion temperatures, masses, and their initial fluid speeds; (2)\nGroup-1 complex waves contain three ingredients: the high-frequency\nion-acoustic (IA) mode, the intermediate-frequency lower-hybrid (LH) mode, and\nthe low-frequency ion-cyclotron (IC) mode; (3) Group-2 simple waves fall within\nthe IA band, featured by one or a combination of the three envelopes:\nsinusoidal, sawtooth, and spiky/bipolar. The study proposes an alternative\nmodel to Quantum Brain Dynamics (QBD) by suggesting that the formation and\npropagation of the nonlinear solitary EEG waves in the brain have the same\nmechanism as that of the waves in space plasmas\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 01:51:18 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Ma", "John Z. G.", ""]]}, {"id": "1802.02678", "submitter": "Charles Delahunt", "authors": "Charles B. Delahunt, Jeffrey A. Riffell, J. Nathan Kutz", "title": "Biological Mechanisms for Learning: A Computational Model of Olfactory\n  Learning in the Manduca sexta Moth, with Applications to Neural Nets", "comments": "35 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The insect olfactory system, which includes the antennal lobe (AL), mushroom\nbody (MB), and ancillary structures, is a relatively simple neural system\ncapable of learning. Its structural features, which are widespread in\nbiological neural systems, process olfactory stimuli through a cascade of\nnetworks where large dimension shifts occur from stage to stage and where\nsparsity and randomness play a critical role in coding. Learning is partly\nenabled by a neuromodulatory reward mechanism of octopamine stimulation of the\nAL, whose increased activity induces rewiring of the MB through Hebbian\nplasticity. Enforced sparsity in the MB focuses Hebbian growth on neurons that\nare the most important for the representation of the learned odor. Based upon\ncurrent biophysical knowledge, we have constructed an end-to-end computational\nmodel of the Manduca sexta moth olfactory system which includes the interaction\nof the AL and MB under octopamine stimulation. Our model is able to robustly\nlearn new odors, and our simulations of integrate-and-fire neurons match the\nstatistical features of in-vivo firing rate data. From a biological\nperspective, the model provides a valuable tool for examining the role of\nneuromodulators, like octopamine, in learning, and gives insight into critical\ninteractions between sparsity, Hebbian growth, and stimulation during learning.\nOur simulations also inform predictions about structural details of the\nolfactory system that are not currently well-characterized. From a machine\nlearning perspective, the model yields bio-inspired mechanisms that are\npotentially useful in constructing neural nets for rapid learning from very few\nsamples. These mechanisms include high-noise layers, sparse layers as noise\nfilters, and a biologically-plausible optimization method to train the network\nbased on octopamine stimulation, sparse layers, and Hebbian growth.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 00:16:31 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Delahunt", "Charles B.", ""], ["Riffell", "Jeffrey A.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1802.02701", "submitter": "Shiang Hu", "authors": "Shiang Hu, Esin Karahan, Pedro A. Valdes-Sosa", "title": "Restate the reference for EEG microstate analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the decades of efforts, the choice of EEG reference is still a\ndebated fundamental issue. Non-neutral reference can inevitably inject the\nuncontrolled temporal biases into all EEG recordings, which may influence the\nspatiotemporal analysis of brain activity. A method, termed microstates,\nidentifying spatiotemporal EEG features as the quasi-stable topography states\nin milliseconds, suggests its potential as biomarkers of neurophysiological\ndisease. As reference electrode standardization technique (REST) could\nreconstruct an infinity reference approximately, it is a question whether REST\nor the other references will be more reliable than average reference (AR) for\nthe microstates analysis. In this study, we design the microstate-based EEG\nforward model, and apply different references for microstates analysis. The\nspatial similarity between the generated and assumed cluster maps is mainly\ninvestigated. Furthermore, the real EEG data by the parametric bootstrap method\nis used to validate the performance of the references. Finally, we find that\nREST is robust to recover more similar cluster maps to the assumption than AR\nin the simulation, and the cluster maps between REST and AR on the real EEG\ndata are quite different. This study may indicate that REST contributes to\nidentifying more objective microstates features than AR.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 03:25:50 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Hu", "Shiang", ""], ["Karahan", "Esin", ""], ["Valdes-Sosa", "Pedro A.", ""]]}, {"id": "1802.02930", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Evolution of the Science Fiction Writer's Capacity to Imagine the Future", "comments": "6 pages; 1 figure. In Proceedings of International Science Fiction\n  Prototyping Conference (SCI-FI'18). Ostend, Belgium: EUROSIS (a division of\n  the European Technology Institute). (Held April 18-19 in Bruges, Belgium.)\n  arXiv admin note: substantial text overlap with arXiv:1704.05056", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawing upon a body of research on the evolution of creativity, this paper\nproposes a theory of how, when, and why the forward-thinking story-telling\nabilities of humans evolved, culminating in the visionary abilities of science\nfiction writers. The ability to recursively chain thoughts together evolved\napproximately two million years ago. Language abilities, and the ability to\nshift between different modes of thought, evolved approximately 100,000 years\nago. Science fiction dates to at least the second Century AD. It is suggested\nthat well before this time, but after 100,000 years ago, and concurrent with\nthe evolution of a division of labour between creators and imitators there\narose a division of labour between past, present, and future thinkers.\nAgent-based model research suggests there are social benefits to the evolution\nof individual differences in creativity such that there is a balance between\nnovelty-generating creators and continuity-perpetuating imitators. A balance\nbetween individuals focused on the past, present, and future would be expected\nto yield similar adaptive benefits.\n", "versions": [{"version": "v1", "created": "Wed, 7 Feb 2018 00:02:19 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 22:02:15 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1802.02937", "submitter": "Jerome Laurin", "authors": "Caroline Pin-Barre (LAMHESS), Annabelle Constans, Jeanick Brisswalter,\n  Christophe Pellegrino, J\\'er\\^ome Laurin (ISM)", "title": "Effects of high vs moderate-intensity training on neuroplasticity and\n  functional recovery after focal ischemia", "comments": null, "journal-ref": "American Heart Association, 2017, 48 (10), pp.2855 - 2864", "doi": "10.1161/STROKEAHA.117.017962", "report-no": null, "categories": "q-bio.NC q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background and Purpose: This study was designed to compare the effects of\nhigh-intensity interval training (HIT) and moderate-intensity continuous\ntraining (MOD) on functional recovery and cerebral plasticity during the first\n2 weeks following cerebral ischemia. Methods: Rats were randomized as follows:\nControl (n=15), SHAM (n=9), MCAO (n=13), MCAO-D1 (n=7), MOD (n=13) and HIT\n(n=13). Incremental tests were performed at day 1 (D1) and 14 (D14) to identify\nthe running speed associated with the lactate threshold (SLT) and the maximal\nspeed (Smax). Functional tests were performed at D1, D7 and D14. Microglia\nform, cytokines, p75NTR, KCC2 and NKCC1 expression were made at D15.\nResults-HIT was more effective to improve the endurance performance than MOD\nand induced a fast recovery of the impaired forelimb grip force. The Iba-1\npositive cells with amoeboid form and the pro- and anti-inflammatory cytokine\nexpression were lower in HIT group, mainly in the ipsilesional hemisphere. A\np75NTR overexpression is observed on the ipsilesional side together with a\nrestored NKCC1/KCC2 ratio on the contralesional side. Conclusions-Low-volume\nHIT based on lactate threshold appears to be more effective after cerebral\nischemia than work-matched MOD to improve aerobic fitness, grip strength and\nmight promote cerebral plasticity.\n", "versions": [{"version": "v1", "created": "Thu, 8 Feb 2018 15:56:19 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Pin-Barre", "Caroline", "", "LAMHESS"], ["Constans", "Annabelle", "", "ISM"], ["Brisswalter", "Jeanick", "", "ISM"], ["Pellegrino", "Christophe", "", "ISM"], ["Laurin", "J\u00e9r\u00f4me", "", "ISM"]]}, {"id": "1802.03390", "submitter": "Junkyung Kim", "authors": "Matthew Ricci, Junkyung Kim, Thomas Serre", "title": "Same-different problems strain convolutional neural networks", "comments": "6 Pages, 4 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robust and efficient recognition of visual relations in images is a\nhallmark of biological vision. We argue that, despite recent progress in visual\nrecognition, modern machine vision algorithms are severely limited in their\nability to learn visual relations. Through controlled experiments, we\ndemonstrate that visual-relation problems strain convolutional neural networks\n(CNNs). The networks eventually break altogether when rote memorization becomes\nimpossible, as when intra-class variability exceeds network capacity. Motivated\nby the comparable success of biological vision, we argue that feedback\nmechanisms including attention and perceptual grouping may be the key\ncomputational components underlying abstract visual reasoning.\\\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 18:55:34 GMT"}, {"version": "v2", "created": "Mon, 12 Feb 2018 22:29:20 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 17:00:23 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Ricci", "Matthew", ""], ["Kim", "Junkyung", ""], ["Serre", "Thomas", ""]]}, {"id": "1802.03397", "submitter": "Sagnik Bhattacharyya", "authors": "Subhadip Paul, Satyam Mukherjee, Sagnik Bhattacharyya", "title": "Network organization of coopetitive genetic influences on cortical\n  morphologies", "comments": "32 pages, 3 tables, 2 figures; 1 supplementary method and 1\n  supplementary figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain can be represented as a network, where regions are the nodes and\nrelations between the regions are edges. Within a network, co-existence of\ncooperative and competitive relationships between different nodes is called\ncoopetition. Inter-regional genetic influences on morphological phenotypes\n(cortical thickness, surface area) of cortex display such coopetitive\nrelationships. Here, we have represented these genetic influences as a network\nand shown that cooperative and competitive genetic influences on cortical\nmorphological phenotypes follow distinct organization principles. Utilizing the\ntheory of structural balance, we have shown that the pattern of collective\nregulation of cortical morphological phenotypes by cooperative and competitive\ngenetic influences are overall bilaterally symmetric and such patterns of\ncollective genetic regulation are similar to the principal modes of population\nvariation of cortical morphological phenotypes. Finally, we have observed that\nthe maximally and minimally imbalanced regions corresponding to the collective\ngenetic regulation partially overlap with the cortical structural network hubs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 17:38:57 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Paul", "Subhadip", ""], ["Mukherjee", "Satyam", ""], ["Bhattacharyya", "Sagnik", ""]]}, {"id": "1802.03405", "submitter": "Marius Oltean", "authors": "Marius Oltean, Carlos F. Sopuerta, Alessandro D.A.M. Spallicci", "title": "Particle-without-Particle: a practical pseudospectral collocation method\n  for linear partial differential equations with distributional sources", "comments": "41 pages, 11 figures; v2: references and clarifications added (mostly\n  in the introduction), matches the published version in Journal of Scientific\n  Computing", "journal-ref": "Journal of Scientific Computing 79, 827 (2019)", "doi": "10.1007/s10915-018-0873-9", "report-no": null, "categories": "physics.comp-ph gr-qc math.NA q-bio.NC q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial differential equations with distributional sources---in particular,\ninvolving (derivatives of) delta distributions---have become increasingly\nubiquitous in numerous areas of physics and applied mathematics. It is often of\nconsiderable interest to obtain numerical solutions for such equations, but any\nsingular (\"particle\"-like) source modeling invariably introduces nontrivial\ncomputational obstacles. A common method to circumvent these is through some\nform of delta function approximation procedure on the computational grid;\nhowever, this often carries significant limitations on the efficiency of the\nnumerical convergence rates, or sometimes even the resolvability of the problem\nat all.\n  In this paper, we present an alternative technique for tackling such\nequations which avoids the singular behavior entirely: the\n\"Particle-without-Particle\" method. Previously introduced in the context of the\nself-force problem in gravitational physics, the idea is to discretize the\ncomputational domain into two (or more) disjoint pseudospectral\n(Chebyshev-Lobatto) grids such that the \"particle\" is always at the interface\nbetween them; thus, one only needs to solve homogeneous equations in each\ndomain, with the source effectively replaced by jump (boundary) conditions\nthereon. We prove here that this method yields solutions to any linear PDE the\nsource of which is any linear combination of delta distributions and\nderivatives thereof supported on a one-dimensional subspace of the problem\ndomain. We then implement it to numerically solve a variety of relevant PDEs:\nhyperbolic (with applications to neuroscience and acoustics), parabolic (with\napplications to finance), and elliptic. We generically obtain improved\nconvergence rates relative to typical past implementations relying on delta\nfunction approximations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Feb 2018 19:00:05 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2018 16:14:18 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Oltean", "Marius", ""], ["Sopuerta", "Carlos F.", ""], ["Spallicci", "Alessandro D. A. M.", ""]]}, {"id": "1802.03627", "submitter": "Hazem Toutounji", "authors": "Hazem Toutounji (1 and 2) and Daniel Durstewitz (1 and 3) ((1)\n  Department of Theoretical Neuroscience, Bernstein Center for Computational\n  Neuroscience, Central Institute of Mental Health, Medical Faculty Mannheim,\n  Heidelberg University, Mannheim, Germany, (2) Institute of Neuroinformatics,\n  University of Zurich and ETH Zurich, Zurich, Switzerland, (3) Faculty of\n  Physics and Astronomy, Heidelberg University, Heidelberg, Germany)", "title": "Detecting Multiple Change Points Using Adaptive Regression Splines with\n  Application to Neural Recordings", "comments": "35 pages, 9 figures, 2 tables, 3 algorithms", "journal-ref": null, "doi": "10.3389/fninf.2018.00067", "report-no": null, "categories": "stat.ME q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series, as frequently the case in neuroscience, are rarely stationary,\nbut often exhibit abrupt changes due to attractor transitions or bifurcations\nin the dynamical systems producing them. A plethora of methods for detecting\nsuch change points in time series statistics have been developed over the\nyears, in addition to test criteria to evaluate their significance. Issues to\nconsider when developing change point analysis methods include computational\ndemands, difficulties arising from either limited amount of data or a large\nnumber of covariates, and arriving at statistical tests with sufficient power\nto detect as many changes as contained in potentially high-dimensional time\nseries. Here, a general method called Paired Adaptive Regressors for Cumulative\nSum is developed for detecting multiple change points in the mean of\nmultivariate time series. The method's advantages over alternative approaches\nare demonstrated through a series of simulation experiments. This is followed\nby a real data application to neural recordings from rat medial prefrontal\ncortex during learning. Finally, the method's flexibility to incorporate useful\nfeatures from state-of-the-art change point detection techniques is discussed,\nalong with potential drawbacks and suggestions to remedy them.\n", "versions": [{"version": "v1", "created": "Sat, 10 Feb 2018 17:57:25 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 07:43:56 GMT"}, {"version": "v3", "created": "Mon, 3 Sep 2018 20:00:05 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Toutounji", "Hazem", "", "1 and 2"], ["Durstewitz", "Daniel", "", "1 and 3"]]}, {"id": "1802.03891", "submitter": "Madhavun Candadai", "authors": "Madhavun Candadai and Eduardo Izquierdo", "title": "Multifunctionality in embodied agents: Three levels of neural reuse", "comments": "Accepted at Cognitive Science Conference, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain in conjunction with the body is able to adapt to new environments\nand perform multiple behaviors through reuse of neural resources and transfer\nof existing behavioral traits. Although mechanisms that underlie this ability\nare not well understood, they are largely attributed to neuromodulation. In\nthis work, we demonstrate that an agent can be multifunctional using the same\nsensory and motor systems across behaviors, in the absence of modulatory\nmechanisms. Further, we lay out the different levels at which neural reuse can\noccur through a dynamical filtering of the brain-body-environment system's\noperation: structural network, autonomous dynamics, and transient dynamics.\nNotably, transient dynamics reuse could only be explained by studying the\nbrain-body-environment system as a whole and not just the brain. The\nmultifunctional agent we present here demonstrates neural reuse at all three\nlevels.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 04:41:18 GMT"}, {"version": "v2", "created": "Sat, 12 May 2018 17:44:36 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 01:44:56 GMT"}, {"version": "v4", "created": "Wed, 16 May 2018 00:43:18 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Candadai", "Madhavun", ""], ["Izquierdo", "Eduardo", ""]]}, {"id": "1802.04069", "submitter": "Lars Rothkegel", "authors": "Lars Oliver Martin Rothkegel, Heiko Herbert Sch\\\"utt, Hans Arne\n  Trukenbrod, Felix Alexander Wichmann and Ralf Engbert", "title": "Searchers adjust their eye movement dynamics to the target\n  characteristics in natural scenes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When searching a target in a natural scene, both the target's visual\nproperties and similarity to the background influence whether (and how fast)\nhumans are able to find it. However, thus far it has been unclear whether\nsearchers adjust the dynamics of their eye movements (e.g., fixation durations,\nsaccade amplitudes) to the target they search for. In our experiment\nparticipants searched natural scenes for six artificial targets with different\nspatial frequency throughout eight consecutive sessions. High-spatial frequency\ntargets led to smaller saccade amplitudes and shorter fixation durations than\nlow-spatial frequency targets if target identity was known before the trial. If\na saccade was programmed in the same direction as the previous saccade\n(saccadic momentum), fixation durations and successive saccade amplitudes were\nnot influenced by target type. Visual saliency and empirical density at the\nendpoints of saccadic momentum saccades were comparatively low, indicating that\nthese saccades were less selective. Our results demonstrate that searchers\nadjust their eye movement dynamics to the search target in a sensible fashion,\nsince low-spatial frequencies are visible farther into the periphery than\nhigh-spatial frequencies. Additionally, the saccade direction specificity of\nour effects suggests a separation of saccades into a default scanning mechanism\nand a selective, target-dependent mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 14:34:01 GMT"}], "update_date": "2018-02-13", "authors_parsed": [["Rothkegel", "Lars Oliver Martin", ""], ["Sch\u00fctt", "Heiko Herbert", ""], ["Trukenbrod", "Hans Arne", ""], ["Wichmann", "Felix Alexander", ""], ["Engbert", "Ralf", ""]]}, {"id": "1802.04118", "submitter": "Romain Veltz M", "authors": "Nicolas Fournier and Etienne Tanr\\'e and Romain Veltz", "title": "On a toy network of neurons interacting through their dendrites", "comments": null, "journal-ref": "Annales de l'Institut Henri Poincare - Probabilites et\n  Statistiques (2020) 56(2), pp. 1041-1071", "doi": "10.1214/19-AIHP993", "report-no": null, "categories": "math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a large number $n$ of neurons, each being connected to approximately\n$N$ other ones, chosen at random. When a neuron spikes, which occurs randomly\nat some rate depending on its electric potential, its potential is set to a\nminimum value $v_{min}$, and this initiates, after a small delay, two fronts on\nthe (linear) dendrites of all the neurons to which it is connected. Fronts move\nat constant speed. When two fronts (on the dendrite of the same neuron)\ncollide, they annihilate. When a front hits the soma of a neuron, its potential\nis increased by a small value $w_n$. Between jumps, the potentials of the\nneurons are assumed to drift in $[v_{min},\\infty)$, according to some\nwell-posed ODE. We prove the existence and uniqueness of a heuristically\nderived mean-field limit of the system when $n,N \\to \\infty$ with $w_n \\simeq\nN^{-1/2}$. We make use of some recent versions of the results of Deuschel and\nZeitouni \\cite{dz} concerning the size of the longest increasing subsequence of\nan i.i.d. collection of points in the plan. We also study, in a very particular\ncase, a slightly different model where the neurons spike when their potential\nreach some maximum value $v_{max}$, and find an explicit formula for the\n(heuristic) mean-field limit.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 15:27:11 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 14:32:49 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Fournier", "Nicolas", ""], ["Tanr\u00e9", "Etienne", ""], ["Veltz", "Romain", ""]]}, {"id": "1802.04255", "submitter": "Eugenio Maria Battaglia", "authors": "Eugenio Maria Battaglia, Jie Mei and Guillaume Dumas", "title": "Systems of Global Governance in the Era of Human-Machine Convergence", "comments": "23 pages, 213 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY physics.soc-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Technology is increasingly shaping our social structures and is becoming a\ndriving force in altering human biology. Besides, human activities already\nproved to have a significant impact on the Earth system which in turn generates\ncomplex feedback loops between social and ecological systems. Furthermore,\nsince our species evolved relatively fast from small groups of hunter-gatherers\nto large and technology-intensive urban agglomerations, it is not a surprise\nthat the major institutions of human society are no longer fit to cope with the\npresent complexity. In this note we draw foundational parallelisms between\nneurophysiological systems and ICT-enabled social systems, discussing how\nframeworks rooted in biology and physics could provide heuristic value in the\ndesign of evolutionary systems relevant to politics and economics. In this\nregard we highlight how the governance of emerging technology (i.e.\nnanotechnology, biotechnology, information technology, and cognitive science),\nand the one of climate change both presently confront us with a number of\nconnected challenges. In particular: historically high level of inequality; the\nco-existence of growing multipolar cultural systems in an unprecedentedly\nconnected world; the unlikely reaching of the institutional agreements required\nto deviate abnormal trajectories of development. We argue that wise general\nsolutions to such interrelated issues should embed the deep understanding of\nhow to elicit mutual incentives in the socio-economic subsystems of Earth\nsystem in order to jointly concur to a global utility function (e.g. avoiding\nthe reach of planetary boundaries and widespread social unrest). We leave some\nopen questions on how techno-social systems can effectively learn and adapt\nwith respect to our understanding of geopolitical complexity.\n", "versions": [{"version": "v1", "created": "Sun, 11 Feb 2018 11:55:39 GMT"}, {"version": "v2", "created": "Wed, 14 Feb 2018 13:15:50 GMT"}], "update_date": "2018-02-15", "authors_parsed": [["Battaglia", "Eugenio Maria", ""], ["Mei", "Jie", ""], ["Dumas", "Guillaume", ""]]}, {"id": "1802.04353", "submitter": "Yu Jin", "authors": "Yu Jin, Joseph F. JaJa, Rong Chen, Edward H. Herskovits", "title": "A Data-Driven Approach to Extract Connectivity Structures from Diffusion\n  Tensor Imaging Data", "comments": "Proceedings of 2015 IEEE International Conference on Big Data", "journal-ref": null, "doi": "10.1109/BigData.2015.7363843", "report-no": null, "categories": "cs.CE q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion Tensor Imaging (DTI) is an effective tool for the analysis of\nstructural brain connectivity in normal development and in a broad range of\nbrain disorders. However efforts to derive inherent characteristics of\nstructural brain networks have been hampered by the very high dimensionality of\nthe data, relatively small sample sizes, and the lack of widely acceptable\nconnectivity-based regions of interests (ROIs). Typical approaches have focused\neither on regions defined by standard anatomical atlases that do not\nincorporate anatomical connectivity, or have been based on voxel-wise analysis,\nwhich results in loss of statistical power relative to structure-wise\nconnectivity analysis. In this work, we propose a novel, computationally\nefficient iterative clustering method to generate connectivity-based\nwhole-brain parcellations that converge to a stable parcellation in a few\niterations. Our algorithm is based on a sparse representation of the whole\nbrain connectivity matrix, which reduces the number of edges from around a half\nbillion to a few million while incorporating the necessary spatial constraints.\nWe show that the resulting regions in a sense capture the inherent connectivity\ninformation present in the data, and are stable with respect to initialization\nand the randomization scheme within the algorithm. These parcellations provide\nconsistent structural regions across the subjects of population samples that\nare homogeneous with respect to anatomic connectivity. Our method also derives\nconnectivity structures that can be used to distinguish between population\nsamples with known different structural connectivity. In particular, new\nresults in structural differences for different population samples such as\nFemales vs Males, Normal Controls vs Schizophrenia, and different age groups in\nNormal Controls are also shown.\n", "versions": [{"version": "v1", "created": "Mon, 12 Feb 2018 20:42:36 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Jin", "Yu", ""], ["JaJa", "Joseph F.", ""], ["Chen", "Rong", ""], ["Herskovits", "Edward H.", ""]]}, {"id": "1802.04794", "submitter": "Joshua Goldwyn", "authors": "Joshua H Goldwyn, Bradley R Slabe, Joseph B Travers, David Terman", "title": "Gain control with A-type potassium current: IA as a switch between\n  divisive and subtractive inhibition", "comments": "20 pages, 11 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1006292", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons process information by transforming barrages of synaptic inputs into\nspiking activity. Synaptic inhibition suppresses the output firing activity of\na neuron, and is commonly classified as having a subtractive or divisive effect\non a neuron's output firing activity. Subtractive inhibition can narrow the\nrange of inputs that evoke spiking activity by eliminating responses to\nnon-preferred inputs. Divisive inhibition is a form of gain control: it\nmodifies firing rates while preserving the range of inputs that evoke firing\nactivity. Since these two \"modes\" of inhibition have distinct impacts on neural\ncoding, it is important to understand the biophysical mechanisms that\ndistinguish these response profiles.\n  We use simulations and mathematical analysis of a neuron model to find the\nspecific conditions for which inhibitory inputs have subtractive or divisive\neffects. We identify a novel role for the A-type Potassium current (IA). In our\nmodel, this fast-activating, slowly- inactivating outward current acts as a\nswitch between subtractive and divisive inhibition. If IA is strong (large\nmaximal conductance) and fast (activates on a time-scale similar to spike\ninitiation), then inhibition has a subtractive effect on neural firing. In\ncontrast, if IA is weak or insufficiently fast-activating, then inhibition has\na divisive effect on neural firing. We explain these findings using dynamical\nsystems methods to define how a spike threshold condition depends on synaptic\ninputs and IA.\n  Our findings suggest that neurons can \"self-regulate\" the gain control\neffects of inhibition via combinations of synaptic plasticity and/or modulation\nof the conductance and kinetics of A-type Potassium channels. This novel role\nfor IA would add flexibility to neurons and networks, and may relate to recent\nobservations of divisive inhibitory effects on neurons in the nucleus of the\nsolitary tract.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 18:56:57 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Goldwyn", "Joshua H", ""], ["Slabe", "Bradley R", ""], ["Travers", "Joseph B", ""], ["Terman", "David", ""]]}, {"id": "1802.05405", "submitter": "Charles Delahunt", "authors": "Charles B. Delahunt, J. Nathan Kutz", "title": "Putting a bug in ML: The moth olfactory network learns to read MNIST", "comments": "23 pages, 7 figures. Version 3: 25 January 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We seek to (i) characterize the learning architectures exploited in\nbiological neural networks for training on very few samples, and (ii) port\nthese algorithmic structures to a machine learning context. The Moth Olfactory\nNetwork is among the simplest biological neural systems that can learn, and its\narchitecture includes key structural elements and mechanisms widespread in\nbiological neural nets, such as cascaded networks, competitive inhibition, high\nintrinsic noise, sparsity, reward mechanisms, and Hebbian plasticity. These\nstructural biological elements, in combination, enable rapid learning.\n  MothNet is a computational model of the Moth Olfactory Network, closely\naligned with the moth's known biophysics and with in vivo electrode data\ncollected from moths learning new odors. We assign this model the task of\nlearning to read the MNIST digits. We show that MothNet successfully learns to\nread given very few training samples (1 to 10 samples per class). In this\nfew-samples regime, it outperforms standard machine learning methods such as\nnearest-neighbors, support-vector machines, and neural networks (NNs), and\nmatches specialized one-shot transfer-learning methods but without the need for\npre-training. The MothNet architecture illustrates how algorithmic structures\nderived from biological brains can be used to build alternative NNs that may\navoid some of the learning rate limitations of current engineered NNs.\n", "versions": [{"version": "v1", "created": "Thu, 15 Feb 2018 04:58:45 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 01:23:22 GMT"}, {"version": "v3", "created": "Sat, 26 Jan 2019 22:40:41 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Delahunt", "Charles B.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1802.05533", "submitter": "Giulia Prando", "authors": "Giulia Prando, Mattia Zorzi, Alessandra Bertoldo, Alessandro Chiuso", "title": "The role of noise modeling in the estimation of resting-state brain\n  effective connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal relations among neuronal populations of the brain are studied through\nthe so-called effective connectivity (EC) network. The latter is estimated from\nEEG or fMRI measurements, by inverting a generative model of the corresponding\ndata. It is clear that the goodness of the estimated network heavily depends on\nthe underlying modeling assumptions. In this present paper we consider the EC\nestimation problem using fMRI data in resting-state condition. Specifically, we\ninvestigate on how to model endogenous fluctuations driving the neuronal\nactivity.\n", "versions": [{"version": "v1", "created": "Tue, 13 Feb 2018 17:39:49 GMT"}], "update_date": "2018-02-16", "authors_parsed": [["Prando", "Giulia", ""], ["Zorzi", "Mattia", ""], ["Bertoldo", "Alessandra", ""], ["Chiuso", "Alessandro", ""]]}, {"id": "1802.06017", "submitter": "Mahmoud Hassan", "authors": "A. Kabbara, H. Eid, EL W. Falou, M. Khalil, F. Wendling, M. Hassan", "title": "Reduced integration and improved segregation of functional brain\n  networks in Alzheimer's disease", "comments": null, "journal-ref": null, "doi": "10.1088/1741-2552/aaaa76", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging evidence shows that cognitive deficits in Alzheimer disease (AD) are\nassociated with disruptions in brain functional connectivity. Thus, the\nidentification of alterations in AD functional networks has become a topic of\nincreasing interest. However, to what extent AD induces disruption of the\nbalance of local and global information processing in the human brain remains\nelusive. The main objective of this study is to explore the dynamic topological\nchanges of AD networks in terms of brain network segregation and integration.\nWe used electroencephalography (EEG) data recorded from 20 participants (10 AD\npatients and 10 healthy controls) during resting state. Functional brain\nnetworks were reconstructed using EEG source connectivity computed in different\nfrequency bands. Graph theoretical analyses were performed assess differences\nbetween both groups. Results revealed that AD networks, compared to networks of\nage matched healthy controls, are characterized by lower global information\nprocessing (integration) and higher local information processing (segregation).\nResults showed also significant correlation between the alterations in the AD\npatients functional brain networks and their cognitive scores. These findings\nmay contribute to the development of EEG network-based test that could\nstrengthen results obtained from currently used neurophysiological tests in\nneurodegenerative diseases.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 16:38:44 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Kabbara", "A.", ""], ["Eid", "H.", ""], ["Falou", "EL W.", ""], ["Khalil", "M.", ""], ["Wendling", "F.", ""], ["Hassan", "M.", ""]]}, {"id": "1802.06108", "submitter": "Ismael Tito Freire Gonz\\'alez", "authors": "Ismael T. Freire, Clement Moulin-Frier, Marti Sanchez-Fibla, Xerxes D.\n  Arsiwalla, Paul Verschure", "title": "Modeling the Formation of Social Conventions from Embodied Real-Time\n  Interactions", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is the role of real-time control and learning in the formation of social\nconventions? To answer this question, we propose a computational model that\nmatches human behavioral data in a social decision-making game that was\nanalyzed both in discrete-time and continuous-time setups. Furthermore, unlike\nprevious approaches, our model takes into account the role of sensorimotor\ncontrol loops in embodied decision-making scenarios. For this purpose, we\nintroduce the Control-based Reinforcement Learning (CRL) model. CRL is grounded\nin the Distributed Adaptive Control (DAC) theory of mind and brain, where\nlow-level sensorimotor control is modulated through perceptual and behavioral\nlearning in a layered structure. CRL follows these principles by implementing a\nfeedback control loop handling the agent's reactive behaviors (pre-wired\nreflexes), along with an adaptive layer that uses reinforcement learning to\nmaximize long-term reward. We test our model in a multi-agent game-theoretic\ntask in which coordination must be achieved to find an optimal solution. We\nshow that CRL is able to reach human-level performance on standard\ngame-theoretic metrics such as efficiency in acquiring rewards and fairness in\nreward distribution.\n", "versions": [{"version": "v1", "created": "Fri, 16 Feb 2018 20:22:41 GMT"}, {"version": "v2", "created": "Tue, 28 May 2019 16:59:56 GMT"}, {"version": "v3", "created": "Tue, 31 Dec 2019 20:08:44 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Freire", "Ismael T.", ""], ["Moulin-Frier", "Clement", ""], ["Sanchez-Fibla", "Marti", ""], ["Arsiwalla", "Xerxes D.", ""], ["Verschure", "Paul", ""]]}, {"id": "1802.06164", "submitter": "Benjamin Walker", "authors": "Benjamin Walker, Katherine Newhall", "title": "Inferring Information Flow in Spike-train Data Sets using a\n  Trial-Shuffle Method", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0206977", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding information processing in the brain requires the ability to\ndetermine the functional connectivity between the different regions of the\nbrain. We present a method using transfer entropy to extract this flow of\ninformation between brain regions from spike-train data commonly obtained in\nneurological experiments. Transfer entropy is a statistical measure based in\ninformation theory that attempts to quantify the information flow from one\nprocess to another, and has been applied to find connectivity in simulated\nspike-train data. Due to statistical error in the estimator, inferring\nfunctional connectivity requires a method for determining significance in the\ntransfer entropy values. We discuss the issues with numerical estimation of\ntransfer entropy and resulting challenges in determining significance before\npresenting the trial-shuffle method as a viable option. The trial-shuffle\nmethod, for spike-train data that is split into multiple trials, determines\nsignificant transfer entropy values independently for each individual pair of\nneurons by comparing to a created baseline distribution using a rigorous\nstatistical test. This is in contrast to either globally comparing all neuron\ntransfer entropy values or comparing pairwise values to a single baseline\nvalue.\n  In establishing the viability of this method by comparison to several\nalternative approaches in the literature, we find evidence that preserving the\ninter-spike-interval timing is important.\n  We then use the trial-shuffle method to investigate information flow within a\nmodel network as we vary model parameters. This includes investigating the\nglobal flow of information within a connectivity network divided into two\nwell-connected subnetworks, going beyond local transfer of information between\npairs of neurons.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 00:32:12 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2018 02:07:39 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Walker", "Benjamin", ""], ["Newhall", "Katherine", ""]]}, {"id": "1802.06327", "submitter": "Ketan Mehta", "authors": "Ketan Mehta and Joerg Kliewer", "title": "Directional and Causal Information Flow in EEG for Assessing Perceived\n  Audio Quality", "comments": "IEEE Transactions on Molecular, Biological, and Multi-Scale\n  Communication, September 2017, Vol. 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP eess.AS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, electroencephalography (EEG) measurements are used to infer\nchange in cortical functional connectivity in response to change in audio\nstimulus. Experiments are conducted wherein the EEG activity of human subjects\nis recorded as they listen to audio sequences whose quality varies with time. A\ncausal information theoretic framework is then proposed to measure the\ninformation flow between EEG sensors appropriately grouped into different\nregions of interest (ROI) over the cortex. A new causal bidirectional\ninformation (CBI) measure is defined as an improvement over standard directed\ninformation measures for the purposes of identifying connectivity between ROIs\nin a generalized cortical network setting. CBI can be intuitively interpreted\nas a causal bidirectional modification of directed information, and inherently\ncalculates the divergence of the observed data from a multiple access channel\nwith feedback. Further, we determine the analytical relationship between the\ndifferent causal measures and compare how well they are able to distinguish\nbetween the perceived audio quality. The connectivity results inferred indicate\na significant change in the rate of information flow between ROIs as the\nsubjects listen to different audio qualities, with CBI being the best in\ndiscriminating between the perceived audio quality, compared to using standard\ndirected information measures.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 03:37:32 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Mehta", "Ketan", ""], ["Kliewer", "Joerg", ""]]}, {"id": "1802.06426", "submitter": "Zoran Tiganj", "authors": "Zoran Tiganj, Samuel J. Gershman, Per B. Sederberg, Marc W. Howard", "title": "Estimating scale-invariant future in continuous time", "comments": "25 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural learners must compute an estimate of future outcomes that follow from\na stimulus in continuous time. Widely used reinforcement learning algorithms\ndiscretize continuous time and estimate either transition functions from one\nstep to the next (model-based algorithms) or a scalar value of\nexponentially-discounted future reward using the Bellman equation (model-free\nalgorithms). An important drawback of model-based algorithms is that\ncomputational cost grows linearly with the amount of time to be simulated. On\nthe other hand, an important drawback of model-free algorithms is the need to\nselect a time-scale required for exponential discounting. We present a\ncomputational mechanism, developed based on work in psychology and\nneuroscience, for computing a scale-invariant timeline of future outcomes. This\nmechanism efficiently computes an estimate of inputs as a function of future\ntime on a logarithmically-compressed scale, and can be used to generate a\nscale-invariant power-law-discounted estimate of expected future reward. The\nrepresentation of future time retains information about what will happen when.\nThe entire timeline can be constructed in a single parallel operation which\ngenerates concrete behavioral and neural predictions. This computational\nmechanism could be incorporated into future reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 19:09:28 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 21:43:23 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 23:46:21 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Tiganj", "Zoran", ""], ["Gershman", "Samuel J.", ""], ["Sederberg", "Per B.", ""], ["Howard", "Marc W.", ""]]}, {"id": "1802.06456", "submitter": "Wei Ji Ma", "authors": "Nuwan de Silva and Wei Ji Ma", "title": "Optimal allocation of attentional resource to multiple items with\n  unequal relevance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In natural perception, different items (objects) in a scene are rarely\nequally relevant to the observer. The brain improves performance by directing\nattention to the most relevant items, for example the ones most likely to be\nprobed. For a general set of probing probabilities, it is not known how\nattentional resources should be allocated to maximize performance. Here, we\ninvestigate the optimal strategy for allocating a fixed resource budget E among\nN items when on each trial, only one item gets probed. We develop an efficient\nalgorithm that, for any concave utility function, reduces the N-dimensional\nproblem to a set of N one-dimensional problems that the brain could plausibly\nsolve. We find that the intuitive strategy of allocating resource in proportion\nto the probing probabilities is in general not optimal. In particular, in some\ntasks, if resource is low, the optimal strategy involves allocating zero\nresource to items with a nonzero probability of being probed. Our work opens\nthe door to normatively guided studies of attentional allocation.\n", "versions": [{"version": "v1", "created": "Sun, 18 Feb 2018 22:23:48 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["de Silva", "Nuwan", ""], ["Ma", "Wei Ji", ""]]}, {"id": "1802.06507", "submitter": "Joaquin Goni", "authors": "Uttara Tipnis, Enrico Amico, Mario Ventresca, Joaquin Goni", "title": "Modeling communication processes in the human connectome through\n  cooperative learning", "comments": "22 pages, 4 tables, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication processes within the human brain at different cognitive states\nare neither well understood nor completely characterized. We assess\ncommunication processes in the human connectome using ant colony-inspired\ncooperative learning algorithm, starting from a source with no a priori\ninformation about the network topology, and cooperatively searching for the\ntarget through a pheromone-inspired model. This framework relies on two\nparameters, namely pheromone perception and edge perception, to define the\ncognizance and subsequent behaviour of the ants on the network and, overall,\nthe communication processes happening between source and target nodes.\nSimulations obtained through different configurations allow the identification\nof path-ensembles that are involved in the communication between node pairs.\nThese path-ensembles may contain different number of paths depending on the\nperception parameters and the node pair. In order to assess the different\ncommunication regimes displayed on the simulations and their associations with\nfunctional connectivity, we introduce two network measurements, effective\npath-length and arrival rate. These communication features are tested as\nindividual as well as combined predictors of functional connectivity during\ndifferent tasks. Finally, different communication regimes are found in\ndifferent specialized functional networks. Overall, this framework may be used\nas a test-bed for different communication regimes on top of an underlaying\ntopology.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 02:58:34 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Tipnis", "Uttara", ""], ["Amico", "Enrico", ""], ["Ventresca", "Mario", ""], ["Goni", "Joaquin", ""]]}, {"id": "1802.06580", "submitter": "Maxime Lucas", "authors": "Maxime Lucas, Duccio Fanelli, Timoteo Carletti, Julien Petit", "title": "Desynchronization induced by time-varying network", "comments": "To appear in Europhys. Lett", "journal-ref": null, "doi": "10.1209/0295-5075/121/50008", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech nlin.PS physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The synchronous dynamics of an array of excitable oscillators, coupled via a\ngeneric graph, is studied. Non homogeneous perturbations can grow and destroy\nsynchrony, via a self-consistent instability which is solely instigated by the\nintrinsic network dynamics. By acting on the characteristic time-scale of the\nnetwork modulation, one can make the examined system to behave as its\n(partially) averaged analog. This result if formally obtained by proving an\nextended version of the averaging theorem, which allows for partial averages to\nbe carried out. As a byproduct of the analysis, oscillation death are reported\nto follow the onset of the network driven instability.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 10:54:28 GMT"}, {"version": "v2", "created": "Tue, 20 Feb 2018 13:23:24 GMT"}, {"version": "v3", "created": "Fri, 13 Apr 2018 12:13:41 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Lucas", "Maxime", ""], ["Fanelli", "Duccio", ""], ["Carletti", "Timoteo", ""], ["Petit", "Julien", ""]]}, {"id": "1802.06591", "submitter": "German I. Parisi", "authors": "Jonathan Tong, German I. Parisi, Stefan Wermter, Brigitte R\\\"oder", "title": "Closing the loop on multisensory interactions: A neural architecture for\n  multisensory causal inference and recalibration", "comments": "The code to implement the network model and simulations can be found\n  online at: https://github.com/jonathan-tong/multisensory-network-model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When the brain receives input from multiple sensory systems, it is faced with\nthe question of whether it is appropriate to process the inputs in combination,\nas if they originated from the same event, or separately, as if they originated\nfrom distinct events. Furthermore, it must also have a mechanism through which\nit can keep sensory inputs calibrated to maintain the accuracy of its internal\nrepresentations. We have developed a neural network architecture capable of i)\napproximating optimal multisensory spatial integration, based on Bayesian\ncausal inference, and ii) recalibrating the spatial encoding of sensory\nsystems. The architecture is based on features of the dorsal processing\nhierarchy, including the spatial tuning properties of unisensory neurons and\nthe convergence of different sensory inputs onto multisensory neurons.\nFurthermore, we propose that these unisensory and multisensory neurons play\ndual roles in i) encoding spatial location as separate or integrated estimates\nand ii) accumulating evidence for the independence or relatedness of\nmultisensory stimuli. We further propose that top-down feedback connections\nspanning the dorsal pathway play key a role in recalibrating spatial encoding\nat the level of early unisensory cortices. Our proposed architecture provides\npossible explanations for a number of human electrophysiological and\nneuroimaging results and generates testable predictions linking neurophysiology\nwith behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 11:31:02 GMT"}, {"version": "v2", "created": "Sat, 24 Feb 2018 14:03:42 GMT"}, {"version": "v3", "created": "Sun, 4 Mar 2018 14:59:39 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Tong", "Jonathan", ""], ["Parisi", "German I.", ""], ["Wermter", "Stefan", ""], ["R\u00f6der", "Brigitte", ""]]}, {"id": "1802.06700", "submitter": "Alessio Franci", "authors": "Guillaume Drion, Alessio Franci, Rodolphe Sepulchre", "title": "Cellular switches orchestrate rhythmic circuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small inhibitory neuronal circuits have long been identified as key neuronal\nmotifs to generate and modulate the coexisting rhythms of various motor\nfunctions. Our paper highlights the role of a cellular switching mechanism to\norchestrate such circuits. The cellular switch makes the circuits\nreconfigurable, robust, adaptable, and externally controllable. Without this\ncellular mechanism, the circuits rhythms entirely rely on specific tunings of\nthe synaptic connectivity, which makes them rigid, fragile, and difficult to\ncontrol externally. We illustrate those properties on the much studied\narchitecture of a small network controlling both the pyloric and gastric\nrhythms of crabs. The cellular switch is provided by a slow negative\nconductance often neglected in mathematical modeling of central pattern\ngenerators. We propose that this conductance is simple to model and key to\ncomputational studies of rhythmic circuit neuromodulation.\n", "versions": [{"version": "v1", "created": "Mon, 19 Feb 2018 16:56:33 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Drion", "Guillaume", ""], ["Franci", "Alessio", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "1802.06772", "submitter": "Salim Arslan", "authors": "Salim Arslan", "title": "Connectivity-Driven Parcellation Methods for the Human Cerebral Cortex", "comments": "Abstract is summarised to satisfy the character limit imposed by\n  Arxiv. Please refer to the pdf for the full text. Forked from\n  https://spiral.imperial.ac.uk/handle/10044/1/54760", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this thesis, we present robust and fully-automated methods for the\nsubdivision of the entire human cerebral cortex based on connectivity\ninformation. Our contributions are four-fold: First, we propose a clustering\napproach to delineate a cortical parcellation that provides a reliable\nabstraction of the brain's functional organisation. Second, we cast the\nparcellation problem as a feature reduction problem and make use of manifold\nlearning and image segmentation techniques to identify cortical regions with\ndistinct structural connectivity patterns. Third, we present a multi-layer\ngraphical model that combines within- and between-subject connectivity, which\nis then decomposed into a cortical parcellation that can represent the whole\npopulation, while accounting for the variability across subjects. Finally, we\nconduct a large-scale, systematic comparison of existing parcellation methods,\nwith a focus on providing some insight into the reliability of brain\nparcellations in terms of reflecting the underlying connectivity, as well as,\nrevealing their impact on network analysis.\n  We evaluate the proposed parcellation methods on publicly available data from\nthe Human Connectome Project and a plethora of quantitative and qualitative\nevaluation techniques investigated in the literature. Experiments across\nmultiple resolutions demonstrate the accuracy of the presented methods at both\nsubject and group levels with regards to reproducibility and fidelity to the\ndata. The neuro-biological interpretation of the proposed parcellations is also\ninvestigated by comparing parcel boundaries with well-structured properties of\nthe cerebral cortex. Results show the advantage of connectivity-driven\nparcellations over traditional approaches in terms of better fitting the\nunderlying connectivity.\n", "versions": [{"version": "v1", "created": "Sat, 17 Feb 2018 13:00:27 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Arslan", "Salim", ""]]}, {"id": "1802.06913", "submitter": "Tamal Batabyal", "authors": "Tamal Batabyal, Scott T. Acton", "title": "ElasticPath2Path: Automated morphological classification of neurons by\n  elastic path matching", "comments": "This paper is submitted to IEEE International Conference on Image\n  Processing, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the study of neurons, morphology influences function. The complexity in\nthe structure of neurons poses a challenge in the identification and analysis\nof similar and dissimilar neuronal cells. Existing methodologies carry out\nstructural and geometrical simplifications, which substantially change the\nmorphological statistics. Using digitally-reconstructed neurons, we extend the\nwork of Path2Path as ElasticPath2Path, which seamlessly integrates the\ngraph-theoretic and differential-geometric frameworks. By decomposing a neuron\ninto a set of paths, we derive graph metrics, which are path concurrence and\npath hierarchy. Next, we model each path as an elastic string to compute the\ngeodesic distance between the paths of a pair of neurons. Later, we formulate\nthe problem of finding the distance between two neurons as a path assignment\nproblem with a cost function combining the graph metrics and the geodesic\ndeformation of paths. ElasticPath2Path is shown to have superior performance\nover the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 20 Feb 2018 00:00:35 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Batabyal", "Tamal", ""], ["Acton", "Scott T.", ""]]}, {"id": "1802.07380", "submitter": "Sean Jewell", "authors": "Sean Jewell, Toby Dylan Hocking, Paul Fearnhead, Daniela Witten", "title": "Fast Nonconvex Deconvolution of Calcium Imaging Data", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calcium imaging data promises to transform the field of neuroscience by\nmaking it possible to record from large populations of neurons simultaneously.\nHowever, determining the exact moment in time at which a neuron spikes, from a\ncalcium imaging data set, amounts to a non-trivial deconvolution problem which\nis of critical importance for downstream analyses. While a number of\nformulations have been proposed for this task in the recent literature, in this\npaper we focus on a formulation recently proposed in Jewell and Witten (2017)\nwhich has shown initial promising results. However, this proposal is slow to\nrun on fluorescence traces of hundreds of thousands of timesteps.\n  Here we develop a much faster online algorithm for solving the optimization\nproblem of Jewell and Witten (2017) that can be used to deconvolve a\nfluorescence trace of 100,000 timesteps in less than a second. Furthermore,\nthis algorithm overcomes a technical challenge of Jewell and Witten (2017) by\navoiding the occurrence of so-called \"negative\" spikes. We demonstrate that\nthis algorithm has superior performance relative to existing methods for spike\ndeconvolution on calcium imaging datasets that were recently released as part\nof the spikefinder challenge (http://spikefinder.codeneuro.org/).\n  Our C++ implementation, along with R and python wrappers, is publicly\navailable on Github at https://github.com/jewellsean/FastLZeroSpikeInference.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 00:04:42 GMT"}], "update_date": "2018-02-22", "authors_parsed": [["Jewell", "Sean", ""], ["Hocking", "Toby Dylan", ""], ["Fearnhead", "Paul", ""], ["Witten", "Daniela", ""]]}, {"id": "1802.07569", "submitter": "German I. Parisi", "authors": "German I. Parisi, Ronald Kemker, Jose L. Part, Christopher Kanan,\n  Stefan Wermter", "title": "Continual Lifelong Learning with Neural Networks: A Review", "comments": null, "journal-ref": null, "doi": "10.1016/j.neunet.2019.01.012.", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Humans and animals have the ability to continually acquire, fine-tune, and\ntransfer knowledge and skills throughout their lifespan. This ability, referred\nto as lifelong learning, is mediated by a rich set of neurocognitive mechanisms\nthat together contribute to the development and specialization of our\nsensorimotor skills as well as to long-term memory consolidation and retrieval.\nConsequently, lifelong learning capabilities are crucial for autonomous agents\ninteracting in the real world and processing continuous streams of information.\nHowever, lifelong learning remains a long-standing challenge for machine\nlearning and neural network models since the continual acquisition of\nincrementally available information from non-stationary data distributions\ngenerally leads to catastrophic forgetting or interference. This limitation\nrepresents a major drawback for state-of-the-art deep neural network models\nthat typically learn representations from stationary batches of training data,\nthus without accounting for situations in which information becomes\nincrementally available over time. In this review, we critically summarize the\nmain challenges linked to lifelong learning for artificial learning systems and\ncompare existing neural network approaches that alleviate, to different\nextents, catastrophic forgetting. We discuss well-established and emerging\nresearch motivated by lifelong learning factors in biological systems such as\nstructural plasticity, memory replay, curriculum and transfer learning,\nintrinsic motivation, and multisensory integration.\n", "versions": [{"version": "v1", "created": "Wed, 21 Feb 2018 13:53:35 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 06:59:28 GMT"}, {"version": "v3", "created": "Wed, 23 Jan 2019 18:40:25 GMT"}, {"version": "v4", "created": "Mon, 11 Feb 2019 01:28:39 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Parisi", "German I.", ""], ["Kemker", "Ronald", ""], ["Part", "Jose L.", ""], ["Kanan", "Christopher", ""], ["Wermter", "Stefan", ""]]}, {"id": "1802.07905", "submitter": "Hanna Keren", "authors": "Hanna Keren, Johannes Partzsch, Shimon Marom, and Christian Mayr", "title": "Closed-loop control of a modular neuromorphic biohybrid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks modularity is a major challenge for the development of\ncontrol circuits of neural activity. Under physiological limitations, the\naccessible regions for external stimulation are possibly different from the\nfunctionally relevant ones, requiring complex indirect control designs.\nMoreover, control over one region might affect activity of other downstream\nnetworks, once sparse connections exist. We address these questions by\ndeveloping a hybrid device of a cortical culture functionally integrated with a\nbiomimetic hardware neural network. This design enables the study of modular\nnetworks controllability, while connectivity is well-defined and key features\nof cortical networks are accessible. Using a closed-loop control to monitor the\nactivity of the coupled hybrid, we show that both modules are congruently\nmodified, in the macroscopic as well as the microscopic activity levels.\nControl impacts efficiently the activity on both sides whether the control\ncircuit is an indirect series one, or implemented independently only on one of\nthe modules. Hence, these results present global functional impacts of a local\ncontrol intervention. Overall, this strategy provides an experimental access to\nthe controllability of neural activity irregularities, when embedded in a\nmodular organization.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 05:08:48 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Keren", "Hanna", ""], ["Partzsch", "Johannes", ""], ["Marom", "Shimon", ""], ["Mayr", "Christian", ""]]}, {"id": "1802.08195", "submitter": "Gamaleldin Elsayed", "authors": "Gamaleldin F. Elsayed, Shreya Shankar, Brian Cheung, Nicolas Papernot,\n  Alex Kurakin, Ian Goodfellow, Jascha Sohl-Dickstein", "title": "Adversarial Examples that Fool both Computer Vision and Time-Limited\n  Humans", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning models are vulnerable to adversarial examples: small changes\nto images can cause computer vision models to make mistakes such as identifying\na school bus as an ostrich. However, it is still an open question whether\nhumans are prone to similar mistakes. Here, we address this question by\nleveraging recent techniques that transfer adversarial examples from computer\nvision models with known parameters and architecture to other models with\nunknown parameters and architecture, and by matching the initial processing of\nthe human visual system. We find that adversarial examples that strongly\ntransfer across computer vision models influence the classifications made by\ntime-limited human observers.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 17:40:51 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 18:46:56 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 03:02:41 GMT"}], "update_date": "2019-09-12", "authors_parsed": [["Elsayed", "Gamaleldin F.", ""], ["Shankar", "Shreya", ""], ["Cheung", "Brian", ""], ["Papernot", "Nicolas", ""], ["Kurakin", "Alex", ""], ["Goodfellow", "Ian", ""], ["Sohl-Dickstein", "Jascha", ""]]}, {"id": "1802.08217", "submitter": "Reza Moazzezi", "authors": "Reza Moazzezi", "title": "A new model for Cerebellar computation", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard state space model is widely believed to account for the\ncerebellar computation in motor adaptation tasks [1]. Here we show that several\nrecent experiments [2-4] where the visual feedback is irrelevant to the motor\nresponse challenge the standard model. Furthermore, we propose a new model that\naccounts for the the results presented in [2-4]. According to this new model,\nlearning and forgetting are coupled and are error size dependent. We also show\nthat under reasonable assumptions, our proposed model is the only model that\naccounts for both the classical adaptation paradigm as well as the recent\nexperiments [2-4].\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 18:15:53 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Moazzezi", "Reza", ""]]}, {"id": "1802.08279", "submitter": "Sarah Solomon", "authors": "Sarah H. Solomon, John D. Medaglia, and Sharon L. Thompson-Schill", "title": "Implementing a Concept Network Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The same concept can mean different things or be instantiated in different\nforms depending on context, suggesting a degree of flexibility within the\nconceptual system. We propose that a compositional network model can be used to\ncapture and predict this flexibility. We modeled individual concepts (e.g.,\nBANANA, BOTTLE) as graph-theoretical networks, in which properties (e.g.,\nYELLOW, SWEET) were represented as nodes and their associations as edges. In\nthis framework, networks capture the within-concept statistics that reflect how\nproperties correlate with each other across instances of a concept. We ran a\nclassification analysis using graph eigendecomposition to validate these\nmodels, and find that these models can successfully discriminate between object\nconcepts. We then computed formal measures from these concept networks and\nexplored their relationship to conceptual structure. We find that diversity\ncoefficients and core-periphery structure can be interpreted as network-based\nmeasures of conceptual flexibility and stability, respectively. These results\nsupport the feasibility of a concept network framework and highlight its\nability to formally capture important characteristics of the conceptual system.\n", "versions": [{"version": "v1", "created": "Thu, 22 Feb 2018 19:49:59 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 16:29:43 GMT"}, {"version": "v3", "created": "Tue, 22 May 2018 16:14:17 GMT"}, {"version": "v4", "created": "Wed, 20 Mar 2019 16:04:03 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Solomon", "Sarah H.", ""], ["Medaglia", "John D.", ""], ["Thompson-Schill", "Sharon L.", ""]]}, {"id": "1802.08747", "submitter": "Kanika Bansal", "authors": "Kanika Bansal, John D. Medaglia, Danielle S. Bassett, Jean M. Vettel,\n  Sarah F. Muldoon", "title": "Data-driven brain network models predict individual variability in\n  behavior", "comments": "26 pages, 6 figures, 3 tables", "journal-ref": null, "doi": "10.1371/journal.pcbi.1006487", "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationship between brain structure and function has been probed using a\nvariety of approaches, but how the underlying structural connectivity of the\nhuman brain drives behavior is far from understood. To investigate the effect\nof anatomical brain organization on human task performance, we use a\ndata-driven computational modeling approach and explore the functional effects\nof naturally occurring structural differences in brain networks. We construct\npersonalized brain network models by combining anatomical connectivity\nestimated from diffusion spectrum imaging of individual subjects with a\nnonlinear model of brain dynamics. By performing computational experiments in\nwhich we measure the excitability of the global brain network and spread of\nsynchronization following a targeted computational stimulation, we quantify how\nindividual variation in the underlying connectivity impacts both local and\nglobal brain dynamics. We further relate the computational results to\nindividual variability in the subjects' performance of three language-demanding\ntasks both before and after transcranial magnetic stimulation to the\nleft-inferior frontal gyrus. Our results show that task performance correlates\nwith either local or global measures of functional activity, depending on the\ncomplexity of the task. By emphasizing differences in the underlying structural\nconnectivity, our model serves as a powerful tool to predict individual\ndifferences in task performances, to dissociate the effect of targeted\nstimulation in tasks that differ in cognitive complexity, and to pave the way\nfor the development of personalized therapeutics.\n", "versions": [{"version": "v1", "created": "Fri, 23 Feb 2018 21:57:52 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Bansal", "Kanika", ""], ["Medaglia", "John D.", ""], ["Bassett", "Danielle S.", ""], ["Vettel", "Jean M.", ""], ["Muldoon", "Sarah F.", ""]]}, {"id": "1802.09046", "submitter": "Hardik Meisheri", "authors": "Hardik Meisheri, Nagraj Ramrao, Suman Mitra", "title": "Multiclass Common Spatial Pattern for EEG based Brain Computer Interface\n  with Adaptive Learning Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In Brain Computer Interface (BCI), data generated from Electroencephalogram\n(EEG) is non-stationary with low signal to noise ratio and contaminated with\nartifacts. Common Spatial Pattern (CSP) algorithm has been proved to be\neffective in BCI for extracting features in motor imagery tasks, but it is\nprone to overfitting. Many algorithms have been devised to regularize CSP for\ntwo class problem, however they have not been effective when applied to\nmulticlass CSP. Outliers present in data affect extracted CSP features and\nreduces performance of the system. In addition to this non-stationarity present\nin the features extracted from the CSP present a challenge in classification.\nWe propose a method to identify and remove artifact present in the data during\npre-processing stage, this helps in calculating eigenvectors which in turn\ngenerates better CSP features. To handle the non-stationarity, Self-Regulated\nInterval Type-2 Neuro-Fuzzy Inference System (SRIT2NFIS) was proposed in the\nliterature for two class EEG classification problem. This paper extends the\nSRIT2NFIS to multiclass using Joint Approximate Diagonalization (JAD). The\nresults on standard data set from BCI competition IV shows significant increase\nin the accuracies from the current state of the art methods for multiclass\nclassification.\n", "versions": [{"version": "v1", "created": "Sun, 25 Feb 2018 17:18:31 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 04:04:47 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Meisheri", "Hardik", ""], ["Ramrao", "Nagraj", ""], ["Mitra", "Suman", ""]]}, {"id": "1802.09442", "submitter": "Valentina Gliozzi", "authors": "Valentina Gliozzi and Kim Plunkett", "title": "Self-organizing maps and generalization: an algorithmic description of\n  Numerosity and Variability Effects", "comments": "24 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Category, or property generalization is a central function in the human\ncognition. It plays a crucial role in a variety of domains, such as learning,\neveryday reasoning, specialized reasoning, and decision making. Judging the\ncontent of a dish as edible, a hormone level as healthy, a building as\nbelonging to the same architectural style as previously seen buildings, are\nexamples of category generalization. In this paper, we propose self-organizing\nmaps as candidates to explain the psychological mechanisms underlying category\ngeneralization. Self-organizing maps are psychologically and biologically\nplausible neural network models that learn after limited exposure to positive\ncategory examples, without any need of contrastive information. Just like\nhumans. They reproduce human behavior in category generalization, in particular\nfor what concerns the well-known Numerosity and Variability effects, which are\nusually explained with Bayesian tools. Where category generalization is\nconcerned, self-organizing maps are good candidates to bridge the gap between\nthe computational level of analysis in Marr's hierarchy (where Bayesian models\nare situated) and the algorithmic level of aanalysis in Marr's hierarchy (where\nBayesian models are situated) and the algorithmic level of analysis in which\nplausible mechanisms are described.\n", "versions": [{"version": "v1", "created": "Mon, 26 Feb 2018 16:38:42 GMT"}], "update_date": "2018-02-27", "authors_parsed": [["Gliozzi", "Valentina", ""], ["Plunkett", "Kim", ""]]}, {"id": "1802.09627", "submitter": "Tito Arecchi", "authors": "F.Tito Arecchi", "title": "Cognition and Reality", "comments": "18 pages; submitted to \"Substantia\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the two moments of human cognition, namely, apprehension (A),\nwhereby a coherent perception emerges from the recruitment of neuronal groups,\nand judgment(B),that entails the comparison of two apprehensions acquired at\ndifferent times, coded in a suitable language and retrieved by memory. (B)\nentails self-consciousness, in so far as the agent who expresses the judgment\nmust be aware that the two apprehensions are submitted to his/her own scrutiny\nand that it is his/her task to extract a mutual relation. Since (B) lasts\naround 3 seconds, the semantic value of the pieces under comparison must be\ndecided within that time. This implies a fast search of the memory contents. As\na fact, exploring human subjects with sequences of simple words, we find\nevidence of a limited time window , corresponding to the memory retrieval of a\nlinguistic item in order to match it with the next one in a text flow (be it\nliterary, or musical,or figurative). While apprehension is globally explained\nas a Bayes inference, judgment tresults from an inverse Bayes inference. As a\nconsequence, two hermeneutics emerge (called respectively circle and coil). The\nfirst one acts in a pre-assigned space of features. The second one provides the\ndiscovery of novel features, thus unveiling previously unknown aspects and\nhence representing the road to reality.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 09:39:38 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Arecchi", "F. Tito", ""]]}, {"id": "1802.10131", "submitter": "Christoph Bauermeister", "authors": "Christoph Bauermeister, Hanna Keren, Jochen Braun", "title": "Broadly heterogeneous network topology begets order-based representation\n  by privileged neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How spiking activity reverberates through neuronal networks, how evoked and\nspontaneous activity interact and blend, and how the combined activities\nrepresent external stimulation are pivotal questions in neuroscience. We\nsimulated minimal models of unstructured spiking networks in silico, asking\nwhether and how gentle external stimulation might be subsequently reflected in\nspontaneous activity fluctuations. Consistent with earlier findings in silico\nand in vitro, we observe a privileged sub-population of 'pioneer neurons' that,\nby their firing order, reliably encode previous external stimulation. We show\nthat the distinctive role of pioneer neurons is owed to a combination of\nexceptional sensitivity to, and pronounced influence on, network activity. We\nfurther show that broadly heterogeneous connection topology - a broad \"middle\nclass\" in degree of connectedness - not only increases the number of 'pioneer\nneurons' in unstructured networks, but also renders the emergence of 'pioneer\nneurons' more robust to changes in the excitatory-inhibitory balance. In\nconclusion, we offer a minimal model for the emergence and representational\nrole of 'pioneer neurons', as observed experimentally in vitro. In addition, we\nshow how broadly heterogeneous connectivity can enhance the representational\ncapacity of unstructured networks.\n", "versions": [{"version": "v1", "created": "Tue, 27 Feb 2018 19:36:05 GMT"}], "update_date": "2018-03-01", "authors_parsed": [["Bauermeister", "Christoph", ""], ["Keren", "Hanna", ""], ["Braun", "Jochen", ""]]}, {"id": "1802.10354", "submitter": "Ryan John Abat Cubero", "authors": "Ryan John Cubero, Matteo Marsili and Yasser Roudi", "title": "Multiscale relevance and informative encoding in neuronal spike trains", "comments": "38 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal responses to complex stimuli and tasks can encompass a wide range of\ntime scales. Understanding these responses requires measures that characterize\nhow the information on these response patterns are represented across multiple\ntemporal resolutions. In this paper we propose a metric -- which we call\nmultiscale relevance (MSR) -- to capture the dynamical variability of the\nactivity of single neurons across different time scales. The MSR is a\nnon-parametric, fully featureless indicator in that it uses only the time\nstamps of the firing activity without resorting to any a priori covariate or\ninvoking any specific structure in the tuning curve for neural activity. When\napplied to neural data from the mEC and from the ADn and PoS regions of\nfreely-behaving rodents, we found that neurons having low MSR tend to have low\nmutual information and low firing sparsity across the correlates that are\nbelieved to be encoded by the region of the brain where the recordings were\nmade. In addition, neurons with high MSR contain significant information on\nspatial navigation and allow to decode spatial position or head direction as\nefficiently as those neurons whose firing activity has high mutual information\nwith the covariate to be decoded and significantly better than the set of\nneurons with high local variations in their interspike intervals. Given these\nresults, we propose that the MSR can be used as a measure to rank and select\nneurons for their information content without the need to appeal to any a\npriori covariate.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 10:56:57 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2019 10:37:50 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Cubero", "Ryan John", ""], ["Marsili", "Matteo", ""], ["Roudi", "Yasser", ""]]}, {"id": "1802.10361", "submitter": "M Rule", "authors": "M. E. Rule and M. Sorbaro and M. H. Hennig", "title": "Optimal encoding in stochastic latent-variable Models", "comments": null, "journal-ref": null, "doi": "10.3390/e22070714", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore encoding strategies learned by statistical models of\nsensory coding in noisy spiking networks. Early stages of sensory communication\nin neural systems can be viewed as encoding channels in the\ninformation-theoretic sense. However, neural populations face constraints not\ncommonly considered in communications theory. Using restricted Boltzmann\nmachines as a model of sensory encoding, we find that networks with sufficient\ncapacity learn to balance precision and noise-robustness in order to adaptively\ncommunicate stimuli with varying information content. Mirroring variability\nsuppression observed in sensory systems, informative stimuli are encoded with\nhigh precision, at the cost of more variable responses to frequent, hence less\ninformative stimuli. Curiously, we also find that statistical criticality in\nthe neural population code emerges at model sizes where the input statistics\nare well captured. These phenomena have well-defined thermodynamic\ninterpretations, and we discuss their connection to prevailing theories of\ncoding and statistical criticality in neural populations.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 11:17:13 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 14:28:59 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 10:33:20 GMT"}, {"version": "v4", "created": "Wed, 24 Jun 2020 06:16:13 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Rule", "M. E.", ""], ["Sorbaro", "M.", ""], ["Hennig", "M. H.", ""]]}, {"id": "1802.10448", "submitter": "Massimiliano Sassoli de Bianchi", "authors": "Diederik Aerts, Massimiliano Sassoli de Bianchi, Sandro Sozzo and\n  Tomas Veloz", "title": "Quantum cognition goes beyond-quantum: modeling the collective\n  participant in psychological measurements", "comments": "19 pages, 1 figure", "journal-ref": "Probing the Meaning of Quantum Mechanics, World Scientific, pp.\n  355-382 (2019)", "doi": "10.1142/9789813276895_0017", "report-no": null, "categories": "q-bio.NC cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In psychological measurements, two levels should be distinguished: the\n'individual level', relative to the different participants in a given cognitive\nsituation, and the 'collective level', relative to the overall statistics of\ntheir outcomes, which we propose to associate with a notion of 'collective\nparticipant'. When the distinction between these two levels is properly\nformalized, it reveals why the modeling of the collective participant generally\nrequires beyond-quantum - non-Bornian - probabilistic models, when sequential\nmeasurements at the individual level are considered, and this though a pure\nquantum description remains valid for single measurement situations.\n", "versions": [{"version": "v1", "created": "Sat, 24 Feb 2018 08:23:11 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Aerts", "Diederik", ""], ["de Bianchi", "Massimiliano Sassoli", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1802.10451", "submitter": "Julien Modolo", "authors": "Julien Modolo, Mahmoud Hassan, Alexandre Legros", "title": "Reconstruction of brain networks involved in magnetophosphene perception\n  using dense electroencephalography", "comments": "6 pages, 1 figure", "journal-ref": "BioEM2018 conference proceedings", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterizing functional brain networks in humans during magnetophosphene\nperception. Dense electroencephalography (EEG, 128 channels) was performed in\nN=3 volunteers during high-level (50 mT) magnetic field (MF) exposure.\nFunctional brain networks were reconstructed, at the cortical level from scalp\nrecordings, using the EEG source connectivity method. Magnetophosphene\nperception appears to consistently activate the right inferior\noccipito-temporal pathway. This study provides the very first neuroimaging\nresults characterizing magnetophosphene perception in humans. The use of\ndense-EEG source connectivity is a promising approach in the field of\nbioelectromagnetics.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 14:52:07 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 08:39:41 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Modolo", "Julien", ""], ["Hassan", "Mahmoud", ""], ["Legros", "Alexandre", ""]]}]