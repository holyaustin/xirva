[{"id": "1008.0062", "submitter": "Tsvi Tlusty", "authors": "Jordi Soriano, Maria Rodrriguez Martinez, Tsvi Tlusty, and Elisha\n  Moses", "title": "Development of input connections in neural cultures", "comments": "Neural cultures | Percolation | Development | Network connectivity\n  http://www.weizmann.ac.il/complex/tlusty/papers/PNAS2008c.pdf", "journal-ref": "Proc Natl Acad Sci U S A. 2008 September 16; 105(37): 13758-13763", "doi": "10.1073/pnas.0707492105.", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel approach for the quantitative assessment of the\nconnectivity in neuronal cultures, based on the statistical mechanics of\npercolation on a graph. This allows us to follow the development of the culture\nand see the emergence of connectivity in the network. The culture becomes fully\nconnected at a time equivalent to full term. The spontaneous bursting activity\nthat characterizes cultures develops in parallel with the connectivity. The\naverage number of inputs per neuron can be quantitatively determined in units\nof $m_0$, the number of activated inputs needed to excite the neuron. For\n$m_0\\sim 10$ we find that hippocampal neurons have on average $\\sim 40-80$\ninputs while cortical neurons have $\\sim 50-100$, depending on neuronal\ndensity. The ratio of excitatory to inhibitory neurons is determined using the\nGABA$_\\text{A}$ antagonist bicuculine. This ratio changes during development\nand reaches the final value at day $7-8$, coinciding with the expected time of\nthe GABA switch. For hippocampal cultures the inhibitory cells comprise about\n$30\\%$ of the neurons in the culture while for cortical cultures they are about\n$20\\%$. Such detailed global information on the connectivity of networks in\nneuronal cultures is at present inaccessible by any electrophysiological or\nother technique.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jul 2010 07:28:39 GMT"}], "update_date": "2010-08-03", "authors_parsed": [["Soriano", "Jordi", ""], ["Martinez", "Maria Rodrriguez", ""], ["Tlusty", "Tsvi", ""], ["Moses", "Elisha", ""]]}, {"id": "1008.0333", "submitter": "Hermann Riecke", "authors": "Clara B. Picallo and Hermann Riecke", "title": "Adaptive Oscillator Networks with Conserved Overall Coupling: Sequential\n  Firing and Near-Synchronized States", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevE.83.036206", "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by recent observations in neuronal systems we investigate\nall-to-all networks of non-identical oscillators with adaptive coupling. The\nadaptation models spike-timing-dependent plasticity in which the sum of the\nweights of all incoming links is conserved. We find multiple phase-locked\nstates that fall into two classes: near-synchronized states and splay states.\nAmong the near-synchronized states are states that oscillate with a frequency\nthat depends only very weakly on the coupling strength and is essentially given\nby the frequency of one of the oscillators, which is, however, neither the\nfastest nor the slowest oscillator. In sufficiently large networks the adaptive\ncoupling is found to develop effective network topologies dominated by one or\ntwo loops. This results in a multitude of stable splay states, which differ in\ntheir firing sequences. With increasing coupling strength their frequency\nincreases linearly and the oscillators become less synchronized. The essential\nfeatures of the two classes of states are captured analytically in perturbation\nanalyses of the extended Kuramoto model used in the simulations.\n", "versions": [{"version": "v1", "created": "Mon, 2 Aug 2010 16:05:24 GMT"}, {"version": "v2", "created": "Tue, 23 Nov 2010 00:18:37 GMT"}], "update_date": "2013-05-29", "authors_parsed": [["Picallo", "Clara B.", ""], ["Riecke", "Hermann", ""]]}, {"id": "1008.0590", "submitter": "Vladimir Gudkov", "authors": "Svetlana V. Shinkareva, Vladimir Gudkov, Jing Wang", "title": "A Network Analysis Approach to fMRI Condition-Specific Functional\n  Connectivity", "comments": null, "journal-ref": null, "doi": "10.1016/j.bandl.2012.11.008", "report-no": null, "categories": "stat.AP nlin.CD physics.bio-ph physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we focus on examination and comparison of whole-brain functional\nconnectivity patterns measured with fMRI across experimental conditions. Direct\nexamination and comparison of condition-specific matrices is challenging due to\nthe large number of elements in a connectivity matrix. We present a framework\nthat uses network analysis to describe condition-specific functional\nconnectivity. Treating the brain as a complex system in terms of a network, we\nextract the most relevant connectivity information by partitioning each network\ninto clusters representing functionally connected brain regions. Extracted\nclusters are used as features for predicting experimental condition in a new\ndata set. The approach is illustrated on fMRI data examining functional\nconnectivity patterns during processing of abstract and concrete concepts.\nTopological (brain regions) and functional (level of connectivity and\ninformation flow) systematic differences in the ROI-based functional networks\nwere identified across participants for concrete and abstract concepts. These\ndifferences were sufficient for classification of previously unseen\nconnectivity matrices as abstract or concrete based on training data derived\nfrom other people.\n", "versions": [{"version": "v1", "created": "Tue, 3 Aug 2010 16:42:40 GMT"}], "update_date": "2013-01-02", "authors_parsed": [["Shinkareva", "Svetlana V.", ""], ["Gudkov", "Vladimir", ""], ["Wang", "Jing", ""]]}, {"id": "1008.1410", "submitter": "Avner Wallach", "authors": "Avner Wallach, Danny Eytan, Asaf Gal, Christoph Zrenner, Ron Meir and\n  Shimon Marom", "title": "Neuronal Response Clamp", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the first recordings made of evoked action potentials it has become\napparent that the responses of individual neurons to ongoing physiologically\nrelevant input, are highly variable. This variability is manifested in\nnon-stationary behavior of practically every observable neuronal response\nfeature. Here we introduce the Neuronal Response Clamp, a closed-loop technique\nenabling full control over two important single neuron activity variables:\nresponse probability and stimulus-spike latency. The technique is applicable\nover extended durations (up to several hours), and is effective even on the\nbackground of ongoing neuronal network activity. The Response Clamp technique\nis a powerful tool, extending the voltage-clamp and dynamic-clamp approaches to\nthe neuron's functional level, namely - its spiking behavior.\n", "versions": [{"version": "v1", "created": "Sun, 8 Aug 2010 15:13:12 GMT"}], "update_date": "2010-08-10", "authors_parsed": [["Wallach", "Avner", ""], ["Eytan", "Danny", ""], ["Gal", "Asaf", ""], ["Zrenner", "Christoph", ""], ["Meir", "Ron", ""], ["Marom", "Shimon", ""]]}, {"id": "1008.1490", "submitter": "Matjaz Perc", "authors": "Xiaojuan Sun, Matjaz Perc, Qishao Lu, J\\\"urgen Kurths", "title": "Effects of correlated Gaussian noise on the mean firing rate and\n  correlations of an electrically coupled neuronal network", "comments": "7 two-column pages, 5 figures; accepted for publication in Chaos", "journal-ref": "Chaos 20 (2010) 033116", "doi": "10.1063/1.3483876", "report-no": null, "categories": "cond-mat.dis-nn physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we examine the effects of correlated Gaussian noise on a\ntwo-dimensional neuronal network that is locally modeled by the Rulkov map.\nMore precisely, we study the effects of the noise correlation on the variations\nof the mean firing rate and the correlations among neurons versus the noise\nintensity. Via numerical simulations, we show that the mean firing rate can\nalways be optimized at an intermediate noise intensity, irrespective of the\nnoise correlation. On the other hand, variations of the population coherence\nwith respect to the noise intensity are strongly influenced by the ratio\nbetween local and global Gaussian noisy inputs. Biological implications of our\nfindings are also discussed.\n", "versions": [{"version": "v1", "created": "Mon, 9 Aug 2010 12:06:55 GMT"}], "update_date": "2010-09-23", "authors_parsed": [["Sun", "Xiaojuan", ""], ["Perc", "Matjaz", ""], ["Lu", "Qishao", ""], ["Kurths", "J\u00fcrgen", ""]]}, {"id": "1008.1909", "submitter": "Djalel Eddine Meskaldji", "authors": "Djalel Eddine Meskaldji, Leila Cammoun, Patric Hagmann, Reto Meuli,\n  Jean Philippe Thiran and Stephan Morgenthaler", "title": "Efficient statistical analysis of large correlated multivariate\n  datasets: a case study on brain connectivity matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neuroimaging, a large number of correlated tests are routinely performed\nto detect active voxels in single-subject experiments or to detect regions that\ndiffer between individuals belonging to different groups. In order to bound the\nprobability of a false discovery of pair-wise differences, a Bonferroni or\nother correction for multiplicity is necessary. These corrections greatly\nreduce the power of the comparisons which means that small signals\n(differences) remain hidden and therefore have been more or less successful\ndepending on the application. We introduce a method that improves the power of\na family of correlated statistical tests by reducing their number in an orderly\nfashion using our a-priori understanding of the problem . The tests are grouped\nby blocks that respect the data structure and only one or a few tests per group\nare performed. For each block we construct an appropriate summary statistic\nthat characterizes a meaningful feature of the block. The comparisons are based\non these summary statistics by a block-wise approach. We contrast this method\nwith the one based on the individual measures in terms of power. Finally, we\napply the method to compare brain connectivity matrices. Although the method is\nused in this study on the particular case of imaging, the proposed strategy can\nbe applied to a large variety of problems that involves multiple comparisons\nwhen the tests can be grouped according to attributes that depend on the\nspecific problem. Keywords and phrases: Multiple comparisons ; Family-wise\nerror rate; False discovery rate; Bonferroni procedure; Human brain\nconnectivity; Brain connectivity matrices.\n", "versions": [{"version": "v1", "created": "Wed, 11 Aug 2010 14:01:13 GMT"}], "update_date": "2010-08-13", "authors_parsed": [["Meskaldji", "Djalel Eddine", ""], ["Cammoun", "Leila", ""], ["Hagmann", "Patric", ""], ["Meuli", "Reto", ""], ["Thiran", "Jean Philippe", ""], ["Morgenthaler", "Stephan", ""]]}, {"id": "1008.1954", "submitter": "Jonathan Touboul", "authors": "Jonathan Touboul", "title": "On the simulation of nonlinear bidimensional spiking neuron models", "comments": null, "journal-ref": null, "doi": "10.1162/NECO_a_00141", "report-no": null, "categories": "cs.NA math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bidimensional spiking models currently gather a lot of attention for their\nsimplicity and their ability to reproduce various spiking patterns of cortical\nneurons, and are particularly used for large network simulations. These models\ndescribe the dynamics of the membrane potential by a nonlinear differential\nequation that blows up in finite time, coupled to a second equation for\nadaptation. Spikes are emitted when the membrane potential blows up or reaches\na cutoff value. The precise simulation of the spike times and of the adaptation\nvariable is critical for it governs the spike pattern produced, and is hard to\ncompute accurately because of the exploding nature of the system at the spike\ntimes. We thoroughly study the precision of fixed time-step integration schemes\nfor this type of models and demonstrate that these methods produce systematic\nerrors that are unbounded, as the cutoff value is increased, in the evaluation\nof the two crucial quantities: the spike time and the value of the adaptation\nvariable at this time. Precise evaluation of these quantities therefore involve\nvery small time steps and long simulation times. In order to achieve a fixed\nabsolute precision in a reasonable computational time, we propose here a new\nalgorithm to simulate these systems based on a variable integration step method\nthat either integrates the original ordinary differential equation or the\nequation of the orbits in the phase plane, and compare this algorithm with\nfixed time-step Euler scheme and other more accurate simulation algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 11 Aug 2010 16:47:35 GMT"}, {"version": "v2", "created": "Fri, 20 Aug 2010 16:44:59 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["Touboul", "Jonathan", ""]]}, {"id": "1008.2066", "submitter": "Lubomir Kostal", "authors": "Lubomir Kostal and Petr Lansky", "title": "Information transfer with small-amplitude signals", "comments": "5 pages, 1 figure; published in Physical Review E; this version\n  improves Fig.1", "journal-ref": "Phys. Rev. E 81, 050901(R) (2010)", "doi": "10.1103/PhysRevE.81.050901", "report-no": null, "categories": "q-bio.NC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the optimality conditions of information transfer in systems with\nmemory in the low signal-to-noise ratio regime of vanishing input amplitude. We\nfind that the optimal mutual information is represented by a maximum-variance\nof the signal time course, with correlation structure determined by the Fisher\ninformation matrix. We provide illustration of the method on a simple\nbiologically-inspired model of electro-sensory neuron. Our general results\napply also to the study of information transfer in single neurons subject to\nweak stimulation, with implications to the problem of coding efficiency in\nbiological systems.\n", "versions": [{"version": "v1", "created": "Thu, 12 Aug 2010 08:36:48 GMT"}], "update_date": "2010-08-13", "authors_parsed": [["Kostal", "Lubomir", ""], ["Lansky", "Petr", ""]]}, {"id": "1008.2069", "submitter": "Lubomir Kostal", "authors": "Lubomir Kostal", "title": "Information capacity in the weak-signal approximation", "comments": "11 pages, 4 figures; accepted for publication in Physical Review E", "journal-ref": null, "doi": "10.1103/PhysRevE.82.026115", "report-no": null, "categories": "cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an approximate expression for mutual information in a broad class\nof discrete-time stationary channels with continuous input, under the\nconstraint of vanishing input amplitude or power. The approximation describes\nthe input by its covariance matrix, while the channel properties are described\nby the Fisher information matrix. This separation of input and channel\nproperties allows us to analyze the optimality conditions in a convenient way.\nWe show that input correlations in memoryless channels do not affect channel\ncapacity since their effect decreases fast with vanishing input amplitude or\npower. On the other hand, for channels with memory, properly matching the input\ncovariances to the dependence structure of the noise may lead to almost\nnoiseless information transfer, even for intermediate values of the noise\ncorrelations. Since many model systems described in mathematical neuroscience\nand biophysics operate in the high noise regime and weak-signal conditions, we\nbelieve, that the described results are of potential interest also to\nresearchers in these areas.\n", "versions": [{"version": "v1", "created": "Thu, 12 Aug 2010 08:46:13 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Kostal", "Lubomir", ""]]}, {"id": "1008.2839", "submitter": "Jonathan Touboul", "authors": "Jonathan Touboul and G. Bard Ermentrout", "title": "Finite-size and correlation-induced effects in Mean-field Dynamics", "comments": null, "journal-ref": null, "doi": "10.1007/s10827-011-0320-5", "report-no": null, "categories": "math.DS nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain's activity is characterized by the interaction of a very large\nnumber of neurons that are strongly affected by noise. However, signals often\narise at macroscopic scales integrating the effect of many neurons into a\nreliable pattern of activity. In order to study such large neuronal assemblies,\none is often led to derive mean-field limits summarizing the effect of the\ninteraction of a large number of neurons into an effective signal. Classical\nmean-field approaches consider the evolution of a deterministic variable, the\nmean activity, thus neglecting the stochastic nature of neural behavior. In\nthis article, we build upon two recent approaches that include correlations and\nhigher order moments in mean-field equations, and study how these stochastic\neffects influence the solutions of the mean-field equations, both in the limit\nof an infinite number of neurons and for large yet finite networks. We\nintroduce a new model, the infinite model, which arises from both equations by\na rescaling of the variables and, which is invertible for finite-size networks,\nand hence, provides equivalent equations to those previously derived models.\nThe study of this model allows us to understand qualitative behavior of such\nlarge-scale networks. We show that, though the solutions of the deterministic\nmean-field equation constitute uncorrelated solutions of the new mean-field\nequations, the stability properties of limit cycles are modified by the\npresence of correlations, and additional non-trivial behaviors including\nperiodic orbits appear when there were none in the mean field. The origin of\nall these behaviors is then explored in finite-size networks where interesting\nmesoscopic scale effects appear. This study leads us to show that the\ninfinite-size system appears as a singular limit of the network equations, and\nfor any finite network, the system will differ from the infinite system.\n", "versions": [{"version": "v1", "created": "Tue, 17 Aug 2010 07:29:37 GMT"}, {"version": "v2", "created": "Fri, 18 Feb 2011 09:50:40 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["Touboul", "Jonathan", ""], ["Ermentrout", "G. Bard", ""]]}, {"id": "1008.3014", "submitter": "Jun Ohkubo", "authors": "Jun Ohkubo, Kazushi Yoshida, Yuichi Iino and Naoki Masuda", "title": "Long-tail Behavior in Locomotion of Caenorhabditis elegans", "comments": "30 pages, 11 figures, some errors were corrected", "journal-ref": "Journal of Theoretical Biology 267 (2010) 213-222", "doi": "10.1016/j.jtbi.2010.08.020", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The locomotion of Caenorhabditis elegans exhibits complex patterns. In\nparticular, the worm combines mildly curved runs and sharp turns to steer its\ncourse. Both runs and sharp turns of various types are important components of\ntaxis behavior. The statistics of sharp turns have been intensively studied.\nHowever, there have been few studies on runs, except for those on klinotaxis\n(also called weathervane mechanism), in which the worm gradually curves toward\nthe direction with a high concentration of chemicals; this phenomenon was\ndiscovered recently. We analyzed the data of runs by excluding sharp turns. We\nshow that the curving rate obeys long-tail distributions, which implies that\nlarge curving rates are relatively frequent. This result holds true for\nlocomotion in environments both with and without a gradient of NaCl\nconcentration; it is independent of klinotaxis. We propose a phenomenological\ncomputational model on the basis of a random walk with multiplicative noise.\nThe assumption of multiplicative noise posits that the fluctuation of the force\nis proportional to the force exerted. The model reproduces the long-tail\nproperty present in the experimental data.\n", "versions": [{"version": "v1", "created": "Wed, 18 Aug 2010 05:14:45 GMT"}, {"version": "v2", "created": "Thu, 19 Aug 2010 02:32:15 GMT"}, {"version": "v3", "created": "Fri, 27 Aug 2010 07:01:50 GMT"}], "update_date": "2010-09-14", "authors_parsed": [["Ohkubo", "Jun", ""], ["Yoshida", "Kazushi", ""], ["Iino", "Yuichi", ""], ["Masuda", "Naoki", ""]]}, {"id": "1008.4043", "submitter": "Lennaert van Veen", "authors": "Federico Frascoli, Lennaert van Veen, Ingo Bojak and David T J Liley", "title": "Metabifurcation analysis of a mean field model of the cortex", "comments": null, "journal-ref": null, "doi": "10.1016/j.physd.2011.02.002", "report-no": null, "categories": "math.DS physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean field models (MFMs) of cortical tissue incorporate salient features of\nneural masses to model activity at the population level. One of the common\naspects of MFM descriptions is the presence of a high dimensional parameter\nspace capturing neurobiological attributes relevant to brain dynamics. We study\nthe physiological parameter space of a MFM of electrocortical activity and\ndiscover robust correlations between physiological attributes of the model\ncortex and its dynamical features. These correlations are revealed by the study\nof bifurcation plots, which show that the model responses to changes in\ninhibition belong to two families. After investigating and characterizing\nthese, we discuss their essential differences in terms of four important\naspects: power responses with respect to the modeled action of anesthetics,\nreaction to exogenous stimuli, distribution of model parameters and oscillatory\nrepertoires when inhibition is enhanced. Furthermore, while the complexity of\nsustained periodic orbits differs significantly between families, we are able\nto show how metamorphoses between the families can be brought about by\nexogenous stimuli. We unveil links between measurable physiological attributes\nof the brain and dynamical patterns that are not accessible by linear methods.\nThey emerge when the parameter space is partitioned according to bifurcation\nresponses. This partitioning cannot be achieved by the investigation of only a\nsmall number of parameter sets, but is the result of an automated bifurcation\nanalysis of a representative sample of 73,454 physiologically admissible sets.\nOur approach generalizes straightforwardly and is well suited to probing the\ndynamics of other models with large and complex parameter spaces.\n", "versions": [{"version": "v1", "created": "Tue, 24 Aug 2010 13:33:56 GMT"}], "update_date": "2015-05-19", "authors_parsed": [["Frascoli", "Federico", ""], ["van Veen", "Lennaert", ""], ["Bojak", "Ingo", ""], ["Liley", "David T J", ""]]}, {"id": "1008.4233", "submitter": "Reinhard  Hoepfner", "authors": "Reinhard Hoepfner", "title": "To which extent is the membrane potential in a neuron between successive\n  spikes adequately modelled by a (continuous) semimartingale?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider $p$-variations in some membrane potential data --viewed as a\nfunction of the step size in case where $p$ is fixed, or viewed as a function\nof $p$ in case where the step size is fixed-- and compare their shape with\nresults in Ait-Sahalia and Jacod (2009) which do hold for general\nsemimartingales. We obtain the following conclusion: in non- or very rarely\nspiking cases the membrane potential behaves as a semimartingale, in some cases\nas a semimartingale with jumps. Once the neuron is spiking, a semimartingale\nmodelization is no longer adequate for the membrane potential between\nsuccessive spikes, even if interspike intervals are relatively long.\n", "versions": [{"version": "v1", "created": "Wed, 25 Aug 2010 09:11:35 GMT"}], "update_date": "2010-08-26", "authors_parsed": [["Hoepfner", "Reinhard", ""]]}, {"id": "1008.5071", "submitter": "Gael Varoquaux", "authors": "Ga\\\"el Varoquaux (LNAO, INRIA Saclay - Ile de France), Alexandre\n  Gramfort (LNAO, INRIA Saclay - Ile de France), Jean Baptiste Poline (LNAO),\n  Bertrand Thirion (LNAO, INRIA Saclay - Ile de France)", "title": "Brain covariance selection: better individual functional connectivity\n  models using population prior", "comments": "in Advances in Neural Information Processing Systems, Vancouver :\n  Canada (2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spontaneous brain activity, as observed in functional neuroimaging, has been\nshown to display reproducible structure that expresses brain architecture and\ncarries markers of brain pathologies. An important view of modern neuroscience\nis that such large-scale structure of coherent activity reflects modularity\nproperties of brain connectivity graphs. However, to date, there has been no\ndemonstration that the limited and noisy data available in spontaneous activity\nobservations could be used to learn full-brain probabilistic models that\ngeneralize to new data. Learning such models entails two main challenges: i)\nmodeling full brain connectivity is a difficult estimation problem that faces\nthe curse of dimensionality and ii) variability between subjects, coupled with\nthe variability of functional signals between experimental runs, makes the use\nof multiple datasets challenging. We describe subject-level brain functional\nconnectivity structure as a multivariate Gaussian process and introduce a new\nstrategy to estimate it from group data, by imposing a common structure on the\ngraphical model in the population. We show that individual models learned from\nfunctional Magnetic Resonance Imaging (fMRI) data using this population prior\ngeneralize better to unseen data than models based on alternative\nregularization schemes. To our knowledge, this is the first report of a\ncross-validated model of spontaneous brain activity. Finally, we use the\nestimated graphical model to explore the large-scale characteristics of\nfunctional architecture and show for the first time that known cognitive\nnetworks appear as the integrated communities of functional connectivity graph.\n", "versions": [{"version": "v1", "created": "Mon, 30 Aug 2010 12:52:36 GMT"}, {"version": "v2", "created": "Tue, 21 Sep 2010 06:02:33 GMT"}, {"version": "v3", "created": "Sat, 30 Oct 2010 16:21:30 GMT"}, {"version": "v4", "created": "Fri, 12 Nov 2010 05:55:55 GMT"}], "update_date": "2010-11-15", "authors_parsed": [["Varoquaux", "Ga\u00ebl", "", "LNAO, INRIA Saclay - Ile de France"], ["Gramfort", "Alexandre", "", "LNAO, INRIA Saclay - Ile de France"], ["Poline", "Jean Baptiste", "", "LNAO"], ["Thirion", "Bertrand", "", "LNAO, INRIA Saclay - Ile de France"]]}, {"id": "1008.5161", "submitter": "Robert Burger PhD", "authors": "John Robert Burger", "title": "Artificial Brain Based on Credible Neural Circuits in a Human Brain", "comments": "14 pages 12 figures corrected Fig. 3 & edited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons are individually translated into simple gates to plan a brain based\non human psychology and intelligence. State machines, assumed previously\nlearned in subconscious associative memory are shown to enable equation solving\nand rudimentary thinking using nanoprocessing within short term memory.\n", "versions": [{"version": "v1", "created": "Mon, 30 Aug 2010 20:33:45 GMT"}, {"version": "v2", "created": "Fri, 17 Sep 2010 18:16:33 GMT"}, {"version": "v3", "created": "Mon, 4 Oct 2010 07:22:34 GMT"}], "update_date": "2010-10-05", "authors_parsed": [["Burger", "John Robert", ""]]}, {"id": "1008.5359", "submitter": "Eugene Lerman", "authors": "R. E. Lee DeVille and Eugene Lerman", "title": "Dynamics on networks I. Combinatorial categories of modular\n  continuous-time systems", "comments": "59 pages. (v2): abstract and introduction re-written, examples added", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS physics.soc-ph q-bio.MN q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a new framework for the study of complex continuous time dynamical\nsystems based on viewing them as collections of interacting control modules.\nThis framework is inspired by and builds upon the groupoid formalism of\nGolubitsky, Stewart and their collaborators. Our approach uses the tools and\n--- more importantly ---the stance of category theory. This enables us to put\nthe groupoid formalism in a coordinate-free setting and to extend it from\nordinary differential equations to vector fields on manifolds. In particular,\nwe construct combinatorial models for categories of modular continuous time\ndynamical systems. Each such model, as a category, is a fibration over an\nappropriate category of labeled directed graphs. This makes precise the\nrelation between dynamical systems living on networks and the combinatorial\nstructure of the underlying directed graphs, allowing us to exploit the\nrelation in new and interesting ways.\n", "versions": [{"version": "v1", "created": "Tue, 31 Aug 2010 16:49:33 GMT"}, {"version": "v2", "created": "Tue, 5 Apr 2011 21:27:14 GMT"}], "update_date": "2011-04-07", "authors_parsed": [["DeVille", "R. E. Lee", ""], ["Lerman", "Eugene", ""]]}]