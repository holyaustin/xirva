[{"id": "1702.00101", "submitter": "Danielle Bassett", "authors": "Elisabeth A. Karuza, Ari E. Kahn, Sharon L. Thompson-Schill, and\n  Danielle S. Bassett", "title": "Process reveals structure: How a network is traversed mediates\n  expectations about its architecture", "comments": "22 pages, 2 figures, 1 table, plus supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network science has emerged as a powerful tool through which we can study the\nhigher-order architectural properties of the world around us. How human\nlearners exploit this information remains an essential question. Here, we focus\non the temporal constraints that govern such a process. Participants viewed a\ncontinuous sequence of images generated by three distinct walks on a modular\nnetwork. Walks varied along two critical dimensions: their predictability and\nthe density with which they sampled from communities of images. Learners\nexposed to walks that richly sampled from each community exhibited a sharp\nincrease in processing time upon entry into a new community. This effect was\neliminated in a highly regular walk that sampled exhaustively from images in\nshort, successive cycles (i.e., that increasingly minimized uncertainty about\nthe nature of upcoming stimuli). These results demonstrate that temporal\norganization plays an essential role in how robustly knowledge of network\narchitecture is acquired.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 01:33:43 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Karuza", "Elisabeth A.", ""], ["Kahn", "Ari E.", ""], ["Thompson-Schill", "Sharon L.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1702.00354", "submitter": "Jason Kim", "authors": "Jason Kim, Jonathan M. Soffer, Ari E. Kahn, Jean M. Vettel, Fabio\n  Pasqualetti, Danielle S. Bassett", "title": "Topological Principles of Control in Dynamical Network Systems", "comments": "7 figures, Supplement", "journal-ref": null, "doi": "10.1038/nphys4268", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networked systems display complex patterns of interactions between a large\nnumber of components. In physical networks, these interactions often occur\nalong structural connections that link components in a hard-wired connection\ntopology, supporting a variety of system-wide dynamical behaviors such as\nsynchronization. While descriptions of these behaviors are important, they are\nonly a first step towards understanding the relationship between network\ntopology and system behavior, and harnessing that relationship to optimally\ncontrol the system's function. Here, we use linear network control theory to\nanalytically relate the topology of a subset of structural connections (those\nlinking driver nodes to non-driver nodes) to the minimum energy required to\ncontrol networked systems. As opposed to the numerical computations of control\nenergy, our accurate closed-form expressions yield general structural features\nin networks that require significantly more or less energy to control,\nproviding topological principles for the design and modification of network\nbehavior. To illustrate the utility of the mathematics, we apply this approach\nto high-resolution connectomes recently reconstructed from drosophila, mouse,\nand human brains. We use these principles to show that connectomes of\nincreasingly complex species are wired to reduce control energy. We then use\nthe analytical expressions we derive to perform targeted manipulation of the\nbrain's control profile by removing single edges in the network, a manipulation\nthat is accessible to current clinical techniques in patients with neurological\ndisorders. Cross-species comparisons suggest an advantage of the human brain in\nsupporting diverse network dynamics with small energetic costs, while remaining\nunexpectedly robust to perturbations. Our results ground the expectation of a\nsystem's dynamical behavior in its network architecture.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 16:55:42 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2017 05:31:08 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Kim", "Jason", ""], ["Soffer", "Jonathan M.", ""], ["Kahn", "Ari E.", ""], ["Vettel", "Jean M.", ""], ["Pasqualetti", "Fabio", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1702.00493", "submitter": "Wentao Huang", "authors": "Wentao Huang, Xin Huang and Kechen Zhang", "title": "Information-theoretic interpretation of tuning curves for multiple\n  motion directions", "comments": "The 51st Annual Conference on Information Sciences and Systems\n  (CISS), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.NE math.IT q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed an efficient information-maximization method for computing\nthe optimal shapes of tuning curves of sensory neurons by optimizing the\nparameters of the underlying feedforward network model. When applied to the\nproblem of population coding of visual motion with multiple directions, our\nmethod yields several types of tuning curves with both symmetric and asymmetric\nshapes that resemble what have been found in the visual cortex. Our result\nsuggests that the diversity or heterogeneity of tuning curve shapes as observed\nin neurophysiological experiment might actually constitute an optimal\npopulation representation of visual motions with multiple components.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 23:03:18 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Huang", "Wentao", ""], ["Huang", "Xin", ""], ["Zhang", "Kechen", ""]]}, {"id": "1702.00614", "submitter": "Miguel Aguilera", "authors": "Miguel Aguilera, Manuel G. Bedia", "title": "Learning Criticality in an Embodied Boltzmann Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cond-mat.dis-nn cond-mat.stat-mech cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many biological and cognitive systems do not operate deep into one or other\nregime of activity. Instead, they exploit critical surfaces poised at\ntransitions in their parameter space. The pervasiveness of criticality in\nnatural systems suggests that there may be general principles inducing this\nbehaviour. However, there is a lack of conceptual models explaining how\nembodied agents propel themselves towards these critical points. In this paper,\nwe present a learning model driving an embodied Boltzmann Machine towards\ncritical behaviour by maximizing the heat capacity of the network. We test and\ncorroborate the model implementing an embodied agent in the mountain car\nbenchmark, controlled by a Boltzmann Machine that adjust its weights according\nto the model. We find that the neural controller reaches a point of\ncriticality, which coincides with a transition point of the behaviour of the\nagent between two regimes of behaviour, maximizing the synergistic information\nbetween its sensors and the hidden and motor neurons. Finally, we discuss the\npotential of our learning model to study the contribution of criticality to the\nbehaviour of embodied living systems in scenarios not necessarily constrained\nby biological restrictions of the examples of criticality we find in nature.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 11:04:48 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Aguilera", "Miguel", ""], ["Bedia", "Manuel G.", ""]]}, {"id": "1702.00687", "submitter": "Alejandro Jimenez Rodriguez", "authors": "Alejandro Jimenez Rodriguez, Juan Carlos Cordero Ceballos and Nestor\n  E. Sanchez", "title": "Heterogeneous gain distributions in neural networks I:The stationary\n  case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study heterogeneous distribution of gains in neural fields using\ntechniques of quantum mechanics by exploiting a relationship of our model and\nthe time-independent Schr\\\"{o}dinger equation. We show that specific\nrelationships between the connectivity kernel and the gain of the population\ncan explain the behavior of the neural field in simulations. In particular, we\nshow this relationships for the gating of activity between two regions (step\npotential), the propagation of activity throughout another region (barrier)\nand, most importantly, the existence of bumps in gain-contained regions (gain\nwell). Our results constitute specific predictions that can be tested in vivo\nor in vitro.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 14:03:36 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Rodriguez", "Alejandro Jimenez", ""], ["Ceballos", "Juan Carlos Cordero", ""], ["Sanchez", "Nestor E.", ""]]}, {"id": "1702.00718", "submitter": "Juan Manuel Romero", "authors": "Erick J. L\\'opez-S\\'anchez, Juan M. Romero", "title": "Cable equation for general geometry", "comments": "13 page, 7 figures", "journal-ref": null, "doi": "10.1103/PhysRevE.95.022403", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cable equation describes the voltage in a straight cylindrical cable,\nthis model has been employed to model electrical potential in dendrites and\naxons. However, sometimes this equation might give incorrect predictions for\nsome realistic geometries, in particular when the radius of the cable changes\nsignificantly. Cables with a non constant radius are important for some\nphenomena, for example discrete swellings along the axons appear in\nneurodegenerative diseases such as Alzheimer, Parkinson, HIV-associated\ndementia and Multiple Sclerosis. In this paper, using the Frenet-Serret frame,\nwe propose a generalized cable equation for a general cable geometry. This\ngeneralized equation depends on geometric quantities such as the curvature and\ntorsion of the cable. We show that when the cable has a constant circular\ncross-section, the first fundamental form of the cable can be simplified and\nthe generalized cable equation depends on neither the curvature nor the torsion\nof the cable. Additionally, we find an exact solution for an ideal cable which\nhas a particular variable circular cross-section and zero curvature. For this\ncase we show that when the cross-section of the cable increases the voltage\ndecreases. Inspired in this ideal case, we rewrite the generalized cable\nequation as a diffusion equation with a source term generated by the cable\ngeometry. This source term depends on the cable cross-section area and its\nderivates. In addition, we study different cables with swelling and provide\ntheir numerical solutions. The numerical solutions show that when the\ncross-section of the cable has abrupt changes, its voltage is smaller than the\nvoltage in the cylindrical cable. Furthermore, these numerical solutions show\nthat the voltage can be affected by geometrical inhomogeneities on the cable.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2017 20:02:12 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["L\u00f3pez-S\u00e1nchez", "Erick J.", ""], ["Romero", "Juan M.", ""]]}, {"id": "1702.00768", "submitter": "Xerxes D. Arsiwalla", "authors": "Riccardo Zucca, Xerxes D. Arsiwalla, Hoang Le, Mikail Rubinov, Paul\n  Verschure", "title": "Scaling Properties of Human Brain Functional Networks", "comments": "International Conference on Artificial Neural Networks - ICANN 2016", "journal-ref": "Artificial Neural Networks and Machine Learning, Lecture Notes in\n  Computer Science, vol 9886, 2016", "doi": "10.1007/978-3-319-44778-0_13", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate scaling properties of human brain functional networks in the\nresting-state. Analyzing network degree distributions, we statistically test\nwhether their tails scale as power-law or not. Initial studies, based on\nleast-squares fitting, were shown to be inadequate for precise estimation of\npower-law distributions. Subsequently, methods based on maximum-likelihood\nestimators have been proposed and applied to address this question.\nNevertheless, no clear consensus has emerged, mainly because results have shown\nsubstantial variability depending on the data-set used or its resolution. In\nthis study, we work with high-resolution data (10K nodes) from the Human\nConnectome Project and take into account network weights. We test for the\npower-law, exponential, log-normal and generalized Pareto distributions. Our\nresults show that the statistics generally do not support a power-law, but\ninstead these degree distributions tend towards the thin-tail limit of the\ngeneralized Pareto model. This may have implications for the number of hubs in\nhuman brain functional networks.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 18:01:07 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Zucca", "Riccardo", ""], ["Arsiwalla", "Xerxes D.", ""], ["Le", "Hoang", ""], ["Rubinov", "Mikail", ""], ["Verschure", "Paul", ""]]}, {"id": "1702.00837", "submitter": "Juan Biondi", "authors": "Juan Biondi, Gerardo Fernandez, Silvia Castro, Osvaldo Agamennoni", "title": "Eye-Movement behavior identification for AD diagnosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work, we develop a deep-learning approach for differentiating\nthe eye-movement behavior of people with neurodegenerative diseases over\nhealthy control subjects during reading well-defined sentences. We define an\ninformation compaction of the eye-tracking data of subjects without and with\nprobable Alzheimer's disease when reading a set of well-defined, previously\nvalidated, sentences including high-, low-predictable sentences, and proverbs.\nUsing this information we train a set of denoising sparse-autoencoders and\nbuild a deep neural network with these and a softmax classifier. Our results\nare very promising and show that these models may help to understand the\ndynamics of eye movement behavior and its relationship with underlying\nneuropsychological correlates.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 21:47:02 GMT"}, {"version": "v2", "created": "Sat, 18 Feb 2017 15:08:34 GMT"}, {"version": "v3", "created": "Mon, 15 Jan 2018 13:14:23 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Biondi", "Juan", ""], ["Fernandez", "Gerardo", ""], ["Castro", "Silvia", ""], ["Agamennoni", "Osvaldo", ""]]}, {"id": "1702.00865", "submitter": "Braden Brinkman", "authors": "Braden A. W. Brinkman, Fred Rieke, Eric Shea-Brown, Michael A. Buice", "title": "Predicting how and when hidden neurons skew measured synaptic\n  interactions", "comments": "~14 pages + 6 figures (main text), ~18 pages + 3 figures (Methods),\n  ~22 pages + 3 figures (supporting info). v3 is a significantly expanded\n  version of the original upload", "journal-ref": null, "doi": "10.1371/journal.pcbi.1006490", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.soft cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major obstacle to understanding neural coding and computation is the fact\nthat experimental recordings typically sample only a small fraction of the\nneurons in a circuit. Measured neural properties are skewed by interactions\nbetween recorded neurons and the \"hidden\" portion of the network. To properly\ninterpret neural data and determine how biological structure gives rise to\nneural circuit function, we thus need a better understanding of the\nrelationships between measured effective neural properties and the true\nunderlying physiological properties. Here, we focus on how the effective\nspatiotemporal dynamics of the synaptic interactions between neurons are\nreshaped by coupling to unobserved neurons. We find that the effective\ninteractions from a pre-synaptic neuron $r'$ to a post-synaptic neuron $r$ can\nbe decomposed into a sum of the true interaction from $r'$ to $r$ plus\ncorrections from every directed path from $r'$ to $r$ through unobserved\nneurons. Importantly, the resulting formula reveals when the hidden units\nhave---or do not have---major effects on reshaping the interactions among\nobserved neurons. As a particular example of interest, we derive a formula for\nthe impact of hidden units in random networks with \"strong\"\ncoupling---connection weights that scale with $1/\\sqrt{N}$, where $N$ is the\nnetwork size, precisely the scaling observed in recent experiments. With this\nquantitative relationship between measured and true interactions, we can study\nhow network properties shape effective interactions, which properties are\nrelevant for neural computations, and how to manipulate effective interactions.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 23:08:21 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 21:57:48 GMT"}, {"version": "v3", "created": "Tue, 15 Aug 2017 18:03:27 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Brinkman", "Braden A. W.", ""], ["Rieke", "Fred", ""], ["Shea-Brown", "Eric", ""], ["Buice", "Michael A.", ""]]}, {"id": "1702.01391", "submitter": "Carmen Oana Tarniceriu", "authors": "Gr\\'egory Dumont, Jacques Henry, Carmen Oana Tarniceriu", "title": "A theoretical connection between the noisy leaky integrate-and-fire and\n  escape rate models: the non-autonomous case", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most important challenges in mathematical neuroscience is to\nproperly illustrate the stochastic nature of neurons. Among different\napproaches, the noisy leaky integrate-and-fire and the escape rate models are\nprobably the most popular. These two models are usually chosen to express\ndifferent noise action over the neural cell. In this paper we investigate the\nlink between the two formalisms in the case of a neuron subject to a time\ndependent input. To this aim, we introduce a new general stochastic framework.\nAs we shall prove, our general framework entails the two already existing ones.\nOur result has theoretical implications since it offers a general view upon the\ntwo stochastic processes mostly used in neuroscience, upon the way they can be\nlinked, and explain their observed statistical similarity.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2017 12:01:06 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Dumont", "Gr\u00e9gory", ""], ["Henry", "Jacques", ""], ["Tarniceriu", "Carmen Oana", ""]]}, {"id": "1702.01522", "submitter": "Johannes Berg", "authors": "H. Chau Nguyen, Riccardo Zecchina and Johannes Berg", "title": "Inverse statistical problems: from the inverse Ising problem to data\n  science", "comments": "Review article, 45 pages", "journal-ref": "Advances in Physics, 66 (3), 197-261 (2017)", "doi": "10.1080/00018732.2017.1341604", "report-no": null, "categories": "cond-mat.dis-nn q-bio.GN q-bio.MN q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse problems in statistical physics are motivated by the challenges of\n`big data' in different fields, in particular high-throughput experiments in\nbiology. In inverse problems, the usual procedure of statistical physics needs\nto be reversed: Instead of calculating observables on the basis of model\nparameters, we seek to infer parameters of a model based on observations. In\nthis review, we focus on the inverse Ising problem and closely related\nproblems, namely how to infer the coupling strengths between spins given\nobserved spin correlations, magnetisations, or other data. We review\napplications of the inverse Ising problem, including the reconstruction of\nneural connections, protein structure determination, and the inference of gene\nregulatory networks. For the inverse Ising problem in equilibrium, a number of\ncontrolled and uncontrolled approximate solutions have been developed in the\nstatistical mechanics community. A particularly strong method,\npseudolikelihood, stems from statistics. We also review the inverse Ising\nproblem in the non-equilibrium case, where the model parameters must be\nreconstructed based on non-equilibrium statistics.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 07:53:10 GMT"}, {"version": "v2", "created": "Fri, 12 May 2017 06:51:51 GMT"}, {"version": "v3", "created": "Fri, 30 Jun 2017 10:13:31 GMT"}, {"version": "v4", "created": "Mon, 6 Nov 2017 08:12:22 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Nguyen", "H. Chau", ""], ["Zecchina", "Riccardo", ""], ["Berg", "Johannes", ""]]}, {"id": "1702.01568", "submitter": "Volker Pernice", "authors": "Volker Pernice, Rava Azeredo da Silveira", "title": "Interpretation of Correlated Neural Variability from Models of\n  Feed-Forward and Recurrent Circuits", "comments": "41 pages, 10 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1005979", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The correlated variability in the responses of a neural population to the\nrepeated presentation of a sensory stimulus is a universally observed\nphenomenon. Such correlations have been studied in much detail, both with\nrespect to their mechanistic origin and to their influence on stimulus\ndiscrimination and on the performance of population codes. In particular,\nrecurrent neural network models have been used to understand the origin (or\nlack) of correlations in neural activity. Here, we apply a model of recurrently\nconnected stochastic neurons to interpret correlations found in a population of\nneurons recorded from mouse auditory cortex. We study the consequences of\nrecurrent connections on the stimulus dependence of correlations, and we\ncompare them to those from alternative sources of correlated variability, like\ncorrelated gain fluctuations and common input in feed-forward architectures. We\nfind that a recurrent network model with random effective connections\nreproduces observed statistics, like the relation between noise and signal\ncorrelations in the data, in a natural way. In the model, we can analyze\ndirectly the relation between network parameters, correlations, and how well\npairs of stimuli can be discriminated based on population activity. In this\nway, we can relate circuit parameters to information processing.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 11:13:15 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Pernice", "Volker", ""], ["da Silveira", "Rava Azeredo", ""]]}, {"id": "1702.01591", "submitter": "Robin Ince", "authors": "Robin A. A. Ince", "title": "The Partial Entropy Decomposition: Decomposing multivariate entropy and\n  mutual information via pointwise common surprisal", "comments": "Added Section 3.7 (Quantifying source vs mechanistic redundancy) and\n  Section 3.8 (Shared entropy as a measure of dependence: pure mutual\n  information) and updated abstract, results, and discussion accordingly", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT math.ST q-bio.NC q-bio.QM stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Obtaining meaningful quantitative descriptions of the statistical dependence\nwithin multivariate systems is a difficult open problem. Recently, the Partial\nInformation Decomposition (PID) was proposed to decompose mutual information\n(MI) about a target variable into components which are redundant, unique and\nsynergistic within different subsets of predictor variables. Here, we propose\nto apply the elegant formalism of the PID to multivariate entropy, resulting in\na Partial Entropy Decomposition (PED). We implement the PED with an entropy\nredundancy measure based on pointwise common surprisal; a natural definition\nwhich is closely related to the definition of MI. We show how this approach can\nreveal the dyadic vs triadic generative structure of multivariate systems that\nare indistinguishable with classical Shannon measures. The entropy perspective\nalso shows that misinformation is synergistic entropy and hence that MI itself\nincludes both redundant and synergistic effects. We show the relationships\nbetween the PED and MI in two predictors, and derive two alternative\ninformation decompositions which we illustrate on several example systems. This\nreveals that in entropy terms, univariate predictor MI is not a proper subset\nof the joint MI, and we suggest this previously unrecognised fact explains in\npart why obtaining a consistent PID has proven difficult. The PED also allows\nseparate quantification of mechanistic redundancy (related to the function of\nthe system) versus source redundancy (arising from dependencies between\ninputs); an important distinction which no existing methods can address. The\nnew perspective provided by the PED helps to clarify some of the difficulties\nencountered with the PID approach and the resulting decompositions provide\nuseful tools for practical data analysis across a wide range of application\nareas.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 12:28:27 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 16:11:20 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Ince", "Robin A. A.", ""]]}, {"id": "1702.01825", "submitter": "Niru Maheswaranathan", "authors": "Lane T. McIntosh, Niru Maheswaranathan, Aran Nayebi, Surya Ganguli,\n  Stephen A. Baccus", "title": "Deep Learning Models of the Retinal Response to Natural Scenes", "comments": "L.T.M. and N.M. contributed equally to this work. Presented at NIPS\n  2016", "journal-ref": "Advances in Neural Information Processing Systems 29 (2016)\n  1361-1369", "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central challenge in neuroscience is to understand neural computations and\ncircuit mechanisms that underlie the encoding of ethologically relevant,\nnatural stimuli. In multilayered neural circuits, nonlinear processes such as\nsynaptic transmission and spiking dynamics present a significant obstacle to\nthe creation of accurate computational models of responses to natural stimuli.\nHere we demonstrate that deep convolutional neural networks (CNNs) capture\nretinal responses to natural scenes nearly to within the variability of a\ncell's response, and are markedly more accurate than linear-nonlinear (LN)\nmodels and Generalized Linear Models (GLMs). Moreover, we find two additional\nsurprising properties of CNNs: they are less susceptible to overfitting than\ntheir LN counterparts when trained on small amounts of data, and generalize\nbetter when tested on stimuli drawn from a different distribution (e.g. between\nnatural scenes and white noise). Examination of trained CNNs reveals several\nproperties. First, a richer set of feature maps is necessary for predicting the\nresponses to natural scenes compared to white noise. Second, temporally precise\nresponses to slowly varying inputs originate from feedforward inhibition,\nsimilar to known retinal mechanisms. Third, the injection of latent noise\nsources in intermediate layers enables our model to capture the sub-Poisson\nspiking variability observed in retinal ganglion cells. Fourth, augmenting our\nCNNs with recurrent lateral connections enables them to capture contrast\nadaptation as an emergent property of accurately describing retinal responses\nto natural scenes. These methods can be readily generalized to other sensory\nmodalities and stimulus ensembles. Overall, this work demonstrates that CNNs\nnot only accurately capture sensory circuit responses to natural scenes, but\nalso yield information about the circuit's internal structure and function.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 23:48:19 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["McIntosh", "Lane T.", ""], ["Maheswaranathan", "Niru", ""], ["Nayebi", "Aran", ""], ["Ganguli", "Surya", ""], ["Baccus", "Stephen A.", ""]]}, {"id": "1702.02462", "submitter": "Thomas Malone", "authors": "David Engel and Thomas W. Malone", "title": "Integrated Information as a Metric for Group Interaction: Analyzing\n  Human and Computer Groups Using a Technique Developed to Measure\n  Consciousness", "comments": null, "journal-ref": "Engel, D., Malone, T. W. (2018) Integrated information as a metric\n  for group interaction. PLOS ONE 13(10): e0205335.\n  https://doi.org/10.1371/journal.pone.0205335", "doi": "10.1371/journal.pone.0205335", "report-no": null, "categories": "cs.SI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers in many disciplines have previously used a variety of\nmathematical techniques for analyzing group interactions. Here we use a new\nmetric for this purpose, called 'integrated information' or 'phi.' Phi was\noriginally developed by neuroscientists as a measure of consciousness in\nbrains, but it captures, in a single mathematical quantity, two properties that\nare important in many other kinds of groups as well: differentiated information\nand integration. Here we apply this metric to the activity of three types of\ngroups that involve people and computers. First, we find that 4-person work\ngroups with higher measured phi perform a wide range of tasks more effectively,\nas measured by their collective intelligence. Next, we find that groups of\nWikipedia editors with higher measured phi create higher quality articles.\nLast, we find that the measured phi of the collection of people and computers\ncommunicating on the Internet increased over a recent six-year period.\nTogether, these results suggest that integrated information can be a useful way\nof characterizing a certain kind of interactional complexity that, at least\nsometimes, predicts group performance. In this sense, phi can be viewed as a\npotential metric of effective group collaboration. Since the metric was\noriginally developed as a measure of consciousness, the results also raise\nintriguing questions about the conditions under which it might be useful to\nregard groups as having a kind of consciousness.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 15:15:24 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Engel", "David", ""], ["Malone", "Thomas W.", ""]]}, {"id": "1702.02485", "submitter": "Laurent Perrinet", "authors": "Laurent U Perrinet (INT)", "title": "Biologically-inspired characterization of sparseness in natural images", "comments": "arXiv admin note: substantial text overlap with arXiv:1611.06834", "journal-ref": "6th European Workshop on Visual Information Processing (EUVIP),\n  Oct 2016, Marseille, France. pp.1--6, 2016", "doi": "10.1109/EUVIP.2016.7764592", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural images follow statistics inherited by the structure of our physical\n(visual) environment. In particular, a prominent facet of this structure is\nthat images can be described by a relatively sparse number of features. We\ndesigned a sparse coding algorithm biologically-inspired by the architecture of\nthe primary visual cortex. We show here that coefficients of this\nrepresentation exhibit a heavy-tailed distribution. For each image, the\nparameters of this distribution characterize sparseness and vary from image to\nimage. To investigate the role of this sparseness, we designed a new class of\nrandom textured stimuli with a controlled sparseness value inspired by our\nmeasurements on natural images. Then, we provide with a method to synthesize\nrandom textures images with a given statistics for sparseness that matches that\nof some given class of natural images and provide perspectives for their use in\nneurophysiology.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 15:57:57 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Perrinet", "Laurent U", "", "INT"]]}, {"id": "1702.02492", "submitter": "Julien Lagarde", "authors": "Julien Lagarde", "title": "To do things with words (only): An introduction to the role of noise in\n  coordination dynamics without equations", "comments": "12 pages, short review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uncertainty, spatial or temporal errors, variability, are classic themes in\nthe study of human and animal behaviors. Several theoretical approaches1 and\nconcepts have been adopted to tackle those issues, often considering the CNS as\nan observer, using Shannon information and entropy, signal to noise ratio, and\nrecently a Bayesian approach, and free energy minimization. In the coordination\ndynamics framework, addressing pattern formation processes underlying cognitive\nfunctions, and goal directed human movement among others, the tools employed\noriginate from the statistical physics of Brownian motion and stochastic\nprocesses. The relations between those theories/ concepts have been drawn for\nsome cases in their original fields, for example between free energy\nminimization and diffusion model in a force field (Jordan et al., 1998). Here\nan introductory presentation of the approach of noise in coordination dynamics\nis proposed, aimed at the experimentalist.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 16:23:56 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Lagarde", "Julien", ""]]}, {"id": "1702.02510", "submitter": "Juan Abdon Miranda Correa", "authors": "Juan Abdon Miranda-Correa and Mojtaba Khomami Abadi and Nicu Sebe and\n  Ioannis Patras", "title": "AMIGOS: A Dataset for Affect, Personality and Mood Research on\n  Individuals and Groups", "comments": "14 pages, Transaction on Affective Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present AMIGOS-- A dataset for Multimodal research of affect, personality\ntraits and mood on Individuals and GrOupS. Different to other databases, we\nelicited affect using both short and long videos in two social contexts, one\nwith individual viewers and one with groups of viewers. The database allows the\nmultimodal study of the affective responses, by means of neuro-physiological\nsignals of individuals in relation to their personality and mood, and with\nrespect to the social context and videos' duration. The data is collected in\ntwo experimental settings. In the first one, 40 participants watched 16 short\nemotional videos. In the second one, the participants watched 4 long videos,\nsome of them alone and the rest in groups. The participants' signals, namely,\nElectroencephalogram (EEG), Electrocardiogram (ECG) and Galvanic Skin Response\n(GSR), were recorded using wearable sensors. Participants' frontal HD video and\nboth RGB and depth full body videos were also recorded. Participants emotions\nhave been annotated with both self-assessment of affective levels (valence,\narousal, control, familiarity, liking and basic emotions) felt during the\nvideos as well as external-assessment of levels of valence and arousal. We\npresent a detailed correlation analysis of the different dimensions as well as\nbaseline methods and results for single-trial classification of valence and\narousal, personality traits, mood and social context. The database is made\npublicly available.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 08:04:47 GMT"}, {"version": "v2", "created": "Tue, 28 Mar 2017 14:27:10 GMT"}, {"version": "v3", "created": "Thu, 13 Apr 2017 16:10:00 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Miranda-Correa", "Juan Abdon", ""], ["Abadi", "Mojtaba Khomami", ""], ["Sebe", "Nicu", ""], ["Patras", "Ioannis", ""]]}, {"id": "1702.02621", "submitter": "Darren Narayan", "authors": "Alexander Strang, Oliver Haynes, Nathan D. Cahill, and Darren A.\n  Narayan", "title": "Relationships Between Characteristic Path Length, Efficiency, Clustering\n  Coefficients, and Graph Density", "comments": "Figure 1 seems to have been dropped during formatting. It can be\n  found at https://ourarchive.otago.ac.nz/handle/10523/4864 Figure 5.8", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph theoretic properties of the clustering coefficient, characteristic\n(or average) path length, global and local efficiency, provide valuable\ninformation regarding the structure of a graph. These four properties have\napplications to biological and social networks and have dominated much of the\nthe literature in these fields. While much work has done in applied settings,\nthere has yet to be a mathematical comparison of these metrics from a\ntheoretical standpoint. Motivated by networks appearing in neuroscience, we\nshow in this paper that these properties can be linked together using a single\nproperty - graph density.\n", "versions": [{"version": "v1", "created": "Fri, 3 Feb 2017 14:10:14 GMT"}, {"version": "v2", "created": "Fri, 22 Sep 2017 10:57:58 GMT"}], "update_date": "2017-09-25", "authors_parsed": [["Strang", "Alexander", ""], ["Haynes", "Oliver", ""], ["Cahill", "Nathan D.", ""], ["Narayan", "Darren A.", ""]]}, {"id": "1702.02684", "submitter": "Elizabeth Reilly", "authors": "Elizabeth P. Reilly, Jeffrey S. Garretson, William Gray Roncal, Dean\n  M. Kleissas, Brock A. Wester, Mark A. Chevillet, Matthew J. Roos", "title": "Neural Reconstruction Integrity: A metric for assessing the connectivity\n  of reconstructed neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscientists are actively pursuing high-precision maps, or graphs,\nconsisting of networks of neurons and connecting synapses in mammalian and\nnon-mammalian brains. Such graphs, when coupled with physiological and\nbehavioral data, are likely to facilitate greater understanding of how circuits\nin these networks give rise to complex information processing capabilities.\nGiven that the automated or semi-automated methods required to achieve the\nacquisition of these graphs are still evolving, we develop a metric for\nmeasuring the performance of such methods by comparing their output with those\ngenerated by human annotators (\"ground truth\" data). Whereas classic metrics\nfor comparing annotated neural tissue reconstructions generally do so at the\nvoxel level, the metric proposed here measures the \"integrity\" of neurons based\non the degree to which a collection of synaptic terminals belonging to a single\nneuron of the reconstruction can be matched to those of a single neuron in the\nground truth data. The metric is largely insensitive to small errors in\nsegmentation and more directly measures accuracy of the generated brain graph.\nIt is our hope that use of the metric will facilitate the broader community's\nefforts to improve upon existing methods for acquiring brain graphs. Herein we\ndescribe the metric in detail, provide demonstrative examples of the intuitive\nscores it generates, and apply it to a synthesized neural network with\nsimulated reconstruction errors.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 02:40:25 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Reilly", "Elizabeth P.", ""], ["Garretson", "Jeffrey S.", ""], ["Roncal", "William Gray", ""], ["Kleissas", "Dean M.", ""], ["Wester", "Brock A.", ""], ["Chevillet", "Mark A.", ""], ["Roos", "Matthew J.", ""]]}, {"id": "1702.02703", "submitter": "Justin Faber", "authors": "Justin Faber, Dolores Bozovic", "title": "Chaotic Dynamics of Inner Ear Hair Cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental records of active bundle motility are used to demonstrate the\npresence of a low-dimensional chaotic attractor in hair cell dynamics.\nDimensionality tests from dynamic systems theory are applied to estimate the\nnumber of independent variables sufficient for modeling the hair cell response.\nPoincare maps are constructed to observe a quasiperiodic transition from chaos\nto order with increasing amplitudes of mechanical forcing. The onset of this\ntransition is accompanied by a reduction of Kolmogorov entropy in the system\nand an increase in mutual information between the stimulus and the hair bundle,\nindicative of signal detection. A simple theoretical model is used to describe\nthe observed chaotic dynamics. The model exhibits an enhancement of sensitivity\nto weak stimuli when the system is poised in the chaotic regime. We propose\nthat chaos may play a role in the hair cell's ability to detect low-amplitude\nsounds.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 04:35:09 GMT"}, {"version": "v2", "created": "Thu, 27 Apr 2017 20:06:30 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Faber", "Justin", ""], ["Bozovic", "Dolores", ""]]}, {"id": "1702.02807", "submitter": "Richard Betzel", "authors": "Richard F. Betzel, John D. Medaglia, Danielle S. Bassett", "title": "Diversity of meso-scale architecture in human and non-human connectomes", "comments": "36 pages, 8 figures (main text), 8 figures (supplementary materials)", "journal-ref": null, "doi": "10.1038/s41467-017-02681-z", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain's functional diversity is reflected in the meso-scale architecture\nof its connectome, i.e. its division into clusters and communities of\ntopologically-related brain regions. The dominant view, and one that is\nreinforced by current analysis techniques, is that communities are strictly\nassortative and segregated from one another, purportedly for the purpose of\ncarrying out specialized information processing. Such a view, however,\nprecludes the possibility of non-assortative communities that could engender a\nricher functional repertoire by allowing for a more complex set of\ninter-community interactions. Here, we use weighted stochastic blockmodels to\nuncover the meso-scale architecture of \\emph{Drosophila}, mouse, rat, macaque,\nand human connectomes. We confirm that while many communities are assortative,\nothers form core-periphery and disassortative structures, which in the human\nbetter recapitulate observed patterns of functional connectivity and in the\nmouse better recapitulate observed patterns of gene co-expression than other\ncommunity detection techniques. We define a set of network measures for\nquantifying the diversity of community types in which brain regions\nparticipate. Finally, we show that diversity is peaked in control and\nsubcortical systems in humans, and that individual differences in diversity\nwithin those systems predicts cognitive performance on Stroop and Navon tasks.\nIn summary, our report paints a more diverse portrait of connectome meso-scale\nstructure and demonstrates its relevance for cognitive performance.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 12:34:21 GMT"}, {"version": "v2", "created": "Fri, 10 Feb 2017 13:56:59 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Betzel", "Richard F.", ""], ["Medaglia", "John D.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1702.02873", "submitter": "Xavier Navarro-Sune", "authors": "X. Navarro, F. Por\\'ee, M. Kuchenbuch, M. Chavez, A. Beuch\\'ee, G.\n  Carrault", "title": "Multi-feature classifiers for burst detection in single EEG channels\n  from preterm infants", "comments": "11 pages, 5 figures. Table 1 in the last page", "journal-ref": null, "doi": "10.1088/1741-2552/aa714a", "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of electroencephalographic (EEG) bursts in preterm infants provides\nvaluable information about maturation or prognostication after perinatal\nasphyxia. Over the last two decades, a number of works proposed algorithms to\nautomatically detect EEG bursts in preterm infants, but they were designed for\npopulations under 35 weeks of post menstrual age (PMA). However, as the brain\nactivity evolves rapidly during postnatal life, these solutions might be\nunder-performing with increasing PMA. In this work we focused on preterm\ninfants reaching term ages (PMA $\\geq$ 36 weeks) using multi-feature\nclassification on a single EEG channel. Five EEG burst detectors relying on\ndifferent machine learning approaches were compared: Logistic regression (LR),\nlinear discriminant analysis (LDA), k-nearest neighbors (kNN), support vector\nmachines (SVM) and thresholding (Th). Classifiers were trained by visually\nlabeled EEG recordings from 14 very preterm infants (born after 28 weeks of\ngestation) with 36 - 41 weeks PMA. The most performing classifiers reached\nabout 95\\% accuracy (kNN, SVM and LR) whereas Th obtained 84\\%. Compared to\nhuman-automatic agreements, LR provided the highest scores (Cohen's kappa =\n0.71) and the best computational efficiency using only three EEG features.\nApplying this classifier in a test database of 21 infants $\\geq$ 36 weeks PMA,\nwe show that long EEG bursts and short inter-bust periods are characteristic of\ninfants with the highest PMA and weights. In view of these results, LR-based\nburst detection could be a suitable tool to study maturation in monitoring or\nportable devices using a single EEG channel.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 09:58:49 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Navarro", "X.", ""], ["Por\u00e9e", "F.", ""], ["Kuchenbuch", "M.", ""], ["Chavez", "M.", ""], ["Beuch\u00e9e", "A.", ""], ["Carrault", "G.", ""]]}, {"id": "1702.03183", "submitter": "Diego Fasoli", "authors": "Diego Fasoli, Anna Cattani, Stefano Panzeri", "title": "Pattern Storage, Bifurcations and Higher-Order Correlation Structure of\n  an Exactly Solvable Asymmetric Neural Network Model", "comments": "Main Text: 25 pages, 10 figures. Supplementary Materials: 25 pages, 3\n  figures. In version 1, we plotted Fig. 7 with an inhibitory current that was\n  different from that stated in the figure caption. We fixed this in version 2,\n  by replotting Fig. 7 with the correct value of the current. Results unchanged", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exactly solvable neural network models with asymmetric weights are rare, and\nexact solutions are available only in some mean-field approaches. In this\narticle we find exact analytical solutions of an asymmetric spin-glass-like\nmodel of arbitrary size and we perform a complete study of its dynamical and\nstatistical properties. The network has discrete-time evolution equations,\nbinary firing rates and can be driven by noise with any distribution. We find\nanalytical expressions of the conditional and stationary joint probability\ndistributions of the membrane potentials and the firing rates. The conditional\nprobability distribution of the firing rates allows us to introduce a new\nlearning rule to store safely, under the presence of noise, point and cyclic\nattractors, with important applications in the field of content-addressable\nmemories. Furthermore, we study the neuronal dynamics in terms of the\nbifurcation structure of the network. We derive analytically examples of the\ncodimension one and codimension two bifurcation diagrams of the network, which\ndescribe how the neuronal dynamics changes with the external stimuli. In\nparticular, we find that the network may undergo transitions among multistable\nregimes, oscillatory behavior elicited by asymmetric synaptic connections, and\nvarious forms of spontaneous symmetry-breaking. On the other hand, the joint\nprobability distributions allow us to calculate analytically the higher-order\ncorrelation structure of the network, which reveals neuronal regimes where,\nstatistically, the membrane potentials and the firing rates are either\nsynchronous or asynchronous. Our results are valid for networks composed of an\narbitrary number of neurons, but for completeness we also derive the network\nequations in the mean-field limit and we study analytically their local\nbifurcations. All the analytical results are extensively validated by numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 14:33:50 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 18:56:49 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Fasoli", "Diego", ""], ["Cattani", "Anna", ""], ["Panzeri", "Stefano", ""]]}, {"id": "1702.03409", "submitter": "Kate Inasaridze", "authors": "Vera Bzhalava, Ketevan Inasaridze", "title": "Disruptive Behavior Disorder (DBD) Rating Scale for Georgian Population", "comments": "9 pages, 2 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the presented study Parent/Teacher Disruptive Behavior Disorder (DBD)\nrating scale based on the Diagnostic and Statistical Manual of Mental Disorders\n(DSM-IV-TR [APA, 2000]) which was developed by Pelham and his colleagues\n(Pelham et al., 1992) was translated and adopted for assessment of childhood\nbehavioral abnormalities, especially ADHD, ODD and CD in Georgian children and\nadolescents. The DBD rating scale was translated into Georgian language using\nback translation technique by English language philologists and checked and\ncorrected by qualified psychologists and psychiatrist of Georgia. Children and\nadolescents in the age range of 6 to 16 years (N 290; Mean Age 10.50, SD=2.88)\nincluding 153 males (Mean Age 10.42, SD= 2.62) and 141 females (Mean Age 10.60,\nSD=3.14) were recruited from different public schools of Tbilisi and the\nNeurology Department of the Pediatric Clinic of the Tbilisi State Medical\nUniversity. Participants objectively were assessed via interviewing\nparents/teachers and qualified psychologists in three different settings\nincluding school, home and clinic. In terms of DBD total scores revealed\nstatistically significant differences between healthy controls (M=27.71,\nSD=17.26) and children and adolescents with ADHD (M=61.51, SD= 22.79).\nStatistically significant differences were found for inattentive subtype\nbetween control (M=8.68, SD=5.68) and ADHD (M=18.15, SD=6.57) groups. In\ngeneral it was shown that children and adolescents with ADHD had high score on\nDBD in comparison to typically developed persons. In the study also was\ndetermined gender wise prevalence in children and adolescents with ADHD, ODD\nand CD. The research revealed prevalence of males in comparison with females in\nall investigated categories.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 10:52:36 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Bzhalava", "Vera", ""], ["Inasaridze", "Ketevan", ""]]}, {"id": "1702.03418", "submitter": "Yanjun Wang Dr.", "authors": "Zhi-Song lv, Chen-Ping Zhu, Pei Nie, Jing Zhao, Hui-Jie Yang, Yan-Jun\n  Wang, Chin-Kun Hu", "title": "Exponential distance distribution of connected neurons in simulations of\n  two-dimensional in vitro neural network development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distribution of the geometric distances of connected neurons is a\npractical factor underlying neural networks in the brain. It can affect the\nbrain\\'s dynamic properties at the ground level. Karbowski derived a power-law\ndecay distribution that has not yet been verified by experiment. In this work,\nwe check its validity using simulations with a phenomenological model. Based on\nthe in vitro two-dimensional development of neural networks in culture vessels\nby Ito, we match the synapse number saturation time to obtain suitable\nparameters for the development process, then determine the distribution of\ndistances between connected neurons under such conditions. Our simulations\nobtain a clear exponential distribution instead of a power-law one, which\nindicates that Karbowski's conclusion is invalid, at least for the case of in\nvitro neural network development in two-dimensional culture vessels.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 12:26:25 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["lv", "Zhi-Song", ""], ["Zhu", "Chen-Ping", ""], ["Nie", "Pei", ""], ["Zhao", "Jing", ""], ["Yang", "Hui-Jie", ""], ["Wang", "Yan-Jun", ""], ["Hu", "Chin-Kun", ""]]}, {"id": "1702.03474", "submitter": "Cheng Ly", "authors": "Andrea K. Barreiro, Cheng Ly", "title": "Practical Approximation Method for Firing Rate Models of Coupled Neural\n  Networks with Correlated Inputs", "comments": "15 pages, 7 figures", "journal-ref": "Phys. Rev. E 96, 022413 (2017)", "doi": "10.1103/PhysRevE.96.022413", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid experimental advances now enable simultaneous electrophysiological\nrecording of neural activity at single-cell resolution across large regions of\nthe nervous system. Models of this neural network activity will necessarily\nincrease in size and complexity, thus increasing the computational cost of\nsimulating them and the challenge of analyzing them. Here we present a novel\nmethod to approximate the activity and firing statistics of a general firing\nrate network model (of Wilson-Cowan type) subject to noisy correlated\nbackground inputs. The method requires solving a system of transcendental\nequations and is fast compared to Monte Carlo simulations of coupled stochastic\ndifferential equations. We implement the method with several examples of\ncoupled neural networks and show that the results are quantitatively accurate\neven with moderate coupling strengths and an appreciable amount of\nheterogeneity in many parameters. This work should be useful for investigating\nhow various neural attributes qualitatively effect the spiking statistics of\ncoupled neural networks. Matlab code implementing the method is freely\navailable at GitHub (\\url{http://github.com/chengly70/FiringRateModReduction}).\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 00:52:12 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 12:07:20 GMT"}, {"version": "v3", "created": "Fri, 4 Aug 2017 16:22:00 GMT"}, {"version": "v4", "created": "Fri, 29 Sep 2017 11:57:42 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Barreiro", "Andrea K.", ""], ["Ly", "Cheng", ""]]}, {"id": "1702.03492", "submitter": "Xaq Pitkow", "authors": "Xaq Pitkow and Dora Angelaki", "title": "How the brain might work: statistics flowing in redundant population\n  codes", "comments": "11 pages, 3 figures, contribution related to workshop called \"How the\n  brain works\" at the University of Copenhagen, 14-16 Sept 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely believed that the brain performs approximate probabilistic\ninference to estimate causal variables in the world from ambiguous sensory\ndata. To understand these computations, we need to analyze how information is\nrepresented and transformed by the actions of nonlinear recurrent neural\nnetworks. We propose that these probabilistic computations function by a\nmessage-passing algorithm operating at the level of redundant neural\npopulations. To explain this framework, we review its underlying concepts,\nincluding graphical models, sufficient statistics, and message-passing, and\nthen describe how these concepts could be implemented by recurrently connected\nprobabilistic population codes. The relevant information flow in these networks\nwill be most interpretable at the population level, particularly for redundant\nneural codes. We therefore outline a general approach to identify the essential\nfeatures of a neural message-passing algorithm. Finally, we argue that to\nreveal the most important aspects of these neural computations, we must study\nlarge-scale activity patterns during moderately complex, naturalistic\nbehaviors.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 05:32:29 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 04:12:09 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Pitkow", "Xaq", ""], ["Angelaki", "Dora", ""]]}, {"id": "1702.03543", "submitter": "Andrea Barreiro", "authors": "Andrea K. Barreiro, Shree Hari Gautam, Woodrow L. Shew, Cheng Ly", "title": "A Theoretical Framework for Analyzing Coupled Neuronal Networks:\n  Application to the Olfactory System", "comments": "Submitted January 2017; Revised May 2017", "journal-ref": null, "doi": "10.1371/journal.pcbi.1005780", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining how synaptic coupling within and between regions is modulated\nduring sensory processing is an important topic in neuroscience.\nElectrophysiological recordings provide detailed information about neural\nspiking but have traditionally been confined to a particular region or layer of\ncortex. Here we develop new theoretical methods to study interactions between\nand within two brain regions, based on experimental measurements of spiking\nactivity simultaneously recorded from the two regions. By systematically\ncomparing experimentally-obtained spiking statistics to (efficiently computed)\nmodel spike rate statistics, we identify regions in model parameter space that\nare consistent with the experimental data. We apply our new technique to dual\nmicro-electrode array in vivo recordings from two distinct regions: olfactory\nbulb (OB) and anterior piriform cortex (PC). Our analysis predicts that: i)\ninhibition within the afferent region (OB) has to be weaker than the inhibition\nwithin PC, ii) excitation from PC to OB is generally stronger than excitation\nfrom OB to PC, iii) excitation from PC to OB and inhibition within PC have to\nboth be relatively strong compared to presynaptic inputs from OB. These\npredictions are validated in a spiking neural network model of the OB--PC\npathway that satisfies the many constraints from our experimental data. We find\nwhen the derived relationships are violated, the spiking statistics no longer\nsatisfy the constraints from the data. In principle this modeling framework can\nbe adapted to other systems and be used to investigate relationships between\nother neural attributes besides network connection strengths. Thus, this work\ncan serve as a guide to further investigations into the relationships of\nvarious neural attributes within and across different regions during sensory\nprocessing.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 17:00:48 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 21:15:06 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Barreiro", "Andrea K.", ""], ["Gautam", "Shree Hari", ""], ["Shew", "Woodrow L.", ""], ["Ly", "Cheng", ""]]}, {"id": "1702.03579", "submitter": "Sayan Biswas", "authors": "Sayan Biswas", "title": "Autonomous line follower robot controlled by cell culture", "comments": "6 pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuro-electronic hybrid promises to bring up a model architecture for\ncomputing. Such computing architecture could help to bring the power of\nbiological connection and electronic circuits together for better computing\nparadigm. Such paradigms for solving real world tasks with higher accuracy is\non demand now. A robot as a autonomous system is modeled here to navigate\nfollowing a particular line. Sensory inputs from robot is directed as input to\nthe cell culture in response to which motor commands are generated from the\nculture.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 21:18:10 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Biswas", "Sayan", ""]]}, {"id": "1702.03762", "submitter": "Etienne Tanr\\'e", "authors": "Alexandre Richard, Patricio Orio and Etienne Tanr\\'e", "title": "An integrate-and-fire model to generate spike trains with long-range\n  dependence", "comments": null, "journal-ref": null, "doi": "10.1007/s10827-018-0680-1", "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-range dependence (LRD) has been observed in a variety of phenomena in\nnature, and for several years also in the spiking activity of neurons. Often,\nthis is interpreted as originating from a non-Markovian system. Here we show\nthat a purely Markovian integrate-and-fire (IF) model, with a noisy slow\nadaptation term, can generate interspike intervals (ISIs) that appear as having\nLRD. However a proper analysis shows that this is not the case asymptotically.\nFor comparison, we also consider a new model of individual IF neuron with\nfractional (non-Markovian) noise. The correlations of its spike trains are\nstudied and proven to have LRD, unlike classical IF models. On the other hand,\nto correctly measure long-range dependence, it is usually necessary to know if\nthe data are stationary. Thus, a methodology to evaluate stationarity of the\nISIs is presented and applied to the various IF models. We explain that\nMarkovian IF models may seem to have LRD because of non-stationarities.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 13:19:07 GMT"}, {"version": "v2", "created": "Thu, 4 May 2017 16:30:12 GMT"}, {"version": "v3", "created": "Wed, 28 Mar 2018 04:50:58 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Richard", "Alexandre", ""], ["Orio", "Patricio", ""], ["Tanr\u00e9", "Etienne", ""]]}, {"id": "1702.03993", "submitter": "Konstantinos Michmizos", "authors": "Leo Kozachkov and Konstantinos P. Michmizos", "title": "The Causal Role of Astrocytes in Slow-Wave Rhythmogenesis: A\n  Computational Modelling Study", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the origin of slow and infra-slow oscillations could reveal or\nexplain brain mechanisms in health and disease. Here, we present a\nbiophysically constrained computational model of a neural network where the\ninclusion of astrocytes introduced slow and infra-slow-oscillations, through\ntwo distinct mechanisms. Specifically, we show how astrocytes can modulate the\nfast network activity through their slow inter-cellular calcium wave speed and\namplitude and possibly cause the oscillatory imbalances observed in diseases\ncommonly known for such abnormalities, namely Alzheimer's disease, Parkinson's\ndisease, epilepsy, depression and ischemic stroke. This work aims to increase\nour knowledge on how astrocytes and neurons synergize to affect brain function\nand dysfunction.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 21:33:06 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Kozachkov", "Leo", ""], ["Michmizos", "Konstantinos P.", ""]]}, {"id": "1702.04195", "submitter": "Vadim Zotev", "authors": "Vadim Zotev, Masaya Misaki, Raquel Phillips, Chung Ki Wong, Jerzy\n  Bodurka", "title": "Real-time fMRI neurofeedback of the mediodorsal and anterior thalamus\n  enhances correlation between thalamic BOLD activity and alpha EEG rhythm", "comments": "26 pages, 14 figures, to appear in Human Brain Mapping", "journal-ref": "Human Brain Mapping 39 (2018) 1024-1042", "doi": "10.1002/hbm.23902", "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time fMRI neurofeedback (rtfMRI-nf) with simultaneous EEG allows\nvolitional modulation of BOLD activity of target brain regions and\ninvestigation of related electrophysiological activity. We applied this\napproach to study correlations between thalamic BOLD activity and alpha EEG\nrhythm. Healthy volunteers in the experimental group (EG, n=15) learned to\nupregulate BOLD activity of the target region consisting of the mediodorsal\n(MD) and anterior (AN) thalamic nuclei using the rtfMRI-nf during retrieval of\nhappy autobiographical memories. Healthy subjects in the control group (CG,\nn=14) were provided with a sham feedback. The EG participants were able to\nsignificantly increase BOLD activities of the MD and AN. Functional\nconnectivity between the MD and the inferior precuneus was significantly\nenhanced during the rtfMRI-nf task. Average individual changes in the occipital\nalpha EEG power significantly correlated with the average MD BOLD activity\nlevels for the EG. Temporal correlations between the occipital alpha EEG power\nand BOLD activities of the MD and AN were significantly enhanced, during the\nrtfMRI-nf task, for the EG compared to the CG. Temporal correlations with the\nalpha power were also significantly enhanced for the posterior nodes of the\ndefault mode network, including the precuneus/posterior cingulate, and for the\ndorsal striatum. Our findings suggest that the temporal correlation between the\nMD BOLD activity and posterior alpha EEG power is modulated by the interaction\nbetween the MD and the inferior precuneus, reflected in their functional\nconnectivity. Our results demonstrate the potential of the rtfMRI-nf with\nsimultaneous EEG for non-invasive neuromodulation studies of human brain\nfunction.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 13:25:23 GMT"}, {"version": "v2", "created": "Sun, 19 Nov 2017 22:28:23 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Zotev", "Vadim", ""], ["Misaki", "Masaya", ""], ["Phillips", "Raquel", ""], ["Wong", "Chung Ki", ""], ["Bodurka", "Jerzy", ""]]}, {"id": "1702.04972", "submitter": "Miroslaw Latka", "authors": "Wojciech Jernajczyk, Pawel Gosek, Miroslaw Latka, Klaudia Kozlowska,\n  Lukasz Swiecicki, Bruce J. West", "title": "Alpha Wavelet Power as a Biomarker of Antidepressant Treatment Response\n  in Bipolar Depression", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is mounting evidence of a link between the properties of\nelectroencephalograms (EEGs) of depressive patients and the outcome of\npharmacotherapy. The goal of this study was to develop an EEG biomarker of\nantidepressant treatment response which would require only a single EEG\nmeasurement. We recorded resting, 21-channel EEG in 17 inpatients suffering\nfrom bipolar depression in eyes closed and eyes open conditions. The EEG\nmeasurement was performed at the end of the short washout period which followed\npreviously unsuccessful pharmacotherapy. We calculated the normalized wavelet\npower of alpha rhythm using two referential montages and an average reference\nmontage. In particular, in the occipital (O1, O2, Oz) channels the wavelet\npower of responders was up to 84% higher than that of nonresponders. Using a\nnovel classification algorithm we were able to correctly predict the outcome of\ntreatment with 90% sensitivity and 100% specificity. The proposed biomarker\nrequires only a single EEG measurement and consequently is intrinsically\ndifferent from biomarkers which exploit the changes in prefrontal EEG induced\nby pharmacotherapy over a given time.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 14:08:31 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Jernajczyk", "Wojciech", ""], ["Gosek", "Pawel", ""], ["Latka", "Miroslaw", ""], ["Kozlowska", "Klaudia", ""], ["Swiecicki", "Lukasz", ""], ["West", "Bruce J.", ""]]}, {"id": "1702.05254", "submitter": "Christopher Kovach", "authors": "Christopher K. Kovach", "title": "A Biased Look at Phase Locking: Brief Critical Review and Proposed\n  Remedy", "comments": null, "journal-ref": "IEEE Tran. Sig. Proc. 65(17), 2017, 4468-4480", "doi": "10.1109/TSP.2017.2711517", "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of popular measures of dependence between pairs of band-limited\nsignals rely on analytic phase. A common misconception is that the dependence\nrevealed by these measures must be specific to the spectral range of the\nfiltered input signals. Implicitly or explicitly, obtaining analytic phase\ninvolves normalizing the signal by its own envelope, which is a nonlinear\noperation that introduces broad spectral leakage. We review how this generates\nbias and complicates the interpretation of commonly used measures of phase\nlocking. A specific example of this effect may create spurious phase locking as\na consequence of nonzero circular mean in the phase of input signals, which can\nbe viewed as spectral leakage to 0 Hz. Corrections for this problem which\nrecenter or uniformize the distribution of phase may fail when the amplitudes\nof the compared signals are correlated. To address the more general problem of\nspectral bias, a novel measure of phase locking is proposed, the\namplitude-weighted phase locking value (awPLV). This measure is closely related\nto coherence, but it removes ambiguities of interpretation that detract from\nthe latter.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 08:22:52 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Kovach", "Christopher K.", ""]]}, {"id": "1702.05259", "submitter": "M\\'iriam R. Garc\\'ia Dr.", "authors": "M\\'iriam R. Garc\\'ia, Mathieu Cloutier and Peter Wellstead", "title": "A reaction-diffusion model for the progression of Parkinson's disease", "comments": "In memorial to Prof. Peter Wellstead. This was his last piece of work", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The temporal and spatial development of Parkinson's disease has been\ncharacterised as the progressive formation of {\\alpha}-synuclein aggregations\nthrough susceptible neuronal pathways. This article describes a new model for\nthis progression mechanism in which Parkinsonian damage moves over time through\nthe nervous system by the combined effect of the reaction kinetics of\npathogenesis and molecular diffusion. In the reaction-diffusion model, the\nchange from a healthy state to the disease state advances through the nervous\nsystem as a wave front of Parkinsonian damage, marking its path by\naccumulations of damaged {\\alpha}-synuclein and neurotoxic levels of oxidative\nspecies. Progression according to this model follows the most vulnerable routes\nthrough the nervous system as described by Braak's staging theory and predicts\nthat damage will advance at differing speeds depending upon the level and\nnumber of risk factors, in a manner that gives new insights into the variations\nwith which Parkinson's disease develops.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 08:55:52 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Garc\u00eda", "M\u00edriam R.", ""], ["Cloutier", "Mathieu", ""], ["Wellstead", "Peter", ""]]}, {"id": "1702.05325", "submitter": "SIlvia Vitali", "authors": "Silvia Vitali and Francesco Mainardi", "title": "Fractional Cable Model for Signal Conduction in Spiny Neuronal Dendrites", "comments": "arXiv admin note: substantial text overlap with arXiv:1702.05339", "journal-ref": null, "doi": "10.1063/1.4981944", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cable model is widely used in several fields of science to describe the\npropagation of signals. A relevant medical and biological example is the\nanomalous subdiffusion in spiny neuronal dendrites observed in several studies\nof the last decade. Anomalous subdiffusion can be modelled in several ways\nintroducing some fractional component into the classical cable model. The\nChauchy problem associated to these kind of models has been investigated by\nmany authors, but up to our knowledge an explicit solution for the signalling\nproblem has not yet been published. Here we propose how this solution can be\nderived applying the generalized convolution theorem (known as Efros theorem)\nfor Laplace transforms. The fractional cable model considered in this paper is\ndefined by replacing the first order time derivative with a fractional\nderivative of order $\\alpha\\in(0,1)$ of Caputo type. The signalling problem is\nsolved for any input function applied to the accessible end of a semi-infinite\ncable, which satisfies the requirements of the Efros theorem. The solutions\ncorresponding to the simple cases of impulsive and step inputs are explicitly\ncalculated in integral form containing Wright functions. Thanks to the\nvariability of the parameter $\\alpha$, the corresponding solutions are expected\nto adapt to the qualitative behaviour of the membrane potential observed in\nexperiments better than in the standard case $\\alpha=1$.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 13:01:23 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Vitali", "Silvia", ""], ["Mainardi", "Francesco", ""]]}, {"id": "1702.05339", "submitter": "Silvia Vitali", "authors": "Silvia Vitali, Gastone Castellani, Francesco Mainardi", "title": "Time Fractional Cable Equation And Applications in Neurophysiology", "comments": "10 figures. arXiv admin note: substantial text overlap with\n  arXiv:1702.05325", "journal-ref": "Chaos, Solitons and Fractals (2017): Special Issue on Future\n  Directions in Fractional Calculus. Guest Editors: Mark M. Meerschaert, Bruce\n  J. West, Yong Zhou. Published on line 29 April 2017;", "doi": "10.1016/j.chaos.2017.04.043", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an extension of the cable equation by introducing a Caputo time\nfractional derivative. The fundamental solutions of the most common boundary\nproblems are derived analitically via Laplace Transform, and result be written\nin terms of known special functions. This generalization could be useful to\ndescribe anomalous diffusion phenomena with leakage as signal conduction in\nspiny dendrites. The presented solutions are computed in Matlab and plotted.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 13:50:54 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 14:29:19 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Vitali", "Silvia", ""], ["Castellani", "Gastone", ""], ["Mainardi", "Francesco", ""]]}, {"id": "1702.05394", "submitter": "Eero Satuvuori", "authors": "Eero Satuvuori, Mario Mulansky, Nebojsa Bozanic, Irene Malvestio,\n  Fleur Zeldenrust, Kerstin Lenk, Thomas Kreuz", "title": "Measures of spike train synchrony for data with multiple time-scales", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Measures of spike train synchrony are widely used in both\nexperimental and computational neuroscience. Time-scale independent and\nparameter-free measures, such as the ISI-distance, the SPIKE-distance and\nSPIKE-synchronization, are preferable to time-scale parametric measures, since\nby adapting to the local firing rate they take into account all the time-scales\nof a given dataset.\n  New Method: In data containing multiple time-scales (e.g. regular spiking and\nbursts) one is typically less interested in the smallest time-scales and a more\nadaptive approach is needed. Here we propose the A-ISI-distance, the\nA-SPIKE-distance and A-SPIKE-synchronization, which generalize the original\nmeasures by considering the local relative to the global time-scales. For the\nA-SPIKE-distance we also introduce a rate-independent extension called the\nRIA-SPIKE-distance, which focuses specifically on spike timing.\n  Results: The adaptive generalizations A-ISI-distance and A-SPIKE-distance\nallow to disregard spike time differences that are not relevant on a more\nglobal scale. A-SPIKE-synchronization does not any longer demand an\nunreasonably high accuracy for spike doublets and coinciding bursts. Finally,\nthe RIA-SPIKE-distance proves to be independent of rate ratios between spike\ntrains.\n  Comparison with Existing Methods: We find that compared to the original\nversions the A-ISI-distance and the A-SPIKE-distance yield improvements for\nspike trains containing different time-scales without exhibiting any unwanted\nside effects in other examples. A-SPIKE-synchronization matches spikes more\nefficiently than SPIKE-Synchronization.\n  Conclusions: With these proposals we have completed the picture, since we now\nprovide adaptive generalized measures that are sensitive to rate only\n(A-ISI-distance), to timing only (ARI-SPIKE-distance), and to both at the same\ntime (A-SPIKE-distance).\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 15:37:46 GMT"}, {"version": "v2", "created": "Tue, 30 May 2017 12:55:04 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Satuvuori", "Eero", ""], ["Mulansky", "Mario", ""], ["Bozanic", "Nebojsa", ""], ["Malvestio", "Irene", ""], ["Zeldenrust", "Fleur", ""], ["Lenk", "Kerstin", ""], ["Kreuz", "Thomas", ""]]}, {"id": "1702.05553", "submitter": "Serena Dipierro", "authors": "Serena Dipierro and Enrico Valdinoci", "title": "A simple mathematical model inspired by the Purkinje cells: from delayed\n  travelling waves to fractional diffusion", "comments": "Bull. Math. Biol", "journal-ref": null, "doi": "10.1007/s11538-018-0437-z", "report-no": null, "categories": "math.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, several experiments have demonstrated the existence of fractional\ndiffusion in the neuronal transmission occurringin the Purkinje cells, whose\nmalfunctioning is known to be related to the lack of voluntary coordination and\nthe appearance of tremors. Also, a classical mathematical feature is that\n(fractional) parabolic equations possess smoothing effects, in contrast with\nthe case of hyperbolic equations, which typically exhibit shocks and\ndiscontinuities. In this paper, we show how a simple toy-model of a highly\nramified structure, somehow inspired by that of the Purkinje cells, may produce\na fractional diffusion via the superposition of travelling waves that solve a\nhyperbolic equation. This could suggest that the high ramification of the\nPurkinje cells might have provided an evolutionary advantage of \"smoothing\" the\ntransmission of signals and avoiding shock propagations (at the price of\nslowing a bit such transmission). Although an experimental confirmation of the\npossibility of such evolutionary advantage goes well beyond the goals of this\npaper, we think that it is intriguing, as a mathematical counterpart, to\nconsider the time fractional diffusion as arising from the superposition of\ndelayed travelling waves in highly ramified transmission media. The case of a\ntravelling concave parabola with sufficiently small curvature is explicitly\ncomputed. The new link that we propose between time fractional diffusion and\nhyperbolic equation also provides a novelty with respect to the usual paradigm\nrelating time fractional diffusion with parabolic equations in the limit. This\npaper is written in such a way as to be of interest to both biologists and\nmathematician alike. In order to accomplish this aim, both complete\nexplanations of the objects considered and detailed lists of references are\nprovided.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 01:12:02 GMT"}, {"version": "v2", "created": "Sun, 29 Apr 2018 09:39:43 GMT"}], "update_date": "2018-05-01", "authors_parsed": [["Dipierro", "Serena", ""], ["Valdinoci", "Enrico", ""]]}, {"id": "1702.05620", "submitter": "Juan Biondi", "authors": "Gerardo Fern\\'andez, Juan Biondi, Silvia Castro, Osvaldo Agamennoni", "title": "Pupil size behavior during on line processing of sentences", "comments": "Journal of Integrative Neuroscience 2017", "journal-ref": null, "doi": "10.1142/S0219635216500266", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work we analyzed the pupil size behavior of forty subjects\nwhile they read well defined sentences with different contextual predictability\n(i.e., regular sentences and proverbs). In general, pupil size increased when\nreading regular sentences, but when readers realized that they were reading\nproverbs their pupils strongly increase until finishing proverbs' reading. Our\nresults suggest that an increased pupil size is not limited to cognitive load\n(i.e., relative difficulty in processing) because when participants accurately\nrecognized words during reading proverbs, theirs pupil size increased too. Our\nresults show that pupil size dynamics may be a reliable measure to investigate\nthe cognitive processes involved in sentence processing and memory functioning.\n", "versions": [{"version": "v1", "created": "Sat, 18 Feb 2017 15:03:58 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Fern\u00e1ndez", "Gerardo", ""], ["Biondi", "Juan", ""], ["Castro", "Silvia", ""], ["Agamennoni", "Osvaldo", ""]]}, {"id": "1702.05939", "submitter": "Andr\\'e Gr\\\"uning", "authors": "Joseph Chrol-Cannon and Yaochu Jin and Andr\\'e Gr\\\"uning", "title": "An Efficient Method for online Detection of Polychronous Patterns in\n  Spiking Neural Network", "comments": "17 pages, 8 figures", "journal-ref": null, "doi": "10.1016/j.neucom.2017.06.025", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polychronous neural groups are effective structures for the recognition of\nprecise spike-timing patterns but the detection method is an inefficient\nmulti-stage brute force process that works off-line on pre-recorded simulation\ndata. This work presents a new model of polychronous patterns that can capture\nprecise sequences of spikes directly in the neural simulation. In this scheme,\neach neuron is assigned a randomized code that is used to tag the post-synaptic\nneurons whenever a spike is transmitted. This creates a polychronous code that\npreserves the order of pre-synaptic activity and can be registered in a hash\ntable when the post-synaptic neuron spikes. A polychronous code is a\nsub-component of a polychronous group that will occur, along with others, when\nthe group is active. We demonstrate the representational and pattern\nrecognition ability of polychronous codes on a direction selective visual task\ninvolving moving bars that is typical of a computation performed by simple\ncells in the cortex. The computational efficiency of the proposed algorithm far\nexceeds existing polychronous group detection methods and is well suited for\nonline detection.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 12:02:50 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Chrol-Cannon", "Joseph", ""], ["Jin", "Yaochu", ""], ["Gr\u00fcning", "Andr\u00e9", ""]]}, {"id": "1702.06251", "submitter": "Jing Wu", "authors": "Jing Wu, Kaitlyn Casimo, David J. Caldwell, Rajesh P.N. Rao, Jeffrey\n  G. Ojemann", "title": "Electrocorticographic Dynamics Predict Visually Guided Motor Imagery of\n  Grasp Shaping", "comments": "4 pages, 6 figures, accepted to IEEE NER 2017 (8th International IEEE\n  EMBS Conference on Neural Engineering)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of intended movement type and movement phase of hand grasp\nshaping are critical features for the control of volitional neuroprosthetics.\nWe demonstrate that neural dynamics during visually-guided imagined grasp\nshaping can encode intended movement. We apply Procrustes analysis and LASSO\nregression to achieve 72% accuracy (chance = 25%) in distinguishing between\nvisually-guided imagined grasp trajectories. Further, we can predict the stage\nof grasp shaping in the form of elapsed time from start of trial (R2=0.4). Our\napproach contributes to more accurate single-trial decoding of higher-level\nmovement goals and the phase of grasping movements in individuals not trained\nwith brain-computer interfaces. We also find that the overall time-varying\ntrajectory structure of imagined movements tend to be consistent within\nindividuals, and that transient trajectory deviations within trials return to\nthe task-dependent trajectory mean. These overall findings may contribute to\nthe further understanding of the cortical dynamics of human motor imagery.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 03:19:37 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Wu", "Jing", ""], ["Casimo", "Kaitlyn", ""], ["Caldwell", "David J.", ""], ["Rao", "Rajesh P. N.", ""], ["Ojemann", "Jeffrey G.", ""]]}, {"id": "1702.06342", "submitter": "Peter Csermely", "authors": "Peter Csermely", "title": "Network support of talented people", "comments": null, "journal-ref": "Gifted Child Quarterly 61 (3): 194-201, 2017", "doi": "10.1177/0016986217701832", "report-no": null, "categories": "physics.soc-ph cs.CY cs.SI nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network support is a key success factor for talented people. As an example,\nthe Hungarian Talent Support Network involves close to 1500 Talent Points and\nmore than 200,000 people. This network started the Hungarian Templeton Program\nidentifying and helping 315 exceptional cognitive talents. This network is a\npart of the European Talent Support Network initiated by the European Council\nfor High Ability involving more than 300 organizations in over 30 countries in\nEurope and extending in other continents. These networks are giving good\nexamples that talented people often occupy a central, but highly dynamic\nposition in social networks. The involvement of such 'creative nodes' in\nnetwork-related decision making processes is vital, especially in novel\nenvironmental challenges. Such adaptive/learning responses characterize a large\nvariety of complex systems from proteins, through brains to society. It is\ncrucial for talent support programs to use these networking and learning\nprocesses to increase their efficiency further.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 11:57:31 GMT"}, {"version": "v2", "created": "Sat, 15 Apr 2017 10:24:05 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Csermely", "Peter", ""]]}, {"id": "1702.06405", "submitter": "David Caldwell", "authors": "David J. Caldwell, Jing Wu, Kaitlyn Casimo, Jeffrey G. Ojemann, Rajesh\n  P.N. Rao", "title": "Interactive Web Application for Exploring Matrices of Neural\n  Connectivity", "comments": "4 pages, IEEE NER 2017", "journal-ref": null, "doi": "10.1109/NER.2017.8008287", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here a browser-based application for visualizing patterns of\nconnectivity in 3D stacked data matrices with large numbers of pairwise\nrelations. Visualizing a connectivity matrix, looking for trends and patterns,\nand dynamically manipulating these values is a challenge for scientists from\ndiverse fields, including neuroscience and genomics. In particular,\nhigh-dimensional neural data include those acquired via electroencephalography\n(EEG), electrocorticography (ECoG), magnetoencephalography (MEG), and\nfunctional MRI. Neural connectivity data contains multivariate attributes for\neach edge between different brain regions, which motivated our lightweight,\nopen source, easy-to-use visualization tool for the exploration of these\nconnectivity matrices to highlight connections of interest. Here we present a\nclient-side, mobile-compatible visualization tool written entirely in\nHTML5/JavaScript that allows in-browser manipulation of user-defined files for\nexploration of brain connectivity. Visualizations can highlight different\naspects of the data simultaneously across different dimensions. Input files are\nin JSON format, and custom Python scripts have been written to parse MATLAB or\nPython data files into JSON-loadable format. We demonstrate the analysis of\nconnectivity data acquired via human ECoG recordings as a domain-specific\nimplementation of our application. We envision applications for this\ninteractive tool in fields seeking to visualize pairwise connectivity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 14:36:17 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Caldwell", "David J.", ""], ["Wu", "Jing", ""], ["Casimo", "Kaitlyn", ""], ["Ojemann", "Jeffrey G.", ""], ["Rao", "Rajesh P. N.", ""]]}, {"id": "1702.06463", "submitter": "Aditya Gilra", "authors": "Aditya Gilra, Wulfram Gerstner", "title": "Predicting non-linear dynamics by stable local learning in a recurrent\n  spiking neural network", "comments": null, "journal-ref": "eLife 2017;6:e28295", "doi": "10.7554/eLife.28295", "report-no": null, "categories": "q-bio.NC cs.LG cs.NE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brains need to predict how the body reacts to motor commands. It is an open\nquestion how networks of spiking neurons can learn to reproduce the non-linear\nbody dynamics caused by motor commands, using local, online and stable learning\nrules. Here, we present a supervised learning scheme for the feedforward and\nrecurrent connections in a network of heterogeneous spiking neurons. The error\nin the output is fed back through fixed random connections with a negative\ngain, causing the network to follow the desired dynamics, while an online and\nlocal rule changes the weights. The rule for Feedback-based Online Local\nLearning Of Weights (FOLLOW) is local in the sense that weight changes depend\non the presynaptic activity and the error signal projected onto the\npostsynaptic neuron. We provide examples of learning linear, non-linear and\nchaotic dynamics, as well as the dynamics of a two-link arm. Using the Lyapunov\nmethod, and under reasonable assumptions and approximations, we show that\nFOLLOW learning is stable uniformly, with the error going to zero\nasymptotically.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 16:15:34 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 17:58:00 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Gilra", "Aditya", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1702.06513", "submitter": "Andrew Sornborger", "authors": "Zhuocheng Xiao, Jiwei Zhang, Andrew T. Sornborger, Louis Tao", "title": "Cusps Enable Line Attractors for Neural Computation", "comments": "7 pages, 5 figures", "journal-ref": "Phys. Rev. E 96, 052308 (2017)", "doi": "10.1103/PhysRevE.96.052308", "report-no": "LA-UR-17-28766", "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Line attractors in neuronal networks have been suggested to be the basis of\nmany brain functions, such as working memory, oculomotor control, head\nmovement, locomotion, and sensory processing. In this paper, we make the\nconnection between line attractors and pulse-gating in feedforward neuronal\nnetworks. In this context, because of their neutral stability along a\none-dimensional manifold, line attractors are associated with a\ntime-translational invariance that allows graded information to be propagated\nfrom one neuronal population to the next. To understand how pulse-gating\nmanifests itself in a high-dimensional, non-linear, feedforward\nintegrate-and-fire network, we use a Fokker-Planck approach to analyze system\ndynamics. We make a connection between pulse-gated propagation in the\nFokker-Planck and population-averaged mean-field (firing rate) models, then\nidentify an approximate line attractor in state space as the essential\nstructure underlying graded information propagation. An analysis of the line\nattractor shows that it consists of three fixed points: a central saddle with\nan unstable manifold along the line and stable manifolds orthogonal to the\nline, which is surrounded on either side by stable fixed points. Along the\nmanifold defined by the fixed points, slow dynamics give rise to a ghost. We\nshow that this line attractor arises at a cusp catastrophe, where a fold\nbifurcation develops as a function of synaptic noise; and that the ghost\ndynamics near the fold of the cusp underly the robustness of the line\nattractor. Understanding the dynamical aspects of this cusp catastrophe allows\nus to show how line attractors can persist in biologically realistic neuronal\nnetworks and how the interplay of pulse gating, synaptic coupling and neuronal\nstochasticity can be used to enable attracting one-dimensional manifolds and\nthus, dynamically control the processing of graded information.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 18:32:52 GMT"}, {"version": "v2", "created": "Mon, 2 Oct 2017 15:35:52 GMT"}, {"version": "v3", "created": "Tue, 3 Oct 2017 20:51:29 GMT"}, {"version": "v4", "created": "Wed, 29 Nov 2017 16:39:04 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Xiao", "Zhuocheng", ""], ["Zhang", "Jiwei", ""], ["Sornborger", "Andrew T.", ""], ["Tao", "Louis", ""]]}, {"id": "1702.06538", "submitter": "Caitlyn Parmelee", "authors": "Caitlyn M. Parmelee", "title": "Applications of Discrete Mathematics for Understanding Dynamics of\n  Synapses and Networks in Neuroscience", "comments": "PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical modeling has broad applications in neuroscience whether modeling\nthe dynamics of a single synapse or an entire network of neurons. In Part I, we\nmodel vesicle replenishment and release at the photoreceptor synapse to better\nunderstand how visual information is processed. In Part II, we explore a simple\nmodel of neural networks with the goal of discovering how network structure\nshapes the behavior of the network.\n  To fully understand how visual information is processed requires an\nunderstanding of the way signals are transformed at the ribbon synapse of\nphotoreceptor neurons. These synapses possess a ribbon-like structure capable\nof storing around 100 synaptic vesicles, allowing graded responses through the\nrelease of different numbers of vesicles in response to visual input. These\nresponses depend critically on the ability of the ribbon to replenish itself as\nribbon sites empty upon release. The rate of vesicle replenishment is thus an\nimportant factor in shaping neural coding in the retina. In collaboration with\nexperimental neuroscientists we developed a mathematical model to describe the\ndynamics of vesicle release and replenishment at the ribbon synapse.\n  To learn more about how network architecture shapes the dynamics of the\nnetwork, we study a specific type of threshold-linear network that is\nconstructed from a simple directed graph. The network construction guarantees\nthat differences in dynamics arise solely from differences in the connectivity\nof the underlying graph. By design, the activity of these networks is bounded\nand there are no stable fixed points. Computational experiments show that most\nof these networks yield limit cycles where the neurons fire in sequence. We\ndevised an algorithm to predict the sequence of firing using the structure of\nthe underlying graph. Using the algorithm we classify all the networks of this\ntype on five or fewer nodes.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 18:38:58 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Parmelee", "Caitlyn M.", ""]]}, {"id": "1702.06665", "submitter": "Michael Beyeler", "authors": "Michael Beyeler and Nikil Dutt and Jeffrey L. Krichmar", "title": "Visual response properties of MSTd emerge from a sparse population code", "comments": null, "journal-ref": null, "doi": "10.1523/JNEUROSCI.0396-16.2016", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the dorsal subregion of the medial superior temporal (MSTd) area\nrespond to large, complex patterns of retinal flow, implying a role in the\nanalysis of self-motion. Some neurons are selective for the expanding radial\nmotion that occurs as an observer moves through the environment (\"heading\"),\nand computational models can account for this finding. However, ample evidence\nsuggests that MSTd neurons may exhibit a continuum of visual response\nselectivity to large-field motion stimuli, but the underlying computational\nprinciples by which these response properties are derived remain poorly\nunderstood. Here we describe a computational model of MSTd based on the\nhypothesis that neurons in MSTd efficiently encode the continuum of large-field\nretinal flow patterns on the basis of inputs received from neurons in MT, with\nreceptive fields that resemble basis vectors recovered with nonnegative matrix\nfactorization (NMF). These assumptions are sufficient to quantitatively\nsimulate neurophysiological response properties of MSTd cells such as radial,\ncircular, and spiral motion tuning, suggesting that these properties might\nsimply be a by-product of MSTd neurons performing dimensionality reduction on\ntheir inputs. At the population level, model MSTd accurately predicts heading\nusing a sparse distributed code, consistent with the idea that biological MSTd\nmight operate in a sparseness regime well-suited to efficiently encode a number\nof self-motion variables. The present work provides an alternative to the\ntemplate-model view of MSTd, and offers a biologically plausible account of the\nreceptive field structure across a wide range of visual response properties in\nMSTd.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 03:41:02 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Beyeler", "Michael", ""], ["Dutt", "Nikil", ""], ["Krichmar", "Jeffrey L.", ""]]}, {"id": "1702.06831", "submitter": "Matej Mihel\\v{c}i\\'c", "authors": "Matej Mihel\\v{c}i\\'c, Goran \\v{S}imi\\'c, Mirjana Babi\\'c Leko, Nada\n  Lavra\\v{c}, Sa\\v{s}o D\\v{z}eroski, Tomislav \\v{S}muc", "title": "Using Redescription Mining to Relate Clinical and Biological\n  Characteristics of Cognitively Impaired and Alzheimer's Disease Patients", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0187364", "report-no": null, "categories": "q-bio.QM cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We used redescription mining to find interpretable rules revealing\nassociations between those determinants that provide insights about the\nAlzheimer's disease (AD). We extended the CLUS-RM redescription mining\nalgorithm to a constraint-based redescription mining (CBRM) setting, which\nenables several modes of targeted exploration of specific, user-constrained\nassociations. Redescription mining enabled finding specific constructs of\nclinical and biological attributes that describe many groups of subjects of\ndifferent size, homogeneity and levels of cognitive impairment. We confirmed\nsome previously known findings. However, in some instances, as with the\nattributes: testosterone, the imaging attribute Spatial Pattern of\nAbnormalities for Recognition of Early AD, as well as the levels of leptin and\nangiopoietin-2 in plasma, we corroborated previously debatable findings or\nprovided additional information about these variables and their association\nwith AD pathogenesis. Applying redescription mining on ADNI data resulted with\nthe discovery of one largely unknown attribute: the Pregnancy-Associated\nProtein-A (PAPP-A), which we found highly associated with cognitive impairment\nin AD. Statistically significant correlations (p <= 0.01) were found between\nPAPP-A and various different clinical tests. The high importance of this\nfinding lies in the fact that PAPP-A is a metalloproteinase, known to cleave\ninsulin-like growth factor binding proteins. Since it also shares similar\nsubstrates with A Disintegrin and the Metalloproteinase family of enzymes that\nact as {\\alpha}-secretase to physiologically cleave amyloid precursor protein\n(APP) in the non-amyloidogenic pathway, it could be directly involved in the\nmetabolism of APP very early during the disease course. Therefore, further\nstudies should investigate the role of PAPP-A in the development of AD more\nthoroughly.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 09:56:34 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 18:15:52 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Mihel\u010di\u0107", "Matej", ""], ["\u0160imi\u0107", "Goran", ""], ["Leko", "Mirjana Babi\u0107", ""], ["Lavra\u010d", "Nada", ""], ["D\u017eeroski", "Sa\u0161o", ""], ["\u0160muc", "Tomislav", ""]]}, {"id": "1702.06907", "submitter": "Zvi Rosen", "authors": "Zvi Rosen and Yan X. Zhang", "title": "Convex Neural Codes in Dimension 1", "comments": "21 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural codes are collections of binary strings motivated by patterns of\nneural activity. In this paper, we study algorithmic and enumerative aspects of\nconvex neural codes in dimension 1 (i.e. on a line or a circle). We use the\ntheory of consecutive-ones matrices to obtain some structural and algorithmic\nresults; we use generating functions to obtain enumerative results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 17:34:16 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Rosen", "Zvi", ""], ["Zhang", "Yan X.", ""]]}, {"id": "1702.07038", "submitter": "Isabel Gauthier Isabel Gauthier", "authors": "Isabel Gauthier", "title": "The Quest for the FFA led to the Expertise Account of its Specialization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is written in response to a Progressions article by Kanwisher in\nthe Journal of Neuroscience, The Quest for the FFA and Where It Led (Kanwisher,\n2017). I reflect on the extensive research program dedicated to the study of\nhow and why perceptual expertise explains the many ways that faces are special,\na research program which both predates and follows the Kanwisher (1997)\nlandmark article where the fusiform face area (FFA) is named. The expertise\naccounts suggests that the FFA is an area recruited by expertise individuating\nobjects that are perceptually similar because they share a configuration of\nparts. While Kanwisher (2017) discussed the expertise account only very briefly\nand only to dismiss it, there is strong and replicable evidence that responses\nin the FFA are highly sensitive to experience with non-face objects. I point\nout that Kanwisher was well positioned to present these findings in their\nhistorical context as she participated in the design of the first fMRI study on\ncar and bird expertise, as well as the first replication of this finding.\nPerhaps most relevant to readers interested in the neural bases of face\nprocessing, it is important to distinguish studies that describe the phenomenon\nof face-selectivity from those that test an explanation for this phenomenon. In\nthe Progressions article, arguments for a face-dedicated processing module that\nis not the result of our experience with faces are provided without attention\nto a great deal of expertise research which is directly inconsistent with that\nclaim. The claim also lacks more direct support, as face-selective responses in\nthe visual system are not found in infants and children and face-selective\nactivity in FFA does not appear to be heritable.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 23:11:00 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Gauthier", "Isabel", ""]]}, {"id": "1702.07227", "submitter": "Bruno Burlando Prof", "authors": "Bruno Burlando", "title": "The knowledge paradox: why knowing more is knowing less", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide an explanation of the evolution of scientific knowledge, I start\nfrom the assumption that knowledge is based on concepts, and propose that each\nconcept about reality is affected by vagueness. This entails a paradox, which I\nterm Knowledge Paradox (KP): i.e. we need concepts to acquire knowledge about\nthe real world but each concept is a step away from reality. The KP provides a\nunifying context for the sorites and the liar paradoxes. Any concept is viewed\nas a sorites, i.e. it is impossible to set a boundary between what is, and what\nis not, the entity to which the concept refers. Hence, any statement about\nreality can be reduced to a liar, wherefrom the KP follows in its most general\nform: -If I know, then I do not know-. The KP is self-referential but not\ncontradictory, as it can be referred to two levels of knowledge: -if I\nknow(epistemic), then I do not know(ontic)-, where the ontic level is made\nunachievable by concept vagueness. Such an interpretation of scientific\nknowledge provides an understanding of its dynamics. Concept proliferation\nwithin theories produces periods of knowledge decay that are episodically\nreversed by the formulation of new theories based on a smaller number of\nsynthetic concepts.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 10:33:03 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Burlando", "Bruno", ""]]}, {"id": "1702.07319", "submitter": "John Pearson", "authors": "Shariq Iqbal and John Pearson", "title": "A Goal-Based Movement Model for Continuous Multi-Agent Tasks", "comments": "New title; substantial simplifications of model", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite increasing attention paid to the need for fast, scalable methods to\nanalyze next-generation neuroscience data, comparatively little attention has\nbeen paid to the development of similar methods for behavioral analysis. Just\nas the volume and complexity of brain data have grown, behavioral paradigms in\nsystems neuroscience have likewise become more naturalistic and less\nconstrained, necessitating an increase in the flexibility and scalability of\nthe models used to study them. In particular, key assumptions made in the\nanalysis of typical decision paradigms --- optimality; analytic tractability;\ndiscrete, low-dimensional action spaces --- may be untenable in richer tasks.\nHere, using the case of a two-player, real-time, continuous strategic game as\nan example, we show how the use of modern machine learning methods allows us to\nrelax each of these assumptions. Following an inverse reinforcement learning\napproach, we are able to succinctly characterize the joint distribution over\nplayers' actions via a generative model that allows us to simulate realistic\ngame play. We compare simulated play from a number of generative time series\nmodels and show that ours successfully resists mode collapse while generating\ntrajectories with the rich variability of real behavior. Together, these\nmethods offer a rich class of models for the analysis of continuous action\ntasks at the single-trial level.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 18:09:14 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 20:14:11 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Iqbal", "Shariq", ""], ["Pearson", "John", ""]]}, {"id": "1702.07368", "submitter": "Benjamin Lansdell", "authors": "Benjamin Lansdell, Ivana Milovanovic, Cooper Mellema, Eberhard E Fetz,\n  Adrienne L Fairhall, Chet T Moritz", "title": "Reconfiguring motor circuits for a joint manual and BCI task", "comments": "17 pages, 5 figures, 2 supplementary figures. Minor revisions", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing brain-computer interfaces (BCIs) that can be used in conjunction\nwith ongoing motor behavior requires an understanding of how neural activity\nco-opted for brain control interacts with existing neural circuits. For\nexample, BCIs may be used to regain lost motor function after stroke. This\nrequires that neural activity controlling unaffected limbs is dissociated from\nactivity controlling the BCI. In this study we investigated how primary motor\ncortex accomplishes simultaneous BCI control and motor control in a task that\nexplicitly required both activities to be driven from the same brain region\n(i.e. a dual-control task). Single-unit activity was recorded from\nintracortical, multi-electrode arrays while a non-human primate performed this\ndual-control task. Compared to activity observed during naturalistic motor\ncontrol, we found that both units used to drive the BCI directly (control\nunits) and units that did not directly control the BCI (non-control units)\nsignificantly changed their tuning to wrist torque. Using a measure of\neffective connectivity, we observed that control units decrease their\nconnectivity. Through an analysis of variance we found that the intrinsic\nvariability of the control units has a significant effect on task proficiency.\nWhen this variance is accounted for, motor cortical activity is flexible enough\nto perform novel BCI tasks that require active decoupling of natural\nassociations to wrist motion. This study provides insight into the neural\nactivity that enables a dual-control brain-computer interface.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 19:13:00 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 15:09:07 GMT"}, {"version": "v3", "created": "Thu, 12 Sep 2019 15:34:54 GMT"}], "update_date": "2019-09-13", "authors_parsed": [["Lansdell", "Benjamin", ""], ["Milovanovic", "Ivana", ""], ["Mellema", "Cooper", ""], ["Fetz", "Eberhard E", ""], ["Fairhall", "Adrienne L", ""], ["Moritz", "Chet T", ""]]}, {"id": "1702.07426", "submitter": "Ramin M. Hasani", "authors": "Ramin M. Hasani, Giorgio Ferrari, Hideaki Yamamoto, Sho Kono, Koji\n  Ishihara, Soya Fujimori, Takashi Tanii and Enrico Prati", "title": "Control of the Correlation of Spontaneous Neuron Activity in Biological\n  and Noise-activated CMOS Artificial Neural Microcircuits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several indications that brain is organized not on a basis of\nindividual unreliable neurons, but on a micro-circuital scale providing Lego\nblocks employed to create complex architectures. At such an intermediate scale,\nthe firing activity in the microcircuits is governed by collective effects\nemerging by the background noise soliciting spontaneous firing, the degree of\nmutual connections between the neurons, and the topology of the connections. We\ncompare spontaneous firing activity of small populations of neurons adhering to\nan engineered scaffold with simulations of biologically plausible CMOS\nartificial neuron populations whose spontaneous activity is ignited by tailored\nbackground noise. We provide a full set of flexible and low-power consuming\nsilicon blocks including neurons, excitatory and inhibitory synapses, and both\nwhite and pink noise generators for spontaneous firing activation. We achieve a\ncomparable degree of correlation of the firing activity of the biological\nneurons by controlling the kind and the number of connection among the silicon\nneurons. The correlation between groups of neurons, organized as a ring of four\ndistinct populations connected by the equivalent of interneurons, is triggered\nmore effectively by adding multiple synapses to the connections than increasing\nthe number of independent point-to-point connections. The comparison between\nthe biological and the artificial systems suggests that a considerable number\nof synapses is active also in biological populations adhering to engineered\nscaffolds.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 00:09:40 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Hasani", "Ramin M.", ""], ["Ferrari", "Giorgio", ""], ["Yamamoto", "Hideaki", ""], ["Kono", "Sho", ""], ["Ishihara", "Koji", ""], ["Fujimori", "Soya", ""], ["Tanii", "Takashi", ""], ["Prati", "Enrico", ""]]}, {"id": "1702.07649", "submitter": "Quinton Skilling", "authors": "Quinton M Skilling, Daniel Maruyama, Nicolette Ognjanovski, Sara J\n  Aton, and Michal Zochowski", "title": "Criticality, stability, competition, and consolidation of new\n  representations in brain networks", "comments": "6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain forms and stores distributed representations from sparse external\ninput that compete for neuronal resources with already stored memory traces. It\nis unclear what dynamical properties of neural systems allow formation and\nsubsequent consolidation of new, distributed memory representations under these\nconditions. Here we use analytical, computational, and experimental approaches\nto show that a dynamical regime near a phase-transition in neuronal network\nactivity (i.e. criticality) may play an important role in this process. Our\nresults reveal that near-critical dynamics are necessary to stabilize and store\nnew sparsely driven representations when they compete with native network\nstates.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 16:30:54 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 17:47:23 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Skilling", "Quinton M", ""], ["Maruyama", "Daniel", ""], ["Ognjanovski", "Nicolette", ""], ["Aton", "Sara J", ""], ["Zochowski", "Michal", ""]]}, {"id": "1702.07734", "submitter": "Souparno Roy", "authors": "Souparno Roy, Archi Banerjee, Ranjan Sengupta, Dipak Ghosh", "title": "Ambiguity invokes Creativity : looking through Quantum physics", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creativity, defined as the tendency to generate or recognize new ideas or\nalternatives and to make connections between seemingly unrelated phenomena, is\ntoo vast a horizon to be summed up in such a simple sentence. The extreme\nabstractness of creativity makes it harder to quantify in its entirety. Yet, a\nlot of efforts have been made both by psychologists and neurobiologists to\nidentify its signature. A general conformity is expressed in the Free\nassociation theory, i.e. the more freely a persons conceptual nodes are\nconnected, the more divergent thinker (also, creative) he or she is. Also,\ntolerance of ambiguity is found to be related to divergent thinking. In this\nstudy, we approach the problem of creativity from a theoretical physics\nstandpoint. Theoretically, for the initial conceptual state, the next jump to\nany other node is equally probable and non-deterministic. Repeated intervention\nof external stimulus (analogous to a measurement) is responsible for such\njumps. And to study such a non-deterministic system with continuous\nmeasurements, Quantum theory has been proven the most successful, time and\nagain. We suggest that this collection of nodes form a system which is likely\nto be governed by quantum physics and specify the transformations which could\nhelp explain the conceptual jump between states. Our argument, from the point\nof view of physics is that the initial evolution of the creative process is\nidentical, person or field independent. To answer the next obvious question\nabout individual creativity, we hypothesize that the quantum system, under\ncontinuous measurements (in the form of external stimuli) evolves with chaotic\ndynamics, hence separating a painter from a musician. Possible experimental\nmethodology of these effects has also been suggested using ambiguous figures.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 13:04:16 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Roy", "Souparno", ""], ["Banerjee", "Archi", ""], ["Sengupta", "Ranjan", ""], ["Ghosh", "Dipak", ""]]}, {"id": "1702.08421", "submitter": "Ines Samengo Dr.", "authors": "Ines Samengo", "title": "The role of the observer in goal-directed behavior", "comments": "11 pages, 5 figures. Essay submitted to FQXi", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In goal-directed behavior, a large number of possible initial states end up\nin the pursued goal. The accompanying information loss implies that\ngoal-oriented behavior is in one-to-one correspondence with an open subsystem\nwhose entropy decreases in time. Yet ultimately, the laws of physics are\nreversible, so systems capable of yielding goal-directed behavior must transfer\nthe information about initial conditions to other degrees of freedom outside\nthe boundaries of the agent. To operate steadily, they must consume ordered\ndegrees of freedom provided as input, and be dispensed of disordered outputs\nthat act as wastes from the point of view of the aimed objective. Here I argue\nthat a physical system may or may not display goal-directed behavior depending\non what exactly is defined as the agent. The borders of the agent must be\ncarefully tailored so as to entail the appropriate information balance sheet.\nIn this game, observers play the role of tailors: They design agents by setting\nthe limits of the system of interest. Brain-guided subjects perform this\ncreative observation task naturally, implying that the observation of\ngoal-oriented behavior is a goal-oriented behavior in itself. Minds evolved to\ncut out pieces of reality and endow them with intentionality, because ascribing\nintentionality is an efficient way of modeling the world, and making\npredictions. One most remarkable agent of whom we have indisputable evidence of\nits goal-pursuing attitude is the self. Notably, this agent is simultaneously\nthe subject and the object of observation.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 18:27:48 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Samengo", "Ines", ""]]}, {"id": "1702.08509", "submitter": "Yonghong Chen", "authors": "YongHong Chen", "title": "The Main Cognitive Model of Visual Recognition: Contour Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we will study the following pattern recognition problem: Every\npattern is a 3-dimensional graph, its surface can be split up into some\nregions, every region is composed of the pixels with the approximately same\ncolour value and the approximately same depth value that is distance to eyes,\nand there may also be some contours, e.g., literal contours, on a surface of\nevery pattern. For this problem we reveal the inherent laws. Moreover, we\nestablish a cognitive model to reflect the essential characteristics of the\nrecognition of this type of patterns. In [1], a coarser model or a basicer one\nis described. In this paper, some important errors are revised, some key things\nare added, at last, a complete model is described.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 02:28:25 GMT"}, {"version": "v2", "created": "Sat, 4 Mar 2017 05:37:20 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Chen", "YongHong", ""]]}, {"id": "1702.08606", "submitter": "Yuncong Chen", "authors": "Yuncong Chen, Lauren McElvain, Alex Tolpygo, Daniel Ferrante, Harvey\n  Karten, Partha Mitra, David Kleinfeld, Yoav Freund", "title": "The Active Atlas: Combining 3D Anatomical Models with Texture Detectors", "comments": "8 pages, 10 figures, appeared in proceeding of MICCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern imaging technologies such as fMRI have opened exciting new\npossibilities for studying the brain in vivo, histological sections remain the\nbest way to study the anatomy of the brain at the level of single neurons. The\nhistological atlas changed little since 1909 and localizing brain regions is a\nstill a labor intensive process performed only by experienced neuro-anatomists.\nExisting digital atlases such as the Allen Brain atlas are limited to low\nresolution images which cannot identify the detailed structure of the neurons.\nWe have developed a digital atlas methodology that combines information about\nthe 3D organization of the brain and the detailed texture of neurons in\ndifferent structures. Using the methodology we developed an atlas for the mouse\nbrainstem and mid-brain, two regions for which there are currently no good\natlases. Our atlas is \"active\" in that it can be used to automatically align a\nhistological stack to the atlas, thus reducing the work of the neuroanatomist.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 02:18:47 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 23:55:35 GMT"}, {"version": "v3", "created": "Mon, 15 Jan 2018 18:33:24 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Chen", "Yuncong", ""], ["McElvain", "Lauren", ""], ["Tolpygo", "Alex", ""], ["Ferrante", "Daniel", ""], ["Karten", "Harvey", ""], ["Mitra", "Partha", ""], ["Kleinfeld", "David", ""], ["Freund", "Yoav", ""]]}, {"id": "1702.08617", "submitter": "Kun-Han Lu", "authors": "Kun-Han Lu, Jun Young Jeong, Haiguang Wen, Zhongming Liu", "title": "Spontaneous Activity in the Visual Cortex is Organized by Visual Streams", "comments": "33 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale functional networks have been extensively studied using resting\nstate functional magnetic resonance imaging. However, the pattern,\norganization, and function of fine-scale network activity remain largely\nunknown. Here we characterized the spontaneously emerging visual cortical\nactivity by applying independent component analysis to resting state fMRI\nsignals exclusively within the visual cortex. In this sub-system scale, we\nobserved about 50 spatially independent components that were reproducible\nwithin and across subjects, and analyzed their spatial patterns and temporal\nrelationships to reveal the intrinsic parcellation and organization of the\nvisual cortex. We found that the visual cortical parcels were aligned with the\nsteepest gradient of cortical myelination, and organized into functional\nmodules segregated along the dorsal/ventral pathways and foveal/peripheral\nearly visual areas. In contrast, cortical retinotopy, folding, and\ncytoarchitecture impose limited constraints to the organization of resting\nstate activity. From these findings, we conclude that spontaneous activity\npatterns in the visual cortex are primarily organized by visual streams, likely\nreflecting feedback network interactions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 03:03:40 GMT"}], "update_date": "2017-03-01", "authors_parsed": [["Lu", "Kun-Han", ""], ["Jeong", "Jun Young", ""], ["Wen", "Haiguang", ""], ["Liu", "Zhongming", ""]]}]