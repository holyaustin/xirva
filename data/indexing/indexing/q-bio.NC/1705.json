[{"id": "1705.00063", "submitter": "Richard Granger", "authors": "Ashok Chandrashekar, Richard Granger", "title": "Derivation of a novel efficient supervised learning algorithm from\n  cortical-subcortical loops", "comments": null, "journal-ref": "Frontiers in Computational Neuroscience, 5 (2012)", "doi": "10.3389/fncom.2011.00050", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although brain circuits presumably carry out useful perceptual algorithms,\nfew instances of derived biological methods have been found to compete\nfavorably against algorithms that have been engineered for specific\napplications. We forward a novel analysis of function of cortico-striatal\nloops, which constitute more than 80% of the human brain, thus likely\nunderlying a broad range of cognitive functions. We describe a family of\noperations performed by the derived method, including a nonstandard method for\nsupervised classification, which may underlie some forms of\ncortically-dependent associative learning. The novel supervised classifier is\ncompared against widely-used algorithms for classification, including support\nvector machines (SVM) and k-nearest neighbor methods, achieving corresponding\nclassification rates --- at a fraction of the time and space costs. This\nrepresents an instance of a biologically-derived algorithm comparing favorably\nagainst widely used machine learning methods on well-studied tasks.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 20:15:45 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Chandrashekar", "Ashok", ""], ["Granger", "Richard", ""]]}, {"id": "1705.00096", "submitter": "Catherine Reason", "authors": "Cathy M Reason", "title": "Consciousness is not a physically provable property", "comments": null, "journal-ref": "Journal of Mind and Behavior 37 (1) pp 31-46 (2016)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a logical proof that computing machines, and by extension physical\nsystems, can never be certain if they possess conscious awareness. This implies\nthat human consciousness is associated with a violation of energy conservation.\nWe examine the significance that a particular interpretation of quantum\nmechanics, known as single mind Q (Barrett 1999), might have for the detection\nof such a violation. Finally we apply single mind Q to the problem of free will\nas it arises in some celebrated experiments by the neurophysiologist Benjamin\nLibet.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 23:21:45 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 15:49:06 GMT"}], "update_date": "2017-09-27", "authors_parsed": [["Reason", "Cathy M", ""]]}, {"id": "1705.00107", "submitter": "Liane Gabora", "authors": "Liane Gabora and Simon Tseng", "title": "The Social Benefits of Balancing Creativity and Imitation: Evidence from\n  an Agent-based Model", "comments": "58 pages, 2 tables, 12 figures; Accepted for publication in\n  Psychology of Aesthetics, Creativity, and the Arts. arXiv admin note: text\n  overlap with arXiv:1408.2512", "journal-ref": "Psychology of Aesthetics, Creativity, and the Arts, Vol 11(4), Nov\n  2017, 403-419", "doi": "10.1037/aca0000132", "report-no": null, "categories": "cs.MA cs.SI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although creativity is encouraged in the abstract it is often discouraged in\neducational and workplace settings. Using an agent-based model of cultural\nevolution, we investigated the idea that tempering the novelty-generating\neffects of creativity with the novelty-preserving effects of imitation is\nbeneficial for society. In Experiment One we systematically introduced\nindividual differences in creativity, and observed a trade-off between the\nratio of creators to imitators, and how creative the creators were. Excess\ncreativity was detrimental because creators invested in unproven ideas at the\nexpense of propagating proven ones. Experiment Two tested the hypothesis that\nsociety as a whole benefits if individuals adjust how creative they are in\naccordance with their creative success. When effective creators created more,\nand ineffective creators created less (social regulation), the agents\nsegregated into creators and imitators, and the mean fitness of outputs was\ntemporarily higher. We hypothesized that the temporary nature of the effect was\ndue to a ceiling on output fitness. In Experiment Three we made the space of\npossible outputs open-ended by giving agents the capacity to chain simple\noutputs into arbitrarily complex ones such that fitter outputs were always\npossible. With the capacity for chained outputs, the effect of social\nregulation could indeed be maintained indefinitely. The results are discussed\nin light of empirical data.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 01:09:18 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Gabora", "Liane", ""], ["Tseng", "Simon", ""]]}, {"id": "1705.00228", "submitter": "Sayan Nag", "authors": "Sourya Sengupta, Sayan Biswas, Sayan Nag, Shankha Sanyal, Archi\n  Banerjee, Ranjan Sengupta and Dipak Ghosh", "title": "Emotion Specification from Musical Stimuli: An EEG Study with AFA and\n  DFA", "comments": "5 pages, 9 figures, Presented in 4th International Conference on\n  Signal Processing and Integrated Networks (SPIN) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present study reports interesting findings in regard to emotional arousal\nbased activities while listening to two Hindustani classical ragas of contrast\nemotion. EEG data was taken on 5 naive listeners while they listened to two\nragas Bahar and Mia ki Malhar which are conventionally known to portray\ncontrast emotions. The EEG data were analyzed with the help of two robust non\nlinear tools viz. Adaptive Fractal Analysis (AFA) and Detrended Fluctuation\nAnalysis (DFA). A comparative study of the Hurst Exponents obtained from the\ntwo methods have been shown which shows that DFA provides more rigorous results\ncompared to AFA when it comes to the scaling analysis of biosignal data. The\nresults and implications have been discussed in detail.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 19:05:52 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Sengupta", "Sourya", ""], ["Biswas", "Sayan", ""], ["Nag", "Sayan", ""], ["Sanyal", "Shankha", ""], ["Banerjee", "Archi", ""], ["Sengupta", "Ranjan", ""], ["Ghosh", "Dipak", ""]]}, {"id": "1705.00550", "submitter": "Jacek Bialowas", "authors": "Jacek Bialowas", "title": "Topography of the nuclei and distribution of Acetylcholinesterase\n  activity in the septum of the telencephalon in man", "comments": "12 pages, 4 figures", "journal-ref": "Folia Morphol. (Warsz.), 1976, 35, 4, 405-412", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distribution of acetylcholinesterase (AChE) activity in the septum of the\ntelencephalon in man was studied in 15 human brains using the acetylthiocholine\nmethod. Highest activity of AChE was found in the nucleus of the diagonal band\nand nucleus accumbens, and lowest in the Lateral nucleus. Comparison of\nhistochemical results with cellular structure and wi.th the course of fibers\nshowed absence in man of some of the nuclei described in animals such as the\nanterior medial nucleus, triangular nucleus, and marked reduction of the\nsepto-hippocampal nucleus and fimbriate nucleus. Areas of the septum showing\nAChE activity were divided into an anterior and posterior system. The\napplicability to man of some neurophysiologic findings in animals is discussed.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 14:50:52 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Bialowas", "Jacek", ""]]}, {"id": "1705.00735", "submitter": "Shao-Qing Zhang", "authors": "Shao-Qing Zhang", "title": "A Proposal for an Electron-Transfer Mechanism of Avian Magnetoreception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of many years of research, the mechanism of avian magnetoreception\nremains a mystery due to its seemingly insurmountable intricacies. Recently Xie\nand colleagues proposed that IscA1 can act as a protein biocompass due to the\nmeasured intrinsic ferromagneticity, and thus named it MagR. However, Meister's\ncalculations showed that the interaction energy of the magnetic moment of IscA1\nwith Earth's magnetic field is five magnitudes smaller than thermal fluctuation\nat room temperature. The other long-proposed compass protein is cryptochrome\n(Cry) with a mechanism of forming singlet-triplet radical pairs. However, this\nsensory mechanism still has no inferable information transmission routes. We\npropose a magnetoreception mechanism involving both the Cry and IscA1 proteins,\nthrough which photoinduced electrons are transported to redox-regulated ion\nchannels to provoke neuronal responses. The structural features of the\nCry-IscA1 complex that make it suitable for long-range electron transfer are\ndiscussed and how the magnetic effect leads to neuronal activity is described.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 22:55:21 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Zhang", "Shao-Qing", ""]]}, {"id": "1705.00816", "submitter": "Panqu Wang", "authors": "Panqu Wang, Garrison W. Cottrell", "title": "Central and peripheral vision for scene recognition: A\n  neurocomputational modeling exploration", "comments": "http://jov.arvojournals.org/Article.aspx?articleid=2623232", "journal-ref": "Journal of Vision April 2017, Vol.17, 9", "doi": "10.1167/17.4.9", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  What are the roles of central and peripheral vision in human scene\nrecognition? Larson and Loschky (2009) showed that peripheral vision\ncontributes more than central vision in obtaining maximum scene recognition\naccuracy. However, central vision is more efficient for scene recognition than\nperipheral, based on the amount of visual area needed for accurate recognition.\nIn this study, we model and explain the results of Larson and Loschky (2009)\nusing a neurocomputational modeling approach. We show that the advantage of\nperipheral vision in scene recognition, as well as the efficiency advantage for\ncentral vision, can be replicated using state-of-the-art deep neural network\nmodels. In addition, we propose and provide support for the hypothesis that the\nperipheral advantage comes from the inherent usefulness of peripheral features.\nThis result is consistent with data presented by Thibaut, Tran, Szaffarczyk,\nand Boucart (2014), who showed that patients with central vision loss can still\ncategorize natural scenes efficiently. Furthermore, by using a deep\nmixture-of-experts model (\"The Deep Model,\" or TDM) that receives central and\nperipheral visual information on separate channels simultaneously, we show that\nthe peripheral advantage emerges naturally in the learning process: When\ntrained to categorize scenes, the model weights the peripheral pathway more\nthan the central pathway. As we have seen in our previous modeling work,\nlearning creates a transform that spreads different scene categories into\ndifferent regions in representational space. Finally, we visualize the features\nfor the two pathways, and find that different preferences for scene categories\nemerge for the two pathways during the training process.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 06:44:02 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Wang", "Panqu", ""], ["Cottrell", "Garrison W.", ""]]}, {"id": "1705.01208", "submitter": "Hanqing Zhu", "authors": "Ashis Pati, Kantwon Rogers and Hanqing Zhu", "title": "A Rule-Based Computational Model of Cognitive Arithmetic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive arithmetic studies the mental processes used in solving math\nproblems. This area of research explores the retrieval mechanisms and\nstrategies used by people during a common cognitive task. Past research has\nshown that human performance in arithmetic operations is correlated to the\nnumerical size of the problem. Past research on cognitive arithmetic has\npinpointed this trend to either retrieval strength, error checking, or\nstrategy-based approaches when solving equations. This paper describes a\nrule-based computational model that performs the four major arithmetic\noperations (addition, subtraction, multiplication and division) on two\noperands. We then evaluated our model to probe its validity in representing the\nprevailing concepts observed in psychology experiments from the related works.\nThe experiments specifically explore the problem size effect, an\nactivation-based model for fact retrieval, backup strategies when retrieval\nfails, and finally optimization strategies when faced with large operands. From\nour experimental results, we concluded that our model's response times were\ncomparable to results observed when people performed similar tasks during\npsychology experiments. The fit of our model in reproducing these results and\nincorporating accuracy into our model are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 00:28:26 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Pati", "Ashis", ""], ["Rogers", "Kantwon", ""], ["Zhu", "Hanqing", ""]]}, {"id": "1705.01436", "submitter": "Sebastian James", "authors": "Sebastian James, Olivia A. Bell, Muhammed A. M. Nazli, Rachel E.\n  Pearce, Jonathan Spencer, Katie Tyrrell, Phillip J. Paine, Timothy J. Heaton,\n  Sean Anderson, Mauro Da Lio, Kevin Gurney", "title": "Target-distractor Synchrony Affects Performance in a Novel Motor Task\n  for Studying Action Selection", "comments": "28 pages, 12 figures, journal article", "journal-ref": null, "doi": "10.1371/journal.pone.0176945", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of action selection in humans can present challenges of task design\nsince our actions are usually defined by many degrees of freedom and therefore\noccupy a large action-space. While saccadic eye-movement offers a more\nconstrained paradigm for investigating action selection, the study of\nreach-and-grasp in upper limbs has often been defined by more complex\nscenarios, not easily interpretable in terms of such selection. Here we present\na novel motor behaviour task which addresses this by limiting the action space\nto a single degree of freedom in which subjects have to track (using a stylus)\na vertical coloured target line displayed on a tablet computer, whilst ignoring\na similarly oriented distractor line in a different colour. We ran this task\nwith 55 subjects and showed that, in agreement with previous studies, the\npresence of the distractor generally increases the movement latency and\ndirectional error rate. Further, we used two distractor conditions according to\nwhether the distractor's location changes asynchronously or synchronously with\nthe location of the target. We found that the asynchronous distractor yielded\npoorer performance than its synchronous counterpart, with significantly higher\nmovement latencies and higher error rates. We interpret these results in an\naction selection framework with two actions (move left or right) and competing\n'action requests' offered by the target and distractor. As such, the results\nprovide insights into action selection performance in humans and supply data\nfor directly constraining future computational models therein.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 14:00:38 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["James", "Sebastian", ""], ["Bell", "Olivia A.", ""], ["Nazli", "Muhammed A. M.", ""], ["Pearce", "Rachel E.", ""], ["Spencer", "Jonathan", ""], ["Tyrrell", "Katie", ""], ["Paine", "Phillip J.", ""], ["Heaton", "Timothy J.", ""], ["Anderson", "Sean", ""], ["Da Lio", "Mauro", ""], ["Gurney", "Kevin", ""]]}, {"id": "1705.01502", "submitter": "Ran Rubin", "authors": "Ran Rubin, L.F. Abbott and Haim Sompolinsky", "title": "Balanced Excitation and Inhibition are Required for High-Capacity,\n  Noise-Robust Neuronal Selectivity", "comments": "Article and supplementary information", "journal-ref": "Proceedings of the National Academy of Sciences of the United\n  States of America, 114(41), 2017", "doi": "10.1073/pnas.1705841114", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons and networks in the cerebral cortex must operate reliably despite\nmultiple sources of noise. To evaluate the impact of both input and output\nnoise, we determine the robustness of single-neuron stimulus selective\nresponses, as well as the robustness of attractor states of networks of neurons\nperforming memory tasks. We find that robustness to output noise requires\nsynaptic connections to be in a balanced regime in which excitation and\ninhibition are strong and largely cancel each other. We evaluate the conditions\nrequired for this regime to exist and determine the properties of networks\noperating within it. A plausible synaptic plasticity rule for learning that\nbalances weight configurations is presented. Our theory predicts an optimal\nratio of the number of excitatory and inhibitory synapses for maximizing the\nencoding capacity of balanced networks for a given statistics of afferent\nactivations. Previous work has shown that balanced networks amplify\nspatio-temporal variability and account for observed asynchronous irregular\nstates. Here we present a novel type of balanced network that amplifies small\nchanges in the impinging signals, and emerges automatically from learning to\nperform neuronal and network functions robustly.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 16:38:01 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Rubin", "Ran", ""], ["Abbott", "L. F.", ""], ["Sompolinsky", "Haim", ""]]}, {"id": "1705.01615", "submitter": "Joaquin Rapela", "authors": "Joaquin Rapela", "title": "Rhythmic production of consonant-vowel syllables synchronizes traveling\n  waves in speech-processing brain regions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nature is abundant in oscillatory activity, with oscillators that have the\nremarkable ability of synchronizing to external events. Using\nelectrocorticographic (ECoG) recordings from a subject rhythmically producing\nconsonant-vowel syllables (CVSs) we show that neural oscillators recorded at\nindividual ECoG electrodes become precisely synchronized to initiations of the\nproduction of CVSs (i.e., that these initiations occur at precise phases of\nbandpassed-filtered voltages recorded at most ECoG electrodes). This\nsynchronization is not a trivial consequence of the rhythmic production of\nCVSs, since it takes several minutes to be fully established and is observed at\nthe frequency of CVS production and at its second harmonic. The phase of\nfiltered voltages at which CVSs are produced varies systematically across the\ngrid of electrodes, consistently with the propagation of traveling waves (TWs).\nUsing these synchronized phases we isolate a first TW in voltages (filtered at\nthe median CVS-production frequency) moving from primary auditory to premotor\ncortex, and a second TW in high-gamma amplitude (coupled to phase at the\nCVS-production frequency) moving along the same path but in opposite direction.\nTo our knowledge, this is the first report of rhythmic motor acts synchronizing\nspatio-temporally organized cortical activity in the human brain.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 20:41:25 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Rapela", "Joaquin", ""]]}, {"id": "1705.02019", "submitter": "Loukianos Spyrou", "authors": "Loukianos Spyrou, Mario Parra and Javier Escudero", "title": "Complex tensor factorisation with PARAFAC2 for the estimation of brain\n  connectivity from the EEG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: The coupling between neuronal populations and its magnitude have\nbeen shown to be informative for various clinical applications. One method to\nestimate brain connectivity is with electroencephalography (EEG) from which the\ncross-spectrum between different sensor locations is derived. We wish to test\nthe efficacy of tensor factorisation in the estimation of brain connectivity.\nMethods: Complex tensor factorisation based on PARAFAC2 is used to decompose\nthe EEG into scalp components described by the spatial, spectral, and complex\ntrial profiles. An EEG model in the complex domain was derived that shows the\nsuitability of PARAFAC2. A connectivity metric was also derived on the complex\ntrial profiles of the extracted components. Results: Results on a benchmark EEG\ndataset confirmed that PARAFAC2 can estimate connectivity better than\ntraditional tensor analysis such as PARAFAC within a range of signal-to-noise\nratios. The analysis of EEG from patients with mild cognitive impairment or\nAlzheimer's disease showed that PARAFAC2 identifies loss of brain connectivity\nbetter than traditional approaches and agreeing with prior pathological\nknowledge. Conclusion: The complex PARAFAC2 algorithm is suitable for EEG\nconnectivity estimation since it allows to extract meaningful coupled sources\nand provides better estimates than complex PARAFAC. Significance: A new\nparadigm that employs complex tensor factorisation has demonstrated to be\nsuccessful in identifying brain connectivity and the location of couples\nsources for both a benchmark and a real-world EEG dataset. This can enable\nfuture applications and has the potential to solve some the issues that\ndeteriorate the performance of traditional connectivity metrics.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 10:59:24 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Spyrou", "Loukianos", ""], ["Parra", "Mario", ""], ["Escudero", "Javier", ""]]}, {"id": "1705.02042", "submitter": "James Aimone", "authors": "James B. Aimone", "title": "Exponential scaling of neural algorithms - a future beyond Moore's Law?", "comments": "Submitted version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the brain has long been considered a potential inspiration for\nfuture computing, Moore's Law - the scaling property that has seen revolutions\nin technologies ranging from supercomputers to smart phones - has largely been\ndriven by advances in materials science. As the ability to miniaturize\ntransistors is coming to an end, there is increasing attention on new\napproaches to computation, including renewed enthusiasm around the potential of\nneural computation. This paper describes how recent advances in\nneurotechnologies, many of which have been aided by computing's rapid\nprogression over recent decades, are now reigniting this opportunity to bring\nneural computation insights into broader computing applications. As we\nunderstand more about the brain, our ability to motivate new computing\nparadigms with continue to progress. These new approaches to computing, which\nwe are already seeing in techniques such as deep learning and neuromorphic\nhardware, will themselves improve our ability to learn about the brain and\naccordingly can be projected to give rise to even further insights. This paper\nwill describe how this positive feedback has the potential to change the\ncomplexion of how computing sciences and neurosciences interact, and suggests\nthat the next form of exponential scaling in computing may emerge from our\nprogressive understanding of the brain.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 22:54:54 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 14:37:34 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Aimone", "James B.", ""]]}, {"id": "1705.02141", "submitter": "Onerva Korhonen", "authors": "Tuomas Alak\\\"orkk\\\"o (1), Heini Saarim\\\"aki (2), Enrico Glerean (2),\n  Jari Saram\\\"aki (1) and Onerva Korhonen (1,2) ((1) Department of Computer\n  Science, School of Science, Aalto University, Espoo, Finland, (2) Department\n  of Neuroscience and Biomedical Engineering, School of Science, Aalto\n  University, Espoo, Finland)", "title": "Effects of spatial smoothing on functional brain networks", "comments": "17+8 pages, 6+6 figures", "journal-ref": "European Journal of Neuroscience 46(9) (2017), 2471-2480", "doi": "10.1111/ejn.13717", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-theoretical methods have rapidly become a standard tool in studies of\nthe structure and function of the human brain. Whereas the structural\nconnectome can be fairly straightforwardly mapped onto a complex network, there\nare more degrees of freedom in constructing networks that represent functional\nconnections between brain areas. For fMRI data, such networks are typically\nbuilt by aggregating the BOLD signal time series of voxels into larger entities\n(such as Regions of Interest in some brain atlas), and determining the\nconnection strengths between these from some measure of time-series\ncorrelations. Although it is evident that the outcome of this procedure must be\naffected by how the voxel-level time series are treated at the preprocessing\nstage, there is a lack of systematic studies of the effects of preprocessing on\nnetwork structure. Here, we focus on the effects of spatial smoothing, which is\na standard preprocessing method for fMRI. We apply various levels of spatial\nsmoothing to resting-state fMRI data, and measure the changes induced in the\ncorresponding functional networks. We show that the level of spatial smoothing\nclearly affects the degrees and other centrality measures of the nodes of the\nfunctional networks; these changes are non-uniform, systematic, and depend on\nthe geometry of the brain. The composition of the largest connected network\ncomponent is also affected in a way that artificially increases the similarity\nof the networks of different subjects. Our conclusion is that wherever\npossible, spatial smoothing should be avoided when preprocessing fMRI data for\nnetwork analysis.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 09:19:46 GMT"}], "update_date": "2017-11-10", "authors_parsed": [["Alak\u00f6rkk\u00f6", "Tuomas", ""], ["Saarim\u00e4ki", "Heini", ""], ["Glerean", "Enrico", ""], ["Saram\u00e4ki", "Jari", ""], ["Korhonen", "Onerva", ""]]}, {"id": "1705.02176", "submitter": "Liudmila Zhilyakova", "authors": "Nikolay Bazenkov, Varvara Dyakonova, Oleg Kuznetsov, Dmitri Sakharov,\n  Dmitry Vorontsov, Liudmila Zhilyakova", "title": "Discrete Modeling of Multi-Transmitter Neural Networks with Neuron\n  Competition", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel discrete model of central pattern generators (CPG),\nneuronal ensembles generating rhythmic activity. The model emphasizes the role\nof nonsynaptic interactions and the diversity of electrical properties in\nnervous systems. Neurons in the model release different neurotransmitters into\nthe shared extracellular space (ECS) so each neuron with the appropriate set of\nreceptors can receive signals from other neurons. We consider neurons,\ndiffering in their electrical activity, represented as finite-state machines\nfunctioning in discrete time steps. Discrete modeling is aimed to provide a\ncomputationally tractable and compact explanation of rhythmic pattern\ngeneration in nervous systems. The important feature of the model is the\nintroduced mechanism of neuronal competition which is shown to be responsible\nfor the generation of proper rhythms. The model is illustrated with two\nexamples: a half-center oscillator considered to be a basic mechanism of\nemerging rhythmic activity and the well-studied feeding network of a pond\nsnail. Future research will focus on the neuromodulatory effects ubiquitous in\nCPG networks and the whole nervous systems.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 11:54:29 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 18:09:35 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Bazenkov", "Nikolay", ""], ["Dyakonova", "Varvara", ""], ["Kuznetsov", "Oleg", ""], ["Sakharov", "Dmitri", ""], ["Vorontsov", "Dmitry", ""], ["Zhilyakova", "Liudmila", ""]]}, {"id": "1705.02201", "submitter": "Antonio Iovanella", "authors": "Matteo Cinelli, Giovanna Ferraro, Antonio Iovanella", "title": "Rich-Club Ordering and the Dyadic Effect: Two Interrelated Phenomena", "comments": null, "journal-ref": "Physica A: Statistical Mechanics and its Applications, Volume 490,\n  2018, Pages 808-818", "doi": "10.1016/j.physa.2017.08.122", "report-no": null, "categories": "cs.SI math.CO physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rich-club ordering and the dyadic effect are two phenomena observed in\ncomplex networks that are based on the presence of certain substructures\ncomposed of specific nodes. Rich-club ordering represents the tendency of\nhighly connected and important elements to form tight communities with other\ncentral elements. The dyadic effect denotes the tendency of nodes that share a\ncommon property to be much more interconnected than expected. In this study, we\nconsider the interrelation between these two phenomena, which until now have\nalways been studied separately. We contribute with a new formulation of the\nrich-club measures in terms of the dyadic effect. Moreover, we introduce\ncertain measures related to the analysis of the dyadic effect, which are useful\nin confirming the presence and relevance of rich-clubs in complex networks. In\naddition, certain computational experiences show the usefulness of the\nintroduced quantities with regard to different classes of real networks.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 16:23:46 GMT"}], "update_date": "2019-04-12", "authors_parsed": [["Cinelli", "Matteo", ""], ["Ferraro", "Giovanna", ""], ["Iovanella", "Antonio", ""]]}, {"id": "1705.02205", "submitter": "Ricarda Schneider", "authors": "Mar\\'ia J. C\\'aceres and Ricarda Schneider", "title": "Towards a realistic NNLIF model: Analysis and numerical solver for\n  excitatory-inhibitory networks with delay and refractory periods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Network of Noisy Leaky Integrate and Fire (NNLIF) model describes the\nbehavior of a neural network at mesoscopic level. It is one of the simplest\nself-contained mean-field models considered for that purpose. Even so, to study\nthe mathematical properties of the model some simplifications were necessary\nC\\'aceres-Carrillo-Perthame(2011), C\\'aceres-Perthame(2014),\nC\\'aceres-Schneider(2017), which disregard crucial phenomena. In this work we\ndeal with the general NNLIF model without simplifications. It involves a\nnetwork with two populations (excitatory and inhibitory), with transmission\ndelays between the neurons and where the neurons remain in a refractory state\nfor a certain time. We have studied the number of steady states in terms of the\nmodel parameters, the long time behaviour via the entropy method and\nPoincar\\'e's inequality, blow-up phenomena, and the importance of transmission\ndelays between excitatory neurons to prevent blow-up and to give rise to\nsynchronous solutions. Besides analytical results, we have presented a\nnumerical resolutor for this model, based on high order flux-splitting WENO\nschemes and an explicit third order TVD Runge-Kutta method, in order to\ndescribe the wide range of phenomena exhibited by the network: blow-up,\nasynchronous/synchronous solutions and instability/stability of the steady\nstates; the solver also allows us to observe the time evolution of the firing\nrates, refractory states and the probability distributions of the excitatory\nand inhibitory populations.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 13:19:28 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 12:40:18 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["C\u00e1ceres", "Mar\u00eda J.", ""], ["Schneider", "Ricarda", ""]]}, {"id": "1705.02301", "submitter": "Erick Olivares", "authors": "Erick Olivares, Eduardo J. Izquierdo and Randall D. Beer", "title": "Potential role of a ventral nerve cord central pattern generator in\n  forward and backward locomotion in Caenorhabditis elegans", "comments": "32 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the relative simplicity of C. elegans, its locomotion machinery is\nnot yet well understood. We focus on the generation of dorsoventral body bends.\nWhile central pattern generators are commonly involved in animal locomotion,\ntheir presence in C. elegans has been questioned due to a lack of an evident\nneural circuit to support it. We developed a computational model grounded in\nthe available neuroanatomy and neurophysiology and we used an evolutionary\nalgorithm to explore the space of possible configurations of the circuit that\nmatched the neural traces observed during forward and backward locomotion in\nthe worm. Our results demonstrate that it is possible for the rhythmic\ncontraction to be produced by a circuit present in the ventral nerve cord.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 17:07:25 GMT"}, {"version": "v2", "created": "Sun, 18 Jun 2017 03:21:09 GMT"}, {"version": "v3", "created": "Mon, 6 Nov 2017 21:05:40 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Olivares", "Erick", ""], ["Izquierdo", "Eduardo J.", ""], ["Beer", "Randall D.", ""]]}, {"id": "1705.02962", "submitter": "R\\\"udiger Alshut", "authors": "R\\\"udiger Alshut", "title": "Konzept f\\\"ur Bildanalysen in Hochdurchsatz-Systemen am Beispiel des\n  Zebrab\\\"arblings", "comments": null, "journal-ref": "Ph.D. Thesis, Karlsruhe Institute of Technology, KIT Scientific\n  Publishing, 2016", "doi": "10.5445/IR/1000061759", "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With image-based high-throughput experiments, new challenges arise in both,\nthe design of experiments and the automated analysis. To be able to handle the\nmassive number of single experiments and the corresponding amount of data, a\ncomprehensive concept for the design of experiments and a new evaluation method\nis needed. This work proposes a new method for an optimized experiment layout\nthat enables the determination of parameters, adapted for the needs of\nautomated image analysis. Furthermore, a catalogue of new image analysis\nmodules, especially developed for zebrafish analysis, is presented. The\ncombination of both parts offers the user, usually a biologist, an approach for\nhigh-throughput zebrafish image analysis, which enables the extraction of new\nsignals and optimizes the design of experiments. The result is a reduction of\ndata amount, redundant information and workload as well as classification\nerrors.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 21:48:49 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Alshut", "R\u00fcdiger", ""]]}, {"id": "1705.03115", "submitter": "Eli Shlizerman", "authors": "David Blaszka, Elischa Sanders, Jeffrey Riffell, Eli Shlizerman", "title": "Classification of Fixed Point Network Dynamics From Multiple Node\n  Timeseries Data", "comments": "submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fixed point networks are dynamic networks that encode stimuli via distinct\noutput patterns. Although such networks are omnipresent in neural systems,\ntheir structures are typically unknown or poorly characterized. It is therefore\nvaluable to use a supervised approach for resolving how a network encodes\ndistinct inputs of interest, and the superposition of those inputs from sampled\nmultiple node time series. In this paper we show that accomplishing such a task\ninvolves finding a low-dimensional state space from supervised recordings. We\ndemonstrate that standard methods for dimension reduction are unable to provide\nthe desired functionality of optimal separation of the fixed points and\ntransient trajectories to them. However, the combination of dimension reduction\nwith selection and optimization can successfully provide such functionality.\nSpecifically, we propose two methods: Exclusive Threshold Reduction (ETR) and\nOptimal Exclusive Threshold Reduction (OETR) for finding a basis for the\nclassification state space. We show that the classification space constructed\nupon combination of dimension reduction optimal separation can directly\nfacilitate recognition of stimuli, and classify complex inputs (mixtures) into\nsimilarity classes. We test our methodology and compare it to standard\nstate-of-the-art methods on a benchmark dataset - an experimental neuronal\nnetwork (the olfactory system) that we recorded from to test these methods. We\nshow that our methods are capable of providing a basis for the classification\nspace in such network, and to perform recognition at a significantly better\nrate than previously proposed approaches.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 22:47:40 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Blaszka", "David", ""], ["Sanders", "Elischa", ""], ["Riffell", "Jeffrey", ""], ["Shlizerman", "Eli", ""]]}, {"id": "1705.03543", "submitter": "Sayan Nag", "authors": "Sayan Nag, Sayan Biswas, Sourya Sengupta, Shankha Sanyal, Archi\n  Banerjee, Ranjan Sengupta and Dipak Ghosh", "title": "Can Musical Emotion Be Quantified With Neural Jitter Or Shimmer? A Novel\n  EEG Based Study With Hindustani Classical Music", "comments": "6 pages, 12 figures, Presented in 4th International Conference on\n  Signal Processing and Integrated Networks (SPIN) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term jitter and shimmer has long been used in the domain of speech and\nacoustic signal analysis as a parameter for speaker identification and other\nprosodic features. In this study, we look forward to use the same parameters in\nneural domain to identify and categorize emotional cues in different musical\nclips. For this, we chose two ragas of Hindustani music which are\nconventionally known to portray contrast emotions and EEG study was conducted\non 5 participants who were made to listen to 3 min clip of these two ragas with\nsufficient resting period in between. The neural jitter and shimmer components\nwere evaluated for each experimental condition. The results reveal interesting\ninformation regarding domain specific arousal of human brain in response to\nmusical stimuli and also regarding trait characteristics of an individual. This\nnovel study can have far reaching conclusions when it comes to modeling of\nemotional appraisal. The results and implications are discussed in detail.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 18:58:54 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Nag", "Sayan", ""], ["Biswas", "Sayan", ""], ["Sengupta", "Sourya", ""], ["Sanyal", "Shankha", ""], ["Banerjee", "Archi", ""], ["Sengupta", "Ranjan", ""], ["Ghosh", "Dipak", ""]]}, {"id": "1705.04192", "submitter": "Carlo Vittorio Cannistraci", "authors": "Alberto Cacciola, Alessandro Muscoloni, Vaibhav Narula, Alessandro\n  Calamuneri, Salvatore Nigro, Emeran A. Mayer, Jennifer S. Labus, Giuseppe\n  Anastasi, Aldo Quattrone, Angelo Quartarone, Demetrio Milardi and Carlo\n  Vittorio Cannistraci", "title": "Coalescent embedding in the hyperbolic space unsupervisedly discloses\n  the hidden geometry of the brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain displays a complex network topology, whose structural\norganization is widely studied using diffusion tensor imaging. The original\ngeometry from which emerges the network topology is known, as well as the\nlocalization of the network nodes in respect to the brain morphology and\nanatomy. One of the most challenging problems of current network science is to\ninfer the latent geometry from the mere topology of a complex network. The\nhuman brain structural connectome represents the perfect benchmark to test\nalgorithms aimed to solve this problem. Coalescent embedding was recently\ndesigned to map a complex network in the hyperbolic space, inferring the node\nangular coordinates. Here we show that this methodology is able to\nunsupervisedly reconstruct the latent geometry of the brain with an incredible\naccuracy and that the intrinsic geometry of the brain networks strongly relates\nto the lobes organization known in neuroanatomy. Furthermore, coalescent\nembedding allowed the detection of geometrical pathological changes in the\nconnectomes of Parkinson's Disease patients. The present study represents the\nfirst evidence of brain networks' angular coalescence in the hyperbolic space,\nopening a completely new perspective, possibly towards the realization of\nlatent geometry network markers for evaluation of brain disorders and\npathologies.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 16:42:03 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Cacciola", "Alberto", ""], ["Muscoloni", "Alessandro", ""], ["Narula", "Vaibhav", ""], ["Calamuneri", "Alessandro", ""], ["Nigro", "Salvatore", ""], ["Mayer", "Emeran A.", ""], ["Labus", "Jennifer S.", ""], ["Anastasi", "Giuseppe", ""], ["Quattrone", "Aldo", ""], ["Quartarone", "Angelo", ""], ["Milardi", "Demetrio", ""], ["Cannistraci", "Carlo Vittorio", ""]]}, {"id": "1705.04405", "submitter": "Luigi Acerbi", "authors": "Luigi Acerbi, Wei Ji Ma", "title": "Practical Bayesian Optimization for Model Fitting with Bayesian Adaptive\n  Direct Search", "comments": "To appear in Advances in Neural Information Processing Systems 30\n  (NIPS 2017). 21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models in fields such as computational neuroscience are often\nevaluated via stochastic simulation or numerical approximation. Fitting these\nmodels implies a difficult optimization problem over complex, possibly noisy\nparameter landscapes. Bayesian optimization (BO) has been successfully applied\nto solving expensive black-box problems in engineering and machine learning.\nHere we explore whether BO can be applied as a general tool for model fitting.\nFirst, we present a novel hybrid BO algorithm, Bayesian adaptive direct search\n(BADS), that achieves competitive performance with an affordable computational\noverhead for the running time of typical models. We then perform an extensive\nbenchmark of BADS vs. many common and state-of-the-art nonconvex,\nderivative-free optimizers, on a set of model-fitting problems with real data\nand models from six studies in behavioral, cognitive, and computational\nneuroscience. With default settings, BADS consistently finds comparable or\nbetter solutions than other methods, including `vanilla' BO, showing great\npromise for advanced BO techniques, and BADS in particular, as a general\nmodel-fitting tool.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 23:53:13 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 13:45:54 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Acerbi", "Luigi", ""], ["Ma", "Wei Ji", ""]]}, {"id": "1705.04739", "submitter": "Eilidh Noyes", "authors": "Eilidh Noyes and Alice J. O'Toole", "title": "Face recognition assessments used in the study of super-recognisers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this paper is to provide a brief overview of nine assessments\nof face processing skills. These tests have been used commonly in recent years\nto gauge the skills of perspective 'super-recognisers' with respect to the\ngeneral population. In the literature, a person has been considered to be a\n'super-recogniser' based on superior scores on one or more of these tests (cf.,\nNoyes, Phillips & O'Toole, in press). The paper provides a supplement to a\nrecent review of super-recognisers aimed at readers who are unfamiliar with\nthese tests. That review provides a complete summary of the super-recongiser\nliterature to date (2017). It also provides a theory and a set of action points\ndirected at answering the question \"What is a super-recogniser?\"\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 20:02:11 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Noyes", "Eilidh", ""], ["O'Toole", "Alice J.", ""]]}, {"id": "1705.04742", "submitter": "Erik Wiersma Dr", "authors": "Erik J Wiersma", "title": "How sustainable are different levels of consciousness?", "comments": "28 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain processes a wide variety of inputs and does so either\nconsciously or subconsciously. According to the Global Workspace theory,\nconscious processing involves broadcasting of information to several regions of\nthe brain and subconscious processing involves more localized processing. This\ntheoretical paper aims to expand on some of the aspects of the Global Workspace\ntheory: how the properties of incoming information result in it being processed\nsubconsciously or consciously; why processing can be either be sustained or\nshort-lived; how the Global Workspace theory may apply both to real-time\nsensory input as well as to internally retained information. This paper\nproposes that: familiar input which does not elicit intense emotions becomes\nprocessed subconsciously and such processing can be continuous and sustained;\ninput that elicits relatively intense emotions is subjected to highly\nsustainable conscious processing; input can also undergo meta-conscious\nprocessing. Such processing is not very sustainable but can exert control over\nother cognitive processes. This paper also discusses possible benefits of\nregulating cognitive processes this way.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 20:15:35 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Wiersma", "Erik J", ""]]}, {"id": "1705.05074", "submitter": "Ruggero Micheletto", "authors": "Takahisa Kishino, Sun Zhe, Roberto Marchisio and Ruggero Micheletto", "title": "Cross-modal codification of images with auditory stimuli: a language for\n  the visually impaired", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we describe a methodology to realize visual images cognition in\nthe broader sense, by a cross-modal stimulation through the auditory channel.\nAn original algorithm of conversion from bi-dimensional images to sounds has\nbeen established and tested on several subjects. Our results show that subjects\nwhere able to discriminate with a precision of 95\\% different sounds\ncorresponding to different test geometric shapes. Moreover, after brief\nlearning sessions on simple images, subjects where able to recognize among a\ngroup of 16 complex and never-trained images a single target by hearing its\nacoustical counterpart. Rate of recognition was found to depend on image\ncharacteristics, in 90% of the cases, subjects did better than choosing at\nrandom. This study contribute to the understanding of cross-modal perception\nand help for the realization of systems that use acoustical signals to help\nvisually impaired persons to recognize objects and improve navigation\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 05:38:01 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Kishino", "Takahisa", ""], ["Zhe", "Sun", ""], ["Marchisio", "Roberto", ""], ["Micheletto", "Ruggero", ""]]}, {"id": "1705.05191", "submitter": "Philippe Terrier PhD", "authors": "Fabienne Reynard and Philippe Terrier", "title": "Determinants of gait stability while walking on a treadmill: a machine\n  learning approach", "comments": "This is the author's version of a manuscript published in the Journal\n  of Biomechanics", "journal-ref": "Journnal of Biomechanics Volume 65, 8 December 2017, Pages 212-215", "doi": "10.1016/j.jbiomech.2017.10.020", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dynamic balance in human locomotion can be assessed through the local dynamic\nstability (LDS) method. Whereas gait LDS has been used successfully in many\nsettings and applications, little is known about its sensitivity to individual\ncharacteristics of healthy adults. Therefore, we reanalyzed a large dataset of\naccelerometric data measured for 100 healthy adults from 20 to 70 years of age\nperforming 10 min. treadmill walking. We sought to assess the extent to which\nthe variations of age, body mass and height, sex, and preferred walking speed\n(PWS) could influence gait LDS. The random forest (RF) and multiple adaptive\nregression splines (MARS) algorithms were selected for their good bias-variance\ntradeoff and their capabilities to handle nonlinear associations. First,\nthrough variable importance measure (VIM), we used RF to evaluate which\nindividual characteristics had the highest influence on gait LDS. Second, we\nused MARS to detect potential interactions among individual characteristics\nthat may influence LDS. The VIM and MARS results indicated that PWS and age\ncorrelated with LDS, whereas no associations were found for sex, body height,\nand body mass. Further, the MARS model detected an age by PWS interaction: on\none hand, at high PWS, gait stability is constant across age while, on the\nother hand, at low PWS, gait instability increases substantially with age. We\nconclude that it is advisable to consider the participants' age as well as\ntheir PWS to avoid potential biases in evaluating dynamic balance through LDS.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 12:47:46 GMT"}, {"version": "v2", "created": "Thu, 26 Oct 2017 12:43:14 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Reynard", "Fabienne", ""], ["Terrier", "Philippe", ""]]}, {"id": "1705.05248", "submitter": "Bertha V\\'azquez-Rodr\\'iguez Bertha", "authors": "Bertha V\\'azquez-Rodr\\'iguez, Andrea Avena-Koenigsberger, Olaf Sporns,\n  Alessandra Griffa, Patric Hagmann, Hern\\'an Larralde", "title": "Stochastic resonance and optimal information transfer at criticality on\n  a network model of the human connectome", "comments": null, "journal-ref": "Scientific Reports 7, Article number: 13020 (2017)", "doi": "10.1038/s41598-017-13400-5", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic resonance is a phenomenon in which noise enhances the response of\na system to an input signal. The brain is an example of a system that has to\ndetect and transmit signals in a noisy environment, suggesting that it is a\ngood candidate to take advantage of SR. In this work, we aim to identify the\noptimal levels of noise that promote signal transmission through a simple\nnetwork model of the human brain. Specifically, using a dynamic model\nimplemented on an anatomical brain network (connectome), we investigate the\nsimilarity between an input signal and a signal that has traveled across the\nnetwork while the system is subject to different noise levels. We find that\nnon-zero levels of noise enhance the similarity between the input signal and\nthe signal that has traveled through the system. The optimal noise level is not\nunique; rather, there is a set of parameter values at which the information is\ntransmitted with greater precision, this set corresponds to the parameter\nvalues that place the system in a critical regime. The multiplicity of critical\npoints in our model allows it to adapt to different noise situations and remain\nat criticality.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 17:43:29 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 16:56:03 GMT"}], "update_date": "2017-10-16", "authors_parsed": [["V\u00e1zquez-Rodr\u00edguez", "Bertha", ""], ["Avena-Koenigsberger", "Andrea", ""], ["Sporns", "Olaf", ""], ["Griffa", "Alessandra", ""], ["Hagmann", "Patric", ""], ["Larralde", "Hern\u00e1n", ""]]}, {"id": "1705.05475", "submitter": "Tsung-Han Lin", "authors": "Ping Tak Peter Tang, Tsung-Han Lin, Mike Davies", "title": "Sparse Coding by Spiking Neural Networks: Convergence Theory and\n  Computational Results", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NA cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a spiking neural network (SNN), individual neurons operate autonomously\nand only communicate with other neurons sparingly and asynchronously via spike\nsignals. These characteristics render a massively parallel hardware\nimplementation of SNN a potentially powerful computer, albeit a non von Neumann\none. But can one guarantee that a SNN computer solves some important problems\nreliably? In this paper, we formulate a mathematical model of one SNN that can\nbe configured for a sparse coding problem for feature extraction. With a\nmoderate but well-defined assumption, we prove that the SNN indeed solves\nsparse coding. To the best of our knowledge, this is the first rigorous result\nof this kind.\n", "versions": [{"version": "v1", "created": "Mon, 15 May 2017 23:06:34 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Tang", "Ping Tak Peter", ""], ["Lin", "Tsung-Han", ""], ["Davies", "Mike", ""]]}, {"id": "1705.05603", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni, Max Hinne, Marcel van Gerven and Eric Maris", "title": "GP CaKe: Effective brain connectivity with causal kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental goal in network neuroscience is to understand how activity in\none region drives activity elsewhere, a process referred to as effective\nconnectivity. Here we propose to model this causal interaction using\nintegro-differential equations and causal kernels that allow for a rich\nanalysis of effective connectivity. The approach combines the tractability and\nflexibility of autoregressive modeling with the biophysical interpretability of\ndynamic causal modeling. The causal kernels are learned nonparametrically using\nGaussian process regression, yielding an efficient framework for causal\ninference. We construct a novel class of causal covariance functions that\nenforce the desired properties of the causal kernels, an approach which we call\nGP CaKe. By construction, the model and its hyperparameters have biophysical\nmeaning and are therefore easily interpretable. We demonstrate the efficacy of\nGP CaKe on a number of simulations and give an example of a realistic\napplication on magnetoencephalography (MEG) data.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 09:07:13 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Ambrogioni", "Luca", ""], ["Hinne", "Max", ""], ["van Gerven", "Marcel", ""], ["Maris", "Eric", ""]]}, {"id": "1705.05647", "submitter": "Diego Fasoli", "authors": "Diego Fasoli, Stefano Panzeri", "title": "Optimized brute-force algorithms for the bifurcation analysis of a\n  spin-glass-like neural network model", "comments": "22 pages, 5 figures, 4 Python scripts", "journal-ref": "Phys. Rev. E 99, 012316 (2019)", "doi": "10.1103/PhysRevE.99.012316", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bifurcation theory is a powerful tool for studying how the dynamics of a\nneural network model depends on its underlying neurophysiological parameters.\nHowever, bifurcation theory has been developed mostly for smooth dynamical\nsystems and for continuous-time non-smooth models, which prevents us from\nunderstanding the changes of dynamics in some widely used classes of artificial\nneural network models. This article is an attempt to fill this gap, through the\nintroduction of algorithms that perform a semi-analytical bifurcation analysis\nof a spin-glass-like neural network model with binary firing rates and\ndiscrete-time evolution. Our approach is based on a numerical brute-force\nsearch of the stationary and oscillatory solutions of the spin-glass model,\nfrom which we derive analytical expressions of its bifurcation structure by\nmeans of the state-to-state transition probability matrix. The algorithms\ndetermine how the network parameters affect the degree of multistability, the\nemergence and the period of the neural oscillations, and the formation of\nsymmetry-breaking in the neural populations. While this technique can be\napplied to networks with arbitrary (generally asymmetric) connectivity\nmatrices, in particular we introduce a highly efficient algorithm for the\nbifurcation analysis of sparse networks. We also provide some examples of the\nobtained bifurcation diagrams and a Python implementation of the algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 11:17:21 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Fasoli", "Diego", ""], ["Panzeri", "Stefano", ""]]}, {"id": "1705.05935", "submitter": "Ricard Sole", "authors": "Ricard Sole", "title": "Rise of the humanbot", "comments": "3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accelerated path of technological development, particularly at the\ninterface between hardware and biology has been suggested as evidence for\nfuture major technological breakthroughs associated to our potential to\novercome biological constraints. This includes the potential of becoming\nimmortal, having expanded cognitive capacities thanks to hardware implants or\nthe creation of intelligent machines. Here I argue that several relevant\nevolutionary and structural constraints might prevent achieving most (if not\nall) these innovations. Instead, the coming future will bring novelties that\nwill challenge many other aspects of our life and that can be seen as other\nfeasible singularities. One particularly important one has to do with the\nevolving interactions between humans and non-intelligent robots capable of\nlearning and communication. Here I argue that a long term interaction can lead\nto a new class of \"agent\" (the humanbot). The way shared memories get tangled\nover time will inevitably have important consequences for both sides of the\npair, whose identity as separated entities might become blurred and ultimately\nvanish. Understanding such hybrid systems requires a second-order neuroscience\napproach while posing serious conceptual challenges, including the definition\nof consciousness.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 21:46:17 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Sole", "Ricard", ""]]}, {"id": "1705.06354", "submitter": "Yiwei Li", "authors": "Yiwei Li, Osman Kahraman, Christoph A. Haselwandter", "title": "Stochastic lattice model of synaptic membrane protein domains", "comments": null, "journal-ref": "Phys. Rev. E 95, 052406 (2017)", "doi": "10.1103/PhysRevE.95.052406", "report-no": null, "categories": "q-bio.SC physics.bio-ph q-bio.BM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurotransmitter receptor molecules, concentrated in synaptic membrane\ndomains along with scaffolds and other kinds of proteins, are crucial for\nsignal transmission across chemical synapses. In common with other membrane\nprotein domains, synaptic domains are characterized by low protein copy numbers\nand protein crowding, with rapid stochastic turnover of individual molecules.\nWe study here in detail a stochastic lattice model of the receptor-scaffold\nreaction-diffusion dynamics at synaptic domains that was found previously to\ncapture, at the mean-field level, the self-assembly, stability, and\ncharacteristic size of synaptic domains observed in experiments. We show that\nour stochastic lattice model yields quantitative agreement with mean-field\nmodels of nonlinear diffusion in crowded membranes. Through a combination of\nanalytic and numerical solutions of the master equation governing the reaction\ndynamics at synaptic domains, together with kinetic Monte Carlo simulations, we\nfind substantial discrepancies between mean-field and stochastic models for the\nreaction dynamics at synaptic domains. Based on the reaction and diffusion\nproperties of synaptic receptors and scaffolds suggested by previous\nexperiments and mean-field calculations, we show that the stochastic\nreaction-diffusion dynamics of synaptic receptors and scaffolds provide a\nsimple physical mechanism for collective fluctuations in synaptic domains, the\nmolecular turnover observed at synaptic domains, key features of the observed\nsingle-molecule trajectories, and spatial heterogeneity in the effective rates\nat which receptors and scaffolds are recycled at the cell membrane. Our work\nsheds light on the physical mechanisms and principles linking the collective\nproperties of membrane protein domains to the stochastic dynamics that rule\ntheir molecular~components.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 21:33:45 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Li", "Yiwei", ""], ["Kahraman", "Osman", ""], ["Haselwandter", "Christoph A.", ""]]}, {"id": "1705.06481", "submitter": "Carlo Nicolini", "authors": "C\\'ecile Bordier, Carlo Nicolini and Angelo Bifone", "title": "Graph analysis and modularity of brain functional connectivity networks:\n  searching for the optimal threshold", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging data can be represented as networks of nodes and edges that\ncapture the topological organization of the brain connectivity. Graph theory\nprovides a general and powerful framework to study these networks and their\nstructure at various scales. By way of example, community detection methods\nhave been widely applied to investigate the modular structure of many natural\nnetworks, including brain functional connectivity networks. Sparsification\nprocedures are often applied to remove the weakest edges, which are the most\naffected by experimental noise, and to reduce the density of the graph, thus\nmaking it theoretically and computationally more tractable. However, weak links\nmay also contain significant structural information, and procedures to identify\nthe optimal tradeoff are the subject of active research. Here, we explore the\nuse of percolation analysis, a method grounded in statistical physics, to\nidentify the optimal sparsification threshold for community detection in brain\nconnectivity networks. By using synthetic networks endowed with a ground-truth\nmodular structure and realistic topological features typical of human brain\nfunctional connectivity networks, we show that percolation analysis can be\napplied to identify the optimal sparsification threshold that maximizes\ninformation on the networks' community structure. We validate this approach\nusing three different community detection methods widely applied to the\nanalysis of brain connectivity networks: Newman's modularity, InfoMap and\nAsymptotical Surprise. Importantly, we test the effects of noise and data\nvariability, which are critical factors to determine the optimal threshold.\nThis data-driven method should prove particularly useful in the analysis of the\ncommunity structure of brain networks in populations characterized by different\nconnectivity strengths, such as patients and controls.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 09:05:09 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Bordier", "C\u00e9cile", ""], ["Nicolini", "Carlo", ""], ["Bifone", "Angelo", ""]]}, {"id": "1705.06502", "submitter": "Chee-Ming Ting PhD", "authors": "Chee-Ming Ting, Hernando Ombao, Sh-Hussain Salleh", "title": "Multi-Scale Factor Analysis of High-Dimensional Brain Signals", "comments": "43 pages", "journal-ref": "IEEE Trans. Network Science and Engineering 7(1), 449 - 465, 2020", "doi": "10.1109/TNSE.2018.2869862", "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop an approach to modeling high-dimensional networks\nwith a large number of nodes arranged in a hierarchical and modular structure.\nWe propose a novel multi-scale factor analysis (MSFA) model which partitions\nthe massive spatio-temporal data defined over the complex networks into a\nfinite set of regional clusters. To achieve further dimension reduction, we\nrepresent the signals in each cluster by a small number of latent factors. The\ncorrelation matrix for all nodes in the network are approximated by\nlower-dimensional sub-structures derived from the cluster-specific factors. To\nestimate regional connectivity between numerous nodes (within each cluster), we\napply principal components analysis (PCA) to produce factors which are derived\nas the optimal reconstruction of the observed signals under the squared loss.\nThen, we estimate global connectivity (between clusters or sub-networks) based\non the factors across regions using the RV-coefficient as the cross-dependence\nmeasure. This gives a reliable and computationally efficient multi-scale\nanalysis of both regional and global dependencies of the large networks. The\nproposed novel approach is applied to estimate brain connectivity networks\nusing functional magnetic resonance imaging (fMRI) data. Results on\nresting-state fMRI reveal interesting modular and hierarchical organization of\nhuman brain networks during rest.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 10:05:56 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Ting", "Chee-Ming", ""], ["Ombao", "Hernando", ""], ["Salleh", "Sh-Hussain", ""]]}, {"id": "1705.06614", "submitter": "Biswa Sengupta", "authors": "Biswa Sengupta and Karl Friston", "title": "Approximate Bayesian inference as a gauge theory", "comments": "Extended version published in PLoS Biology, ICML 2017 Computational\n  Biology Workshop (spotlight presentation)", "journal-ref": null, "doi": "10.1371/journal.pbio.1002400", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a published paper [Sengupta, 2016], we have proposed that the brain (and\nother self-organized biological and artificial systems) can be characterized\nvia the mathematical apparatus of a gauge theory. The picture that emerges from\nthis approach suggests that any biological system (from a neuron to an\norganism) can be cast as resolving uncertainty about its external milieu,\neither by changing its internal states or its relationship to the environment.\nUsing formal arguments, we have shown that a gauge theory for neuronal dynamics\n-- based on approximate Bayesian inference -- has the potential to shed new\nlight on phenomena that have thus far eluded a formal description, such as\nattention and the link between action and perception. Here, we describe the\ntechnical apparatus that enables such a variational inference on manifolds.\nParticularly, the novel contribution of this paper is an algorithm that utlizes\na Schild's ladder for parallel transport of sufficient statistics (means,\ncovariances, etc.) on a statistical manifold.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 13:13:28 GMT"}, {"version": "v2", "created": "Sun, 12 Nov 2017 09:18:27 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Sengupta", "Biswa", ""], ["Friston", "Karl", ""]]}, {"id": "1705.06786", "submitter": "Matjaz Perc", "authors": "Bidesh K. Bera, Soumen Majhi, Dibakar Ghosh, Matjaz Perc", "title": "Chimera states: Effects of different coupling topologies", "comments": "7 two-column pages, 4 figures; Perspective accepted for publication\n  in EPL", "journal-ref": "EPL 118, 10001 (2017)", "doi": "10.1209/0295-5075/118/10001", "report-no": null, "categories": "nlin.AO physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective behavior among coupled dynamical units can emerge in various forms\nas a result of different coupling topologies as well as different types of\ncoupling functions. Chimera states have recently received ample attention as a\nfascinating manifestation of collective behavior, in particular describing a\nsymmetry breaking spatiotemporal pattern where synchronized and desynchronized\nstates coexist in a network of coupled oscillators. In this perspective, we\nreview the emergence of different chimera states, focusing on the effects of\ndifferent coupling topologies that describe the interaction network connecting\nthe oscillators. We cover chimera states that emerge in local, nonlocal and\nglobal coupling topologies, as well as in modular, temporal and multilayer\nnetworks. We also provide an outline of challenges and directions for future\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 20:24:03 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Bera", "Bidesh K.", ""], ["Majhi", "Soumen", ""], ["Ghosh", "Dibakar", ""], ["Perc", "Matjaz", ""]]}, {"id": "1705.07109", "submitter": "Ya\\u{g}mur G\\\"u\\c{c}l\\\"ut\\\"urk", "authors": "Ya\\u{g}mur G\\\"u\\c{c}l\\\"ut\\\"urk, Umut G\\\"u\\c{c}l\\\"u, Katja Seeliger,\n  Sander Bosch, Rob van Lier, Marcel van Gerven", "title": "Deep adversarial neural decoding", "comments": "Added appendix and updated figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we present a novel approach to solve the problem of reconstructing\nperceived stimuli from brain responses by combining probabilistic inference\nwith deep learning. Our approach first inverts the linear transformation from\nlatent features to brain responses with maximum a posteriori estimation and\nthen inverts the nonlinear transformation from perceived stimuli to latent\nfeatures with adversarial training of convolutional neural networks. We test\nour approach with a functional magnetic resonance imaging experiment and show\nthat it can generate state-of-the-art reconstructions of perceived faces from\nbrain activations.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 17:43:01 GMT"}, {"version": "v2", "created": "Thu, 1 Jun 2017 13:15:25 GMT"}, {"version": "v3", "created": "Thu, 15 Jun 2017 16:56:34 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["G\u00fc\u00e7l\u00fct\u00fcrk", "Ya\u011fmur", ""], ["G\u00fc\u00e7l\u00fc", "Umut", ""], ["Seeliger", "Katja", ""], ["Bosch", "Sander", ""], ["van Lier", "Rob", ""], ["van Gerven", "Marcel", ""]]}, {"id": "1705.07360", "submitter": "Andrea Barreiro", "authors": "Thomas J. Anastasio and Andrea K. Barreiro and Jared C Bronski", "title": "A geometric method for eigenvalue problems with low rank perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.SP math.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of finding the spectrum of an operator taking the\nform of a low-rank (rank one or two) non-normal perturbation of a\nwell-understood operator, motivated by a number of problems of applied interest\nwhich take this form. We use the fact that the system is a low rank\nperturbation of a solved problem, together with a simple idea of classical\ndifferential geometry (the envelope of a family of curves) to completely\nanalyze the spectrum. We use these techniques to analyze three problems of this\nform: a model of the oculomotor integrator due to Anastasio and Gad (2007), a\ncontinuum integrator model, and a nonlocal model of phase separation due to\nRubinstein and Sternberg (1992).\n", "versions": [{"version": "v1", "created": "Sat, 20 May 2017 20:55:03 GMT"}, {"version": "v2", "created": "Fri, 11 Aug 2017 00:28:01 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Anastasio", "Thomas J.", ""], ["Barreiro", "Andrea K.", ""], ["Bronski", "Jared C", ""]]}, {"id": "1705.07441", "submitter": "Alireza Alemi", "authors": "Alireza Alemi and Alia Abbara", "title": "Exponential Capacity in an Autoencoder Neural Network with a Hidden\n  Layer", "comments": "3 figures, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental aspect of limitations in learning any computation in neural\narchitectures is characterizing their optimal capacities.\n  An important, widely-used neural architecture is known as autoencoders where\nthe network reconstructs the input at the output layer via a representation at\na hidden layer.\n  Even though capacities of several neural architectures have been addressed\nusing statistical physics methods, the capacity of autoencoder neural networks\nis not well-explored.\n  Here, we analytically show that an autoencoder network of binary neurons with\na hidden layer can achieve a capacity that grows exponentially with network\nsize.\n  The network has fixed random weights encoding a set of dense input patterns\ninto a dense, expanded (or \\emph{overcomplete}) hidden layer representation. A\nset of learnable weights decodes the input patters at the output layer. We\nperform a mean-field approximation of the model to reduce the model to a\nperceptron problem with an input-output dependency. Carrying out Gardner's\n\\emph{replica} calculation, we show that as the expansion ratio, defined as the\nnumber of hidden units over the number of input units, increases, the\nautoencoding capacity grows exponentially even when the sparseness or the\ncoding level of the hidden layer representation is changed. The\nreplica-symmetric solution is locally stable and is in good agreement with\nsimulation results obtained using a local learning rule. In addition, the\ndegree of symmetry between the encoding and decoding weights monotonically\nincreases with the expansion ratio.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 12:13:42 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Alemi", "Alireza", ""], ["Abbara", "Alia", ""]]}, {"id": "1705.07614", "submitter": "Robert Legenstein", "authors": "Zeno Jonke, Robert Legenstein, Stefan Habenschuss, Wolfgang Maass", "title": "Feedback inhibition shapes emergent computational properties of cortical\n  microcircuit motifs", "comments": "25 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical microcircuits are very complex networks, but they are composed of a\nrelatively small number of stereotypical motifs. Hence one strategy for\nthrowing light on the computational function of cortical microcircuits is to\nanalyze emergent computational properties of these stereotypical microcircuit\nmotifs. We are addressing here the question how spike-timing dependent\nplasticity (STDP) shapes the computational properties of one motif that has\nfrequently been studied experimentally: interconnected populations of pyramidal\ncells and parvalbumin-positive inhibitory cells in layer 2/3. Experimental\nstudies suggest that these inhibitory neurons exert some form of divisive\ninhibition on the pyramidal cells. We show that this data-based form of\nfeedback inhibition, which is softer than that of winner-take-all models that\nare commonly considered in theoretical analyses, contributes to the emergence\nof an important computational function through STDP: The capability to\ndisentangle superimposed firing patterns in upstream networks, and to represent\ntheir information content through a sparse assembly code.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 08:52:31 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Jonke", "Zeno", ""], ["Legenstein", "Robert", ""], ["Habenschuss", "Stefan", ""], ["Maass", "Wolfgang", ""]]}, {"id": "1705.07887", "submitter": "Abhishek Bhattacharjee", "authors": "Abhishek Bhattacharjee", "title": "Using Branch Predictors to Monitor Brain Activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem with neuroprostheses and brain monitoring interfaces is that\nthey need extreme energy efficiency. One way of lowering energy is to use the\nlow power modes avail- able on the processors embedded in these devices. We\npresent a technique to predict when neuronal activity of interest is likely to\noccur, so that the processor can run at nominal operating frequency at those\ntimes, and be placed in low power modes otherwise. To achieve this, we discover\nthat branch predictors can also predict brain activity. By performing brain\nsurgeries on awake and anesthetized mice, we evaluate several branch predictors\nand find that perceptron branch predictors can predict cerebellar activity with\naccuracies as high as 85%. Consequently, we co-opt branch predictors to dictate\nwhen to transition between low power and normal operating modes, saving as much\nas 59% of processor energy.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 19:24:18 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Bhattacharjee", "Abhishek", ""]]}, {"id": "1705.07998", "submitter": "Koray Ciftci", "authors": "Koray \\c{C}ift\\c{c}i", "title": "Synaptic Noise Facilitates the Emergence of Self-Organized Criticality\n  in the Caenorhabditis elegans Neuronal Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Avalanches with power-law distributed size parameters have been observed in\nneuronal networks. This observation might be a manifestation of the\nself-organized criticality (SOC). Yet, the physiological mechanicsm of this\nbehavior is currently unknown. Describing synaptic noise as transmission\nfailures mainly originating from the probabilistic nature of neurotransmitter\nrelease, this study investigates the potential of this noise as a mechanism for\ndriving the functional architecture of the neuronal networks towards SOC. To\nthis end, a simple finite state neuron model, with activity dependent and\nsynapse specific failure probabilities, was built based on the known anatomical\nconnectivity data of the nematode Ceanorhabditis elegans. Beginning from random\nvalues, it was observed that synaptic noise levels picked out a set of synapses\nand consequently an active subnetwork which generates power-law distributed\nneuronal avalanches. The findings of this study brings up the possibility that\nsynaptic failures might be a component of physiological processes underlying\nSOC in neuronal networks.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 20:55:43 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["\u00c7ift\u00e7i", "Koray", ""]]}, {"id": "1705.08006", "submitter": "Mainak Jas", "authors": "Mainak Jas and Tom Dupr\\'e La Tour and Umut \\c{S}im\\c{s}ekli and\n  Alexandre Gramfort", "title": "Learning the Morphology of Brain Signals Using Alpha-Stable\n  Convolutional Sparse Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural time-series data contain a wide variety of prototypical signal\nwaveforms (atoms) that are of significant importance in clinical and cognitive\nresearch. One of the goals for analyzing such data is hence to extract such\n'shift-invariant' atoms. Even though some success has been reported with\nexisting algorithms, they are limited in applicability due to their heuristic\nnature. Moreover, they are often vulnerable to artifacts and impulsive noise,\nwhich are typically present in raw neural recordings. In this study, we address\nthese issues and propose a novel probabilistic convolutional sparse coding\n(CSC) model for learning shift-invariant atoms from raw neural signals\ncontaining potentially severe artifacts. In the core of our model, which we\ncall $\\alpha$CSC, lies a family of heavy-tailed distributions called\n$\\alpha$-stable distributions. We develop a novel, computationally efficient\nMonte Carlo expectation-maximization algorithm for inference. The maximization\nstep boils down to a weighted CSC problem, for which we develop a\ncomputationally efficient optimization algorithm. Our results show that the\nproposed algorithm achieves state-of-the-art convergence speeds. Besides,\n$\\alpha$CSC is significantly more robust to artifacts when compared to three\ncompeting algorithms: it can extract spike bursts, oscillations, and even\nreveal more subtle phenomena such as cross-frequency coupling when applied to\nnoisy neural time series.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 21:09:13 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 12:51:41 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Jas", "Mainak", ""], ["La Tour", "Tom Dupr\u00e9", ""], ["\u015eim\u015fekli", "Umut", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1705.08026", "submitter": "Alireza Alemi", "authors": "Alireza Alemi, Christian Machens, Sophie Den\\`eve, Jean-Jacques\n  Slotine", "title": "Learning arbitrary dynamics in efficient, balanced spiking networks\n  using local plasticity rules", "comments": "minor editorial changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how recurrent neural circuits can learn to implement dynamical\nsystems is a fundamental challenge in neuroscience. The credit assignment\nproblem, i.e. determining the local contribution of each synapse to the\nnetwork's global output error, is a major obstacle in deriving biologically\nplausible local learning rules. Moreover, spiking recurrent networks\nimplementing such tasks should not be hugely costly in terms of number of\nneurons and spikes, as they often are when adapted from rate models. Finally,\nthese networks should be robust to noise and neural deaths in order to sustain\nthese representations in the face of such naturally occurring perturbation. We\napproach this problem by fusing the theory of efficient, balanced spiking\nnetworks (EBN) with nonlinear adaptive control theory. Local learning rules are\nensured by feeding back into the network its own error, resulting in a synaptic\nplasticity rule depending solely on presynaptic inputs and post-synaptic\nfeedback. The spiking efficiency and robustness of the network are guaranteed\nby maintaining a tight excitatory/inhibitory balance, ensuring that each spike\nrepresents a local projection of the global output error and minimizes a loss\nfunction. The resulting networks can learn to implement complex dynamics with\nvery small numbers of neurons and spikes, exhibit the same spike train\nvariability as observed experimentally, and are extremely robust to noise and\nneuronal loss.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 22:18:01 GMT"}, {"version": "v2", "created": "Sat, 5 Aug 2017 00:28:05 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Alemi", "Alireza", ""], ["Machens", "Christian", ""], ["Den\u00e8ve", "Sophie", ""], ["Slotine", "Jean-Jacques", ""]]}, {"id": "1705.08031", "submitter": "Alireza Alemi", "authors": "Sophie Den\\`eve, Alireza Alemi, Ralph Bourdoukan", "title": "The brain as an efficient and robust adaptive learner", "comments": "In press in Neuron journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how the brain learns to compute functions reliably, efficiently\nand robustly with noisy spiking activity is a fundamental challenge in\nneuroscience. Most sensory and motor tasks can be described as dynamical\nsystems and could presumably be learned by adjusting connection weights in a\nrecurrent biological neural network. However, this is greatly complicated by\nthe credit assignment problem for learning in recurrent network, e.g. the\ncontribution of each connection to the global output error cannot be determined\nbased only on locally accessible quantities to the synapse. Combining tools\nfrom adaptive control theory and efficient coding theories, we propose that\nneural circuits can indeed learn complex dynamic tasks with local synaptic\nplasticity rules as long as they associate two experimentally established\nneural mechanisms. First, they should receive top-down feedbacks driving both\ntheir activity and their synaptic plasticity. Second, inhibitory interneurons\nshould maintain a tight balance between excitation and inhibition in the\ncircuit. The resulting networks could learn arbitrary dynamical systems and\nproduce irregular spike trains as variable as those observed experimentally.\nYet, this variability in single neurons may hide an extremely efficient and\nrobust computation at the population level.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 22:36:10 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Den\u00e8ve", "Sophie", ""], ["Alemi", "Alireza", ""], ["Bourdoukan", "Ralph", ""]]}, {"id": "1705.08128", "submitter": "Andrei Khrennikov Yu", "authors": "Irina Basieva, Emmanuel Pothos, Jennifer Trueblood, Andrei Khrennikov,\n  and Jerome Busemeyer", "title": "Quantum probability updating from zero prior (by-passing Cromwell's\n  rule)", "comments": null, "journal-ref": "Journal of Mathematical Psychology, 77, 58-69 (2017)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cromwell's rule (also known as the zero priors paradox) refers to the\nconstraint of classical probability theory that if one assigns a prior\nprobability of 0 or 1 to a hypothesis, then the posterior has to be 0 or 1 as\nwell (this is a straightforward implication of how Bayes's rule works).\nRelatedly, hypotheses with a very low prior cannot be updated to have a very\nhigh posterior without a tremendous amount of new evidence to support them (or\nto make other possibilities highly improbable). Cromwell's rule appears at odds\nwith our intuition of how humans update probabilities. In this work, we report\ntwo simple decision making experiments, which seem to be inconsistent with\nCromwell's rule. Quantum probability theory, the rules for how to assign\nprobabilities from the mathematical formalism of quantum mechanics, provides an\nalternative framework for probabilistic inference. An advantage of quantum\nprobability theory is that it is not subject to Cromwell's rule and it can\naccommodate changes from zero or very small priors to significant posteriors.\nWe outline a model of decision making, based on quantum theory, which can\naccommodate the changes from priors to posteriors, observed in our experiments.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 08:45:35 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Basieva", "Irina", ""], ["Pothos", "Emmanuel", ""], ["Trueblood", "Jennifer", ""], ["Khrennikov", "Andrei", ""], ["Busemeyer", "Jerome", ""]]}, {"id": "1705.08145", "submitter": "Paolo Moretti", "authors": "Ali Safari, Paolo Moretti, Miguel A. Mu\\~noz", "title": "Topological dimension tunes activity patterns in hierarchical modular\n  network models", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": "10.1088/1367-2630/aa823e", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectivity patterns of relevance in neuroscience and systems biology can be\nencoded in hierarchical modular networks (HMNs). Moreover, recent studies\nhighlight the role of hierarchical modular organization in shaping brain\nactivity patterns, providing an excellent substrate to promote both the\nsegregation and integration of neural information. Here we propose an extensive\nnumerical analysis of the critical spreading rate (or \"epidemic\" threshold)\n--separating a phase with endemic persistent activity from one in which\nactivity ceases-- on diverse HMNs. By employing analytical and computational\ntechniques we determine the nature of such a threshold and scrutinize how it\ndepends on general structural features of the underlying HMN. We critically\ndiscuss the extent to which current graph-spectral methods can be applied to\npredict the onset of spreading in HMNs, and we propose the network topological\ndimension as a relevant and unifying structural parameter, controlling the\nepidemic threshold.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 09:03:14 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Safari", "Ali", ""], ["Moretti", "Paolo", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}, {"id": "1705.08261", "submitter": "Samir Suweis Dr.", "authors": "Chengyi Tu, Rodrigo P. Rocha, Maurizio Corbetta, Sandro Zampieri,\n  Marzo Zorzi and Samir Suweis", "title": "Warnings and Caveats in Brain Controllability", "comments": "9 pages, 1 Figure, 1 Table", "journal-ref": "NeuroImage, Volume 176, 1 August 2018, Pages 83-91", "doi": "10.1016/j.neuroimage.2018.04.010", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we challenge the main conclusions of Gu et al work\n(Controllability of structural brain networks. Nature communications 6, 8414,\ndoi:10.1038/ncomms9414, 2015) on brain controllability. Using the same methods\nand analyses on four datasets we find that the minimum set of nodes to control\nbrain networks is always larger than one. We also find that the relationships\nbetween the average/modal controllability and weighted degrees also hold for\nrandomized data and the there are not specific roles played by Resting State\nNetworks in controlling the brain. In conclusion, we show that there is no\nevidence that topology plays specific and unique roles in the controllability\nof brain networks. Accordingly, Gu et al. interpretation of their results, in\nparticular in terms of translational applications (e.g. using single node\ncontrollability properties to define target region(s) for neurostimulation)\nshould be revisited. Though theoretically intriguing, our understanding of the\nrelationship between controllability and structural brain network remains\nelusive.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 15:51:37 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Tu", "Chengyi", ""], ["Rocha", "Rodrigo P.", ""], ["Corbetta", "Maurizio", ""], ["Zampieri", "Sandro", ""], ["Zorzi", "Marzo", ""], ["Suweis", "Samir", ""]]}, {"id": "1705.08265", "submitter": "Biswa Sengupta", "authors": "Biswa Sengupta and Karl Friston", "title": "Sentient Self-Organization: Minimal dynamics and circular causality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theoretical arguments and empirical evidence in neuroscience suggests that\norganisms represent or model their environment by minimizing a variational\nfree-energy bound on the surprise associated with sensory signals from the\nenvironment. In this paper, we study phase transitions in coupled dissipative\ndynamical systems (complex Ginzburg-Landau equations) under a variety of\ncoupling conditions to model the exchange of a system (agent) with its\nenvironment. We show that arbitrary coupling between sensory signals and the\ninternal state of a system -- or those between its action and external\n(environmental) states -- do not guarantee synchronous dynamics between\nexternal and internal states: the spatial structure and the temporal dynamics\nof sensory signals and action (that comprise the system's Markov blanket) have\nto be pruned to produce synchrony. This synchrony is necessary for an agent to\ninfer environmental states -- a pre-requisite for survival. Therefore, such\nsentient dynamics, relies primarily on approximate synchronization between the\nagent and its niche.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 14:04:59 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Sengupta", "Biswa", ""], ["Friston", "Karl", ""]]}, {"id": "1705.08753", "submitter": "Rukhsan Ul Haq Wani", "authors": "Rukhsan Ul Haq and Shalini Harkar", "title": "Quantum theory of time perception: phases,clocks and quantum algebra", "comments": "8pp,typos corrected,references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience of time is one of the primordial human experiences which is deeply\ntied to human consciousness. But despite this intimate relation of time with\nhuman conscious experience, time has proved to be very elusive. Particularly in\nphysics, though there is already some understanding of time, there are still so\nmany paradoxes that plague this understanding. In this paper we take rather a\ndifferent route to question of time. We first attempt to come up with a\ntheoretical understanding of time perception. Quite interestingly we find that\nquantum theory provides an algebraic formulation within which we can understand\nsome essential aspects of time perception by human mind. We then ask whether a\nsimilar formalism can furnish the understanding of time as well and find\nconnections of our formulation of time with similar works by other researchers.\nOur underlying approach to question of time has been inspired by R. W. Hamilton\nwho considers algebra as science of pure time. Hence our work has an extensive\nalgebraic flavor. Our work also incorporates another approach based on\nKauffman's iterant algebra which relates time to underlying recursions and\noscillations. We believe that our work will initiate more investigations in\nthis direction.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 13:08:10 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 14:54:38 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Haq", "Rukhsan Ul", ""], ["Harkar", "Shalini", ""]]}, {"id": "1705.08756", "submitter": "R. A. J. van Elburg", "authors": "Oltman O. de Wiljes, Ronald A.J. van Elburg, Fred A. Keijzer", "title": "Short and random: Modelling the effects of (proto-)neural elongations", "comments": "12 pages, 5 figures, Keywords: early nervous systems, neural\n  elongations, nervous system evolution, computational modelling, internal\n  coordination", "journal-ref": null, "doi": "10.1098/rsif.2017.0399", "report-no": null, "categories": "q-bio.NC q-bio.PE q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand how neurons and nervous systems first evolved, we need an\naccount of the origins of neural elongations: Why did neural elongations (axons\nand dendrites) first originate, such that they could become the central\ncomponent of both neurons and nervous systems? Two contrasting conceptual\naccounts provide different answers to this question. Braitenberg's vehicles\nprovide the iconic illustration of the dominant input-output (IO) view. Here\nthe basic role of neural elongations is to connect sensors to effectors, both\nsituated at different positions within the body. For this function, neural\nelongations are thought of as comparatively long and specific connections,\nwhich require an articulated body involving substantial developmental processes\nto build. Internal coordination (IC) models stress a different function for\nearly nervous systems. Here the coordination of activity across extended parts\nof a multicellular body is held central, in particular for the contractions of\n(muscle) tissue. An IC perspective allows the hypothesis that the earliest\nproto-neural elongations could have been functional even when they were\ninitially simple short and random connections, as long as they enhanced the\npatterning of contractile activity across a multicellular surface. The present\ncomputational study provides a proof of concept that such short and random\nneural elongations can play this role. While an excitable epithelium can\ngenerate basic forms of patterning for small body-configurations, adding\nelongations allows such patterning to scale up to larger bodies. This result\nsupports a new, more gradual evolutionary route towards the origins of the very\nfirst full neurons and nervous systems.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 09:08:14 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["de Wiljes", "Oltman O.", ""], ["van Elburg", "Ronald A. J.", ""], ["Keijzer", "Fred A.", ""]]}, {"id": "1705.09132", "submitter": "Milad Mozafari", "authors": "Milad Mozafari, Saeed Reza Kheradpisheh, Timoth\\'ee Masquelier, Abbas\n  Nowzari-Dalini, Mohammad Ganjtabesh", "title": "First-spike based visual categorization using reward-modulated STDP", "comments": "supplementary materials are added, Caltech face/motorbike\n  demonstration figure is updated, some parts of the main manuscript are moved\n  to the supplementary materials, additional network analysis and performance\n  comparison with deep nets are added", "journal-ref": "Mozafari, Milad, et al. \"First-Spike-Based Visual Categorization\n  Using Reward-Modulated STDP\". IEEE Transactions on Neural Networks and\n  Learning Systems (2018). DOI: https://doi.org/10.1109/TNNLS.2018.2826721", "doi": "10.1109/TNNLS.2018.2826721", "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has recently regained popularity, with major\nachievements such as beating the European game of Go champion. Here, for the\nfirst time, we show that RL can be used efficiently to train a spiking neural\nnetwork (SNN) to perform object recognition in natural images without using an\nexternal classifier. We used a feedforward convolutional SNN and a temporal\ncoding scheme where the most strongly activated neurons fire first, while less\nactivated ones fire later, or not at all. In the highest layers, each neuron\nwas assigned to an object category, and it was assumed that the stimulus\ncategory was the category of the first neuron to fire. If this assumption was\ncorrect, the neuron was rewarded, i.e. spike-timing-dependent plasticity (STDP)\nwas applied, which reinforced the neuron's selectivity. Otherwise, anti-STDP\nwas applied, which encouraged the neuron to learn something else. As\ndemonstrated on various image datasets (Caltech, ETH-80, and NORB), this reward\nmodulated STDP (R-STDP) approach extracted particularly discriminative visual\nfeatures, whereas classic unsupervised STDP extracts any feature that\nconsistently repeats. As a result, R-STDP outperformed STDP on these datasets.\nFurthermore, R-STDP is suitable for online learning, and can adapt to drastic\nchanges such as label permutations. Finally, it is worth mentioning that both\nfeature extraction and classification were done with spikes, using at most one\nspike per neuron. Thus the network is hardware friendly and energy efficient.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 11:38:16 GMT"}, {"version": "v2", "created": "Tue, 2 Jan 2018 11:31:48 GMT"}, {"version": "v3", "created": "Tue, 10 Jul 2018 12:20:52 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Mozafari", "Milad", ""], ["Kheradpisheh", "Saeed Reza", ""], ["Masquelier", "Timoth\u00e9e", ""], ["Nowzari-Dalini", "Abbas", ""], ["Ganjtabesh", "Mohammad", ""]]}, {"id": "1705.09156", "submitter": "Christopher Buckley", "authors": "Christopher L. Buckley, Chang Sub Kim, Simon McGregor and Anil K. Seth", "title": "The free energy principle for action and perception: A mathematical\n  review", "comments": "77 pages 2 fugures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The 'free energy principle' (FEP) has been suggested to provide a unified\ntheory of the brain, integrating data and theory relating to action,\nperception, and learning. The theory and implementation of the FEP combines\ninsights from Helmholtzian 'perception as inference', machine learning theory,\nand statistical thermodynamics. Here, we provide a detailed mathematical\nevaluation of a suggested biologically plausible implementation of the FEP that\nhas been widely used to develop the theory. Our objectives are (i) to describe\nwithin a single article the mathematical structure of this implementation of\nthe FEP; (ii) provide a simple but complete agent-based model utilising the\nFEP; (iii) disclose the assumption structure of this implementation of the FEP\nto help elucidate its significance for the brain sciences.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 11:40:27 GMT"}], "update_date": "2017-05-26", "authors_parsed": [["Buckley", "Christopher L.", ""], ["Kim", "Chang Sub", ""], ["McGregor", "Simon", ""], ["Seth", "Anil K.", ""]]}, {"id": "1705.09205", "submitter": "Ernest Montbrio", "authors": "Federico Devalle, Alex Roxin, Ernest Montbri\\'o", "title": "Firing rate equations require a spike synchrony mechanism to correctly\n  describe fast oscillations in inhibitory networks", "comments": null, "journal-ref": "PLoS Comput Biol 13(12): e1005881 (2017)", "doi": "10.1371/journal.pcbi.1005881", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrently coupled networks of inhibitory neurons robustly generate\noscillations in the gamma band. Nonetheless, the corresponding Wilson-Cowan\ntype firing rate equation for such an inhibitory population does not generate\nsuch oscillations without an explicit time delay. We show that this discrepancy\nis due to a voltage-dependent spike-synchronization mechanism inherent in\nnetworks of spiking neurons which is not captured by standard firing rate\nequations. Here we investigate an exact low-dimensional description for a\nnetwork of heterogeneous canonical type-I inhibitory neurons which includes the\nsub-threshold dynamics crucial for generating synchronous states. In the limit\nof slow synaptic kinetics the spike-synchrony mechanism is suppressed and the\nstandard Wilson-Cowan equations are formally recovered as long as external\ninputs are also slow. However, even in this limit synchronous spiking can be\nelicited by inputs which fluctuate on a time-scale of the membrane\ntime-constant of the neurons. Our meanfield equations therefore represent an\nextension of the standard Wilson-Cowan equations in which spike synchrony is\nalso correctly described.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 14:48:31 GMT"}, {"version": "v2", "created": "Tue, 30 May 2017 06:31:31 GMT"}, {"version": "v3", "created": "Fri, 5 Jan 2018 14:10:07 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Devalle", "Federico", ""], ["Roxin", "Alex", ""], ["Montbri\u00f3", "Ernest", ""]]}, {"id": "1705.09249", "submitter": "Xinwei Sun", "authors": "Xinwei Sun, Lingjing Hu, Yuan Yao, Yizhou Wang", "title": "GSplit LBI: Taming the Procedural Bias in Neuroimaging for Disease\n  Prediction", "comments": "Conditional Accepted by Miccai,2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In voxel-based neuroimage analysis, lesion features have been the main focus\nin disease prediction due to their interpretability with respect to the related\ndiseases. However, we observe that there exists another type of features\nintroduced during the preprocessing steps and we call them \"\\textbf{Procedural\nBias}\". Besides, such bias can be leveraged to improve classification accuracy.\nNevertheless, most existing models suffer from either under-fit without\nconsidering procedural bias or poor interpretability without differentiating\nsuch bias from lesion ones. In this paper, a novel dual-task algorithm namely\n\\emph{GSplit LBI} is proposed to resolve this problem. By introducing an\naugmented variable enforced to be structural sparsity with a variable splitting\nterm, the estimators for prediction and selecting lesion features can be\noptimized separately and mutually monitored by each other following an\niterative scheme. Empirical experiments have been evaluated on the Alzheimer's\nDisease Neuroimaging Initiative\\thinspace(ADNI) database. The advantage of\nproposed model is verified by improved stability of selected lesion features\nand better classification results.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 16:25:14 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 06:01:19 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Sun", "Xinwei", ""], ["Hu", "Lingjing", ""], ["Yao", "Yuan", ""], ["Wang", "Yizhou", ""]]}, {"id": "1705.09730", "submitter": "Antonio Bianconi Prof.", "authors": "G. Campi, M. Di Gioacchino, N. Poccia, A. Ricci, M. Burghammer, A.\n  Bianconi", "title": "Intrinsic dynamical fluctuations of PNS myelin", "comments": "7 pages, 1 figure, International Conference Superstripes 2017, Ischia\n  (Italy) June, 4-10 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ultrastructure fluctuations and complex dynamics of the multi-layered\nmembrane structure of myelin are fundamental for understanding and control its\nformation process and its degeneration and repair in neurological diseases such\nas multiple sclerosis (MS). Myelin is considered a liquid-crystal but\ninformation are confined to its average structure due to limitations of the\navailable standard techniques. To overcome this limitation in this work we have\nused Scanning micro X-ray Diffraction (S{\\mu}XRD) which is a unique\nnon-invasive probe of both k-space and real space allowing to visualize\ndisorder in myelin with high spatial resolution in real space. We have used\nthis method to examine the myelin sheath in the sciatic nerve of Xenopus\nlaevis. Our results open could open new venues for understanding formation and\ndegradation of myelin.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 22:10:57 GMT"}, {"version": "v2", "created": "Thu, 1 Jun 2017 10:18:15 GMT"}, {"version": "v3", "created": "Thu, 26 Oct 2017 13:38:06 GMT"}], "update_date": "2017-10-27", "authors_parsed": [["Campi", "G.", ""], ["Di Gioacchino", "M.", ""], ["Poccia", "N.", ""], ["Ricci", "A.", ""], ["Burghammer", "M.", ""], ["Bianconi", "A.", ""]]}, {"id": "1705.09873", "submitter": "Sarah Fineberg", "authors": "Sarah K Fineberg, Jacob Leavitt, Christopher D Landry, Eli S\n  Neustadter, Rebecca Lesser, Dylan Stahl, Sasha Deutsch-Link, Philip R Corlett", "title": "Individuals with Borderline Personality Disorder Show Larger Preferred\n  Social Distance in Live Dyadic Interactions", "comments": "pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personal space (PS) regulation is a key component of effective social\nengagement. PS varies among individuals and is regulated by brain circuits\ninvolving the amygdala and the frontoparietal network. Others have reported\nthat simulated PS intrusions suggest larger preferred interpersonal distance\n(PID) and a central role of amygdala hyperactivity in PS regulation in\nBorderline Personality Disorder (BPD). This study is the first report of live\ninterpersonal distance preferences and relation to specific symptoms in BPD. We\nfound a 2-fold larger PID in BPD than control (n=30, n=23). There were no\nsignificant differences in PID in BPD subject by medication status or pre-study\ndiagnosis, and no significant correlations between PID and intensity of BPD,\nmood, anxiety, impulsive, or psychotic symptoms. In summary, PID is larger in\nBPD than control subjects. Unexpectedly, BPD subject PID did not differ in by\nmedication status and did not correlate with intensity of any of the symptom\ntypes tested. We discuss these findings in context of severe attachment\ndisturbances in BPD and the relationship between metaphoric social distance in\nthe attachment framework. Future work is needed to identify neural circuits\nunderlying PS regulation in BPD, individual differences in attachment, and\nrelationship to symptom trajectory.\n", "versions": [{"version": "v1", "created": "Sat, 27 May 2017 22:38:37 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Fineberg", "Sarah K", ""], ["Leavitt", "Jacob", ""], ["Landry", "Christopher D", ""], ["Neustadter", "Eli S", ""], ["Lesser", "Rebecca", ""], ["Stahl", "Dylan", ""], ["Deutsch-Link", "Sasha", ""], ["Corlett", "Philip R", ""]]}, {"id": "1705.09932", "submitter": "Ramon Ferrer i Cancho", "authors": "Ramon Ferrer-i-Cancho", "title": "The placement of the head that maximizes predictability. An information\n  theoretic approach", "comments": "in press in Glottometrics", "journal-ref": "Glottometrics 39, 38-71", "doi": null, "report-no": null, "categories": "cs.CL nlin.AO physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimization of the length of syntactic dependencies is a\nwell-established principle of word order and the basis of a mathematical theory\nof word order. Here we complete that theory from the perspective of information\ntheory, adding a competing word order principle: the maximization of\npredictability of a target element. These two principles are in conflict: to\nmaximize the predictability of the head, the head should appear last, which\nmaximizes the costs with respect to dependency length minimization. The\nimplications of such a broad theoretical framework to understand the\noptimality, diversity and evolution of the six possible orderings of subject,\nobject and verb are reviewed.\n", "versions": [{"version": "v1", "created": "Sun, 28 May 2017 12:19:03 GMT"}, {"version": "v2", "created": "Thu, 13 Jul 2017 05:31:21 GMT"}, {"version": "v3", "created": "Sun, 3 Sep 2017 12:25:35 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""]]}, {"id": "1705.10170", "submitter": "Rainer Kujala", "authors": "Rainer Kujala, Enrico Glerean, Raj Kumar Pan, Iiro P.\n  J\\\"a\\\"askel\\\"ainen, Mikko Sams, Jari Saram\\\"aki", "title": "Graph coarse-graining reveals differences in the module-level structure\n  of functional brain networks", "comments": "Manuscript + Supplementary materials", "journal-ref": "European Journal of Neuroscience, 2016, 44, 2673", "doi": "10.1111/ejn.13392", "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network analysis is rapidly becoming a standard tool for studying functional\nmagnetic resonance imaging (fMRI) data. In this framework, different brain\nareas are mapped to the nodes of a network, whose links depict functional\ndependencies between the areas. The sizes of the areas that the nodes portray\nvary between studies. Recently, it has been recommended that the original\nvolume elements, voxels, of the imaging experiment should be used as the\nnetwork nodes to avoid artefacts and biases. However, this results in a large\nnumbers of nodes and links, and the sheer amount of detail may obscure\nimportant network features that are manifested on larger scales. One fruitful\napproach to detecting such features is to partition networks into modules, i.e.\ngroups of nodes that are densely connected internally but have few connections\nbetween them. However, attempting to understand how functional networks differ\nby simply comparing their individual modular structures can be a daunting task,\nand results may be hard to interpret. We show that instead of comparing\ndifferent partitions, it is beneficial to analyze differences in the\nconnectivity between and within the very same modules in networks obtained\nunder different conditions. We develop a network coarse-graining methodology\nthat provides easily interpretable results and allows assessing the statistical\nsignificance of observed differences. The feasibility of the method is\ndemonstrated by analyzing fMRI data recorded from 13 healthy subjects during\nrest and movie viewing. While independent partitioning of the networks\ncorresponding to the the two conditions yields few insights on their\ndifferences, network coarse-graining allows us to pinpoint e.g. the increased\nnumber of intra-module links within the visual cortex during movie viewing.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 13:18:37 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Kujala", "Rainer", ""], ["Glerean", "Enrico", ""], ["Pan", "Raj Kumar", ""], ["J\u00e4\u00e4skel\u00e4inen", "Iiro P.", ""], ["Sams", "Mikko", ""], ["Saram\u00e4ki", "Jari", ""]]}, {"id": "1705.10358", "submitter": "Luis Aguirre", "authors": "Luis A. Aguirre, Leonardo L. Portes, Christophe Letellier", "title": "Observability and Synchronization of Neuron Models", "comments": null, "journal-ref": "Chaos, 65:83--99, 2017", "doi": "10.1063/1.4985291", "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Observability is the property that enables to distinguish two different\nlocations in $n$-dimensional state space from a reduced number of measured\nvariables, usually just one. In high-dimensional systems it is therefore\nimportant to make sure that the variable recorded to perform the analysis\nconveys good observability of the system dynamics. In the case of networks\ncomposed of neuron models, the observability of the network depends\nnontrivially on the observability of the node dynamics and on the topology of\nthe network. The aim of this paper is twofold. First, a study of observability\nis conducted using four well-known neuron models by computing three different\nobservability coefficients. This not only clarifies observability properties of\nthe models but also shows the limitations of applicability of each type of\ncoefficients in the context of such models. Second, a multivariate singular\nspectrum analysis (M-SSA) is performed to detect phase synchronization in\nnetworks composed by neuron models. This tool, to the best of the authors'\nknowledge has not been used in the context of networks of neuron models. It is\nshown that it is possible to detect phase synchronization i)~without having to\nmeasure all the state variables, but only one from each node, and ii)~without\nhaving to estimate the phase.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 18:44:33 GMT"}], "update_date": "2019-05-06", "authors_parsed": [["Aguirre", "Luis A.", ""], ["Portes", "Leonardo L.", ""], ["Letellier", "Christophe", ""]]}, {"id": "1705.10435", "submitter": "Christopher Kovach", "authors": "Christopher K. Kovach, Hiroyuki Oya and Hiroto Kawasaki", "title": "The Bispectrum and Its Relationship to Phase-Amplitude Coupling", "comments": null, "journal-ref": "NeuroImage 173, 2018, 518 - 539", "doi": "10.1016/j.neuroimage.2018.02.033", "report-no": null, "categories": "stat.ME q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most biological signals are non-Gaussian, reflecting their origins in highly\nnonlinear physiological systems. A versatile set of techniques for studying\nnon-Gaussian signals relies on the spectral representations of higher moments,\nknown as polyspectra, which describe forms of cross-frequency dependence that\ndo not arise in time-invariant Gaussian signals. The most commonly used of\nthese employ the bispectrum. Recently, other measures of cross-frequency\ndependence have drawn interest in EEG literature, in particular those which\naddress phase-amplitude coupling (PAC). Here we demonstrate a close\nrelationship between the bispectrum and popular measures of PAC, which we\nrelate to smoothings of the signal bispectrum, making them fundamentally\nbispectral estimators. Viewed this way, however, conventional PAC measures\nexhibit some unfavorable qualities, including poor bias properties, lack of\ncorrect symmetry and artificial constraints on the spectral range and\nresolution of the estimate. Moreover, information obscured by smoothing in\nmeasures of PAC, but preserved in standard bispectral estimators, may be\ncritical for distinguishing nested oscillations from transient signal features\nand other non-oscillatory causes of \"spurious\" PAC. We propose guidelines for\ngauging the nature and origin of cross-frequency coupling with bispectral\nstatistics. Beyond clarifying the relationship between PAC and the bispectrum,\nthe present work lays out a general framework for the interpretation of the\nbispectrum, which extends to other higher-order spectra. In particular, this\nframework holds promise for the detailed identification of signal features\nrelated to both nested oscillations and transient phenomena. We conclude with a\ndiscussion of some broader theoretical implications of this framework and\nhighlight promising directions for future development.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 02:36:54 GMT"}, {"version": "v2", "created": "Thu, 1 Mar 2018 19:18:39 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Kovach", "Christopher K.", ""], ["Oya", "Hiroyuki", ""], ["Kawasaki", "Hiroto", ""]]}, {"id": "1705.10478", "submitter": "Christian Schmidt", "authors": "Christian Schmidt and Ursula van Rienen", "title": "Adaptive Estimation of the Neural Activation Extent in Computational\n  Volume Conductor Models of Deep Brain Stimulation", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: The aim of this study is to propose an adaptive scheme embedded\ninto an open-source environment for the estimation of the neural activation\nextent during deep brain stimulation and to investigate the feasibility of\napproximating the neural activation extent by thresholds of the field solution.\nMethods: Open-source solutions for solving the field equation in volume\nconductor models of deep brain stimulation and computing the neural activation\nare embedded into a Python package to estimate the neural activation dependent\non the dielectric tissue properties and axon parameters by employing a\nspatially adaptive scheme. Feasibility of the approximation of the neural\nactivation extent by field thresholds is investigated to further reduce the\ncomputational expense. Results: The varying extents of neural activation for\ndifferent patient-specific dielectric properties were estimated with the\nadaptive scheme. The results revealed the strong influence of the dielectric\nproperties of the encapsulation layer in the acute and chronic phase after\nsurgery. The computational time required to determine the neural activation\nextent in each studied model case was substantially reduced. Conclusion: The\nneural activation extent is altered by patient-specific parameters. Threshold\nvalues of the electric potential and electric field norm facilitate a\ncomputationally efficient method to estimate the neural activation extent.\nSignificance: The presented adaptive scheme is able to robustly determine\nneural activation extents and field threshold estimates for varying dielectric\ntissue properties and axon diameters while reducing substantially the\ncomputational expense.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 07:12:21 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 14:50:12 GMT"}, {"version": "v3", "created": "Mon, 7 Aug 2017 18:24:45 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Schmidt", "Christian", ""], ["van Rienen", "Ursula", ""]]}, {"id": "1705.10496", "submitter": "Christian Schmidt", "authors": "Christian Schmidt and Eleanor Dunn and Madeleine Lowery and Ursula van\n  Rienen", "title": "Uncertainty Quantification of Oscillation Suppression during DBS in a\n  Coupled Finite Element and Network Model", "comments": "10 pages", "journal-ref": null, "doi": "10.1109/TNSRE.2016.2608925", "report-no": null, "categories": "q-bio.NC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Models of the cortico-basal ganglia network and volume conductor models of\nthe brain can provide insight into the mechanisms of action of deep brain\nstimulation (DBS). In this study, the coupling of a network model, under\nparkinsonian conditions, to the extracellular field distribution obtained from\na three dimensional finite element model of a rodent's brain during DBS is\npresented. This coupled model is used to investigate the influence of\nuncertainty in the electrical properties of brain tissue and encapsulation\ntissue, formed around the electrode after implantation, on the suppression of\noscillatory neural activity during DBS. The resulting uncertainty in this\neffect of DBS on the network activity is quantified using a computationally\nefficient and non-intrusive stochastic approach based on the generalized\nPolynomial Chaos. The results suggest that variations in the electrical\nproperties of brain tissue may have a substantial influence on the level of\nsuppression of oscillatory activity during DBS. Applying a global sensitivity\nanalysis on the suppression of the simulated oscillatory activity showed that\nthe influence of uncertainty in the electrical properties of the encapsulation\ntissue had only a minor influence, in agreement with previous experimental and\ncomputational studies investigating the mechanisms of current-controlled DBS in\nthe literature.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 07:59:49 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Schmidt", "Christian", ""], ["Dunn", "Eleanor", ""], ["Lowery", "Madeleine", ""], ["van Rienen", "Ursula", ""]]}, {"id": "1705.10672", "submitter": "David Esp\\'indola", "authors": "David Espindola, Stephen Lee and Gianmarco Pinton", "title": "Shear shock waves are observed in the brain", "comments": null, "journal-ref": "Phys. Rev. Applied 8, 044024 (2017)", "doi": "10.1103/PhysRevApplied.8.044024", "report-no": null, "categories": "cond-mat.soft physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The internal deformation of the brain is far more complex than the rigid\nmotion of the skull. An ultrasound imaging technique that we have developed has\na combination of penetration, frame-rate, and motion detection accuracy\nrequired to directly observe, for the first time, the formation and evolution\nof shear shock waves in the brain. Experiments at low impacts on the traumatic\nbrain injury scale demonstrate that they are spontaneously generated and\npropagate within the porcine brain. Compared to the initially smooth impact,\nthe acceleration at the shock front is amplified up to a factor of 8.5. This\nhighly localized increase in acceleration suggests that shear shock waves are a\nfundamental mechanism for traumatic injuries in soft tissue.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 14:29:34 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Espindola", "David", ""], ["Lee", "Stephen", ""], ["Pinton", "Gianmarco", ""]]}, {"id": "1705.10805", "submitter": "Jun Qin", "authors": "Wisam Subhi Al-Dayyeni, Pengfei Sun, Jun Qin", "title": "Investigations of Auditory Filters Based Excitation Patterns for\n  Assessment of Noise Induced Hearing Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noise induced hearing loss (NIHL) as one of major avoidable occupational\nrelated health issues has been studied for decades. To assess NIHL, the\nexcitation pattern (EP) has been considered as one of mechanisms to estimate\nmovements of basilar membrane (BM) in cochlea. In this study, two auditory\nfilters, dual resonance nonlinear (DRNL) filter and rounded-exponential (ROEX)\nfilter, have been applied to create two EPs, referring as the velocity EP and\nthe loudness EP, respectively. Two noise hazard metrics are also proposed based\non the developed EPs to evaluate hazardous levels caused by different types of\nnoise. Moreover, Gaussian noise and pure-tone noise have been simulated to\nevaluate performances of the developed EPs and noise metrics. The results show\nthat both developed EPs can reflect the responses of BM to different types of\nnoise. For Gaussian noise, there is a frequency shift between the velocity EP\nand the loudness EP. For pure-tone noise, both EPs can reflect the frequencies\nof input noise accurately. The results suggest that both EPs can be potentially\nused for assessment of NIHL.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 18:02:35 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Al-Dayyeni", "Wisam Subhi", ""], ["Sun", "Pengfei", ""], ["Qin", "Jun", ""]]}, {"id": "1705.10854", "submitter": "Larissa Albantakis", "authors": "Larissa Albantakis", "title": "A Tale of Two Animats: What does it take to have goals?", "comments": "This article is a contribution to the FQXi 2016-2017 essay contest\n  \"Wandering Towards a Goal\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What does it take for a system, biological or not, to have goals? Here, this\nquestion is approached in the context of in silico artificial evolution. By\nexamining the informational and causal properties of artificial organisms\n('animats') controlled by small, adaptive neural networks (Markov Brains), this\nessay discusses necessary requirements for intrinsic information, autonomy, and\nmeaning. The focus lies on comparing two types of Markov Brains that evolved in\nthe same simple environment: one with purely feedforward connections between\nits elements, the other with an integrated set of elements that causally\nconstrain each other. While both types of brains 'process' information about\ntheir environment and are equally fit, only the integrated one forms a causally\nautonomous entity above a background of external influences. This suggests that\nto assess whether goals are meaningful for a system itself, it is important to\nunderstand what the system is, rather than what it does.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 20:19:17 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Albantakis", "Larissa", ""]]}, {"id": "1705.10882", "submitter": "David Rolnick", "authors": "David Rolnick, Yaron Meirovitch, Toufiq Parag, Hanspeter Pfister,\n  Viren Jain, Jeff W. Lichtman, Edward S. Boyden, Nir Shavit", "title": "Morphological Error Detection in 3D Segmentations", "comments": "13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning algorithms for connectomics rely upon localized classification,\nrather than overall morphology. This leads to a high incidence of erroneously\nmerged objects. Humans, by contrast, can easily detect such errors by acquiring\nintuition for the correct morphology of objects. Biological neurons have\ncomplicated and variable shapes, which are challenging to learn, and merge\nerrors take a multitude of different forms. We present an algorithm, MergeNet,\nthat shows 3D ConvNets can, in fact, detect merge errors from high-level\nneuronal morphology. MergeNet follows unsupervised training and operates across\ndatasets. We demonstrate the performance of MergeNet both on a variety of\nconnectomics data and on a dataset created from merged MNIST images.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 22:25:44 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Rolnick", "David", ""], ["Meirovitch", "Yaron", ""], ["Parag", "Toufiq", ""], ["Pfister", "Hanspeter", ""], ["Jain", "Viren", ""], ["Lichtman", "Jeff W.", ""], ["Boyden", "Edward S.", ""], ["Shavit", "Nir", ""]]}, {"id": "1705.11146", "submitter": "Friedemann Zenke", "authors": "Friedemann Zenke and Surya Ganguli", "title": "SuperSpike: Supervised learning in multi-layer spiking neural networks", "comments": null, "journal-ref": null, "doi": "10.1162/neco_a_01086", "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A vast majority of computation in the brain is performed by spiking neural\nnetworks. Despite the ubiquity of such spiking, we currently lack an\nunderstanding of how biological spiking neural circuits learn and compute\nin-vivo, as well as how we can instantiate such capabilities in artificial\nspiking circuits in-silico. Here we revisit the problem of supervised learning\nin temporally coding multi-layer spiking neural networks. First, by using a\nsurrogate gradient approach, we derive SuperSpike, a nonlinear voltage-based\nthree factor learning rule capable of training multi-layer networks of\ndeterministic integrate-and-fire neurons to perform nonlinear computations on\nspatiotemporal spike patterns. Second, inspired by recent results on feedback\nalignment, we compare the performance of our learning rule under different\ncredit assignment strategies for propagating output errors to hidden units.\nSpecifically, we test uniform, symmetric and random feedback, finding that\nsimpler tasks can be solved with any type of feedback, while more complex tasks\nrequire symmetric feedback. In summary, our results open the door to obtaining\na better scientific understanding of learning and computation in spiking neural\nnetworks by advancing our ability to train them to solve nonlinear problems\ninvolving transformations between different spatiotemporal spike-time patterns.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 15:31:26 GMT"}, {"version": "v2", "created": "Sat, 14 Oct 2017 15:08:04 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Zenke", "Friedemann", ""], ["Ganguli", "Surya", ""]]}, {"id": "1705.11190", "submitter": "Xerxes D. Arsiwalla", "authors": "Xerxes D. Arsiwalla, Ricard Sole, Clement Moulin-Frier, Ivan Herreros,\n  Marti Sanchez-Fibla, Paul Verschure", "title": "The Morphospace of Consciousness", "comments": "23 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.AI physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a complexity-based morphospace to study systems-level properties\nof conscious & intelligent systems. The axes of this space label 3 complexity\ntypes: autonomous, cognitive & social. Given recent proposals to synthesize\nconsciousness, a generic complexity-based conceptualization provides a useful\nframework for identifying defining features of conscious & synthetic systems.\nBased on current clinical scales of consciousness that measure cognitive\nawareness and wakefulness, we take a perspective on how contemporary\nartificially intelligent machines & synthetically engineered life forms measure\non these scales. It turns out that awareness & wakefulness can be associated to\ncomputational & autonomous complexity respectively. Subsequently, building on\ninsights from cognitive robotics, we examine the function that consciousness\nserves, & argue the role of consciousness as an evolutionary game-theoretic\nstrategy. This makes the case for a third type of complexity for describing\nconsciousness: social complexity. Having identified these complexity types,\nallows for a representation of both, biological & synthetic systems in a common\nmorphospace. A consequence of this classification is a taxonomy of possible\nconscious machines. We identify four types of consciousness, based on\nembodiment: (i) biological consciousness, (ii) synthetic consciousness, (iii)\ngroup consciousness (resulting from group interactions), & (iv) simulated\nconsciousness (embodied by virtual agents within a simulated reality). This\ntaxonomy helps in the investigation of comparative signatures of consciousness\nacross domains, in order to highlight design principles necessary to engineer\nconscious machines. This is particularly relevant in the light of recent\ndevelopments at the crossroads of cognitive neuroscience, biomedical\nengineering, artificial intelligence & biomimetics.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 17:45:39 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 17:42:04 GMT"}, {"version": "v3", "created": "Sat, 24 Nov 2018 23:05:40 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Arsiwalla", "Xerxes D.", ""], ["Sole", "Ricard", ""], ["Moulin-Frier", "Clement", ""], ["Herreros", "Ivan", ""], ["Sanchez-Fibla", "Marti", ""], ["Verschure", "Paul", ""]]}]