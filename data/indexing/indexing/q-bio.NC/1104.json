[{"id": "1104.0025", "submitter": "Chris Adami", "authors": "Christoph Adami, Jifeng Qian, Matthew Rupp, and Arend Hintze", "title": "Information content of colored motifs in complex networks", "comments": "21 pages, 8 figures, to appear in Artificial Life", "journal-ref": "Artificial Life 17 (2011) 375-390", "doi": "10.1162/artl_a_00045", "report-no": null, "categories": "q-bio.QM cs.IT math.IT nlin.AO q-bio.MN q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study complex networks in which the nodes of the network are tagged with\ndifferent colors depending on the functionality of the nodes (colored graphs),\nusing information theory applied to the distribution of motifs in such\nnetworks. We find that colored motifs can be viewed as the building blocks of\nthe networks (much more so than the uncolored structural motifs can be) and\nthat the relative frequency with which these motifs appear in the network can\nbe used to define the information content of the network. This information is\ndefined in such a way that a network with random coloration (but keeping the\nrelative number of nodes with different colors the same) has zero color\ninformation content. Thus, colored motif information captures the\nexceptionality of coloring in the motifs that is maintained via selection. We\nstudy the motif information content of the C. elegans brain as well as the\nevolution of colored motif information in networks that reflect the interaction\nbetween instructions in genomes of digital life organisms. While we find that\ncolored motif information appears to capture essential functionality in the C.\nelegans brain (where the color assignment of nodes is straightforward) it is\nnot obvious whether the colored motif information content always increases\nduring evolution, as would be expected from a measure that captures network\ncomplexity. For a single choice of color assignment of instructions in the\ndigital life form Avida, we find rather that colored motif information content\nincreases or decreases during evolution, depending on how the genomes are\norganized, and therefore could be an interesting tool to dissect genomic\nrearrangements.\n", "versions": [{"version": "v1", "created": "Thu, 31 Mar 2011 20:35:44 GMT"}], "update_date": "2011-11-08", "authors_parsed": [["Adami", "Christoph", ""], ["Qian", "Jifeng", ""], ["Rupp", "Matthew", ""], ["Hintze", "Arend", ""]]}, {"id": "1104.0305", "submitter": "C.C. Alan Fung", "authors": "C. C. Alan Fung, K. Y. Michael Wong, He Wang, Si Wu", "title": "Dynamical Synapses Enhance Neural Information Processing: Gracefulness,\n  Accuracy and Mobility", "comments": "40 pages, 17 figures", "journal-ref": "Neural Comput. 24 (2012) 1147-1185", "doi": "10.1162/NECO_a_00269", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental data have revealed that neuronal connection efficacy exhibits\ntwo forms of short-term plasticity, namely, short-term depression (STD) and\nshort-term facilitation (STF). They have time constants residing between fast\nneural signaling and rapid learning, and may serve as substrates for neural\nsystems manipulating temporal information on relevant time scales. The present\nstudy investigates the impact of STD and STF on the dynamics of continuous\nattractor neural networks (CANNs) and their potential roles in neural\ninformation processing. We find that STD endows the network with slow-decaying\nplateau behaviors-the network that is initially being stimulated to an active\nstate decays to a silent state very slowly on the time scale of STD rather than\non the time scale of neural signaling. This provides a mechanism for neural\nsystems to hold sensory memory easily and shut off persistent activities\ngracefully. With STF, we find that the network can hold a memory trace of\nexternal inputs in the facilitated neuronal interactions, which provides a way\nto stabilize the network response to noisy inputs, leading to improved accuracy\nin population decoding. Furthermore, we find that STD increases the mobility of\nthe network states. The increased mobility enhances the tracking performance of\nthe network in response to time-varying stimuli, leading to anticipative neural\nresponses. In general, we find that STD and STP tend to have opposite effects\non network dynamics and complementary computational advantages, suggesting that\nthe brain may employ a strategy of weighting them differentially depending on\nthe computational purpose.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2011 09:10:42 GMT"}, {"version": "v2", "created": "Mon, 11 Apr 2011 09:42:36 GMT"}, {"version": "v3", "created": "Thu, 5 Apr 2012 01:30:21 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Fung", "C. C. Alan", ""], ["Wong", "K. Y. Michael", ""], ["Wang", "He", ""], ["Wu", "Si", ""]]}, {"id": "1104.1090", "submitter": "Juergen Reingruber", "authors": "Juergen Reingruber and David Holcman", "title": "The Narrow Escape problem in a flat cylindrical microdomain with\n  application to diffusion in the synaptic cleft", "comments": "24 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mean first passage time (MFPT) for a Brownian particle to reach a small\ntarget in cellular microdomains is a key parameter for chemical activation.\nAlthough asymptotic estimations of the MFPT are available for various\ngeometries, these formula cannot be applied to degenerated structures where one\ndimension of is much smaller compared to the others. Here we study the narrow\nescape time (NET) problem for a Brownian particle to reach a small target\nlocated on the surface of a flat cylinder, where the cylinder height is\ncomparable to the target size, and much smaller than the cylinder radius. When\nthe cylinder is sealed, we estimate the MFPT for a Brownian particle to hit a\nsmall disk located centrally on the lower surface. For a laterally open\ncylinder, we estimate the conditional probability and the conditional MFPT to\nreach the small disk before exiting through the lateral opening. We apply our\nresults to diffusion in the narrow synaptic cleft, and compute the fraction and\nthe mean time for neurotransmitters to find their specific receptors located on\nthe postsynaptic terminal. Finally, we confirm our formulas with Brownian\nsimulations.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2011 13:20:03 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Reingruber", "Juergen", ""], ["Holcman", "David", ""]]}, {"id": "1104.1202", "submitter": "Joaquin Torres", "authors": "J.J. Torres and J. Marro and J.F. Mejias", "title": "Can intrinsic noise induce various resonant peaks?", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": "10.1088/1367-2630/13/5/053014", "report-no": null, "categories": "physics.data-an cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We theoretically describe how weak signals may be efficiently transmitted\nthroughout more than one frequency range in noisy excitable media by kind of\nstochastic multiresonance. This serves us here to reinterpret recent\nexperiments in neuroscience, and to suggest that many other systems in nature\nmight be able to exhibit several resonances. In fact, the observed behavior\nhappens in our (network) model as a result of competition between (1) changes\nin the transmitted signals as if the units were varying their activation\nthreshold, and (2) adaptive noise realized in the model as rapid\nactivity-dependent fluctuations of the connection intensities. These two\nconditions are indeed known to characterize heterogeneously networked systems\nof excitable units, e.g., sets of neurons and synapses in the brain. Our\nresults may find application also in the design of detector devices.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2011 21:58:05 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Torres", "J. J.", ""], ["Marro", "J.", ""], ["Mejias", "J. F.", ""]]}, {"id": "1104.1355", "submitter": "Cedric Ginestet", "authors": "Cedric E. Ginestet and Andrew Simmons", "title": "Recursive Shortest Path Algorithm with Application to\n  Density-integration of Weighted Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.DS q-bio.NC stat.CO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Graph theory is increasingly commonly utilised in genetics, proteomics and\nneuroimaging. In such fields, the data of interest generally constitute\nweighted graphs. Analysis of such weighted graphs often require the integration\nof topological metrics with respect to the density of the graph. Here, density\nrefers to the proportion of the number of edges present in that graph. When\ntopological metrics based on shortest paths are of interest, such\ndensity-integration usually necessitates the iterative application of\nDijkstra's algorithm in order to compute the shortest path matrix at each\ndensity level. In this short note, we describe a recursive shortest path\nalgorithm based on single edge updating, which replaces the need for the\niterative use of Dijkstra's algorithm. Our proposed procedure is based on pairs\nof breadth-first searches around each of the vertices incident to the edge\nadded at each recursion. An algorithmic analysis of the proposed technique is\nprovided. When the graph of interest is coded as an adjacency list, our\nalgorithm can be shown to be more efficient than an iterative use of Dijkstra's\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2011 15:23:24 GMT"}], "update_date": "2011-06-09", "authors_parsed": [["Ginestet", "Cedric E.", ""], ["Simmons", "Andrew", ""]]}, {"id": "1104.1503", "submitter": "Jocelyne Troccaz", "authors": "R\\'emy Cuisinier (TIMC), Isabelle Olivier (TIMC), Jocelyne Troccaz\n  (TIMC), Nicolas Vuillerme (AGIM), Vincent Nougier (TIMC)", "title": "Short-term memory effects of an auditory biofeedback on isometric force\n  control: Is there a differential effect as a function of transition trials?", "comments": "Human Movement Science (2011) epub ahead of print", "journal-ref": null, "doi": "10.1016/j.humov.2010.06.008", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the present study was to investigate memory effects, force\naccuracy, and variability during constant isometric force at different force\nlevels, using auditory biofeedback. Two types of transition trials were used: a\nbiofeedback-no biofeedback transition trial and a no biofeedback-biofeedback\ntransition trial. The auditory biofeedback produced a low- or high-pitched\nsound when participants produced an isometric force lower or higher than\nrequired, respectively. To achieve this goal, 16 participants were asked to\nproduce and maintain two different isometric forces (30$\\pm$5% and 90N$\\pm$5%)\nduring 25s. Constant error and standard deviation of the isometric force were\ncalculated. While accuracy and variability of the isometric force varied\naccording to the transition trial, a drift of the force appeared in the no\nbiofeedback condition. This result suggested that the degradation of\ninformation about force output in the no biofeedback condition was provided by\na leaky memory buffer which was mainly dependent on the sense of effort.\nBecause this drift remained constant whatever the transition used, this memory\nbuffer seemed to be independent of short-term memory processes.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2011 07:31:18 GMT"}], "update_date": "2011-04-11", "authors_parsed": [["Cuisinier", "R\u00e9my", "", "TIMC"], ["Olivier", "Isabelle", "", "TIMC"], ["Troccaz", "Jocelyne", "", "TIMC"], ["Vuillerme", "Nicolas", "", "AGIM"], ["Nougier", "Vincent", "", "TIMC"]]}, {"id": "1104.1824", "submitter": "Francis Cabarle", "authors": "Francis Cabarle, Henry Adorna, Miguel A. Martinez-del-Amor", "title": "Simulating Spiking Neural P systems without delays using GPUs", "comments": "19 pages in total, 4 figures, listings/algorithms, submitted at the\n  9th Brainstorming Week in Membrane Computing, University of Seville, Spain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.ET cs.FL cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present in this paper our work regarding simulating a type of P system\nknown as a spiking neural P system (SNP system) using graphics processing units\n(GPUs). GPUs, because of their architectural optimization for parallel\ncomputations, are well-suited for highly parallelizable problems. Due to the\nadvent of general purpose GPU computing in recent years, GPUs are not limited\nto graphics and video processing alone, but include computationally intensive\nscientific and mathematical applications as well. Moreover P systems, including\nSNP systems, are inherently and maximally parallel computing models whose\ninspirations are taken from the functioning and dynamics of a living cell. In\nparticular, SNP systems try to give a modest but formal representation of a\nspecial type of cell known as the neuron and their interactions with one\nanother. The nature of SNP systems allowed their representation as matrices,\nwhich is a crucial step in simulating them on highly parallel devices such as\nGPUs. The highly parallel nature of SNP systems necessitate the use of hardware\nintended for parallel computations. The simulation algorithms, design\nconsiderations, and implementation are presented. Finally, simulation results,\nobservations, and analyses using an SNP system that generates all numbers in\n$\\mathbb N$ - {1} are discussed, as well as recommendations for future work.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2011 01:17:01 GMT"}], "update_date": "2011-04-13", "authors_parsed": [["Cabarle", "Francis", ""], ["Adorna", "Henry", ""], ["Martinez-del-Amor", "Miguel A.", ""]]}, {"id": "1104.1946", "submitter": "Wolfgang Keil", "authors": "Wolfgang Keil and Fred Wolf", "title": "Coverage, Continuity and Visual Cortical Architecture", "comments": "100 pages, including an Appendix, 21 + 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary visual cortex of many mammals contains a continuous\nrepresentation of visual space, with a roughly repetitive aperiodic map of\norientation preferences superimposed. It was recently found that orientation\npreference maps (OPMs) obey statistical laws which are apparently invariant\namong species widely separated in eutherian evolution. Here, we examine whether\none of the most prominent models for the optimization of cortical maps, the\nelastic net (EN) model, can reproduce this common design. The EN model\ngenerates representations which optimally trade of stimulus space coverage and\nmap continuity. While this model has been used in numerous studies, no\nanalytical results about the precise layout of the predicted OPMs have been\nobtained so far. We present a mathematical approach to analytically calculate\nthe cortical representations predicted by the EN model for the joint mapping of\nstimulus position and orientation. We find that in all previously studied\nregimes, predicted OPM layouts are perfectly periodic. An unbiased search\nthrough the EN parameter space identifies a novel regime of aperiodic OPMs with\npinwheel densities lower than found in experiments. In an extreme limit,\naperiodic OPMs quantitatively resembling experimental observations emerge.\nStabilization of these layouts results from strong nonlocal interactions rather\nthan from a coverage-continuity-compromise. Our results demonstrate that\noptimization models for stimulus representations dominated by nonlocal\nsuppressive interactions are in principle capable of correctly predicting the\ncommon OPM design. They question that visual cortical feature representations\ncan be explained by a coverage-continuity-compromise.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2011 13:38:22 GMT"}, {"version": "v2", "created": "Sun, 4 Dec 2011 13:17:50 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Keil", "Wolfgang", ""], ["Wolf", "Fred", ""]]}, {"id": "1104.2443", "submitter": "Gabriel Lord", "authors": "Emma J. Coutts and Gabriel J. Lord", "title": "Effects of noise on models of spiny dendrites", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effects of noise in two models of spiny dendrites. Through the\nintroduction of different types of noise to both the Spike-diffuse-spike (SDS)\nand Baer-Rinzel (BR) models we investigate the change in behaviour of the\ntravelling wave solutions present in the deterministic systems, as noise\nintensity increases. We show that the speed of wave propagation in the SDS and\nBR models respectively decreases and increases as the noise intensity in the\nspine heads increases. Interestingly the discrepancy between the models does\nnot seem to arise from the type of active spine head dynamics employed by the\nmodel but rather by the form of the spine density used. In contrast the cable\nis very robust to noise and as such the speed shows very little variation from\nthe deterministic system. We look at the effect of the noise interpretation\nused to evaluate the stochastic integral; Ito or Statonovich and discuss which\nmay be appropriate. We also show that the correlation time and length scales of\nthe noise can enhance propagation of travelling wave solutions where the white\nnoise dominates the signal and produces noise induced phenomena.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2011 10:48:21 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Coutts", "Emma J.", ""], ["Lord", "Gabriel J.", ""]]}, {"id": "1104.2532", "submitter": "Sebastiano Stramaglia", "authors": "Sebastiano Stramaglia, Daniele Marinazzo, Mario Pellicoro, and Marina\n  de Tommaso", "title": "Abnormal effective connectivity in migraine with aura under photic\n  stimulation", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Migraine patients with aura show a peculiar pattern of visual reactivity\ncompared with those of migraine patients without aura: an increased effective\nconnectivity, connected to a reduced synchronization among EEG channels, for\nfrequencies in the beta band. The effective connectivity is evaluated in terms\nof the Granger causality. This anomalous response to visual stimuli may play a\ncrucial role in the progression of spreading depression and clinical evidences\nof aura symptoms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2011 15:51:15 GMT"}, {"version": "v2", "created": "Wed, 11 May 2011 18:19:53 GMT"}], "update_date": "2011-05-12", "authors_parsed": [["Stramaglia", "Sebastiano", ""], ["Marinazzo", "Daniele", ""], ["Pellicoro", "Mario", ""], ["de Tommaso", "Marina", ""]]}, {"id": "1104.2616", "submitter": "Pascal Grange", "authors": "Pascal Grange, Partha P. Mitra", "title": "Algorithmic choice of coordinates for injections into the brain:\n  encoding a neuroanatomical atlas on a grid", "comments": "13 pages, LaTeX", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an atlas of the brain and a number of injections to be performed in\norder to map out the connections between parts of the brain, we propose an\nalgorithm to compute the coordinates of the injections. The algorithm is\ndesigned to sample the brain in the most homogeneous way compatible with the\nseparation of brain regions. It can be applied to other species for which a\nneuroanatomical atlas is available. The computation is tested on the annotation\nat a resolution of 25 microns corresponding to the Allen Reference Atlas, which\nis hierarchical and consists of 209 regions. The resulting injection\ncoordinates are being used for the injection protocol of the Mouse Brain\nArchitecture project. Due to its large size and layered structure, the cerebral\ncortex is treated in a separate algorithm, which is more adapted to its\ngeometry.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2011 20:46:43 GMT"}], "update_date": "2011-04-15", "authors_parsed": [["Grange", "Pascal", ""], ["Mitra", "Partha P.", ""]]}, {"id": "1104.2717", "submitter": "Mengxin Li", "authors": "Mengxin Li, Wei-Liem Loh", "title": "Estimating the number of neurons in multi-neuronal spike trains", "comments": "Published in at http://dx.doi.org/10.1214/10-AOAS371 the Annals of\n  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of\n  Mathematical Statistics (http://www.imstat.org)", "journal-ref": "Annals of Applied Statistics 2011, Vol. 5, No. 1, 176-200", "doi": "10.1214/10-AOAS371", "report-no": "IMS-AOAS-AOAS371", "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common way of studying the relationship between neural activity and\nbehavior is through the analysis of neuronal spike trains that are recorded\nusing one or more electrodes implanted in the brain. Each spike train typically\ncontains spikes generated by multiple neurons. A natural question that arises\nis \"what is the number of neurons $\\nu$ generating the spike train?\"; This\narticle proposes a method-of-moments technique for estimating $\\nu$. This\ntechnique estimates the noise nonparametrically using data from the silent\nregion of the spike train and it applies to isolated spikes with a possibly\nsmall, but nonnegligible, presence of overlapping spikes. Conditions are\nestablished in which the resulting estimator for $\\nu$ is shown to be strongly\nconsistent. To gauge its finite sample performance, the technique is applied to\nsimulated spike trains as well as to actual neuronal spike train data.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2011 10:41:28 GMT"}], "update_date": "2011-04-15", "authors_parsed": [["Li", "Mengxin", ""], ["Loh", "Wei-Liem", ""]]}, {"id": "1104.3433", "submitter": "Huijun Jiang", "authors": "Hao Wu and Huijun Jiang and Zhonghuai Hou", "title": "Spatiotemporal dynamics on small-world neuronal networks: The roles of\n  two types of time-delayed coupling", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": "10.1016/j.chaos.2011.06.016", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate temporal coherence and spatial synchronization on small-world\nnetworks consisting of noisy Terman-Wang (TW) excitable neurons in dependence\non two types of time-delayed coupling: $\\{x_j(t-\\tau)-x_i (t)\\}$ and\n$\\{x_j(t-\\tau)-x_i(t-\\tau)\\}$. For the former case, we show that time delay in\nthe coupling can dramatically enhance temporal coherence and spatial synchrony\nof the noise-induced spike trains. In addition, if the delay time $\\tau$ is\ntuned to nearly match the intrinsic spike period of the neuronal network, the\nsystem dynamics reaches a most ordered state, which is both periodic in time\nand nearly synchronized in space, demonstrating an interesting resonance\nphenomenon with delay. For the latter case, however, we can not achieve a\nsimilar spatiotemporal ordered state, but the neuronal dynamics exhibits\ninteresting synchronization transition with time delay from zigzag fronts of\nexcitations to dynamic clustering anti-phase synchronization (APS), and further\nto clustered chimera states which have spatially distributed anti-phase\ncoherence separated by incoherence. Furthermore, we also show how these\nfindings are influenced by the change of the noise intensity and the rewiring\nprobability. Finally, qualitative analysis is given to illustrate the numerical\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2011 11:10:58 GMT"}, {"version": "v2", "created": "Tue, 19 Apr 2011 02:39:19 GMT"}], "update_date": "2011-09-01", "authors_parsed": [["Wu", "Hao", ""], ["Jiang", "Huijun", ""], ["Hou", "Zhonghuai", ""]]}, {"id": "1104.3707", "submitter": "Cedric Ginestet", "authors": "Cedric E. Ginestet, Thomas E. Nichols, Ed T. Bullmore, Andrew Simmons", "title": "Brain Network Analysis: Separating Cost from Topology using\n  Cost-integration", "comments": "Accepted for publication in PLoS one, in June 2011", "journal-ref": null, "doi": "10.1371/journal.pone.0021570", "report-no": null, "categories": "q-bio.MN q-bio.NC q-bio.QM stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A statistically principled way of conducting weighted network analysis is\nstill lacking. Comparison of different populations of weighted networks is hard\nbecause topology is inherently dependent on wiring cost, where cost is defined\nas the number of edges in an unweighted graph. In this paper, we evaluate the\nbenefits and limitations associated with using cost-integrated topological\nmetrics. Our focus is on comparing populations of weighted undirected graphs\nusing global efficiency. We evaluate different approaches to the comparison of\nweighted networks that differ in mean association weight. Our key result shows\nthat integrating over cost is equivalent to controlling for any monotonic\ntransformation of the weight set of a weighted graph. That is, when integrating\nover cost, we eliminate the differences in topology that may be due to a\nmonotonic transformation of the weight set. Our result holds for any unweighted\ntopological measure. Cost-integration is therefore helpful in disentangling\ndifferences in cost from differences in topology. By contrast, we show that the\nuse of the weighted version of a topological metric does not constitute a valid\napproach to this problem. Indeed, we prove that, under mild conditions, the use\nof the weighted version of global efficiency is equivalent to simply comparing\nweighted costs. Thus, we recommend the reporting of (i) differences in weighted\ncosts and (ii) differences in cost-integrated topological measures. We\ndemonstrate the application of these techniques in a re-analysis of an fMRI\nworking memory task. Finally, we discuss the limitations of integrating\ntopology over cost, which may pose problems when some weights are zero, when\nmultiplicities exist in the ranks of the weights, and when one expects subtle\ncost-dependent topological differences, which could be masked by\ncost-integration.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2011 10:56:44 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2011 05:49:51 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Ginestet", "Cedric E.", ""], ["Nichols", "Thomas E.", ""], ["Bullmore", "Ed T.", ""], ["Simmons", "Andrew", ""]]}, {"id": "1104.3795", "submitter": "Bruno. Cessac", "authors": "B. Cessac", "title": "Statistics of spike trains in conductance-based neural networks:\n  Rigorous results", "comments": "42 pages, 1 figure, to appear in Journal of Mathematical Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.DS math.MP physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a conductance based neural network inspired by the generalized\nIntegrate and Fire model introduced by Rudolph and Destexhe. We show the\nexistence and uniqueness of a unique Gibbs distribution characterizing spike\ntrain statistics. The corresponding Gibbs potential is explicitly computed.\nThese results hold in presence of a time-dependent stimulus and apply therefore\nto non-stationary dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2011 16:30:02 GMT"}, {"version": "v2", "created": "Thu, 23 Jun 2011 05:35:26 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Cessac", "B.", ""]]}, {"id": "1104.3805", "submitter": "Joel Zylberberg", "authors": "Joel Zylberberg and Michael R. DeWeese", "title": "How shoud prey animals respond to uncertain threats?", "comments": "5 figures, 10 pages of text", "journal-ref": "Frontiers in Computational Neuroscience (2011) 5:20", "doi": "10.3389/fncom.2011.00020", "report-no": null, "categories": "q-bio.PE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A prey animal surveying its environment must decide whether there is a\ndangerous predator present or not. If there is, it may flee. Flight has an\nassociated cost, so the animal should not flee if there is no danger. However,\nthe prey animal cannot know the state of its environment with certainty, and is\nthus bound to make some errors. We formulate a probabilistic automaton model of\na prey animal's life and use it to compute the optimal escape decision\nstrategy, subject to the animal's uncertainty. The uncertainty is a major\nfactor in determining the decision strategy: only in the presence of\nuncertainty do economic factors (like mating opportunities lost due to flight)\ninfluence the decision. We performed computer simulations and found that\n\\emph{in silico} populations of animals subject to predation evolve to display\nthe strategies predicted by our model, confirming our choice of objective\nfunction for our analytic calculations. To the best of our knowledge, this is\nthe first theoretical study of escape decisions to incorporate the effects of\nuncertainty, and to demonstrate the correctness of the objective function used\nin the model.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2011 17:12:50 GMT"}], "update_date": "2011-04-20", "authors_parsed": [["Zylberberg", "Joel", ""], ["DeWeese", "Michael R.", ""]]}, {"id": "1104.4586", "submitter": "Bradly  Alicea", "authors": "Bradly Alicea", "title": "Relativistic virtual worlds: an emerging framework", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, I will attempt to establish a framework for representation in\nvirtual worlds that may allow for input data from many different scales and\nvirtual physics to be merged. For example, a typical virtual environment must\neffectively handle user input, sensor data, and virtual world physics all in\nreal- time. Merging all of these data into a single interactive system requires\nthat we adapt approaches from topological methods such as n-dimensional\nrelativistic representation. A number of hypothetical examples will be provided\nthroughout the paper to clarify technical challenges that need to be overcome\nto realize this vision.\n  The long-term goal of this work is that truly invariant representations will\nultimately result from establishing formal, inclusive relationships between\nthese different domains. Using this framework, incomplete information in one or\nmore domains can be compensated for by parallelism and mappings within the\nvirtual world representation. To introduce this approach, I will review recent\ndevelopments in embodiment, virtual world technology, and neuroscience relevant\nto the control of virtual worlds. The next step will be to borrow ideas from\nfields such as brain science, applied mathematics, and cosmology to give proper\nperspective to this approach. A simple demonstration will then be given using\nan intuitive example of physical relativism. Finally, future directions for the\napplication of this method will be considered.\n", "versions": [{"version": "v1", "created": "Sat, 23 Apr 2011 20:07:49 GMT"}], "update_date": "2011-04-26", "authors_parsed": [["Alicea", "Bradly", ""]]}, {"id": "1104.4823", "submitter": "Joshua Goldwyn", "authors": "Joshua H. Goldwyn and Eric Shea-Brown", "title": "The what and where of adding channel noise to the Hodgkin-Huxley\n  equations", "comments": "14 pages, 3 figures, review article", "journal-ref": null, "doi": "10.1371/journal.pcbi.1002247", "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most celebrated successes in computational biology is the\nHodgkin-Huxley framework for modeling electrically active cells. This\nframework, expressed through a set of differential equations, synthesizes the\nimpact of ionic currents on a cell's voltage -- and the highly nonlinear impact\nof that voltage back on the currents themselves -- into the rapid push and pull\nof the action potential. Latter studies confirmed that these cellular dynamics\nare orchestrated by individual ion channels, whose conformational changes\nregulate the conductance of each ionic current. Thus, kinetic equations\nfamiliar from physical chemistry are the natural setting for describing\nconductances; for small-to-moderate numbers of channels, these will predict\nfluctuations in conductances and stochasticity in the resulting action\npotentials. At first glance, the kinetic equations provide a far more complex\n(and higher-dimensional) description than the original Hodgkin-Huxley\nequations. This has prompted more than a decade of efforts to capture channel\nfluctuations with noise terms added to the Hodgkin-Huxley equations. Many of\nthese approaches, while intuitively appealing, produce quantitative errors when\ncompared to kinetic equations; others, as only very recently demonstrated, are\nboth accurate and relatively simple. We review what works, what doesn't, and\nwhy, seeking to build a bridge to well-established results for the\ndeterministic Hodgkin-Huxley equations. As such, we hope that this review will\nspeed emerging studies of how channel noise modulates electrophysiological\ndynamics and function. We supply user-friendly Matlab simulation code of these\nstochastic versions of the Hodgkin-Huxley equations on the ModelDB website\n(accession number 138950) and\nhttp://www.amath.washington.edu/~etsb/tutorials.html.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2011 23:39:12 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Goldwyn", "Joshua H.", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1104.4931", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "State sampling dependence of the Hopfield network inference", "comments": "4 pages, 1 figure, further discussions added and relevant references\n  added", "journal-ref": "Commun. Theor. Phys. 57 (2012) 169-172", "doi": "10.1088/0253-6102/57/1/27", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fully connected Hopfield network is inferred based on observed\nmagnetizations and pairwise correlations. We present the system in the glassy\nphase with low temperature and high memory load. We find that the inference\nerror is very sensitive to the form of state sampling. When a single state is\nsampled to compute magnetizations and correlations, the inference error is\nalmost indistinguishable irrespective of the sampled state. However, the error\ncan be greatly reduced if the data is collected with state transitions. Our\nresult holds for different disorder samples and accounts for the previously\nobserved large fluctuations of inference error at low temperatures.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2011 14:21:23 GMT"}, {"version": "v2", "created": "Wed, 31 Aug 2011 09:40:53 GMT"}], "update_date": "2014-12-24", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1104.5425", "submitter": "Jonathan Touboul", "authors": "Jonathan Touboul, Geoffroy Hermann and Olivier Faugeras", "title": "Noise-induced behaviors in neural mean field dynamics", "comments": null, "journal-ref": null, "doi": "10.1137/110832392", "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The collective behavior of cortical neurons is strongly affected by the\npresence of noise at the level of individual cells. In order to study these\nphenomena in large-scale assemblies of neurons, we consider networks of\nfiring-rate neurons with linear intrinsic dynamics and nonlinear coupling,\nbelonging to a few types of cell populations and receiving noisy currents.\nAsymptotic equations as the number of neurons tends to infinity (mean field\nequations) are rigorously derived based on a probabilistic approach. These\nequations are implicit on the probability distribution of the solutions which\ngenerally makes their direct analysis difficult. However, in our case, the\nsolutions are Gaussian, and their moments satisfy a closed system of nonlinear\nordinary differential equations (ODEs), which are much easier to study than the\noriginal stochastic network equations, and the statistics of the empirical\nprocess uniformly converge towards the solutions of these ODEs. Based on this\ndescription, we analytically and numerically study the influence of noise on\nthe collective behaviors, and compare these asymptotic regimes to simulations\nof the network. We observe that the mean field equations provide an accurate\ndescription of the solutions of the network equations for network sizes as\nsmall as a few hundreds of neurons. In particular, we observe that the level of\nnoise in the system qualitatively modifies its collective behavior, producing\nfor instance synchronized oscillations of the whole network, desynchronization\nof oscillating regimes, and stabilization or destabilization of stationary\nsolutions. These results shed a new light on the role of noise in shaping\ncollective dynamics of neurons, and gives us clues for understanding similar\nphenomena observed in biological networks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2011 15:28:07 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2015 16:16:46 GMT"}], "update_date": "2015-03-27", "authors_parsed": [["Touboul", "Jonathan", ""], ["Hermann", "Geoffroy", ""], ["Faugeras", "Olivier", ""]]}, {"id": "1104.5458", "submitter": "George Kesidis", "authors": "Yaman Aksu, David J. Miller, George Kesidis, Don C. Bigler, Qing X.\n  Yang", "title": "An MRI-Derived Definition of MCI-to-AD Conversion for Long-Term,\n  Automati c Prognosis of MCI Patients", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0025074", "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alzheimer's disease (AD) and mild cognitive impairment (MCI), continue to be\nwidely studied. While there is no consensus on whether MCIs actually \"convert\"\nto AD, the more important question is not whether MCIs convert, but what is the\nbest such definition. We focus on automatic prognostication, nominally using\nonly a baseline image brain scan, of whether an MCI individual will convert to\nAD within a multi-year period following the initial clinical visit. This is in\nfact not a traditional supervised learning problem since, in ADNI, there are no\ndefinitive labeled examples of MCI conversion. Prior works have defined MCI\nsubclasses based on whether or not clinical/cognitive scores such as CDR\nsignificantly change from baseline. There are concerns with these definitions,\nhowever, since e.g. most MCIs (and ADs) do not change from a baseline CDR=0.5,\neven while physiological changes may be occurring. These works ignore rich\nphenotypical information in an MCI patient's brain scan and labeled AD and\nControl examples, in defining conversion. We propose an innovative conversion\ndefinition, wherein an MCI patient is declared to be a converter if any of the\npatient's brain scans (at follow-up visits) are classified \"AD\" by an\n(accurately-designed) Control-AD classifier. This novel definition bootstraps\nthe design of a second classifier, specifically trained to predict whether or\nnot MCIs will convert. This second classifier thus predicts whether an\nAD-Control classifier will predict that a patient has AD. Our results\ndemonstrate this new definition leads not only to much higher prognostic\naccuracy than by-CDR conversion, but also to subpopulations much more\nconsistent with known AD brain region biomarkers. We also identify key\nprognostic region biomarkers, essential for accurately discriminating the\nconverter and nonconverter groups.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2011 17:56:32 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Aksu", "Yaman", ""], ["Miller", "David J.", ""], ["Kesidis", "George", ""], ["Bigler", "Don C.", ""], ["Yang", "Qing X.", ""]]}, {"id": "1104.5674", "submitter": "Stanley Lazic", "authors": "Stanley E. Lazic", "title": "Using causal models to distinguish between neurogenesis-dependent and\n  -independent effects on behaviour", "comments": "To be published in the Journal of the Royal Society Interface", "journal-ref": null, "doi": "10.1098/?rsif.2011.0510", "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a substantial amount of research on the relationship between\nhippocampal neurogenesis and behaviour over the past fifteen years, but the\ncausal role that new neurons have on cognitive and affective behavioural tasks\nis still far from clear. This is partly due to the difficulty of manipulating\nlevels of neurogenesis without inducing off-target effects, which might also\ninfluence behaviour. In addition, the analytical methods typically used do not\ndirectly test whether neurogenesis mediates the effect of an intervention on\nbehaviour. Previous studies may have incorrectly attributed changes in\nbehavioural performance to neurogenesis because the role of known (or unknown)\nneurogenesis-independent mechanisms were not formally taken into consideration\nduring the analysis. Causal models can tease apart complex causal relationships\nand were used to demonstrate that the effect of exercise on pattern separation\nis via neurogenesis-independent mechanisms. Many studies in the neurogenesis\nliterature would benefit from the use of statistical methods that can separate\nneurogenesis-dependent from neurogenesis-independent effects on behaviour.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2011 16:32:00 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2011 20:35:55 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Lazic", "Stanley E.", ""]]}]