[{"id": "2011.00034", "submitter": "Cassie Meeker", "authors": "Cassie Meeker, Michaela Fraser, Sangwoo Park, Ava Chen, Lynne M.\n  Weber, Mitchell Miya, Joel Stein, Matei Ciocarlie", "title": "Semi-Supervised Intent Inferral Using Ipsilateral Biosignals on a Hand\n  Orthosis for Stroke Subjects", "comments": "7 pages, 2 figures, 3 tables, under review ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to provide therapy in a functional context, controls for wearable\northoses need to be robust and intuitive. We have previously introduced an\nintuitive, user-driven, EMG based orthotic control, but the process of training\na control which is robust to concept drift (changes in the input signal) places\na substantial burden on the user. In this paper, we explore semi-supervised\nlearning as a paradigm for wearable orthotic controls. We are the first to use\nsemi-supervised learning for an orthotic application. We propose a K-means\nsemi-supervision and a disagreement-based semi-supervision algorithm. This is\nan exploratory study designed to determine the feasibility of semi-supervised\nlearning as a control paradigm for wearable orthotics. In offline experiments\nwith stroke subjects, we show that these algorithms have the potential to\nreduce the training burden placed on the user, and that they merit further\nstudy.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 18:33:03 GMT"}], "update_date": "2020-11-21", "authors_parsed": [["Meeker", "Cassie", ""], ["Fraser", "Michaela", ""], ["Park", "Sangwoo", ""], ["Chen", "Ava", ""], ["Weber", "Lynne M.", ""], ["Miya", "Mitchell", ""], ["Stein", "Joel", ""], ["Ciocarlie", "Matei", ""]]}, {"id": "2011.00088", "submitter": "Richard Granger", "authors": "Sarah Oh, Elijah FW Bowen, Antonio Rodriguez, Damian Sowinski, Eva\n  Childers, Annemarie Brown, Laura Ray, Richard Granger", "title": "Towards a perceptual distance metric for auditory stimuli", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SD", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Although perceptual (dis)similarity between sensory stimuli seems akin to\ndistance, measuring the Euclidean distance between vector representations of\nauditory stimuli is a poor estimator of subjective dissimilarity. In hearing,\nnonlinear response patterns, interactions between stimulus components, temporal\neffects, and top-down modulation transform the information contained in\nincoming frequency-domain stimuli in a way that seems to preserve some notion\nof distance, but not that of familiar Euclidean space. This work proposes that\ntransformations applied to auditory stimuli during hearing can be modeled as a\nfunction mapping stimulus points to their representations in a perceptual\nspace, inducing a Riemannian distance metric. A dataset was collected in a\nsubjective listening experiment, the results of which were used to explore\napproaches (biologically inspired, data-driven, and combinations thereof) to\napproximating the perceptual map. Each of the proposed measures achieved\ncomparable or stronger correlations with subjective ratings (r ~ 0.8) compared\nto state-of-the-art audio quality measures.\n", "versions": [{"version": "v1", "created": "Fri, 30 Oct 2020 20:19:59 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Oh", "Sarah", ""], ["Bowen", "Elijah FW", ""], ["Rodriguez", "Antonio", ""], ["Sowinski", "Damian", ""], ["Childers", "Eva", ""], ["Brown", "Annemarie", ""], ["Ray", "Laura", ""], ["Granger", "Richard", ""]]}, {"id": "2011.00163", "submitter": "Martin Vasilev", "authors": "Martin R. Vasilev, Fabrice B. R. Parmentier, Julie A. Kirkby", "title": "Distraction by auditory novelty during reading: Evidence for disruption\n  in saccade planning, but not saccade execution", "comments": null, "journal-ref": null, "doi": "10.1177/1747021820982267", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Novel or unexpected sounds that deviate from an otherwise repetitive sequence\nof the same sound cause behavioural distraction. Recent work has suggested that\ndistraction also occurs during reading as fixation durations increased when a\ndeviant sound was presented at the fixation onset of words. The present study\ntested the hypothesis that this increase in fixation durations occurs due to\nsaccadic inhibition. This was done by manipulating the temporal onset of sounds\nrelative to the fixation onset of words in the text. If novel sounds cause\nsaccadic inhibition, they should be more distracting when presented during the\nsecond half of fixations when saccade programming usually takes place.\nParticipants read single sentences and heard a 120 ms sound when they fixated\nfive target words in the sentence. On most occasions (p= 0.9), the same sine\nwave tone was presented (\"standard\"), while on the remaining occasions (p= 0.1)\na new sound was presented (\"novel\"). Critically, sounds were played either\nduring the first half of the fixation (0 ms delay) or during the second half of\nthe fixation (120 ms delay). Consistent with the saccadic inhibition\nhypothesis, novel sounds led to longer fixation durations in the 120 ms\ncompared to the 0 ms delay condition. However, novel sounds did not generally\ninfluence the execution of the subsequent saccade. These results suggest that\nunexpected sounds have a rapid influence on saccade planning, but not saccade\nexecution.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 01:35:52 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Vasilev", "Martin R.", ""], ["Parmentier", "Fabrice B. R.", ""], ["Kirkby", "Julie A.", ""]]}, {"id": "2011.00257", "submitter": "Kirill Efimov Vadimovich", "authors": "Kirill V. Efimov, Alina O. Tetereva, Aleksey M. Ivanitskiy, Sergey I.\n  Kartashov, Olga V. Martynova", "title": "Temporary changes in large-scale memory neural networks after fear\n  learning and extinction in healthy adults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the functional connectivity of brain sections associated with\nfear-conditioned training is one of the methods of study of memory neural\nnetworks. Before, the majority of studies focused on the functional\nconnectivity of the brain regions that are known for emotional processing such\nas amygdala and areas of the ventromedial prefrontal cortex in the resting\nstate right after the formation of a fear-conditioned reflex. In the present\nstudy authors applied the methods of the theory of graphs to search for changes\nin the functional connectivity at the level of the brain in the resting state\nin a week dynamics after the extinction of a conditioned reflex with partial\nreinforcement. The most significant changes were observed in the functional\nconnectivity of the left parahippocampal area. In particular, the rostral part\nof the left parahippocampal gyrus became the center of a new subnetwork\nconnected with the rostral part of the left hippocampus in all the sessions and\nafter the extinction of a conditioned reflex and the lateral part of the left\namygdala right after the extinction and a day after the extinction of a\nconditioned reflex. A week after the extinction of a conditioned reflex, the\nrostral part of the left parahippocampal gyrus also had more connections with\nthe areas of the middle frontal gyrus in comparison with the parameters of the\nbaseline resting state to the stimulus. Besides, these changes remained within\none week from the moment of the extinction of a conditioned reflex, which could\nbe explained by the chosen paradigm of conditioned reflex with partial\nreinforcement that led to a slower extinction than a paradigm with full\nreinforcement.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 12:17:05 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Efimov", "Kirill V.", ""], ["Tetereva", "Alina O.", ""], ["Ivanitskiy", "Aleksey M.", ""], ["Kartashov", "Sergey I.", ""], ["Martynova", "Olga V.", ""]]}, {"id": "2011.00297", "submitter": "Jantine Broek PhD", "authors": "Jantine A.C. Broek and Guillaume Drion", "title": "Generalisation of neuronal excitability allows for the identification of\n  an excitability change parameter that links to an experimentally measurable\n  value", "comments": "21 pages, 10 main figures, 3 supplementary figures", "journal-ref": null, "doi": "10.5281/zenodo.4159691", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal excitability is the phenomena that describes action potential\ngeneration due to a stimulus input. Commonly, neuronal excitability is divided\ninto two classes: Type I and Type II, both having different properties that\naffect information processing, such as thresholding and gain scaling. These\nproperties can be mathematically studied using generalised phenomenological\nmodels, such as the Fitzhugh-Nagumo model and the mirrored FHN. The FHN model\nshows that each excitability type corresponds to one specific type of\nbifurcation in the phase plane: Type I underlies a saddle-node on invariant\ncycle bifurcation, and Type II a Hopf bifurcation. The difficulty of modelling\nType I excitability is that it is not only represented by its underlying\nbifurcation, but also should be able to generate frequency while maintaining a\nsmall depolarising current. Using the mFHN model, we show that this situation\nis possible without modifying the phase portrait, due to the incorporation of a\nslow regenerative variable. We show that in the singular limit of the mFHN\nmodel, the time-scale separation can be chosen such that there is a\nconfiguration of a classical phase portrait that allows for SNIC bifurcation,\nzero-frequency onset and a depolarising current, such as observed in Type I\nexcitability. Using the definition of slow conductance, g_s, we show that these\nmathematical findings for excitability change are translatable to reduced\nconductance based models and also relates to an experimentally measurable\nquantity. This not only allows for a measure of excitability change, but also\nrelates the mathematical parameters that indicate a physiological Type I\nexcitability to parameters that can be tuned during experiments.\n", "versions": [{"version": "v1", "created": "Sat, 31 Oct 2020 15:58:02 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Broek", "Jantine A. C.", ""], ["Drion", "Guillaume", ""]]}, {"id": "2011.01750", "submitter": "Susanna Gordleeva", "authors": "Susanna Yu. Gordleeva, Yulia A. Tsybina, Mikhail I. Krivonosov,\n  Mikhail V. Ivanchenko, Alexey A. Zaikin, Victor B. Kazantsev, Alexander N.\n  Gorban", "title": "Formation of working memory in a spiking neuron network accompanied by\n  astrocytes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a biologically plausible computational model of working memory\n(WM) implemented by the spiking neuron network (SNN) interacting with a network\nof astrocytes. SNN is modelled by the synaptically coupled Izhikevich neurons\nwith a non-specific architecture connection topology. Astrocytes generating\ncalcium signals are connected by local gap junction diffusive couplings and\ninteract with neurons by chemicals diffused in the extracellular space. Calcium\nelevations occur in response to the increase of concentration of a\nneurotransmitter released by spiking neurons when a group of them fire\ncoherently. In turn, gliotransmitters are released by activated astrocytes\nmodulating the strengths of synaptic connections in the corresponding neuronal\ngroup. Input information is encoded as two-dimensional patterns of short\napplied current pulses stimulating neurons. The output is taken from\nfrequencies of transient discharges of corresponding neurons. We show how a set\nof information patterns with quite significant overlapping areas can be\nuploaded into the neuron-astrocyte network and stored for several seconds.\nInformation retrieval is organised by the application of a cue pattern\nrepresenting the one from the memory set distorted by noise. We found that\nsuccessful retrieval with level of the correlation between recalled pattern and\nideal pattern more than 90% is possible for multi-item WM task. Having analysed\nthe dynamical mechanism of WM formation, we discovered that astrocytes\noperating at a time scale of a dozen of seconds can successfully store traces\nof neuronal activations corresponding to information patterns. In the retrieval\nstage, the astrocytic network selectively modulates synaptic connections in SNN\nleading to the successful recall. Information and dynamical characteristics of\nthe proposed WM model agrees with classical concepts and other WM models.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 14:56:35 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Gordleeva", "Susanna Yu.", ""], ["Tsybina", "Yulia A.", ""], ["Krivonosov", "Mikhail I.", ""], ["Ivanchenko", "Mikhail V.", ""], ["Zaikin", "Alexey A.", ""], ["Kazantsev", "Victor B.", ""], ["Gorban", "Alexander N.", ""]]}, {"id": "2011.01795", "submitter": "Chaoqing Xu", "authors": "Chaoqing Xu, Guodao Sun, Ronghua Liang, and Xiufang Xu", "title": "Vector Field Streamline Clustering Framework for Brain Fiber Tract\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain fiber tracts are widely used in studying brain diseases, which may lead\nto a better understanding of how disease affects the brain. The segmentation of\nbrain fiber tracts assumed enormous importance in disease analysis. In this\npaper, we propose a novel vector field streamline clustering framework for\nbrain fiber tract segmentations. Brain fiber tracts are firstly expressed in a\nvector field and compressed using the streamline simplification algorithm.\nAfter streamline normalization and regular-polyhedron projection,\nhigh-dimensional features of each fiber tract are computed and fed to the IDEC\nclustering algorithm. We also provide qualitative and quantitative evaluations\nof the IDEC clustering method and QB clustering method. Our clustering results\nof the brain fiber tracts help researchers gain perception of the brain\nstructure. This work has the potential to automatically create a robust fiber\nbundle template that can effectively segment brain fiber tracts while enabling\nconsistent anatomical tract identification.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2020 15:40:13 GMT"}], "update_date": "2020-11-04", "authors_parsed": [["Xu", "Chaoqing", ""], ["Sun", "Guodao", ""], ["Liang", "Ronghua", ""], ["Xu", "Xiufang", ""]]}, {"id": "2011.03019", "submitter": "Paulo Protachevicz", "authors": "P. R. Protachevicz, K. C. Iarosz, I. L. Caldas, C. G. Antonopoulos, A.\n  M. Batista, J. Kurths", "title": "Influence of autapses on synchronisation in neural networks with\n  chemical synapses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A great deal of research has been devoted on the investigation of neural\ndynamics in various network topologies. However, only a few studies have\nfocused on the influence of autapses, synapses from a neuron onto itself via\nclosed loops, on neural synchronisation. Here, we build a random network with\nadaptive exponential integrate-and-fire neurons coupled with chemical synapses,\nequipped with autapses, to study the effect of the latter on synchronous\nbehaviour. We consider time delay in the conductance of the pre-synaptic neuron\nfor excitatory and inhibitory connections. Interestingly, in neural networks\nconsisting of both excitatory and inhibitory neurons, we uncover that\nsynchronous behaviour depends on their synapse type. Our results provide\nevidence on the synchronous and desynchronous activities that emerge in random\nneural networks with chemical, inhibitory and excitatory synapses where neurons\nare equipped with autapses.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2020 18:27:02 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2020 16:05:10 GMT"}], "update_date": "2020-11-09", "authors_parsed": [["Protachevicz", "P. R.", ""], ["Iarosz", "K. C.", ""], ["Caldas", "I. L.", ""], ["Antonopoulos", "C. G.", ""], ["Batista", "A. M.", ""], ["Kurths", "J.", ""]]}, {"id": "2011.03263", "submitter": "Pablo Villegas G\\'ongora", "authors": "Victor Buend\\'ia, Pablo Villegas, Raffaella Burioni, Miguel A. Mu\\~noz", "title": "Hybrid-type synchronization transitions: where marginal coherence,\n  scale-free avalanches, and bistability live together", "comments": "7 pages, 4 figures, and Supplementary Information. Accepted to be\n  published in PRR", "journal-ref": "Phys. Rev. Research 3, 023224 (2021)", "doi": "10.1103/PhysRevResearch.3.023224", "report-no": null, "categories": "cond-mat.stat-mech cond-mat.dis-nn nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human cortex is never at rest but in a state of sparse and noisy neural\nactivity that can be detected at broadly diverse resolution scales. It has been\nconjectured that such a state is best described as a critical dynamical process\n-- whose nature is still not fully understood -- where scale-free avalanches of\nactivity emerge at the edge of a phase transition. In particular, some works\nsuggest that this is most likely a synchronization transition, separating\nsynchronous from asynchronous phases. Here, by investigating a simplified model\nof coupled excitable oscillators describing the cortex dynamics at a mesoscopic\nlevel, we investigate the possible nature of such a synchronization phase\ntransition. Within our modeling approach, we conclude that -- in order to\nreproduce all key empirical observations, such as scale-free avalanches and\nbistability, on which fundamental functional advantages rely -- the transition\nto collective oscillatory behavior needs to be of an unconventional hybrid\ntype, with mixed features of type-I and type-II excitability, opening the\npossibility for a particularly rich dynamical repertoire.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2020 10:13:48 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 14:14:06 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Buend\u00eda", "Victor", ""], ["Villegas", "Pablo", ""], ["Burioni", "Raffaella", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}, {"id": "2011.03852", "submitter": "Zakaria Djebbara", "authors": "Zakaria Djebbara, Thomas Parr and Karl Friston", "title": "Anticipation in architectural experience: a computational\n  neurophenomenology for architecture?", "comments": "1 title-page, 23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The perceptual experience of architecture is enacted by the sensory and motor\nsystem. When we act, we change the perceived environment according to a set of\nexpectations that depend on our body and the built environment. The continuous\nprocess of collecting sensory information is thus based on bodily affordances.\nAffordances characterize the fit between the physical structure of the body and\ncapacities for movement in the built environment. Since little has been done\nregarding the role of architectural design in the emergence of perceptual\nexperience on a neuronal level, this paper offers a first step towards the role\nof architectural design in perceptual experience. An approach to synthesize\nconcepts from computational neuroscience with architectural phenomenology into\na computational neurophenomenology is considered. The outcome is a framework\nunder which studies of architecture and cognitive neuroscience can be cast.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2020 21:27:04 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Djebbara", "Zakaria", ""], ["Parr", "Thomas", ""], ["Friston", "Karl", ""]]}, {"id": "2011.03913", "submitter": "Eli Shlizerman", "authors": "Rahul Biswas and Eli Shlizerman", "title": "Neuro-PC: Causal Functional Connectivity from Neural Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional connectome extends the anatomical connectome by capturing the\nrelations between neurons according to their activity and interactions. When\nthese relations are causal, the functional connectome maps how neural activity\nflows within neural circuits and provides the possibility for inference of\nfunctional neural pathways, such as sensory-motor-behavioral pathways. While\nthere exist various information approaches for non-causal estimations of the\nfunctional connectome, approaches that characterize the causal functional\nconnectivity - the causal relationships between neuronal time series, are\nscarce. In this work, we develop the Neuro-PC algorithm which is a novel\nmethodology for inferring the causal functional connectivity between neurons\nfrom multi-dimensional time series, such as neuronal recordings. The core of\nour methodology relies on a novel adaptation of the PC algorithm, a\nstate-of-the-art method for statistical causal inference, to the\nmulti-dimensional time-series of neural dynamics. We validate the performance\nof the method on network motifs with various interactions between their neurons\nsimulated using continuous-time artificial network of neurons. We then consider\nthe application of the method to obtain the causal functional connectome for\nrecent multi-array electrophysiological recordings from the mouse visual cortex\nin the presence of different stimuli. We show how features of the mapping can\nbe used for quantification of the similarities between neural responses subject\nto different stimuli.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 07:09:39 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Biswas", "Rahul", ""], ["Shlizerman", "Eli", ""]]}, {"id": "2011.04040", "submitter": "Rafael Barrio", "authors": "Hernan Barrio Zhang, Mariana Marquez-Machorro, Vito S. Hernandez,\n  Andres Molina, Limei Zhang, Tzipe Govezensky, Rafael A. Barrio", "title": "Analysis and modeling of low frequency local field oscillations in a\n  hippocampus circuit under osmotic challenge: the possible role of arginine\n  vasopressin circuit for hippocampal function", "comments": "11 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrophysiological time series were taken simultaneously in two locations\nin the hippocampus of a rat brain previously described as receiving innervation\nfrom the osmosensitive vasopressinergic neurons of the hypothalamus. A\nhyperosmotic saline solution injection was administered during the time of the\nexperiment. We analyze the recorded time series using different methods. We\ndetect a modification of the delta and theta oscillations just after the\nperturbation caused by the injection. We compare the quality and information\nthat each one of the methods exhibit and we analyze the characteristics of the\nperturbation based on a hypothesis that the strength of the functional\nconnections between the vasopressinergic hypothalamic magnocellular neurons and\ntheir target in the hippocampus is modified by the perturbation. We built a\nmodel of the hypothetic neural connections and numerically calculate the time\nseries produced by the system when simulating the perturbation caused by the\nsaline injection. The theoretical results resemble the experimental findings\nconcerning the frequency and amplitude alterations of the delta and theta\nbands.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2020 18:06:05 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Zhang", "Hernan Barrio", ""], ["Marquez-Machorro", "Mariana", ""], ["Hernandez", "Vito S.", ""], ["Molina", "Andres", ""], ["Zhang", "Limei", ""], ["Govezensky", "Tzipe", ""], ["Barrio", "Rafael A.", ""]]}, {"id": "2011.04441", "submitter": "Luka Ribar", "authors": "Luka Ribar, Rodolphe Sepulchre", "title": "Neuromorphic Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.NE cs.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic engineering is a rapidly developing field that aims to take\ninspiration from the biological organization of neural systems to develop novel\ntechnology for computing, sensing and actuating. The unique properties of such\nsystems call for new signal processing and control paradigms. The article\nintroduces the mixed feedback organization of excitable neuronal systems,\nconsisting of interlocked positive and negative feedback loops acting in\ndistinct timescales. The principles of biological neuromodulation suggest a\nmethodology for designing and controlling mixed-feedback systems\nneuromorphically. The proposed design consists of a parallel interconnection of\nelementary circuit elements that mirrors the organization of biological neurons\nand utilizes the hardware components of neuromorphic electronic circuits. The\ninterconnection structure endows the neuromorphic systems with a simple control\nmethodology that reframes the neuronal control as an input-output shaping\nproblem. The potential of neuronal control is illustrated on simple network\nexamples that suggest the scalability of the mixed-feedback principles.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 14:06:06 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ribar", "Luka", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "2011.04565", "submitter": "Patrick Chan", "authors": "Patrick Chan, Katherine Johnston, Joseph Lent, Alexander Ruys de\n  Perez, Anne Shiu", "title": "Nondegenerate Neural Codes and Obstructions to Closed-Convexity", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work on convexity of neural codes has produced codes that are\nopen-convex but not closed-convex -- or vice-versa. However, why a code is one\nbut not the other, and how to detect such discrepancies are open questions. We\ntackle these questions in two ways. First, we investigate the concept of\ndegeneracy introduced by Cruz et al., and extend their results to show that\nnondegeneracy precisely captures the situation when taking closures or\ninteriors of open or closed realizations, respectively, yields another\nrealization of the code. Second, we give the first general criteria for\nprecluding a code from being closed-convex (without ruling out open-convexity),\nunifying ad-hoc geometric arguments in prior works. One criterion is built on a\nphenomenon we call a rigid structure, while the other can be stated\nalgebraically, in terms of the neural ideal of the code. These results\ncomplement existing criteria having the opposite purpose: precluding\nopen-convexity but not closed-convexity. Finally, we show that a family of\ncodes shown by Jeffs to be not open-convex is in fact closed-convex and\nrealizable in dimension two.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 17:10:54 GMT"}], "update_date": "2020-11-10", "authors_parsed": [["Chan", "Patrick", ""], ["Johnston", "Katherine", ""], ["Lent", "Joseph", ""], ["de Perez", "Alexander Ruys", ""], ["Shiu", "Anne", ""]]}, {"id": "2011.04798", "submitter": "Ding Zhou", "authors": "Ding Zhou, Xue-Xin Wei", "title": "Learning identifiable and interpretable latent models of\n  high-dimensional neural activity using pi-VAE", "comments": null, "journal-ref": "NeurIPS 2020", "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The ability to record activities from hundreds of neurons simultaneously in\nthe brain has placed an increasing demand for developing appropriate\nstatistical techniques to analyze such data. Recently, deep generative models\nhave been proposed to fit neural population responses. While these methods are\nflexible and expressive, the downside is that they can be difficult to\ninterpret and identify. To address this problem, we propose a method that\nintegrates key ingredients from latent models and traditional neural encoding\nmodels. Our method, pi-VAE, is inspired by recent progress on identifiable\nvariational auto-encoder, which we adapt to make appropriate for neuroscience\napplications. Specifically, we propose to construct latent variable models of\nneural activity while simultaneously modeling the relation between the latent\nand task variables (non-neural variables, e.g. sensory, motor, and other\nexternally observable states). The incorporation of task variables results in\nmodels that are not only more constrained, but also show qualitative\nimprovements in interpretability and identifiability. We validate pi-VAE using\nsynthetic data, and apply it to analyze neurophysiological datasets from rat\nhippocampus and macaque motor cortex. We demonstrate that pi-VAE not only fits\nthe data better, but also provides unexpected novel insights into the structure\nof the neural codes.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2020 22:00:38 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Zhou", "Ding", ""], ["Wei", "Xue-Xin", ""]]}, {"id": "2011.05212", "submitter": "Joaquin Goni", "authors": "Uttara Tipnis, Kausar Abbas, Elizabeth Tran, Enrico Amico, Li Shen,\n  Alan D. Kaplan, Joaqu\\'in Go\\~ni", "title": "Functional Connectome Fingerprint Gradients in Young Adults", "comments": "26 pages, 10 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The assessment of brain fingerprints has emerged in the recent years as an\nimportant tool to study individual differences and to infer quality of\nneuroimaging datasets. Studies so far have mainly focused on connectivity\nfingerprints between different brain scans of the same individual. Here, we\nextend the concept of brain connectivity fingerprints beyond test/retest and\nassess fingerprint gradients in young adults by developing an extension of the\ndifferential identifiability framework. To do so, we look at the similarity\nbetween not only the multiple scans of an individual (subject fingerprint), but\nalso between the scans of monozygotic and dizygotic twins (twin fingerprint).\nWe have carried out this analysis on the 8 fMRI conditions present in the Human\nConnectome Project -- Young Adult dataset, which we processed into functional\nconnectomes (FCs) and timeseries parcellated according to the Schaefer Atlas\nscheme, which has multiple levels of resolution. Our differential\nidentifiability results show that the fingerprint gradients based on genetic\nand environmental similarities are indeed present when comparing FCs for all\nparcellations and fMRI conditions. Importantly, only when assessing optimally\nreconstructed FCs, we fully uncover fingerprints present in higher resolution\natlases. We also study the effect of scanning length on subject fingerprint of\nresting-state FCs to analyze the effect of scanning length and parcellation. In\nthe pursuit of open science, we have also made available the processed and\nparcellated FCs and timeseries for all conditions for ~1200 subjects part of\nthe HCP-YA dataset to the scientific community.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 16:11:12 GMT"}, {"version": "v2", "created": "Mon, 11 Jan 2021 21:13:51 GMT"}], "update_date": "2021-01-13", "authors_parsed": [["Tipnis", "Uttara", ""], ["Abbas", "Kausar", ""], ["Tran", "Elizabeth", ""], ["Amico", "Enrico", ""], ["Shen", "Li", ""], ["Kaplan", "Alan D.", ""], ["Go\u00f1i", "Joaqu\u00edn", ""]]}, {"id": "2011.05215", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley, Adam Reeves", "title": "Color for the perceptual organization of the pictorial plane: Victor\n  Vasarely's legacy to Gestalt Psychology", "comments": null, "journal-ref": "Heliyon. 2020;6(7):e04375", "doi": "10.1016/j.heliyon.2020.e04375", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Victor Vasarely (1906-1997)and his important legacy to the study of human\nperception are brought to the forefront and discussed. A large part of his\nimpressive work conveys the appearance of striking three-dimensional shapes and\nstructures in a large-scale pictorial plane. Current perception science\nexplains such effects by invoking brain mechanisms for the processing of\nmonocular (2D) depth cues. Here in this study, we illustrate and explain local\neffects of 2D color and contrast cues on the perceptual organization in terms\nof figure-ground assignments, i.e. which local surfaces are likely to be seen\nas nearer or bigger in the image plane. Paired configurations are embedded in a\nlarger, structurally ambivalent pictorial context inspired by some of Vasarelys\ncreations. The figure-ground effects the configurations produce reveal a\nsignificant correlation between perceptual solutions for nearer and bigger when\nother monocular depth cues are not provided. In consistency with previous\nfindings on similar, albeit simpler visual displays, a specific color may\ncompete with luminance contrast to resolve the planar ambiguity of a complex\npattern context at a critical point in the hierarchical resolution of\nfigure-ground uncertainty. The potential role of color temperature in this\nprocess is brought forward here. Vasarely intuitively understood and\nsuccessfully exploited the subtle context effects accounted for in this paper,\nwell before empirical investigation had set out to study and explain them in\nterms of information processing by the visual brain.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 16:14:26 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Dresp-Langley", "Birgitta", ""], ["Reeves", "Adam", ""]]}, {"id": "2011.05292", "submitter": "Varsha V", "authors": "Varsha V, Aditya Murthy and Radhakant Padhi", "title": "A Stochastic Optimal Control Model with Internal Feedback and Velocity\n  Tracking for Saccades", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": "10.1016/j.bspc.2021.102679", "report-no": null, "categories": "eess.SY cs.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stochastic optimal control based model with velocity tracking and internal\nfeedback for saccadic eye movements is presented in this paper. Recent evidence\nfrom neurophysiological studies of superior colliculus suggests the presence of\na dynamic input to the saccade generation system that encodes saccade velocity,\nrather than just the saccade amplitude and direction. The new evidence makes it\nimperative to test if saccade control can use a desired velocity input which is\nthe basis for the proposed velocity tracking model. The model is validated\nusing behavioral data of saccades generated by healthy human subjects. It\ngenerates trajectories of horizontal saccades made to different amplitudes as\nwell as predicts vertical and oblique saccade behavior. This paper presents the\nfirst-ever model of the saccadic system in an optimal control framework using\nan alternate interpretation of velocity-based control, contrary to the dominant\nend-point based models available in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:24:19 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["V", "Varsha", ""], ["Murthy", "Aditya", ""], ["Padhi", "Radhakant", ""]]}, {"id": "2011.05294", "submitter": "Mike Steel Prof.", "authors": "Mike Steel", "title": "Modelling aspects of consciousness: a topological perspective", "comments": "13 pages, 1 figure, (version 5 is a slightly revised version of\n  version 4, which was a moderately revised version of 3 (which was identical\n  to versions 1 and 2, except that the figure was reduced in size to allow\n  easier downloads)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Attention Schema Theory (AST) is a recent proposal to provide a scientific\nexplanation for the basis of subjective awareness. In AST, the brain constructs\na representation of attention taking place in its own (and others') mind (`the\nattention schema'). Moreover, this representation is incomplete for efficiency\nreasons. This inherent incompleteness of the attention schema results in the\ninability of humans to understand how their own subjective awareness arises\n(related to the so-called `hard problem' of consciousness). Given this theory,\nthe present paper asks whether a mind (either human or machine-based) that\nincorporates attention, and that contains a representation of its own\nattention, can ever have a complete representation. Using a simple yet general\nmodel and a mathematical argument based on classical topology, we show that a\ncomplete representation of attention is not possible, since it cannot\nfaithfully represent streams of attention. In this way, the study supports one\nof the core aspects of AST, that the brain's representation of its own\nattention is necessarily incomplete.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2020 18:32:00 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 04:08:38 GMT"}, {"version": "v3", "created": "Sun, 22 Nov 2020 03:42:26 GMT"}, {"version": "v4", "created": "Fri, 9 Apr 2021 05:34:35 GMT"}, {"version": "v5", "created": "Tue, 27 Apr 2021 02:40:44 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Steel", "Mike", ""]]}, {"id": "2011.05595", "submitter": "Yu Liu", "authors": "Yu Liu, Yinghong Zhao and Mo Chen", "title": "Desires and Motivation: The Computational Rule, the Underlying Neural\n  Circuitry, and the Relevant Clinical Disorders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As organism is a dissipative system. The process from multi desires to\nexclusive motivation is of great importance among all sensory-action loops. In\nthis paper we argued that a proper Desire-Motivation model should be a\ncontinuous dynamic mapping from the dynamic desire vector to the sparse\nmotivation vector. Meanwhile, it should at least have specific stability and\nadjustability of motivation intensity. Besides, the neuroscience evidences\nsuggest that the Desire-Motivation model should have dynamic information\nacquisition and should be a recurrent neural network. A five-equation model is\nbuilt based on the above arguments, namely the Recurrent Gating\nDesire-Motivation (RGDM) model. Additionally, a heuristic speculation based on\nthe RGDM model about corresponding brain regions is carried out. It believes\nthat the tonic and phasic firing of ventral tegmental area dopamine neurons\nshould execute the respective and collective feedback functions of recurrent\nprocessing. The analysis about the RGMD model shows the expectations about\nindividual personality from three dimensions, namely stability, intensity, and\nmotivation decision speed. These three dimensions can be combined and create\neight different personalities, which is correspondent to Jung's personality\nstructure theorem. Furthermore, the RGDM model can be used to predict three\ndifferent brand-new types of depressive disorder with different phenotypes.\nMoreover, it can also explain several other psychiatry disorders from new\nperspectives.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 06:46:51 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Liu", "Yu", ""], ["Zhao", "Yinghong", ""], ["Chen", "Mo", ""]]}, {"id": "2011.05623", "submitter": "Li Yuan", "authors": "Li Yuan, Will Xiao, Gabriel Kreiman, Francis E.H. Tay, Jiashi Feng,\n  Margaret S. Livingstone", "title": "Adversarial images for the primate brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.NE eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep artificial neural networks have been proposed as a model of primate\nvision. However, these networks are vulnerable to adversarial attacks, whereby\nintroducing minimal noise can fool networks into misclassifying images. Primate\nvision is thought to be robust to such adversarial images. We evaluated this\nassumption by designing adversarial images to fool primate vision. To do so, we\nfirst trained a model to predict responses of face-selective neurons in macaque\ninferior temporal cortex. Next, we modified images, such as human faces, to\nmatch their model-predicted neuronal responses to a target category, such as\nmonkey faces. These adversarial images elicited neuronal responses similar to\nthe target category. Remarkably, the same images fooled monkeys and humans at\nthe behavioral level. These results challenge fundamental assumptions about the\nsimilarity between computer and primate vision and show that a model of\nneuronal activity can selectively direct primate visual behavior.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 08:30:54 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Yuan", "Li", ""], ["Xiao", "Will", ""], ["Kreiman", "Gabriel", ""], ["Tay", "Francis E. H.", ""], ["Feng", "Jiashi", ""], ["Livingstone", "Margaret S.", ""]]}, {"id": "2011.05853", "submitter": "Robert Worden", "authors": "Robert Worden", "title": "The Aggregator Model of Spatial Cognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracking the positions of objects in local space is a core function of animal\nbrains. We do not yet understand how it is done with limited neural resources.\nThe challenges of spatial cognition are discussed under the criteria: (a)\nscaling of computational costs; (b) feature binding; (c) precise calculation of\nspatial displacements; (d) fast learning of invariant patterns; and (e)\nexploiting the strong Bayesian prior of object constancy. The leading current\nmodels of spatial cognition are Hierarchical Bayesian models of vision, and\nDeep Neural Nets. These are typically fully distributed models, which compute\nusing direct communication links between a set of modular knowledge sources,\nand no other essential components. Their distributed nature leads to\ndifficulties with the criteria (a) - (e). I discuss an alternative model of\nspatial cognition, which uses a single central position aggregator to store\nestimated locations of each object or feature, and applies constraints on\nlocations in an iterative cycle between the aggregator and the knowledge\nsources. This model has advantages in addressing the criteria (a) - (e). If\nthere is an aggregator in mammalian brains, there are reasons to believe that\nit is in the thalamus. I outline a possible neural realisation of the\naggregator function in the thalamus.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2020 12:22:59 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2020 18:01:40 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Worden", "Robert", ""]]}, {"id": "2011.05859", "submitter": "Sitabhra Sinha", "authors": "Richa Tripathi, Shakti N. Menon and Sitabhra Sinha", "title": "The nonlinearity of interactions drives networks of neural oscillators\n  to decoherence at strong coupling", "comments": "6 pages, 3 figures (+ 6 pages SI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While phase oscillators are often used to model neuronal populations, in\ncontrast to the Kuramoto paradigm, strong interactions between brain areas can\nbe associated with loss of synchrony. Using networks of coupled oscillators\ndescribed by neural mass models, we find that a transition to decoherence at\nincreased coupling strength results from the fundamental nonlinearity, e.g.,\narising from refractoriness, of the interactions between the nodes. The\nnonlinearity-driven transition also depends on the connection topology,\nunderlining the role of network structure in shaping brain activity.\n", "versions": [{"version": "v1", "created": "Thu, 29 Oct 2020 17:58:47 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Tripathi", "Richa", ""], ["Menon", "Shakti N.", ""], ["Sinha", "Sitabhra", ""]]}, {"id": "2011.05860", "submitter": "Alejandro Ramos Lora", "authors": "Mar\\'ia J. C\\'aceres and Alejandro Ramos-Lora", "title": "An understanding of the physical solutions and the blow-up phenomenon\n  for Nonlinear Noisy Leaky Integrate and Fire neuronal models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Nonlinear Noisy Leaky Integrate and Fire neuronal models are mathematical\nmodels that describe the activity of neural networks. These models have been\nstudied at a microscopic level, using Stochastic Differential Equations, and at\na mesoscopic/macroscopic level, through the mean field limits using\nFokker-Planck type equations. The aim of this paper is to improve their\nunderstanding, using a numerical study of their particle systems. We analyse in\ndepth the behaviour of the classical and physical solutions of the Stochastic\nDifferential Equations and, we compare it with what is already known about the\nFokker-Planck equation. This allows us to better understand what happens in the\nneural network when an explosion occurs in finite time. After firing all\nneurons at the same time, if the system is weakly connected, the neural network\nconverges towards its unique steady state. Otherwise, its behaviour is more\ncomplex, because it can tend towards a stationary state or a \"plateau\"\ndistribution.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 20:00:38 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["C\u00e1ceres", "Mar\u00eda J.", ""], ["Ramos-Lora", "Alejandro", ""]]}, {"id": "2011.05861", "submitter": "Jing Mu", "authors": "Jing Mu, Ying Tan, David B. Grayden, and Denny Oetomo", "title": "Multi-Frequency Canonical Correlation Analysis (MFCCA): An Extended\n  Decoding Algorithm for Multi-Frequency SSVEP", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stimulation methods that utilise more than one stimulation frequency have\nbeen developed in steady-state visual evoked potential (SSVEP) brain-computer\ninterfaces (BCIs) for the purpose of increasing the number of targets that can\nbe presented simultaneously. However, there is no unified decoding algorithm\nthat can be applied to a large class of multi-frequency stimulated SSVEP\nsettings. This paper extends the widely used canonical correlation analysis\n(CCA) decoder to explicitly accommodate multi-frequency SSVEP by exploiting the\ninteractions between the multiple stimulation frequencies. A concept \"order\"\nwas defined as the sum of absolute values of the coefficients in the linear\ninteraction. The probability distribution of the order in the resulting SSVEP\nresponse was then used to improve decoding accuracy. Results show that,\ncompared to the standard CCA formulation, the proposed multi-frequency CCA\n(MFCCA) has a 20% improvement in decoding accuracy on average at order 2.\nAlthough the proposed methods were only tested with two input frequencies, the\ntechnique is capable of handling more than two simultaneous input frequencies.\n", "versions": [{"version": "v1", "created": "Tue, 27 Oct 2020 09:02:03 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Mu", "Jing", ""], ["Tan", "Ying", ""], ["Grayden", "David B.", ""], ["Oetomo", "Denny", ""]]}, {"id": "2011.05868", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley", "title": "Seven properties of self-organization in the human brain", "comments": null, "journal-ref": "Big Data and Cognitive Computing, 2020; 4, article10", "doi": "10.3390/bdcc4020010", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of self-organization has acquired a fundamental significance in\nthe newly emerging field of computational philosophy. Self-organizing systems\nhave been described in various domains in science and philosophy including\nphysics, neuroscience, biology and medicine, ecology, and sociology. While\nsystem architecture and their general purpose may depend on domain specific\nconcepts and definitions, there are at least seven key properties of\nself-organization clearly identified in brain systems: modular connectivity,\nunsupervised learning, adaptive ability, functional resiliency, functional\nplasticity, from-local-to-global functional organization and dynamic system\ngrowth. These are defined here in the light of insight from neurobiology,\ncognitive neuroscience and Adaptive Resonance Theory (ART), and physics to show\nthat self-organization achieves stability and functional plasticity while\nminimizing structural system complexity. A specific example informed by\nempirical research is discussed to illustrate how modularity, adaptive\nlearning, and dynamic network growth enable stable yet plastic somatosensory\nrepresentation for human grip force control. Implications for the design of\nstrong artificial intelligence in robotics are brought forward.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 16:03:15 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Dresp-Langley", "Birgitta", ""]]}, {"id": "2011.06066", "submitter": "Lee Susman", "authors": "Lee Susman, Francesca Mastrogiuseppe, Naama Brenner, Omri Barak", "title": "Quality of internal representation shapes learning performance in\n  feedback neural networks", "comments": "37 pages, 11 figures; including appendices", "journal-ref": "Phys. Rev. Research 3, 013176 (2021)", "doi": "10.1103/PhysRevResearch.3.013176", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A fundamental feature of complex biological systems is the ability to form\nfeedback interactions with their environment. A prominent model for studying\nsuch interactions is reservoir computing, where learning acts on\nlow-dimensional bottlenecks. Despite the simplicity of this learning scheme,\nthe factors contributing to or hindering the success of training in reservoir\nnetworks are in general not well understood. In this work, we study non-linear\nfeedback networks trained to generate a sinusoidal signal, and analyze how\nlearning performance is shaped by the interplay between internal network\ndynamics and target properties. By performing exact mathematical analysis of\nlinearized networks, we predict that learning performance is maximized when the\ntarget is characterized by an optimal, intermediate frequency which\nmonotonically decreases with the strength of the internal reservoir\nconnectivity. At the optimal frequency, the reservoir representation of the\ntarget signal is high-dimensional, de-synchronized, and thus maximally robust\nto noise. We show that our predictions successfully capture the qualitative\nbehaviour of performance in non-linear networks. Moreover, we find that the\nrelationship between internal representations and performance can be further\nexploited in trained non-linear networks to explain behaviours which do not\nhave a linear counterpart. Our results indicate that a major determinant of\nlearning success is the quality of the internal representation of the target,\nwhich in turn is shaped by an interplay between parameters controlling the\ninternal network and those defining the task.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2020 20:46:01 GMT"}], "update_date": "2021-03-03", "authors_parsed": [["Susman", "Lee", ""], ["Mastrogiuseppe", "Francesca", ""], ["Brenner", "Naama", ""], ["Barak", "Omri", ""]]}, {"id": "2011.06387", "submitter": "Nisheet Patel", "authors": "Nisheet Patel, Luigi Acerbi, Alexandre Pouget", "title": "Dynamic allocation of limited memory resources in reinforcement learning", "comments": "In Advances in Neural Information Processing Systems 33 (NeurIPS\n  2020). [16 pages: 9 main + 3 references + 4 supplementary; 4 figures: 3 main\n  + 1 supplementary]", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biological brains are inherently limited in their capacity to process and\nstore information, but are nevertheless capable of solving complex tasks with\napparent ease. Intelligent behavior is related to these limitations, since\nresource constraints drive the need to generalize and assign importance\ndifferentially to features in the environment or memories of past experiences.\nRecently, there have been parallel efforts in reinforcement learning and\nneuroscience to understand strategies adopted by artificial and biological\nagents to circumvent limitations in information storage. However, the two\nthreads have been largely separate. In this article, we propose a dynamical\nframework to maximize expected reward under constraints of limited resources,\nwhich we implement with a cost function that penalizes precise representations\nof action-values in memory, each of which may vary in its precision. We derive\nfrom first principles an algorithm, Dynamic Resource Allocator (DRA), which we\napply to two standard tasks in reinforcement learning and a model-based\nplanning task, and find that it allocates more resources to items in memory\nthat have a higher impact on cumulative rewards. Moreover, DRA learns faster\nwhen starting with a higher resource budget than what it eventually allocates\nfor performing well on tasks, which may explain why frontal cortical areas in\nbiological brains appear more engaged in early stages of learning before\nsettling to lower asymptotic levels of activity. Our work provides a normative\nsolution to the problem of learning how to allocate costly resources to a\ncollection of uncertain memories in a manner that is capable of adapting to\nchanges in the environment.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 13:58:07 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2020 11:37:12 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Patel", "Nisheet", ""], ["Acerbi", "Luigi", ""], ["Pouget", "Alexandre", ""]]}, {"id": "2011.06662", "submitter": "Ewan McNay", "authors": "Damon Vinciguerra, Margot Vigeant, Ewan C. McNay", "title": "Mathematical Model of Hippocampal Microdialysis: Validation of in vivo\n  Methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Microdialysis is a well-established method for in vivo neurochemical\nmeasurements of small molecules, with implanted concentric-design probes\noffering minimized tissue damage and good temporal and spatial resolution.\nHowever, the large majority of measurements do not allow the perfusate to reach\nequilibrium with the brain, so that inferential methods of sample concentration\ncorrection such as zero-net-flux must be used to determine actual brain\nextracellular fluid glucose concentrations. In order for such methods to be\nvalid, steady-state transfer of the analyte of interest within the brain is\nrequired, but this situation has not previously been confirmed. A\nfirst-principles mathematical model of fluid flow and analyte diffusion around\nan implanted microdialysis probe was developed and implemented in COMSOL in\norder to validate the zero-net-flux approach, using measurement of\nextracellular brain glucose levels as a well-explored example system against\nwhich to compare the model. Results from the model accurately reproduced and\npredicted results from in vivo experiments. Importantly, the model predicts\nthat the time for an implanted probe to achieve steady-state equilibrium with\nthe surrounding extracellular fluid is on the order of one to two minutes,\nsupporting the validity of this technique for quantitative measurement of in\nvivo neurochemistry.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 21:36:03 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Vinciguerra", "Damon", ""], ["Vigeant", "Margot", ""], ["McNay", "Ewan C.", ""]]}, {"id": "2011.06723", "submitter": "Richard Betzel", "authors": "Richard F. Betzel", "title": "Community detection in network neuroscience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many real-world networks, including nervous systems, exhibit meso-scale\nstructure. This means that their elements can be grouped into meaningful\nsub-networks. In general, these sub-networks are unknown ahead of time and must\nbe \"discovered\" algorithmically using community detection methods. In this\narticle, we review evidence that nervous systems exhibit meso-scale structure\nin the form of communities, clusters, and modules. We also provide a set of\nguidelines to assist users in applying community detection methods to their own\nnetwork data. These guidelines focus on the method of modularity maximization\nbut, in many cases, are general and applicable to other techniques.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 02:10:19 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Betzel", "Richard F.", ""]]}, {"id": "2011.06878", "submitter": "Giulia Cisotto", "authors": "Giulia Cisotto", "title": "REPAC: Reliable estimation of phase-amplitude coupling in brain networks", "comments": null, "journal-ref": "2021 IEEE International Conference on Acoustics, Speech and Signal\n  Processing (ICASSP)", "doi": "10.1109/ICASSP39728.2021.9414749", "report-no": null, "categories": "eess.SP cs.CV cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent evidence has revealed cross-frequency coupling and, particularly,\nphase-amplitude coupling (PAC) as an important strategy for the brain to\naccomplish a variety of high-level cognitive and sensory functions. However,\ndecoding PAC is still challenging. This contribution presents REPAC, a reliable\nand robust algorithm for modeling and detecting PAC events in EEG signals.\nFirst, we explain the synthesis of PAC-like EEG signals, with special attention\nto the most critical parameters that characterize PAC, i.e., SNR, modulation\nindex, duration of coupling. Second, REPAC is introduced in detail. We use\ncomputer simulations to generate a set of random PAC-like EEG signals and test\nthe performance of REPAC with regard to a baseline method. REPAC is shown to\noutperform the baseline method even with realistic values of SNR, e.g., -10 dB.\nThey both reach accuracy levels around 99%, but REPAC leads to a significant\nimprovement of sensitivity, from 20.11% to 65.21%, with comparable specificity\n(around 99%). REPAC is also applied to a real EEG signal showing preliminary\nencouraging results.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 12:26:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Cisotto", "Giulia", ""]]}, {"id": "2011.06962", "submitter": "Sophie Beraud-Dufour", "authors": "Thierry Coppola (IPMC), Sophie B\\'eraud-Dufour (IPMC), Patricia Lebrun\n  (UNSA), Nicolas Blondeau (IPMC)", "title": "Bridging the Gap Between Diabetes and Stroke in Search of High Clinical\n  Relevance Therapeutic Targets", "comments": "NeuroMolecular Medicine, Humana Press, 2019", "journal-ref": null, "doi": "10.1007/s12017-019-08563-5", "report-no": null, "categories": "q-bio.TO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diabetes affects more than 425 million people worldwide, a scale approaching\npandemic proportion. Diabetes represents a major risk factor for stroke, and\ntherefore is actively addressed for stroke prevention. However, how diabetes\naffects stroke severity has not yet been extensively considered, which is\nsurprising given the evident but understudied common mechanistic features of\nboth pathologies. The increase in number of diabetic people, in the incidence\nof stroke in presence of this specific risk factor, and the exacerbation of\nischemic brain damage in diabetic conditions (at least in animal models)\nwarrant the need to integrate this comorbidity in pre-clinical studies of brain\nischemia to develop novel therapeutic approaches. Therefore, a better\nunderstanding of the commonalties involved in the course of both diseases would\noffer the promise of discovering novel neuroprotective pathways that would be\nmore appropriated to clinical situations. In this article, we will review the\nrelevant mechanisms that have been identified as common traits of both\npathologies and that could be to our knowledge, potential targets for both\npathologies.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2020 15:19:22 GMT"}], "update_date": "2020-11-16", "authors_parsed": [["Coppola", "Thierry", "", "IPMC"], ["B\u00e9raud-Dufour", "Sophie", "", "IPMC"], ["Lebrun", "Patricia", "", "UNSA"], ["Blondeau", "Nicolas", "", "IPMC"]]}, {"id": "2011.07334", "submitter": "Eli Moore", "authors": "Eli Moore and Rishidev Chaudhuri", "title": "Using noise to probe recurrent neural network structure and prune\n  synapses", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 33 (NeurIPS\n  2020)", "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many networks in the brain are sparsely connected, and the brain eliminates\nsynapses during development and learning. How could the brain decide which\nsynapses to prune? In a recurrent network, determining the importance of a\nsynapse between two neurons is a difficult computational problem, depending on\nthe role that both neurons play and on all possible pathways of information\nflow between them. Noise is ubiquitous in neural systems, and often considered\nan irritant to be overcome. Here we suggest that noise could play a functional\nrole in synaptic pruning, allowing the brain to probe network structure and\ndetermine which synapses are redundant. We construct a simple, local,\nunsupervised plasticity rule that either strengthens or prunes synapses using\nonly synaptic weight and the noise-driven covariance of the neighboring\nneurons. For a subset of linear and rectified-linear networks, we prove that\nthis rule preserves the spectrum of the original matrix and hence preserves\nnetwork dynamics even when the fraction of pruned synapses asymptotically\napproaches 1. The plasticity rule is biologically-plausible and may suggest a\nnew role for noise in neural computation.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 16:51:05 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 18:07:01 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Moore", "Eli", ""], ["Chaudhuri", "Rishidev", ""]]}, {"id": "2011.07365", "submitter": "Arunesh Mittal", "authors": "Arunesh Mittal, Scott Linderman, John Paisley, Paul Sajda", "title": "Bayesian recurrent state space model for rs-fMRI", "comments": "Machine Learning for Health (ML4H) at NeurIPS 2020 - Extended\n  Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a hierarchical Bayesian recurrent state space model for modeling\nswitching network connectivity in resting state fMRI data. Our model allows us\nto uncover shared network patterns across disease conditions. We evaluate our\nmethod on the ADNI2 dataset by inferring latent state patterns corresponding to\naltered neural circuits in individuals with Mild Cognitive Impairment (MCI). In\naddition to states shared across healthy and individuals with MCI, we discover\nlatent states that are predominantly observed in individuals with MCI. Our\nmodel outperforms current state of the art deep learning method on ADNI2\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 18:53:24 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Mittal", "Arunesh", ""], ["Linderman", "Scott", ""], ["Paisley", "John", ""], ["Sajda", "Paul", ""]]}, {"id": "2011.07388", "submitter": "Shahriar Iravanian", "authors": "Shahriar Iravanian", "title": "Discovery of the Hidden State in Ionic Models Using a Domain-Specific\n  Recurrent Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ionic models, the set of ordinary differential equations (ODEs) describing\nthe time evolution of the state of excitable cells, are the cornerstone of\nmodeling in neuro- and cardiac electrophysiology. Modern ionic models can have\ntens of state variables and hundreds of tunable parameters. Fitting ionic\nmodels to experimental data, which usually covers only a limited subset of\nstate variables, remains a challenging problem. In this paper, we describe a\nrecurrent neural network architecture designed specifically to encode ionic\nmodels. The core of the model is a Gating Neural Network (GNN) layer, capturing\nthe dynamics of classic (Hodgkin-Huxley) gating variables. The network is\ntrained in two steps: first, it learns the theoretical model coded in a set of\nODEs, and second, it is retrained on experimental data. The retrained network\nis interpretable, such that its results can be incorporated back into the model\nODEs. We tested the GNN networks using simulated ventricular action potential\nsignals and showed that it could deduce physiologically-feasible alterations of\nionic currents. Such domain-specific neural networks can be employed in the\nexploratory phase of data assimilation before further fine-tuning using\nstandard optimization techniques.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2020 21:13:41 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Iravanian", "Shahriar", ""]]}, {"id": "2011.08024", "submitter": "Shailaja Akella", "authors": "Shailaja Akella, Ali Mohebi, Kiersten Riels, Andreas Keil, Karim\n  Oweiss, Jose C. Principe", "title": "Local power estimation of neuromodulations using point process modeling", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracellular electrical potentials (EEP) recorded from the brain are an\nactive manifestation of all cellular processes that propagate within a volume\nof brain tissue. A standard approach for their quantification are power\nspectral analyses methods that reflect the global distribution of signal power\nover frequency. However, these methods incorporate analysis windows to achieve\nlocality and therefore, are limited by the inherent trade - off between time\nand frequency resolutions. In this paper, we present a novel approach to\nestimate local power more precisely at a resolution as high as the sampling\nfrequency. Our methods are well grounded on established neurophysiology of the\nbio-signals where we model EEPs as comprising of two components:\nneuromodulations and background activity. A local measure of power, we call\nMarked Point Process (MPP) spectrogram, is then derived as a power - weighted\nintensity function of the point process for neuromodulations. We demonstrate\nour results on two datasets: 1) local field potentials recorded from the\nprefrontal cortex of 3 rats performing a working memory task and 2) EEPs\nrecorded via electroencephalography from the visual cortex of human subjects\nperforming a conditioned stimulus task. A detailed analysis of the power -\nspecific marked features of neuromodulations confirm high correlation between\npower spectral density and power in neuromodulations establishing the aptness\nof MPP spectrogram as a finer measure of power where it is able to track local\nvariations in power while preserving the global structure of signal power\ndistribution.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 15:20:33 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Akella", "Shailaja", ""], ["Mohebi", "Ali", ""], ["Riels", "Kiersten", ""], ["Keil", "Andreas", ""], ["Oweiss", "Karim", ""], ["Principe", "Jose C.", ""]]}, {"id": "2011.08081", "submitter": "Morteza Nattagh Najafi", "authors": "M. Rahimi-Majd, M. A. Seifi, L. de Arcangelis, M. N. Najafi", "title": "On the role of anaxonic local neurons in the crossover to continuously\n  varying exponents for avalanche activity", "comments": null, "journal-ref": "Phys. Rev. E 103, 042402 (2021)", "doi": "10.1103/PhysRevE.103.042402", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local anaxonic neurons with graded potential release are important\ningredients of nervous systems, present in the olfactory bulb system of\nmammalians, in the human visual system, as well as in arthropods and nematodes.\nWe develop a neuronal network model including both axonic and anaxonic neurons\nand monitor the activity tuned by the following parameters: The decay length of\nthe graded potential in local neurons, the fraction of local neurons, the\nlargest eigenvalue of the adjacency matrix and the range of connections of the\nlocal neurons. Tuning the fraction of local neurons, we derive the phase\ndiagram including two transition lines: A critical line separating subcritical\nand supercritical regions, characterized by power law distributions of\navalanche sizes and durations, and a bifurcation line. We find that the overall\nbehavior of the system is controlled by a parameter tuning the relevance of\nlocal neuron transmission with respect to the axonal one. The statistical\nproperties of spontaneous activity are affected by local neurons at large\nfractions and in the condition that the graded potential transmission dominates\nthe axonal one. In this case the scaling properties of spontaneous activity\nexhibit continuously varying exponents, rather than the mean field branching\nmodel universality class.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 16:27:29 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Rahimi-Majd", "M.", ""], ["Seifi", "M. A.", ""], ["de Arcangelis", "L.", ""], ["Najafi", "M. N.", ""]]}, {"id": "2011.08088", "submitter": "Mark Humphries", "authors": "Mark D Humphries", "title": "Strong and weak principles of neural dimension reduction", "comments": "27 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  If spikes are the medium, what is the message? Answering that question is\ndriving the development of large-scale, single neuron resolution recordings\nfrom behaving animals, on the scale of thousands of neurons. But these data are\ninherently high-dimensional, with as many dimensions as neurons - so how do we\nmake sense of them? For many the answer is to reduce the number of dimensions.\nHere I argue we can distinguish weak and strong principles of neural dimension\nreduction. The weak principle is that dimension reduction is a convenient tool\nfor making sense of complex neural data. The strong principle is that dimension\nreduction shows us how neural circuits actually operate and compute.\nElucidating these principles is crucial, for which we subscribe to provides\nradically different interpretations of the same neural activity data. I show\nhow we could make either the weak or strong principles appear to be true based\non innocuous looking decisions about how we use dimension reduction on our\ndata. To counteract these confounds, I outline the experimental evidence for\nthe strong principle that do not come from dimension reduction; but also show\nthere are a number of neural phenomena that the strong principle fails to\naddress. To reconcile these conflicting data, I suggest that the brain has both\nprinciples at play.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 16:39:56 GMT"}, {"version": "v2", "created": "Thu, 18 Mar 2021 17:22:03 GMT"}, {"version": "v3", "created": "Mon, 24 May 2021 10:51:20 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Humphries", "Mark D", ""]]}, {"id": "2011.08215", "submitter": "Wojciech Tarnowski", "authors": "Wojciech Tarnowski", "title": "Transient amplification in balanced neural networks", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transient amplification has been proposed as an important mechanism not only\nin neuroscience but in many areas modeled by dynamical systems. Despite that,\nthere is no clear biologically plausible mechanism which fine-tunes the\ncoupling matrix or selects signals to be amplified. In this work we\nquantitatively study transient dynamics in the Rajan-Abbott model of a\nrecurrent neural network [K. Rajan and L.F. Abbot PRL 97, 188104 (2006)]. We\nfind a second order transition between a phase of weakly or no amplified\ntransients and a phase of strong amplification, where the average trajectory is\namplified. In the latter phase the combination of Dale's principle and\nexcitatory/inhibitory balance allows for strong weights, while maintaining the\nsystem at the edge of chaos. Moreover, we show that the amplification goes hand\nin hand with greater variability of the dynamics. By numerically studying the\nfull probability density of the squared norm, we observe as the strength of\nweights grows, the right tail of the distribution becomes heavier, moving from\nthe Gaussian to the exponential tail.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2020 19:03:16 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Tarnowski", "Wojciech", ""]]}, {"id": "2011.08444", "submitter": "Shusen Pu", "authors": "Shusen Pu and Peter J. Thomas", "title": "Resolving Molecular Contributions of Ion Channel Noise to Interspike\n  Interval Variability through Stochastic Shielding", "comments": "51 pages, 14 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NA math.DS math.NA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The contributions of independent noise sources to the variability of action\npotential timing has not previously been studied at the level of individual\ndirected molecular transitions within a conductance-based model ion-state\ngraph. The underlying connection provides an important example of how\nmathematics can be applied to study the effects of unobservable microscopic\nfluctuations to macroscopically observable quantities. We study a stochastic\nLangevin model and show how to resolve the individual contributions that each\ntransition in the ion channel graph makes to the variance of the interspike\ninterval (ISI). We extend the mean--return-time (MRT) phase reduction developed\nin (Cao et al. 2020, SIAM J. Appl. Math) to the second moment of the return\ntime from an MRT isochron to itself. Because fixed-voltage spike-detection\ntriggers do not correspond to MRT isochrons, the inter-phase interval (IPI)\nvariance only approximates the ISI variance. We find the IPI variance and ISI\nvariance agree to within a few percent when both can be computed. Moreover, we\nprove rigorously, and show numerically, that our expression for the IPI\nvariance is accurate in the small noise (large system size) regime; our theory\nis exact in the limit of small noise. By selectively including the noise\nassociated with only those few transitions responsible for most of the ISI\nvariance, our analysis extends the stochastic shielding (SS) paradigm (Schmandt\net al. 2012, Phys. Rev. Lett.) from the stationary voltage-clamp case to the\ncurrent-clamp case. We show numerically that the SS approximation has a high\ndegree of accuracy even for larger, physiologically relevant noise levels. We\nshow that the ISI variance is not an unambiguously defined quantity, but\ndepends on the choice of voltage level set as the spike-detection threshold,\nboth in vitro and in silico.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 05:54:50 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Pu", "Shusen", ""], ["Thomas", "Peter J.", ""]]}, {"id": "2011.08783", "submitter": "Karla Burelo", "authors": "Karla Burelo and Mohammadali Sharifshazileh and Niklaus Krayenb\\\"uhl\n  and Georgia Ramantani and Giacomo Indiveri and Johannes Sarnthein", "title": "A Spiking Neural Network (SNN) for detecting High Frequency Oscillations\n  (HFOs) in the intraoperative ECoG", "comments": "11 pages, 3 figures, 2 tables. The results of this publication were\n  obtained by simulating our hardware platform, built for online processing of\n  biological signals. This hardware combines neural recording headstages with a\n  multi-core neuromorphic processor arxiv.org/abs/2009.11245", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve seizure freedom, epilepsy surgery requires the complete resection\nof the epileptogenic brain tissue. In intraoperative ECoG recordings, high\nfrequency oscillations (HFOs) generated by epileptogenic tissue can be used to\ntailor the resection margin. However, automatic detection of HFOs in real-time\nremains an open challenge. Here we present a spiking neural network (SNN) for\nautomatic HFO detection that is optimally suited for neuromorphic hardware\nimplementation. We trained the SNN to detect HFO signals measured from\nintraoperative ECoG on-line, using an independently labeled dataset. We\ntargeted the detection of HFOs in the fast ripple frequency range (250-500 Hz)\nand compared the network results with the labeled HFO data. We endowed the SNN\nwith a novel artifact rejection mechanism to suppress sharp transients and\ndemonstrate its effectiveness on the ECoG dataset. The HFO rates (median 6.6\nHFO/min in pre-resection recordings) detected by this SNN are comparable to\nthose published in the dataset (58 min, 16 recordings). The postsurgical\nseizure outcome was \"predicted\" with 100% accuracy for all 8 patients. These\nresults provide a further step towards the construction of a real-time portable\nbattery-operated HFO detection system that can be used during epilepsy surgery\nto guide the resection of the epileptogenic zone.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2020 17:24:46 GMT"}], "update_date": "2020-11-18", "authors_parsed": [["Burelo", "Karla", ""], ["Sharifshazileh", "Mohammadali", ""], ["Krayenb\u00fchl", "Niklaus", ""], ["Ramantani", "Georgia", ""], ["Indiveri", "Giacomo", ""], ["Sarnthein", "Johannes", ""]]}, {"id": "2011.09057", "submitter": "Pablo M. Gleiser", "authors": "Carlos E. Valencia Urbina, Sergio A. Cannas, Pablo M. Gleiser", "title": "Linking the connectome to action: Emergent dynamics in a robotic model\n  of C. elegans", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We analyse the neural dynamics and its relation with the emergent behaviour\nof a robotic vehicle that is controlled by a neural network numerical\nsimulation based on the nervous system of the nematode Caenorhabditis elegans.\nThe robot interacts with the environment through a sensor, that transmits the\ninformation to sensory neurons, while motor neurons outputs are connected to\nwheels. This is enough to allow robot movement in complex environments,\navoiding collisions with obstacles. Working with a robotic model makes it\npossible to keep track simultaneously of the detailed microscopic dynamics of\nall the neurons and also register the actions of the robot in the environment\nin real time. This allowed us to study the interplay between connectome and\ncomplex behaviors. We found that some basic features of the global neural\ndynamics and their correlation with behaviour observed in the worm appear\nspontaneously in the robot, suggesting they are just an emergent property of\nthe connectome.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 02:59:23 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Urbina", "Carlos E. Valencia", ""], ["Cannas", "Sergio A.", ""], ["Gleiser", "Pablo M.", ""]]}, {"id": "2011.09232", "submitter": "Audrey B\\\"urki", "authors": "Pamela Fuhrmeister, Sylvain Madec, Antje Lorenz, Shereen Elbuy, Audrey\n  B\\\"urki", "title": "Behavioral and EEG evidence for inter-individual variability in late\n  encoding stages of word production", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individuals differ in the time it takes to produce words when naming a\npicture. However, it is unknown whether this inter-individual variability\nemerges in earlier stages of word production (e.g., lexical selection) or later\nstages (e.g., articulation). The current study measured participants' (N = 45)\nnaming latencies and continuous EEG in a picture-word-interference task, as\nwell as naming latencies in a delayed naming task. The inter-individual\nvariability in naming latencies in immediate naming was not larger than the\nvariability in the delayed task. Thus, a large part of the variability in\nimmediate naming seems to originate in relatively late stages of word\nproduction. This interpretation was complemented by the EEG data: Differences\nbetween relatively fast vs. slow speakers were seen in response-aligned\nanalyses in a time window close to the vocal response. Finally, we show that\ninter-individual variability can influence EEG results at the group level.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 11:58:32 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Fuhrmeister", "Pamela", ""], ["Madec", "Sylvain", ""], ["Lorenz", "Antje", ""], ["Elbuy", "Shereen", ""], ["B\u00fcrki", "Audrey", ""]]}, {"id": "2011.09283", "submitter": "Tom Froese", "authors": "Tom Froese, Emiliano Gallaga", "title": "Measuring entanglement in material traces of ritualized interaction:\n  Preferential attachment in a prehistoric petroglyph distribution", "comments": "To be published in \"The Routledge Handbook of Material Religion\"\n  edited by S Brent Rodriguez-Plate, Pooyan Tamimi Arab, and Jennifer Scheper\n  Hughes", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Prehistoric rock art is often analyzed predominantly as the product of\nartists intentions to create public representations of their perceptual\nexperiences and mental imagery. However, this representation-centered approach\ntends to overlook the performative role of much material engagement. Many forms\nof rock art are better conceived of as traces from artists repeated engagement\nwith a surface, including with previous traces. For these artists, a\npotentially more relevant intention was ritualized interaction, such as\ncommunion and petition, which were realized as materially mediated transactions\nwith the agencies that were believed to animate specific areas of the\nenvironment. If so, we can expect the motifs to be strongly clustered on\nritually attractive areas, rather than to be evenly distributed on canvas-like\nsurfaces that would maximize their visibility as public representations. Here\nwe propose a novel way of testing the interaction-centered approach in terms of\npreferential attachment, which is a concept from network science that describe\nthe well-known social phenomenon that popular agents tend to attract more\nfollowers. We applied this approach to a case study of an archaic site in\nChihuahua, Mexico, and found that its petroglyph distribution has the form of a\npower law, which is consistent with preferential attachment. We conclude that\nthis approach could be developed into a measure of the entanglement between\nritual processes and products in prehistoric material engagement.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2020 04:25:57 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Froese", "Tom", ""], ["Gallaga", "Emiliano", ""]]}, {"id": "2011.09316", "submitter": "Audrey B\\\"urki", "authors": "Pamela Fuhrmeister, Audrey B\\\"urki", "title": "Delta plot analyses do not reflect individual differences in selective\n  inhibition during picture-word interference tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Individuals vary in the time needed to produce a spoken word, for example\nwhen naming a picture. Similarly, they vary in how much their responses are\ndelayed by interfering stimuli. Several studies have linked this variability to\nindividual differences in inhibition abilities. The present study focuses on\nthe relationship between the semantic interference effect in a picture-word\nnaming task (longer picture-naming latencies in trials with semantically\nrelated than unrelated distractor words) and the change in the magnitude of\nthis effect in the tail of the response time distribution. The positive\ncorrelation between these two measures, when computed separately for each\nparticipant, has been argued to reflect the involvement of selective inhibition\nin the naming task. We report a series of Bayesian meta-analyses to investigate\nthe reliability of this relationship and to rule out possible alternative\nexplanations. We find that while the relationship is robust, the same\nrelationship is found when we calculate the index of inhibition for individual\nitems, rather than participants. This latter finding challenges the assumption\nthat this measurement reflects individual differences in inhibition ability.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 14:36:50 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Fuhrmeister", "Pamela", ""], ["B\u00fcrki", "Audrey", ""]]}, {"id": "2011.09380", "submitter": "Alireza Nadafian Neghabi", "authors": "Alireza Nadafian, Mohammad Ganjtabesh", "title": "Bio-plausible Unsupervised Delay Learning for Extracting Temporal\n  Features in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The plasticity of the conduction delay between neurons plays a fundamental\nrole in learning. However, the exact underlying mechanisms in the brain for\nthis modulation is still an open problem. Understanding the precise adjustment\nof synaptic delays could help us in developing effective brain-inspired\ncomputational models in providing aligned insights with the experimental\nevidence. In this paper, we propose an unsupervised biologically plausible\nlearning rule for adjusting the synaptic delays in spiking neural networks.\nThen, we provided some mathematical proofs to show that our learning rule gives\na neuron the ability to learn repeating spatio-temporal patterns. Furthermore,\nthe experimental results of applying an STDP-based spiking neural network\nequipped with our proposed delay learning rule on Random Dot Kinematogram\nindicate the efficacy of the proposed delay learning rule in extracting\ntemporal features.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 16:25:32 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Nadafian", "Alireza", ""], ["Ganjtabesh", "Mohammad", ""]]}, {"id": "2011.09512", "submitter": "Rodrigo Cofre", "authors": "Rodrigo Cofr\\'e and Cesar Maldonado and Bruno Cessac", "title": "Thermodynamic Formalism in Neuronal Dynamics and Spike Train Statistics", "comments": null, "journal-ref": null, "doi": "10.3390/e22111330", "report-no": null, "categories": "q-bio.NC math-ph math.MP nlin.CD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Thermodynamic Formalism provides a rigorous mathematical framework to\nstudy quantitative and qualitative aspects of dynamical systems. At its core\nthere is a variational principle corresponding, in its simplest form, to the\nMaximum Entropy principle. It is used as a statistical inference procedure to\nrepresent, by specific probability measures (Gibbs measures), the collective\nbehaviour of complex systems. This framework has found applications in\ndifferent domains of science. In particular, it has been fruitful and\ninfluential in neurosciences. In this article, we review how the Thermodynamic\nFormalism can be exploited in the field of theoretical neuroscience, as a\nconceptual and operational tool, to link the dynamics of interacting neurons\nand the statistics of action potentials from either experimental data or\nmathematical models. We comment on perspectives and open problems in\ntheoretical neuroscience that could be addressed within this formalism.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2020 19:36:58 GMT"}], "update_date": "2020-12-30", "authors_parsed": [["Cofr\u00e9", "Rodrigo", ""], ["Maldonado", "Cesar", ""], ["Cessac", "Bruno", ""]]}, {"id": "2011.09958", "submitter": "Thierry Mora", "authors": "Daniele Conti and Thierry Mora", "title": "Non-equilibrium dynamics of adaptation in sensory systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adaptation is used by biological sensory systems to respond to a wide range\nof environmental signals, by adapting their response properties to the\nstatistics of the stimulus in order to maximize information transmission. We\nderive rules of optimal adaptation to changes in the mean and variance of a\ncontinuous stimulus in terms of Bayesian filters, and map them onto stochastic\nequations that couple the state of the environment to an internal variable\ncontroling the response function. We calculate numerical and exact results for\nthe speed and accuracy of adaptation, and its impact on information\ntransmission. We find that, in the regime of efficient adaptation, the speed of\nadaptation scales sublinearly with the rate of change of the environment.\nFinally, we exploit the mathematical equivalence between adaptation and\nstochastic thermodynamics to quantitatively relate adaptation to the\nirreversibility of the adaptation time course, defined by the rate of entropy\nproduction. Our results suggest a means to empirically quantify adaptation in a\nmodel-free and non-parametric way.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 16:57:40 GMT"}, {"version": "v2", "created": "Mon, 12 Apr 2021 18:41:46 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Conti", "Daniele", ""], ["Mora", "Thierry", ""]]}, {"id": "2011.10079", "submitter": "Joaquin Goni", "authors": "Benjamin Chi\\^em, Kausar Abbas, Enrico Amico, Duy Anh Duong-Tran,\n  Fr\\'ed\\'eric Crevecoeur, Joaqu\\'in Go\\~ni", "title": "Improving Functional Connectome Fingerprinting with Degree-Normalization", "comments": "Main: 23 pages, 7 Figures, Supplementary: 3 pages, 3 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Functional connectivity quantifies the statistical dependencies between the\nactivity of brain regions, measured using neuroimaging data such as functional\nMRI BOLD time series. The network representation of functional connectivity,\ncalled a Functional Connectome (FC), has been shown to contain an individual\nfingerprint allowing participants identification across consecutive testing\nsessions. Recently, researchers have focused on the extraction of these\nfingerprints, with potential applications in personalized medicine.\n  Here, we show that a mathematical operation denominated degree-normalization\ncan improve the extraction of FC fingerprints. Degree-normalization has the\neffect of reducing the excessive influence of strongly connected brain areas in\nthe whole-brain network. We adopt the differential identifiability framework\nand apply it to both original and degree-normalized FCs of 409 individuals from\nthe Human Connectome Project, in resting-state and 7 fMRI tasks.\n  Our results indicate that degree-normalization systematically improves three\nfingerprinting metrics, namely differential identifiability, identification\nrate and matching rate. Moreover, the results related to the matching rate\nmetric suggest that individual fingerprints are embedded in a low-dimensional\nspace.\n  The results suggest that low-dimensional functional fingerprints lie in part\nin weakly connected subnetworks of the brain, and that degree-normalization\nhelps uncovering them. This work introduces a simple mathematical operation\nthat could lead to significant improvements in future FCs fingerprinting\nstudies.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2020 19:29:10 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Chi\u00eam", "Benjamin", ""], ["Abbas", "Kausar", ""], ["Amico", "Enrico", ""], ["Duong-Tran", "Duy Anh", ""], ["Crevecoeur", "Fr\u00e9d\u00e9ric", ""], ["Go\u00f1i", "Joaqu\u00edn", ""]]}, {"id": "2011.10319", "submitter": "Vincent Huin", "authors": "Vincent Huin, Mathieu Barbier, Armand Bottani, Johannes Lobrinus,\n  Fabienne Clot, Foudil Lamari, Laureen Chat, Beno\\^it Rucheton, Fr\\'ed\\'erique\n  Fluch\\`ere, St\\'ephane Auvin, Peter Myers, Antoinette Gelot, Agn\\`es Camuzat,\n  Catherine Caillaud, Ludmila Jorn\\'ea, Sylvie Forlani, Dario Saracino, Charles\n  Duyckaerts, Alexis Brice, Alexandra Durr, Isabelle Le Ber", "title": "Homozygous GRN mutations: unexpected phenotypes and new insights into\n  pathological and molecular mechanisms", "comments": null, "journal-ref": "Brain - A Journal of Neurology , Oxford University Press (OUP),\n  2020, 143 (1), pp.303-319", "doi": "10.1093/brain/awz377", "report-no": null, "categories": "q-bio.BM q-bio.GN q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Homozygous mutations in the progranulin gene (GRN) are associated with\nneuronal ceroid lipofuscinosis 11 (CLN11), a rare lysosomal-storage disorder\ncharacterized by cerebellar ataxia, seizures, retinitis pigmentosa, and\ncognitive disorders, usually beginning between 13 and 25 years of age. This is\na rare condition, previously reported in only four families. In contrast,\nheterozygous GRN mutations are a major cause of frontotemporal dementia\nassociated with neuronal cytoplasmic TDP-43 inclusions. We identified\nhomozygous GRN mutations in six new patients. The phenotypic spectrum is much\nbroader than previously reported, with two remarkably distinct presentations,\ndepending on the age of onset. A childhood/juvenile form is characterized by\nclassical CLN11 symptoms at an early age at onset. Unexpectedly, other\nhomozygous patients presented a distinct delayed phenotype of frontotemporal\ndementia and parkinsonism after 50 years; none had epilepsy or cerebellar\nataxia. Another major finding of this study is that all GRN mutations may not\nhave the same impact on progranulin protein synthesis. A hypomorphic effect of\nsome mutations is supported by the presence of residual levels of plasma\nprogranulin and low levels of normal transcript detected in one case with a\nhomozygous splice-site mutation and late onset frontotemporal dementia. This is\na new critical finding that must be considered in therapeutic trials based on\nreplacement strategies. The first neuropathological study in a homozygous\ncarrier provides new insights into the pathological mechanisms of the disease.\nHallmarks of neuronal ceroid lipofuscinosis were present. The absence of TDP-43\ncytoplasmic inclusions markedly differs from observations of heterozygous\nmutations, suggesting a pathological shift between lysosomal and TDP-43\npathologies depending on the mono or bi-allelic status. An intriguing\nobservation was the loss of normal TDP-43 staining in the nucleus of some\nneurons, which could be the first stage of the TDP-43 pathological process\npreceding the formation of typical cytoplasmic inclusions. Finally, this study\nhas important implications for genetic counselling and molecular diagnosis.\nSemi-dominant inheritance of GRN mutations implies that specific genetic\ncounseling should be delivered to children and parents of CLN11 patients, as\nthey are heterozygous carriers with a high risk of developing dementia. More\nbroadly, this study illustrates the fact that genetic variants can lead to\ndifferent phenotypes according to their mono- or bi-allelic state, which is a\nchallenge for genetic diagnosis.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 10:16:03 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Huin", "Vincent", ""], ["Barbier", "Mathieu", ""], ["Bottani", "Armand", ""], ["Lobrinus", "Johannes", ""], ["Clot", "Fabienne", ""], ["Lamari", "Foudil", ""], ["Chat", "Laureen", ""], ["Rucheton", "Beno\u00eet", ""], ["Fluch\u00e8re", "Fr\u00e9d\u00e9rique", ""], ["Auvin", "St\u00e9phane", ""], ["Myers", "Peter", ""], ["Gelot", "Antoinette", ""], ["Camuzat", "Agn\u00e8s", ""], ["Caillaud", "Catherine", ""], ["Jorn\u00e9a", "Ludmila", ""], ["Forlani", "Sylvie", ""], ["Saracino", "Dario", ""], ["Duyckaerts", "Charles", ""], ["Brice", "Alexis", ""], ["Durr", "Alexandra", ""], ["Ber", "Isabelle Le", ""]]}, {"id": "2011.10447", "submitter": "Vincent Huin", "authors": "Vincent Huin (JPArc), Vincent Deramecourt, Dominique\n  Caparros-Lefebvre, Claude-Alain Maurage, Charles Duyckaerts, Eniko Kovari,\n  Florence Pasquier, Val\\'erie Bu\\'ee-Scherrer, Julien Labreuche, H\\'el\\`ene\n  Behal, Luc Bu\\'ee, Claire-Marie Dhaenens, Bernard Sablonni\\`ere", "title": "The MAPT gene is differentially methylated in the progressive\n  supranuclear palsy brain", "comments": null, "journal-ref": "Movement Disorders, Wiley, 2016, 31 (12), pp.1883-1890", "doi": "10.1002/mds.26820", "report-no": null, "categories": "q-bio.GN q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Progressive supranuclear palsy (PSP) is a rare neurodegenerative\ndisease causing parkinsonian symptoms. Altered DNA methylation of the\nmicrotubule-associated protein tau gene correlates with the expression changes\nin Alzheimer's disease and Parkinson's disease brains. However, few studies\nexamine the sequences beyond the constitutive promoter.Objectives: Because\nactivating different microtubule associated protein tau gene control regions\nvia methylation might regulate the differential tau expression constituting the\nspecific signatures of individual tauopathies, we compared methylation of a\ncandidate promoter, intron 0.Methods: We assessed DNA methylation in the brains\nof patients with different tauopathies (35 Alzheimer's disease, 10 corticobasal\ndegeneration, and 18 PSP) and 19 controls by intron 0 pyrosequencing. We also\nevaluated methylation in an independent cohort of 11 PSP cases and 12 controls.\nFrontal (affected by tau pathology) and occipital (unaffected) cortices were\nanalyzed.Results: In the initial samples, one CpG island site in intron 0\n(CpG1) showed significant hypomethylation in PSP-affected frontal cortices when\ncompared with controls (p = 0.022). Such hypomethylation was observed in\nreplicate samples, but not in occipital cortices or other tauopathies. PSP and\ncontrol samples (combining the initial and replicate samples) remained\nsignificantly different after adjustment for potential confounding factors\n(age, H1/H1 diplotype; p = 0.0005). PSP-affected tissues exhibited\nmicrotubule-associated protein tau RNA hyperexpression when compared with\ncontrols (p = 0.004), although no correlation with CpG1 methylation was\nobserved.Conclusions: This exploratory study suggests that regions other than\nthe constitutive promoter may be involved in microtubule-associated protein tau\ngene regulation in tauopathies and that intron 0 hypomethylation may be a\nspecific epigenetic signature of PSP. These preliminary findings require\nconfirmation.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 15:22:09 GMT"}], "update_date": "2020-11-23", "authors_parsed": [["Huin", "Vincent", "", "JPArc"], ["Deramecourt", "Vincent", ""], ["Caparros-Lefebvre", "Dominique", ""], ["Maurage", "Claude-Alain", ""], ["Duyckaerts", "Charles", ""], ["Kovari", "Eniko", ""], ["Pasquier", "Florence", ""], ["Bu\u00e9e-Scherrer", "Val\u00e9rie", ""], ["Labreuche", "Julien", ""], ["Behal", "H\u00e9l\u00e8ne", ""], ["Bu\u00e9e", "Luc", ""], ["Dhaenens", "Claire-Marie", ""], ["Sablonni\u00e8re", "Bernard", ""]]}, {"id": "2011.10854", "submitter": "Lawrence Ward", "authors": "Conor L. Morrison and Priscilla E. Greenwood and Lawrence M. Ward", "title": "Plastic systemic inhibition controls amplitude while allowing phase\n  pattern in a stochastic neural field model", "comments": "Supplementary material available from lward@psych.ubc.ca", "journal-ref": "Phys. Rev. E 103, 032311 (2021)", "doi": "10.1103/PhysRevE.103.032311", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Oscillatory phase pattern formation and amplitude control for a linearized\nstochastic neuron field model was investigated by simulating coupled stochastic\nprocesses defined by stochastic differential equations. It was found, for\nseveral choices of parameters, that pattern formation in the phases of these\nprocesses occurred if and only if the amplitudes were allowed to grow large.\nStimulated by recent work on homeostatic inhibitory plasticity, we introduced\nstatic and plastic (adaptive) systemic inhibitory mechanisms to keep the\namplitudes stochastically bounded in subsequent simulations. The systems with\nstatic systemic inhibition exhibited bounded amplitudes but no sustained phase\npatterns, whereas the systems with plastic systemic inhibition exhibited both\nbounded amplitudes and sustained phase patterns. These results demonstrate that\nplastic inhibitory mechanisms in neural field models can stochastically control\namplitudes while allowing patterns of phase synchronization to develop. Similar\nmechanisms of plastic systemic inhibition could play a role in regulating\noscillatory functioning in the brain.\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2020 19:50:29 GMT"}], "update_date": "2021-03-24", "authors_parsed": [["Morrison", "Conor L.", ""], ["Greenwood", "Priscilla E.", ""], ["Ward", "Lawrence M.", ""]]}, {"id": "2011.10955", "submitter": "Tyler Maltba", "authors": "Tyler E. Maltba (1), Hongli Zhao (1), Daniel M. Tartakovsky (2) ((1)\n  UC Berkeley, (2) Stanford University)", "title": "Autonomous learning of nonlocal stochastic neuron dynamics", "comments": "26 pages, 12 figures, First author: Tyler E. Maltba, Corresponding\n  author: Daniel M. Tartakovsky", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NA math.NA q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal dynamics is driven by externally imposed or internally generated\nrandom excitations/noise, and is often described by systems of stochastic\nordinary differential equations. A solution to these equations is the joint\nprobability density function (PDF) of neuron states. It can be used to\ncalculate such information-theoretic quantities as the mutual information\nbetween the stochastic stimulus and various internal states of the neuron\n(e.g., membrane potential), as well as various spiking statistics. When random\nexcitations are modeled as Gaussian white noise, the joint PDF of neuron states\nsatisfies exactly a Fokker-Planck equation. However, most biologically\nplausible noise sources are correlated (colored). In this case, the resulting\nPDF equations require a closure approximation. We propose two methods for\nclosing such equations: a modified nonlocal large-eddy-diffusivity closure and\na data-driven closure relying on sparse regression to learn relevant features.\nThe closures are tested for stochastic leaky integrate-and-fire (LIF) and\nFitzHugh-Nagumo (FHN) neurons driven by sine-Wiener noise. Mutual information\nand total correlation between the random stimulus and the internal states of\nthe neuron are calculated for the FHN neuron.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 06:47:18 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Maltba", "Tyler E.", ""], ["Zhao", "Hongli", ""], ["Tartakovsky", "Daniel M.", ""]]}, {"id": "2011.11128", "submitter": "Junhua Li", "authors": "Shu Gong, Kaibo Xing, Andrzej Cichocki, Junhua Li", "title": "Deep Learning in EEG: Advance of the Last Ten-Year Critical Period", "comments": "Accepted for publication in the IEEE Transactions on Cognitive and\n  Developmental Systems", "journal-ref": "IEEE Transactions on Cognitive and Developmental Systems, 2021", "doi": "10.1109/TCDS.2021.3079712", "report-no": null, "categories": "eess.SP cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has achieved excellent performance in a wide range of domains,\nespecially in speech recognition and computer vision. Relatively less work has\nbeen done for EEG, but there is still significant progress attained in the last\ndecade. Due to the lack of a comprehensive and topic widely covered survey for\ndeep learning in EEG, we attempt to summarize recent progress to provide an\noverview, as well as perspectives for future developments. We first briefly\nmention the artifacts removal for EEG signal and then introduce deep learning\nmodels that have been utilized in EEG processing and classification.\nSubsequently, the applications of deep learning in EEG are reviewed by\ncategorizing them into groups such as brain-computer interface, disease\ndetection, and emotion recognition. They are followed by the discussion, in\nwhich the pros and cons of deep learning are presented and future directions\nand challenges for deep learning in EEG are proposed. We hope that this paper\ncould serve as a summary of past work for deep learning in EEG and the\nbeginning of further developments and achievements of EEG studies based on deep\nlearning.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 22:34:26 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 17:43:53 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 19:24:56 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Gong", "Shu", ""], ["Xing", "Kaibo", ""], ["Cichocki", "Andrzej", ""], ["Li", "Junhua", ""]]}, {"id": "2011.11335", "submitter": "Sacha van Albada", "authors": "Sacha Jennifer van Albada, Jari Pronold, Alexander van Meegen, Markus\n  Diesmann", "title": "Usage and Scaling of an Open-Source Spiking Multi-Area Model of Monkey\n  Cortex", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We are entering an age of `big' computational neuroscience, in which neural\nnetwork models are increasing in size and in numbers of underlying data sets.\nConsolidating the zoo of models into large-scale models simultaneously\nconsistent with a wide range of data is only possible through the effort of\nlarge teams, which can be spread across multiple research institutions. To\nensure that computational neuroscientists can build on each other's work, it is\nimportant to make models publicly available as well-documented code. This\nchapter describes such an open-source model, which relates the connectivity\nstructure of all vision-related cortical areas of the macaque monkey with their\nresting-state dynamics. We give a brief overview of how to use the executable\nmodel specification, which employs NEST as simulation engine, and show its\nruntime scaling. The solutions found serve as an example for organizing the\nworkflow of future models from the raw experimental data to the visualization\nof the results, expose the challenges, and give guidance for the construction\nof ICT infrastructure for neuroscience.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 11:25:14 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["van Albada", "Sacha Jennifer", ""], ["Pronold", "Jari", ""], ["van Meegen", "Alexander", ""], ["Diesmann", "Markus", ""]]}, {"id": "2011.11400", "submitter": "Feng Qi", "authors": "Feng Qi", "title": "Language guided machine action", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Here we build a hierarchical modular network called Language guided machine\naction (LGMA), whose modules process information stream mimicking human\ncortical network that allows to achieve multiple general tasks such as language\nguided action, intention decomposition and mental simulation before action\nexecution etc. LGMA contains 3 main systems: (1) primary sensory system that\nmultimodal sensory information of vision, language and sensorimotor. (2)\nassociation system involves and Broca modules to comprehend and synthesize\nlanguage, BA14/40 module to translate between sensorimotor and language,\nmidTemporal module to convert between language and vision, and superior\nparietal lobe to integrate attended visual object and arm state into cognitive\nmap for future spatial actions. Pre-supplementary motor area (pre-SMA) can\nconverts high level intention into sequential atomic actions, while SMA can\nintegrate these atomic actions, current arm and attended object state into\nsensorimotor vector to apply corresponding torques on arm via pre-motor and\nprimary motor of arm to achieve the intention. The high-level executive system\ncontains PFC that does explicit inference and guide voluntary action based on\nlanguage, while BG is the habitual action control center.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 13:49:02 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Qi", "Feng", ""]]}, {"id": "2011.11495", "submitter": "Ee Hou Yong", "authors": "Shu Tian Eu and Ee Hou Yong", "title": "Contours information and the perception of various visual illusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The simplicity principle states that the human visual system prefers the\nsimplest interpretation. However, conventional coding models could not resolve\nthe incompatibility between predictions from the global minimum principle and\nthe local minimum principle. By quantitatively evaluating the total information\ncontent of all possible visual interpretations, we show that the perceived\npattern is always the one with the simplest local completion as well as the\nleast total surprisal globally, thus solving this apparent conundrum. Our\nproposed framework consist of (1) the information content of visual contours,\n(2) direction of visual contour, and (3) the von Mises distribution governing\nhuman visual expectation. We used it to explain the perception of prominent\nvisual illusions such as Kanizsa triangle, Ehrenstein cross, and Rubin's vase.\nThis provides new insight into the celebrated simplicity principle and could\nserve as a fundamental explanation of the perception of illusory boundaries and\nthe bi-stability of perceptual grouping.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2020 03:36:06 GMT"}], "update_date": "2020-11-24", "authors_parsed": [["Eu", "Shu Tian", ""], ["Yong", "Ee Hou", ""]]}, {"id": "2011.11710", "submitter": "Mihai Alexandru Petrovici", "authors": "Elena Kreutzer, Walter M. Senn, Mihai A. Petrovici", "title": "Natural-gradient learning for spiking neurons", "comments": "Joint senior authorship: Walter M. Senn and Mihai A. Petrovici", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE math.DG stat.CO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In many normative theories of synaptic plasticity, weight updates implicitly\ndepend on the chosen parametrization of the weights. This problem relates, for\nexample, to neuronal morphology: synapses which are functionally equivalent in\nterms of their impact on somatic firing can differ substantially in spine size\ndue to their different positions along the dendritic tree. Classical theories\nbased on Euclidean gradient descent can easily lead to inconsistencies due to\nsuch parametrization dependence. The issues are solved in the framework of\nRiemannian geometry, in which we propose that plasticity instead follows\nnatural gradient descent. Under this hypothesis, we derive a synaptic learning\nrule for spiking neurons that couples functional efficiency with the\nexplanation of several well-documented biological phenomena such as dendritic\ndemocracy, multiplicative scaling and heterosynaptic plasticity. We therefore\nsuggest that in its search for functional synaptic plasticity, evolution might\nhave come up with its own version of natural gradient descent.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2020 20:26:37 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Kreutzer", "Elena", ""], ["Senn", "Walter M.", ""], ["Petrovici", "Mihai A.", ""]]}, {"id": "2011.12012", "submitter": "Shashi Kant Gupta", "authors": "Shashi Kant Gupta", "title": "A More Biologically Plausible Local Learning Rule for ANNs", "comments": "8 pages (4 main + 1 reference + 3 supplementary)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The backpropagation algorithm is often debated for its biological\nplausibility. However, various learning methods for neural architecture have\nbeen proposed in search of more biologically plausible learning. Most of them\nhave tried to solve the \"weight transport problem\" and try to propagate errors\nbackward in the architecture via some alternative methods. In this work, we\ninvestigated a slightly different approach that uses only the local information\nwhich captures spike timing information with no propagation of errors. The\nproposed learning rule is derived from the concepts of spike timing dependant\nplasticity and neuronal association. A preliminary evaluation done on the\nbinary classification of MNIST and IRIS datasets with two hidden layers shows\ncomparable performance with backpropagation. The model learned using this\nmethod also shows a possibility of better adversarial robustness against the\nFGSM attack compared to the model learned through backpropagation of\ncross-entropy loss. The local nature of learning gives a possibility of large\nscale distributed and parallel learning in the network. And finally, the\nproposed method is a more biologically sound method that can probably help in\nunderstanding how biological neurons learn different abstractions.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 10:35:47 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Gupta", "Shashi Kant", ""]]}, {"id": "2011.12050", "submitter": "Alessandro Sarracino", "authors": "Dario Raimo, Alessandro Sarracino, Lucilla de Arcangelis", "title": "Role of inhibitory neurons in temporal correlations of critical and\n  supercritical spontaneous activity", "comments": "15 pages, 6 figures", "journal-ref": "Physica A, 125555 (2020)", "doi": "10.1016/j.physa.2020.125555", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental and numerical results suggest that the brain can be viewed as a\nsystem acting close to a critical point, as confirmed by scale-free\ndistributions of relevant quantities in a variety of different systems and\nmodels. Less attention has received the investigation of the temporal\ncorrelation functions in brain activity in different, healthy and pathological,\nconditions. Here we perform this analysis by means of a model with short and\nlong-term plasticity which implements the novel feature of different recovery\nrates for excitatory and inhibitory neurons, found experimentally. We evidence\nthe important role played by inhibitory neurons in the supercritical state: We\ndetect an unexpected oscillatory behaviour of the correlation decay, whose\nfrequency depends on the fraction of inhibitory neurons and their connectivity\ndegree. This behaviour can be rationalized by the observation that bursts in\nactivity become more frequent and with a smaller amplitude as inhibition\nbecomes more relevant.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 11:58:06 GMT"}], "update_date": "2020-11-25", "authors_parsed": [["Raimo", "Dario", ""], ["Sarracino", "Alessandro", ""], ["de Arcangelis", "Lucilla", ""]]}, {"id": "2011.12067", "submitter": "Saeed Aljaberi", "authors": "Saeed Aljaberi, Timothy O'Leary, Fulvio Forni", "title": "Dendritic trafficking: synaptic scaling and structural plasticity", "comments": "Accepted to the European Control Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal circuits internally regulate electrical signaling via a host of\nhomeostatic mechanisms. Two prominent mechanisms, synaptic scaling and\nstructural plasticity, are believed to maintain average activity within an\noperating range by modifying the strength and spatial extent of network\nconnectivity using negative feedback. However, both mechanisms operate on\nrelatively slow timescales and thus face fundamental limits due to delays. We\nshow that these mechanisms fulfill complementary roles in maintaining stability\nin a large network. In particular, even relatively, slow growth dynamics\nimproves performance significantly beyond synaptic scaling alone.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2020 12:46:45 GMT"}, {"version": "v2", "created": "Tue, 6 Apr 2021 16:47:26 GMT"}], "update_date": "2021-04-07", "authors_parsed": [["Aljaberi", "Saeed", ""], ["O'Leary", "Timothy", ""], ["Forni", "Fulvio", ""]]}, {"id": "2011.12676", "submitter": "Mohammadreza Edalati", "authors": "Mohammadreza Edalati, Mahdi Mahmoudzadeh, Javad Safaie, Fabrice\n  Wallois, Sahar Moghimi", "title": "Great expectations in music: violation of rhythmic expectancies elicits\n  late frontal gamma activity nested in theta oscillations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rhythm processing involves building expectations according to the\nhierarchical temporal structure of auditory events. Although rhythm processing\nhas been addressed in the context of predictive coding, the properties of the\noscillatory response in different cortical areas is still not clear. We\nexplored the oscillatory properties of the neural response to rhythmic\nincongruence and explored the cross-frequency coupling between multiple\nfrequencies to provide links between the concepts of predictive coding and\nrhythm perception. We designed an experiment to investigate the neural response\nto rhythmic deviations in which the tone either arrived earlier than expected\nor the tone in the same metrical position was omitted. These two manipulations\nmodulate the rhythmic structure differently, with the former creating a larger\nviolation of the general structure of the musical stimulus than the latter.\nBoth deviations resulted in an MMN response, whereas only the rhythmic deviant\nresulted in a subsequent P3a. Rhythmic deviants due to the early occurrence of\na tone, but not omission deviants, elicited a late high gamma response (60-80\nHz) at the end of the P3a over the left frontal region, which, interestingly,\ncorrelated with the P3a amplitude over the same region and was also nested in\ntheta oscillations. The timing of the elicited high-frequency gamma\noscillations related to rhythmic deviation suggests that it might be related to\nthe update of the predictive neural model, corresponding to the temporal\nstructure of the events in higher-level cortical areas.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 12:11:40 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Edalati", "Mohammadreza", ""], ["Mahmoudzadeh", "Mahdi", ""], ["Safaie", "Javad", ""], ["Wallois", "Fabrice", ""], ["Moghimi", "Sahar", ""]]}, {"id": "2011.12789", "submitter": "Alain Louilot", "authors": "Hana Saoud, Duco De Beus, Severine Eybrard and Alain Louilot", "title": "Postnatal functional inactivation of the ventral subiculum enhances\n  dopaminergic responses in the core part of the nucleus accumbens following\n  ketamine injection in adult rats", "comments": null, "journal-ref": null, "doi": "10.1101/859322", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For almost two decades schizophrenia has been considered to be a functional\ndisconnection disorder. This functional disconnectivity between several brain\nregions could have a neurodevelopmental origin. Various approaches suggest the\nventral subiculum (SUB) is a particular target region for neurodevelopemental\ndisturbances in schizophrenia. It is also commonly acknowledged that there is a\nstriatal dopaminergic (DA) dysregulation in schizophrenia which may depend on a\nsubiculo-striatal disconnection involving glutamatergic NMDA receptors. The\npresent study was designed to investigate, in adult rats, the effects of the\nnon-competitive NMDA receptor antagonist ketamine on DA responses in the\nventral striatum, or, more specifically, the core part of the nucleus accumbens\n(Nacc), following postnatal functional inactivation of the SUB. Functional\ninactivation of the left SUB was carried out by local tetrodotoxin (TTX)\nmicroinjection at postnatal day 8 (PND8), i.e. at a critical point in the\nneurodevelopmental period. DA variations were recorded using in vivo\nvoltammetry in freely moving adult rats (11 weeks). Locomotor activity was\nrecorded simultaneously with the extracellular levels of DA in the core part of\nthe Nacc. Data obtained during the present study showed that after\nadministration of ketamine, the two indexes were higher in TTX animals than PBS\nanimals, the suggestion being that animals microinjected with TTX in the left\nSUB at PND8 present greater reactivity to ketamine than animals microinjected\nwith PBS. These findings could provide new information regarding the\ninvolvement of NMDA glutamatergic receptors in the core part of the Nacc in the\npathophysiology of schizophrenia.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2020 18:57:09 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Saoud", "Hana", ""], ["De Beus", "Duco", ""], ["Eybrard", "Severine", ""], ["Louilot", "Alain", ""]]}, {"id": "2011.12826", "submitter": "Takahiro Wada", "authors": "Takahiro Wada", "title": "Computational Model of Motion Sickness Describing the Effects of\n  Learning Exogenous Motion Dynamics", "comments": "Author manuscript, provisionally accepted for publication, in\n  Frontiers in Systems Neuroscience", "journal-ref": null, "doi": "10.3389/fnsys.2021.634604", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing computational models used to estimate motion sickness are\nincapable of describing the fact that the predictability of motion patterns\naffects motion sickness. Therefore, the present study proposes a computational\nmodel to describe the effect of the predictability of dynamics or the pattern\nof motion stimuli on motion sickness. In the proposed model, a submodel, in\nwhich a recursive Gaussian process regression is used to represent human\nfeatures of online learning and future prediction of motion dynamics, is\ncombined with a conventional model of motion sickness based on an observer\ntheory. A simulation experiment was conducted in which the proposed model\npredicted motion sickness caused by a 900 s horizontal movement. The movement\nwas composed of a 9 m repetitive back-and-forth movement pattern with a pause.\nRegarding the motion condition, the direction and timing of the motion were\nvaried as follows: a) Predictable motion (M_P): the direction of the motion and\nduration of the pause were set to 8 s; b) Motion with unpredicted direction\n(M_dU): the pause duration was fixed as in (P), but the motion direction was\nrandomly determined; c) Motion with unpredicted timing (M_tU): the motion\ndirection was fixed as in (M_P), but the pause duration was randomly selected\nfrom 4 to 12 s. The results obtained using the proposed model demonstrated that\nthe predicted motion sickness incidence for (M_P) was smaller than those for\n(M_dU) and (M_tU). This tendency agrees with the sickness patterns observed in\na previous experimental study in which the human participants were subject to\nmotion conditions similar to those used in our simulations. Moreover, no\nsignificant differences were found in the predicted motion sickness incidences\nat different conditions when the conventional model was used.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:29:51 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2021 09:29:59 GMT"}, {"version": "v3", "created": "Fri, 15 Jan 2021 11:51:17 GMT"}], "update_date": "2021-01-18", "authors_parsed": [["Wada", "Takahiro", ""]]}, {"id": "2011.12832", "submitter": "Ailar Mahdizadeh", "authors": "Emad Arasteh Emamzadeh-Hashemi, Ailar Mahdizadeh", "title": "External Electromagnetic Wave Excitation of a PreSynaptic Neuron Based\n  on LIF model", "comments": "5pages,4figures,etech2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction of electromagnetic (EM) waves with human tissue has been a\nlongstanding research topic for electrical and biomedical engineers. However,\nfew numbers of publications discuss the impacts of external EM-waves on neural\nstimulation and communication through the nervous system. In fact, complex\nbiological neural channels are a main barrier for intact and comprehensive\nanalyses in this area. One of the everpresent challenges in neural\ncommunication responses is dependency of vesicle release probability on the\ninput spiking pattern. In this regard, this study sheds light on consequences\nof changing the frequency of external EM-wave excitation on the post-synaptic\nneuron's spiking rate. It is assumed that the penetration depth of the wave in\nbrain does not cover the postsynaptic neuron. Consequently, we model\nneurotransmission of a bipartite chemical synapse. In addition, the way that\nexternal stimulation affects neurotransmission is examined. Unlike multiple\nfrequency component EM-waves, the monochromatic incident wave does not face\nfrequency shift and distortion in dispersive media. In this manner, a single\nfrequency signal is added as external current in the modified leaky\nintegrated-andfire (LIF) model. The results demonstrate existence of a node\nequilibrium point in the first order dynamical system of LIF model. A fold\nbifurcation (for presupposed LIF model values) occurs when the external\nexcitation frequency is near 200 Hz. The outcomes provided in this paper enable\nus to select proper frequency excitation for neural signaling. Correspondingly,\nthe cut-off frequency reliance on elements' values in LIF circuit is found.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 15:40:38 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Emamzadeh-Hashemi", "Emad Arasteh", ""], ["Mahdizadeh", "Ailar", ""]]}, {"id": "2011.12859", "submitter": "Elena Sizikova", "authors": "Omkar Kumbhar, Elena Sizikova, Najib Majaj, Denis G. Pelli", "title": "Anytime Prediction as a Model of Human Reaction Time", "comments": "7 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks today often recognize objects as well as people do, and thus\nmight serve as models of the human recognition process. However, most such\nnetworks provide their answer after a fixed computational effort, whereas human\nreaction time varies, e.g. from 0.2 to 10 s, depending on the properties of\nstimulus and task. To model the effect of difficulty on human reaction time, we\nconsidered a classification network that uses early-exit classifiers to make\nanytime predictions. Comparing human and MSDNet accuracy in classifying\nCIFAR-10 images in added Gaussian noise, we find that the network equivalent\ninput noise SD is 15 times higher than human, and that human efficiency is only\n0.6\\% that of the network. When appropriate amounts of noise are present to\nbring the two observers (human and network) into the same accuracy range, they\nshow very similar dependence on duration or FLOPS, i.e. very similar\nspeed-accuracy tradeoff. We conclude that Anytime classification (i.e. early\nexits) is a promising model for human reaction time in recognition tasks.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 16:30:52 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Kumbhar", "Omkar", ""], ["Sizikova", "Elena", ""], ["Majaj", "Najib", ""], ["Pelli", "Denis G.", ""]]}, {"id": "2011.12865", "submitter": "Christian Schiffer", "authors": "Christian Schiffer, Katrin Amunts, Stefan Harmeling, Timo Dickscheid", "title": "Contrastive Representation Learning for Whole Brain Cytoarchitectonic\n  Mapping in Histological Human Brain Sections", "comments": "Accepted to ISBI 2021", "journal-ref": null, "doi": "10.1109/ISBI48211.2021.9433986", "report-no": null, "categories": "eess.IV cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cytoarchitectonic maps provide microstructural reference parcellations of the\nbrain, describing its organization in terms of the spatial arrangement of\nneuronal cell bodies as measured from histological tissue sections. Recent work\nprovided the first automatic segmentations of cytoarchitectonic areas in the\nvisual system using Convolutional Neural Networks. We aim to extend this\napproach to become applicable to a wider range of brain areas, envisioning a\nsolution for mapping the complete human brain. Inspired by recent success in\nimage classification, we propose a contrastive learning objective for encoding\nmicroscopic image patches into robust microstructural features, which are\nefficient for cytoarchitectonic area classification. We show that a model\npre-trained using this learning task outperforms a model trained from scratch,\nas well as a model pre-trained on a recently proposed auxiliary task. We\nperform cluster analysis in the feature space to show that the learned\nrepresentations form anatomically meaningful groups.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 16:44:23 GMT"}, {"version": "v2", "created": "Thu, 28 Jan 2021 10:17:01 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Schiffer", "Christian", ""], ["Amunts", "Katrin", ""], ["Harmeling", "Stefan", ""], ["Dickscheid", "Timo", ""]]}, {"id": "2011.13024", "submitter": "Elisa Castagnola Dr.", "authors": "Elisa Castagnola, Sanitta Thongpang, Mieko Hirabayashi, Giorgio Nava,\n  Surabhi Nimbalkar, Tri Nguyen, Sandra Lara, Alexis Oyawale, James Bunnell,\n  Chet Moritz, Sam Kassegne", "title": "Glassy Carbon Microelectrode Arrays Enable Voltage-Peak Separated\n  Simultaneous Detection of Dopamine and Serotonin Using Fast Scan Cyclic\n  Voltammetry", "comments": null, "journal-ref": null, "doi": "10.1039/D1AN00425E", "report-no": null, "categories": "q-bio.BM q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Progress in real-time, simultaneous in vivo detection of multiple\nneurotransmitters will help accelerate advances in neuroscience research. The\nneed for development of probes capable of stable electrochemical detection of\nrapid neurotransmitter fluctuations with high sensitivity and selectivity and\nsub-second temporal resolution has, therefore, become compelling. Additionally,\na higher spatial resolution multi-channel capability is required to capture the\ncomplex neurotransmission dynamics across different brain regions. These\nresearch needs have inspired the introduction of glassy carbon (GC)\nmicroelectrode arrays on flexible polymer substrates through carbon MEMS\n(C-MEMS) microfabrication process followed by a novel pattern transfer\ntechnique. These implantable GC microelectrodes offer unique advantages in\nelectrochemical detection of electroactive neurotransmitters through the\npresence of active carboxyl, carbonyl, and hydroxyl functional groups. In\naddition, they offer fast electron transfer kinetics, capacitive\nelectrochemical behavior, and wide electrochemical window. Here, we combine the\nuse of these GC microelectrodes with the fast scan cyclic voltammetry (FSCV)\ntechnique to optimize the co-detection of dopamine and serotonin in vitro and\nin vivo. We demonstrate that using optimized FSCV triangular waveform at scan\nrates lower than 700 V/s and holding and switching at potentials of 0.4 and 1V\nrespectively, it is possible to discriminate voltage reduction and oxidation\npeaks of serotonin and dopamine, with serotonin contributing distinct multiple\noxidation peaks. Taken together, our results present a compelling case for a\ncarbon-based MEA platform rich with active functional groups that allows for\nrepeatable and stable detection of electroactive multiple neurotransmitters at\nconcentrations as low as 10 nM\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2020 21:17:01 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Castagnola", "Elisa", ""], ["Thongpang", "Sanitta", ""], ["Hirabayashi", "Mieko", ""], ["Nava", "Giorgio", ""], ["Nimbalkar", "Surabhi", ""], ["Nguyen", "Tri", ""], ["Lara", "Sandra", ""], ["Oyawale", "Alexis", ""], ["Bunnell", "James", ""], ["Moritz", "Chet", ""], ["Kassegne", "Sam", ""]]}, {"id": "2011.13506", "submitter": "Jesus M Cortes", "authors": "Izaro Fernandez-Iriondo, Antonio Jimenez-Marin, Ibai Diez, Paolo\n  Bonifazi, Stephan P. Swinnen, Miguel A. Mu\\~noz and Jesus M. Cortes", "title": "Small variation in dynamic functional connectivity in cerebellar\n  networks", "comments": "19 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain networks can be defined and explored through their connectivity. Here,\nwe analyzed the relationship between structural connectivity (SC) across 2,514\nregions that cover the entire brain and brainstem, and their dynamic functional\nconnectivity (DFC). To do so, we focused on a combination of two metrics: the\nfirst assesses the degree of SC-DFC similarity and the second is the intrinsic\nvariability of the DFC networks over time. Overall, we found that cerebellar\nnetworks have a smaller DFC variability than other networks in the brain.\nMoreover, the internal structure of the cerebellum could be clearly divided in\ntwo distinct posterior and anterior parts, the latter also connected to the\nbrainstem. The mechanism to maintain small variability of the DFC in the\nposterior part of the cerebellum is consistent with another of our findings,\nnamely, that this structure exhibits the highest SC-DFC similarity relative to\nthe other networks studied. By contrast, the anterior part of the cerebellum\nalso exhibits small DFC variability but it has the lowest SC-DFC similarity,\nsuggesting a different mechanism is at play. Because this structure connects to\nthe brainstem, which regulates sleep cycles, cardiac and respiratory\nfunctioning, we suggest that such critical functionality drives the low\nvariability in the DFC. Overall, the low variability detected in DFC expands\nour current knowledge of cerebellar networks, which are extremely rich and\ncomplex, participating in a wide range of cognitive functions, from movement\ncontrol and coordination to executive function or emotional regulation.\nMoreover, the association between such low variability and structure suggests\nthat differentiated computational principles can be applied in the cerebellum\nas opposed to other structures, such as the cerebral cortex.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 00:39:42 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Fernandez-Iriondo", "Izaro", ""], ["Jimenez-Marin", "Antonio", ""], ["Diez", "Ibai", ""], ["Bonifazi", "Paolo", ""], ["Swinnen", "Stephan P.", ""], ["Mu\u00f1oz", "Miguel A.", ""], ["Cortes", "Jesus M.", ""]]}, {"id": "2011.13533", "submitter": "Arnd Pralle", "authors": "Weixiang Jin, Michael Zucker and Arnd Pralle", "title": "Membrane Nanodomains Homeostasis During Propofol Anesthesia as Function\n  of Dosage and Temperature", "comments": null, "journal-ref": null, "doi": "10.1016/j.bbamem.2020.183511", "report-no": null, "categories": "q-bio.CB q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Some anesthetics bind and potentiate gamma-aminobutyric-acid-type receptors,\nbut no universal mechanism for general anesthesia is known. Furthermore, often\nencountered complications such as anesthesia induced amnesia are not\nunderstood. General anesthetics are hydrophobic molecules easily dissolving\ninto lipid bilayers. Recently, it was shown that general anesthetics perturb\nphase separation in vesicles extracted from fixed cells. Unclear is whether\nunder physiological conditions general anesthetics induce perturbation of the\nlipid bilayer, and whether this contributes to the transient loss of\nconsciousness or anesthesia side effects. Here we show that propofol perturbs\nlipid nanodomains in the outer and inner leaflet of the plasma membrane in\nintact cells, affecting membrane nanodomains in a concentration dependent\nmanner: 1 {\\mu}M to 5 {\\mu}M propofol destabilize nanodomains; however,\npropofol concentrations higher than 5 {\\mu}M stabilize nanodomains with time.\nStabilization occurs only at physiological temperature and in intact cells.\nThis process requires ARP2/3 mediated actin nucleation and Myosin II activity.\nThe rate of nanodomain stabilization is potentiated by GABA receptor activity.\nOur results show that active nanodomain homeostasis counteracts the initial\ndisruption causing large changes in cortical actin.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 03:05:54 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Jin", "Weixiang", ""], ["Zucker", "Michael", ""], ["Pralle", "Arnd", ""]]}, {"id": "2011.13778", "submitter": "Geza Odor", "authors": "G\\'eza \\'Odor and Beatriz de Simoni", "title": "Heterogeneous excitable systems exhibit Griffiths phases below hybrid\n  phase transitions", "comments": "10 pages 11 figures, accepted version to appear in Phys. Rev.\n  Research", "journal-ref": "Phys. Rev. Research 3, 013106 (2021)", "doi": "10.1103/PhysRevResearch.3.013106", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In $d > 2$ dimensional, homogeneous threshold models discontinuous transition\noccur, but the mean-field solution provides $1/t$ power-law activity decay and\nother power-laws, thus it is called mixed-order or hybrid type. It has recently\nbeen shown that the introduction of quenched disorder rounds the discontinuity\nand second order phase transition and Griffiths phases appear. Here we provide\nnumerical evidence, that even in case of high graph dimensional hierarchical\nmodular networks the Griffiths phase of the $K=2$ threshold model is present\nbelow the hybrid phase transition. This is due to the fragmentation of the\nactivity propagation by modules, which are connected via single links. This\nprovides a widespread mechanism in case of threshold type of heterogeneous\nsystems, modeling the brain or epidemics for the occurrence of dynamical\ncriticality in extended Griffiths phase parameter spaces. We investigate this\nin synthetic modular networks with and without inhibitory links as well as in\nthe presence of refractory states.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2020 15:26:12 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2021 19:56:27 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["\u00d3dor", "G\u00e9za", ""], ["de Simoni", "Beatriz", ""]]}, {"id": "2011.14731", "submitter": "Caglar Cakan", "authors": "Caglar Cakan, Cristiana Dimulescu, Liliia Khakimova, Daniela Obst,\n  Agnes Fl\\\"oel, Klaus Obermayer", "title": "Criticality and the role of the connectome in shaping slow oscillations\n  in the brain during deep sleep", "comments": "For the simulations, the whole-brain neural mass modeling framework\n  neurolib (https://github.com/neurolib-dev/neurolib) was used. Code for\n  reproducing all figures can be found at\n  https://github.com/caglarcakan/sleeping_brain", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  During slow-wave sleep, the brain is in a self-organized regime in which slow\noscillations (SOs) between up- and down-states propagate across the cortex. We\naddress the mechanism of how SOs emerge and can recruit large parts of the\nbrain using a whole-brain model based on empirical connectivity data.\nIndividual brain areas generate SOs that are induced by a local adaptation\nmechanism. Optimal fits to human resting-state fMRI data and EEG during deep\nsleep are found at critical values of the adaptation strength where the model\nproduces a balance between local and global SOs with realistic spatiotemporal\nstatistics. Local oscillations are more frequent, last shorter, and have a\nlower amplitude. Global oscillations spread as waves of silence across the\nbrain, traveling from anterior to posterior regions due to the heterogeneous\nnetwork structure of the human brain. Our results demonstrate the utility of\nwhole-brain models for explaining the origin of large-scale cortical\noscillations and how they are shaped by the connectome.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 12:18:12 GMT"}, {"version": "v2", "created": "Thu, 3 Dec 2020 16:42:34 GMT"}, {"version": "v3", "created": "Mon, 22 Mar 2021 09:13:58 GMT"}], "update_date": "2021-03-23", "authors_parsed": [["Cakan", "Caglar", ""], ["Dimulescu", "Cristiana", ""], ["Khakimova", "Liliia", ""], ["Obst", "Daniela", ""], ["Fl\u00f6el", "Agnes", ""], ["Obermayer", "Klaus", ""]]}, {"id": "2011.14990", "submitter": "Vivek Gopalakrishnan", "authors": "Vivek Gopalakrishnan, Jaewon Chung, Eric Bridgeford, Benjamin D.\n  Pedigo, Jes\\'us Arroyo, Lucy Upchurch, G. Allan Johnson, Nian Wang, Youngser\n  Park, Carey E. Priebe, Joshua T. Vogelstein", "title": "Multiscale Comparative Connectomics", "comments": "29 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ME", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A connectome is a map of the structural and/or functional connections in the\nbrain. This information-rich representation has the potential to transform our\nunderstanding of the relationship between patterns in brain connectivity and\nneurological processes, disorders, and diseases. However, existing\ncomputational techniques used to analyze connectomes are often insufficient for\ninterrogating multi-subject connectomics datasets. Several methods are either\nsolely designed to analyze single connectomes, or leverage heuristic graph\ninvariants that ignore the complete topology of connections between brain\nregions. To enable more rigorous comparative connectomics analysis, we\nintroduce robust and interpretable statistical methods motivated by recent\ntheoretical advances in random graph models. These methods enable simultaneous\nanalysis of multiple connectomes across different scales of network topology,\nfacilitating the discovery of hierarchical brain structures that vary in\nrelation with phenotypic profiles. We validated these methods through extensive\nsimulation studies, as well as synthetic and real-data experiments. Using a set\nof high-resolution connectomes obtained from genetically distinct mouse strains\n(including the BTBR mouse -- a standard model of autism -- and three behavioral\nwild-types), we show that these methods uncover valuable latent information in\nmulti-subject connectomics data and yield novel insights into the connective\ncorrelates of neurological phenotypes.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 16:58:25 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2020 20:31:55 GMT"}, {"version": "v3", "created": "Wed, 20 Jan 2021 06:24:43 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Gopalakrishnan", "Vivek", ""], ["Chung", "Jaewon", ""], ["Bridgeford", "Eric", ""], ["Pedigo", "Benjamin D.", ""], ["Arroyo", "Jes\u00fas", ""], ["Upchurch", "Lucy", ""], ["Johnson", "G. Allan", ""], ["Wang", "Nian", ""], ["Park", "Youngser", ""], ["Priebe", "Carey E.", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "2011.15031", "submitter": "Siavash Golkar", "authors": "Siavash Golkar, David Lipshutz, Yanis Bahroun, Anirvan M. Sengupta,\n  Dmitri B. Chklovskii", "title": "A biologically plausible neural network for local supervision in\n  cortical microcircuits", "comments": "Abstract presented at the NeurIPS 2020 workshop \"Beyond\n  Backpropagation\". arXiv admin note: text overlap with arXiv:2010.12660", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The backpropagation algorithm is an invaluable tool for training artificial\nneural networks; however, because of a weight sharing requirement, it does not\nprovide a plausible model of brain function. Here, in the context of a\ntwo-layer network, we derive an algorithm for training a neural network which\navoids this problem by not requiring explicit error computation and\nbackpropagation. Furthermore, our algorithm maps onto a neural network that\nbears a remarkable resemblance to the connectivity structure and learning rules\nof the cortex. We find that our algorithm empirically performs comparably to\nbackprop on a number of datasets.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2020 17:35:22 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Golkar", "Siavash", ""], ["Lipshutz", "David", ""], ["Bahroun", "Yanis", ""], ["Sengupta", "Anirvan M.", ""], ["Chklovskii", "Dmitri B.", ""]]}]