[{"id": "1210.0564", "submitter": "Tao Hu", "authors": "Tao Hu, Juan Nunez-Iglesias, Shiv Vitaladevuni, Lou Scheffer, Shan Xu,\n  Mehdi Bolorizadeh, Harald Hess, Richard Fetter and Dmitri Chklovskii", "title": "Super-resolution using Sparse Representations over Learned Dictionaries:\n  Reconstruction of Brain Structure using Electron Microscopy", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem in neuroscience is reconstructing neuronal circuits on the\nsynapse level. Due to a wide range of scales in brain architecture such\nreconstruction requires imaging that is both high-resolution and\nhigh-throughput. Existing electron microscopy (EM) techniques possess required\nresolution in the lateral plane and either high-throughput or high depth\nresolution but not both. Here, we exploit recent advances in unsupervised\nlearning and signal processing to obtain high depth-resolution EM images\ncomputationally without sacrificing throughput. First, we show that the brain\ntissue can be represented as a sparse linear combination of localized basis\nfunctions that are learned using high-resolution datasets. We then develop\ncompressive sensing-inspired techniques that can reconstruct the brain tissue\nfrom very few (typically 5) tomographic views of each section. This enables\ntracing of neuronal processes and, hence, high throughput reconstruction of\nneural circuits on the level of individual synapses.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 20:30:36 GMT"}], "update_date": "2012-10-03", "authors_parsed": [["Hu", "Tao", ""], ["Nunez-Iglesias", "Juan", ""], ["Vitaladevuni", "Shiv", ""], ["Scheffer", "Lou", ""], ["Xu", "Shan", ""], ["Bolorizadeh", "Mehdi", ""], ["Hess", "Harald", ""], ["Fetter", "Richard", ""], ["Chklovskii", "Dmitri", ""]]}, {"id": "1210.0754", "submitter": "Tony Lindeberg", "authors": "Tony Lindeberg", "title": "Invariance of visual operations at the level of receptive fields", "comments": "40 pages, 17 figures", "journal-ref": "PLoS ONE 8(7):e66990, 2013", "doi": "10.1371/journal.pone.0066990", "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Receptive field profiles registered by cell recordings have shown that\nmammalian vision has developed receptive fields tuned to different sizes and\norientations in the image domain as well as to different image velocities in\nspace-time. This article presents a theoretical model by which families of\nidealized receptive field profiles can be derived mathematically from a small\nset of basic assumptions that correspond to structural properties of the\nenvironment. The article also presents a theory for how basic invariance\nproperties to variations in scale, viewing direction and relative motion can be\nobtained from the output of such receptive fields, using complementary\nselection mechanisms that operate over the output of families of receptive\nfields tuned to different parameters. Thereby, the theory shows how basic\ninvariance properties of a visual system can be obtained already at the level\nof receptive fields, and we can explain the different shapes of receptive field\nprofiles found in biological vision from a requirement that the visual system\nshould be invariant to the natural types of image transformations that occur in\nits environment.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 12:43:18 GMT"}], "update_date": "2014-04-09", "authors_parsed": [["Lindeberg", "Tony", ""]]}, {"id": "1210.1530", "submitter": "Tao Hu", "authors": "Tao Hu, Alexander Genkin and Dmitri B. Chklovskii", "title": "A network of spiking neurons for computing sparse representations in an\n  energy efficient way", "comments": "5 figures Early Access:\n  http://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00353", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing sparse redundant representations is an important problem both in\napplied mathematics and neuroscience. In many applications, this problem must\nbe solved in an energy efficient way. Here, we propose a hybrid distributed\nalgorithm (HDA), which solves this problem on a network of simple nodes\ncommunicating via low-bandwidth channels. HDA nodes perform both\ngradient-descent-like steps on analog internal variables and\ncoordinate-descent-like steps via quantized external variables communicated to\neach other. Interestingly, such operation is equivalent to a network of\nintegrate-and-fire neurons, suggesting that HDA may serve as a model of neural\ncomputation. We show that the numerical performance of HDA is on par with\nexisting algorithms. In the asymptotic regime the representation error of HDA\ndecays with time, t, as 1/t. HDA is stable against time-varying noise,\nspecifically, the representation error decays as 1/sqrt(t) for Gaussian white\nnoise.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 18:26:03 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Hu", "Tao", ""], ["Genkin", "Alexander", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1210.1544", "submitter": "Tao Hu", "authors": "Tao Hu and Dmitri B. Chklovskii", "title": "Reconstruction of Sparse Circuits Using Multi-neuronal Excitation\n  (RESCUME)", "comments": "9 pages, 6 figures. Advances in Neural Information Processing Systems\n  (NIPS) 22, 790 (2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the central problems in neuroscience is reconstructing synaptic\nconnectivity in neural circuits. Synapses onto a neuron can be probed by\nsequentially stimulating potentially pre-synaptic neurons while monitoring the\nmembrane voltage of the post-synaptic neuron. Reconstructing a large neural\ncircuit using such a \"brute force\" approach is rather time-consuming and\ninefficient because the connectivity in neural circuits is sparse. Instead, we\npropose to measure a post-synaptic neuron's voltage while stimulating\nsequentially random subsets of multiple potentially pre-synaptic neurons. To\nreconstruct these synaptic connections from the recorded voltage we apply a\ndecoding algorithm recently developed for compressive sensing. Compared to the\nbrute force approach, our method promises significant time savings that grow\nwith the size of the circuit. We use computer simulations to find optimal\nstimulation parameters and explore the feasibility of our reconstruction method\nunder realistic experimental conditions including noise and non-linear synaptic\nintegration. Multineuronal stimulation allows reconstructing synaptic\nconnectivity just from the spiking activity of post-synaptic neurons, even when\nsub-threshold voltage is unavailable. By using calcium indicators,\nvoltage-sensitive dyes, or multi-electrode arrays one could monitor activity of\nmultiple postsynaptic neurons simultaneously, thus mapping their synaptic\ninputs in parallel, potentially reconstructing a complete neural circuit.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 19:03:19 GMT"}], "update_date": "2012-10-05", "authors_parsed": [["Hu", "Tao", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1210.1983", "submitter": "Dorian Aur", "authors": "Dorian Aur", "title": "Reply to Comments on Neuroelectrodynamics: Where are the Real Conceptual\n  Pitfalls?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE nlin.AO physics.bio-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The fundamental, powerful process of computation in the brain has been widely\nmisunderstood. The paper [1] associates the general failure to build\nintelligent thinking machines with current reductionist principles of temporal\ncoding and advocates for a change in paradigm regarding the brain analogy.\nSince fragments of information are stored in proteins which can shift between\nseveral structures to perform their function, the biological substrate is\nactively involved in physical computation. The intrinsic nonlinear dynamics of\naction potentials and synaptic activities maintain physical interactions within\nand between neurons in the brain. During these events the required information\nis exchanged between molecular structures (proteins) which store fragments of\ninformation and the generated electric flux which carries and integrates\ninformation in the brain. The entire process of physical interaction explains\nhow the brain actively creates or experiences meaning. This process of\ninteraction during an action potential generation can be simply seen as the\nmoment when the neuron solves a many-body problem. A neuroelectrodynamic theory\nshows that the neuron solves equations rather than exclusively computes\nfunctions. With the main focus on temporal patterns, the spike timing dogma\n(STD) has neglected important forms of computation which do occur inside\nneurons. In addition, artificial neural models have missed the most important\npart since the real super-computing power of the brain has its origins in\ncomputations that occur within neurons.\n", "versions": [{"version": "v1", "created": "Sat, 6 Oct 2012 18:19:11 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Aur", "Dorian", ""]]}, {"id": "1210.2104", "submitter": "Rodrigo Laje", "authors": "Rodrigo Laje and Dean V. Buonomano", "title": "Complexity without chaos: Plasticity within random recurrent networks\n  generates robust timing and motor control", "comments": null, "journal-ref": "Nat. Neurosci. 16 (2013) 925-933", "doi": "10.1038/nn.3405", "report-no": null, "categories": "nlin.CD cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely accepted that the complex dynamics characteristic of recurrent\nneural circuits contributes in a fundamental manner to brain function. Progress\nhas been slow in understanding and exploiting the computational power of\nrecurrent dynamics for two main reasons: nonlinear recurrent networks often\nexhibit chaotic behavior and most known learning rules do not work in robust\nfashion in recurrent networks. Here we address both these problems by\ndemonstrating how random recurrent networks (RRN) that initially exhibit\nchaotic dynamics can be tuned through a supervised learning rule to generate\nlocally stable neural patterns of activity that are both complex and robust to\nnoise. The outcome is a novel neural network regime that exhibits both\ntransiently stable and chaotic trajectories. We further show that the recurrent\nlearning rule dramatically increases the ability of RRNs to generate complex\nspatiotemporal motor patterns, and accounts for recent experimental data\nshowing a decrease in neural variability in response to stimulus onset.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2012 21:02:16 GMT"}], "update_date": "2013-07-18", "authors_parsed": [["Laje", "Rodrigo", ""], ["Buonomano", "Dean V.", ""]]}, {"id": "1210.2140", "submitter": "Sheng-Yong Xu", "authors": "Jiongwei Xue and Shengyong Xu", "title": "Natural electromagnetic waveguide structures based on myelin sheath in\n  the neural system", "comments": "24 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.soft physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The saltatory propagation of action potentials on myelinated axons is\nconventionally explained by the mechanism employing local circuit ionic current\nflows between nodes of Ranvier. Under this framework, the myelin sheath with up\nto 100 layers of membrane only serves as the insulating shell. The speed of\naction potentials is measured to be as fast as 100 m/s on myelinated axons, but\nions move in fluids at just 100 nm/s in a 1 V/m electric field. We show here\nthe action potentials, in the form of electromagnetic (EM) pulses, can\npropagate in natural EM waveguide structures formed by the myelin sheath merged\nin fluids. The propagation time is mainly cost on the duration for triggering\nEM pulses at nodes of Ranvier. The result clearly reveals the evolution of\naxons from the unmyelinated to the myelinated, which has remarkably enhanced\nthe propagation efficiency by increasing the thickness of myelin sheath.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 03:41:45 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Xue", "Jiongwei", ""], ["Xu", "Shengyong", ""]]}, {"id": "1210.2147", "submitter": "Dal Young Kim Prof.", "authors": "Seok-Hee Kim and Dal-Young Kim", "title": "Differences in the Brain Waves of 3D and 2.5D Motion Picture Viewers", "comments": "10 pages, 1 figure, and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We measured brain waves of viewers watching the 2D, 2.5D, and 3D motion\npictures, comparing them with one another. The relative intensity of\n{\\alpha}-frequency band of 2.5D-viewer was lower than that of 2D-viewer, while\nthat of 3D-viewer remained with similar intensity. This result implies visual\nneuro-processing of the 2.5D-viewer differs from that of the 3D-viewer.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 05:20:22 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Kim", "Seok-Hee", ""], ["Kim", "Dal-Young", ""]]}, {"id": "1210.2901", "submitter": "Ido Kanter", "authors": "H. Brama, Y. Peleg, W. Kinzel and I. Kanter", "title": "Transient to Zero-Lag Synchronization in Excitable Networks", "comments": "5 pages, 3 figures, 1 table", "journal-ref": null, "doi": "10.1103/PhysRevE.87.032813", "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scaling of transient times to zero-lag synchronization in networks\ncomposed of excitable units is shown to be governed by three features of the\ngraph representing the network: the longest path between pairs of neurons\n(diameter), the largest loop (circumference) and the loop with the maximal\naverage out degree. The upper bound of transient times can vary between O(1)\nand O(N2), where N is the size of the network, and its scaling can be predicted\nin many scenarios from finite time accumulated information of the transient.\nResults challenge the assumption that functionality of neural networks might\ndepend solely upon the synchronized repeated activation such as zero-lag\nsynchronization.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 13:07:09 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Brama", "H.", ""], ["Peleg", "Y.", ""], ["Kinzel", "W.", ""], ["Kanter", "I.", ""]]}, {"id": "1210.2942", "submitter": "Tomasz Rutkowski", "authors": "Hiromu Mori, Yoshihiro Matsumito, Shoji Makino, Victor Kryssanov, and\n  Tomasz M. Rutkowski", "title": "Vibrotactile Stimulus Frequency Optimization for the Haptic BCI\n  Prototype", "comments": "The 6th International Conference on Soft Computing and Intelligent\n  Systems and The 13th International Symposium on Advanced Intelligent Systems,\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents results from a psychophysical study conducted to optimize\nvibrotactile stimuli delivered to subject finger tips in order to evoke the\nsomatosensory responses to be utilized next in a haptic brain computer\ninterface (hBCI) paradigm. We also present the preliminary EEG evoked responses\nfor the chosen stimulating frequency. The obtained results confirm our\nhypothesis that the hBCI paradigm concept is valid and it will allow for rapid\nstimuli presentation in order to improve information-transfer-rate (ITR) of the\nBCI.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 14:57:01 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2012 02:44:10 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Mori", "Hiromu", ""], ["Matsumito", "Yoshihiro", ""], ["Makino", "Shoji", ""], ["Kryssanov", "Victor", ""], ["Rutkowski", "Tomasz M.", ""]]}, {"id": "1210.2943", "submitter": "Tomasz Rutkowski", "authors": "Yoshihiro Matsumoto, Nozomu Nishikawa, Takeshi Yamada, Shoji Makino,\n  and Tomasz M. Rutkowski", "title": "Auditory Steady-State Response Stimuli based BCI Application - The\n  Optimization of the Stimuli Types and Lengths", "comments": "APSIPA ASC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for an improvement of auditory BCI (aBCI) paradigm based\non a combination of ASSR stimuli optimization by choosing the subjects' best\nresponses to AM-, flutter-, AM/FM and click-envelope modulated sounds. As the\nASSR response features we propose pairwise phase-locking-values calculated from\nthe EEG and next classified using binary classifier to detect attended and\nignored stimuli. We also report on a possibility to use the stimuli as short as\nhalf a second, which is a step forward in ASSR based aBCI. The presented\nresults are helpful for optimization of the aBCI stimuli for each subject.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 14:58:37 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Matsumoto", "Yoshihiro", ""], ["Nishikawa", "Nozomu", ""], ["Yamada", "Takeshi", ""], ["Makino", "Shoji", ""], ["Rutkowski", "Tomasz M.", ""]]}, {"id": "1210.2944", "submitter": "Tomasz Rutkowski", "authors": "Zhenyu Cai, Shoji Makino, Takeshi Yamada, and Tomasz M. Rutkowski", "title": "Spatial Auditory BCI Paradigm Utilizing N200 and P300 Responses", "comments": "APSIPA ASC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents our recent results obtained with a new auditory spatial\nlocalization based BCI paradigm in which the ERP shape differences at early\nlatencies are employed to enhance the traditional P300 responses in an oddball\nexperimental setting. The concept relies on the recent results in auditory\nneuroscience showing a possibility to differentiate early anterior\ncontralateral responses to attended spatial sources. Contemporary\nstimuli-driven BCI paradigms benefit mostly from the P300 ERP latencies in so\ncalled \"aha-response\" settings. We show the further enhancement of the\nclassification results in spatial auditory paradigms by incorporating the N200\nlatencies, which differentiate the brain responses to lateral, in relation to\nthe subject head, sound locations in the auditory space. The results reveal\nthat those early spatial auditory ERPs boost online classification results of\nthe BCI application. The online BCI experiments with the multi-command BCI\nprototype support our research hypothesis with the higher classification\nresults and the improved information-transfer-rates.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 14:59:26 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Cai", "Zhenyu", ""], ["Makino", "Shoji", ""], ["Yamada", "Takeshi", ""], ["Rutkowski", "Tomasz M.", ""]]}, {"id": "1210.2945", "submitter": "Tomasz Rutkowski", "authors": "Nozomu Nishikawa, Yoshihiro Matsumoto, Shoji Makino, and Tomasz M.\n  Rutkowski", "title": "The Spatial Real and Virtual Sound Stimuli Optimization for the Auditory\n  BCI", "comments": "APSIPA ASC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.SD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents results from a project aiming to create horizontally\ndistributed surround sound sources and virtual sound images as auditory BCI\n(aBCI) stimuli. The purpose is to create evoked brain wave response patterns\ndepending on attended or ignored sound directions. We propose to use a modified\nversion of the vector based amplitude panning (VBAP) approach to achieve the\ngoal. The so created spatial sound stimulus system for the novel oddball aBCI\nparadigm allows us to create a multi-command experimental environment with very\nencouraging results reported in this paper. We also present results showing\nthat a modulation of the sound image depth changes also the subject responses.\nFinally, we also compare the proposed virtual sound approach with the\ntraditional one based on real sound sources generated from the real loudspeaker\ndirections. The so obtained results confirm the hypothesis of the possibility\nto modulate independently the brain responses to spatial types and depths of\nsound sources which allows for the development of the novel multi-command aBCI.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 15:00:00 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Nishikawa", "Nozomu", ""], ["Matsumoto", "Yoshihiro", ""], ["Makino", "Shoji", ""], ["Rutkowski", "Tomasz M.", ""]]}, {"id": "1210.2959", "submitter": "Tomasz Rutkowski", "authors": "Moonjeong Chang, Nozomu Nishikawa, Zhenyu Cai, Shoji Makino, and\n  Tomasz M. Rutkowski", "title": "Psychophysical Responses Comparison in Spatial Visual, Audiovisual, and\n  Auditory BCI-Spelling Paradigms", "comments": "The 6th International Conference on Soft Computing and Intelligent\n  Systems and The 13th International Symposium on Advanced Intelligent Systems,\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents a pilot study conducted with spatial visual, audiovisual\nand auditory brain-computer-interface (BCI) based speller paradigms. The\npsychophysical experiments are conducted with healthy subjects in order to\nevaluate a difficulty and a possible response accuracy variability. We also\npresent preliminary EEG results in offline BCI mode. The obtained results\nvalidate a thesis, that spatial auditory only paradigm performs as good as the\ntraditional visual and audiovisual speller BCI tasks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 15:42:23 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Chang", "Moonjeong", ""], ["Nishikawa", "Nozomu", ""], ["Cai", "Zhenyu", ""], ["Makino", "Shoji", ""], ["Rutkowski", "Tomasz M.", ""]]}, {"id": "1210.3229", "submitter": "Kseniia Kravchuk", "authors": "Kseniia Kravchuk and Alexander Vidybida", "title": "Firing statistics of inhibitory neuron with delayed feedback. II.\n  Non-Markovian behavior", "comments": "The paper was presented at the BIOCOMP2012 meeting at Vietri sul\n  Mare, Italy. Paper contains 33 pages, including 7 figures", "journal-ref": "BioSystems 112 (2013) 233-248", "doi": "10.1016/j.biosystems.2013.02.002", "report-no": null, "categories": "q-bio.NC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The instantaneous state of a neural network consists of both the degree of\nexcitation of each neuron the network is composed of and positions of impulses\nin communication lines between the neurons. In neurophysiological experiments,\nthe neuronal firing moments are registered, but not the state of communication\nlines. But future spiking moments depend essentially on the past positions of\nimpulses in the lines. This suggests, that the sequence of intervals between\nfiring moments (inter-spike intervals, ISIs) in the network could be\nnon-Markovian.\n  In this paper, we address this question for a simplest possible neural \"net\",\nnamely, a single inhibitory neuron with delayed feedback. The neuron receives\nexcitatory input from the driving Poisson stream and inhibitory impulses from\nits own output through the feedback line. We obtain analytic expressions for\nconditional probability density P(t_{n+1}| t_n,...,t_1,t_0), which gives the\nprobability to get an output ISI of duration t_{n+1} provided the previous\n(n+1) output ISIs had durations t_n,...,t_1,t_0. It is proven exactly, that\nP(t_{n+1}| t_n,...,t_1,t_0) does not reduce to P(t_{n+1}| t_n,...,t_1) for any\nn>=0. This means that the output ISIs stream cannot be represented as a Markov\nchain of any finite order.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 13:28:23 GMT"}, {"version": "v2", "created": "Mon, 9 Sep 2013 12:04:02 GMT"}], "update_date": "2013-09-10", "authors_parsed": [["Kravchuk", "Kseniia", ""], ["Vidybida", "Alexander", ""]]}, {"id": "1210.3474", "submitter": "Claudius Gros", "authors": "Claudius Gros, Dimitrije Markovic", "title": "Observing scale-invariance in non-critical dynamical systems", "comments": null, "journal-ref": null, "doi": "10.1063/1.4776500", "report-no": null, "categories": "cond-mat.dis-nn nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent observation for scale invariant neural avalanches in the brain have\nbeen discussed in details in the scientific literature. We point out, that\nthese results do not necessarily imply that the properties of the underlying\nneural dynamics are also scale invariant. The reason for this discrepancy lies\nin the fact that the sampling statistics of observations and experiments is\ngenerically biased by the size of the basins of attraction of the processes to\nbe studied. One has hence to precisely define what one means with statements\nlike `the brain is critical'.\n  We recapitulate the notion of criticality, as originally introduced in\nstatistical physics for second order phase transitions, turning then to the\ndiscussion of critical dynamical systems. We elucidate in detail the difference\nbetween a 'critical system', viz a system on the verge of a phase transition,\nand a 'critical state', viz state with scale-invariant correlations, stressing\nthe fact that the notion of universality is linked to critical states.\n  We then discuss rigorous results for two classes of critical dynamical\nsystems, the Kauffman net and a vertex routing model, which both have\nnon-critical states. However, an external observer that samples randomly the\nphase space of these two critical models, would find scale invariance. We\ndenote this phenomenon as 'observational criticality' and discuss its relevance\nfor the response properties of critical dynamical systems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 10:48:41 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Gros", "Claudius", ""], ["Markovic", "Dimitrije", ""]]}, {"id": "1210.3555", "submitter": "Danielle Bassett", "authors": "Danielle S. Bassett, Nicholas F. Wymbs, M. Puck Rombach, Mason A.\n  Porter, Peter J. Mucha, Scott T. Grafton", "title": "Task-Based Core-Periphery Organisation of Human Brain Dynamics", "comments": "21 pages, 9 figures, and Supplementary Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a person learns a new skill, distinct synapses, brain regions, and\ncircuits are engaged and change over time. In this paper, we develop methods to\nexamine patterns of correlated activity across a large set of brain regions.\nOur goal is to identify properties that enable robust learning of a motor\nskill. We measure brain activity during motor sequencing and characterize\nnetwork properties based on coherent activity between brain regions. Using\nrecently developed algorithms to detect time-evolving communities, we find that\nthe complex reconfiguration patterns of the brain's putative functional modules\nthat control learning can be described parsimoniously by the combined presence\nof a relatively stiff temporal core that is composed primarily of sensorimotor\nand visual regions whose connectivity changes little in time and a flexible\ntemporal periphery that is composed primarily of multimodal association regions\nwhose connectivity changes frequently. The separation between temporal core and\nperiphery changes over the course of training and, importantly, is a good\npredictor of individual differences in learning success. The core of\ndynamically stiff regions exhibits dense connectivity, which is consistent with\nnotions of core-periphery organization established previously in social\nnetworks. Our results demonstrate that core-periphery organization provides an\ninsightful way to understand how putative functional modules are linked. This,\nin turn, enables the prediction of fundamental human capacities, including the\nproduction of complex goal-directed behavior.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 15:50:47 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2013 15:30:56 GMT"}], "update_date": "2013-10-31", "authors_parsed": [["Bassett", "Danielle S.", ""], ["Wymbs", "Nicholas F.", ""], ["Rombach", "M. Puck", ""], ["Porter", "Mason A.", ""], ["Mucha", "Peter J.", ""], ["Grafton", "Scott T.", ""]]}, {"id": "1210.3632", "submitter": "Dante Chialvo", "authors": "Dante R. Chialvo", "title": "Critical brain dynamics at large scale", "comments": "In \"Criticality in Neural Systems\", Niebur E, Plenz D, Schuster HG.\n  (eds.) 2013 (in press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly correlated brain dynamics produces synchronized states with no\nbehavioral value, while weakly correlated dynamics prevent information flow. In\nbetween these states, the unique dynamical features of the critical state endow\nthe brain with properties which are fundamental for adaptive behavior. We\ndiscuss the idea put forward two decades ago by Per Bak that the working brain\nstays at an intermediate (critical) regime characterized by power-law\ncorrelations. This proposal is now supported by a wide body of empirical\nevidence at different scales demonstrating that the spatiotemporal brain\ndynamics exhibit key signatures of critical dynamics, previously recognized in\nother complex systems. The rationale behind this program is discussed in these\nnotes, followed by an account of the most recent results.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 20:31:40 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Chialvo", "Dante R.", ""]]}, {"id": "1210.3633", "submitter": "Daniel  Sheltraw", "authors": "D. Sheltraw, B. Inglis", "title": "A Simulation of the Effects of Receive Field Contrast on\n  Motion-Corrected EPI Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph physics.ins-det q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The receive field of MRI imparts an image contrast which is spatially fixed\nrelative to the receive coil. If motion correction is used to correct subject\nmotion occurring during an EPI time series then the receiver contrast will\neffectively move relative to the subject and produce temporal modulations in\nthe image amplitude. This effect, which we will call the RFC-MoCo effect, may\nhave consequences in the analysis and interpretation of fMRI results. There are\nmany potential causes of motion-related noise and systematic error in EPI time\nseries and isolating the RFC-MoCo effect would be difficult. Therefore, we have\nundertaken a simulation of this effect to better understand its severity. The\nsimulations examine this effect for a receive-only single-channel 16-leg\nbirdcage coil and a receive-only 12-channel phased array. In particular we\nstudy: (1) The effect size; (2) Its consequences to the temporal correlations\nbetween signals arising at different spatial locations (spatial-temporal\ncorrelations) as is often calculated in resting state fMRI analyses; and (3)\nIts impact on the temporal signal-to-noise ratio of an EPI time series. We find\nthat signal changes arising from the RFC-MoCo effect are likely to compete with\nBOLD (blood-oxygen-level-dependent) signal changes in the presence of\nsignificant motion, even under the assumption of perfect motion correction.\nConsequently, we find that the RFC-MoCo effect may lead to spurious temporal\ncorrelations across the image space, and that temporal SNR may be degraded with\nincreasing motion.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2012 20:52:55 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Sheltraw", "D.", ""], ["Inglis", "B.", ""]]}, {"id": "1210.3741", "submitter": "Tao Hu", "authors": "Tao Hu and Dmitri B. Chklovskii", "title": "Online computation of sparse representations of time varying stimuli\n  using a biologically motivated neural network", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural stimuli are highly redundant, possessing significant spatial and\ntemporal correlations. While sparse coding has been proposed as an efficient\nstrategy employed by neural systems to encode sensory stimuli, the underlying\nmechanisms are still not well understood. Most previous approaches model the\nneural dynamics by the sparse representation dictionary itself and compute the\nrepresentation coefficients offline. In reality, faced with the challenge of\nconstantly changing stimuli, neurons must compute the sparse representations\ndynamically in an online fashion. Here, we describe a leaky linearized Bregman\niteration (LLBI) algorithm which computes the time varying sparse\nrepresentations using a biologically motivated network of leaky rectifying\nneurons. Compared to previous attempt of dynamic sparse coding, LLBI exploits\nthe temporal correlation of stimuli and demonstrate better performance both in\nrepresentation error and the smoothness of temporal evolution of sparse\ncoefficients.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2012 21:49:32 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Hu", "Tao", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1210.4145", "submitter": "Sacha Sokoloski", "authors": "Sacha Sokoloski", "title": "A Biologically Realistic Model of Saccadic Eye Control with\n  Probabilistic Population Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The posterior parietal cortex is believed to direct eye movements, especially\nin regards to target tracking tasks, and a number of debates exist over the\nprecise nature of the computations performed by the parietal cortex, with each\nside supported by different sets of biological evidence. In this paper I will\npresent my model which navigates a course between some of these debates,\ntowards the end of presenting a model which can explain some of the competing\ninterpretations among the data sets. In particular, rather than assuming that\nproprioception or efference copies form the key source of information for\ncomputing eye position information, I use a biological plausible implementation\nof a Kalman filter to optimally combine the two signals, and a simple gain\ncontrol mechanism in order to accommodate the latency of the proprioceptive\nsignal. Fitting within the Bayesian brain hypothesis, the result is a Bayes\noptimal solution to the eye control problem, with a range of data supporting\nclaims of biological plausibility.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 19:33:27 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Sokoloski", "Sacha", ""]]}, {"id": "1210.4485", "submitter": "Benjamin de Bivort", "authors": "Jamey Kain, Chris Stokes, Quentin Gaudry, Xiangzhi Song, James Foley,\n  Rachel Wilson, Benjamin de Bivort", "title": "Leg-tracking and automated behavioral classification in Drosophila", "comments": "22 pages, incl 4 figures", "journal-ref": null, "doi": "10.1038/ncomms2908", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we present the first method for tracking each leg of a fruit fly\nbehaving spontaneously upon a trackball, in real time. Legs were tracked with\ninfrared-fluorescent dye invisible to the fly, and compatible with two-photon\nmicroscopy and controlled visual stimuli. We developed machine learning\nclassifiers to identify instances of numerous behavioral features (e.g.\nwalking, turning, grooming) thus producing the highest resolution ethological\nprofiles for individual flies.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 16:41:57 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Kain", "Jamey", ""], ["Stokes", "Chris", ""], ["Gaudry", "Quentin", ""], ["Song", "Xiangzhi", ""], ["Foley", "James", ""], ["Wilson", "Rachel", ""], ["de Bivort", "Benjamin", ""]]}, {"id": "1210.4695", "submitter": "David Balduzzi", "authors": "David Balduzzi", "title": "Regulating the information in spikes: a useful bias", "comments": "NIPS 2012 workshop on Information in Perception and Action", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bias/variance tradeoff is fundamental to learning: increasing a model's\ncomplexity can improve its fit on training data, but potentially worsens\nperformance on future samples. Remarkably, however, the human brain\neffortlessly handles a wide-range of complex pattern recognition tasks. On the\nbasis of these conflicting observations, it has been argued that useful biases\nin the form of \"generic mechanisms for representation\" must be hardwired into\ncortex (Geman et al).\n  This note describes a useful bias that encourages cooperative learning which\nis both biologically plausible and rigorously justified.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 11:12:02 GMT"}], "update_date": "2012-10-18", "authors_parsed": [["Balduzzi", "David", ""]]}, {"id": "1210.4784", "submitter": "Lennaert van Veen", "authors": "Kevin R. Green and Lennaert van Veen", "title": "Open-source tools for dynamical analysis of Liley's mean-field cortex\n  model", "comments": "25 pages, 8 figures", "journal-ref": "J. Comput. Sci. 5 (2014) pp. 507-516", "doi": "10.1016/j.jocs.2013.06.001", "report-no": null, "categories": "math.DS physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mean-field models of the mammalian cortex treat this part of the brain as a\ntwo-dimensional excitable medium. The electrical potentials, generated by the\nexcitatory and inhibitory neuron populations, are described by nonlinear,\ncoupled, partial differential equations, that are known to generate complicated\nspatio-temporal behaviour. We focus on the model by Liley {\\sl et al.}\n(Network: Comput. Neural Syst. (2002) 13, 67-113). Several reductions of this\nmodel have been studied in detail, but a direct analysis of its spatio-temporal\ndynamics has, to the best of our knowledge, never been attempted before. Here,\nwe describe the implementation of implicit time-stepping of the model and the\ntangent linear model, and solving for equilibria and time-periodic solutions,\nusing the open-source library PETSc. By using domain decomposition for\nparallelization, and iterative solving of linear problems, the code is capable\nof parsing some dynamics of a macroscopic slice of cortical tissue with a\nsub-millimetre resolution.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 16:23:12 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Green", "Kevin R.", ""], ["van Veen", "Lennaert", ""]]}, {"id": "1210.5082", "submitter": "Jonathan Touboul", "authors": "Gilles Wainrib, Jonathan Touboul", "title": "Topological and Dynamical Complexity of Random Neural Networks", "comments": null, "journal-ref": "Physical Review Letters 110, 118101 (2013)", "doi": "10.1103/PhysRevLett.110.118101", "report-no": null, "categories": "math-ph cond-mat.dis-nn math.MP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random neural networks are dynamical descriptions of randomly interconnected\nneural units. These show a phase transition to chaos as a disorder parameter is\nincreased. The microscopic mechanisms underlying this phase transition are\nunknown, and similarly to spin-glasses, shall be fundamentally related to the\nbehavior of the system. In this Letter we investigate the explosion of\ncomplexity arising near that phase transition. We show that the mean number of\nequilibria undergoes a sharp transition from one equilibrium to a very large\nnumber scaling exponentially with the dimension on the system. Near\ncriticality, we compute the exponential rate of divergence, called topological\ncomplexity. Strikingly, we show that it behaves exactly as the maximal Lyapunov\nexponent, a classical measure of dynamical complexity. This relationship\nunravels a microscopic mechanism leading to chaos which we further demonstrate\non a simpler class of disordered systems, suggesting a deep and underexplored\nlink between topological and dynamical complexity.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 10:25:50 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2012 19:33:34 GMT"}, {"version": "v3", "created": "Fri, 15 Mar 2013 12:20:24 GMT"}], "update_date": "2013-03-18", "authors_parsed": [["Wainrib", "Gilles", ""], ["Touboul", "Jonathan", ""]]}, {"id": "1210.5348", "submitter": "Erich Schmid", "authors": "Erich W. Schmid and Wolfgang Fink", "title": "Operational Design Considerations for Retinal Prostheses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Three critical improvements for present day and future retinal vision\nimplants are proposed and discussed: (1) A time profile for the stimulation\ncurrent that leads predominantly to transverse stimulation of nerve cells; (2)\nauxiliary electric currents for electric field shaping with a time profile\nchosen such that these currents have small probability to cause stimulation;\nand (3) a local area scanning procedure that results in high pixel density for\nimage/percept formation (except for losses at the boundary of an electrode\narray).\n", "versions": [{"version": "v1", "created": "Fri, 19 Oct 2012 09:07:33 GMT"}], "update_date": "2012-10-22", "authors_parsed": [["Schmid", "Erich W.", ""], ["Fink", "Wolfgang", ""]]}, {"id": "1210.6082", "submitter": "Richard Churchill", "authors": "Richard L. Churchill", "title": "Interplay: Dispersed Activation in Neural Networks", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a multi-point stimulation of a Hebbian neural network\nwith investigation of the interplay between the stimulus waves through the\nneurons of the network. Equilibrium of the resulting memory is achieved for\nrecall of specific memory data at a rate faster than single point stimulus. The\ninterplay of the intersecting stimuli appears to parallel the clarification\nprocess of recall in biological systems.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2012 22:59:58 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Churchill", "Richard L.", ""]]}, {"id": "1210.6230", "submitter": "Guillermo Ludue\\~na", "authors": "Guillermo A. Ludue\\~na and Claudius Gros", "title": "A Self-Organized Neural Comparator", "comments": null, "journal-ref": "G. A. Ludue\\~na and C. Gros, A self-organized neural comparator,\n  Neural Computation, 25, pp 1006 (2013)", "doi": "10.1162/NECO_a_00424", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms need generally the possibility to compare several streams\nof information. Neural learning architectures hence need a unit, a comparator,\nable to compare several inputs encoding either internal or external\ninformation, like for instance predictions and sensory readings. Without the\npossibility of comparing the values of prediction to actual sensory inputs,\nreward evaluation and supervised learning would not be possible.\n  Comparators are usually not implemented explicitly, necessary comparisons are\ncommonly performed by directly comparing one-to-one the respective activities.\nThis implies that the characteristics of the two input streams (like size and\nencoding) must be provided at the time of designing the system.\n  It is however plausible that biological comparators emerge from\nself-organizing, genetically encoded principles, which allow the system to\nadapt to the changes in the input and in the organism.\n  We propose an unsupervised neural circuitry, where the function of input\ncomparison emerges via self-organization only from the interaction of the\nsystem with the respective inputs, without external influence or supervision.\n  The proposed neural comparator adapts, unsupervised, according to the\ncorrelations present in the input streams. The system consists of a multilayer\nfeed-forward neural network which follows a local output minimization\n(anti-Hebbian) rule for adaptation of the synaptic weights.\n  The local output minimization allows the circuit to autonomously acquire the\ncapability of comparing the neural activities received from different neural\npopulations, which may differ in the size of the population and in the neural\nencoding used. The comparator is able to compare objects never encountered\nbefore in the sensory input streams and to evaluate a measure of their\nsimilarity, even when differently encoded.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 13:19:08 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2012 13:55:10 GMT"}], "update_date": "2013-03-14", "authors_parsed": [["Ludue\u00f1a", "Guillermo A.", ""], ["Gros", "Claudius", ""]]}, {"id": "1210.6317", "submitter": "Shivakumar Viswanathan", "authors": "Shivakumar Viswanathan, Matthew Cieslak and Scott T. Grafton", "title": "On the geometric structure of fMRI searchlight-based information maps", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information mapping is a popular application of Multivoxel Pattern Analysis\n(MVPA) to fMRI. Information maps are constructed using the so called\nsearchlight method, where the spherical multivoxel neighborhood of every voxel\n(i.e., a searchlight) in the brain is evaluated for the presence of\ntask-relevant response patterns. Despite their widespread use, information maps\npresent several challenges for interpretation. One such challenge has to do\nwith inferring the size and shape of a multivoxel pattern from its signature on\nthe information map. To address this issue, we formally examined the geometric\nbasis of this mapping relationship. Based on geometric considerations, we show\nhow and why small patterns (i.e., having smaller spatial extents) can produce a\nlarger signature on the information map as compared to large patterns,\nindependent of the size of the searchlight radius. Furthermore, we show that\nthe number of informative searchlights over the brain increase as a function of\nsearchlight radius, even in the complete absence of any multivariate response\npatterns. These properties are unrelated to the statistical capabilities of the\npattern-analysis algorithms used but are obligatory geometric properties\narising from using the searchlight procedure.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 18:21:16 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Viswanathan", "Shivakumar", ""], ["Cieslak", "Matthew", ""], ["Grafton", "Scott T.", ""]]}, {"id": "1210.6554", "submitter": "Antonio Giuliano Zippo Dr.", "authors": "Antonio G. Zippo, Riccardo Storchi, Giuliana Gelsomino, Sara Nencini,\n  Gian Carlo Caramenti, Maurizio Valente, Gabriele E. M. Biella", "title": "Neuronal functional connectivity among multiple areas of the rat\n  somatosensory system during spontaneous and evoked activities", "comments": null, "journal-ref": "PLoS Computational Biology 06/2013", "doi": "10.1371/journal.pcbi.1003104", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small-World Networks (SWNs) represent a fundamental model for the\ncomprehension of many complex man-made and biological networks. In the central\nnervous system, SWN models have been shown to fit well both anatomical and\nfunctional maps at the macroscopic level. However the functional microscopic\nlevel, where the nodes of a network are composed of single neurons, is still\npoorly understood. At this level, although recent evidences suggest that\nfunctional connectivity maps exhibit small-world organization, it is not known\nwhether and how these maps, distributed in multiple brain regions, change\nacross different conditions. We addressed these questions by simultaneous\nmulti-array extracellular recordings in three brain regions diversely involved\nin somatosensory information processing: the ventropostero-lateral thalamic\nnuclei (VPL), the primary somatosensory cortex (S1) and the centro-median\nthalamic nuclei (CM). From both spike and Local Field Potential (LFP)\nrecordings, we estimated the functional connectivity maps by using the\nNormalized Compression Similarity (spikes) and the Phase Synchrony (LFPs).\nThen, by using graph-theoretical statistics, we characterized the functional\nmap topology both during spontaneous activity and sensory stimulation. Our main\nresults show that: (i) spikes and LFPs show SWN organization during spontaneous\nactivity; (ii) After stimulation onset, while substantial functional map\nreconfigurations occur both in spike and LFPs, small-worldness is nonetheless\npreserved (iii) The stimulus triggers a significant increase of inter-area LFP\nconnections without modifying the topology of intra-area functional\nconnections; (iv) Through computer simulations of the fundamental concept of\ncell assemblies, transient groups of activating neurons can be described by\nsmall-world networks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2012 14:50:34 GMT"}, {"version": "v2", "created": "Thu, 17 Jan 2013 11:20:34 GMT"}], "update_date": "2013-06-17", "authors_parsed": [["Zippo", "Antonio G.", ""], ["Storchi", "Riccardo", ""], ["Gelsomino", "Giuliana", ""], ["Nencini", "Sara", ""], ["Caramenti", "Gian Carlo", ""], ["Valente", "Maurizio", ""], ["Biella", "Gabriele E. M.", ""]]}, {"id": "1210.6789", "submitter": "Ferdinando Giacco", "authors": "Silvia Scarpetta and Ferdinando Giacco", "title": "Associative memory of phase-coded spatiotemporal patterns in leaky\n  Integrate and Fire networks", "comments": null, "journal-ref": "Journal of Computational Neuroscience. Publication date:\n  03.10.2012", "doi": "10.1007/s10827-012-0423-7", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the collective dynamics of a Leaky Integrate and Fire network in\nwhich precise relative phase relationship of spikes among neurons are stored,\nas attractors of the dynamics, and selectively replayed at differentctime\nscales. Using an STDP-based learning process, we store in the connectivity\nseveral phase-coded spike patterns, and we find that, depending on the\nexcitability of the network, different working regimes are possible, with\ntransient or persistent replay activity induced by a brief signal. We introduce\nan order parameter to evaluate the similarity between stored and recalled\nphase-coded pattern, and measure the storage capacity. Modulation of spiking\nthresholds during replay changes the frequency of the collective oscillation or\nthe number of spikes per cycle, keeping preserved the phases relationship. This\nallows a coding scheme in which phase, rate and frequency are dissociable.\nRobustness with respect to noise and heterogeneity of neurons parameters is\nstudied, showing that, since dynamics is a retrieval process, neurons preserve\nstablecprecise phase relationship among units, keeping a unique frequency of\noscillation, even in noisy conditions and with heterogeneity of internal\nparameters of the units.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 10:40:05 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["Scarpetta", "Silvia", ""], ["Giacco", "Ferdinando", ""]]}, {"id": "1210.6979", "submitter": "Ferdinando Giacco", "authors": "Ferdinando Giacco and Silvia Scarpetta", "title": "Attractor networks and memory replay of phase coded spike patterns", "comments": "arXiv admin note: text overlap with arXiv:1210.6789", "journal-ref": "Frontiers in Artificial Intelligence and Applications, Volume 234,\n  2011, pag 265-274", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyse the storage and retrieval capacity in a recurrent neural network\nof spiking integrate and fire neurons. In the model we distinguish between a\nlearning mode, during which the synaptic connections change according to a\nSpike-Timing Dependent Plasticity (STDP) rule, and a recall mode, in which\nconnections strengths are no more plastic. Our findings show the ability of the\nnetwork to store and recall periodic phase coded patterns a small number of\nneurons has been stimulated. The self sustained dynamics selectively gives an\noscillating spiking activity that matches one of the stored patterns, depending\non the initialization of the network.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 11:09:56 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Giacco", "Ferdinando", ""], ["Scarpetta", "Silvia", ""]]}, {"id": "1210.6989", "submitter": "Robert Rosenbaum", "authors": "Steven Reich and Robert Rosenbaum", "title": "The impact of short term synaptic depression and stochastic vesicle\n  dynamics on neural variability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural variability plays a central role in neural coding and neuronal network\ndynamics. Unreliability of synaptic transmission is a major source of neural\nvariability: synaptic neurotransmitter vesicles are released probabilistically\nin response to presynaptic spikes and are recovered stochastically in time. The\nstochastic dynamics of this process interacts with variability in the arrival\ntimes of presynaptic spikes to shape the variability of the postsynaptic\nresponse. We use continuous time Markov chain methods to analyze a model of\nshort term synaptic depression with stochastic vesicle dynamics coupled with\nthree different models of presynaptic spiking: one model in which the timing of\npresynaptic spikes are modeled as a Poisson process, one in which spikes occur\nmore regularly than a Poisson process and one in which spikes occur more\nirregularly. We use this analysis to investigate how variability in a\npresynaptic spike train is transformed by short term synaptic depression and\nstochastic vesicle dynamics to determine the variability of the postsynaptic\nresponse to a presynaptic spike train. We find that regular presynaptic spiking\nincreases the average rate at which vesicles are released, that the number of\nvesicles released over a time window is more variable for smaller time windows\nthan for larger time windows, and that fast presynaptic spiking gives rise to\nPoisson-like variability of the postsynaptic response even when presynaptic\nspike times are highly non-Poisson. Our results complement and extend\npreviously reported theoretical results and provide possible explanations for\nsome trends observed in recorded data.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 20:01:51 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Reich", "Steven", ""], ["Rosenbaum", "Robert", ""]]}, {"id": "1210.7083", "submitter": "Thomas Pfeil", "authors": "Thomas Pfeil, Andreas Gr\\\"ubl, Sebastian Jeltsch, Eric M\\\"uller, Paul\n  M\\\"uller, Mihai A. Petrovici, Michael Schmuker, Daniel Br\\\"uderle, Johannes\n  Schemmel, Karlheinz Meier", "title": "Six networks on a universal neuromorphic computing substrate", "comments": "21 pages, 9 figures", "journal-ref": "Front. Neurosci. 7:11 (2013)", "doi": "10.3389/fnins.2013.00011", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we present a highly configurable neuromorphic computing\nsubstrate and use it for emulating several types of neural networks. At the\nheart of this system lies a mixed-signal chip, with analog implementations of\nneurons and synapses and digital transmission of action potentials. Major\nadvantages of this emulation device, which has been explicitly designed as a\nuniversal neural network emulator, are its inherent parallelism and high\nacceleration factor compared to conventional computers. Its configurability\nallows the realization of almost arbitrary network topologies and the use of\nwidely varied neuronal and synaptic parameters. Fixed-pattern noise inherent to\nanalog circuitry is reduced by calibration routines. An integrated development\nenvironment allows neuroscientists to operate the device without any prior\nknowledge of neuromorphic circuit design. As a showcase for the capabilities of\nthe system, we describe the successful emulation of six different neural\nnetworks which cover a broad spectrum of both structure and functionality.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 09:51:03 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2012 00:13:53 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2013 14:19:14 GMT"}, {"version": "v4", "created": "Thu, 21 Feb 2013 16:55:08 GMT"}], "update_date": "2013-04-08", "authors_parsed": [["Pfeil", "Thomas", ""], ["Gr\u00fcbl", "Andreas", ""], ["Jeltsch", "Sebastian", ""], ["M\u00fcller", "Eric", ""], ["M\u00fcller", "Paul", ""], ["Petrovici", "Mihai A.", ""], ["Schmuker", "Michael", ""], ["Br\u00fcderle", "Daniel", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1210.7165", "submitter": "Farzad Farkhooi", "authors": "Farzad Farkhooi, Anja Froese, Eilif Muller, Randolf Menzel, Martin P.\n  Nawrot", "title": "Cellular Adaptation Accounts for the Sparse and Reliable Sensory\n  Stimulus Representation", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most neurons in peripheral sensory pathways initially respond vigorously when\na preferred stimulus is presented, but adapt as stimulation continues. It is\nunclear how this phenomenon affects stimulus representation in the later stages\nof cortical sensory processing. Here, we show that a temporally sparse and\nreliable stimulus representation develops naturally in a network with adapting\nneurons. We find that cellular adaptation plays a critical role in the\ntransient reduction of the trial-by-trial variability of cortical spiking,\nproviding an explanation for a wide-spread and hitherto unexplained phenomenon\nby a simple mechanism. In insect olfaction, cellular adaptation is sufficient\nto explain the emergence of the temporally sparse and reliable stimulus\nrepresentation in the mushroom body, independent of inhibitory mechanisms. Our\nresults reveal a computational principle that relates neuronal firing rate\nadaptation to temporal sparse coding and variability suppression in nervous\nsystems with a sequential processing architecture.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 15:15:08 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Farkhooi", "Farzad", ""], ["Froese", "Anja", ""], ["Muller", "Eilif", ""], ["Menzel", "Randolf", ""], ["Nawrot", "Martin P.", ""]]}, {"id": "1210.7414", "submitter": "Asaf Gal", "authors": "Asaf Gal and Shimon Marom", "title": "Self-organized criticality in single neuron excitability", "comments": "5 pages, 2 figures", "journal-ref": "Phys. Rev. E 88, 062717 (2013)", "doi": "10.1103/PhysRevE.88.062717", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present experimental and theoretical arguments, at the single neuron\nlevel, suggesting that neuronal response fluctuations reflect a process that\npositions the neuron near a transition point that separates excitable and\nunexcitable phases. This view is supported by the dynamical properties of the\nsystem as observed in experiments on isolated cultured cortical neurons, as\nwell as by a theoretical mapping between the constructs of self organized\ncriticality and membrane excitability biophysics.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2012 07:30:49 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2012 19:34:24 GMT"}, {"version": "v3", "created": "Wed, 31 Oct 2012 15:21:20 GMT"}, {"version": "v4", "created": "Wed, 27 Feb 2013 11:46:34 GMT"}, {"version": "v5", "created": "Wed, 7 Aug 2013 10:35:08 GMT"}], "update_date": "2013-12-25", "authors_parsed": [["Gal", "Asaf", ""], ["Marom", "Shimon", ""]]}, {"id": "1210.7495", "submitter": "Eduardo Mizraji", "authors": "Eduardo Mizraji", "title": "Illustrating a neural model of logic computations: The case of Sherlock\n  Holmes' old maxim", "comments": "Corrected version with new references", "journal-ref": "THEORIA 31/1 (2016): 7-25", "doi": "10.1387/theoria.13959", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural languages can express some logical propositions that humans are able\nto understand. We illustrate this fact with a famous text that Conan Doyle\nattributed to Holmes: 'It is an old maxim of mine that when you have excluded\nthe impossible, whatever remains, however improbable, must be the truth'. This\nis a subtle logical statement usually felt as an evident truth. The problem we\nare trying to solve is the cognitive reason for such a feeling. We postulate\nhere that we accept Holmes' maxim as true because our adult brains are equipped\nwith neural modules that naturally perform modal logical computations.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2012 19:37:33 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2012 12:00:10 GMT"}, {"version": "v3", "created": "Sat, 27 Feb 2016 14:45:52 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Mizraji", "Eduardo", ""]]}, {"id": "1210.8295", "submitter": "Luc Berthouze", "authors": "Timothy J. Taylor, Caroline Hartley, P\\'eter L. Simon, Istvan Z Kiss,\n  Luc Berthouze", "title": "Identification of criticality in neuronal avalanches: I. A theoretical\n  investigation of the non-driven case", "comments": "33 pages, 10 figures", "journal-ref": "The Journal of Mathematical Neuroscience 2013, 3:5", "doi": "10.1186/2190-8567-3-5", "report-no": null, "categories": "q-bio.NC math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a simple model of a purely excitatory neural network\nthat, by construction, operates at a critical point. This model allows us to\nconsider various markers of criticality and illustrate how they should perform\nin a finite-size system. By calculating the exact distribution of avalanche\nsizes we are able to show that, over a limited range of avalanche sizes which\nwe precisely identify, the distribution has scale free properties but is not a\npower law. This suggests that it would be inappropriate to dismiss a system as\nnot being critical purely based on an inability to rigorously fit a power law\ndistribution as has been recently advocated. In assessing whether a system,\nespecially a finite-size one, is critical it is thus important to consider\nother possible markers. We illustrate one of these by showing the divergence of\nsusceptibility as the critical point of the system is approached. Finally, we\nprovide evidence that power laws may underlie other observables of the system,\nthat may be more amenable to robust experimental assessment.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 11:01:56 GMT"}], "update_date": "2013-05-17", "authors_parsed": [["Taylor", "Timothy J.", ""], ["Hartley", "Caroline", ""], ["Simon", "P\u00e9ter L.", ""], ["Kiss", "Istvan Z", ""], ["Berthouze", "Luc", ""]]}, {"id": "1210.8406", "submitter": "Natasha Cayco Gajic", "authors": "Natasha Cayco Gajic, Eric Shea-Brown", "title": "Neutral stability, rate propagation, and critical branching in\n  feedforward networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental and computational evidence suggests that several\ndynamical properties may characterize the operating point of functioning neural\nnetworks: critical branching, neutral stability, and production of a wide range\nof firing patterns. We seek the simplest setting in which these properties\nemerge, clarifying their origin and relationship in random, feedforward\nnetworks of McCullochs-Pitts neurons. Two key parameters are the thresholds at\nwhich neurons fire spikes, and the overall level of feedforward connectivity.\nWhen neurons have low thresholds, we show that there is always a connectivity\nfor which the properties in question all occur: that is, these networks\npreserve overall firing rates from layer to layer and produce broad\ndistributions of activity in each layer. This fails to occur, however, when\nneurons have high thresholds. A key tool in explaining this difference is\neigenstructure of the resulting mean-field Markov chain, as this reveals which\nactivity modes will be preserved from layer to layer. We extend our analysis\nfrom purely excitatory networks to more complex models that include inhibition\nand 'local' noise, and find that both of these features extend the parameter\nranges over which networks produce the properties of interest.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 17:29:31 GMT"}], "update_date": "2012-11-01", "authors_parsed": [["Gajic", "Natasha Cayco", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1210.8415", "submitter": "Markus Dahlem", "authors": "Markus A. Dahlem and Jan Tusch", "title": "Predicted selective increase of cortical magnification due to cortical\n  folding", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cortical magnification matrix M is introduced founded on a notion similar\nto that of the scalar cortical magnification factor M. Unlike M, this matrix is\nsuitable to describe anisotropy in cortical magnification, which is of\nparticular interest in the highly gyrified human cerebral cortex. The advantage\nof our tensor method over other surface-based 3D methods to explore cortical\nmorphometry is that M expresses cortical quantities in the corresponding\nsensory space. It allows us to investigate the spatial relation between sensory\nfunction and anatomical structure. To this end, we consider the calcarine\nsulcus (CS) as an anatomical landmark for the primary visual cortex (V1). We\nfound that a stereotypically formed 3D model of V1 compared to a flat model\nexplains an excess of cortical tissue for the representation of visual\ninformation coming from the horizon of the visual field. This suggests that the\nintrinsic geometry of this sulcus is adapted to encephalize a particular\nfunction along the horizon. Since visual functions are assumed to be M-scaled,\ncortical folding can serve as an anatomical basis for increased functionality\non the horizon similar to a retinal specialization known as visual streak,\nwhich is found in animals with lower encephalization. Thus, the gain of surface\narea by cortical folding links anatomical structure to cortical function in a\npreviously unrecognized way, which may guide sulci development.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 17:47:21 GMT"}], "update_date": "2012-11-01", "authors_parsed": [["Dahlem", "Markus A.", ""], ["Tusch", "Jan", ""]]}, {"id": "1210.8442", "submitter": "Louis Shao", "authors": "Louis Yuanlong Shao", "title": "Linear-Nonlinear-Poisson Neuron Networks Perform Bayesian Inference On\n  Boltzmann Machines", "comments": "Submitted to International Conference of Learning Representation\n  (ICLR) 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One conjecture in both deep learning and classical connectionist viewpoint is\nthat the biological brain implements certain kinds of deep networks as its\nback-end. However, to our knowledge, a detailed correspondence has not yet been\nset up, which is important if we want to bridge between neuroscience and\nmachine learning. Recent researches emphasized the biological plausibility of\nLinear-Nonlinear-Poisson (LNP) neuron model. We show that with neurally\nplausible settings, the whole network is capable of representing any Boltzmann\nmachine and performing a semi-stochastic Bayesian inference algorithm lying\nbetween Gibbs sampling and variational inference.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 19:14:41 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2013 01:23:04 GMT"}, {"version": "v3", "created": "Sun, 27 Jan 2013 05:30:35 GMT"}], "update_date": "2013-01-29", "authors_parsed": [["Shao", "Louis Yuanlong", ""]]}]