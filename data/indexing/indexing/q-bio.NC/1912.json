[{"id": "1912.00009", "submitter": "Shiyuan Li", "authors": "Shiyuan Li", "title": "MSTDP: A More Biologically Plausible Learning", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike-timing dependent plasticity (STDP) which observed in the brain has\nproven to be important in biological learning. On the other hand, artificial\nneural networks use a different way to learn, such as Back-Propagation or\nContrastive Hebbian Learning. In this work, we propose a new framework called\nmstdp that learn almost the same way biological learning use, it only uses STDP\nrules for supervised and unsupervised learning and don' t need a global loss or\nother supervise information. The framework works like an auto-encoder by making\neach input neuron also an output neuron. It can make predictions or generate\npatterns in one model without additional configuration. We also brought a new\niterative inference method using momentum to make the framework more efficient,\nwhich can be used in training and testing phases. Finally, we verified our\nframework on MNIST dataset for classification and generation task.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 05:42:50 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 02:33:20 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Li", "Shiyuan", ""]]}, {"id": "1912.00091", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Creativity", "comments": "Reference: Gabora, L. (in press). Creativity. Oxford Research\n  Encyclopedia of Psychology. Oxford UK: Oxford University Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creativity is perhaps what most differentiates humans from other species. It\ninvolves the capacity to shift between divergent and convergent modes of\nthought in response to task demands. Divergent thought has been characterized\nas the kind of thinking needed to generate multiple solutions, while convergent\nthought has been characterized as the kind of thinking needed for tasks in with\none solution. Divergent thought has been conceived of as reflecting on the task\nfrom unconventional perspectives, while convergent thought has been conceived\nof as reflecting on it from conventional perspectives. Personality traits\ncorrelated with creativity include openness to experience, tolerance of\nambiguity, and self-confidence. Evidence that creativity is linked with\naffective disorders is mixed. Neuroscientific research using\nelectroencephalography (EEG) or functional magnetic resonance imaging (fMRI)\nsuggests that creativity is associated with a loosening of cognitive control\nand decreased arousal. The distributed, content-addressable structure of\nassociative memory is conducive to bringing task-relevant items to mind without\nthe need for explicit search. Human creativity dates back to the earliest stone\ntools over three million years ago, with the Paleolithic marking the onset of\nart, science, and religion. Areas of controversy concern the relative\ncontributions of expertise, chance, and intuition, the importance of process\nversus product, whether creativity is domain-specific versus domain-general,\nthe extent to which creativity is correlated with affective disorders, and\nwhether divergent thought entails the generation of multiple ideas or the\nhoning of a single initially ambiguous mental representation that may manifest\nas different external outputs. Areas for further research include computational\nmodeling, the biological basis of creativity, and studies that track ideation\nprocesses over time.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2019 23:17:03 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1912.00226", "submitter": "Yoshiki Ito", "authors": "Yoshiki Ito and Taro Toyoizumi", "title": "Learning poly-synaptic paths with traveling waves", "comments": "PLOS Computational Biology Accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traveling waves are commonly observed across the brain. While previous\nstudies have suggested the role of traveling waves in learning, the mechanism\nis still unclear. We adopted a computational approach to investigate the effect\nof traveling waves on synaptic plasticity. Our results indicate that traveling\nwaves facilitate the learning of poly-synaptic network-paths when combined with\na reward-dependent local synaptic plasticity rule. We also demonstrate that\ntraveling waves expedite finding the shortest paths and learning nonlinear\ninput/output-mapping, such as exclusive or (XOR) function.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 16:28:36 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 07:07:49 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Ito", "Yoshiki", ""], ["Toyoizumi", "Taro", ""]]}, {"id": "1912.00270", "submitter": "Gerrit Hilgen", "authors": "Gerrit Hilgen (Biosciences Institute, Faculty of Medical Sciences,\n  Newcastle University, Newcastle, NE2 4HH, United Kingdom)", "title": "Challenges for automated spike sorting: beware of pharmacological\n  manipulations", "comments": "mini review, 1 figure, 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of large-scale and high-density extracellular recording devices\nallows simultaneous recording from thousands of neurons. However, the\ncomplexity and size of the data makes it mandatory to develop robust algorithms\nfor fully automated spike sorting. Here it is shown that limitations imposed by\nbiological constraints such as changes in spike waveforms induced under\ndifferent drug regimes should be carefully taken into consideration in future\ndevelopments.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2019 21:51:28 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Hilgen", "Gerrit", "", "Biosciences Institute, Faculty of Medical Sciences,\n  Newcastle University, Newcastle, NE2 4HH, United Kingdom"]]}, {"id": "1912.00421", "submitter": "Thomas Dean", "authors": "Thomas Dean, Chaofei Fan, Francis E. Lewis, Megumi Sano", "title": "Biological Blueprints for Next Generation AI Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diverse subfields of neuroscience have enriched artificial intelligence for\nmany decades. With recent advances in machine learning and artificial neural\nnetworks, many neuroscientists are partnering with AI researchers and machine\nlearning experts to analyze data and construct models. This paper attempts to\ndemonstrate the value of such collaborations by providing examples of how\ninsights derived from neuroscience research are helping to develop new machine\nlearning algorithms and artificial neural network architectures. We survey the\nrelevant neuroscience necessary to appreciate these insights and then describe\nhow we can translate our current understanding of the relevant neurobiology\ninto algorithmic techniques and architectural designs. Finally, we characterize\nsome of the major challenges facing current AI technology and suggest avenues\nfor overcoming these challenges that draw upon research in developmental and\ncomparative cognitive neuroscience.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2019 14:50:23 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Dean", "Thomas", ""], ["Fan", "Chaofei", ""], ["Lewis", "Francis E.", ""], ["Sano", "Megumi", ""]]}, {"id": "1912.00581", "submitter": "William Paul Boyce", "authors": "W. Paul Boyce, Tony Lindsay, Arkady Zgonnikov, Ignacio Rano, and\n  KongFatt Wong-Lin", "title": "Optimality and limitations of audio-visual integration for cognitive\n  systems", "comments": "20 pages, 6 figures, 1 table 16/06/2020: Updated version includes\n  expanded discussion and addition of new references. Also updated author\n  affiliation information. This version has been accepted for publication with\n  Frontiers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multimodal integration is an important process in perceptual decision-making.\nIn humans, this process has often been shown to be statistically optimal, or\nnear optimal: sensory information is combined in a fashion that minimises the\naverage error in perceptual representation of stimuli. However, sometimes there\nare costs that come with the optimization, manifesting as illusory percepts. We\nreview audio-visual facilitations and illusions that are products of\nmultisensory integration, and the computational models that account for these\nphenomena. In particular, the same optimal computational model can lead to\nillusory percepts, and we suggest that more studies should be needed to detect\nand mitigate these illusions, as artefacts in artificial cognitive systems. We\nprovide cautionary considerations when designing artificial cognitive systems\nwith the view of avoiding such artefacts. Finally, we suggest avenues of\nresearch towards solutions to potential pitfalls in system design. We conclude\nthat detailed understanding of multisensory integration and the mechanisms\nbehind audio-visual illusions can benefit the design of artificial cognitive\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 05:08:39 GMT"}, {"version": "v2", "created": "Sat, 11 Jan 2020 06:27:55 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 02:10:31 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Boyce", "W. Paul", ""], ["Lindsay", "Tony", ""], ["Zgonnikov", "Arkady", ""], ["Rano", "Ignacio", ""], ["Wong-Lin", "KongFatt", ""]]}, {"id": "1912.00766", "submitter": "Tim Ziemer", "authors": "Tim Ziemer and Holger Schultheis", "title": "Three Orthogonal Dimensions for Psychoacoustic Sonification", "comments": "Keywords: Auditory Display, Audition, Noise/acoustics, Sound Design,\n  Interpretability", "journal-ref": null, "doi": "10.21785/icad2019.018", "report-no": null, "categories": "cs.SD eess.AS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Three perceptually orthogonal auditory dimensions for\nmultidimensional and multivariate data sonification are identified and\nexperimentally validated. Background: Psychoacoustic investigations have shown\nthat orthogonal acoustical parameters may interfere perceptually. The\nliterature hardly offers any solutions to this problem, and previous auditory\ndisplay approaches have failed to implement auditory dimensions that are\nperceived orthogonally by a user. In this study we demonstrate how a location\nin three-dimensional space can be sonified unambiguously by the implementation\nof perceptually orthogonal psychoacoustic attributes in monophonic playback.\nMethod: Perceptually orthogonal auditory attributes are identified from\nliterature research and experience in music and psychoacoustic research. We\ncarried out an experiment with 21 participants who identified sonified\nlocations in two-dimensional space. Results: With just 5 minutes of explanation\nand exploration, naive users can interpret our multidimensional sonification\nwith high accuracy. Conclusion: We identified a set of perceptually orthogonal\nauditory dimensions suitable for three-dimensional data sonification.\nApplication: Three-dimensional data sonification promises blind navigation,\ne.g. for unmanned vehicles, and reliable real-time monitoring of multivariate\ndata, e.g., in the patient care sector.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2019 13:19:50 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Ziemer", "Tim", ""], ["Schultheis", "Holger", ""]]}, {"id": "1912.00866", "submitter": "Huy Phi", "authors": "Huy Phi, Sanjeev Janarthanan, Larry Zhang, Reza Hosseini Ghomi", "title": "Voice Biomarker Identification for Effects of Deep-Brain Stimulation on\n  Parkinson's Disease", "comments": "5 pages, including 3 tables, 2 figures, and references", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep-Brain Stimulation (DBS) is a therapy used in conjunction with medication\nto help alleviate the motor symptoms of Parkinson's Disease (PD). However, the\nmonitoring and adjustment of DBS settings is tedious and expensive, requiring\nlong programming appointments every few months. We investigated the possible\ncorrelation between PD motor score severity and digitally extracted patient\nvoice features to potentially aid clinicians in their monitoring and treatment\nof PD with DBS, and eventually enable a closed-loop DBS system. 5 DBS PD\npatients were enrolled. Voice samples were collected for various voice tasks\n(single phoneme vocalization, free speech task, sentence reading task, counting\nbackward task, categorical fluency task) for DBS ON and OFF states. Motor\nscores per the Unified Parkinson's Disease Rating Scale (UPDRS) were also\ncollected for DBS ON and OFF states. Voice samples were then analyzed to\nextract voice features using publicly available voice feature library sets, and\nstatistically compared for DBS ON and OFF. Of the feature categories explored\n(Acoustic, Prosodic, Linguistic) 6 features from the GeMAPS feature set for\nacoustic features demonstrated significant differences with DBS ON and OFF\n(p<0.05). Prosodic features such as pause length/percentage were found to be\nnegatively correlated with increased motor symptom severity. Non-significant\ndifferences were found for linguistic features. These findings provide\npreliminary evidence for acoustic and prosodic speech features to act as\npotential biomarkers for PD disease severity in DBS patients. We hope to\nexplore further by expanding our data set, identifying other features, applying\nmachine learning models, and working towards a closed-loop DBS system that can\nauto-tune itself based on changes in a patient's voice.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2019 07:46:27 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Phi", "Huy", ""], ["Janarthanan", "Sanjeev", ""], ["Zhang", "Larry", ""], ["Ghomi", "Reza Hosseini", ""]]}, {"id": "1912.00939", "submitter": "Duccio Fanelli", "authors": "Claudio Pereti, Duccio Fanelli", "title": "Stabilizing Stuart-Landau oscillators via time-varying networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.chaos.2019.109587", "report-no": null, "categories": "nlin.AO cond-mat.stat-mech nlin.PS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A procedure is developed and tested to enforce synchronicity in a family of\nStuart-Landau oscillators, coupled through a symmetric network. The proposed\nmethod exploits network plasticity, as an inherent non autonomous drive. More\nspecifically, we assume that the system is initially confined on a network\nwhich turns the underlying homogeneous synchronous state unstable. A properly\nengineered network can be always generated, which links the same set of nodes,\nand allows for synchronicity to be eventually restored, upon performing\ncontinuously swappings, at a sufficient rate, between the two aforementioned\nnetworks. The result is cast in rigorous terms, as follows an application of\nthe average theorem and the critical swapping rate determined analytically.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:11:13 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Pereti", "Claudio", ""], ["Fanelli", "Duccio", ""]]}, {"id": "1912.00963", "submitter": "Anne Shiu", "authors": "Brianna Gambacini, R. Amzi Jeffs, Sam Macdonald, Anne Shiu", "title": "Non-monotonicity of closed convexity in neural codes", "comments": "Many minor edits, as suggested by referees", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural codes are lists of subsets of neurons that fire together. Of\nparticular interest are neurons called place cells, which fire when an animal\nis in specific, usually convex regions in space. A fundamental question,\ntherefore, is to determine which neural codes arise from the regions of some\ncollection of open convex sets or closed convex sets in Euclidean space. This\nwork focuses on how these two classes of codes -- open convex and closed convex\ncodes -- are related. As a starting point, open convex codes have a desirable\nmonotonicity property, namely, adding non-maximal codewords preserves open\nconvexity; but here we show that this property fails to hold for closed convex\ncodes. Additionally, while adding non-maximal codewords can only increase the\nopen embedding dimension by 1, here we demonstrate that adding a single such\ncodeword can increase the closed embedding dimension by an arbitrarily large\namount. Finally, we disprove a conjecture of Goldrup and Phillipson, and also\npresent an example of a code that is neither open convex nor closed convex.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:51:33 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2020 19:40:03 GMT"}, {"version": "v3", "created": "Fri, 2 Apr 2021 15:44:54 GMT"}], "update_date": "2021-04-05", "authors_parsed": [["Gambacini", "Brianna", ""], ["Jeffs", "R. Amzi", ""], ["Macdonald", "Sam", ""], ["Shiu", "Anne", ""]]}, {"id": "1912.01088", "submitter": "Campbell Scott", "authors": "J. Campbell Scott, Thomas F. Hayes, Ahmet S. Ozcan and Winfried W.\n  Wilcke", "title": "Simulation of neural function in an artificial Hebbian network", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial neural networks have diverged far from their early inspiration in\nneurology. In spite of their technological and commercial success, they have\nseveral shortcomings, most notably the need for a large number of training\nexamples and the resulting computation resources required for iterative\nlearning. Here we describe an approach to neurological network simulation, both\narchitectural and algorithmic, that adheres more closely to established\nbiological principles and overcomes some of the shortcomings of conventional\nnetworks.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 21:41:15 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Scott", "J. Campbell", ""], ["Hayes", "Thomas F.", ""], ["Ozcan", "Ahmet S.", ""], ["Wilcke", "Winfried W.", ""]]}, {"id": "1912.01268", "submitter": "Martino Sorbaro", "authors": "Martino Sorbaro, Qian Liu, Massimo Bortone, Sadique Sheik", "title": "Optimizing the energy consumption of spiking neural networks for\n  neuromorphic applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the last few years, spiking neural networks have been demonstrated to\nperform on par with regular convolutional neural networks. Several works have\nproposed methods to convert a pre-trained CNN to a Spiking CNN without a\nsignificant sacrifice of performance. We demonstrate first that\nquantization-aware training of CNNs leads to better accuracy in SNNs. One of\nthe benefits of converting CNNs to spiking CNNs is to leverage the sparse\ncomputation of SNNs and consequently perform equivalent computation at a lower\nenergy consumption. Here we propose an efficient optimization strategy to train\nspiking networks at lower energy consumption, while maintaining similar\naccuracy levels. We demonstrate results on the MNIST-DVS and CIFAR-10 datasets.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 09:54:57 GMT"}, {"version": "v2", "created": "Mon, 4 May 2020 15:53:25 GMT"}], "update_date": "2020-05-05", "authors_parsed": [["Sorbaro", "Martino", ""], ["Liu", "Qian", ""], ["Bortone", "Massimo", ""], ["Sheik", "Sadique", ""]]}, {"id": "1912.01359", "submitter": "Sidney Pontes-Filho", "authors": "Sidney Pontes-Filho, Annelene Gulden Dahl, Stefano Nichele and Gustavo\n  Borges Moreno e Mello", "title": "A deep learning based tool for automatic brain extraction from\n  functional magnetic resonance images in rodents", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Removing skull artifacts from functional magnetic images (fMRI) is a well\nunderstood and frequently encountered problem. Because the fMRI field has grown\nmostly due to human studies, many new tools were developed to handle human\ndata. Nonetheless, these tools are not equally useful to handle the data\nderived from animal studies, especially from rodents. This represents a major\nproblem to the field because rodent studies generate larger datasets from\nlarger populations, which implies that preprocessing these images manually to\nremove the skull becomes a bottleneck in the data analysis pipeline. In this\nstudy, we address this problem by implementing a neural network based method\nthat uses a U-Net architecture to segment the brain area into a mask and\nremoving the skull and other tissues from the image. We demonstrate several\nstrategies to speed up the process of generating the training dataset using\nwatershedding and several strategies for data augmentation that allowed to\ntrain faster the U-Net to perform the segmentation. Finally, we deployed the\ntrained network freely available.\n", "versions": [{"version": "v1", "created": "Tue, 3 Dec 2019 13:35:03 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 00:11:09 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Pontes-Filho", "Sidney", ""], ["Dahl", "Annelene Gulden", ""], ["Nichele", "Stefano", ""], ["Mello", "Gustavo Borges Moreno e", ""]]}, {"id": "1912.01505", "submitter": "Shu-Chuan Chen", "authors": "Shu-Chuan Chen, Lung-An Li, and Jiping He", "title": "An integrated heterogeneous Poisson model for neuron functions in hand\n  movement during reaching and grasp", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand potential encoding mechanism of motor cortical neurons for\ncontrol commands during reach-to-grasp movements, experiments to record\nneuronal activities from primary motor cortical regions have been conducted in\nmany research laboratories (for example, (7), (17)). The most popular approach\nin neuroscience community is to fit the Analysis of Variance (ANOVA) model\nusing the firing rates of individual neurons. In addition to consider neural\nfiring counts but also temporal intervals, (5) proposed to apply Analysis of\nCovariance (ANCOVA) model. Due to the nature of the data, in this paper we\npropose to apply an integrated method, called heterogeneous Poisson regression\nmodel, to categorize different neural activities. Three scenarios are discussed\nto show that the proposed heterogeneous Poisson regression model can overcome\nsome disadvantages of the traditional Poisson regression model.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 07:30:55 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Chen", "Shu-Chuan", ""], ["Li", "Lung-An", ""], ["He", "Jiping", ""]]}, {"id": "1912.01507", "submitter": "Yao Li", "authors": "Wenjie Li and Yao Li", "title": "Entropy, mutual information, and systematic measures of structured\n  spiking neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to investigate various information-theoretic\nmeasures, including entropy, mutual information, and some systematic measures\nthat based on mutual information, for a class of structured spiking neuronal\nnetwork. In order to analyze and compute these information-theoretic measures\nfor large networks, we coarse-grained the data by ignoring the order of spikes\nthat fall into the same small time bin. The resultant coarse-grained entropy\nmainly capture the information contained in the rhythm produced by a local\npopulation of the network. We first proved that these information theoretical\nmeasures are well-defined and computable by proving the stochastic stability\nand the law of large numbers. Then we use three neuronal network examples, from\nsimple to complex, to investigate these information-theoretic measures. Several\nanalytical and computational results about properties of these\ninformation-theoretic measures are given.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2019 02:31:04 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Li", "Wenjie", ""], ["Li", "Yao", ""]]}, {"id": "1912.02040", "submitter": "Carlos Calvo Tapia", "authors": "Carlos Calvo Tapia, Ivan Tyukin, Valeri A. Makarov", "title": "Universal principles justify the existence of concept cells", "comments": "5 pages, 5 figures, Supplemental Material (+4 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is largely believed that complex cognitive phenomena require the perfect\norchestrated collaboration of many neurons. However, this is not what\nconverging experimental evidence suggests. Single neurons, the so-called\nconcept cells, may be responsible for complex tasks performed by an individual.\nHere, starting from a few first principles, we layout physical foundations\nshowing that concept cells are not only possible but highly likely, given that\nneurons work in a high dimensional space.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 15:06:17 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Tapia", "Carlos Calvo", ""], ["Tyukin", "Ivan", ""], ["Makarov", "Valeri A.", ""]]}, {"id": "1912.02291", "submitter": "Vince Grolmusz", "authors": "Laszlo Keresztes, Evelin Szogi, Balint Varga, Vince Grolmusz", "title": "Identifying Super-Feminine, Super-Masculine and Sex-Defining Connections\n  in the Human Braingraph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For more than a decade now, we can discover and study thousands of cerebral\nconnections with the application of diffusion magnetic resonance imaging (dMRI)\ntechniques and the accompanying algorithmic workflow. While numerous\nconnectomical results were published enlightening the relation between the\nbraingraph and certain biological, medical, and psychological properties, it is\nstill a great challenge to identify a small number of brain connections,\nclosely related to those conditions. In the present contribution, by applying\nthe 1200 Subjects Release of the Human Connectome Project (HCP), we identify\njust 102 connections out of the total number of 1950 connections in the\n83-vertex graphs of 1065 subjects, which -- by a simple linear test --\nprecisely, without any error determine the sex of the subject. Very\nsurprisingly, we were able to identify two graph edges out of these 102, if,\nwhose weights, measured in fiber numbers, are all high, then the connectome\nalways belongs to a female subject, independently of the other edges.\nSimilarly, we have identified 3 edges from these 102, whose weights, if two of\nthem are high and one is low, imply that the graph belongs to a male subject --\nagain, independently of the other edges. We call the former 2 edges\nsuperfeminine and the first two of the 3 edges supermasculine edges of the\nhuman connectome. Even more interestingly, one of the edges, connecting the\nright Pars Triangularis and the right Superior Parietal areas, is one of the 2\nsuperfeminine edges, and it is also the third edge, accompanying the two\nsupermasculine connections, if its weight is low; therefore it is also a\n\"switching\" connection.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2019 22:46:54 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Keresztes", "Laszlo", ""], ["Szogi", "Evelin", ""], ["Varga", "Balint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1912.02331", "submitter": "James Hope Mr", "authors": "James Hope, Narrendar Ravi Chandra, Frederique Vanholsbeeck, Andrew\n  McDaid", "title": "Investigation of ephaptic interactions in peripheral nerve of sheep\n  using 6 kHz subthreshold currents", "comments": "12 pages, 5 figures, journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this work was to determine whether application of\nsubthreshold currents to the peripheral nerve increases the excitability of the\nunderlying nerve fibres, and how this increased excitability would alter neural\nactivity as it propagates through the subthreshold currents. Experiments were\nperformed on two Romney cross-breed sheep in vivo, by applying subthreshold\ncurrents either at the stimulus site or between the stimulus and recording\nsites. Neural recordings were obtained from nerve cuff implanted on the\nperoneal or sciatic nerve branches, while stimulus was applied to either the\nperoneal nerve or pins placed through the lower hindshank. Results showed that\nsubthreshold currents applied to the same site as stimulus increased excitation\nof underlying nerve fibres (p < 0.0001). With stimulus and subthreshold\ncurrents applied to different sites on the peroneal nerve, the primary CAP in\nthe sciatic displayed a temporal shift of -2.5 to -3 us which agreed with\nstatistically significant changes in the CAP waveform (p<0.02). These findings\ncontribute to the understanding of mechanisms in myelinated fibres of\nsubthreshold current neuromodulation therapies.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 01:17:30 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Hope", "James", ""], ["Chandra", "Narrendar Ravi", ""], ["Vanholsbeeck", "Frederique", ""], ["McDaid", "Andrew", ""]]}, {"id": "1912.02723", "submitter": "David Guti\\'errez", "authors": "Myriam Alanis-Espinosa and David Guti\\'errez", "title": "On the assesment of functional connectivity in an immersive\n  brain-computer interface during motor imagery", "comments": "Manuscript under review for Frontiers in Psychology, ID: 491168", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New trends on brain-computer interface (BCI) design are aiming to combine\nthis technology with immersive virtual reality in order to provide a sense of\nrealism to its users. In this study, we propose an experimental BCI to control\nan immersive telepresence system using motor imagery (MI). The system is\nimmersive in the sense that the users can control the movement of a NAO\nhumanoid robot in a first person perspective (1PP), i.e., as if the movement of\nthe robot was his/her own. We analyze functional brain connectivity between 1PP\nand 3PP during the control of our BCI using graph theory properties such as\ndegree, betweenness centrality, and efficiency. Changes in these metrics are\nobtained for the case of the 1PP, as well as for the traditional third person\nperspective (3PP) in which the user can see the movement of the robot as\nfeedback. As proof-of-concept, electroencephalography (EEG) signals were\nrecorded from two subjects while they performed MI to control the movement of\nthe robot. The graph theoretical analysis was applied to the binary directed\nnetworks obtained through the partial directed coherence (PDC). In our\npreliminary assessment we found that the efficiency in the alpha brain rhythm\nis greater in 1PP condition in comparison to the 3PP at the prefrontal cortex.\nAlso, a stronger influence of signals measured at EEG channel C3 (primary motor\ncortex) to other regions was found in 1PP condition. Furthermore, our\npreliminary results seem to indicate that alpha and beta brain rhythms have a\nhigh indegree at prefrontal cortex in 1PP condition, and this could be possibly\nrelated to the experience of sense of agency. Therefore, using the PDC combined\nwith graph theory while controlling a telepresence robot in an immersive system\nmay contribute to understand the organization and behavior of brain networks in\nthese environments.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 16:58:21 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Alanis-Espinosa", "Myriam", ""], ["Guti\u00e9rrez", "David", ""]]}, {"id": "1912.02745", "submitter": "Fabrizio De Vico Fallani", "authors": "Tiziana Cattai, Stefania Colonnese, Marie-Constance Corsi, Danielle S.\n  Bassett, Gaetano Scarano, Fabrizio De Vico Fallani", "title": "Phase/amplitude synchronization of brain signals during motor imagery\n  BCI tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extraction of brain functioning features is a crucial step in the\ndefinition of brain-computer interfaces (BCIs). In the last decade, functional\nconnectivity (FC) estimators have been increasingly explored based on their\nability to capture synchronization between multivariate brain signals. However,\nthe underlying neurophysiological mechanisms and the extent to which they can\nimprove performance in BCI-related tasks, is still poorly understood. To\naddress this gap in knowledge, we considered a group of 20 healthy subjects\nduring an EEG-based hand motor imagery (MI) task. We studied two\nwell-established FC estimators, i.e. spectral- and imaginary-coherence, and\ninvestigated how they were modulated by the MI task. We characterized the\nresulting FC networks by extracting the strength of connectivity of each EEG\nsensor and compared the discriminant power with respect to standard power\nspectrum features. At the group level, results showed that while\nspectral-coherence based network features were increasing the controlateral\nmotor area, those based on imaginary-coherence were decreasing. We demonstrated\nthat this opposite, but complementary, behavior was respectively determined by\nthe increase in amplitude and phase synchronization between the brain signals.\nAt the individual level, we proved that including these network connectivity\nfeatures in the classification of MI mental states led to an overall\nimprovement in accuracy. Taken together, our results provide fresh insights\ninto the oscillatory mechanisms subserving brain network changes during MI and\noffer new perspectives to improve BCI performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 17:33:12 GMT"}], "update_date": "2019-12-06", "authors_parsed": [["Cattai", "Tiziana", ""], ["Colonnese", "Stefania", ""], ["Corsi", "Marie-Constance", ""], ["Bassett", "Danielle S.", ""], ["Scarano", "Gaetano", ""], ["Fallani", "Fabrizio De Vico", ""]]}, {"id": "1912.02899", "submitter": "Kamen Atanasov Tsvetanov Dr", "authors": "Kamen A. Tsvetanov, Richard N.A. Henson and James B. Rowe", "title": "Separating vascular and neuronal effects of age on fMRI BOLD signals", "comments": "57 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Accurate identification of brain function is necessary to understand the\nneurobiology of cognitive ageing, and thereby promote well-being across the\nlifespan. A common tool used to investigate neurocognitive ageing is functional\nmagnetic resonance imaging (fMRI). However, although fMRI data are often\ninterpreted in terms of neuronal activity, the blood-oxygen-level-dependent\n(BOLD) signal measured by fMRI includes contributions of both vascular and\nneuronal factors, which change differentially with age. While some studies\ninvestigate vascular ageing factors, the results of these studies are not well\nknown within the field of neurocognitive ageing and therefore vascular\nconfounds in neurocognitive fMRI studies are common. In contrast to over 10,000\nBOLD-fMRI papers on ageing, fewer than 20 have applied techniques to correct\nfor vascular effects. However, neurovascular ageing is not only a confound in\nfMRI, but an important feature in its own right, to be assessed alongside\nmeasures of neuronal ageing. We review current approaches to dissociate\nneuronal and vascular components of BOLD-fMRI of regional activity and\nfunctional connectivity. We highlight emerging evidence that vascular\nmechanisms in the brain do not simply control blood flow to support the\nmetabolic needs of neurons, but form complex neurovascular interactions that\ninfluence neuronal function in health and disease.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 22:03:49 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 21:47:42 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Tsvetanov", "Kamen A.", ""], ["Henson", "Richard N. A.", ""], ["Rowe", "James B.", ""]]}, {"id": "1912.02901", "submitter": "Yufen Chen", "authors": "Yufen Chen, Amy A Herrold, Zoran Martinovich, Anne J Blood, Nicole\n  Vike, Alexa E Walter, Jaroslaw Harezlak, Peter H Seidenberg, Manish Bhomia,\n  Barbara Knollmann-Ritschel, James L Reilly, Eric A Nauman, Thomas M Talavage,\n  Linda Papa, Semyon Slobounov, Hans C Breiter (for the Concussion Neuroimaging\n  Consortium)", "title": "Brain perfusion mediates the relationship between miRNA levels and\n  postural control", "comments": "32 pages, 2 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcriptomics, regional cerebral blood flow (rCBF), and a spatial motor\nvirtual reality task were integrated using mediation analysis in a novel\ndemonstration of \"imaging omics\". Data collected in NCAA Division I football\nathletes cleared for play before in-season training showed significant\nrelationships in a) elevated levels of miR-30d and miR-92a to elevated putamen\nrCBF, (b) elevated putamen rCBF to compromised balance scores, and (c)\ncompromised balance scores to elevated miRNA levels. rCBF acted as a mediator\nvariable (minimum 70% mediation, significant Sobel's test) between abnormal\nmiRNA levels and compromised balance scores. Given the involvement of these\nmiRNAs in inflammation and immune function, and that vascular perfusion is a\ncomponent of the inflammatory response, these findings support a chronic\ninflammatory model of repetitive head acceleration events (HAEs). rCBF, a\nsystems biology measure, was necessary for miRNA to affect behavior. These\nresults suggest miRNA as a potential diagnostic biomarker for repetitive HAEs.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2019 22:16:54 GMT"}], "update_date": "2019-12-09", "authors_parsed": [["Chen", "Yufen", "", "for the Concussion Neuroimaging\n  Consortium"], ["Herrold", "Amy A", "", "for the Concussion Neuroimaging\n  Consortium"], ["Martinovich", "Zoran", "", "for the Concussion Neuroimaging\n  Consortium"], ["Blood", "Anne J", "", "for the Concussion Neuroimaging\n  Consortium"], ["Vike", "Nicole", "", "for the Concussion Neuroimaging\n  Consortium"], ["Walter", "Alexa E", "", "for the Concussion Neuroimaging\n  Consortium"], ["Harezlak", "Jaroslaw", "", "for the Concussion Neuroimaging\n  Consortium"], ["Seidenberg", "Peter H", "", "for the Concussion Neuroimaging\n  Consortium"], ["Bhomia", "Manish", "", "for the Concussion Neuroimaging\n  Consortium"], ["Knollmann-Ritschel", "Barbara", "", "for the Concussion Neuroimaging\n  Consortium"], ["Reilly", "James L", "", "for the Concussion Neuroimaging\n  Consortium"], ["Nauman", "Eric A", "", "for the Concussion Neuroimaging\n  Consortium"], ["Talavage", "Thomas M", "", "for the Concussion Neuroimaging\n  Consortium"], ["Papa", "Linda", "", "for the Concussion Neuroimaging\n  Consortium"], ["Slobounov", "Semyon", "", "for the Concussion Neuroimaging\n  Consortium"], ["Breiter", "Hans C", "", "for the Concussion Neuroimaging\n  Consortium"]]}, {"id": "1912.03934", "submitter": "Lionel Gil", "authors": "Dora Matzakos-Karvouniari, Bruno Cessac and L. Gil", "title": "Noise driven broadening of the neural synchronisation transition in\n  stage II retinal waves", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on a biophysical model of retinal Starburst Amacrine Cell (SAC)\n\\cite{karvouniari-gil-etal:19} we analyse here the dynamics of retinal waves,\narising during the visual system development. Waves are induced by spontaneous\nbursting of SACs and their coupling via acetycholine. We show that, despite the\nacetylcholine coupling intensity has been experimentally observed to change\nduring development \\cite{zheng-lee-etal:04}, SACs retinal waves can\nnevertheless stay in a regime with power law distributions, reminiscent of a\ncritical regime. Thus, this regime occurs on a range of coupling parameters\ninstead of a single point as in usual phase transitions. We explain this\nphenomenon thanks to a coherence-resonance mechanism, where noise is\nresponsible for the broadening of the critical coupling strength range.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 09:58:51 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Matzakos-Karvouniari", "Dora", ""], ["Cessac", "Bruno", ""], ["Gil", "L.", ""]]}, {"id": "1912.04083", "submitter": "Dr. Alexander Paraskevov", "authors": "A.V. Paraskevov, T.S. Zemskova", "title": "Analytical solution of linearized equations of the Morris-Lecar neuron\n  model at large constant stimulation", "comments": "12 pages, 5 Figures (including 2 supplementary ones). Supplementary\n  Material contains two supplementary Figures, MATLAB scripts, and generated\n  data used for Figures", "journal-ref": "Phys. Lett. A 402, 127379 (2021)", "doi": "10.1016/j.physleta.2021.127379", "report-no": null, "categories": "q-bio.NC math.DS physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical biophysical Morris-Lecar model of neuronal excitability\npredicts that upon stimulation of the neuron with a sufficiently large constant\ndepolarizing current there exists a finite interval of the current values where\nperiodic spike generation occurs. Above the upper boundary of this interval,\nthere is four-stage damping of the spike amplitude: 1) minor primary damping,\nwhich reflects a typical transient to stationary dynamic state, 2) plateau of\nnearly undamped periodic oscillations, 3) strong damping, and 4) reaching a\nconstant asymptotic value of the neuron potential. We have shown that in the\nvicinity of the asymptote the Morris-Lecar equations can be reduced to the\nstandard equation for exponentially damped harmonic oscillations. Importantly,\nall coefficients of this equation can be explicitly expressed through\nparameters of the original Morris-Lecar model, enabling direct comparison of\nthe numerical and analytical solutions for the neuron potential dynamics at\nlater stages of the spike amplitude damping.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 14:37:09 GMT"}, {"version": "v2", "created": "Wed, 25 Dec 2019 15:42:39 GMT"}, {"version": "v3", "created": "Wed, 5 Feb 2020 09:44:38 GMT"}, {"version": "v4", "created": "Thu, 1 Apr 2021 00:44:04 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Paraskevov", "A. V.", ""], ["Zemskova", "T. S.", ""]]}, {"id": "1912.04116", "submitter": "Cailey Kerley", "authors": "Cailey I. Kerley, Kurt G. Schilling, Justin Blaber, Beth Miller, Allen\n  Newton, Adam W. Anderson, Bennett A. Landman, and Tonia S. Rex", "title": "MRI correlates of chronic symptoms in mild traumatic brain injury", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Veterans with mild traumatic brain injury (mTBI) have reported auditory and\nvisual dysfunction that persists beyond the acute incident. The etiology behind\nthese symptoms is difficult to characterize with current clinical imaging.\nThese functional deficits may be caused by shear injury or micro-bleeds, which\ncan be detected with special imaging modalities. We explore these hypotheses in\na pilot study of multi-parametric MRI. We extract over 1,000 imaging and\nclinical metrics and project them to a low-dimensional space, where we can\ndiscriminate between healthy controls and patients with mTBI. We also show\ncorrelations between the metric representations and patient symptoms.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2019 17:30:51 GMT"}, {"version": "v2", "created": "Mon, 22 Jun 2020 20:46:06 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Kerley", "Cailey I.", ""], ["Schilling", "Kurt G.", ""], ["Blaber", "Justin", ""], ["Miller", "Beth", ""], ["Newton", "Allen", ""], ["Anderson", "Adam W.", ""], ["Landman", "Bennett A.", ""], ["Rex", "Tonia S.", ""]]}, {"id": "1912.04246", "submitter": "Santosh Manicka", "authors": "Santosh Manicka and Michael Levin", "title": "Modeling somatic computation with non-neural bioelectric networks", "comments": "30 pages, 8 figures in main article", "journal-ref": "Sci Rep 9, 18612 (2019)", "doi": "10.1038/s41598-019-54859-8", "report-no": null, "categories": "q-bio.NC cs.NE nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The field of basal cognition seeks to understand how adaptive,\ncontext-specific behavior occurs in non-neural biological systems.\nEmbryogenesis and regeneration require plasticity in many tissue types to\nachieve structural and functional goals in diverse circumstances. Thus,\nadvances in both evolutionary cell biology and regenerative medicine require an\nunderstanding of how non-neural tissues could process information. Neurons\nevolved from ancient cell types that used bioelectric signaling to perform\ncomputation. However, it has not been shown whether or how non-neural\nbioelectric cell networks can support computation. We generalize connectionist\nmethods to non-neural tissue architectures, showing that a minimal non-neural\nBio-Electric Network (BEN) model that utilizes the general principles of\nbioelectricity (electrodiffusion and gating) can compute. We characterize BEN\nbehaviors ranging from elementary logic gates to pattern detectors, using both\nfixed and transient inputs to recapitulate various biological scenarios. We\ncharacterize the mechanisms of such networks using dynamical-systems and\ninformation-theory tools, demonstrating that logic can manifest in\nbidirectional, continuous, and relatively slow bioelectrical systems,\ncomplementing conventional neural-centric architectures. Our results reveal a\nvariety of non-neural decision-making processes as manifestations of general\ncellular biophysical mechanisms and suggest novel bioengineering approaches to\nconstruct functional tissues for regenerative medicine and synthetic biology as\nwell as new machine learning architectures.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 18:36:14 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Manicka", "Santosh", ""], ["Levin", "Michael", ""]]}, {"id": "1912.04635", "submitter": "Alessandro Betti", "authors": "Alessandro Betti and Marco Gori", "title": "Backprop Diffusion is Biologically Plausible", "comments": "9 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:1907.05106", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Backpropagation algorithm relies on the abstraction of using a neural\nmodel that gets rid of the notion of time, since the input is mapped\ninstantaneously to the output. In this paper, we claim that this abstraction of\nignoring time, along with the abrupt input changes that occur when feeding the\ntraining set, are in fact the reasons why, in some papers, Backprop biological\nplausibility is regarded as an arguable issue. We show that as soon as a deep\nfeedforward network operates with neurons with time-delayed response, the\nbackprop weight update turns out to be the basic equation of a biologically\nplausible diffusion process based on forward-backward waves. We also show that\nsuch a process very well approximates the gradient for inputs that are not too\nfast with respect to the depth of the network. These remarks somewhat disclose\nthe diffusion process behind the backprop equation and leads us to interpret\nthe corresponding algorithm as a degeneration of a more general diffusion\nprocess that takes place also in neural networks with cyclic connections.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 10:50:15 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2020 10:04:48 GMT"}], "update_date": "2020-06-19", "authors_parsed": [["Betti", "Alessandro", ""], ["Gori", "Marco", ""]]}, {"id": "1912.04823", "submitter": "Ata Ak{\\i}n", "authors": "Ipek Ustun, Ege Ozer, Erim Habib, Burcin Tatliesme, Ata Akin", "title": "Vigilance Overload Measured by Computerized Mackworth Clock Test", "comments": "4 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studied the change of vigilance based on stimulus coming\nconsecutively using the computerized version of the Mackworth Clock Test run\nfrom PsyToolkit website. 7 participants (16.57 +/-1 years old, 2 males),\nperformed 10 consecutive trials in order to measure whether or not it is a\nrealistic goal for high school students to display the level of vigilance\nexpected from them in class. Success percentages were calculated by dividing\nthe number of correct jumps to the total number of jumps. The results indicated\nthat while the average success percentage for all subjects remained relatively\nstable over the 10 trials (79% +/-7%), success percentages drop relatively as\nthe number of jumps increase. Success rate dropped from 90% (2 jumps) to 70% (7\njumps). We conclude that there is an upper limit of vigilance that should be\nexpected from students when they are exposed to more than 4 randomly occurring\nattention requiring task within a minute.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2019 12:33:25 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Ustun", "Ipek", ""], ["Ozer", "Ege", ""], ["Habib", "Erim", ""], ["Tatliesme", "Burcin", ""], ["Akin", "Ata", ""]]}, {"id": "1912.04828", "submitter": "Behnam Reyhani-Masoleh", "authors": "Behnam Reyhani-Masoleh (1 and 2) and Tom Chau (1 and 2) ((1) Bloorview\n  Research Institute, Holland Bloorview Kids Rehabilitation Hospital, Toronto,\n  (2) Institute of Biomaterials and Biomedical Engineering, University of\n  Toronto)", "title": "Navigating in Virtual Reality using Thought: The Development and\n  Assessment of a Motor Imagery based Brain-Computer Interface", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interface (BCI) systems have potential as assistive\ntechnologies for individuals with severe motor impairments. Nevertheless,\nindividuals must first participate in many training sessions to obtain adequate\ndata for optimizing the classification algorithm and subsequently acquiring\nbrain-based control. Such traditional training paradigms have been dubbed\nunengaging and unmotivating for users. In recent years, it has been shown that\nthe synergy of virtual reality (VR) and a BCI can lead to increased user\nengagement. This study created a 3-class BCI with a rather elaborate EEG signal\nprocessing pipeline that heavily utilizes machine learning. The BCI initially\npresented sham feedback but was eventually driven by EEG associated with motor\nimagery. The BCI tasks consisted of motor imagery of the feet and left and\nright hands, which were used to navigate a single-path maze in VR. Ten of the\neleven recruited participants achieved online performance superior to chance (p\n< 0.01), while the majority successfully completed more than 70% of the\nprescribed navigational tasks. These results indicate that the proposed\nparadigm warrants further consideration as neurofeedback BCI training tool. A\nparadigm that allows users, from their perspective, control from the outset\nwithout the need for prior data collection sessions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 17:14:34 GMT"}], "update_date": "2019-12-11", "authors_parsed": [["Reyhani-Masoleh", "Behnam", "", "1 and 2"], ["Chau", "Tom", "", "1 and 2"]]}, {"id": "1912.04975", "submitter": "Ahmad Mayeli", "authors": "Ahmad Mayeli, Obada Al Zoubi, Masaya Misaki, Jennifer L. Stewart,\n  Vadim Zotev, Qingfei Luo, Raquel Phillips, Stefan Fischer, Marcus Goetz,\n  Martin P. Paulus, Hazem Refai, and Jerzy Bodurka", "title": "Integration of Simultaneous Resting-State Electroencephalography,\n  Functional Magnetic Resonance Imaging, and Eye-Tracker Methods to Determine\n  and Verify Electroencephalography Vigilance Measure", "comments": null, "journal-ref": "Brain Connectivity 10.10 (2020): 535-546", "doi": "10.1089/brain.2019.0731", "report-no": null, "categories": "eess.SP physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background/Introduction: Concurrent electroencephalography and resting-state\nfunctional magnetic resonance imaging (rsfMRI) have been widely used for\nstudying the (presumably) awake and alert human brain with high\ntemporal/spatial resolution. Although rsfMRI scans are typically collected\nwhile individuals are instructed to focus their eyes on a fixated cross,\nobjective and verified experimental measures to quantify degree of vigilance\nare not readily available. Electroencephalography (EEG) is the modality\nextensively used for estimating vigilance, especially during eyes-closed\nresting state. However, pupil size measured using an eye-tracker device could\nprovide an indirect index of vigilance. Methods: Three 12-min resting scans\n(eyes open, fixating on the cross) were collected from 10 healthy control\nparticipants. We simultaneously collected EEG, fMRI, physiological, and\neye-tracker data and investigated the correlation between EEG features, pupil\nsize, and heart rate. Furthermore, we used pupil size and EEG features as\nregressors to find their correlations with blood-oxygen-level-dependent fMRI\nmeasures. Results: EEG frontal and occipital beta power (FOBP) correlates with\npupil size changes, an indirect index for locus coeruleus activity implicated\nin vigilance regulation (r = 0.306, p < 0.001). Moreover, FOBP also correlated\nwith heart rate (r = 0.255, p < 0.001), as well as several brain regions in the\nanticorrelated network, including the bilateral insula and inferior parietal\nlobule. Discussion: In this study, we investigated whether simultaneous\nEEG-fMRI combined with eye-tracker measurements can be used to determine EEG\nsignal feature associated with vigilance measures during eyes-open rsfMRI. Our\nresults support the conclusion that FOBP is an objective measure of vigilance\nin healthy human subjects.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 20:52:26 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 03:45:08 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Mayeli", "Ahmad", ""], ["Zoubi", "Obada Al", ""], ["Misaki", "Masaya", ""], ["Stewart", "Jennifer L.", ""], ["Zotev", "Vadim", ""], ["Luo", "Qingfei", ""], ["Phillips", "Raquel", ""], ["Fischer", "Stefan", ""], ["Goetz", "Marcus", ""], ["Paulus", "Martin P.", ""], ["Refai", "Hazem", ""], ["Bodurka", "Jerzy", ""]]}, {"id": "1912.05050", "submitter": "Hideaki Yamamoto PhD", "authors": "Takuma Sumi, Hideaki Yamamoto, Ayumi Hirano-Iwata", "title": "Suppression of hypersynchronous network activity in cultured cortical\n  neurons using an ultrasoft silicone scaffold", "comments": "23 pages, 6 figures", "journal-ref": "Soft Matter 16 (2020) 3195-3202", "doi": "10.1039/C9SM02432H", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spontaneous activity pattern of cortical neurons in dissociated culture\nis characterized by burst firing that is highly synchronized among a wide\npopulation of cells. The degree of synchrony, however, is excessively higher\nthan that in cortical tissues. Here, we employed polydimethylsiloxane (PDMS)\nelastomers to establish a novel system for culturing neurons on a scaffold with\nan elastic modulus resembling brain tissue, and investigated the effect of the\nscaffold's elasticity on network activity patterns in cultured rat cortical\nneurons. Using whole-cell patch clamp to assess the scaffold effect on the\ndevelopment of synaptic connections, we found that the amplitude of excitatory\npostsynaptic current, as well as the frequency of spontaneous transmissions,\nwas reduced in neuronal networks grown on an ultrasoft PDMS with an elastic\nmodulus of 0.5 kPa. Furthermore, the ultrasoft scaffold was found to suppress\nneural correlations in the spontaneous activity of the cultured neuronal\nnetwork. The dose of GsMTx-4, an antagonist of stretch-activated cation\nchannels (SACs), required to reduce the generation of the events below 1.0\nevent/min on PDMS substrates was lower than that for neurons on a glass\nsubstrate. This suggests that the difference in the baseline level of SAC\nactivation is a molecular mechanism underlying the alteration in neuronal\nnetwork activity depending on scaffold stiffness. Our results demonstrate the\npotential application of PDMS with biomimetic elasticity as cell-culture\nscaffold for bridging the in vivo-in vitro gap in neuronal systems.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 23:49:31 GMT"}], "update_date": "2020-06-12", "authors_parsed": [["Sumi", "Takuma", ""], ["Yamamoto", "Hideaki", ""], ["Hirano-Iwata", "Ayumi", ""]]}, {"id": "1912.05433", "submitter": "Tiberiu Tesileanu", "authors": "Tiberiu Tesileanu, Mary M. Conte, John J. Briguglio, Ann M.\n  Hermundstad, Jonathan D. Victor, Vijay Balasubramanian", "title": "Efficient coding of natural scene statistics predicts discrimination\n  thresholds for grayscale textures", "comments": "33 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Previously, in (Hermundstad et al., 2014), we showed that when sampling is\nlimiting, the efficient coding principle leads to a \"variance is salience\"\nhypothesis, and that this hypothesis accounts for visual sensitivity to binary\nimage statistics. Here, using extensive new psychophysical data and image\nanalysis, we show that this hypothesis accounts for visual sensitivity to a\nlarge set of grayscale image statistics at a striking level of detail, and also\nidentify the limits of the prediction. We define a 66-dimensional space of\nlocal grayscale light-intensity correlations, and measure the relevance of each\ndirection to natural scenes. The \"variance is salience\" hypothesis predicts\nthat two-point correlations are most salient, and predicts their relative\nsalience. We tested these predictions in a texture-segregation task using\nun-natural, synthetic textures. As predicted, correlations beyond second order\nare not salient, and predicted thresholds for over 300 second-order\ncorrelations match psychophysical thresholds closely (median fractional error\n<0.13).\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 16:41:27 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2020 19:39:24 GMT"}], "update_date": "2020-07-14", "authors_parsed": [["Tesileanu", "Tiberiu", ""], ["Conte", "Mary M.", ""], ["Briguglio", "John J.", ""], ["Hermundstad", "Ann M.", ""], ["Victor", "Jonathan D.", ""], ["Balasubramanian", "Vijay", ""]]}, {"id": "1912.05595", "submitter": "Sourish Chakravarty", "authors": "Sourish Chakravarty, Zachary D. Threlkeld, Yelena G. Bodien, Brian L.\n  Edlow, Emery N. Brown", "title": "A state-space model for dynamic functional connectivity", "comments": "Presented in 53rd Annual Asilomar Conference on Signals, Systems, and\n  Computers, Pacific Grove, CA", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic functional connectivity (DFC) analysis involves measuring correlated\nneural activity over time across multiple brain regions. Significant regional\ncorrelations among neural signals, such as those obtained from resting-state\nfunctional magnetic resonance imaging (fMRI), may represent neural circuits\nassociated with rest. The conventional approach of estimating the correlation\ndynamics as a sequence of static correlations from sliding time-windows has\nstatistical limitations. To address this issue, we propose a multivariate\nstochastic volatility model for estimating DFC inspired by recent work in\neconometrics research. This model assumes a state-space framework where the\ncorrelation dynamics of a multivariate normal observation sequence is governed\nby a positive-definite matrix-variate latent process. Using this statistical\nmodel within a sequential Bayesian estimation framework, we use blood\noxygenation level dependent activity from multiple brain regions to estimate\nposterior distributions on the correlation trajectory. We demonstrate the\nutility of this DFC estimation framework by analyzing its performance on\nsimulated data, and by estimating correlation dynamics in resting state fMRI\ndata from a patient with a disorder of consciousness (DoC). Our work advances\nthe state-of-the-art in DFC analysis and its principled use in DoC biomarker\nexploration.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2019 20:01:45 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Chakravarty", "Sourish", ""], ["Threlkeld", "Zachary D.", ""], ["Bodien", "Yelena G.", ""], ["Edlow", "Brian L.", ""], ["Brown", "Emery N.", ""]]}, {"id": "1912.05841", "submitter": "Prajna Upadhyaya", "authors": "Prajna Upadhyaya and Tohru Yagi", "title": "Modified Computation of Correlation Integral for Analyzing Epileptic\n  Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Epilepsy is a chronic neurological disorder characterized by recurrent\nseizures. One method for analyzing seizure activity is to compute the\ncorrelation dimension of time-series electroencephalographic signals. The\nGrasserberg and Proccacia algorithm is commonly used to compute this\ncorrelation dimension. The algorithm uses the Heaviside function to determine\nthe correlation integral by counting the number of distances between vectors\n(d_ij) that are greater than a threshold. However, information about the\nchaotic nature of the signal is not completely retained by this function. In\nthis work, instead of using the Heaviside function, we calculated the\ncorrelation integral by using an exponential function of d_ij. Greater\nsensitivity to the interictal and ictal signals using this modified algorithm\nwas verified using three datasets. Comparing heatmaps of d_ij obtained using\nthe original and modified methods showed additional information that was\nretained with the new algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 09:13:50 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Upadhyaya", "Prajna", ""], ["Yagi", "Tohru", ""]]}, {"id": "1912.05869", "submitter": "Dorothea Kolossa", "authors": "Ahmed Hussen Abdelaziz, Shuo-Yiin Chang, Nelson Morgan, Erik Edwards,\n  Dorothea Kolossa, Dan Ellis, David A. Moses, Edward F. Chang", "title": "On Neural Phone Recognition of Mixed-Source ECoG Signals", "comments": "5 pages, showing algorithms, results and references from our\n  collaboration during a 2017 postdoc stay of the first author", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.NE cs.SD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging field of neural speech recognition (NSR) using\nelectrocorticography has recently attracted remarkable research interest for\nstudying how human brains recognize speech in quiet and noisy surroundings. In\nthis study, we demonstrate the utility of NSR systems to objectively prove the\nability of human beings to attend to a single speech source while suppressing\nthe interfering signals in a simulated cocktail party scenario. The\nexperimental results show that the relative degradation of the NSR system\nperformance when tested in a mixed-source scenario is significantly lower than\nthat of automatic speech recognition (ASR). In this paper, we have\nsignificantly enhanced the performance of our recently published framework by\nusing manual alignments for initialization instead of the flat start technique.\nWe have also improved the NSR system performance by accounting for the possible\ntranscription mismatch between the acoustic and neural signals.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 10:37:22 GMT"}], "update_date": "2019-12-13", "authors_parsed": [["Abdelaziz", "Ahmed Hussen", ""], ["Chang", "Shuo-Yiin", ""], ["Morgan", "Nelson", ""], ["Edwards", "Erik", ""], ["Kolossa", "Dorothea", ""], ["Ellis", "Dan", ""], ["Moses", "David A.", ""], ["Chang", "Edward F.", ""]]}, {"id": "1912.06018", "submitter": "Geza Odor", "authors": "G\\'eza \\'Odor, Jeffrey Kelling, Gustavo Deco", "title": "The effect of noise on the synchronization dynamics of the Kuramoto\n  model on a large human connectome graph", "comments": "26 pages, 11 figures, accepted version in J. Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cond-mat.dis-nn cond-mat.stat-mech physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have extended the study of the Kuramoto model with additive Gaussian noise\nrunning on the KKI-18 large human connectome graph. We determined the dynamical\nbehavior of this model by solving it numerically in an assumed homeostatic\nstate, below the synchronization crossover point we determined previously. The\nde-synchronization duration distributions exhibit power-law tails,\ncharacterized by the exponent in the range $1.1 < \\tau_t < 2$, overlapping the\nin vivo human brain activity experiments by Palva et al. We show that these\nscaling results remain valid, by a transformation of the ultra-slow\neigen-frequencies to Gaussian with unit variance. We also compare the\nconnectome results with those, obtained on a regular cube with $N=10^6$ nodes,\nrelated to the embedding space, and show that the quenched internal frequencies\nthemselves can cause frustrated synchronization scaling in an extended coupling\nspace.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2019 14:15:20 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 13:33:59 GMT"}, {"version": "v3", "created": "Sat, 11 Apr 2020 17:36:12 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["\u00d3dor", "G\u00e9za", ""], ["Kelling", "Jeffrey", ""], ["Deco", "Gustavo", ""]]}, {"id": "1912.06207", "submitter": "Hidenori Tanaka", "authors": "Hidenori Tanaka, Aran Nayebi, Niru Maheswaranathan, Lane McIntosh,\n  Stephen A. Baccus, Surya Ganguli", "title": "From deep learning to mechanistic understanding in neuroscience: the\n  structure of retinal prediction", "comments": null, "journal-ref": "Neural Information Processing Systems (NeurIPS), 2019", "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep feedforward neural networks have achieved considerable success\nin modeling biological sensory processing, in terms of reproducing the\ninput-output map of sensory neurons. However, such models raise profound\nquestions about the very nature of explanation in neuroscience. Are we simply\nreplacing one complex system (a biological circuit) with another (a deep\nnetwork), without understanding either? Moreover, beyond neural\nrepresentations, are the deep network's computational mechanisms for generating\nneural responses the same as those in the brain? Without a systematic approach\nto extracting and understanding computational mechanisms from deep neural\nnetwork models, it can be difficult both to assess the degree of utility of\ndeep learning approaches in neuroscience, and to extract experimentally\ntestable hypotheses from deep networks. We develop such a systematic approach\nby combining dimensionality reduction and modern attribution methods for\ndetermining the relative importance of interneurons for specific visual\ncomputations. We apply this approach to deep network models of the retina,\nrevealing a conceptual understanding of how the retina acts as a predictive\nfeature extractor that signals deviations from expectations for diverse\nspatiotemporal stimuli. For each stimulus, our extracted computational\nmechanisms are consistent with prior scientific literature, and in one case\nyields a new mechanistic hypothesis. Thus overall, this work not only yields\ninsights into the computational mechanisms underlying the striking predictive\ncapabilities of the retina, but also places the framework of deep networks as\nneuroscientific models on firmer theoretical foundations, by providing a new\nroadmap to go beyond comparing neural representations to extracting and\nunderstand computational mechanisms.\n", "versions": [{"version": "v1", "created": "Thu, 12 Dec 2019 20:54:08 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Tanaka", "Hidenori", ""], ["Nayebi", "Aran", ""], ["Maheswaranathan", "Niru", ""], ["McIntosh", "Lane", ""], ["Baccus", "Stephen A.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1912.06403", "submitter": "Gweneth Andersen", "authors": "Gweneth Andersen", "title": "Tracking the Effects of Cancer on Microtubule Dynamic Instability", "comments": "10 pages, 10 figures (non-original) Withdrawn due to insufficiency of\n  background", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph physics.bio-ph q-bio.NC q-bio.SC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic instability in the cytoskeleton underlies a great many vital cellular\nprocesses. In neurons, it is thought to play a role in information processing\nand the establishment of synaptic connections. It is from this interneuronal\nconnectivity that the large-scale organization and function of the brain\nultimately emerges. While brain networks above the cellular scale have been\nextensively investigated with medical imaging, no research has yet examined the\ncontribution of the dynamic architecture subserving the components of these\nnetworks to their functionality. Simultaneous functional imaging at molecular\nand whole-brain scales may yield more comprehensive knowledge of this\nentailment. Procedures of statistical analysis based on a recently developed\nnonlinear model of microtubule dynamics are proposed to verify predictions\nabout the spatiotemporal relationships between various microtubule-associated\nprotein activities and functional connectivity. Known effects of brain cancer\non functional connectivity and peritumoral complexity serve as the basis for a\ncomparative study of these phenomena in regions of interest with particularly\nhigh and low complexity.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 10:52:20 GMT"}, {"version": "v2", "created": "Tue, 17 Dec 2019 20:05:48 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Andersen", "Gweneth", ""]]}, {"id": "1912.06610", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley, Adam Reeves", "title": "Correlated Effects of Relative Size and Depth in the Perceptual\n  Organization of Multiple Figure-Ground Configurations", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural networks of the human visual brain derive representations of\nthree-dimensional structure from specific two-dimensional image cues. Neural\nmodels backed by psychophysical data predict how local differences in either\nluminance contrast or physical size of local boundaries in 2D images may\ndetermine the perception of 3D properties. Predictions relative to the role of\ncolor in this process do not follow from any of the current models. To further\nclarify the potential contribution of color to perceptual organization, image\nconfigurations with multiple surface representations where the relative\nphysical size of local boundaries between contrast regions was held constant\nwere submitted to perceptual judgments of relative size and relative depth. The\nonly potential cues available in the images were generated by the specific\nlocal combinations of color and luminance contrast. It is shown that response\nprobabilities for subjective depth and subjective size are systematically and\nconsistently determined by local surface colors and their immediate\nbackgrounds. There is a statistically significant correlation between\nsubjective depth and subjective size, and a color specific effect on both\ndependent variables. This effect depends on the polarity of the immediate\nsurround of the reference surface rather than on local center-surround contrast\nintensity. It is suggested that the underlying neural mechanisms selectively\nexploit specific color and background cues to enable intrinsically coherent\nperceptual organization of ambiguous image input.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 17:18:16 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Dresp-Langley", "Birgitta", ""], ["Reeves", "Adam", ""]]}, {"id": "1912.06615", "submitter": "Andrew Glennerster", "authors": "Alex Muryy, N. Siddharth, Nantas Nardelli, Philip H. S. Torr, Andrew\n  Glennerster", "title": "Lessons from reinforcement learning for biological representations of\n  space", "comments": "40 pages including Appendix, 6 figures plus 3 figures in Appendix.\n  Accepted for publication in Vision Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neuroscientists postulate 3D representations in the brain in a variety of\ndifferent coordinate frames (e.g. 'head-centred', 'hand-centred' and\n'world-based'). Recent advances in reinforcement learning demonstrate a quite\ndifferent approach that may provide a more promising model for biological\nrepresentations underlying spatial perception and navigation. In this paper, we\nfocus on reinforcement learning methods that reward an agent for arriving at a\ntarget image without any attempt to build up a 3D 'map'. We test the ability of\nthis type of representation to support geometrically consistent spatial tasks\nsuch as interpolating between learned locations using decoding of feature\nvectors. We introduce a hand-crafted representation that has, by design, a high\ndegree of geometric consistency and demonstrate that, in this case, information\nabout the persistence of features as the camera translates (e.g. distant\nfeatures persist) can improve performance on the geometric tasks. These\nexamples avoid Cartesian (in this case, 2D) representations of space.\nNon-Cartesian, learned representations provide an important stimulus in\nneuroscience to the search for alternatives to a 'cognitive map'.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 17:26:34 GMT"}, {"version": "v2", "created": "Thu, 28 May 2020 09:35:46 GMT"}, {"version": "v3", "created": "Mon, 6 Jul 2020 13:20:41 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Muryy", "Alex", ""], ["Siddharth", "N.", ""], ["Nardelli", "Nantas", ""], ["Torr", "Philip H. S.", ""], ["Glennerster", "Andrew", ""]]}, {"id": "1912.06686", "submitter": "Claas Flint", "authors": "Claas Flint, Micah Cearns, Nils Opel, Ronny Redlich, David M. A.\n  Mehler, Daniel Emden, Nils R. Winter, Ramona Leenings, Simon B. Eickhoff,\n  Tilo Kircher, Axel Krug, Igor Nenadic, Volker Arolt, Scott Clark, Bernhard T.\n  Baune, Xiaoyi Jiang, Udo Dannlowski, Tim Hahn", "title": "Systematic Misestimation of Machine Learning Performance in Neuroimaging\n  Studies of Depression", "comments": null, "journal-ref": "Neuropsychopharmacology 46 (2021) 1510-1517", "doi": "10.1038/s41386-021-01020-7", "report-no": null, "categories": "q-bio.NC cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We currently observe a disconcerting phenomenon in machine learning studies\nin psychiatry: While we would expect larger samples to yield better results due\nto the availability of more data, larger machine learning studies consistently\nshow much weaker performance than the numerous small-scale studies. Here, we\nsystematically investigated this effect focusing on one of the most heavily\nstudied questions in the field, namely the classification of patients suffering\nfrom major depressive disorder (MDD) and healthy control (HC) based on\nneuroimaging data. Drawing upon structural magnetic resonance imaging (MRI)\ndata from a balanced sample of $N = 1,868$ MDD patients and HC from our recent\ninternational Predictive Analytics Competition (PAC), we first trained and\ntested a classification model on the full dataset which yielded an accuracy of\n$61\\,\\%$. Next, we mimicked the process by which researchers would draw samples\nof various sizes ($N = 4$ to $N = 150$) from the population and showed a strong\nrisk of misestimation. Specifically, for small sample sizes ($N = 20$), we\nobserve accuracies of up to $95\\,\\%$. For medium sample sizes ($N = 100$)\naccuracies up to $75\\,\\%$ were found. Importantly, further investigation showed\nthat sufficiently large test sets effectively protect against performance\nmisestimation whereas larger datasets per se do not. While these results\nquestion the validity of a substantial part of the current literature, we\noutline the relatively low-cost remedy of larger test sets, which is readily\navailable in most cases.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 20:12:52 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 15:10:35 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Flint", "Claas", ""], ["Cearns", "Micah", ""], ["Opel", "Nils", ""], ["Redlich", "Ronny", ""], ["Mehler", "David M. A.", ""], ["Emden", "Daniel", ""], ["Winter", "Nils R.", ""], ["Leenings", "Ramona", ""], ["Eickhoff", "Simon B.", ""], ["Kircher", "Tilo", ""], ["Krug", "Axel", ""], ["Nenadic", "Igor", ""], ["Arolt", "Volker", ""], ["Clark", "Scott", ""], ["Baune", "Bernhard T.", ""], ["Jiang", "Xiaoyi", ""], ["Dannlowski", "Udo", ""], ["Hahn", "Tim", ""]]}, {"id": "1912.06690", "submitter": "Juan G. Restrepo", "authors": "Kathleen Finlinson, Woodrow L. Shew, Daniel B. Larremore, Juan G.\n  Restrepo", "title": "Control of excitable systems is optimal near criticality", "comments": "5 pages, 3 figures", "journal-ref": "Phys. Rev. Research 2, 033450 (2020)", "doi": "10.1103/PhysRevResearch.2.033450", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments suggest that cerebral cortex gains several functional advantages\nby operating in a dynamical regime near the critical point of a phase\ntransition. However, a long-standing criticism of this hypothesis is that\ncritical dynamics are rather noisy, which might be detrimental to aspects of\nbrain function that require precision. If the cortex does operate near\ncriticality, how might it mitigate the noisy fluctuations? One possibility is\nthat other parts of the brain may act to control the fluctuations and reduce\ncortical noise. To better understand this possibility, here we numerically and\nanalytically study a network of binary neurons. We determine how efficacy of\ncontrolling the population firing rate depends on proximity to criticality as\nwell as different structural properties of the network. We found that control\nis most effective - errors are minimal for the widest range of target firing\nrates - near criticality. Optimal control is slightly away from criticality for\nnetworks with heterogeneous degree distributions. Thus, while criticality is\nthe noisiest dynamical regime, it is also the regime that is easiest to\ncontrol, which may offer a way to mitigate the noise.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2019 20:14:14 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Finlinson", "Kathleen", ""], ["Shew", "Woodrow L.", ""], ["Larremore", "Daniel B.", ""], ["Restrepo", "Juan G.", ""]]}, {"id": "1912.07567", "submitter": "Samuel Bobholz", "authors": "Samuel Bobholz, Allison Lowman, Alexander Barrington, Michael Brehler,\n  Sean McGarry, Elizabeth J. Cochran, Jennifer Connelly, Wade M. Mueller, Mohit\n  Agarwal, Darren O'Neill, Anjishnu Banerjee, Peter S. LaViolette", "title": "Radiomic features of multi-parametric MRI present stable associations\n  with analogous histological features in brain cancer patients", "comments": "16 pages, 1 table, 5 figures, 1 supplemental figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM physics.med-ph q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MR-derived radiomic features have demonstrated substantial predictive utility\nin modeling different prognostic factors of glioblastomas and other brain\ncancers. However, the biological relationship underpinning these predictive\nmodels has been largely unstudied, with the generalizability of these models\nalso called into question. Here, we examine the localized relationship between\nMR-derived radiomic features and histology-derived histomic features using a\ndataset of 16 brain cancer patients. Tile-based radiomics features were\ncollected on T1W, post-contrast T1W, FLAIR, and DWI-derived ADC images acquired\nprior to patient death, with analogous histomic features collected for autopsy\nsamples co-registered to the MRI. Features were collected for each original\nimage, as well as a 3D wavelet decomposition of each image, resulting in 837\nfeatures per MR image and histology image. Correlative analyses were used to\nassess the degree of association between radiomic-histomic pairs for each MRI.\nThe influence of several confounds were also assessed using linear mixed effect\nmodels for the normalized radiomic-histomic distance, testing for main effects\nof scanners from different vendors and acquisition field strength. Results as a\nwhole were largely heterogenous, but several features demonstrated substantial\nassociations with their histomic analogs, particularly those derived from the\nFLAIR and post-contrast T1W images. These most-associated features typically\npresented as stable across confounding factors as well. These data suggest that\na subset of radiomic features are able to consistently capture texture\ninformation about the underlying tissue histology.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 18:30:46 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Bobholz", "Samuel", ""], ["Lowman", "Allison", ""], ["Barrington", "Alexander", ""], ["Brehler", "Michael", ""], ["McGarry", "Sean", ""], ["Cochran", "Elizabeth J.", ""], ["Connelly", "Jennifer", ""], ["Mueller", "Wade M.", ""], ["Agarwal", "Mohit", ""], ["O'Neill", "Darren", ""], ["Banerjee", "Anjishnu", ""], ["LaViolette", "Peter S.", ""]]}, {"id": "1912.07660", "submitter": "Seth Herd", "authors": "Seth Herd, Kai Krueger, Ananta Nair, Jessica Mollick, and Randall\n  OReilly", "title": "Neural Mechanisms of Human Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a computational and theoretical model of the neural mechanisms\nunderlying human decision-making. We propose a detailed model of the\ninteraction between brain regions, under a proposer-predictor-actor-critic\nframework. Task-relevant areas of cortex propose a candidate plan using fast,\nmodel-free, parallel constraint-satisfaction computations. Other areas of\ncortex and medial temporal lobe can then predict likely outcomes of that plan\nin this situation. This step is optional. This prediction-(or model-) based\ncomputation produces better accuracy and generalization, at the expense of\nspeed. Next, linked regions of basal ganglia act to accept or reject the\nproposed plan based on its reward history in similar contexts. Finally the\nreward-prediction system acts as a critic to determine the value of the outcome\nrelative to expectations, and produce dopamine as a training signal for cortex\nand basal ganglia. This model gains many constraints from the hypothesis that\nthe mechanisms of complex human decision-making are closely analogous to those\nthat have been empirically studied in detail for animal action-selection. We\nargue that by operating sequentially and hierarchically, these same mechanisms\nare responsible for the most complex human plans and decisions. Finally, we use\nthe computational model to generate novel hypotheses on causes of human risky\ndecision-making, and compare this to other theories of human decision-making.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 19:48:08 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Herd", "Seth", ""], ["Krueger", "Kai", ""], ["Nair", "Ananta", ""], ["Mollick", "Jessica", ""], ["OReilly", "Randall", ""]]}, {"id": "1912.08144", "submitter": "John Abel", "authors": "John H. Abel, Marcus A. Badgeley, Taylor E. Baum, Sourish Chakravarty,\n  Patrick L. Purdon, Emery N. Brown", "title": "Constructing a control-ready model of EEG signal during general\n  anesthesia in humans", "comments": "7 pages, 6 figures. This work has been submitted to IFAC for possible\n  publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Significant effort toward the automation of general anesthesia has been made\nin the past decade. One open challenge is in the development of control-ready\npatient models for closed-loop anesthesia delivery. Standard\ndepth-of-anesthesia tracking does not readily capture inter-individual\ndifferences in response to anesthetics, especially those due to age, and does\nnot aim to predict a relationship between a control input (infused anesthetic\ndose) and system state (commonly, a function of electroencephalography (EEG)\nsignal). In this work, we developed a control-ready patient model for\nclosed-loop propofol-induced anesthesia using data recorded during a clinical\nstudy of EEG during general anesthesia in ten healthy volunteers. We used\nprincipal component analysis to identify the low-dimensional state-space in\nwhich EEG signal evolves during anesthesia delivery. We parameterized the\nresponse of the EEG signal to changes in propofol target-site concentration\nusing logistic models. We note that inter-individual differences in anesthetic\nsensitivity may be captured by varying a constant cofactor of the predicted\neffect-site concentration. We linked the EEG dose-response with the control\ninput using a pharmacokinetic model. Finally, we present a simple nonlinear\nmodel predictive control in silico demonstration of how such a closed-loop\nsystem would work.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2019 17:24:49 GMT"}], "update_date": "2019-12-18", "authors_parsed": [["Abel", "John H.", ""], ["Badgeley", "Marcus A.", ""], ["Baum", "Taylor E.", ""], ["Chakravarty", "Sourish", ""], ["Purdon", "Patrick L.", ""], ["Brown", "Emery N.", ""]]}, {"id": "1912.08343", "submitter": "Charles Iglehart", "authors": "Charles Iglehart (1), Martin Monti (2 and 3), Joshua Cain (2), Thomas\n  Tourdias (4), Manojkumar Saranathan (1 and 5) ((1) Department of Electrical\n  and Computer Engineering, University of Arizona, Tucson, Arizona, United\n  States, (2) Department of Psychology, University of California Los Angeles,\n  Los Angeles, California, United States, (3) Neurosurgery Brain Research\n  Center, University of California Los Angeles, Los Angeles, California, United\n  States (4) Service de Neuroimagerie Diagnostique et Th\\'erapeutique and\n  INSERM U1215, Universit\\'e de Bordeaux, Bordeaux, France, (5) Department of\n  Medical Imaging, University of Arizona, Tucson, Arizona, United States)", "title": "A systematic comparison of structural, structural connectivity, and\n  functional connectivity based thalamus parcellation techniques", "comments": "24 pages, 9 figures, submitted to Brain Structure and Function\n  December 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The thalamus consists of several histologically and functionally distinct\nnuclei increasingly implicated in brain pathology and important for treatment,\nmotivating the need for development of fast and accurate thalamic segmentation.\nThe contrast between thalamic nuclei as well as between the thalamus and\nsurrounding tissues is poor in T1 and T2 weighted magnetic resonance imaging\n(MRI), inhibiting efforts to date to segment the thalamus using standard\nclinical MRI. Automatic segmentation techniques have been developed to leverage\nthalamic features better captured by advanced MRI methods, including\nmagnetization prepared rapid acquisition gradient echo (MP-RAGE) , diffusion\ntensor imaging (DTI), and resting state functional MRI (fMRI). Despite\noperating on fundamentally different image features, these methods claim a high\ndegree of agreement with the Morel stereotactic atlas of the thalamus. However,\nno comparison has been undertaken to compare the results of these disparate\nsegmentation methods. We have implemented state-of-the-art structural,\ndiffusion, and functional imaging-based thalamus segmentation techniques and\nused them on a single set of subjects. We present the first systematic\nqualitative and quantitative comparison of these methods. We found that\nfunctional connectivity-based parcellation exhibited a close correspondence\nwith structural parcellation on the basis of qualitative concordance with the\nMorel thalamic atlas as well as the quantitative measures of Dice scores and\nvolumetric similarity index.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2019 02:19:34 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Iglehart", "Charles", "", "2 and 3"], ["Monti", "Martin", "", "2 and 3"], ["Cain", "Joshua", "", "1 and 5"], ["Tourdias", "Thomas", "", "1 and 5"], ["Saranathan", "Manojkumar", "", "1 and 5"]]}, {"id": "1912.09207", "submitter": "Ekkehard Ullner", "authors": "Ekkehard Ullner, Antonio Politi, Alessandro Torcini", "title": "Quantitative and qualitative analysis of asynchronous neural activity", "comments": "12 pages, 12 figures", "journal-ref": "Phys. Rev. Research 2, 023103 (2020)", "doi": "10.1103/PhysRevResearch.2.023103", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The activity of a sparse network of leaky integrate-and-fire neurons is\ncarefully revisited with reference to a regime of a bona-fide asynchronous\ndynamics. The study is preceded by a finite-size scaling analysis, carried out\nto identify a setup where collective synchronization is negligible. The\ncomparison between quenched and annealed networks reveals the emergence of\nsubstantial differences when the coupling strength is increased, via a scenario\nsomehow reminiscent of a phase transition. For sufficiently strong synaptic\ncoupling, quenched networks exhibit a highly bursting neural activity, well\nreproduced by a self-consistent approach, based on the assumption that the\ninput synaptic current is the superposition of independent renewal processes.\nThe distribution of interspike intervals turns out to be relatively\nlong-tailed; a crucial feature required for the self-sustainment of the\nbursting activity in a regime where neurons operate on average (much) below\nthreshold. A semi-quantitative analogy with Ornstein-Uhlenbeck processes helps\nvalidating this interpretation. Finally, an alternative explanation in terms of\nPoisson processes is offered under the additional assumption of mutual\ncorrelations among excitatory and inhibitory spikes.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2019 14:15:11 GMT"}], "update_date": "2020-05-06", "authors_parsed": [["Ullner", "Ekkehard", ""], ["Politi", "Antonio", ""], ["Torcini", "Alessandro", ""]]}, {"id": "1912.10079", "submitter": "Ohad Felsenstein", "authors": "O. Felsenstein, N. Peled, E. Hahn, A. P. Rockhill, L. Folsom, T.\n  Gholipour, K. Macadams, N. Rozengard, A. C. Paulk, D. Dougherty, S. S. Cash,\n  A. S. Widge, M. H\\\"am\\\"al\\\"ainen, S. Stufflebeam", "title": "Multi-Modal Neuroimaging Analysis and Visualization Tool (MMVT)", "comments": "29 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sophisticated visualization tools are essential for the presentation and\nexploration of human neuroimaging data. While two-dimensional orthogonal views\nof neuroimaging data are conventionally used to display activity and\nstatistical analysis, three-dimensional (3D) representation is useful for\nshowing the spatial distribution of a functional network, as well as its\ntemporal evolution. For these purposes, there is currently no open-source, 3D\nneuroimaging tool that can simultaneously visualize desired combinations of\nMRI, CT, EEG, MEG, fMRI, PET, and intracranial EEG (i.e., ECoG, depth\nelectrodes, and DBS). Here we present the Multi-Modal Visualization Tool\n(MMVT), which is designed for researchers to interact with their neuroimaging\nfunctional and anatomical data through simultaneous visualization of these\nexisting imaging modalities. MMVT contains two separate modules: The first is\nan add-on to the open-source, 3D-rendering program Blender. It is an\ninteractive graphical interface that enables users to simultaneously visualize\nmulti-modality functional and statistical data on cortical and subcortical\nsurfaces as well as MEEG sensors and intracranial electrodes. This tool also\nenables highly accurate 3D visualization of neuroanatomy, including the\nlocation of invasive electrodes relative to brain structures. The second module\nincludes complete stand-alone pre-processing pipelines, from raw data to\nstatistical maps. Each of the modules and module features can be integrated,\nseparate from the tool, into existing data pipelines. This gives the tool a\ndistinct advantage in both clinical and research domains as each has highly\nspecialized visual and processing needs. MMVT leverages open-source software to\nbuild a comprehensive tool for data visualization and exploration.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2019 19:58:06 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Felsenstein", "O.", ""], ["Peled", "N.", ""], ["Hahn", "E.", ""], ["Rockhill", "A. P.", ""], ["Folsom", "L.", ""], ["Gholipour", "T.", ""], ["Macadams", "K.", ""], ["Rozengard", "N.", ""], ["Paulk", "A. C.", ""], ["Dougherty", "D.", ""], ["Cash", "S. S.", ""], ["Widge", "A. S.", ""], ["H\u00e4m\u00e4l\u00e4inen", "M.", ""], ["Stufflebeam", "S.", ""]]}, {"id": "1912.10189", "submitter": "Christopher J. Cueva", "authors": "Christopher J. Cueva, Peter Y. Wang, Matthew Chin, Xue-Xin Wei", "title": "Emergence of functional and structural properties of the head direction\n  system by optimization of recurrent neural networks", "comments": "International Conference on Learning Representations (ICLR) 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work suggests goal-driven training of neural networks can be used to\nmodel neural activity in the brain. While response properties of neurons in\nartificial neural networks bear similarities to those in the brain, the network\narchitectures are often constrained to be different. Here we ask if a neural\nnetwork can recover both neural representations and, if the architecture is\nunconstrained and optimized, the anatomical properties of neural circuits. We\ndemonstrate this in a system where the connectivity and the functional\norganization have been characterized, namely, the head direction circuits of\nthe rodent and fruit fly. We trained recurrent neural networks (RNNs) to\nestimate head direction through integration of angular velocity. We found that\nthe two distinct classes of neurons observed in the head direction system, the\nCompass neurons and the Shifter neurons, emerged naturally in artificial neural\nnetworks as a result of training. Furthermore, connectivity analysis and\nin-silico neurophysiology revealed structural and mechanistic similarities\nbetween artificial networks and the head direction system. Overall, our results\nshow that optimization of RNNs in a goal-driven task can recapitulate the\nstructure and function of biological circuits, suggesting that artificial\nneural networks can be used to study the brain at the level of both neural\nactivity and anatomical organization.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 03:51:58 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 09:06:33 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Cueva", "Christopher J.", ""], ["Wang", "Peter Y.", ""], ["Chin", "Matthew", ""], ["Wei", "Xue-Xin", ""]]}, {"id": "1912.10262", "submitter": "Lyudmila Kushnir", "authors": "Lyudmila Kushnir, Sophie Den\\`eve", "title": "Learning temporal structure of the input with a network of\n  integrate-and-fire neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of the brain is to look for structure in the external input. We\nstudy a network of integrate-and-fire neurons with several types of recurrent\nconnections that learns the structure of its time-varying feedforward input by\nattempting to efficiently represent this input with spikes. The efficiency of\nthe representation arises from incorporating the structure of the input into\nthe decoder, which is implicit in the learned synaptic connectivity of the\nnetwork. While in the original work of [Boerlin, Machens, Den\\`eve 2013] and\n[Brendel et al., 2017] the structure learned by the network to make the\nrepresentation efficient was the low-dimensionality of the feedforward input,\nin the present work it is its temporal dynamics. The network achieves the\nefficiency by adjusting its synaptic weights in such a way, that for any neuron\nin the network, the recurrent input cancels the feedforward for most of the\ntime. We show that if the only temporal structure that the input possesses is\nthat it changes slowly on the time scale of neuronal integration, the\ndimensionality of the network dynamics is equal to the dimensionality of the\ninput. However, if the input follows a linear differential equation of the\nfirst order, the efficiency of the representation can be increased by\nincreasing the dimensionality of the network dynamics in comparison to the\ndimensionality of the input. If there is only one type of slow synaptic current\nin the network, the increase is two-fold, while if there are two types of slow\nsynaptic currents that decay with different rates and whose amplitudes can be\nadjusted separately, it is advantageous to make the increase three-fold. We\nnumerically simulate the network with synaptic weights that imply the most\nefficient input representation in the above cases. We also propose a learning\nrule by means of which the corresponding synaptic weights can be learned.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2019 13:04:30 GMT"}, {"version": "v2", "created": "Sat, 28 Dec 2019 23:11:50 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2020 19:50:24 GMT"}, {"version": "v4", "created": "Sun, 11 Oct 2020 18:34:22 GMT"}], "update_date": "2020-10-13", "authors_parsed": [["Kushnir", "Lyudmila", ""], ["Den\u00e8ve", "Sophie", ""]]}, {"id": "1912.10489", "submitter": "Tai Sing Lee", "authors": "Siming Yan, Xuyang Fang, Bowen Xiao, Harold Rockwell, Yimeng Zhang,\n  Tai Sing Lee", "title": "Recurrent Feedback Improves Feedforward Representations in Deep Neural\n  Networks", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abundant recurrent horizontal and feedback connections in the primate\nvisual cortex are thought to play an important role in bringing global and\nsemantic contextual information to early visual areas during perceptual\ninference, helping to resolve local ambiguity and fill in missing details. In\nthis study, we find that introducing feedback loops and horizontal recurrent\nconnections to a deep convolution neural network (VGG16) allows the network to\nbecome more robust against noise and occlusion during inference, even in the\ninitial feedforward pass. This suggests that recurrent feedback and contextual\nmodulation transform the feedforward representations of the network in a\nmeaningful and interesting way. We study the population codes of neurons in the\nnetwork, before and after learning with feedback, and find that learning with\nfeedback yielded an increase in discriminability (measured by d-prime) between\nthe different object classes in the population codes of the neurons in the\nfeedforward path, even at the earliest layer that receives feedback. We find\nthat recurrent feedback, by injecting top-down semantic meaning to the\npopulation activities, helps the network learn better feedforward paths to\nrobustly map noisy image patches to the latent representations corresponding to\nimportant visual concepts of each object class, resulting in greater robustness\nof the network against noises and occlusion as well as better fine-grained\nrecognition.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2019 17:40:19 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Yan", "Siming", ""], ["Fang", "Xuyang", ""], ["Xiao", "Bowen", ""], ["Rockwell", "Harold", ""], ["Zhang", "Yimeng", ""], ["Lee", "Tai Sing", ""]]}, {"id": "1912.10749", "submitter": "Muhammad Saif-Ur-Rehman", "authors": "Muhammad Saif-ur-Rehman, Omair Ali, Robin Lienkaemper, Sussane Dyck,\n  Marita Metzler, Yaroslav Parpaley, Joerg Wellmer, Charles Liu, Brian Lee,\n  Spencer Kellis, Richard Andersen, Ioannis Iossifidis, Tobias Glasmachers,\n  Christian Klaes", "title": "SpikeDeep-Classifier: A deep-learning based fully automatic offline\n  spike sorting algorithm", "comments": "33 Pages, 14 Figures, 10 Tables", "journal-ref": null, "doi": "10.1088/1741-2552/abc8d4", "report-no": null, "categories": "q-bio.QM eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective. Recent advancements in electrode designs and micro-fabrication\ntechnology has allowed existence of microelectrode arrays with hundreds of\nchannels for single-cell recordings. In such electrophysiological recordings,\neach implanted micro-electrode can record the activities of more than one\nneuron in its vicinity. Recording the activities of multiple neurons may also\nbe referred to as multiple unit activity. However, for any further analysis,\nthe main goal is to isolate the activity of each recorded neuron and thus\ncalled single-unit activity. This process may also be referred to as spike\nsorting or spike classification. Recent approaches to extract SUA are time\nconsuming, mainly due to the requirement of human intervention at various\nstages of spike sorting pipeline. Lack of standardization is another drawback\nof the current available approaches. Therefore, in this study we proposed a\nstandard spike sorter: SpikeDeep-Classifier, a fully automatic spike sorting\nalgorithm. Approach. We proposed a novel spike sorting pipeline, based on a set\nof supervised and unsupervised learning algorithms. We used supervised, deep\nlearning-based algorithms for extracting meaningful channels and removing\nbackground activities (noise) from the extracted channels. We also showed that\nthe process of clustering becomes straight-forward, once the noise/artifact is\ncompletely removed from the data. Therefore, in the next stage, we applied a\nsimple clustering algorithm (K-mean) with predefined maximum number of\nclusters. Lastly, we used a similarity-based criterion to keep distinct\nclusters and merge similar-looking clusters. Main results. We evaluated our\nalgorithm on a dataset collected from two different species (humans and\nnon-human primates (NHPs)) without any retraining. We also validated our\nalgorithm on two publicly available labeled datasets.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 11:42:16 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Saif-ur-Rehman", "Muhammad", ""], ["Ali", "Omair", ""], ["Lienkaemper", "Robin", ""], ["Dyck", "Sussane", ""], ["Metzler", "Marita", ""], ["Parpaley", "Yaroslav", ""], ["Wellmer", "Joerg", ""], ["Liu", "Charles", ""], ["Lee", "Brian", ""], ["Kellis", "Spencer", ""], ["Andersen", "Richard", ""], ["Iossifidis", "Ioannis", ""], ["Glasmachers", "Tobias", ""], ["Klaes", "Christian", ""]]}, {"id": "1912.11126", "submitter": "Ryan Grgurich", "authors": "Ryan Grgurich and Hugh T. Blair", "title": "An uncertainty principle for neural coding: Conjugate representations of\n  position and velocity are mapped onto firing rates and co-firing rates of\n  neural spike trains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hippocampal system contains neural populations that encode an animal's\nposition and velocity as it navigates through space. Here, we show that such\npopulations can embed two codes within their spike trains: a firing rate code\n(R) conveyed by within-cell spike intervals, and a co-firing rate code (R')\nconveyed by between-cell spike intervals. These two codes behave as conjugates\nof one another, obeying an analog of the uncertainty principle from physics:\ninformation conveyed in R comes at the expense of information in R', and vice\nversa. An exception to this trade-off occurs when spike trains encode a pair of\nconjugate variables, such as position and velocity, which do not compete for\ncapacity across R and R'. To illustrate this, we describe two biologically\ninspired methods for decoding R and R', referred to as sigma and sigma-chi\ndecoding, respectively. Simulations of head direction (HD) and grid cells show\nthat if firing rates are tuned for position (but not velocity), then position\nis recovered by sigma decoding, whereas velocity is recovered by sigma-chi\ndecoding. Conversely, simulations of oscillatory interference among\ntheta-modulated \"speed cells\" show that if co-firing rates are tuned for\nposition (but not velocity), then position is recovered by sigma-chi decoding,\nwhereas velocity is recovered by sigma decoding. Between these two extremes,\ninformation about both variables can be distributed across both channels, and\npartially recovered by both decoders. These results suggest that neurons with\ndifferent spatial and temporal tuning properties-such as speed versus grid\ncells-might not encode different information, but rather, distribute similar\ninformation about position and velocity in different ways across R and R'.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2019 22:02:06 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Grgurich", "Ryan", ""], ["Blair", "Hugh T.", ""]]}, {"id": "1912.11371", "submitter": "Amirmohammad Mijani", "authors": "S.A. Karimi, A.M.Mijani, M.T. Talebian and S. Mirzakuchaki", "title": "Comparison of the P300 detection accuracy related to the BCI speller and\n  image recognition scenarios", "comments": "8 pages, 3 figures, 2 tables, 24 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are several protocols in the Electroencephalography (EEG) recording\nscenarios which produce various types of event-related potentials (ERP). P300\npattern is a well-known ERP which produced by auditory and visual oddball\nparadigm and BCI speller system. In this study, P300 and non-P300 separability\nare investigated in two scenarios including image recognition paradigm and BCI\nspeller. Image recognition scenario is an experiment that examines the\nparticipants, knowledge about an image that shown to them before by analyzing\nthe EEG signal recorded during the observing of that image as visual\nstimulation. To do this, three types of famous classifiers (SVM, Bayes LDA, and\nsparse logistic regression) were used to classify EEG recordings in six classes\nproblem. Filtered and down-sampled (temporal samples) of EEG recording were\nconsidered as features in classification P300 pattern. Also, different sets of\nEEG recording including 4, 8 and 16 channels and different trial numbers were\nused to considering various situations in comparison. The accuracy was\nincreased by increasing the number of trials and channels. The results prove\nthat better accuracy is observed in the case of the image recognition scenario\nfor the different sets of channels and by using the different number of trials.\nSo it can be concluded that P300 pattern which produced in image recognition\nparadigm is more separable than BCI (matrix speller).\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 14:04:24 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Karimi", "S. A.", ""], ["Mijani", "A. M.", ""], ["Talebian", "M. T.", ""], ["Mirzakuchaki", "S.", ""]]}, {"id": "1912.11443", "submitter": "Julian G\\\"oltz", "authors": "Julian G\\\"oltz, Laura Kriener, Andreas Baumbach, Sebastian\n  Billaudelle, Oliver Breitwieser, Benjamin Cramer, Dominik Dold, Akos Ferenc\n  Kungl, Walter Senn, Johannes Schemmel, Karlheinz Meier, Mihai Alexandru\n  Petrovici", "title": "Fast and energy-efficient neuromorphic deep learning with first-spike\n  times", "comments": "24 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.ET q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For a biological agent operating under environmental pressure, energy\nconsumption and reaction times are of critical importance. Similarly,\nengineered systems are optimized for short time-to-solution and low\nenergy-to-solution characteristics. At the level of neuronal implementation,\nthis implies achieving the desired results with as few and as early spikes as\npossible. With time-to-first-spike coding both of these goals are inherently\nemerging features of learning. Here, we describe a rigorous derivation of a\nlearning rule for such first-spike times in networks of leaky\nintegrate-and-fire neurons, relying solely on input and output spike times, and\nshow how this mechanism can implement error backpropagation in hierarchical\nspiking networks. Furthermore, we emulate our framework on the BrainScaleS-2\nneuromorphic system and demonstrate its capability of harnessing the system's\nspeed and energy characteristics. Finally, we examine how our approach\ngeneralizes to other neuromorphic platforms by studying how its performance is\naffected by typical distortive effects induced by neuromorphic substrates.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 17:18:07 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2020 16:27:45 GMT"}, {"version": "v3", "created": "Thu, 19 Nov 2020 18:43:48 GMT"}, {"version": "v4", "created": "Mon, 17 May 2021 15:35:57 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["G\u00f6ltz", "Julian", ""], ["Kriener", "Laura", ""], ["Baumbach", "Andreas", ""], ["Billaudelle", "Sebastian", ""], ["Breitwieser", "Oliver", ""], ["Cramer", "Benjamin", ""], ["Dold", "Dominik", ""], ["Kungl", "Akos Ferenc", ""], ["Senn", "Walter", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""], ["Petrovici", "Mihai Alexandru", ""]]}, {"id": "1912.11449", "submitter": "Mehdi Jorfi", "authors": "Shen Ning and Mehdi Jorfi", "title": "p75NTR as a Molecular Memory Switch", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": "10.20944/preprints201912.0333.v1", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many molecular and environmental factors have been studied\nto understand how synaptic plasticity is modulated. Sleep, as an evolutionary\nconserved biological function, has shown to be a critical player for the\nconsolidation and filtering of synaptic circuitry underlying memory traces.\nAlthough sleep disturbances do not alter normal memory consolidation, they may\nreflect fundamental circuit malfunctions that can play a significant role in\nexacerbating diseases, such as autism and Alzheimer's disease. Very recently,\nscientists sought to answer part of this enigma and they identified p75\nneurotrophic receptor (p75NTR) as a critical player in mediating impairments in\nhippocampal-dependent associative plasticity upon sleep deprivation. This paper\nwill review the role of the p75NTR, critically discuss the impact and\nimplications of this research as the bridge for sleep research and neurological\ndiseases.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 17:33:38 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Ning", "Shen", ""], ["Jorfi", "Mehdi", ""]]}, {"id": "1912.11494", "submitter": "Narciso L\\'opez", "authors": "Andrea V\\'azquez, Narciso L\\'opez-L\\'opez, Nicole Labra, Miguel\n  Figueroa, Cyril Poupon, Jean-Fran\\c{c}ois Mangin, Cecilia Hern\\'andez, Pamela\n  Guevara", "title": "Parallel optimization of fiber bundle segmentation for massive\n  tractography datasets", "comments": "This research has received funding from the European Union's Horizon\n  2020 research and innovation programme under the Marie Sk{\\l}odowska-Curie\n  Actions H2020-MSCA-RISE-2015 BIRDS GA No. 690941, CONICYT PFCHA/ DOCTORADO\n  NACIONAL/2016-21160342, CONICYT FONDECYT 1161427, CONICYT PIA/Anillo de\n  Investigaci\\'on en Ciencia y Tecnolog\\'ia ACT172121, CONICYT BASAL FB0008 and\n  from CONICYT Basal FB0001", "journal-ref": null, "doi": "10.1109/ISBI.2019.8759208", "report-no": null, "categories": "cs.DS cs.CV eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an optimized algorithm that performs automatic classification of\nwhite matter fibers based on a multi-subject bundle atlas. We implemented a\nparallel algorithm that improves upon its previous version in both execution\ntime and memory usage. Our new version uses the local memory of each processor,\nwhich leads to a reduction in execution time. Hence, it allows the analysis of\nbigger subject and/or atlas datasets. As a result, the segmentation of a\nsubject of 4,145,000 fibers is reduced from about 14 minutes in the previous\nversion to about 6 minutes, yielding an acceleration of 2.34. In addition, the\nnew algorithm reduces the memory consumption of the previous version by a\nfactor of 0.79.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2019 19:08:51 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["V\u00e1zquez", "Andrea", ""], ["L\u00f3pez-L\u00f3pez", "Narciso", ""], ["Labra", "Nicole", ""], ["Figueroa", "Miguel", ""], ["Poupon", "Cyril", ""], ["Mangin", "Jean-Fran\u00e7ois", ""], ["Hern\u00e1ndez", "Cecilia", ""], ["Guevara", "Pamela", ""]]}, {"id": "1912.12047", "submitter": "Sebastian Billaudelle", "authors": "Sebastian Billaudelle, Benjamin Cramer, Mihai A. Petrovici, Korbinian\n  Schreiber, David Kappel, Johannes Schemmel, Karlheinz Meier", "title": "Structural plasticity on an accelerated analog neuromorphic hardware\n  system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In computational neuroscience, as well as in machine learning, neuromorphic\ndevices promise an accelerated and scalable alternative to neural network\nsimulations. Their neural connectivity and synaptic capacity depends on their\nspecific design choices, but is always intrinsically limited. Here, we present\na strategy to achieve structural plasticity that optimizes resource allocation\nunder these constraints by constantly rewiring the pre- and gpostsynaptic\npartners while keeping the neuronal fan-in constant and the connectome sparse.\nIn particular, we implemented this algorithm on the analog neuromorphic system\nBrainScaleS-2. It was executed on a custom embedded digital processor located\non chip, accompanying the mixed-signal substrate of spiking neurons and synapse\ncircuits. We evaluated our implementation in a simple supervised learning\nscenario, showing its ability to optimize the network topology with respect to\nthe nature of its training data, as well as its overall computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 10:15:58 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2020 08:20:35 GMT"}], "update_date": "2020-10-01", "authors_parsed": [["Billaudelle", "Sebastian", ""], ["Cramer", "Benjamin", ""], ["Petrovici", "Mihai A.", ""], ["Schreiber", "Korbinian", ""], ["Kappel", "David", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1912.12093", "submitter": "Jesus Malo", "authors": "Jesus Malo", "title": "Information Flow in Color Appearance Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Color Appearance Models are biological networks that consist of a cascade of\nlinear+nonlinear layers that modify the linear measurements at the retinal\nphoto-receptors leading to an internal (nonlinear) representation of color that\ncorrelates with psychophysical experience. The basic layers of these networks\ninclude: (1) chromatic adaptation (normalization of the mean and covariance of\nthe color manifold), (2) change to opponent color channels (PCA-like rotation\nin the color space), and (3) saturating nonlinearities to get perceptually\nEuclidean color representations (similar to dimensionwise equalization). The\nEfficient Coding Hypothesis argues that these transforms should emerge from\ninformation-theoretic goals. In case this hypothesis holds in color vision, the\nquestion is, what is the coding gain due to the different layers of the color\nappearance networks?\n  In this work, a representative family of Color Appearance Models is analyzed\nin terms of how the redundancy among the chromatic components is modified along\nthe network and how much information is transferred from the input data to the\nnoisy response. The proposed analysis is done using data and methods that were\nnot available before: (1) new colorimetrically calibrated scenes in different\nCIE illuminations for proper evaluation of chromatic adaptation, and (2) new\nstatistical tools to estimate (multivariate) information-theoretic quantities\nbetween multidimensional sets based on Gaussianization. Results confirm that\nthe Efficient Coding Hypothesis holds for current color vision models, and\nidentify the psychophysical mechanisms critically responsible for gains in\ninformation transference: opponent channels and their nonlinear nature are more\nimportant than chromatic adaptation at the retina.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2019 13:41:34 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Malo", "Jesus", ""]]}, {"id": "1912.12762", "submitter": "Andrey Kuznetsov", "authors": "I. A. Kuznetsov and A. V. Kuznetsov", "title": "How old are dense core vesicles residing in en passant boutons:\n  Simulation of the mean age of dense core vesicles in axonal arbors accounting\n  for resident and transiting vesicle populations", "comments": "Final, accepted manuscript version", "journal-ref": "Proc. R. Soc. A, vol. 476: 20200454, 2020", "doi": "10.1098/rspa.2020.0454", "report-no": null, "categories": "q-bio.SC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neurons, neuropeptides are synthesized in the soma and are then\ntransported along the axon in dense core vesicles (DCVs). DCVs are captured in\nvaricosities located along the axon terminal called en passant boutons, which\nare active terminal sites that accumulate and release neurotransmitters.\nRecently developed experimental techniques allow for the estimation of the age\nof DCVs in various locations in the axon terminal. Accurate simulation of the\nmean age of DCVs in boutons requires the development of a model that would\naccount for resident, transiting-anterograde, and transiting-retrograde DCV\npopulations. In this paper, such a model is developed. The model is applied to\nsimulating DCV transport in Drosophila type II motoneurons. The model simulates\nDCV transport and capture in the axon terminals and makes it possible to\npredict the age density distribution of DCVs in en passant boutons as well as\nDCV's mean age in boutons. The predicted prevalence of older organelles in\ndistal boutons may explain the \"dying back\" pattern of axonal degeneration\nobserved in dopaminergic neurons in Parkinson's disease. The predicted\ndifference of two hours between the age of older DCVs residing in distal\nboutons and the age of younger DCVs residing in proximal boutons is consistent\nwith an approximate estimate of age difference deduced from experimental\nobservations. The age density of resident DCVs is found to be bimodal, which is\nbecause DCVs are captured from two transiting states: the anterograde\ntransiting state that contains younger DCVs and the retrograde transiting state\nthat contains older DCVs.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 00:07:33 GMT"}, {"version": "v2", "created": "Sat, 1 Feb 2020 16:39:11 GMT"}, {"version": "v3", "created": "Wed, 6 May 2020 17:00:06 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 18:25:00 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Kuznetsov", "I. A.", ""], ["Kuznetsov", "A. V.", ""]]}, {"id": "1912.12763", "submitter": "Hemal Naik", "authors": "Hemal Naik, Renaud Bastien, Nassir Navab, Iain Couzin", "title": "Animals in Virtual Environments", "comments": "Conditional acceptance in IEEE TVCG", "journal-ref": "IEEE Transactions on Visualization and Computer Graphics Feb 13\n  2020", "doi": "10.1109/TVCG.2020.2973063", "report-no": null, "categories": "cs.GR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The core idea in an XR (VR/MR/AR) application is to digitally stimulate one\nor more sensory systems (e.g. visual, auditory, olfactory) of the human user in\nan interactive way to achieve an immersive experience. Since the early 2000s\nbiologists have been using Virtual Environments (VE) to investigate the\nmechanisms of behavior in non-human animals including insect, fish, and\nmammals. VEs have become reliable tools for studying vision, cognition, and\nsensory-motor control in animals. In turn, the knowledge gained from studying\nsuch behaviors can be harnessed by researchers designing biologically inspired\nrobots, smart sensors, and multi-agent artificial intelligence. VE for animals\nis becoming a widely used application of XR technology but such applications\nhave not previously been reported in the technical literature related to XR.\nBiologists and computer scientists can benefit greatly from deepening\ninterdisciplinary research in this emerging field and together we can develop\nnew methods for conducting fundamental research in behavioral sciences and\nengineering. To support our argument we present this review which provides an\noverview of animal behavior experiments conducted in virtual environments.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 00:14:57 GMT"}, {"version": "v2", "created": "Thu, 2 Jan 2020 18:39:18 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Naik", "Hemal", ""], ["Bastien", "Renaud", ""], ["Navab", "Nassir", ""], ["Couzin", "Iain", ""]]}, {"id": "1912.12980", "submitter": "Benjamin Cramer", "authors": "Sebastian Billaudelle, Yannik Stradmann, Korbinian Schreiber, Benjamin\n  Cramer, Andreas Baumbach, Dominik Dold, Julian G\\\"oltz, Akos F. Kungl, Timo\n  C. Wunderlich, Andreas Hartel, Eric M\\\"uller, Oliver Breitwieser, Christian\n  Mauch, Mitja Kleider, Andreas Gr\\\"ubl, David St\\\"ockel, Christian Pehle,\n  Arthur Heimbrecht, Philipp Spilger, Gerd Kiene, Vitali Karasenko, Walter\n  Senn, Mihai A. Petrovici, Johannes Schemmel, Karlheinz Meier", "title": "Versatile emulation of spiking neural networks on an accelerated\n  neuromorphic substrate", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present first experimental results on the novel BrainScaleS-2 neuromorphic\narchitecture based on an analog neuro-synaptic core and augmented by embedded\nmicroprocessors for complex plasticity and experiment control. The high\nacceleration factor of 1000 compared to biological dynamics enables the\nexecution of computationally expensive tasks, by allowing the fast emulation of\nlong-duration experiments or rapid iteration over many consecutive trials. The\nflexibility of our architecture is demonstrated in a suite of five distinct\nexperiments, which emphasize different aspects of the BrainScaleS-2 system.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2019 16:12:14 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Billaudelle", "Sebastian", ""], ["Stradmann", "Yannik", ""], ["Schreiber", "Korbinian", ""], ["Cramer", "Benjamin", ""], ["Baumbach", "Andreas", ""], ["Dold", "Dominik", ""], ["G\u00f6ltz", "Julian", ""], ["Kungl", "Akos F.", ""], ["Wunderlich", "Timo C.", ""], ["Hartel", "Andreas", ""], ["M\u00fcller", "Eric", ""], ["Breitwieser", "Oliver", ""], ["Mauch", "Christian", ""], ["Kleider", "Mitja", ""], ["Gr\u00fcbl", "Andreas", ""], ["St\u00f6ckel", "David", ""], ["Pehle", "Christian", ""], ["Heimbrecht", "Arthur", ""], ["Spilger", "Philipp", ""], ["Kiene", "Gerd", ""], ["Karasenko", "Vitali", ""], ["Senn", "Walter", ""], ["Petrovici", "Mihai A.", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1912.13490", "submitter": "Gianluca Baldassarre PhD", "authors": "Gianluca Baldassarre and Giovanni Granato", "title": "Representation Internal-Manipulation (RIM): A Neuro-Inspired\n  Computational Theory of Consciousness", "comments": "16 pages, 5 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many theories, based on neuroscientific and psychological empirical evidence\nand on computational concepts, have been elaborated to explain the emergence of\nconsciousness in the central nervous system. These theories propose key\nfundamental mechanisms to explain consciousness, but they only partially\nconnect such mechanisms to the possible functional and adaptive role of\nconsciousness. Recently, some cognitive and neuroscientific models try to solve\nthis gap by linking consciousness to various aspects of goal-directed\nbehaviour, the pivotal cognitive process that allows mammals to flexibly act in\nchallenging environments. Here we propose the Representation\nInternal-Manipulation (RIM) theory of consciousness, a theory that links the\nmain elements of consciousness theories to components and functions of\ngoal-directed behaviour, ascribing a central role for consciousness to the\ngoal-directed manipulation of internal representations. This manipulation\nrelies on four specific computational operations to perform the flexible\ninternal adaptation of all key elements of goal-directed computation, from the\nrepresentations of objects to those of goals, actions, and plans. Finally, we\npropose the concept of `manipulation agency' relating the sense of agency to\nthe internal manipulation of representations. This allows us to propose that\nthe subjective experience of consciousness is associated to the human capacity\nto generate and control a simulated internal reality that is vividly perceived\nand felt through the same perceptual and emotional mechanisms used to tackle\nthe external world.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2019 18:45:33 GMT"}], "update_date": "2020-01-01", "authors_parsed": [["Baldassarre", "Gianluca", ""], ["Granato", "Giovanni", ""]]}]