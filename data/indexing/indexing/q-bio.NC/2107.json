[{"id": "2107.00567", "submitter": "Marcus Lewis", "authors": "Marcus Lewis", "title": "Hippocampal Spatial Mapping As Fast Graph Learning", "comments": "9 pages, 4 figures, writeup of poster for 30th Annual Computational\n  Neuroscience Meeting (CNS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The hippocampal formation is thought to learn spatial maps of environments,\nand in many models this learning process consists of forming a sensory\nassociation for each location in the environment. This is inefficient, akin to\nlearning a large lookup table for each environment. Spatial maps can be learned\nmuch more efficiently if the maps instead consist of arrangements of sparse\nenvironment parts. In this work, I approach spatial mapping as a problem of\nlearning graphs of environment parts. Each node in the learned graph,\nrepresented by hippocampal engram cells, is associated with feature information\nin lateral entorhinal cortex (LEC) and location information in medial\nentorhinal cortex (MEC) using empirically observed neuron types. Each edge in\nthe graph represents the relation between two parts, and it is associated with\ncoarse displacement information. This core idea of associating arbitrary\ninformation with nodes and edges is not inherently spatial, so this proposed\nfast-relation-graph-learning algorithm can expand to incorporate many spatial\nand non-spatial tasks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 16:05:42 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Lewis", "Marcus", ""]]}, {"id": "2107.00731", "submitter": "Andrew Zaharia", "authors": "Andrew D Zaharia, Anish S Potnis, Alexander Walther, Nikolaus\n  Kriegeskorte", "title": "Visualizing the geometry of labeled high-dimensional data with spheres", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data visualizations summarize high-dimensional distributions in two or three\ndimensions. Dimensionality reduction entails a loss of information, and what is\npreserved differs between methods. Existing methods preserve the local or the\nglobal geometry of the points, and most techniques do not consider labels. Here\nwe introduce \"hypersphere2sphere\" (H2S), a new method that aims to visualize\nnot the points, but the relationships between the labeled distributions. H2S\nfits a hypersphere to each labeled set of points in a high-dimensional space\nand visualizes each hypersphere as a sphere in 3D (or circle in 2D). H2S\nperfectly captures the geometry of up to 4 hyperspheres in 3D (or 3 in 2D), and\napproximates the geometry for larger numbers of distributions, matching the\nsizes (radii), and the pairwise separations (between-center distances) and\noverlaps (along the center-connection line). The resulting visualizations are\nrobust to sampling imbalances. Leveraging labels and the sphere as the simplest\ngeometrical primitive, H2S provides an important addition to the toolbox of\nvisualization techniques.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 20:15:54 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Zaharia", "Andrew D", ""], ["Potnis", "Anish S", ""], ["Walther", "Alexander", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "2107.00814", "submitter": "Emmanuel Guigon", "authors": "Emmanuel Guigon", "title": "A computational theory for the production of limb movements", "comments": "107 pages, 21 figures. To appear in Psychological Review. Minor\n  corrections (Table 2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Motor control is a fundamental process that underlies all voluntary\nbehavioral responses. Several different theories based on different principles\n(task dynamics, equilibrium-point theory, passive-motion paradigm, active\ninference, optimal control) account for specific aspects of how actions are\nproduced, but fail to provide a unified view on this problem. Here we propose a\nconcise theory of motor control based on three principles: optimal feedback\ncontrol, control with a receding time horizon, and task representation by a\nseries of via-points updated at fixed frequency. By construction, the theory\nprovides a suitable solution to the degrees-of-freedom problem, i.e. trajectory\nformation in the presence of redundancies and noise. We show through computer\nsimulations that the theory also explains the production of discrete,\ncontinuous, rhythmic and temporally-constrained movements, and their parametric\nand statistical properties (scaling laws, power laws, speed/accuracy\ntradeoffs). The theory has no free parameters and only limited variations in\nits implementation details and in the nature of noise are necessary to\nguarantee its explanatory power.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 03:41:51 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 12:23:49 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Guigon", "Emmanuel", ""]]}, {"id": "2107.01303", "submitter": "Javid Dadashkarimi", "authors": "Javid Dadashkarimi and Amin Karbasi and Dustin Scheinost", "title": "Data-driven mapping between functional connectomes using optimal\n  transport", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional connectomes derived from functional magnetic resonance imaging\nhave long been used to understand the functional organization of the brain.\nNevertheless, a connectome is intrinsically linked to the atlas used to create\nit. In other words, a connectome generated from one atlas is different in scale\nand resolution compared to a connectome generated from another atlas. Being\nable to map connectomes and derived results between different atlases without\nadditional pre-processing is a crucial step in improving interpretation and\ngeneralization between studies that use different atlases. Here, we use optimal\ntransport, a powerful mathematical technique, to find an optimum mapping\nbetween two atlases. This mapping is then used to transform time series from\none atlas to another in order to reconstruct a connectome. We validate our\napproach by comparing transformed connectomes against their \"gold-standard\"\ncounterparts (i.e., connectomes generated directly from an atlas) and\ndemonstrate the utility of transformed connectomes by applying these\nconnectomes to predictive models based on a different atlas. We show that these\ntransformed connectomes are significantly similar to their \"gold-standard\"\ncounterparts and maintain individual differences in brain-behavior\nassociations, demonstrating both the validity of our approach and its utility\nin downstream analyses. Overall, our approach is a promising avenue to increase\nthe generalization of connectome-based results across different atlases.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 23:43:34 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Dadashkarimi", "Javid", ""], ["Karbasi", "Amin", ""], ["Scheinost", "Dustin", ""]]}, {"id": "2107.01312", "submitter": "Mason A. Porter", "authors": "Elisa C. Baek, Ryan Hyon, Karina L\\'opez, Mason A. Porter, and Carolyn\n  Parkinson", "title": "Lonely individuals process the world in idiosyncratic ways", "comments": "arXiv admin note: substantial text overlap with arXiv:2106.02726", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loneliness (i.e., the distressing feeling that often accompanies the\nsubjective sense of social disconnection) is detrimental to mental and physical\nhealth, and deficits in self-reported feelings of being understood by others is\na risk factor for loneliness. What contributes to these deficits in lonely\npeople? We used functional magnetic resonance imaging (fMRI) to unobtrusively\nmeasure the relative alignment of various aspects of people's mental processing\nof naturalistic stimuli (specifically, videos) as they unfold over time. We\nthereby tested whether lonely people actually process the world in\nidiosyncratic ways, rather than only exaggerating or misperceiving how\ndissimilar others' views are to their own (which could lead them to feel\nmisunderstood, even if they actually see the world similarly to those around\nthem). We found evidence for such idiosyncrasy: lonely individuals' neural\nresponses during free viewing of the videos were dissimilar to peers in their\ncommunities, particularly in brain regions (e.g., regions of the default-mode\nnetwork) in which similar responses have been associated with shared\npsychological perspectives and subjective understanding. Our findings were\nrobust even after controlling for demographic similarities, participants'\noverall levels of objective social isolation, and their friendships with each\nother. These results suggest that being surrounded predominantly by people who\nsee the world differently from oneself may be a risk factor for loneliness,\neven if one is friends with them.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 00:34:16 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Baek", "Elisa C.", ""], ["Hyon", "Ryan", ""], ["L\u00f3pez", "Karina", ""], ["Porter", "Mason A.", ""], ["Parkinson", "Carolyn", ""]]}, {"id": "2107.01699", "submitter": "Vince Grolmusz", "authors": "Laszlo Keresztes and Evelin Szogi and Balint Varga and Vince Grolmusz", "title": "Discovering Sex and Age Implicator Edges in the Human Connectome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining important vertices in large graphs (e.g., Google's PageRank in\nthe case of the graph of the World Wide Web) facilitated the construction of\nexcellent web search engines, returning the most important hits corresponding\nto the submitted user queries. Interestingly, finding important edges --\ninstead of vertices -- in large graphs has received much less attention until\nnow. Here we examine the human structural braingraph (or connectome),\nidentified by diffusion magnetic resonance imaging (dMRI) methods, with edges\nconnecting cortical and subcortical gray matter areas and weighted by fiber\nstrengths, measured by the number of the discovered fiber tracts along the\nedge. We identify several \"single\" important edges in these braingraphs, whose\nhigh or low weights imply the sex or the age of the subject observed. We call\nthese edges implicator edges since solely from their weight, one can infer the\nsex of the subject with more than 67 \\% accuracy or their age group with more\nthan 62\\% accuracy. We argue that these brain connections are the most\nimportant ones characterizing the sex or the age of the subjects. Surprisingly,\nthe edges implying the male sex are mostly located in the anterior parts of the\nbrain, while those implying the female sex are mostly in the posterior regions.\nAdditionally, most of the inter-hemispheric implicator edges are male ones,\nwhile the intra-hemispheric ones are predominantly female edges. Our pioneering\nmethod for finding the sex- or age implicator edges can also be applied for\ncharacterizing other biological and medical properties, including\nneurodegenerative- and psychiatric diseases besides the sex or the age of the\nsubject, if large and high-quality neuroimaging datasets become available.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 18:09:23 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Keresztes", "Laszlo", ""], ["Szogi", "Evelin", ""], ["Varga", "Balint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "2107.02146", "submitter": "Ali Mahzarnia", "authors": "Ali Mahzarnia and Jun Song", "title": "Multivariate functional group sparse regression: functional predictor\n  selection", "comments": "The R package that is developed for this paper is available at\n  GitHub. See https://github.com/Ali-Mahzarnia/MFSGrp", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.ST q-bio.NC stat.AP stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose methods for functional predictor selection and the\nestimation of smooth functional coefficients simultaneously in a\nscalar-on-function regression problem under high-dimensional multivariate\nfunctional data setting. In particular, we develop two methods for functional\ngroup-sparse regression under a generic Hilbert space of infinite dimension. We\nshow the convergence of algorithms and the consistency of the estimation and\nthe selection (oracle property) under infinite-dimensional Hilbert spaces.\nSimulation studies show the effectiveness of the methods in both the selection\nand the estimation of functional coefficients. The applications to the\nfunctional magnetic resonance imaging (fMRI) reveal the regions of the human\nbrain related to ADHD and IQ.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 17:11:28 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 15:03:06 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Mahzarnia", "Ali", ""], ["Song", "Jun", ""]]}, {"id": "2107.02429", "submitter": "Hong-Gyu Yoon", "authors": "Hong-Gyu Yoon and Pilwon Kim", "title": "STDP-based Associative Memory Formation and Retrieval", "comments": "7 pages of main article, 12 pages of appendices. arXiv admin note:\n  substantial text overlap with arXiv:2104.12249", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spike-timing-dependent plasticity(STDP) is a biological process in which the\nprecise order and timing of neuronal spikes affect the degree of synaptic\nmodification. While there have been numerous research focusing on the role of\nSTDP in neural coding, the functional implications of STDP at the macroscopic\nlevel in the brain have not been fully explored yet. In this work, we propose a\nneurodynamical model based on STDP that renders storage and retrieval of a\ngroup of associative memories. We showed that the function of STDP at the\nmacroscopic level is to form a \"memory plane\" in the neural state space which\ndynamically encodes high dimensional data. We derived the analytic relation\nbetween the input, the memory plane, and the induced macroscopic neural\noscillations around the memory plane. Such plane produces a limit cycle in\nreaction to a similar memory cue, which can be used for retrieval of the\noriginal input.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 07:08:21 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 04:18:20 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Yoon", "Hong-Gyu", ""], ["Kim", "Pilwon", ""]]}, {"id": "2107.02704", "submitter": "Divya Varadarajan", "authors": "Divya Varadarajan, Katherine L. Bouman, Andre van der Kouwe, Bruce\n  Fischl, Adrian V. Dalca", "title": "Unsupervised learning of MRI tissue properties using MRI physics models", "comments": "11 Pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In neuroimaging, MRI tissue properties characterize underlying neurobiology,\nprovide quantitative biomarkers for neurological disease detection and\nanalysis, and can be used to synthesize arbitrary MRI contrasts. Estimating\ntissue properties from a single scan session using a protocol available on all\nclinical scanners promises to reduce scan time and cost, enable quantitative\nanalysis in routine clinical scans and provide scan-independent biomarkers of\ndisease. However, existing tissue properties estimation methods - most often\n$\\mathbf{T_1}$ relaxation, $\\mathbf{T_2^*}$ relaxation, and proton density\n($\\mathbf{PD}$) - require data from multiple scan sessions and cannot estimate\nall properties from a single clinically available MRI protocol such as the\nmultiecho MRI scan. In addition, the widespread use of non-standard acquisition\nparameters across clinical imaging sites require estimation methods that can\ngeneralize across varying scanner parameters. However, existing learning\nmethods are acquisition protocol specific and cannot estimate from heterogenous\nclinical data from different imaging sites. In this work we propose an\nunsupervised deep-learning strategy that employs MRI physics to estimate all\nthree tissue properties from a single multiecho MRI scan session, and\ngeneralizes across varying acquisition parameters. The proposed strategy\noptimizes accurate synthesis of new MRI contrasts from estimated latent tissue\nproperties, enabling unsupervised training, we also employ random acquisition\nparameters during training to achieve acquisition generalization. We provide\nthe first demonstration of estimating all tissue properties from a single\nmultiecho scan session. We demonstrate improved accuracy and generalizability\nfor tissue property estimation and MRI synthesis.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 16:07:14 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Varadarajan", "Divya", ""], ["Bouman", "Katherine L.", ""], ["van der Kouwe", "Andre", ""], ["Fischl", "Bruce", ""], ["Dalca", "Adrian V.", ""]]}, {"id": "2107.02993", "submitter": "Mayela Zamora Dr", "authors": "Mayela Zamora, Sebastian Meller, Filip Kajin, James J Sermon, Robert\n  Toth, Moaad Benjaber, Derk-Jan Dijk, Rafal Bogacz, Gregory A Worrell, Antonio\n  Valentin, Benoit Duchet, Holger A Volk, Timothy Denison", "title": "Embedding digital chronotherapy into medical devices -- A canine case\n  study in controlling status epilepticus through multi-scale rhythmic brain\n  stimulation", "comments": "6 text pages, 4 main figures, Fig 1 has 4 panels, Fig 2 has 3 panels,\n  Fig 4 has 2 panels. 2 text pages of supplementary material, 1 supplementary\n  figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY eess.SP q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Circadian and other physiological rhythms play a key role in both normal\nhomeostasis and disease processes. Such is the case of circadian and infradian\nseizure patterns observed in epilepsy. However, these rhythms are not fully\nexploited in the design of active implantable medical devices. In this paper we\nexplore a new implantable stimulator that implements chronotherapy as a\nfeedforward input to supplement both open-loop and closed-loop methods. This\nintegrated algorithm allows for stimulation to be adjusted to the ultradian,\ncircadian, and infradian patterns observed in patients through slowly-varying\ntemporal adjustments of stimulation and algorithm sub-components, while also\nenabling adaption of stimulation based on immediate physiological needs such as\na breakthrough seizure or change of posture. Embedded physiological sensors in\nthe stimulator can be used to refine the baseline stimulation circadian pattern\nas a \"digital zeitgeber\". This algorithmic approach is tested on a canine with\nsevere drug-resistant idiopathic generalized epilepsy exhibiting a\ncharacteristic diurnal pattern correlated with sleep-wake cycles. Prior to\nimplantation, the canine's cluster seizures evolved to status epilepticus (SE)\nand required emergency pharmacological intervention. The cranially-mounted\nsystem was fully-implanted bilaterally into the centromedian nucleus of the\nthalamus. Using combinations of time-based modulation, thalamocortical\nrhythm-specific tuning of frequency parameters, and fast-adaptive modes based\non activity, the canine has experienced no further SE events post-implant at\nthe time of writing (7 months), and no significant clusters are observed any\nlonger. The use of digitally-enabled chronotherapy as a feedforward signal to\naugment adaptive neurostimulators could prove a useful algorithmic method where\nsensitivity to temporal patterns are characteristics of the disease state.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:18:40 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zamora", "Mayela", ""], ["Meller", "Sebastian", ""], ["Kajin", "Filip", ""], ["Sermon", "James J", ""], ["Toth", "Robert", ""], ["Benjaber", "Moaad", ""], ["Dijk", "Derk-Jan", ""], ["Bogacz", "Rafal", ""], ["Worrell", "Gregory A", ""], ["Valentin", "Antonio", ""], ["Duchet", "Benoit", ""], ["Volk", "Holger A", ""], ["Denison", "Timothy", ""]]}, {"id": "2107.02995", "submitter": "Kaiyuan Yang", "authors": "Zhanghao Yu, Joshua C. Chen, Fatima T. Alrashdan, Benjamin W. Avants,\n  Yan He, Amanda Singer, Jacob T. Robinson, Kaiyuan Yang", "title": "MagNI: A Magnetoelectrically Powered and Controlled Wireless\n  Neurostimulating Implant", "comments": "This work has been accepted to 2020 IEEE Transactions on Biomedical\n  Circuits and Systems (TBioCAS)", "journal-ref": "IEEE Transactions on Biomedical Circuits and Systems (TBioCAS),\n  Volume: 14, Issue: 6, Pages: 1241-1252, Dec. 2020", "doi": "10.1109/TBCAS.2020.3037862", "report-no": null, "categories": "q-bio.NC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first wireless and programmable neural stimulator\nleveraging magnetoelectric (ME) effects for power and data transfer. Thanks to\nlow tissue absorption, low misalignment sensitivity and high power transfer\nefficiency, the ME effect enables safe delivery of high power levels (a few\nmilliwatts) at low resonant frequencies (~250 kHz) to mm-sized implants deep\ninside the body (30-mm depth). The presented MagNI (Magnetoelectric Neural\nImplant) consists of a 1.5-mm$^2$ 180-nm CMOS chip, an in-house built 4x2 mm ME\nfilm, an energy storage capacitor, and on-board electrodes on a flexible\npolyimide substrate with a total volume of 8.2 mm$^3$ . The chip with a power\nconsumption of 23.7 $\\mu$W includes robust system control and data recovery\nmechanisms under source amplitude variations (1-V variation tolerance). The\nsystem delivers fully-programmable bi-phasic current-controlled stimulation\nwith patterns covering 0.05-to-1.5-mA amplitude, 64-to-512-$\\mu$s pulse width,\nand 0-to-200Hz repetition frequency for neurostimulation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 03:30:10 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Yu", "Zhanghao", ""], ["Chen", "Joshua C.", ""], ["Alrashdan", "Fatima T.", ""], ["Avants", "Benjamin W.", ""], ["He", "Yan", ""], ["Singer", "Amanda", ""], ["Robinson", "Jacob T.", ""], ["Yang", "Kaiyuan", ""]]}, {"id": "2107.03220", "submitter": "Yanqiao Zhu", "authors": "Yanqiao Zhu, Hejie Cui, Lifang He, Lichao Sun, Carl Yang", "title": "Joint Embedding of Structural and Functional Brain Networks with Graph\n  Neural Networks for Mental Illness Diagnosis", "comments": "Accepted to ICML 2021 Workshop on Computational Approaches to Mental\n  Health", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG physics.med-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal brain networks characterize complex connectivities among different\nbrain regions from both structural and functional aspects and provide a new\nmeans for mental disease analysis. Recently, Graph Neural Networks (GNNs) have\nbecome a de facto model for analyzing graph-structured data. However, how to\nemploy GNNs to extract effective representations from brain networks in\nmultiple modalities remains rarely explored. Moreover, as brain networks\nprovide no initial node features, how to design informative node attributes and\nleverage edge weights for GNNs to learn is left unsolved. To this end, we\ndevelop a novel multiview GNN for multimodal brain networks. In particular, we\nregard each modality as a view for brain networks and employ contrastive\nlearning for multimodal fusion. Then, we propose a GNN model which takes\nadvantage of the message passing scheme by propagating messages based on degree\nstatistics and brain region connectivities. Extensive experiments on two\nreal-world disease datasets (HIV and Bipolar) demonstrate the effectiveness of\nour proposed method over state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:49:57 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhu", "Yanqiao", ""], ["Cui", "Hejie", ""], ["He", "Lifang", ""], ["Sun", "Lichao", ""], ["Yang", "Carl", ""]]}, {"id": "2107.03231", "submitter": "Arthur Prat-Carrabin", "authors": "Arthur Prat-Carrabin, Florent Meyniel, Misha Tsodyks and Rava Azeredo\n  da Silveira", "title": "Biases and Variability from Costly Bayesian Inference", "comments": "17 pages, 4 figures", "journal-ref": "Entropy 2021, 23(5), 603", "doi": "10.3390/e23050603", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  When humans infer underlying probabilities from stochastic observations, they\nexhibit biases and variability that cannot be explained on the basis of sound,\nBayesian manipulations of probability. This is especially salient when beliefs\nare updated as a function of sequential observations. We introduce a\ntheoretical framework in which biases and variability emerge from a trade-off\nbetween Bayesian inference and a cognitive cost of carrying out probabilistic\ncomputations. We consider two forms of the cost: a precision cost and an\nunpredictability cost; these penalize beliefs that are less entropic and less\ndeterministic, respectively. We apply our framework to the case of a Bernoulli\nvariable: the bias of a coin is inferred from a sequence of coin flips.\nTheoretical predictions are qualitatively different depending on the form of\nthe cost. A precision cost induces overestimation of small probabilities on\naverage and a limited memory of past observations, and, consequently, a\nfluctuating bias. An unpredictability cost induces underestimation of small\nprobabilities and a fixed bias that remains appreciable even for nearly\nunbiased observations. The case of a fair (equiprobable) coin, however, is\nsingular, with non-trivial and slow fluctuations of the inferred bias. The\nproposed framework of costly Bayesian inference illustrates the richness of a\n'resource-rational' (or 'bounded-rational') picture of seemingly irrational\nhuman cognition.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:02:38 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Prat-Carrabin", "Arthur", ""], ["Meyniel", "Florent", ""], ["Tsodyks", "Misha", ""], ["da Silveira", "Rava Azeredo", ""]]}, {"id": "2107.03372", "submitter": "Ankush Kumar", "authors": "Ankush Kumar, Kamila Janzakova, Yannick Coffinier, S\\'ebastien\n  Pecqueur, Fabien Alibart", "title": "Theoretical modeling of dendrite growth from conductive wire\n  electropolymerization", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech physics.app-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electropolymerization is a bottom-up materials engineering process of micro\nand nano-scale that utilizes electrical signals to deposit conducting\ndendrites' morphologies by a redox reaction in the liquid phase. It resembles\nsynaptogenesis in the brain, in which electrical stimulation in the brain\ncauses the formation of synapses from the cellular neural composites. The\nstrategy has been recently explored for neuromorphic engineering by\nestablishing link between the electrical signals and the dendrites' shapes.\nSince the geometry of these structures determines their electrochemical\nproperties, understanding the mechanisms that regulate the polymer assembly\nunder electrically programmed conditions is an important aspect. In this\nmanuscript, we simulate this phenomenon using mesoscale simulations, taking\ninto account the important features of spatial-temporal potential mapping based\non the time-varying signal, the motion of charged particles in the liquid due\nto the electric field, and the attachment of particles on the electrode. The\nstudy helps in visualizing the motion of particles in different electrical\nconditions, which is not possible to probe experimentally. Consistent with the\nexperiments, the higher AC frequency of electrical activities favors linear\nwire-like growth, while lower frequency leads to more dense and fractal\ndendrites growth, and voltage offset leads to asymmetrical growth. We find that\ndendrites' shape and growth process systematically depend on particle\nconcentration and random scattering. We discover that the different dendrites'\narchitectures are associated with different Laplace and diffusion fields, which\ngovern the monomers trajectory and subsequent dendrites' growth. Such\nunconventional engineering routes could have a variety of applications from\nneuromorphic engineering to bottom-up computing strategies.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 17:35:49 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Kumar", "Ankush", ""], ["Janzakova", "Kamila", ""], ["Coffinier", "Yannick", ""], ["Pecqueur", "S\u00e9bastien", ""], ["Alibart", "Fabien", ""]]}, {"id": "2107.03387", "submitter": "Tim Cvetko", "authors": "Tim Cvetko, Tinkara Robek", "title": "Sleep syndromes onset detection based on automatic sleep staging\n  algorithm", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel method and a practical approach to\npredicting early onsets of sleep syndromes, including restless leg syndrome,\ninsomnia, based on an algorithm that is comprised of two modules. A Fast\nFourier Transform is applied to 30 seconds long epochs of EEG recordings to\nprovide localized time-frequency information, and a deep convolutional LSTM\nneural network is trained for sleep stage classification. Automating sleep\nstages detection from EEG data offers great potential to tackling sleep\nirregularities on a daily basis. Thereby, a novel approach for sleep stage\nclassification is proposed which combines the best of signal processing and\nstatistics. In this study, we used the PhysioNet Sleep European Data Format\n(EDF) Database. The code evaluation showed impressive results, reaching an\naccuracy of 86.43, precision of 77.76, recall of 93,32, F1-score of 89.12 with\nthe final mean false error loss of 0.09.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:38:47 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Cvetko", "Tim", ""], ["Robek", "Tinkara", ""]]}, {"id": "2107.03475", "submitter": "Pantea Moghimi", "authors": "Pantea Moghimi, Anh The Dang, Theoden I. Netoff, Kelvin O. Lim,\n  Gowtham Atluri", "title": "A Review on MR Based Human Brain Parcellation Methods", "comments": "31 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Brain parcellations play a ubiquitous role in the analysis of magnetic\nresonance imaging (MRI) datasets. Over 100 years of research has been conducted\nin pursuit of an ideal brain parcellation. Different methods have been\ndeveloped and studied for constructing brain parcellations using different\nimaging modalities. More recently, several data-driven parcellation methods\nhave been adopted from data mining, machine learning, and statistics\ncommunities. With contributions from different scientific fields, there is a\nrich body of literature that needs to be examined to appreciate the breadth of\nexisting research and the gaps that need to be investigated. In this work, we\nreview the large body of in vivo brain parcellation research spanning different\nneuroimaging modalities and methods. A key contribution of this work is a\nsemantic organization of this large body of work into different taxonomies,\nmaking it easy to understand the breadth and depth of the brain parcellation\nliterature. Specifically, we categorized the existing parcellations into three\ngroups: Anatomical parcellations, functional parcellations, and structural\nparcellations which are constructed using T1-weighted MRI, functional MRI\n(fMRI), and diffusion-weighted imaging (DWI) datasets, respectively. We provide\na multi-level taxonomy of different methods studied in each of these\ncategories, compare their relative strengths and weaknesses, and highlight the\nchallenges currently faced for the development of brain parcellations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 20:55:51 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Moghimi", "Pantea", ""], ["Dang", "Anh The", ""], ["Netoff", "Theoden I.", ""], ["Lim", "Kelvin O.", ""], ["Atluri", "Gowtham", ""]]}, {"id": "2107.03971", "submitter": "Julien Lagarde", "authors": "Julien Lagarde", "title": "The classical mean negative asynchrony in sensorimotor synchronization\n  is not universal in humans. A cross-cultural study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The present study examines to what extent cultural background determines\nsensorimotor synchronization in humans\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 16:56:05 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Lagarde", "Julien", ""]]}, {"id": "2107.04084", "submitter": "Srdjan Ostojic", "authors": "Mehrdad Jazayeri, Srdjan Ostojic", "title": "Interpreting neural computations by examining intrinsic and embedding\n  dimensionality of neural activity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current exponential rise in recording capacity calls for new approaches\nfor analysing and interpreting neural data. Effective dimensionality has\nemerged as a key concept for describing neural activity at the collective\nlevel, yet different studies rely on a variety of definitions of it. Here we\nfocus on the complementary notions of intrinsic and embedding dimensionality,\nand argue that they provide a useful framework for extracting computational\nprinciples from data. Reviewing recent works, we propose that the intrinsic\ndimensionality reflects information about the latent variables encoded in\ncollective activity, while embedding dimensionality reveals the manner in which\nthis information is processed. Network models form an ideal substrate for\ntesting more specifically the hypotheses on the computational principles\nreflected through intrinsic and embedding dimensionality.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 19:38:29 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Jazayeri", "Mehrdad", ""], ["Ostojic", "Srdjan", ""]]}, {"id": "2107.04724", "submitter": "Qingyu Zhao", "authors": "Qingyu Zhao, Ehsan Adeli, Kilian M. Pohl", "title": "Longitudinal Correlation Analysis for Decoding Multi-Modal Brain\n  Development", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting from childhood, the human brain restructures and rewires throughout\nlife. Characterizing such complex brain development requires effective analysis\nof longitudinal and multi-modal neuroimaging data. Here, we propose such an\nanalysis approach named Longitudinal Correlation Analysis (LCA). LCA couples\nthe data of two modalities by first reducing the input from each modality to a\nlatent representation based on autoencoders. A self-supervised strategy then\nrelates the two latent spaces by jointly disentangling two directions, one in\neach space, such that the longitudinal changes in latent representations along\nthose directions are maximally correlated between modalities. We applied LCA to\nanalyze the longitudinal T1-weighted and diffusion-weighted MRIs of 679 youths\nfrom the National Consortium on Alcohol and Neurodevelopment in Adolescence.\nUnlike existing approaches that focus on either cross-sectional or single-modal\nmodeling, LCA successfully unraveled coupled macrostructural and\nmicrostructural brain development from morphological and diffusivity features\nextracted from the data. A retesting of LCA on raw 3D image volumes of those\nsubjects successfully replicated the findings from the feature-based analysis.\nLastly, the developmental effects revealed by LCA were inline with the current\nunderstanding of maturational patterns of the adolescent brain.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 00:07:06 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhao", "Qingyu", ""], ["Adeli", "Ehsan", ""], ["Pohl", "Kilian M.", ""]]}, {"id": "2107.05097", "submitter": "Hejie Cui", "authors": "Hejie Cui, Wei Dai, Yanqiao Zhu, Xiaoxiao Li, Lifang He, Carl Yang", "title": "BrainNNExplainer: An Interpretable Graph Neural Network Framework for\n  Brain Network based Disease Analysis", "comments": "This paper has been accepted to ICML 2021 Workshop on Interpretable\n  Machine Learning in Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretable brain network models for disease prediction are of great value\nfor the advancement of neuroscience. GNNs are promising to model complicated\nnetwork data, but they are prone to overfitting and suffer from poor\ninterpretability, which prevents their usage in decision-critical scenarios\nlike healthcare. To bridge this gap, we propose BrainNNExplainer, an\ninterpretable GNN framework for brain network analysis. It is mainly composed\nof two jointly learned modules: a backbone prediction model that is\nspecifically designed for brain networks and an explanation generator that\nhighlights disease-specific prominent brain network connections. Extensive\nexperimental results with visualizations on two challenging disease prediction\ndatasets demonstrate the unique interpretability and outstanding performance of\nBrainNNExplainer.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 17:33:02 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Cui", "Hejie", ""], ["Dai", "Wei", ""], ["Zhu", "Yanqiao", ""], ["Li", "Xiaoxiao", ""], ["He", "Lifang", ""], ["Yang", "Carl", ""]]}, {"id": "2107.05242", "submitter": "S{\\o}ren Andersen", "authors": "S{\\o}ren S. L. Andersen", "title": "Real time large scale $\\textit{in vivo}$ observations by light-sheet\n  microscopy reveal intrinsic synchrony, plasticity and growth cone dynamics of\n  midline crossing axons at the ventral floor plate of the zebrafish spinal\n  cord", "comments": "38 A4 pages, 19 PNG figures, 16 MP4 movies", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM q-bio.SC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Axonal growth and guidance at the ventral floor plate is here followed\n$\\textit{in vivo}$ in real time at high resolution by light-sheet microscopy\nalong several hundred micrometers of the zebrafish spinal cord. The recordings\nshow the strikingly stereotyped spatio-temporal control that governs midline\ncrossing. Commissural axons are observed crossing the ventral floor plate\nmidline perpendicularly at about 20 microns/h, in a manner dependent on the\nRobo3 receptor and with a growth rate minimum around the midline, confirming\nprevious observations. At guidance points, commissural axons are seen to\ndecrease their growth rate and growth cones increase in size. Commissural\nfilopodia appear to interact with the nascent neural network, and thereby\ntrigger immediate plastic and reversible sinusoidal-shaped bending movements of\nneighboring commissural shafts. Ipsilateral axons extend concurrently, but\nstraight and without bends, at three to six times higher growth rates than\ncommissurals, indicating they project their path on a substrate-bound surface\nrather than relying on diffusible guidance cues. Growing axons appeared to be\nunder stretch, an observation that is of relevance for tension-based models of\ncortical morphogenesis. The \\textit{in vivo} observations provide for a\ndiscussion of the current distinction between substrate-bound and diffusible\nguidance cues. The study applies the transparent zebrafish model that provides\nan experimental model system to explore further the cellular, molecular and\nphysical mechanisms involved during axonal growth, guidance and midline\ncrossing through a combination of $\\textit{in vitro}$ and $\\textit{in vivo}$\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:06:27 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Andersen", "S\u00f8ren S. L.", ""]]}, {"id": "2107.05336", "submitter": "Fabian Schubert", "authors": "Fabian Schubert and Claudius Gros", "title": "Nonlinear Dendritic Coincidence Detection for Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cortical pyramidal neurons have a complex dendritic anatomy, whose function\nis an active research field. In particular, the segregation between its soma\nand the apical dendritic tree is believed to play an active role in processing\nfeed-forward sensory information and top-down or feedback signals. In this\nwork, we use a simple two-compartment model accounting for the nonlinear\ninteractions between basal and apical input streams and show that standard\nunsupervised Hebbian learning rules in the basal compartment allow the neuron\nto align the feed-forward basal input with the top-down target signal received\nby the apical compartment. We show that this learning process, termed\ncoincidence detection, is robust against strong distractions in the basal input\nspace and demonstrate its effectiveness in a linear classification task.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:51:12 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Schubert", "Fabian", ""], ["Gros", "Claudius", ""]]}, {"id": "2107.05438", "submitter": "Noor Sajid", "authors": "Noor Sajid and Francesco Faccio and Lancelot Da Costa and Thomas Parr\n  and J\\\"urgen Schmidhuber and Karl Friston", "title": "Bayesian brains and the R\\'enyi divergence", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Under the Bayesian brain hypothesis, behavioural variations can be attributed\nto different priors over generative model parameters. This provides a formal\nexplanation for why individuals exhibit inconsistent behavioural preferences\nwhen confronted with similar choices. For example, greedy preferences are a\nconsequence of confident (or precise) beliefs over certain outcomes. Here, we\noffer an alternative account of behavioural variability using R\\'enyi\ndivergences and their associated variational bounds. R\\'enyi bounds are\nanalogous to the variational free energy (or evidence lower bound) and can be\nderived under the same assumptions. Importantly, these bounds provide a formal\nway to establish behavioural differences through an $\\alpha$ parameter, given\nfixed priors. This rests on changes in $\\alpha$ that alter the bound (on a\ncontinuous scale), inducing different posterior estimates and consequent\nvariations in behaviour. Thus, it looks as if individuals have different\npriors, and have reached different conclusions. More specifically, $\\alpha \\to\n0^{+}$ optimisation leads to mass-covering variational estimates and increased\nvariability in choice behaviour. Furthermore, $\\alpha \\to + \\infty$\noptimisation leads to mass-seeking variational posteriors and greedy\npreferences. We exemplify this formulation through simulations of the\nmulti-armed bandit task. We note that these $\\alpha$ parameterisations may be\nespecially relevant, i.e., shape preferences, when the true posterior is not in\nthe same family of distributions as the assumed (simpler) approximate density,\nwhich may be the case in many real-world scenarios. The ensuing departure from\nvanilla variational inference provides a potentially useful explanation for\ndifferences in behavioural preferences of biological (or artificial) agents\nunder the assumption that the brain performs variational Bayesian inference.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:14:36 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Sajid", "Noor", ""], ["Faccio", "Francesco", ""], ["Da Costa", "Lancelot", ""], ["Parr", "Thomas", ""], ["Schmidhuber", "J\u00fcrgen", ""], ["Friston", "Karl", ""]]}, {"id": "2107.05709", "submitter": "Guillermo Barrios Morales", "authors": "Guillermo B. Morales and Miguel A. Mu\\~noz", "title": "Optimal input representation in neural systems at the edge of chaos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Shedding light onto how biological systems represent, process and store\ninformation in noisy environments is a key and challenging goal. A stimulating,\nthough controversial, hypothesis poses that operating in dynamical regimes near\nthe edge of a phase transition, i.e. at criticality or the \"edge of chaos\", can\nprovide information-processing living systems with important operational\nadvantages, creating, e.g., an optimal trade-off between robustness and\nflexibility. Here, we elaborate on a recent theoretical result, which\nestablishes that the spectrum of covariance matrices of neural networks\nrepresenting complex inputs in a robust way needs to decay as a power-law of\nthe rank, with an exponent close to unity, a result that has been indeed\nexperimentally verified in neurons of the mouse visual cortex. Aimed at\nunderstanding and mimicking these results, we construct an artificial neural\nnetwork and train it to classify images. Remarkably, we find that the best\nperformance in such a task is obtained when the network operates near the\ncritical point, at which the eigenspectrum of the covariance matrix follows the\nvery same statistics as actual neurons do. Thus, we conclude that operating\nnear criticality can also have -- besides the usually alleged virtues -- the\nadvantage of allowing for flexible, robust and efficient input representations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 19:55:03 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Morales", "Guillermo B.", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}, {"id": "2107.05747", "submitter": "Timoleon Moraitis", "authors": "Timoleon Moraitis, Dmitry Toichkin, Yansong Chua, Qinghai Guo", "title": "SoftHebb: Bayesian inference in unsupervised Hebbian soft\n  winner-take-all networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art artificial neural networks (ANNs) require labelled data or\nfeedback between layers, are often biologically implausible, and are vulnerable\nto adversarial attacks that humans are not susceptible to. On the other hand,\nHebbian learning in winner-take-all (WTA) networks, is unsupervised,\nfeed-forward, and biologically plausible. However, an objective optimization\ntheory for WTA networks has been missing, except under very limiting\nassumptions. Here we derive formally such a theory, based on biologically\nplausible but generic ANN elements. Through Hebbian learning, network\nparameters maintain a Bayesian generative model of the data. There is no\nsupervisory loss function, but the network does minimize cross-entropy between\nits activations and the input distribution. The key is a \"soft\" WTA where there\nis no absolute \"hard\" winner neuron, and a specific type of Hebbian-like\nplasticity of weights and biases. We confirm our theory in practice, where, in\nhandwritten digit (MNIST) recognition, our Hebbian algorithm, SoftHebb,\nminimizes cross-entropy without having access to it, and outperforms the more\nfrequently used, hard-WTA-based method. Strikingly, it even outperforms\nsupervised end-to-end backpropagation, under certain conditions. Specifically,\nin a two-layered network, SoftHebb outperforms backpropagation when the\ntraining dataset is only presented once, when the testing data is noisy, and\nunder gradient-based adversarial attacks. Adversarial attacks that confuse\nSoftHebb are also confusing to the human eye. Finally, the model can generate\ninterpolations of objects from its input distribution.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 21:34:45 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Moraitis", "Timoleon", ""], ["Toichkin", "Dmitry", ""], ["Chua", "Yansong", ""], ["Guo", "Qinghai", ""]]}, {"id": "2107.05807", "submitter": "Ankush Kumar", "authors": "Kamila Janzakova, Mahdi Ghazal, Ankush Kumar, Yannick Coffinier,\n  S\\'ebastien Pecqueur, and Fabien Alibart", "title": "Dendritic organic electrochemical transistors grown by\n  electropolymerization for 3D neuromorphic engineering", "comments": "22 pages, 4 figures. K. Janzakova, M. Ghazal and A. Kumar contributed\n  equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.mtrl-sci cs.ET physics.app-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major limitation of standard top-down technologies used in today's\nneuromorphic engineering is their inability to map the 3D nature of biological\nbrains. Here, we show how bipolar electropolymerization can be used to engineer\n3D networks of PEDOT:PSS dendritic fibers. By controlling the growth conditions\nof the electropolymerized material, we investigate how dendritic fibers can\nreproduce structural plasticity by creating structures of controllable shape.\nWe demonstrate gradual topologies evolution in a multi-electrode configuration.\nWe conduct a detail electrical characterization of the PEDOT:PSS dendrites\nthrough DC and impedance spectroscopy measurements and we show how organic\nelectrochemical transistors (OECT) can be realized with these structures. These\nmeasurements reveal that quasi-static and transient response of OECTs can be\nadjust by controlling dendrites' morphologies. The unique properties of organic\ndendrites are used to demonstrate short-term, long-term and structural\nplasticity, which are essential features required for future neuromorphic\nhardware development.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 01:56:48 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Janzakova", "Kamila", ""], ["Ghazal", "Mahdi", ""], ["Kumar", "Ankush", ""], ["Coffinier", "Yannick", ""], ["Pecqueur", "S\u00e9bastien", ""], ["Alibart", "Fabien", ""]]}, {"id": "2107.06281", "submitter": "Islem Rekik", "authors": "Islem Mhiri and Ahmed Nebli and Mohamed Ali Mahjoub and Islem Rekik", "title": "Non-isomorphic Inter-modality Graph Alignment and Synthesis for Holistic\n  Brain Mapping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Brain graph synthesis marked a new era for predicting a target brain graph\nfrom a source one without incurring the high acquisition cost and processing\ntime of neuroimaging data. However, existing multi-modal graph synthesis\nframeworks have several limitations. First, they mainly focus on generating\ngraphs from the same domain (intra-modality), overlooking the rich multimodal\nrepresentations of brain connectivity (inter-modality). Second, they can only\nhandle isomorphic graph generation tasks, limiting their generalizability to\nsynthesizing target graphs with a different node size and topological structure\nfrom those of the source one. More importantly, both target and source domains\nmight have different distributions, which causes a domain fracture between them\n(i.e., distribution misalignment). To address such challenges, we propose an\ninter-modality aligner of non-isomorphic graphs (IMANGraphNet) framework to\ninfer a target graph modality based on a given modality. Our three core\ncontributions lie in (i) predicting a target graph (e.g., functional) from a\nsource graph (e.g., morphological) based on a novel graph generative\nadversarial network (gGAN); (ii) using non-isomorphic graphs for both source\nand target domains with a different number of nodes, edges and structure; and\n(iii) enforcing the predicted target distribution to match that of the ground\ntruth graphs using a graph autoencoder to relax the designed loss oprimization.\nTo handle the unstable behavior of gGAN, we design a new Ground\nTruth-Preserving (GT-P) loss function to guide the generator in learning the\ntopological structure of ground truth brain graphs. Our comprehensive\nexperiments on predicting functional from morphological graphs demonstrate the\noutperformance of IMANGraphNet in comparison with its variants. This can be\nfurther leveraged for integrative and holistic brain mapping in health and\ndisease.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 08:59:55 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mhiri", "Islem", ""], ["Nebli", "Ahmed", ""], ["Mahjoub", "Mohamed Ali", ""], ["Rekik", "Islem", ""]]}, {"id": "2107.06446", "submitter": "Dmitry Krotov", "authors": "Dmitry Krotov", "title": "Hierarchical Associative Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense Associative Memories or Modern Hopfield Networks have many appealing\nproperties of associative memory. They can do pattern completion, store a large\nnumber of memories, and can be described using a recurrent neural network with\na degree of biological plausibility and rich feedback between the neurons. At\nthe same time, up until now all the models of this class have had only one\nhidden layer, and have only been formulated with densely connected network\narchitectures, two aspects that hinder their machine learning applications.\nThis paper tackles this gap and describes a fully recurrent model of\nassociative memory with an arbitrary large number of layers, some of which can\nbe locally connected (convolutional), and a corresponding energy function that\ndecreases on the dynamical trajectory of the neurons' activations. The memories\nof the full network are dynamically \"assembled\" using primitives encoded in the\nsynaptic weights of the lower layers, with the \"assembling rules\" encoded in\nthe synaptic weights of the higher layers. In addition to the bottom-up\npropagation of information, typical of commonly used feedforward neural\nnetworks, the model described has rich top-down feedback from higher layers\nthat help the lower-layer neurons to decide on their response to the input\nstimuli.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 01:38:40 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Krotov", "Dmitry", ""]]}, {"id": "2107.06572", "submitter": "Danko Georgiev", "authors": "Danko D. Georgiev", "title": "Quantum propensities in the brain cortex and free will", "comments": "21 pages, 4 figures", "journal-ref": "Biosystems 2021; 208: 104474", "doi": "10.1016/j.biosystems.2021.104474", "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Capacity of conscious agents to perform genuine choices among future\nalternatives is a prerequisite for moral responsibility. Determinism that\npervades classical physics, however, forbids free will, undermines the\nfoundations of ethics, and precludes meaningful quantification of personal\nbiases. To resolve that impasse, we utilize the characteristic indeterminism of\nquantum physics and derive a quantitative measure for the amount of free will\nmanifested by the brain cortical network. The interaction between the central\nnervous system and the surrounding environment is shown to perform a quantum\nmeasurement upon the neural constituents, which actualize a single measurement\noutcome selected from the resulting quantum probability distribution. Inherent\nbiases in the quantum propensities for alternative physical outcomes provide\nvarying amounts of free will, which can be quantified with the expected\ninformation gain from learning the actual course of action chosen by the\nnervous system. For example, neuronal electric spikes evoke deterministic\nsynaptic vesicle release in the synapses of sensory or somatomotor pathways,\nwith no free will manifested. In cortical synapses, however, vesicle release is\ntriggered indeterministically with probability of 0.35 per spike. This grants\nthe brain cortex, with its over 100 trillion synapses, an amount of free will\nexceeding 96 terabytes per second. Although reliable deterministic transmission\nof sensory or somatomotor information ensures robust adaptation of animals to\ntheir physical environment, unpredictability of behavioral responses initiated\nby decisions made by the brain cortex is evolutionary advantageous for avoiding\npredators. Thus, free will may have a survival value and could be optimized\nthrough natural selection.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 09:24:11 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Georgiev", "Danko D.", ""]]}, {"id": "2107.06762", "submitter": "Ruxandra Barbulescu", "authors": "Gon\\c{c}alo Mestre (1 and 2), Ruxandra Barbulescu (1), Arlindo L.\n  Oliveira (1 and 2) and L. Miguel Silveira (1 and 2) ((1) INESC-ID, Rua Alves\n  Redol 9, 1000-029 Lisboa, (2) IST Tecnico Lisboa, Universidade de Lisboa, Av.\n  Rovisco Pais 1, 1049-001 Lisboa)", "title": "Modelling Neuronal Behaviour with Time Series Regression: Recurrent\n  Neural Networks on C. Elegans Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given the inner complexity of the human nervous system, insight into the\ndynamics of brain activity can be gained from understanding smaller and simpler\norganisms, such as the nematode C. Elegans. The behavioural and structural\nbiology of these organisms is well-known, making them prime candidates for\nbenchmarking modelling and simulation techniques. In these complex neuronal\ncollections, classical, white-box modelling techniques based on intrinsic\nstructural or behavioural information are either unable to capture the profound\nnonlinearities of the neuronal response to different stimuli or generate\nextremely complex models, which are computationally intractable. In this paper\nwe show how the nervous system of C. Elegans can be modelled and simulated with\ndata-driven models using different neural network architectures. Specifically,\nwe target the use of state of the art recurrent neural networks architectures\nsuch as LSTMs and GRUs and compare these architectures in terms of their\nproperties and their accuracy as well as the complexity of the resulting\nmodels. We show that GRU models with a hidden layer size of 4 units are able to\naccurately reproduce with high accuracy the system's response to very different\nstimuli.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 10:39:30 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Mestre", "Gon\u00e7alo", "", "1 and 2"], ["Barbulescu", "Ruxandra", "", "1 and 2"], ["Oliveira", "Arlindo L.", "", "1 and 2"], ["Silveira", "L. Miguel", "", "1 and 2"]]}, {"id": "2107.06850", "submitter": "\\'Angel Poc-L\\'opez", "authors": "\\'Angel Poc-L\\'opez, Miguel Aguilera", "title": "Inference in neural networks using conditional mean-field methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend previous mean-field approaches for non-equilibrium neural network\nmodels to estimate correlations in the system. This offers a powerful tool for\napproximating the system dynamics as well as a fast method to infer network\nparameters from observations. We develop our method in an asymmetric kinetic\nIsing model and test its performance on 1) synthetic data generated by an\nasymmetric version of the Sherrington Kirkpatric model and 2) recordings of in\nvitro neuron spiking activity from the mouse somatosensory cortex. We find that\nour mean-field method outperforms previous ones in estimating networks\ncorrelations and successfully reconstructs network dynamics from data near a\nphase transition showing large fluctuations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 17:05:32 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Poc-L\u00f3pez", "\u00c1ngel", ""], ["Aguilera", "Miguel", ""]]}, {"id": "2107.07617", "submitter": "Yang Shen", "authors": "Yang Shen, Sanjoy Dasgupta, Saket Navlakha", "title": "Algorithmic insights on continual learning from fruit flies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continual learning in computational systems is challenging due to\ncatastrophic forgetting. We discovered a two layer neural circuit in the fruit\nfly olfactory system that addresses this challenge by uniquely combining sparse\ncoding and associative learning. In the first layer, odors are encoded using\nsparse, high dimensional representations, which reduces memory interference by\nactivating non overlapping populations of neurons for different odors. In the\nsecond layer, only the synapses between odor activated neurons and the output\nneuron associated with the odor are modified during learning; the rest of the\nweights are frozen to prevent unrelated memories from being overwritten. We\nshow empirically and analytically that this simple and lightweight algorithm\nsignificantly boosts continual learning performance. The fly associative\nlearning algorithm is strikingly similar to the classic perceptron learning\nalgorithm, albeit two modifications, which we show are critical for reducing\ncatastrophic forgetting. Overall, fruit flies evolved an efficient lifelong\nlearning algorithm, and circuit mechanisms from neuroscience can be translated\nto improve machine computation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 21:28:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Shen", "Yang", ""], ["Dasgupta", "Sanjoy", ""], ["Navlakha", "Saket", ""]]}, {"id": "2107.08514", "submitter": "Amit Joshi Dr", "authors": "Pranali Kokate, Sidharth Pancholi, Amit M. Joshi", "title": "Classification of Upper Arm Movements from EEG signals using Machine\n  Learning with ICA Analysis", "comments": "41 Pages, Figures 32, Table 9", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.HC cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Brain-Computer Interface system is a profoundly developing area of\nexperimentation for Motor activities which plays vital role in decoding\ncognitive activities. Classification of Cognitive-Motor Imagery activities from\nEEG signals is a critical task. Hence proposed a unique algorithm for\nclassifying left/right-hand movements by utilizing Multi-layer Perceptron\nNeural Network. Handcrafted statistical Time domain and Power spectral density\nfrequency domain features were extracted and obtained a combined accuracy of\n96.02%. Results were compared with the deep learning framework. In addition to\naccuracy, Precision, F1-Score, and recall was considered as the performance\nmetrics. The intervention of unwanted signals contaminates the EEG signals\nwhich influence the performance of the algorithm. Therefore, a novel approach\nwas approached to remove the artifacts using Independent Components Analysis\nwhich boosted the performance. Following the selection of appropriate feature\nvectors that provided acceptable accuracy. The same method was used on all nine\nsubjects. As a result, intra-subject accuracy was obtained for 9 subjects\n94.72%. The results show that the proposed approach would be useful to classify\nthe upper limb movements accurately.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 18:56:28 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Kokate", "Pranali", ""], ["Pancholi", "Sidharth", ""], ["Joshi", "Amit M.", ""]]}, {"id": "2107.08530", "submitter": "Christopher Stock", "authors": "Christopher H. Stock, Sarah E. Harvey, Samuel A. Ocko, Surya Ganguli", "title": "Synaptic balancing: a biologically plausible local learning rule that\n  provably increases neural network noise robustness without sacrificing task\n  performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel, biologically plausible local learning rule that\nprovably increases the robustness of neural dynamics to noise in nonlinear\nrecurrent neural networks with homogeneous nonlinearities. Our learning rule\nachieves higher noise robustness without sacrificing performance on the task\nand without requiring any knowledge of the particular task. The plasticity\ndynamics -- an integrable dynamical system operating on the weights of the\nnetwork -- maintains a multiplicity of conserved quantities, most notably the\nnetwork's entire temporal map of input to output trajectories. The outcome of\nour learning rule is a synaptic balancing between the incoming and outgoing\nsynapses of every neuron. This synaptic balancing rule is consistent with many\nknown aspects of experimentally observed heterosynaptic plasticity, and\nmoreover makes new experimentally testable predictions relating plasticity at\nthe incoming and outgoing synapses of individual neurons. Overall, this work\nprovides a novel, practical local learning rule that exactly preserves overall\nnetwork function and, in doing so, provides new conceptual bridges between the\ndisparate worlds of the neurobiology of heterosynaptic plasticity, the\nengineering of regularized noise-robust networks, and the mathematics of\nintegrable Lax dynamical systems.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 20:15:43 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Stock", "Christopher H.", ""], ["Harvey", "Sarah E.", ""], ["Ocko", "Samuel A.", ""], ["Ganguli", "Surya", ""]]}, {"id": "2107.09133", "submitter": "Daniel Kunin", "authors": "Daniel Kunin, Javier Sagastuy-Brena, Lauren Gillespie, Eshed Margalit,\n  Hidenori Tanaka, Surya Ganguli, Daniel L. K. Yamins", "title": "Rethinking the limiting dynamics of SGD: modified loss, phase space\n  oscillations, and anomalous diffusion", "comments": "30 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cond-mat.stat-mech q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we explore the limiting dynamics of deep neural networks trained\nwith stochastic gradient descent (SGD). We find empirically that long after\nperformance has converged, networks continue to move through parameter space by\na process of anomalous diffusion in which distance travelled grows as a power\nlaw in the number of gradient updates with a nontrivial exponent. We reveal an\nintricate interaction between the hyperparameters of optimization, the\nstructure in the gradient noise, and the Hessian matrix at the end of training\nthat explains this anomalous diffusion. To build this understanding, we first\nderive a continuous-time model for SGD with finite learning rates and batch\nsizes as an underdamped Langevin equation. We study this equation in the\nsetting of linear regression, where we can derive exact, analytic expressions\nfor the phase space dynamics of the parameters and their instantaneous\nvelocities from initialization to stationarity. Using the Fokker-Planck\nequation, we show that the key ingredient driving these dynamics is not the\noriginal training loss, but rather the combination of a modified loss, which\nimplicitly regularizes the velocity, and probability currents, which cause\noscillations in phase space. We identify qualitative and quantitative\npredictions of this theory in the dynamics of a ResNet-18 model trained on\nImageNet. Through the lens of statistical physics, we uncover a mechanistic\norigin for the anomalous limiting dynamics of deep neural networks trained with\nSGD.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 20:18:57 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Kunin", "Daniel", ""], ["Sagastuy-Brena", "Javier", ""], ["Gillespie", "Lauren", ""], ["Margalit", "Eshed", ""], ["Tanaka", "Hidenori", ""], ["Ganguli", "Surya", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "2107.09360", "submitter": "Constantinos Siettos", "authors": "Konstantinos Spiliotis, Giannis Kahramanoglou, Jens Starke, Nikolaos\n  Smyrnis, Constantinos Siettos", "title": "A biophysical network model reveals the link between deficient\n  inhibitory cognitive control and major neurotransmitter and neural\n  connectivity hypotheses in schizophrenia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NA math.DS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address a biophysical network dynamical model to study how the modulation\nof dopamine (DA) activity and related N-methyl-d-aspartate (NMDA) glutamate\nreceptor activity as well as the emerging Pre-Frontal Cortex (PFC) functional\nconnectivity network (FCN) affect inhibitory cognitive function in\nschizophrenia in an antisaccade task. The values of the model parameters and\nthe topology of the PFC-FCN were estimated by minimizing the differences\nbetween simulations and the observed distributions of reaction times (RT)\nduring the performance of the antisaccade task in 30 patients with\nschizophrenia and 30 healthy controls. We show that the proposed model\napproximates remarkably well the predicted prefrontal cortical DA hypo-activity\nand the related NMDA receptor hypo-function as well as the FCN dysconnection\npattern that are considered as the major etio-pathological hypotheses to\nexplain cognitive deficits in schizophrenia.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 09:29:05 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Spiliotis", "Konstantinos", ""], ["Kahramanoglou", "Giannis", ""], ["Starke", "Jens", ""], ["Smyrnis", "Nikolaos", ""], ["Siettos", "Constantinos", ""]]}, {"id": "2107.09384", "submitter": "Dirk Ostwald", "authors": "Dirk Ostwald and Franziska Us\\'ee", "title": "An induction proof of the backpropagation algorithm in matrix notation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG math.ST q-bio.NC stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Backpropagation (BP) is a core component of the contemporary deep learning\nincarnation of neural networks. Briefly, BP is an algorithm that exploits the\ncomputational architecture of neural networks to efficiently evaluate the\ngradient of a cost function during neural network parameter optimization. The\nvalidity of BP rests on the application of a multivariate chain rule to the\ncomputational architecture of neural networks and their associated objective\nfunctions. Introductions to deep learning theory commonly present the\ncomputational architecture of neural networks in matrix form, but eschew a\nparallel formulation and justification of BP in the framework of matrix\ndifferential calculus. This entails several drawbacks for the theory and\ndidactics of deep learning. In this work, we overcome these limitations by\nproviding a full induction proof of the BP algorithm in matrix notation.\nSpecifically, we situate the BP algorithm in the framework of matrix\ndifferential calculus, encompass affine-linear potential functions, prove the\nvalidity of the BP algorithm in inductive form, and exemplify the\nimplementation of the matrix form BP algorithm in computer code.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 10:02:17 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Ostwald", "Dirk", ""], ["Us\u00e9e", "Franziska", ""]]}, {"id": "2107.09507", "submitter": "Jian Cui", "authors": "Jian Cui, Yisi Liu, Zirui Lan, Olga Sourina, Wolfgang M\\\"uller-Wittig", "title": "EEG-based Cross-Subject Driver Drowsiness Recognition with Interpretable\n  CNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the context of electroencephalogram (EEG)-based driver drowsiness\nrecognition, it is still a challenging task to design a calibration-free\nsystem, since there exists a significant variability of EEG signals among\ndifferent subjects and recording sessions. As deep learning has received much\nresearch attention in recent years, many efforts have been made to use deep\nlearning methods for EEG signal recognition. However, existing works mostly\ntreat deep learning models as blackbox classifiers, while what have been\nlearned by the models and to which extent they are affected by the noise from\nEEG data are still underexplored. In this paper, we develop a novel\nconvolutional neural network that can explain its decision by highlighting the\nlocal areas of the input sample that contain important information for the\nclassification. The network has a compact structure for ease of interpretation\nand takes advantage of separable convolutions to process the EEG signals in a\nspatial-temporal sequence. Results show that the model achieves an average\naccuracy of 78.35% on 11 subjects for leave-one-out cross-subject drowsiness\nrecognition, which is higher than the conventional baseline methods of\n53.4%-72.68% and state-of-art deep learning methods of 63.90%-65.61%.\nVisualization results show that the model has learned to recognize biologically\nexplainable features from EEG signals, e.g., Alpha spindles, as strong\nindicators of drowsiness across different subjects. In addition, we also\nexplore reasons behind some wrongly classified samples and how the model is\naffected by artifacts and noise in the data. Our work illustrates a promising\ndirection on using interpretable deep learning models to discover meaning\npatterns related to different mental states from complex EEG signals.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 14:47:20 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Cui", "Jian", ""], ["Liu", "Yisi", ""], ["Lan", "Zirui", ""], ["Sourina", "Olga", ""], ["M\u00fcller-Wittig", "Wolfgang", ""]]}, {"id": "2107.10169", "submitter": "Kelvin Sarink", "authors": "Tim Hahn, Nils R. Winter, Jan Ernsting, Marius Gruber, Marco J.\n  Mauritz, Lukas Fisch, Ramona Leenings, Kelvin Sarink, Julian Blanke, Vincent\n  Holstein, Daniel Emden, Marie Beisemann, Nils Opel, Dominik Grotegerd,\n  Susanne Meinert, Walter Heindel, Stephanie Witt, Marcella Rietschel, Markus\n  M. N\\\"othen, Andreas J. Forstner, Tilo Kircher, Igor Nenadic, Andreas Jansen,\n  Bertram M\\\"uller-Myhsok, Till F. M. Andlauer, Martin Walter, Martijn P. van\n  den Heuvel, Hamidreza Jamalabadi, Udo Dannlowski, Jonathan Repple", "title": "Genetic, Individual, and Familial Risk Correlates of Brain Network\n  Controllability in Major Depressive Disorder", "comments": "24 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Background: A therapeutic intervention in psychiatry can be viewed as an\nattempt to influence the brain's large-scale, dynamic network state transitions\nunderlying cognition and behavior. Building on connectome-based graph analysis\nand control theory, Network Control Theory is emerging as a powerful tool to\nquantify network controllability - i.e., the influence of one brain region over\nothers regarding dynamic network state transitions. If and how network\ncontrollability is related to mental health remains elusive.\n  Methods: From Diffusion Tensor Imaging data, we inferred structural\nconnectivity and inferred calculated network controllability parameters to\ninvestigate their association with genetic and familial risk in patients\ndiagnosed with major depressive disorder (MDD, n=692) and healthy controls\n(n=820).\n  Results: First, we establish that controllability measures differ between\nhealthy controls and MDD patients while not varying with current symptom\nseverity or remission status. Second, we show that controllability in MDD\npatients is associated with polygenic scores for MDD and psychiatric\ncross-disorder risk. Finally, we provide evidence that controllability varies\nwith familial risk of MDD and bipolar disorder as well as with body mass index.\n  Conclusions: We show that network controllability is related to genetic,\nindividual, and familial risk in MDD patients. We discuss how these insights\ninto individual variation of network controllability may inform mechanistic\nmodels of treatment response prediction and personalized intervention-design in\nmental health.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 15:53:49 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Hahn", "Tim", ""], ["Winter", "Nils R.", ""], ["Ernsting", "Jan", ""], ["Gruber", "Marius", ""], ["Mauritz", "Marco J.", ""], ["Fisch", "Lukas", ""], ["Leenings", "Ramona", ""], ["Sarink", "Kelvin", ""], ["Blanke", "Julian", ""], ["Holstein", "Vincent", ""], ["Emden", "Daniel", ""], ["Beisemann", "Marie", ""], ["Opel", "Nils", ""], ["Grotegerd", "Dominik", ""], ["Meinert", "Susanne", ""], ["Heindel", "Walter", ""], ["Witt", "Stephanie", ""], ["Rietschel", "Marcella", ""], ["N\u00f6then", "Markus M.", ""], ["Forstner", "Andreas J.", ""], ["Kircher", "Tilo", ""], ["Nenadic", "Igor", ""], ["Jansen", "Andreas", ""], ["M\u00fcller-Myhsok", "Bertram", ""], ["Andlauer", "Till F. M.", ""], ["Walter", "Martin", ""], ["Heuvel", "Martijn P. van den", ""], ["Jamalabadi", "Hamidreza", ""], ["Dannlowski", "Udo", ""], ["Repple", "Jonathan", ""]]}, {"id": "2107.10178", "submitter": "Kelvin Sarink", "authors": "Tim Hahn, Hamidreza Jamalabadi, Daniel Emden, Janik Goltermann, Jan\n  Ernsting, Nils R. Winter, Lukas Fisch, Ramona Leenings, Kelvin Sarink,\n  Vincent Holstein, Marius Gruber, Dominik Grotegerd, Susanne Meinert,\n  Katharina Dohm, Elisabeth J. Leehr, Maike Richter, Lisa Sindermann, Verena\n  Enneking, Hannah Lemke, Stephanie Witt, Marcella Rietschel, Katharina Brosch,\n  Julia-Katharina Pfarr, Tina Meller, Kai Gustav Ringwald, Simon Schmitt,\n  Frederike Stein, Igor Nenadic, Tilo Kircher, Bertram M\\\"uller-Myhsok, Till\n  F.M. Andlauer, Jonathan Repple, Udo Dannlowski, Nils Opel", "title": "A Network Control Theory Approach to Longitudinal Symptom Dynamics in\n  Major Depressive Disorder", "comments": "21 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.SY q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Background: The evolution of symptoms over time is at the heart of\nunderstanding and treating mental disorders. However, a principled,\nquantitative framework explaining symptom dynamics remains elusive. Here, we\npropose a Network Control Theory of Psychopathology allowing us to formally\nderive a theoretical control energy which we hypothesize quantifies resistance\nto future symptom improvement in Major Depressive Disorder (MDD). We test this\nhypothesis and investigate the relation to genetic and environmental risk as\nwell as resilience.\n  Methods: We modelled longitudinal symptom-network dynamics derived from\nN=2,059 Beck Depression Inventory measurements acquired over a median of 134\ndays in a sample of N=109 patients suffering from MDD. We quantified the\ntheoretical energy required for each patient and time-point to reach a\nsymptom-free state given individual symptom-network topology (E 0 ) and 1)\ntested if E 0 predicts future symptom improvement and 2) whether this\nrelationship is moderated by Polygenic Risk Scores (PRS) of mental disorders,\nchildhood maltreatment experience, and self-reported resilience.\n  Outcomes: We show that E 0 indeed predicts symptom reduction at the next\nmeasurement and reveal that this coupling between E 0 and future symptom change\nincreases with higher genetic risk and childhood maltreatment while it\ndecreases with resilience.\n  Interpretation: Our study provides a mechanistic framework capable of\npredicting future symptom improvement based on individual symptom-network\ntopology and clarifies the role of genetic and environmental risk as well as\nresilience. Our control-theoretic framework makes testable, quantitative\npredictions for individual therapeutic response and provides a starting-point\nfor the theory-driven design of personalized interventions.\n  Funding: German Research Foundation and Interdisciplinary Centre for Clinical\nResearch, M\\\"unster\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 16:07:32 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Hahn", "Tim", ""], ["Jamalabadi", "Hamidreza", ""], ["Emden", "Daniel", ""], ["Goltermann", "Janik", ""], ["Ernsting", "Jan", ""], ["Winter", "Nils R.", ""], ["Fisch", "Lukas", ""], ["Leenings", "Ramona", ""], ["Sarink", "Kelvin", ""], ["Holstein", "Vincent", ""], ["Gruber", "Marius", ""], ["Grotegerd", "Dominik", ""], ["Meinert", "Susanne", ""], ["Dohm", "Katharina", ""], ["Leehr", "Elisabeth J.", ""], ["Richter", "Maike", ""], ["Sindermann", "Lisa", ""], ["Enneking", "Verena", ""], ["Lemke", "Hannah", ""], ["Witt", "Stephanie", ""], ["Rietschel", "Marcella", ""], ["Brosch", "Katharina", ""], ["Pfarr", "Julia-Katharina", ""], ["Meller", "Tina", ""], ["Ringwald", "Kai Gustav", ""], ["Schmitt", "Simon", ""], ["Stein", "Frederike", ""], ["Nenadic", "Igor", ""], ["Kircher", "Tilo", ""], ["M\u00fcller-Myhsok", "Bertram", ""], ["Andlauer", "Till F. M.", ""], ["Repple", "Jonathan", ""], ["Dannlowski", "Udo", ""], ["Opel", "Nils", ""]]}, {"id": "2107.10244", "submitter": "Carina Curto", "authors": "Carina Curto, Juliana Londono-Alvarez, Katherine Morrison, Caitlyn\n  Parmelee", "title": "Sequential attractors in combinatorial threshold-linear networks", "comments": "85 pages, 45 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequences of neural activity arise in many brain areas, including cortex,\nhippocampus, and central pattern generator circuits that underlie rhythmic\nbehaviors like locomotion. While network architectures supporting sequence\ngeneration vary considerably, a common feature is an abundance of inhibition.\nIn this work, we focus on architectures that support sequential activity in\nrecurrently connected networks with inhibition-dominated dynamics.\nSpecifically, we study emergent sequences in a special family of\nthreshold-linear networks, called combinatorial threshold-linear networks\n(CTLNs), whose connectivity matrices are defined from directed graphs. Such\nnetworks naturally give rise to an abundance of sequences whose dynamics are\ntightly connected to the underlying graph. We find that architectures based on\ngeneralizations of cycle graphs produce limit cycle attractors that can be\nactivated to generate transient or persistent (repeating) sequences. Each\narchitecture type gives rise to an infinite family of graphs that can be built\nfrom arbitrary component subgraphs. Moreover, we prove a number of graph rules\nfor the corresponding CTLNs in each family. The graph rules allow us to\nstrongly constrain, and in some cases fully determine, the fixed points of the\nnetwork in terms of the fixed points of the component subnetworks. Finally, we\napply these results to identify all graphs up to size $n=5$ that are\nparameter-independent core motifs. Core motifs are special graphs with a single\nfixed point that are in some sense irreducible, and typically support a single\nattractor. Additionally, we show how the structure of certain architectures\ngives insight into the sequential dynamics of the corresponding attractor.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 17:47:17 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Curto", "Carina", ""], ["Londono-Alvarez", "Juliana", ""], ["Morrison", "Katherine", ""], ["Parmelee", "Caitlyn", ""]]}, {"id": "2107.11477", "submitter": "Peter A. V. DiBerardino", "authors": "Peter A. V. DiBerardino, Alexandre L. S. Filipowicz, James Danckert,\n  Britt Anderson", "title": "Plinko: A Theory-Free Behavioral Measure of Priors for Statistical\n  Learning and Mental Model Updating", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probability distributions are central to Bayesian accounts of cognition, but\nbehavioral assessments do not directly measure them. Posterior distributions\nare typically computed from collections of individual participant actions, yet\nare used to draw conclusions about the internal structure of participant\nbeliefs. Also not explicitly measured are the prior distributions that\ndistinguish Bayesian models from others by representing initial states of\nbelief. Instead, priors are usually derived from experimenters' intuitions or\nmodel assumptions and applied equally to all participants. Here we present\nthree experiments using \"Plinko\", a behavioral task in which participants\nestimate distributions of ball drops over all available outcomes and where\ndistributions are explicitly measured before any observations. In Experiment 1,\nwe show that participant priors cluster around prototypical probability\ndistributions (Gaussian, bimodal, etc.), and that prior cluster membership may\nindicate learning ability. In Experiment 2, we highlight participants' ability\nto update to unannounced changes of presented distributions and how this\nability is affected by environmental manipulation. Finally, in Experiment 3, we\nverify that individual participant priors are reliable representations and that\nlearning is not impeded when faced with a physically implausible ball drop\ndistribution that is dynamically defined according to individual participant\ninput. This task will prove useful in more closely examining mechanisms of\nstatistical learning and mental model updating without requiring many of the\nassumptions made by more traditional computational modeling methodologies.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 22:27:30 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["DiBerardino", "Peter A. V.", ""], ["Filipowicz", "Alexandre L. S.", ""], ["Danckert", "James", ""], ["Anderson", "Britt", ""]]}, {"id": "2107.12026", "submitter": "Eneko Uru\\~nuela", "authors": "Eneko Uru\\~nuela, Thomas A.W. Bolton, Dimitri Van De Ville, C\\'esar\n  Caballero-Gaudes", "title": "Hemodynamic Deconvolution Demystified: Sparsity-Driven Regularization at\n  Work", "comments": "17 pages, 6 figures, submitted to NeuroImage as a technical note", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deconvolution of the hemodynamic response is an important step to access\nshort timescales of brain activity recorded by functional magnetic resonance\nimaging (fMRI). Albeit conventional deconvolution algorithms have been around\nfor a long time (e.g., Wiener deconvolution), recent state-of-the-art methods\nbased on sparsity-pursuing regularization are attracting increasing interest to\ninvestigate brain dynamics and connectivity. This technical note revisits the\nmain concepts underlying two main methods, Paradigm Free Mapping and Total\nActivation, in the most accessible way. Despite their apparent differences,\nthese methods are theoretically equivalent as they represent the synthesis and\nanalysis sides of the same problem. We demonstrate this equivalence in practice\nwith their best-available implementations using both simulations, with\ndifferent signal-to-noise ratios, and experimental data of motor task and\nresting-state fMRI. We evaluate the parameter settings that lead to equivalent\nresults, and showcase the potential of these algorithms compared to other\nwidely-used approaches. This note is useful for practitioners interested in\ngaining a better understanding of state-of-the-art hemodynamic deconvolution,\nand who want to make use of them with the most efficient implementation.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 08:30:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Uru\u00f1uela", "Eneko", ""], ["Bolton", "Thomas A. W.", ""], ["Van De Ville", "Dimitri", ""], ["Caballero-Gaudes", "C\u00e9sar", ""]]}, {"id": "2107.12536", "submitter": "Caetano Mazzoni Ranieri", "authors": "Caetano M. Ranieri, Jhielson M. Pimentel, Marcelo R. Romano, Leonardo\n  A. Elias, Roseli A. F. Romero, Michael A. Lones, Mariana F. P. Araujo,\n  Patricia A. Vargas, Renan C. Moioli", "title": "A Data-Driven Biophysical Computational Model of Parkinson's Disease\n  based on Marmoset Monkeys", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we propose a new biophysical computational model of brain\nregions relevant to Parkinson's Disease based on local field potential data\ncollected from the brain of marmoset monkeys. Parkinson's disease is a\nneurodegenerative disorder, linked to the death of dopaminergic neurons at the\nsubstantia nigra pars compacta, which affects the normal dynamics of the basal\nganglia-thalamus-cortex neuronal circuit of the brain. Although there are\nmultiple mechanisms underlying the disease, a complete description of those\nmechanisms and molecular pathogenesis are still missing, and there is still no\ncure. To address this gap, computational models that resemble neurobiological\naspects found in animal models have been proposed. In our model, we performed a\ndata-driven approach in which a set of biologically constrained parameters is\noptimised using differential evolution. Evolved models successfully resembled\nsingle-neuron mean firing rates and spectral signatures of local field\npotentials from healthy and parkinsonian marmoset brain data. As far as we are\nconcerned, this is the first computational model of Parkinson's Disease based\non simultaneous electrophysiological recordings from seven brain regions of\nMarmoset monkeys. Results show that the proposed model could facilitate the\ninvestigation of the mechanisms of PD and support the development of techniques\nthat can indicate new therapies. It could also be applied to other\ncomputational neuroscience problems in which biological data could be used to\nfit multi-scale models of brain circuits.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 01:09:11 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Ranieri", "Caetano M.", ""], ["Pimentel", "Jhielson M.", ""], ["Romano", "Marcelo R.", ""], ["Elias", "Leonardo A.", ""], ["Romero", "Roseli A. F.", ""], ["Lones", "Michael A.", ""], ["Araujo", "Mariana F. P.", ""], ["Vargas", "Patricia A.", ""], ["Moioli", "Renan C.", ""]]}, {"id": "2107.12609", "submitter": "Shuhang Chen", "authors": "Shuhang Chen, Xiang Zhang, Xiang Shen, Yifan Huang, and Yiwen Wang", "title": "Tracking Fast Neural Adaptation by Globally Adaptive Point Process\n  Estimation for Brain-Machine Interface", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-machine interfaces (BMIs) help the disabled restore body functions by\ntranslating neural activity into digital commands to control external devices.\nNeural adaptation, where the brain signals change in response to external\nstimuli or movements, plays an important role in BMIs. When subjects purely use\nneural activity to brain-control a prosthesis, some neurons will actively\nexplore a new tuning property to accomplish the movement task. The prediction\nof this neural tuning property can help subjects adapt more efficiently to\nbrain control and maintain good decoding performance. Existing prediction\nmethods track the slow change of the tuning property in the manual control,\nwhich is not suitable for the fast neural adaptation in brain control. In order\nto identify the active neurons in brain control and track their tuning property\nchanges, we propose a globally adaptive point process method (GaPP) to estimate\nthe neural modulation state from spike trains, decompose the states into the\nhyper preferred direction and reconstruct the kinematics in a dual-model\nframework. We implement the method on real data from rats performing a\ntwo-lever discrimination task under manual control and brain control. The\nresults show our method successfully predicts the neural modulation state and\nidentifies the neurons that become active in brain control. Compared to\nexisting methods, ours tracks the fast changes of the hyper preferred direction\nfrom manual control to brain control more accurately and efficiently and\nreconstructs the kinematics better and faster.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 05:31:31 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Chen", "Shuhang", ""], ["Zhang", "Xiang", ""], ["Shen", "Xiang", ""], ["Huang", "Yifan", ""], ["Wang", "Yiwen", ""]]}, {"id": "2107.12838", "submitter": "Fuad Noman", "authors": "Fuad Noman, Chee-Ming Ting, Hakmook Kang, Raphael C.-W. Phan, Brian D.\n  Boyd, Warren D. Taylor, and Hernando Ombao", "title": "Graph Autoencoders for Embedding Learning in Brain Networks and Major\n  Depressive Disorder Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Brain functional connectivity (FC) reveals biomarkers for identification of\nvarious neuropsychiatric disorders. Recent application of deep neural networks\n(DNNs) to connectome-based classification mostly relies on traditional\nconvolutional neural networks using input connectivity matrices on a regular\nEuclidean grid. We propose a graph deep learning framework to incorporate the\nnon-Euclidean information about graph structure for classifying functional\nmagnetic resonance imaging (fMRI)- derived brain networks in major depressive\ndisorder (MDD). We design a novel graph autoencoder (GAE) architecture based on\nthe graph convolutional networks (GCNs) to embed the topological structure and\nnode content of large-sized fMRI networks into low-dimensional latent\nrepresentations. In network construction, we employ the Ledoit-Wolf (LDW)\nshrinkage method to estimate the high-dimensional FC metrics efficiently from\nfMRI data. We consider both supervised and unsupervised approaches for the\ngraph embedded learning. The learned embeddings are then used as feature inputs\nfor a deep fully-connected neural network (FCNN) to discriminate MDD from\nhealthy controls. Evaluated on a resting-state fMRI MDD dataset with 43\nsubjects, results show that the proposed GAE-FCNN model significantly\noutperforms several state-of-the-art DNN methods for brain connectome\nclassification, achieving accuracy of 72.50% using the LDW-FC metrics as node\nfeatures. The graph embeddings of fMRI FC networks learned by the GAE also\nreveal apparent group differences between MDD and HC. Our new framework\ndemonstrates feasibility of learning graph embeddings on brain networks to\nprovide discriminative information for diagnosis of brain disorders.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 14:12:39 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Noman", "Fuad", ""], ["Ting", "Chee-Ming", ""], ["Kang", "Hakmook", ""], ["Phan", "Raphael C. -W.", ""], ["Boyd", "Brian D.", ""], ["Taylor", "Warren D.", ""], ["Ombao", "Hernando", ""]]}, {"id": "2107.12979", "submitter": "Beren Millidge Mr", "authors": "Beren Millidge, Anil Seth, Christopher L Buckley", "title": "Predictive Coding: a Theoretical and Experimental Review", "comments": "27/07/21 initial upload", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive coding offers a potentially unifying account of cortical function\n-- postulating that the core function of the brain is to minimize prediction\nerrors with respect to a generative model of the world. The theory is closely\nrelated to the Bayesian brain framework and, over the last two decades, has\ngained substantial influence in the fields of theoretical and cognitive\nneuroscience. A large body of research has arisen based on both empirically\ntesting improved and extended theoretical and mathematical models of predictive\ncoding, as well as in evaluating their potential biological plausibility for\nimplementation in the brain and the concrete neurophysiological and\npsychological predictions made by the theory. Despite this enduring popularity,\nhowever, no comprehensive review of predictive coding theory, and especially of\nrecent developments in this field, exists. Here, we provide a comprehensive\nreview both of the core mathematical structure and logic of predictive coding,\nthus complementing recent tutorials in the literature. We also review a wide\nrange of classic and recent work within the framework, ranging from the\nneurobiologically realistic microcircuits that could implement predictive\ncoding, to the close relationship between predictive coding and the widely-used\nbackpropagation of error algorithm, as well as surveying the close\nrelationships between predictive coding and modern machine learning techniques.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 17:44:21 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Millidge", "Beren", ""], ["Seth", "Anil", ""], ["Buckley", "Christopher L", ""]]}, {"id": "2107.13219", "submitter": "Rong Wang", "authors": "Rong Wang and Yongchen Fan and Ying Wu and Changsong Zhou", "title": "Heterogeneous aging trajectories within resting-state brain networks\n  predict distinct ADHD symptoms in adults", "comments": "28 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Attention-deficit/hyperactivity disorder (ADHD) is increasingly being\ndiagnosed in adults, but the neural mechanisms underlying its distinct clinical\nsymptoms (hyperactivity and inattention) remain poorly understood. Here, we\nused a nested-spectral partition approach to study resting-state brain networks\nfor ADHD patients and healthy adults and adopted hierarchical segregation and\nintegration to predict clinical symptoms. Adult ADHD is typically characterized\nby an overintegrated interaction within default mode network. Limbic system is\ndominantly affected by ADHD and has an earlier aging functional pattern, but\nsalient attention system is preferably affected by age and shows an opposite\naging trajectory. More importantly, these two systems selectively and robustly\npredict distinct ADHD symptoms. Earlier-aging limbic system prefers to predict\nhyperactivity, and age-affected salient attention system better predicts\ninattention. Our findings provide a more comprehensive and deeper understanding\nof the neural basis of distinct ADHD symptoms and could contribute to the\ndevelopment of more objective clinical diagnoses.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 08:08:24 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Wang", "Rong", ""], ["Fan", "Yongchen", ""], ["Wu", "Ying", ""], ["Zhou", "Changsong", ""]]}, {"id": "2107.13272", "submitter": "Nicholas Gale", "authors": "Nicholas Gale, Jennifer Rodger, Michael Small and Stephen Eglen", "title": "Development of Topographic Maps in Neural Field Theory with Short Time\n  Scale Dependent Plasticity", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Topographic maps are a brain structure connecting pre-synpatic and\npost-synaptic brain regions. Topographic development is dependent on\nHebbian-based plasticity mechanisms working in conjunction with spontaneous\npatterns of neural activity generated in the pre-synaptic regions. Studies\nperformed in mouse have shown that these spontaneous patterns can exhibit\ncomplex spatial-temporal structures which existing models cannot incorporate.\nNeural field theories are appropriate modelling paradigms for topographic\nsystems due to the dense nature of the connections between regions and can be\naugmented with a plasticity rule general enough to capture complex time-varying\nstructures.\n  We propose a theoretical framework for studying the development of topography\nin the context of complex spatial-temporal activity fed-forward from the\npre-synaptic to post-synaptic regions. Analysis of the model leads to an\nanalytic solution corroborating the conclusion that activity can drive the\nrefinement of topographic projections. The analysis also suggests that\nbiological noise is used in the development of topography to stabilise the\ndynamics. MCMC simulations are used to analyse and understand the differences\nin topographic refinement between wild-type and the $\\beta2$ knock-out mutant\nin mice. The time scale of the synaptic plasticity window is estimated as\n$0.56$ seconds in this context with a model fit of $R^2 = 0.81$.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 11:12:09 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Gale", "Nicholas", ""], ["Rodger", "Jennifer", ""], ["Small", "Michael", ""], ["Eglen", "Stephen", ""]]}, {"id": "2107.13393", "submitter": "Yoonsuck Choe", "authors": "Yoonsuck Choe", "title": "Meaning Versus Information, Prediction Versus Memory, and Question\n  Versus Answer", "comments": "14 pages", "journal-ref": null, "doi": "10.1016/B978-0-12-815480-9.00014-1", "report-no": null, "categories": "q-bio.NC cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brain science and artificial intelligence have made great progress toward the\nunderstanding and engineering of the human mind. The progress has accelerated\nsignificantly since the turn of the century thanks to new methods for probing\nthe brain (both structure and function), and rapid development in deep learning\nresearch. However, despite these new developments, there are still many open\nquestions, such as how to understand the brain at the system level, and various\nrobustness issues and limitations of deep learning. In this informal essay, I\nwill talk about some of the concepts that are central to brain science and\nartificial intelligence, such as information and memory, and discuss how a\ndifferent view on these concepts can help us move forward, beyond current\nlimits of our understanding in these fields.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jun 2021 18:22:49 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Choe", "Yoonsuck", ""]]}, {"id": "2107.13408", "submitter": "Jonathan Tsay", "authors": "Jonathan S. Tsay, Alan Lee, Richard B. Ivry, Guy Avraham", "title": "Moving outside the lab: The viability of conducting sensorimotor\n  learning studies online", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Collecting data online via crowdsourcing platforms has proven to be a very\nefficient way to recruit a large and diverse sample. Studies of motor learning,\nhowever, have been largely confined to the lab due to the need for special\nequipment to record movement kinematics and, as such, are typically only\naccessible to specific participants (e.g., college students). As a first foray\nto make motor learning studies accessible to a larger and more diverse\naudience, we developed an online, web-based platform (OnPoint) to collect\nkinematic data, serving as a template for researchers to create their own\nonline sensorimotor control and learning experiments. As a proof-of-concept, we\nasked if fundamental motor learning phenomena discovered in the lab could be\nreplicated online. In a series of three experiments, we observed a close\ncorrespondence between the results obtained online with those previously\nreported from research conducted in the laboratory. This web-based platform\npaired with online crowdsourcing can serve as a powerful new method for the\nstudy of motor control and learning.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 14:54:49 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Tsay", "Jonathan S.", ""], ["Lee", "Alan", ""], ["Ivry", "Richard B.", ""], ["Avraham", "Guy", ""]]}, {"id": "2107.13461", "submitter": "Ignacio Carlucho", "authors": "Ignacio Carlucho, Manuel F. Bailey, Mariano De Paula, Corina Barbalata", "title": "Marine Vehicles Localization Using Grid Cells for Path Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous Underwater Vehicles (AUVs) are platforms used for research and\nexploration of marine environments. However, these types of vehicles face many\nchallenges that hinder their widespread use in the industry. One of the main\nlimitations is obtaining accurate position estimation, due to the lack of GPS\nsignal underwater. This estimation is usually done with Kalman filters.\nHowever, new developments in the neuroscience field have shed light on the\nmechanisms by which mammals are able to obtain a reliable estimation of their\ncurrent position based on external and internal motion cues. A new type of\nneuron, called Grid cells, has been shown to be part of path integration system\nin the brain. In this article, we show how grid cells can be used for obtaining\na position estimation of underwater vehicles. The model of grid cells used\nrequires only the linear velocities together with heading orientation and\nprovides a reliable estimation of the vehicle's position. We provide simulation\nresults for an AUV which show the feasibility of our proposed methodology.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:13:56 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Carlucho", "Ignacio", ""], ["Bailey", "Manuel F.", ""], ["De Paula", "Mariano", ""], ["Barbalata", "Corina", ""]]}, {"id": "2107.13473", "submitter": "Nicolas Valenchon", "authors": "Nicolas Valenchon, Yann Bouteiller, Hugo R. Jourde, Emily B.J. Coffey\n  and Giovanni Beltrame", "title": "The Portiloop: a deep learning-based open science tool for closed-loop\n  brain stimulation", "comments": "12 pages, 13 Figures, journal paper. Open source code at\n  https://github.com/mistlab/portiloop", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electroencephalography (EEG) is a method of measuring the brain's electrical\nactivity, using non-invasive scalp electrodes. In this article, we propose the\nPortiloop, a deep learning-based portable and low-cost device enabling the\nneuroscience community to capture EEG, process it in real time, detect patterns\nof interest, and respond with precisely-timed stimulation. The core of the\nPortiloop is a System on Chip composed of an Analog to Digital Converter (ADC)\nand a Field-Programmable Gate Array (FPGA). After being converted to digital by\nthe ADC, the EEG signal is processed in the FPGA. The FPGA contains an ad-hoc\nArtificial Neural Network (ANN) with convolutional and recurrent units,\ndirectly implemented in hardware. The output of the ANN is then used to trigger\nthe user-defined feedback. We use the Portiloop to develop a real-time sleep\nspindle stimulating application, as a case study. Sleep spindles are a specific\ntype of transient oscillation ($\\sim$2.5 s, 12-16 Hz) that are observed in EEG\nrecordings, and are related to memory consolidation during sleep. We tested the\nPortiloop's capacity to detect and stimulate sleep spindles in real time using\nan existing database of EEG sleep recordings. With 71% for both precision and\nrecall as compared with expert labels, the system is able to stimulate spindles\nwithin $\\sim$300 ms of their onset, enabling experimental manipulation of early\nthe entire spindle. The Portiloop can be extended to detect and stimulate other\nneural events in EEG. It is fully available to the research community as an\nopen science project.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:29:58 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Valenchon", "Nicolas", ""], ["Bouteiller", "Yann", ""], ["Jourde", "Hugo R.", ""], ["Coffey", "Emily B. J.", ""], ["Beltrame", "Giovanni", ""]]}, {"id": "2107.13532", "submitter": "Markus Meister", "authors": "Markus Meister", "title": "Curved Micro-Electrode Arrays", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-electrode arrays serve to record electrical signals of many neurons in\nthe brain simultaneously. For most of the past century, electrodes that\npenetrate brain tissue have had exactly one shape: a straight needle. Certainly\nthis was a good starting choice at the time, but there is no reason to think\nthat a straight line would be the optimal shape in all Neuroscience\napplications. Here I argue that, in fact, a wide variety of curved shapes is\nequally practical: all possible helices. I discuss the manufacture and\nmanipulation of such devices, and illustrate a few use cases where they will\nlikely outperform conventional needles. With some collective action from the\nresearch community, curved arrays could be manufactured and distributed at low\ncost.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:58:58 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Meister", "Markus", ""]]}, {"id": "2107.13704", "submitter": "Lenore Blum", "authors": "Lenore Blum, Manuel Blum", "title": "A Theory of Consciousness from a Theoretical Computer Science\n  Perspective 2: Insights from the Conscious Turing Machine", "comments": "arXiv admin note: text overlap with arXiv:2011.09850", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The quest to understand consciousness, once the purview of philosophers and\ntheologians, is now actively pursued by scientists of many stripes. We examine\nconsciousness from the perspective of theoretical computer science (TCS), a\nbranch of mathematics concerned with understanding the underlying principles of\ncomputation and complexity, including the implications and surprising\nconsequences of resource limitations. In the spirit of Alan Turing's simple yet\npowerful definition of a computer, the Turing Machine (TM), and perspective of\ncomputational complexity theory, we formalize a modified version of the Global\nWorkspace Theory (GWT) of consciousness originated by cognitive neuroscientist\nBernard Baars and further developed by him, Stanislas Dehaene, Jean-Pierre\nChangeaux and others. We are not looking for a complex model of the brain nor\nof cognition, but for a simple computational model of (the admittedly complex\nconcept of) consciousness. We do this by defining the Conscious Turing Machine\n(CTM), also called a conscious AI, and then we define consciousness and related\nnotions in the CTM. While these are only mathematical (TCS) definitions, we\nsuggest why the CTM has the feeling of consciousness. The TCS perspective\nprovides a simple formal framework to employ tools from computational\ncomplexity theory and machine learning to help us understand consciousness and\nrelated concepts. Previously we explored high level explanations for the\nfeelings of pain and pleasure in the CTM. Here we consider three examples\nrelated to vision (blindsight, inattentional blindness, and change blindness),\nfollowed by discussions of dreams, free will, and altered states of\nconsciousness.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 01:47:52 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Blum", "Lenore", ""], ["Blum", "Manuel", ""]]}]