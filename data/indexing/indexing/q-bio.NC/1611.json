[{"id": "1611.00033", "submitter": "Sergey Agapov", "authors": "S.N. Agapov, V.A Bulanov, A.V. Zakharov, M.S. Sergeeva", "title": "Wavelet algorithm for the identification of P300 ERP component", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interfaces have many algorithms based on the P300 component of\nERP. Modern industry has started to produce consumer grade EEG equipment which\nis handy and not too expensive. This gives us an opportunity to use BCI in\neveryday practice. In order to improve the performance of these devices, we\nneed effective algorithms for time series analysis and pattern recognition. We\nhave tested Emotiv Insight headset in a real live environment and we have\nconducted several tests for series of standard wavelets in P300 pattern\nrecognition task.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2016 06:04:02 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Agapov", "S. N.", ""], ["Bulanov", "V. A", ""], ["Zakharov", "A. V.", ""], ["Sergeeva", "M. S.", ""]]}, {"id": "1611.00285", "submitter": "Till Frank", "authors": "J.M. Gordon, S. Kim, T.D. Frank", "title": "Linear non-equilibrium thermodynamics of human voluntary behavior: a\n  canonical-dissipative Fokker-Planck equation approach involving potentials\n  beyond the harmonic oscillator case", "comments": "6 pages, 0 figure", "journal-ref": "Condens. Matter Phys., vol. 19, No. 3, 34001 (2016)", "doi": "10.5488/CMP.19.34001", "report-no": null, "categories": "q-bio.NC cond-mat.soft cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel experimental paradigm and a novel modelling approach are presented to\ninvestigate oscillatory human motor performance by means of a key concept from\ncondensed matter physics, namely, thermodynamic state variables. To this end,\nin the novel experimental paradigm participants performed pendulum swinging\nmovements at self-selected oscillation frequencies in contrast to earlier\nstudies in which pacing signals were used. Moreover, in the novel modelling\napproach, a canonical-dissipative limit cycle oscillator model was used with a\nconservative part that accounts for nonharmonic oscillator components in\ncontrast to earlier studies in which only harmonic components were considered.\nConsistent with the Landau theory of magnetic phase transitions, we found that\nthe oscillator model free energy decayed when participants performed\noscillations further and further away from the Hopf bifurcation point of the\ncanonical-dissipative limit cycle oscillator.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 16:10:43 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Gordon", "J. M.", ""], ["Kim", "S.", ""], ["Frank", "T. D.", ""]]}, {"id": "1611.00294", "submitter": "Tilo Schwalger", "authors": "Tilo Schwalger, Moritz Deger and Wulfram Gerstner", "title": "Towards a theory of cortical columns: From spiking neurons to\n  interacting neural populations of finite size", "comments": "Simulation code available from\n  https://github.com/schwalger/mesopopdyn_gif", "journal-ref": "PLoS Comput. Biol., 13(4):e1005507, 2017", "doi": "10.1371/journal.pcbi.1005507", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural population equations such as neural mass or field models are widely\nused to study brain activity on a large scale. However, the relation of these\nmodels to the properties of single neurons is unclear. Here we derive an\nequation for several interacting populations at the mesoscopic scale starting\nfrom a microscopic model of randomly connected generalized integrate-and-fire\nneuron models. Each population consists of 50 -- 2000 neurons of the same type\nbut different populations account for different neuron types. The stochastic\npopulation equations that we find reveal how spike-history effects in\nsingle-neuron dynamics such as refractoriness and adaptation interact with\nfinite-size fluctuations on the population level. Efficient integration of the\nstochastic mesoscopic equations reproduces the statistical behavior of the\npopulation activities obtained from microscopic simulations of a full spiking\nneural network model. The theory describes nonlinear emergent dynamics like\nfinite-size-induced stochastic transitions in multistable networks and\nsynchronization in balanced networks of excitatory and inhibitory neurons. The\nmesoscopic equations are employed to rapidly simulate a model of a local\ncortical microcircuit consisting of eight neuron types. Our theory establishes\na general framework for modeling finite-size neural population dynamics based\non single cell and synapse parameters and offers an efficient approach to\nanalyzing cortical circuits and computations.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 16:56:09 GMT"}, {"version": "v2", "created": "Mon, 7 Nov 2016 18:48:07 GMT"}, {"version": "v3", "created": "Fri, 21 Apr 2017 08:41:24 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Schwalger", "Tilo", ""], ["Deger", "Moritz", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1611.00313", "submitter": "Joaquin Rapela", "authors": "Joaquin Rapela and Marissa Westerfield and Jeanne Townsend and Scott\n  Makeig", "title": "A new foreperiod effect on single-trial phase coherence. Part I:\n  existence and relevance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expecting events in time leads to more efficient behavior. A remarkable early\nfinding in the study of temporal expectancy is the foreperiod effect on\nreaction times; i.e., the influence or reaction time of the time period between\na warning signal and an imperative stimulus to which subjects are instructed to\nrespond as quickly as possible. Recently it has been shown that the phase of\noscillatory activity preceding stimulus presentation is related to behavior.\nHere we connect both of these findings by reporting a novel foreperiod effect\non the inter-trial phase coherence of the electroencephalogram (EEG) triggered\nby stimuli to which subjects are instructed not to respond. Inter-trial phase\ncoherence has been used to describe regularities in phases of groups of trials\ntime locked to an event of interest. We propose a single-trial measure of\ninter-trial phase coherence and prove its soundness. Equipped with this\nmeasure, and using a multivariate decoding method, we demonstrate that the\nforeperiod duration in and audiovisual attention-shifting task modulates\nsingle-trial phase coherence. In principle, this modulation could be an\nartifact of the decoding method used to detect it. We show that this is not the\ncase, since the modulation can also be observed using a simple averaging\nmethod. We show that the strength of this modulation correlates with subject\nbehavior (both error rates and mean-reaction times). We anticipate that the new\nforeperiod effect on inter-trial phase coherence, and the decoding method used\nhere to detect it, will be important tools to understand cognition at the\nsingle-trial level. In Part II of this manuscript, we support this claim, by\nshowing that changes in attention modulate the strength of the new foreperiod\neffect on a trial-by-trial basis.\n", "versions": [{"version": "v1", "created": "Fri, 26 Aug 2016 18:50:12 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Rapela", "Joaquin", ""], ["Westerfield", "Marissa", ""], ["Townsend", "Jeanne", ""], ["Makeig", "Scott", ""]]}, {"id": "1611.00358", "submitter": "Aline Amabile Viol Barbosa", "authors": "A. Viol, Fernanda Palhano-Fontes, Heloisa Onias, Draulio B. de Araujo\n  and G. M. Viswanathan", "title": "Shannon entropy of brain functional complex networks under the influence\n  of the psychedelic Ayahuasca", "comments": "27 pages, 6 figures", "journal-ref": "Scientific Reports 7: 7388,2017", "doi": "10.1038/s41598-017-06854-0", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The entropic brain hypothesis holds that the key facts concerning\npsychedelics are partially explained in terms of increased entropy of the\nbrain's functional connectivity. Ayahuasca is a psychedelic beverage of\nAmazonian indigenous origin with legal status in Brazil in religious and\nscientific settings. In this context, we use tools and concepts from the theory\nof complex networks to analyze resting state fMRI data of the brains of human\nsubjects under two distinct conditions: (i) under ordinary waking state and\n(ii) in an altered state of consciousness induced by ingestion of Ayahuasca. We\nreport an increase in the Shannon entropy of the degree distribution of the\nnetworks subsequent to Ayahuasca ingestion. We also find increased local and\ndecreased global network integration. Our results are broadly consistent with\nthe entropic brain hypothesis. Finally, we discuss our findings in the context\nof descriptions of \"mind-expansion\" frequently seen in self-reports of users of\npsychedelic drugs.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 17:20:00 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Viol", "A.", ""], ["Palhano-Fontes", "Fernanda", ""], ["Onias", "Heloisa", ""], ["de Araujo", "Draulio B.", ""], ["Viswanathan", "G. M.", ""]]}, {"id": "1611.00388", "submitter": "Uygar S\\\"umb\\\"ul", "authors": "Uygar S\\\"umb\\\"ul, Douglas Roussien Jr., Fei Chen, Nicholas Barry,\n  Edward S. Boyden, Dawen Cai, John P. Cunningham, Liam Paninski", "title": "Automated scalable segmentation of neurons from multispectral images", "comments": "main text: 9 pages and 5 figures, supplementary text: 11 pages and 8\n  figures (NIPS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstruction of neuroanatomy is a fundamental problem in neuroscience.\nStochastic expression of colors in individual cells is a promising tool,\nalthough its use in the nervous system has been limited due to various sources\nof variability in expression. Moreover, the intermingled anatomy of neuronal\ntrees is challenging for existing segmentation algorithms. Here, we propose a\nmethod to automate the segmentation of neurons in such (potentially\npseudo-colored) images. The method uses spatio-color relations between the\nvoxels, generates supervoxels to reduce the problem size by four orders of\nmagnitude before the final segmentation, and is parallelizable over the\nsupervoxels. To quantify performance and gain insight, we generate simulated\nimages, where the noise level and characteristics, the density of expression,\nand the number of fluorophore types are variable. We also present segmentations\nof real Brainbow images of the mouse hippocampus, which reveal many of the\ndendritic segments.\n", "versions": [{"version": "v1", "created": "Tue, 1 Nov 2016 21:01:44 GMT"}, {"version": "v2", "created": "Sun, 22 Jan 2017 01:48:48 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["S\u00fcmb\u00fcl", "Uygar", ""], ["Roussien", "Douglas", "Jr."], ["Chen", "Fei", ""], ["Barry", "Nicholas", ""], ["Boyden", "Edward S.", ""], ["Cai", "Dawen", ""], ["Cunningham", "John P.", ""], ["Paninski", "Liam", ""]]}, {"id": "1611.00509", "submitter": "Stefan Engblom", "authors": "Pavol Bauer, Stefan Engblom, Sanja Mikulovic and Aleksandar Senek", "title": "Multiscale modeling via split-step methods in neural firing", "comments": "23 pages, 10 figures", "journal-ref": "Math. Comput. Model. Dyn. Syst. 24(4):409--425, (2018)", "doi": "10.1080/13873954.2018.1488740", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal models based on the Hodgkin-Huxley equation form a fundamental\nframework in the field of computational neuroscience. While the neuronal state\nis often modeled deterministically, experimental recordings show stochastic\nfluctuations, presumably driven by molecular noise from the underlying\nmicrophysical conditions. In turn, the firing of individual neurons gives rise\nto an electric field n extracellular space, also thought to affect the firing\npattern of nearby neurons.\n  We develop a multiscale model which combines a stochastic ion channel gating\nprocess taking place on the neuronal membrane, together with the propagation of\nan action potential along the neuronal structure. We also devise a numerical\nmethod relying on a split-step strategy which effectively couples these two\nprocesses and we experimentally test the feasibility of this approach. We\nfinally also explain how the approach can be extended with Maxwell's equations\nto allow the potential to be propagated in extracellular space.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 08:59:40 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 07:57:26 GMT"}], "update_date": "2018-10-26", "authors_parsed": [["Bauer", "Pavol", ""], ["Engblom", "Stefan", ""], ["Mikulovic", "Sanja", ""], ["Senek", "Aleksandar", ""]]}, {"id": "1611.00607", "submitter": "Nithin Nagaraj", "authors": "Nithin Nagaraj and Karthi Balasubramanian", "title": "Three Perspectives on Complexity $-$ Entropy, Compression, Subsymmetry", "comments": "12 pages, 7 figures, under review (EPJ-ST special issue on \"New\n  perspectives on complex systems\")", "journal-ref": null, "doi": "10.1140/epjst/e2016-60347-2", "report-no": null, "categories": "physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is no single universally accepted definition of \"Complexity\". There are\nseveral perspectives on complexity and what constitutes complex behaviour or\ncomplex systems, as opposed to regular, predictable behaviour and simple\nsystems. In this paper, we explore the following perspectives on complexity:\n\"effort-to-describe\" (Shannon entropy $H$, Lempel-Ziv complexity $LZ$),\n\"effort-to-compress\" ($ETC$ complexity) and \"degree-of-order\" (Subsymmetry or\n$SubSym$). While Shannon entropy and $LZ$ are very popular and widely used,\n$ETC$ is a recently proposed measure for time series. In this paper, we also\npropose a novel normalized measure $SubSym$ based on the existing idea of\ncounting the number of subsymmetries or palindromes within a sequence. We\ncompare the performance of these complexity measures on the following tasks: a)\ncharacterizing complexity of short binary sequences of lengths 4 to 16, b)\ndistinguishing periodic and chaotic time series from 1D logistic map and 2D\nH\\'{e}non map, and c) distinguishing between tonic and irregular spiking\npatterns generated from the \"Adaptive exponential integrate-and-fire\" neuron\nmodel. Our study reveals that each perspective has its own advantages and\nuniqueness while also having an overlap with each other.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 13:45:04 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Nagaraj", "Nithin", ""], ["Balasubramanian", "Karthi", ""]]}, {"id": "1611.00834", "submitter": "Alexei Koulakov", "authors": "Sergey A. Shuvaev, Batuhan Ba\\c{s}erdem, Anthony Zador, Alexei A.\n  Koulakov", "title": "Network cloning using DNA barcodes", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to measure or manipulate network connectivity is the main\nchallenge in the field of connectomics. Recently, a set of approaches has been\ndeveloped that takes advantage of next generation DNA sequencing to scan\nconnections between neurons into a set of DNA barcodes. Individual DNA\nsequences called markers represent single neurons, while pairs of markers,\ncalled barcodes contain information about connections. Here we propose a\nstrategy for 'copying' or 'cloning' connectivity contained in barcodes into a\nclean slate tabula rasa network. We show that a one marker one cell (OMOC)\nrule, which forces all markers with the same sequence to condense into the same\nneuron, leads to fast and reliable formation of desired connectivity in a new\nnetwork. We show that OMOC rule yields convergence in a number of steps given\nby a power law function of the network size. We thus propose that copying\nnetwork connectivity from one network to another is theoretically possible.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 22:55:10 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Shuvaev", "Sergey A.", ""], ["Ba\u015ferdem", "Batuhan", ""], ["Zador", "Anthony", ""], ["Koulakov", "Alexei A.", ""]]}, {"id": "1611.00864", "submitter": "R Devon Hjelm", "authors": "R Devon Hjelm and Eswar Damaraju and Kyunghyun Cho and Helmut Laufs\n  and Sergey M. Plis and Vince Calhoun", "title": "Spatio-temporal Dynamics of Intrinsic Networks in Functional Magnetic\n  Imaging Data Using Recurrent Neural Networks", "comments": "Accepted to Frontiers of Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel recurrent neural network (RNN) approach to account for\ntemporal dynamics and dependencies in brain networks observed via functional\nmagnetic resonance imaging (fMRI). Our approach directly parameterizes temporal\ndynamics through recurrent connections, which can be used to formulate blind\nsource separation with a conditional (rather than marginal) independence\nassumption, which we call RNN-ICA. This formulation enables us to visualize the\ntemporal dynamics of both first order (activity) and second order (directed\nconnectivity) information in brain networks that are widely studied in a static\nsense, but not well-characterized dynamically. RNN-ICA predicts dynamics\ndirectly from the recurrent states of the RNN in both task and resting state\nfMRI. Our results show both task-related and group-differentiating directed\nconnectivity.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 02:45:26 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 13:32:41 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Hjelm", "R Devon", ""], ["Damaraju", "Eswar", ""], ["Cho", "Kyunghyun", ""], ["Laufs", "Helmut", ""], ["Plis", "Sergey M.", ""], ["Calhoun", "Vince", ""]]}, {"id": "1611.00945", "submitter": "Dylan Muir", "authors": "Hongzhi You and Giacomo Indiveri and Dylan Richard Muir", "title": "Surround suppression explained by long-range recruitment of local\n  competition, in a columnar V1 model", "comments": "32 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although neurons in columns of visual cortex of adult carnivores and primates\nshare similar orientation tuning preferences, responses of nearby neurons are\nsurprisingly sparse and temporally uncorrelated, especially in response to\ncomplex visual scenes. The mechanisms underlying this counter-intuitive\ncombination of response properties are still unknown. Here we present a\ncomputational model of columnar visual cortex which explains experimentally\nobserved integration of complex features across the visual field, and which is\nconsistent with anatomical and physiological profiles of cortical excitation\nand inhibition. In this model, sparse local excitatory connections within\ncolumns, coupled with strong unspecific local inhibition and\nfunctionally-specific long-range excitatory connections across columns, give\nrise to competitive dynamics that reproduce experimental observations. Our\nresults explain surround modulation of responses to simple and complex visual\nstimuli, including reduced correlation of nearby excitatory neurons, increased\nexcitatory response selectivity, increased inhibitory selectivity, and complex\norientation-tuning of surround modulation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Nov 2016 10:27:27 GMT"}, {"version": "v2", "created": "Thu, 30 Mar 2017 12:14:21 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["You", "Hongzhi", ""], ["Indiveri", "Giacomo", ""], ["Muir", "Dylan Richard", ""]]}, {"id": "1611.01390", "submitter": "Jonathan Vacher", "authors": "Jonathan Vacher, Andrew Isaac Meso, Laurent U. Perrinet and Gabriel\n  Peyr\\'e", "title": "Bayesian Modeling of Motion Perception using Dynamical Stochastic\n  Textures", "comments": "article+supplementary, 34+5 pages, 10+1 figures, accepted to Neural\n  Computation. arXiv admin note: text overlap with arXiv:1511.02705", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common practice to account for psychophysical biases in vision is to frame\nthem as consequences of a dynamic process relying on optimal inference with\nrespect to a generative model. The present study details the complete\nformulation of such a generative model intended to probe visual motion\nperception with a dynamic texture model. It is first derived in a set of\naxiomatic steps constrained by biological plausibility. We extend previous\ncontributions by detailing three equivalent formulations of this texture model.\nFirst, the composite dynamic textures are constructed by the random aggregation\nof warped patterns, which can be viewed as 3D Gaussian fields. Secondly, these\ntextures are cast as solutions to a stochastic partial differential equation\n(sPDE). This essential step enables real time, on-the-fly texture synthesis\nusing time-discretized auto-regressive processes. It also allows for the\nderivation of a local motion-energy model, which corresponds to the\nlog-likelihood of the probability density. The log-likelihoods are essential\nfor the construction of a Bayesian inference framework. We use the dynamic\ntexture model to psychophysically probe speed perception in humans using\nzoom-like changes in the spatial frequency content of the stimulus. The human\ndata replicates previous findings showing perceived speed to be positively\nbiased by spatial frequency increments. A Bayesian observer who combines a\nGaussian likelihood centered at the true speed and a spatial frequency\ndependent width with a \"slow speed prior\" successfully accounts for the\nperceptual bias. More precisely, the bias arises from a decrease in the\nobserver's likelihood width estimated from the experiments as the spatial\nfrequency increases. Such a trend is compatible with the trend of the dynamic\ntexture likelihood width.\n", "versions": [{"version": "v1", "created": "Wed, 2 Nov 2016 21:20:03 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 21:02:49 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Vacher", "Jonathan", ""], ["Meso", "Andrew Isaac", ""], ["Perrinet", "Laurent U.", ""], ["Peyr\u00e9", "Gabriel", ""]]}, {"id": "1611.01437", "submitter": "Joram Soch", "authors": "Joram Soch, Carsten Allefeld", "title": "Kullback-Leibler Divergence for the Normal-Gamma Distribution", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive the Kullback-Leibler divergence for the normal-gamma distribution\nand show that it is identical to the Bayesian complexity penalty for the\nunivariate general linear model with conjugate priors. Based on this finding,\nwe provide two applications of the KL divergence, one in simulated and one in\nempirical data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 16:16:24 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Soch", "Joram", ""], ["Allefeld", "Carsten", ""]]}, {"id": "1611.01439", "submitter": "Joram Soch", "authors": "Joram Soch, Carsten Allefeld", "title": "Exceedance Probabilities for the Dirichlet Distribution", "comments": "10 pages, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive an efficient method to calculate exceedance probabilities (EP) for\nthe Dirichlet distribution when the number of event types is larger than two.\nAlso, we present an intuitive application of Dirichlet EPs and compare our\nmethod to a sampling approach which is the current practice in neuroimaging\nmodel selection.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 16:20:10 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Soch", "Joram", ""], ["Allefeld", "Carsten", ""]]}, {"id": "1611.01557", "submitter": "Robert Rosenbaum", "authors": "Ryan Pyle and Robert Rosenbaum", "title": "Spatiotemporal dynamics and reliable computations in recurrent spiking\n  neural networks", "comments": null, "journal-ref": "Phys. Rev. Lett. 118, 018103 (2017)", "doi": "10.1103/PhysRevLett.118.018103", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomly connected networks of excitatory and inhibitory spiking neurons\nprovide a parsimonious model of neural variability, but are notoriously\nunreliable for performing computations. We show that this difficulty is\novercome by incorporating the well-documented dependence of connection\nprobability on distance. Spatially extended spiking networks exhibit\nsymmetry-breaking bifurcations and generate spatiotemporal patterns that can be\ntrained to perform dynamical computations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Nov 2016 22:31:03 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Pyle", "Ryan", ""], ["Rosenbaum", "Robert", ""]]}, {"id": "1611.01639", "submitter": "Patrick McClure", "authors": "Patrick McClure, Nikolaus Kriegeskorte", "title": "Robustly representing uncertainty in deep neural networks through\n  sampling", "comments": "Bayesian Deep Learning Workshop (NIPS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As deep neural networks (DNNs) are applied to increasingly challenging\nproblems, they will need to be able to represent their own uncertainty.\nModeling uncertainty is one of the key features of Bayesian methods. Using\nBernoulli dropout with sampling at prediction time has recently been proposed\nas an efficient and well performing variational inference method for DNNs.\nHowever, sampling from other multiplicative noise based variational\ndistributions has not been investigated in depth. We evaluated Bayesian DNNs\ntrained with Bernoulli or Gaussian multiplicative masking of either the units\n(dropout) or the weights (dropconnect). We tested the calibration of the\nprobabilistic predictions of Bayesian convolutional neural networks (CNNs) on\nMNIST and CIFAR-10. Sampling at prediction time increased the calibration of\nthe DNNs' probabalistic predictions. Sampling weights, whether Gaussian or\nBernoulli, led to more robust representation of uncertainty compared to\nsampling of units. However, using either Gaussian or Bernoulli dropout led to\nincreased test set classification accuracy. Based on these findings we used\nboth Bernoulli dropout and Gaussian dropconnect concurrently, which we show\napproximates the use of a spike-and-slab variational distribution without\nincreasing the number of learned parameters. We found that spike-and-slab\nsampling had higher test set performance than Gaussian dropconnect and more\nrobustly represented its uncertainty compared to Bernoulli dropout.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 12:32:16 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 09:27:46 GMT"}, {"version": "v3", "created": "Thu, 2 Feb 2017 10:21:33 GMT"}, {"version": "v4", "created": "Fri, 1 Sep 2017 02:50:59 GMT"}, {"version": "v5", "created": "Tue, 5 Dec 2017 16:11:17 GMT"}, {"version": "v6", "created": "Fri, 8 Dec 2017 17:36:22 GMT"}, {"version": "v7", "created": "Sat, 20 Jan 2018 13:44:32 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["McClure", "Patrick", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "1611.01643", "submitter": "David Leitman", "authors": "David I. Leitman, Christopher Edgar, Jeffery Berman, Krystal Gamez,\n  Sascha Fruhholz and Timothy P. L. Roberts", "title": "Amygdala and insula contributions to dorsal-ventral pathway integration\n  in the prosodic neural network", "comments": "Main document: 41 pages 6 figures 1 table supplemental material: 4\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speech prosody enables communication of emotional intentions via modulation\nof vocal intonations. Reciprocal interactions between superior temporal (STG)\nand inferior frontal gyri (IFG) have been shown to anchor a neural network for\nprosodic comprehension, which we refer to as the Prosody Neural Network (PNN).\nAlthough the amygdala is critical for socio-emotional processing, its integral\nfunctional and structural role in processing social information from speech\nprosody as well as its role in the PNN is largely unexplored including\ninconsistent recent empirical findings. Here, we used magnetoencephalography\nand diffusion magnetic resonance imaging of white-matter pathways to establish\nthat the PNN is characterized by (1) a robust amygdala-cortical functional\nconnectivity that dynamically evolves as prosodic interpretation progresses,\n(2) direct structural fiber connections between amygdala and STG/IFG traversing\na ventral white-matter pathway, and (3) robust amygdala-insula functional\nconnectivity and structural insula fiber projections to arcuate STG-IFG\nconnections. These findings support a role for functional and structural\namygdala-centric ventral pathways in combining speech features to form prosodic\npercepts. They also highlight insula contributions to prosodic comprehension,\npotentially via vertical integration of amygdala-centric ventral processing\ninto dorsal pathways responsible for prosodic motor articulation and speech\nplanning.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 12:53:05 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Leitman", "David I.", ""], ["Edgar", "Christopher", ""], ["Berman", "Jeffery", ""], ["Gamez", "Krystal", ""], ["Fruhholz", "Sascha", ""], ["Roberts", "Timothy P. L.", ""]]}, {"id": "1611.01886", "submitter": "Wentao Huang", "authors": "Wentao Huang and Kechen Zhang", "title": "An Information-Theoretic Framework for Fast and Robust Unsupervised\n  Learning via Neural Population Infomax", "comments": "25 pages, 7 figures, 5th International Conference on Learning\n  Representations (ICLR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A framework is presented for unsupervised learning of representations based\non infomax principle for large-scale neural populations. We use an asymptotic\napproximation to the Shannon's mutual information for a large neural population\nto demonstrate that a good initial approximation to the global\ninformation-theoretic optimum can be obtained by a hierarchical infomax method.\nStarting from the initial solution, an efficient algorithm based on gradient\ndescent of the final objective function is proposed to learn representations\nfrom the input datasets, and the method works for complete, overcomplete, and\nundercomplete bases. As confirmed by numerical experiments, our method is\nrobust and highly efficient for extracting salient features from input\ndatasets. Compared with the main existing methods, our algorithm has a distinct\nadvantage in both the training speed and the robustness of unsupervised\nrepresentation learning. Furthermore, the proposed method is easily extended to\nthe supervised or unsupervised model for training deep structure networks.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 04:17:28 GMT"}, {"version": "v2", "created": "Thu, 19 Jan 2017 17:53:31 GMT"}, {"version": "v3", "created": "Mon, 6 Feb 2017 17:11:34 GMT"}, {"version": "v4", "created": "Fri, 10 Mar 2017 16:41:16 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Huang", "Wentao", ""], ["Zhang", "Kechen", ""]]}, {"id": "1611.01912", "submitter": "Xiao-hua Cao", "authors": "Xiaoli Ma, Cuiyin Zhu, Chenglin Li, Xiaohua Cao", "title": "Category specificity of N170 response recovery speeds for faces and\n  Chinese characters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural selectivity of N170 responses is an important phenomenon in perceptual\nprocessing; however, the recovery times of neural selective responses remain\nunclear. In the present study, we used an adaptation paradigm to test the\nrecovery speeds of N170 responses to faces and Chinese characters. The results\nshowed that recovery of N170 responses elicited by faces occurred between 1400\nand 1800 ms after stimuli onset, whereas recovery of N170 responses elicited by\nChinese characters occurred between 600 and 800 ms after stimuli onset. These\nresults demonstrate category-specific recovery speeds of N170 responses\ninvolved in the processing of faces and Chinese characters.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 06:54:32 GMT"}], "update_date": "2016-11-08", "authors_parsed": [["Ma", "Xiaoli", ""], ["Zhu", "Cuiyin", ""], ["Li", "Chenglin", ""], ["Cao", "Xiaohua", ""]]}, {"id": "1611.02116", "submitter": "Zachary Kilpatrick PhD", "authors": "Daniel B. Poll and Zachary P. Kilpatrick", "title": "Velocity integration in a multilayer neural field model of spatial\n  working memory", "comments": "37 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze a multilayer neural field model of spatial working memory,\nfocusing on the impact of interlaminar connectivity, spatial heterogeneity, and\nvelocity inputs. Models of spatial working memory typically employ networks\nthat generate persistent activity via a combination of local excitation and\nlateral inhibition. Our model is comprised of a multilayer set of equations\nthat describes connectivity between neurons in the same and different layers\nusing an integral term. The kernel of this integral term then captures the\nimpact of different interlaminar connection strengths, spatial heterogeneity,\nand velocity input. We begin our analysis by focusing on how interlaminar\nconnectivity shapes the form and stability of (persistent) bump attractor\nsolutions to the model. Subsequently, we derive a low-dimensional approximation\nthat describes how spatial heterogeneity, velocity input, and noise combine to\ndetermine the position of bump solutions. The main impact of spatial\nheterogeneity is to break the translation symmetry of the network, so bumps\nprefer to reside at one of a finite number of local attractors in the domain.\nWith the reduced model in hand, we can then approximate the dynamics of the\nbump position using a continuous time Markov chain model that describes bump\nmotion between local attractors. While heterogeneity reduces the effective\ndiffusion of the bumps, it also disrupts the processing of velocity inputs by\nslowing the velocity-induced propagation of bumps. However, we demonstrate that\nnoise can play a constructive role by promoting bump motion transitions,\nrestoring a mean bump velocity that is close to the input velocity.\n", "versions": [{"version": "v1", "created": "Mon, 7 Nov 2016 15:34:56 GMT"}, {"version": "v2", "created": "Mon, 16 Jan 2017 16:42:41 GMT"}], "update_date": "2017-01-17", "authors_parsed": [["Poll", "Daniel B.", ""], ["Kilpatrick", "Zachary P.", ""]]}, {"id": "1611.02272", "submitter": "Alexander Tait", "authors": "Alexander N. Tait, Thomas Ferreira de Lima, Ellen Zhou, Allie X. Wu,\n  Mitchell A. Nahmias, Bhavin J. Shastri, and Paul R. Prucnal", "title": "Neuromorphic Silicon Photonic Networks", "comments": "12 pages, 4 figures, accepted in Scientific Reports", "journal-ref": "Sci.Rep. 7 (2017) 7430", "doi": "10.1038/s41598-017-07754-z", "report-no": null, "categories": "q-bio.NC cs.NE physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photonic systems for high-performance information processing have attracted\nrenewed interest. Neuromorphic silicon photonics has the potential to integrate\nprocessing functions that vastly exceed the capabilities of electronics. We\nreport first observations of a recurrent silicon photonic neural network, in\nwhich connections are configured by microring weight banks. A mathematical\nisomorphism between the silicon photonic circuit and a continuous neural\nnetwork model is demonstrated through dynamical bifurcation analysis.\nExploiting this isomorphism, a simulated 24-node silicon photonic neural\nnetwork is programmed using \"neural compiler\" to solve a differential system\nemulation task. A 294-fold acceleration against a conventional benchmark is\npredicted. We also propose and derive power consumption analysis for\nmodulator-class neurons that, as opposed to laser-class neurons, are compatible\nwith silicon photonic platforms. At increased scale, Neuromorphic silicon\nphotonics could access new regimes of ultrafast information processing for\nradio, control, and scientific computing.\n", "versions": [{"version": "v1", "created": "Sat, 5 Nov 2016 00:15:59 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 17:35:37 GMT"}, {"version": "v3", "created": "Mon, 12 Jun 2017 15:56:45 GMT"}], "update_date": "2017-11-17", "authors_parsed": [["Tait", "Alexander N.", ""], ["de Lima", "Thomas Ferreira", ""], ["Zhou", "Ellen", ""], ["Wu", "Allie X.", ""], ["Nahmias", "Mitchell A.", ""], ["Shastri", "Bhavin J.", ""], ["Prucnal", "Paul R.", ""]]}, {"id": "1611.03026", "submitter": "Ariel Haimovici", "authors": "Ariel Haimovici, Pablo Balenzuela and Enzo Tagliazucchi", "title": "Dynamical signatures of structural connectivity damage to a model of the\n  brain posed at criticality", "comments": "6 figures, 26 pages", "journal-ref": "Brain Connectivity, 2016", "doi": "10.1089/brain.2016.0455", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronization of brain activity fluctuations is believed to represent\ncommunication between spatially distant neural processes. These inter-areal\nfunctional interactions develop in the background of a complex network of\naxonal connections linking cortical and sub-cortical neurons, termed the human\n\"structural connectome\". Theoretical considerations and experimental evidence\nsupport the view that the human brain can be modeled as a system operating at a\ncritical point between ordered (sub-critical) and disordered (super-critical)\nphases. Here, we explore the hypothesis that pathologies resulting from brain\ninjury of different etiology are related to the model of a critical brain. For\nthis purpose, we investigate how damage to the integrity of the structural\nconnectome impacts on the signatures of critical dynamics. Adopting a hybrid\nmodeling approach combining an empirical weighted network of human structural\nconnections with a conceptual model of critical dynamics, we show that lesions\nlocated at highly transited connections progressively displace the model\ntowards the sub-critical regime. The topological properties of the nodes and\nlinks are of less importance when considered independently of their weight in\nthe network. We observe that damage to midline hubs such as the middle and\nposterior cingulate cortex is most crucial for the disruption of criticality in\nthe model. However, a similar effect can be achieved by targeting less\ntransited nodes and links whose connection weights add up to an equivalent\namount. This implies that brain pathology does not necessarily arise due to\ninsult targeted at well-connected areas and that inter- subject variability\ncould obscure lesions located at non-hub regions. Finally, we discuss the\npredictions of our model in the context of clinical studies of traumatic brain\ninjury and neurodegenerative disorders.\n", "versions": [{"version": "v1", "created": "Wed, 9 Nov 2016 17:48:45 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Haimovici", "Ariel", ""], ["Balenzuela", "Pablo", ""], ["Tagliazucchi", "Enzo", ""]]}, {"id": "1611.03363", "submitter": "Sarah Parisot", "authors": "Sarah Parisot, Jonathan Passerat-Palmbach, Markus D. Schirmer, Boris\n  Gutman", "title": "Proceedings of the Workshop on Brain Analysis using COnnectivity\n  Networks - BACON 2016", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding brain connectivity in a network-theoretic context has shown\nmuch promise in recent years. This type of analysis identifies brain\norganisational principles, bringing a new perspective to neuroscience. At the\nsame time, large public databases of connectomic data are now available.\nHowever, connectome analysis is still an emerging field and there is a crucial\nneed for robust computational methods to fully unravelits potential. This\nworkshop provides a platform to discuss the development of new analytic\ntechniques; methods for evaluating and validating commonly used approaches; as\nwell as the effects of variations in pre-processing steps.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 15:51:42 GMT"}, {"version": "v2", "created": "Fri, 11 Nov 2016 12:21:03 GMT"}, {"version": "v3", "created": "Thu, 24 Nov 2016 17:04:05 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Parisot", "Sarah", ""], ["Passerat-Palmbach", "Jonathan", ""], ["Schirmer", "Markus D.", ""], ["Gutman", "Boris", ""]]}, {"id": "1611.03441", "submitter": "Chun-Chung Chen", "authors": "Kevin Sean Chen, Chun-Chung Chen, C. K. Chan", "title": "Measurement of Anticipative Power of a Retina by Predictive Information", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictive properties of a retina are studied by measuring the mutual\ninformation (MI) between its stimulation and the corresponding firing rates\nwhile it is being probed by a train of short pulses with stochastic intervals.\nFeatures of the measured MI at various time shifts between the stimulation and\nthe response are used to characterize the predictive properties of the retina.\nBy varying the statistical properties of the pulse train, our experiments show\nthat a retina has the ability to predict future events of the stimulation if\nthe information rate of the stimulation is low enough. Also, this predictive\nproperty of the retina occurs at a time scale similar to the well established\nanticipative phenomenon of omitted stimulus response in a retina. Furthermore,\na retina can make use of its predictive ability to distinguish between time\nseries created by an Ornstein--Uhlenbeck and a hidden Markovian process.\n", "versions": [{"version": "v1", "created": "Thu, 10 Nov 2016 18:38:45 GMT"}], "update_date": "2016-11-11", "authors_parsed": [["Chen", "Kevin Sean", ""], ["Chen", "Chun-Chung", ""], ["Chan", "C. K.", ""]]}, {"id": "1611.03605", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "A Possible Role for Entropy in Creative Cognition", "comments": "6 pages; http://sciforum.net/conference/84/paper/3652; in Proceedings\n  3rd International Electronic Conf on Entropy and its Applications, 1-10 Nov\n  (2016)", "journal-ref": null, "doi": "10.3390/ecea-3-E001", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper states the case for applying the conceptual and analytic tools\nassociated with the study of entropy in physical systems to cognition, focusing\non creative cognition. It is proposed that minds modify their contents and\nadapt to their environments to minimize psychological entropy:\narousal-provoking uncertainty, which can be experienced negatively as anxiety,\nor positively as a wellspring for creativity (or both). Thus, intrinsically\nmotivated creativity begins with detection of high psychological entropy\nmaterial (e.g., a question or inconsistency), which provokes uncertainty and is\narousal-inducing. This material is recursively considering from new contexts\nuntil it is sufficiently restructured that arousal dissipates and entropy\nreaches an acceptable level. Restructuring involves neural synchrony and\ndynamic binding, and may be facilitated by temporarily shifting to a more\nassociative mode of thought. The creative outcome may similarly induce\nrestructuring in others, and thereby contribute to the cultural evolution of\nmore nuanced understandings. Thus, the concept of entropy could play a unifying\nrole in cognitive science as a driver of thought and action, and in cultural\nstudies as the driver of the creative innovations that fuel cultural evolution.\nThe paper concludes with an invitation for cross-disciplinary exploration of\nthis potential new arena of entropy studies.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 08:08:49 GMT"}], "update_date": "2016-11-14", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1611.03609", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "The Neural Basis and Evolution of Divergent and Convergent Thought", "comments": "29 pages; 5 figures; in O. Vartanian & R. Jung (Eds.) The Cambridge\n  Handbook of the Neuroscience of Creativity. Cambridge MA: Cambridge\n  University Press. arXiv admin note: text overlap with arXiv:1610.02484", "journal-ref": "In O. Vartanian & R. Jung, Eds. The Cambridge Handbook of the\n  Neuroscience of Creativity (pp. 58-70). Cambridge MA: CUP (2018)", "doi": "10.1017/9781316556238", "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter takes as its departure point a neural level theory of insight\nthat arose from studies of the sparse, distributed, content-addressable\narchitecture of associative memory. It is argued that convergent thought is\nmost fruitfully characterized in terms of, not the generation of a single\ncorrect solution (as it is conventionally construed), but using concepts in\ntheir most compact form by activating neural cell assemblies that respond to\ntheir most typical properties. This allows them to be deployed in a\nconventional manner such that effort is reserved for exploring causal\nrelationships. Conversely, it is argued that divergent thought is most\nfruitfully characterized in terms of, not the generation of multiple solutions\n(as it is conventionally construed), but using concepts in a form that is,\nalbeit expanded, constrained by the situation, by activating neural cell\nassemblies that respond to context-specific atypical properties. This allows\nthem to be deployed in a manner that is conducive to exploring unconventional\nyet potentially relevant associations, and unearthing potentially useful\nrelationships of correlation. Thus, divergent thought can involve as few as one\nidea. This proposal is compatible with widespread beliefs that (1) most\ncreative tasks require not many solutions but one, yet entail both divergent\nand convergent thinking, and (2) not all problems with multiple solutions\nrequire creative thinking, and conversely, some problems with single solution\ndo require creative thought. The chapter discusses how the ability to shift\nbetween convergent and divergent modes of thought may have evolved, and it\nconcludes with educational and vocational implications.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 08:25:06 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 22:28:19 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1611.03698", "submitter": "Michael G. M\\\"uller", "authors": "Michael G. M\\\"uller, Christos H. Papadimitriou, Wolfgang Maass, Robert\n  Legenstein", "title": "A model for structured information representation in neural networks", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans possess the capability to reason at an abstract level and to structure\ninformation into abstract categories, but the underlying neural processes have\nremained unknown. Experimental evidence has recently emerged for the\norganization of an important aspect of abstract reasoning: for assigning words\nto semantic roles in a sentence, such as agent (or subject) and patient (or\nobject). Using minimal assumptions, we show how such a binding of words to\nsemantic roles emerges in a generic spiking neural network through Hebbian\nplasticity. The resulting model is consistent with the experimental data and\nenables new computational functionalities such as structured information\nretrieval, copying data, and comparisons. It thus provides a basis for the\nimplementation of more demanding cognitive computations by networks of spiking\nneurons.\n", "versions": [{"version": "v1", "created": "Fri, 11 Nov 2016 13:33:35 GMT"}, {"version": "v2", "created": "Mon, 23 Apr 2018 09:43:21 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 16:41:57 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["M\u00fcller", "Michael G.", ""], ["Papadimitriou", "Christos H.", ""], ["Maass", "Wolfgang", ""], ["Legenstein", "Robert", ""]]}, {"id": "1611.03965", "submitter": "Reza Ebrahimpour", "authors": "Farzaneh Olianezhad, Maryam Tohidi-Moghaddam, Sajjad Zabbah, Reza\n  Ebrahimpour", "title": "Residual Information of Previous Decision Affects Evidence Accumulation\n  in Current Decision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bias in perceptual decisions comes to pass when the advance knowledge\ncolludes with the current sensory evidence in support of the final choice. The\nliterature on decision making suggests two main hypotheses to account for this\nkind of bias: internal bias signals are derived from (a) the residual of motor\nresponse-related signals, and (b) the sensory information residues of the\ndecisions that we made in the past. Beside these hypotheses, a credible\nhypothesis proposed by this study to explain the cause of decision biasing,\nsuggests that the decision-related neuron can make use of the residual\ninformation of the previous decision for the current decision. We demonstrate\nthe validity of this assumption, first by performing behavioral experiments\nbased on the two-alternative forced-choice (TAFC) discrimination of motion\ndirection paradigms and then, we modified the pure drift-diffusion model (DDM)\nbased on accumulation to the bound mechanism to account for the sequential\neffect. In both cases, the trace of the previous trial influences the current\ndecision. Results indicate that the probability of being correct in a current\ndecision increases if it is in line with the previously made decision. Also,\nthe model that keeps the previous decision information provides a better fit to\nthe behavioral data. Our findings suggest that the state of a decision variable\nwhich is represented in the activity of decision-related neurons after crossing\nthe bound (in the previous decision) can accumulate with the decision variable\nfor the current decision in consecutive trials.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 07:33:13 GMT"}, {"version": "v2", "created": "Sat, 14 Oct 2017 11:26:03 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Olianezhad", "Farzaneh", ""], ["Tohidi-Moghaddam", "Maryam", ""], ["Zabbah", "Sajjad", ""], ["Ebrahimpour", "Reza", ""]]}, {"id": "1611.04023", "submitter": "Gerard Rinkus", "authors": "Gerard J. Rinkus", "title": "Sparsey: Event Recognition via Deep Hierarchical Spare Distributed Codes", "comments": "This is a manuscript form of a paper published in Frontiers in\n  Computational Neuroscience in 2014\n  (http://dx.doi.org/10.3389/fncom.2014.00160). 65 pages, 28 figures, 8 tables", "journal-ref": "Frontiers in Computational Neuroscience, Vol. 8, Article 160\n  (2014)", "doi": "10.3389/fncom.2014.00160", "report-no": null, "categories": "q-bio.NC cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual cortex's hierarchical, multi-level organization is captured in many\nbiologically inspired computational vision models, the general idea being that\nprogressively larger scale, more complex spatiotemporal features are\nrepresented in progressively higher areas. However, most earlier models use\nlocalist representations (codes) in each representational field, which we\nequate with the cortical macrocolumn (mac), at each level. In localism, each\nrepresented feature/event (item) is coded by a single unit. Our model, Sparsey,\nis also hierarchical but crucially, uses sparse distributed coding (SDC) in\nevery mac in all levels. In SDC, each represented item is coded by a small\nsubset of the mac's units. SDCs of different items can overlap and the size of\noverlap between items can represent their similarity. The difference between\nlocalism and SDC is crucial because SDC allows the two essential operations of\nassociative memory, storing a new item and retrieving the best-matching stored\nitem, to be done in fixed time for the life of the model. Since the model's\ncore algorithm, which does both storage and retrieval (inference), makes a\nsingle pass over all macs on each time step, the overall model's\nstorage/retrieval operation is also fixed-time, a criterion we consider\nessential for scalability to huge datasets. A 2010 paper described a\nnonhierarchical version of this model in the context of purely spatial pattern\nprocessing. Here, we elaborate a fully hierarchical model (arbitrary numbers of\nlevels and macs per level), describing novel model principles like progressive\ncritical periods, dynamic modulation of principal cells' activation functions\nbased on a mac-level familiarity measure, representation of multiple\nsimultaneously active hypotheses, a novel method of time warp invariant\nrecognition, and we report results showing learning/recognition of\nspatiotemporal patterns.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 17:35:23 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Rinkus", "Gerard J.", ""]]}, {"id": "1611.04184", "submitter": "Ehtibar Dzhafarov", "authors": "V\\'ictor H. Cervantes and Ehtibar N. Dzhafarov", "title": "Advanced Analysis of Quantum Contextuality in a Psychophysical\n  Double-Detection Experiment", "comments": "10 pp, contains experimental data. To be published in Journal of\n  Mathematical Psychology", "journal-ref": "Journal of Mathematical Psychology 79, 77-84, 2017", "doi": "10.1016/j.jmp.2017.03.003", "report-no": null, "categories": "q-bio.NC math.PR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The results of behavioral experiments typically exhibit inconsistent\nconnectedness, i.e., they violate the condition known as \"no-signaling,\"\n\"no-disturbance,\" or \"marginal selectivity.\" This prevents one from evaluating\nthese experiments in terms of quantum contextuality if the latter understood\ntraditionally (as, e.g., in the Kochen-Specker theorem or Bell-type\ninequalities). The Contextuality-by-Default (CbD) theory separates\ncontextuality from inconsistent connectedness. When applied to quantum physical\nexperiments that exhibit inconsistent connectedness (due to context-dependent\nerrors and/or signaling), the CbD computations reveal quantum contextuality in\nspite of this. When applied to a large body of published behavioral\nexperiments, the CbD computations reveal no quantum contextuality: all\ncontext-dependence in these experiments is described by inconsistent\nconnectedness alone. Until recently, however, experimental analysis of\ncontextuality was confined to so-called cyclic systems of binary random\nvariables. Here, we present the results of a psychophysical double-detection\nexperiment that do not form a cyclic system: their analysis requires that we\nuse a recent modification of CbD, one that makes the class of noncontextual\nsystems more restricted. Nevertheless our results once again indicate that when\ninconsistent connectedness is taken into account, the system exhibits no\ncontextuality. KEYWORDS: contextuality, cyclic systems, double-detection,\ninconsistent connectedness, psychophysics.\n", "versions": [{"version": "v1", "created": "Sun, 13 Nov 2016 20:30:54 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 04:53:02 GMT"}, {"version": "v3", "created": "Fri, 31 Mar 2017 14:54:26 GMT"}], "update_date": "2017-09-05", "authors_parsed": [["Cervantes", "V\u00edctor H.", ""], ["Dzhafarov", "Ehtibar N.", ""]]}, {"id": "1611.04364", "submitter": "Laurent Perrinet", "authors": "Wahiba Taouali (INT), Giacomo Benvenuti (INT), Pascal Wallisch,\n  Fr\\'ed\\'eric Chavane (INT), Laurent Perrinet (INT)", "title": "Testing the Odds of Inherent versus Observed Over-dispersion in Neural\n  Spike Counts Odds of Inherent versus Observed Over-dispersion", "comments": null, "journal-ref": "Journal of Neurophysiology, American Physiological Society, 2016,\n  115 (1), pp.434-444", "doi": "10.1152/jn.00194.2015", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The repeated presentation of an identical visual stimulus in the receptive\nfield of a neuron may evoke different spiking patterns at each trial.\nProbabilistic methods are essential to understand the functional role of this\nvariance within the neural activity. In that case, a Poisson process is the\nmost common model of trial-to-trial variability. For a Poisson process, the\nvariance of the spike count is constrained to be equal to the mean,\nirrespective of the duration of measurements. Numerous studies have shown that\nthis relationship does not generally hold. Specifically, a majority of\nelectrophysiological recordings show an \" over-dispersion \" effect: Responses\nthat exhibit more inter-trial variability than expected from a Poisson process\nalone. A model that is particularly well suited to quantify over-dispersion is\nthe Negative-Binomial distribution model. This model is well-studied and widely\nused but has only recently been applied to neuroscience. In this paper, we\naddress three main issues. First, we describe how the Negative-Binomial\ndistribution provides a model apt to account for overdispersed spike counts.\nSecond, we quantify the significance of this model for any neurophysiological\ndata by proposing a statistical test, which quantifies the odds that\nover-dispersion could be due to the limited number of repetitions (trials). We\napply this test to three neurophysiological tests along the visual pathway.\nFinally, we compare the performance of this model to the Poisson model on a\npopulation decoding task. We show that the decoding accuracy is improved when\naccounting for over-dispersion, especially under the hypothesis of tuned\nover-dispersion.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 12:50:47 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Taouali", "Wahiba", "", "INT"], ["Benvenuti", "Giacomo", "", "INT"], ["Wallisch", "Pascal", "", "INT"], ["Chavane", "Fr\u00e9d\u00e9ric", "", "INT"], ["Perrinet", "Laurent", "", "INT"]]}, {"id": "1611.04393", "submitter": "Amanmeet Garg", "authors": "Amanmeet Garg, Donghuan Lu, Karteek Popuri and Mirza Faisal Beg", "title": "Cortical Geometry Network and Topology Markers for Parkinson's Disease", "comments": "Presented at The MICCAI-BACON 16 Workshop (arXiv:1611.03363) Report\n  number: BACON/2016/02", "journal-ref": null, "doi": null, "report-no": "BACON/2016/02", "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurodegeneration affects cortical gray matter leading to loss of cortical\nmantle volume. As a result of such volume loss, the geometrical arrangement of\nthe regions on the cortical surface is expected to be altered in comparison to\nhealthy brains. Here we present a novel method to study the alterations in\nbrain cortical surface geometry in Parkinson's disease (PD) subjects with a\n\\emph{Geometry Networks (GN)} framework. The local geometrical arrangement of\nthe cortical surface is captured as the 3D coordinates of the centroids of\nanatomically defined parcels on the surface. The inter-regional distance\nbetween cortical patches is the signal of interest and is captured as a\ngeometry network. We study its topology by computing the dimensionality of\nsimplicial complexes induced on a filtration of binary undirected networks for\neach geometry network. In a permutation statistics test, a statistically\nsignificant ($p<0.05$) difference was observed in the homology features between\nPD and healthy control groups highlighting its potential to differentiate\nbetween the groups and their potential utility in disease diagnosis.\n", "versions": [{"version": "v1", "created": "Mon, 14 Nov 2016 14:33:47 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Garg", "Amanmeet", ""], ["Lu", "Donghuan", ""], ["Popuri", "Karteek", ""], ["Beg", "Mirza Faisal", ""]]}, {"id": "1611.04758", "submitter": "Eduardo  Cocca Padovani", "authors": "Eduardo C. Padovani", "title": "Structure and Dynamics of Brain Lobes Functional Networks at the Onset\n  of Anesthesia Induced Loss of Consciousness", "comments": "41 pages; 30 figures; 30 tables. arXiv admin note: substantial text\n  overlap with arXiv:1604.00002", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anesthetic agents are neurotropic drugs able to induce dramatic alterations\nin the thalamo-cortical system, promoting a drastic reduction in awareness and\nlevel of consciousness. There is experimental evidence that general anesthesia\nimpacts large scale functional networks leading to alterations in the brain\nstate. However, the way anesthetics affect the structure assumed by functional\nconnectivity in different brain regions have not been reported yet. Within this\ncontext, the present study has sought to characterize the functional brain\nnetworks respective to the frontal, parietal, temporal and occipital lobes. In\nthis experiment, electro-physiological neural activity was recorded through the\nuse of a dense ECoG-electrode array positioned directly over the cortical\nsurface of an old world monkey of the species Macaca fuscata. Networks were\nserially estimated over time at each five seconds, while the animal model was\nunder controlled experimental conditions of an anesthetic induction process. In\neach one of the four cortical brain lobes, prominent alterations on distinct\nproperties of the networks evidenced a transition in the networks architecture,\nwhich occurred within about one and a half minutes after the administration of\nthe anesthetics. The characterization of functional brain networks performed in\nthis study represents important experimental evidence and brings new knowledge\ntowards the understanding of neural correlates of consciousness in terms of the\nstructure and properties of the functional brain networks.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 09:49:01 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Padovani", "Eduardo C.", ""]]}, {"id": "1611.04783", "submitter": "Sofia Ira Ktena", "authors": "Sofia Ira Ktena, Sarah Parisot, Jonathan Passerat-Palmbach, Daniel\n  Rueckert", "title": "Comparison of Brain Networks with Unknown Correspondences", "comments": "Presented at The MICCAI-BACON 16 Workshop\n  (https://arxiv.org/abs/1611.03363)", "journal-ref": null, "doi": null, "report-no": "BACON/2016/03", "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph theory has drawn a lot of attention in the field of Neuroscience during\nthe last decade, mainly due to the abundance of tools that it provides to\nexplore the interactions of elements in a complex network like the brain. The\nlocal and global organization of a brain network can shed light on mechanisms\nof complex cognitive functions, while disruptions within the network can be\nlinked to neurodevelopmental disorders. In this effort, the construction of a\nrepresentative brain network for each individual is critical for further\nanalysis. Additionally, graph comparison is an essential step for inference and\nclassification analyses on brain graphs. In this work we explore a method based\non graph edit distance for evaluating graph similarity, when correspondences\nbetween network elements are unknown due to different underlying subdivisions\nof the brain. We test this method on 30 unrelated subjects as well as 40 twin\npairs and show that this method can accurately reflect the higher similarity\nbetween two related networks compared to unrelated ones, while identifying node\ncorrespondences.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 10:51:15 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Ktena", "Sofia Ira", ""], ["Parisot", "Sarah", ""], ["Passerat-Palmbach", "Jonathan", ""], ["Rueckert", "Daniel", ""]]}, {"id": "1611.04794", "submitter": "Liviu Badea", "authors": "Liviu Badea, Mihaela Onu, Tao Wu, Adina Roceanu, Ovidiu Bajenaru", "title": "Exploring the reproducibility of functional connectivity alterations in\n  Parkinson's Disease", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0188196", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since anatomic MRI is presently not able to directly discern neuronal loss in\nParkinson's Disease (PD), studying the associated functional connectivity (FC)\nchanges seems a promising approach toward developing non-invasive and\nnon-radioactive neuroimaging markers for this disease. While several groups\nhave reported such FC changes in PD, there are also significant discrepancies\nbetween studies. Investigating the reproducibility of PD-related FC changes on\nindependent datasets is therefore of crucial importance. We acquired\nresting-state fMRI scans for 43 subjects (27 patients , 16 controls) and\ncompared the observed FC changes with those obtained in 2 independent datasets,\none made available by the PPMI consortium and a second one by the group of Tao\nWu. Unfortunately, PD-related functional connectivity changes turned out to be\nnon-reproducible across datasets. This could be due to disease heterogeneity,\nbut also to technical differences. To distinguish between the two, we devised a\nmethod to directly check for disease heterogeneity using random splits of a\nsingle dataset. Since we still observe non-reproducibility in a large fraction\nof random splits of the same dataset, we conclude that functional heterogeneity\nmay be a dominating factor behind the lack of reproducibility of FC alterations\nin different rs-fMRI studies of PD. While global PD-related functional\nconnectivity changes were non-reproducible across datasets, we identified a few\nindividual brain region pairs with marginally consistent FC changes across all\nthree datasets. However, training classifiers on each one of the 3 datasets to\ndiscriminate PD scans from controls produced only low accuracies on the\nremaining two test datasets. Moreover, classifiers trained and tested on random\nsplits of the same dataset (which are technically homogeneous) also had low\ntest accuracies, directly substantiating disease heterogeneity.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 11:26:22 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 11:30:52 GMT"}, {"version": "v3", "created": "Fri, 1 Sep 2017 13:57:18 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Badea", "Liviu", ""], ["Onu", "Mihaela", ""], ["Wu", "Tao", ""], ["Roceanu", "Adina", ""], ["Bajenaru", "Ovidiu", ""]]}, {"id": "1611.04842", "submitter": "Francesco Fumarola", "authors": "Francesco Fumarola", "title": "The Role of Word Length in Semantic Topology", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A topological argument is presented concering the structure of semantic\nspace, based on the negative correlation between polysemy and word length. The\nresulting graph structure is applied to the modeling of free-recall\nexperiments, resulting in predictions on the comparative values of recall\nprobabilities. Associative recall is found to favor longer words whereas\nsequential recall is found to favor shorter words. Data from the PEERS\nexperiments of Lohnas et al. (2015) and Healey and Kahana (2016) confirm both\npredictons, with correlation coefficients $r_{seq}= -0.17$ and $r_{ass}=\n+0.17$. The argument is then applied to predicting global properties of list\nrecall, which leads to a novel explanation for the word-length effect based on\nthe optimization of retrieval strategies.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 14:12:41 GMT"}], "update_date": "2016-11-16", "authors_parsed": [["Fumarola", "Francesco", ""]]}, {"id": "1611.04872", "submitter": "Emanuela Merelli", "authors": "Marco Piangerelli, Matteo Rucco and Emanuela Merelli", "title": "Topological classifier for detecting the emergence of epileptic seizures", "comments": "Open data: Physionet data-set", "journal-ref": "BMC Res Notes 11, 392, 2018", "doi": "10.1186/s13104-018-3482-7", "report-no": null, "categories": "q-bio.NC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study how to apply topological data analysis to create a\nmethod suitable to classify EEGs of patients affected by epilepsy. The\ntopological space constructed from the collection of EEGs signals is analyzed\nby Persistent Entropy acting as a global topological feature for discriminating\nbetween healthy and epileptic signals. The Physionet data-set has been used for\ntesting the classifier.\n", "versions": [{"version": "v1", "created": "Sat, 12 Nov 2016 10:11:30 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Piangerelli", "Marco", ""], ["Rucco", "Matteo", ""], ["Merelli", "Emanuela", ""]]}, {"id": "1611.05080", "submitter": "Hugo Gabriel Eyherabide Dr", "authors": "Hugo Gabriel Eyherabide", "title": "Neural stochastic codes, encoding and decoding", "comments": "The additional material and some of the theorems have been integrated\n  within the main results of the manuscript, and few typos have been corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT math.IT q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding brain function, constructing computational models and\nengineering neural prosthetics require assessing two problems, namely encoding\nand decoding, but their relation remains controversial. For decades, the\nencoding problem has been shown to provide insight into the decoding problem,\nfor example, by upper bounding the decoded information. However, here we show\nthat this need not be the case when studying response aspects beyond noise\ncorrelations, and trace back the actual causes of this major departure from\ntraditional views. To that end, we reformulate the encoding and decoding\nproblems from the observer or organism perspective. In addition, we study the\nrole of spike-time precision and response discrimination, among other response\naspects, using stochastic transformations of the neural responses, here called\nstochastic codes. Our results show that stochastic codes may cause different\ninformation losses when used to describe neural responses and when employed to\ntrain optimal decoders. Therefore, we conclude that response aspects beyond\nnoise correlations may play different roles in encoding and decoding. In\npractice, our results show for the first time that decoders constructed\nlow-quality descriptions of response aspects may operate optimally on\nhigh-quality descriptions and vice versa, thereby potentially yielding\nexperimental and computational savings, as well as new opportunities for\nsimplifying the design of computational brain models and neural prosthetics.\n", "versions": [{"version": "v1", "created": "Tue, 15 Nov 2016 22:26:50 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2017 11:19:12 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Eyherabide", "Hugo Gabriel", ""]]}, {"id": "1611.05137", "submitter": "Takahiro Ezaki", "authors": "Takahiro Ezaki, Takamitsu Watanabe, Masayuki Ohzeki, Naoki Masuda", "title": "Energy landscape analysis of neuroimaging data", "comments": "22 pages, 4 figures, 1 table", "journal-ref": "Phil. Trans. R. Soc. A 375, 20160287 (2017)", "doi": "10.1098/rsta.2016.0287", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational neuroscience models have been used for understanding neural\ndynamics in the brain and how they may be altered when physiological or other\nconditions change. We review and develop a data-driven approach to neuroimaging\ndata called the energy landscape analysis. The methods are rooted in\nstatistical physics theory, in particular the Ising model, also known as the\n(pairwise) maximum entropy model and Boltzmann machine. The methods have been\napplied to fitting electrophysiological data in neuroscience for a decade, but\ntheir use in neuroimaging data is still in its infancy. We first review the\nmethods and discuss some algorithms and technical aspects. Then, we apply the\nmethods to functional magnetic resonance imaging data recorded from healthy\nindividuals to inspect the relationship between the accuracy of fitting, the\nsize of the brain system to be analyzed, and the data length.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 04:17:12 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 14:01:27 GMT"}], "update_date": "2017-05-26", "authors_parsed": [["Ezaki", "Takahiro", ""], ["Watanabe", "Takamitsu", ""], ["Ohzeki", "Masayuki", ""], ["Masuda", "Naoki", ""]]}, {"id": "1611.05150", "submitter": "Chi Keung Chan", "authors": "Yu-Ting Huang, Yu-Lin Chang, Chun-Chung Chen, Pik-Yin Lai, C. K. Chan", "title": "Positive Feedback and Synchronized Bursts in Neuronal Cultures", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0187276", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronized bursts (SBs) with complex structures are common in neuronal\ncultures. Although the origin of SBs is still unclear, they have been studied\nfor their information processing capabilities. Here, we investigate the\nproperties of these SBs in a culture on multi-electrode array system. We find\nthat structures of these SBs are related to the different developmental stages\nof the cultures. A model based on short term synaptic plasticity, recurrent\nconnections and astrocytic recycling of neurotransmitters has been developed\nsuccessfully to understand these structures. A phase diagram obtained from this\nmodel shows that networks exhibiting SBs are in an oscillatory state due to\nlarge enough positive feedback provided by synaptic facilitation and recurrent\nconnections. In this model, the structures of the SBs are the results of\nintrinsic synaptic interactions; not information stored in the network.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 05:25:35 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Huang", "Yu-Ting", ""], ["Chang", "Yu-Lin", ""], ["Chen", "Chun-Chung", ""], ["Lai", "Pik-Yin", ""], ["Chan", "C. K.", ""]]}, {"id": "1611.05443", "submitter": "Francesco Alderisio", "authors": "Chao Zhai, Michael Z. Q. Chen, Francesco Alderisio, Alexei Yu.\n  Uteshev, Mario di Bernardo", "title": "Bridging the Gap between Individuality and Joint Improvisation in the\n  Mirror Game", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extensive experiments in Human Movement Science suggest that solo motions are\ncharacterized by unique features that define the individuality or motor\nsignature of people. While interacting with others, humans tend to\nspontaneously coordinate their movement and unconsciously give rise to joint\nimprovisation. However, it has yet to be shed light on the relationship between\nindividuality and joint improvisation. By means of an ad-hoc virtual agent, in\nthis work we uncover the internal mechanisms of the transition from solo to\njoint improvised motion in the mirror game, a simple yet effective paradigm for\nstudying interpersonal human coordination. According to the analysis of\nexperimental data, normalized segments of velocity in solo motion are regarded\nas individual motor signature, and the existence of velocity segments\npossessing a prescribed signature is theoretically guaranteed. In this work, we\nfirst develop a systematic approach based on velocity segments to generate\n\\emph{in-silico} trajectories of a given human participant playing solo. Then\nwe present an online algorithm for the virtual player to produce joint\nimprovised motion with another agent while exhibiting some desired kinematic\ncharacteristics, and to account for movement coordination and mutual adaptation\nduring joint action tasks. Finally, we demonstrate that the proposed approach\nsucceeds in revealing the kinematic features transition from solo to joint\nimprovised motions, thus revealing the existence of a tight relationship\nbetween individuality and joint improvisation.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 14:27:12 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Zhai", "Chao", ""], ["Chen", "Michael Z. Q.", ""], ["Alderisio", "Francesco", ""], ["Uteshev", "Alexei Yu.", ""], ["di Bernardo", "Mario", ""]]}, {"id": "1611.05479", "submitter": "Anish Simhal", "authors": "Anish K. Simhal, Cecilia Aguerrebere, Forrest Collman, Joshua T.\n  Vogelstein, Kristina D. Micheva, Richard J. Weinberg, Stephen J. Smith,\n  Guillermo Sapiro", "title": "Probabilistic Fluorescence-Based Synapse Detection", "comments": "Current awaiting peer review", "journal-ref": null, "doi": "10.1371/journal.pcbi.1005493", "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain function results from communication between neurons connected by\ncomplex synaptic networks. Synapses are themselves highly complex and diverse\nsignaling machines, containing protein products of hundreds of different genes,\nsome in hundreds of copies, arranged in precise lattice at each individual\nsynapse. Synapses are fundamental not only to synaptic network function but\nalso to network development, adaptation, and memory. In addition, abnormalities\nof synapse numbers or molecular components are implicated in most mental and\nneurological disorders. Despite their obvious importance, mammalian synapse\npopulations have so far resisted detailed quantitative study. In human brains\nand most animal nervous systems, synapses are very small and very densely\npacked: there are approximately 1 billion synapses per cubic millimeter of\nhuman cortex. This volumetric density poses very substantial challenges to\nproteometric analysis at the critical level of the individual synapse. The\npresent work describes new probabilistic image analysis methods for\nsingle-synapse analysis of synapse populations in both animal and human brains.\n", "versions": [{"version": "v1", "created": "Wed, 16 Nov 2016 22:01:31 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Simhal", "Anish K.", ""], ["Aguerrebere", "Cecilia", ""], ["Collman", "Forrest", ""], ["Vogelstein", "Joshua T.", ""], ["Micheva", "Kristina D.", ""], ["Weinberg", "Richard J.", ""], ["Smith", "Stephen J.", ""], ["Sapiro", "Guillermo", ""]]}, {"id": "1611.05693", "submitter": "Benno M. Blaschke", "authors": "Benno M. Blaschke, N\\'uria Tort-Colet, Anton Guimer\\`a-Brunet, Julia\n  Weinert, Lionel Rousseau, Axel Heimann, Simon Drieschner, Oliver Kempski,\n  Rosa Villa, Maria V. Sanchez-Vives and Jose A. Garrido", "title": "Mapping brain activity with flexible graphene micro-transistors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Establishing a reliable communication interface between the brain and\nelectronic devices is of paramount importance for exploiting the full potential\nof neural prostheses. Current microelectrode technologies for recording\nelectrical activity, however, evidence important shortcomings, e.g. challenging\nhigh density integration. Solution-gated field-effect transistors (SGFETs), on\nthe other hand, could overcome these shortcomings if a suitable transistor\nmaterial were available. Graphene is particularly attractive due to its\nbiocompatibility, chemical stability, flexibility, low intrinsic electronic\nnoise and high charge carrier mobilities. Here, we report on the use of an\narray of flexible graphene SGFETs for recording spontaneous slow waves, as well\nas visually evoked and also pre-epileptic activity in vivo in rats. The\nflexible array of graphene SGFETs allows mapping brain electrical activity with\nexcellent signal-to-noise ratio (SNR), suggesting that this technology could\nlay the foundation for a future generation of in vivo recording implants.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 14:20:04 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Blaschke", "Benno M.", ""], ["Tort-Colet", "N\u00faria", ""], ["Guimer\u00e0-Brunet", "Anton", ""], ["Weinert", "Julia", ""], ["Rousseau", "Lionel", ""], ["Heimann", "Axel", ""], ["Drieschner", "Simon", ""], ["Kempski", "Oliver", ""], ["Villa", "Rosa", ""], ["Sanchez-Vives", "Maria V.", ""], ["Garrido", "Jose A.", ""]]}, {"id": "1611.05834", "submitter": "Matjaz Perc", "authors": "Soumen Majhi, Matjaz Perc, Dibakar Ghosh", "title": "Chimera states in uncoupled neurons induced by a multilayer structure", "comments": "10 two-column pages, 8 figures, supplementary information; accepted\n  for publication in Scientific Reports", "journal-ref": "Sci. Rep. 6 (2016) 39033", "doi": "10.1038/srep39033", "report-no": null, "categories": "nlin.CD physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial coexistence of coherent and incoherent dynamics in network of coupled\noscillators is called a chimera state. We study such chimera states in a\nnetwork of neurons without any direct interactions but connected through\nanother medium of neurons, forming a multilayer structure. The upper layer is\nthus made up of uncoupled neurons and the lower layer plays the role of a\nmedium through which the neurons in the upper layer share information among\neach other. Hindmarsh-Rose neurons with square wave bursting dynamics are\nconsidered as nodes in both layers. In addition, we also discuss the existence\nof chimera states in presence of inter layer heterogeneity. The neurons in the\nbottom layer are globally connected through electrical synapses, while across\nthe two layers chemical synapses are formed. According to our research, the\ncompeting effects of these two types of synapses can lead to chimera states in\nthe upper layer of uncoupled neurons. Remarkably, we find a density-dependent\nthreshold for the emergence of chimera states in uncoupled neurons, similar to\nthe quorum sensing transition to a synchronized state. Finally, we examine the\nimpact of both homogeneous and heterogeneous inter-layer information\ntransmission delays on the observed chimera states over a wide parameter space.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 19:54:20 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Majhi", "Soumen", ""], ["Perc", "Matjaz", ""], ["Ghosh", "Dibakar", ""]]}, {"id": "1611.05918", "submitter": "Sujoy Ganguly", "authors": "Sujoy Ganguly and Olivier Trottier and Xin Liang and Hugo\n  Bowne-Anderson and Jonathon Howard", "title": "Morphology of Fly Larval Class IV Dendrites Accords with a Random\n  Branching and Contact Based Branch Deletion Model", "comments": "12 pages, 4 figures. Supplementary Information: 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dendrites are branched neuronal processes that receive input signals from\nother neurons or the outside world [1]. To maintain connectivity as the\norganism grows, dendrites must also continue to grow. For example, the\ndendrites in the peripheral nervous system continue to grow and branch to\nmaintain proper coverage of their receptor fields [2, 3, 4, 5]. One such neuron\nis the Drosophila melanogaster class IV dendritic arborization neuron [6]. The\ndendritic arbors of these neurons tile the larval surface [7], where they\ndetect localized noxious stimuli, such as jabs from parasitic wasps [8]. In the\npresent study, we used a novel measure, the hitting probability, to show that\nthe class IV neuron forms a tight mesh that covers the larval surface.\nFurthermore, we found that the mesh size remains largely unchanged during the\nlarval stages, despite a dramatic increase in overall size of the neuron and\nthe larva. We also found that the class IV dendrites are dense (assayed with\nthe fractal dimension) and uniform (assayed with the lacunarity) throughout the\nlarval stages. To understand how the class IV neuron maintains its morphology\nduring larval development, we constructed a mathematical model based on random\nbranching and self-avoidance. We found that if the branching rate is uniform in\nspace and time and that if all contacting branches are deleted, we can\nreproduce the branch length distribution, mesh size and density of the class IV\ndendrites throughout the larval stages. Thus, a simple set of statistical rules\ncan generate and maintain a complex branching morphology during growth.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 22:08:20 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Ganguly", "Sujoy", ""], ["Trottier", "Olivier", ""], ["Liang", "Xin", ""], ["Bowne-Anderson", "Hugo", ""], ["Howard", "Jonathon", ""]]}, {"id": "1611.06066", "submitter": "Alexandre Abraham", "authors": "Alexandre Abraham (NEUROSPIN, PARIETAL), Michael Milham (NKI), Adriana\n  Di Martino, R. Cameron Craddock (NKI), Dimitris Samaras (SUNY), Bertrand\n  Thirion (PARIETAL, NEUROSPIN), Ga\\\"el Varoquaux (PARIETAL, NEUROSPIN)", "title": "Deriving reproducible biomarkers from multi-site resting-state data: An\n  Autism-based example", "comments": "in NeuroImage, Elsevier, 2016", "journal-ref": null, "doi": "10.1016/j.neuroimage.2016.10.045", "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resting-state functional Magnetic Resonance Imaging (R-fMRI) holds the\npromise to reveal functional biomarkers of neuropsychiatric disorders. However,\nextracting such biomarkers is challenging for complex multi-faceted\nneuropatholo-gies, such as autism spectrum disorders. Large multi-site datasets\nincrease sample sizes to compensate for this complexity, at the cost of\nuncontrolled heterogeneity. This heterogeneity raises new challenges, akin to\nthose face in realistic diagnostic applications. Here, we demonstrate the\nfeasibility of inter-site classification of neuropsychiatric status, with an\napplication to the Autism Brain Imaging Data Exchange (ABIDE) database, a large\n(N=871) multi-site autism dataset. For this purpose, we investigate pipelines\nthat extract the most predictive biomarkers from the data. These R-fMRI\npipelines build participant-specific connectomes from functionally-defined\nbrain areas. Connectomes are then compared across participants to learn\npatterns of connectivity that differentiate typical controls from individuals\nwith autism. We predict this neuropsychiatric status for participants from the\nsame acquisition sites or different, unseen, ones. Good choices of methods for\nthe various steps of the pipeline lead to 67% prediction accuracy on the full\nABIDE data, which is significantly better than previously reported results. We\nperform extensive validation on multiple subsets of the data defined by\ndifferent inclusion criteria. These enables detailed analysis of the factors\ncontributing to successful connectome-based prediction. First, prediction\naccuracy improves as we include more subjects, up to the maximum amount of\nsubjects available. Second, the definition of functional brain areas is of\nparamount importance for biomarker discovery: brain areas extracted from large\nR-fMRI datasets outperform reference atlases in the classification tasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 13:31:47 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Abraham", "Alexandre", "", "NEUROSPIN, PARIETAL"], ["Milham", "Michael", "", "NKI"], ["Di Martino", "Adriana", "", "NKI"], ["Craddock", "R. Cameron", "", "NKI"], ["Samaras", "Dimitris", "", "SUNY"], ["Thirion", "Bertrand", "", "PARIETAL, NEUROSPIN"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL, NEUROSPIN"]]}, {"id": "1611.06197", "submitter": "Daniel Moyer", "authors": "Daniel Moyer, Boris A. Gutman, Joshua Faskowitz, Neda Jahanshad, Paul\n  M. Thompson", "title": "An Empirical Study of Continuous Connectivity Degree Sequence\n  Equivalents", "comments": "Presented at The MICCAI-BACON 16 Workshop\n  (https://arxiv.org/abs/1611.03363)", "journal-ref": null, "doi": null, "report-no": "BACON/2016/04", "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work we demonstrate the use of a parcellation free\nconnectivity model based on Poisson point processes. This model produces for\neach subject a continuous bivariate intensity function that represents for\nevery possible pair of points the relative rate at which we observe tracts\nterminating at those points. We fit this model to explore degree sequence\nequivalents for spatial continuum graphs, and to investigate the local\ndifferences between estimated intensity functions for two different\ntractography methods. This is a companion paper to Moyer et al. (2016), where\nthe model was originally defined.\n", "versions": [{"version": "v1", "created": "Fri, 18 Nov 2016 18:53:45 GMT"}], "update_date": "2016-11-21", "authors_parsed": [["Moyer", "Daniel", ""], ["Gutman", "Boris A.", ""], ["Faskowitz", "Joshua", ""], ["Jahanshad", "Neda", ""], ["Thompson", "Paul M.", ""]]}, {"id": "1611.06831", "submitter": "Miguel Aguilera", "authors": "Miguel Aguilera", "title": "Rhythms of the collective brain: Metastable synchronization and\n  cross-scale interactions in connected multitudes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SI nlin.AO q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Crowd behaviour challenges our fundamental understanding of social phenomena.\nInvolving complex interactions between multiple temporal and spatial scales of\nactivity, its governing mechanisms defy conventional analysis. Using 1.5\nmillion Twitter messages from the 15M movement in Spain as an example of\nmultitudinous self-organization, we describe the coordination dynamics of the\nsystem measuring phase-locking statistics at different frequencies using\nwavelet transforms, identifying 8 frequency bands of entrained oscillations\nbetween 15 geographical nodes. Then we apply maximum entropy inference methods\nto describe Ising models capturing transient synchrony in our data at each\nfrequency band. The models show that 1) all frequency bands of the system\noperate near critical points of their parameter space and 2) while fast\nfrequencies present only a few metastable states displaying all-or-none\nsynchronization, slow frequencies present a diversity of metastable states of\npartial synchronization. Furthermore, describing the state at each frequency\nband using the energy of the corresponding Ising model, we compute transfer\nentropy to characterize cross-scale interactions between frequency bands,\nshowing 1) a cascade of upward information flows in which each frequency band\ninfluences its contiguous slower bands and 2) downward information flows where\nslow frequencies modulate distant fast frequencies.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 15:25:02 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 13:11:39 GMT"}, {"version": "v3", "created": "Wed, 17 Jan 2018 17:45:51 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Aguilera", "Miguel", ""]]}, {"id": "1611.06834", "submitter": "Laurent Perrinet", "authors": "Cesar Ravello (CINV), Maria-Jose Escobar, Adrian Palacios (CINV),\n  Laurent Perrinet (INT)", "title": "Differential response of the retinal neural code with respect to the\n  sparseness of natural images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural images follow statistics inherited by the structure of our physical\n(visual) environment. In particular, a prominent facet of this structure is\nthat images can be described by a relatively sparse number of features. To\ninvestigate the role of this sparseness in the efficiency of the neural code,\nwe designed a new class of random textured stimuli with a controlled sparseness\nvalue inspired by measurements of natural images. Then, we tested the impact of\nthis sparseness parameter on the firing pattern observed in a population of\nretinal ganglion cells recorded ex vivo in the retina of a rodent, the Octodon\ndegus. These recordings showed in particular that the reliability of spike\ntimings varies with respect to the sparseness with globally a similar trend\nthan the distribution of sparseness statistics observed in natural images.\nThese results suggest that the code represented in the spike pattern of\nganglion cells may adapt to this aspect of the statistics of natural images.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 15:28:16 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Ravello", "Cesar", "", "CINV"], ["Escobar", "Maria-Jose", "", "CINV"], ["Palacios", "Adrian", "", "CINV"], ["Perrinet", "Laurent", "", "INT"]]}, {"id": "1611.06893", "submitter": "Catalina Obando", "authors": "Catalina Obando, Fabrizio De Vico Fallani", "title": "A statistical model for brain networks inferred from large-scale\n  electrophysiological signals", "comments": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract appearing here is slightly shorter than that in the\n  PDF file", "journal-ref": null, "doi": "10.1098/rsif.2016.0940", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network science has been extensively developed to characterize structural\nproperties of complex systems, including brain networks inferred from\nneuroimaging data. As a result of the inference process, networks estimated\nfrom experimentally obtained biological data, represent one instance of a\nlarger number of realizations with similar intrinsic topology. A modeling\napproach is therefore needed to support statistical inference on the bottom-up\nlocal connectivity mechanisms influencing the formation of the estimated brain\nnetworks. We adopted a statistical model based on exponential random graphs\n(ERGM) to reproduce brain networks, or connectomes, estimated by spectral\ncoherence between high-density electroencephalographic (EEG) signals. We\nvalidated this approach in a dataset of 108 healthy subjects during eyes-open\n(EO) and eyes-closed (EC) resting-state conditions. Results showed that the\ntendency to form triangles and stars, reflecting clustering and node\ncentrality, better explained the global properties of the EEG connectomes as\ncompared to other combinations of graph metrics. Synthetic networks generated\nby this model configuration replicated the characteristic differences found in\nbrain networks, with EO eliciting significantly higher segregation in the alpha\nfrequency band (8-13 Hz) as compared to EC. Furthermore, the fitted ERGM\nparameter values provided complementary information showing that clustering\nconnections are significantly more represented from EC to EO in the alpha\nrange, but also in the beta band (14-29 Hz), which is known to play a crucial\nrole in cortical processing of visual input and externally oriented attention.\nThese findings support the current view of the brain functional segregation and\nintegration in terms of modules and hubs, and provide a statistical approach to\nextract new information on the (re)organizational mechanisms in healthy and\ndiseased brains.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 16:38:06 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 17:11:38 GMT"}, {"version": "v3", "created": "Wed, 23 Nov 2016 20:29:02 GMT"}, {"version": "v4", "created": "Fri, 17 Feb 2017 16:49:14 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Obando", "Catalina", ""], ["Fallani", "Fabrizio De Vico", ""]]}, {"id": "1611.06937", "submitter": "Jonathan Suen", "authors": "Jonathan Y. Suen and Saket Navlakha", "title": "Using inspiration from synaptic plasticity rules to optimize traffic\n  flow in distributed engineered networks", "comments": "43 pages, 5 Figures. Submitted to Neural Computation", "journal-ref": "Neural Comput. 29(5) (2017) 1204-1228", "doi": "10.1162/NECO_a_00945", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Controlling the flow and routing of data is a fundamental problem in many\ndistributed networks, including transportation systems, integrated circuits,\nand the Internet. In the brain, synaptic plasticity rules have been discovered\nthat regulate network activity in response to environmental inputs, which\nenable circuits to be stable yet flexible. Here, we develop a new\nneuro-inspired model for network flow control that only depends on modifying\nedge weights in an activity-dependent manner. We show how two fundamental\nplasticity rules (long-term potentiation and long-term depression) can be cast\nas a distributed gradient descent algorithm for regulating traffic flow in\nengineered networks. We then characterize, both via simulation and\nanalytically, how different forms of edge-weight update rules affect network\nrouting efficiency and robustness. We find a close correspondence between\ncertain classes of synaptic weight update rules derived experimentally in the\nbrain and rules commonly used in engineering, suggesting common principles to\nboth.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 18:38:17 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Suen", "Jonathan Y.", ""], ["Navlakha", "Saket", ""]]}, {"id": "1611.06973", "submitter": "Seymour Knowles-Barley", "authors": "Seymour Knowles-Barley, Verena Kaynig, Thouis Ray Jones, Alyssa\n  Wilson, Joshua Morgan, Dongil Lee, Daniel Berger, Narayanan Kasthuri, Jeff W.\n  Lichtman, Hanspeter Pfister", "title": "RhoanaNet Pipeline: Dense Automatic Neural Annotation", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing a synaptic wiring diagram, or connectome, from electron\nmicroscopy (EM) images of brain tissue currently requires many hours of manual\nannotation or proofreading (Kasthuri and Lichtman, 2010; Lichtman and Sanes,\n2008; Seung, 2009). The desire to reconstruct ever larger and more complex\nnetworks has pushed the collection of ever larger EM datasets. A cubic\nmillimeter of raw imaging data would take up 1 PB of storage and present an\nannotation project that would be impractical without relying heavily on\nautomatic segmentation methods. The RhoanaNet image processing pipeline was\ndeveloped to automatically segment large volumes of EM data and ease the burden\nof manual proofreading and annotation. Based on (Kaynig et al., 2015), we\nupdated every stage of the software pipeline to provide better throughput\nperformance and higher quality segmentation results. We used state of the art\ndeep learning techniques to generate improved membrane probability maps, and\nGala (Nunez-Iglesias et al., 2014) was used to agglomerate 2D segments into 3D\nobjects.\n  We applied the RhoanaNet pipeline to four densely annotated EM datasets, two\nfrom mouse cortex, one from cerebellum and one from mouse lateral geniculate\nnucleus (LGN). All training and test data is made available for benchmark\ncomparisons. The best segmentation results obtained gave\n$V^\\text{Info}_\\text{F-score}$ scores of 0.9054 and 09182 for the cortex\ndatasets, 0.9438 for LGN, and 0.9150 for Cerebellum.\n  The RhoanaNet pipeline is open source software. All source code, training\ndata, test data, and annotations for all four benchmark datasets are available\nat www.rhoana.org.\n", "versions": [{"version": "v1", "created": "Mon, 21 Nov 2016 19:48:29 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Knowles-Barley", "Seymour", ""], ["Kaynig", "Verena", ""], ["Jones", "Thouis Ray", ""], ["Wilson", "Alyssa", ""], ["Morgan", "Joshua", ""], ["Lee", "Dongil", ""], ["Berger", "Daniel", ""], ["Kasthuri", "Narayanan", ""], ["Lichtman", "Jeff W.", ""], ["Pfister", "Hanspeter", ""]]}, {"id": "1611.07218", "submitter": "Harish Katti", "authors": "Harish Katti, Marius V. Peelen, S. P. Arun", "title": "Deep neural networks can be improved using human-derived contextual\n  expectations", "comments": "30 pages, 5 figures, 3 tables, 2 supplementary tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world objects occur in specific contexts. Such context has been shown to\nfacilitate detection by constraining the locations to search. But can context\ndirectly benefit object detection? To do so, context needs to be learned\nindependently from target features. This is impossible in traditional object\ndetection where classifiers are trained on images containing both target\nfeatures and surrounding context. In contrast, humans can learn context and\ntarget features separately, such as when we see highways without cars. Here we\nshow for the first time that human-derived scene expectations can be used to\nimprove object detection performance in machines. To measure contextual\nexpectations, we asked human subjects to indicate the scale, location and\nlikelihood at which cars or people might occur in scenes without these objects.\nHumans showed highly systematic expectations that we could accurately predict\nusing scene features. This allowed us to predict human expectations on novel\nscenes without requiring manual annotation. On augmenting deep neural networks\nwith predicted human expectations, we obtained substantial gains in accuracy\nfor detecting cars and people (1-3%) as well as on detecting associated objects\n(3-20%). In contrast, augmenting deep networks with other conventional features\nyielded far smaller gains. This improvement was due to relatively poor matches\nat highly likely locations being correctly labelled as target and conversely\nstrong matches at unlikely locations being correctly rejected as false alarms.\nTaken together, our results show that augmenting deep neural networks with\nhuman-derived context features improves their performance, suggesting that\nhumans learn scene context separately unlike deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 09:45:01 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 09:17:23 GMT"}, {"version": "v3", "created": "Sun, 15 Oct 2017 06:33:50 GMT"}, {"version": "v4", "created": "Thu, 29 Mar 2018 00:59:25 GMT"}], "update_date": "2018-03-30", "authors_parsed": [["Katti", "Harish", ""], ["Peelen", "Marius V.", ""], ["Arun", "S. P.", ""]]}, {"id": "1611.07272", "submitter": "Ines Samengo", "authors": "Maria da Fonseca and Ines Samengo", "title": "Derivation of human chromatic discrimination ability from an\n  information-theoretical notion of distance in color space", "comments": "23 pages, 10 figures", "journal-ref": "Neural Computation doi:10.1162/NECO_a_00903 pp 1-18 (2016)", "doi": "10.1162/NECO_a_00903", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accuracy with which humans can detect small chromatic differences varies\nthroughout color space. For example, we are far more precise when\ndiscriminating two similar orange stimuli than two similar green stimuli. In\norder for two colors to be perceived as different, the neurons representing\nchromatic information must respond differently, and the difference must be\nlarger than the trial-to-trial variability of the response to each separate\ncolor. Photoreceptors constitute the first stage in the processing of color\ninformation; many more stages are required before humans can consciously report\nwhether two stimuli are perceived as chromatically distinguishable or not.\nTherefore, although photoreceptor absorption curves are expected to influence\nthe accuracy of conscious discriminability, there is no reason to believe that\nthey should suffice to explain it. Here we develop information-theoretical\ntools based on the Fisher metric that demonstrate that photoreceptor absorption\nproperties explain ~87% of the variance of human color discrimination ability,\nas tested by previous behavioral experiments. In the context of this theory,\nthe bottleneck in chromatic information processing is determined by\nphotoreceptor absorption characteristics. Subsequent encoding stages modify\nonly marginally the chromatic discriminability at the photoreceptor level.\n", "versions": [{"version": "v1", "created": "Tue, 22 Nov 2016 12:27:04 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["da Fonseca", "Maria", ""], ["Samengo", "Ines", ""]]}, {"id": "1611.07677", "submitter": "Claus Metzner", "authors": "Patrick Krauss, Claus Metzner, Achim Schilling, Konstantin Tziridis,\n  Maximilian Traxdorf and Holger Schulze", "title": "A statistical method for analyzing and comparing spatiotemporal cortical\n  activation patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new statistical method to analyze multichannel steady-state\nlocal field potentials (LFP) recorded within different sensory cortices of\ndifferent rodent species. Our spatiotemporal multi-dimensional cluster\nstatistics (MCS) method enables statistical analyzing and comparing clusters of\ndata points in n-dimensional space. We demonstrate that using this approach\nstimulus-specific attractor-like spatiotemporal activity patterns can be\ndetected and be significantly different from each other during stimulation with\nlong-lasting stimuli. Our method may be applied to other types of multichannel\nneuronal data, like EEG, MEG or spiking responses and used for the development\nof new read-out algorithms of brain activity and by that opens new perspectives\nfor the development of brain-computer interfaces.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 08:08:17 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Krauss", "Patrick", ""], ["Metzner", "Claus", ""], ["Schilling", "Achim", ""], ["Tziridis", "Konstantin", ""], ["Traxdorf", "Maximilian", ""], ["Schulze", "Holger", ""]]}, {"id": "1611.07831", "submitter": "Laurent Perrinet", "authors": "Anna Montagnini (INT), Laurent Perrinet (INT), Guillaume S Masson\n  (INT)", "title": "Visual motion processing and human tracking behavior", "comments": null, "journal-ref": "Biologically Inspired Computer Vision, 2015, 9783527680863", "doi": "10.1002/9783527680863.ch12", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate visual tracking of a moving object is a human fundamental skill\nthat allows to reduce the relative slip and instability of the object's image\non the retina, thus granting a stable, high-quality vision. In order to\noptimize tracking performance across time, a quick estimate of the object's\nglobal motion properties needs to be fed to the oculomotor system and\ndynamically updated. Concurrently, performance can be greatly improved in terms\nof latency and accuracy by taking into account predictive cues, especially\nunder variable conditions of visibility and in presence of ambiguous retinal\ninformation. Here, we review several recent studies focusing on the integration\nof retinal and extra-retinal information for the control of human smooth\npursuit.By dynamically probing the tracking performance with well established\nparadigms in the visual perception and oculomotor literature we provide the\nbasis to test theoretical hypotheses within the framework of dynamic\nprobabilistic inference. We will in particular present the applications of\nthese results in light of state-of-the-art computer vision algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 15:11:12 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Montagnini", "Anna", "", "INT"], ["Perrinet", "Laurent", "", "INT"], ["Masson", "Guillaume S", "", "INT"]]}, {"id": "1611.07962", "submitter": "Andrew Murphy", "authors": "Andrew C. Murphy, Shi Gu, Ankit N. Khambhati, Nicholas F. Wymbs, Scott\n  T. Grafton, Theodore D. Satterthwaite, and Danielle S. Bassett", "title": "Explicitly Linking Regional Activation and Function Connectivity:\n  Community Structure of Weighted Networks with Continuous Annotation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge in neuroimaging is understanding the mapping of\nneurophysiological dynamics onto cognitive functions. Traditionally, these maps\nhave been constructed by examining changes in the activity magnitude of regions\nrelated to task performance. Recently, network neuroscience has produced\nmethods to map connectivity patterns among many regions to certain cognitive\nfunctions by drawing on tools from network science and graph theory. However,\nthese two different views are rarely addressed simultaneously, largely because\nfew tools exist that account for patterns between nodes while simultaneously\nconsidering activation of nodes. We address this gap by solving the problem of\ncommunity detection on weighted networks with continuous (non-integer)\nannotations by deriving a generative probabilistic model. This model generates\ncommunities whose members connect densely to nodes within their own community,\nand whose members share similar annotation values. We demonstrate the utility\nof the model in the context of neuroimaging data gathered during a motor\nlearning paradigm, where edges are task-based functional connectivity and\nannotations to each node are beta weights from a general linear model that\nencoded a linear decrease in blood-oxygen-level-dependent signal with practice.\nInterestingly, we observe that individuals who learn at a faster rate exhibit\nthe greatest dissimilarity between functional connectivity and activation\nmagnitudes, suggesting that activation and functional connectivity are distinct\ndimensions of neurophysiology that track behavioral change. More generally, the\ntool that we develop offers an explicit, mathematically principled link between\nfunctional activation and functional connectivity, and can readily be applied\nto a other similar problems in which one set of imaging data offers network\ndata, and a second offers a regional attribute.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 20:13:47 GMT"}], "update_date": "2016-11-24", "authors_parsed": [["Murphy", "Andrew C.", ""], ["Gu", "Shi", ""], ["Khambhati", "Ankit N.", ""], ["Wymbs", "Nicholas F.", ""], ["Grafton", "Scott T.", ""], ["Satterthwaite", "Theodore D.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1611.07999", "submitter": "Moritz Augustin", "authors": "Moritz Augustin, Josef Ladenbauer, Fabian Baumann, Klaus Obermayer", "title": "Low-dimensional spike rate models derived from networks of adaptive\n  integrate-and-fire neurons: Comparison and implementation", "comments": "concatenation of main text (including 8 figures), supplementary\n  methods text and supporting figure", "journal-ref": "PLOS Comput Biol 13, e1005545 (2017)", "doi": "10.1371/journal.pcbi.1005545", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spiking activity of single neurons can be well described by a nonlinear\nintegrate-and-fire model that includes somatic adaptation. When exposed to\nfluctuating inputs sparsely coupled populations of these model neurons exhibit\nstochastic collective dynamics that can be effectively characterized using the\nFokker-Planck equation. [...] Here we derive from that description four simple\nmodels for the spike rate dynamics in terms of low-dimensional ordinary\ndifferential equations using two different reduction techniques: one uses the\nspectral decomposition of the Fokker-Planck operator, the other is based on a\ncascade of two linear filters and a nonlinearity, which are determined from the\nFokker-Planck equation and semi-analytically approximated. We evaluate the\nreduced models for a wide range of biologically plausible input statistics and\nfind that both approximation approaches lead to spike rate models that\naccurately reproduce the spiking behavior of the underlying adaptive\nintegrate-and-fire population. [...] The low-dimensional models also well\nreproduce stable oscillatory spike rate dynamics that is generated by recurrent\nsynaptic excitation and neuronal adaptation. [...] We have made available\nimplementations that allow to numerically integrate the low-dimensional spike\nrate models as well as the Fokker-Planck partial differential equation in\nefficient ways for arbitrary model parametrizations as open source software.\nThe derived spike rate descriptions retain a direct link to the properties of\nsingle neurons, allow for convenient mathematical analyses of network states,\nand are well suited for application in neural mass/mean-field based brain\nnetwork models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 21:17:07 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 14:21:20 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Augustin", "Moritz", ""], ["Ladenbauer", "Josef", ""], ["Baumann", "Fabian", ""], ["Obermayer", "Klaus", ""]]}, {"id": "1611.08024", "submitter": "Vernon Lawhern", "authors": "Vernon J. Lawhern, Amelia J. Solon, Nicholas R. Waytowich, Stephen M.\n  Gordon, Chou P. Hung, Brent J. Lance", "title": "EEGNet: A Compact Convolutional Network for EEG-based Brain-Computer\n  Interfaces", "comments": "30 pages, 10 figures. Added additional feature relevance analyses.\n  Minor change to EEGNet architecture. Source code can be found at\n  https://github.com/vlawhern/arl-eegmodels", "journal-ref": null, "doi": "10.1088/1741-2552/aace8c", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain computer interfaces (BCI) enable direct communication with a computer,\nusing neural activity as the control signal. This neural signal is generally\nchosen from a variety of well-studied electroencephalogram (EEG) signals. For a\ngiven BCI paradigm, feature extractors and classifiers are tailored to the\ndistinct characteristics of its expected EEG control signal, limiting its\napplication to that specific signal. Convolutional Neural Networks (CNNs),\nwhich have been used in computer vision and speech recognition, have\nsuccessfully been applied to EEG-based BCIs; however, they have mainly been\napplied to single BCI paradigms and thus it remains unclear how these\narchitectures generalize to other paradigms. Here, we ask if we can design a\nsingle CNN architecture to accurately classify EEG signals from different BCI\nparadigms, while simultaneously being as compact as possible. In this work we\nintroduce EEGNet, a compact convolutional network for EEG-based BCIs. We\nintroduce the use of depthwise and separable convolutions to construct an\nEEG-specific model which encapsulates well-known EEG feature extraction\nconcepts for BCI. We compare EEGNet to current state-of-the-art approaches\nacross four BCI paradigms: P300 visual-evoked potentials, error-related\nnegativity responses (ERN), movement-related cortical potentials (MRCP), and\nsensory motor rhythms (SMR). We show that EEGNet generalizes across paradigms\nbetter than the reference algorithms when only limited training data is\navailable. We demonstrate three different approaches to visualize the contents\nof a trained EEGNet model to enable interpretation of the learned features. Our\nresults suggest that EEGNet is robust enough to learn a wide variety of\ninterpretable features over a range of BCI tasks, suggesting that the observed\nperformances were not due to artifact or noise sources in the data.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 22:36:58 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 16:03:13 GMT"}, {"version": "v3", "created": "Fri, 9 Mar 2018 01:02:21 GMT"}, {"version": "v4", "created": "Wed, 16 May 2018 01:14:34 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Lawhern", "Vernon J.", ""], ["Solon", "Amelia J.", ""], ["Waytowich", "Nicholas R.", ""], ["Gordon", "Stephen M.", ""], ["Hung", "Chou P.", ""], ["Lance", "Brent J.", ""]]}, {"id": "1611.08310", "submitter": "Jiaying Zhang Jiaying Zhang", "authors": "Xuehai Wu, Jiaying Zhang, Zaixu Cui, Weijun Tang, Chunhong Shao, Jin\n  Hu, Jianhong Zhu, Liangfu Zhou, Yao Zhao, Lu Lu, Gang Chen, Georg Northoff,\n  Gaolang Gong, Ying Mao, Yong He", "title": "White matter deficits underlie the loss of consciousness level and\n  predict recovery outcome in disorders of consciousness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study aimed to identify white matter (WM) deficits underlying the loss\nof consciousness in disorder of consciousness (DOC) patients using Diffusion\nTensor Imaging (DTI) and to demonstrate the potential value of DTI parameters\nin predicting recovery outcomes of DOC patients. With 30 DOC patients (8\ncomatose, 8 unresponsive wakefulness syndrome/vegetative state, and 14 minimal\nconscious state) and 25 patient controls, we performed group comparison of DTI\nparameters across 48 core WM regions of interest (ROIs) using Analysis of\nCovariance. Compared with controls, DOC patients had decreased Fractional\nanisotropy (FA) and increased diffusivities in widespread WM area.The\ncorresponding DTI parameters of those WM deficits in DOC patients significantly\ncorrelated with the consciousness level evaluated by Coma Recovery Scale\nRevised (CRS-R) and Glasgow Coma Scale (GCS). As for predicting the recovery\noutcomes (i.e., regaining consciousness or not, grouped by their Glasgow\nOutcome Scale more than 2 or not) at 3 months post scan, radial diffusivity of\nleft superior cerebellar peduncle and FA of right sagittal stratum reached an\naccuracy of 87.5% and 75% respectively. Our findings showed multiple WM\ndeficits underlying the loss of consciousness level, and demonstrated the\npotential value of these WM areas in predicting the recovery outcomes of DOC\npatients who have lost awareness of the environment and themselves.\n", "versions": [{"version": "v1", "created": "Thu, 24 Nov 2016 21:09:55 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Wu", "Xuehai", ""], ["Zhang", "Jiaying", ""], ["Cui", "Zaixu", ""], ["Tang", "Weijun", ""], ["Shao", "Chunhong", ""], ["Hu", "Jin", ""], ["Zhu", "Jianhong", ""], ["Zhou", "Liangfu", ""], ["Zhao", "Yao", ""], ["Lu", "Lu", ""], ["Chen", "Gang", ""], ["Northoff", "Georg", ""], ["Gong", "Gaolang", ""], ["Mao", "Ying", ""], ["He", "Yong", ""]]}, {"id": "1611.08699", "submitter": "Colin Brown J", "authors": "Colin J Brown, Ghassan Hamarneh", "title": "Machine Learning on Human Connectome Data from MRI", "comments": "51 pages, 6 figures. To be submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional MRI (fMRI) and diffusion MRI (dMRI) are non-invasive imaging\nmodalities that allow in-vivo analysis of a patient's brain network (known as a\nconnectome). Use of these technologies has enabled faster and better diagnoses\nand treatments of neurological disorders and a deeper understanding of the\nhuman brain. Recently, researchers have been exploring the application of\nmachine learning models to connectome data in order to predict clinical\noutcomes and analyze the importance of subnetworks in the brain. Connectome\ndata has unique properties, which present both special challenges and\nopportunities when used for machine learning. The purpose of this work is to\nreview the literature on the topic of applying machine learning models to\nMRI-based connectome data. This field is growing rapidly and now encompasses a\nlarge body of research. To summarize the research done to date, we provide a\ncomparative, structured summary of 77 relevant works, tabulated according to\ndifferent criteria, that represent the majority of the literature on this\ntopic. (We also published a living version of this table online at\nhttp://connectomelearning.cs.sfu.ca that the community can continue to\ncontribute to.) After giving an overview of how connectomes are constructed\nfrom dMRI and fMRI data, we discuss the variety of machine learning tasks that\nhave been explored with connectome data. We then compare the advantages and\ndrawbacks of different machine learning approaches that have been employed,\ndiscussing different feature selection and feature extraction schemes, as well\nas the learning models and regularization penalties themselves. Throughout this\ndiscussion, we focus particularly on how the methods are adapted to the unique\nnature of graphical connectome data. Finally, we conclude by summarizing the\ncurrent state of the art and by outlining what we believe are strategic\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 11:14:22 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Brown", "Colin J", ""], ["Hamarneh", "Ghassan", ""]]}, {"id": "1611.08751", "submitter": "John Medaglia", "authors": "John D. Medaglia, Weiyu Huang, Elisabeth A. Karuza, Sharon L.\n  Thompson-Schill, Alejandro Ribeiro, Danielle S. Bassett", "title": "Functional Alignment with Anatomical Networks is Associated with\n  Cognitive Flexibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive flexibility describes the human ability to switch between modes of\nmental function to achieve goals. Mental switching is accompanied by transient\nchanges in brain activity, which must occur atop an anatomical architecture\nthat bridges disparate cortical and subcortical regions by underlying white\nmatter tracts. However, an integrated perspective regarding how white matter\nnetworks might constrain brain dynamics during cognitive processes requiring\nflexibility has remained elusive. To address this challenge, we applied\nemerging tools from graph signal processing to decompose BOLD signals based on\ndiffusion imaging tractography in 28 individuals performing a perceptual task\nthat probed cognitive flexibility. We found that the alignment between\nfunctional signals and the architecture of the underlying white matter network\nwas associated with greater cognitive flexibility across subjects. Signals with\nbehaviorally-relevant alignment were concentrated in the basal ganglia and\nanterior cingulate cortex, consistent with cortico-striatal mechanisms of\ncognitive flexibility. Importantly, these findings are not accessible to\nunimodal analyses of functional or anatomical neuroimaging alone. Instead, by\ntaking a generalizable and concise reduction of multimodal neuroimaging data,\nwe uncover an integrated structure-function driver of human behavior.\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 22:24:29 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Medaglia", "John D.", ""], ["Huang", "Weiyu", ""], ["Karuza", "Elisabeth A.", ""], ["Thompson-Schill", "Sharon L.", ""], ["Ribeiro", "Alejandro", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1611.08844", "submitter": "Benedetta Franceschiello Dr.", "authors": "B. Franceschiello, A. Sarti, G. Citti", "title": "A neuro-mathematical model for geometrical optical illusions", "comments": "13 pages, 38 figures divided in 15 groups", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometrical optical illusions have been object of many studies due to the\npossibility they offer to understand the behaviour of low-level visual\nprocessing. They consist in situations in which the perceived geometrical\nproperties of an object differ from those of the object in the visual stimulus.\nStarting from the geometrical model introduced by Citti and Sarti in [3], we\nprovide a mathematical model and a computational algorithm which allows to\ninterpret these phenomena and to qualitatively reproduce the perceived\nmisperception.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 13:52:24 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Franceschiello", "B.", ""], ["Sarti", "A.", ""], ["Citti", "G.", ""]]}, {"id": "1611.08913", "submitter": "Nadav Amir", "authors": "Nadav Amir, Israel Nelken, Naftali Tishby", "title": "A Simple Model of Attentional Blink", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The attentional blink (AB) effect is the reduced ability of subjects to\nreport a second target stimuli (T2) among a rapidly presented series of\nnon-target stimuli, when it appears within a time window of about 200-500 ms\nafter a first target (T1). We present a simple dynamical systems model\nexplaining the AB as resulting from the temporal response dynamics of a\nstochastic, linear system with threshold, whose output represents the amount of\nattentional resources allocated to the incoming sensory stimuli. The model\npostulates that the available attention capacity is limited by activity of the\ndefault mode network (DMN), a correlated set of brain regions related to task\nirrelevant processing which is known to exhibit reduced activation following\nmental training such as mindfulness meditation. The model provides a\nparsimonious account relating key findings from the AB, DMN and meditation\nresearch literature, and suggests some new testable predictions.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 21:08:26 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 13:40:49 GMT"}], "update_date": "2017-09-28", "authors_parsed": [["Amir", "Nadav", ""], ["Nelken", "Israel", ""], ["Tishby", "Naftali", ""]]}, {"id": "1611.08928", "submitter": "Francesco Fumarola", "authors": "Francesco Fumarola", "title": "A theory of interpretive clustering in free recall", "comments": "24 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A stochastic model of short-term verbal memory is proposed, in which the\npsychological state of the subject is encoded as the instantaneous position of\na particle diffusing over a semantic graph with a probabilistic structure. The\nmodel is particularly suitable for studying the dependence of free-recall\nobservables on semantic properties of the words to be recalled. Besides\npredicting some well-known experimental features (contiguity effect, forward\nasymmetry, word-length effect), a novel prediction is obtained on the\nrelationship between the contiguity effect and the syllabic length of words;\nshorter words, by way of their wider semantic range, are predicted to be\ncharacterized by stronger forward contiguity. A fresh analysis of archival data\nallows to confirm this prediction.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 22:42:13 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 17:15:23 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Fumarola", "Francesco", ""]]}, {"id": "1611.08929", "submitter": "Md Jahoor Alam", "authors": "Md. Jahoor Alam", "title": "GnRH induced Phase Synchrony of Coupled Neurons", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gonadotropin-releasing hormone (GnRH) is reported to control mammalian\nreproductive processes. GnRH a neurohormone which is pulsatile released into\nthe pituitary portal blood by hypothalamic GnRH neurons. In the present study,\nthe phase synchronization among a population of identical neurons subjected to\na pool of coupling molecules GnRH in extracellular medium via mean-field\ncoupling mechanism is investigated. In the model of populated neurons, GnRH is\nconsidered to be autocrine signaling molecule and is taken to be common to all\nneurons to act as synchronizing agent. The rate of synchrony is estimated\nqualitatively and quantitatively by measuring phase locking values, time\nevolution of the phase differences and recurrence plots. Our numerical results\nshow a phase transition like behavior separating the synchronized and\ndesynchronized regimes. We also investigated long range communication or relay\ninformation transfer for one dimensional array of such neurons.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 22:43:24 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Alam", "Md. Jahoor", ""]]}, {"id": "1611.09024", "submitter": "Sang-Yoon  Kim", "authors": "Sang-Yoon Kim and Woochang Lim", "title": "Dynamical Responses to External Stimuli for Both Cases of Excitatory and\n  Inhibitory Synchronization in A Complex Neuronal Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For studying how dynamical responses to external stimuli depend on the\nsynaptic-coupling type, we consider two types of excitatory and inhibitory\nsynchronization (i.e., synchronization via synaptic excitation and inhibition)\nin complex small-world networks of excitatory regular spiking (RS) pyramidal\nneurons and inhibitory fast spiking (FS) interneurons. For both cases of\nexcitatory and inhibitory synchronization, effects of synaptic couplings on\ndynamical responses to external time-periodic stimuli $S(t)$ (applied to a\nfraction of neurons) are investigated by varying the driving amplitude $A$ of\n$S(t)$. Stimulated neurons are phase-locked to external stimuli for both cases\nof excitatory and inhibitory couplings. On the other hand, the stimulation\neffect on non-stimulated neurons depends on the type of synaptic coupling. The\nexternal stimulus $S(t)$ makes a constructive effect on excitatory\nnon-stimulated RS neurons (i.e., it causes external phase lockings in the\nnon-stimulated sub-population), while $S(t)$ makes a destructive effect on\ninhibitory non-stimulated FS interneurons (i.e., it breaks up original\ninhibitory synchronization in the non-stimulated sub-population). As results of\nthese different effects of $S(t)$, the type and degree of dynamical response\n(e.g., synchronization enhancement or suppression), characterized by the\ndynamical response factor $D_f$ (given by the ratio of synchronization degree\nin the presence and absence of stimulus), are found to vary in a distinctly\ndifferent way, depending on the synaptic-coupling type. Furthermore, we also\nmeasure the matching degree between the dynamics of the two sub-populations of\nstimulated and non-stimulated neurons in terms of a \"cross-correlation\" measure\n$M_c$. With increasing $A$, based on $M_c$, we discuss the cross-correlations\nbetween the two sub-populations, affecting the dynamical responses to $S(t)$.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 08:45:26 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Kim", "Sang-Yoon", ""], ["Lim", "Woochang", ""]]}, {"id": "1611.09089", "submitter": "Alain Destexhe", "authors": "Zahara Girones and Alain Destexhe", "title": "Enhanced responsiveness in asynchronous irregular neuronal networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks of excitatory and inhibitory neurons display asynchronous irregular\n(AI) states, where the activities of the two populations are balanced. At the\nsingle cell level, it was shown that neurons subject to balanced and noisy\nsynaptic inputs can display enhanced responsiveness. We show here that this\nenhanced responsiveness is also present at the network level, but only when\nsingle neurons are in a conductance state and fluctuation regime consistent\nwith experimental measurements. In such states, the entire population of\nneurons is globally influenced by the external input. We suggest that this\nnetwork-level enhanced responsiveness constitute a low-level form of sensory\nawareness.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 12:02:10 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Girones", "Zahara", ""], ["Destexhe", "Alain", ""]]}, {"id": "1611.09212", "submitter": "Riccardo Franco", "authors": "Riccardo Franco", "title": "Towards a new quantum cognition model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a new quantum-like model for cognition explicitly based\non knowledge. It is shown that this model, called QKT (quantum knowledge-based\ntheory), is able to coherently describe some experimental results that are\nproblematic for the prior quantum-like decision models. In particular, I\nconsider the experimental results relevant to the post-decision cognitive\ndissonance, the problems relevant to the question order effect and response\nreplicability, and those relevant to the grand-reciprocity equations. A new set\nof postulates is proposed, which evidence the different meaning given to the\nprojectors and to the quantum states. In the final part, I show that the use of\nquantum gates can help to better describe and understand the evolution of\nquantum-like models.\n", "versions": [{"version": "v1", "created": "Wed, 23 Nov 2016 23:17:10 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Franco", "Riccardo", ""]]}, {"id": "1611.09245", "submitter": "G Manjunath", "authors": "G Manjunath", "title": "Evolving Network Model that Almost Regenerates Epileptic Data", "comments": "To Appear in Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many realistic networks, the edges representing the interactions between\nthe nodes are time-varying. There is growing evidence that the complex network\nthat models the dynamics of the human brain has time-varying interconnections,\ni.e., the network is evolving. Based on this evidence, we construct a patient\nand data specific evolving network model (comprising discrete-time dynamical\nsystems) in which epileptic seizures or their terminations in the brain are\nalso determined by the nature of the time-varying interconnections between the\nnodes. A novel and unique feature of our methodology is that the evolving\nnetwork model remembers the data from which it was conceived from, in the sense\nthat it evolves to almost regenerate the patient data even upon presenting an\narbitrary initial condition to it. We illustrate a potential utility of our\nmethodology by constructing an evolving network from clinical data that aids in\nidentifying an approximate seizure focus -- nodes in such a theoretically\ndetermined seizure focus are outgoing hubs that apparently act as spreaders of\nseizures. We also point out the efficacy of removal of such spreaders in\nlimiting seizures.\n", "versions": [{"version": "v1", "created": "Thu, 17 Nov 2016 14:25:45 GMT"}], "update_date": "2016-11-29", "authors_parsed": [["Manjunath", "G", ""]]}, {"id": "1611.09520", "submitter": "Yukiyasu Kamitani", "authors": "Tomoyasu Horikawa and Yukiyasu Kamitani", "title": "Hierarchical Neural Representation of Dreamed Objects Revealed by Brain\n  Decoding with Deep Neural Network Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dreaming is generally thought to be generated by spontaneous brain activity\nduring sleep with patterns common to waking experience. This view is supported\nby a recent study demonstrating that dreamed objects can be predicted from\nbrain activity during sleep using statistical decoders trained with\nstimulus-induced brain activity. However, it remains unclear whether and how\nvisual image features associated with dreamed objects are represented in the\nbrain. In this study, we used a deep neural network (DNN) model for object\nrecognition as a proxy for hierarchical visual feature representation, and DNN\nfeatures for dreamed objects were analyzed with brain decoding of fMRI data\ncollected during dreaming. The decoders were first trained with\nstimulus-induced brain activity labeled with the feature values of the stimulus\nimage from multiple DNN layers. The decoders were then used to decode DNN\nfeatures from the dream fMRI data, and the decoded features were compared with\nthe averaged features of each object category calculated from a large-scale\nimage database. We found that the feature values decoded from the dream fMRI\ndata positively correlated with those associated with dreamed object categories\nat mid- to high-level DNN layers. Using the decoded features, the dreamed\nobject category could be identified at above-chance levels by matching them to\nthe averaged features for candidate categories. The results suggest that\ndreaming recruits hierarchical visual feature representations associated with\nobjects, which may support phenomenal aspects of dream experience.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 08:18:38 GMT"}, {"version": "v2", "created": "Mon, 23 Jan 2017 06:54:20 GMT"}], "update_date": "2017-01-24", "authors_parsed": [["Horikawa", "Tomoyasu", ""], ["Kamitani", "Yukiyasu", ""]]}, {"id": "1611.09819", "submitter": "Daniel Harari", "authors": "Daniel Harari, Tao Gao, Nancy Kanwisher, Joshua Tenenbaum, Shimon\n  Ullman", "title": "Measuring and modeling the perception of natural and unconstrained gaze\n  in humans and machines", "comments": "Daniel Harari and Tao Gao contributed equally to this work", "journal-ref": null, "doi": null, "report-no": "Center for Brains, Minds and Machines Memo No. 059", "categories": "q-bio.NC cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans are remarkably adept at interpreting the gaze direction of other\nindividuals in their surroundings. This skill is at the core of the ability to\nengage in joint visual attention, which is essential for establishing social\ninteractions. How accurate are humans in determining the gaze direction of\nothers in lifelike scenes, when they can move their heads and eyes freely, and\nwhat are the sources of information for the underlying perceptual processes?\nThese questions pose a challenge from both empirical and computational\nperspectives, due to the complexity of the visual input in real-life\nsituations. Here we measure empirically human accuracy in perceiving the gaze\ndirection of others in lifelike scenes, and study computationally the sources\nof information and representations underlying this cognitive capacity. We show\nthat humans perform better in face-to-face conditions compared with recorded\nconditions, and that this advantage is not due to the availability of input\ndynamics. We further show that humans are still performing well when only the\neyes-region is visible, rather than the whole face. We develop a computational\nmodel, which replicates the pattern of human performance, including the finding\nthat the eyes-region contains on its own, the required information for\nestimating both head orientation and direction of gaze. Consistent with\nneurophysiological findings on task-specific face regions in the brain, the\nlearned computational representations reproduce perceptual effects such as the\nWollaston illusion, when trained to estimate direction of gaze, but not when\ntrained to recognize objects or faces.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 20:11:09 GMT"}], "update_date": "2016-11-30", "authors_parsed": [["Harari", "Daniel", ""], ["Gao", "Tao", ""], ["Kanwisher", "Nancy", ""], ["Tenenbaum", "Joshua", ""], ["Ullman", "Shimon", ""]]}, {"id": "1611.09888", "submitter": "Saptarshi Das", "authors": "Wasifa Jamal, Saptarshi Das, and Koushik Maharatna", "title": "Existence of Millisecond-order Stable States in Time-Varying Phase\n  Synchronization Measure in EEG Signals", "comments": "4 pages, 8 figures, 1 table", "journal-ref": "Engineering in Medicine and Biology Society (EMBC), 2013 35th\n  Annual International Conference of the IEEE, pp. 2539-2542, July 2013, Osaka,\n  Japan", "doi": "10.1109/EMBC.2013.6610057", "report-no": null, "categories": "physics.med-ph q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we have developed a new measure of understanding the temporal\nevolution of phase synchronization for EEG signals using cross-electrode\ninformation. From this measure it is found that there exists a small number of\nwell-defined phase-synchronized states, each of which is stable for few\nmilliseconds during the execution of a face perception task. We termed these\nquasi-stable states as synchrostates. We used k-means clustering algorithms to\nestimate the optimal number of synchrostates from 100 trials of EEG signals\nover 128 channels. Our results show that these synchrostates exist consistently\nin all the different trials. It is also found that from the onset of the\nstimulus, switching between these synchrostates results in well-behaved\ntemporal sequence with repeatability which may be indicative of the dynamics of\nthe cognitive process underlying that task. Therefore these synchrostates and\ntheir temporal switching sequences may be used as a new measure of the\nstability of phase synchrony and information exchange between different regions\nof a human brain.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 21:22:04 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Jamal", "Wasifa", ""], ["Das", "Saptarshi", ""], ["Maharatna", "Koushik", ""]]}, {"id": "1611.09891", "submitter": "Saptarshi Das", "authors": "Wasifa Jamal, Saptarshi Das, Koushik Maharatna, Doga Kuyucu, Federico\n  Sicca, Lucia Billeci, Fabio Apicella, and Filippo Muratori", "title": "Using Brain Connectivity Measure of EEG Synchrostates for Discriminating\n  Typical and Autism Spectrum Disorder", "comments": "4 pages, 11 figures, 1 table", "journal-ref": "Neural Engineering (NER), 2013 6th International IEEE/EMBS\n  Conference on, pp. 1402-1405, Nov. 2013, San Diego, CA", "doi": "10.1109/NER.2013.6696205", "report-no": null, "categories": "physics.med-ph q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we utilized the concept of stable phase synchronization\ntopography - synchrostates - over the scalp derived from EEG recording for\nformulating brain connectivity network in Autism Spectrum Disorder (ASD) and\ntypically-growing children. A synchronization index is adapted for forming the\nedges of the connectivity graph capturing the stability of each of the\nsynchrostates. Such network is formed for 11 ASD and 12 control group children.\nComparative analyses of these networks using graph theoretic measures show that\nchildren with autism have a different modularity of such networks from typical\nchildren. This result could pave the way to a new modality for possible\nidentification of ASD from non-invasively recorded EEG data.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 21:26:30 GMT"}], "update_date": "2016-12-04", "authors_parsed": [["Jamal", "Wasifa", ""], ["Das", "Saptarshi", ""], ["Maharatna", "Koushik", ""], ["Kuyucu", "Doga", ""], ["Sicca", "Federico", ""], ["Billeci", "Lucia", ""], ["Apicella", "Fabio", ""], ["Muratori", "Filippo", ""]]}, {"id": "1611.10003", "submitter": "Tom Anderson", "authors": "Tom A. F. Anderson, C.-H. Ruan", "title": "Vocabulary and the Brain: Evidence from Neuroimaging Studies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In summary of the research findings presented in this paper, various brain\nregions are correlated with vocabulary and vocabulary acquisition. Semantic\nassociations for vocabulary seem to be located near brain areas that vary\naccording to the type of vocabulary, e.g. ventral temporal regions important\nfor words for things that can be seen. Semantic processing is believed to be\nstrongly associated with the ANG. Phonological ability has been closely related\nto the anterior surfaces of the SMG. Pathways through the posterior SMG are\nthought to link the anterior SMG and the ANG. In vocabulary tasks,\nmediotemporal structures may be related to long-term memory processing, with\nleft hippocampal and parahippocampal regions related to long-term and working\nmemory, respectively. Precentral structures are associated with phonological\nretrieval. Furthermore, many more regions of the brain are of interest in\nvocabulary tasks, particularly in areas important for visual and auditory\nprocessing. Furthermore, differences between brain anatomies can be attributed\nto vocabulary demands of different languages.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 05:17:11 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Anderson", "Tom A. F.", ""], ["Ruan", "C. -H.", ""]]}, {"id": "1611.10047", "submitter": "Alain Destexhe", "authors": "Claude Bedard, Jean-Marie Gomes, Thierry Bal and Alain Destexhe", "title": "A framework to reconcile frequency scaling measurements, from\n  intracellular recordings, local-field potentials, up to EEG and MEG signals", "comments": "(in press)", "journal-ref": "Journal of Integrative Neuroscience 16: 3-18, 2017", "doi": "10.3233/JIN-160001", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this viewpoint article, we discuss the electric properties of the medium\naround neurons, which are important to correctly interpret extracellular\npotentials or electric field effects in neural tissue. We focus on how these\nelectric properties shape the frequency scaling of brain signals at different\nscales, such as intracellular recordings, the local field potential (LFP), the\nelectroencephalogram (EEG) or the magnetoencephalogram (MEG). These signals\ndisplay frequency-scaling properties which are not consistent with resistive\nmedia. The medium appears to exert a frequency filtering scaling as\n$1/\\sqrt{f}$, which is the typical frequency scaling of ionic diffusion. Such a\nscaling was also found recently by impedance measurements in physiological\nconditions. Ionic diffusion appears to be the only possible explanation to\nreconcile these measurements and the frequency-scaling properties found in\ndifferent brain signals. However, other measurements suggest that the\nextracellular medium is essentially resistive. To resolve this discrepancy, we\nshow new evidence that metal-electrode measurements can be perturbed by shunt\ncurrents going through the surface of the brain. Such a shunt may explain the\ncontradictory measurements, and together with ionic diffusion, provides a\nframework where all observations can be reconciled. Finally, we propose a\nmethod to perform measurements avoiding shunting effects, thus enabling to test\nthe predictions of this framework.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2016 08:28:10 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Bedard", "Claude", ""], ["Gomes", "Jean-Marie", ""], ["Bal", "Thierry", ""], ["Destexhe", "Alain", ""]]}, {"id": "1611.10162", "submitter": "Hosnieh Sattar", "authors": "Hosnieh Sattar and Andreas Bulling and Mario Fritz", "title": "Predicting the Category and Attributes of Visual Search Targets Using\n  Deep Gaze Pooling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the target of visual search from eye fixation (gaze) data is a\nchallenging problem with many applications in human-computer interaction. In\ncontrast to previous work that has focused on individual instances as a search\ntarget, we propose the first approach to predict categories and attributes of\nsearch targets based on gaze data. However, state of the art models for\ncategorical recognition, in general, require large amounts of training data,\nwhich is prohibitive for gaze data. To address this challenge, we propose a\nnovel Gaze Pooling Layer that integrates gaze information into CNN-based\narchitectures as an attention mechanism - incorporating both spatial and\ntemporal aspects of human gaze behavior. We show that our approach is effective\neven when the gaze pooling layer is added to an already trained CNN, thus\neliminating the need for expensive joint data collection of visual and gaze\ndata. We propose an experimental setup and data set and demonstrate the\neffectiveness of our method for search target prediction based on gaze\nbehavior. We further study how to integrate temporal and spatial gaze\ninformation most effectively, and indicate directions for future research in\nthe gaze-based prediction of mental states.\n", "versions": [{"version": "v1", "created": "Sun, 27 Nov 2016 07:44:49 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 11:52:29 GMT"}, {"version": "v3", "created": "Mon, 3 Apr 2017 11:05:07 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Sattar", "Hosnieh", ""], ["Bulling", "Andreas", ""], ["Fritz", "Mario", ""]]}, {"id": "1611.10252", "submitter": "Jingkang Yang", "authors": "Jingkang Yang, Haohan Wang, Jun Zhu, Eric P. Xing", "title": "SeDMiD for Confusion Detection: Uncovering Mind State from Time Series\n  Brain Wave Data", "comments": "11 pages, 2 figures, NIPS 2016 Time Series Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how brain functions has been an intriguing topic for years.\nWith the recent progress on collecting massive data and developing advanced\ntechnology, people have become interested in addressing the challenge of\ndecoding brain wave data into meaningful mind states, with many machine\nlearning models and algorithms being revisited and developed, especially the\nones that handle time series data because of the nature of brain waves.\nHowever, many of these time series models, like HMM with hidden state in\ndiscrete space or State Space Model with hidden state in continuous space, only\nwork with one source of data and cannot handle different sources of information\nsimultaneously. In this paper, we propose an extension of State Space Model to\nwork with different sources of information together with its learning and\ninference algorithms. We apply this model to decode the mind state of students\nduring lectures based on their brain waves and reach a significant better\nresults compared to traditional methods.\n", "versions": [{"version": "v1", "created": "Tue, 29 Nov 2016 18:11:00 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Yang", "Jingkang", ""], ["Wang", "Haohan", ""], ["Zhu", "Jun", ""], ["Xing", "Eric P.", ""]]}]