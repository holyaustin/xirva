[{"id": "1108.0073", "submitter": "Susanne Ditlevsen", "authors": "Susanne Ditlevsen and Priscilla Greenwood", "title": "The Morris-Lecar neuron model embeds a leaky integrate-and-fire model", "comments": "19 pages, 6 figures", "journal-ref": "Journal of Mathematical Biology, 67(2), 239-259, 2013", "doi": "10.1007/s00285-012-0552-7", "report-no": null, "categories": "math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the stochastic Morris-Lecar neuron, in a neighborhood of its\nstable point, can be approximated by a two-dimensional Ornstein-Uhlenbeck (OU)\nmodulation of a constant circular motion. The associated radial OU process is\nan example of a leaky integrate-and-fire (LIF) model prior to firing. A new\nmodel constructed from a radial OU process together with a simple firing\nmechanism based on detailed Morris-Lecar firing statistics reproduces the\nMorris-Lecar Interspike Interval (ISI) distribution, and has the computational\nadvantages of a LIF. The result justifies the large amount of attention paid to\nthe LIF models.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jul 2011 14:46:46 GMT"}], "update_date": "2014-02-04", "authors_parsed": [["Ditlevsen", "Susanne", ""], ["Greenwood", "Priscilla", ""]]}, {"id": "1108.0251", "submitter": "Roberto D. Pascual-Marqui", "authors": "Roberto D. Pascual-Marqui, Rolando J. Biscay, Pedro A. Valdes-Sosa,\n  Jorge Bosch-Bayard, Jorge J. Riera-Diaz", "title": "Cortical current source connectivity by means of partial coherence\n  fields", "comments": null, "journal-ref": null, "doi": null, "report-no": "Technical Beatles Report 2011-08-01", "categories": "stat.AP physics.bio-ph q-bio.NC stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  An important field of research in functional neuroimaging is the discovery of\nintegrated, distributed brain systems and networks, whose different regions\nneed to work in unison for normal functioning.\n  The EEG is a non-invasive technique that can provide information for massive\nconnectivity analyses. Cortical signals of time varying electric neuronal\nactivity can be estimated from the EEG. Although such techniques have very high\ntime resolution, two cortical signals even at distant locations will appear to\nbe highly similar due to the low spatial resolution nature of the EEG.\n  In this study a method for eliminating the effect of common sources due to\nlow spatial resolution is presented. It is based on an efficient estimation of\nthe whole-cortex partial coherence matrix. Using as a starting point any linear\nEEG tomography that satisfies the EEG forward equation, it is shown that the\ngeneralized partial coherences for the cortical grey matter current density\ntime series are invariant to the selected tomography. It is empirically shown\nwith simulation experiments that the generalized partial coherences have higher\nspatial resolution than the classical coherences. The results demonstrate that\nwith as little as 19 electrodes, lag-connected brain regions can often be\nmissed and misplaced even with lagged coherence measures, while the new method\ndetects and localizes correctly the connected regions using the lagged partial\ncoherences.\n", "versions": [{"version": "v1", "created": "Mon, 1 Aug 2011 07:07:01 GMT"}], "update_date": "2011-08-20", "authors_parsed": [["Pascual-Marqui", "Roberto D.", ""], ["Biscay", "Rolando J.", ""], ["Valdes-Sosa", "Pedro A.", ""], ["Bosch-Bayard", "Jorge", ""], ["Riera-Diaz", "Jorge J.", ""]]}, {"id": "1108.2407", "submitter": "Jonathan Touboul", "authors": "Jonathan Touboul", "title": "Mean-field equations for stochastic firing-rate neural fields with\n  delays: Derivation and noise-induced transitions", "comments": "Updated to the latest version published, and clarified the dependence\n  in space of Brownian motions", "journal-ref": "Physica D 241 (15), 2012, pp. 1223-1244", "doi": "10.1016/j.physd.2012.03.010", "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript we analyze the collective behavior of mean-field limits of\nlarge-scale, spatially extended stochastic neuronal networks with delays.\nRigorously, the asymptotic regime of such systems is characterized by a very\nintricate stochastic delayed integro-differential McKean-Vlasov equation that\nremain impenetrable, leaving the stochastic collective dynamics of such\nnetworks poorly understood. In order to study these macroscopic dynamics, we\nanalyze networks of firing-rate neurons, i.e. with linear intrinsic dynamics\nand sigmoidal interactions. In that case, we prove that the solution of the\nmean-field equation is Gaussian, hence characterized by its two first moments,\nand that these two quantities satisfy a set of coupled delayed\nintegro-differential equations. These equations are similar to usual neural\nfield equations, and incorporate noise levels as a parameter, allowing analysis\nof noise-induced transitions. We identify through bifurcation analysis several\nqualitative transitions due to noise in the mean-field limit. In particular,\nstabilization of spatially homogeneous solutions, synchronized oscillations,\nbumps, chaotic dynamics, wave or bump splitting are exhibited and arise from\nstatic or dynamic Turing-Hopf bifurcations. These surprising phenomena allow\nfurther exploring the role of noise in the nervous system.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2011 14:11:01 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2011 08:30:24 GMT"}, {"version": "v3", "created": "Mon, 31 Oct 2011 09:36:56 GMT"}, {"version": "v4", "created": "Sun, 19 Feb 2017 13:39:17 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Touboul", "Jonathan", ""]]}, {"id": "1108.2414", "submitter": "Jonathan Touboul", "authors": "Jonathan Touboul", "title": "Propagation of chaos in neural fields", "comments": "Updated to correct an erroneous suggestion of extension of the\n  results in Appendix B, and to clarify some measurability questions in the\n  proof of Theorem 2", "journal-ref": "Annals of Applied Probability 2014, Vol. 24, No. 3, 1298-1328", "doi": "10.1214/13-AAP950", "report-no": "IMS-AAP-AAP950", "categories": "math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of the limit of bio-inspired spatially extended\nneuronal networks including an infinite number of neuronal types (space\nlocations), with space-dependent propagation delays modeling neural fields. The\npropagation of chaos property is proved in this setting under mild assumptions\non the neuronal dynamics, valid for most models used in neuroscience, in a\nmesoscopic limit, the neural-field limit, in which we can resolve the quite\nfine structure of the neuron's activity in space and where averaging effects\noccur. The mean-field equations obtained are of a new type: they take the form\nof well-posed infinite-dimensional delayed integro-differential equations with\na nonlocal mean-field term and a singular spatio-temporal Brownian motion. We\nalso show how these intricate equations can be used in practice to uncover\nmathematically the precise mesoscopic dynamics of the neural field in a\nparticular model where the mean-field equations exactly reduce to deterministic\nnonlinear delayed integro-differential equations. These results have several\ntheoretical implications in neuroscience we review in the discussion.\n", "versions": [{"version": "v1", "created": "Thu, 11 Aug 2011 14:26:25 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2011 21:47:30 GMT"}, {"version": "v3", "created": "Mon, 31 Oct 2011 09:39:48 GMT"}, {"version": "v4", "created": "Sun, 29 Jul 2012 09:55:58 GMT"}, {"version": "v5", "created": "Mon, 5 May 2014 13:42:57 GMT"}, {"version": "v6", "created": "Fri, 27 May 2016 16:23:50 GMT"}], "update_date": "2016-05-30", "authors_parsed": [["Touboul", "Jonathan", ""]]}, {"id": "1108.2819", "submitter": "Robert Burger PhD", "authors": "John Robert Burger", "title": "Qubit-wannabe Neural Networks", "comments": "Re-worked algorithms concerning function classification and\n  satisfiability", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neurons, or \"simulated\" qubits, can store simultaneous true and\nfalse with probabilistic behaviors usually reserved for the qubits of quantum\nphysics. Although possible to construct artificially, simulated qubits are\nintended to explain biological mysteries. It is shown below that they can\nsimulate certain quantum computations and, although less potent than the qubits\nof quantum physics, they nevertheless are shown to significantly exceed the\ncapabilities of classical deterministic circuits.\n", "versions": [{"version": "v1", "created": "Sat, 13 Aug 2011 20:47:25 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2012 01:38:16 GMT"}, {"version": "v3", "created": "Fri, 25 May 2012 00:36:55 GMT"}], "update_date": "2012-05-28", "authors_parsed": [["Burger", "John Robert", ""]]}, {"id": "1108.2840", "submitter": "Miguel \\'A. Carreira-Perpi\\~n\\'an", "authors": "Miguel \\'A. Carreira-Perpi\\~n\\'an, Geoffrey J. Goodhill", "title": "Generalised elastic nets", "comments": "52 pages, 16 figures. Original manuscript dated August 14, 2003 and\n  not updated since. Current authors' email addresses:\n  mcarreira-perpinan@ucmerced.edu, g.goodhill@uq.edu.au", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The elastic net was introduced as a heuristic algorithm for combinatorial\noptimisation and has been applied, among other problems, to biological\nmodelling. It has an energy function which trades off a fitness term against a\ntension term. In the original formulation of the algorithm the tension term was\nimplicitly based on a first-order derivative. In this paper we generalise the\nelastic net model to an arbitrary quadratic tension term, e.g. derived from a\ndiscretised differential operator, and give an efficient learning algorithm. We\nrefer to these as generalised elastic nets (GENs). We give a theoretical\nanalysis of the tension term for 1D nets with periodic boundary conditions, and\nshow that the model is sensitive to the choice of finite difference scheme that\nrepresents the discretised derivative. We illustrate some of these issues in\nthe context of cortical map models, by relating the choice of tension term to a\ncortical interaction function. In particular, we prove that this interaction\ntakes the form of a Mexican hat for the original elastic net, and of\nprogressively more oscillatory Mexican hats for higher-order derivatives. The\nresults apply not only to generalised elastic nets but also to other methods\nusing discrete differential penalties, and are expected to be useful in other\nareas, such as data analysis, computer graphics and optimisation problems.\n", "versions": [{"version": "v1", "created": "Sun, 14 Aug 2011 03:47:14 GMT"}], "update_date": "2011-08-16", "authors_parsed": [["Carreira-Perpi\u00f1\u00e1n", "Miguel \u00c1.", ""], ["Goodhill", "Geoffrey J.", ""]]}, {"id": "1108.4167", "submitter": "Jean-Louis Dessalles", "authors": "Jean-Louis Dessalles (INFRES, LTCI)", "title": "Storing events to retell them (Commentary on Suddendorf and Corballis:\n  'The evolution of foresight')", "comments": "jld-07051403", "journal-ref": "Behavioral and Brain Sciences 30, 3 (2007) 321-322", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Episodic memory is certainly a unique endowment, but its primary purpose is\nsomething other than to provide raw material for creative synthesis of future\nscenarios. Remembered episodes are exactly those which are worth telling. The\nfunction of episodic memory, in our view, is to accumulate stories that are\nrelevant to recount in conversation.\n", "versions": [{"version": "v1", "created": "Sun, 21 Aug 2011 06:54:49 GMT"}], "update_date": "2011-08-23", "authors_parsed": [["Dessalles", "Jean-Louis", "", "INFRES, LTCI"]]}, {"id": "1108.4296", "submitter": "Jean-Louis Dessalles", "authors": "Jean-Louis Dessalles (INFRES, LTCI), Tiziana Zalla (CREA)", "title": "On the evolution of phenomenal consciousness", "comments": "jld-98072405; On the evolution of phenomenal consciousness (1998) 350", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A number of concepts are included in the term 'consciousness'. We choose to\nconcentrate here on phenomenal consciousness, the process through which we are\nable to experience aspects of our environment or of our physical state. We\nprobably share this aspect of consciousness with many animals which, like us,\nfeel pain or pleasure and experience colours, sounds, flavours, etc. Since\nphenomenal consciousness is a feature of some living species, we should be able\nto account for it in terms of natural selection. Does it have an adaptive\nfunction, or is it an epiphenomenon ? We shall give arguments to reject the\nsecond alternative. We propose that phenomenal properties of consciousness are\ninvolved in a labelling process that allows us to discriminate and to evaluate\nmental representations. We also discuss to what extent consciousness as such\nhas been selected for this labelling function.\n", "versions": [{"version": "v1", "created": "Mon, 22 Aug 2011 12:54:54 GMT"}], "update_date": "2011-08-23", "authors_parsed": [["Dessalles", "Jean-Louis", "", "INFRES, LTCI"], ["Zalla", "Tiziana", "", "CREA"]]}, {"id": "1108.4297", "submitter": "Jean-Louis Dessalles", "authors": "Jean-Louis Dessalles (INFRES, LTCI)", "title": "Why is language well-designed for communication? (Commentary on\n  Christiansen and Chater: 'Language as shaped by the brain')", "comments": "jld-08041101", "journal-ref": "Behavioral and Brain Sciences 31, 5 (2008) 518-519", "doi": null, "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selection through iterated learning explains no more than other\nnon-functional accounts, such as universal grammar, why language is so\nwell-designed for communicative efficiency. It does not predict several\ndistinctive features of language like central embedding, large lexicons or the\nlack of iconicity, that seem to serve communication purposes at the expense of\nlearnability.\n", "versions": [{"version": "v1", "created": "Mon, 22 Aug 2011 12:55:20 GMT"}], "update_date": "2011-08-23", "authors_parsed": [["Dessalles", "Jean-Louis", "", "INFRES, LTCI"]]}, {"id": "1108.4644", "submitter": "Shahab Kadkhodaeian Bakhtiari", "authors": "Shahab Kadkhodaeian Bakhtiari, Gholam-Ali Hossein-Zadeh", "title": "Subspace-based Identification Algorithm for Characterizing Causal\n  Networks in Resting Brain", "comments": "Accepted in Neuroimage Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analysis of brain activity in resting-state is of fundamental importance in\nidentifying functional characteristics of neuronal system. Although resting\nbrain has been extensively investigated for low frequency synchrony between\nbrain regions, namely Functional Connectivity (FC), the other main stream of\nbrain connectivity analysis that seeks causal interactions between brain\nregions, Effective Connectivity (EC), has been little explored in spontaneous\nbrain oscillations. Inherent complexity of brain activities in resting-state,\nas is observed in BOLD (Blood Oxygenation-Level Dependant) fluctuations, call\nfor exploratory methods for characterizing these causal networks. On the other\nhand, the inevitable effects that hemodynamic system imposes on causal\ninferences based on fMRI data, lead us toward the methods in which causal\ninferences can take place in latent neuronal level, rather than observed BOLD\ntime-series. To simultaneously satisfy these two concerns, in this paper, we\nintroduce a novel state-space system identification approach for studying\ncausal interactions among brain regions in the absence of explicit cognitive\ntask. Using extensive simulations, we study the effects of network size and\nsignal to noise ratio (SNR) on the accuracy of our proposed method in EC\ndetection. Our simulations demonstrate that Subspace-based Identification\nAlgorithm (SIA) is sufficiently robust against above-mentioned factors, and can\nreliably unravel the underlying causal interactions of resting-state BOLD fMRI\n", "versions": [{"version": "v1", "created": "Tue, 23 Aug 2011 16:03:15 GMT"}, {"version": "v2", "created": "Sat, 31 Dec 2011 08:45:32 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Bakhtiari", "Shahab Kadkhodaeian", ""], ["Hossein-Zadeh", "Gholam-Ali", ""]]}, {"id": "1108.4796", "submitter": "Ajaz Bhat", "authors": "Ajaz Ahmad Bhat, Gaurang Mahajan, Anita Mehta", "title": "Learning with a network of competing synapses", "comments": "16 pages, 9 figures; published in PLoS ONE", "journal-ref": "PLoS ONE 6(9) (2011): e25048", "doi": "10.1371/journal.pone.0025048", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech nlin.AO q-bio.NC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Competition between synapses arises in some forms of correlation-based\nplasticity. Here we propose a game theory-inspired model of synaptic\ninteractions whose dynamics is driven by competition between synapses in their\nweak and strong states, which are characterized by different timescales. The\nlearning of inputs and memory are meaningfully definable in an effective\ndescription of networked synaptic populations. We study, numerically and\nanalytically, the dynamic responses of the effective system to various signal\ntypes, particularly with reference to an existing empirical motor adaptation\nmodel. The dependence of the system-level behavior on the synaptic parameters,\nand the signal strength, is brought out in a clear manner, thus illuminating\nissues such as those of optimal performance, and the functional role of\nmultiple timescales.\n", "versions": [{"version": "v1", "created": "Wed, 24 Aug 2011 09:54:35 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2011 14:16:19 GMT"}], "update_date": "2011-10-19", "authors_parsed": [["Bhat", "Ajaz Ahmad", ""], ["Mahajan", "Gaurang", ""], ["Mehta", "Anita", ""]]}, {"id": "1108.6271", "submitter": "Joshua Vogelstein", "authors": "Carey E. Priebe, Joshua T. Vogelstein, Davi Bock", "title": "Optimizing the quantity/quality trade-off in connectome inference", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We demonstrate a meaningful prospective power analysis for an (admittedly\nidealized) illustrative connectome inference task. Modeling neurons as vertices\nand synapses as edges in a simple random graph model, we optimize the trade-off\nbetween the number of (putative) edges identified and the accuracy of the edge\nidentification procedure. We conclude that explicit analysis of the\nquantity/quality trade-off is imperative for optimal neuroscientific\nexperimental design. In particular, more though more errorful edge\nidentification can yield superior inferential performance.\n", "versions": [{"version": "v1", "created": "Wed, 31 Aug 2011 15:35:36 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2011 00:09:53 GMT"}], "update_date": "2011-10-13", "authors_parsed": [["Priebe", "Carey E.", ""], ["Vogelstein", "Joshua T.", ""], ["Bock", "Davi", ""]]}]