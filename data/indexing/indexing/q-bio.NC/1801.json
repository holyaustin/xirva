[{"id": "1801.00002", "submitter": "William Softky Ph.D.", "authors": "William R. Softky", "title": "9.5 Hypotheses on the Informational Structure of Life which are\n  Multi-scale, Human-readable, Provocative, Coherent, Plausible, Falsifiable,\n  and Actionable", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document has an unorthodox structure to accomplish an unorthodox goal:\npresenting the scaffolding for a zero-parameter Unified Theory of Life inside\nseveral dozen pages. Ideally, that length is short enough to be understood in a\nfew hours, yet complete and principled enough to unfold into solutions to\ncivilization's most urgent problem: the accelerating de-calibration of fluid\nhuman brains by compelling digitized signals. The stakes of understanding\nhumans as informational beings are huge. Without drastic changes, crucial human\nfunctionality will vanish in a generation. Fortunately, the cures are cheap and\neasy if promoted properly. These ten hypotheses re-present in more abstract,\nencapsulated form a Framework published a few months ago in a reputable\npeer-reviewed journal, which concluded that human sensory systems must be\naccorded data of the same quality as the data which already trains algorithmic\nintelligences. While the lack of experiment-grade detail might make these\nhypotheses seem \"unscientific,\" in compensation the breadth of this Framework\nought to provide the virtues of theory: clarity, simplicity, coherence, and\nself-evidence. Five of the hypotheses span humanity's current problem-space,\nand five a possible solution space. They are: H1.0 Stably evolving\ndistributions must balance themselves between narrowing and broadening H2.0\nStabilization and homeostasis are fragile in multiple ways H3.0 Representing\nspacetime requires micro-timing and mega-assumptions H4.0 When in doubt, ping!\nH5.0 Mediated communication becomes infected with pinging H6.0 If scaling and\nincentives are the problems, then entropy and affection are the solutions H7.0\n\"Paleo everything but violence\" provides sensorimotor nutrition H8.0 Humans\nevolved to resonate ecstatically H9.0 Symmetric spinal health syndrome H9.5\nHelping the irresistible force beat the immovable object\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 23:38:15 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Softky", "William R.", ""]]}, {"id": "1801.00048", "submitter": "Daniel McNamee", "authors": "Daniel McNamee", "title": "Characterizing optimal hierarchical policy inference on graphs via\n  non-equilibrium thermodynamics", "comments": "NIPS 2017 Workshop on Hierarchical Reinforcement Learning. 8 pages, 1\n  figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hierarchies are of fundamental interest in both stochastic optimal control\nand biological control due to their facilitation of a range of desirable\ncomputational traits in a control algorithm and the possibility that they may\nform a core principle of sensorimotor and cognitive control systems. However, a\ntheoretically justified construction of state-space hierarchies over all\nspatial resolutions and their evolution through a policy inference process\nremains elusive. Here, a formalism for deriving such normative representations\nof discrete Markov decision processes is introduced in the context of graphs.\nThe resulting hierarchies correspond to a hierarchical policy inference\nalgorithm approximating a discrete gradient flow between state-space trajectory\ndensities generated by the prior and optimal policies.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 22:19:16 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["McNamee", "Daniel", ""]]}, {"id": "1801.00062", "submitter": "Jo\\~ao Sacramento", "authors": "Jo\\~ao Sacramento and Rui Ponte Costa and Yoshua Bengio and Walter\n  Senn", "title": "Dendritic error backpropagation in deep cortical microcircuits", "comments": "27 pages, 5 figures, 10 pages supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animal behaviour depends on learning to associate sensory stimuli with the\ndesired motor command. Understanding how the brain orchestrates the necessary\nsynaptic modifications across different brain areas has remained a longstanding\npuzzle. Here, we introduce a multi-area neuronal network model in which\nsynaptic plasticity continuously adapts the network towards a global desired\noutput. In this model synaptic learning is driven by a local dendritic\nprediction error that arises from a failure to predict the top-down input given\nthe bottom-up activities. Such errors occur at apical dendrites of pyramidal\nneurons where both long-range excitatory feedback and local inhibitory\npredictions are integrated. When local inhibition fails to match excitatory\nfeedback an error occurs which triggers plasticity at bottom-up synapses at\nbasal dendrites of the same pyramidal neurons. We demonstrate the learning\ncapabilities of the model in a number of tasks and show that it approximates\nthe classical error backpropagation algorithm. Finally, complementing this\ncortical circuit with a disinhibitory mechanism enables attention-like stimulus\ndenoising and generation. Our framework makes several experimental predictions\non the function of dendritic integration and cortical microcircuits, is\nconsistent with recent observations of cross-area learning, and suggests a\nbiological implementation of deep learning.\n", "versions": [{"version": "v1", "created": "Sat, 30 Dec 2017 00:16:56 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Sacramento", "Jo\u00e3o", ""], ["Costa", "Rui Ponte", ""], ["Bengio", "Yoshua", ""], ["Senn", "Walter", ""]]}, {"id": "1801.00257", "submitter": "Martin Frasch", "authors": "Martin G. Frasch, Silvia Lobmaier, Tamara Stampalija, Paula Desplats,\n  Mar\\'ia Eugenia Pallar\\'es, Ver\\'onica Pastor, Marcela Brocco, Hau-tieng Wu,\n  Jay Schulkin, Christophe Herry, Andrew Seely, Gerlinde A.S. Metz, Yoram\n  Louzoun, Marta Antonelli", "title": "Non-invasive biomarkers of fetal brain development reflecting prenatal\n  stress: an integrative multi-scale multi-species perspective on data\n  collection and analysis", "comments": "Focused review, 13 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.neubiorev.2018.05.026", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Prenatal stress (PS) impacts early postnatal behavioural and cognitive\ndevelopment. This process of 'fetal programming' is mediated by the effects of\nthe prenatal experience on the developing hypothalamic-pituitary-adrenal (HPA)\naxis and autonomic nervous system (ANS). The HPA axis is a dynamic system\nregulating homeostasis, especially the stress response, and is highly sensitive\nto adverse early life experiences. We review the evidence for the effects of PS\non fetal programming of the HPA axis and the ANS. We derive a multi-scale\nmulti-species approach to devising preclinical and clinical studies to identify\nearly non-invasively available pre- and postnatal biomarkers of these\nprogramming effects. Such approach would identify adverse postnatal brain\ndevelopmental trajectories, a prerequisite for designing therapeutic\ninterventions. The multiple scales include the biomarkers reflecting changes in\nthe brain epigenome, metabolome, microbiome and the ANS activity gauged via an\narray of advanced non-invasively obtainable properties of fetal heart rate\nfluctuations. The proposed framework has the potential to reveal mechanistic\nlinks between maternal stress during pregnancy and changes across these\nphysiological scales. Such biomarkers may hence be useful as early and\nnon-invasive predictors of neurodevelopmental trajectories influenced by the\nPS. We conclude that studies into PS effects must be conducted on multiple\nscales derived from concerted observations in multiple animal models and human\ncohorts performed in an interactive and iterative manner and deploying machine\nlearning for data synthesis, identification and validation of the best\nnon-invasive biomarkers.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 09:20:09 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Frasch", "Martin G.", ""], ["Lobmaier", "Silvia", ""], ["Stampalija", "Tamara", ""], ["Desplats", "Paula", ""], ["Pallar\u00e9s", "Mar\u00eda Eugenia", ""], ["Pastor", "Ver\u00f3nica", ""], ["Brocco", "Marcela", ""], ["Wu", "Hau-tieng", ""], ["Schulkin", "Jay", ""], ["Herry", "Christophe", ""], ["Seely", "Andrew", ""], ["Metz", "Gerlinde A. S.", ""], ["Louzoun", "Yoram", ""], ["Antonelli", "Marta", ""]]}, {"id": "1801.00475", "submitter": "M Rule", "authors": "M. E. Rule and G. Sanguinetti", "title": "Autoregressive Point-Processes as Latent State-Space Models: a\n  Moment-Closure Approach to Fluctuations and Autocorrelations", "comments": null, "journal-ref": null, "doi": "10.1162/neco_a_01121", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling and interpreting spike train data is a task of central importance in\ncomputational neuroscience, with significant translational implications. Two\npopular classes of data-driven models for this task are autoregressive Point\nProcess Generalized Linear models (PPGLM) and latent State-Space models (SSM)\nwith point-process observations. In this letter, we derive a mathematical\nconnection between these two classes of models. By introducing an auxiliary\nhistory process, we represent exactly a PPGLM in terms of a latent, infinite\ndimensional dynamical system, which can then be mapped onto an SSM by basis\nfunction projections and moment closure. This representation provides a new\nperspective on widely used methods for modeling spike data, and also suggests\nnovel algorithmic approaches to fitting such models. We illustrate our results\non a phasic bursting neuron model, showing that our proposed approach provides\nan accurate and efficient way to capture neural dynamics.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jan 2018 16:56:15 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 13:30:41 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Rule", "M. E.", ""], ["Sanguinetti", "G.", ""]]}, {"id": "1801.00602", "submitter": "Kai Qiao", "authors": "Kai Qiao, Chi Zhang, Linyuan Wang, Bin Yan, Jian Chen, Lei Zeng, Li\n  Tong", "title": "Accurate reconstruction of image stimuli from human fMRI based on the\n  decoding model with capsule network architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neuroscience, all kinds of computation models were designed to answer the\nopen question of how sensory stimuli are encoded by neurons and conversely, how\nsensory stimuli can be decoded from neuronal activities. Especially, functional\nMagnetic Resonance Imaging (fMRI) studies have made many great achievements\nwith the rapid development of the deep network computation. However, comparing\nwith the goal of decoding orientation, position and object category from\nactivities in visual cortex, accurate reconstruction of image stimuli from\nhuman fMRI is a still challenging work. In this paper, the capsule network\n(CapsNet) architecture based visual reconstruction (CNAVR) method is developed\nto reconstruct image stimuli. The capsule means containing a group of neurons\nto perform the better organization of feature structure and representation,\ninspired by the structure of cortical mini column including several hundred\nneurons in primates. The high-level capsule features in the CapsNet includes\ndiverse features of image stimuli such as semantic class, orientation, location\nand so on. We used these features to bridge between human fMRI and image\nstimuli. We firstly employed the CapsNet to train the nonlinear mapping from\nimage stimuli to high-level capsule features, and from high-level capsule\nfeatures to image stimuli again in an end-to-end manner. After estimating the\nserviceability of each voxel by encoding performance to accomplish the\nselecting of voxels, we secondly trained the nonlinear mapping from\ndimension-decreasing fMRI data to high-level capsule features. Finally, we can\npredict the high-level capsule features with fMRI data, and reconstruct image\nstimuli with the CapsNet. We evaluated the proposed CNAVR method on the dataset\nof handwritten digital images, and exceeded about 10% than the accuracy of all\nexisting state-of-the-art methods on the structural similarity index (SSIM).\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 10:39:05 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Qiao", "Kai", ""], ["Zhang", "Chi", ""], ["Wang", "Linyuan", ""], ["Yan", "Bin", ""], ["Chen", "Jian", ""], ["Zeng", "Lei", ""], ["Tong", "Li", ""]]}, {"id": "1801.00864", "submitter": "Gianluca Susi PhD", "authors": "Gianluca Susi, Pilar Garces, Alessandro Cristini, Emanuele Paracone,\n  Mario Salerno, Fernando Maestu, Ernesto Pereda", "title": "FNS: an event-driven spiking neural network simulator based on the LIFL\n  neuron model", "comments": "Changed title, added references, corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limitations in processing capabilities and memory of today's computers make\nspiking neuron-based (human) whole-brain simulations inevitably characterized\nby a compromise between bio-plausibility and computational cost. It translates\ninto brain models composed of a reduced number of neurons and a simplified\nneuron's mathematical model, leading to the search for new simulation\nstrategies. Taking advantage of the sparse character of brain-like computation,\nthe event-driven technique could represent a way to carry out efficient\nsimulation of large-scale Spiking Neural Networks (SNN). The recent Leaky\nIntegrate-and-Fire with Latency (LIFL) spiking neuron model is event-driven\ncompatible and exhibits some realistic neuronal features, opening new avenues\nfor brain modelling. In this paper we introduce FNS, the first LIFL-based\nspiking neural network framework, which combines spiking/synaptic neural\nmodelling with the event-driven approach, allowing us to define heterogeneous\nneuron modules and multi-scale connectivity with delayed connections and\nplastic synapses. In order to allow multi-thread implementations a novel\nparallelization strategy is also introduced. This paper presents mathematical\nmodels, software implementation and simulation routines on which FNS is based.\nFinally, a brain subnetwork is modeled on the basis of real brain structural\ndata, and the resulting simulated activity is compared with associated brain\nfunctional (source-space MEG) data, demonstrating a good matching between the\nactivity of the model and that of the experimetal data. This work aims to lay\nthe groundwork for future event-driven based personalised brain models.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 23:49:13 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 09:52:41 GMT"}, {"version": "v3", "created": "Thu, 16 Jul 2020 17:07:07 GMT"}], "update_date": "2020-07-17", "authors_parsed": [["Susi", "Gianluca", ""], ["Garces", "Pilar", ""], ["Cristini", "Alessandro", ""], ["Paracone", "Emanuele", ""], ["Salerno", "Mario", ""], ["Maestu", "Fernando", ""], ["Pereda", "Ernesto", ""]]}, {"id": "1801.01362", "submitter": "Ulisse Ferrari", "authors": "Ulisse Ferrari, Stephane Deny, Olivier Marre, Thierry Mora", "title": "A simple model for low variability in neural spike trains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural noise sets a limit to information transmission in sensory systems. In\nseveral areas, the spiking response (to a repeated stimulus) has shown a higher\ndegree of regularity than predicted by a Poisson process. However, a simple\nmodel to explain this low variability is still lacking. Here we introduce a new\nmodel, with a correction to Poisson statistics, which can accurately predict\nthe regularity of neural spike trains in response to a repeated stimulus. The\nmodel has only two parameters, but can reproduce the observed variability in\nretinal recordings in various conditions. We show analytically why this\napproximation can work. In a model of the spike emitting process where a\nrefractory period is assumed, we derive that our simple correction can well\napproximate the spike train statistics over a broad range of firing rates. Our\nmodel can be easily plugged to stimulus processing models, like\nLinear-nonlinear model or its generalizations, to replace the Poisson spike\ntrain hypothesis that is commonly assumed. It estimates the amount of\ninformation transmitted much more accurately than Poisson models in retinal\nrecordings. Thanks to its simplicity this model has the potential to explain\nlow variability in other areas.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 14:17:15 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Ferrari", "Ulisse", ""], ["Deny", "Stephane", ""], ["Marre", "Olivier", ""], ["Mora", "Thierry", ""]]}, {"id": "1801.01385", "submitter": "Sang-Yoon  Kim", "authors": "Sang-Yoon Kim, Woochang Lim", "title": "Effect of Inhibitory Spike-Timing-Dependent Plasticity on Fast Sparsely\n  Synchronized Rhythms in A Small-World Neuronal Network", "comments": "arXiv admin note: text overlap with arXiv:1704.03150", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the Watts-Strogatz small-world network (SWN) consisting of\ninhibitory fast spiking Izhikevich interneurons. This inhibitory neuronal\npopulation has adaptive dynamic synaptic strengths governed by the inhibitory\nspike-timing-dependent plasticity (iSTDP). In previous works without iSTDP,\nfast sparsely synchronized rhythms, associated with diverse cognitive\nfunctions, were found to appear in a range of large noise intensities for fixed\nstrong synaptic inhibition strengths. Here, we investigate the effect of iSTDP\non fast sparse synchronization (FSS) by varying the noise intensity $D$. We\nemploy an asymmetric anti-Hebbian time window for the iSTDP update rule [which\nis in contrast to the Hebbian time window for the excitatory STDP (eSTDP)].\nDepending on values of $D$, population-averaged values of saturated synaptic\ninhibition strengths are potentiated [long-term potentiation (LTP)] or\ndepressed [long-term depression (LTD)] in comparison with the initial mean\nvalue, and dispersions from the mean values of LTP/LTD are much increased when\ncompared with the initial dispersion, independently of $D$. In most cases of\nLTD where the effect of mean LTD is dominant in comparison with the effect of\ndispersion, good FSS (with higher spiking measure) is found to get better via\nLTD, while bad FSS (with lower spiking measure) is found to get worse via LTP.\nThis kind of Matthew effect in inhibitory synaptic plasticity is in contrast to\nthat in excitatory synaptic plasticity where good (bad) synchronization gets\nbetter (worse) via LTP (LTD). Emergences of LTD and LTP of synaptic inhibition\nstrengths are intensively investigated via a microscopic method based on the\ndistributions of time delays between the pre- and the post-synaptic spike\ntimes. Furthermore, we also investigate the effects of network architecture on\nFSS by changing the rewiring probability $p$ of the SWN in the presence of\niSTDP.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 01:29:34 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 09:46:39 GMT"}, {"version": "v3", "created": "Fri, 11 May 2018 17:05:43 GMT"}, {"version": "v4", "created": "Mon, 14 May 2018 04:59:47 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Kim", "Sang-Yoon", ""], ["Lim", "Woochang", ""]]}, {"id": "1801.01441", "submitter": "Pieter Segaert", "authors": "K. Segaert, S.J.E. Lucas, C.V. Burley, Pieter Segaert, A. E. Milner,\n  M. Ryan, L. Wheeldon", "title": "Higher physical fitness levels are associated with less language decline\n  in healthy ageing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Healthy ageing is associated with decline in cognitive abilities such as\nlanguage. Aerobic fitness has been shown to ameliorate decline in some\ncognitive domains, but the potential benefits for language have not been\nexamined. In a cross-sectional sample, we investigated the relationship between\naerobic fitness and tip-of-the-tongue states. These are among the most frequent\ncognitive failures in healthy older adults and occur when a speaker knows a\nword but is unable to produce it. We found that healthy older adults indeed\nexperience more tip-of-the-tongue states than young adults. Importantly, higher\naerobic fitness levels decrease the probability of experiencing\ntip-of-the-tongue states in healthy older adults. Fitness-related differences\nin word finding abilities are observed over and above effects of age. This is\nthe first demonstration of a link between aerobic fitness and language\nfunctioning in healthy older adults.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 16:56:59 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 13:33:01 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Segaert", "K.", ""], ["Lucas", "S. J. E.", ""], ["Burley", "C. V.", ""], ["Segaert", "Pieter", ""], ["Milner", "A. E.", ""], ["Ryan", "M.", ""], ["Wheeldon", "L.", ""]]}, {"id": "1801.01577", "submitter": "Liang Zhan", "authors": "Sean D. Conrin, Liang Zhan, Zachery D. Morrissey, Mengqi Xing, Angus\n  Forbes, Pauline Maki, Mohammed R. Milad, Olusola Ajilore, Alex D. Leow", "title": "Sex-by-age differences in the resting-state brain connectivity", "comments": "22 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we developed a novel method for assessing the hierarchical\nmodularity of functional brain networks - the probability associated community\nestimation(PACE). The PACE algorithm is unique in that it permits a dual\nformulation, thus yielding equivalent connectome modular structure regardless\nof whether considering positive or negative edges. This method was rigorously\nvalidated using F1000 and HCP data. We detected novel sex differences in\nresting-state connectivity that were not previously reported. This current\nstudy more thoroughly examined sex differences as a function of age and their\nclinical correlates, with findings supporting a basal configuration framework.\nTo this end, we found that men and women do not significantly differ in the\n22-25 age range. However, these same non-significant differences attained\nstatistical significance in the 26-30 age group, while becoming highly\nstatistically significant in the 31-35 age group. At the most global level,\nareas of diverging sex difference include parts of the prefrontal cortex and\nthe temporal lobe, amygdala, hippocampus, inferior parietal lobule, posterior\ncingulate, and precuneus. Further, we identified statistically different\nself-reported summary scores of inattention, hyperactivity, and anxiety\nproblems between men and women. These self-reports additionally divergently\ninteract with age and the basal configuration between sexes. In sum, our study\nsupports a paradigm change in how we conceptualize the functional connectome,\nshifting away from simple concepts, and towards thinking globally and\nprobabilistically how the brain exhibits dynamic sex-specific connectivity\nconfiguration as a function of age, and the role this sex-by-age configuration\nat rest might play in mental health frequency and presentation, including\nsymptom patterns in depression.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 23:14:27 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Conrin", "Sean D.", ""], ["Zhan", "Liang", ""], ["Morrissey", "Zachery D.", ""], ["Xing", "Mengqi", ""], ["Forbes", "Angus", ""], ["Maki", "Pauline", ""], ["Milad", "Mohammed R.", ""], ["Ajilore", "Olusola", ""], ["Leow", "Alex D.", ""]]}, {"id": "1801.01651", "submitter": "Leonardo L. Gollo", "authors": "Penelope Kale, Andrew Zalesky, Leonardo L. Gollo", "title": "Estimating the impact of structural directionality: How reliable are\n  undirected connectomes?", "comments": "29 pages, 6 figures, 9 supplementary figures, 4 supplementary tables", "journal-ref": "Network Neuroscience (2018)", "doi": "10.1162/NETN_a_00040", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directionality is a fundamental feature of network connections. Most\nstructural brain networks are intrinsically directed because of the nature of\nchemical synapses, which comprise most neuronal connections. Due to limitations\nof non-invasive imaging techniques, the directionality of connections between\nstructurally connected regions of the human brain cannot be confirmed. Hence,\nconnections are represented as undirected, and it is still unknown how this\nlack of directionality affects brain network topology. Using six directed brain\nnetworks from different species and parcellations (cat, mouse, C. elegans, and\nthree macaque networks), we estimate the inaccuracies in network measures\n(degree, betweenness, clustering coefficient, path length, global efficiency,\nparticipation index, and small worldness) associated with the removal of the\ndirectionality of connections. We employ three different methods to render\ndirected brain networks undirected: (i) remove uni-directional connections,\n(ii) add reciprocal connections, and (iii) combine equal numbers of removed and\nadded uni-directional connections. We quantify the extent of inaccuracy in\nnetwork measures introduced through neglecting connection directionality for\nindividual nodes and across the network. We find that the coarse division\nbetween core and peripheral nodes remains accurate for undirected networks.\nHowever, hub nodes differ considerably when directionality is neglected.\nComparing the different methods to generate undirected networks from directed\nones, we generally find that the addition of reciprocal connections (false\npositives) causes larger errors in graph-theoretic measures than the removal of\nthe same number of directed connections (false negatives). These findings\nsuggest that directionality plays an essential role in shaping brain networks\nand highlight some limitations of undirected connectomes.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 07:27:47 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Kale", "Penelope", ""], ["Zalesky", "Andrew", ""], ["Gollo", "Leonardo L.", ""]]}, {"id": "1801.01711", "submitter": "Sacha van Albada", "authors": "Sacha Jennifer van Albada, Christopher J. Rennie, Peter A. Robinson", "title": "Variability of model-free and model-based quantitative measures of EEG", "comments": null, "journal-ref": "J. Integr. Neurosci. 06(02):279-307 (2007)", "doi": "10.1142/S0219635207001520", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extent of intra-individual and inter-individual variability is an\nimportant factor in determining the statistical, and hence possibly clinical,\nsignificance of observed differences in the EEG. This study investigates the\nchanges in classical quantitative EEG (qEEG) measures, as well as of parameters\nobtained by fitting frequency spectra to a continuum model of brain electrical\nactivity. These parameters may have extra variability due to model selection\nand fitting. Besides estimating levels of intra-individual and inter-individual\nvariability, we determine approximate time scales for change in qEEG measures\nand model parameters. This provides an estimate of the recording length needed\nto capture a given percentage of the total intra-individual variability. Also,\nif more precise time scales can be obtained in future, these may aid the\ncharacterization of physiological processes underlying various EEG measures.\nHeterogeneity of the subject group was constrained by testing only healthy\nmales in a narrow age range (mean = 22.3 years, sd = 2.7). Resting eyes-closed\nEEGs of 32 subjects were recorded at weekly intervals over an approximately\nsix-week period. Of these, 13 subjects had follow-up recordings spanning up to\na year. QEEG measures, computed from Cz spectra, were powers in five frequency\nbands, alpha peak frequency, and spectral entropy. Of these, theta, alpha, and\nbeta band powers were most reproducible. Of nine model parameters obtained by\nfitting model predictions to experiment, the most reproducible ones quantified\nthe total power and the time delay between cortex and thalamus. About 95% of\nthe maximum change in spectral parameters was reached within minutes of\nrecording time, implying that repeat recordings are not necessary to capture\nthe bulk of the variability in EEG spectra likely to occur in the resting\neyes-closed state on the scale of a year.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 11:06:06 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["van Albada", "Sacha Jennifer", ""], ["Rennie", "Christopher J.", ""], ["Robinson", "Peter A.", ""]]}, {"id": "1801.01748", "submitter": "Sacha van Albada", "authors": "Sacha Jennifer van Albada, Peter A. Robinson", "title": "Transformation of arbitrary distributions to the normal distribution\n  with application to EEG test-retest reliability", "comments": null, "journal-ref": "J. Neurosci. Methods 161: 205-211 (2007)", "doi": "10.1016/j.jneumeth.2006.11.004", "report-no": null, "categories": "stat.ME q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many variables in the social, physical, and biosciences, including\nneuroscience, are non-normally distributed. To improve the statistical\nproperties of such data, or to allow parametric testing, logarithmic or logit\ntransformations are often used. Box-Cox transformations or ad hoc methods are\nsometimes used for parameters for which no transformation is known to\napproximate normality. However, these methods do not always give good agreement\nwith the Gaussian. A transformation is discussed that maps probability\ndistributions as closely as possible to the normal distribution, with exact\nagreement for continuous distributions. To illustrate, the transformation is\napplied to a theoretical distribution, and to quantitative\nelectroencephalographic (qEEG) measures from repeat recordings of 32 subjects\nwhich are highly non-normal. Agreement with the Gaussian was better than using\nlogarithmic, logit, or Box-Cox transformations. Since normal data have\npreviously been shown to have better test-retest reliability than non-normal\ndata under fairly general circumstances, the implications of our transformation\nfor the test-retest reliability of parameters were investigated. Reliability\nwas shown to improve with the transformation, where the improvement was\ncomparable to that using Box-Cox. An advantage of the general transformation is\nthat it does not require laborious optimization over a range of parameters or a\ncase-specific choice of form.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 13:09:49 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["van Albada", "Sacha Jennifer", ""], ["Robinson", "Peter A.", ""]]}, {"id": "1801.01821", "submitter": "Sacha van Albada", "authors": "Sacha Jennifer van Albada, Richard T. Gray, Peter M. Drysdale, Peter\n  A. Robinson", "title": "Mean-field modeling of the basal ganglia-thalamocortical system. II.\n  Dynamics of parkinsonian oscillations", "comments": null, "journal-ref": "J. Theor. Biol. 257:664-688 (2009)", "doi": "10.1016/j.jtbi.2008.12.013", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal correlates of Parkinson's disease (PD) include a slowing of the\nelectroencephalogram (EEG) and enhanced synchrony at 3-7 and 7-30 Hz in the\nbasal ganglia, thalamus, and cortex. This study describes the dynamics of a\nphysiologically based mean-field model of the basal ganglia-thalamocortical\nsystem, and shows how it accounts for key electrophysiological correlates of\nPD. Its connectivity comprises partially segregated direct and indirect\npathways through the striatum, a hyperdirect pathway involving a\ncorticosubthalamic projection, thalamostriatal feedback, and local inhibition\nin striatum and external pallidum (GPe). In a companion paper, realistic\nsteady-state firing rates were obtained for the healthy state, and after\ndopamine loss modeled by weaker direct and stronger indirect pathways, reduced\nintrapallidal inhibition, lower firing thresholds of the GPe and subthalamic\nnucleus (STN), a stronger striato-GPe projection, and weaker cortical\ninteractions. Here we show that oscillations around 5 and 20 Hz can arise with\na strong indirect pathway, which also increases synchrony throughout the basal\nganglia. Further, increased theta power with nigrostriatal degeneration\ncorrelates with reduced alpha power and peak frequency, matching experiments.\nUnlike the hyperdirect pathway, the indirect pathway sustains oscillations with\nrealistic phase relationships. Changes in basal ganglia responses to transient\nstimuli accord with experimental data. Reduced cortical gains due to both\nnigrostriatal and mesocortical dopamine loss lead to slower cortical activity\nchanges and may be related to bradykinesia. Finally, increased EEG power found\nin some studies may be partly explained by a lower effective GPe firing\nthreshold, reduced GPe-GPe inhibition, and/or weaker intracortical connections\nin PD. Strict separation of the direct and indirect pathways is not necessary\nfor these results.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 16:29:48 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["van Albada", "Sacha Jennifer", ""], ["Gray", "Richard T.", ""], ["Drysdale", "Peter M.", ""], ["Robinson", "Peter A.", ""]]}, {"id": "1801.01822", "submitter": "Sacha van Albada", "authors": "Sacha Jennifer van Albada, Peter A. Robinson", "title": "Mean-field modeling of the basal ganglia-thalamocortical system. I.\n  Firing rates in healthy and parkinsonian states", "comments": null, "journal-ref": "J. Theor. Biol. 257: 642-663 (2009)", "doi": "10.1016/j.jtbi.2008.12.018", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinsonism leads to various electrophysiological changes in the basal\nganglia-thalamocortical system (BGTCS), often including elevated discharge\nrates of the subthalamic nucleus (STN) and the output nuclei, and reduced\nactivity of the globus pallidus external segment (GPe). These rate changes have\nbeen explained qualitatively in terms of the direct/indirect pathway model,\ninvolving projections of distinct striatal populations to the output nuclei and\nGPe. Although these populations partly overlap, evidence suggests dopamine\ndepletion differentially affects cortico-striato-pallidal connection strengths\nto the two pallidal segments. Dopamine loss may also decrease the striatal\nsignal-to-noise ratio, reducing both corticostriatal coupling and striatal\nfiring thresholds. Here we present a mean-field model of the BGTCS with\nstructure and parameter estimates closely based on physiology and anatomy.\nChanges in firing rates due to modeled dopamine loss are compared with\nexperiment. Our results suggest that a stronger indirect pathway, possibly\ncombined with a weakened direct pathway, is compatible with empirical evidence.\nHowever, altered corticostriatal connection strengths are probably not solely\nresponsible for substantially increased STN activity often found. A lower STN\nfiring threshold, weaker intracortical inhibition, and stronger striato-GPe\ninhibition help explain the relatively large increase in STN rate. Changes in\ncortex, GPe, and STN help normalize the cortical rate, also in accord with\nexperiments. The model integrates the basal ganglia into a unified framework\nalong with an existing thalamocortical model that accounts for a wide range of\nelectrophysiological phenomena. A companion paper discusses the dynamics and\noscillations of this combined system.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 16:31:42 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["van Albada", "Sacha Jennifer", ""], ["Robinson", "Peter A.", ""]]}, {"id": "1801.01823", "submitter": "Ulisse Ferrari", "authors": "Ulisse Ferrari, Stephane Deny, Matthew Chalk, Gasper Tkacik, Olivier\n  Marre, Thierry Mora", "title": "Separating intrinsic interactions from extrinsic correlations in a\n  network of sensory neurons", "comments": null, "journal-ref": "Phys. Rev. E 98, 042410 (2018)", "doi": "10.1103/PhysRevE.98.042410", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlations in sensory neural networks have both extrinsic and intrinsic\norigins. Extrinsic or stimulus correlations arise from shared inputs to the\nnetwork, and thus depend strongly on the stimulus ensemble. Intrinsic or noise\ncorrelations reflect biophysical mechanisms of interactions between neurons,\nwhich are expected to be robust to changes of the stimulus ensemble. Despite\nthe importance of this distinction for understanding how sensory networks\nencode information collectively, no method exists to reliably separate\nintrinsic interactions from extrinsic correlations in neural activity data,\nlimiting our ability to build predictive models of the network response. In\nthis paper we introduce a general strategy to infer {population models of\ninteracting neurons that collectively encode stimulus information}. The key to\ndisentangling intrinsic from extrinsic correlations is to infer the {couplings\nbetween neurons} separately from the encoding model, and to combine the two\nusing corrections calculated in a mean-field approximation. We demonstrate the\neffectiveness of this approach on retinal recordings. The same coupling network\nis inferred from responses to radically different stimulus ensembles, showing\nthat these couplings indeed reflect stimulus-independent interactions between\nneurons. The inferred model predicts accurately the collective response of\nretinal ganglion cell populations as a function of the stimulus.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 16:36:56 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 15:54:44 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Ferrari", "Ulisse", ""], ["Deny", "Stephane", ""], ["Chalk", "Matthew", ""], ["Tkacik", "Gasper", ""], ["Marre", "Olivier", ""], ["Mora", "Thierry", ""]]}, {"id": "1801.01853", "submitter": "Trang-Anh Estelle Nghiem", "authors": "Trang-Anh Nghiem, Bartosz Telenczuk, Olivier Marre, Alain Destexhe,\n  Ulisse Ferrari", "title": "Maximum entropy models reveal the excitatory and inhibitory correlation\n  structures in cortical neuronal activity", "comments": "17 pages, 11 figures (including 5 supplementary)", "journal-ref": "Phys. Rev. E 98, 012402 (2018)", "doi": "10.1103/PhysRevE.98.012402", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum Entropy models can be inferred from large data-sets to uncover how\ncollective dynamics emerge from local interactions. Here, such models are\nemployed to investigate neurons recorded by multielectrode arrays in the human\nand monkey cortex. Taking advantage of the separation of excitatory and\ninhibitory neuron types, we construct a model including this distinction. This\napproach allows to shed light upon differences between excitatory and\ninhibitory activity across different brain states such as wakefulness and deep\nsleep, in agreement with previous findings. Additionally, Maximum Entropy\nmodels can also unveil novel features of neuronal interactions, which are found\nto be dominated by pairwise interactions during wakefulness, but are\npopulation-wide during deep sleep. In particular, inhibitory neurons are\nobserved to be strongly tuned to the inhibitory population. Overall, we\ndemonstrate Maximum Entropy models can be useful to analyze data-sets with\nclassified neuron types, and to reveal the respective roles of excitatory and\ninhibitory neurons in organizing coherent dynamics in the cerebral cortex.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 17:49:05 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 17:34:49 GMT"}, {"version": "v3", "created": "Tue, 10 Jul 2018 13:25:59 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Nghiem", "Trang-Anh", ""], ["Telenczuk", "Bartosz", ""], ["Marre", "Olivier", ""], ["Destexhe", "Alain", ""], ["Ferrari", "Ulisse", ""]]}, {"id": "1801.01913", "submitter": "Federico Battiston", "authors": "Federico Battiston, Jeremy Guillon, Mario Chavez, Vito Latora,\n  Fabrizio De Vico Fallani", "title": "Multiplex core-periphery organization of the human connectome", "comments": "Main text (12 pages, 5 figures) + Supplementary material (6 pages, 5\n  figures, 1 table)", "journal-ref": "J. R. Soc. Interface 2018", "doi": "10.1098/rsif.2018.0514", "report-no": null, "categories": "q-bio.NC cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of many complex systems is determined by a core of densely\ninterconnected units. While many methods are available to identify the core of\na network when connections between nodes are all of the same type, a principled\napproach to define the core when multiple types of connectivity are allowed is\nstill lacking. Here we introduce a general framework to define and extract the\ncore-periphery structure of multi-layer networks by explicitly taking into\naccount the connectivity of the nodes at each layer. We show how our method\nworks on synthetic networks with different size, density, and overlap between\nthe cores at the different layers. We then apply the method to multiplex brain\nnetworks whose layers encode information both on the anatomical and the\nfunctional connectivity among regions of the human cortex. Results confirm the\npresence of the main known hubs, but also suggest the existence of novel brain\ncore regions that have been discarded by previous analysis which focused\nexclusively on the structural layer. Our work is a step forward in the\nidentification of the core of the human connectome, and contributes to shed\nlight to a fundamental question in modern neuroscience.\n", "versions": [{"version": "v1", "created": "Sat, 23 Dec 2017 16:03:45 GMT"}], "update_date": "2018-09-14", "authors_parsed": [["Battiston", "Federico", ""], ["Guillon", "Jeremy", ""], ["Chavez", "Mario", ""], ["Latora", "Vito", ""], ["Fallani", "Fabrizio De Vico", ""]]}, {"id": "1801.02256", "submitter": "Ernest Greene", "authors": "Ernest Greene", "title": "Rapid de novo shape encoding: a challenge to connectionist modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Neural network (connectionist) models are designed to encode image features\nand provide the building blocks for object and shape recognition. These models\ngenerally call for: a) initial diffuse connections from one neuron population\nto another, and b) training to bring about a functional change in those\nconnections so that one or more high-tier neurons will selectively respond to a\nspecific shape stimulus. Advanced models provide for translation, size, and\nrotation invariance. The present discourse notes that recent work on human\nperceptual skills has demonstrated immediate encoding of unknown shapes that\nwere seen only once. Further, the perceptual mechanism provided for\ntranslation, size, and rotation invariance. This finding represents a challenge\nto connectionist models that require many training trials to achieve\nrecognition and invariance.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 21:47:29 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Greene", "Ernest", ""]]}, {"id": "1801.02304", "submitter": "Alex Kunin", "authors": "Vladimir Itskov, Alex Kunin, Zvi Rosen", "title": "Hyperplane Neural Codes and the Polar Complex", "comments": "23 pages, 5 figures. To appear in Proceedings of the Abel Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperplane codes are a class of convex codes that arise as the output of a\none layer feed-forward neural network. Here we establish several natural\nproperties of stable hyperplane codes in terms of the {\\it polar complex} of\nthe code, a simplicial complex associated to any combinatorial code. We prove\nthat the polar complex of a stable hyperplane code is shellable and show that\nmost currently known properties of the hyperplane codes follow from the\nshellability of the appropriate polar complex.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 04:03:17 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 22:25:43 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 18:42:52 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Itskov", "Vladimir", ""], ["Kunin", "Alex", ""], ["Rosen", "Zvi", ""]]}, {"id": "1801.02472", "submitter": "Meysam Golmohammadi", "authors": "Vinit Shah, Meysam Golmohammadi, Saeedeh Ziyabari, Eva Von Weltin,\n  Iyad Obeid and Joseph Picone", "title": "Optimizing Channel Selection for Seizure Detection", "comments": "Published in Dec 2017 publication IEEE Signal Processing in Medicine\n  and Biology Symposium. Philadelphia, Pennsylvania, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpretation of electroencephalogram (EEG) signals can be complicated by\nobfuscating artifacts. Artifact detection plays an important role in the\nobservation and analysis of EEG signals. Spatial information contained in the\nplacement of the electrodes can be exploited to accurately detect artifacts.\nHowever, when fewer electrodes are used, less spatial information is available,\nmaking it harder to detect artifacts. In this study, we investigate the\nperformance of a deep learning algorithm, CNN-LSTM, on several channel\nconfigurations. Each configuration was designed to minimize the amount of\nspatial information lost compared to a standard 22-channel EEG. Systems using a\nreduced number of channels ranging from 8 to 20 achieved sensitivities between\n33% and 37% with false alarms in the range of [38, 50] per 24 hours. False\nalarms increased dramatically (e.g., over 300 per 24 hours) when the number of\nchannels was further reduced. Baseline performance of a system that used all 22\nchannels was 39% sensitivity with 23 false alarms. Since the 22-channel system\nwas the only system that included referential channels, the rapid increase in\nthe false alarm rate as the number of channels was reduced underscores the\nimportance of retaining referential channels for artifact reduction. This\ncautionary result is important because one of the biggest differences between\nvarious types of EEGs administered is the type of referential channel used.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 00:59:32 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Shah", "Vinit", ""], ["Golmohammadi", "Meysam", ""], ["Ziyabari", "Saeedeh", ""], ["Von Weltin", "Eva", ""], ["Obeid", "Iyad", ""], ["Picone", "Joseph", ""]]}, {"id": "1801.02549", "submitter": "Mahmoud Hassan", "authors": "M. Hassan and F. Wendling", "title": "Electroencephalography source connectivity: toward high time/space\n  resolution brain networks", "comments": "Accepted in the IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain is a large-scale network which function depends on dynamic\ninteractions between spatially-distributed regions. In the rapidly-evolving\nfield of network neuroscience, two yet unresolved challenges are potential\nbreakthroughs. First, functional brain networks should be estimated from\nnoninvasive and easy to use neuroimaging techniques. Second, the time/space\nresolution of these techniques should be high enough to assess the dynamics of\nidentified networks. Emerging evidence suggests that Electroencephalography\n(EEG) source connectivity method may offer solutions to both issues provided\nthat scalp EEG signals are appropriately processed. Therefore, the performance\nof EEG source connectivity method strongly depends on signal processing (SP)\nthat involves various methods such as preprocessing techniques, inverse\nsolutions, statistical couplings between signals and network science. The main\nobjective of this tutorial-like review is to provide an overview on EEG source\nconnectivity. We describe the major contributions that the SP community brought\nto this research field. We emphasize the methodological issues that need to be\ncarefully addressed to obtain relevant results and we stress the current\nlimitations that need further investigation. We also report results obtained in\nconcrete applications, in both normal and pathological brain states. Future\ndirections in term of signal processing methods and applications are eventually\nprovided\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 16:47:59 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Hassan", "M.", ""], ["Wendling", "F.", ""]]}, {"id": "1801.02645", "submitter": "Kaare Mikkelsen", "authors": "Kaare Mikkelsen and Maarten de Vos", "title": "Personalizing deep learning models for automatic sleep staging", "comments": "9 pages, 7 figures, journal submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite continued advancement in machine learning algorithms and increasing\navailability of large data sets, there is still no universally acceptable\nsolution for automatic sleep staging of human sleep recordings. One reason is\nthat a skilled neurophysiologist scoring brain recordings of a sleeping person\nimplicitly adapts his/her staging to the individual characteristics present in\nthe brain recordings. Trying to incorporate this adaptation step in an\nautomatic scoring algorithm, we introduce in this paper a method for\npersonalizing a general sleep scoring model. Starting from a general\nconvolutional neural network architecture, we allow the model to learn\nindividual characteristics of the first night of sleep in order to quantify\nsleep stages of the second night. While the original neural network allows to\nsleep stage on a public database with a state of the art accuracy,\npersonalizing the model further increases performance (on the order of two\npercentage points on average, but more for difficult subjects). This\nimprovement is particularly present in subjects where the original algorithm\ndid not perform well (typically subjects with accuracy less than $80\\%$).\nLooking deeper, we find that optimal classification can be achieved when broad\nknowledge of sleep staging in general (at least 20 separate nights) is combined\nwith subject-specific knowledge. We hypothesize that this method will be very\nvaluable for improving scoring of lower quality sleep recordings, such as those\nfrom wearable devices.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 19:08:17 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Mikkelsen", "Kaare", ""], ["de Vos", "Maarten", ""]]}, {"id": "1801.02657", "submitter": "Ernest Greene", "authors": "Ernest Greene, Onyinye Onwuzulike", "title": "What constitutes elemental shape information for biological vision?", "comments": "Five pages, three figures, 19 references", "journal-ref": "Trends in Artificial Intelligence, 2017, 1 (1) 22-26", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We do not yet understand how the vertebrate visual system provides for\nrecognition of ob- jects. Countless experiments have been performed to examine\nthe contribution of cues such as color, texture, and shadowing, but the most\nimportant cues are the con- tours of the outer boundary. Most objects that we\ncan name can be identified as a silhouette, or equally well as a line drawing\nof the boundary. This has long been ap- preciated, so it is somewhat surprising\nthat after more than a century of experimental research, we have not yet\nestablished how our visual system encodes this shape in- formation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 19:38:59 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Greene", "Ernest", ""], ["Onwuzulike", "Onyinye", ""]]}, {"id": "1801.02730", "submitter": "Mario Michael Krell", "authors": "Mario Michael Krell, Anett Seeland, Su Kyoung Kim", "title": "Data Augmentation for Brain-Computer Interfaces: Analysis on\n  Event-Related Potentials Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On image data, data augmentation is becoming less relevant due to the large\namount of available training data and regularization techniques. Common\napproaches are moving windows (cropping), scaling, affine distortions, random\nnoise, and elastic deformations. For electroencephalographic data, the lack of\nsufficient training data is still a major issue. We suggest and evaluate\ndifferent approaches to generate augmented data using temporal and\nspatial/rotational distortions. Our results on the perception of rare stimuli\n(P300 data) and movement prediction (MRCP data) show that these approaches are\nfeasible and can significantly increase the performance of signal processing\nchains for brain-computer interfaces by 1% to 6%.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 00:34:34 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Krell", "Mario Michael", ""], ["Seeland", "Anett", ""], ["Kim", "Su Kyoung", ""]]}, {"id": "1801.03268", "submitter": "Ming Song", "authors": "Ming Song, Yi Yang, Jianghong He, Zhengyi Yang, Shan Yu, Qiuyou Xie,\n  Xiaoyu Xia, Yuanyuan Dang, Qiang Zhang, Xinhuai Wu, Yue Cui, Bing Hou,\n  Ronghao Yu, Ruxiang Xu, Tianzi Jiang", "title": "Prognostication of chronic disorders of consciousness using brain\n  functional networks and clinical characteristics", "comments": "Although some prognostic indicators and models have been proposed for\n  disorders of consciousness, each single method when used alone carries risks\n  of false prediction. Song et al. report that a model combining resting state\n  functional MRI with clinical characteristics provided accurate, robust, and\n  interpretable prognostications. 52 pages, 1 table, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Disorders of consciousness are a heterogeneous mixture of different diseases\nor injuries. Although some indicators and models have been proposed for\nprognostication, any single method when used alone carries a high risk of false\nprediction. This study aimed to develop a multidomain prognostic model that\ncombines resting state functional MRI with three clinical characteristics to\npredict one year outcomes at the single-subject level. The model discriminated\nbetween patients who would later recover consciousness and those who would not\nwith an accuracy of around 90% on three datasets from two medical centers. It\nwas also able to identify the prognostic importance of different predictors,\nincluding brain functions and clinical characteristics. To our knowledge, this\nis the first implementation reported of a multidomain prognostic model based on\nresting state functional MRI and clinical characteristics in chronic disorders\nof consciousness. We therefore suggest that this novel prognostic model is\naccurate, robust, and interpretable.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 08:35:48 GMT"}, {"version": "v2", "created": "Thu, 22 Feb 2018 01:46:52 GMT"}, {"version": "v3", "created": "Fri, 7 Sep 2018 01:29:06 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Song", "Ming", ""], ["Yang", "Yi", ""], ["He", "Jianghong", ""], ["Yang", "Zhengyi", ""], ["Yu", "Shan", ""], ["Xie", "Qiuyou", ""], ["Xia", "Xiaoyu", ""], ["Dang", "Yuanyuan", ""], ["Zhang", "Qiang", ""], ["Wu", "Xinhuai", ""], ["Cui", "Yue", ""], ["Hou", "Bing", ""], ["Yu", "Ronghao", ""], ["Xu", "Ruxiang", ""], ["Jiang", "Tianzi", ""]]}, {"id": "1801.03610", "submitter": "David Ahmedt Aristizabal", "authors": "David Ahmedt-Aristizabal, Clinton Fookes, Kien Nguyen, Sridha\n  Sridharan", "title": "Deep Classification of Epileptic Signals", "comments": "4 pages, 3 figures", "journal-ref": "In Proceedings of the IEEE International Conference of Engineering\n  in Medicine and Biology Society. 2018", "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrophysiological observation plays a major role in epilepsy evaluation.\nHowever, human interpretation of brain signals is subjective and prone to\nmisdiagnosis. Automating this process, especially seizure detection relying on\nscalp-based Electroencephalography (EEG) and intracranial EEG, has been the\nfocus of research over recent decades. Nevertheless, its numerous challenges\nhave inhibited a definitive solution. Inspired by recent advances in deep\nlearning, we propose a new classification approach for EEG time series based on\nRecurrent Neural Networks (RNNs) via the use of Long-Short Term Memory (LSTM)\nnetworks. The proposed deep network effectively learns and models\ndiscriminative temporal patterns from EEG sequential data. Especially, the\nfeatures are automatically discovered from the raw EEG data without any\npre-processing step, eliminating humans from laborious feature design task. We\nalso show that, in the epilepsy scenario, simple architectures can achieve\ncompetitive performance. Using simple architectures significantly benefits in\nthe practical scenario considering their low computation complexity and reduced\nrequirement for large training datasets. Using a public dataset, a multi-fold\ncross-validation scheme exhibited an average validation accuracy of 95.54\\% and\nan average AUC of 0.9582 of the ROC curve among all sets defined in the\nexperiment. This work reinforces the benefits of deep learning to be further\nattended in clinical applications and neuroscientific research.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 01:58:42 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Ahmedt-Aristizabal", "David", ""], ["Fookes", "Clinton", ""], ["Nguyen", "Kien", ""], ["Sridharan", "Sridha", ""]]}, {"id": "1801.03880", "submitter": "Xerxes D. Arsiwalla", "authors": "Xerxes D. Arsiwalla and Paul Verschure", "title": "Measuring the Complexity of Consciousness", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quest for a scientific description of consciousness has given rise to new\ntheoretical and empirical paradigms for the investigation of phenomenological\ncontents as well as clinical disorders of consciousness. An outstanding\nchallenge in the field is to develop measures that uniquely quantify global\nbrain states tied to consciousness. In particular, information-theoretic\ncomplexity measures such as integrated information have recently been proposed\nas measures of conscious awareness. This suggests a new framework to\nquantitatively classify states of consciousness. However, it has proven\nincreasingly difficult to apply these complexity measures to realistic brain\nnetworks. In part, this is due to high computational costs incurred when\nimplementing these measures on realistically large network dimensions.\nNonetheless, complexity measures for quantifying states of consciousness are\nimportant for assisting clinical diagnosis and therapy. This article is meant\nto serve as a lookup table of measures of consciousness, with particular\nemphasis on clinical applicability of these measures. We consider both,\nprinciple-based complexity measures as well as empirical measures tested on\npatients. We address challenges facing these measures with regard to realistic\nbrain networks, and where necessary, suggest possible resolutions.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 17:18:42 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Arsiwalla", "Xerxes D.", ""], ["Verschure", "Paul", ""]]}, {"id": "1801.03984", "submitter": "Mufti Mahmud", "authors": "Mufti Mahmud, M. Shamim Kaiser, M. Mostafizur Rahman, M. Arifur\n  Rahman, Antesar Shabut, Shamim Al-Mamun and Amir Hussain", "title": "A Brain-Inspired Trust Management Model to Assure Security in a Cloud\n  based IoT Framework for Neuroscience Applications", "comments": "17 pages, 10 figures, 2 tables", "journal-ref": "Cognitive Computation, 2018", "doi": "10.1007/s12559-018-9543-3", "report-no": null, "categories": "cs.CR cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Rapid popularity of Internet of Things (IoT) and cloud computing permits\nneuroscientists to collect multilevel and multichannel brain data to better\nunderstand brain functions, diagnose diseases, and devise treatments. To ensure\nsecure and reliable data communication between end-to-end (E2E) devices\nsupported by current IoT and cloud infrastructure, trust management is needed\nat the IoT and user ends. This paper introduces a Neuro-Fuzzy based\nBrain-inspired trust management model (TMM) to secure IoT devices and relay\nnodes, and to ensure data reliability. The proposed TMM utilizes node\nbehavioral trust and data trust estimated using Adaptive Neuro-Fuzzy Inference\nSystem and weighted-additive methods respectively to assess the nodes\ntrustworthiness. In contrast to the existing fuzzy based TMMs, the NS2\nsimulation results confirm the robustness and accuracy of the proposed TMM in\nidentifying malicious nodes in the communication network. With the growing\nusage of cloud based IoT frameworks in Neuroscience research, integrating the\nproposed TMM into the existing infrastructure will assure secure and reliable\ndata communication among the E2E devices.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 20:45:01 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Mahmud", "Mufti", ""], ["Kaiser", "M. Shamim", ""], ["Rahman", "M. Mostafizur", ""], ["Rahman", "M. Arifur", ""], ["Shabut", "Antesar", ""], ["Al-Mamun", "Shamim", ""], ["Hussain", "Amir", ""]]}, {"id": "1801.04510", "submitter": "Jia Wu", "authors": "Chenglong Dai, Jia Wu, Dechang Pi, Lin Cui", "title": "Brain EEG Time Series Selection: A Novel Graph-Based Approach for\n  Classification", "comments": "9 pages, 5 figures, Accepted by SDM-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain Electroencephalography (EEG) classification is widely applied to\nanalyze cerebral diseases in recent years. Unfortunately, invalid/noisy EEGs\ndegrade the diagnosis performance and most previously developed methods ignore\nthe necessity of EEG selection for classification. To this end, this paper\nproposes a novel maximum weight clique-based EEG selection approach, named\nmwcEEGs, to map EEG selection to searching maximum similarity-weighted cliques\nfrom an improved Fr\\'{e}chet distance-weighted undirected EEG graph\nsimultaneously considering edge weights and vertex weights. Our mwcEEGs\nimproves the classification performance by selecting intra-clique pairwise\nsimilar and inter-clique discriminative EEGs with similarity threshold\n$\\delta$. Experimental results demonstrate the algorithm effectiveness compared\nwith the state-of-the-art time series selection algorithms on real-world EEG\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 04:51:22 GMT"}, {"version": "v2", "created": "Fri, 9 Feb 2018 06:19:21 GMT"}], "update_date": "2018-02-12", "authors_parsed": [["Dai", "Chenglong", ""], ["Wu", "Jia", ""], ["Pi", "Dechang", ""], ["Cui", "Lin", ""]]}, {"id": "1801.04515", "submitter": "Ueli Rutishauser", "authors": "Ueli Rutishauser, Jean-Jacques Slotine, Rodney J. Douglas", "title": "Solving constraint-satisfaction problems with distributed\n  neocortical-like neuronal networks", "comments": "Accepted manuscript, in press, Neural Computation (2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding actions that satisfy the constraints imposed by both external inputs\nand internal representations is central to decision making. We demonstrate that\nsome important classes of constraint satisfaction problems (CSPs) can be solved\nby networks composed of homogeneous cooperative-competitive modules that have\nconnectivity similar to motifs observed in the superficial layers of neocortex.\nThe winner-take-all modules are sparsely coupled by programming neurons that\nembed the constraints onto the otherwise homogeneous modular computational\nsubstrate. We show rules that embed any instance of the CSPs planar four-color\ngraph coloring, maximum independent set, and Sudoku on this substrate, and\nprovide mathematical proofs that guarantee these graph coloring problems will\nconvergence to a solution. The network is composed of non-saturating linear\nthreshold neurons. Their lack of right saturation allows the overall network to\nexplore the problem space driven through the unstable dynamics generated by\nrecurrent excitation. The direction of exploration is steered by the constraint\nneurons. While many problems can be solved using only linear inhibitory\nconstraints, network performance on hard problems benefits significantly when\nthese negative constraints are implemented by non-linear multiplicative\ninhibition. Overall, our results demonstrate the importance of instability\nrather than stability in network computation, and also offer insight into the\ncomputational role of dual inhibitory mechanisms in neural circuits.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 05:44:36 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Rutishauser", "Ueli", ""], ["Slotine", "Jean-Jacques", ""], ["Douglas", "Rodney J.", ""]]}, {"id": "1801.04623", "submitter": "Danielle Bassett", "authors": "Eli J. Cornblath, Evelyn Tang, Graham L. Baum, Tyler M. Moore, David\n  R. Roalf, Ruben C. Gur, Raquel E. Gur, Fabio Pasqualetti, Theodore D.\n  Satterthwaite, Danielle S. Bassett", "title": "Sex differences in network controllability as a predictor of executive\n  function in youth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Executive function emerges late in development and displays different\ndevelopmental trends in males and females. Sex differences in executive\nfunction in youth have been linked to vulnerability to psychopathology as well\nas to behaviors that impinge on health. Yet, the neurobiological basis of these\ndifferences is not well understood. Here we test the hypothesis that sex\ndifferences in executive function in youth stem from sex differences in the\ncontrollability of structural brain networks as they rewire over development.\nCombining methods from network neuroscience and network control theory, we\ncharacterize the network control properties of structural brain networks\nestimated from diffusion imaging data acquired in males and females in a sample\nof 882 youth aged 8-22 years. We summarize the control properties of these\nnetworks by estimating average and modal controllability, two statistics that\nprobe the ease with which brain areas can drive the network towards easy-\nversus difficult-to-reach states. We find that females have higher modal\ncontrollability in frontal, parietal, and subcortical regions while males have\nhigher average controllability in frontal and subcortical regions. Furthermore,\naverage controllability values in the medial frontal cortex and subcortex, both\nhigher in males, are negatively related to executive function. Finally, we find\nthat average controllability predicts sex-dependent individual differences in\nactivation during an n-back working memory task. Taken together, our findings\nsupport the notion that sex differences in the controllability of structural\nbrain networks can partially explain sex differences in executive function.\nControllability of structural brain networks also predicts features of\ntask-relevant activation, suggesting the potential for controllability to\nrepresent context-specific constraints on network state more generally.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 00:10:29 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Cornblath", "Eli J.", ""], ["Tang", "Evelyn", ""], ["Baum", "Graham L.", ""], ["Moore", "Tyler M.", ""], ["Roalf", "David R.", ""], ["Gur", "Ruben C.", ""], ["Gur", "Raquel E.", ""], ["Pasqualetti", "Fabio", ""], ["Satterthwaite", "Theodore D.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1801.04631", "submitter": "Lawrence Ward", "authors": "Peter H. Baxendale and Priscilla E. Greenwood and Lawrence M. Ward", "title": "Noise Sharing and Mexican Hat Coupling in a Stochastic Neural Field", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": "10.1103/PhysRevE.100.022130", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A diffusion-type coupling operator biologically significant in neuroscience\nis a difference of Gaussian functions (Mexican Hat operator) used as a\nspatial-convolution kernel. We are interested in pattern formation by\n\\emph{stochastic} neural field equations, a class of space-time stochastic\ndifferential-integral equations using the Mexican Hat kernel. We explore,\nquantitatively, how the parameters that control the shape of the coupling\nkernel, coupling strength, and aspects of spatially-smoothed space-time noise,\ninfluence the pattern in the resulting evolving random field. We confirm that a\nspatial pattern that is damped in time in a deterministic system may be\nsustained and amplified by stochasticity. We find that spatially-smoothed noise\nalone causes pattern formation even without direct spatial coupling. Our\nanalysis of the interaction between coupling and noise sharing allows us to\ndetermine parameter combinations that are optimal for the formation of spatial\npattern.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 00:52:36 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 21:55:14 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Baxendale", "Peter H.", ""], ["Greenwood", "Priscilla E.", ""], ["Ward", "Lawrence M.", ""]]}, {"id": "1801.04778", "submitter": "Mario Chavez Mr", "authors": "Mario Chavez and Bernard Cazelles", "title": "Detecting dynamic spatial correlation patterns with generalized wavelet\n  coherence and non-stationary surrogate data", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time series measured from real-world systems are generally noisy, complex and\ndisplay statistical properties that evolve continuously over time. Here, we\npresent a method that combines wavelet analysis and non-stationary surrogates\nto detect short-lived spatial coherent patterns from multivari- ate\ntime-series. In contrast with standard methods, the surrogate data used here\nare realisations of a non-stationary stochastic process, preserving both the\namplitude and time-frequency distributions of original data. We evaluate this\nframework on synthetic and real-world time series, and we show that it can\nprovide useful insights into the time-resolved structure of spatially extended\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 12:51:25 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 08:43:58 GMT"}], "update_date": "2018-04-12", "authors_parsed": [["Chavez", "Mario", ""], ["Cazelles", "Bernard", ""]]}, {"id": "1801.04819", "submitter": "Matej Hoffmann", "authors": "Matej Hoffmann and Rolf Pfeifer", "title": "Robots as Powerful Allies for the Study of Embodied Cognition from the\n  Bottom Up", "comments": "22 pages, 3 figures", "journal-ref": "in A. Newen, L. de Bruin; & S. Gallagher, ed., 'The Oxford\n  Handbook 4e Cognition', Oxford University Press, pp. 841-862 (2018)", "doi": "10.1093/oxfordhb/9780198735410.013.45", "report-no": null, "categories": "cs.AI cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large body of compelling evidence has been accumulated demonstrating that\nembodiment - the agent's physical setup, including its shape, materials,\nsensors and actuators - is constitutive for any form of cognition and as a\nconsequence, models of cognition need to be embodied. In contrast to methods\nfrom empirical sciences to study cognition, robots can be freely manipulated\nand virtually all key variables of their embodiment and control programs can be\nsystematically varied. As such, they provide an extremely powerful tool of\ninvestigation. We present a robotic bottom-up or developmental approach,\nfocusing on three stages: (a) low-level behaviors like walking and reflexes,\n(b) learning regularities in sensorimotor spaces, and (c) human-like cognition.\nWe also show that robotic based research is not only a productive path to\ndeepening our understanding of cognition, but that robots can strongly benefit\nfrom human-like cognition in order to become more autonomous, robust,\nresilient, and safe.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 14:29:14 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 18:45:52 GMT"}], "update_date": "2020-04-03", "authors_parsed": [["Hoffmann", "Matej", ""], ["Pfeifer", "Rolf", ""]]}, {"id": "1801.05017", "submitter": "Chendi Wang", "authors": "Chendi Wang, Rafeef Abugharbieh", "title": "Hypergraph based Subnetwork Extraction using Fusion of Task and Rest\n  Functional Connectivity", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional subnetwork extraction is commonly used to explore the brain's\nmodular structure. However, reliable subnetwork extraction from functional\nmagnetic resonance imaging (fMRI) data remains challenging due to the\npronounced noise in neuroimaging data. In this paper, we proposed a high order\nrelation informed approach based on hypergraph to combine the information from\nmulti-task data and resting state data to improve subnetwork extraction. Our\nassumption is that task data can be beneficial for the subnetwork extraction\nprocess, since the repeatedly activated nodes involved in diverse tasks might\nbe the canonical network components which comprise pre-existing repertoires of\nresting state subnetworks. Our proposed high order relation informed subnetwork\nextraction based on a strength information embedded hypergraph, (1) facilitates\nthe multisource integration for subnetwork extraction, (2) utilizes information\non relationships and changes between the nodes across different tasks, and (3)\nenables the study on higher order relations among brain network nodes. On real\ndata, we demonstrated that fusing task activation, task-induced connectivity\nand resting state functional connectivity based on hypergraphs improves\nsubnetwork extraction compared to employing a single source from either rest or\ntask data in terms of subnetwork modularity measure, inter-subject\nreproducibility, along with more biologically meaningful subnetwork\nassignments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 21:17:37 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Wang", "Chendi", ""], ["Abugharbieh", "Rafeef", ""]]}, {"id": "1801.05116", "submitter": "Roman Sandler", "authors": "Roman A. Sandler, Kunling Geng, Dong Song, Robert E. Hampson, Mark R.\n  Witcher, Sam A. Deadwyler, Theodore W. Berger, Vasilis Z. Marmarelis", "title": "Designing Patient-Specific Optimal Neurostimulation Patterns for Seizure\n  Suppression", "comments": null, "journal-ref": "Neural.Computation 30.5 (2018) 1180-1208", "doi": "10.1162/neco_a_01075", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurostimulation is a promising therapy for abating epileptic seizures.\nHowever, it is extremely difficult to identify optimal stimulation patterns\nexperimentally. In this study human recordings are used to develop a functional\n24 neuron network statistical model of hippocampal connectivity and dynamics.\nSpontaneous seizure-like activity is induced in-silico in this reconstructed\nneuronal network. The network is then used as a testbed to design and validate\na wide range of neurostimulation patterns. Commonly used periodic trains were\nnot able to permanently abate seizures at any frequency. A simulated annealing\nglobal optimization algorithm was then used to identify an optimal stimulation\npattern which successfully abated 92% of seizures. Finally, in a fully\nresponsive, or \"closed-loop\" neurostimulation paradigm, the optimal stimulation\nsuccessfully prevented the network from entering the seizure state. We propose\nthat the framework presented here for algorithmically identifying\npatient-specific neurostimulation patterns can greatly increase the efficacy of\nneurostimulation devices for seizures.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 04:59:25 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Sandler", "Roman A.", ""], ["Geng", "Kunling", ""], ["Song", "Dong", ""], ["Hampson", "Robert E.", ""], ["Witcher", "Mark R.", ""], ["Deadwyler", "Sam A.", ""], ["Berger", "Theodore W.", ""], ["Marmarelis", "Vasilis Z.", ""]]}, {"id": "1801.05151", "submitter": "Kai Qiao", "authors": "Chi Zhang, Kai Qiao, Linyuan Wang, Li Tong, Ying Zeng, Bin Yan", "title": "Constraint-free Natural Image Reconstruction from fMRI Signals Based on\n  Convolutional Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, research on decoding brain activity based on functional\nmagnetic resonance imaging (fMRI) has made remarkable achievements. However,\nconstraint-free natural image reconstruction from brain activity is still a\nchallenge. The existing methods simplified the problem by using semantic prior\ninformation or just reconstructing simple images such as letters and digitals.\nWithout semantic prior information, we present a novel method to reconstruct\nnature images from fMRI signals of human visual cortex based on the computation\nmodel of convolutional neural network (CNN). Firstly, we extracted the units\noutput of viewed natural images in each layer of a pre-trained CNN as CNN\nfeatures. Secondly, we transformed image reconstruction from fMRI signals into\nthe problem of CNN feature visualizations by training a sparse linear\nregression to map from the fMRI patterns to CNN features. By iteratively\noptimization to find the matched image, whose CNN unit features become most\nsimilar to those predicted from the brain activity, we finally achieved the\npromising results for the challenging constraint-free natural image\nreconstruction. As there was no use of semantic prior information of the\nstimuli when training decoding model, any category of images (not constraint by\nthe training set) could be reconstructed theoretically. We found that the\nreconstructed images resembled the natural stimuli, especially in position and\nshape. The experimental results suggest that hierarchical visual features can\neffectively express the visual perception process of human brain.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 08:34:18 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Zhang", "Chi", ""], ["Qiao", "Kai", ""], ["Wang", "Linyuan", ""], ["Tong", "Li", ""], ["Zeng", "Ying", ""], ["Yan", "Bin", ""]]}, {"id": "1801.05219", "submitter": "Dane Corneil", "authors": "Wulfram Gerstner, Marco Lehmann, Vasiliki Liakoni, Dane Corneil, and\n  Johanni Brea", "title": "Eligibility Traces and Plasticity on Behavioral Time Scales:\n  Experimental Support of neoHebbian Three-Factor Learning Rules", "comments": null, "journal-ref": null, "doi": "10.3389/fncir.2018.00053", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most elementary behaviors such as moving the arm to grasp an object or\nwalking into the next room to explore a museum evolve on the time scale of\nseconds; in contrast, neuronal action potentials occur on the time scale of a\nfew milliseconds. Learning rules of the brain must therefore bridge the gap\nbetween these two different time scales.\n  Modern theories of synaptic plasticity have postulated that the co-activation\nof pre- and postsynaptic neurons sets a flag at the synapse, called an\neligibility trace, that leads to a weight change only if an additional factor\nis present while the flag is set. This third factor, signaling reward,\npunishment, surprise, or novelty, could be implemented by the phasic activity\nof neuromodulators or specific neuronal inputs signaling special events. While\nthe theoretical framework has been developed over the last decades,\nexperimental evidence in support of eligibility traces on the time scale of\nseconds has been collected only during the last few years.\n  Here we review, in the context of three-factor rules of synaptic plasticity,\nfour key experiments that support the role of synaptic eligibility traces in\ncombination with a third factor as a biological implementation of neoHebbian\nthree-factor learning rules.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 12:08:03 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Gerstner", "Wulfram", ""], ["Lehmann", "Marco", ""], ["Liakoni", "Vasiliki", ""], ["Corneil", "Dane", ""], ["Brea", "Johanni", ""]]}, {"id": "1801.05421", "submitter": "Wenpo Yao", "authors": "Wenpo Yao, Wenli Yao, Jun Wang and Jiafei Dai", "title": "Quantifying time irreversibility using probabilistic differences between\n  symmetric permutations", "comments": null, "journal-ref": "Physics Letters A. 2019, 383(8): 738-743", "doi": "10.1016/j.physleta.2018.11.043", "report-no": null, "categories": "physics.med-ph physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To simplify the quantification of time irreversibility, we employ order\npatterns instead of the raw multi-dimension vectors in time series, and\nconsidering the existence of forbidden permutation, we propose a\nsubtraction-based parameter, Ys, to measure the probabilistic differences\nbetween symmetric permutations for time irreversibility. Two chaotic models,\nthe logistic and Henon systems, and reversible Gaussian process and their\nsurrogate data are used to validate the time-irreversible measure, and time\nirreversibility of epileptic EEGs from Nanjing General Hospital is detected by\nthe parameter. Test results prove that it is promising to quantify time\nirreversibility by measuring the subtraction-based probabilistic differences\nbetween symmetric order patterns, and our findings highlight the manifestation\nof nonlinearity of whether healthy or diseased EEGs and suggest that the\nepilepsy leads to a decline in the nonlinearity of brain electrical activities\nduring seize-free intervals.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 08:13:53 GMT"}, {"version": "v2", "created": "Thu, 19 Jul 2018 02:18:12 GMT"}, {"version": "v3", "created": "Sun, 23 Dec 2018 08:16:30 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Yao", "Wenpo", ""], ["Yao", "Wenli", ""], ["Wang", "Jun", ""], ["Dai", "Jiafei", ""]]}, {"id": "1801.05703", "submitter": "Stefanie Heyden", "authors": "Stefanie Heyden and Michael Ortiz", "title": "Functional optimality of the sulcus pattern of the human brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a mathematical model of information transmission across the\nbiological neural network of the human brain. The overall function of the brain\nconsists of the emergent processes resulting from the spread of information\nthrough the neural network. The capacity of the brain is therefore related to\nthe rate at which it can transmit information through the neural network. The\nparticular transmission model under consideration allows for information to be\ntransmitted along multiple paths between points of the cortex. The resulting\ntransmission rates are governed by potential theory. According to this theory,\nthe brain has preferred and quantized transmission modes that correspond to\neigenfunctions of the classical Steklov eigenvalue problem, with the reciprocal\neigenvalues quantifying the corresponding transmission rates. We take the model\nas a basis for testing the hypothesis that the sulcus pattern of the human\nbrain has evolved to maximize the rate of transmission of information between\npoints in the cerebral cortex. We show that the introduction of sulci, or cuts,\nin an otherwise smooth domain indeed increases the overall transmission rate.\nWe demonstrate this result by means of numerical experiments concerned with a\nspherical domain with a varying number of slits on its surface.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 15:05:42 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 20:36:58 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Heyden", "Stefanie", ""], ["Ortiz", "Michael", ""]]}, {"id": "1801.05878", "submitter": "Zachary Kilpatrick PhD", "authors": "Gregory Faye and Zachary P Kilpatrick", "title": "Threshold of front propagation in neural fields: An interface dynamics\n  approach", "comments": "27 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.PS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural field equations model population dynamics of large-scale networks of\nneurons. Wave propagation in neural fields is often studied by constructing\ntraveling wave solutions in the wave coordinate frame. Nonequilibrium dynamics\nare more challenging to study, due to the nonlinearity and nonlocality of\nneural fields, whose interactions are described by the kernel of an integral\nterm. Here, we leverage interface methods to describe the threshold of wave\ninitiation away from equilibrium. In particular, we focus on traveling front\ninitiation in an excitatory neural field. In a neural field with a Heaviside\nfiring rate, neural activity can be described by the dynamics of the\ninterfaces, where the neural activity is at the firing threshold. This allows\nus to derive conditions for the portion of the neural field that must be\nactivated for traveling fronts to be initiated in a purely excitatory neural\nfield. Explicit equations are possible for a single active (superthreshold)\nregion, and special cases of multiple disconnected active regions. The dynamic\nspreading speed of the excited region can also be approximated asymptotically.\nWe also discuss extensions to the problem of finding the critical\nspatiotemporal input needed to initiate waves.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 22:34:50 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Faye", "Gregory", ""], ["Kilpatrick", "Zachary P", ""]]}, {"id": "1801.06046", "submitter": "Johanna Senk", "authors": "Johanna Senk, Karol\\'ina Korvasov\\'a, Jannis Schuecker, Espen Hagen,\n  Tom Tetzlaff, Markus Diesmann, Moritz Helias", "title": "Conditions for wave trains in spiking neural networks", "comments": "36 pages, 8 figures, 4 tables", "journal-ref": "Phys. Rev. Research 2, 023174 (2020)", "doi": "10.1103/PhysRevResearch.2.023174", "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatiotemporal patterns such as traveling waves are frequently observed in\nrecordings of neural activity. The mechanisms underlying the generation of such\npatterns are largely unknown. Previous studies have investigated the existence\nand uniqueness of different types of waves or bumps of activity using\nneural-field models, phenomenological coarse-grained descriptions of\nneural-network dynamics. But it remains unclear how these insights can be\ntransferred to more biologically realistic networks of spiking neurons, where\nindividual neurons fire irregularly. Here, we employ mean-field theory to\nreduce a microscopic model of leaky integrate-and-fire (LIF) neurons with\ndistance-dependent connectivity to an effective neural-field model. In contrast\nto existing phenomenological descriptions, the dynamics in this neural-field\nmodel depends on the mean and the variance in the synaptic input, both\ndetermining the amplitude and the temporal structure of the resulting effective\ncoupling kernel. For the neural-field model we employ liner stability analysis\nto derive conditions for the existence of spatial and temporal oscillations and\nwave trains, that is, temporally and spatially periodic traveling waves. We\nfirst prove that wave trains cannot occur in a single homogeneous population of\nneurons, irrespective of the form of distance dependence of the connection\nprobability. Compatible with the architecture of cortical neural networks, wave\ntrains emerge in two-population networks of excitatory and inhibitory neurons\nas a combination of delay-induced temporal oscillations and spatial\noscillations due to distance-dependent connectivity profiles. Finally, we\ndemonstrate quantitative agreement between predictions of the analytically\ntractable neural-field model and numerical simulations of both networks of\nnonlinear rate-based units and networks of LIF neurons.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 14:40:27 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2019 14:44:17 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Senk", "Johanna", ""], ["Korvasov\u00e1", "Karol\u00edna", ""], ["Schuecker", "Jannis", ""], ["Hagen", "Espen", ""], ["Tetzlaff", "Tom", ""], ["Diesmann", "Markus", ""], ["Helias", "Moritz", ""]]}, {"id": "1801.06079", "submitter": "Antoine Allard", "authors": "Antoine Allard and M. \\'Angeles Serrano", "title": "Navigable maps of structural brain networks across species", "comments": "20 pages, 5 figures, 2 supp. tables, 3 supp. appendices, 10 supp.\n  figures", "journal-ref": "PLOS Computational Biology 16, e1007584 (2020)", "doi": "10.1371/journal.pcbi.1007584", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectomes are spatially embedded networks whose architecture has been\nshaped by physical constraints and communication needs throughout evolution.\nUsing a decentralized navigation protocol, we investigate the relationship\nbetween the structure of the connectomes of different species and their spatial\nlayout. As a navigation strategy, we use greedy routing where nearest\nneighbors, in terms of geometric distance, are visited. We measure the fraction\nof successful greedy paths and their length as compared to shortest paths in\nthe topology of connectomes. In Euclidean space, we find a striking difference\nbetween the navigability properties of mammalian and non-mammalian species,\nwhich implies the inability of Euclidean distances to fully explain the\nstructural organization of their connectomes. In contrast, we find that\nhyperbolic space, the effective geometry of complex networks, provides almost\nperfectly navigable maps of connectomes for all species, meaning that\nhyperbolic distances are exceptionally congruent with the structure of\nconnectomes. Hyperbolic maps therefore offer a quantitative meaningful\nrepresentation of connectomes that suggests a new cartography of the brain\nbased on the combination of its connectivity with its effective geometry rather\nthan on its anatomy only. Hyperbolic maps also provide a universal framework to\nstudy decentralized communication processes in connectomes of different species\nand at different scales on an equal footing.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 15:02:42 GMT"}, {"version": "v2", "created": "Thu, 6 Feb 2020 13:21:34 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Allard", "Antoine", ""], ["Serrano", "M. \u00c1ngeles", ""]]}, {"id": "1801.06168", "submitter": "Youngmin Park", "authors": "Youngmin Park, G. Bard Ermentrout", "title": "Scalar Reduction of a Neural Field Model with Spike Frequency Adaptation", "comments": "60 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a deterministic version of a one- and two-dimensional attractor\nneural network model of hippocampal activity first studied by Itskov et al\n2011. We analyze the dynamics of the system on the ring and torus domain with\nan even periodized weight matrix, assum- ing weak and slow spike frequency\nadaptation and a weak stationary input current. On these domains, we find\ntransitions from spatially localized stationary solutions (\"bumps\") to\n(periodically modulated) solutions (\"sloshers\"), as well as constant and\nnon-constant velocity traveling bumps depending on the relative strength of\nexternal input current and adaptation. The weak and slow adaptation allows for\na reduction of the system from a distributed partial integro-differential\nequation to a system of scalar Volterra integro-differential equations\ndescribing the movement of the centroid of the bump solution. Using this\nreduction, we show that on both domains, sloshing solutions arise through an\nAndronov-Hopf bifurcation and derive a normal form for the Hopf bifurcation on\nthe ring. We also show existence and stability of constant velocity solutions\non both domains using Evans functions. In contrast to existing studies, we\nassume a general weight matrix of Mexican-hat type in addition to a smooth\nfiring rate function.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 18:46:21 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Park", "Youngmin", ""], ["Ermentrout", "G. Bard", ""]]}, {"id": "1801.06226", "submitter": "Eve Armstrong", "authors": "Eve Armstrong", "title": "Computational model of avian nervous system nuclei governing learned\n  song", "comments": "21 pages and 11 figures, without appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The means by which neuronal activity yields robust behavior is a ubiquitous\nquestion in neuroscience. In the songbird, the timing of a highly stereotyped\nsong motif is attributed to the cortical nucleus HVC, and to feedback to HVC\nfrom downstream nuclei in the song motor pathway. Control of the acoustic\nstructure appears to be shared by various structures, whose functional\nconnectivity is largely unknown. Currently there exists no model for functional\nsynaptic architecture that links HVC to song output in a manner consistent with\nexperiments. Here we build on a previous model of HVC in which a distinct\nfunctional architecture may act as a pattern generator to drive downstream\nregions. Using a specific functional connectivity of the song motor pathway, we\nshow how this HVC mechanism can generate simple representations of the driving\nforces for song. The model reproduces observed correlations between neuronal\nand respiratory activity and acoustic features of song. It makes testable\npredictions regarding the electrophysiology of distinct populations in the\nrobust nucleus of the arcopallium (RA), the connectivity within HVC and RA and\nbetween them, and the activity patterns of vocal-respiratory neurons in the\nbrainstem.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 20:27:21 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Armstrong", "Eve", ""]]}, {"id": "1801.06452", "submitter": "Qinbing Fu", "authors": "Qinbing Fu and Cheng Hu and Shigang Yue", "title": "Collision Selective Visual Neural Network Inspired by LGMD2 Neurons in\n  Juvenile Locusts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For autonomous robots in dynamic environments mixed with human, it is vital\nto detect impending collision quickly and robustly. The biological visual\nsystems evolved over millions of years may provide us efficient solutions for\ncollision detection in complex environments. In the cockpit of locusts, two\nLobula Giant Movement Detectors, i.e. LGMD1 and LGMD2, have been identified\nwhich respond to looming objects rigorously with high firing rates. Compared to\nLGMD1, LGMD2 matures early in the juvenile locusts with specific selectivity to\ndark moving objects against bright background in depth while not responding to\nlight objects embedded in dark background - a similar situation which ground\nvehicles and robots are facing with. However, little work has been done on\nmodeling LGMD2, let alone its potential in robotics and other vision-based\napplications. In this article, we propose a novel way of modeling LGMD2 neuron,\nwith biased ON and OFF pathways splitting visual streams into parallel channels\nencoding brightness increments and decrements separately to fulfill its\nselectivity. Moreover, we apply a biophysical mechanism of spike frequency\nadaptation to shape the looming selectivity in such a collision-detecting\nneuron model. The proposed visual neural network has been tested with\nsystematic experiments, challenged against synthetic and real physical stimuli,\nas well as image streams from the sensor of a miniature robot. The results\ndemonstrated this framework is able to detect looming dark objects embedded in\nbright backgrounds selectively, which make it ideal for ground mobile\nplatforms. The robotic experiments also showed its robustness in collision\ndetection - it performed well for near range navigation in an arena with many\nobstacles. Its enhanced collision selectivity to dark approaching objects\nversus receding and translating ones has also been verified via systematic\nexperiments.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 00:34:55 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Fu", "Qinbing", ""], ["Hu", "Cheng", ""], ["Yue", "Shigang", ""]]}, {"id": "1801.07244", "submitter": "Marius Nann", "authors": "M. Nann, L. G. Cohen, L. Deecke, S. R. Soekadar", "title": "To jump or not to jump: The Bereitschaftspotential required to jump into\n  192-meter abyss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-initiated voluntary acts, such as pressing a button, are preceded by a\nnegative electrical brain potential, the Bereitschaftspotential (BP), that can\nbe recorded over the human scalp using electroencephalography (EEG). Up to now,\nthe BP required to initiate voluntary acts has only been recorded under\nwell-controlled laboratory conditions. It is thus not known if this form of\nbrain activity also underlies motor initiation in possible life-threatening\ndecision making, such as jumping into a 192-meter abyss, an act requiring\nextraordinary willpower. Here, we report BP before self-initiated 192-meter\nextreme bungee jumping across two semi-professional cliff divers (both male,\nmean age 19.3 years). We found that the spatiotemporal dynamics of the BP is\ncomparable to that recorded under laboratory conditions. These results,\npossible through recent advancements in wireless and portable EEG technology,\ndocument for the first time pre-movement brain activity preceding possible\nlife-threatening decision making.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 18:59:37 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Nann", "M.", ""], ["Cohen", "L. G.", ""], ["Deecke", "L.", ""], ["Soekadar", "S. R.", ""]]}, {"id": "1801.07654", "submitter": "Pablo Barros", "authors": "Pablo Barros, German I. Parisi, Di Fu, Xun Liu, and Stefan Wermter", "title": "Expectation Learning for Adaptive Crossmodal Stimuli Association", "comments": "3 pages 2017 EUCog meeting abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The human brain is able to learn, generalize, and predict crossmodal stimuli.\nLearning by expectation fine-tunes crossmodal processing at different levels,\nthus enhancing our power of generalization and adaptation in highly dynamic\nenvironments. In this paper, we propose a deep neural architecture trained by\nusing expectation learning accounting for unsupervised learning tasks. Our\nlearning model exhibits a self-adaptable behavior, setting the first steps\ntowards the development of deep learning architectures for crossmodal stimuli\nassociation.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 16:47:32 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Barros", "Pablo", ""], ["Parisi", "German I.", ""], ["Fu", "Di", ""], ["Liu", "Xun", ""], ["Wermter", "Stefan", ""]]}, {"id": "1801.07936", "submitter": "Paolo Detti", "authors": "Paolo Detti, Garazi Zabalo Manrique de Lara, Renato Bruni, Marco\n  Pranzo, Francesco Sarnari", "title": "Anticipating epileptic seizures through the analysis of EEG\n  synchronization as a data classification problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is a neurological disorder arising from anomalies of the electrical\nactivity in the brain, affecting about 0.5--0.8\\% of the world population.\nSeveral studies investigated the relationship between seizures and brainwave\nsynchronization patterns, pursuing the possibility of identifying interictal,\npreictal, ictal and postictal states. In this work, we introduce a graph-based\nmodel of the brain interactions developed to study synchronization patterns in\nthe electroencephalogram (EEG) signals. The aim is to develop a\npatient-specific approach, also for a real-time use, for the prediction of\nepileptic seizures' occurrences. Different synchronization measures of the EEG\nsignals and easily computable functions able to capture in real-time the\nvariations of EEG synchronization have been considered. Both standard and\nad-hoc classification algorithms have been developed and used. Results on scalp\nEEG signals show that this simple and computationally viable processing is able\nto highlight the changes in the synchronization corresponding to the preictal\nstate.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 11:43:29 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Detti", "Paolo", ""], ["de Lara", "Garazi Zabalo Manrique", ""], ["Bruni", "Renato", ""], ["Pranzo", "Marco", ""], ["Sarnari", "Francesco", ""]]}, {"id": "1801.07938", "submitter": "Caio Seguin", "authors": "Caio Seguin, Martijn P. van den Heuvel, Andrew Zalesky", "title": "Navigation of brain networks", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1801351115", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the mechanisms of neural communication in large-scale brain\nnetworks remains a major goal in neuroscience. We investigated whether\nnavigation is a parsimonious routing model for connectomics. Navigating a\nnetwork involves progressing to the next node that is closest in distance to a\ndesired destination. We developed a measure to quantify navigation efficiency\nand found that connectomes in a range of mammalian species (human, mouse and\nmacaque) can be successfully navigated with near-optimal efficiency (>80% of\noptimal efficiency for typical connection densities). Rewiring network topology\nor repositioning network nodes resulted in 45%-60% reductions in navigation\nperformance. Specifically, we found that brain networks cannot be progressively\nrewired (randomized or clusterized) to result in topologies with significantly\nimproved navigation performance. Navigation was also found to: i) promote a\nresource-efficient distribution of the information traffic load, potentially\nrelieving communication bottlenecks; and, ii) explain significant variation in\nfunctional connectivity. Unlike prevalently studied communication strategies in\nconnectomics, navigation does not mandate biologically unrealistic assumptions\nabout global knowledge of network topology. We conclude that the wiring and\nspatial embedding of brain networks is conducive to effective decentralized\ncommunication. Graph-theoretic studies of the connectome should consider\nmeasures of network efficiency and centrality that are consistent with\ndecentralized models of neural communication.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 11:45:20 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Seguin", "Caio", ""], ["Heuvel", "Martijn P. van den", ""], ["Zalesky", "Andrew", ""]]}, {"id": "1801.08085", "submitter": "Meysam Golmohammadi", "authors": "Vinit Shah, Eva von Weltin, Silvia Lopez, James Riley McHugh, Lily\n  Veloso, Meysam Golmohammadi, Iyad Obeid and Joseph Picone", "title": "The Temple University Hospital Seizure Detection Corpus", "comments": "Under review in Frontiers in Neuroscience", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM eess.SP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the TUH EEG Seizure Corpus (TUSZ), which is the largest open\nsource corpus of its type, and represents an accurate characterization of\nclinical conditions. In this paper, we describe the techniques used to develop\nTUSZ, evaluate their effectiveness, and present some descriptive statistics on\nthe resulting corpus.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 01:16:26 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Shah", "Vinit", ""], ["von Weltin", "Eva", ""], ["Lopez", "Silvia", ""], ["McHugh", "James Riley", ""], ["Veloso", "Lily", ""], ["Golmohammadi", "Meysam", ""], ["Obeid", "Iyad", ""], ["Picone", "Joseph", ""]]}, {"id": "1801.08087", "submitter": "Ariadne Costa", "authors": "Ariadne de Andrade Costa, Mary Jean Amon, Olaf Sporns, Luis Favela", "title": "Fractal analyses of networks of integrate-and-fire stochastic spiking\n  neurons", "comments": "11 pages, 3 subfigures divided into 2 figures", "journal-ref": null, "doi": "10.1007/978-3-319-73198-8_14", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there is increasing evidence of criticality in the brain, the\nprocesses that guide neuronal networks to reach or maintain criticality remain\nunclear. The present research examines the role of neuronal gain plasticity in\ntime-series of simulated neuronal networks composed of integrate-and-fire\nstochastic spiking neurons, and the utility of fractal methods in assessing\nnetwork criticality. Simulated time-series were derived from a network model of\nfully connected discrete-time stochastic excitable neurons. Monofractal and\nmultifractal analyses were applied to neuronal gain time-series. Fractal\nscaling was greatest in networks with a mid-range of neuronal plasticity,\nversus extremely high or low levels of plasticity. Peak fractal scaling\ncorresponded closely to additional indices of criticality, including average\nbranching ratio. Networks exhibited multifractal structure, or multiple scaling\nrelationships. Multifractal spectra around peak criticality exhibited elongated\nright tails, suggesting that the fractal structure is relatively insensitive to\nhigh-amplitude local fluctuations. Networks near critical states exhibited\nmid-range multifractal spectra width and tail length, which is consistent with\nliterature suggesting that networks poised at quasi-critical states must be\nstable enough to maintain organization but unstable enough to be adaptable.\nLastly, fractal analyses may offer additional information about critical state\ndynamics of networks by indicating scales of influence as networks approach\ncritical states.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 22:32:48 GMT"}], "update_date": "2018-02-21", "authors_parsed": [["Costa", "Ariadne de Andrade", ""], ["Amon", "Mary Jean", ""], ["Sporns", "Olaf", ""], ["Favela", "Luis", ""]]}, {"id": "1801.08108", "submitter": "Matthias Keil", "authors": "Matthias S. Keil, Elisenda Roca-Moreno, and Angel Rodriguez-Vazquez", "title": "A neural model of the locust visual system for detection of object\n  approaches with real-world scenes", "comments": "Originally published in the Proceedings of the Fourth IASTED\n  International Conference on Visualization, Imaging, and Image Processing,\n  September 6-8, 2004, Marbella, Spain (see\n  http://www.actapress.com/Abstract.aspx?paperId=18773)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the central nervous systems of animals like pigeons and locusts, neurons\nwere identified which signal objects approaching the animal on a direct\ncollision course. Unraveling the neural circuitry for collision avoidance, and\nidentifying the underlying computational principles, is promising for building\nvision-based neuromorphic architectures, which in the near future could find\napplications in cars or planes. At the present there is no published model\navailable for robust detection of approaching objects under real-world\nconditions. Here we present a computational architecture for signalling\nimpending collisions, based on known anatomical data of the locust \\emph{lobula\ngiant movement detector} (LGMD) neuron. Our model shows robust performance even\nin adverse situations, such as with approaching low-contrast objects, or with\nhighly textured and moving backgrounds. We furthermore discuss which components\nneed to be added to our model to convert it into a full-fledged\nreal-world-environment collision detector. KEYWORDS: Locust, LGMD, collision\ndetection, lateral inhibition, diffusion, ON-OFF-pathways, neuronal dynamics,\ncomputer vision, image processing\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 18:13:12 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Keil", "Matthias S.", ""], ["Roca-Moreno", "Elisenda", ""], ["Rodriguez-Vazquez", "Angel", ""]]}, {"id": "1801.08116", "submitter": "Joel Leibo", "authors": "Joel Z. Leibo, Cyprien de Masson d'Autume, Daniel Zoran, David Amos,\n  Charles Beattie, Keith Anderson, Antonio Garc\\'ia Casta\\~neda, Manuel\n  Sanchez, Simon Green, Audrunas Gruslys, Shane Legg, Demis Hassabis, Matthew\n  M. Botvinick", "title": "Psychlab: A Psychology Laboratory for Deep Reinforcement Learning Agents", "comments": "28 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psychlab is a simulated psychology laboratory inside the first-person 3D game\nworld of DeepMind Lab (Beattie et al. 2016). Psychlab enables implementations\nof classical laboratory psychological experiments so that they work with both\nhuman and artificial agents. Psychlab has a simple and flexible API that\nenables users to easily create their own tasks. As examples, we are releasing\nPsychlab implementations of several classical experimental paradigms including\nvisual search, change detection, random dot motion discrimination, and multiple\nobject tracking. We also contribute a study of the visual psychophysics of a\nspecific state-of-the-art deep reinforcement learning agent: UNREAL (Jaderberg\net al. 2016). This study leads to the surprising conclusion that UNREAL learns\nmore quickly about larger target stimuli than it does about smaller stimuli. In\nturn, this insight motivates a specific improvement in the form of a simple\nmodel of foveal vision that turns out to significantly boost UNREAL's\nperformance, both on Psychlab tasks, and on standard DeepMind Lab tasks. By\nopen-sourcing Psychlab we hope to facilitate a range of future such studies\nthat simultaneously advance deep reinforcement learning and improve its links\nwith cognitive science.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 18:31:51 GMT"}, {"version": "v2", "created": "Sun, 4 Feb 2018 19:29:12 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Leibo", "Joel Z.", ""], ["d'Autume", "Cyprien de Masson", ""], ["Zoran", "Daniel", ""], ["Amos", "David", ""], ["Beattie", "Charles", ""], ["Anderson", "Keith", ""], ["Casta\u00f1eda", "Antonio Garc\u00eda", ""], ["Sanchez", "Manuel", ""], ["Green", "Simon", ""], ["Gruslys", "Audrunas", ""], ["Legg", "Shane", ""], ["Hassabis", "Demis", ""], ["Botvinick", "Matthew M.", ""]]}, {"id": "1801.08366", "submitter": "Stephen Coombes", "authors": "S Coombes, Y-M Lai, M Sayli and R Thul", "title": "Networks of piecewise linear neural mass models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural mass models are ubiquitous in large scale brain modelling. At the node\nlevel they are written in terms of a set of ODEs with a nonlinearity that is\ntypically a sigmoidal shape. Using structural data from brain atlases they may\nbe connected into a network to investigate the emergence of functional dynamic\nstates, such as synchrony. With the simple restriction of the classic sigmoidal\nnonlinearity to a piecewise linear caricature we show that the famous\nWilson-Cowan neural mass model can be analysed at both the node and network\nlevel. The construction of periodic orbits at the node level is achieved by\npatching together matrix exponential solutions, and stability is determined\nusing Floquet theory. For networks with interactions described by circulant\nmatrices, we show that the stability of the synchronous state can be determined\nin terms of a low-dimensional Floquet problem parameterised by the eigenvalues\nof the interaction matrix. This network Floquet problem is readily solved using\nlinear algebra, to predict the onset of spatio-temporal network patterns\narising from a synchronous instability. We consider the case of a discontinuous\nchoice for the node nonlinearity, namely the replacement of the sigmoid by a\nHeaviside nonlinearity. This gives rise to a continuous-time switching network.\nAt the node level this allows for the existence of unstable sliding periodic\norbits, which we construct. The stability of a periodic orbit is now treated\nwith a modification of Floquet theory to treat the evolution of small\nperturbations through switching manifolds via saltation matrices. At the\nnetwork level the stability analysis of the synchronous state is considerably\nmore challenging. Here we report on the use of ideas originally developed for\nthe study of Glass networks to treat the stability of periodic network states\nin neural mass models with discontinuous interactions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 11:55:24 GMT"}], "update_date": "2018-01-26", "authors_parsed": [["Coombes", "S", ""], ["Lai", "Y-M", ""], ["Sayli", "M", ""], ["Thul", "R", ""]]}, {"id": "1801.08585", "submitter": "Matthias Keil", "authors": "Matthias S. Keil", "title": "From Neuronal Models to Neuronal Dynamics and Image Processing", "comments": "First published as chapter 10 in the Wiley book \"Biologically\n  Inspired Computer Vision: Fundamentals and Applications\". (ISBN:\n  978-3-527-68047-4)", "journal-ref": "\"Biologically Inspired Computer Vision: Fundamentals and\n  Applications\" (first edition). Gabriel Cristobal, Laurent Perrinet, &\n  Matthias S. Keil (Editors), pp. 221-243 (chapter 10), ISBN:\n  978-3-527-68047-4, Wiley, 2015", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an introduction to the membrane potential equation for neurons.\nIts properties are described, as well as sample applications. Networks of these\nequations can be used for modeling neuronal systems, which also process images\nand video sequences, respectively. Specifically, (i) a dynamic retina is\nproposed (based on a reaction-diffusion system), which predicts afterimages and\nsimple visual illusions, (ii) a system for texture segregation (texture\nelements are understood as even-symmetric contrast features), and (iii) a\nnetwork for detecting object approaches (inspired by the locust visual system).\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 20:10:49 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Keil", "Matthias S.", ""]]}, {"id": "1801.08806", "submitter": "John Medaglia", "authors": "John D. Medaglia", "title": "Clarifying Cognitive Control and the Controllable Connectome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive control researchers aim to describe the processes that support\nadaptive cognition to achieve specific goals. Control theorists consider how to\ninfluence the state of systems to reach certain user-defined goals. In brain\nnetworks, some conceptual and lexical similarities between cognitive control\nand control theory offer appealing avenues for scientific discovery. However,\nthese opportunities also come with the risk of conceptual confusion. Here, I\nsuggest that each field of inquiry continues to produce novel and distinct\ninsights. Then, I describe opportunities for synergistic research at the\nintersection of these subdisciplines with a critical stance that reduces the\nrisk of conceptual confusion. Through this exercise, we can observe that both\ncognitive neuroscience and systems engineering have much to contribute to\ncognitive control research in human brain networks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 13:43:32 GMT"}, {"version": "v2", "created": "Wed, 28 Feb 2018 22:21:52 GMT"}, {"version": "v3", "created": "Fri, 2 Mar 2018 15:08:42 GMT"}, {"version": "v4", "created": "Fri, 1 Jun 2018 17:03:42 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Medaglia", "John D.", ""]]}, {"id": "1801.08950", "submitter": "Kaushik Majumdar", "authors": "Puneet Dheer, Sandipan Pati, Srinath Jayachandran, Kaushik Kumar\n  Majumdar", "title": "Ictal and Post Ictal Impaired Consciousness due to Enhanced Mutual\n  Information in Temporal Lobe Epilepsy", "comments": "30 pages, 5 figures, 8 tables, under review in Brain Topography", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Seizure and synchronization are related to each other in complex manner.\nAltered synchrony has been implicated in loss of consciousness during partial\nseizures. However, the mechanism of altered consciousness following termination\nof seizures has not been studied well. In this work we used bivariate mutual\ninformation as a measure of synchronization to understand the neural correlate\nof altered consciousness during and after termination of mesial temporal lobe\nonset seizures. First, we have compared discrete bivariate mutual information\n(MI) measure with amplitude correlation (AC), phase synchronization (PS),\nnonlinear correlation and coherence, and established MI as a robust measure of\nsynchronization. Next, we have extended MI to more than two signals by\nprincipal component method. The extended MI was applied on intracranial\nelectroencephalogram (iEEG) before, during and after 23 temporal lobe seizures\nrecorded from 11 patients. The analyses were carried out in delta, theta,\nalpha, beta and gamma bands. In 77% of the complex partial seizures MI was\nhigher towards the seizure offset than in the first half of the seizure in the\nseizure onset zone (SOZ) channels in beta and gamma bands, whereas MI remained\nhigher in the beginning or in the middle of the seizure than towards the offset\nacross the least involved channels in the same bands. Synchronization seems\nbuilt up outside the SOZ, gradually spread and culminated in SOZ and remained\nhigh beyond offset leading to impaired consciousness in 82% of the complex\npartial temporal lobe seizures. Consciousness impairment was scored according\nto a method previously applied to assess the same in patients with temporal\nlobe epilepsy during seizure.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 19:27:40 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Dheer", "Puneet", ""], ["Pati", "Sandipan", ""], ["Jayachandran", "Srinath", ""], ["Majumdar", "Kaushik Kumar", ""]]}, {"id": "1801.09024", "submitter": "John Medaglia", "authors": "John D. Medaglia, David Yaden, Chelsea Helion, Madeline Haslam", "title": "Moral attitudes and willingness to induce cognitive enhancement and\n  repair with brain stimulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of technological means to enhance and repair human cognitive\nfunction raises questions about the perceived morality of their use. In this\nstudy, we administered a survey to the public in which subjects were asked to\nreport how willing they would be to enhance and/or repair specific cognitive\nabilities. Among 894 responders, we found that subjects were more willing to\nuse technologies to repair other people than themselves, and especially to\nenhance or repair functions more \"core\" to authentic identity in others.\nSubjects' ratings of the moral acceptability of specific uses was related to\ntheir reported willingness to use brain stimulation. These findings suggest\nthat the public endorses an altruistic approach to applying brain stimulation\nfor cognitive gains. Further, this study establishes a basis to guide moral\npsychological studies of cognitive modification and social processes that guide\nattitudes toward and uses of brain stimulation.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jan 2018 02:17:05 GMT"}, {"version": "v2", "created": "Thu, 1 Feb 2018 16:17:21 GMT"}], "update_date": "2018-02-02", "authors_parsed": [["Medaglia", "John D.", ""], ["Yaden", "David", ""], ["Helion", "Chelsea", ""], ["Haslam", "Madeline", ""]]}, {"id": "1801.09165", "submitter": "Vadim Zotev", "authors": "Vadim Zotev, Raquel Phillips, Masaya Misaki, Chung Ki Wong, Brent E.\n  Wurfel, Frank Krueger, Matthew Feldner, Jerzy Bodurka", "title": "Real-time fMRI neurofeedback training of the amygdala activity with\n  simultaneous EEG in veterans with combat-related PTSD", "comments": "26 pages, 16 figures, to appear in NeuroImage: Clinical", "journal-ref": "NeuroImage: Clinical 19 (2018) 106-121", "doi": "10.1016/j.nicl.2018.04.010", "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Posttraumatic stress disorder (PTSD) is a chronic and disabling\nneuropsychiatric disorder characterized by insufficient top-down modulation of\nthe amygdala activity by the prefrontal cortex. Real-time fMRI neurofeedback\n(rtfMRI-nf) is an emerging method with potential for modifying the\namygdala-prefrontal interactions. We report the first controlled emotion\nself-regulation study in veterans with combat-related PTSD utilizing rtfMRI-nf\nof the amygdala activity. PTSD patients in the experimental group (EG, n=20)\nlearned to upregulate BOLD activity of the left amygdala (LA) using rtfMRI-nf\nduring a happy emotion induction task. PTSD patients in the control group (CG,\nn=11) were provided with a sham rtfMRI-nf. The study included three rtfMRI-nf\ntraining sessions, and EEG recordings were performed simultaneously with fMRI.\nPTSD severity was assessed using the Clinician-Administered PTSD Scale (CAPS).\nThe EG participants showed a significant reduction in total CAPS ratings,\nincluding significant reductions in avoidance and hyperarousal symptoms.\nOverall, 80% of the EG participants demonstrated clinically meaningful\nreductions in CAPS ratings, compared to 38% in the CG. During the first\nsession, fMRI connectivity of the LA with the orbitofrontal cortex and the\ndorsolateral prefrontal cortex (DLPFC) was progressively enhanced, and this\nenhancement significantly and positively correlated with initial CAPS ratings.\nLeft-lateralized enhancement in upper alpha EEG coherence also exhibited a\nsignificant positive correlation with the initial CAPS. Reduction in PTSD\nseverity between the first and last rtfMRI-nf sessions significantly correlated\nwith enhancement in functional connectivity between the LA and the left DLPFC.\nOur results demonstrate that the rtfMRI-nf of the amygdala activity has the\npotential to correct the amygdala-prefrontal functional connectivity\ndeficiencies specific to PTSD.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 01:41:00 GMT"}, {"version": "v2", "created": "Tue, 10 Apr 2018 22:11:15 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Zotev", "Vadim", ""], ["Phillips", "Raquel", ""], ["Misaki", "Masaya", ""], ["Wong", "Chung Ki", ""], ["Wurfel", "Brent E.", ""], ["Krueger", "Frank", ""], ["Feldner", "Matthew", ""], ["Bodurka", "Jerzy", ""]]}, {"id": "1801.09257", "submitter": "Hyekyoung Lee", "authors": "Hyekyoung Lee, Eunkyung Kim, Hyejin Kang, Youngmin Huh, Youngjo Lee,\n  Seonhee Lim, Dong Soo Lee", "title": "Volume entropy and information flow in a brain graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entropy is a classical measure to quantify the amount of information or\ncomplexity of a system. Various entropy-based measures such as functional and\nspectral entropies have been proposed in brain network analysis. However, they\nare less widely used than traditional graph theoretic measures such as global\nand local efficiencies because either they are not well-defined on a graph or\ndifficult to interpret its biological meaning. In this paper, we propose a new\nentropy-based graph invariant, called volume entropy. It measures the\nexponential growth rate of the number of paths in a graph, which is a relevant\nmeasure if information flows through the graph forever. We model the\ninformation propagation on a graph by the generalized Markov system associated\nto the weighted edge-transition matrix. We estimate the volume entropy using\nthe stationary equation of the generalized Markov system. A prominent advantage\nof using the stationary equation is that it assigns certain distribution of\nweights on the edges of the brain graph, which we call the stationary\ndistribution. The stationary distribution shows the information capacity of\nedges and the direction of information flow on a brain graph. The simulation\nresults show that the volume entropy distinguishes the underlying graph\ntopology and geometry better than the existing graph measures. In brain imaging\ndata application, the volume entropy of brain graphs was significantly related\nto healthy normal aging from 20s to 60s. In addition, the stationary\ndistribution of information propagation gives a new insight into the\ninformation flow of functional brain graph.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 17:51:43 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 05:16:50 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Lee", "Hyekyoung", ""], ["Kim", "Eunkyung", ""], ["Kang", "Hyejin", ""], ["Huh", "Youngmin", ""], ["Lee", "Youngjo", ""], ["Lim", "Seonhee", ""], ["Lee", "Dong Soo", ""]]}, {"id": "1801.09300", "submitter": "Tiberiu Tesileanu", "authors": "Tiberiu Tesileanu, Simona Cocco, Remi Monasson, Vijay Balasubramanian", "title": "Adaptation of olfactory receptor abundances for efficient coding", "comments": "36 pages, 13 figures", "journal-ref": null, "doi": "10.1101/255547", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Olfactory receptor usage is highly heterogeneous, with some receptor types\nbeing orders of magnitude more abundant than others. We propose an explanation\nfor this striking fact: the receptor distribution is tuned to maximally\nrepresent information about the olfactory environment in a regime of efficient\ncoding that is sensitive to the global context of correlated sensor responses.\nThis model predicts that in mammals, where olfactory sensory neurons are\nreplaced regularly, receptor abundances should continuously adapt to odor\nstatistics. Experimentally, increased exposure to odorants leads variously, but\nreproducibly, to increased, decreased, or unchanged abundances of different\nactivated receptors. We demonstrate that this diversity of effects is required\nfor efficient coding when sensors are broadly correlated, and provide an\nalgorithm for predicting which olfactory receptors should increase or decrease\nin abundance following specific environmental changes. Finally, we give simple\ndynamical rules for neural birth and death processes that might underlie this\nadaptation.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 21:55:51 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 00:27:34 GMT"}, {"version": "v3", "created": "Thu, 19 Jul 2018 20:22:16 GMT"}, {"version": "v4", "created": "Tue, 22 Jan 2019 18:45:16 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Tesileanu", "Tiberiu", ""], ["Cocco", "Simona", ""], ["Monasson", "Remi", ""], ["Balasubramanian", "Vijay", ""]]}, {"id": "1801.09589", "submitter": "Chendi Wang", "authors": "Chendi Wang, Rafeef Abugharbieh", "title": "Coactivated Clique Based Multisource Overlapping Brain Subnetwork\n  Extraction", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subnetwork extraction using community detection methods is commonly used to\nstudy the brain's modular structure. Recent studies indicated that certain\nbrain regions are known to interact with multiple subnetworks. However, most\nexisting methods are mainly for non-overlapping subnetwork extraction. In this\npaper, we present an approach for overlapping brain subnetwork extraction using\ncliques, which we defined as co-activated node groups performing multiple\ntasks. We proposed a multisource subnetwork extraction approach based on the\nco-activated clique, which (1) uses task co-activation and task connectivity\nstrength information for clique identification, (2) automatically detects\ncliques of different sizes having more neuroscientific justifications, and (3)\nshares the subnetwork membership, derived from a fusion of rest and task data,\namong the nodes within a clique for overlapping subnetwork extraction. On real\ndata, compared to the commonly used overlapping community detection techniques,\nwe showed that our approach improved subnetwork extraction in terms of\ngroup-level and subject-wise reproducibility. We also showed that our\nmultisource approach identified subnetwork overlaps within brain regions that\nmatched well with hubs defined using functional and anatomical information,\nwhich enables us to study the interactions between the subnetworks and how hubs\nplay their role in information flow across different subnetworks. We further\ndemonstrated that the assignments of interacting/individual nodes using our\napproach correspond with the posterior probability derived independently from\nour multimodal random walker based approach.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 18:56:23 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Wang", "Chendi", ""], ["Abugharbieh", "Rafeef", ""]]}, {"id": "1801.09632", "submitter": "Marcelo Bertalm\\'io", "authors": "Marina Martinez-Garcia, Marcelo Bertalm\\'io and Jes\\'us Malo", "title": "In Praise of Artifice Reloaded: Caution with subjective image quality\n  databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subjective image quality databases are a major source of raw data on how the\nvisual system works in naturalistic environments. These databases describe the\nsensitivity of many observers to a wide range of distortions (of different\nnature and with different suprathreshold intensities) seen on top of a variety\nof natural images. They seem like a dream for the vision scientist to check the\nmodels in realistic scenarios.\n  However, while these natural databases are great benchmarks for models\ndeveloped in some other way (e.g. by using the well-controlled artificial\nstimuli of traditional psychophysics), they should be carefully used when\ntrying to fit vision models. Given the high dimensionality of the image space,\nit is very likely that some basic phenomenon (e.g. sensitivity to distortions\nin certain environments) are under-represented in the database. Therefore, a\nmodel fitted on these large-scale natural databases will not reproduce these\nunder-represented basic phenomena that could otherwise be easily illustrated\nwith well selected artificial stimuli.\n  In this work we study a specific example of the above statement. A\nwavelet+divisive normalization layer of a sensible cascade of linear+nonlinear\nlayers fitted to maximize the correlation with subjective opinion of observers\non a large image quality database fails to reproduce basic crossmasking. Here\nwe outline a solution for this problem using artificial stimuli. Then, we show\nthat the resulting model is also a competitive solution for the large-scale\ndatabase. In line with Rust and Movshon (2005), our report (misrepresentation\nof basic visual phenomena in subjectively-rated natural image databases) is an\nadditional argument in praise of artifice.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 17:17:45 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Martinez-Garcia", "Marina", ""], ["Bertalm\u00edo", "Marcelo", ""], ["Malo", "Jes\u00fas", ""]]}, {"id": "1801.09848", "submitter": "Ardavan Salehi Nobandegani", "authors": "Ardavan S. Nobandegani, Kevin da Silva Castanheira, A. Ross Otto,\n  Thomas R. Shultz", "title": "Over-representation of Extreme Events in Decision-Making: A Rational\n  Metacognitive Account", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Availability bias, manifested in the over-representation of extreme\neventualities in decision-making, is a well-known cognitive bias, and is\ngenerally taken as evidence of human irrationality. In this work, we present\nthe first rational, metacognitive account of the Availability bias, formally\narticulated at Marr's algorithmic level of analysis. Concretely, we present a\nnormative, metacognitive model of how a cognitive system should over-represent\nextreme eventualities, depending on the amount of time available at its\ndisposal for decision-making. Our model also accounts for two well-known\nframing effects in human decision-making under risk---the fourfold pattern of\nrisk preferences in outcome probability (Tversky & Kahneman, 1992) and in\noutcome magnitude (Markovitz, 1952)---thereby providing the first\nmetacognitively-rational basis for those effects. Empirical evidence,\nfurthermore, confirms an important prediction of our model. Surprisingly, our\nmodel is unimaginably robust with respect to its focal parameter. We discuss\nthe implications of our work for studies on human decision-making, and conclude\nby presenting a counterintuitive prediction of our model, which, if confirmed,\nwould have intriguing implications for human decision-making under risk. To our\nknowledge, our model is the first metacognitive, resource-rational process\nmodel of cognitive biases in decision-making.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 04:33:25 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Nobandegani", "Ardavan S.", ""], ["Castanheira", "Kevin da Silva", ""], ["Otto", "A. Ross", ""], ["Shultz", "Thomas R.", ""]]}, {"id": "1801.09858", "submitter": "Xiaoxiao Wang", "authors": "Xiaoxiao Wang, Xiao Liang, Zhoufan Jiang, Benedictor Alexander Nguchu,\n  Yawen Zhou, Yanming Wang, Huijuan Wang, Yu Li, Yuying Zhu, Feng Wu, Jia-Hong\n  Gao, Benching Qiu", "title": "Decoding and mapping task states of the human brain via deep learning", "comments": "27 pages, 8 figures, 4 table", "journal-ref": null, "doi": "10.1002/hbm.24891", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support vector machine (SVM) based multivariate pattern analysis (MVPA) has\ndelivered promising performance in decoding specific task states based on\nfunctional magnetic resonance imaging (fMRI) of the human brain.\nConventionally, the SVM-MVPA requires careful feature selection/extraction\naccording to expert knowledge. In this study, we propose a deep neural network\n(DNN) for directly decoding multiple brain task states from fMRI signals of the\nbrain without any burden for feature handcrafts. We trained and tested the DNN\nclassifier using task fMRI data from the Human Connectome Project's S1200\ndataset (N=1034). In tests to verify its performance, the proposed\nclassification method identified seven tasks with an average accuracy of 93.7%.\nWe also showed the general applicability of the DNN for transfer learning to\nsmall datasets (N=43), a situation encountered in typical neuroscience\nresearch. The proposed method achieved an average accuracy of 89.0% and 94.7%\non a working memory task and a motor classification task, respectively, higher\nthan the accuracy of 69.2% and 68.6% obtained by the SVM-MVPA. A network\nvisualization analysis showed that the DNN automatically detected features from\nareas of the brain related to each task. Without incurring the burden of\nhandcrafting the features, the proposed deep decoding method can classify brain\ntask states highly accurately, and is a powerful tool for fMRI researchers.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 05:58:18 GMT"}, {"version": "v2", "created": "Tue, 17 Sep 2019 03:27:16 GMT"}, {"version": "v3", "created": "Wed, 4 Dec 2019 06:40:15 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Wang", "Xiaoxiao", ""], ["Liang", "Xiao", ""], ["Jiang", "Zhoufan", ""], ["Nguchu", "Benedictor Alexander", ""], ["Zhou", "Yawen", ""], ["Wang", "Yanming", ""], ["Wang", "Huijuan", ""], ["Li", "Yu", ""], ["Zhu", "Yuying", ""], ["Wu", "Feng", ""], ["Gao", "Jia-Hong", ""], ["Qiu", "Benching", ""]]}, {"id": "1801.09900", "submitter": "Bo Schenkman", "authors": "Bo N. Schenkman, Vijay Kiran Gidla", "title": "Human Echolocation in Static Situations: Auditory Models of Detection\n  Thresholds for Distance, Pitch, Loudness and Timbre", "comments": "53 pages, 23 figures, 2 Supporting information with one figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated, by using auditory models, how three perceptual parameters,\nloudness, pitch and sharpness, determine human echolocation. We used acoustic\nrecordings from two previous studies, both from stationary situations, and\ntheir resulting perceptual data as input to our analysis. An initial analysis\nwas on the room acoustics of the recordings. The parameters of interest were\nsound pressure level, autocorrelation and spectral centroid. The auditory\nmodels were used to analyze echolocation resulting from the perceptual\nvariables, i.e. loudness, pitch and sharpness. Relevant auditory models were\nchosen to simulate each variable. Based on these results, we calculated\npsychophysical thresholds for detecting a reflecting object with constant\nphysical size. A non-parametric method was used to determine thresholds for\ndistance, loudness, pitch and sharpness. Difference thresholds were calculated\nfor the psychophysical variables, since a 2-Alternative-Forced-Choice Paradigm\nhad originally been used. We found that (1) blind persons could detect objects\nat lower loudness values, lower pitch strength, different sharpness values and\nat further distances than sighted persons, (2) detection thresholds based on\nrepetition pitch, loudness and sharpness varied and depended on room acoustics\nand type of sound stimuli, (3) repetition pitch was useful for detection at\nshorter distances and was determined from the peaks in the temporal profile of\nthe autocorrelation function, (4) loudness at shorter distances provides\necholocation information, (5) at longer distances, timbre aspects, such as\nsharpness, might be used to detect objects. We also discuss binaural\ninformation, movements and the auditory model approach. Autocorrelation was\nassumed as a proper measure for pitch, but the question is raised whether a\nmechanism based on strobe integration is a viable possibility.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 09:01:00 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Schenkman", "Bo N.", ""], ["Gidla", "Vijay Kiran", ""]]}, {"id": "1801.09997", "submitter": "Wilten Nicola", "authors": "Wilten Nicola, Peter Hellyer, Sue Ann Campbell, Claudia Clopath", "title": "Chaos in Homeostatically Regulated Neural Systems", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": "10.1063/1.5026489", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-dimensional yet rich dynamics often emerge in the brain. Examples include\noscillations and chaotic dynamics during sleep, epilepsy, and voluntary\nmovement. However, a general mechanism for the emergence of low dimensional\ndynamics remains elusive. Here, we consider Wilson-Cowan networks and\ndemonstrate through numerical and analytical work that a type of homeostatic\nregulation of the network firing rates can paradoxically lead to a rich\ndynamical repertoire. The dynamics include mixed-mode oscillations, mixed-mode\nchaos, and chaotic synchronization. This is true for single recurrently coupled\nnode, pairs of reciprocally coupled nodes without self-coupling, and networks\ncoupled through experimentally determined weights derived from functional\nmagnetic resonance imaging data. In all cases, the stability of the homeostatic\nset point is analytically determined or approximated. The dynamics at the\nnetwork level are directly determined by the behavior of a single node system\nthrough synchronization in both oscillatory and non-oscillatory states. Our\nresults demonstrate that rich dynamics can be preserved under homeostatic\nregulation or even be caused by homeostatic regulation.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 14:20:37 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Nicola", "Wilten", ""], ["Hellyer", "Peter", ""], ["Campbell", "Sue Ann", ""], ["Clopath", "Claudia", ""]]}, {"id": "1801.10186", "submitter": "Ardavan Salehi Nobandegani", "authors": "Ardavan S. Nobandegani, Ioannis N. Psaromiligkos", "title": "A Rational Distributed Process-level Account of Independence Judgment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is inconceivable how chaotic the world would look to humans, faced with\ninnumerable decisions a day to be made under uncertainty, had they been lacking\nthe capacity to distinguish the relevant from the irrelevant---a capacity which\ncomputationally amounts to handling probabilistic independence relations. The\nhighly parallel and distributed computational machinery of the brain suggests\nthat a satisfying process-level account of human independence judgment should\nalso mimic these features. In this work, we present the first rational,\ndistributed, message-passing, process-level account of independence judgment,\ncalled $\\mathcal{D}^\\ast$. Interestingly, $\\mathcal{D}^\\ast$ shows a curious,\nbut normatively-justified tendency for quick detection of dependencies,\nwhenever they hold. Furthermore, $\\mathcal{D}^\\ast$ outperforms all the\npreviously proposed algorithms in the AI literature in terms of worst-case\nrunning time, and a salient aspect of it is supported by recent work in\nneuroscience investigating possible implementations of Bayes nets at the neural\nlevel. $\\mathcal{D}^\\ast$ nicely exemplifies how the pursuit of cognitive\nplausibility can lead to the discovery of state-of-the-art algorithms with\nappealing properties, and its simplicity makes $\\mathcal{D}^\\ast$ potentially a\ngood candidate for pedagogical purposes.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 19:42:45 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Nobandegani", "Ardavan S.", ""], ["Psaromiligkos", "Ioannis N.", ""]]}, {"id": "1801.10356", "submitter": "Pablo Villegas G\\'ongora", "authors": "Serena di Santo, Pablo Villegas, Raffaella Burioni and Miguel A.\n  Mu\\~noz", "title": "Landau-Ginzburg theory of cortex dynamics: Scale-free avalanches emerge\n  at the edge of synchronization", "comments": "Pre-print version of the paper published in Proc. Natl. Acad. Sci.\n  USA", "journal-ref": null, "doi": "10.1073/pnas.1712989115", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech nlin.AO physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the origin, nature, and functional significance of complex\npatterns of neural activity, as recorded by diverse electrophysiological and\nneuroimaging techniques, is a central challenge in neuroscience. Such patterns\ninclude collective oscillations emerging out of neural synchronization as well\nas highly heterogeneous outbursts of activity interspersed by periods of\nquiescence, called \"neuronal avalanches.\" Much debate has been generated about\nthe possible scale invariance or criticality of such avalanches and its\nrelevance for brain function. Aimed at shedding light onto this, here we\nanalyze the large-scale collective properties of the cortex by using a\nmesoscopic approach following the principle of parsimony of Landau-Ginzburg.\nOur model is similar to that of Wilson-Cowan for neural dynamics but crucially,\nincludes stochasticity and space; synaptic plasticity and inhibition are\nconsidered as possible regulatory mechanisms. Detailed analyses uncover a phase\ndiagram including down-state, synchronous, asynchronous, and up-state phases\nand reveal that empirical findings for neuronal avalanches are consistently\nreproduced by tuning our model to the edge of synchronization. This reveals\nthat the putative criticality of cortical dynamics does not correspond to a\nquiescent-to-active phase transition as usually assumed in theoretical\napproaches but to a synchronization phase transition, at which incipient\noscillations and scale-free avalanches coexist. Furthermore, our model also\naccounts for up and down states as they occur (e.g., during deep sleep). This\napproach constitutes a framework to rationalize the possible collective phases\nand phase transitions of cortical networks in simple terms, thus helping to\nshed light on basic aspects of brain functioning from a very broad perspective.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 08:57:39 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["di Santo", "Serena", ""], ["Villegas", "Pablo", ""], ["Burioni", "Raffaella", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}, {"id": "1801.10542", "submitter": "Miho Fuyama", "authors": "Miho Fuyama, Hayato Saigo", "title": "Meanings, Metaphors, and Morphisms: Theory of Indeterminate Natural\n  Transformation (TINT)", "comments": "6 pages, 3figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present paper, we propose a new theory named \"Theory of indeterminate\nnatural transformation (TINT)\" to investigate the dynamical creation of\nmeanings as association relationships between images, focusing on the metaphor\ncomprehension as an example. TINT models the meaning creation as a kind of\nstochastic processes based on the mathematical structure defined by association\nrelationships as morphisms in category theory, so as to represent the\nindeterminate nature of structure-structure interactions between the systems of\nthe meanings of images. Such interactions are formulated in terms of so-called\ncoslice categories and functors as structure-preserving correspondence between\nthem. The relationship between such functors is \"indeterminate natural\ntransformation\", the central notion in TINT, which models the creation of\nmeanings in a precise manner. For instance, the process of metaphor\ncomprehension is modeled by the construction of indeterminate natural\ntransformation from a canonically defined functor which we call the\nbase-of-metaphor functor.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 16:48:46 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Fuyama", "Miho", ""], ["Saigo", "Hayato", ""]]}]