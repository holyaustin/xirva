[{"id": "1012.0353", "submitter": "Daniel Takahashi", "authors": "Daniel Yasumasa Takahashi, Luiz Antonio Baccal\\'a, Koichi Sameshima", "title": "Information theoretic interpretation of frequency domain connectivity\n  measures", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To provide adequate multivariate measures of information flow between neural\nstructures, modified expressions of Partial Directed Coherence (PDC) and\nDirected Transfer Function (DTF), two popular multivariate connectivity\nmeasures employed in neuroscience, are introduced and their formal relationship\nto mutual information rates are proved.\n", "versions": [{"version": "v1", "created": "Thu, 2 Dec 2010 00:11:52 GMT"}], "update_date": "2010-12-03", "authors_parsed": [["Takahashi", "Daniel Yasumasa", ""], ["Baccal\u00e1", "Luiz Antonio", ""], ["Sameshima", "Koichi", ""]]}, {"id": "1012.0490", "submitter": "Alexander K. Vidybida", "authors": "Alexander K. Vidybida", "title": "Testing of information condensation in a model reverberating spiking\n  neural network", "comments": "12 pages, 9 figures, 40 references. Content of this work was\n  partially published in an abstract form in the abstract book of the 2nd\n  International Biophysics Congress and Biotechnology at GAP & 21th National\n  Biophysics Congress, (5-9 Oct. 2009) Diyarbakir, Turkey,\n  http://www.ibc2009.org/. In v2 the ancillary file movie.pdf is added, which\n  offers examples of neuronal network dynamics", "journal-ref": "International Journal of Neural Systems (IJNS), Volume: 21, Issue:\n  3 (June 2011), Page: 187-198", "doi": "10.1142/S0129065711002742", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information about external world is delivered to the brain in the form of\nstructured in time spike trains. During further processing in higher areas,\ninformation is subjected to a certain condensation process, which results in\nformation of abstract conceptual images of external world, apparently,\nrepresented as certain uniform spiking activity partially independent on the\ninput spike trains details. Possible physical mechanism of condensation at the\nlevel of individual neuron was discussed recently. In a reverberating spiking\nneural network, due to this mechanism the dynamics should settle down to the\nsame uniform/periodic activity in response to a set of various inputs. Since\nthe same periodic activity may correspond to different input spike trains, we\ninterpret this as possible candidate for information condensation mechanism in\na network. Our purpose is to test this possibility in a network model\nconsisting of five fully connected neurons, particularly, the influence of\ngeometric size of the network, on its ability to condense information. Dynamics\nof 20 spiking neural networks of different geometric sizes are modelled by\nmeans of computer simulation. Each network was propelled into reverberating\ndynamics by applying various initial input spike trains. We run the dynamics\nuntil it becomes periodic. The Shannon's formula is used to calculate the\namount of information in any input spike train and in any periodic state found.\nAs a result, we obtain explicit estimate of the degree of information\ncondensation in the networks, and conclude that it depends strongly on the\nnet's geometric size.\n", "versions": [{"version": "v1", "created": "Thu, 2 Dec 2010 16:52:04 GMT"}, {"version": "v2", "created": "Mon, 10 Jan 2011 16:42:46 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Vidybida", "Alexander K.", ""]]}, {"id": "1012.0946", "submitter": "Kingsley Cox", "authors": "Kingsley J.A. Cox and Paul R. Adams", "title": "Hocus-Socus: An Error Catastrophe for Complex Hebbian Learning Implies\n  Neocortical Proofreading", "comments": "10 pages 3 figs main text,85 pages 1 fig Suppl text Originally\n  submitted to Nature in June 2009 (but rejected)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neocortex is widely believed to be the seat of intelligence and \"mind\".\nHowever, it's unclear what \"mind\" is, or how the special features of neocortex\nenable it, though likely \"connectionist\" principles are involved *A. The key to\nintelligence1 is learning relationships between large numbers of signals (such\nas pixel values), rather than memorizing explicit patterns. Causes (such as\nobjects) can then be inferred from a learned internal model. These\nrelationships fall into 2 classes: simple pairwise or second-order correlations\n(socs), and complex, and vastly more numerous, higher-order correlations\n(hocsB), such as the product of 3 or more pixels averaged over a set of images.\nThus if 3 pixels correlate, they may give an \"edge\". Neurons with \"Hebbian\"\nsynapses (changing strength in response to input-output spike-coincidences) are\nsensitive to such correlations, and it's likely that learned internal models\nuse such neurons. Because output firing depends on input firing via the\nrelevant connection strengths, Hebbian learning provides, in a feedback manner,\nsensitivity to input correlations. Hocs are vital, since they express\n\"interesting\" structure2 (e.g. edges), but their detection requires nonlinear\nrules operating at synapses of individual neurons. Here we report that in\nsingle model neurons learning from hocs fails, and defaults to socs, if\nnonlinear Hebbian rules are not sufficiently connection-specific. Such failure\nwould inevitably occur if a neuron's input synapses were too crowded, and would\nundermine biological connectionism. Since the cortex must be hoc-sensitive to\nachieve the type of learning enabling mind, we propose it uses known, detailed\nbut poorly understood circuitry and physiology to \"proofread\" Hebbian\nconnections. Analogous DNA proofreading allows evolution of complex genomes\n(i.e. \"life\").\n", "versions": [{"version": "v1", "created": "Sat, 4 Dec 2010 20:23:23 GMT"}], "update_date": "2010-12-07", "authors_parsed": [["Cox", "Kingsley J. A.", ""], ["Adams", "Paul R.", ""]]}, {"id": "1012.1611", "submitter": "Alexander Bershadskii", "authors": "A. Bershadskii", "title": "Broken chaotic clocks of brain neurons and depression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Irregular spiking time-series obtained in vitro and in vivo from singular\nbrain neurons of different types of rats are analyzed by mapping to telegraph\nsignals. Since the neural information is coded in the length of the interspike\nintervals and their positions on the time axis, this mapping is the most direct\nway to map a spike train into a signal which allows a proper application of the\nFourier transform methods. This analysis shows that healthy neurons firing has\nperiodic and chaotic deterministic clocks while for the rats representing\ngenetic animal model of human depression these neuron clocks might be broken,\nthat results in decoherence between the depressive neurons firing. Since\ndepression is usually accompanied by a narrowing of consciousness this specific\ndecoherence can be considered as a cause of the phenomenon of the consciousness\nnarrowing as well. This suggestion is also supported by observation of the\nlarge-scale chaotic coherence of the posterior piriform and entorhinal\ncortices' electrical activity at transition from anesthesia to the waking state\nwith full consciousness.\n", "versions": [{"version": "v1", "created": "Tue, 7 Dec 2010 21:20:40 GMT"}, {"version": "v2", "created": "Sat, 5 Mar 2011 17:28:20 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Bershadskii", "A.", ""]]}, {"id": "1012.1813", "submitter": "Sebastiano de Franciscis Mr.", "authors": "Sebastiano de Franciscis, Samuel Johnson, and Joaqu\\'in J. Torres", "title": "Enhancing neural-network performance via assortativity", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": "10.1103/PhysRevE.83.036114", "report-no": null, "categories": "cond-mat.dis-nn cs.PF physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of attractor neural networks has been shown to depend\ncrucially on the heterogeneity of the underlying topology. We take this\nanalysis a step further by examining the effect of degree-degree correlations\n-- or assortativity -- on neural-network behavior. We make use of a method\nrecently put forward for studying correlated networks and dynamics thereon,\nboth analytically and computationally, which is independent of how the topology\nmay have evolved. We show how the robustness to noise is greatly enhanced in\nassortative (positively correlated) neural networks, especially if it is the\nhub neurons that store the information.\n", "versions": [{"version": "v1", "created": "Wed, 8 Dec 2010 17:33:04 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["de Franciscis", "Sebastiano", ""], ["Johnson", "Samuel", ""], ["Torres", "Joaqu\u00edn J.", ""]]}, {"id": "1012.2155", "submitter": "Hugo Gabriel Eyherabide", "authors": "Hugo Gabriel Eyherabide and In\\'es Samengo", "title": "Time and category information in pattern-based codes", "comments": "Free access at\n  http://www.frontiersin.org/computational_neuroscience/10.3389/fncom.2010.00145/abstract", "journal-ref": "Frontiers in Computational Neuroscience 4:145 (2010)", "doi": "10.3389/fncom.2010.00145", "report-no": null, "categories": "q-bio.NC q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensory stimuli are usually composed of different features (the what)\nappearing at irregular times (the when). Neural responses often use spike\npatterns to represent sensory information. The what is hypothesized to be\nencoded in the identity of the elicited patterns (the pattern categories), and\nthe when, in the time positions of patterns (the pattern timing). However, this\nstandard view is oversimplified. In the real world, the what and the when might\nnot be separable concepts, for instance, if they are correlated in the\nstimulus. In addition, neuronal dynamics can condition the pattern timing to be\ncorrelated with the pattern categories. Hence, timing and categories of\npatterns may not constitute independent channels of information. In this paper,\nwe assess the role of spike patterns in the neural code, irrespective of the\nnature of the patterns. We first define information-theoretical quantities that\nallow us to quantify the information encoded by different aspects of the neural\nresponse. We also introduce the notion of synergy/redundancy between time\npositions and categories of patterns. We subsequently establish the relation\nbetween the what and the when in the stimulus with the timing and the\ncategories of patterns. To that aim, we quantify the mutual information between\ndifferent aspects of the stimulus and different aspects of the response. This\nformal framework allows us to determine the precise conditions under which the\nstandard view holds, as well as the departures from this simple case. Finally,\nwe study the capability of different response aspects to represent the what and\nthe when in the neural response.\n", "versions": [{"version": "v1", "created": "Fri, 10 Dec 2010 01:29:10 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Eyherabide", "Hugo Gabriel", ""], ["Samengo", "In\u00e9s", ""]]}, {"id": "1012.3371", "submitter": "Vahid Salari", "authors": "M. Rahnama, I. Bokkon, J. Tuszynski, M. Cifra, P. Sardar, V. Salari", "title": "Emission of Mitochondrial Biophotons and their Effect on Electrical\n  Activity of Membrane via Microtubules", "comments": "22 pages, 7 figures", "journal-ref": "J Integrative Neuroscience, Vol. 10, No. 1, pages 65-88, 2011", "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we argue that, in addition to electrical and chemical signals\npropagating in the neurons of the brain, signal propagation takes place in the\nform of biophoton production. This statement is supported by recent\nexperimental confirmation of photon guiding properties of a single neuron. We\nhave investigated the interaction of mitochondrial biophotons with microtubules\nfrom a quantum mechanical point of view. Our theoretical analysis indicates\nthat the interaction of biophotons and microtubules causes\ntransitions/fluctuations of microtubules between coherent and incoherent\nstates. A significant relationship between the fluctuation function of\nmicrotubules and alpha-EEG diagrams is elaborated on in this paper. We argue\nthat the role of biophotons in the brain merits special attention.\n", "versions": [{"version": "v1", "created": "Mon, 13 Dec 2010 15:44:46 GMT"}, {"version": "v2", "created": "Fri, 14 Jan 2011 23:33:55 GMT"}, {"version": "v3", "created": "Wed, 30 Mar 2011 15:26:14 GMT"}], "update_date": "2011-03-31", "authors_parsed": [["Rahnama", "M.", ""], ["Bokkon", "I.", ""], ["Tuszynski", "J.", ""], ["Cifra", "M.", ""], ["Sardar", "P.", ""], ["Salari", "V.", ""]]}, {"id": "1012.3618", "submitter": "Vahid Salari", "authors": "I. Bokkon, V. Salari, J. Tuszynski", "title": "Emergence of Intrinsic Representations of Images by Feedforward and\n  Feedback Processes and Bioluminescent Photons in Early Retinotopic Areas", "comments": "18 pages, 4 figures, to be published in Journal of Integrative\n  Neuroscience", "journal-ref": "J Integrative Neuroscience, Vol 10, No. 1, pages 47-64, 2011", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we put forwarded a redox molecular hypothesis involving the natural\nbiophysical substrate of visual perception and imagery. Here, we explicitly\npropose that the feedback and feedforward iterative operation processes can be\ninterpreted in terms of a homunculus looking at the biophysical picture in our\nbrain during visual imagery. We further propose that the brain can use both\npicture-like and language-like representation processes. In our interpretation,\nvisualization (imagery) is a special kind of representation i.e., visual\nimagery requires a peculiar inherent biophysical (picture-like) mechanism. We\nalso conjecture that the evolution of higher levels of complexity made the\nbiophysical picture representation of the external visual world possible by\ncontrolled redox and bioluminescent nonlinear (iterative) biochemical reactions\nin the V1 and V2 areas during visual imagery. Our proposal deals only with the\nprimary level of visual representation (i.e. perceived \"scene\").\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 14:32:19 GMT"}], "update_date": "2011-03-31", "authors_parsed": [["Bokkon", "I.", ""], ["Salari", "V.", ""], ["Tuszynski", "J.", ""]]}, {"id": "1012.3623", "submitter": "Woodrow L Shew", "authors": "Woodrow L. Shew, Hongdian Yang, Shan Yu, Rajarshi Roy, Dietmar Plenz", "title": "Information capacity and transmission are maximized in balanced cortical\n  networks with neuronal avalanches", "comments": null, "journal-ref": "The Journal of Neuroscience, January 5, 2011 31(01)", "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The repertoire of neural activity patterns that a cortical network can\nproduce constrains the network's ability to transfer and process information.\nHere, we measured activity patterns obtained from multi-site local field\npotential (LFP) recordings in cortex cultures, urethane anesthetized rats, and\nawake macaque monkeys. First, we quantified the information capacity of the\npattern repertoire of ongoing and stimulus-evoked activity using Shannon\nentropy. Next, we quantified the efficacy of information transmission between\nstimulus and response using mutual information. By systematically changing the\nratio of excitation/inhibition (E/I) in vitro and in a network model, we\ndiscovered that both information capacity and information transmission are\nmaximized at a particular intermediate E/I, at which ongoing activity emerges\nas neuronal avalanches. Next, we used our in vitro and model results to\ncorrectly predict in vivo information capacity and interactions between\nneuronal groups during ongoing activity. Close agreement between our\nexperiments and model suggest that neuronal avalanches and peak information\ncapacity arise due to criticality and are general properties of cortical\nnetworks with balanced E/I.\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 14:37:47 GMT"}], "update_date": "2010-12-17", "authors_parsed": [["Shew", "Woodrow L.", ""], ["Yang", "Hongdian", ""], ["Yu", "Shan", ""], ["Roy", "Rajarshi", ""], ["Plenz", "Dietmar", ""]]}, {"id": "1012.3625", "submitter": "Vahid Salari", "authors": "I. Bokkon, V. Salari, J. Tuszynski, I. Antal", "title": "Estimation of the number of biophotons involved in the visual perception\n  of a single-object image: Biophoton intensity can be considerably higher\n  inside cells than outside", "comments": "16 pages, 3 figures", "journal-ref": "J Photochem Photobiol B, 100, 160-166, (2010)", "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we have proposed a redox molecular hypothesis about the natural\nbiophysical substrate of visual perception and imagery (B\\'okkon, 2009.\nBioSystems; B\\'okkon and D'Angiulli, 2009. Bioscience Hypotheses). Namely, the\nretina transforms external photon signals into electrical signals that are\ncarried to the V1 (striate cortex). Then, V1 retinotopic electrical signals\n(spike-related electrical signals along classical axonal-dendritic pathways)\ncan be converted into regulated ultraweak bioluminescent photons (biophotons)\nthrough redox processes within retinotopic visual neurons that make it possible\nto create intrinsic biophysical pictures during visual perception and imagery.\nHowever, the consensus opinion is to consider biophotons as by-products of\ncellular metabolism. This paper argues that biophotons are not by-products,\nother than originating from regulated cellular radical/redox processes. It also\nshows that the biophoton intensity can be considerably higher inside cells than\noutside. Our simple calculations, within a level of accuracy, suggest that the\nreal biophoton intensity in retinotopic neurons may be sufficient for creating\nintrinsic biophysical picture representation of a single-object image during\nvisual perception.\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 14:43:29 GMT"}], "update_date": "2010-12-17", "authors_parsed": [["Bokkon", "I.", ""], ["Salari", "V.", ""], ["Tuszynski", "J.", ""], ["Antal", "I.", ""]]}, {"id": "1012.3743", "submitter": "Lech S. Borkowski", "authors": "L. S. Borkowski", "title": "Bistability and resonance in the periodically stimulated Hodgkin-Huxley\n  model with noise", "comments": "The size of the figures in this version is larger than in the\n  published article", "journal-ref": "Physical Review E 83, 051901 (2011)", "doi": "10.1103/PhysRevE.83.051901", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe general characteristics of the Hodgkin-Huxley neuron's response\nto a periodic train of short current pulses with Gaussian noise. The\ndeterministic neuron is bistable for antiresonant frequencies. When the stimuli\narrive at the resonant frequency the firing rate is a continuous function of\nthe current amplitude $I_0$ and scales as $(I_0-I_{th})^{1/2}$, where $I_{th}$\nis an approximate threshold. Intervals of continuous irregular response\nalternate with integer mode-locked regions with bistable excitation edge. There\nis an even-all multimodal transition between the 2:1 and 3:1 states in the\nvicinity of the main resonance, which is analogous to the odd-all transition\ndiscovered earlier in the high-frequency regime. For $I_0<I_{th}$ and small\nnoise the firing rate has a maximum at the resonant frequency. For larger noise\nand subthreshold stimulation the maximum firing rate initially shifts towards\nlower frequencies, then returns to higher frequencies in the limit of large\nnoise. The stochastic coherence antiresonance, defined as the maximum of the\ncoefficient of variation as a function of noise intensity, occurs over a wide\nrange of parameter values, including monostable regions.\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 20:51:32 GMT"}, {"version": "v2", "created": "Thu, 21 Apr 2011 12:58:34 GMT"}, {"version": "v3", "created": "Thu, 26 May 2011 13:20:51 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Borkowski", "L. S.", ""]]}, {"id": "1012.3801", "submitter": "Leonid Perlovsky", "authors": "Leonid Perlovsky", "title": "Beauty and Art. Cognitive Function, Evolution, and Mathematical Models\n  of the Mind", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper discusses relationships between aesthetics theory and mathematical\nmodels of mind. Mathematical theory describes abilities for concepts, emotions,\ninstincts, imagination, adaptation, learning, cognition, language, approximate\nhierarchy of the mind and evolution of these abilities. The knowledge instinct\nis the foundation of higher mental abilities and aesthetic emotions. Aesthetic\nemotions are present in every act of perception and cognition, and at the top\nof the mind hierarchy they become emotions of the beautiful. The learning\nability is essential to everyday perception and cognition as well as to the\nhistorical development of understanding of the meaning of life. I discuss a\ncontroversy surrounding this issue. Conclusions based on cognitive and\nmathematical models confirm that judgments of taste are at once subjective and\nobjective, and I discuss what it means. The paper relates cognitive and\nmathematical concepts to those of philosophy and aesthetics, from Plato to our\ndays, clarifies cognitive mechanisms and functions of the beautiful, and\nresolves many difficulties of contemporary aesthetics.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 03:18:55 GMT"}], "update_date": "2010-12-20", "authors_parsed": [["Perlovsky", "Leonid", ""]]}, {"id": "1012.3803", "submitter": "Leonid Perlovsky", "authors": "Leonid Perlovsky", "title": "Physics of the mind: Concepts, emotions, language, cognition,\n  consciousness, beauty, music, and symbolic culture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical approaches to modeling the mind since the 1950s are reviewed.\nDifficulties faced by these approaches are related to the fundamental\nincompleteness of logic discovered by K. G\\\"odel. A recent mathematical\nadvancement, dynamic logic (DL) overcame these past difficulties. DL is\ndescribed conceptually and related to neuroscience, psychology, cognitive\nscience, and philosophy. DL models higher cognitive functions: concepts,\nemotions, instincts, understanding, imagination, intuition, consciousness. DL\nis related to the knowledge instinct that drives our understanding of the world\nand serves as a foundation for higher cognitive functions. Aesthetic emotions\nand perception of beauty are related to 'everyday' functioning of the mind. The\narticle reviews mechanisms of human symbolic ability, language and cognition,\njoint evolution of the mind, consciousness, and cultures. It touches on a\nmanifold of aesthetic emotions in music, their cognitive function, origin, and\nevolution. The article concentrates on elucidating the first principles and\nreviews aspects of the theory proven in laboratory research.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 03:45:00 GMT"}], "update_date": "2010-12-20", "authors_parsed": [["Perlovsky", "Leonid", ""]]}, {"id": "1012.3879", "submitter": "Vahid Salari", "authors": "V. Salari, J. Tuszynski, M. Rahnama, G. Bernroider", "title": "Plausibility of Quantum Coherent States in Biological Systems", "comments": "10 pages, no figures. DICE 2010, In press in Journal of Physics,\n  Conf. Ser", "journal-ref": "JPCS, 306 (2011) 012075", "doi": "10.1088/1742-6596/306/1/012075", "report-no": null, "categories": "physics.bio-ph q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we briefly discuss the necessity of using quantum mechanics as\na fundamental theory applicable to some key functional aspects of biological\nsystems. This is especially relevant to three important parts of a neuron in\nthe human brain, namely the cell membrane, microtubules (MT) and ion channels.\nWe argue that the recently published papers criticizing the use of quantum\ntheory in these systems are not convincing.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 13:55:55 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Salari", "V.", ""], ["Tuszynski", "J.", ""], ["Rahnama", "M.", ""], ["Bernroider", "G.", ""]]}, {"id": "1012.3896", "submitter": "William Bialek", "authors": "Greg J. Stephens, Leslie C. Osborne and William Bialek", "title": "Searching for simplicity: Approaches to the analysis of neurons and\n  behavior", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1010868108", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What fascinates us about animal behavior is its richness and complexity, but\nunderstanding behavior and its neural basis requires a simpler description.\nTraditionally, simplification has been imposed by training animals to engage in\na limited set of behaviors, by hand scoring behaviors into discrete classes, or\nby limiting the sensory experience of the organism. An alternative is to ask\nwhether we can search through the dynamics of natural behaviors to find\nexplicit evidence that these behaviors are simpler than they might have been.\nWe review two mathematical approaches to simplification, dimensionality\nreduction and the maximum entropy method, and we draw on examples from\ndifferent levels of biological organization, from the crawling behavior of C.\nelegans to the control of smooth pursuit eye movements in primates, and from\nthe coding of natural scenes by networks of neurons in the retina to the rules\nof English spelling. In each case, we argue that the explicit search for\nsimplicity uncovers new and unexpected features of the biological system, and\nthat the evidence for simplification gives us a language with which to phrase\nnew questions for the next generation of experiments. The fact that similar\nmathematical structures succeed in taming the complexity of very different\nbiological systems hints that there is something more general to be discovered.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 14:51:35 GMT"}], "update_date": "2016-07-13", "authors_parsed": [["Stephens", "Greg J.", ""], ["Osborne", "Leslie C.", ""], ["Bialek", "William", ""]]}, {"id": "1012.3957", "submitter": "Leonid Perlovsky", "authors": "Leonid Perlovsky", "title": "Free Will and Advances in Cognitive Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Free will is fundamental to morality, intuition of self, and normal\nfunctioning of the society. However, science does not provide a clear logical\nfoundation for this idea. This paper considers the fundamental scientific\nargument against free will, called reductionism, and explains the reasons for\nchoosing dualism against monism. Then, the paper summarizes unexpected\nconclusions from recent discoveries in cognitive science. Classical logic turns\nout not to be the fundamental mechanism of mind. It is replaced by dynamic\nlogic. Mathematical and experimental evidence are considered conceptually.\nDynamic logic counters logical arguments for reductionism. Contemporary science\nof mind is not reducible; free will can be scientifically accepted along with\nscientific monism.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 18:37:54 GMT"}], "update_date": "2010-12-20", "authors_parsed": [["Perlovsky", "Leonid", ""]]}, {"id": "1012.4422", "submitter": "Christoph Haselwandter", "authors": "Christoph A. Haselwandter, Martino Calamai, Mehran Kardar, Antoine\n  Triller, and Rava Azeredo da Silveira", "title": "Formation and Stability of Synaptic Receptor Domains", "comments": "5 pages, 3 figures, Supplementary Material", "journal-ref": "Phys. Rev. Lett. 106, 238104 (2011)", "doi": "10.1103/PhysRevLett.106.238104", "report-no": null, "categories": "q-bio.NC cond-mat.soft cond-mat.stat-mech q-bio.BM q-bio.MN q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurotransmitter receptor molecules, concentrated in postsynaptic domains\nalong with scaffold and a number of other molecules, are key regulators of\nsignal transmission across synapses. Employing experiment and theory, we\ndevelop a quantitative description of synaptic receptor domains in terms of a\nreaction-diffusion model. We show that interactions between only receptor and\nscaffold molecules, together with the rapid diffusion of receptors on the cell\nmembrane, are sufficient for the formation and stable characteristic size of\nsynaptic receptor domains. Our work reconciles long-term stability of synaptic\nreceptor domains with rapid turnover and diffusion of individual receptors.\n", "versions": [{"version": "v1", "created": "Mon, 20 Dec 2010 18:08:22 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Haselwandter", "Christoph A.", ""], ["Calamai", "Martino", ""], ["Kardar", "Mehran", ""], ["Triller", "Antoine", ""], ["da Silveira", "Rava Azeredo", ""]]}, {"id": "1012.5649", "submitter": "Valmir Barbosa", "authors": "Andre Nathan, Valmir C. Barbosa", "title": "Network algorithmics and the emergence of information integration in\n  cortical models", "comments": null, "journal-ref": "Physical Review E 84 (2011), 011904", "doi": "10.1103/PhysRevE.84.011904", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An information-theoretic framework known as integrated information theory\n(IIT) has been introduced recently for the study of the emergence of\nconsciousness in the brain [D. Balduzzi and G. Tononi, PLoS Comput. Biol. 4,\ne1000091 (2008)]. IIT purports that this phenomenon is to be equated with the\ngeneration of information by the brain surpassing the information which the\nbrain's constituents already generate independently of one another. IIT is not\nfully plausible in its modeling assumptions, nor is it testable due to severe\ncombinatorial growth embedded in its key definitions. Here we introduce an\nalternative to IIT which, while inspired in similar information-theoretic\nprinciples, seeks to address some of IIT's shortcomings to some extent. Our\nalternative framework uses the same network-algorithmic cortical model we\nintroduced earlier [A. Nathan and V. C. Barbosa, Phys. Rev. E 81, 021916\n(2010)] and, to allow for somewhat improved testability relative to IIT, adopts\nthe well-known notions of information gain and total correlation applied to a\nset of variables representing the reachability of neurons by messages in the\nmodel's dynamics. We argue that these two quantities relate to each other in\nsuch a way that can be used to quantify the system's efficiency in generating\ninformation beyond that which does not depend on integration, and give\ncomputational results on our cortical model and on variants thereof that are\neither structurally random in the sense of an Erdos-Renyi random directed graph\nor structurally deterministic. We have found that our cortical model stands out\nwith respect to the others in the sense that many of its instances are capable\nof integrating information more efficiently than most of those others'\ninstances.\n", "versions": [{"version": "v1", "created": "Mon, 27 Dec 2010 19:42:38 GMT"}], "update_date": "2011-07-11", "authors_parsed": [["Nathan", "Andre", ""], ["Barbosa", "Valmir C.", ""]]}, {"id": "1012.5958", "submitter": "Erich Schmid", "authors": "Erich W. Schmid, Robert Wilke", "title": "Electric Stimulation of the Retina", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two computational models to be used as tools for experimental research on the\nretinal implant are presented. In the first model, the electric field produced\nby a multi-electrode array in a uniform retina is calculated. In the second\nmodel, the depolarization of the cell membrane of a probe cylinder is\ncalculated. It is shown how these models can be used to answer questions as to\ncross talk of activated electrodes, bunching of field lines in monopole and\ndipole activation, sequential stimulation, etc. The depolarization as a\nfunction of time indicates that shorter signals stimulate better, as long as\nthe current does not change sign during stimulation.\n", "versions": [{"version": "v1", "created": "Wed, 29 Dec 2010 15:13:43 GMT"}], "update_date": "2010-12-30", "authors_parsed": [["Schmid", "Erich W.", ""], ["Wilke", "Robert", ""]]}, {"id": "1012.5987", "submitter": "Feraz Azhar", "authors": "Feraz Azhar, William Bialek", "title": "When are correlations strong?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inverse problem of statistical mechanics involves finding the minimal\nHamiltonian that is consistent with some observed set of correlation functions.\nThis problem has received renewed interest in the analysis of biological\nnetworks; in particular, several such networks have been described successfully\nby maximum entropy models consistent with pairwise correlations. These\ncorrelations are usually weak in an absolute sense (e.g., correlation\ncoefficients ~ 0.1 or less), and this is sometimes taken as evidence against\nthe existence of interesting collective behavior in the network. If\ncorrelations are weak, it should be possible to capture their effects in\nperturbation theory, so we develop an expansion for the entropy of Ising\nsystems in powers of the correlations, carrying this out to fourth order. We\nthen consider recent work on networks of neurons [Schneidman et al., Nature\n440, 1007 (2006); Tkacik et al., arXiv:0912.5409 [q-bio.NC] (2009)], and show\nthat even though all pairwise correlations are weak, the fact that these\ncorrelations are widespread means that their impact on the network as a whole\nis not captured in the leading orders of perturbation theory. More positively,\nthis means that recent successes of maximum entropy approaches are not simply\nthe result of correlations being weak.\n", "versions": [{"version": "v1", "created": "Wed, 29 Dec 2010 17:29:34 GMT"}], "update_date": "2010-12-30", "authors_parsed": [["Azhar", "Feraz", ""], ["Bialek", "William", ""]]}, {"id": "1012.6019", "submitter": "Alexander K. Vidybida", "authors": "Kseniya Kravchuk and Alexander Vidybida", "title": "Delayed feedback causes non-Markovian behavior of neuronal firing\n  statistics", "comments": "21 pages, 7 figures, 20 refs, submitted to Journal of Physics A. File\n  movie.pdf is added as ancillary file", "journal-ref": "Ukrainian Mathematical Journal, Vol. 64, pp. 1587--1609 (2012)", "doi": null, "report-no": null, "categories": "q-bio.NC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The instantaneous state of a neural network consists of both the degree of\nexcitation of each neuron, the network is composed of, and positions of\nimpulses in communication lines between neurons. In neurophysiological\nexperiments, the neuronal firing moments are registered, but not the state of\ncommunication lines. But future spiking moments depend essentially on the past\npositions of impulses in the lines. This suggests, that the sequence of\nintervals between firing moments (interspike intervals, ISIs) in the network\ncould be non-Markovian. In this paper, we address this question for a simplest\npossible neural \"net\", namely, a single neuron with delayed feedback. The\nneuron receives excitatory input both from the driving Poisson stream and from\nits own output through the feedback line. We obtain analytical expressions for\nconditional probability density $P(t_{n+1} | t_n,...,t_1,t_0)$, which gives the\nprobability to get an output ISI of duration $t_{n+1}$ provided the previous\n$(n+1)$ output ISIs had durations $t_n,...,t_1,t_0$. It is proven exactly, that\n$P(t_{n+1} | t_n,...,t_1,t_0)$ does not reduce to $P(t_{n+1} | t_n,...,t_1)$\nfor any $n \\geq 0$. This means that the output ISIs stream cannot be\nrepresented as Markov chain of any finite order.\n", "versions": [{"version": "v1", "created": "Wed, 29 Dec 2010 20:01:46 GMT"}, {"version": "v2", "created": "Thu, 30 Dec 2010 14:36:25 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Kravchuk", "Kseniya", ""], ["Vidybida", "Alexander", ""]]}]