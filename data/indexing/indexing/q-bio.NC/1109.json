[{"id": "1109.2036", "submitter": "Leonardo L. Gollo", "authors": "Leonardo L. Gollo, Osame Kinouchi and Mauro Copelli", "title": "Statistical Physics approach to dendritic computation: The\n  excitable-wave mean-field approximation", "comments": "30 pages, 8 figures", "journal-ref": "Phys. Rev. E, 85, 011911 (2012)", "doi": "10.1103/PhysRevE.85.011911", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech nlin.CG physics.bio-ph q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analytically study the input-output properties of a neuron whose active\ndendritic tree, modeled as a Cayley tree of excitable elements, is subjected to\nPoisson stimulus. Both single-site and two-site mean-field approximations\nincorrectly predict a non-equilibrium phase transition which is not allowed in\nthe model. We propose an excitable-wave mean-field approximation which shows\ngood agreement with previously published simulation results [Gollo et al., PLoS\nComput. Biol. 5(6) e1000402 (2009)] and accounts for finite-size effects. We\nalso discuss the relevance of our results to experiments in neuroscience,\nemphasizing the role of active dendrites in the enhancement of dynamic range\nand in gain control modulation.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2011 15:03:09 GMT"}, {"version": "v2", "created": "Fri, 13 Jan 2012 20:10:34 GMT"}], "update_date": "2012-01-18", "authors_parsed": [["Gollo", "Leonardo L.", ""], ["Kinouchi", "Osame", ""], ["Copelli", "Mauro", ""]]}, {"id": "1109.2083", "submitter": "Fernanda Matias", "authors": "Fernanda S. Matias, Pedro V. Carelli, Claudio R. Mirasso and Mauro\n  Copelli", "title": "Anticipated Synchronization in a Biologically Plausible Model of\n  Neuronal Motifs", "comments": null, "journal-ref": "Physical Review E 84, 021922 (2011)", "doi": "10.1103/PhysRevE.84.021922", "report-no": null, "categories": "q-bio.NC physics.bio-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two identical autonomous dynamical systems coupled in a master-slave\nconfiguration can exhibit anticipated synchronization (AS) if the slave also\nreceives a delayed negative self-feedback. Recently, AS was shown to occur in\nsystems of simplified neuron models, requiring the coupling of the neuronal\nmembrane potential with its delayed value. However, this coupling has no\nobvious biological correlate. Here we propose a canonical neuronal microcircuit\nwith standard chemical synapses, where the delayed inhibition is provided by an\ninterneuron. In this biologically plausible scenario, a smooth transition from\ndelayed synchronization (DS) to AS typically occurs when the inhibitory\nsynaptic conductance is increased. The phenomenon is shown to be robust when\nmodel parameters are varied within physiological range. Since the DS-AS\ntransition amounts to an inversion in the timing of the pre- and post-synaptic\nspikes, our results could have a bearing on spike-timing-dependent-plasticity\nmodels.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2011 18:21:04 GMT"}], "update_date": "2011-09-12", "authors_parsed": [["Matias", "Fernanda S.", ""], ["Carelli", "Pedro V.", ""], ["Mirasso", "Claudio R.", ""], ["Copelli", "Mauro", ""]]}, {"id": "1109.2239", "submitter": "Joel Zylberberg", "authors": "Joel Zylberberg, Jason Timothy Murphy, and Michael Robert DeWeese", "title": "A sparse coding model with synaptically local plasticity and spiking\n  neurons can account for the diverse shapes of V1 simple cell receptive fields", "comments": "33 pages, 6 figures. To appear in PLoS Computational Biology. Some of\n  these data were presented by author JZ at the 2011 CoSyNe meeting in Salt\n  Lake City", "journal-ref": "PLoS Computational Biology (2011) 7(10): e1002250", "doi": "10.1371/journal.pcbi.1002250", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding algorithms trained on natural images can accurately predict the\nfeatures that excite visual cortical neurons, but it is not known whether such\ncodes can be learned using biologically realistic plasticity rules. We have\ndeveloped a biophysically motivated spiking network, relying solely on\nsynaptically local information, that can predict the full diversity of V1\nsimple cell receptive field shapes when trained on natural images. This\nrepresents the first demonstration that sparse coding principles, operating\nwithin the constraints imposed by cortical architecture, can successfully\nreproduce these receptive fields. We further prove, mathematically, that\nsparseness and decorrelation are the key ingredients that allow for\nsynaptically local plasticity rules to optimize a cooperative, linear\ngenerative image model formed by the neural representation. Finally, we discuss\nseveral interesting emergent properties of our network, with the intent of\nbridging the gap between theoretical and experimental studies of visual cortex.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2011 17:36:38 GMT"}], "update_date": "2011-11-01", "authors_parsed": [["Zylberberg", "Joel", ""], ["Murphy", "Jason Timothy", ""], ["DeWeese", "Michael Robert", ""]]}, {"id": "1109.2556", "submitter": "Choongseok Park", "authors": "Choongseok Park and Leonid L. Rubchinsky", "title": "Intermittent synchronization in a network of bursting neurons", "comments": "36 pages, 11 figures", "journal-ref": "Chaos, 21, 033125, 2011", "doi": "10.1063/1.3633078", "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronized oscillations in networks of inhibitory and excitatory coupled\nbursting neurons are common in a variety of neural systems from central pattern\ngenerators to human brain circuits. One example of the latter is the\nsubcortical network of the basal ganglia, formed by excitatory and inhibitory\nbursters of the subthalamic nucleus and globus pallidus, involved in motor\ncontrol and affected in Parkinson's disease. Recent experiments have\ndemonstrated the intermittent nature of the phase-locking of neural activity in\nthis network. Here we explore one potential mechanism to explain the\nintermittent phase-locking in a network. We simplify the network to obtain a\nmodel of two inhibitory coupled elements and explore its dynamics. We used\ngeometric analysis and singular perturbation methods for dynamical systems to\nreduce the full model to a simpler set of equations. Mathematical analysis was\ncompleted using three slow variables with two different time scales.\nIntermittently synchronous oscillations are generated by overlapped spiking\nwhich crucially depends on the geometry of the slow phase plane and the\ninterplay between slow variables as well as the strength of synapses. Two slow\nvariables are responsible for the generation of activity patterns with\noverlapped spiking and the other slower variable enhances the robustness of an\nirregular and intermittent activity pattern. While the analyzed network and the\nexplored mechanism of intermittent synchrony appear to be quite generic, the\nresults of this analysis can be used to trace particular values of biophysical\nparameters (synaptic strength and parameters of calcium dynamics), which are\nknown to be impacted in Parkinson's disease.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 18:18:34 GMT"}], "update_date": "2011-09-21", "authors_parsed": [["Park", "Choongseok", ""], ["Rubchinsky", "Leonid L.", ""]]}, {"id": "1109.2577", "submitter": "Sinisa Pajevic", "authors": "Sinisa Pajevic, Dietmar Plenz", "title": "The Organization of Strong Links in Complex Networks", "comments": "21 pages, 9 figures, 1 table in the main text + Supplementary\n  Material", "journal-ref": null, "doi": "10.1038/nphys2257", "report-no": null, "categories": "physics.soc-ph cs.SI q-bio.NC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  A small-world topology characterizes many complex systems including the\nstructural and functional organization of brain networks. The topology allows\nsimultaneously for local and global efficiency in the interaction of the system\nconstituents. However, it ignores the gradations of interactions commonly\nquantified by the link weight, w. Here, we identify an integrative weight\norganization for brain, gene, social, and language networks, in which strong\nlinks preferentially occur between nodes with overlapping neighbourhoods and\nthe small-world properties are robust to removal of a large fraction of the\nweakest links. We also determine local learning rules that dynamically\nestablish such weight organization in response to past activity and capacity\ndemands, while preserving efficient local and global communication.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 19:39:02 GMT"}, {"version": "v2", "created": "Wed, 14 Sep 2011 19:21:18 GMT"}], "update_date": "2015-05-30", "authors_parsed": [["Pajevic", "Sinisa", ""], ["Plenz", "Dietmar", ""]]}, {"id": "1109.2893", "submitter": "Lech S. Borkowski", "authors": "L. S. Borkowski", "title": "Multimodal transition and excitability of a neural oscillator", "comments": null, "journal-ref": "Acta Phys. Pol. A 122, 776 (2012)", "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the response of the Morris-Lecar model to a periodic train of\nshort current pulses in the period-amplitude plane. For a wide parameter range\nencompassing both class 2 and class 3 behavior in Hodgkin's classification\nthere is a multimodal transition between the set of odd modes and the set of\nall modes. It is located between the 2:1 and 3:1 locked-in regions. It is the\nsame dynamic instability as the one discovered earlier in the Hodgkin-Huxley\nmodel and observed experimentally in squid giant axons. It appears\nsimultaneously with the bistability of the states 2:1 and 3:1 in the\nperithreshold regime. These results imply that the multimodal transition may be\na universal property of resonant neurons.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2011 19:45:19 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2012 19:56:57 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["Borkowski", "L. S.", ""]]}, {"id": "1109.3014", "submitter": "Salort Delphine", "authors": "Khashayar Pakdaman, Beno\\^it Perthame, Delphine Salort", "title": "Relaxation and self-sustained oscillations in the time elapsed neuron\n  network model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time elapsed model describes the firing activity of an homogeneous\nassembly of neurons thanks to the distribution of times elapsed since the last\ndischarge. It gives a mathematical description of the probability density of\nneurons structured by this time. In an earlier work, based on generalized\nrelative entropy methods, it is proved that for highly or weakly connected\nnetworks the model exhibits relaxation to the steady state and for moderately\nconnected networks it is obtained numerical evidence of appearance of\nself-sustained periodic solutions.\n  Here, we go further and, using the particular form of the model, we quantify\nthe regime where relaxation to a stationary state occurs in terms of the\nnetwork connectivity. To introduce our methodology, we first consider the case\nwhere the neurons are not connected and we give a new statement showing that\ntotal asynchronous firing of neurons appears asymptotically. In a second step,\nwe consider the case with connections and give a low connectivity condition\nthat still leads to asynchronous firing. Our low connectivity condition is\nsomehow sharp because we can give an example, when this condition is not\nfulfilled, where synchronous rhythmic activity occurs. Indeed, we are able to\nbuild several explicit families of periodic solutions. Our construction is\nfully nonlinear and the resynchronization of the neural activity in the network\ndoes not follow from bifurcation analysis. It relies on an algebraically\nnonlinear boundary condition that occurs in the model.These analytic results\nare compared with numerical simulations under broader hypotheses and shown to\nbe robust.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2011 08:27:46 GMT"}, {"version": "v2", "created": "Thu, 15 Sep 2011 08:52:56 GMT"}], "update_date": "2011-09-16", "authors_parsed": [["Pakdaman", "Khashayar", ""], ["Perthame", "Beno\u00eet", ""], ["Salort", "Delphine", ""]]}, {"id": "1109.3582", "submitter": "Carlo Barbieri", "authors": "Carlo Barbieri", "title": "Some inverse problems in biophysics", "comments": "PhD dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cond-mat.dis-nn cond-mat.stat-mech q-bio.GN q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the past few years the development of experimental techniques has\nallowed the quantitative analysis of biological systems ranging from\nneurobiology and molecular biology. This work focuses on the quantitative\ndescription of these systems by means of theoretical and numerical tools\nranging from statistical physics to probability theory.\n  This dissertation is divided in three parts, each of which has a different\nbiological system as its focus.\n  The first such system is Infotaxis, an olfactory search algorithm proposed by\nVergassola et al. in 2007: we give a continuous formulation and we characterize\nits performances.\n  Secondly we will focus on single-molecule experiments, especially unzipping\nof DNA molecules, whose experimental traces depend strongly on the DNA\nsequence: we develop a detailed model of the dynamics for this kind of\nexperiments and then we propose several inference algorithm aiming at the\ncharacterization of the genetic sequence.\n  The last section is devoted to the description of an algorithm that allows\nthe inference of interactions between neurons given the recording of neural\nactivity from multi-electrode experiments; we propose an integrated software\nthat will allow the analysis of these data.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2011 11:07:10 GMT"}], "update_date": "2011-09-19", "authors_parsed": [["Barbieri", "Carlo", ""]]}, {"id": "1109.3798", "submitter": "Jr-Shin Li", "authors": "Isuru Dasanayake and Jr-Shin Li", "title": "Charge-Balanced Minimum-Power Controls for Spiking Neuron Oscillators", "comments": "24 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.SY math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the optimal control of phase models for spiking\nneuron oscillators. We focus on the design of minimum-power current stimuli\nthat elicit spikes in neurons at desired times. We furthermore take the\ncharge-balanced constraint into account because in practice undesirable side\neffects may occur due to the accumulation of electric charge resulting from\nexternal stimuli. Charge-balanced minimum-power controls are derived for a\ngeneral phase model using the maximum principle, where the cases with unbounded\nand bounded control amplitude are examined. The latter is of practical\nimportance since phase models are more accurate for weak forcing. The developed\noptimal control strategies are then applied to both mathematically ideal and\nexperimentally observed phase models to demonstrate their applicability,\nincluding the phase model for the widely studied Hodgkin-Huxley equations.\n", "versions": [{"version": "v1", "created": "Sat, 17 Sep 2011 15:54:06 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Dasanayake", "Isuru", ""], ["Li", "Jr-Shin", ""]]}, {"id": "1109.3888", "submitter": "Daniel Kelleher", "authors": "Daniel J. Kelleher, Tyler M. Reese, Dylan T. Yott, Antoni Brzoska", "title": "Analysing properties of the C. Elegans neural network: mathematically\n  modeling a biological system", "comments": "24 Pages, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain is one of the most studied and highly complex systems in the\nbiological world. It is the information center behind all vertebrate and most\ninvertebrate life, and thus has become a major focus in current research. While\nmany of these studies have concentrated on studying the brain directly, our\nfocus is the structure of the brain itself: at its core an interconnected\nnetwork of nodes (neurons). A better understanding of the structural aspects of\nthe brain should elucidate some of its functional properties. In this paper we\nanalyze the brain of the nematode Caenorhabditis elegans. Consisting of only\n302 neurons, it is one of the better-understood neural networks. Using a\nLaplacian matrix of the 279-neuron \"giant component\" of the network, we use an\neigenvalue counting function to look for fractal-like self similarity. This\nmatrix representation is also used to plot (in eigenfunction coordinates) both\n2 and 3 dimensional visualizations of the neural network. Further analysis\nexamines the small-world properties of the system, including average path\nlength and clustering coefficient. We then test for localization of\neigenfunctions, using graph energy and spacial variance. To better understand\nthese results, all of these calculations are also performed on random networks,\nbranching trees, and known fractals, as well as fractals which have been\n\"rewired\" to have small-world properties. This analysis is one of many\nstepping-stones in the research of neural networks. While many of the\nstructures and functions within the brain are known, understanding how the two\ninteract is also important. A firmer grasp on the structural properties of the\nneural network is a key step in this process\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2011 17:03:11 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Kelleher", "Daniel J.", ""], ["Reese", "Tyler M.", ""], ["Yott", "Dylan T.", ""], ["Brzoska", "Antoni", ""]]}, {"id": "1109.4140", "submitter": "Marat Rvachev", "authors": "Marat M. Rvachev", "title": "Neuron as a reward-modulated combinatorial switch and a model of\n  learning behavior", "comments": "Version 5: added computer code in the ancillary files section", "journal-ref": "Neural Networks 46 (2013) 62-74", "doi": "10.1016/j.neunet.2013.04.010 10.17632/zk6t7tgrx9.1", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a neuronal circuitry layout and synaptic plasticity\nprinciples that allow the (pyramidal) neuron to act as a \"combinatorial\nswitch\". Namely, the neuron learns to be more prone to generate spikes given\nthose combinations of firing input neurons for which a previous spiking of the\nneuron had been followed by a positive global reward signal. The reward signal\nmay be mediated by certain modulatory hormones or neurotransmitters, e.g., the\ndopamine. More generally, a trial-and-error learning paradigm is suggested in\nwhich a global reward signal triggers long-term enhancement or weakening of a\nneuron's spiking response to the preceding neuronal input firing pattern. Thus,\nrewards provide a feedback pathway that informs neurons whether their spiking\nwas beneficial or detrimental for a particular input combination. The neuron's\nability to discern specific combinations of firing input neurons is achieved\nthrough a random or predetermined spatial distribution of input synapses on\ndendrites that creates synaptic clusters that represent various permutations of\ninput neurons. The corresponding dendritic segments, or the enclosed individual\nspines, are capable of being particularly excited, due to local sigmoidal\nthresholding involving voltage-gated channel conductances, if the segment's\nexcitatory and absence of inhibitory inputs are temporally coincident. Such\nnonlinear excitation corresponds to a particular firing combination of input\nneurons, and it is posited that the excitation strength encodes the\ncombinatorial memory and is regulated by long-term plasticity mechanisms. It is\nalso suggested that the spine calcium influx that may result from the\nspatiotemporal synaptic input coincidence may cause the spine head actin\nfilaments to undergo mechanical (muscle-like) contraction, with the ensuing\ncytoskeletal deformation transmitted to the axon initial segment where it\nmay...\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2011 03:19:08 GMT"}, {"version": "v2", "created": "Sun, 25 Sep 2011 21:55:40 GMT"}, {"version": "v3", "created": "Mon, 5 Mar 2012 02:01:18 GMT"}, {"version": "v4", "created": "Sat, 27 Apr 2013 21:32:06 GMT"}, {"version": "v5", "created": "Sun, 7 May 2017 22:49:11 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Rvachev", "Marat M.", ""]]}, {"id": "1109.6524", "submitter": "Yasser Roudi", "authors": "Peter E. Latham and Yasser Roudi", "title": "Role of correlations in population coding", "comments": "To appear in \"Principles of Neural Coding\", edited by Stefano Panzeri\n  and Rodrigo Quian Quiroga", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlations among spikes, both on the same neuron and across neurons, are\nubiquitous in the brain. For example cross-correlograms can have large peaks,\nat least in the periphery, and smaller -- but still non-negligible -- ones in\ncortex, and auto-correlograms almost always exhibit non-trivial temporal\nstructure at a range of timescales. Although this has been known for over forty\nyears, it's still not clear what role these correlations play in the brain --\nand, indeed, whether they play any role at all. The goal of this chapter is to\nshed light on this issue by reviewing some of the work on this subject.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2011 13:37:34 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Latham", "Peter E.", ""], ["Roudi", "Yasser", ""]]}]