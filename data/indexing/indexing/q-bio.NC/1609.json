[{"id": "1609.00001", "submitter": "Igor Ovchinnikov V.", "authors": "Igor V. Ovchinnikov, Wenyuan Li, Yuquan Sun, Robert N. Schwartz,\n  Andrew E. Hudson, Karlheinz Meier, Kang L. Wang", "title": "Criticality or Supersymmetry Breaking ?", "comments": "elsevier format, updated refs", "journal-ref": "Symmetry 12, 805 (2020)", "doi": "10.3390/sym12050805", "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many stochastic dynamical systems, ordinary chaotic behavior is preceded\nby a full-dimensional phase that exhibits 1/f-type power-spectra and/or\nscale-free statistics of (anti)instantons such as neuroavalanches, earthquakes,\netc. In contrast with the phenomenological concept of self-organized\ncriticality, the recently developed approximation-free supersymmetric theory of\nstochastic differential equations, or stochastics, (STS) identifies this phase\nas the noise-induced chaos (N-phase), i.e., the phase where the topological\nsupersymmetry pertaining to all stochastic dynamical systems is broken\nspontaneously by the condensation of the noise-induced (anti-)instantons. Here,\nwe support this picture in the context of neurodynamics. We study a 1D chain of\nneuron-like elements and find that the dynamics in the N-phase is indeed\nfeatured by positive stochastic Lyapunov exponents and dominated by\n(anti)instantonic processes of (creation)annihilation of kinks and antikinks,\nwhich can be viewed as predecessors of boundaries of neuroavalanches. We also\nconstruct the phase diagram of emulated stochastic neurodynamics on Spikey\nneuromorphic hardware and demonstrate that the width of the N-phase vanishes in\nthe deterministic limit in accordance with STS. As a first result of the\napplication of STS to neurodynamics comes the conclusion that a conscious brain\ncan reside only in the N-phase.\n", "versions": [{"version": "v1", "created": "Tue, 30 Aug 2016 21:04:10 GMT"}, {"version": "v2", "created": "Sun, 14 May 2017 03:05:36 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 22:29:03 GMT"}], "update_date": "2020-05-19", "authors_parsed": [["Ovchinnikov", "Igor V.", ""], ["Li", "Wenyuan", ""], ["Sun", "Yuquan", ""], ["Schwartz", "Robert N.", ""], ["Hudson", "Andrew E.", ""], ["Meier", "Karlheinz", ""], ["Wang", "Kang L.", ""]]}, {"id": "1609.00032", "submitter": "Qing Wan", "authors": "Chang Jin Wan, Wei Wang, Li Qiang Zhu, Yang Hui Liu, Ping Feng, Zhao\n  Ping Liu, Yi Shi, and Qing Wan", "title": "Flexible Metal Oxide/Graphene Oxide Hybrid Neuromorphic Devices on\n  Flexible Conducting Graphene Substrates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flexible metal oxide/graphene oxide hybrid multi-gate neuron transistors were\nfabricated on flexible graphene substrates. Dendritic integrations in both\nspatial and temporal modes were successfully emulated, and spatiotemporal\ncorrelated logics were obtained. A proof-of-principle visual system model for\nemulating lobula giant motion detector neuron was investigated. Our results are\nof great interest for flexible neuromorphic cognitive systems.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 07:02:51 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Wan", "Chang Jin", ""], ["Wang", "Wei", ""], ["Zhu", "Li Qiang", ""], ["Liu", "Yang Hui", ""], ["Feng", "Ping", ""], ["Liu", "Zhao Ping", ""], ["Shi", "Yi", ""], ["Wan", "Qing", ""]]}, {"id": "1609.00183", "submitter": "Lauri Ahonen", "authors": "Lauri Ahonen and Benjamin Cowley", "title": "A short review and primer on electroencephalography in human computer\n  interaction applications", "comments": "13 pages, 1 figure. Part of a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of psychophysiology in human-computer interaction is a\ngrowing field with significant potential for future smart personalised systems.\nWorking in this emerging field requires comprehension of an array of\nphysiological signals and analysis techniques.\n  Methods to study central nervous system (CNS) are usually expensive and\nlaborious. However, electroencephalography (EEG) is one of the most affordable\nand ambulatory methodologies for CNS research. It is in use in various clinical\nstudies and have been broadly studied over decades. Despite that the recorded\nEEG signals are quite prone to noise and environmental factors it is the most\nwidely used method in study of brain-computer interaction (BCI). Here we\ndiscuss briefly on various aspects of the recorded signals, their\ninterpretation, and usage in the field of interaction studies.\n  This paper aims to serve as a primer for the novice, enabling rapid\nfamiliarisation with the latest core concepts. We put special emphasis on\neveryday human-computer interface applications to distinguish from the more\ncommon clinical or sports uses of psychophysiology.\n  This paper is an extract from a comprehensive review of the entire field of\nambulatory psychophysiology, including 12 similar chapters, plus application\nguidelines and systematic review. Thus any citation should be made using the\nfollowing reference:\n  B. Cowley, M. Filetti, K. Lukander, J. Torniainen, A. Henelius, L. Ahonen, O.\nBarral, I. Kosunen, T. Valtonen, M. Huotilainen, N. Ravaja, G. Jacucci. The\nPsychophysiology Primer: a guide to methods and a broad review with a focus on\nhuman-computer interaction. Foundations and Trends in Human-Computer\nInteraction, vol. 9, no. 3-4, pp. 150--307, 2016.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 11:05:47 GMT"}, {"version": "v2", "created": "Mon, 5 Sep 2016 12:04:33 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Ahonen", "Lauri", ""], ["Cowley", "Benjamin", ""]]}, {"id": "1609.00360", "submitter": "Shuo Chen", "authors": "Shuo Chen, Yishi Xing, Jian Kang, Dinesh Shukla, Peter Kochunov, and\n  L. Elliot Hong", "title": "A Network Object Method to Uncover Hidden Disorder-Related Brain\n  Connectome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuropsychiatric disorders impact functional connectivity of the brain at the\nnetwork level. The identification and statistical testing of disorder-related\nnetworks remains challenging. We propose novel methods to streamline the\ndetection and testing of the hidden, disorder-related connectivity patterns as\nnetwork-objects. We define an abnormal connectome subnetwork as a\nnetwork-object that includes three classes: nodes of brain areas, edges\nrepresenting brain connectomic features, and an organized graph topology formed\nby these nodes and edges. Comparing to the conventional statistical methods,\nthe proposed approach simultaneously reduces false positive and negative\ndiscovery rates by letting edges borrow strengths precisely with the guidance\nof graph topological information, which effectively improves the\nreproducibility of findings across brain connectome studies. The network-object\nanalyses may provide insights into how brain connectome is systematically\nimpaired by brain illnesses.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 19:38:14 GMT"}, {"version": "v2", "created": "Thu, 12 Jan 2017 21:45:30 GMT"}], "update_date": "2017-01-16", "authors_parsed": [["Chen", "Shuo", ""], ["Xing", "Yishi", ""], ["Kang", "Jian", ""], ["Shukla", "Dinesh", ""], ["Kochunov", "Peter", ""], ["Hong", "L. Elliot", ""]]}, {"id": "1609.00491", "submitter": "Leonardo L. Gollo", "authors": "Leonardo L. Gollo, James A. Roberts, Luca Cocchi", "title": "Mapping how local perturbations influence systems-level brain dynamics", "comments": "41 pages, 9 figures", "journal-ref": "Neuroimage 160:97-112 (2017)", "doi": "10.1016/j.neuroimage.2017.01.057", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain exhibits a relatively stable spatiotemporal organization that\nsupports brain function and can be manipulated via local brain stimulation.\nSuch perturbations to local cortical dynamics are globally integrated by\ndistinct neural systems. However, it remains unclear how and why local changes\nin neural activity affect large-scale system dynamics. Here, we briefly review\nempirical and computational studies addressing how localized perturbations\naffect brain activity. We then systematically analyze a model of large-scale\nbrain dynamics, assessing how localized changes in brain activity at the\ndifferent sites affect whole-brain dynamics. We find that local stimulation\ninduces changes in brain activity that can be summarized by relatively smooth\ntuning curves, which relate a region's effectiveness as a stimulation site to\nits position within the cortical hierarchy. Our results also support the notion\nthat brain hubs, operating in a slower regime, are more resilient to focal\nperturbations and critically contribute to maintain stability in global brain\ndynamics. In contrast, perturbations of peripheral regions, characterized by\nfaster activity, have greater impact on functional connectivity. As a parallel\nwith this region-level result, we also find that peripheral systems such as the\nvisual and sensorimotor networks were more affected by local perturbations than\nhigh-level systems such as the cingulo-opercular network. Our results highlight\nthe importance of a periphery-to-core hierarchy to determine the effect of\nlocal stimulation on the brain network. We also provide novel resources to\norient empirical work aiming at manipulating functional connectivity using\nnon-invasive brain stimulation.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 07:51:27 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Gollo", "Leonardo L.", ""], ["Roberts", "James A.", ""], ["Cocchi", "Luca", ""]]}, {"id": "1609.00639", "submitter": "Johannes Friedrich", "authors": "Johannes Friedrich, Pengcheng Zhou, Liam Paninski", "title": "Fast Online Deconvolution of Calcium Imaging Data", "comments": "Extended version that significantly elaborates on the conference\n  proceeding that appeared at NIPS 2016", "journal-ref": "PLOS Computational Biology 2017; 13(3): e1005423", "doi": "10.1371/journal.pcbi.1005423", "report-no": null, "categories": "q-bio.NC q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluorescent calcium indicators are a popular means for observing the spiking\nactivity of large neuronal populations, but extracting the activity of each\nneuron from raw fluorescence calcium imaging data is a nontrivial problem. We\npresent a fast online active set method to solve this sparse non-negative\ndeconvolution problem. Importantly, the algorithm progresses through each time\nseries sequentially from beginning to end, thus enabling real-time online\nestimation of neural activity during the imaging session. Our algorithm is a\ngeneralization of the pool adjacent violators algorithm (PAVA) for isotonic\nregression and inherits its linear-time computational complexity. We gain\nremarkable increases in processing speed: more than one order of magnitude\ncompared to currently employed state of the art convex solvers relying on\ninterior point methods. Unlike these approaches, our method can exploit warm\nstarts; therefore optimizing model hyperparameters only requires a handful of\npasses through the data. A minor modification can further improve the quality\nof activity inference by imposing a constraint on the minimum spike size. The\nalgorithm enables real-time simultaneous deconvolution of $O(10^5)$ traces of\nwhole-brain larval zebrafish imaging data on a laptop.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 15:10:38 GMT"}, {"version": "v2", "created": "Thu, 24 Nov 2016 18:19:55 GMT"}, {"version": "v3", "created": "Thu, 16 Mar 2017 17:06:50 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Friedrich", "Johannes", ""], ["Zhou", "Pengcheng", ""], ["Paninski", "Liam", ""]]}, {"id": "1609.00658", "submitter": "Alexandre Castro", "authors": "Alexandre de Castro", "title": "On the quantum principles of cognitive learning", "comments": null, "journal-ref": "Behav Brain Sci. 2013 Jun;36(3):281-2", "doi": "10.1017/S0140525X12002919", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pothos & Busemeyer's (P&B's) query about whether quantum probability can\nprovide a foundation for the cognitive modeling embodies so many underlying\nimplications that the subject is far from exhausted. In this brief commentary,\nhowever, I suggest that the conceptual thresholds of the meaningful learning\ngive rise to a typical Boltzmann's weighting measure, which indicates a\nstatistical verisimilitude of quantum behavior in the human cognitive ensemble.\n", "versions": [{"version": "v1", "created": "Sun, 14 Aug 2016 06:03:55 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["de Castro", "Alexandre", ""]]}, {"id": "1609.00739", "submitter": "Mikhail Shneider", "authors": "M.N. Shneider and M. Pekker", "title": "Bypassing damaged nervous tissue", "comments": "arXiv admin note: text overlap with arXiv:1606.01272", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show the principal ability of bypassing damaged demyelinated portions of\nnervous tissue, thereby restoring its normal function for the passage of action\npotentials. We carry out a theoretical analysis on the basis of the\nsynchronization mechanism of action potential propagation along a bundle of\nneurons, proposed recently in [1]. And we discuss the feasibility of implement\na bypass to restore damaged nervous tissue and creating an artificial neuron\nnetwork.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 20:16:47 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 12:20:58 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Shneider", "M. N.", ""], ["Pekker", "M.", ""]]}, {"id": "1609.00762", "submitter": "Guillaume Lajoie", "authors": "Guillaume Lajoie, Nedialko I. Krouchev, John F. Kalaska, Adrienne L.\n  Fairhall, and Eberhard E. Fetz", "title": "Correlation-based model of artificially induced plasticity in motor\n  cortex by a bidirectional brain-computer interface", "comments": "35 pages, 9 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1005343", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments show that spike-triggered stimulation performed with\nBidirectional Brain-Computer-Interfaces (BBCI) can artificially strengthen\nconnections between separate neural sites in motor cortex (MC). What are the\nneuronal mechanisms responsible for these changes and how does targeted\nstimulation by a BBCI shape population-level synaptic connectivity? The present\nwork describes a recurrent neural network model with probabilistic spiking\nmechanisms and plastic synapses capable of capturing both neural and synaptic\nactivity statistics relevant to BBCI conditioning protocols. When spikes from a\nneuron recorded at one MC site trigger stimuli at a second target site after a\nfixed delay, the connections between sites are strengthened for spike-stimulus\ndelays consistent with experimentally derived spike time dependent plasticity\n(STDP) rules. However, the relationship between STDP mechanisms at the level of\nnetworks, and their modification with neural implants remains poorly\nunderstood. Using our model, we successfully reproduces key experimental\nresults and use analytical derivations, along with novel experimental data. We\nthen derive optimal operational regimes for BBCIs, and formulate predictions\nconcerning the efficacy of spike-triggered stimulation in different regimes of\ncortical activity.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 22:41:29 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Lajoie", "Guillaume", ""], ["Krouchev", "Nedialko I.", ""], ["Kalaska", "John F.", ""], ["Fairhall", "Adrienne L.", ""], ["Fetz", "Eberhard E.", ""]]}, {"id": "1609.00900", "submitter": "Ta\\c{s}k{\\i}n Deniz", "authors": "Taskin Deniz, Stefan Rotter", "title": "Joint Statistics of Strongly Correlated Neurons via Dimensional\n  Reduction", "comments": "40 pages, 11 figures. Submitted to IOP-Journal of Physics A", "journal-ref": null, "doi": "10.1088/1751-8121/aa677e", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relative timing of action potentials in neurons recorded from local\ncortical networks often shows a non-trivial dependence, which is then\nquantified by cross-correlation functions. Theoretical models emphasize that\nsuch spike train correlations are an inevitable consequence of two neurons\nbeing part of the same network and sharing some synaptic input. For non-linear\nneuron models, however, explicit correlation functions are difficult to compute\nanalytically, and perturbative methods work only for weak shared input. In\norder to treat strong correlations, we suggest here an alternative\nnon-perturbative method. Specifically, we study the case of two leaky\nintegrate-and-fire neurons with strong shared input. Correlation functions\nderived from simulated spike trains fit our theoretical predictions very\naccurately. Using our method, we computed the non-linear correlation transfer\nas well as correlation functions that are asymmetric due to inhomogeneous\nintrinsic parameters or unequal input.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 08:12:11 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Deniz", "Taskin", ""], ["Rotter", "Stefan", ""]]}, {"id": "1609.00921", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad and Daoqiang Zhang", "title": "Decoding visual stimuli in human brain by using Anatomical Pattern\n  Analysis on fMRI images", "comments": "The 8th International Conference on Brain Inspired Cognitive Systems\n  (BICS'16), Beijing, China, Nov/28-30/2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A universal unanswered question in neuroscience and machine learning is\nwhether computers can decode the patterns of the human brain. Multi-Voxels\nPattern Analysis (MVPA) is a critical tool for addressing this question.\nHowever, there are two challenges in the previous MVPA methods, which include\ndecreasing sparsity and noises in the extracted features and increasing the\nperformance of prediction. In overcoming mentioned challenges, this paper\nproposes Anatomical Pattern Analysis (APA) for decoding visual stimuli in the\nhuman brain. This framework develops a novel anatomical feature extraction\nmethod and a new imbalance AdaBoost algorithm for binary classification.\nFurther, it utilizes an Error-Correcting Output Codes (ECOC) method for\nmulti-class prediction. APA can automatically detect active regions for each\ncategory of the visual stimuli. Moreover, it enables us to combine homogeneous\ndatasets for applying advanced classification. Experimental studies on 4 visual\ncategories (words, consonants, objects and scrambled photos) demonstrate that\nthe proposed approach achieves superior performance to state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2016 12:01:50 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1609.01015", "submitter": "Arian Ashourvan", "authors": "Arian Ashourvan, Shi Gu, Marcelo G. Mattar, Jean M. Vettel, Danielle\n  S. Bassett", "title": "The Energy Landscape Underpinning Module Dynamics in the Human Brain\n  Connectome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human brain dynamics can be profitably viewed through the lens of statistical\nmechanics, where neurophysiological activity evolves around and between local\nattractors representing preferred mental states. Many physically-inspired\nmodels of these dynamics define the state of the brain based on instantaneous\nmeasurements of regional activity. Yet, recent work in network neuroscience has\nprovided initial evidence that the brain might also be well-characterized by\ntime-varying states composed of locally coherent activity or functional\nmodules. Here we study this network-based notion of brain state to understand\nhow functional modules dynamically interact with one another to perform\ncognitive functions. We estimate the functional relationships between regions\nof interest (ROIs) by fitting a pair-wise maximum entropy model to each ROI's\npattern of allegiance to functional modules. Local minima in this model\nrepresent attractor states characterized by specific patterns of modular\nstructure. The clustering of local minima highlights three classes of ROIs with\nsimilar patterns of allegiance to community states. Visual, attention,\nsensorimotor, and subcortical ROIs tend to form a single functional community.\nThe remaining ROIs tend to form a putative executive control community or a\nputative default mode and salience community. We simulate the brain's dynamic\ntransitions between these community states using a Markov Chain Monte Carlo\nrandom walk. We observe that simulated transition probabilities between basins\nresemble empirically observed transitions between community allegiance states\nin resting state fMRI data. These results collectively offer a view of the\nbrain as a dynamical system that transitions between basins of attraction\ncharacterized by coherent activity in small groups of brain regions, and that\nthe strength of these attractors depends on the cognitive computations being\nperformed.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 01:51:59 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Ashourvan", "Arian", ""], ["Gu", "Shi", ""], ["Mattar", "Marcelo G.", ""], ["Vettel", "Jean M.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1609.01384", "submitter": "Liang Zhan", "authors": "Liang Zhan, Lisanne M. Jenkins, Ouri E. Wolfson, Johnson J.\n  GadElkarim, Kevin Nocito, Paul M. Thompson, Olusola A. Ajilore, Moo K. Chung,\n  Alex D. Leow", "title": "The Importance of Being Negative: A serious treatment of non-trivial\n  edges in brain functional connectome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the modularity of fMRI-derived brain networks or connectomes\ncan inform the study of brain function organization. However, fMRI connectomes\nadditionally involve negative edges, which are not rigorously accounted for by\nexisting approaches to modularity that either ignores or arbitrarily weight\nthese connections. Furthermore, most Q maximization-based modularity algorithms\nyield variable results with suboptimal reproducibility. Here we present an\nalternative, reproducible approach that exploits how frequent the BOLD-signal\ncorrelation between two nodes is negative. We validated this novel\nprobability-based modularity approach on two independent publicly-available\nresting-state connectome dataset (the Human Connectome Project and the 1000\nFunctional Connectomes) and demonstrated that negative correlations alone are\nsufficient in understanding resting-state modularity. In fact, this approach a)\npermits a dual formulation, leading to equivalent solutions regardless of\nwhether one considers positive or negative edges; b) is theoretically linked to\nthe Ising model defined on the connectome, thus yielding modularity result that\nmaximizes data likelihood. We additionally were able to detect sex differences\nin modularity that the most widely utilized methods did not. Results confirmed\nthe superiority of our approach in that: a) correlations with the highest\nprobability of being negative are consistently placed between modules, b) due\nto the equivalent dual forms, no arbitrary weighting factor is required to\nbalance the influence between negative and positive correlations, unlike\nexisting Q maximization-based modularity approaches. As datasets like HCP\nbecome widely available for analysis by the neuroscience community at large,\nappropriate computational tools to understand the neurobiological information\nof negative edges in fMRI connectomes are increasingly important.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 04:03:12 GMT"}, {"version": "v2", "created": "Sat, 14 Jan 2017 05:54:59 GMT"}, {"version": "v3", "created": "Mon, 5 Jun 2017 21:19:43 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Zhan", "Liang", ""], ["Jenkins", "Lisanne M.", ""], ["Wolfson", "Ouri E.", ""], ["GadElkarim", "Johnson J.", ""], ["Nocito", "Kevin", ""], ["Thompson", "Paul M.", ""], ["Ajilore", "Olusola A.", ""], ["Chung", "Moo K.", ""], ["Leow", "Alex D.", ""]]}, {"id": "1609.01534", "submitter": "Kelly Iarosz", "authors": "M. S. Santos, J. D. Szezech Jr., F. S. Borges, K. C. Iarosz, I. L.\n  Caldas, A. M. Batista, R. L. Viana, J. Kurths", "title": "Chimera in a neuronal network model of the cat brain", "comments": null, "journal-ref": null, "doi": "10.1016/j.chaos.2017.05.028", "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal systems have been modeled by complex networks in different\ndescription levels. Recently, it has been verified that networks can\nsimultaneously exhibit one coherent and other incoherent domain, known as\nchimera states. In this work, we study the existence of chimera states in a\nnetwork considering the connectivity matrix based on the cat cerebral cortex.\nThe cerebral cortex of the cat can be separated in 65 cortical areas organised\ninto the four cognitive regions: visual, auditory, somatosensory-motor and\nfrontolimbic. We consider a network where the local dynamics is given by the\nHindmarsh-Rose model. The Hindmarsh-Rose equations are a well known model of\nneuronal activity that has been considered to simulate membrane potential in\nneuron. Here, we analyse under which conditions chimera states are present, as\nwell as the affects induced by intensity of coupling on them. We observe the\nexistence of chimera states in that incoherent structure can be composed of\ndesynchronised spikes or desynchronised bursts. Moreover, we find that chimera\nstates with desynchronised bursts are more robust to neuronal noise than with\ndesynchronised spikes.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 16:13:50 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2017 13:25:22 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Santos", "M. S.", ""], ["Szezech", "J. D.", "Jr."], ["Borges", "F. S.", ""], ["Iarosz", "K. C.", ""], ["Caldas", "I. L.", ""], ["Batista", "A. M.", ""], ["Viana", "R. L.", ""], ["Kurths", "J.", ""]]}, {"id": "1609.01663", "submitter": "Joseph Griffis", "authors": "Joseph C. Griffis, Rodolphe Nenert, Jane B. Allendorfer, Jennifer\n  Vannest, Scott Holland, Aimee Dietz, Jerzy P. Szaflarski", "title": "The canonical semantic network supports residual language function in\n  chronic post-stroke aphasia", "comments": "67 pages, 5 figures, 4 tables, 5 supplementary figures, 2\n  supplementary tables", "journal-ref": null, "doi": "10.1002/hbm.23476", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current theories of language recovery after stroke are limited by a reliance\non small studies. Here, we aimed to test predictions of current theory and\nresolve inconsistencies regarding right hemispheric contributions to long-term\nrecovery. We first defined the canonical semantic network in 43 healthy\ncontrols. Then, in a group of 43 patients with chronic post-stroke aphasia, we\ntested whether activity in this network predicted performance on measures of\nsemantic comprehension, naming, and fluency while controlling for lesion volume\neffects. Canonical network activation accounted for 22-33% of the variance in\nlanguage test scores. Whole-brain analyses corroborated these findings, and\nrevealed a core set of regions showing positive relationships to all language\nmeasures. We next evaluated the relationship between activation magnitudes in\nleft and right hemispheric portions of the network, and how right hemispheric\nactivation related to the extent of left hemispheric damage. Activation\nmagnitudes in the each hemispheric network were strongly correlated, but four\nright frontal regions showed heightened activity in patients with large\nlesions. Activity in two of these regions (inferior frontal gyrus pars\nopercularis and supplementary motor area) was associated with better language\nabilities in patients with larger lesions, but poorer language abilities in\npatients with smaller lesions. Our results indicate that bilateral language\nnetworks support language processing after stroke, and that right hemispheric\nactivations related to extensive left hemisphere damage occur outside of the\ncanonical semantic network and differentially contribute to in their\nrelationship to behavior depending on the extent of left hemispheric damage\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 17:31:13 GMT"}, {"version": "v2", "created": "Wed, 26 Oct 2016 16:19:04 GMT"}], "update_date": "2017-01-13", "authors_parsed": [["Griffis", "Joseph C.", ""], ["Nenert", "Rodolphe", ""], ["Allendorfer", "Jane B.", ""], ["Vannest", "Jennifer", ""], ["Holland", "Scott", ""], ["Dietz", "Aimee", ""], ["Szaflarski", "Jerzy P.", ""]]}, {"id": "1609.01790", "submitter": "Danielle Bassett", "authors": "Marcelo G. Mattar and Danielle S. Bassett", "title": "Brain Network Architecture: Implications for Human Learning", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human learning is a complex phenomenon that requires adaptive processes\nacross a range of temporal and spacial scales. While our understanding of those\nprocesses at single scales has increased exponentially over the last few years,\na mechanistic understanding of the entire phenomenon has remained elusive. We\npropose that progress has been stymied by the lack of a quantitative framework\nthat can account for the full range of neurophysiological and behavioral\ndynamics both across scales in the systems and also across different types of\nlearning. We posit that network neuroscience offers promise in meeting this\nchallenge. Built on the mathematical fields of complex systems science and\ngraph theory, network neuroscience embraces the interconnected and hierarchical\nnature of human learning, offering insights into the emergent properties of\nadaptability. In this review, we discuss the utility of network neuroscience as\na tool to build a quantitative framework in which to study human learning,\nwhich seeks to explain the full chain of events in the brain from sensory input\nto motor output, being both biologically plausible and able to make predictions\nabout how an intervention at a single level of the chain may cause alterations\nin another level of the chain. We close by laying out important remaining\nchallenges in network neuroscience in explicitly bridging spatial scales at\nwhich neurophysiological processes occur, and underscore the utility of such a\nquantitative framework for education and therapy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 00:22:40 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Mattar", "Marcelo G.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1609.02081", "submitter": "Kaushik Majumdar", "authors": "Kaushik Majumdar, Anagh Pathak and Viswadeep Sarangi", "title": "An Investigation into the Mathematical Nature of Electrophysiological\n  Signals with Applications", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we have proposed a rigorous mathematical definition for the one\ndimensional time domain electrophysiological signals and established its\nrelationship with two of the three Dirichlet's conditions. We have argues that\nany such signal can be represented as the trajectory of a particle moving in a\nforce field with one degree of freedom. At point on the trajectory, that is, on\nthe signal, the kinetic energy dissipated by the particle embeds semantic\ninformation into the trajectory or the signal in terms of giving its shape. We\nhave shown that the rate of kinetic energy dissipation operator or the power\noperator P is of importance in shape analysis of the signal by considering its\nsign changes. Operating the P-operator on digital signals we have\nmathematically proved that its sign change can induce 13 different shapes to a\nthree successive point configuration. In other words, semantic information at\neach point in a digital signal can be embedded by a syllable of 13 different\nletters. We have shown some preliminary applications.\n", "versions": [{"version": "v1", "created": "Sat, 3 Sep 2016 20:03:02 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Majumdar", "Kaushik", ""], ["Pathak", "Anagh", ""], ["Sarangi", "Viswadeep", ""]]}, {"id": "1609.02114", "submitter": "Joseph Griffis", "authors": "Joseph C. Griffis, Rodolphe Nenert, Jane B. Allendorfer, Jerzy P.\n  Szaflarski", "title": "Damage to white matter bottlenecks contributes to language impairments\n  after left hemispheric stroke", "comments": "39 pages, 5 figures, 1 table, 1 supplementary table, 3 supplementary\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Damage to the white matter underlying the left posterior temporal lobe leads\nto deficits in multiple language functions. The posterior temporal white matter\nmay correspond to a bottleneck where both dorsal and ventral language pathways\nare vulnerable to simultaneous damage. Damage to a second putative white matter\nbottleneck in the left deep prefrontal white matter involving projections\nassociated with ventral language pathways and thalamo-cortical projections has\nrecently been proposed as a source of semantic deficits after stroke. However,\nthe effects of damage to a priori identified white matter bottlenecks on\nlanguage function have not been directly investigated. Here, we first used\nwhite matter atlases to identify the previously described white matter\nbottlenecks in the posterior temporal and deep prefrontal white matter. We then\nassessed the effects of damage to each region on measures of category fluency,\npicture naming, and auditory semantic decision-making in 43 patients with\nchronic aphasia. Damage to the posterior temporal bottleneck predicted deficits\non all language measures, while damage to the anterior bottleneck only\npredicted deficits in category fluency. Importantly, the effects of damage to\nthe bottleneck regions were not attributable to lesion volume, lesion loads on\nthe tracts traversing the bottlenecks, or damage to nearby cortical language\nareas. Multivariate lesion-symptom mapping and fiber tracking analyses\ncorroborated these findings. Together, our results provide strong support for\nthe proposal that spatially specific white matter damage affecting white matter\nbottlenecks, particularly in the posterior temporal lobe, contribute to chronic\nlanguage deficits after left hemispheric stroke. Our results suggest that\ndamage to this area is likely to simultaneously disrupt signaling via the\nsimultaneous disruption of dorsal and ventral language processing streams.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 19:02:34 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Griffis", "Joseph C.", ""], ["Nenert", "Rodolphe", ""], ["Allendorfer", "Jane B.", ""], ["Szaflarski", "Jerzy P.", ""]]}, {"id": "1609.02202", "submitter": "Alexei Koulakov", "authors": "Daniel Kepple, Hamza Giaffar, Dmitry Rinberg, and Alexei Koulakov", "title": "Deconstructing Odorant Identity via Primacy in Dual Networks", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the olfactory system, odor percepts retain their identity despite\nsubstantial variations in concentration, timing, and background. We propose a\nnovel strategy for encoding intensity-invariant stimuli identity that is based\non representing relative rather than absolute values of the stimulus features.\nBecause, in this scheme, stimulus identity depends on relative amplitudes of\nstimulus features, identity becomes invariant with respect to variations in\nintensity and monotonous non-linearities of neuronal responses. In the\nolfactory system, stimulus identity can be represented by the identities of the\np strongest responding odorant receptor types out of a species dependent\ncomplement. We show that this information is sufficient to recover sparse\nstimuli (odorants) via elastic net loss minimization. Such a minimization has\nto be performed under constraints imposed by the relationships between stimulus\nfeatures. We map this problem onto the dual problem of minimizing a functional\nof Lagrange multipliers. The dual problem, in turn, can be solved by a neural\nnetwork whose Lyapunov function represents the dual Lagrangian. We thus propose\nthat networks in the piriform cortex compute odorant identity and implement\ndual computations with the sparse activities of individual neurons representing\nthe Lagrange multipliers.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 21:50:38 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Kepple", "Daniel", ""], ["Giaffar", "Hamza", ""], ["Rinberg", "Dmitry", ""], ["Koulakov", "Alexei", ""]]}, {"id": "1609.02228", "submitter": "Thomas Miconi", "authors": "Thomas Miconi", "title": "Learning to learn with backpropagation of Hebbian plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hebbian plasticity is a powerful principle that allows biological brains to\nlearn from their lifetime experience. By contrast, artificial neural networks\ntrained with backpropagation generally have fixed connection weights that do\nnot change once training is complete. While recent methods can endow neural\nnetworks with long-term memories, Hebbian plasticity is currently not amenable\nto gradient descent. Here we derive analytical expressions for activity\ngradients in neural networks with Hebbian plastic connections. Using these\nexpressions, we can use backpropagation to train not just the baseline weights\nof the connections, but also their plasticity. As a result, the networks \"learn\nhow to learn\" in order to solve the problem at hand: the trained networks\nautomatically perform fast learning of unpredictable environmental features\nduring their lifetime, expanding the range of solvable problems. We test the\nalgorithm on various on-line learning tasks, including pattern completion,\none-shot learning, and reversal learning. The algorithm successfully learns how\nto learn the relevant associations from one-shot instruction, and fine-tunes\nthe temporal dynamics of plasticity to allow for continual learning in response\nto changing environmental parameters. We conclude that backpropagation of\nHebbian plasticity offers a powerful model for lifelong learning.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 00:02:20 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2016 17:51:25 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Miconi", "Thomas", ""]]}, {"id": "1609.02261", "submitter": "Ryuta Mizutani", "authors": "Ryuta Mizutani, Rino Saiga, Akihisa Takeuchi, Kentaro Uesugi, and\n  Yoshio Suzuki", "title": "Three-dimensional network of Drosophila brain hemisphere", "comments": "39 pages, 7 figures, 1 table", "journal-ref": "J.Struct.Biol. 184 (2013) 271-279", "doi": "10.1016/j.jsb.2013.08.012", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The first step to understanding brain function is to determine the brain's\nnetwork structure. We report a three-dimensional analysis of the brain network\nof the fruit fly Drosophila melanogaster by synchrotron-radiation tomographic\nmicroscopy. A skeletonized wire model of the left half of the brain network was\nbuilt by tracing the three-dimensional distribution of X-ray absorption\ncoefficients. The obtained models of neuronal processes were classified into\ngroups on the basis of their three-dimensional structures. These classified\ngroups correspond to neuronal tracts that send long-range projections or\nrepeated structures of the optic lobe. The skeletonized model is also composed\nof neuronal processes that could not be classified into the groups. The\ndistribution of these unclassified structures correlates with the distribution\nof contacts between neuronal processes. This suggests that neurons that cannot\nbe classified into typical structures should play important roles in brain\nfunctions. The quantitative description of the brain network provides a basis\nfor structural and statistical analyses of the Drosophila brain. The challenge\nis to establish a methodology for reconstructing the brain network in a\nhigher-resolution image, leading to a comprehensive understanding of the brain\nstructure.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 04:11:10 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Mizutani", "Ryuta", ""], ["Saiga", "Rino", ""], ["Takeuchi", "Akihisa", ""], ["Uesugi", "Kentaro", ""], ["Suzuki", "Yoshio", ""]]}, {"id": "1609.02272", "submitter": "Ryuta Mizutani", "authors": "Ryuta Mizutani, Akihisa Takeuchi, Kentaro Uesugi, Masami Ohyama,\n  Susumu Takekoshi, R. Yoshiyuki Osamura, Yoshio Suzuki", "title": "Three-dimensional microtomographic imaging of human brain cortex", "comments": "23 pages, 2 figures. The first author surname in the metadata was\n  corrected. Hidden information in the pdf file (bookmarks and metadata) was\n  removed", "journal-ref": "Brain Res 1199 (2008) 53-61", "doi": "10.1016/j.brainres.2008.01.029", "report-no": null, "categories": "physics.bio-ph physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an x-ray microtomographic technique for imaging the\nthree-dimensional structure of the human cerebral cortex. Neurons in the brain\nconstitute a neural circuit as a three-dimensional network. The brain tissue is\ncomposed of light elements that give little contrast in a hard x-ray\ntransmission image. The contrast was enhanced by staining neural cells with\nmetal compounds. The obtained structure revealed the microarchitecture of the\ngray and white matter regions of the frontal cortex, which is responsible for\nthe higher brain functions.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 04:52:40 GMT"}, {"version": "v2", "created": "Sun, 2 Oct 2016 08:20:21 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Mizutani", "Ryuta", ""], ["Takeuchi", "Akihisa", ""], ["Uesugi", "Kentaro", ""], ["Ohyama", "Masami", ""], ["Takekoshi", "Susumu", ""], ["Osamura", "R. Yoshiyuki", ""], ["Suzuki", "Yoshio", ""]]}, {"id": "1609.02535", "submitter": "Mette Olufsen", "authors": "Jacob Sturdy, Johnny T Ottesen, Mette S Olufsen", "title": "Modeling the differentiation of A- and C-type baroreceptor firing\n  patterns", "comments": "Keywords: Baroreflex model, mechanosensitivity, A- and C-type\n  afferent baroreceptors, biophysical model, computational model", "journal-ref": "Journal of Computational Neuroscience, 2016", "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The baroreceptor neurons serve as the primary transducers of blood pressure\nfor the autonomic nervous system and are thus critical in enabling the body to\nrespond effectively to changes in blood pressure. These neurons can be\nseparated into two types (A and C) based on the myelination of their axons and\ntheir distinct firing patterns elicited in response to specific pressure\nstimuli. This study has developed a comprehensive model of the afferent\nbaroreceptor discharge built on physiological knowledge of arterial wall\nmechanics, firing rate responses to controlled pressure stimuli, and ion\nchannel dynamics within the baroreceptor neurons. With this model, we were able\nto predict firing rates observed in previously published experiments in both A-\nand C-type neurons. These results were obtained by adjusting model parameters\ndetermining the maximal ion-channel conductances. The observed variation in the\nmodel parameters are hypothesized to correspond to physiological differences\nbetween A- and C-type neurons. In agreement with published experimental\nobservations, our simulations suggest that a twofold lower potassium\nconductance in C-type neurons is responsible for the observed sustained basal\nfiring, whereas a tenfold higher mechanosensitive conductance is responsible\nfor the greater firing rate observed in A-type neurons. A better understanding\nof the difference between the two neuron types can potentially be used to gain\nmore insight into the underlying pathophysiology facilitating development of\ntargeted interventions improving baroreflex function in diseased individuals,\ne.g. in patients with autonomic failure, a syndrome that is difficult to\ndiagnose in terms of its pathophysiology.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 18:48:44 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Sturdy", "Jacob", ""], ["Ottesen", "Johnny T", ""], ["Olufsen", "Mette S", ""]]}, {"id": "1609.02545", "submitter": "Wilten Nicola", "authors": "Wilten Nicola and Claudia Clopath", "title": "Supervised Learning in Spiking Neural Networks with FORCE Training", "comments": null, "journal-ref": "Nicola, W., & Clopath, C. (2017). Supervised learning in spiking\n  neural networks with FORCE training. Nature communications, 8(1), 2208", "doi": "10.1038/s41467-017-01827-3", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Populations of neurons display an extraordinary diversity in the behaviors\nthey affect and display. Machine learning techniques have recently emerged that\nallow us to create networks of model neurons that display behaviours of similar\ncomplexity. Here, we demonstrate the direct applicability of one such\ntechnique, the FORCE method, to spiking neural networks. We train these\nnetworks to mimic dynamical systems, classify inputs, and store discrete\nsequences that correspond to the notes of a song. Finally, we use FORCE\ntraining to create two biologically motivated model circuits. One is inspired\nby the zebra-finch and successfully reproduces songbird singing. The second\nnetwork is motivated by the hippocampus and is trained to store and replay a\nmovie scene. FORCE trained networks reproduce behaviors comparable in\ncomplexity to their inspired circuits and yield information not easily\nobtainable with other techniques such as behavioral responses to\npharmacological manipulations and spike timing statistics.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 19:43:30 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 15:53:32 GMT"}, {"version": "v3", "created": "Thu, 4 Jan 2018 17:02:11 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Nicola", "Wilten", ""], ["Clopath", "Claudia", ""]]}, {"id": "1609.02893", "submitter": "Leandro Alonso", "authors": "Leandro M. Alonso", "title": "Emergent computation in simple model of neural activity", "comments": "Reason for withdrawal is that in the draft the study is not\n  sufficiently well-motivated and incomplete. The draft as it is may be\n  misleading. The network introduced in this draft was studied thoroughly and\n  the results were published elsewhere. Please see\n  https://doi.org/10.1063/1.4984800", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the dynamics of a network consisting of an array of identical\ncortical units with nearest neighbor interactions under periodic arousal. Each\nunit consists of two interconnected populations of neurons tuned to a state in\nwhich many nonlinear resonances are available. The network is critically\nbalanced due to short-ranged antisymmetric connections between units. For wide\nranges of the network parameters, the patterns of activity resemble the\ndynamics of cellular automata. It is argued that these dynamical states may\nprovide a template in which computation can be implemented.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 19:16:34 GMT"}, {"version": "v2", "created": "Sat, 9 Feb 2019 20:45:33 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Alonso", "Leandro M.", ""]]}, {"id": "1609.02896", "submitter": "Leandro Alonso", "authors": "Leandro M. Alonso", "title": "Nonlinear resonances and multi-stability in simple neural circuits", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": "10.1063/1.4974028", "report-no": null, "categories": "nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a numerical procedure designed to tune the parameters\nof periodically-driven dynamical systems to a state in which they exhibit rich\ndynamical behavior. This is achieved by maximizing the diversity of subharmonic\nsolutions available to the system within a range of the parameters that define\nthe driving. The procedure is applied to a problem of interest in computational\nneuroscience: a circuit composed of two interacting populations of neurons\nunder external periodic forcing. Depending on the parameters that define the\ncircuit, such as the weights of the connections between the populations, the\nresponse of the circuit to the driving can be strikingly rich and diverse. The\nprocedure is employed to find circuits that, when driven by external input,\nexhibit multiple stable patterns of periodic activity organized in complex\ntuning diagrams and signatures of low dimensional chaos.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 19:19:49 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 20:16:56 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Alonso", "Leandro M.", ""]]}, {"id": "1609.03224", "submitter": "Ali Fatih Demir", "authors": "A. Fatih Demir, Huseyin Arslan, Ismail Uysal", "title": "Bio-Inspired Filter Banks for SSVEP-based Brain-Computer Interfaces", "comments": "2016 IEEE International Conference on Biomedical and Health\n  Informatics (BHI)", "journal-ref": "2016 IEEE-EMBS International Conference on Biomedical and Health\n  Informatics (BHI), Feb. 2016, pp. 144-147", "doi": "10.1109/BHI.2016.7455855", "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interfaces (BCI) have the potential to play a vital role in\nfuture healthcare technologies by providing an alternative way of communication\nand control. More specifically, steady-state visual evoked potential (SSVEP)\nbased BCIs have the advantage of higher accuracy and higher information\ntransfer rate (ITR). In order to fully exploit the capabilities of such\ndevices, it is necessary to understand the features of SSVEP and design the\nsystem considering its biological characteristics. This paper introduces\nbio-inspired filter banks (BIFB) for a novel SSVEP frequency detection method.\nIt is known that SSVEP response to a flickering visual stimulus is frequency\nselective and gets weaker as the frequency of the stimuli increases. In the\nproposed approach, the gain and bandwidth of the filters are designed and tuned\nbased on these characteristics while also incorporating harmonic SSVEP\nresponses. This method not only improves the accuracy but also increases the\navailable number of commands by allowing the use of stimuli frequencies elicit\nweak SSVEP responses. The BIFB method achieved reliable performance when tested\non datasets available online and compared with two well-known SSVEP frequency\ndetection methods, power spectral density analysis (PSDA) and canonical\ncorrelation analysis (CCA). The results show the potential of bio-inspired\ndesign which will be extended to include further SSVEP characteristic (e.g.\ntime-domain waveform) for future SSVEP based BCIs.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 22:15:12 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Demir", "A. Fatih", ""], ["Arslan", "Huseyin", ""], ["Uysal", "Ismail", ""]]}, {"id": "1609.03372", "submitter": "Xindi Wang", "authors": "Xindi Wang, Qixiang Lin, Mingrui Xia, Yong He", "title": "Differentially Categorized Structural Connectome Hubs are Involved in\n  Differential Microstructural Basis and Functional Implications and Contribute\n  to Individual Identification", "comments": "32 text pages, 6 figures, 1 table (Supplementary Information: 20 text\n  pages, 9 figures, 1 table)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human brain structural networks contain sets of centrally embedded hub\nregions that enable efficient information communication. However, it remains\nlargely unknown about categories of structural brain hubs and their\nmicrostructural, functional and cognitive characteristics as well as\ncontributions to individual identification. Here, we employed three multi-modal\nimaging data sets with structural MRI, diffusion MRI and resting-state\nfunctional MRI to construct individual structural brain networks, identify\nbrain hubs based on eight commonly used graph-nodal metrics, and perform\ncomprehensive validation analysis. We found three categories of structural hubs\nin the brain networks, namely, aggregated, distributed and connector hubs.\nSpatially, these distinct categories of hubs were primarily located in the\ndefault-mode system and additionally in the visual and limbic systems for\naggregated hubs, in the frontoparietal system for distributed hubs, and in the\nsensorimotor and ventral attention systems for connector hubs. Importantly,\nthese three categories of hubs exhibited various distinct characteristics, with\nthe highest level of microstructural organization in the aggregated hubs, the\nlargest wiring cost and topological vulnerability in the distributed hubs, and\nthe highest functional associations and cognitive flexibility in the connector\nhubs, although they behaved better regarding these characteristics compared to\nnon-hubs. Finally, all three categories of hub indices displayed high\nacross-session spatial similarities and acted as a structural fingerprint with\nhigh predictive rates (100%, 100% and 84.2%) for individual identification.\nCollectively, our findings highlighted three categories of brain hubs with\ndifferential microstructural, functional and cognitive associations, which may\nshed light on the topological mechanisms of the human connectome.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 12:41:29 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Wang", "Xindi", ""], ["Lin", "Qixiang", ""], ["Xia", "Mingrui", ""], ["He", "Yong", ""]]}, {"id": "1609.03502", "submitter": "Vladimir Itskov", "authors": "Joshua Cruz, Chad Giusti, Vladimir Itskov, Bill Kronholm", "title": "On open and closed convex codes", "comments": "Minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural codes serve as a language for neurons in the brain. Convex codes,\nwhich arise from the pattern of intersections of convex sets in Euclidean\nspace, are of particular relevance to neuroscience. Not every code is convex,\nhowever, and the combinatorial properties of a code that determine its\nconvexity are still poorly understood. Here we find that a code that can be\nrealized by a collection of open convex sets may or may not be realizable by\nclosed convex sets, and vice versa, establishing that open convex and closed\nconvex codes are distinct classes. We also prove that max intersection-complete\ncodes (i.e. codes that contain all intersections of maximal codewords) are both\nopen convex and closed convex, and provide an upper bound for their minimal\nembedding dimension. Finally, we show that the addition of non-maximal\ncodewords to an open convex code preserves convexity.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 17:50:02 GMT"}, {"version": "v2", "created": "Tue, 1 Nov 2016 22:22:44 GMT"}, {"version": "v3", "created": "Tue, 30 May 2017 17:02:40 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Cruz", "Joshua", ""], ["Giusti", "Chad", ""], ["Itskov", "Vladimir", ""], ["Kronholm", "Bill", ""]]}, {"id": "1609.03519", "submitter": "Yuval Harel", "authors": "Yuval Harel, Ron Meir, Manfred Opper", "title": "Optimal Encoding and Decoding for Point Process Observations: an\n  Approximate Closed-Form Filter", "comments": "arXiv admin note: text overlap with arXiv:1507.07813", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of dynamic state estimation (filtering) based on point process\nobservations is in general intractable. Numerical sampling techniques are often\npractically useful, but lead to limited conceptual insight about optimal\nencoding/decoding strategies, which are of significant relevance to\nComputational Neuroscience. We develop an analytically tractable Bayesian\napproximation to optimal filtering based on point process observations, which\nallows us to introduce distributional assumptions about sensor properties, that\ngreatly facilitate the analysis of optimal encoding in situations deviating\nfrom common assumptions of uniform coding. Numerical comparison with particle\nfiltering demonstrate the quality of the approximation. The analytic framework\nleads to insights which are difficult to obtain from numerical algorithms, and\nis consistent with biological observations about the distribution of sensory\ncells' tuning curve centers.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 18:33:50 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Harel", "Yuval", ""], ["Meir", "Ron", ""], ["Opper", "Manfred", ""]]}, {"id": "1609.03529", "submitter": "Abhimanyu Dubey", "authors": "Abhimanyu Dubey, Jayadeva, Sumeet Agarwal", "title": "Examining Representational Similarity in ConvNets and the Primate Visual\n  Cortex", "comments": "4 pages, short abstract, Accepted to the Workshop on Biological and\n  Artificial Vision, ECCV, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare several ConvNets with different depth and regularization\ntechniques with multi-unit macaque IT cortex recordings and assess the impact\nof the same on representational similarity with the primate visual cortex. We\nfind that with increasing depth and validation performance, ConvNet features\nare closer to cortical IT representations.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 19:00:24 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Dubey", "Abhimanyu", ""], ["Jayadeva", "", ""], ["Agarwal", "Sumeet", ""]]}, {"id": "1609.03622", "submitter": "Jung Lee", "authors": "Jung H. Lee, Christof Koch and Stefan Mihalas", "title": "A Computational Analysis of the Function of Three Inhibitory Cell Types\n  in Contextual Visual Processing", "comments": "39 pages, 5 figures, 4 supplemental figures, 2 tables", "journal-ref": null, "doi": "10.3389/fncom.2017.00028", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most cortical inhibitory cell types exclusively express one of three genes,\nparvalbumin, somatostatin and 5HT3a. The visual responses of cortical neurons\nare affected not only by local cues, but also by visual context. As the\ninhibitory neuron types have distinctive synaptic sources and targets over\ndifferent spatial extents and from different areas, we conjecture that they\npossess distinct roles in contextual processing. We use modeling to relate\nstructural information to function in primary visual cortex (V1) of the mouse,\nand investigate their role in contextual visual processing. Our findings are\nthreefold. First, the inhibition mediated by parvalbumin positive (PV) cells\nmediates local processing and could underlie their role in boundary detection.\nSecond, the inhibition mediated by somatostatin-positive (SST) cells\nfacilitates longer range spatial competition among receptive fields. Third,\nnon-specific top-down modulation to interneurons expressing vasoactive\nintestinal polypeptide (VIP), a subclass of 5HT3a neurons, can selectively\nenhance V1 responses.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 22:41:09 GMT"}], "update_date": "2018-06-18", "authors_parsed": [["Lee", "Jung H.", ""], ["Koch", "Christof", ""], ["Mihalas", "Stefan", ""]]}, {"id": "1609.03730", "submitter": "Raunaq Pradhan Mr", "authors": "Raunaq Pradhan, Yuanjin Zheng", "title": "A hierarchical neural stimulation model for pain relief by variation of\n  coil design parameters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural stimulation represents a powerful technique for neural disorder\ntreatment. This paper deals with optimization of coil design parameters to be\nused during stimulation for modulation of neuronal firing to achieve pain\nrelief. Pain mechanism is briefly introduced and a hierarchical stimulation\nmodel from coil stimulation to neuronal firing is proposed. Electromagnetic\nfield distribution for circular, figure of 8 and Magnetic resonance coupling\nfigure of 8 coils are analyzed with respect to the variation of stimulation\nparameters such as distance between coils, stimulation frequency, number of\nturns and radius of coils. MRC figure of 8 coils were responsible for inducing\nthe maximum Electric field for same amount of driving current in coils.\nVariation of membrane potential, ion channel conductance and neuronal firing\nfrequency in a pyramidal neuronal model due to magnetic and acoustic\nstimulation are studied. The frequency of neuronal firing for cortical neurons\nis higher during pain state, compared to no pain state. Lowest neuronal firing\nfrequency 18 Hz was found for MRC figure of 8 coils, compared to 30 Hz for\ncircular coils. Therefore, MRC figure of 8 coils are most effective for\nmodulation of neuronal firing, thereby achieving pain relief in comparison to\nother coils considered in this study\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 08:53:08 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Pradhan", "Raunaq", ""], ["Zheng", "Yuanjin", ""]]}, {"id": "1609.03893", "submitter": "Yu Jin", "authors": "Yu Jin, Joseph F. JaJa, Rong Chen, Edward H. Herskovits", "title": "Scalable Algorithms for Generating and Analyzing Structural Brain\n  Networks with a Varying Number of Nodes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion Magnetic Resonance Imaging (MRI) exploits the anisotropic diffusion\nof water molecules in the brain to enable the estimation of the brain's\nanatomical fiber tracts at a relatively high resolution. In particular,\ntractographic methods can be used to generate whole-brain anatomical\nconnectivity matrix where each element provides an estimate of the connectivity\nstrength between the corresponding voxels. Structural brain networks are built\nusing the connectivity information and a predefined brain parcellation, where\nthe nodes of the network represent the brain regions and the edge weights\ncapture the connectivity strengths between the corresponding brain regions.\nThis paper introduces a number of novel scalable methods to generate and\nanalyze structural brain networks with a varying number of nodes. In\nparticular, we introduce a new parallel algorithm to quickly generate large\nscale connectivity-based parcellations for which voxels in a region possess\nhighly similar connectivity patterns to the rest of the regions. We show that\nthe corresponding regional structural consistency is always superior to\nrandomly generated parcellations over a wide range of parcellation sizes.\nCorresponding brain networks with a varying number of nodes are analyzed using\nstandard graph-theorectic measures, as well as, new measures derived from\nspectral graph theory. Our results indicate increasingly more statistical power\nof brain networks with larger numbers of nodes and the relatively unique shape\nof the spectral profile of large brain networks relative to other well-known\nnetworks.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 15:17:58 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Jin", "Yu", ""], ["JaJa", "Joseph F.", ""], ["Chen", "Rong", ""], ["Herskovits", "Edward H.", ""]]}, {"id": "1609.03962", "submitter": "Arkady Zgonnikov", "authors": "Arkady Zgonnikov, Ihor Lubashevsky", "title": "Noise-induced phase transition in the model of human virtual stick\n  balancing", "comments": "2 pages, 3 figures Submitted to International Symposium on Stochastic\n  Systems Theory and Its Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans face the task of balancing dynamic systems near an unstable\nequilibrium repeatedly throughout their lives. Much research has been aimed at\nunderstanding the mechanisms of intermittent control in the context of human\nbalance control. The present paper deals with one of the recent developments in\nthe theory of human intermittent control, namely, the double-well model of\nnoise-driven control activation. We demonstrate that the double-well model can\nreproduce the whole range of experimentally observed distributions under\ndifferent conditions. Moreover, we show that a slight change in the noise\nintensity parameter leads to a sudden shift of the action point distribution\nshape, that is, a phase transition is observed.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 12:10:40 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Zgonnikov", "Arkady", ""], ["Lubashevsky", "Ihor", ""]]}, {"id": "1609.04033", "submitter": "Peter Grindrod", "authors": "Peter Grindrod", "title": "On Human Consciousness", "comments": "2 Figures 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the implications of the mathematical analysis of\nneurone-to-neurone dynamical complex networks. We show how the dynamical\nbehaviour of small scale strongly connected networks lead naturally to\nnon-binary information processing and thus multiple hypothesis decision making,\neven at the very lowest level of the brain's architecture. In turn we build on\nthese ideas to address the hard problem of consciousness. We discuss how a\nproposed \"dual hierarchy model\", made up form of both external perceived,\nphysical, elements of increasing complexity, and internal mental elements\n(experiences), may support a leaning and evolving consciousness. We discuss the\nidea that a human brain ought to be able to re-conjure subjective mental\nfeelings at will and thus these cannot depend on internal nose (chatter) or\ninternal instability-driven activity. An immediate consequence of this model,\ngrounded in dynamical systems and non-binary information processing, is that\nfinite human brains must always be learning or forgetteing and that any\npossible subjective internal feeling that may be idealised with a countable\ninfinity of facets, can never be learned by zombies or automata: though it can\nbe experienced more and more fully by an evolving brain (yet never in totality,\nnot even in a lifetime).\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 17:52:56 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Grindrod", "Peter", ""]]}, {"id": "1609.04245", "submitter": "Felix Z. Hoffmann", "authors": "Felix Z. Hoffmann, Jochen Triesch", "title": "Non-random network connectivity comes in pairs", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Overrepresentation of bidirectional connections in local cortical networks\nhas been repeatedly reported and is in the focus of the ongoing discussion of\nnon-random connectivity. Here we show in a brief mathematical analysis that in\na network in which connection probabilities are symmetric in pairs, $P_{ij} =\nP_{ji}$, the occurrence of bidirectional connections and non-random structures\nare inherently linked; an overabundance of reciprocally connected pairs emerges\nnecessarily when the network structure deviates from a random network in any\nform.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 12:54:43 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 17:59:01 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Hoffmann", "Felix Z.", ""], ["Triesch", "Jochen", ""]]}, {"id": "1609.04316", "submitter": "Carlo Nicolini", "authors": "Carlo Nicolini, C\\'ecile Bordier, Angelo Bifone", "title": "Community detection in weighted brain connectivity networks beyond the\n  resolution limit", "comments": "27 pages with 6 figures and 1 table. Conference version for CCS2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.soc-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph theory provides a powerful framework to investigate brain functional\nconnectivity networks and their modular organization. However, most graph-based\nmethods suffer from a fundamental resolution limit that may have affected\nprevious studies and prevented detection of modules, or communities, that are\nsmaller than a specific scale. Surprise, a resolution-limit-free function\nrooted in discrete probability theory, has been recently introduced and applied\nto brain networks, revealing a wide size-distribution of functional modules, in\ncontrast with many previous reports. However, the use of Surprise is limited to\nbinary networks, while brain networks are intrinsically weighted, reflecting a\ncontinuous distribution of connectivity strengths between different brain\nregions. Here, we propose Asymptotical Surprise, a continuous version of\nSurprise, for the study of weighted brain connectivity networks, and validate\nthis approach in synthetic networks endowed with a ground-truth modular\nstructure. We compare Asymptotical Surprise with leading community detection\nmethods currently in use and show its superior sensitivity in the detection of\nsmall modules even in the presence of noise and intersubject variability such\nas those observed in fMRI data. Finally, we apply our novel approach to\nfunctional connectivity networks from resting state fMRI experimenta, and\ndemonstrate a heterogeneous modular organization, with a wide distribution of\nclusters spanning multiple scales.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 15:36:49 GMT"}], "update_date": "2016-09-15", "authors_parsed": [["Nicolini", "Carlo", ""], ["Bordier", "C\u00e9cile", ""], ["Bifone", "Angelo", ""]]}, {"id": "1609.04419", "submitter": "Fernanda Matias", "authors": "Fernanda S. Matias, Leonardo L. Gollo, Pedro V. Carelli, Claudio R.\n  Mirasso, Mauro Copelli", "title": "Inhibitory loop robustly induces anticipated synchronization in neuronal\n  microcircuits", "comments": null, "journal-ref": null, "doi": "10.1103/PhysRevE.94.042411", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the synchronization properties between two excitatory coupled\nneurons in the presence of an inhibitory loop mediated by an interneuron.\nDynamical inhibition together with noise independently applied to each neuron\nprovide phase diversity in the dynamics of the neuronal motif. We show that the\ninterplay between the coupling strengths and external noise controls the phase\nrelations between the neurons in a counter-intuitive way. For a master-slave\nconfiguration (unidirectional coupling) we find that the slave can anticipate\nthe master, on average, if the slave is subject to the inhibitory feedback. In\nthis non-usual regime, called anticipated synchronization (AS), the phase of\nthe post-synaptic neuron is advanced with respect to that of the pre-synaptic\nneuron. We also show that the AS regime survives even in the presence of\nunbalanced bidirectional excitatory coupling. Moreover, for the symmetric\nmutually coupled situation, the neuron that is subject to the inhibitory loop\nleads in phase.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 20:03:50 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Matias", "Fernanda S.", ""], ["Gollo", "Leonardo L.", ""], ["Carelli", "Pedro V.", ""], ["Mirasso", "Claudio R.", ""], ["Copelli", "Mauro", ""]]}, {"id": "1609.04636", "submitter": "Erik van Oort", "authors": "Erik S.B. van Oort, Maarten Mennes, Tobias Navarro Schr\\\"oder, Vinod\n  J. Kumar, Nestor I. Zaragoza Jimenez, Wolfgang Grodd, Christian F. Doeller,\n  Christian F. Beckmann", "title": "Human brain parcellation using time courses of instantaneous\n  connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional neuroimaging studies have lead to understanding the brain as a\ncollection of spatially segregated functional networks. It is thought that each\nof these networks is in turn composed of a set of distinct sub-regions that\ntogether support each network's function. Considering the sub-regions to be an\nessential part of the brain's functional architecture, several strategies have\nbeen put forward that aim at identifying the functional sub-units of the brain\nby means of functional parcellations. Current parcellation strategies typically\nemploy a bottom-up strategy, creating a parcellation by clustering smaller\nunits. We propose a novel top-down parcellation strategy, using time courses of\ninstantaneous connectivity to subdivide an initial region of interest into\nsub-regions. We use split-half reproducibility to choose the optimal number of\nsub-regions. We apply our Instantaneous Connectivity Parcellation (ICP)\nstrategy on high-quality resting-state FMRI data, and demonstrate the ability\nto generate parcellations for thalamus, entorhinal cortex, motor cortex, and\nsubcortex including brainstem and striatum. We evaluate the subdivisions\nagainst available cytoarchitecture maps to show that the our parcellation\nstrategy recovers biologically valid subdivisions that adhere to known\ncytoarchitectural features.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 13:32:56 GMT"}, {"version": "v2", "created": "Mon, 21 Nov 2016 12:34:17 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["van Oort", "Erik S. B.", ""], ["Mennes", "Maarten", ""], ["Schr\u00f6der", "Tobias Navarro", ""], ["Kumar", "Vinod J.", ""], ["Jimenez", "Nestor I. Zaragoza", ""], ["Grodd", "Wolfgang", ""], ["Doeller", "Christian F.", ""], ["Beckmann", "Christian F.", ""]]}, {"id": "1609.05517", "submitter": "Andrew Eckford", "authors": "Andrew W. Eckford, Kenneth A. Loparo, and Peter J. Thomas", "title": "Finite-State Channel Models for Signal Transduction in Neural Systems", "comments": "Accepted for publication in 2016 IEEE International Conference on\n  Acoustics, Speech, and Signal Processing, Shanghai, China", "journal-ref": null, "doi": "10.1109/ICASSP.2016.7472889", "report-no": null, "categories": "q-bio.QM cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information theory provides powerful tools for understanding communication\nsystems. This analysis can be applied to intercellular signal transduction,\nwhich is a means of chemical communication among cells and microbes. We discuss\nhow to apply information-theoretic analysis to ligand-receptor systems, which\nform the signal carrier and receiver in intercellular signal transduction\nchannels. We also discuss the applications of these results to neuroscience.\n", "versions": [{"version": "v1", "created": "Sun, 18 Sep 2016 17:25:05 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Eckford", "Andrew W.", ""], ["Loparo", "Kenneth A.", ""], ["Thomas", "Peter J.", ""]]}, {"id": "1609.05606", "submitter": "Ajay Deep Kachhvah", "authors": "Ajay Deep Kachhvah", "title": "The effect of distributed time-delays on the synchronization of neuronal\n  networks", "comments": "10 pages, 9 figures", "journal-ref": "The European Physical Journal B (2017)", "doi": "10.1140/epjb/e2016-70572-9", "report-no": "90 (8)", "categories": "physics.comp-ph nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we investigate the synchronization of networks of FitzHugh-Nagumo\nneurons coupled in scale-free, small-world and random topologies, in the\npresence of distributed time delays in the coupling of neurons. We explore how\nthe synchronization transition is affected when the time delays in the\ninteractions between pairs of interacting neurons are non-uniform. We find that\nthe presence of distributed time-delays does not change the behavior of the\nsynchronization transition significantly, vis-a-vis networks with constant\ntime-delay, where the value of the constant time-delay is the mean of the\ndistributed delays. We also notice that a normal distribution of delays gives\nrise to a transition at marginally lower coupling strengths, vis-a-vis\nuniformly distributed delays. These trends hold across classes of networks and\nfor varying standard deviations of the delay distribution, indicating the\ngenerality of these results. So we conclude that distributed delays, which may\nbe typically expected in real-world situations, do not have a notable effect on\nsynchronization. This allows results obtained with constant delays to remain\nrelevant even in the case of randomly distributed delays.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 06:22:19 GMT"}], "update_date": "2019-12-23", "authors_parsed": [["Kachhvah", "Ajay Deep", ""]]}, {"id": "1609.05730", "submitter": "Moritz Deger", "authors": "Moritz Deger, Alexander Seeholzer, Wulfram Gerstner", "title": "Multi-contact synapses for stable networks: a spike-timing dependent\n  model of dendritic spine plasticity and turnover", "comments": "28 pages, 9 figures", "journal-ref": "Cerebral Cortex 28-4 (2018) 1396-1415", "doi": "10.1093/cercor/bhx339", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excitatory synaptic connections in the adult neocortex consist of multiple\nsynaptic contacts, almost exclusively formed on dendritic spines. Changes of\ndendritic spine shape and volume, a correlate of synaptic strength, can be\ntracked in vivo for weeks. Here, we present a combined model of spike-timing\ndependent dendritic spine plasticity and turnover that explains the steady\nstate multi-contact configuration of synapses in adult neocortical networks. In\nthis model, many presynaptic neurons compete to make strong synaptic\nconnections onto postsynaptic neurons, while the synaptic contacts comprising\neach connection cooperate via postsynaptic firing. We demonstrate that the\nmodel is consistent with experimentally observed long-term dendritic spine\ndynamics under steady-state and lesion induced conditions, and show that\ncooperation of multiple synaptic contacts is crucial for stable, long-term\nsynaptic memories. In simulations of a simplified network of barrel cortex, our\nplasticity rule reproduces whisker-trimming induced rewiring of\nthalamo-cortical and recurrent synaptic connectivity on realistic time scales.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 13:56:01 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Deger", "Moritz", ""], ["Seeholzer", "Alexander", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1609.06069", "submitter": "Siddhartha Sen", "authors": "Siddhartha Sen", "title": "Measuring Consciousness", "comments": "23 Pages, Latex file", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A measurement based formula for consciousness, C, as a function of time t, is\nconstructed. The formula depends on identifying a natural relevant\nself-generated, time-dependent dynamical process inherent in any entity. For\nhuman beings the relevant dynamical process identified is the ensemble of brain\nwaves, observed in EEG measurements, that are represented in the model by their\nmeasured time dependent correlation functions. These correlation functions\ndefine the accessible dynamical state of the brain at any moment of time. From\nthem a time dependent probability function, P(t), is extracted by using a\nmathematical identity. According to information theory, -P(t) log P(t), is a\nmeasure of the information contained in the brain waves. Consciousness, C, is\ndefined by this information theory formula: it is not localized, does not\ndepend on specific hardwire details of the brain, but reflects the information\ncontent present in brain waves. Justifications, based on observational\nevidence, are given for the formula and it is shown that C reflects the degree\nof \"awareness\" that a person has at a given moment of time. The model explains\nthe observed time delay between when a brain wave is seen to initiate an action\nand when there is awareness that the action has been initiated, in terms of the\nway brain waves processes information. Some testable consequences of the model,\nincluding the role dreaming sleep plays in long term memory storage, are\ndiscussed. It is also shown that non living entities have C=0.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 09:38:28 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 11:07:08 GMT"}], "update_date": "2018-02-28", "authors_parsed": [["Sen", "Siddhartha", ""]]}, {"id": "1609.06462", "submitter": "Rodrigo Echeveste", "authors": "Rodrigo Echeveste and Claudius Gros", "title": "Drifting states and synchronization induced chaos in autonomous networks\n  of excitable neurons", "comments": null, "journal-ref": "Frontiers in Computational Neuroscience, 10:98, 2016", "doi": "10.3389/fncom.2016.00098", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of balanced networks of excitatory and inhibitory neurons has led\nto several open questions. On the one hand it is yet unclear whether the\nasynchronous state observed in the brain is autonomously generated, or if it\nresults from the interplay between external drivings and internal dynamics. It\nis also not known, which kind of network variabilities will lead to irregular\nspiking and which to synchronous firing states. Here we show how isolated\nnetworks of purely excitatory neurons generically show asynchronous firing\nwhenever a minimal level of structural variability is present together with a\nrefractory period. Our autonomous networks are composed of excitable units, in\nthe form of leaky integrators spiking only in response to driving inputs. For a\nnon-uniform network, composed exclusively of excitatory neurons, we find a rich\nrepertoire of self-induced dynamical states, including asynchronous drifting\nstates, fully synchronized, or mixed, containing both drifting and synchronized\ncomponents. The individual neurons considered are excitable and hence do not\ndispose of intrinsic natural firing frequencies. An effective network-wide\ndistribution of natural frequencies is however generated autonomously through\nself-consistent feedback loops. We find two types of asynchronous activity,\nwith the individual neurons spiking regularly in the pure drifting state,\nalbeit with a continuous distribution of firing frequencies. The activity of\nthe drifting component, however, becomes irregular in the mixed state, due to\nthe periodic driving of the synchronized component. We propose a new tool for\nthe study of chaos in spiking neural networks, which consists of an analysis of\nthe time series of pairs of consecutive interspike intervals. In this space, we\nshow that a strange attractor with a fractal dimension is formed.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 08:37:07 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Echeveste", "Rodrigo", ""], ["Gros", "Claudius", ""]]}, {"id": "1609.07060", "submitter": "Madhu Advani", "authors": "Madhu Advani, Surya Ganguli", "title": "An equivalence between high dimensional Bayes optimal inference and\n  M-estimation", "comments": "To appear in NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When recovering an unknown signal from noisy measurements, the computational\ndifficulty of performing optimal Bayesian MMSE (minimum mean squared error)\ninference often necessitates the use of maximum a posteriori (MAP) inference, a\nspecial case of regularized M-estimation, as a surrogate. However, MAP is\nsuboptimal in high dimensions, when the number of unknown signal components is\nsimilar to the number of measurements. In this work we demonstrate, when the\nsignal distribution and the likelihood function associated with the noise are\nboth log-concave, that optimal MMSE performance is asymptotically achievable\nvia another M-estimation procedure. This procedure involves minimizing convex\nloss and regularizer functions that are nonlinearly smoothed versions of the\nwidely applied MAP optimization problem. Our findings provide a new heuristic\nderivation and interpretation for recent optimal M-estimators found in the\nsetting of linear measurements and additive noise, and further extend these\nresults to nonlinear measurements with non-additive noise. We numerically\ndemonstrate superior performance of our optimal M-estimators relative to MAP.\nOverall, at the heart of our work is the revelation of a remarkable equivalence\nbetween two seemingly very different computational problems: namely that of\nhigh dimensional Bayesian integration underlying MMSE inference, and high\ndimensional convex optimization underlying M-estimation. In essence we show\nthat the former difficult integral may be computed by solving the latter,\nsimpler optimization problem.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 16:46:18 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Advani", "Madhu", ""], ["Ganguli", "Surya", ""]]}, {"id": "1609.07068", "submitter": "Yujiang Wang", "authors": "Yujiang Wang, Andrew J Trevelyan, Antonio Valentin, Gonzalo Alarcon,\n  Peter N Taylor, Marcus Kaiser", "title": "Mechanisms underlying different onset patterns of focal seizures", "comments": null, "journal-ref": "PLOS Computational Biology 2017 13(5): e1005475", "doi": "10.1371/journal.pcbi.1005475", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Focal seizures are episodes of pathological brain activity that appear to\narise from a localised area of the brain. The onset patterns of focal seizure\nactivity have been studied intensively, and they have largely been\ndistinguished into two types - low amplitude fast oscillations (LAF), or high\namplitude spikes (HAS). Here we explore whether these two patterns arise from\nfundamentally different mechanisms. Here, we use a previously established\ncomputational model of neocortical tissue, and validate it as an adequate model\nusing clinical recordings of focal seizures. We then reproduce the two onset\npatterns in their most defining properties and investigate the possible\nmechanisms underlying the different focal seizure onset patterns in the model.\nWe show that the two patterns are associated with different mechanisms at the\nspatial scale of a single ECoG electrode. The LAF onset is initiated by\nindependent patches of localised activity, which slowly invade the surrounding\ntissue and coalesce over time. In contrast, the HAS onset is a global, systemic\ntransition to a coexisting seizure state triggered by a local event. We find\nthat such a global transition is enabled by an increase in the excitability of\nthe \"healthy\" surrounding tissue, which by itself does not generate seizures,\nbut can support seizure activity when incited. In our simulations, the\ndifference in surrounding tissue excitability also offers a simple explanation\nof the clinically reported difference in surgical outcomes. Finally, we\ndemonstrate in the model how changes in tissue excitability could be\nelucidated, in principle, using active stimulation. Taken together, our\nmodelling results suggest that the excitability of the tissue surrounding the\nseizure core may play a determining role in the seizure onset pattern, as well\nas in the surgical outcome.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 17:03:08 GMT"}, {"version": "v2", "created": "Fri, 5 May 2017 13:20:15 GMT"}], "update_date": "2017-05-08", "authors_parsed": [["Wang", "Yujiang", ""], ["Trevelyan", "Andrew J", ""], ["Valentin", "Antonio", ""], ["Alarcon", "Gonzalo", ""], ["Taylor", "Peter N", ""], ["Kaiser", "Marcus", ""]]}, {"id": "1609.07103", "submitter": "Etienne Tanr\\'e", "authors": "Pierre Guiraud and Etienne Tanr\\'e", "title": "Stability of synchronization under stochastic perturbations in leaky\n  integrate and fire neural networks of finite size", "comments": null, "journal-ref": null, "doi": "10.3934/dcdsb.2019056", "report-no": null, "categories": "math.PR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the synchronization of fully-connected and totally excitatory\nintegrate and fire neural networks in presence of Gaussian white noises. Using\na large deviation principle, we prove the stability of the synchronized state\nunder stochastic perturbations. Then, we give a lower bound on the probability\nof synchronization for networks which are not initially synchronized. This\nbound shows the robustness of the emergence of synchronization in presence of\nsmall stochastic perturbations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 18:37:50 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 07:43:46 GMT"}], "update_date": "2019-04-22", "authors_parsed": [["Guiraud", "Pierre", ""], ["Tanr\u00e9", "Etienne", ""]]}, {"id": "1609.07355", "submitter": "Peteris Daugulis", "authors": "Peteris Daugulis", "title": "Strong connectivity and its applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM math.CO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed graphs are widely used in modelling of nonsymmetric relations in\nvarious sciences and engineering disciplines. We discuss invariants of strongly\nconnected directed graphs - minimal number of vertices or edges necessary to\nremove to make remaining graphs not strongly connected. By analogy with\nundirected graphs these invariants are called strong vertex/edge\nconnectivities. We review some properties of these invariants. Computational\nresults for some publicly available connectome graphs used in neuroscience are\ndescribed.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 11:35:44 GMT"}, {"version": "v2", "created": "Thu, 20 Oct 2016 11:57:24 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Daugulis", "Peteris", ""]]}, {"id": "1609.07365", "submitter": "Dimitrios Adamos Dr", "authors": "Dimitrios A. Adamos (1 and 3), Stavros I. Dimitriadis (2), Nikolaos A.\n  Laskaris (2 and 3), ((1) School of Music Studies, Faculty of Fine Arts,\n  Aristotle University of Thessaloniki, (2) AIIA Lab, Department of\n  Informatics, Aristotle University of Thessaloniki, (3) Neuroinformatics\n  GRoup, Aristotle University of Thessaloniki)", "title": "Towards the bio-personalization of music recommendation systems: A\n  single-sensor EEG biomarker of subjective music preference", "comments": null, "journal-ref": "Information Sciences, Volumes 343 - 344, 20 May 2016, Pages 94 -\n  108", "doi": "10.1016/j.ins.2016.01.005", "report-no": null, "categories": "q-bio.NC cs.AI cs.HC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in biosensors technology and mobile electroencephalographic\n(EEG) interfaces have opened new application fields for cognitive monitoring. A\ncomputable biomarker for the assessment of spontaneous aesthetic brain\nresponses during music listening is introduced here. It derives from\nwell-established measures of cross-frequency coupling (CFC) and quantifies the\nmusic-induced alterations in the dynamic relationships between brain rhythms.\nDuring a stage of exploratory analysis, and using the signals from a suitably\ndesigned experiment, we established the biomarker, which acts on brain\nactivations recorded over the left prefrontal cortex and focuses on the\nfunctional coupling between high-beta and low-gamma oscillations. Based on data\nfrom an additional experimental paradigm, we validated the introduced biomarker\nand showed its relevance for expressing the subjective aesthetic appreciation\nof a piece of music. Our approach resulted in an affordable tool that can\npromote human-machine interaction and, by serving as a personalized music\nannotation strategy, can be potentially integrated into modern flexible music\nrecommendation systems.\n  Keywords: Cross-frequency coupling; Human-computer interaction;\nBrain-computer interface\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 09:24:01 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Adamos", "Dimitrios A.", "", "1 and 3"], ["Dimitriadis", "Stavros I.", "", "2 and 3"], ["Laskaris", "Nikolaos A.", "", "2 and 3"]]}, {"id": "1609.07656", "submitter": "Melanie Weber", "authors": "Melanie Weber, Pedro D. Maia and J. Nathan Kutz", "title": "Associative Memory Impairments arising from Neurodegenerative Diseases\n  and Traumatic Brain Injuries in a Hopfield Network Model", "comments": "23 pages, 6 figures. Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurodegenerative diseases and traumatic brain injuries (TBI) are among the\nmain causes of cognitive dysfunction in humans. Both manifestations exhibit the\nextensive presence of focal axonal swellings (FAS). FAS compromises the\ninformation encoded in spike trains, thus leading to potentially severe\nfunctional deficits. Complicating our understanding of the impact of FAS is our\ninability to access small scale injuries with non-invasive methods, the overall\ncomplexity of neuronal pathologies, and our limited knowledge of how networks\nprocess biological signals. Building on Hopfield's pioneering work, we extend a\nmodel for associative memory to account for FAS and its impact on memory\nencoding. We calibrate all FAS parameters from biophysical observations of\ntheir statistical distribution and size, providing a framework to simulate the\neffects of brain disorders on memory recall performance. A face recognition\nexample is used to demonstrate and validate the functionality of the novel\nmodel. Our results link memory recall ability to observed FAS statistics,\nallowing for a description of different stages of brain disorders within\nneuronal networks. This provides a first theoretical model to bridge\nexperimental observations of FAS in neurodegeneration and TBI with compromised\nmemory recall, thus closing the large gap between theory and experiment on how\nbiological signals are processed in damaged, high-dimensional functional\nnetworks. The work further lends new insight into positing diagnostic tools to\nmeasure cognitive deficits.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 19:06:35 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Weber", "Melanie", ""], ["Maia", "Pedro D.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1609.08083", "submitter": "Kieran Fox", "authors": "Kieran C.R. Fox, Nicholas S. Fitz, Peter B. Reiner", "title": "The multiplicity of memory enhancement: Practical and ethical\n  implications of the diverse neural substrates underlying human memory systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural basis of human memory is incredibly complex. We argue that the\ndiversity of neural systems underlying various forms of memory suggests that\nany discussion of enhancing 'memory' per se is too broad, thus obfuscating the\nbiopolitical debate about human enhancement. Memory can be differentiated into\nat least four major (and several minor) systems with largely dissociable (i.e.,\nnon-overlapping) neural substrates. We outline each system, and discuss both\nthe practical and the ethical implications of these diverse neural substrates.\nIn practice, distinct neural bases imply the possibility, and likely the\nnecessity, of specific approaches for the safe and effective enhancement of\nvarious memory systems. In the debate over the ethical and social implications\nof enhancement technologies, this fine-grained perspective clarifies - and may\npartially mitigate - certain common concerns in enhancement debates, including\nissues related to safety, fairness, coercion, and authenticity. While many\nresearchers certainly appreciate the neurobiological complexity of memory, the\npolitical debate tends to revolve around a monolithic one-size-fits-all\nconception. The overall project - exploring how human enhancement technologies\naffect society - stands to benefit from a deeper appreciation of memory's\nneurobiological diversity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 17:17:04 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Fox", "Kieran C. R.", ""], ["Fitz", "Nicholas S.", ""], ["Reiner", "Peter B.", ""]]}, {"id": "1609.08213", "submitter": "Chandan Singh", "authors": "Chandan Singh, William B. Levy", "title": "Complexity Leads to Simplicity: A Consensus Layer V Pyramidal Neuron Can\n  Sustain Interpulse-Interval Coding", "comments": "submitted to PLOS Computational Biology", "journal-ref": "Published in PLOS One 2017", "doi": "10.1371/journal.pone.0180839", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In terms of the long-distance communication of a single neuron, interpulse\nintervals (IPIs) are a possible alternative to rate and binary codes. As a\nproxy for IPI, the time-to-spike (TTS) for a neuron can be found in the\nbiophysical and experimental literature. Using the current, consensus layer V\npyramidal neuron, the present study examines the feasibility of IPI-coding and\nexamines the noise sources that limit the information rate of such an encoding.\nIn descending order of noise intensity, the noise sources are (i) synaptic\nvariability, (ii) sodium channel shot-noise, followed by (iii) thermal noise\nwith synaptic noise much greater than the sodium channel-noise. More\nimportantly, the biophysical model demonstrates a linear relationship between\ninput intensity and inverse TTS. This linear observation contradicts the\nassumption that a neuron should be treated as a passive, electronic circuit (an\nRC circuit, as in the Stein model). Finally, the biophysical simulations allow\nthe calculation of mutual information, which is about 3.0 bits/spike.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 22:31:25 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Singh", "Chandan", ""], ["Levy", "William B.", ""]]}, {"id": "1609.08320", "submitter": "Matjaz Perc", "authors": "Ehsan Bolhasani, Yousef Azizi, Alireza Valizadeh, Matjaz Perc", "title": "Synchronization of oscillators through time-shifted common inputs", "comments": "6 two-column pages, 3 figures; accepted for publication in Physical\n  Review E", "journal-ref": "Phys. Rev. E 95, 032207 (2017)", "doi": "10.1103/PhysRevE.95.032207", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared upstream dynamical processes are frequently the source of common\ninputs in various physical and biological systems. However, due to finite\nsignal transmission speeds and differences in the distance to the source, time\nshifts between otherwise common inputs are unavoidable. Since common inputs can\nbe a source of correlation between the elements of multi-unit dynamical\nsystems, regardless of whether these elements are directly connected with one\nanother or not, it is of importance to understand their impact on\nsynchronization. As a canonical model that is representative for a variety of\ndifferent dynamical systems, we study limit-cycle oscillators that are driven\nby stochastic time-shifted common inputs. We show that if the oscillators are\ncoupled, time shifts in stochastic common inputs do not simply shift the\ndistribution of the phase differences, but rather the distribution actually\nchanges as a result. The best synchronization is therefore achieved at a\nprecise intermediate value of the time shift, which is due to a resonance-like\neffect with the most probable phase difference that is determined by the\ndeterministic dynamics.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 08:55:24 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 20:49:36 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Bolhasani", "Ehsan", ""], ["Azizi", "Yousef", ""], ["Valizadeh", "Alireza", ""], ["Perc", "Matjaz", ""]]}, {"id": "1609.08855", "submitter": "Maurizio Mattia", "authors": "Maurizio Mattia", "title": "Low-dimensional firing rate dynamics of spiking neuron networks", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting from a spectral expansion of the Fokker-Plank equation for the\nmembrane potential density in a network of spiking neurons, a low-dimensional\ndynamics of the collective firing rate is derived. As a result a $n$-order\nordinary differential equation for the network activity can be worked out by\ntaking into account the slowest $n$ modes of the expansion. The resulting\nlow-dimensional dynamics naturally takes into account the strength of the\nsynaptic couplings under the hypothesis of a not too fast changing membrane\npotential density. By considering only the two slowest modes, the firing rate\ndynamics is equivalent to the one of a damped oscillator in which the angular\nfrequency and the relaxation time are state-dependent. The presented results\napply to a wide class of networks of one-compartment neuron models.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 10:43:41 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Mattia", "Maurizio", ""]]}, {"id": "1609.08980", "submitter": "Rahul Remanan", "authors": "Rahul Remanan (M.B.B.S.), Viktor Sukhotskiy (Ph.D. graduate student),\n  Mona Shahbazi (N.P.), Edward P. Furlani (Ph.D.), Dale J. Lange (M.D.)", "title": "Assessment of corticospinal tract dysfunction and disease severity in\n  amyotrophic lateral sclerosis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The upper motor neuron dysfunction in amyotrophic lateral sclerosis was\nquantified using triple stimulation and more focal transcranial magnetic\nstimulation techniques that were developed to reduce recording variability.\nThese measurements were combined with clinical and neurophysiological data to\ndevelop a novel random forest based supervised machine learning prediction\nmodel. This model was capable of predicting cross-sectional ALS disease\nseverity as measured by the ALSFRSr scale with 97% overall accuracy and 99%\nprecision. The machine learning model developed in this research provides a\nnew, unique and objective diagnostic method for quantifying disease severity\nand identifying subtle changes in disease progression in ALS.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 15:59:12 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Remanan", "Rahul", "", "M.B.B.S."], ["Sukhotskiy", "Viktor", "", "Ph.D. graduate student"], ["Shahbazi", "Mona", "", "N.P."], ["Furlani", "Edward P.", "", "Ph.D."], ["Lange", "Dale J.", "", "M.D."]]}, {"id": "1609.09036", "submitter": "Vince Grolmusz", "authors": "Bal\\'azs Szalkai and Csaba Kerepesi and B\\'alint Varga and Vince\n  Grolmusz", "title": "High-Resolution Directed Human Connectomes and the Consensus Connectome\n  Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we show a method of directing the edges of the connectomes, prepared\nfrom diffusion tensor imaging (DTI) datasets from the human brain. Before the\npresent work, no high-definition directed braingraphs (or connectomes) were\npublished, because the tractography methods in use are not capable of assigning\ndirections to the neural tracts discovered. Previous work on the functional\nconnectomes applied low-resolution functional MRI-detected statistical\ncausality for the assignment of directions of connectomes of typically several\ndozens of vertices. Our method is based on the phenomenon of the \"Consensus\nConnectome Dynamics\" (CCD), described earlier by our research group. In this\ncontribution, we apply the method to the 423 braingraphs, each with 1015\nvertices, computed from the public release of the Human Connectome Project, and\nwe also made the directed connectomes publicly available at the site\n\\url{http://braingraph.org}. We also show the robustness of our edge directing\nmethod in four independently chosen connectome datasets: we have found that\n86\\% of the edges, which were present in all four datasets, get the very same\ndirections in all datasets; therefore the direction method is robust, it does\nnot depend on the particular choice of the dataset. We think that our present\ncontribution opens up new possibilities in the analysis of the high-definition\nhuman connectome: from now on we can work with a robust assignment of\ndirections of the connections of the human brain.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 18:35:30 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Szalkai", "Bal\u00e1zs", ""], ["Kerepesi", "Csaba", ""], ["Varga", "B\u00e1lint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1609.09059", "submitter": "Ingmar Kanitscheider", "authors": "Ingmar Kanitscheider and Ila Fiete", "title": "Training recurrent networks to generate hypotheses about how the brain\n  solves hard navigation problems", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-localization during navigation with noisy sensors in an ambiguous world\nis computationally challenging, yet animals and humans excel at it. In\nrobotics, Simultaneous Location and Mapping (SLAM) algorithms solve this\nproblem though joint sequential probabilistic inference of their own\ncoordinates and those of external spatial landmarks. We generate the first\nneural solution to the SLAM problem by training recurrent LSTM networks to\nperform a set of hard 2D navigation tasks that include generalization to\ncompletely novel trajectories and environments. The hidden unit representations\nexhibit several key properties of hippocampal place cells, including stable\ntuning curves that remap between environments. Our result is also a proof of\nconcept for end-to-end-learning of a SLAM algorithm using recurrent networks,\nand a demonstration of why this approach may have some advantages for robotic\nSLAM.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 19:59:27 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 22:44:18 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Kanitscheider", "Ingmar", ""], ["Fiete", "Ila", ""]]}, {"id": "1609.09144", "submitter": "Dmitry Novikov", "authors": "Dmitry S. Novikov, Jelle Veraart, Ileana O. Jelescu, Els Fieremans", "title": "Rotationally-invariant mapping of scalar and orientational metrics of\n  neuronal microstructure with diffusion MRI", "comments": "25 pages, 12 figures, elsarticle two-column", "journal-ref": "NeuroImage 174, 518-538 (2018)", "doi": "10.1016/j.neuroimage.2018.03.006", "report-no": null, "categories": "physics.bio-ph physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a general analytical and numerical framework for estimating intra-\nand extra-neurite water fractions and diffusion coefficients, as well as\nneurite orientational dispersion, in each imaging voxel. By employing a set of\nrotational invariants and their expansion in the powers of diffusion weighting,\nwe analytically uncover the nontrivial topology of the parameter estimation\nlandscape, showing that multiple branches of parameters describe the\nmeasurement almost equally well, with only one of them corresponding to the\nbiophysical reality. A comprehensive acquisition shows that the branch choice\nvaries across the brain. Our framework reveals hidden degeneracies in MRI\nparameter estimation for neuronal tissue, provides microstructural and\norientational maps in the whole brain without constraints or priors, and\nconnects modern biophysical modeling with clinical MRI.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 22:37:21 GMT"}, {"version": "v2", "created": "Fri, 6 Apr 2018 05:09:39 GMT"}], "update_date": "2018-04-10", "authors_parsed": [["Novikov", "Dmitry S.", ""], ["Veraart", "Jelle", ""], ["Jelescu", "Ileana O.", ""], ["Fieremans", "Els", ""]]}, {"id": "1609.09145", "submitter": "Dmitry Novikov", "authors": "Jelle Veraart, Els Fieremans, and Dmitry S. Novikov", "title": "Universal power-law scaling of water diffusion in human brain defines\n  what we see with MRI", "comments": "7 pages, 4 figures, revtex4-1", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Development of successful therapies for neurological disorders depends on our\nability to diagnose and monitor the progression of underlying pathologies at\nthe cellular level. Physics and physiology limit the resolution of human MRI to\nmillimeters, three orders of magnitude coarser than the cell dimensions of\nmicrons. A promising way to access cellular structure is provided by\ndiffusion-weighted MRI (dMRI), a modality which exploits the sensitivity of the\nMRI signal to micron-level Brownian motion of water molecules strongly hindered\nby cell walls. By analyzing diffusion of water molecules in human subjects,\nhere we demonstrate that biophysical modeling has the potential to break the\nintrinsic MRI resolution limits. The observation of a universal power-law\nscaling of the dMRI signal identifies the contribution from water specifically\nconfined inside narrow impermeable axons, validating the overarching assumption\nbehind models of diffusion in neuronal tissue. This scaling behavior\nestablishes dMRI as an in vivo instrument able to quantify intra-axonal\nproperties orders of magnitude below the nominal MRI resolution, spurring our\nunderstanding of brain anatomy and function.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 22:37:27 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Veraart", "Jelle", ""], ["Fieremans", "Els", ""], ["Novikov", "Dmitry S.", ""]]}, {"id": "1609.09218", "submitter": "Ruedi Stoop", "authors": "Kalris Kanders and Ruedi Stoop", "title": "Is cortical criticality unique?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are indications that for optimizing neural computation, neural networks\n- including the brain - operate at criticality. Previous approaches have,\nhowever, used diverse fingerprints of criticality, leaving open the question\nwhether they refer to a unique critical point or whether there could be\nseveral. Using a recurrent spiking neural network as the model, we demonstrate\nthat avalanche criticality does not necessarily lie at the dynamical\nedge-of-chaos and that therefore, the different fingerprints indicate distinct\nphenomena with an as yet unclarified relationship.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 06:32:45 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Kanders", "Kalris", ""], ["Stoop", "Ruedi", ""]]}, {"id": "1609.09432", "submitter": "Hejia Zhang", "authors": "Hejia Zhang, Po-Hsuan Chen, Janice Chen, Xia Zhu, Javier S. Turek,\n  Theodore L. Willke, Uri Hasson, Peter J. Ramadge", "title": "A Searchlight Factor Model Approach for Locating Shared Information in\n  Multi-Subject fMRI Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing interest in joint multi-subject fMRI analysis. The\nchallenge of such analysis comes from inherent anatomical and functional\nvariability across subjects. One approach to resolving this is a shared\nresponse factor model. This assumes a shared and time synchronized stimulus\nacross subjects. Such a model can often identify shared information, but it may\nnot be able to pinpoint with high resolution the spatial location of this\ninformation. In this work, we examine a searchlight based shared response model\nto identify shared information in small contiguous regions (searchlights)\nacross the whole brain. Validation using classification tasks demonstrates that\nwe can pinpoint informative local regions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 17:20:23 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Zhang", "Hejia", ""], ["Chen", "Po-Hsuan", ""], ["Chen", "Janice", ""], ["Zhu", "Xia", ""], ["Turek", "Javier S.", ""], ["Willke", "Theodore L.", ""], ["Hasson", "Uri", ""], ["Ramadge", "Peter J.", ""]]}, {"id": "1609.09578", "submitter": "Jing Jin", "authors": "Zhaoyang Qiu, Brendan Z. Allison, Jing Jin, Yu Zhang, Xingyu Wang, Wei\n  Li, Andrzej Cichocki", "title": "Optimized motor imagery paradigm based on imagining Chinese characters\n  writing movement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motor imagery (MI) is a mental representation of motor behavior that has been\nwidely used as a control method for a brain-computer interface (BCI), allowing\ncommunication for the physically impaired. The performance of MI based BCI\nmainly depends on the subject's ability to self-modulate EEG signals. Proper\ntraining can help naive subjects learn to modulate brain activity proficiently.\nHowever, training subjects typically involves abstract motor tasks and is\ntime-consuming. To improve the performance of naive subjects during motor\nimagery, a novel paradigm was presented that would guide naive subjects to\nmodulate brain activity effectively. In this new paradigm, pictures of the left\nor right hand were used as cues for subjects to finish the motor imagery task.\nFourteen healthy subjects (11 male, aged 22-25 years, mean 23.6+/-1.16)\nparticipated in this study. The task was to imagine writing a Chinese\ncharacter. Specifically, subjects could imagine hand movements following the\nsequence of writing strokes in the Chinese character. This paradigm was meant\nto find an effective and familiar action for most Chinese people, to provide\nthem with a specific, extensively practiced task and help them modulate brain\nactivity. Results showed that the writing task paradigm yielded significantly\nbetter performance than the traditional arrow paradigm (p<0.001). Questionnaire\nreplies indicated that most subjects thought the new paradigm was easier and\nmore comfortable. The proposed new motor imagery paradigm could guide subjects\nto help them modulate brain activity effectively. Results showed that there\nwere significant improvements using new paradigm, both in classification\naccuracy and usability.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 03:02:28 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Qiu", "Zhaoyang", ""], ["Allison", "Brendan Z.", ""], ["Jin", "Jing", ""], ["Zhang", "Yu", ""], ["Wang", "Xingyu", ""], ["Li", "Wei", ""], ["Cichocki", "Andrzej", ""]]}, {"id": "1609.09602", "submitter": "Luis David Garcia-Puente", "authors": "Ethan Petersen, Nora Youngs, Ryan Kruse, Dane Miyata, Rebecca Garcia,\n  Luis David Garcia Puente", "title": "Neural Ideals in SageMath", "comments": "8 pages, 2 tables, software available at\n  https://github.com/e6-1/NeuralIdeals", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.AC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major area in neuroscience research is the study of how the brain processes\nspatial information. Neurons in the brain represent external stimuli via neural\ncodes. These codes often arise from stereotyped stimulus-response maps,\nassociating to each neuron a convex receptive field. An important problem\nconsists in determining what stimulus space features can be extracted directly\nfrom a neural code. The neural ideal is an algebraic object that encodes the\nfull combinatorial data of a neural code. This ideal can be expressed in a\ncanonical form that directly translates to a minimal description of the\nreceptive field structure intrinsic to the code. In here, we describe a\nSageMath package that contains several algorithms related to the canonical form\nof a neural ideal.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 05:43:17 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Petersen", "Ethan", ""], ["Youngs", "Nora", ""], ["Kruse", "Ryan", ""], ["Miyata", "Dane", ""], ["Garcia", "Rebecca", ""], ["Puente", "Luis David Garcia", ""]]}]