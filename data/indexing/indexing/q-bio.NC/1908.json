[{"id": "1908.00077", "submitter": "Jennifer Stiso", "authors": "Jennifer Stiso, Marie-Constance Corsi, Jean M. Vettel, Javier O.\n  Garcia, Fabio Pasqualetti, Fabrizio De Vico Fallani, Timothy H. Lucas,\n  Danielle S. Bassett", "title": "Learning in brain-computer interface control evidenced by joint\n  decomposition of brain and behavior", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motor imagery-based brain-computer interfaces (BCIs) use an individuals\nability to volitionally modulate localized brain activity as a therapy for\nmotor dysfunction or to probe causal relations between brain activity and\nbehavior. However, many individuals cannot learn to successfully modulate their\nbrain activity, greatly limiting the efficacy of BCI for therapy and for basic\nscientific inquiry. Previous research suggests that coherent activity across\ndiverse cognitive systems is a hallmark of individuals who can successfully\nlearn to control the BCI. However, little is known about how these distributed\nnetworks interact through time to support learning. Here, we address this gap\nin knowledge by constructing and applying a multimodal network approach to\ndecipher brain-behavior relations in motor imagery-based brain-computer\ninterface learning using MEG. Specifically, we employ a minimally constrained\nmatrix decomposition method (non-negative matrix factorization) to\nsimultaneously identify regularized, covarying subgraphs of functional\nconnectivity, to assess their similarity to task performance, and to detect\ntheir time-varying expression. Individuals also displayed marked variation in\nthe spatial properties of subgraphs such as the connectivity between the\nfrontal lobe and the rest of the brain, and in the temporal properties of\nsubgraphs such as the stage of learning at which they reached maximum\nexpression. From these observations, we posit a conceptual model in which\ncertain subgraphs support learning by modulating brain activity in regions\nimportant for sustaining attention. To test this model, we use tools that\nstipulate regional dynamics on a networked system (network control theory), and\nfind that good learners display a single subgraph whose temporal expression\ntracked performance and whose architecture supports easy modulation of brain\nregions important for attention.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 20:17:07 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2019 13:42:25 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Stiso", "Jennifer", ""], ["Corsi", "Marie-Constance", ""], ["Vettel", "Jean M.", ""], ["Garcia", "Javier O.", ""], ["Pasqualetti", "Fabio", ""], ["Fallani", "Fabrizio De Vico", ""], ["Lucas", "Timothy H.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1908.00876", "submitter": "Henrik Skibbe", "authors": "Henrik Skibbe, Akiya Watakabe, Ken Nakae, Carlos Enrique Gutierrez,\n  Hiromichi Tsukada, Junichi Hata, Takashi Kawase, Rui Gong, Alexander\n  Woodward, Kenji Doya, Hideyuki Okano, Tetsuo Yamamori, Shin Ishii", "title": "MarmoNet: a pipeline for automated projection mapping of the common\n  marmoset brain from whole-brain serial two-photon tomography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the connectivity in the brain is an important prerequisite for\nunderstanding how the brain processes information. In the Brain/MINDS project,\na connectivity study on marmoset brains uses two-photon microscopy fluorescence\nimages of axonal projections to collect the neuron connectivity from defined\nbrain regions at the mesoscopic scale. The processing of the images requires\nthe detection and segmentation of the axonal tracer signal. The objective is to\ndetect as much tracer signal as possible while not misclassifying other\nbackground structures as the signal. This can be challenging because of imaging\nnoise, a cluttered image background, distortions or varying image contrast\ncause problems.\n  We are developing MarmoNet, a pipeline that processes and analyzes tracer\nimage data of the common marmoset brain. The pipeline incorporates\nstate-of-the-art machine learning techniques based on artificial convolutional\nneural networks (CNN) and image registration techniques to extract and map all\nrelevant information in a robust manner. The pipeline processes new images in a\nfully automated way.\n  This report introduces the current state of the tracer signal analysis part\nof the pipeline.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 14:20:27 GMT"}], "update_date": "2019-08-05", "authors_parsed": [["Skibbe", "Henrik", ""], ["Watakabe", "Akiya", ""], ["Nakae", "Ken", ""], ["Gutierrez", "Carlos Enrique", ""], ["Tsukada", "Hiromichi", ""], ["Hata", "Junichi", ""], ["Kawase", "Takashi", ""], ["Gong", "Rui", ""], ["Woodward", "Alexander", ""], ["Doya", "Kenji", ""], ["Okano", "Hideyuki", ""], ["Yamamori", "Tetsuo", ""], ["Ishii", "Shin", ""]]}, {"id": "1908.01548", "submitter": "Maria Masoliver", "authors": "Cristian Estarellas, Maria Masoliver, Cristina Masoller and Claudio\n  Mirasso", "title": "Characterizing signal encoding and transmission in class I and class II\n  neurons via ordinal time-series analysis", "comments": null, "journal-ref": null, "doi": "10.1063/1.5121257", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons encode and transmit information in spike sequences. However, despite\nthe effort devoted to quantify their information content, little progress has\nbeen made in this regard. Here we use a nonlinear method of time-series\nanalysis (known as ordinal analysis) to compare the statistics of spike\nsequences generated by applying an input signal to the neuronal model of\nMorris-Lecar. In particular we consider two different regimes for the neurons\nwhich lead to two classes of excitability: class I, where the frequency-current\ncurve is continuous and class II, where the frequency-current curve is\ndiscontinuous.\n  By applying ordinal analysis to sequences of inter-spike-intervals (ISIs) our\ngoals are (1) to investigate if different neuron types can generate spike\nsequences which have similar symbolic properties;\n  (2) to get deeper understanding on the effects that electrical (diffusive)\nand excitatory chemical (i.e., excitatory synapse) couplings have; and (3) to\ncompare, when a small--amplitude periodic signal is applied to one of the\nneurons, how the signal features (amplitude and frequency) are encoded and\ntransmitted in the generated ISI sequences for both class I and class II type\nneurons and electrical or chemical couplings. We find that depending on the\nfrequency, specific combinations of neuron/class and coupling-type allow a more\neffective encoding, or a more effective transmission of the signal.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 10:23:40 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Estarellas", "Cristian", ""], ["Masoliver", "Maria", ""], ["Masoller", "Cristina", ""], ["Mirasso", "Claudio", ""]]}, {"id": "1908.01555", "submitter": "Ricardo Pio Monti", "authors": "Ricardo Pio Monti, Alex Gibberd, Sandipan Roy, Matt Nunes, Romy\n  Lorenz, Robert Leech, Takeshi Ogawa, Motoaki Kawanabe, Aapo Hyvarinen", "title": "Interpretable brain age prediction using linear latent variable models\n  of functional connectivity", "comments": "21 pages, 11 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0232296", "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging-driven prediction of brain age, defined as the predicted\nbiological age of a subject using only brain imaging data, is an exciting\navenue of research. In this work we seek to build models of brain age based on\nfunctional connectivity while prioritizing model interpretability and\nunderstanding. This way, the models serve to both provide accurate estimates of\nbrain age as well as allow us to investigate changes in functional connectivity\nwhich occur during the ageing process. The methods proposed in this work\nconsist of a two-step procedure: first, linear latent variable models, such as\nPCA and its extensions, are employed to learn reproducible functional\nconnectivity networks present across a cohort of subjects. The activity within\neach network is subsequently employed as a feature in a linear regression model\nto predict brain age. The proposed framework is employed on the data from the\nCamCAN repository and the inferred brain age models are further demonstrated to\ngeneralize using data from two open-access repositories: the Human Connectome\nProject and the ATR Wide-Age-Range.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 10:42:47 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Monti", "Ricardo Pio", ""], ["Gibberd", "Alex", ""], ["Roy", "Sandipan", ""], ["Nunes", "Matt", ""], ["Lorenz", "Romy", ""], ["Leech", "Robert", ""], ["Ogawa", "Takeshi", ""], ["Kawanabe", "Motoaki", ""], ["Hyvarinen", "Aapo", ""]]}, {"id": "1908.01867", "submitter": "Cengiz Pehlevan", "authors": "Cengiz Pehlevan, Dmitri B. Chklovskii", "title": "Neuroscience-inspired online unsupervised learning algorithms", "comments": "Accepted for publication in IEEE Signal Processing Magazine", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the currently popular deep learning networks achieve unprecedented\nperformance on some tasks, the human brain still has a monopoly on general\nintelligence. Motivated by this and biological implausibility of deep learning\nnetworks, we developed a family of biologically plausible artificial neural\nnetworks (NNs) for unsupervised learning. Our approach is based on optimizing\nprincipled objective functions containing a term that matches the pairwise\nsimilarity of outputs to the similarity of inputs, hence the name -\nsimilarity-based. Gradient-based online optimization of such similarity-based\nobjective functions can be implemented by NNs with biologically plausible local\nlearning rules. Similarity-based cost functions and associated NNs solve\nunsupervised learning tasks such as linear dimensionality reduction, sparse\nand/or nonnegative feature extraction, blind nonnegative source separation,\nclustering and manifold learning.\n", "versions": [{"version": "v1", "created": "Mon, 5 Aug 2019 21:30:35 GMT"}, {"version": "v2", "created": "Fri, 6 Sep 2019 23:02:01 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Pehlevan", "Cengiz", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1908.02333", "submitter": "Sara Ranjbar", "authors": "Sara Ranjbar, Kyle W. Singleton, Lee Curtin, Susan Christine Massey,\n  Andrea Hawkins-Daarud, Pamela R. Jackson and Kristin R. Swanson", "title": "Sex differences in predicting fluid intelligence of adolescent brain\n  from T1-weighted MRIs", "comments": "8 pages plus references, 2 figures, 2 tables. Submission to the ABCD\n  Neurocognitive Prediction Challenge at MICCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluid intelligence (Gf) has been defined as the ability to reason and solve\npreviously unseen problems. Links to Gf have been found in magnetic resonance\nimaging (MRI) sequences such as functional MRI and diffusion tensor imaging. As\npart of the Adolescent Brain Cognitive Development Neurocognitive Prediction\nChallenge 2019, we sought to predict Gf in children aged 9-10 from T1-weighted\n(T1W) MRIs. The data included atlas-aligned volumetric T1W images,\natlas-defined segmented regions, age, and sex for 3739 subjects used for\ntraining and internal validation and 415 subjects used for external validation.\nWe trained sex-specific convolutional neural net (CNN) and random forest models\nto predict Gf. For the convolutional model, skull-stripped volumetric T1W\nimages aligned to the SRI24 brain atlas were used for training. Volumes of\nsegmented atlas regions along with each subject's age were used to train the\nrandom forest regressor models. Performance was measured using the mean squared\nerror (MSE) of the predictions. Random forest models achieved lower MSEs than\nCNNs. Further, the external validation data had a better MSE for females than\nmales (60.68 vs. 80.74), with a combined MSE of 70.83. Our results suggest that\npredictive models of Gf from volumetric T1W MRI features alone may perform\nbetter when trained separately on male and female data. However, the\nperformance of our models indicates that more information is necessary beyond\nthe available data to make accurate predictions of Gf.\n", "versions": [{"version": "v1", "created": "Tue, 6 Aug 2019 19:09:02 GMT"}], "update_date": "2019-08-08", "authors_parsed": [["Ranjbar", "Sara", ""], ["Singleton", "Kyle W.", ""], ["Curtin", "Lee", ""], ["Massey", "Susan Christine", ""], ["Hawkins-Daarud", "Andrea", ""], ["Jackson", "Pamela R.", ""], ["Swanson", "Kristin R.", ""]]}, {"id": "1908.02702", "submitter": "Andreas Herten", "authors": "Andreas Herten, Thorsten Hater, Wouter Klijn, Dirk Pleiter", "title": "Performance Comparison for Neuroscience Application Benchmarks", "comments": "Presented at ISC19 Conference Workshop IWOPH (International Workshop\n  on OpenPOWER for HPC)", "journal-ref": null, "doi": "10.1007/978-3-030-34356-9_31", "report-no": null, "categories": "cs.PF q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers within the Human Brain Project and related projects have in the\nlast couple of years expanded their needs for high-performance computing\ninfrastructures. The needs arise from a diverse set of science challenges that\nrange from large-scale simulations of brain models to processing of\nextreme-scale experimental data sets. The ICEI project, which is in the process\nof creating a distributed infrastructure optimised for brain research, started\nto build-up a set of benchmarks that reflect the diversity of applications in\nthis field. In this paper we analyse the performance of some selected\nbenchmarks on an IBM POWER8 and Intel Skylake based systems with and without\nGPUs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Aug 2019 16:19:15 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Herten", "Andreas", ""], ["Hater", "Thorsten", ""], ["Klijn", "Wouter", ""], ["Pleiter", "Dirk", ""]]}, {"id": "1908.03260", "submitter": "Vikram Ravindra", "authors": "Vikram Ravindra and Ananth Grama", "title": "De-anonymization Attacks on Neuroimaging Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR eess.IV q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advances in imaging technologies, combined with inexpensive storage, have led\nto an explosion in the volume of publicly available neuroimaging datasets.\nEffective analyses of these images hold the potential for uncovering mechanisms\nthat govern functioning of the human brain, and understanding various\nneurological diseases and disorders. The potential significance of these\nstudies notwithstanding, a growing concern relates to the protection of privacy\nand confidentiality of subjects who participate in these studies. In this\npaper, we present a de-anonymization attack rooted in the innate uniqueness of\nthe structure and function of the human brain. We show that the attack reveals\nnot only the identity of an individual, but also the task they are performing,\nand their efficacy in performing the tasks. Our attack relies on novel matrix\nanalyses techniques that are used to extract discriminating features in\nneuroimages. These features correspond to individual-specific signatures that\ncan be matched across datasets to yield highly accurate identification. We\npresent data preprocessing, signature extraction, and matching techniques that\nare computationally inexpensive, and can scale to large datasets. We discuss\nimplications of the attack and challenges associated with defending against\nsuch attacks.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 20:26:59 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Ravindra", "Vikram", ""], ["Grama", "Ananth", ""]]}, {"id": "1908.03264", "submitter": "Ruben Sanchez-Romero", "authors": "Ruben Sanchez-Romero, Joseph D. Ramsey, Kun Zhang, Clark Glymour", "title": "Identification of Effective Connectivity Subregions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard fMRI connectivity analyses depend on aggregating the time series of\nindividual voxels within regions of interest (ROIs). In certain cases, this\nspatial aggregation implies a loss of valuable functional and anatomical\ninformation about smaller subsets of voxels that drive the ROI level\nconnectivity. We use two recently published graphical search methods to\nidentify subsets of voxels that are highly responsible for the connectivity\nbetween larger ROIs. To illustrate the procedure, we apply both methods to\nlongitudinal high-resolution resting state fMRI data from regions in the medial\ntemporal lobe from a single individual. Both methods recovered similar subsets\nof voxels within larger ROIs of entorhinal cortex and hippocampus subfields\nthat also show spatial consistency across different scanning sessions and\nacross hemispheres. In contrast to standard functional connectivity methods,\nboth algorithms applied here are robust against false positive connections\nproduced by common causes and indirect paths (in contrast to Pearson's\ncorrelation) and common effect conditioning (in contrast to partial correlation\nbased approaches). These algorithms allow for identification of subregions of\nvoxels driving the connectivity between regions of interest, recovering\nvaluable anatomical and functional information that is lost when ROIs are\naggregated. Both methods are specially suited for voxelwise connectivity\nresearch, given their running times and scalability to big data problems.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 20:43:22 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Sanchez-Romero", "Ruben", ""], ["Ramsey", "Joseph D.", ""], ["Zhang", "Kun", ""], ["Glymour", "Clark", ""]]}, {"id": "1908.03336", "submitter": "Nicolas Blondeau", "authors": "Michel Tauc, Nicolas Melis (IBV), Miled Bourourou (IPMC), S\\'ebastien\n  Giraud (LPS), Thierry Hauet (IRTOMIT), Nicolas Blondeau (IPMC)", "title": "A new pharmacological preconditioning-based target: from drosophila to\n  kidney transplantation", "comments": "Conditioning Medicine, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the biggest challenges in medicine is to dampen the pathophysiological\nstress induced by an episode of ischemia. Such stress, due to various\npathological or clinical situations, follows a restriction in blood and oxygen\nsupply to tissue, causing a shortage of oxygen and nutrients that are required\nfor cellular metabolism. Ischemia can cause irreversible damage to target\ntissue leading to a poor physiological recovery outcome for the patient.\nContrariwise, preconditioning by brief periods of ischemia has been shown in\nmultiple organs to confer tolerance against subsequent normally lethal\nischemia. By definition, preconditioning of organs must be applied\npreemptively. This limits the applicability of preconditioning in clinical\nsituations, which arise unpredictably, such as myocardial infarction and\nstroke. There are, however, clinical situations that arise as a result of\nischemia-reperfusion injury, which can be anticipated, and are therefore\nadequate candidates for preconditioning. Organ and more particularly kidney\ntransplantation, the optimal treatment for suitable patients with end stage\nrenal disease (ESRD), is a predictable surgery that permits the use of\npreconditioning protocols to prepare the organ for subsequent\nischemic/reperfusion stress. It therefore seems crucial to develop appropriate\npreconditioning protocols against ischemia that will occur under\ntransplantation conditions, which up to now mainly referred to mechanical\nischemic preconditioning that triggers innate responses. It is not known if\npreconditioning has to be applied to the donor, the recipient, or both. No\ndrug/target pair has been envisioned and validated in the clinic. Options for\nidentifying new target/drug pairs involve the use of model animals, such as\ndrosophila, in which some physiological pathways, such as the management of\noxygen, are highly conserved across evolution. Oxygen is the universal element\nof life existence on earth. In this review we focus on a very specific pathway\nof pharmacological preconditioning identified in drosophila that was\nsuccessfully transferred to mammalian models that has potential application in\nhuman health. Very few mechanisms identified in these model animals have been\ntranslated to an upper evolutionary level. This review highlights the\ncommonality between oxygen regulation between diverse animals.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 07:00:08 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Tauc", "Michel", "", "IBV"], ["Melis", "Nicolas", "", "IBV"], ["Bourourou", "Miled", "", "IPMC"], ["Giraud", "S\u00e9bastien", "", "LPS"], ["Hauet", "Thierry", "", "IRTOMIT"], ["Blondeau", "Nicolas", "", "IPMC"]]}, {"id": "1908.03514", "submitter": "Teresa Karrer", "authors": "Teresa M. Karrer, Jason Z. Kim, Jennifer Stiso, Ari E. Kahn, Fabio\n  Pasqualetti, Ute Habel, Danielle S. Bassett", "title": "A practical guide to methodological considerations in the\n  controllability of structural brain networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting how the brain can be driven to specific states by means of\ninternal or external control requires a fundamental understanding of the\nrelationship between neural connectivity and activity. Network control theory\nis a powerful tool from the physical and engineering sciences that can provide\ninsights regarding that relationship; it formalizes the study of how the\ndynamics of a complex system can arise from its underlying structure of\ninterconnected units. Given the recent use of network control theory in\nneuroscience, it is now timely to offer a practical guide to methodological\nconsiderations in the controllability of structural brain networks. Here we\nprovide a systematic overview of the framework, examine the impact of modeling\nchoices on frequently studied control metrics, and suggest potentially useful\ntheoretical extensions. We ground our discussions, numerical demonstrations,\nand theoretical advances in a dataset of high-resolution diffusion imaging with\n730 diffusion directions acquired over approximately 1 hour of scanning from\nten healthy young adults. Following a didactic introduction of the theory, we\nprobe how a selection of modeling choices affects four common statistics:\naverage controllability, modal controllability, minimum control energy, and\noptimal control energy. Next, we extend the current state of the art in two\nways: first, by developing an alternative measure of structural connectivity\nthat accounts for radial propagation of activity through abutting tissue, and\nsecond, by defining a complementary metric quantifying the complexity of the\nenergy landscape of a system. We close with specific modeling recommendations\nand a discussion of methodological constraints.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 16:13:12 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Karrer", "Teresa M.", ""], ["Kim", "Jason Z.", ""], ["Stiso", "Jennifer", ""], ["Kahn", "Ari E.", ""], ["Pasqualetti", "Fabio", ""], ["Habel", "Ute", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1908.03532", "submitter": "Leendert Remmelzwaal", "authors": "Leendert A Remmelzwaal, George F R Ellis, Jonathan Tapson, Amit K\n  Mishra", "title": "Biologically-inspired Salience Affected Artificial Neural Network (SANN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we introduce a novel Salience Affected Artificial Neural\nNetwork (SANN) that models the way neuromodulators such as dopamine and\nnoradrenaline affect neural dynamics in the human brain by being distributed\ndiffusely through neocortical regions, allowing both salience signals to\nmodulate cognition immediately, and one time learning to take place through\nstrengthening entire patterns of activation at one go. We present a model that\nis capable of one-time salience tagging in a neural network trained to classify\nobjects, and returns a salience response during classification (inference). We\nexplore the effects of salience on learning via its effect on the activation\nfunctions of each node, as well as on the strength of weights between nodes in\nthe network. We demonstrate that salience tagging can improve classification\nconfidence for both the individual image as well as the class of images it\nbelongs to. We also show that the computation impact of producing a salience\nresponse is minimal. This research serves as a proof of concept, and could be\nthe first step towards introducing salience tagging into Deep Learning Networks\nand robotics.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 16:40:52 GMT"}, {"version": "v2", "created": "Mon, 12 Aug 2019 06:43:09 GMT"}, {"version": "v3", "created": "Fri, 23 Aug 2019 07:59:29 GMT"}, {"version": "v4", "created": "Fri, 7 Feb 2020 13:56:30 GMT"}, {"version": "v5", "created": "Mon, 30 Nov 2020 07:50:48 GMT"}], "update_date": "2020-12-01", "authors_parsed": [["Remmelzwaal", "Leendert A", ""], ["Ellis", "George F R", ""], ["Tapson", "Jonathan", ""], ["Mishra", "Amit K", ""]]}, {"id": "1908.03615", "submitter": "Rodrigo Laje", "authors": "Claudia R. Gonz\\'alez, M. Luz Bavassi, Rodrigo Laje", "title": "Response to perturbations as a built-in feature in a mathematical model\n  for paced finger tapping", "comments": null, "journal-ref": "Phys. Rev. E 100, 062412 (2019)", "doi": "10.1103/PhysRevE.100.062412", "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paced finger tapping is one of the simplest tasks to study sensorimotor\nsynchronization. The subject is instructed to tap in synchrony with a periodic\nsequence of brief tones, and the time difference (called asynchrony) between\neach response and the corresponding stimulus is recorded. Despite its\nsimplicity, this task helps to unveil interesting features of the underlying\nneural system and the error correction mechanism responsible for\nsynchronization. Perturbation experiments are usually performed to probe the\nsubject's response, for example in the form of a \"step change\", i.e. an\nunexpected change in tempo. The asynchrony is the usual observable in such\nexperiments and it is chosen as the main variable in many mathematical models\nthat attempt to describe the phenomenon. In this work we show that although\nasynchrony can be perfectly described in operational terms, it is not well\ndefined as a model variable when tempo perturbations are considered. We\nintroduce an alternative variable and a mathematical model that intrinsically\ntakes into account the perturbation, and make theoretical predictions about the\nresponse to novel perturbations based on the geometrical organization of the\ntrajectories in phase space. Our proposal is relevant to understand\ninterpersonal synchronization and the synchronization to non-periodic stimuli.\n", "versions": [{"version": "v1", "created": "Fri, 9 Aug 2019 20:06:18 GMT"}], "update_date": "2019-12-25", "authors_parsed": [["Gonz\u00e1lez", "Claudia R.", ""], ["Bavassi", "M. Luz", ""], ["Laje", "Rodrigo", ""]]}, {"id": "1908.03886", "submitter": "Hao Si", "authors": "Hao Si and Xiaojuan Sun", "title": "Population rate coding in recurrent neuronal networks with\n  undetermined-type neurons", "comments": "14 pages,10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural coding is a key problem in neuroscience, which can promote people's\nunderstanding of the mechanism that brain processes information. Among the\nclassical theories of neural coding, the population rate coding has been\nstudied widely in many works. Most computational studies considered the neurons\nand the corresponding presynaptic synapses as pre-determined excitatory or\ninhibitory types. According to physiological evidence, however, that the real\neffect of a synapse is inhibitory or excitatory is determined by the type of\nthe activated receptors. The co-release of excitatory and inhibitory receptors\nin the same synapse exists widely in the brain. In this paper, we study the\npopulation rate coding in recurrent neuronal networks with undetermined neurons\nand synapses, different from the traditional works, in which one neuron can\nperform either excitatory or inhibitory effect to the corresponding\npostsynaptic neurons. We find such neuronal networks can encode the stimuli\ninformation in population firing rate well. We find that intermediate recurrent\nprobability together with moderate Inhibitory-Excitatory strength ratio can\nenhance the encoding performance. Suitable combinations of the previous two\nparameters with the noise intensity, the excitatory synaptic strength and the\nsynaptic time constant have promoting effects on the performance of population\nrate coding. Finally, we compare the performance of population rate coding\nbetween the traditional (determined) model and ours, and we find that it is\nrational to consider the co-release of inhibitory and excitatory receptors.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 11:23:24 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Si", "Hao", ""], ["Sun", "Xiaojuan", ""]]}, {"id": "1908.04118", "submitter": "Nils Hampe", "authors": "Nils Hampe, Ulrich Katscher, Cornelis A. T. van den Berg, Khin Khin\n  Tha, Stefano Mandija", "title": "Deep learning brain conductivity mapping using a patch-based 3D U-net", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose: To investigate deep learning electrical properties tomography (EPT)\nfor application on different simulated and in-vivo datasets including\npathologies for obtaining quantitative brain conductivity maps. Methods: 3D\npatch-based convolutional neural networks were trained to predict conductivity\nmaps from B1 transceive phase data. To compare the performance of DLEPT\nnetworks on different datasets, three datasets were used throughout this work,\none from simulations and two from in-vivo measurements from healthy volunteers\nand cancer patients, respectively. At first, networks trained on simulations\nare tested on all datasets with different levels of homogeneous Gaussian noise\nintroduced in training and testing. Secondly, to investigate potential\nrobustness towards systematical differences between simulated and measured\nphase maps, in-vivo data with conductivity labels from conventional EPT is used\nfor training. Results: High quality of reconstructions from networks trained on\nsimulations with and without noise confirms the potential of deep learning for\nEPT. However, artifact encumbered results in this work uncover challenges in\napplication of DLEPT to in-vivo data. Training DLEPT networks on conductivity\nlabels from conventional EPT improves quality of results. This is argued to be\ncaused by robustness to artifacts from image acquisition. Conclusions: Networks\ntrained on simulations with added homogeneous Gaussian noise yield\nreconstruction artifacts when applied to in-vivo data. Training with realistic\nphase data and conductivity labels from conventional EPT allows for severely\nreducing these artifacts.\n", "versions": [{"version": "v1", "created": "Mon, 12 Aug 2019 12:38:02 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Hampe", "Nils", ""], ["Katscher", "Ulrich", ""], ["Berg", "Cornelis A. T. van den", ""], ["Tha", "Khin Khin", ""], ["Mandija", "Stefano", ""]]}, {"id": "1908.04290", "submitter": "Denis Le Bihan", "authors": "Denis Le Bihan", "title": "Is the brain relativistic?", "comments": null, "journal-ref": null, "doi": "10.1016/j.brain.2020.100016", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the very large body of knowledge which neuroimaging has put at\nour fingertips over the last three decades we looked at the brain with a fresh\nview which could unveil those 'old' things in new ways, in a framework which\ncould help us making predictions tailored made for a scrutiny with the\noutstanding imaging instruments to come, such as ultra high field MRI. By doing\nso, switching back and forth between physics and neurobiology, we came across\nthe view that time and space in the brain, as in the Universe, were, indeed,\ntightly mingled, and could fade away to be unified through a brain 'spacetime'.\nConsidering that there is a speed limit for action potentials flowing along\nmyelinated axons further thinking led us to envision that this 4-dimensional\nbrain spacetime would obey a kind of relativistic pseudo-diffusion principle\nand present a functional curvature governed by brain activity, in a similar way\ngravitational masses give our 4-dimensional Universe spacetime its curvature.\nWe then looked at how this whole-brain framework may shed light on brain\ndysfunction phenotypes (clinical expression of diseases) observed in some\nneuropsychiatric and consciousness disorders.\n", "versions": [{"version": "v1", "created": "Sat, 10 Aug 2019 07:24:43 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 08:22:47 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Bihan", "Denis Le", ""]]}, {"id": "1908.04696", "submitter": "Xaq Pitkow", "authors": "Saurabh Daptardar, Paul Schrater, Xaq Pitkow", "title": "Inverse Rational Control with Partially Observable Continuous Nonlinear\n  Dynamics", "comments": "8 pages plus references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Continuous control and planning remains a major challenge in robotics and\nmachine learning. Neuroscience offers the possibility of learning from animal\nbrains that implement highly successful controllers, but it is unclear how to\nrelate an animal's behavior to control principles. Animals may not always act\noptimally from the perspective of an external observer, but may still act\nrationally: we hypothesize that animals choose actions with highest expected\nfuture subjective value according to their own internal model of the world.\nTheir actions thus result from solving a different optimal control problem from\nthose on which they are evaluated in neuroscience experiments. With this\nassumption, we propose a novel framework of model-based inverse rational\ncontrol that learns the agent's internal model that best explains their actions\nin a task described as a partially observable Markov decision process (POMDP).\nIn this approach we first learn optimal policies generalized over the entire\nmodel space of dynamics and subjective rewards, using an extended Kalman filter\nto represent the belief space, a neural network in the actor-critic framework\nto optimize the policy, and a simplified basis for the parameter space. We then\ncompute the model that maximizes the likelihood of the experimentally\nobservable data comprising the agent's sensory observations and chosen actions.\nOur proposed method is able to recover the true model of simulated agents\nwithin theoretical error bounds given by limited data. We illustrate this\nmethod by applying it to a complex naturalistic task currently used in\nneuroscience experiments. This approach provides a foundation for interpreting\nthe behavioral and neural dynamics of highly adapted controllers in animal\nbrains.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 15:12:22 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Daptardar", "Saurabh", ""], ["Schrater", "Paul", ""], ["Pitkow", "Xaq", ""]]}, {"id": "1908.04758", "submitter": "Philippe Terrier PhD", "authors": "Philippe Terrier", "title": "Gait recognition via deep learning of the center-of-pressure trajectory", "comments": "A revised and augmented version of this preprint has been published\n  in the journal Applied Sciences in January 2020", "journal-ref": "Appl. Sci. 2020, 10, 774", "doi": "10.3390/app10030774", "report-no": null, "categories": "q-bio.QM cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The fact that every human has a distinctive walking style has prompted a\nproposal to use gait recognition as an identification criterion. Using\nend-to-end learning, I investigated whether the center-of-pressure trajectory\nis sufficiently unique to identify a person with a high certainty. Thirty-six\nadults walked on a treadmill equipped with a force platform that recorded the\npositions of the center of pressure. The raw two-dimensional signals were\nsliced into segments of two gait cycles. A set of 20,250 segments from 30\nsubjects was used to configure and train convolutional neural networks (CNNs).\nThe best CNN classified a separate set containing 2,250 segments with 99.9%\noverall accuracy. A second set of 4,500 segments from the six remaining\nsubjects was then used for transfer learning. Several small subsamples of this\nset were selected randomly and used for fine tuning. Training with two segments\nper subject was sufficient to achieve 100% accuracy. The results suggest that\nevery person produces a unique trajectory of underfoot pressures and that CNNs\ncan learn the distinctive features of these trajectories. Using transfer\nlearning, a few strides could be sufficient to learn and identify new gaits.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:49:57 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 13:47:44 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 13:06:26 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Terrier", "Philippe", ""]]}, {"id": "1908.04911", "submitter": "Nicolas Christianson", "authors": "Nicolas H. Christianson, Ann Sizemore Blevins, Danielle S. Bassett", "title": "Architecture and evolution of semantic networks in mathematics texts", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": "10.1098/rspa.2019.0741", "report-no": null, "categories": "cs.CL physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge is a network of interconnected concepts. Yet, precisely how the\ntopological structure of knowledge constrains its acquisition remains unknown,\nhampering the development of learning enhancement strategies. Here we study the\ntopological structure of semantic networks reflecting mathematical concepts and\ntheir relations in college-level linear algebra texts. We hypothesize that\nthese networks will exhibit structural order, reflecting the logical sequence\nof topics that ensures accessibility. We find that the networks exhibit strong\ncore-periphery architecture, where a dense core of concepts presented early is\ncomplemented with a sparse periphery presented evenly throughout the\nexposition; the latter is composed of many small modules each reflecting more\nnarrow domains. Using tools from applied topology, we find that the\nexpositional evolution of the semantic networks produces and subsequently fills\nknowledge gaps, and that the density of these gaps tracks negatively with\ncommunity ratings of each textbook. Broadly, our study lays the groundwork for\nfuture efforts developing optimal design principles for textbook exposition and\nteaching in a classroom setting.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 01:38:07 GMT"}, {"version": "v2", "created": "Tue, 24 Sep 2019 22:10:22 GMT"}], "update_date": "2021-03-17", "authors_parsed": [["Christianson", "Nicolas H.", ""], ["Blevins", "Ann Sizemore", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1908.05086", "submitter": "Peter Stiles", "authors": "P. J. Stiles and C. G. Gray", "title": "Improved Hodgkin & Huxley-type model for action potentials in squid", "comments": "29 pages, 7 figures This replacement version contains a new section\n  on periodic action potentials in low external calcium ion environments. It\n  also includes expanded discussions of temperature dependences and oscillator\n  behaviors of membrane potentials", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  By extending the crude Goldman-Hodgkin-Katz electrodiffusion model for\nresting-state membrane potentials in perfused giant axons of squid, we\nreformulate the Hodgkin-Huxley (HH) phenomenological quantitative model to\ncreate a new model which is simpler and based more fundamentally on\nelectrodiffusion principles. Our dynamical system, like that of HH, behaves as\na 4-dimensional resonator exhibiting subthreshold oscillations. The predicted\nspeed of propagating action potentials at 20 degrees Celsius is in good\nagreement with the HH experimental value at 18.5 degrees Celsius. After the\nexternal concentration of calcium ions is reduced, the generation of repetitive\nrebound action potentials is predicted by our model, in agreement with\nexperiment, when the membrane is stimulated by a brief (0.1 ms) depolarizing\ncurrent. Unlike the HH model, our model predicts, in agreement with experiment,\nthat prolonged constant-current stimulation does not generate spike trains in\nperfused axons. Our resonator model predicts rebound spiking following\nprolonged hyperpolarizing stimulation, observed at 18.5 degrees Celsius by HH\nbut not predicted at this temperature by their quantitative model. Spiking\npromoted by brief hyperpolarization is also predicted, at room temperature, by\nour electrodiffusion model, but only at much lower temperatures (ca. 6 degrees\nCelsius) by the HH model. We discuss qualitatively, more completely than do HH,\ntemperature dependences of the various physical effects which determine resting\nand action potentials.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 12:00:30 GMT"}, {"version": "v2", "created": "Wed, 5 Feb 2020 22:11:40 GMT"}], "update_date": "2020-02-07", "authors_parsed": [["Stiles", "P. J.", ""], ["Gray", "C. G.", ""]]}, {"id": "1908.05240", "submitter": "Cesar Salas Rommel", "authors": "Cesar R. Salas Guerra", "title": "Epistemological approach in immersive virtual environments and the\n  neurophysiology learning process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently virtual reality (VR) usage in training processes is increasing due\nto their usefulness in the learning processes based on visual information\nempowered. The information in virtual environments is perceived by sight, sound\nand touch, but the relationship or impact that these stimuli can have on the\noscillatory activity of the brain such as the processing, propagation and\nsynchronization of information still needs to be established in relation to the\ncognitive load of attention. Therefore, this study seeks to identify the\nsuggested epistemological basis through literature review and current research\nagendas in the relationship that exists between the immersive virtual\nenvironment and the neurophysiology of learning processes by means of the\nanalysis of visual information. The suggested dimensional modeling of this\nresearch is composed by the theory of information processing which allows the\nincorporation of learning through stimuli with the use of attention, perception\nand storage by means of information management and the Kolb's learning model\nwhich defines the perception and processing of information as dimensions of\nlearning. Regarding to the neurophysiology of learning, the literature has\nestablished he links between the prefrontal cortex and working memory within\nthe process of information management. The challenges and advances discussed in\nthis research are based in the relationship between the identified constructs\n(Income Stimuli, Information Management and Cognitive Processing) and the\nestablishment of a research agenda on how to identify the necessary indicators\nto measure memory and attention in the virtual immersion environments.\n", "versions": [{"version": "v1", "created": "Sun, 4 Aug 2019 05:41:11 GMT"}], "update_date": "2019-08-15", "authors_parsed": [["Guerra", "Cesar R. Salas", ""]]}, {"id": "1908.05298", "submitter": "Alex Bersellini Farinotti", "authors": "Alex Bersellini Farinotti, Gustaf Wigerblad, Diana Nascimento, Duygu B\n  Bas, Carlos Morado Urbina, Kutty Selva Nandakumar, Katalin Sandor, Bingze Xu,\n  Sally Abdelmoaty, Matthew A Hunt, Kristina \\\"Angeby M\\\"oller, Azar Baharpoor,\n  Jon Sinclair, Kent Jardemark, Johanna T Lanner, Ia Khmaladze, Lars E. Borm,\n  Lu Zhang, Fredrik Wermeling, Mark S Cragg, Johan Lengqvist, Anne-Julie\n  Chabot-Dor\\'e, Luda Diatchenko, Inna Belfer, Mattias Collin, Kim Kultima,\n  Birgitta Heyman, Juan M. Jimenez-Andrade, Simone Codeluppi, Rikard Holmdahl,\n  Camilla I Svensson", "title": "Cartilage-binding antibodies induce pain through immune complex-mediated\n  activation of neurons", "comments": null, "journal-ref": "Journal of Experimental Medicine Aug 2019, 216 (8) 1904-1924", "doi": "10.1084/jem.20181657", "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rheumatoid arthritis-associated joint pain is frequently observed independent\nof disease activity, suggesting unidentified pain mechanisms. We demonstrate\nthat antibodies binding to cartilage, specific for collagen type II (CII) or\ncartilage oligomeric matrix protein (COMP), elicit mechanical hypersensitivity\nin mice, uncoupled from visual, histological and molecular indications of\ninflammation. Cartilage antibody-induced pain-like behavior does not depend on\ncomplement activation or joint inflammation, but instead on tissue antigen\nrecognition and local immune complex (IC) formation. smFISH and IHC suggest\nthat neuronal Fcgr1 and Fcgr2b mRNA are transported to peripheral ends of\nprimary afferents. CII-ICs directly activate cultured WT but not FcR{\\gamma}\nchain-deficient DRG neurons. In line with this observation, CII-IC does not\ninduce mechanical hypersensitivity in FcR{\\gamma} chain-deficient mice.\nFurthermore, injection of CII antibodies does not generate pain-like behavior\nin FcR{\\gamma} chain-deficient mice or mice lacking activating Fc{\\gamma}Rs in\nneurons. In summary, this study defines functional coupling between\nautoantibodies and pain transmission that may facilitate the development of new\ndisease-relevant pain therapeutics.\n", "versions": [{"version": "v1", "created": "Thu, 8 Aug 2019 13:10:21 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Farinotti", "Alex Bersellini", ""], ["Wigerblad", "Gustaf", ""], ["Nascimento", "Diana", ""], ["Bas", "Duygu B", ""], ["Urbina", "Carlos Morado", ""], ["Nandakumar", "Kutty Selva", ""], ["Sandor", "Katalin", ""], ["Xu", "Bingze", ""], ["Abdelmoaty", "Sally", ""], ["Hunt", "Matthew A", ""], ["M\u00f6ller", "Kristina \u00c4ngeby", ""], ["Baharpoor", "Azar", ""], ["Sinclair", "Jon", ""], ["Jardemark", "Kent", ""], ["Lanner", "Johanna T", ""], ["Khmaladze", "Ia", ""], ["Borm", "Lars E.", ""], ["Zhang", "Lu", ""], ["Wermeling", "Fredrik", ""], ["Cragg", "Mark S", ""], ["Lengqvist", "Johan", ""], ["Chabot-Dor\u00e9", "Anne-Julie", ""], ["Diatchenko", "Luda", ""], ["Belfer", "Inna", ""], ["Collin", "Mattias", ""], ["Kultima", "Kim", ""], ["Heyman", "Birgitta", ""], ["Jimenez-Andrade", "Juan M.", ""], ["Codeluppi", "Simone", ""], ["Holmdahl", "Rikard", ""], ["Svensson", "Camilla I", ""]]}, {"id": "1908.05627", "submitter": "Lu Wang", "authors": "Lu Wang and Zhengwu Zhang", "title": "Learning Signal Subgraphs from Longitudinal Brain Networks with\n  Symmetric Bilinear Logistic Regression", "comments": "34 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern neuroimaging technologies, combined with state-of-the-art data\nprocessing pipelines, have made it possible to collect longitudinal\nobservations of an individual's brain connectome at different ages. It is of\nsubstantial scientific interest to study how brain connectivity varies over\ntime in relation to human cognitive traits. In brain connectomics, the\nstructural brain network for an individual corresponds to a set of\ninterconnections among brain regions. We propose a symmetric bilinear logistic\nregression to learn a set of small subgraphs relevant to a binary outcome from\nlongitudinal brain networks as well as estimating the time effects of the\nsubgraphs. We enforce the extracted signal subgraphs to have clique structure\nwhich has appealing interpretations as they can be related to neurological\ncircuits. The time effect of each signal subgraph reflects how its predictive\neffect on the outcome varies over time, which may improve our understanding of\ninteractions between the aging of brain structure and neurological disorders.\nApplication of this method on longitudinal brain connectomics and cognitive\ncapacity data shows interesting discovery of relevant interconnections among a\nsmall set of brain regions in frontal and temporal lobes with better predictive\nperformance than competitors.\n", "versions": [{"version": "v1", "created": "Thu, 15 Aug 2019 16:36:02 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Wang", "Lu", ""], ["Zhang", "Zhengwu", ""]]}, {"id": "1908.05736", "submitter": "Pascal Wallisch", "authors": "Pascal Wallisch and Michael Karlovich", "title": "Disagreeing about Crocs and socks: Creating profoundly ambiguous color\n  displays", "comments": "24 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is an increasing interest in the systematic disagreement about\nprofoundly ambiguous stimuli in the color domain. However, this research has\nbeen hobbled by the fact that we could not create such stimuli at will. Here,\nwe describe a design principle that allows the creation of such stimuli and\napply this principle to create one such stimulus set - the crocs and socks.\nUsing this set, we probed the color perception of a large sample of observers,\nshowing that these stimuli are indeed categorically ambiguous and that we can\npredict the percept from fabric priors resulting from experience. We also\nrelate the perception of these crocs to other color-ambiguous stimuli - the\ndress and the sneaker and conclude that differential priors likely underlie\npolarized disagreement in cognition more generally.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 08:42:22 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Wallisch", "Pascal", ""], ["Karlovich", "Michael", ""]]}, {"id": "1908.05956", "submitter": "Chulwook Park", "authors": "Chulwook Park", "title": "Evolutionary Understanding of the Conditions Leading to Estimation of\n  Behavioral Properties through System Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the basic frameworks in science views behavioral products as a process\nwithin a dynamic system. The mechanism might be seen as a representation of\nmany instances of centralized control in real time. Many real systems, however,\nexhibit autonomy by denying statically treated mechanisms. This study addresses\nthe issues related to the identification of dynamic systems and suggests how\ndetermining the basic principles of a collective structure may be key to\nunderstanding complex behavioral processes. A fundamental model is derived to\nassess the advantages of this perspective using a basic methodology. The\nconnection between perspective and technique demonstrates certain aspects\nwithin their actual context, while also clearly including the framework of\nactual dynamic system identification.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 12:58:16 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Park", "Chulwook", ""]]}, {"id": "1908.06180", "submitter": "Dongrui Wu", "authors": "Zhenhua Shi, Xiaomo Chen, Changming Zhao, He He, Veit Stuphorn and\n  Dongrui Wu", "title": "Multi-View Broad Learning System for Primate Oculomotor Decision\n  Decoding", "comments": null, "journal-ref": "IEEE Transactions on Neural Systems and Rehabilitation\n  Engineering, 2020", "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view learning improves the learning performance by utilizing multi-view\ndata: data collected from multiple sources, or feature sets extracted from the\nsame data source. This approach is suitable for primate brain state decoding\nusing cortical neural signals. This is because the complementary components of\nsimultaneously recorded neural signals, local field potentials (LFPs) and\naction potentials (spikes), can be treated as two views. In this paper, we\nextended broad learning system (BLS), a recently proposed wide neural network\narchitecture, from single-view learning to multi-view learning, and validated\nits performance in decoding monkeys' oculomotor decision from medial frontal\nLFPs and spikes. We demonstrated that medial frontal LFPs and spikes in\nnon-human primate do contain complementary information about the oculomotor\ndecision, and that the proposed multi-view BLS is a more effective approach for\ndecoding the oculomotor decision than several classical and state-of-the-art\nsingle-view and multi-view learning approaches.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 21:23:20 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2020 16:18:49 GMT"}, {"version": "v3", "created": "Thu, 2 Jul 2020 22:53:26 GMT"}], "update_date": "2020-07-06", "authors_parsed": [["Shi", "Zhenhua", ""], ["Chen", "Xiaomo", ""], ["Zhao", "Changming", ""], ["He", "He", ""], ["Stuphorn", "Veit", ""], ["Wu", "Dongrui", ""]]}, {"id": "1908.06197", "submitter": "Joaquin Goni", "authors": "Diana O. Svaldi, Joaqu\\'in Go\\~ni, Kausar Abbas, Enrico Amico, David\n  G. Clark, Charanya Muralidharan, Mario Dzemidzic, John D. West, Shannon L.\n  Risacher, Andrew J. Saykin, Liana G. Apostolova (for the Alzheimer's Disease\n  Neuroimaging Initiative)", "title": "Optimizing Differential Identifiability Improves Connectome Predictive\n  Modeling of Cognitive Deficits in Alzheimer's Disease", "comments": "26 pages; 7 Figures, 2 Tables, 8 Supplementary Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional connectivity, as estimated using resting state fMRI, has shown\npotential in bridging the gap between pathophysiology and cognition. However,\nclinical use of functional connectivity biomarkers is impeded by unreliable\nestimates of individual functional connectomes and lack of generalizability of\nmodels predicting cognitive outcomes from connectivity. To address these\nissues, we combine the frameworks of connectome predictive modeling and\ndifferential identifiability. Using the combined framework, we show that\nenhancing the individual fingerprint of resting state functional connectomes\nleads to robust identification of functional networks associated to cognitive\noutcomes and also improves prediction of cognitive outcomes from functional\nconnectomes. Using a comprehensive spectrum of cognitive outcomes associated to\nAlzheimer's disease, we identify and characterize functional networks\nassociated to specific cognitive deficits exhibited in Alzheimer's disease.\nThis combined framework is an important step in making individual level\npredictions of cognition from resting state functional connectomes and in\nunderstanding the relationship between cognition and connectivity.\n", "versions": [{"version": "v1", "created": "Fri, 16 Aug 2019 22:35:57 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2019 15:10:36 GMT"}, {"version": "v3", "created": "Fri, 13 Dec 2019 04:05:37 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Svaldi", "Diana O.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Go\u00f1i", "Joaqu\u00edn", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Abbas", "Kausar", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Amico", "Enrico", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Clark", "David G.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Muralidharan", "Charanya", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Dzemidzic", "Mario", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["West", "John D.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Risacher", "Shannon L.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Saykin", "Andrew J.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"], ["Apostolova", "Liana G.", "", "for the Alzheimer's Disease\n  Neuroimaging Initiative"]]}, {"id": "1908.06678", "submitter": "Erik Fagerholm", "authors": "Erik D. Fagerholm, W.M.C. Foulkes, Yasir Gallero-Salas, Fritjof\n  Helmchen, Karl J. Friston, Robert Leech, Rosalyn J. Moran", "title": "Network constraints in scale free dynamical systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scale free dynamics are observed in a variety of physical and biological\nsystems. These include neural activity in which evidence for scale freeness has\nbeen reported using a range of imaging modalities. Here, we derive the ways in\nwhich connections within a network must transform - relative to system size -\nin order to maintain scale freeness and test these theoretical transformations\nvia simulations. First, we explore the known invariance of planetary motion for\norbits varying in size. Using parametric empirical Bayesian modelling and a\ngeneric dynamical systems model, we show that we recover Kepler's third law\nfrom orbital timeseries, using our proposed transformations; thereby providing\nconstruct validation. We then demonstrate that the dynamical critical exponent\nis inversely proportional to the time rescaling exponent, in the context of\ncoarse graining operations. Using murine calcium imaging data, we then show\nthat the dynamical critical exponent can be estimated in an empirical\nbiological setting. Specifically, we compare dynamical critical exponents -\nassociated with spontaneous and task states in two regions of imaged cortex -\nthat are classified as task-relevant and task-irrelevant. We find, consistently\nacross animals, that the task-irrelevant region exhibits higher dynamical\ncritical exponents during spontaneous activity than during task performance.\nConversely, the task-relevant region is associated with higher dynamical\ncritical exponents in task vs. spontaneous states. These data support the idea\nthat higher dynamical critical exponents, within relevant cortical structures,\nunderwrite neuronal processing due to the implicit increase in cross-scale\ninformation transmission.\n", "versions": [{"version": "v1", "created": "Mon, 19 Aug 2019 10:09:54 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Fagerholm", "Erik D.", ""], ["Foulkes", "W. M. C.", ""], ["Gallero-Salas", "Yasir", ""], ["Helmchen", "Fritjof", ""], ["Friston", "Karl J.", ""], ["Leech", "Robert", ""], ["Moran", "Rosalyn J.", ""]]}, {"id": "1908.07039", "submitter": "Henry Mitchell", "authors": "Henry M. Mitchell, Peter Sheridan Dodds, J. Matthew Mahoney,\n  Christopher M. Danforth", "title": "Chimera States and Seizures in a Mouse Neuronal Model", "comments": "16 pages, 17 figures", "journal-ref": null, "doi": "10.1142/S0218127420502569", "report-no": null, "categories": "q-bio.NC nlin.PS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Chimera states---the coexistence of synchrony and asynchrony in a\nnonlocally-coupled network of identical oscillators---are often used as a model\nframework for epileptic seizures. Here, we explore the dynamics of chimera\nstates in a network of modified Hindmarsh-Rose neurons, configured to reflect\nthe graph of the mesoscale mouse connectome. Our model produces superficially\nepileptiform activity converging on persistent chimera states in a large region\nof a two-parameter space governing connections (a) between subcortices within a\ncortex and (b) between cortices. Our findings contribute to a growing body of\nliterature suggesting mathematical models can qualitatively reproduce epileptic\nseizure dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 2 Aug 2019 18:00:02 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2020 15:34:40 GMT"}], "update_date": "2020-12-02", "authors_parsed": [["Mitchell", "Henry M.", ""], ["Dodds", "Peter Sheridan", ""], ["Mahoney", "J. Matthew", ""], ["Danforth", "Christopher M.", ""]]}, {"id": "1908.07428", "submitter": "Gautam Kumar", "authors": "Benjamin Plaster and Gautam Kumar", "title": "Data-Driven Predictive Modeling of Neuronal Dynamics using Long\n  Short-Term Memory", "comments": "35 pages, 26 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling brain dynamics to better understand and control complex behaviors\nunderlying various cognitive brain functions are of interests to engineers,\nmathematicians, and physicists from the last several decades. With a motivation\nof developing computationally efficient models of brain dynamics to use in\ndesigning control-theoretic neurostimulation strategies, we have developed a\nnovel data-driven approach in a long short-term memory (LSTM) neural network\narchitecture to predict the temporal dynamics of complex systems over an\nextended long time-horizon in future. In contrast to recent LSTM-based\ndynamical modeling approaches that make use of multi-layer perceptrons or\nlinear combination layers as output layers, our architecture uses a single\nfully connected output layer and reversed-order sequence-to-sequence mapping to\nimprove short time-horizon prediction accuracy and to make multi-timestep\npredictions of dynamical behaviors. We demonstrate the efficacy of our approach\nin reconstructing the regular spiking to bursting dynamics exhibited by an\nexperimentally-validated 9-dimensional Hodgkin-Huxley model of hippocampal CA1\npyramidal neurons. Through simulations, we show that our LSTM neural network\ncan predict the multi-time scale temporal dynamics underlying various spiking\npatterns with reasonable accuracy. Moreover, our results show that the\npredictions improve with increasing predictive time-horizon in the\nmulti-timestep deep LSTM neural network.\n", "versions": [{"version": "v1", "created": "Sun, 11 Aug 2019 17:36:46 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Plaster", "Benjamin", ""], ["Kumar", "Gautam", ""]]}, {"id": "1908.07446", "submitter": "Alex Gomez-Marin", "authors": "Regina Zaghi-Lara, Miguel \\'Angel Gea, Jordi Cam\\'i, Luis M.\n  Mart\\'inez, Alex Gomez-Marin", "title": "Playing magic tricks to deep neural networks untangles human deception", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Magic is the art of producing in the spectator an illusion of impossibility.\nAlthough the scientific study of magic is in its infancy, the advent of recent\ntracking algorithms based on deep learning allow now to quantify the skills of\nthe magician in naturalistic conditions at unprecedented resolution and\nrobustness. In this study, we deconstructed stage magic into purely motor\nmaneuvers and trained an artificial neural network (DeepLabCut) to follow coins\nas a professional magician made them appear and disappear in a series of\ntricks. Rather than using AI as a mere tracking tool, we conceived it as an\n\"artificial spectator\". When the coins were not visible, the algorithm was\ntrained to infer their location as a human spectator would (i.e. in the left\nfist). This created situations where the human was fooled while AI (as seen by\na human) was not, and vice versa. Magic from the perspective of the machine\nreveals our own cognitive biases.\n", "versions": [{"version": "v1", "created": "Tue, 20 Aug 2019 15:50:11 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Zaghi-Lara", "Regina", ""], ["Gea", "Miguel \u00c1ngel", ""], ["Cam\u00ed", "Jordi", ""], ["Mart\u00ednez", "Luis M.", ""], ["Gomez-Marin", "Alex", ""]]}, {"id": "1908.07935", "submitter": "Catarina Moreira", "authors": "Lauren Fell and Shahram Dehdashti and Peter Bruza and Catarina Moreira", "title": "An Experimental Protocol to Derive and Validate a Quantum Model of\n  Decision-Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study utilises an experiment famous in quantum physics, the\nStern-Gerlach experiment, to inform the structure of an experimental protocol\nfrom which a quantum cognitive decision model can be developed. The\n'quantumness' of this model is tested by computing a discrete\nquasi-probabilistic Wigner function. Based on theory from quantum physics, our\nhypothesis is that the Stern-Gerlach protocol will admit negative values in the\nWigner function, thus signalling that the cognitive decision model is quantum.\nA crowdsourced experiment of two images was used to collect decisions around\nthree questions related to image trustworthiness. The resultant data was used\nto instantiate the quantum model and compute the Wigner function. Negative\nvalues in the Wigner functions of both images were encountered, thus\nsubstantiating our hypothesis. Findings also revealed that the quantum\ncognitive model was a more accurate predictor of decisions when compared to\npredictions computed using Bayes' rule.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 10:21:54 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Fell", "Lauren", ""], ["Dehdashti", "Shahram", ""], ["Bruza", "Peter", ""], ["Moreira", "Catarina", ""]]}, {"id": "1908.07957", "submitter": "Elke Kirschbaum", "authors": "Elke Kirschbaum, Alberto Bailoni, Fred A. Hamprecht", "title": "DISCo: Deep learning, Instance Segmentation, and Correlations for cell\n  segmentation in calcium imaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calcium imaging is one of the most important tools in neurophysiology as it\nenables the observation of neuronal activity for hundreds of cells in parallel\nand at single-cell resolution. In order to use the data gained with calcium\nimaging, it is necessary to extract individual cells and their activity from\nthe recordings. We present DISCo, a novel approach for the cell segmentation in\ncalcium imaging videos. We use temporal information from the recordings in a\ncomputationally efficient way by computing correlations between pixels and\ncombine it with shape-based information to identify active as well as\nnon-active cells. We first learn to predict whether two pixels belong to the\nsame cell; this information is summarized in an undirected, edge-weighted grid\ngraph which we then partition. In so doing, we approximately solve the NP-hard\ncorrelation clustering problem with a recently proposed greedy algorithm.\nEvaluating our method on the Neurofinder public benchmark shows that DISCo\noutperforms all existing models trained on these datasets.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 16:04:10 GMT"}, {"version": "v2", "created": "Thu, 22 Aug 2019 05:57:30 GMT"}, {"version": "v3", "created": "Fri, 10 Jan 2020 19:02:13 GMT"}, {"version": "v4", "created": "Sat, 4 Apr 2020 11:52:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Kirschbaum", "Elke", ""], ["Bailoni", "Alberto", ""], ["Hamprecht", "Fred A.", ""]]}, {"id": "1908.08024", "submitter": "Anup Das", "authors": "Anup Das and Yuefeng Wu and Khanh Huynh and Francesco Dell'Anna and\n  Francky Catthoor and Siebren Schaafsma", "title": "Mapping of Local and Global Synapses on Spiking Neuromorphic Hardware", "comments": "17 pages, 7 figures, published in 2018 Design, Automation & Test in\n  Europe Conference & Exhibition (DATE)", "journal-ref": null, "doi": "10.23919/DATE.2018.8342201", "report-no": null, "categories": "q-bio.NC cs.ET cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking Neural Networks (SNNs) are widely deployed to solve complex pattern\nrecognition, function approximation and image classification tasks. With the\ngrowing size and complexity of these networks, hardware implementation becomes\nchallenging because scaling up the size of a single array (crossbar) of fully\nconnected neurons is no longer feasible due to strict energy budget. Modern\nneromorphic hardware integrates small-sized crossbars with time-multiplexed\ninterconnects. Partitioning SNNs becomes essential in order to map them on\nneuromorphic hardware with the major aim to reduce the global communication\nlatency and energy overhead. To achieve this goal, we propose our instantiation\nof particle swarm optimization, which partitions SNNs into local synapses\n(mapped on crossbars) and global synapses (mapped on time-multiplexed\ninterconnects), with the objective of reducing spike communication on the\ninterconnect. This improves latency, power consumption as well as application\nperformance by reducing inter-spike interval distortion and spike disorders.\nOur framework is implemented in Python, interfacing CARLsim, a GPU-accelerated\napplication-level spiking neural network simulator with an extended version of\nNoxim, for simulating time-multiplexed interconnects. Experiments are conducted\nwith realistic and synthetic SNN-based applications with different computation\nmodels, topologies and spike coding schemes. Using power numbers from in-house\nneuromorphic chips, we demonstrate significant reductions in energy consumption\nand spike latency over PACMAN, the widely-used partitioning technique for SNNs\non SpiNNaker.\n", "versions": [{"version": "v1", "created": "Tue, 13 Aug 2019 23:28:35 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Das", "Anup", ""], ["Wu", "Yuefeng", ""], ["Huynh", "Khanh", ""], ["Dell'Anna", "Francesco", ""], ["Catthoor", "Francky", ""], ["Schaafsma", "Siebren", ""]]}, {"id": "1908.08095", "submitter": "Yuting Ye", "authors": "Yuting Ye, Yin Xia, Lexin Li", "title": "Paired Test of Matrix Graphs and Brain Connectivity Analysis", "comments": "30 pages, 1 figure, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring brain connectivity network and quantifying the significance of\ninteractions between brain regions are of paramount importance in neuroscience.\nAlthough there have recently emerged some tests for graph inference based on\nindependent samples, there is no readily available solution to test the change\nof brain network for paired and correlated samples. In this article, we develop\na paired test of matrix graphs to infer brain connectivity network when the\ngroups of samples are correlated. The proposed test statistic is both bias\ncorrected and variance corrected, and achieves a small estimation error rate.\nThe subsequent multiple testing procedure built on this test statistic is\nguaranteed to asymptotically control the false discovery rate at the\npre-specified level. Both the methodology and theory of the new test are\nconsiderably different from the two independent samples framework, owing to the\nstrong correlations of measurements on the same subjects before and after the\nstimulus activity. We illustrate the efficacy of our proposal through\nsimulations and an analysis of an Alzheimer's Disease Neuroimaing Initiative\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 21 Aug 2019 19:37:10 GMT"}], "update_date": "2019-08-23", "authors_parsed": [["Ye", "Yuting", ""], ["Xia", "Yin", ""], ["Li", "Lexin", ""]]}, {"id": "1908.08642", "submitter": "Artemy Kolchinsky", "authors": "Artemy Kolchinsky", "title": "A novel approach to multivariate redundancy and synergy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a situation in which a set of $n$ \"source\" random variables\n$X_{1},\\dots,X_{n}$ have information about some \"target\" random variable $Y$.\nFor example, in neuroscience $Y$ might represent the state of an external\nstimulus and $X_{1},\\dots,X_{n}$ the activity of $n$ different brain regions.\nRecent work in information theory has considered how to decompose the\ninformation that the sources $X_{1},\\dots,X_{n}$ provide about the target $Y$\ninto separate terms such as (1) the \"redundant information\" that is shared\namong all of sources, (2) the \"unique information\" that is provided only by a\nsingle source, (3) the \"synergistic information\" that is provided by all\nsources only when considered jointly, and (4) the \"union information\" that is\nprovided by at least one source. We propose a novel framework deriving such a\ndecomposition that can be applied to any number of sources. Our measures are\nmotivated in three distinct ways: via a formal analogy to intersection and\nunion operators in set theory, via a decision-theoretic operationalization\nbased on Blackwell's theorem, and via an axiomatic derivation. A key aspect of\nour approach is that we relax the assumption that measures of redundancy and\nunion information should be related by the inclusion-exclusion principle. We\ndiscuss relations to previous proposals as well as possible generalizations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 02:33:27 GMT"}, {"version": "v2", "created": "Sat, 7 Dec 2019 01:37:06 GMT"}, {"version": "v3", "created": "Thu, 6 Feb 2020 20:25:58 GMT"}], "update_date": "2020-02-10", "authors_parsed": [["Kolchinsky", "Artemy", ""]]}, {"id": "1908.08655", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia", "title": "Spiking Neural Predictive Coding for Continual Learning from Data\n  Streams", "comments": "Revised version of manuscript -- includes updated experimental\n  results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For energy-efficient computation in specialized neuromorphic hardware, we\npresent the Spiking Neural Coding Network, an instantiation of a family of\nartificial neural models strongly motivated by the theory of predictive coding.\nThe model, in essence, works by operating in a never-ending process of\n\"guess-and-check\", where neurons predict the activity values of one another and\nthen immediately adjust their own activities to make better future predictions.\nThe interactive, iterative nature of our neural system fits well into the\ncontinuous time formulation of data sensory stream prediction and, as we show,\nthe model's structure yields a simple, local synaptic update rule, which could\nbe used to complement or replace online spike-timing dependent plasticity. In\nthis article, we experiment with an instantiation of our model that consists of\nleaky integrate-and-fire units. However, the general framework within which our\nmodel is situated can naturally incorporate more complex, formal neurons such\nas the Hodgkin-Huxley model. Our experimental results in pattern recognition\ndemonstrate the potential of the proposed model when binary spike trains are\nthe primary paradigm for inter-neuron communication. Notably, our model is\ncompetitive in terms of classification performance, can conduct online\nsemi-supervised learning, naturally experiences less forgetting when learning\nfrom a sequence of tasks, and is more computationally economical and\nbiologically-plausible than popular artificial neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 03:44:27 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2020 20:30:45 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Ororbia", "Alexander", ""]]}, {"id": "1908.08807", "submitter": "Badong Chen", "authors": "Hao Wu, Ziyu Zhu, Jiayi Wang, Nanning Zheng, Badong Chen", "title": "An encoding framework with brain inner state for natural image\n  identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural encoding and decoding, which aim to characterize the relationship\nbetween stimuli and brain activities, have emerged as an important area in\ncognitive neuroscience. Traditional encoding models, which focus on feature\nextraction and mapping, consider the brain as an input-output mapper without\ninner states. In this work, inspired by the fact that human brain acts like a\nstate machine, we proposed a novel encoding framework that combines information\nfrom both the external world and the inner state to predict brain activity. The\nframework comprises two parts: forward encoding model that deals with visual\nstimuli and inner state model that captures influence from intrinsic\nconnections in the brain. The forward model can be any traditional encoding\nmodel, making the framework flexible. The inner state model is a linear model\nto utilize information in the prediction residuals of the forward model. The\nproposed encoding framework can achieve much better performance on natural\nimage identification from fMRI response than forwardonly models. The\nidentification accuracy will decrease slightly with the dataset size\nincreasing, but remain relatively stable with different identification methods.\nThe results confirm that the new encoding framework is effective and robust\nwhen used for brain decoding.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 13:41:49 GMT"}], "update_date": "2019-08-26", "authors_parsed": [["Wu", "Hao", ""], ["Zhu", "Ziyu", ""], ["Wang", "Jiayi", ""], ["Zheng", "Nanning", ""], ["Chen", "Badong", ""]]}, {"id": "1908.08973", "submitter": "Klaus Lehnertz", "authors": "Theresa Wilkat and Thorsten Rings and Klaus Lehnertz", "title": "No evidence for critical slowing down prior to human epileptic seizures", "comments": "6 pages, 3 figures", "journal-ref": "Chaos 29, 033115, 2019", "doi": "10.1063/1.5122759", "report-no": null, "categories": "physics.med-ph physics.bio-ph q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is a ongoing debate whether generic early warning signals for critical\ntransitions exist that can be applied across diverse systems. The human\nepileptic brain is often considered as a prototypical system, given the\ndevastating and, at times, even life-threatening nature of the extreme event\nepileptic seizure. More than three decades of international effort has\nsuccessfully identified predictors of imminent seizures. However, the\nsuitability of typically applied early warning indicators for critical slowing\ndown, namely variance and lag-1 autocorrelation, for indexing seizure\nsusceptibility is still controversially discussed. Here, we investigated\nlong-term, multichannel recordings of brain dynamics from 28 subjects with\nepilepsy. Using a surrogate-based evaluation procedure of sensitivity and\nspecificity of time-resolved estimates of early warning indicators, we found no\nevidence for critical slowing down prior to 105 epileptic seizures.\n", "versions": [{"version": "v1", "created": "Fri, 23 Aug 2019 18:37:03 GMT"}], "update_date": "2019-10-23", "authors_parsed": [["Wilkat", "Theresa", ""], ["Rings", "Thorsten", ""], ["Lehnertz", "Klaus", ""]]}, {"id": "1908.08993", "submitter": "Dmitry Krotov", "authors": "Leopold Grinberg, John Hopfield, Dmitry Krotov", "title": "Local Unsupervised Learning for Image Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local Hebbian learning is believed to be inferior in performance to\nend-to-end training using a backpropagation algorithm. We question this popular\nbelief by designing a local algorithm that can learn convolutional filters at\nscale on large image datasets. These filters combined with patch normalization\nand very steep non-linearities result in a good classification accuracy for\nshallow networks trained locally, as opposed to end-to-end. The filters learned\nby our algorithm contain both orientation selective units and unoriented color\nunits, resembling the responses of pyramidal neurons located in the cytochrome\noxidase 'interblob' and 'blob' regions in the primary visual cortex of\nprimates. It is shown that convolutional networks with patch normalization\nsignificantly outperform standard convolutional networks on the task of\nrecovering the original classes when shadows are superimposed on top of\nstandard CIFAR-10 images. Patch normalization approximates the retinal\nadaptation to the mean light intensity, important for human vision. We also\ndemonstrate a successful transfer of learned representations between CIFAR-10\nand ImageNet 32x32 datasets. All these results taken together hint at the\npossibility that local unsupervised training might be a powerful tool for\nlearning general representations (without specifying the task) directly from\nunlabeled data.\n", "versions": [{"version": "v1", "created": "Wed, 14 Aug 2019 17:42:11 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Grinberg", "Leopold", ""], ["Hopfield", "John", ""], ["Krotov", "Dmitry", ""]]}, {"id": "1908.09116", "submitter": "Markus D Schirmer", "authors": "Ai Wern Chung and Markus D. Schirmer", "title": "Network Dependency Index Stratified Subnetwork Analysis of Functional\n  Connectomes: An application to autism", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-32391-2_13", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism spectrum disorder (ASD) is a neurodevelopmental condition impacting\nhigh-level cognitive processing and social behavior. Recognizing the\ndistributed nature of brain function, neuroscientists are exploiting the\nconnectome to aid with the characterization of this complex disease. The human\nconnectome has demonstrated the brain to be a highly organized system with a\ncentralized core vital for effective function. As such, many have used this\ntopological principle to not only assess core regions, but have stratified the\nremaining graph into subnetworks depending on their relation to the core.\nSubnetworks are then utilized to further understand the supporting role of more\nperipheral nodes with respects to the overall function in the network. A\nrecently proposed framework for subnetwork definition is based on the network\ndependency index (NDI), a measure of a node's importance based on its\ncontribution to overall efficiency in the network, and the derived subnetworks,\nor Tiers, have been shown to be largely stable across ages in structural\nnetworks. Here, we extend the NDI framework to test its efficacy against a\nnumber experimental conditions. We first not only demonstrated NDI's\nfeasibility on resting-state functional MRI data, but also its stability\nirrespective of the group connectome on which NDI was determined for various\nedge thresholds. Secondly, by comparing network theory measures of transitivity\nand efficiency, significant group differences were identified in NDI Tiers of\ngreatest importance. This demonstrates the efficacy of utilizing NDI stratified\nsubnetworks, which can help to improve our understanding of diseases and how\nthey affect overall brain connectivity.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 09:44:39 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 09:06:06 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Chung", "Ai Wern", ""], ["Schirmer", "Markus D.", ""]]}, {"id": "1908.09117", "submitter": "Markus D Schirmer", "authors": "Markus D. Schirmer and Ai Wern Chung", "title": "Heat kernels with functional connectomes reveal atypical energy\n  transport in peripheral subnetworks in autism", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-32391-2_6", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism is increasing in prevalence and is a neurodevelopmental disorder\ncharacterised by impairments in communication skills and social behaviour.\nConnectomes enable a systems-level representation of the brain with recent\ninterests in understanding the distributed nature of higher order cognitive\nfunction using modules or subnetworks. By dividing the connectome according to\na central component of the brain critical for its function (it's hub), we\ninvestigate network organisation in autism from hub through to peripheral\nsubnetworks. We complement this analysis by extracting features of energy\ntransport computed from heat kernels fitted with increasing time steps. This\nheat kernel framework is advantageous as it can capture the energy transported\nin all direct and indirect pathways between pair-wise regions over 'time', with\nfeatures that have correspondence to small-world properties. We apply our\nframework to resting-state functional MRI connectomes from a large, publically\navailable autism dataset, ABIDE. We show that energy propagating through the\nbrain over time are different between subnetworks, and that heat kernel\nfeatures significantly differ between autism and controls. Furthermore, the hub\nwas functionally preserved and similar to controls, however, increasing\nstatistical significance between groups was found in increasingly peripheral\nsubnetworks. Our results support the increasing opinion of non-hub regions\nplaying an important role in functional organisation. This work shows that\nanalysing autism by subnetworks with the heat kernel reflects the atypical\nactivations in peripheral regions as alterations in energy dispersion and may\nprovide useful features towards understanding the distributed impact of this\ndisorder on the functional connectome.\n", "versions": [{"version": "v1", "created": "Sat, 24 Aug 2019 09:48:36 GMT"}, {"version": "v2", "created": "Wed, 25 Sep 2019 09:08:25 GMT"}], "update_date": "2019-09-26", "authors_parsed": [["Schirmer", "Markus D.", ""], ["Chung", "Ai Wern", ""]]}, {"id": "1908.09314", "submitter": "Mamoru Sugamoto", "authors": "Naoaki Fujimoto, Muneharu Onoue, Akio Sugamoto, Mamoru Sugamoto, and\n  Tsukasa Yumibayashi", "title": "Surround Inhibition Mechanism by Deep Learning", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": "OUJ-FTC-3, OCHA-PP-356", "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the sensation of tones, visions and other stimuli, the \"surround\ninhibition mechanism\" (or \"lateral inhibition mechanism\") is crucial. The\nmechanism enhances the signals of the strongest tone, color and other stimuli,\nby reducing and inhibiting the surrounding signals, since the latter signals\nare less important. This surround inhibition mechanism is well studied in the\nphysiology of sensor systems. The neural network with two hidden layers in\naddition to input and output layers is constructed; having 60 neurons (units)\nin each of the four layers. The label (correct answer) is prepared from an\ninput signal by applying seven times operations of the \"Hartline mechanism\",\nthat is, by sending inhibitory signals from the neighboring neurons and\namplifying all the signals afterwards. The implication obtained by the deep\nlearning of this neural network is compared with the standard physiological\nunderstanding of the surround inhibition mechanism.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 12:41:56 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Fujimoto", "Naoaki", ""], ["Onoue", "Muneharu", ""], ["Sugamoto", "Akio", ""], ["Sugamoto", "Mamoru", ""], ["Yumibayashi", "Tsukasa", ""]]}, {"id": "1908.09593", "submitter": "Anjali Tarun", "authors": "Anjali Tarun, Hamid Behjat, David Abramian, Dimitri Van De Ville", "title": "Structural mediation of human brain activity revealed by white-matter\n  interpolation of fMRI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anatomy of the human brain constrains the formation of large-scale functional\nnetworks. Here, given measured brain activity in gray matter, we interpolate\nthese functional signals into the white matter on a structurally-informed\nhigh-resolution voxel-level brain grid. The interpolated volumes reflect the\nunderlying anatomical information, revealing white matter structures that\nmediate functional signal flow between temporally coherent gray matter regions.\nFunctional connectivity analyses of the interpolated volumes reveal an enriched\npicture of the default mode network (DMN) and its subcomponents, including how\nwhite matter bundles support their formation, thus transcending currently known\nspatial patterns that are limited within the gray matter only. These\nsubcomponents have distinct structure-function patterns, each of which are\ndifferentially recruited during tasks, demonstrating plausible structural\nmechanisms for functional switching between task-positive and -negative\ncomponents. This work opens new avenues for integration of brain structure and\nfunction and demonstrates how global patterns of activity arise from a\ncollective interplay of signal propagation along different white matter\npathways.\n", "versions": [{"version": "v1", "created": "Mon, 26 Aug 2019 11:05:24 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Tarun", "Anjali", ""], ["Behjat", "Hamid", ""], ["Abramian", "David", ""], ["Van De Ville", "Dimitri", ""]]}, {"id": "1908.10101", "submitter": "Kenneth Miller", "authors": "Yashar Ahmadian and Kenneth D. Miller", "title": "What is the dynamical regime of cerebral cortex?", "comments": "21 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies have shown that the excitation and inhibition received by\ncortical neurons remain roughly balanced across many conditions. A key question\nfor understanding the dynamical regime of cortex is the nature of this\nbalancing. Theorists have shown that network dynamics can yield systematic\ncancellation of most of a neuron's excitatory input by inhibition. We review a\nwide range of evidence pointing to this cancellation occurring in a regime in\nwhich the balance is loose, meaning that the net input remaining after\ncancellation of excitation and inhibition is comparable in size to the factors\nthat cancel, rather than tight, meaning that the net input is very small\nrelative to the cancelling factors. This choice of regime has important\nimplications for cortical functional responses, as we describe: loose balance,\nbut not tight balance, can yield many nonlinear population behaviors seen in\nsensory cortical neurons, allow the presence of correlated variability, and\nyield decrease of that variability with increasing external stimulus drive as\nobserved across multiple cortical areas.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 09:29:45 GMT"}, {"version": "v2", "created": "Wed, 28 Aug 2019 09:44:21 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Ahmadian", "Yashar", ""], ["Miller", "Kenneth D.", ""]]}, {"id": "1908.10162", "submitter": "Benedetta Franceschiello Dr.", "authors": "Benedetta Franceschiello, Alessandro Sarti, Giovanna Citti", "title": "A neuro-mathematical model for size and context related illusions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide here a mathematical model of size/context illusions, inspired by\nthe functional architecture of the visual cortex. We first recall previous\nmodels of scale and orientation, in particular the one in (Sarti et al., 2008),\nand simplify it, only considering the feature of scale. Then we recall the\ndeformation model of illusion, introduced by (Franceschiello et al. 2017), to\ndescribe orientation related GOIs, and adapt it to size illusions. We finally\napply the model to the Ebbinghaus and Delboeuf illusions, validating the\nresults by comparing with experimental data from (Massaro et al., 1971) and\n(Roberts et al., 2005).\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 12:36:41 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Franceschiello", "Benedetta", ""], ["Sarti", "Alessandro", ""], ["Citti", "Giovanna", ""]]}, {"id": "1908.10206", "submitter": "Raul Vicente", "authors": "Raul Vicente", "title": "The many faces of deep learning", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG physics.data-an q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning has sparked a network of mutual interactions between different\ndisciplines and AI. Naturally, each discipline focuses and interprets the\nworkings of deep learning in different ways. This diversity of perspectives on\ndeep learning, from neuroscience to statistical physics, is a rich source of\ninspiration that fuels novel developments in the theory and applications of\nmachine learning. In this perspective, we collect and synthesize different\nintuitions scattered across several communities as for how deep learning works.\nIn particular, we will briefly discuss the different perspectives that\ndisciplines across mathematics, physics, computation, and neuroscience take on\nhow deep learning does its tricks. Our discussion on each perspective is\nnecessarily shallow due to the multiple views that had to be covered. The\ndeepness in this case should come from putting all these faces of deep learning\ntogether in the reader's mind, so that one can look at the same problem from\ndifferent angles.\n", "versions": [{"version": "v1", "created": "Sun, 25 Aug 2019 12:04:49 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Vicente", "Raul", ""]]}, {"id": "1908.10240", "submitter": "Ghada Zamzmi", "authors": "Matthew Compton, Ghada Zamzmi, Rahul Mhaskar, Maria Gieron, Marcia\n  Kneusel, Judy Zarit, Terri Ashmeade", "title": "Pain Analysis, in Premature Infants, Using Near Infrared Spectroscopy\n  (NIRS)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The role of neonatal pain on the developing nervous system is not\ncompletely understood, but evidence suggests that sensory pathways are\ninfluenced by an infants pain experience. Research has shown that an infants\nprevious pain experiences lead to an increased, and likely abnormal, response\nto subsequent painful stimuli. We are working to improve neonatal pain\ndetection through automated devices that continuously monitor an infant. The\ncurrent study outlines some of the initial steps we have taken to evaluate Near\nInfrared Spectroscopy (NIRS) as a technology to detect neonatal pain. Our\nfindings may provide neonatal intensive care unit (NICU) practitioners with the\ndata necessary to monitor and perhaps better manage an abnormal pain response.\nMethods: A prospective pilot study was conducted to evaluate nociceptive evoked\ncortical activity in preterm infants. NIRS data were recorded for approximately\n10 minutes prior to an acute painful procedure and for approximately 10 minutes\nafter the procedure. Individual data collection events were performed at a\nweekly maximum frequency. Eligible infants included those admitted to the Tampa\nGeneral Hospital (TGH) NICU with a birth gestational age of less than 37 weeks.\nResults: A total of 15 infants were enrolled and 25 individual studies were\ncompleted. Analysis demonstrated a statistically significant difference between\nthe median of the pre- and post-painful procedure data sets in each infants\nfirst NIRS collection (p value = 0.01). Conclusions: Initial analysis shows\nNIRS may be useful in detecting acute pain. An acute painful procedure is\ntypically followed by a negative deflection in NIRS readings.\n", "versions": [{"version": "v1", "created": "Thu, 22 Aug 2019 03:26:39 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Compton", "Matthew", ""], ["Zamzmi", "Ghada", ""], ["Mhaskar", "Rahul", ""], ["Gieron", "Maria", ""], ["Kneusel", "Marcia", ""], ["Zarit", "Judy", ""], ["Ashmeade", "Terri", ""]]}, {"id": "1908.10300", "submitter": "James Olds PhD", "authors": "J.L. Olds, M.S. Khan, M. Nayebpour and N. Koizumi", "title": "Explainable AI: A Neurally-Inspired Decision Stack Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  European Law now requires AI to be explainable in the context of adverse\ndecisions affecting European Union (EU) citizens. At the same time, it is\nexpected that there will be increasing instances of AI failure as it operates\non imperfect data. This paper puts forward a neurally-inspired framework called\ndecision stacks that can provide for a way forward in research aimed at\ndeveloping explainable AI. Leveraging findings from memory systems in\nbiological brains, the decision stack framework operationalizes the definition\nof explainability and then proposes a test that can potentially reveal how a\ngiven AI decision came to its conclusion.\n", "versions": [{"version": "v1", "created": "Tue, 27 Aug 2019 16:22:31 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Olds", "J. L.", ""], ["Khan", "M. S.", ""], ["Nayebpour", "M.", ""], ["Koizumi", "N.", ""]]}, {"id": "1908.10522", "submitter": "Jacob George", "authors": "Jacob A. George, Tyler S. Davis, Mark R. Brinton, Gregory A. Clark", "title": "Intuitive Neuromyoelectric Control of a Dexterous Bionic Arm Using a\n  Modified Kalman Filter", "comments": "10 figures. Accepted in J. Neurosci. Methods (2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Multi-articulate prostheses are capable of performing dexterous\nhand movements. However, clinically available control strategies fail to\nprovide users with intuitive, independent and proportional control over\nmultiple degrees of freedom (DOFs) in real-time. New Method: We detail the use\nof a modified Kalman filter (MKF) to provide intuitive, independent and\nproportional control over six-DOF prostheses such as the DEKA \"LUKE\" Arm. Input\nfeatures include neural firing rates recorded from Utah Slanted Electrode\nArrays and mean absolute value of intramuscular electromyographic (EMG)\nrecordings. Ad-hoc modifications include thresholds and non-unity gains on the\noutput of a Kalman filter. Results: We demonstrate that both neural and EMG\ndata can be combined effectively. We also highlight that modifications can be\noptimized to significantly improve performance relative to an unmodified Kalman\nfilter. Thresholds significantly reduced unintended movement and promoted more\nindependent control of the different DOFs. Gain were significantly greater than\none and served to amplify participant effort. Optimal modifications can be\ndetermined quickly offline and translate to functional improvements online.\nUsing a portable take-home system, participants performed various activities of\ndaily living. Comparison with Existing Methods: In contrast to pattern\nrecognition, the MKF allows users to continuously modulate their force output,\nwhich is critical for fine dexterity. The MKF is also computationally efficient\nand can be trained in less than five minutes. Conclusions: The MKF can be used\nto explore the functional and psychological benefits associated with long-term,\nat-home control of dexterous prosthetic hands.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 02:24:35 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 16:03:52 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["George", "Jacob A.", ""], ["Davis", "Tyler S.", ""], ["Brinton", "Mark R.", ""], ["Clark", "Gregory A.", ""]]}, {"id": "1908.10592", "submitter": "Ahmad Mheich", "authors": "Ahmad Mheich, Fabrice Wendling, Mahmoud Hassan", "title": "Brain network similarity:Methods and applications", "comments": "31 pages, 8 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph theoretical approach has proved an effective tool to understand,\ncharacterize and quantify the complex brain network. However, much less\nattention has been paid to methods that quantitatively compare two graphs, a\ncrucial issue in the context of brain networks. Comparing brain networks is\nindeed mandatory in several network neuroscience applications. Here, we discuss\nthe current state of the art, challenges, and a collection of analysis tools\nthat have been developed in recent years to compare brain networks. We first\nintroduce the graph similarity problem in brain network application. We then\ndescribe the methodological background of the available metrics and algorithms\nof comparing graphs, their strengths and limitations. We also report results\nobtained in concrete applications from normal brain networks. More precisely,\nwe show the potential use of brain network similarity to build a 'network of\nnetworks' that may give new insights into the object categorization in the\nhuman brain. Additionally, we discuss future directions in terms of network\nsimilarity methods and applications.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 08:02:33 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Mheich", "Ahmad", ""], ["Wendling", "Fabrice", ""], ["Hassan", "Mahmoud", ""]]}, {"id": "1908.10773", "submitter": "Karen Dijkstra", "authors": "Karen Dijkstra, Jason Farquhar and Peter Desain", "title": "The N400 for Brain Computer Interfacing: complexities and opportunities", "comments": "28 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The N400 is an Event Related Potential that is evoked in response to\nconceptually meaningful stimuli. It is for instance more negative in response\nto incongruent than congruent words in a sentence, and more negative for\nunrelated than related words following a prime word. This sensitivity to\nsemantic content of a stimulus in relation to the mental context of an\nindividual makes it a signal of interest for Brain Computer Interfaces. Given\nthis potential it is notable that the BCI literature exploiting the N400 is\nlimited. We identify three existing application areas: (1) exploiting the\nsemantic processing of faces to enhance matrix speller performance, (2)\ndetecting language processing in patients with Disorders of Consciousness, and\n(3) using semantic stimuli to probe what is on a user's mind. Drawing on\nstudies from these application areas, we illustrate that the N400 can\nsuccessfully be exploited for BCI purposes, but that the signal-to-noise ratio\nis a limiting factor, with signal strength also varying strongly across\nsubjects. Furthermore, we put findings in context of the general N400\nliterature, noting open questions and identifying opportunities for further\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 15:24:02 GMT"}], "update_date": "2019-08-29", "authors_parsed": [["Dijkstra", "Karen", ""], ["Farquhar", "Jason", ""], ["Desain", "Peter", ""]]}, {"id": "1908.10922", "submitter": "Gregory Kiar", "authors": "Gregory Kiar, Pablo de Oliveira Castro, Pierre Rioux, Eric Petit,\n  Shawn T. Brown, Alan C. Evans, Tristan Glatard", "title": "Comparing Perturbation Models for Evaluating Stability of Neuroimaging\n  Pipelines", "comments": "9 pages, 5 figures, 1 table, paper published at IJHPCA", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lack of software reproducibility has become increasingly apparent in the\nlast several years, calling into question the validity of scientific findings\naffected by published tools. Reproducibility issues may have numerous sources\nof error, including the underlying numerical stability of algorithms and\nimplementations employed. Various forms of instability have been observed in\nneuroimaging, including across operating system versions, minor noise\ninjections, and implementation of theoretically equivalent algorithms. In this\npaper we explore the effect of various perturbation methods on a typical\nneuroimaging pipeline through the use of i) targeted noise injections, ii)\nMonte Carlo Arithmetic, and iii) varying operating systems to identify the\nquality and severity of their impact. The work presented here demonstrates that\neven low order computational models such as the connectome estimation pipeline\nthat we used are susceptible to noise. This suggests that stability is a\nrelevant axis upon which tools should be compared, developed, or improved,\nalongside more commonly considered axes such as accuracy/biological feasibility\nor performance. The heterogeneity observed across participants clearly\nillustrates that stability is a property of not just the data or tools\nindependently, but their interaction. Characterization of stability should\ntherefore be evaluated for specific analyses and performed on a representative\nset of subjects for consideration in subsequent statistical testing.\nAdditionally, identifying how this relationship scales to higher-order models\nis an exciting next step which will be explored. Finally, the joint application\nof perturbation methods with post-processing approaches such as bagging or\nsignal normalization may lead to the development of more numerically stable\nanalyses while maintaining sensitivity to meaningful variation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Aug 2019 19:39:11 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 16:23:33 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2020 16:10:38 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Kiar", "Gregory", ""], ["Castro", "Pablo de Oliveira", ""], ["Rioux", "Pierre", ""], ["Petit", "Eric", ""], ["Brown", "Shawn T.", ""], ["Evans", "Alan C.", ""], ["Glatard", "Tristan", ""]]}, {"id": "1908.11463", "submitter": "Haoqi Sun", "authors": "Haoqi Sun, Wolfgang Ganglberger, Ezhil Panneerselvam, Michael J.\n  Leone, Syed A. Quadri, Balaji Goparaju, Ryan A. Tesh, Oluwaseun Akeju, Robert\n  J. Thomas, M. Brandon Westover", "title": "Sleep Staging from Electrocardiography and Respiration with Deep\n  Learning", "comments": "Contains supplementary material at the end. Sleep 2019", "journal-ref": null, "doi": "10.1093/sleep/zsz306", "report-no": null, "categories": "q-bio.QM eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Study Objective: Sleep is reflected not only in the electroencephalogram but\nalso in heart rhythms and breathing patterns. Therefore, we hypothesize that it\nis possible to accurately stage sleep based on the electrocardiogram (ECG) and\nrespiratory signals. Methods: Using a dataset including 8,682 polysomnographs,\nwe develop deep neural networks to stage sleep from ECG and respiratory\nsignals. Five deep neural networks consisting of convolutional networks and\nlong short-term memory networks are trained to stage sleep using heart and\nbreathing, including the timing of R peaks from ECG, abdominal and chest\nrespiratory effort, and the combinations of these signals. Results: ECG in\ncombination with the abdominal respiratory effort achieve the best performance\nfor staging all five sleep stages with a Cohen's kappa of 0.600 (95% confidence\ninterval 0.599 -- 0.602); and 0.762 (0.760 -- 0.763) for discriminating awake\nvs. rapid eye movement vs. non-rapid eye movement sleep. The performance is\nbetter for young participants and for those with a low apnea-hypopnea index,\nwhile it is robust for commonly used outpatient medications. Conclusions: Our\nresults validate that ECG and respiratory effort provide substantial\ninformation about sleep stages in a large population. It opens new\npossibilities in sleep research and applications where electroencephalography\nis not readily available or may be infeasible, such as in critically ill\npatients.\n", "versions": [{"version": "v1", "created": "Thu, 29 Aug 2019 22:06:00 GMT"}, {"version": "v2", "created": "Mon, 16 Sep 2019 00:01:16 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Sun", "Haoqi", ""], ["Ganglberger", "Wolfgang", ""], ["Panneerselvam", "Ezhil", ""], ["Leone", "Michael J.", ""], ["Quadri", "Syed A.", ""], ["Goparaju", "Balaji", ""], ["Tesh", "Ryan A.", ""], ["Akeju", "Oluwaseun", ""], ["Thomas", "Robert J.", ""], ["Westover", "M. Brandon", ""]]}, {"id": "1908.11865", "submitter": "Katherine Newhall", "authors": "Pamela B Pyzza, Katherine A Newhall, Douglas Zhou, Gregor Kovacic,\n  David Cai", "title": "Network Mechanism for Insect Olfaction", "comments": "43 pages with 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early olfactory pathway responses to the presentation of an odor exhibit\nremarkably similar dynamical behavior across phyla from insects to mammals, and\nfrequently involve transitions among quiescence, collective network\noscillations, and asynchronous firing. We hypothesize that the time scales of\nfast excitation and fast and slow inhibition present in these networks may be\nthe essential element underlying this similar behavior, and design an\nidealized, conductance-based integrate-and-fire (I&F) model to verify this\nhypothesis via numerical simulations. To better understand the mathematical\nstructure underlying the common dynamical behavior across species, we derive a\nfiring-rate (FR) model and use it to extract a slow passage through a\nsaddle-node-on-an-invariant-circle (SNIC) bifurcation structure. We expect this\nbifurcation structure to provide new insights into the understanding of the\ndynamical behavior of neuronal assemblies and that a similar structure can be\nfound in other sensory systems.\n", "versions": [{"version": "v1", "created": "Fri, 30 Aug 2019 17:50:55 GMT"}, {"version": "v2", "created": "Sun, 27 Sep 2020 14:51:03 GMT"}], "update_date": "2020-09-29", "authors_parsed": [["Pyzza", "Pamela B", ""], ["Newhall", "Katherine A", ""], ["Zhou", "Douglas", ""], ["Kovacic", "Gregor", ""], ["Cai", "David", ""]]}]