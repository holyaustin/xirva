[{"id": "1601.00334", "submitter": "Elliot Martin", "authors": "Elliot A. Martin, Jaroslav Hlinka, J\\\"orn Davidsen", "title": "Pairwise Network Information and Nonlinear Correlations", "comments": null, "journal-ref": "Phys. Rev. E 94, 040301 (2016)", "doi": "10.1103/PhysRevE.94.040301", "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconstructing the structural connectivity between interacting units from\nobserved activity is a challenge across many different disciplines. The\nfundamental first step is to establish whether or to what extent the\ninteractions between the units can be considered pairwise and, thus, can be\nmodeled as an interaction network with simple links corresponding to pairwise\ninteractions. In principle this can be determined by comparing the maximum\nentropy given the bivariate probability distributions to the true joint\nentropy. In many practical cases this is not an option since the bivariate\ndistributions needed may not be reliably estimated, or the optimization is too\ncomputationally expensive. Here we present an approach that allows one to use\nmutual informations as a proxy for the bivariate distributions. This has the\nadvantage of being less computationally expensive and easier to estimate. We\nachieve this by introducing a novel entropy maximization scheme that is based\non conditioning on entropies and mutual informations. This renders our approach\ntypically superior to other methods based on linear approximations. The\nadvantages of the proposed method are documented using oscillator networks and\na resting-state human brain network as generic relevant examples.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jan 2016 20:10:09 GMT"}, {"version": "v2", "created": "Thu, 29 Sep 2016 05:14:05 GMT"}], "update_date": "2016-11-02", "authors_parsed": [["Martin", "Elliot A.", ""], ["Hlinka", "Jaroslav", ""], ["Davidsen", "J\u00f6rn", ""]]}, {"id": "1601.00364", "submitter": "Elad Ganmor", "authors": "Elad Ganmor, Michael Krumin, Luigi F. Rossi, Matteo Carandini and Eero\n  P. Simoncelli", "title": "Direct Estimation of Firing Rates from Calcium Imaging Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-photon imaging of calcium indicators allows simultaneous recording of\nresponses of hundreds of neurons over hours and even days, but provides a\nrelatively indirect measure of their spiking activity. Existing deconvolution\nalgorithms attempt to recover spikes from observed imaging data, which are then\ncommonly subjected to the same analyses that are applied to\nelectrophysiologically recorded spikes (e.g., estimation of average firing\nrates, or tuning curves). Here we show, however, that in the presence of noise\nthis approach is often heavily biased. We propose an alternative analysis that\naims to estimate the underlying rate directly, by integrating over the\nunobserved spikes instead of committing to a single estimate of the spike\ntrain. This approach can be used to estimate average firing rates or tuning\ncurves directly from the imaging data, and is sufficiently flexible to\nincorporate prior knowledge about tuning structure. We show that directly\nestimated rates are more accurate than those obtained from averaging of spikes\nestimated through deconvolution, both on simulated data and on imaging data\nacquired in mouse visual cortex.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 02:01:19 GMT"}], "update_date": "2016-01-05", "authors_parsed": [["Ganmor", "Elad", ""], ["Krumin", "Michael", ""], ["Rossi", "Luigi F.", ""], ["Carandini", "Matteo", ""], ["Simoncelli", "Eero P.", ""]]}, {"id": "1601.00496", "submitter": "S{\\o}ren F{\\o}ns Vind Nielsen", "authors": "S{\\o}ren F. V. Nielsen and Kristoffer H. Madsen and Rasmus R{\\o}ge and\n  Mikkel N. Schmidt and Morten M{\\o}rup", "title": "Nonparametric Modeling of Dynamic Functional Connectivity in fMRI Data", "comments": "8 pages, 1 figure. Presented at the Machine Learning and\n  Interpretation in Neuroimaging Workshop (MLINI-2015), 2015 (arXiv:1605.04435)", "journal-ref": null, "doi": null, "report-no": "MLINI/2015/08", "categories": "stat.AP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic functional connectivity (FC) has in recent years become a topic of\ninterest in the neuroimaging community. Several models and methods exist for\nboth functional magnetic resonance imaging (fMRI) and electroencephalography\n(EEG), and the results point towards the conclusion that FC exhibits dynamic\nchanges. The existing approaches modeling dynamic connectivity have primarily\nbeen based on time-windowing the data and k-means clustering. We propose a\nnon-parametric generative model for dynamic FC in fMRI that does not rely on\nspecifying window lengths and number of dynamic states. Rooted in Bayesian\nstatistical modeling we use the predictive likelihood to investigate if the\nmodel can discriminate between a motor task and rest both within and across\nsubjects. We further investigate what drives dynamic states using the model on\nthe entire data collated across subjects and task/rest. We find that the number\nof states extracted are driven by subject variability and preprocessing\ndifferences while the individual states are almost purely defined by either\ntask or rest. This questions how we in general interpret dynamic FC and points\nto the need for more research on what drives dynamic FC.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 13:24:45 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 07:42:53 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Nielsen", "S\u00f8ren F. V.", ""], ["Madsen", "Kristoffer H.", ""], ["R\u00f8ge", "Rasmus", ""], ["Schmidt", "Mikkel N.", ""], ["M\u00f8rup", "Morten", ""]]}, {"id": "1601.00701", "submitter": "Carlos Stein Naves De Brito", "authors": "Carlos S. N. Brito, Wulfram Gerstner", "title": "Nonlinear Hebbian learning as a unifying principle in receptive field\n  formation", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1005070", "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of sensory receptive fields has been modeled in the past by a\nvariety of models including normative models such as sparse coding or\nindependent component analysis and bottom-up models such as spike-timing\ndependent plasticity or the Bienenstock-Cooper-Munro model of synaptic\nplasticity. Here we show that the above variety of approaches can all be\nunified into a single common principle, namely Nonlinear Hebbian Learning. When\nNonlinear Hebbian Learning is applied to natural images, receptive field shapes\nwere strongly constrained by the input statistics and preprocessing, but\nexhibited only modest variation across different choices of nonlinearities in\nneuron models or synaptic plasticity rules. Neither overcompleteness nor sparse\nnetwork activity are necessary for the development of localized receptive\nfields. The analysis of alternative sensory modalities such as auditory models\nor V2 development lead to the same conclusions. In all examples, receptive\nfields can be predicted a priori by reformulating an abstract model as\nnonlinear Hebbian learning. Thus nonlinear Hebbian learning and natural\nstatistics can account for many aspects of receptive field formation across\nmodels and sensory modalities.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jan 2016 23:35:41 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Brito", "Carlos S. N.", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1601.00720", "submitter": "Subutai Ahmad", "authors": "Subutai Ahmad, Jeff Hawkins", "title": "How do neurons operate on sparse distributed representations? A\n  mathematical theory of sparsity, neurons and active dendrites", "comments": "Journal submission, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a formal mathematical model for sparse representations and active\ndendrites in neocortex. Our model is inspired by recent experimental findings\non active dendritic processing and NMDA spikes in pyramidal neurons. These\nexperimental and modeling studies suggest that the basic unit of pattern memory\nin the neocortex is instantiated by small clusters of synapses operated on by\nlocalized non-linear dendritic processes. We derive a number of scaling laws\nthat characterize the accuracy of such dendrites in detecting activation\npatterns in a neuronal population under adverse conditions. We introduce the\nunion property which shows that synapses for multiple patterns can be randomly\nmixed together within a segment and still lead to highly accurate recognition.\nWe describe simulation results that provide further insight into sparse\nrepresentations as well as two primary results. First we show that pattern\nrecognition by a neuron with active dendrites can be extremely accurate and\nrobust with high dimensional sparse inputs even when using a tiny number of\nsynapses to recognize large patterns. Second, equations representing\nrecognition accuracy of a dendrite predict optimal NMDA spiking thresholds\nunder a generous set of assumptions. The prediction tightly matches NMDA\nspiking thresholds measured in the literature. Our model matches many of the\nknown properties of pyramidal neurons. As such the theory provides a\nmathematical framework for understanding the benefits and limits of sparse\nrepresentations in cortical networks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 02:53:09 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 01:12:00 GMT"}], "update_date": "2016-05-16", "authors_parsed": [["Ahmad", "Subutai", ""], ["Hawkins", "Jeff", ""]]}, {"id": "1601.00909", "submitter": "Mihai Alexandru Petrovici", "authors": "Mihai A. Petrovici, Ilja Bytschok, Johannes Bill, Johannes Schemmel\n  and Karlheinz Meier", "title": "The high-conductance state enables neural sampling in networks of LIF\n  neurons", "comments": "3 pages, 1 figure", "journal-ref": null, "doi": "10.1186/1471-2202-16-S1-O2", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE physics.bio-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The apparent stochasticity of in-vivo neural circuits has long been\nhypothesized to represent a signature of ongoing stochastic inference in the\nbrain. More recently, a theoretical framework for neural sampling has been\nproposed, which explains how sample-based inference can be performed by\nnetworks of spiking neurons. One particular requirement of this approach is\nthat the neural response function closely follows a logistic curve.\n  Analytical approaches to calculating neural response functions have been the\nsubject of many theoretical studies. In order to make the problem tractable,\nparticular assumptions regarding the neural or synaptic parameters are usually\nmade. However, biologically significant activity regimes exist which are not\ncovered by these approaches: Under strong synaptic bombardment, as is often the\ncase in cortex, the neuron is shifted into a high-conductance state (HCS)\ncharacterized by a small membrane time constant. In this regime, synaptic time\nconstants and refractory periods dominate membrane dynamics.\n  The core idea of our approach is to separately consider two different \"modes\"\nof spiking dynamics: burst spiking and transient quiescence, in which the\nneuron does not spike for longer periods. We treat the former by propagating\nthe PDF of the effective membrane potential from spike to spike within a burst,\nwhile using a diffusion approximation for the latter. We find that our\nprediction of the neural response function closely matches simulation data.\nMoreover, in the HCS scenario, we show that the neural response function\nbecomes symmetric and can be well approximated by a logistic function, thereby\nproviding the correct dynamics in order to perform neural sampling. We hereby\nprovide not only a normative framework for Bayesian inference in cortex, but\nalso powerful applications of low-power, accelerated neuromorphic systems to\nrelevant machine learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 17:15:37 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Petrovici", "Mihai A.", ""], ["Bytschok", "Ilja", ""], ["Bill", "Johannes", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1601.00987", "submitter": "Sarah Muldoon", "authors": "Sarah Feldt Muldoon, Fabio Pasqualetti, Shi Gu, Matthew Cieslak, Scott\n  T. Grafton, Jean M. Vettel, and Danielle S. Bassett", "title": "Stimulation-based control of dynamic brain networks", "comments": "54 pages, 10 figures, includes Supplementary Information", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to modulate brain states using targeted stimulation is\nincreasingly being employed to treat neurological disorders and to enhance\nhuman performance. Despite the growing interest in brain stimulation as a form\nof neuromodulation, much remains unknown about the network-level impact of\nthese focal perturbations. To study the system wide impact of regional\nstimulation, we employ a data-driven computational model of nonlinear brain\ndynamics to systematically explore the effects of targeted stimulation.\nValidating predictions from network control theory, we uncover the relationship\nbetween regional controllability and the focal versus global impact of\nstimulation, and we relate these findings to differences in the underlying\nnetwork architecture. Finally, by mapping brain regions to cognitive systems,\nwe observe that the default mode system imparts large global change despite\nbeing highly constrained by structural connectivity. This work forms an\nimportant step towards the development of personalized stimulation protocols\nfor medical treatment or performance enhancement.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jan 2016 21:33:24 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Muldoon", "Sarah Feldt", ""], ["Pasqualetti", "Fabio", ""], ["Gu", "Shi", ""], ["Cieslak", "Matthew", ""], ["Grafton", "Scott T.", ""], ["Vettel", "Jean M.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1601.01358", "submitter": "Leyla Isik", "authors": "Leyla Isik, Andrea Tacchetti, and Tomaso Poggio", "title": "Fast, invariant representation for human action in the visual system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can effortlessly recognize others' actions in the presence of complex\ntransformations, such as changes in viewpoint. Several studies have located the\nregions in the brain involved in invariant action recognition, however, the\nunderlying neural computations remain poorly understood. We use\nmagnetoencephalography (MEG) decoding and a dataset of well-controlled,\nnaturalistic videos of five actions (run, walk, jump, eat, drink) performed by\ndifferent actors at different viewpoints to study the computational steps used\nto recognize actions across complex transformations. In particular, we ask when\nthe brain discounts changes in 3D viewpoint relative to when it initially\ndiscriminates between actions. We measure the latency difference between\ninvariant and non-invariant action decoding when subjects view full videos as\nwell as form-depleted and motion-depleted stimuli. Our results show no\ndifference in decoding latency or temporal profile between invariant and\nnon-invariant action recognition in full videos. However, when either form or\nmotion information is removed from the stimulus set, we observe a decrease and\ndelay in invariant action decoding. Our results suggest that the brain\nrecognizes actions and builds invariance to complex transformations at the same\ntime, and that both form and motion information are crucial for fast, invariant\naction recognition.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 00:28:06 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 14:46:56 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Isik", "Leyla", ""], ["Tacchetti", "Andrea", ""], ["Poggio", "Tomaso", ""]]}, {"id": "1601.01580", "submitter": "Ran Levi", "authors": "Pawe Dotko, Kathryn Hess, Ran Levi, Max Nolte, Michael Reimann,\n  Martina Scolamiero, Katharine Turner, Eilif Muller, Henry Markram", "title": "Topological analysis of the connectome of digital reconstructions of\n  neural microcircuits", "comments": null, "journal-ref": null, "doi": "10.3389/fncom.2017.00048", "report-no": null, "categories": "q-bio.NC math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent publication provides the network graph for a neocortical\nmicrocircuit comprising 8 million connections between 31,000 neurons (H.\nMarkram, et al., Reconstruction and simulation of neocortical microcircuitry,\nCell, 163 (2015) no. 2, 456-492). Since traditional graph-theoretical methods\nmay not be sufficient to understand the immense complexity of such a biological\nnetwork, we explored whether methods from algebraic topology could provide a\nnew perspective on its structural and functional organization. Structural\ntopological analysis revealed that directed graphs representing connectivity\namong neurons in the microcircuit deviated significantly from different\nvarieties of randomized graph. In particular, the directed graphs contained in\nthe order of $10^7$ simplices {\\DH} groups of neurons with all-to-all directed\nconnectivity. Some of these simplices contained up to 8 neurons, making them\nthe most extreme neuronal clustering motif ever reported. Functional\ntopological analysis of simulated neuronal activity in the microcircuit\nrevealed novel spatio-temporal metrics that provide an effective classification\nof functional responses to qualitatively different stimuli. This study\nrepresents the first algebraic topological analysis of structural connectomics\nand connectomics-based spatio-temporal activity in a biologically realistic\nneural microcircuit. The methods used in the study show promise for more\ngeneral applications in network science.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 16:02:05 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Dotko", "Pawe", ""], ["Hess", "Kathryn", ""], ["Levi", "Ran", ""], ["Nolte", "Max", ""], ["Reimann", "Michael", ""], ["Scolamiero", "Martina", ""], ["Turner", "Katharine", ""], ["Muller", "Eilif", ""], ["Markram", "Henry", ""]]}, {"id": "1601.01649", "submitter": "Jan Cho{\\l}oniewski", "authors": "Jan Cho{\\l}oniewski, Anna Chmiel, Julian Sienkiewicz, Janusz\n  Ho{\\l}yst, Dennis K\\\"uster and Arvid Kappas", "title": "Temporal Taylor's scaling of facial electromyography and electrodermal\n  activity in the course of emotional stimulation", "comments": null, "journal-ref": null, "doi": "10.1016/j.chaos.2016.04.023", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High frequency psychophysiological data create a challenge for quantitative\nmodeling based on Big Data tools since they reflect the complexity of processes\ntaking place in human body and its responses to external events. Here we\npresent studies of fluctuations in facial electromyography (fEMG) and\nelectrodermal activity (EDA) massive time series and changes of such signals in\nthe course of emotional stimulation. Zygomaticus major (ZYG, \"smiling\" muscle)\nactivity, corrugator supercilii (COR, \"frowning\"bmuscle) activity, and phasic\nskin conductance (PHSC, sweating) levels of 65 participants were recorded\nduring experiments that involved exposure to emotional stimuli (i.e., IAPS\nimages, reading and writing messages on an artificial online discussion board).\nTemporal Taylor's fluctuations scaling were found when signals for various\nparticipants and during various types of emotional events were compared. Values\nof scaling exponents were close to 1, suggesting an external origin of system\ndynamics and/or strong interactions between system's basic elements (e.g.,\nmuscle fibres). Our statistical analysis shows that the scaling exponents\nenable identification of high valence and arousal levels in ZYG and COR\nsignals.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 19:50:13 GMT"}, {"version": "v2", "created": "Sun, 24 Apr 2016 19:39:44 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Cho\u0142oniewski", "Jan", ""], ["Chmiel", "Anna", ""], ["Sienkiewicz", "Julian", ""], ["Ho\u0142yst", "Janusz", ""], ["K\u00fcster", "Dennis", ""], ["Kappas", "Arvid", ""]]}, {"id": "1601.01704", "submitter": "Chad Giusti", "authors": "Chad Giusti and Robert Ghrist and Danielle S. Bassett", "title": "Two's company, three (or more) is a simplex: Algebraic-topological tools\n  for understanding higher-order structure in neural data", "comments": "16 pages, 7 figures, expanded literature review section and added\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.AT q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The language of graph theory, or network science, has proven to be an\nexceptional tool for addressing myriad problems in neuroscience. Yet, the use\nof networks is predicated on a critical simplifying assumption: that the\nquintessential unit of interest in a brain is a dyad -- two nodes (neurons or\nbrain regions) connected by an edge. While rarely mentioned, this fundamental\nassumption inherently limits the types of neural structure and function that\ngraphs can be used to model. Here, we describe a generalization of graphs that\novercomes these limitations, thereby offering a broad range of new\npossibilities in terms of modeling and measuring neural phenomena.\nSpecifically, we explore the use of \\emph{simplicial complexes}, a theoretical\nnotion developed in the field of mathematics known as algebraic topology, which\nis now becoming applicable to real data due to a rapidly growing computational\ntoolset. We review the underlying mathematical formalism as well as the budding\nliterature applying simplicial complexes to neural data, from\nelectrophysiological recordings in animal models to hemodynamic fluctuations in\nhumans. Based on the exceptional flexibility of the tools and recent\nground-breaking insights into neural function, we posit that this framework has\nthe potential to eclipse graph theory in unraveling the fundamental mysteries\nof cognition.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jan 2016 21:15:41 GMT"}, {"version": "v2", "created": "Wed, 13 Jan 2016 19:52:44 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Giusti", "Chad", ""], ["Ghrist", "Robert", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1601.01878", "submitter": "Rafael Borges Ribaski", "authors": "Rafael R. Borges, Fernando S. Borges, Ewandson L. Lameu, Antonio\n  Marcos Batista, Kelly C. Iarosz, Iber\\^e L. Caldas, Chris G. Antonopoulos,\n  Murilo S. Baptista", "title": "Spike timing-dependent plasticity induces non-trivial topology in the\n  brain", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the capacity of Hodgkin-Huxley neuron in a network to change\ntemporarily or permanently their connections and behavior, the so called spike\ntiming-dependent plasticity (STDP), as a function of their synchronous\nbehavior. We consider STDP of excitatory and inhibitory synapses driven by\nHebbian rules. We show that the final state of networks evolved by a STDP\ndepend on the initial network configuration. Specifically, an initial\nall-to-all topology envolves to a complex topology. Moreover, external\nperturbations can induce co-existence of clusters, those whose neurons are\nsynchronous and those whose neurons are desynchronous. This work reveals that\nSTDP based on Hebbian rules leads to a change in the direction of the synapses\nbetween high and low frequency neurons, and therefore, Hebbian learning can be\nexplained in terms of preferential attachment between these two diverse\ncommunities of neurons, those with low-frequency spiking neurons, and those\nwith higher-frequency spiking neurons.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jan 2016 14:04:57 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2017 01:47:01 GMT"}, {"version": "v3", "created": "Wed, 8 Feb 2017 17:38:08 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Borges", "Rafael R.", ""], ["Borges", "Fernando S.", ""], ["Lameu", "Ewandson L.", ""], ["Batista", "Antonio Marcos", ""], ["Iarosz", "Kelly C.", ""], ["Caldas", "Iber\u00ea L.", ""], ["Antonopoulos", "Chris G.", ""], ["Baptista", "Murilo S.", ""]]}, {"id": "1601.02189", "submitter": "Ido Kanter", "authors": "Amir Goldental, Pinhas Sabo, Shira Sardi, Roni Vardi and Ido Kanter", "title": "Mimicking Collective Firing Patterns of Hundreds of Connected Neurons\n  using a Single-Neuron Experiment", "comments": "26 pages and 6 figures,\n  http://journal.frontiersin.org/article/10.3389/fnins.2015.00508/", "journal-ref": "Front. Neurosci. 9:508 (2015)", "doi": "10.3389/fnins.2015.00508", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The experimental study of neural networks requires simultaneous measurements\nof a massive number of neurons, while monitoring properties of the\nconnectivity, synaptic strengths and delays. Current technological barriers\nmake such a mission unachievable. In addition, as a result of the enormous\nnumber of required measurements, the estimated network parameters would differ\nfrom the original ones. Here we present a versatile experimental technique,\nwhich enables the study of recurrent neural networks activity while being\ncapable of dictating the network connectivity and synaptic strengths. This\nmethod is based on the observation that the response of neurons depends solely\non their recent stimulations, a short-term memory. It allows a long-term scheme\nof stimulation and recording of a single neuron, to mimic simultaneous activity\nmeasurements of neurons in a recurrent network. Utilization of this technique\ndemonstrates the spontaneous emergence of cooperative synchronous oscillations,\nin particular the coexistence of fast Gamma and slow Delta oscillations, and\nopens the horizon for the experimental study of other cooperative phenomena\nwithin large-scale neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jan 2016 09:07:09 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Goldental", "Amir", ""], ["Sabo", "Pinhas", ""], ["Sardi", "Shira", ""], ["Vardi", "Roni", ""], ["Kanter", "Ido", ""]]}, {"id": "1601.02626", "submitter": "Max Tegmark", "authors": "Max Tegmark (MIT)", "title": "Improved Measures of Integrated Information", "comments": "Replaced to match final accepted version. 21 pages, 5 figs", "journal-ref": "PLoS Comput Biol 12(11): e1005123.\n  doi:10.1371/journal.pcbi.1005123 (2016)", "doi": "10.1371/journal.pcbi.1005123", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there is growing interest in measuring integrated information in\ncomputational and cognitive systems, current methods for doing so in practice\nare computationally unfeasible. Existing and novel integration measures are\ninvestigated and classified by various desirable properties. A simple taxonomy\nof Phi-measures is presented where they are each characterized by their choice\nof factorization method (5 options), choice of probability distributions to\ncompare (3x4 options) and choice of measure for comparing probability\ndistributions (7 options). When requiring the Phi-measures to satisfy a minimum\nof attractive properties, these hundreds of options reduce to a mere handful,\nsome of which turn out to be identical. Useful exact and approximate formulas\nare derived that can be applied to real-world data from laboratory experiments\nwithout posing unreasonable computational demands.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jan 2016 21:00:08 GMT"}, {"version": "v2", "created": "Mon, 18 Jul 2016 01:14:02 GMT"}, {"version": "v3", "created": "Tue, 29 Nov 2016 21:00:16 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Tegmark", "Max", "", "MIT"]]}, {"id": "1601.02709", "submitter": "Guillaume Lajoie", "authors": "Guillaume Lajoie and Lai-Sang Young", "title": "Dynamic signal tracking in a simple V1 spiking model", "comments": "27 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work is part of an effort to understand the neural basis for our visual\nsystem's ability, or failure, to accurately track moving visual signals. We\nconsider here a ring model of spiking neurons, intended as a simplified\ncomputational model of a single hypercolumn of the primary visual cortex.\nSignals that consist of edges with time-varying orientations localized in space\nare considered. Our model is calibrated to produce spontaneous and driven\nfiring rates roughly consistent with experiments, and our two main findings,\nfor which we offer dynamical explanation on the level of neuronal interactions,\nare the following: (1) We have documented consistent transient overshoots in\nsignal perception following signal switches due to emergent interactions of the\nE- and I-populations, and (2) for continuously moving signals, we have found\nthat accuracy is considerably lower at reversals of orientation than when\ncontinuing in the same direction (as when the signal is a rotating bar). To\nmeasure performance, we use two metrics, called fidelity and reliability, to\ncompare signals reconstructed by the system to the ones presented, and to\nassess trial-to-trial variability. We propose that the same population\nmechanisms responsible for orientation selectivity also impose constraints on\ndynamic signal tracking that manifest in perception failures consistent with\npsychophysical observations.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 01:37:46 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Lajoie", "Guillaume", ""], ["Young", "Lai-Sang", ""]]}, {"id": "1601.02948", "submitter": "Yoram Burak", "authors": "Noga Weiss Mosheiff, Haggai Agmon, Avraham Moriel, and Yoram Burak", "title": "An Efficient Coding Theory for a Dynamic Trajectory Predicts non-Uniform\n  Allocation of Grid Cells to Modules in the Entorhinal Cortex", "comments": "23 pages, 5 figures. Supplemental Information available from the\n  authors on request. A previous version of this work appeared in abstract form\n  (Program No. 727.02. 2015 Neuroscience Meeting Planner. Chicago, IL: Society\n  for Neuroscience, 2015. Online.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid cells in the entorhinal cortex encode the position of an animal in its\nenvironment using spatially periodic tuning curves of varying periodicity.\nRecent experiments established that these cells are functionally organized in\ndiscrete modules with uniform grid spacing. Here we develop a theory for\nefficient coding of position, which takes into account the temporal statistics\nof the animal's motion. The theory predicts a sharp decrease of module\npopulation sizes with grid spacing, in agreement with the trends seen in the\nexperimental data. We identify a simple scheme for readout of the grid cell\ncode by neural circuitry, that can match in accuracy the optimal Bayesian\ndecoder of the spikes. This readout scheme requires persistence over varying\ntimescales, ranging from ~1ms to ~1s, depending on the grid cell module. Our\nresults suggest that the brain employs an efficient representation of position\nwhich takes advantage of the spatiotemporal statistics of the encoded variable,\nin similarity to the principles that govern early sensory coding.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 16:38:14 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Mosheiff", "Noga Weiss", ""], ["Agmon", "Haggai", ""], ["Moriel", "Avraham", ""], ["Burak", "Yoram", ""]]}, {"id": "1601.02970", "submitter": "Radoslaw Cichy", "authors": "Radoslaw M. Cichy, Aditya Khosla, Dimitrios Pantazis, Antonio\n  Torralba, Aude Oliva", "title": "Deep Neural Networks predict Hierarchical Spatio-temporal Cortical\n  Dynamics of Human Visual Object Recognition", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complex multi-stage architecture of cortical visual pathways provides the\nneural basis for efficient visual object recognition in humans. However, the\nstage-wise computations therein remain poorly understood. Here, we compared\ntemporal (magnetoencephalography) and spatial (functional MRI) visual brain\nrepresentations with representations in an artificial deep neural network (DNN)\ntuned to the statistics of real-world visual recognition. We showed that the\nDNN captured the stages of human visual processing in both time and space from\nearly visual areas towards the dorsal and ventral streams. Further\ninvestigation of crucial DNN parameters revealed that while model architecture\nwas important, training on real-world categorization was necessary to enforce\nspatio-temporal hierarchical relationships with the brain. Together our results\nprovide an algorithmically informed view on the spatio-temporal dynamics of\nvisual object recognition in the human visual brain.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 17:34:32 GMT"}], "update_date": "2016-01-13", "authors_parsed": [["Cichy", "Radoslaw M.", ""], ["Khosla", "Aditya", ""], ["Pantazis", "Dimitrios", ""], ["Torralba", "Antonio", ""], ["Oliva", "Aude", ""]]}, {"id": "1601.02974", "submitter": "James Roach", "authors": "James P. Roach, Leonard M Sander, Michal R. Zochowski", "title": "Memory Recall and Spike Frequency Adaptation", "comments": null, "journal-ref": "Phys. Rev. E 93, 052307 (2016)", "doi": "10.1103/PhysRevE.93.052307", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain can reproduce memories from partial data; this ability is critical\nfor memory recall. The process of memory recall has been studied using\nauto-associative networks such as the Hopfield model. This kind of model\nreliably converges to stored patterns which contain the memory. However, it is\nunclear how the behavior is controlled by the brain so that after convergence\nto one configuration, it can proceed with recognition of another one. In the\nHopfield model this happens only through unrealistic changes of an effective\nglobal temperature that destabilizes all stored configurations. Here we show\nthat spike frequency adaptation (SFA), a common mechanism affecting neuron\nactivation in the brain, can provide state dependent control of pattern\nretrieval. We demonstrate this in a Hopfield network modified to include SFA,\nand also in a model network of biophysical neurons. In both cases SFA allows\nfor selective stabilization of attractors with different basins of attraction,\nand also for temporal dynamics of attractor switching that is not possible in\nstandard auto-associative schemes. The dynamics of our models give a plausible\naccount of different sorts of memory retrieval.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 17:40:38 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 17:10:11 GMT"}], "update_date": "2016-05-18", "authors_parsed": [["Roach", "James P.", ""], ["Sander", "Leonard M", ""], ["Zochowski", "Michal R.", ""]]}, {"id": "1601.03022", "submitter": "Xavier Navarro-Sune", "authors": "X Navarro-Sune, A.L. Hudson, F. De Vico Fallani, J. Martinerie, A.\n  Witon, P. Pouget, M. Raux, T. Similowski and M. Chavez", "title": "Riemannian geometry applied to detection of respiratory states from EEG\n  signals: the basis for a brain-ventilator interface", "comments": "14 pages, 7 figures", "journal-ref": "IEEE Transactions on Biomedical Engineering, 2016", "doi": "10.1109/TBME.2016.2592820", "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During mechanical ventilation, patient-ventilator disharmony is frequently\nobserved and may result in increased breathing effort, compromising the\npatient's comfort and recovery. This circumstance requires clinical\nintervention and becomes challenging when verbal communication is difficult. In\nthis work, we propose a brain computer interface (BCI) to automatically and\nnon-invasively detect patient-ventilator disharmony from\nelectroencephalographic (EEG) signals: a brain-ventilator interface (BVI). Our\nframework exploits the cortical activation provoked by the inspiratory\ncompensation when the subject and the ventilator are desynchronized. Use of a\none-class approach and Riemannian geometry of EEG covariance matrices allows\neffective classification of respiratory states. The BVI is validated on nine\nhealthy subjects that performed different respiratory tasks that mimic a\npatient-ventilator disharmony. Classification performances, in terms of areas\nunder ROC curves, are significantly improved using EEG signals compared to\ndetection based on air flow. Reduction in the number of electrodes that can\nachieve discrimination can often be desirable (e.g. for portable BCI systems).\nBy using an iterative channel selection technique, the Common Highest Order\nRanking (CHOrRa), we find that a reduced set of electrodes (n=6) can slightly\nimprove for an intra-subject configuration, and it still provides fairly good\nperformances for a general inter-subject setting. Results support the\ndiscriminant capacity of our approach to identify anomalous respiratory states,\nby learning from a training set containing only normal respiratory epochs. The\nproposed framework opens the door to brain-ventilator interfaces for monitoring\npatient's breathing comfort and adapting ventilator parameters to patient\nrespiratory needs.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 20:32:30 GMT"}, {"version": "v2", "created": "Tue, 20 Sep 2016 14:09:22 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Navarro-Sune", "X", ""], ["Hudson", "A. L.", ""], ["Fallani", "F. De Vico", ""], ["Martinerie", "J.", ""], ["Witon", "A.", ""], ["Pouget", "P.", ""], ["Raux", "M.", ""], ["Similowski", "T.", ""], ["Chavez", "M.", ""]]}, {"id": "1601.03060", "submitter": "Emin Orhan", "authors": "A. Emin Orhan, Wei Ji Ma", "title": "Efficient Probabilistic Inference in Generic Neural Networks Trained\n  with Non-Probabilistic Feedback", "comments": "30 pages, 10 figures, 6 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals perform near-optimal probabilistic inference in a wide range of\npsychophysical tasks. Probabilistic inference requires trial-to-trial\nrepresentation of the uncertainties associated with task variables and\nsubsequent use of this representation. Previous work has implemented such\ncomputations using neural networks with hand-crafted and task-dependent\noperations. We show that generic neural networks trained with a simple\nerror-based learning rule perform near-optimal probabilistic inference in nine\ncommon psychophysical tasks. In a probabilistic categorization task,\nerror-based learning in a generic network simultaneously explains a monkey's\nlearning curve and the evolution of qualitative aspects of its choice behavior.\nIn all tasks, the number of neurons required for a given level of performance\ngrows sub-linearly with the input population size, a substantial improvement on\nprevious implementations of probabilistic inference. The trained networks\ndevelop a novel sparsity-based probabilistic population code. Our results\nsuggest that probabilistic inference emerges naturally in generic neural\nnetworks trained with error-based learning rules.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jan 2016 21:16:35 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 17:01:52 GMT"}, {"version": "v3", "created": "Mon, 5 Dec 2016 01:49:45 GMT"}, {"version": "v4", "created": "Fri, 21 Apr 2017 21:22:34 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Orhan", "A. Emin", ""], ["Ma", "Wei Ji", ""]]}, {"id": "1601.03192", "submitter": "Benjamin Gagl", "authors": "Benjamin Gagl", "title": "Blue hypertext is a perfect design decision: No perceptual disadvantage\n  in reading and successful highlighting of relevant information", "comments": "15 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Highlighted text in the Internet (i.e. Hypertext) is predominantly blue and\nunderlined. The percept of these hypertext characteristics were heavily\nquestioned by applied research and empirical tests resulted in inconclusive\nresults. The ability to identify blue text in foveal and parafoveal vision was\nidentified as potentially constrained by the low number of foveally centered\nblue light sensitive retinal cells. The present study investigates if foveal\nand parafoveal perceptibility of hypertext is reduced during reading. A\nsilent-sentence reading study with simultaneous eye movement recordings and the\ninvisible boundary paradigm, which allows the investigation of foveal and\nparafoveal perceptibility, separately, was realized. Target words in sentences\nwere presented in either black or blue and either underlined or normal. No\neffect of color and underlining, but a preview benefit could be detected for\nfirst pass reading measures (comparing fixation times after degraded vs. un-\ndegraded parafoveal previews). Fixation time measures that included re-reading\n(i.e., total viewing times) showed, in addition to a preview effect, a reduced\nfixation time for not highlighted (black not underlined) in contrast to\nhighlighted target words (either blue or underlined or both). Thus, the present\npattern reflects no detectable perceptual disadvantage of hyperlink stimuli but\nincreased attraction of attention resources, after first pass reading, through\nhighlighting. Blue or underlined text allows readers to easily perceive\nhypertext and at the same time readers re-visited hypertext longer as a\nconsequence of highlighting. On the basis of the present evidence blue\nhypertext can be safely recommended to web designers for future use.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 10:27:56 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Gagl", "Benjamin", ""]]}, {"id": "1601.03214", "submitter": "Nithin Nagaraj", "authors": "Nithin Nagaraj and K. R. Sahasranand", "title": "Neural Signal Multiplexing via Compressed Sensing", "comments": "6 pages, 4 figures", "journal-ref": "2016 International Conference on Signal Processing and\n  Communications (SPCOM), Bangalore, pp. 1-5", "doi": "10.1109/SPCOM.2016.7746641", "report-no": null, "categories": "cs.IT math.IT nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transport of neural signals in the brain is challenging, owing to neural\ninterference and neural noise. There is experimental evidence of multiplexing\nof sensory information across population of neurons, particularly in the\nvertebrate visual and olfactory systems. Recently, it has been discovered that\nin lateral intraparietal cortex of the brain, decision signals are multiplexed\nwith decision-irrelevant visual signals. Furthermore, it is well known that\nseveral cortical neurons exhibit chaotic spiking patterns. Multiplexing of\nchaotic neural signals and their successful demultiplexing in the neurons\namidst interference and noise, is difficult to explain. In this work, a novel\ncompressed sensing model for efficient multiplexing of chaotic neural signals\nconstructed using the Hindmarsh-Rose spiking model is proposed. The signals are\nmultiplexed from a pre-synaptic neuron to its neighbouring post-synaptic\nneuron, in the presence of $10^4$ interfering noisy neural signals and\ndemultiplexed using compressed sensing techniques.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 12:28:14 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Nagaraj", "Nithin", ""], ["Sahasranand", "K. R.", ""]]}, {"id": "1601.03236", "submitter": "Peter Fransson", "authors": "William Hedley Thompson and Peter Fransson", "title": "Bursty and persistent properties of large-scale brain networks revealed\n  with a point-based method for dynamic functional connectivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel and versatile method to study the dynamics\nof resting-state fMRI brain connectivity with a high temporal sensitivity.\nWhereas most existing methods often rely on dividing the time-series into\nlarger segments of data (i.e. so called sliding window techniques), the\npoint-based method (PBM) proposed here provides an estimate of brain\nconnectivity at the level of individual sampled time-points. The achieved\nincrease in temporal sensitivity, together with temporal graph network theory\nallowed us to study functional integration between, as well as within,\nresting-state networks. Our results show that functional integrations between\ntwo resting-state networks predominately occurs in bursts of activity with\nintermittent periods of less connectivity, whereas the functional connectivity\nwithin resting-state networks is characterized by a tonic/periodic connectivity\npattern. Moreover, the point-based approach allowed us to estimate the\npersistency of brain connectivity, i.e. the duration of the intrinsic trace or\nmemory of resting-state connectivity patterns. The described point-based method\nof dynamic resting-state functional connectivity allows for a detailed and\nexpanded view on the temporal dynamics of resting-state connectivity that\nprovides novel insights into how neuronal information processing is integrated\nin the human brain at the level of large-scale networks.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 13:26:33 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Thompson", "William Hedley", ""], ["Fransson", "Peter", ""]]}, {"id": "1601.03255", "submitter": "Kaushik Majumdar", "authors": "Aditya Ramesh, Anagh Pathak and Kaushik Majumdar", "title": "A Novel Matrix Representation of Discrete Biomedical Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose a novel symmetric square matrix representation of one\nor more digital signals of finite equal length. For appropriate window length\nand sliding paradigm this matrix contains useful information about the signals\nin a two dimensional image form. Then this representation can be treated either\nas an algebraic matrix or as a geometric image. We have shown applications of\nboth on human multichannel intracranial electroencephalogram (iEEG). In the\nfirst application we have shown that for certain patients the highest\neigenvalue of the matrix obtained from the epileptic focal channels goes up\nduring a seizure. The focus of this paper is on an application of the second\nconcept, by which we have come up with an automatic seizure detection algorithm\non a publicly available benchmark data. Except for delay in detection in all\nother aspects the new algorithm outperformed the detection performance based on\na support vector machine based algorithm. We have also indicated how this\nsparse random matrix representation of brain electrical signals can encode the\nactivities of the brain.\n", "versions": [{"version": "v1", "created": "Wed, 13 Jan 2016 14:18:33 GMT"}], "update_date": "2016-01-14", "authors_parsed": [["Ramesh", "Aditya", ""], ["Pathak", "Anagh", ""], ["Majumdar", "Kaushik", ""]]}, {"id": "1601.03649", "submitter": "Brian Gardner BG", "authors": "Brian Gardner and Andr\\'e Gr\\\"uning", "title": "Supervised Learning in Spiking Neural Networks for Precise Temporal\n  Encoding", "comments": "26 pages, 10 figures, this version is published in PLoS ONE and\n  incorporates reviewer comments", "journal-ref": null, "doi": "10.1371/journal.pone.0161335", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precise spike timing as a means to encode information in neural networks is\nbiologically supported, and is advantageous over frequency-based codes by\nprocessing input features on a much shorter time-scale. For these reasons, much\nrecent attention has been focused on the development of supervised learning\nrules for spiking neural networks that utilise a temporal coding scheme.\nHowever, despite significant progress in this area, there still lack rules that\nhave a theoretical basis, and yet can be considered biologically relevant. Here\nwe examine the general conditions under which synaptic plasticity most\neffectively takes place to support the supervised learning of a precise\ntemporal code. As part of our analysis we examine two spike-based learning\nmethods: one of which relies on an instantaneous error signal to modify\nsynaptic weights in a network (INST rule), and the other one on a filtered\nerror signal for smoother synaptic weight modifications (FILT rule). We test\nthe accuracy of the solutions provided by each rule with respect to their\ntemporal encoding precision, and then measure the maximum number of input\npatterns they can learn to memorise using the precise timings of individual\nspikes as an indication of their storage capacity. Our results demonstrate the\nhigh performance of FILT in most cases, underpinned by the rule's\nerror-filtering mechanism, which is predicted to provide smooth convergence\ntowards a desired solution during learning. We also find FILT to be most\nefficient at performing input pattern memorisations, and most noticeably when\npatterns are identified using spikes with sub-millisecond temporal precision.\nIn comparison with existing work, we determine the performance of FILT to be\nconsistent with that of the highly efficient E-learning Chronotron, but with\nthe distinct advantage that FILT is also implementable as an online method for\nincreased biological realism.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jan 2016 16:28:32 GMT"}, {"version": "v2", "created": "Fri, 28 Oct 2016 18:35:05 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Gardner", "Brian", ""], ["Gr\u00fcning", "Andr\u00e9", ""]]}, {"id": "1601.04183", "submitter": "Peter Diehl Peter U. Diehl", "authors": "Peter U. Diehl, Bruno U. Pedroni, Andrew Cassidy, Paul Merolla, Emre\n  Neftci and Guido Zarrella", "title": "TrueHappiness: Neuromorphic Emotion Recognition on TrueNorth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to constructing a neuromorphic device that responds to\nlanguage input by producing neuron spikes in proportion to the strength of the\nappropriate positive or negative emotional response. Specifically, we perform a\nfine-grained sentiment analysis task with implementations on two different\nsystems: one using conventional spiking neural network (SNN) simulators and the\nother one using IBM's Neurosynaptic System TrueNorth. Input words are projected\ninto a high-dimensional semantic space and processed through a fully-connected\nneural network (FCNN) containing rectified linear units trained via\nbackpropagation. After training, this FCNN is converted to a SNN by\nsubstituting the ReLUs with integrate-and-fire neurons. We show that there is\npractically no performance loss due to conversion to a spiking network on a\nsentiment analysis test set, i.e. correlations between predictions and human\nannotations differ by less than 0.02 comparing the original DNN and its spiking\nequivalent. Additionally, we show that the SNN generated with this technique\ncan be mapped to existing neuromorphic hardware -- in our case, the TrueNorth\nchip. Mapping to the chip involves 4-bit synaptic weight discretization and\nadjustment of the neuron thresholds. The resulting end-to-end system can take a\nuser input, i.e. a word in a vocabulary of over 300,000 words, and estimate its\nsentiment on TrueNorth with a power consumption of approximately 50 uW.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jan 2016 17:04:25 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Diehl", "Peter U.", ""], ["Pedroni", "Bruno U.", ""], ["Cassidy", "Andrew", ""], ["Merolla", "Paul", ""], ["Neftci", "Emre", ""], ["Zarrella", "Guido", ""]]}, {"id": "1601.04253", "submitter": "Yuri A. Dabaghian", "authors": "Kentaro Hoffman, Andrey Babichev and Yuri Dabaghian", "title": "Topological mapping of space in bat hippocampus", "comments": "14 pages, 4 figures, 3 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mammalian hippocampus plays a key role in spatial learning and memory, but\nthe exact nature of the hippocampal representation of space is still being\nexplored. Recently, there has been a fair amount of success in modeling\nhippocampal spatial maps in rats, assuming a topological perspective on spatial\ninformation processing. In this paper, we use the topological model to study\n$3D$ learning in bats, which produces several insights into neurophysiological\nmechanisms of the hippocampal spatial mapping. First, we demonstrate functional\nimportance of the cell assemblies for producing accurate maps of the $3D$\nenvironments. Second, the model suggests that the readout neurons in these cell\nassemblies should function as integrators of synaptic inputs, rather than\ndetectors of place cells' coactivity and allows estimating the integration time\nwindow. Lastly, the model suggests that, in contrast with relatively slow\nmoving rats, suppressing $\\theta$-precession in bats improves the place cells\ncapacity to encode spatial maps, which is consistent with the experimental\nobservations.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jan 2016 05:56:02 GMT"}], "update_date": "2016-01-19", "authors_parsed": [["Hoffman", "Kentaro", ""], ["Babichev", "Andrey", ""], ["Dabaghian", "Yuri", ""]]}, {"id": "1601.04685", "submitter": "Ilya Nemenman", "authors": "Kawai Leung, Aylia Mohammadi, William S. Ryu and Ilya Nemenman", "title": "Stereotypical escape behavior in Caenorhabditis elegans allows\n  quantification of nociceptive stimuli levels", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1005262", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments of pain with human subjects are difficult, subjective, and\nethically constrained. Since the molecular mechanisms of pain transduction are\nreasonably conserved among different species, these problems are partially\nsolved by the use of animal models. However, animals cannot easily communicate\nto us their own pain levels. Thus progress depends crucially on our ability to\nquantitatively and objectively infer the perceived level of noxious stimuli\nfrom the behavior of animals. Here we develop a quantitative model to infer the\nperceived level of thermal nociception from the stereotyped nociceptive\nresponse of individual nematodes Caenorhabditis elegans stimulated by an IR\nlaser. The model provides a method for quantification of analgesic effects of\nchemical stimuli or genetic mutations in C. elegans. We test the nociception of\nibuprofen-treated worms and a TRPV (transient receptor potential) mutant, and\nwe show that the perception of thermal nociception for the ibuprofen treated\nworms is lower than the wild-type. At the same time, our model shows that the\nmutant changes the worm's behavior beyond affecting nociception. Finally, we\ndetermine the stimulus level that best distinguishes the analgesic effects and\nthe minimum number of worms that allow for a statistically significant\nidentification of these effects.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jan 2016 20:41:23 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Leung", "Kawai", ""], ["Mohammadi", "Aylia", ""], ["Ryu", "William S.", ""], ["Nemenman", "Ilya", ""]]}, {"id": "1601.04972", "submitter": "Robert Rosenbaum", "authors": "Ryan Pyle and Robert Rosenbaum", "title": "Highly connected neurons spike less frequently in balanced networks", "comments": null, "journal-ref": "Phys. Rev. E 93, 040302 (2016)", "doi": "10.1103/PhysRevE.93.040302", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many biological neuronal networks exhibit highly variable spiking activity.\nBalanced networks offer a parsimonious model of this variability. In balanced\nnetworks, strong excitatory synaptic inputs are canceled by strong inhibitory\ninputs on average and spiking activity is driven by transient breaks in this\nbalance. Most previous studies of balanced networks assume a homogeneous or\ndistance-dependent connectivity structure, but connectivity in biological\ncortical networks is more intricate. We use a heterogeneous mean-field theory\nof balanced networks to show that heterogeneous in-degrees can break balance,\nbut balance can be restored by heterogeneous out-degrees that are correlated\nwith in-degrees. In all examples considered, we find that highly connected\nneurons spike less frequently, consistent with recent experimental\nobservations.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 16:09:10 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Pyle", "Ryan", ""], ["Rosenbaum", "Robert", ""]]}, {"id": "1601.05065", "submitter": "James Shine", "authors": "James M. Shine, Oluwasanmi Koyejo, Russell A. Poldrack", "title": "Temporal meta-states are associated with differential patterns of\n  dynamic connectivity, network topology and attention", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": "10.1073/pnas.1604898113", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Little is currently known about the coordination of neural activity over\nlongitudinal time-scales and how these changes relate to behavior. To\ninvestigate this issue, we used resting-state fMRI data from a single\nindividual to identify the presence of two distinct temporal states that\nfluctuated over the course of 18 months. We then demonstrated that these\ntemporal states were associated with distinct neural dynamics within individual\nscanning sessions. In addition, the temporal states were also related to\nsignificant alterations in global efficiency, as well as differences in\nself-reported attention. These patterns were replicated in a separate\nlongitudinal dataset, providing further supportive evidence for the presence of\nfluctuations in functional network topology over time. Together, our results\nunderscore the importance of longitudinal phenotyping in cognitive\nneuroscience.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 20:28:00 GMT"}, {"version": "v2", "created": "Mon, 15 Aug 2016 23:53:14 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Shine", "James M.", ""], ["Koyejo", "Oluwasanmi", ""], ["Poldrack", "Russell A.", ""]]}, {"id": "1601.05113", "submitter": "Pedro Antonio Vald\\'es-Hern\\'andez", "authors": "Pedro A. Valdes-Hernandez, Jihye Bae, Yinchen Song, Akira Sumiyoshi,\n  Eduardo Aubert-Vazquez, Jorge J. Riera", "title": "Validating non-invasive EEG source imaging using optimal electrode\n  configurations on a representative rat head model", "comments": "27 pages, 2 tables and 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The curtain of technical limitations impeding rat multichannel non-invasive\nelectroencephalography (EEG) has risen. Given the importance of this\npreclinical model, development and validation of EEG source imaging (ESI) is\nessential. We investigate the validity of well-known human ESI methodologies in\nrats which individual tissue geometries have been approximated by those\nextracted from an MRI template, leading also to imprecision in electrode\nlocalizations. With the half and fifth sensitivity volumes we determine both\nthe theoretical minimum electrode separation for non-redundant scalp EEG\nmeasurements and the electrode sensitivity resolution, which vary over the\nscalp because of the head geometry. According to our results, electrodes should\nbe at least ~3-3.5 mm apart for an optimal configuration. The sensitivity\nresolution is generally worse for electrodes at the boundaries of the scalp\nmeasured region, though, by analogy with human montages, concentrates the\nsensitivity enough to localize sources. Cram\\'er-Rao lower bounds of source\nlocalization errors indicate it is theoretically possible to achieve ESI\naccuracy at the level of anatomical structures, such as the stimulus-specific\nsomatosensory areas, using the template. More validation for this approximation\nis provided through the comparison between the template and the individual lead\nfield matrices, for several rats. Finally, using well-accepted inverse methods,\nwe demonstrate that somatosensory ESI is not only expected but also allows\nexploring unknown phenomena related to global sensory integration. Inheriting\nthe advantages and pitfalls of human ESI, rat ESI will boost the understanding\nof brain pathophysiological mechanisms and the evaluation of ESI methodologies,\nnew pharmacological treatments and ESI-based biomarkers.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jan 2016 22:03:07 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2016 18:56:41 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Valdes-Hernandez", "Pedro A.", ""], ["Bae", "Jihye", ""], ["Song", "Yinchen", ""], ["Sumiyoshi", "Akira", ""], ["Aubert-Vazquez", "Eduardo", ""], ["Riera", "Jorge J.", ""]]}, {"id": "1601.06116", "submitter": "James Mnatzaganian", "authors": "James Mnatzaganian, Ernest Fokou\\'e, and Dhireesha Kudithipudi", "title": "A Mathematical Formalization of Hierarchical Temporal Memory's Spatial\n  Pooler", "comments": "This work was submitted for publication and is currently under\n  review. For associated code, see https://github.com/tehtechguy/mHTM", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical temporal memory (HTM) is an emerging machine learning algorithm,\nwith the potential to provide a means to perform predictions on spatiotemporal\ndata. The algorithm, inspired by the neocortex, currently does not have a\ncomprehensive mathematical framework. This work brings together all aspects of\nthe spatial pooler (SP), a critical learning component in HTM, under a single\nunifying framework. The primary learning mechanism is explored, where a maximum\nlikelihood estimator for determining the degree of permanence update is\nproposed. The boosting mechanisms are studied and found to be only relevant\nduring the initial few iterations of the network. Observations are made\nrelating HTM to well-known algorithms such as competitive learning and\nattribute bagging. Methods are provided for using the SP for classification as\nwell as dimensionality reduction. Empirical evidence verifies that given the\nproper parameterizations, the SP may be used for feature learning.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jan 2016 19:26:16 GMT"}, {"version": "v2", "created": "Thu, 31 Mar 2016 02:26:49 GMT"}, {"version": "v3", "created": "Thu, 8 Sep 2016 20:15:01 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Mnatzaganian", "James", ""], ["Fokou\u00e9", "Ernest", ""], ["Kudithipudi", "Dhireesha", ""]]}, {"id": "1601.06248", "submitter": "Takuya Koumura", "authors": "Takuya Koumura and Kazuo Okanoya", "title": "Automatic recognition of element classes and boundaries in the birdsong\n  with variable sequences", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0159188", "report-no": null, "categories": "q-bio.NC cs.LG cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Researches on sequential vocalization often require analysis of vocalizations\nin long continuous sounds. In such studies as developmental ones or studies\nacross generations in which days or months of vocalizations must be analyzed,\nmethods for automatic recognition would be strongly desired. Although methods\nfor automatic speech recognition for application purposes have been intensively\nstudied, blindly applying them for biological purposes may not be an optimal\nsolution. This is because, unlike human speech recognition, analysis of\nsequential vocalizations often requires accurate extraction of timing\ninformation. In the present study we propose automated systems suitable for\nrecognizing birdsong, one of the most intensively investigated sequential\nvocalizations, focusing on the three properties of the birdsong. First, a song\nis a sequence of vocal elements, called notes, which can be grouped into\ncategories. Second, temporal structure of birdsong is precisely controlled,\nmeaning that temporal information is important in song analysis. Finally, notes\nare produced according to certain probabilistic rules, which may facilitate the\naccurate song recognition. We divided the procedure of song recognition into\nthree sub-steps: local classification, boundary detection, and global\nsequencing, each of which corresponds to each of the three properties of\nbirdsong. We compared the performances of several different ways to arrange\nthese three steps. As results, we demonstrated a hybrid model of a deep neural\nnetwork and a hidden Markov model is effective in recognizing birdsong with\nvariable note sequences. We propose suitable arrangements of methods according\nto whether accurate boundary detection is needed. Also we designed the new\nmeasure to jointly evaluate the accuracy of note classification and boundary\ndetection. Our methods should be applicable, with small modification and\ntuning, to the songs in other species that hold the three properties of the\nsequential vocalization.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jan 2016 07:57:56 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Koumura", "Takuya", ""], ["Okanoya", "Kazuo", ""]]}, {"id": "1601.06420", "submitter": "Vaibhav Srivastava", "authors": "Vaibhav Srivastava and Philip Holmes and Patrick Simen", "title": "Explicit moments of decision times for single- and double-threshold\n  drift-diffusion processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.PR q-fin.MF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We derive expressions for the first three moments of the decision time (DT)\ndistribution produced via first threshold crossings by sample paths of a\ndrift-diffusion equation. The \"pure\" and \"extended\" diffusion processes are\nwidely used to model two-alternative forced choice decisions, and, while simple\nformulae for accuracy, mean DT and coefficient of variation are readily\navailable, third and higher moments and conditioned moments are not generally\navailable. We provide explicit formulae for these, describe their behaviors as\ndrift rates and starting points approach interesting limits, and, with the\nsupport of numerical simulations, discuss how trial-to-trial variability of\ndrift rates, starting points, and non-decision times affect these behaviors in\nthe extended diffusion model. Both unconditioned moments and those conditioned\non correct and erroneous responses are treated. We argue that the results will\nassist in exploring mechanisms of evidence accumulation and in fitting\nparameters to experimental data.\n", "versions": [{"version": "v1", "created": "Sun, 24 Jan 2016 19:31:44 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Srivastava", "Vaibhav", ""], ["Holmes", "Philip", ""], ["Simen", "Patrick", ""]]}, {"id": "1601.06749", "submitter": "Deirel Paz-Linares", "authors": "Deirel Paz-Linares, Mayrim Vega-Hern\\'andez, Pedro A. Rojas-L\\'opez,\n  Pedro A. Vald\\'es-Sosa and Eduardo Mart\\'inez-Montes", "title": "Empirical bayes formulation of the elastic net and mixed-norm models:\n  application to the eeg inverse problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The estimation of EEG generating sources constitutes an Inverse Problem (IP)\nin Neuroscience. This is an ill-posed problem, due to the non-uniqueness of the\nsolution, and many kinds of prior information have been used to constrain it. A\ncombination of smoothness (L2 norm-based) and sparseness (L1 norm-based)\nconstraints is a flexible approach that have been pursued by important examples\nsuch as the Elastic Net (ENET) and mixed-norm (MXN) models. The former is used\nto find solutions with a small number of smooth non-zero patches, while the\nlatter imposes sparseness and smoothness simultaneously along different\ndimensions of the spatio-temporal matrix solutions. Both models have been\naddressed within the penalized regression approach, where the regularization\nparameters are selected heuristically, leading usually to non-optimal\nsolutions. The existing Bayesian formulation of ENET allows hyperparameter\nlearning, but using computationally intensive Monte Carlo/Expectation\nMaximization methods. In this work we attempt to solve the EEG IP using a\nBayesian framework for models based on mixtures of L1/L2 norms penalization\nfunctions (Laplace/Normal priors) such as ENET and MXN. We propose a Sparse\nBayesian Learning algorithm based on combining the Empirical Bayes and the\niterative coordinate descent procedures to estimate both the parameters and\nhyperparameters. Using simple but realistic simulations we found that our\nmethods are able to recover complicated source setups more accurately and with\na more robust variable selection than the ENET and LASSO solutions using\nclassical algorithms. We also solve the EEG IP using data coming from a visual\nattention experiment, finding more interpretable neurophysiological patterns\nwith our methods, as compared with other known methods such as LORETA, ENET and\nLASSO FUSION using the classical regularization approach.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jan 2016 20:14:05 GMT"}, {"version": "v2", "created": "Sun, 7 Feb 2016 01:28:00 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Paz-Linares", "Deirel", ""], ["Vega-Hern\u00e1ndez", "Mayrim", ""], ["Rojas-L\u00f3pez", "Pedro A.", ""], ["Vald\u00e9s-Sosa", "Pedro A.", ""], ["Mart\u00ednez-Montes", "Eduardo", ""]]}, {"id": "1601.06999", "submitter": "Kelly Iarosz", "authors": "Ewandson L. Lameu, Fernando S. Borges, Rafael R. Borges, Kelly C.\n  Iarosz, Iber\\^e L. Caldas, Antonio M. Batista, Ricardo L. Viana, J\\\"urgen\n  Kurths", "title": "Suppression of neuronal phase synchronisation in cat cerebral cortex", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have studied effects of perturbations on the cat cerebral cortex.\nAccording to the literature, this cortex structure can be described by a\nclustered network. This way, we construct a clustered network with the same\nnumber of areas as in the cat matrix, where each area is described as a\nsub-network with small-world property. We focus on the suppression of neuronal\nphase synchronisation considering different kinds of perturbations. Among the\nvarious controlling interventions, we choose three methods: delayed feedback\ncontrol, external time-periodic driving, and activation of selected neurons. We\nsimulate these interventions to provide a procedure to suppress undesired and\npathological abnormal rhythms that can be associated with many forms of\nsynchronisation. In our simulations, we have verified that the efficiency of\nsynchronisation suppression by delayed feedback control is higher than external\ntime-periodic driving and activation of selected neurons for the cat cerebral\ncortex with the same coupling strengths.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 12:54:07 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Lameu", "Ewandson L.", ""], ["Borges", "Fernando S.", ""], ["Borges", "Rafael R.", ""], ["Iarosz", "Kelly C.", ""], ["Caldas", "Iber\u00ea L.", ""], ["Batista", "Antonio M.", ""], ["Viana", "Ricardo L.", ""], ["Kurths", "J\u00fcrgen", ""]]}, {"id": "1601.07054", "submitter": "Massimiliano Zanin", "authors": "Massimiliano Zanin", "title": "On causality of extreme events", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple metrics have been developed to detect causality relations between\ndata describing the elements constituting complex systems, all of them\nconsidering their evolution through time. Here we propose a metric able to\ndetect causality within static data sets, by analysing how extreme events in\none element correspond to the appearance of extreme events in a second one. The\nmetric is able to detect non- linear causalities; to analyse both\ncross-sectional and longitudinal data sets; and to discriminate between real\ncausalities and correlations caused by confounding factors. We validate the\nmetric through synthetic data, dynamical and chaotic systems, and data\nrepresenting the human brain activity in a cognitive task. We further show how\nthe proposed metric is able to outperform classical causality metrics, provided\nnon-linear relationships are present and large enough data sets are available.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 14:57:40 GMT"}, {"version": "v2", "created": "Wed, 2 Mar 2016 12:37:12 GMT"}, {"version": "v3", "created": "Thu, 19 May 2016 11:23:06 GMT"}], "update_date": "2016-05-20", "authors_parsed": [["Zanin", "Massimiliano", ""]]}, {"id": "1601.07126", "submitter": "Marc de Kamps", "authors": "Yi Ming Lai and Marc de Kamps", "title": "Population Density Equations for Stochastic Processes with Memory\n  Kernels", "comments": null, "journal-ref": "Phys. Rev. E 95, 062125 (2017)", "doi": "10.1103/PhysRevE.95.062125", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method for solving population density equations (PDEs),\nwhere the populations can be subject to non-Markov noise for arbitrary\ndistributions of jump sizes. The method combines recent developments in two\ndifferent disciplines that traditionally have had limited interaction:\ncomputational neuroscience and the theory of random networks. The method uses a\ngeometric binning scheme, based on the method of characteristics, to capture\nthe deterministic neurodynamics of the population, separating the deterministic\nand stochastic process cleanly. We can independently vary the choice of the\ndeterministic model and the model for the stochastic process, leading to a\nhighly modular numerical solution strategy. We demonstrate this by replacing\nthe Master equation implicit in many formulations of the PDE formalism, by a\ngeneralization called the generalized Montroll-Weiss equation - a recent result\nfrom random network theory - describing a random walker subject to transitions\nrealized by a non-Markovian process. We demonstrate the method for leaky- (LIF)\nand quadratic-integrate and fire (QIF) neurons subject to spike trains with\nPoisson and gamma distributed spike intervals. We are able to model jump\nresponses for both models accurately to both excitatory and inhibitory input\nunder the assumption that all inputs are generated by one renewal process.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jan 2016 18:35:09 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 10:12:27 GMT"}, {"version": "v3", "created": "Mon, 6 Feb 2017 23:30:52 GMT"}, {"version": "v4", "created": "Wed, 17 May 2017 11:42:21 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Lai", "Yi Ming", ""], ["de Kamps", "Marc", ""]]}, {"id": "1601.07534", "submitter": "Henning U. Voss", "authors": "Henning U. Voss", "title": "The leaky integrator with recurrent inhibition as a predictor", "comments": "1 figure included in text. published as a note", "journal-ref": "Neural Computation 28, 1498-1502 (2016)", "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is shown that the leaky integrator, the basis for many neuronal models,\npossesses a negative group delay when a time-delayed recurrent inhibition is\nadded to it. By means of this negative group delay, the leaky integrator\nbecomes a predictor for some frequency components of the input signal. The\nprediction properties are derived analytically and an application to a local\nfield potential is provided.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 20:20:57 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2016 18:41:28 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2016 20:23:11 GMT"}], "update_date": "2016-07-29", "authors_parsed": [["Voss", "Henning U.", ""]]}, {"id": "1601.07574", "submitter": "Tiziano Squartini", "authors": "Giampiero Bardella, Angelo Bifone, Andrea Gabrielli, Alessandro Gozzi,\n  Tiziano Squartini", "title": "Hierarchical organization of functional connectivity in the mouse brain:\n  a complex network approach", "comments": "11 pages, 9 figures", "journal-ref": "Sci. Rep. 6 (32060) (2016)", "doi": "10.1038/srep32060", "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper represents a contribution to the study of the brain functional\nconnectivity from the perspective of complex networks theory. More\nspecifically, we apply graph theoretical analyses to provide evidence of the\nmodular structure of the mouse brain and to shed light on its hierarchical\norganization. We propose a novel percolation analysis and we apply our approach\nto the analysis of a resting-state functional MRI data set from 41 mice. This\napproach reveals a robust hierarchical structure of modules persistent across\ndifferent subjects. Importantly, we test this approach against a statistical\nbenchmark (or null model) which constrains only the distributions of empirical\ncorrelations. Our results unambiguously show that the hierarchical character of\nthe mouse brain modular structure is not trivially encoded into this\nlower-order constraint. Finally, we investigate the modular structure of the\nmouse brain by computing the Minimal Spanning Forest, a technique that\nidentifies subnetworks characterized by the strongest internal correlations.\nThis approach represents a faster alternative to other community detection\nmethods and provides a means to rank modules on the basis of the strength of\ntheir internal edges.\n", "versions": [{"version": "v1", "created": "Wed, 27 Jan 2016 21:30:06 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Bardella", "Giampiero", ""], ["Bifone", "Angelo", ""], ["Gabrielli", "Andrea", ""], ["Gozzi", "Alessandro", ""], ["Squartini", "Tiziano", ""]]}, {"id": "1601.07620", "submitter": "Brian DePasquale", "authors": "Brian DePasquale, Mark M. Churchland, L.F. Abbott", "title": "Using Firing-Rate Dynamics to Train Recurrent Networks of Spiking Model\n  Neurons", "comments": "17 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks are powerful tools for understanding and modeling\ncomputation and representation by populations of neurons. Continuous-variable\nor \"rate\" model networks have been analyzed and applied extensively for these\npurposes. However, neurons fire action potentials, and the discrete nature of\nspiking is an important feature of neural circuit dynamics. Despite significant\nadvances, training recurrently connected spiking neural networks remains a\nchallenge. We present a procedure for training recurrently connected spiking\nnetworks to generate dynamical patterns autonomously, to produce complex\ntemporal outputs based on integrating network input, and to model physiological\ndata. Our procedure makes use of a continuous-variable network to identify\ntargets for training the inputs to the spiking model neurons. Surprisingly, we\nare able to construct spiking networks that duplicate tasks performed by\ncontinuous-variable networks with only a relatively minor expansion in the\nnumber of neurons. Our approach provides a novel view of the significance and\nappropriate use of \"firing rate\" models, and it is a useful approach for\nbuilding model spiking networks that can be used to address important questions\nabout representation and computation in neural systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 01:48:42 GMT"}], "update_date": "2016-01-29", "authors_parsed": [["DePasquale", "Brian", ""], ["Churchland", "Mark M.", ""], ["Abbott", "L. F.", ""]]}, {"id": "1601.07740", "submitter": "Eva M. Navarro-L\\'opez Dr.", "authors": "Utku \\c{C}elikok, Eva M. Navarro-L\\'opez, Neslihan S. \\c{S}eng\\\"or", "title": "A computational model describing the interplay of basal ganglia and\n  subcortical background oscillations during working memory processes", "comments": "35 pages, 31 figures. This paper has not been published in any\n  conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working memory is responsible for the temporary manipulation and storage of\ninformation to support reasoning, learning and comprehension in the human\nbrain. Background oscillations from subcortical structures may drive a gating\nor switching mechanism during working memory computations, and different\nfrequency bands may be associated with different processes while working memory\ntasks are performed. There are three well-known relationships between working\nmemory processes and specific frequency bands of subcortical oscillations,\nnamely: the storage of new information which correlates positively with\nbeta/gamma-frequency band oscillations, the maintenance of information while\nignoring irrelevant stimulation which is directly linked to theta-frequency\nband oscillations, and the clearance of memory which is associated with\nalpha-frequency band oscillations. Although these relationships between working\nmemory processes and subcortical background oscillations have been observed, a\nfull explanation of these phenomena is still needed. This paper will aid\nunderstanding of the working memory's operation and phase switching by\nproposing a novel and biophysical realistic mathematical-computational\nframework which unifies the generation of subcortical background oscillations,\nthe role of basal ganglia-thalamo-cortical circuits and the influence of\ndopamine in the selection of working memory operations and phases: this has\nnever been attempted before.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 12:43:49 GMT"}], "update_date": "2016-01-29", "authors_parsed": [["\u00c7elikok", "Utku", ""], ["Navarro-L\u00f3pez", "Eva M.", ""], ["\u015eeng\u00f6r", "Neslihan S.", ""]]}, {"id": "1601.07766", "submitter": "Luca Puviani", "authors": "Luca Puviani, Sidita Rama, Giorgio Vitetta", "title": "Prediction Errors Drive UCS Revaluation and not Classical Conditioning:\n  Evidence and Neurophysiological Consequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the experimental study of emotional learning is commonly based on\nclassical conditioning paradigms and models, which have been thoroughly\ninvestigated in the last century. On the contrary, limited attention has been\npaid to the revaluation of an unconditioned stimulus (UCS), which, as\nexperimentally observed by various researchers in the last four decades, occurs\nout of classical conditioning. For this reason, no analytical or quantitative\ntheory has been developed for this phenomenon and its dynamics. Unluckily,\nmodels based on classical conditioning are unable to explain or predict\nimportant psychophysiological phenomena, such as the failure of the extinction\nof emotional responses in certain circumstances. In this manuscript an\nanalytical representation of UCS revaluation learning is developed; this allows\nus to identify the conditions determining the \"inextinguishability\" (or\nresistant-to-extinction) property of emotional responses and reactions (such as\nthose observed in evaluative conditioning, in the nonreinforcement presentation\nof a conditioned inhibitor, in post-traumatic stress disorders and in panic\nattacks). Furthermore, an analysis of the causal relation existing between\nclassical conditioning and UCS revaluation is provided. Starting from this\nresult, a theory of implicit emotional learning and a novel interpretation of\nclassical conditioning are derived. Moreover, we discuss how the proposed\ntheory can lead to the development of new methodologies for the detection and\nthe treatment of undesired or pathological emotional responses, and can inspire\nanimal models for resistant-to-extinction responses and reactions.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 14:12:22 GMT"}], "update_date": "2016-01-29", "authors_parsed": [["Puviani", "Luca", ""], ["Rama", "Sidita", ""], ["Vitetta", "Giorgio", ""]]}, {"id": "1601.07810", "submitter": "Andreas N\\\"u{\\ss}ing", "authors": "Andreas N\\\"u{\\ss}ing, Carsten H. Wolters, Heinrich Brinck, Christian\n  Engwer", "title": "The Unfitted Discontinuous Galerkin Method for Solving the EEG Forward\n  Problem", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE math.NA q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: The purpose of this study is to introduce and evaluate the\nunfitted discontinuous Galerkin finite element method (UDG-FEM) for solving the\nelectroencephalography (EEG) forward problem. Methods: This new approach for\nsource analysis does not use a geometry conforming volume triangulation, but\ninstead uses a structured mesh that does not resolve the geometry. The geometry\nis described using level set functions and is incorporated implicitly in its\nmathematical formulation. As no triangulation is necessary, the complexity of a\nsimulation pipeline and the need for manual interaction for patient specific\nsimulations can be reduced and is comparable with that of the FEM for\nhexahedral meshes. In addition, it maintains conservation laws on a discrete\nlevel. Here, we present the theory for UDG-FEM forward modeling, its\nverification using quasi-analytical solutions in multi-layer sphere models and\nan evaluation in a comparison with a discontinuous Galerkin (DG-FEM) method on\nhexahedral and on conforming tetrahedral meshes. We furthermore apply the\nUDG-FEM forward approach in a realistic head model simulation study. Results:\nThe given results show convergence and indicate a good overall accuracy of the\nUDG-FEM approach. UDG-FEM performs comparable or even better than DG-FEM on a\nconforming tetrahedral mesh while providing a less complex simulation pipeline.\nWhen compared to DG-FEM on hexahedral meshes, an overall better accuracy is\nachieved. Conclusion: The UDG-FEM approach is an accurate, flexible and\npromising method to solve the EEG forward problem. Significance: This study\nshows the first application of the UDG-FEM approach to the EEG forward problem.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 16:02:50 GMT"}, {"version": "v2", "created": "Mon, 2 May 2016 08:27:17 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["N\u00fc\u00dfing", "Andreas", ""], ["Wolters", "Carsten H.", ""], ["Brinck", "Heinrich", ""], ["Engwer", "Christian", ""]]}, {"id": "1601.07867", "submitter": "John Medaglia", "authors": "John D. Medaglia, Weiyu Huang, Santiago Segarra, Christopher Olm,\n  James Gee, Murray Grossman, Alejandro Ribeiro, Corey T. McMillan, Danielle S.\n  Bassett", "title": "Brain network efficiency is influenced by pathological source of\n  corticobasal syndrome", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal neuroimaging studies of corticobasal syndrome using volumetric MRI\nand DTI successfully discriminate between Alzheimer's disease and\nfrontotemporal lobar degeneration but this evidence has typically included\nclinically heterogeneous patient cohorts and has rarely assessed the network\nstructure of these distinct sources of pathology. Using structural MRI data, we\nidentify areas in fronto-temporo-parietal cortex with reduced gray matter\ndensity in corticobasal syndrome relative to age matched controls. A support\nvector machine procedure demonstrates that gray matter density poorly\ndiscriminates between frontotemporal lobar degeneration and Alzheimer's disease\npathology subgroups with low sensitivity and specificity. In contrast, a\nstatistic of local network efficiency demonstrates excellent discriminatory\npower, with high sensitivity and specificity. Our results indicate that the\nunderlying pathological sources of corticobasal syndrome can be classified more\naccurately using graph theoretical statistics of white matter microstructure in\nassociation cortex than by regional gray matter density alone. These results\nhighlight the importance of a multimodal neuroimaging approach to diagnostic\nanalyses of corticobasal syndrome and suggest that distinct sources of\npathology mediate the circuitry of brain regions affected by corticobasal\nsyndrome.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 19:12:44 GMT"}], "update_date": "2016-01-29", "authors_parsed": [["Medaglia", "John D.", ""], ["Huang", "Weiyu", ""], ["Segarra", "Santiago", ""], ["Olm", "Christopher", ""], ["Gee", "James", ""], ["Grossman", "Murray", ""], ["Ribeiro", "Alejandro", ""], ["McMillan", "Corey T.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1601.07881", "submitter": "Richard Betzel", "authors": "Richard F. Betzel, Theodore D. Satterthwaite, Joshua I. Gold, Danielle\n  S. Bassett", "title": "A positive mood, a flexible brain", "comments": "15 pages, 15 figures + 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flexible reconfiguration of human brain networks supports cognitive\nflexibility and learning. However, modulating flexibility to enhance learning\nrequires an understanding of the relationship between flexibility and brain\nstate. In an unprecedented longitudinal data set, we investigate the\nrelationship between flexibility and mood, demonstrating that flexibility is\npositively correlated with emotional state. Our results inform the modulation\nof brain state to enhance response to training in health and injury.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2016 20:00:09 GMT"}], "update_date": "2016-01-29", "authors_parsed": [["Betzel", "Richard F.", ""], ["Satterthwaite", "Theodore D.", ""], ["Gold", "Joshua I.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1601.08165", "submitter": "Emanuele Olivetti", "authors": "Thien Bao Nguyen, Emanuele Olivetti, Paolo Avesani", "title": "Mapping Tractography Across Subjects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion magnetic resonance imaging (dMRI) and tractography provide means to\nstudy the anatomical structures within the white matter of the brain. When\nstudying tractography data across subjects, it is usually necessary to align,\ni.e. to register, tractographies together. This registration step is most often\nperformed by applying the transformation resulting from the registration of\nother volumetric images (T1, FA). In contrast with registration methods that\n\"transform\" tractographies, in this work, we try to find which streamline in\none tractography correspond to which streamline in the other tractography,\nwithout any transformation. In other words, we try to find a \"mapping\" between\nthe tractographies. We propose a graph-based solution for the tractography\nmapping problem and we explain similarities and differences with the related\nwell-known graph matching problem. Specifically, we define a loss function\nbased on the pairwise streamline distance and reformulate the mapping problem\nas combinatorial optimization of that loss function. We show preliminary\npromising results where we compare the proposed method, implemented with\nsimulated annealing, against a standard registration techniques in a task of\nsegmentation of the corticospinal tract.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 15:50:20 GMT"}], "update_date": "2016-02-01", "authors_parsed": [["Nguyen", "Thien Bao", ""], ["Olivetti", "Emanuele", ""], ["Avesani", "Paolo", ""]]}]