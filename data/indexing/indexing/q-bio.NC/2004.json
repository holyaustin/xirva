[{"id": "2004.00055", "submitter": "Simon DeDeo", "authors": "Scott Viteri and Simon DeDeo", "title": "Explosive Proofs of Mathematical Truths", "comments": "16 pages, 5 figures. Comments solicited", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.AI math.HO physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematical proofs are both paradigms of certainty and some of the most\nexplicitly-justified arguments that we have in the cultural record. Their very\nexplicitness, however, leads to a paradox, because their probability of error\ngrows exponentially as the argument expands. Here we show that under a\ncognitively-plausible belief formation mechanism that combines deductive and\nabductive reasoning, mathematical arguments can undergo what we call an\nepistemic phase transition: a dramatic and rapidly-propagating jump from\nuncertainty to near-complete confidence at reasonable levels of claim-to-claim\nerror rates. To show this, we analyze an unusual dataset of forty-eight\nmachine-aided proofs from the formalized reasoning system Coq, including major\ntheorems ranging from ancient to 21st Century mathematics, along with four\nhand-constructed cases from Euclid, Apollonius, Spinoza, and Andrew Wiles. Our\nresults bear both on recent work in the history and philosophy of mathematics,\nand on a question, basic to cognitive science, of how we form beliefs, and\njustify them to others.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:39:56 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Viteri", "Scott", ""], ["DeDeo", "Simon", ""]]}, {"id": "2004.00058", "submitter": "Larissa Albantakis", "authors": "Larissa Albantakis, Francesco Massari, Maggie Beheler-Amass and Giulio\n  Tononi", "title": "A macro agent and its actions", "comments": "18 pages, 5 figures; to appear as a chapter in \"Top-Down Causation\n  and Emergence\" published by Springer as part of the Synthese Library Book\n  Series; F.M. and M.B. contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.NE q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In science, macro level descriptions of the causal interactions within\ncomplex, dynamical systems are typically deemed convenient, but ultimately\nreducible to a complete causal account of the underlying micro constituents.\nYet, such a reductionist perspective is hard to square with several issues\nrelated to autonomy and agency: (1) agents require (causal) borders that\nseparate them from the environment, (2) at least in a biological context,\nagents are associated with macroscopic systems, and (3) agents are supposed to\nact upon their environment. Integrated information theory (IIT) (Oizumi et al.,\n2014) offers a quantitative account of causation based on a set of causal\nprinciples, including notions such as causal specificity, composition, and\nirreducibility, that challenges the reductionist perspective in multiple ways.\nFirst, the IIT formalism provides a complete account of a system's causal\nstructure, including irreducible higher-order mechanisms constituted of\nmultiple system elements. Second, a system's amount of integrated information\n($\\Phi$) measures the causal constraints a system exerts onto itself and can\npeak at a macro level of description (Hoel et al., 2016; Marshall et al.,\n2018). Finally, the causal principles of IIT can also be employed to identify\nand quantify the actual causes of events (\"what caused what\"), such as an\nagent's actions (Albantakis et al., 2019). Here, we demonstrate this framework\nby example of a simulated agent, equipped with a small neural network, that\nforms a maximum of $\\Phi$ at a macro scale.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 18:51:18 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Albantakis", "Larissa", ""], ["Massari", "Francesco", ""], ["Beheler-Amass", "Maggie", ""], ["Tononi", "Giulio", ""]]}, {"id": "2004.00498", "submitter": "Jordi Garcia-Ojalvo", "authors": "Miguel A. Casal, Santiago Galella, Oscar Vilarroya and Jordi\n  Garcia-Ojalvo", "title": "Soft-wired long-term memory in a natural recurrent neuronal network", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": "10.1063/5.0009709", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.CD physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal networks provide living organisms with the ability to process\ninformation. They are also characterized by abundant recurrent connections,\nwhich give rise to strong feedback that dictates their dynamics and endows them\nwith fading (short-term) memory. The role of recurrence in long-term memory, on\nthe other hand, is still unclear. Here we use the neuronal network of the\nroundworm C. elegans to show that recurrent architectures in living organisms\ncan exhibit long-term memory without relying on specific hard-wired modules. A\ngenetic algorithm reveals that the experimentally observed dynamics of the\nworm's neuronal network exhibits maximal complexity (as measured by permutation\nentropy). In that complex regime, the response of the system to repeated\npresentations of a time-varying stimulus reveals a consistent behavior that can\nbe interpreted as soft-wired long-term memory.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 15:22:36 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Casal", "Miguel A.", ""], ["Galella", "Santiago", ""], ["Vilarroya", "Oscar", ""], ["Garcia-Ojalvo", "Jordi", ""]]}, {"id": "2004.01254", "submitter": "Constantin Waubert de Puiseau", "authors": "Richard Meyes, Constantin Waubert de Puiseau, Andres Posada-Moreno,\n  Tobias Meisen", "title": "Under the Hood of Neural Networks: Characterizing Learned\n  Representations by Functional Neuron Populations and Network Ablations", "comments": "17 pages, 14 figures, adjusted \"under review\" statement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for more transparency of the decision-making processes in artificial\nneural networks steadily increases driven by their applications in safety\ncritical and ethically challenging domains such as autonomous driving or\nmedical diagnostics. We address today's lack of transparency of neural networks\nand shed light on the roles of single neurons and groups of neurons within the\nnetwork fulfilling a learned task. Inspired by research in the field of\nneuroscience, we characterize the learned representations by activation\npatterns and network ablations, revealing functional neuron populations that a)\nact jointly in response to specific stimuli or b) have similar impact on the\nnetwork's performance after being ablated. We find that neither a neuron's\nmagnitude or selectivity of activation, nor its impact on network performance\nare sufficient stand-alone indicators for its importance for the overall task.\nWe argue that such indicators are essential for future advances in transfer\nlearning and modern neuroscience.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 20:45:01 GMT"}, {"version": "v2", "created": "Mon, 11 May 2020 09:09:15 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Meyes", "Richard", ""], ["de Puiseau", "Constantin Waubert", ""], ["Posada-Moreno", "Andres", ""], ["Meisen", "Tobias", ""]]}, {"id": "2004.01665", "submitter": "Fidel Santamaria", "authors": "Horacio G. Rotstein and Fidel Santamaria", "title": "Present and future frameworks of theoretical neuroscience: outcomes of a\n  community discussion", "comments": "Workshop outcomes, 9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We organized a workshop on the \"Present and Future Frameworks of Theoretical\nNeuroscience\", with the support of the National Science Foundation. The\nobjective was to identify the challenges and strategies that this field will\nneed to tackle in order to incorporate vast and multi-scale streams of\nexperimental data from the technologies developed by the BRAIN initiative. The\nparticipants, divided in workgroups, identified five key areas that, while not\nexhaustive, cover multiple aspects of current challenges needed to be\ndeveloped: Dynamics-statistics; multi-scale integration; coding; brain-body\nintegration; and structure of neuroscience theories. While each area is\ndifferent, there were coincidences on finding theoretical paths to incorporate\nbiophysics, energetics, and ethology with more abstract coding and\ncomputational approaches. Each workgroup has continued to work after the\nmeeting to develop the ideas seeded there, which are started to being\npublished. Here, we provide a perspective of the discussions of each workgroup\nthat point to building on the present foundations of theoretical neuroscience\nand extend them by incorporating multi-scale information with the objective of\nproviding mechanistic insights into the nervous system.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 16:38:31 GMT"}], "update_date": "2020-04-06", "authors_parsed": [["Rotstein", "Horacio G.", ""], ["Santamaria", "Fidel", ""]]}, {"id": "2004.01834", "submitter": "Pedro Henrique Juliano Nardelli", "authors": "Renan C. Moioli, Pedro H. J. Nardelli, Michael Taynnan Barros, Walid\n  Saad, Amin Hekmatmanesh, Pedro G\\'oria, Arthur S. de Sena, Merim Dzaferagic,\n  Harun Siljak, Werner van Leekwijck, Dick Carrillo, Steven Latr\\'e", "title": "Neurosciences and 6G: Lessons from and Needs of Communicative Brains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.ET cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the first comprehensive tutorial on a promising research\nfield located at the frontier of two well-established domains: Neurosciences\nand wireless communications, motivated by the ongoing efforts to define how the\nsixth generation of mobile networks (6G) will be. In particular, this tutorial\nfirst provides a novel integrative approach that bridges the gap between these\ntwo, seemingly disparate fields. Then, we present the state-of-the-art and key\nchallenges of these two topics. In particular, we propose a novel\nsystematization that divides the contributions into two groups, one focused on\nwhat neurosciences will offer to 6G in terms of new applications and systems\narchitecture (Neurosciences for Wireless), and the other focused on how\nwireless communication theory and 6G systems can provide new ways to study the\nbrain (Wireless for Neurosciences). For the first group, we concretely explain\nhow current scientific understanding of the brain would enable new application\nfor 6G within the context of a new type of service that we dub braintype\ncommunications and that has more stringent requirements than human- and\nmachine-type communication. In this regard, we expose the key requirements of\nbrain-type communication services and we discuss how future wireless networks\ncan be equipped to deal with such services. Meanwhile, for the second group, we\nthoroughly explore modern communication system paradigms, including Internet of\nBio-nano Things and chaosbased communications, in addition to highlighting how\ncomplex systems tools can help bridging 6G and neuroscience applications.\nBrain-controlled vehicles are then presented as our case study. All in all,\nthis tutorial is expected to provide a largely missing articulation between\nthese two emerging fields while delineating concrete ways to move forward in\nsuch an interdisciplinary endeavor.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2020 01:58:54 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Moioli", "Renan C.", ""], ["Nardelli", "Pedro H. J.", ""], ["Barros", "Michael Taynnan", ""], ["Saad", "Walid", ""], ["Hekmatmanesh", "Amin", ""], ["G\u00f3ria", "Pedro", ""], ["de Sena", "Arthur S.", ""], ["Dzaferagic", "Merim", ""], ["Siljak", "Harun", ""], ["van Leekwijck", "Werner", ""], ["Carrillo", "Dick", ""], ["Latr\u00e9", "Steven", ""]]}, {"id": "2004.02318", "submitter": "Corey Weistuch", "authors": "Corey Weistuch, Luca Agozzino, Lilianne R. Mujica-Parodi, and Ken A.\n  Dill", "title": "Inferring a network from dynamical signals at its nodes", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1008435", "report-no": null, "categories": "physics.bio-ph physics.data-an q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an approximate solution to the difficult inverse problem of inferring\nthe topology of an unknown network from given time-dependent signals at the\nnodes. For example, we measure signals from individual neurons in the brain,\nand infer how they are inter-connected. We use Maximum Caliber as an inference\nprinciple. The combinatorial challenge of high-dimensional data is handled\nusing two different approximations to the pairwise couplings. We show two\nproofs of principle: in a nonlinear genetic toggle switch circuit, and in a toy\nneural network.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2020 21:17:33 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 15:54:00 GMT"}, {"version": "v3", "created": "Thu, 3 Sep 2020 16:27:17 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Weistuch", "Corey", ""], ["Agozzino", "Luca", ""], ["Mujica-Parodi", "Lilianne R.", ""], ["Dill", "Ken A.", ""]]}, {"id": "2004.02450", "submitter": "Ludovic Sacchelli", "authors": "Ugo Boscain (LJLL (UMR\\_7598), CNRS, CaGE ), Dario Prandi (CNRS, L2S),\n  Ludovic Sacchelli (LAGEPP), Giuseppina Turco (CNRS, LLF UMR7110)", "title": "A bio-inspired geometric model for sound reconstruction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS math.AP math.OC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconstruction mechanisms built by the human auditory system during sound\nreconstruction are still a matter of debate. The purpose of this study is to\npropose a mathematical model of sound reconstruction based on the functional\narchitecture of the auditory cortex (A1). The model is inspired by the\ngeometrical modelling of vision, which has undergone a great development in the\nlast ten years. There are however fundamental dissimilarities, due to the\ndifferent role played by the time and the different group of symmetries. The\nalgorithm transforms the degraded sound in an 'image' in the time-frequency\ndomain via a short-time Fourier transform. Such an image is then lifted in the\nHeisenberg group and it is reconstructed via a Wilson-Cowan differo-integral\nequation. Preliminary numerical experiments are provided, showing the good\nreconstruction properties of the algorithm on synthetic sounds concentrated\naround two frequencies.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 07:47:32 GMT"}, {"version": "v2", "created": "Mon, 19 Oct 2020 13:10:07 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Boscain", "Ugo", "", "LJLL"], ["Prandi", "Dario", "", "CNRS, L2S"], ["Sacchelli", "Ludovic", "", "LAGEPP"], ["Turco", "Giuseppina", "", "CNRS, LLF UMR7110"]]}, {"id": "2004.02702", "submitter": "Guy Ropars", "authors": "Albert Le Floch, Samuel Henriat, Rosane Fourage, Guy Ropars", "title": "Postural instability in a young dyslexic adult improved by Hebbian\n  pulse-width modulated lighting", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Postural stability is linked to vision in everyone, since when the eyes are\nclosed stability decreases by a factor of 2 or more. However, in persons with\ndyslexia postural stability is often deficient even when the eyes are open,\nsince they show deficits in motor as well as specific cognitive functions. In\ndyslexics we have shown that abnormal symmetry between retinal Maxwell's\ncentroid outlines occurs, perturbing the interhemispheric connections. We have\nalso shown that pulse-width modulated lighting can compensate for this lack of\nasymmetry, improving the reading skills. As the postural stability and the\nvision are correlated, one may wonder if the excess of the postural instability\nrecorded in a young adult with dyslexia can also be reduced by a pulse-width\nmodulated light controlling the Hebbian synaptic plasticity. Using a force\nplatform we compared the postural responses of an observer without dyslexia\nwith the responses of a subject with dyslexia, by measuring their respective\nstanding postures with eyes open looking at a target in a room with either\ncontinuous or pulse lighting. There was no effect of changing the lighting\nconditions on the postural control of the subject without dyslexia. However, we\nfound that the postural stability of the subject with dyslexia which was\nactually impaired during continuous light, but was greatly improved when a 80\nHz pulsed light frequency was used. Importantly, the excursions of the surface\narea of the center of pressure on the force platform were reduced by a factor\nof 2.3.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 14:31:01 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Floch", "Albert Le", ""], ["Henriat", "Samuel", ""], ["Fourage", "Rosane", ""], ["Ropars", "Guy", ""]]}, {"id": "2004.02873", "submitter": "Lorenzo Resca Dr.", "authors": "Lorenzo Resca, Pamela M. Greenwood, Terrance D. Keech", "title": "How do eyes and brain search a randomly structured uninformative scene?\n  Exploiting a basic interplay of attention and memory", "comments": "https://novapublishers.com/shop/eye-movement-developmental-perspectives-dysfunctions-and-disorders-in-humans/\n  This Chapter is granted OPEN ACCESS. Click at the above LINK on the tab on\n  \"Table of Contents\"", "journal-ref": "Eye Movement: Developmental Perspectives, Dysfunctions and\n  Disorders in Humans, Ed. L. C. Stewart, Chapter 1, pp. 1-48, 2013. NOVA\n  Science Publisher, Inc., ISBN: 978-1-62808-601-0", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tracked the eye movements of seven young and seven older adults performing\na conjunctive visual search task similar to that performed by two highly\ntrained monkeys in an original influential study of Motter and Belky (1998a,\n1998b). We obtained results consistent with theirs regarding elements of\nperception, selection, attention and object recognition, but we found a much\ngreater role played by long-range memory. A design inadequacy in the original\nMotter-Belky study is not sufficient to explain such discrepancy, nor is the\nhigh level of training of their monkeys. Perhaps monkeys and humans do not use\nmnemonic resources compatibly already in basic visual search tasks, contrary to\na common expectation, further supported by cortical representation studies. We\nalso found age-related differences in various measures of eye movements,\nconsistently indicating slightly reduced conspicuity areas for the older\nadults, hence, correspondingly reduced processing and memory capacities.\nHowever, because of sample size and age differential limitations, statistically\nsignificant differences were found only for a few variables, most notably\noverall reaction times. Results reported here provide the basis for\ndemonstrating the formation of spiraling or circulating patterns in the eye\nmovement trajectories and for developing corresponding computational models and\nsimulations.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 01:49:03 GMT"}], "update_date": "2020-04-08", "authors_parsed": [["Resca", "Lorenzo", ""], ["Greenwood", "Pamela M.", ""], ["Keech", "Terrance D.", ""]]}, {"id": "2004.03059", "submitter": "Brittany H Scheid", "authors": "Brittany H. Scheid, Arian Ashourvan, Jennifer Stiso, Kathryn A. Davis,\n  Fadi Mikhail, Fabio Pasqualetti, Brian Litt, Danielle S. Bassett", "title": "Time-evolving controllability of effective connectivity networks during\n  seizure progression", "comments": "Main text is 7 pages and contains 4 figures, supplement is 17 pages\n  and contains 9 figures and one table", "journal-ref": "PNAS 2021 Vol. 118 No. 5", "doi": "10.1073/pnas.2006436118", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Over one third of the estimated 3 million people with epilepsy in the US are\nmedication resistant. Responsive neurostimulation from chronically implanted\nelectrodes provides a promising treatment option and alternative to resective\nsurgery. However, determining personalized optimal stimulation parameters,\nincluding when and where to intervene to guarantee a positive patient outcome,\nis a major open challenge. Network neuroscience and control theory offer useful\ntools that may guide improvements in parameter selection for control of\nanomalous neural activity. Here we use a novel method to characterize dynamic\ncontrollability across consecutive effective connectivity (EC) networks based\non regularized partial correlations between implanted electrodes during the\nonset, propagation, and termination phases of thirty-four seizures. We estimate\nregularized partial correlation adjacency matrices from one-second time windows\nof intracranial electrocorticography recordings using the Graphical Least\nAbsolute Shrinkage and Selection Operator (GLASSO). Average and modal\ncontrollability metrics calculated from each resulting EC network track the\ntime-varying controllability of the brain on an evolving landscape of\nconditionally dependent network interactions. We show that average\ncontrollability increases throughout a seizure and is negatively correlated\nwith modal controllability throughout. Furthermore, our results support the\nhypothesis that the energy required to drive the brain to a seizure-free state\nfrom an ictal state is smallest during seizure onset; yet, we find that\napplying control energy at electrodes in the seizure onset zone may not always\nbe energetically favorable. Our work suggests that a low-complexity model of\ntime-evolving controllability may offer new insights for developing and\nimproving control strategies targeting seizure suppression.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 00:57:25 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Scheid", "Brittany H.", ""], ["Ashourvan", "Arian", ""], ["Stiso", "Jennifer", ""], ["Davis", "Kathryn A.", ""], ["Mikhail", "Fadi", ""], ["Pasqualetti", "Fabio", ""], ["Litt", "Brian", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "2004.03541", "submitter": "Erik Hoel", "authors": "Johannes Kleiner, Erik Hoel", "title": "Falsification and consciousness", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": "10.1093/nc/niab001", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The search for a scientific theory of consciousness should result in theories\nthat are falsifiable. However, here we show that falsification is especially\nproblematic for theories of consciousness. We formally describe the standard\nexperimental setup for testing these theories. Based on a theory's application\nto some physical system, such as the brain, testing requires comparing a\ntheory's predicted experience (given some internal observables of the system\nlike brain imaging data) with an inferred experience (using report or\nbehavior). If there is a mismatch between inference and prediction, a theory is\nfalsified. We show that if inference and prediction are independent, it follows\nthat any minimally informative theory of consciousness is automatically\nfalsified. This is deeply problematic since the field's reliance on report or\nbehavior to infer conscious experiences implies such independence, so this\nfragility affects many contemporary theories of consciousness. Furthermore, we\nshow that if inference and prediction are strictly dependent, it follows that a\ntheory is unfalsifiable. This affects theories which claim consciousness to be\ndetermined by report or behavior. Finally, we explore possible ways out of this\ndilemma.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2020 17:07:55 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 22:43:19 GMT"}, {"version": "v3", "created": "Wed, 28 Apr 2021 15:47:09 GMT"}], "update_date": "2021-04-29", "authors_parsed": [["Kleiner", "Johannes", ""], ["Hoel", "Erik", ""]]}, {"id": "2004.04157", "submitter": "Theerawit Wilaiprasitporn", "authors": "Nannapas Banluesombatkul, Pichayoot Ouppaphan, Pitshaporn Leelaarporn,\n  Payongkit Lakhan, Busarakum Chaitusaney, Nattapong Jaimchariyatam, Ekapol\n  Chuangsuwanich, Wei Chen, Huy Phan, Nat Dilokthanakul and Theerawit\n  Wilaiprasitporn", "title": "MetaSleepLearner: A Pilot Study on Fast Adaptation of Bio-signals-Based\n  Sleep Stage Classifier to New Individual Subject Using Meta-Learning", "comments": "IEEE Journal of Biomedical and Health Informatics (Accepted) (source\n  code is available at https://github.com/IoBT-VISTEC/MetaSleepLearner)", "journal-ref": "IEEE Journal of Biomedical and Health Informatics (2020)", "doi": "10.1109/JBHI.2020.3037693", "report-no": null, "categories": "q-bio.NC cs.LG eess.SP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying bio-signals based-sleep stages requires time-consuming and\ntedious labor of skilled clinicians. Deep learning approaches have been\nintroduced in order to challenge the automatic sleep stage classification\nconundrum. However, the difficulties can be posed in replacing the clinicians\nwith the automatic system due to the differences in many aspects found in\nindividual bio-signals, causing the inconsistency in the performance of the\nmodel on every incoming individual. Thus, we aim to explore the feasibility of\nusing a novel approach, capable of assisting the clinicians and lessening the\nworkload. We propose the transfer learning framework, entitled\nMetaSleepLearner, based on Model Agnostic Meta-Learning (MAML), in order to\ntransfer the acquired sleep staging knowledge from a large dataset to new\nindividual subjects. The framework was demonstrated to require the labelling of\nonly a few sleep epochs by the clinicians and allow the remainder to be handled\nby the system. Layer-wise Relevance Propagation (LRP) was also applied to\nunderstand the learning course of our approach. In all acquired datasets, in\ncomparison to the conventional approach, MetaSleepLearner achieved a range of\n5.4\\% to 17.7\\% improvement with statistical difference in the mean of both\napproaches. The illustration of the model interpretation after the adaptation\nto each subject also confirmed that the performance was directed towards\nreasonable learning. MetaSleepLearner outperformed the conventional approaches\nas a result from the fine-tuning using the recordings of both healthy subjects\nand patients. This is the first work that investigated a non-conventional\npre-training method, MAML, resulting in a possibility for human-machine\ncollaboration in sleep stage classification and easing the burden of the\nclinicians in labelling the sleep stages through only several epochs rather\nthan an entire recording.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 16:31:03 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 15:58:42 GMT"}, {"version": "v3", "created": "Sun, 6 Sep 2020 16:14:44 GMT"}, {"version": "v4", "created": "Tue, 10 Nov 2020 17:08:12 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Banluesombatkul", "Nannapas", ""], ["Ouppaphan", "Pichayoot", ""], ["Leelaarporn", "Pitshaporn", ""], ["Lakhan", "Payongkit", ""], ["Chaitusaney", "Busarakum", ""], ["Jaimchariyatam", "Nattapong", ""], ["Chuangsuwanich", "Ekapol", ""], ["Chen", "Wei", ""], ["Phan", "Huy", ""], ["Dilokthanakul", "Nat", ""], ["Wilaiprasitporn", "Theerawit", ""]]}, {"id": "2004.04190", "submitter": "Luca Mazzucato", "authors": "David Wyrick and Luca Mazzucato", "title": "State-dependent regulation of cortical processing speed via gain\n  modulation", "comments": "7 figures, 9 suppl. figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To thrive in dynamic environments, animals must be capable of rapidly and\nflexibly adapting behavioral responses to a changing context and internal\nstate. Examples of behavioral flexibility include faster stimulus responses\nwhen attentive and slower responses when distracted. Contextual or\nstate-dependent modulations may occur early in the cortical hierarchy and may\nbe implemented via top-down projections from cortico-cortical or\nneuromodulatory pathways. However, the computational mechanisms mediating the\neffects of such projections are not known. Here, we introduce a theoretical\nframework to classify the effects of cell-type specific top-down perturbations\non the information processing speed of cortical circuits. Our theory\ndemonstrates that perturbation effects on stimulus processing can be predicted\nby intrinsic gain modulation, which controls the timescale of the circuit\ndynamics. Our theory leads to counter-intuitive effects such as improved\nperformance with increased input variance. We tested the model predictions\nusing large-scale electrophysiological recordings from the visual hierarchy in\nfreely running mice, where we found that a decrease in single-cell intrinsic\ngain during locomotion led to an acceleration of visual processing. Our results\nestablish a novel theory of cell-type specific perturbations, applicable to\ntop-down modulation as well as optogenetic and pharmacological manipulations.\nOur theory links connectivity, dynamics, and information processing via gain\nmodulation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 18:19:02 GMT"}, {"version": "v2", "created": "Fri, 22 Jan 2021 03:56:19 GMT"}, {"version": "v3", "created": "Tue, 26 Jan 2021 02:10:03 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Wyrick", "David", ""], ["Mazzucato", "Luca", ""]]}, {"id": "2004.04258", "submitter": "Seungyong Hwang", "authors": "Seungyong Hwang, Thomas C.M. Lee, Debashis Paul, Jie Peng", "title": "Estimating Fiber Orientation Distribution through Blockwise Adaptive\n  Thresholding with Application to HCP Young Adults Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to recent technological advances, large brain imaging data sets can now\nbe collected. Such data are highly complex so extraction of meaningful\ninformation from them remains challenging. Thus, there is an urgent need for\nstatistical procedures that are computationally scalable and can provide\naccurate estimates that capture the neuronal structures and their\nfunctionalities. We propose a fast method for estimating the fiber orientation\ndistribution(FOD) based on diffusion MRI data. This method models the observed\ndMRI signal at any voxel as a convolved and noisy version of the underlying\nFOD, and utilizes the spherical harmonics basis for representing the FOD, where\nthe spherical harmonic coefficients are adaptively and nonlinearly shrunk by\nusing a James-Stein type estimator. To further improve the estimation accuracy\nby enhancing the localized peaks of the FOD, as a second step a\nsuper-resolution sharpening process is then applied. The resulting estimated\nFODs can be fed to a fiber tracking algorithm to reconstruct the white matter\nfiber tracts. We illustrate the overall methodology using both synthetic data\nand data from the Human Connectome Project.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2020 21:12:01 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 18:57:19 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Hwang", "Seungyong", ""], ["Lee", "Thomas C. M.", ""], ["Paul", "Debashis", ""], ["Peng", "Jie", ""]]}, {"id": "2004.04362", "submitter": "Chee-Ming Ting PhD", "authors": "Chee-Ming Ting, S. Balqis Samdin, Meini Tang, Hernando Ombao", "title": "Detecting Dynamic Community Structure in Functional Brain Networks\n  Across Individuals: A Multilayer Approach", "comments": "Main paper: 12 pages, 13 figures. Supplemental file: 16 pages.\n  Accepted for IEEE Trans Medical Imaging", "journal-ref": null, "doi": "10.1109/TMI.2020.3030047", "report-no": null, "categories": "cs.LG eess.SP physics.soc-ph q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified statistical framework for characterizing community\nstructure of brain functional networks that captures variation across\nindividuals and evolution over time. Existing methods for community detection\nfocus only on single-subject analysis of dynamic networks; while recent\nextensions to multiple-subjects analysis are limited to static networks. To\novercome these limitations, we propose a multi-subject, Markov-switching\nstochastic block model (MSS-SBM) to identify state-related changes in brain\ncommunity organization over a group of individuals. We first formulate a\nmultilayer extension of SBM to describe the time-dependent, multi-subject brain\nnetworks. We develop a novel procedure for fitting the multilayer SBM that\nbuilds on multislice modularity maximization which can uncover a common\ncommunity partition of all layers (subjects) simultaneously. By augmenting with\na dynamic Markov switching process, our proposed method is able to capture a\nset of distinct, recurring temporal states with respect to inter-community\ninteractions over subjects and the change points between them. Simulation shows\naccurate community recovery and tracking of dynamic community regimes over\nmultilayer networks by the MSS-SBM. Application to task fMRI reveals meaningful\nnon-assortative brain community motifs, e.g., core-periphery structure at the\ngroup level, that are associated with language comprehension and motor\nfunctions suggesting their putative role in complex information integration.\nOur approach detected dynamic reconfiguration of modular connectivity elicited\nby varying task demands and identified unique profiles of intra and\ninter-community connectivity across different task conditions. The proposed\nmultilayer network representation provides a principled way of detecting\nsynchronous, dynamic modularity in brain networks across subjects.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 04:23:26 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 06:38:07 GMT"}, {"version": "v3", "created": "Thu, 8 Oct 2020 04:53:23 GMT"}, {"version": "v4", "created": "Fri, 16 Oct 2020 07:59:58 GMT"}], "update_date": "2020-10-19", "authors_parsed": [["Ting", "Chee-Ming", ""], ["Samdin", "S. Balqis", ""], ["Tang", "Meini", ""], ["Ombao", "Hernando", ""]]}, {"id": "2004.04472", "submitter": "Zi-Gang Huang", "authors": "Chun-Wang Su, Liang Zheng, You-Jun Li, Hai-Jun Zhou, Jue Wang, Zi-Gang\n  Huang, and Ying-Cheng Lai", "title": "Hysteresis in anesthesia and recovery: Experimental observation and\n  dynamical mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamical mechanism underlying the processes of anesthesia-induced loss\nof consciousness and recovery is key to gaining insights into the working of\nthe nervous system. Previous experiments revealed an asymmetry between neural\nsignals during the anesthesia and recovery processes. Here we obtain\nexperimental evidence for the hysteresis loop and articulate the dynamical\nmechanism based on percolation on multilayer complex networks with\nself-similarity. Model analysis reveals that, during anesthesia, the network is\nable to maintain its neural pathways despite the loss of a substantial fraction\nof the edges. A predictive and potentially testable result is that, in the\nforward process of anesthesia, the average shortest path and the clustering\ncoefficient of the neural network are markedly smaller than those associated\nwith the recovery process. This suggests that the network strives to maintain\ncertain neurological functions by adapting to a relatively more compact\nstructure in response to anesthesia.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 10:44:07 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Su", "Chun-Wang", ""], ["Zheng", "Liang", ""], ["Li", "You-Jun", ""], ["Zhou", "Hai-Jun", ""], ["Wang", "Jue", ""], ["Huang", "Zi-Gang", ""], ["Lai", "Ying-Cheng", ""]]}, {"id": "2004.04474", "submitter": "Lorenzo Vannucci", "authors": "Lorenzo Vannucci, Maria Pasquini, Cristina Spalletti, Matteo Caleo,\n  Silvestro Micera, Cecilia Laschi, Egidio Falotico", "title": "Towards in-silico robotic post-stroke rehabilitation for mice", "comments": "7 pages, 9 figures. To be published in the 2019 IEEE International\n  Conference on Cyborg and Bionic Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possibility of simulating in detail in-vivo experiments could be highly\nbeneficial to the neuroscientific community. It could easily allow for\npreliminary testing of different experimental conditions without having to be\nconstrained by factors such as training of the subjects or resting times\nbetween experimental trials. In order to achieve this, the simulation of the\nenvironment, of the subject and of the neural system, should be as accurate as\npossible. Unfortunately, it is not possible to completely simulate physical\nsystems, alongside their neural counterparts, without greatly increasing the\ncomputational cost of the simulation. For this reason, it is crucial to limit\nthe simulation to all physical and neural areas that are involved in the\nexperiment. We propose that using a combination of data analysis and simulated\nmodels is beneficial in determining the minimal subset of entities that have to\nbe included in the simulation to replicate the in-vivo experiment. In\nparticular, we focused on a pulling task performed by mice on a robotic\nplatform before and after lesion of the central nervous system. Here, we show\nthat, while it is possible to replicate the behaviour of the healthy mouse just\nby including models of the mouse forelimb, spinal cord, and recording of the\nrostral forelimb area (RFA), it is not possible to reproduce the behaviour of\nthe post-stroke mouse. This can give us insights on what other elements would\nbe needed to replicate the complete experiment.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 10:47:04 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Vannucci", "Lorenzo", ""], ["Pasquini", "Maria", ""], ["Spalletti", "Cristina", ""], ["Caleo", "Matteo", ""], ["Micera", "Silvestro", ""], ["Laschi", "Cecilia", ""], ["Falotico", "Egidio", ""]]}, {"id": "2004.04617", "submitter": "Lilla Zollei", "authors": "Jieyu Cheng, Adrian V. Dalca, Bruce Fischl, Lilla Zollei (for the\n  Alzheimer's Disease Neuroimaging Initiative)", "title": "Cortical surface registration using unsupervised learning", "comments": "cortical surface registration, deep network, unsupervised learning,\n  registration, deep learning, cortical, spherical, invertible", "journal-ref": "NeuroImage, Volume 221, 1 November 2020, 117161", "doi": "10.1016/j.neuroimage.2020.117161", "report-no": null, "categories": "eess.IV cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-rigid cortical registration is an important and challenging task due to\nthe geometric complexity of the human cortex and the high degree of\ninter-subject variability. A conventional solution is to use a spherical\nrepresentation of surface properties and perform registration by aligning\ncortical folding patterns in that space. This strategy produces accurate\nspatial alignment but often requires a high computational cost. Recently,\nconvolutional neural networks (CNNs) have demonstrated the potential to\ndramatically speed up volumetric registration. However, due to distortions\nintroduced by projecting a sphere to a 2D plane, a direct application of recent\nlearning-based methods to surfaces yields poor results. In this study, we\npresent SphereMorph, a diffeomorphic registration framework for cortical\nsurfaces using deep networks that addresses these issues. SphereMorph uses a\nUNet-style network associated with a spherical kernel to learn the displacement\nfield and warps the sphere using a modified spatial transformer layer. We\npropose a resampling weight in computing the data fitting loss to account for\ndistortions introduced by polar projection, and demonstrate the performance of\nour proposed method on two tasks, including cortical parcellation and\ngroup-wise functional area alignment. The experiments show that the proposed\nSphereMorph is capable of modeling the geometric registration problem in a CNN\nframework and demonstrate superior registration accuracy and computational\nefficiency. The source code of SphereMorph will be released to the public upon\nacceptance of this manuscript at https://github.com/voxelmorph/spheremorph.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 15:59:13 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 09:06:55 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cheng", "Jieyu", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Dalca", "Adrian V.", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Fischl", "Bruce", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"], ["Zollei", "Lilla", "", "for the\n  Alzheimer's Disease Neuroimaging Initiative"]]}, {"id": "2004.04649", "submitter": "Noa Malem-Shinitski", "authors": "Noa Malem-Shinitski, Manfred Opper, Sebastian Reich, Lisa Schwetlick,\n  Stefan A. Seelig and Ralf Engbert", "title": "A Mathematical Model of Local and Global Attention in Natural Scene\n  Viewing", "comments": "24 pages, 10 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1007880", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the decision process underlying gaze control is an important\nquestion in cognitive neuroscience with applications in diverse fields ranging\nfrom psychology to computer vision. The decision for choosing an upcoming\nsaccade target can be framed as a selection process between two states: Should\nthe observer further inspect the information near the current gaze position\n(local attention) or continue with exploration of other patches of the given\nscene (global attention)? Here we propose and investigate a mathematical model\nmotivated by switching between these two attentional states during scene\nviewing. The model is derived from a minimal set of assumptions that generates\nrealistic eye movement behavior. We implemented a Bayesian approach for model\nparameter inference based on the model's likelihood function. In order to\nsimplify the inference, we applied data augmentation methods that allowed the\nuse of conjugate priors and the construction of an efficient Gibbs sampler.\nThis approach turned out to be numerically efficient and permitted fitting\ninterindividual differences in saccade statistics. Thus, the main contribution\nof our modeling approach is two--fold; first, we propose a new model for\nsaccade generation in scene viewing. Second, we demonstrate the use of novel\nmethods from Bayesian inference in the field of scan path modeling.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2020 16:36:16 GMT"}, {"version": "v2", "created": "Tue, 1 Sep 2020 09:37:44 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Malem-Shinitski", "Noa", ""], ["Opper", "Manfred", ""], ["Reich", "Sebastian", ""], ["Schwetlick", "Lisa", ""], ["Seelig", "Stefan A.", ""], ["Engbert", "Ralf", ""]]}, {"id": "2004.05069", "submitter": "Gianluca Calcagni", "authors": "Gianluca Calcagni, Justin A. Harris, Ricardo Pell\\'on", "title": "Beyond Rescorla-Wagner: the ups and downs of learning", "comments": "39 pages, 11 figures, 8 tables. v2: discussion improved, figures\n  added, some parts shortened, conclusions unchanged, matches published version", "journal-ref": "Comput. Brain Behav. (2021)", "doi": "10.1007/s42113-021-00103-4", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We check the robustness of a recently proposed dynamical model of associative\nPavlovian learning that extends the Rescorla-Wagner (RW) model in a natural way\nand predicts progressively damped oscillations in the response of the subjects.\nUsing the data of two experiments, we compare the dynamical oscillatory model\n(DOM) with an oscillatory model made of the superposition of the RW learning\ncurve and oscillations. Not only do data clearly show an oscillatory pattern,\nbut they also favor the DOM over the added oscillation model, thus pointing out\nthat these oscillations are the manifestation of an associative process. The\nlatter is interpreted as the fact that subjects make predictions on trial\noutcomes more extended in time than in the RW model, but with more uncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 15:16:18 GMT"}, {"version": "v2", "created": "Sun, 18 Apr 2021 20:13:59 GMT"}], "update_date": "2021-04-20", "authors_parsed": [["Calcagni", "Gianluca", ""], ["Harris", "Justin A.", ""], ["Pell\u00f3n", "Ricardo", ""]]}, {"id": "2004.05209", "submitter": "David Carlson", "authors": "Austin Talbot, David Dunson, Kafui Dzirasa, David Carlson", "title": "Supervised Autoencoders Learn Robust Joint Factor Models of Neural\n  Activity", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factor models are routinely used for dimensionality reduction in modeling of\ncorrelated, high-dimensional data. We are particularly motivated by\nneuroscience applications collecting high-dimensional `predictors'\ncorresponding to brain activity in different regions along with behavioral\noutcomes. Joint factor models for the predictors and outcomes are natural, but\nmaximum likelihood estimates of these models can struggle in practice when\nthere is model misspecification. We propose an alternative inference strategy\nbased on supervised autoencoders; rather than placing a probability\ndistribution on the latent factors, we define them as an unknown function of\nthe high-dimensional predictors. This mapping function, along with the\nloadings, can be optimized to explain variance in brain activity while\nsimultaneously being predictive of behavior. In practice, the mapping function\ncan range in complexity from linear to more complex forms, such as splines or\nneural networks, with the usual tradeoff between bias and variance. This\napproach yields distinct solutions from a maximum likelihood inference\nstrategy, as we demonstrate by deriving analytic solutions for a linear\nGaussian factor model. Using synthetic data, we show that this function-based\napproach is robust against multiple types of misspecification. We then apply\nthis technique to a neuroscience application resulting in substantial gains in\npredicting behavioral tasks from electrophysiological measurements in multiple\nfactor models.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2020 19:31:57 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Talbot", "Austin", ""], ["Dunson", "David", ""], ["Dzirasa", "Kafui", ""], ["Carlson", "David", ""]]}, {"id": "2004.05479", "submitter": "Cengiz Pehlevan", "authors": "Alper T. Erdogan, Cengiz Pehlevan", "title": "Blind Bounded Source Separation Using Neural Networks with Local\n  Learning Rules", "comments": "ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053114", "report-no": null, "categories": "eess.SP cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important problem encountered by both natural and engineered signal\nprocessing systems is blind source separation. In many instances of the\nproblem, the sources are bounded by their nature and known to be so, even\nthough the particular bound may not be known. To separate such bounded sources\nfrom their mixtures, we propose a new optimization problem, Bounded Similarity\nMatching (BSM). A principled derivation of an adaptive BSM algorithm leads to a\nrecurrent neural network with a clipping nonlinearity. The network adapts by\nlocal learning rules, satisfying an important constraint for both biological\nplausibility and implementability in neuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 20:20:22 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Erdogan", "Alper T.", ""], ["Pehlevan", "Cengiz", ""]]}, {"id": "2004.05488", "submitter": "Lyes Khacef", "authors": "Lyes Khacef, Laurent Rodriguez, Benoit Miramond", "title": "Brain-inspired self-organization with cellular neuromorphic computing\n  for multimodal unsupervised learning", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical plasticity is one of the main features that enable our ability to\nlearn and adapt in our environment. Indeed, the cerebral cortex self-organizes\nitself through structural and synaptic plasticity mechanisms that are very\nlikely at the basis of an extremely interesting characteristic of the human\nbrain development: the multimodal association. In spite of the diversity of the\nsensory modalities, like sight, sound and touch, the brain arrives at the same\nconcepts (convergence). Moreover, biological observations show that one\nmodality can activate the internal representation of another modality when both\nare correlated (divergence). In this work, we propose the Reentrant\nSelf-Organizing Map (ReSOM), a brain-inspired neural system based on the\nreentry theory using Self-Organizing Maps and Hebbian-like learning. We propose\nand compare different computational methods for unsupervised learning and\ninference, then quantify the gain of the ReSOM in a multimodal classification\ntask. The divergence mechanism is used to label one modality based on the\nother, while the convergence mechanism is used to improve the overall accuracy\nof the system. We perform our experiments on a constructed written/spoken\ndigits database and a DVS/EMG hand gestures database. The proposed model is\nimplemented on a cellular neuromorphic architecture that enables distributed\ncomputing with local connectivity. We show the gain of the so-called hardware\nplasticity induced by the ReSOM, where the system's topology is not fixed by\nthe user but learned along the system's experience through self-organization.\n", "versions": [{"version": "v1", "created": "Sat, 11 Apr 2020 21:02:45 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 15:36:46 GMT"}, {"version": "v3", "created": "Wed, 2 Sep 2020 17:10:21 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Khacef", "Lyes", ""], ["Rodriguez", "Laurent", ""], ["Miramond", "Benoit", ""]]}, {"id": "2004.05895", "submitter": "Audrey B\\\"urki", "authors": "A. B\\\"urki, S. Elbuy, S. Madec, S. Vasishth", "title": "What did we learn from forty years of research on semantic interference?\n  A Bayesian metaanalysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When participants in an experiment have to name pictures while ignoring\ndistractor words superimposed on the picture or presented auditorily (i.e.,\npicture-word interference paradigm), they take more time when the word to be\nnamed (or target) and distractor words are from the same semantic category\n(e.g., cat-dog). This experimental effect is known as the semantic interference\neffect, and is probably one of the most studied in the language production\nliterature. The functional origin of the effect and the exact conditions in\nwhich it occurs are however still debated. Since Lupker reported the effect in\nthe first response time experiment about 40 years ago, more than 300 similar\nexperiments have been conducted. The semantic interference effect was\nreplicated in many experiments, but several studies also reported the absence\nof an effect in a subset of experimental conditions. The aim of the present\nstudy is to provide a comprehensive theoretical review of the existing evidence\nto date and several Bayesian meta-analyses and meta-regressions to determine\nthe size of the effect and explore the experimental conditions in which the\neffect surfaces. The results are discussed in the light of current debates\nabout the functional origin of the semantic interference effect and its\nimplications for our understanding of the language production system.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 15:07:26 GMT"}, {"version": "v2", "created": "Sun, 26 Apr 2020 09:41:47 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["B\u00fcrki", "A.", ""], ["Elbuy", "S.", ""], ["Madec", "S.", ""], ["Vasishth", "S.", ""]]}, {"id": "2004.06766", "submitter": "Yusuf Ziya Ider Dr", "authors": "M. N. Yasinzai, Y. Z. Ider", "title": "New Approach for Designing cVEP BCI Stimuli Based on Superposition of\n  Edge Responses", "comments": "This paper has two parts: the main text and the supporting material.\n  Main text is 16 pages, has 11 figures, and has 1 table. Supporting material\n  is 11 pages, has one figure, and has 24 tables. This paper is submitted to\n  IOP BPEX journal", "journal-ref": null, "doi": "10.1088/2057-1976/ab98e7", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of this study is to develop a new methodology for designing\nstimulus sequences for cVEP BCI based on experimental studies regarding the\nbehavior and the properties of the actual EEG responses of the visual system to\ncoded visual stimuli, such that training time is reduced and the possible\nnumber of targets is increased. EEG from 8 occipital sites is recorded with\n2000 samples/sec per channel, in response to visual stimuli presented on a\ncomputer monitor with 60Hz refresh rate. Onset and offset EEG responses to long\nvisual stimulus pulses are obtained through 160-trial signal averaging. These\nedge responses are used to predict the EEG responses to arbitrary stimulus\nsequences using the superposition principle. A BCI speller which utilizes the\ntarget templates generated by this principle is also implemented and tested. It\nis found that certain short stimulus patterns can be accurately predicted by\nthe superposition principle. BCI sequences that are constructed by combinations\nof these optimal patterns yield higher accuracy (95.9%) and ITR (57.2 bpm)\ncompared to when the superposition principle is applied to conventional\nm-sequences and randomly generated sequences. Training time for the BCI\napplication involves only the acquisition of the edge responses and is less\nthan 4 minutes, and a huge number of sequences is possible. This is the first\nstudy in which cVEP BCI sequences are designed based on constraints obtained by\nobserving the actual brain responses to several stimulus patterns.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2020 13:16:44 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Yasinzai", "M. N.", ""], ["Ider", "Y. Z.", ""]]}, {"id": "2004.07580", "submitter": "Stephanie Nelli", "authors": "Andrew Saxe, Stephanie Nelli and Christopher Summerfield", "title": "If deep learning is the answer, then what is the question?", "comments": "4 Figures, 17 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neuroscience research is undergoing a minor revolution. Recent advances in\nmachine learning and artificial intelligence (AI) research have opened up new\nways of thinking about neural computation. Many researchers are excited by the\npossibility that deep neural networks may offer theories of perception,\ncognition and action for biological brains. This perspective has the potential\nto radically reshape our approach to understanding neural systems, because the\ncomputations performed by deep networks are learned from experience, not\nendowed by the researcher. If so, how can neuroscientists use deep networks to\nmodel and understand biological brains? What is the outlook for neuroscientists\nwho seek to characterise computations or neural codes, or who wish to\nunderstand perception, attention, memory, and executive functions? In this\nPerspective, our goal is to offer a roadmap for systems neuroscience research\nin the age of deep learning. We discuss the conceptual and methodological\nchallenges of comparing behaviour, learning dynamics, and neural representation\nin artificial and biological systems. We highlight new research questions that\nhave emerged for neuroscience as a direct consequence of recent advances in\nmachine learning.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 10:42:44 GMT"}, {"version": "v2", "created": "Fri, 17 Apr 2020 13:24:03 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Saxe", "Andrew", ""], ["Nelli", "Stephanie", ""], ["Summerfield", "Christopher", ""]]}, {"id": "2004.07780", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, J\\\"orn-Henrik Jacobsen, Claudio Michaelis, Richard\n  Zemel, Wieland Brendel, Matthias Bethge, Felix A. Wichmann", "title": "Shortcut Learning in Deep Neural Networks", "comments": "perspective article published at Nature Machine Intelligence\n  (https://doi.org/10.1038/s42256-020-00257-z)", "journal-ref": null, "doi": "10.1038/s42256-020-00257-z", "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has triggered the current rise of artificial intelligence and\nis the workhorse of today's machine intelligence. Numerous success stories have\nrapidly spread all over science, industry and society, but its limitations have\nonly recently come into focus. In this perspective we seek to distil how many\nof deep learning's problem can be seen as different symptoms of the same\nunderlying problem: shortcut learning. Shortcuts are decision rules that\nperform well on standard benchmarks but fail to transfer to more challenging\ntesting conditions, such as real-world scenarios. Related issues are known in\nComparative Psychology, Education and Linguistics, suggesting that shortcut\nlearning may be a common characteristic of learning systems, biological and\nartificial alike. Based on these observations, we develop a set of\nrecommendations for model interpretation and benchmarking, highlighting recent\nadvances in machine learning to improve robustness and transferability from the\nlab to real-world applications.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 17:18:49 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 08:03:44 GMT"}, {"version": "v3", "created": "Wed, 20 May 2020 09:10:46 GMT"}, {"version": "v4", "created": "Fri, 26 Mar 2021 13:53:12 GMT"}], "update_date": "2021-03-29", "authors_parsed": [["Geirhos", "Robert", ""], ["Jacobsen", "J\u00f6rn-Henrik", ""], ["Michaelis", "Claudio", ""], ["Zemel", "Richard", ""], ["Brendel", "Wieland", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""]]}, {"id": "2004.07937", "submitter": "Syed Muhammad Usman", "authors": "Syed Muhammad Usman, Shahzad Latif, Arshad Beg", "title": "Principle components analysis for seizures prediction using wavelet\n  transform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG eess.SP stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Epilepsy is a disease in which frequent seizures occur due to abnormal\nactivity of neurons. Patients affected by this disease can be treated with the\nhelp of medicines or surgical procedures. However, both of these methods are\nnot quite useful. The only method to treat epilepsy patients effectively is to\npredict the seizure before its onset. It has been observed that abnormal\nactivity in the brain signals starts before the occurrence of seizure known as\nthe preictal state. Many researchers have proposed machine learning models for\nprediction of epileptic seizures by detecting the start of preictal state.\nHowever, pre-processing, feature extraction and classification remains a great\nchallenge in the prediction of preictal state. Therefore, we propose a model\nthat uses common spatial pattern filtering and wavelet transform for\npreprocessing, principal component analysis for feature extraction and support\nvector machines for detecting preictal state. We have applied our model on 23\nsubjects and an average sensitivity of 93.1% has been observed for 84 seizures.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 04:32:57 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Usman", "Syed Muhammad", ""], ["Latif", "Shahzad", ""], ["Beg", "Arshad", ""]]}, {"id": "2004.07975", "submitter": "Uygar S\\\"umb\\\"ul", "authors": "Stephen J. Smith, Michael Hawrylycz, Jean Rossier, Uygar S\\\"umb\\\"ul", "title": "New Light on Cortical Neuropeptides and Synaptic Network Plasticity", "comments": "22 pages, 4 figures, 1 table, to be published in Current Opinion in\n  Neurobiology", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neuropeptides, members of a large and evolutionarily ancient family of\nproteinaceous cell-cell signaling molecules, are widely recognized as extremely\npotent regulators of brain function and behavior. At the cellular level,\nneuropeptides are known to act mainly via modulation of ion channel and synapse\nfunction, but functional impacts emerging at the level of complex cortical\nsynaptic networks have resisted mechanistic analysis. New findings from\nsingle-cell RNA-seq transcriptomics now illuminate intricate patterns of\ncortical neuropeptide signaling gene expression and new tools now offer\npowerful molecular access to cortical neuropeptide signaling. Here we highlight\nsome of these new findings and tools, focusing especially on prospects for\nexperimental and theoretical exploration of peptidergic and synaptic networks\ninteractions underlying cortical function and plasticity.\n", "versions": [{"version": "v1", "created": "Thu, 16 Apr 2020 22:01:34 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Smith", "Stephen J.", ""], ["Hawrylycz", "Michael", ""], ["Rossier", "Jean", ""], ["S\u00fcmb\u00fcl", "Uygar", ""]]}, {"id": "2004.08091", "submitter": "Merav Stern", "authors": "Merav Stern, Eric Shea-Brown", "title": "Network Dynamics Governed by Lyapunov Functions: From Memory to\n  Classification", "comments": "Trends in Neurosciences (2020)", "journal-ref": null, "doi": "10.1016/j.tins.2020.04.002", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1982 John Hopfield published a neural network model for memory retrieval,\na model that became a cornerstone in theoretical neuroscience. A key ingredient\nof the Hopfield model was the use of a network dynamics that is governed by a\nLyapunov function. In a recent paper, Krotov and Hopfield showed how a Lyapunov\nfunction governs a biological plausible learning rule for the neural networks'\nconnectivity. By doing so, they bring an intriguing approach to classification\ntasks, and show the relevance of the broader framework across decades in the\nfield.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 07:26:06 GMT"}, {"version": "v2", "created": "Fri, 8 May 2020 19:24:05 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Stern", "Merav", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "2004.08220", "submitter": "Fernando Rosas", "authors": "Fernando E. Rosas, Pedro A.M. Mediano, Henrik J. Jensen, Anil K. Seth,\n  Adam B. Barrett, Robin L. Carhart-Harris, Daniel Bor", "title": "Reconciling emergences: An information-theoretic approach to identify\n  causal emergence in multivariate data", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": "10.1371/journal.pcbi.1008289", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broad concept of emergence is instrumental in various of the most\nchallenging open scientific questions -- yet, few quantitative theories of what\nconstitutes emergent phenomena have been proposed. This article introduces a\nformal theory of causal emergence in multivariate systems, which studies the\nrelationship between the dynamics of parts of a system and macroscopic features\nof interest. Our theory provides a quantitative definition of downward\ncausation, and introduces a complementary modality of emergent behaviour --\nwhich we refer to as causal decoupling. Moreover, the theory allows practical\ncriteria that can be efficiently calculated in large systems, making our\nframework applicable in a range of scenarios of practical interest. We\nillustrate our findings in a number of case studies, including Conway's Game of\nLife, Reynolds' flocking model, and neural activity as measured by\nelectrocorticography.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 13:05:39 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["Rosas", "Fernando E.", ""], ["Mediano", "Pedro A. M.", ""], ["Jensen", "Henrik J.", ""], ["Seth", "Anil K.", ""], ["Barrett", "Adam B.", ""], ["Carhart-Harris", "Robin L.", ""], ["Bor", "Daniel", ""]]}, {"id": "2004.08248", "submitter": "Shankha Sanyal", "authors": "Chirayata Bhattacharyya, Sourya Sengupta, Sayan Nag, Shankha Sanyal,\n  Archi Banerjee, Ranjan Sengupta and Dipak Ghosh", "title": "Acoustical classification of different speech acts using nonlinear\n  methods", "comments": "6 pages, 2 figures; Proceedings of WESPAC 2018, New Delhi, India,\n  November 11-15, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD nlin.CD q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A recitation is a way of combining the words together so that they have a\nsense of rhythm and thus an emotional content is imbibed within. In this study\nwe envisaged to answer these questions in a scientific manner taking into\nconsideration 5 (five) well known Bengali recitations of different poets\nconveying a variety of moods ranging from joy to sorrow. The clips were recited\nas well as read (in the form of flat speech without any rhythm) by the same\nperson to avoid any perceptual difference arising out of timbre variation.\nNext, the emotional content from the 5 recitations were standardized with the\nhelp of listening test conducted on a pool of 50 participants. The recitations\nas well as the speech were analyzed with the help of a latest non linear\ntechnique called Detrended Fluctuation Analysis (DFA) that gives a scaling\nexponent {\\alpha}, which is essentially the measure of long range correlations\npresent in the signal. Similar pieces (the parts which have the exact lyrical\ncontent in speech as well as in the recital) were extracted from the complete\nsignal and analyzed with the help of DFA technique. Our analysis shows that the\nscaling exponent for all parts of recitation were much higher in general as\ncompared to their counterparts in speech. We have also established a critical\nvalue from our analysis, above which a mere speech may become a recitation. The\ncase may be similar to the conventional phase transition, wherein the\nmeasurement of external condition at which the transformation occurs (generally\ntemperature) is called phase transition. Further, we have also categorized the\n5 recitations on the basis of their emotional content with the help of the same\nDFA technique. Analysis with a greater variety of recitations is being carried\nout to yield more interesting results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2020 22:33:16 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 09:11:36 GMT"}], "update_date": "2020-08-06", "authors_parsed": [["Bhattacharyya", "Chirayata", ""], ["Sengupta", "Sourya", ""], ["Nag", "Sayan", ""], ["Sanyal", "Shankha", ""], ["Banerjee", "Archi", ""], ["Sengupta", "Ranjan", ""], ["Ghosh", "Dipak", ""]]}, {"id": "2004.08320", "submitter": "Vignayanandam Ravindernath Muddapu", "authors": "Vignayanandam R. Muddapu, Karthik Vijayakumar, Keerthiga Ramakrishnan,\n  V Srinivasa Chakravarthy", "title": "A Computational Model of Levodopa-Induced Toxicity in Substantia Nigra\n  Pars Compacta in Parkinson's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Parkinson's disease (PD) is caused by the progressive loss of dopaminergic\ncells in substantia nigra pars compacta (SNc). The root cause of this cell loss\nin PD is still not decisively elucidated. A recent line of thinking traces the\ncause of PD neurodegeneration to metabolic deficiency. Due to exceptionally\nhigh energy demand, SNc neurons exhibit a higher basal metabolic rate and\nhigher oxygen consumption rate, which results in oxidative stress. Recently, we\nhave suggested that the excitotoxic loss of SNc cells might be due to energy\ndeficiency occurring at different levels of neural hierarchy. Levodopa (LDOPA),\na precursor of dopamine, which is used as a symptom-relieving treatment for PD,\nleads to outcomes that are both positive and negative. Several researchers\nsuggested that LDOPA might be harmful to SNc cells due to oxidative stress. The\nrole of LDOPA in the course of PD pathogenesis is still debatable. We\nhypothesize that energy deficiency can lead to LDOPA-induced toxicity (LIT) in\ntwo ways: by promoting dopamine-induced oxidative stress and by exacerbating\nexcitotoxicity in SNc. We present a multiscale computational model of\nSNc-striatum system, which will help us in understanding the mechanism behind\nneurodegeneration postulated above and provides insights for developing\ndisease-modifying therapeutics. It was observed that SNc terminals are more\nvulnerable to energy deficiency than SNc somas. During LDOPA therapy, it was\nobserved that higher LDOPA dosage results in increased loss of somas and\nterminals in SNc. It was also observed that co-administration of LDOPA and\nglutathione (antioxidant) evades LDOPA-induced toxicity in SNc neurons. We show\nthat our proposed model was able to capture LDOPA-induced toxicity in SNc,\ncaused by energy deficiency.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2020 11:04:52 GMT"}], "update_date": "2020-04-20", "authors_parsed": [["Muddapu", "Vignayanandam R.", ""], ["Vijayakumar", "Karthik", ""], ["Ramakrishnan", "Keerthiga", ""], ["Chakravarthy", "V Srinivasa", ""]]}, {"id": "2004.08390", "submitter": "Gavindya Jayawardena", "authors": "Gavindya Jayawardena (1), Anne M. P. Michalek (1), Andrew T. Duchowski\n  (2), Sampath Jayarathna (1) ((1) Old Dominion University, Norfolk VA (2)\n  Clemson University, Clemson SC)", "title": "Audiovisual Speech-In-Noise (SIN) Performance of Young Adults with ADHD", "comments": "To be published in Symposium on Eye Tracking Research and\n  Applications (ETRA '20 Short Papers), 6 pages, 3 figures, 2 tables", "journal-ref": null, "doi": "10.1145/3379156.3391373", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adolescents with Attention-deficit/hyperactivity disorder (ADHD) have\ndifficulty processing speech with background noise due to reduced inhibitory\ncontrol and working memory capacity (WMC). This paper presents a pilot study of\nan audiovisual Speech-In-Noise (SIN) task for young adults with ADHD compared\nto age-matched controls using eye-tracking measures. The audiovisual SIN task\nconsists of varying six levels of background babble, accompanied by visual\ncues. A significant difference between ADHD and neurotypical (NT) groups was\nobserved at 15 dB signal-to-noise ratio (SNR). These results contribute to the\nliterature of young adults with ADHD.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2020 20:52:09 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Jayawardena", "Gavindya", ""], ["Michalek", "Anne M. P.", ""], ["Duchowski", "Andrew T.", ""], ["Jayarathna", "Sampath", ""]]}, {"id": "2004.08926", "submitter": "Mahmoud Hassan", "authors": "Fabio Barollo, R\\'un Fri{\\dh}riksd\\'ottir, Kyle J. Edmunds, Gunnar H.\n  Karlsson, Halld\\'or \\'A. Svansson, Mahmoud Hassan, Antonio Fratini, Hannes\n  Petersen and Paolo Gargiulo", "title": "Postural control adaptation and habituation during vibratory\n  proprioceptive stimulation: an HD-EEG investigation of cortical recruitment\n  and kinematics", "comments": "6 figures", "journal-ref": null, "doi": "10.1109/TNSRE.2020.2988585", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of the present work is to measure postural kinematics and power\nspectral variation from HD-EEG to assess changes in cortical activity during\nadaptation and habituation to postural perturbation. To evoke proprioceptive\npostural perturbation, vibratory stimulation at 85 Hz was applied to the calf\nmuscles of 33 subjects over four 75-second stimulation periods. Stimulation was\nperformed according to a pseudorandom binary sequence. Vibratory impulses were\nsynchronized to high-density electroencephalography (HD-EEG, 256 channels).\nChanges in absolute spectral power (ASP) were analyzed over four frequency\nbands (Delta: 0.5-3.5 Hz; theta: 3.5-7.5 Hz; alpha: 7.5-12.5 Hz; beta:12.5-30\nHz). A force platform recorded torque actuated by the feet, and normalized sway\npath length (SPL) was computed as a construct for postural performance during\neach period. SPL values indicated improvement in postural performance over the\ntrial periods. Significant variation in absolute power values (ASP) was found\nin assessing postural adaptation: an increase in theta band ASP in the\nfrontal-central region for closed-eyes trials, an increase in theta and beta\nband ASP in the parietal region for open-eyes trials. In habituation, no\nsignificant variations in ASP were observed during closed-eyes trials, whereas\nan increase in theta, alpha, and beta band ASP was observed with open eyes.\nFurthermore, open-eyed trials generally yielded a greater number of significant\nASP differences across all bands during both adaptation and habituation,\nsuggesting that following cortical activity during postural perturbation may be\nup-regulated with the availability of visual feedback. Results provide deeper\ninsight into pathological postural control failure by exploring the dynamic\nchanges in both cortical activity and postural kinematics during adaptation and\nhabituation to proprioceptive postural perturbation.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2020 18:06:49 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Barollo", "Fabio", ""], ["Fri\u00f0riksd\u00f3ttir", "R\u00fan", ""], ["Edmunds", "Kyle J.", ""], ["Karlsson", "Gunnar H.", ""], ["Svansson", "Halld\u00f3r \u00c1.", ""], ["Hassan", "Mahmoud", ""], ["Fratini", "Antonio", ""], ["Petersen", "Hannes", ""], ["Gargiulo", "Paolo", ""]]}, {"id": "2004.09107", "submitter": "Kingsley Cox", "authors": "Kingsley Cox and Paul Adams", "title": "A Minimal Model of the Interaction of Social and Individual learning", "comments": "24 pages and 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social, supervised, learning from others might amplify individual, possibly\nunsupervised, learning by individuals, and might underlie the development and\nevolution of culture. We studied a minimal model of the interaction of\nindividual unsupervised and social supervised learning by interacting agents.\nAgents attempted to learn to track a hidden fluctuation \"source\", which,\nlinearly mixed with other masking fluctuations, generated observable input\nvectors. Learning was driven either solely by direct observation of inputs\n(unsupervised, Hebbian) or, in addition, by observation of another agent's\noutput (supervised, Delta rule). To enhance biological realism, the learning\nrules were made slightly connection-inspecific, so that incorrect learning\nsometimes occurs. We found that social interaction can foster both correct and\nincorrect learning. Useful social learning therefore presumably involves\nadditional factors some of which we outline.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 07:46:41 GMT"}, {"version": "v2", "created": "Wed, 20 May 2020 11:33:45 GMT"}], "update_date": "2020-05-21", "authors_parsed": [["Cox", "Kingsley", ""], ["Adams", "Paul", ""]]}, {"id": "2004.09406", "submitter": "Christina Funke", "authors": "Christina M. Funke, Judy Borowski, Karolina Stosio, Wieland Brendel,\n  Thomas S. A. Wallis, Matthias Bethge", "title": "Five Points to Check when Comparing Visual Perception in Humans and\n  Machines", "comments": "V3: minor changes like in published JOV version\n  (https://doi.org/10.1167/jov.21.3.16) V2: New title; added general section\n  (checklist); manuscript restructured such that each case study is one\n  chapter; adversarial examples in first study replaced by different analysis", "journal-ref": "Journal of Vision 21, no. 3 (2021): 16-16", "doi": "10.1167/jov.21.3.16", "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of machines to human-level performance in complex recognition\ntasks, a growing amount of work is directed towards comparing information\nprocessing in humans and machines. These studies are an exciting chance to\nlearn about one system by studying the other. Here, we propose ideas on how to\ndesign, conduct and interpret experiments such that they adequately support the\ninvestigation of mechanisms when comparing human and machine perception. We\ndemonstrate and apply these ideas through three case studies. The first case\nstudy shows how human bias can affect how we interpret results, and that\nseveral analytic tools can help to overcome this human reference point. In the\nsecond case study, we highlight the difference between necessary and sufficient\nmechanisms in visual reasoning tasks. Thereby, we show that contrary to\nprevious suggestions, feedback mechanisms might not be necessary for the tasks\nin question. The third case study highlights the importance of aligning\nexperimental conditions. We find that a previously-observed difference in\nobject recognition does not hold when adapting the experiment to make\nconditions more equitable between humans and machines. In presenting a\nchecklist for comparative studies of visual reasoning in humans and machines,\nwe hope to highlight how to overcome potential pitfalls in design or inference.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 16:05:36 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2020 08:37:22 GMT"}, {"version": "v3", "created": "Tue, 13 Apr 2021 16:03:20 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Funke", "Christina M.", ""], ["Borowski", "Judy", ""], ["Stosio", "Karolina", ""], ["Brendel", "Wieland", ""], ["Wallis", "Thomas S. A.", ""], ["Bethge", "Matthias", ""]]}, {"id": "2004.09426", "submitter": "Roy de Kleijn", "authors": "Rutger Goekoop (Parnassia Group, PsyQ, Netherlands), Roy de Kleijn\n  (Leiden University)", "title": "How higher goals are constructed and collapse under stress: a\n  hierarchical Bayesian control systems perspective", "comments": null, "journal-ref": "Neuroscience & Biobehavioral Reviews 123 (2021) 257-285", "doi": "10.1016/j.neubiorev.2020.12.021", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we show that organisms can be modeled as hierarchical Bayesian\ncontrol systems with small world and information bottleneck (bow-tie) network\nstructure. Such systems combine hierarchical perception with hierarchical goal\nsetting and hierarchical action control. We argue that hierarchical Bayesian\ncontrol systems produce deep hierarchies of goal states, from which it follows\nthat organisms must have some form of 'highest goals'. For all organisms, these\ninvolve internal (self) models, external (social) models and overarching\n(normative) models. We show that goal hierarchies tend to decompose in a\ntop-down manner under severe and prolonged levels of stress. This produces\nbehavior that favors short-term and self-referential goals over long term,\nsocial and/or normative goals. The collapse of goal hierarchies is universally\naccompanied by an increase in entropy (disorder) in control systems that can\nserve as an early warning sign for tipping points (disease or death of the\norganism). In humans, learning goal hierarchies corresponds to personality\ndevelopment (maturation). The failure of goal hierarchies to mature properly\ncorresponds to personality deficits. A top-down collapse of such hierarchies\nunder stress is identified as a common factor in all forms of episodic mental\ndisorders (psychopathology). The paper concludes by discussing ways of testing\nthese hypotheses empirically.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2020 16:30:52 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 13:30:27 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Goekoop", "Rutger", "", "Parnassia Group, PsyQ, Netherlands"], ["de Kleijn", "Roy", "", "Leiden University"]]}, {"id": "2004.09874", "submitter": "Milena \\v{C}uki\\'c Dr", "authors": "Victoria Lopez and Milena \\v{C}uki\\'c", "title": "The comparison of trends in Spain and the Nederland: a Dynamical\n  compartment model of the transmission of Coronavirus", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph q-bio.NC q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent spreading of coronavirus made many countries impose restrictions\nin order to control its dangerous effect on the citizens. We developed a\ntheoretical dynamical model based on compartmental SIR system with additional\nadjustment taken from Flow network and Markov chain frameworks to illustrate\ndevelopments and trends based on publicly available data. Based on this Model,\ncode in R was written and fed by stamped publicly available data from\nauthorized governmental websites in Spain and in the Nederlands, to compare\ntrends. Our results show that the 'peak' of infection is already behind us in\nboth countries, but also demonstrate that there is a danger of rebound of a\nspread. It is obvious that measures imposed are giving the results, but we\nshould be precarious of near future practices and developments since the\nmajority of population will still be without immunity.\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 10:08:29 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 09:11:54 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Lopez", "Victoria", ""], ["\u010cuki\u0107", "Milena", ""]]}, {"id": "2004.10282", "submitter": "Malte Hoffmann", "authors": "Malte Hoffmann, Benjamin Billot, Juan Eugenio Iglesias, Bruce Fischl,\n  Adrian V. Dalca", "title": "Learning image registration without images", "comments": "17 pages, 12 figures, deformable image registration, contrast\n  invariance, training without data, expanded analyses", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a learning strategy for contrast-invariant image registration\nwithout requiring imaging data. While classical registration methods accurately\nestimate the spatial correspondence between images, they solve a costly\noptimization problem for every image pair. Learning-based techniques are fast\nat test time, but can only register images with image contrast and geometric\ncontent that are similar to those available during training. We focus on\nremoving this image-data dependency of learning methods. Our approach leverages\na generative model for diverse label maps and images that exposes networks to a\nwide range of variability during training, forcing them to learn features\ninvariant to image type (contrast). This strategy results in powerful networks\ntrained to generalize to a broad array of real input images. We present\nextensive experiments, with a focus on 3D neuroimaging, showing that this\nstrategy enables robust registration of arbitrary image contrasts without the\nneed to retrain for new modalities. We demonstrate registration accuracy that\nmost often surpasses the state of the art both within and across modalities,\nusing a single model. Critically, we show that input labels from which we\nsynthesize images need not be of actual anatomy: training on randomly generated\ngeometric shapes also results in competitive registration performance, albeit\nslightly less accurate, while alleviating the dependency on real data of any\nkind. Our code is available at: http://voxelmorph.csail.mit.edu\n", "versions": [{"version": "v1", "created": "Tue, 21 Apr 2020 20:29:39 GMT"}, {"version": "v2", "created": "Fri, 26 Jun 2020 18:24:37 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Hoffmann", "Malte", ""], ["Billot", "Benjamin", ""], ["Iglesias", "Juan Eugenio", ""], ["Fischl", "Bruce", ""], ["Dalca", "Adrian V.", ""]]}, {"id": "2004.10352", "submitter": "James Hope Mr", "authors": "James Hope, Matthew Goodwin, Frederique Vanholsbeeck", "title": "Optical coherence tomography imaging of evoked neural activity in\n  sciatic nerve of rat", "comments": "24 pages, 21 figures, journal article submission", "journal-ref": null, "doi": "10.1088/1361-6463/ac021b", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significance: Imaging neural activity in myelinated tissue using optical\ncoherence tomography (OCT) creates new possibilities for functional imaging in\nthe peripheral and central nervous systems. Aim: To investigate changes in OCT\nimages in response to evoked neural activity in sciatic nerve of rat in vitro.\nApproach: M-scans were obtained on peripheral nerves of rat using a swept\nsource polarisation sensitive OCT system, while a nerve cuff acquired\nelectrical neural recordings. From a total of 10 subjects: 3 had no stimulation\n(controls), 3 had paw stimulation, and 4 had nerve stimulation. Changes in the\nOCT signal intensity, phase retardation, phase, and frequency spectra were\ncalculated for each subject and reference samples of a mirror and microspheres\nin solution. Results: Observed changes in intensity in 3 paw stimulation and 2\nnerve stimulation subjects and changes in frequency spectra amplitude in 2 paw\nstimulation subjects were above the reference noise level and were temporally\nconsistent with osmotic swelling from ion currents during neural activity.\nConclusion: Light scattering changes produced by osmotic swelling, which have\npreviously been characterised in squid and crab nerve, are also thought to\noccur in myelinated fibres on a scale which is detectable using OCT\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 00:43:38 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2021 14:29:32 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Hope", "James", ""], ["Goodwin", "Matthew", ""], ["Vanholsbeeck", "Frederique", ""]]}, {"id": "2004.10642", "submitter": "Annika Hagemann", "authors": "Annika Hagemann, Jens Wilting, Bita Samimizad, Florian Mormann, Viola\n  Priesemann", "title": "Assessing criticality in pre-seizure single-neuron activity of human\n  epileptic cortex", "comments": "19 pages, 8 Figures", "journal-ref": "PLOS Computational Biology, 17(3), e1008773 (2021)", "doi": "10.1371/journal.pcbi.1008773", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epileptic seizures are characterized by abnormal and excessive neural\nactivity, where cortical network dynamics seem to become unstable. However,\nmost of the time, during seizure-free periods, cortex of epilepsy patients\nshows perfectly stable dynamics. This raises the question of how recurring\ninstability can arise in the light of this stable default state. In this work,\nwe examine two potential scenarios of seizure generation: (i) epileptic\ncortical areas might generally operate closer to instability, which would make\nepilepsy patients generally more susceptible to seizures, or (ii) epileptic\ncortical areas might drift systematically towards instability before seizure\nonset. We analyzed single-unit spike recordings from both the epileptogenic\n(focal) and the nonfocal cortical hemispheres of 20 epilepsy patients. We\nquantified the distance to instability in the framework of criticality, using a\nnovel estimator, which enables an unbiased inference from a small set of\nrecorded neurons. Surprisingly, we found no evidence for either scenario:\nNeither did focal areas generally operate closer to instability, nor were\nseizures preceded by a drift towards instability. In fact, our results from\nboth pre-seizure and seizure-free intervals suggest that despite epilepsy,\nhuman cortex operates in the stable, slightly subcritical regime, just like\ncortex of other healthy mammalians.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 15:38:08 GMT"}, {"version": "v2", "created": "Mon, 5 Apr 2021 14:53:58 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Hagemann", "Annika", ""], ["Wilting", "Jens", ""], ["Samimizad", "Bita", ""], ["Mormann", "Florian", ""], ["Priesemann", "Viola", ""]]}, {"id": "2004.10656", "submitter": "Benjamin Ambrosio", "authors": "M. Maama, B. Ambrosio and M.A. Aziz-Alaoui", "title": "Emergent Properties in a V1 Network of Hodgkin-Huxley Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article is devoted to the theoretical and numerical analysis of a\nnetwork of excitatory and inhibitory neurons of Hodgkin and Huxley type\ninspired by the visual cortex V1. The model emphasizes an approach combining a\ndriven stochastic drive for each neuron and recurrent inputs resulting from the\nnetwork activity. After a review of the dynamics of a single HH equation, for\nboth deterministic and stochastic driven case, we proceed to the analysis of\nthe network. Our numerical analysis highlights emergent properties such as\npartial synchronization and synchronization, waves of excitability, and\noscillations in the gamma-band frequency.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2020 16:47:16 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Maama", "M.", ""], ["Ambrosio", "B.", ""], ["Aziz-Alaoui", "M. A.", ""]]}, {"id": "2004.10658", "submitter": "Ian Jordan", "authors": "Ian D. Jordan and Il Memming Park", "title": "Birhythmic Analog Circuit Maze: A Nonlinear Neurostimulation Testbed", "comments": null, "journal-ref": null, "doi": "10.3390/e22050537", "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain dynamics can exhibit narrow-band nonlinear oscillations and\nmultistability. For a subset of disorders of consciousness and motor control,\nwe hypothesize that some symptoms originate from the inability to spontaneously\ntransition from one attractor to another. Using external perturbations, such as\nelectrical pulses delivered by deep brain stimulation devices, it may be\npossible to induce such transition out of the pathological attractors. However,\nthe induction of transition may be non-trivial, rendering the current open-loop\nstimulation strategies insufficient. In order to develop next-generation neural\nstimulators that can intelligently learn to induce attractor transitions, we\nrequire a platform to test the efficacy of such systems. To this end, we\ndesigned an analog circuit as a model for the multistable brain dynamics. The\ncircuit spontaneously oscillates stably on two periods as an instantiation of a\n3-dimensional continuous-time gated recurrent neural network. To discourage\nsimple perturbation strategies such as constant or random stimulation patterns\nfrom easily inducing transition between the stable limit cycles, we designed a\nstate-dependent nonlinear circuit interface for external perturbation. We\ndemonstrate the existence of nontrivial solutions to the transition problem in\nour circuit implementation.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2020 20:33:43 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Jordan", "Ian D.", ""], ["Park", "Il Memming", ""]]}, {"id": "2004.10671", "submitter": "Zachary Kilpatrick PhD", "authors": "Zachary P Kilpatrick, Jacob D Davidson, and Ahmed El Hady", "title": "Normative theory of patch foraging decisions", "comments": "28 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Foraging is a fundamental behavior as animals' search for food is crucial for\ntheir survival. Patch leaving is a canonical foraging behavior, but classic\ntheoretical conceptions of patch leaving decisions lack some key naturalistic\ndetails. Optimal foraging theory provides general rules for when an animal\nshould leave a patch, but does not provide mechanistic insights about how those\nrules change with the structure of the environment. Such a mechanistic\nframework would aid in designing quantitative experiments to unravel behavioral\nand neural underpinnings of foraging. To address these shortcomings, we develop\na normative theory of patch foraging decisions. Using a Bayesian approach, we\ntreat patch leaving behavior as a statistical inference problem. We derive the\nanimals' optimal decision strategies in both non-depleting and depleting\nenvironments. A majority of these cases can be analyzed explicitly using\nmethods from stochastic processes. Our behavioral predictions are expressed in\nterms of the optimal patch residence time and the decision rule by which an\nanimal departs a patch. We also extend our theory to a hierarchical model in\nwhich the forager learns the environmental food resource distribution. The\nquantitative framework we develop will therefore help experimenters move from\nanalyzing trial based behavior to continuous behavior without the loss of\nquantitative rigor. Our theoretical framework both extends optimal foraging\ntheory and motivates a variety of behavioral and neuroscientific experiments\ninvestigating patch foraging behavior.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 16:09:04 GMT"}], "update_date": "2020-04-23", "authors_parsed": [["Kilpatrick", "Zachary P", ""], ["Davidson", "Jacob D", ""], ["Hady", "Ahmed El", ""]]}, {"id": "2004.10832", "submitter": "Alexander Vasilyev", "authors": "Alexander Vasilyev", "title": "Control of fixation duration during visual search task execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the ability of human observer to control fixation duration during\nexecution of visual search tasks. We conducted the eye-tracking experiments\nwith natural and synthetic images and found the dependency of fixation duration\non difficulty of the task and the lengths of preceding and succeeding saccades.\nIn order to explain it, we developed the novel control model of human\neye-movements that incorporates continuous-time decision making, observation\nand update of belief state. This model is based on Partially Observable Markov\nDecision Process with delay in observation and saccade execution that accounts\nfor a delay between eye and cortex. We validated the computational model\nthrough comparison of statistical properties of simulated and experimental\neye-movement trajectories.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2020 20:25:01 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Vasilyev", "Alexander", ""]]}, {"id": "2004.11114", "submitter": "Patrick McClure", "authors": "Patrick McClure, Dustin Moraczewski, Ka Chun Lam, Adam Thomas,\n  Francisco Pereira", "title": "Improving the Interpretability of fMRI Decoding using Deep Neural\n  Networks and Adversarial Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) are being increasingly used to make predictions\nfrom functional magnetic resonance imaging (fMRI) data. However, they are\nwidely seen as uninterpretable \"black boxes\", as it can be difficult to\ndiscover what input information is used by the DNN in the process, something\nimportant in both cognitive neuroscience and clinical applications. A saliency\nmap is a common approach for producing interpretable visualizations of the\nrelative importance of input features for a prediction. However, methods for\ncreating maps often fail due to DNNs being sensitive to input noise, or by\nfocusing too much on the input and too little on the model. It is also\nchallenging to evaluate how well saliency maps correspond to the truly relevant\ninput information, as ground truth is not always available. In this paper, we\nreview a variety of methods for producing gradient-based saliency maps, and\npresent a new adversarial training method we developed to make DNNs robust to\ninput noise, with the goal of improving interpretability. We introduce two\nquantitative evaluation procedures for saliency map methods in fMRI, applicable\nwhenever a DNN or linear model is being trained to decode some information from\nimaging data. We evaluate the procedures using a synthetic dataset where the\ncomplex activation structure is known, and on saliency maps produced for DNN\nand linear models for task decoding in the Human Connectome Project (HCP)\ndataset. Our key finding is that saliency maps produced with different methods\nvary widely in interpretability, in both in synthetic and HCP fMRI data.\nStrikingly, even when DNN and linear models decode at comparable levels of\nperformance, DNN saliency maps score higher on interpretability than linear\nmodel saliency maps (derived via weights or gradient). Finally, saliency maps\nproduced with our adversarial training method outperform those from other\nmethods.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2020 12:56:24 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2020 16:15:40 GMT"}, {"version": "v3", "created": "Thu, 17 Dec 2020 16:01:57 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["McClure", "Patrick", ""], ["Moraczewski", "Dustin", ""], ["Lam", "Ka Chun", ""], ["Thomas", "Adam", ""], ["Pereira", "Francisco", ""]]}, {"id": "2004.11763", "submitter": "Sebastian Gottwald", "authors": "Sebastian Gottwald, Daniel A. Braun", "title": "The Two Kinds of Free Energy and the Bayesian Revolution", "comments": null, "journal-ref": "PLOS Computational Biology 16(12), 2020", "doi": "10.1371/journal.pcbi.1008420", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of free energy has its origins in 19th century thermodynamics,\nbut has recently found its way into the behavioral and neural sciences, where\nit has been promoted for its wide applicability and has even been suggested as\na fundamental principle of understanding intelligent behavior and brain\nfunction. We argue that there are essentially two different notions of free\nenergy in current models of intelligent agency, that can both be considered as\napplications of Bayesian inference to the problem of action selection: one that\nappears when trading off accuracy and uncertainty based on a general maximum\nentropy principle, and one that formulates action selection in terms of\nminimizing an error measure that quantifies deviations of beliefs and policies\nfrom given reference models. The first approach provides a normative rule for\naction selection in the face of model uncertainty or when information\nprocessing capabilities are limited. The second approach directly aims to\nformulate the action selection problem as an inference problem in the context\nof Bayesian brain theories, also known as Active Inference in the literature.\nWe elucidate the main ideas and discuss critical technical and conceptual\nissues revolving around these two notions of free energy that both claim to\napply at all levels of decision-making, from the high-level deliberation of\nreasoning down to the low-level information processing of perception.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 14:09:28 GMT"}, {"version": "v2", "created": "Sat, 15 Aug 2020 11:56:08 GMT"}, {"version": "v3", "created": "Thu, 10 Sep 2020 07:17:59 GMT"}, {"version": "v4", "created": "Mon, 7 Dec 2020 00:03:21 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Gottwald", "Sebastian", ""], ["Braun", "Daniel A.", ""]]}, {"id": "2004.11978", "submitter": "Andrea Bellotti", "authors": "Andrea Bellotti, Sergey Antopolskiy, Anna Marchenkova, Alessia\n  Colucciello, Pietro Avanzini, Giovanni Vecchiato, Jonas Ambeck-Madsen, Luca\n  Ascari", "title": "Brain-based control of car infotainment", "comments": null, "journal-ref": null, "doi": "10.1109/SMC.2019.8914448", "report-no": null, "categories": "cs.HC cs.LG eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the possibility to run advanced AI on embedded systems allows\nnatural interaction between humans and machines, especially in the automotive\nfield. We present a custom portable EEG-based Brain-Computer Interface (BCI)\nthat exploits Event-Related Potentials (ERPs) induced with an oddball\nexperimental paradigm to control the infotainment menu of a car. A preliminary\nevaluation of the system was performed on 10 participants in a standard\nlaboratory setting and while driving on a closed private track. The task\nconsisted of repeated presentations of 6 different menu icons in oddball\nfashion. Subject-specific models were trained with different machine learning\napproaches on cerebral data from either only laboratory or driving experiments\n(in-lab and in-car models) or a combination of the two (hybrid model) to\nclassify EEG responses to target and non-target stimuli. All models were tested\non the subjects' last in-car sessions that were not used for the training.\nAnalysis of ERPs amplitude showed statistically significant (p < 0.05)\ndifferences between the EEG responses associated with target and non-target\nicons, both in the laboratory and while driving. Classification Accuracy (CA)\nwas above chance level for all subjects in all training configurations, with a\ndeep CNN trained on the hybrid set achieving the highest scores (mean CA = 53\n$\\pm$ 12 %, with 16 % chance level for the 6-class discrimination). The ranking\nof the features importance provided by a classical BCI approach suggests an\nERP-based discrimination between target and non-target responses. No\nstatistical differences were observed between the CAs for the in-lab and in-car\ntraining sets, nor between the EEG responses in these conditions, indicating\nthat the data collected in the standard laboratory setting could be readily\nused for a real driving application without a noticeable decrease in\nperformance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2020 20:32:05 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Bellotti", "Andrea", ""], ["Antopolskiy", "Sergey", ""], ["Marchenkova", "Anna", ""], ["Colucciello", "Alessia", ""], ["Avanzini", "Pietro", ""], ["Vecchiato", "Giovanni", ""], ["Ambeck-Madsen", "Jonas", ""], ["Ascari", "Luca", ""]]}, {"id": "2004.12453", "submitter": "Alan Akil", "authors": "Alan Eric Akil, Robert Rosenbaum and Kre\\v{s}imir Josi\\'c", "title": "Synaptic Plasticity in Correlated Balanced Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamics of local cortical networks are irregular, but correlated.\nDynamic excitatory--inhibitory balance is a plausible mechanism that generates\nsuch irregular activity, but it remains unclear how balance is achieved and\nmaintained in plastic neural networks. In particular, it is not fully\nunderstood how plasticity induced changes in the network affect balance, and in\nturn, how correlated, balanced activity impacts learning. How does the dynamics\nof balanced networks change under different plasticity rules? How does\ncorrelated spiking activity in recurrent networks change the evolution of\nweights, their eventual magnitude, and structure across the network? To address\nthese questions, we develop a general theory of plasticity in balanced\nnetworks. We show that balance can be attained and maintained under plasticity\ninduced weight changes. We find that correlations in the input mildly, but\nsignificantly affect the evolution of synaptic weights. Under certain\nplasticity rules, we find an emergence of correlations between firing rates and\nsynaptic weights. Under these rules, synaptic weights converge to a stable\nmanifold in weight space with their final configuration dependent on the\ninitial state of the network. Lastly, we show that our framework can also\ndescribe the dynamics of plastic balanced networks when subsets of neurons\nreceive targeted optogenetic input.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2020 18:40:46 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Akil", "Alan Eric", ""], ["Rosenbaum", "Robert", ""], ["Josi\u0107", "Kre\u0161imir", ""]]}, {"id": "2004.12669", "submitter": "Andrei Khrennikov Yu", "authors": "Andrei Khrennikov", "title": "Social laser model for the Bandwagon effect: generation of coherent\n  information waves", "comments": null, "journal-ref": "Entropy 2020, 22(5), 559", "doi": "10.3390/e22050559", "report-no": null, "categories": "physics.soc-ph q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last years our society was often exposed to the coherent\ninformation waves of high amplitudes. These are waves of huge social energy.\nOften they are of the destructive character, a kind of information tsunami.\nBut, they can carry as well positive improvements in the human society, as\nwaves of decision making matching rational recommendations of societal\ninstitutes. The main distinguishing features of these waves are their high\namplitude, coherence (homogeneous character of social actions generated by\nthem), and short time needed for their generation and relaxation. Such waves\ncan be treated as large scale exhibition of the Bandwagon effect. We show that\nthis socio-psychic phenomenon can be modeled on the basis of the recently\ndeveloped {\\it social laser theory}. This theory can be used to model {\\it\nstimulated amplification of coherent social actions}. \"Actions\" are treated\nvery generally, from mass protests to votes and other collective decisions, as,\ne.g., acceptance (often unconscious) of some societal recommendations. In this\npaper, we concentrate on theory of laser resonators, physical vs. social. For\nthe latter, we analyze in very detail functioning of the internet based\nEcho-Chambers. Their main purpose is increasing of the power of the quantum\ninformation field as well as its coherence. Of course, the Bandwagon effect is\nwell known and well studied in social psychology. However, the social laser\ntheory gives the possibility to model it by using the general formalism of\nquantum field theory. The paper contains minimum of mathematics and it can be\nreadable by researchers working in psychology, cognitive, social, and political\nsciences; it might also be interesting for experts in information theory and\nartificial intelligence.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 09:36:23 GMT"}], "update_date": "2020-12-18", "authors_parsed": [["Khrennikov", "Andrei", ""]]}, {"id": "2004.12676", "submitter": "Alban Bornet", "authors": "Adrien Doerig, Alban Bornet, Oh-Hyeon Choung, Micahel H. Herzog", "title": "Crowding Reveals Fundamental Differences in Local vs. Global Processing\n  in Humans and Machines", "comments": null, "journal-ref": "Vision Research, 167, 39-45 (2020)", "doi": "10.1016/j.visres.2019.12.006", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Feedforward Convolutional Neural Networks (ffCNNs) have become\nstate-of-the-art models both in computer vision and neuroscience. However,\nhuman-like performance of ffCNNs does not necessarily imply human-like\ncomputations. Previous studies have suggested that current ffCNNs do not make\nuse of global shape information. However, it is currently unclear whether this\nreflects fundamental differences between ffCNN and human processing or is\nmerely an artefact of how ffCNNs are trained. Here, we use visual crowding as a\nwell-controlled, specific probe to test global shape computations. Our results\nprovide evidence that ffCNNs cannot produce human-like global shape\ncomputations for principled architectural reasons. We lay out approaches that\nmay address shortcomings of ffCNNs to provide better models of the human visual\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 09:43:27 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Doerig", "Adrien", ""], ["Bornet", "Alban", ""], ["Choung", "Oh-Hyeon", ""], ["Herzog", "Micahel H.", ""]]}, {"id": "2004.12926", "submitter": "Greg Hager", "authors": "Polina Golland, Jack Gallant, Greg Hager, Hanspeter Pfister, Christos\n  Papadimitriou, Stefan Schaal, and Joshua T. Vogelstein", "title": "A New Age of Computing and the Brain", "comments": "A Computing Community Consortium (CCC) workshop report, 24 pages", "journal-ref": null, "doi": null, "report-no": "ccc2014report_5", "categories": "cs.CY cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The history of computer science and brain sciences are intertwined. In his\nunfinished manuscript \"The Computer and the Brain,\" von Neumann debates whether\nor not the brain can be thought of as a computing machine and identifies some\nof the similarities and differences between natural and artificial computation.\nTuring, in his 1950 article in Mind, argues that computing devices could\nultimately emulate intelligence, leading to his proposed Turing test. Herbert\nSimon predicted in 1957 that most psychological theories would take the form of\na computer program. In 1976, David Marr proposed that the function of the\nvisual system could be abstracted and studied at computational and algorithmic\nlevels that did not depend on the underlying physical substrate.\n  In December 2014, a two-day workshop supported by the Computing Community\nConsortium (CCC) and the National Science Foundation's Computer and Information\nScience and Engineering Directorate (NSF CISE) was convened in Washington, DC,\nwith the goal of bringing together computer scientists and brain researchers to\nexplore these new opportunities and connections, and develop a new, modern\ndialogue between the two research communities. Specifically, our objectives\nwere: 1. To articulate a conceptual framework for research at the interface of\nbrain sciences and computing and to identify key problems in this interface,\npresented in a way that will attract both CISE and brain researchers into this\nspace. 2. To inform and excite researchers within the CISE research community\nabout brain research opportunities and to identify and explain strategic roles\nthey can play in advancing this initiative. 3. To develop new connections,\nconversations and collaborations between brain sciences and CISE researchers\nthat will lead to highly relevant and competitive proposals, high-impact\nresearch, and influential publications.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2020 16:38:17 GMT"}], "update_date": "2020-04-28", "authors_parsed": [["Golland", "Polina", ""], ["Gallant", "Jack", ""], ["Hager", "Greg", ""], ["Pfister", "Hanspeter", ""], ["Papadimitriou", "Christos", ""], ["Schaal", "Stefan", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "2004.13256", "submitter": "Ze Wang", "authors": "Ze Wang", "title": "Assessing the neurocognitive correlates of resting brain entropy", "comments": "Part of the work is accepted for presentation in ISMRM 2020", "journal-ref": "Neuroimage 2021", "doi": "10.1016/j.neuroimage.2021.117893", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain exhibits large-scale spontaneous fluctuations that account\nfor most of its total energy metabolism. Independent of any overt function,\nthis immense ongoing activity likely creates or maintains a potential\nfunctional brain reserve to facilitate normal brain function. An important\nproperty of spontaneous brain activity is the long-range temporal coherence,\nwhich can be characterized by resting state fMRI-based brain entropy mapping\n(BEN), a relatively new method that has gained increasing research interest.\nThe purpose of this study was to leverage the large resting state fMRI and\nbehavioral data publicly available from the human connectome project to address\nthree important but still unknown questions: temporal stability of\nrsfMRI-derived BEN; the relationship of resting BEN to latent functional\nreserve; associations of resting BEN to neurocognition. Our results showed that\nrsfMRI-derived BEN was highly stable across time; resting BEN in the default\nmode network (DMN) and executive control network (ECN) was related to brain\nreserve in a negative correlation to education years; and lower DMN/ECN BEN\ncorresponds to higher fluid intelligence and better task performance. These\nresults suggest that resting BEN is a temporally stable brain trait; BEN in\nDMN/ECN may provide a means to measure the latent functional reserve that\nbestows better brain functionality and may be enhanced by education.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 02:55:36 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Wang", "Ze", ""]]}, {"id": "2004.13361", "submitter": "Manuel Morante", "authors": "Manuel Morante", "title": "A lite parametric model for the Hemodynamic Response Function", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When working with task-related fMRI data, one of the most crucial parts of\nthe data analysis consists of determining a proper estimate of the BOLD\nresponse. The following document presents a lite model for the Hemodynamic\nResponse Function HRF. Between other advances, the proposed model present less\nnumber of parameters compared to other similar HRF alternative, which reduces\nits optimization complexity and facilitates its potential applications.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 08:29:41 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Morante", "Manuel", ""]]}, {"id": "2004.13376", "submitter": "Fabio Angelo Maccheroni", "authors": "Simone Cerreia-Vioglio, Fabio Maccheroni, Massimo Marinacci, and Aldo\n  Rustichini", "title": "Multinomial logit processes and preference discovery: inside and outside\n  the black box", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "econ.TH q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide two characterizations, one axiomatic and the other\nneuro-computational, of the dependence of choice probabilities on deadlines,\nwithin the widely used softmax representation \\[ p_{t}\\left( a,A\\right)\n=\\dfrac{e^{\\frac{u\\left( a\\right) }{\\lambda \\left( t\\right) }+\\alpha \\left(\na\\right) }}{\\sum_{b\\in A}e^{\\frac{u\\left( b\\right) }{\\lambda \\left( t\\right)\n}+\\alpha \\left( b\\right) }}% \\] where $p_{t}\\left( a,A\\right) $ is the\nprobability that alternative $a$ is selected from the set $A$ of feasible\nalternatives if $t$ is the time available to decide, $\\lambda$ is a time\ndependent noise parameter measuring the unit cost of information, $u$ is a time\nindependent utility function, and $\\alpha$ is an alternative-specific bias that\ndetermines the initial choice probabilities reflecting prior information and\nmemory anchoring.\n  Our axiomatic analysis provides a behavioral foundation of softmax (also\nknown as Multinomial Logit Model when $\\alpha$ is constant). Our\nneuro-computational derivation provides a biologically inspired algorithm that\nmay explain the emergence of softmax in choice behavior. Jointly, the two\napproaches provide a thorough understanding of soft-maximization in terms of\ninternal causes (neurophysiological mechanisms) and external effects (testable\nimplications).\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 09:10:40 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 21:21:00 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 09:26:24 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Cerreia-Vioglio", "Simone", ""], ["Maccheroni", "Fabio", ""], ["Marinacci", "Massimo", ""], ["Rustichini", "Aldo", ""]]}, {"id": "2004.13462", "submitter": "Charles Hudin", "authors": "Charles Hudin and Vincent Hayward", "title": "When Hearing Defers to Touch", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hearing is often believed to be more sensitive than touch. This assertion is\nbased on a comparison of sensitivities to weak stimuli. The respective stimuli,\nhowever, are not easily comparable since hearing is gauged using acoustic\npressure and touch using skin displacement. We show that under reasonable\nassumptions the auditory and tactile detection thresholds can be reconciled on\na level playing field. The results indicate that the capacity of touch and\nhearing to detect weak stimuli varies according to the size of a sensed object\nas well as to the frequency of its oscillations. In particular, touch is found\nto be more effective than hearing at detecting small and slow objects.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 12:47:04 GMT"}, {"version": "v2", "created": "Thu, 7 May 2020 06:56:21 GMT"}], "update_date": "2020-05-08", "authors_parsed": [["Hudin", "Charles", ""], ["Hayward", "Vincent", ""]]}, {"id": "2004.13532", "submitter": "Richard Gerum", "authors": "Richard C. Gerum, Achim Schilling", "title": "Integration of Leaky-Integrate-and-Fire-Neurons in Deep Learning\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Up to now, modern Machine Learning is mainly based on fitting high\ndimensional functions to enormous data sets, taking advantage of huge hardware\nresources. We show that biologically inspired neuron models such as the\nLeaky-Integrate-and-Fire (LIF) neurons provide novel and efficient ways of\ninformation encoding. They can be integrated in Machine Learning models, and\nare a potential target to improve Machine Learning performance.\n  Thus, we derived simple update-rules for the LIF units from the differential\nequations, which are easy to numerically integrate. We apply a novel approach\nto train the LIF units supervisedly via backpropagation, by assigning a\nconstant value to the derivative of the neuron activation function exclusively\nfor the backpropagation step. This simple mathematical trick helps to\ndistribute the error between the neurons of the pre-connected layer. We apply\nour method to the IRIS blossoms image data set and show that the training\ntechnique can be used to train LIF neurons on image classification tasks.\nFurthermore, we show how to integrate our method in the KERAS (tensorflow)\nframework and efficiently run it on GPUs. To generate a deeper understanding of\nthe mechanisms during training we developed interactive illustrations, which we\nprovide online.\n  With this study we want to contribute to the current efforts to enhance\nMachine Intelligence by integrating principles from biology.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2020 13:57:42 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2020 13:27:06 GMT"}], "update_date": "2020-09-14", "authors_parsed": [["Gerum", "Richard C.", ""], ["Schilling", "Achim", ""]]}, {"id": "2004.14185", "submitter": "Simon Van Eyndhoven", "authors": "Simon Van Eyndhoven, Patrick Dupont, Simon Tousseyn, Nico Vervliet,\n  Wim Van Paesschen, Sabine Van Huffel, Borb\\'ala Hunyadi", "title": "Augmenting interictal mapping with neurovascular coupling biomarkers by\n  structured factorization of epileptic EEG and fMRI data", "comments": null, "journal-ref": null, "doi": null, "report-no": "20-59", "categories": "eess.SP cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EEG-correlated fMRI analysis is widely used to detect regional blood oxygen\nlevel dependent fluctuations that are significantly synchronized to interictal\nepileptic discharges, which can provide evidence for localizing the ictal onset\nzone. However, such an asymmetrical, mass-univariate approach cannot capture\nthe inherent, higher order structure in the EEG data, nor multivariate\nrelations in the fMRI data, and it is nontrivial to accurately handle varying\nneurovascular coupling over patients and brain regions. We aim to overcome\nthese drawbacks in a data-driven manner by means of a novel structured\nmatrix-tensor factorization: the single-subject EEG data (represented as a\nthird-order spectrogram tensor) and fMRI data (represented as a spatiotemporal\nBOLD signal matrix) are jointly decomposed into a superposition of several\nsources, characterized by space-time-frequency profiles. In the shared temporal\nmode, Toeplitz-structured factors account for a spatially specific,\nneurovascular `bridge' between the EEG and fMRI temporal fluctuations,\ncapturing the hemodynamic response's variability over brain regions. We show\nthat the extracted source signatures provide a sensitive localization of the\nictal onset zone, and, moreover, that complementary localizing information can\nbe derived from the spatial variation of the hemodynamic response. Hence, this\nmultivariate, multimodal factorization provides two useful sets of EEG-fMRI\nbiomarkers, which can inform the presurgical evaluation of epilepsy. We make\nall code required to perform the computations available.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 13:27:45 GMT"}], "update_date": "2020-05-04", "authors_parsed": [["Van Eyndhoven", "Simon", ""], ["Dupont", "Patrick", ""], ["Tousseyn", "Simon", ""], ["Vervliet", "Nico", ""], ["Van Paesschen", "Wim", ""], ["Van Huffel", "Sabine", ""], ["Hunyadi", "Borb\u00e1la", ""]]}, {"id": "2004.14580", "submitter": "Md Navid Akbar", "authors": "Md Navid Akbar, Marianna La Rocca, Rachael Garner, Dominique Duncan,\n  Deniz Erdo\\u{g}mu\\c{s}", "title": "Prediction of Epilepsy Development in Traumatic Brain Injury Patients\n  from Diffusion Weighted MRI", "comments": "2 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-traumatic epilepsy (PTE) is a life-long complication of traumatic brain\ninjury (TBI) and is a major public health problem that has an estimated\nincidence that ranges from 2%-50%, depending on the severity of the TBI.\nCurrently, the pathomechanism that in-duces epileptogenesis in TBI patients is\nunclear, and one of the most challenging goals in the epilepsy community is to\npredict which TBI patients will develop epilepsy. In this work, we used\ndiffusion-weighted imaging (DWI) of 14 TBI patients recruited in the Epilepsy\nBioinformatics Study for Antiepileptogenic Therapy (EpiBioS4Rx)to measure and\nanalyze fractional anisotropy (FA), obtained from tract-based spatial statistic\n(TBSS) analysis. Then we used these measurements to train two support vector\nmachine (SVM) models to predict which TBI patients have developed epilepsy. Our\napproach, tested on these 14 patients with a leave-two-out cross-validation,\nallowed us to obtain an accuracy of 0.857 $\\pm$ 0.18 (with a 95% level of\nconfidence), demonstrating it to be potentially promising for the early\ncharacterization of PTE.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2020 04:06:24 GMT"}, {"version": "v2", "created": "Fri, 1 May 2020 22:22:57 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Akbar", "Md Navid", ""], ["La Rocca", "Marianna", ""], ["Garner", "Rachael", ""], ["Duncan", "Dominique", ""], ["Erdo\u011fmu\u015f", "Deniz", ""]]}, {"id": "2004.14802", "submitter": "Kasturi Saha", "authors": "Madhur Parashar, Kasturi Saha, Sharba Bandyopadhyay", "title": "Axon Hillock Currents Allow Single-Neuron-Resolution 3-Dimensional\n  Functional Neural Imaging Using Diamond Quantum Defect-Based Vector\n  Magnetometry", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.mes-hall physics.app-ph quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetic field sensing, with its recent advances, is emerging as a viable\nalternative to measure functional activity of single neurons in the brain by\nsensing action potential associated magnetic fields (APMFs). Measurement of\nAPMFs of large axons of worms have been possible due to their size. In the\nmammalian brain, axon sizes, their numbers and routes, restricts using such\nfunctional imaging methods. With segmented model of mammalian pyramidal\nneurons, we show that the APMF of intra-axonal currents in the axon hillock are\ntwo orders of magnitude larger than other neuronal locations. Expected\n2-dimensional vector magnetic field maps of naturalistic spiking activity of a\nvolume of neurons via widefield diamond-nitrogen-vacancy-center-magnetometry\n(DNVM) were simulated. A dictionary based matching pursuit type algorithm\napplied to the data using the axon-hillock's APMF signature allowed\nspatiotemporal reconstruction of APs in the volume of brain tissue at single\ncell resolution. Enhancement of APMF signals coupled with NVMM advances thus\ncan potentially replace current functional brain mapping techniques.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 03:49:41 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Parashar", "Madhur", ""], ["Saha", "Kasturi", ""], ["Bandyopadhyay", "Sharba", ""]]}, {"id": "2004.14829", "submitter": "Korbinian Schreiber", "authors": "K. Schreiber, T. C. Wunderlich, C. Pehle, M. A. Petrovici, J.\n  Schemmel, and K. Meier", "title": "Closed-loop experiments on the BrainScaleS-2 architecture", "comments": "Neuro-inspired Computational Elements Workshop (NICE 2020). arXiv\n  admin note: text overlap with arXiv:1912.12980", "journal-ref": null, "doi": "10.1145/3381755.3381776", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evolution of biological brains has always been contingent on their\nembodiment within their respective environments, in which survival required\nappropriate navigation and manipulation skills. Studying such interactions thus\nrepresents an important aspect of computational neuroscience and, by extension,\na topic of interest for neuromorphic engineering. Here, we present three\nexamples of embodiment on the BrainScaleS-2 architecture, in which dynamical\ntimescales of both agents and environment are accelerated by several orders of\nmagnitude with respect to their biological archetypes.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2020 12:15:24 GMT"}], "update_date": "2020-05-01", "authors_parsed": [["Schreiber", "K.", ""], ["Wunderlich", "T. C.", ""], ["Pehle", "C.", ""], ["Petrovici", "M. A.", ""], ["Schemmel", "J.", ""], ["Meier", "K.", ""]]}]