[{"id": "1603.00058", "submitter": "Eero Simoncelli", "authors": "Deep Ganguli and Eero P. Simoncelli", "title": "Neural and perceptual signatures of efficient sensory coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mammalian brain is a metabolically expensive device, and evolutionary\npressures have presumably driven it to make productive use of its resources.\nFor sensory areas, this concept has been expressed more formally as an\noptimality principle: the brain maximizes the information that is encoded about\nrelevant sensory variables, given available resources. Here, we develop this\nefficiency principle for encoding a sensory variable with a heterogeneous\npopulation of noisy neurons, each responding to a particular range of values.\nThe accuracy with which the population represents any particular value depends\non the number of cells that respond to that value, their selectivity, and their\nresponse levels. We derive the optimal solution for these parameters in closed\nform, as a function of the probability of stimulus values encountered in the\nenvironment. This optimal neural population also imposes limitations on the\nability of the organism to discriminate different values of the encoded\nvariable. As a result, we predict an explicit relationship between the\nstatistical properties of the environment, the allocation and selectivity of\nneurons within populations, and perceptual discriminability. We test this\nrelationship for three visual and two auditory attributes, and find that it is\nremarkably consistent with existing data.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 21:40:36 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Ganguli", "Deep", ""], ["Simoncelli", "Eero P.", ""]]}, {"id": "1603.00097", "submitter": "Marcel Nonnenmacher", "authors": "Marcel Nonnenmacher, Christian Behrens, Philipp Berens, Matthias\n  Bethge, Jakob H Macke", "title": "Signatures of criticality arise in simple neural population models with\n  correlations", "comments": "36 pages, LaTeX; added journal reference on page 1, added link to\n  code repository", "journal-ref": "PLoS Comput Biol 13(10): e1005718 (2017)", "doi": "10.1371/journal.pcbi.1005718", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale recordings of neuronal activity make it possible to gain insights\ninto the collective activity of neural ensembles. It has been hypothesized that\nneural populations might be optimized to operate at a 'thermodynamic critical\npoint', and that this property has implications for information processing.\nSupport for this notion has come from a series of studies which identified\nstatistical signatures of criticality in the ensemble activity of retinal\nganglion cells. What are the underlying mechanisms that give rise to these\nobservations? Here we show that signatures of criticality arise even in simple\nfeed-forward models of retinal population activity. In particular, they occur\nwhenever neural population data exhibits correlations, and is randomly\nsub-sampled during data analysis. These results show that signatures of\ncriticality are not necessarily indicative of an optimized coding strategy, and\nchallenge the utility of analysis approaches based on equilibrium\nthermodynamics for understanding partially observed biological systems.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 23:52:46 GMT"}, {"version": "v2", "created": "Wed, 31 Jan 2018 16:35:58 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Nonnenmacher", "Marcel", ""], ["Behrens", "Christian", ""], ["Berens", "Philipp", ""], ["Bethge", "Matthias", ""], ["Macke", "Jakob H", ""]]}, {"id": "1603.00200", "submitter": "Javier Buldu", "authors": "David Papo, Massimiliano Zanin, Johann H. Mart\\'inez, and Javier M.\n  Buld\\'u", "title": "Beware of the Small-World neuroscientist!", "comments": null, "journal-ref": "Front. Hum. Neurosci. 10:96 (2016)", "doi": "10.3389/fnhum.2016.00096", "report-no": null, "categories": "q-bio.NC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The SW has undeniably been one of the most popular network descriptors in the\nneuroscience literature. Two main reasons for its lasting popularity are its\napparent ease of computation and the intuitions it is thought to provide on how\nnetworked systems operate. Over the last few years, some pitfalls of the SW\nconstruct and, more generally, of network summary measures, have widely been\nacknowledged.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 09:44:36 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Papo", "David", ""], ["Zanin", "Massimiliano", ""], ["Mart\u00ednez", "Johann H.", ""], ["Buld\u00fa", "Javier M.", ""]]}, {"id": "1603.00201", "submitter": "William Hedley Thompson", "authors": "William Hedley Thompson and Peter Fransson", "title": "On stabilizing the variance of dynamic functional brain connectivity\n  time series", "comments": "20 pages, 5 figures + 1 supplementary figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessment of dynamic functional brain connectivity (dFC) based on fMRI data\nis an increasingly popular strategy to investigate temporal dynamics of the\nbrain's large-scale network architecture. Current practice when deriving\nconnectivity estimates over time is to use the Fisher transform which aims to\nstabilize the variance of correlation values that fluctuate around varying true\ncorrelation values. It is however unclear how well the stabilization of signal\nvariance performed by the Fisher transform works for each connectivity time\nseries, when the true correlation is assumed to be fluctuating. This is of\nimportance because many subsequent analyses either assume or perform better\nwhen the time series have stable variance or adheres to an approximate Gaussian\ndistribution. In this paper, using simulations and analysis of resting-state\nfMRI data, we analyze the effect of applying different variance stabilization\nstrategies on connectivity time-series. We here focus our investigation on the\nFisher transform, the Box Cox transform and an approach that combines both\ntransforms. Our results show that, if the intention of stabilizing the variance\nis to use metrics on the time series where stable variance or a Gaussian\ndistribution is desired (e.g. clustering), the Fisher transform is not optimal\nand may even skew connectivity time series away from being Gaussian. Further,\nwe show that the suboptimal performance of the Fisher transform can be\nsubstantially improved by including an additional Box-Cox transformation after\nthe dFC time series has been Fisher transformed.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 09:51:07 GMT"}, {"version": "v2", "created": "Wed, 13 Apr 2016 13:38:58 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Thompson", "William Hedley", ""], ["Fransson", "Peter", ""]]}, {"id": "1603.00397", "submitter": "Carlos Eduardo Cardoso Galhardo", "authors": "C.E.C. Galhardo, B. C. Coutinho, T.J.P.Penna, M.A. de Menezes and\n  P.P.S. Soares", "title": "A Langevin model for complex cardiological time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been considerable efforts to understand the underlying complex\ndynamics in physiological time series. Methods originated from statistical\nphysics revealed a non-Gaussian statistics and long range correlations in those\nsignals. This suggests that the regulatory system operates out of equilibrium.\nHerein the complex fluctuations in blood pressure time series were successful\ndescribed by physiological motivated Langevin equation under a sigmoid\nrestoring force with multiplicative noise.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 18:44:23 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Galhardo", "C. E. C.", ""], ["Coutinho", "B. C.", ""], ["Penna", "T. J. P.", ""], ["de Menezes", "M. A.", ""], ["Soares", "P. P. S.", ""]]}, {"id": "1603.00415", "submitter": "Leo Ai", "authors": "Leo Ai, Jerel K. Mueller, Andrea Grant, Yigitcan Eryaman, and Wynn\n  Legon", "title": "Transcranial Focused Ultrasound for BOLD fMRI Signal Modulation in\n  Humans", "comments": "EMBC 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transcranial focused ultrasound (tFUS) is an emerging form of non-surgical\nhuman neuromodulation that confers advantages over existing electro and\nelectromagnetic technologies by providing a superior spatial resolution on the\nmillimeter scale as well as the capability to target sub-cortical structures\nnon-invasively. An examination of the pairing of tFUS and blood oxygen level\ndependent (BOLD) functional MRI (fMRI) in humans is presented here.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 19:22:12 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Ai", "Leo", ""], ["Mueller", "Jerel K.", ""], ["Grant", "Andrea", ""], ["Eryaman", "Yigitcan", ""], ["Legon", "Wynn", ""]]}, {"id": "1603.00500", "submitter": "Werner Van Geit", "authors": "Werner Van Geit, Michael Gevaert, Giuseppe Chindemi, Christian\n  R\\\"ossert, Jean-Denis Courcol, Eilif Muller, Felix Sch\\\"urmann, Idan Segev\n  and Henry Markram", "title": "BluePyOpt: Leveraging open source software and cloud infrastructure to\n  optimise model parameters in neuroscience", "comments": null, "journal-ref": "Front. Neuroinform., 07 June 2016", "doi": "10.3389/fninf.2016.00017", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At many scales in neuroscience, appropriate mathematical models take the form\nof complex dynamical systems. Parametrising such models to conform to the\nmultitude of available experimental constraints is a global nonlinear\noptimisation problem with a complex fitness landscape, requiring numerical\ntechniques to find suitable approximate solutions. Stochastic optimisation\napproaches, such as evolutionary algorithms, have been shown to be effective,\nbut often the setting up of such optimisations and the choice of a specific\nsearch algorithm and its parameters is non-trivial, requiring domain-specific\nexpertise. Here we describe BluePyOpt, a Python package targeted at the broad\nneuroscience community to simplify this task. BluePyOpt is an extensible\nframework for data-driven model parameter optimisation that wraps and\nstandardises several existing open-source tools. It simplifies the task of\ncreating and sharing these optimisations, and the associated techniques and\nknowledge. This is achieved by abstracting the optimisation and evaluation\ntasks into various reusable and flexible discrete elements according to\nestablished best-practices. Further, BluePyOpt provides methods for setting up\nboth small- and large-scale optimisations on a variety of platforms, ranging\nfrom laptops to Linux clusters and cloud-based compute infrastructures. The\nversatility of the BluePyOpt framework is demonstrated by working through three\nrepresentative neuroscience specific use cases.\n", "versions": [{"version": "v1", "created": "Tue, 1 Mar 2016 21:43:14 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Van Geit", "Werner", ""], ["Gevaert", "Michael", ""], ["Chindemi", "Giuseppe", ""], ["R\u00f6ssert", "Christian", ""], ["Courcol", "Jean-Denis", ""], ["Muller", "Eilif", ""], ["Sch\u00fcrmann", "Felix", ""], ["Segev", "Idan", ""], ["Markram", "Henry", ""]]}, {"id": "1603.00802", "submitter": "Christoph Adami", "authors": "Ali Tehrani-Saleh and Christoph Adami", "title": "Flies as Ship Captains? Digital Evolution Unravels Selective Pressures\n  to Avoid Collision in Drosophila", "comments": "8 pages, 10 figures, submitted to 15th Artificial Life conference\n  (ALife 2016)", "journal-ref": "Proceedings Artificial Life 15 (C. Gershenson, T. Froese, J.M.\n  Sisqueiros, W. Aguilar, E.J. Izquierdo, H. Sayama, eds.) MIT Press\n  (Cambridge, MA, 2016), pp. 554-561", "doi": "10.7551/978-0-262-33936-0-ch089", "report-no": null, "categories": "q-bio.PE cs.CV nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flies that walk in a covered planar arena on straight paths avoid colliding\nwith each other, but which of the two flies stops is not random.\nHigh-throughput video observations, coupled with dedicated experiments with\ncontrolled robot flies have revealed that flies utilize the type of optic flow\non their retina as a determinant of who should stop, a strategy also used by\nship captains to determine which of two ships on a collision course should\nthrow engines in reverse. We use digital evolution to test whether this\nstrategy evolves when collision avoidance is the sole penalty. We find that the\nstrategy does indeed evolve in a narrow range of cost/benefit ratios, for\nexperiments in which the \"regressive motion\" cue is error free. We speculate\nthat these stringent conditions may not be sufficient to evolve the strategy in\nreal flies, pointing perhaps to auxiliary costs and benefits not modeled in our\nstudy\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 17:36:31 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Tehrani-Saleh", "Ali", ""], ["Adami", "Christoph", ""]]}, {"id": "1603.00904", "submitter": "Vince Grolmusz", "authors": "Bal\\'azs Szalkai, B\\'alint Varga, Vince Grolmusz", "title": "The Graph of Our Mind", "comments": "arXiv admin note: substantial text overlap with arXiv:1512.01156,\n  arXiv:1501.00727", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph theory in the last two decades penetrated sociology, molecular biology,\ngenetics, chemistry, computer engineering, and numerous other fields of\nscience. One of the more recent areas of its applications is the study of the\nconnections of the human brain. By the development of diffusion magnetic\nresonance imaging (diffusion MRI), it is possible today to map the connections\nbetween the 1-1.5 cm$^2$ regions of the gray matter of the human brain. These\nconnections can be viewed as a graph: the vertices are the anatomically\nidentified regions of the gray matter, and two vertices are connected by an\nedge if the diffusion MRI-based workflow finds neuronal fiber tracts between\nthese areas. This way we can compute 1015-vertex graphs with tens of thousands\nof edges. In a previous work, we have analyzed the male and female braingraphs\ngraph-theoretically, and we have found statistically significant differences in\nnumerous parameters between the sexes: the female braingraphs are better\nexpanders, have more edges, larger bipartition widths, and larger vertex cover\nthan the braingraphs of the male subjects. Our previous study has applied the\ndata of 96 subjects; here we present a much larger study of 426 subjects. Our\ndata source is an NIH-founded project, the \"Human Connectome Project (HCP)\"\npublic data release. As a service to the community, we have also made all of\nthe braingraphs computed by us from the HCP data publicly available at the\n\\url{http://braingraph.org} for independent validation and further\ninvestigations.\n", "versions": [{"version": "v1", "created": "Wed, 2 Mar 2016 21:52:50 GMT"}, {"version": "v2", "created": "Tue, 17 Mar 2020 22:35:59 GMT"}], "update_date": "2020-03-19", "authors_parsed": [["Szalkai", "Bal\u00e1zs", ""], ["Varga", "B\u00e1lint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1603.01077", "submitter": "Pouya Ghaemmaghami Tabrizi", "authors": "Pouya Ghaemmaghami", "title": "Functional Connectivity in Default Mode Network During Resting State: An\n  Evaluation of the Effects of Data Pre-processing", "comments": "Master's thesis, July 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resting state functional connectivity estimates from MRI measures has become\na promising tool to characterize human brain networks. There are, however,\nlimitations in the method since several sources of errors have been seen to\nsignificantly affect the final estimates. This has lead to a great interest in\nthe field to do systematic investigations that help determine the most reliable\nand robust strategies to perform functional connectivity analysis. In the\npresent study, we examine the influence of two aspects of data pre- processing\nin resting state functional connectivity analysis: the effect of criteria used\nto select nodes in the default mode network (DMN) for the computation of\nconnectivity, and the effect of using or not physiological noise correction.\nThree different strategies of region of interest (ROI) selection were compared\nto define DMN node coordinates: (1) ROIs centered on atlas-based coordinates,\n(2) ROIs based on the result of group independent component analysis, and (3)\nROIs based on the estimated DMN of each individual. The study was done using\ndata of 15 healthy volunteers, which had resting state data available from a\nseparate project. We found that both effects, ROI selection criteria for DMN\nnodes and physiological noise correction, have significant effects on the\nfunctional connectivity estimates. In particular, our results show that\nphysiological noise correction introduces small but significant reductions in\nfunctional connectivity, consistent with a reduction of artifactual non-neural\ncorrelations introduced by physiological effects. Further, selecting DMN nodes\nbased on the single subject ICA results introduced small but significant\nincreases in functional connectivity, consistent with higher subject\nspecificity of the node selection.\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2016 12:49:09 GMT"}], "update_date": "2016-03-04", "authors_parsed": [["Ghaemmaghami", "Pouya", ""]]}, {"id": "1603.01160", "submitter": "Hanna Keren", "authors": "Hanna Keren and Shimon Marom", "title": "Long-range synchrony and emergence of reentry in neural networks", "comments": null, "journal-ref": null, "doi": "10.1038/srep36837", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronization across long neural distances is a functionally important\nphenomenon. In order to access the mechanistic basis of long-range synchrony,\nwe constructed an experimental model that enables monitoring of spiking\nactivities over centimeter scale distances in large random networks of cortical\nneutrons. We show that the mode of synchrony over these distances depends upon\na length scale, $\\lambda$, which is the minimal path that activity should\ntravel through before meeting its point of origin ready for reactivation. When\n$\\lambda$ is experimentally made larger than the physical dimension of the\nnetwork, distant neuronal populations operate synchronously, giving rise to\nirregularly occurring network-wide events that last hundreds of milliseconds to\ncouple of seconds. In contrast, when $\\lambda$ approaches the dimension of the\nnetwork, a continuous self-sustained reentry propagation emerges, a regular\ndynamical mode that is marked by precise spatiotemporal patterns (`synfire\nchains') that may last many minutes. These results contribute to discussions on\nthe origin of different modes of neural synchrony in normal and pathological\nconditions\n", "versions": [{"version": "v1", "created": "Thu, 3 Mar 2016 16:26:55 GMT"}, {"version": "v2", "created": "Mon, 6 Jun 2016 09:25:32 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Keren", "Hanna", ""], ["Marom", "Shimon", ""]]}, {"id": "1603.01351", "submitter": "Kazuhisa Shibata", "authors": "Kazuhisa Shibata, Takeo Watanabe, Mitsuo Kawato, Yuka Sasaki", "title": "Differential activation patterns in the same brain region led to\n  opposite emotional states", "comments": "49 pages, 7 figures", "journal-ref": "PLoS Biol 14(9): e1002546 (2016)", "doi": "10.1371/journal.pbio.1002546", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In human studies, how averaged activation in a brain region relates to human\nbehavior has been extensively investigated. This approach has led to the\nfinding that positive and negative facial preferences are represented by\ndifferent brain regions. However, using a multi-voxel pattern induction method\nwe found that different patterns of neural activations within the cingulate\ncortex (CC) play roles in representing opposite emotional states. In the\npresent study, while neutrally-preferred faces were presented, activation\npatterns in the CC that corresponded to higher (or lower) preference were\nrepeatedly induced by the pattern induction method. As a result, previously\nneutrally-preferred faces became more (or less) preferred. We conclude that a\ndifferent activation pattern in the CC, rather than averaged activation in a\ndifferent area, represents and causally determines positive or negative facial\npreference. This new approach may reveal importance in an activation pattern\nwithin a brain region in many cognitive functions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2016 05:41:33 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Shibata", "Kazuhisa", ""], ["Watanabe", "Takeo", ""], ["Kawato", "Mitsuo", ""], ["Sasaki", "Yuka", ""]]}, {"id": "1603.01857", "submitter": "Danilo Bzdok", "authors": "Danilo Bzdok", "title": "Classical Statistics and Statistical Learning in Imaging Neuroscience", "comments": "61 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging research has predominantly drawn conclusions based on classical\nstatistics, including null-hypothesis testing, t-tests, and ANOVA. Throughout\nrecent years, statistical learning methods enjoy increasing popularity,\nincluding cross-validation, pattern classification, and sparsity-inducing\nregression. These two methodological families used for neuroimaging data\nanalysis can be viewed as two extremes of a continuum. Yet, they originated\nfrom different historical contexts, build on different theories, rest on\ndifferent assumptions, evaluate different outcome metrics, and permit different\nconclusions. This paper portrays commonalities and differences between\nclassical statistics and statistical learning with their relation to\nneuroimaging research. The conceptual implications are illustrated in three\ncommon analysis scenarios. It is thus tried to resolve possible confusion\nbetween classical hypothesis testing and data-guided model estimation by\ndiscussing their ramifications for the neuroimaging access to neurobiology.\n", "versions": [{"version": "v1", "created": "Sun, 6 Mar 2016 18:56:08 GMT"}, {"version": "v2", "created": "Wed, 4 May 2016 12:09:01 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Bzdok", "Danilo", ""]]}, {"id": "1603.01880", "submitter": "Jannis Schuecker", "authors": "Jannis Schuecker, Sven Goedeke and Moritz Helias", "title": "Optimal sequence memory in driven random networks", "comments": null, "journal-ref": "Phys. Rev. X 8, 041029 (2018)", "doi": "10.1103/PhysRevX.8.041029", "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous randomly coupled neural networks display a transition to chaos at\na critical coupling strength. We here investigate the effect of a time-varying\ninput on the onset of chaos and the resulting consequences for information\nprocessing. Dynamic mean-field theory yields the statistics of the activity,\nthe maximum Lyapunov exponent, and the memory capacity of the network. We find\nan exact condition that determines the transition from stable to chaotic\ndynamics and the sequential memory capacity in closed form. The input\nsuppresses chaos by a dynamic mechanism, shifting the transition to\nsignificantly larger coupling strengths than predicted by local stability\nanalysis. Beyond linear stability, a regime of coexistent locally expansive,\nbut non-chaotic dynamics emerges that optimizes the capacity of the network to\nstore sequential input.\n", "versions": [{"version": "v1", "created": "Sun, 6 Mar 2016 21:21:03 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 16:29:48 GMT"}, {"version": "v3", "created": "Fri, 22 Sep 2017 17:22:28 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Schuecker", "Jannis", ""], ["Goedeke", "Sven", ""], ["Helias", "Moritz", ""]]}, {"id": "1603.01970", "submitter": "Shimon Marom", "authors": "Shimon Marom", "title": "Emergence and Maintenance of Excitability: Kinetics over Structure", "comments": null, "journal-ref": "Current Opinion in Neurobiology Volume 40, October 2016, Pages\n  66--71", "doi": "10.1016/j.conb.2016.06.013", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emergence and maintenance of excitability is often phrased in terms of\narriving at and remaining about a manifold of 'solutions' embedded in a high\ndimensional parameter space. Alongside studies that extend traditional focus on\ncontrol-based regulation of structural parameters (channel densities), there is\na budding interest in self-organization of kinetic parameters. In this picture,\nionic channels are continually forced by activity in-and-out of a large pool of\nstates not available for the mechanism of excitability. The process, acting on\nexpressed structure, provides a bed for generation of a spectrum of\nexcitability modes. Driven by microscopic fluctuations over a broad range of\ntemporal scales, self-organization of kinetic parameters extends the metaphors\nand tools used in the study of development of excitability.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 08:11:19 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2016 17:54:45 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Marom", "Shimon", ""]]}, {"id": "1603.02007", "submitter": "Christian Scheppach", "authors": "Christian Scheppach, Hugh P.C. Robinson", "title": "Fluctuation analysis in nonstationary conditions: single Ca channel\n  current in cortical pyramidal neurons", "comments": null, "journal-ref": "Biophys. J., 5th Dec. 2017, 113(11):2383-2395", "doi": "10.1016/j.bpj.2017.09.025", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fluctuation analysis is a method which allows measurement of the single\nchannel current of ion channels even when it is too small to be resolved\ndirectly with the patch clamp technique. This is the case for voltage-gated\nCa2+ channels (VGCCs). They are present in all mammalian central neurons,\ncontrolling presynaptic release of transmitter, postsynaptic signaling and\nsynaptic integration. The amplitudes of their single channel currents in a\nphysiological concentration of extracellular Ca2+, however, are small and not\nwell determined. But measurement of this quantity is essential for estimating\nnumbers of functional VGCCs in the membrane and the size of channel-associated\nCa2+ signaling domains, and for understanding the stochastic nature of Ca2+\nsignaling. Here, we recorded the VGCC current in nucleated patches from layer 5\npyramidal neurons in rat neocortex, in physiological external Ca2+ (1-2 mM).\nThe ensemble-averaging of current responses required for conventional\nfluctuation analysis proved impractical because of the rapid rundown of VGCC\ncurrents. We therefore developed a more robust method, using mean current\nfitting of individual current responses and band-pass filtering. Furthermore,\nvoltage ramp stimulation proved useful. We validated the accuracy of the method\nby analyzing simulated data. At an external Ca2+ concentration of 1 mM, and a\nmembrane potential of -20 mV, we found that the average single channel current\namplitude was about 0.04 pA, increasing to 0.065 pA at 2 mM external Ca2+, and\n0.12 pA at 5 mM. The relaxation time constant of the fluctuations was in the\nrange 0.2-0.8 ms. The results are relevant to understanding the stochastic\nproperties of dendritic Ca2+ spikes in neocortical layer 5 pyramidal neurons.\nWith the reported method, single channel current amplitude of native VGCCs can\nbe resolved accurately despite conditions of unstable rundown.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 11:14:19 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 09:49:36 GMT"}, {"version": "v3", "created": "Tue, 29 Aug 2017 12:55:07 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Scheppach", "Christian", ""], ["Robinson", "Hugh P. C.", ""]]}, {"id": "1603.02238", "submitter": "Stanis{\\l}aw  Ambroszkiewicz", "authors": "Stanislaw Ambroszkiewicz", "title": "On higher order computations, rewiring the connectome, and non-von\n  Neumann computer architecture", "comments": "This version: a substantial extension and revision of the paper\n  published in Proc. ICANN2016. Keywords: computations in human brain, higher\n  order functions and functionals, synaptic meta-plasticity, glia and\n  atrocytes, non-von Neumann computer architecture, Backus' function-level\n  programming language", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural plasticity in the brain (i.e. rewiring the connectome) may be\nviewed as mechanisms for dynamic reconfiguration of neural circuits. First\norder computations in the brain are done by static neural circuits, whereas\nhigher order computations are done by dynamic reconfigurations of the links\n(synapses) between the neural circuits. Static neural circuits correspond to\nfirst order computable functions. Synapse creation (activation) between them\ncorrespond to the mathematical notion of function composition. Functionals are\nhigher order functions that take functions as their arguments. The construction\nof functionals is based on dynamic reconfigurations of function compositions.\nPerhaps the functionals correspond to rewiring mechanisms of the connectome.\nThe architecture of human mind is different than the von Neumann computer\narchitecture. Higher order computations in the human brain (based on\nfunctionals) may suggest a non-von Neumann computer architecture, a challenge\nposed by John Backus in 1977 \\cite{Backus}. The presented work is a substantial\nextension and revision of the paper published in Proc. ICANN2016.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2016 20:10:16 GMT"}, {"version": "v2", "created": "Wed, 30 Mar 2016 13:04:57 GMT"}, {"version": "v3", "created": "Thu, 16 Jun 2016 12:26:15 GMT"}, {"version": "v4", "created": "Sat, 3 Oct 2020 21:31:08 GMT"}], "update_date": "2020-10-06", "authors_parsed": [["Ambroszkiewicz", "Stanislaw", ""]]}, {"id": "1603.02406", "submitter": "Youngmin Park", "authors": "Youngmin Park and Bard Ermentrout", "title": "Weakly Coupled Oscillators in a Slowly Varying World", "comments": "28 pages, 11 figures", "journal-ref": null, "doi": "10.1007/s10827-016-0596-6", "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the theory of weakly coupled oscillators to incorporate slowly\nvarying inputs and parameters. We employ a combination of regular perturbation\nand an adiabatic approximation to derive equations for the phase-difference\nbetween a pair of oscillators. We apply this to the simple Hopf oscillator and\nthen to a biophysical model. The latter represents the behavior of a neuron\nthat is subject to slow modulation of a muscarinic current such as would occur\nduring transient attention through cholinergic activation. Our method extends\nand simplifies the recent work of Kurebayashi (Physical Review Letters, 111,\n214101, 2013) to include coupling. We apply the method to an all-to-all network\nand show that there is a waxing and waning of synchrony of modulated neurons.\n", "versions": [{"version": "v1", "created": "Tue, 8 Mar 2016 07:55:23 GMT"}], "update_date": "2016-03-09", "authors_parsed": [["Park", "Youngmin", ""], ["Ermentrout", "Bard", ""]]}, {"id": "1603.02773", "submitter": "Tom Chou", "authors": "Lae Un Kim, Maria R. D'Orsogna, Tom Chou", "title": "Onset, timing, and exposure therapy of stress disorders: mechanistic\n  insight from a mathematical model of oscillating neuroendocrine dynamics", "comments": "30 pages, 16 figures, submitted to BMC Biology Direct", "journal-ref": null, "doi": "10.1016/j.bpj.2015.11.2545", "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hypothalamic-pituitary-adrenal (HPA) axis is a neuroendocrine system that\nregulates numerous physiological processes. Disruptions in the activity of the\nHPA axis are correlated with many stress-related diseases such as\npost-traumatic stress disorder (PTSD) and major depressive disorder. In this\npaper, we characterize \"normal\" and \"diseased\" states of the HPA axis as basins\nof attraction of a dynamical system describing the inhibition of peptide\nhormones such as corticotropin-releasing hormone (CRH) and adrenocorticotropic\nhormone (ACTH) by circulating glucocorticoids such as cortisol (CORT). In\naddition to including key physiological features such as ultradian oscillations\nin cortisol levels and self-upregulation of CRH neuron activity, our model\ndistinguishes the relatively slow process of cortisol-mediated CRH biosynthesis\nfrom rapid trans-synaptic effects that regulate the CRH secretion process.\nCrucially, we find that the slow regulation mechanism mediates external\nstress-driven transitions between the stable states in novel, intensity,\nduration, and timing-dependent ways. These results indicate that the timing of\ntraumatic events may be an important factor in determining if and how patients\nwill exhibit hallmarks of stress disorders. Our model also suggests a mechanism\nwhereby exposure therapy of stress disorders such as PTSD may act to normalize\ndownstream dysregulation of the HPA axis.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 03:01:41 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Kim", "Lae Un", ""], ["D'Orsogna", "Maria R.", ""], ["Chou", "Tom", ""]]}, {"id": "1603.02798", "submitter": "Agnieszka Pregowska", "authors": "Agnieszka Pregowska and Janusz Szczepanski and Eligiusz Wajnryb\n  (Institute of Fundamental Technological Research, Polish Academy of Sciences)", "title": "Temporal code versus rate code for binary Information Sources", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscientists formulate very different hypotheses about the nature of\nneural code. At one extreme, it has been argued that neurons encode information\nin relatively slow changes of individual spikes arriving \"rates codes\" and the\nirregularity in the spike trains reflects noise in the system, while in the\nother extreme this irregularity is the temporal codes thus the precise timing\nof every spike carries additional information about the input. It is known that\nin the estimation of Shannon information the patterns and temporal structures\nare taken into account, while the rate code is determined by firing rate. We\ncompare these types of codes for binary Information Sources which model encoded\nspike-trains. Assuming that the information transmitted by a neuron is governed\nby uncorrelated stochastic process or by process with a memory we compare the\ninformation transmission rates carried by such spike-trains with their firing\nrates. We showed that the crucial role in the relation between information and\nfiring rates is played by a quantity which we call \"jumping\" parameter. It\ncorresponds to the probabilities of transitions from no-spike-state to the\nspike-state and vice versa. For low values of jumping parameter the quotient of\ninformation and firing rates is monotonically decreasing function of firing\nrate, thus there is straightforward, one-to-one, relation between temporal and\nrate codes. On the contrary, it turns out that for large enough jumping\nparameter this quotient is non-monotonic function of firing rate and it\nexhibits a global maximum, in this case optimal firing rate exists. Moreover,\nthere is no one-to-one relation between information and firing rates, so the\ntemporal and rate codes differ qualitatively. This leads to the observation\nthat the behavior of the quotient of information and firing rates for large\njumping parameter is important in the context of bursting phenomena.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 07:38:26 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["Pregowska", "Agnieszka", "", "Institute of Fundamental Technological Research, Polish Academy of Sciences"], ["Szczepanski", "Janusz", "", "Institute of Fundamental Technological Research, Polish Academy of Sciences"], ["Wajnryb", "Eligiusz", "", "Institute of Fundamental Technological Research, Polish Academy of Sciences"]]}, {"id": "1603.02916", "submitter": "Zachary Roth", "authors": "Zachary Roth", "title": "Analysis of neuronal sequences using pairwise biases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequences of neuronal activation have long been implicated in a variety of\nbrain functions. In particular, these sequences have been tied to memory\nformation and spatial navigation in the hippocampus, a region of mammalian\nbrains. Traditionally, neuronal sequences have been interpreted as noisy\nmanifestations of neuronal templates (i.e., orderings), ignoring much richer\nstructure contained in the sequences. This paper introduces a new tool for\nunderstanding neuronal sequences: the bias matrix. The bias matrix captures the\nprobabilistic tendency of each neuron to fire before or after each other\nneuron. Despite considering only pairs of neurons, the bias matrix captures the\nbest total ordering of neurons for a sequence (Proposition 3.3) and, thus,\ngeneralizes the concept of a neuronal template.\n  We establish basic mathematical properties of bias matrices, in particular\ndescribing the fundamental polytope in which all biases reside (Theorem 3.25).\nWe show how the underlying simple digraph of a bias matrix, which we term the\nbias network, serves as a combinatorial generalization of neuronal templates.\nSurprisingly, every simple digraph is realizable as the bias network of some\nsequence (Theorem 3.34). The bias-matrix representation leads us to a natural\nmethod for sequence correlation, which then leads to a probabilistic framework\nfor determining the similarity of one set of sequences to another. Using data\nfrom rat hippocampus, we describe events of interest and also\nsequence-detection techniques. Finally, the bias matrix and the similarity\nmeasure are applied to this real-world data using code developed by us.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 15:18:11 GMT"}], "update_date": "2016-03-10", "authors_parsed": [["Roth", "Zachary", ""]]}, {"id": "1603.03031", "submitter": "Rafal Paprocki Mr", "authors": "Rafal Paprocki, Temesgen Gebrehiwot, Marija Gradinscak and Artem\n  Lenskiy", "title": "Extracting Blink Rate Variability from EEG Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generally, blinks are treated on equal with artifacts and noise while\nanalyzing EEG signals. However, blinks carry important information about mental\nprocesses and thus it is important to detect blinks accurately. The aim of the\npresented study is to propose a blink detection method and discuss its\napplication for extracting blink rate variability, a novel concept that might\nshed some light on the mental processes. In this study, 14 EEG recordings were\nselected for assessing the quality of the proposed blink detection algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 9 Mar 2016 06:56:23 GMT"}, {"version": "v2", "created": "Sat, 26 Mar 2016 08:27:02 GMT"}, {"version": "v3", "created": "Sat, 2 Apr 2016 11:45:03 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Paprocki", "Rafal", ""], ["Gebrehiwot", "Temesgen", ""], ["Gradinscak", "Marija", ""], ["Lenskiy", "Artem", ""]]}, {"id": "1603.03079", "submitter": "Andrei Khrennikov Yu", "authors": "Irina Basieva and Andrei Khrennikov", "title": "Testing boundaries of applicability of quantum probabilistic formalism\n  to modeling of cognition", "comments": null, "journal-ref": "Lecture Notes in Computer Science, 10106, 49-56, 2016", "doi": null, "report-no": null, "categories": "q-bio.NC math.PR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently the mathematical formalism of quantum mechanics, especially methods\nof quantum probability theory, started to be widely used in a variety of\napplications outside of physics, e.g., cognition and psychology as well as\neconomy and finances. To distinguish such models from genuine quantum physical\nmodels, they often called quantum-like (although often people simply speak\nabout, e.g., \"quantum cognition\"). These novel applications generate a number\nof foundational questions. Nowadays we can speak about a new science -\nfoundations of quantum-like modeling. At the first stage this science was\nmainly about comparison of classical and quantum models, mainly in the\nprobabilistic setting. It was found that statistical data from cognitive\npsychology violate some basic constraints posed on data by classical\nprobability theory (Kolmogorov, 1933); in particular, the constraints given by\nthe formula of total probability and Bell's type inequalities. Recently another\nquestion attracted some attention. In spite of real success in applications,\nthere are no reason to believe that the quantum probability would cover\ncompletely all problems of, e.g., cognition. May be more general probability\nmodels have to be explored. A similar problem attracted a lot of attention in\nfoundations of quantum physics culminating in a series of experiments to check\nSorkin's equality for the triple-slit experiment by Weihs' group. In this note\nwe present a similar test in the cognitive experimental setting. Performance of\nthis test would either give further confirmation of the adequacy of the quantum\nprobability model to cognitive applications or rejection of the conventional\nquantum model. Thus this note opens the door for a series of exciting\nexperimental tests for the quantum-like model of cognition.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 09:04:01 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Basieva", "Irina", ""], ["Khrennikov", "Andrei", ""]]}, {"id": "1603.03162", "submitter": "Aurelio Cortese", "authors": "Aurelio Cortese, Kaoru Amano, Ai Koizumi, Hakwan Lau and Mitsuo Kawato", "title": "Decoded fMRI neurofeedback can induce bidirectional behavioral changes\n  within single participants", "comments": "31 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies using real-time functional magnetic resonance imaging (rt-fMRI) have\nrecently incorporated the decoding approach, allowing for fMRI to be used as a\ntool for manipulation of fine-grained neural activity. Because of the\ntremendous potential for clinical applications, certain questions regarding\ndecoded neurofeedback (DecNef) must be addressed. Neurofeedback effects can\nlast for months, but the short- to mid-term dynamics are not known.\nSpecifically, can the same subjects learn to induce neural patterns in two\nopposite directions in different sessions? This leads to a further question,\nwhether learning to reverse a neural pattern may be less effective after\ntraining to induce it in a previous session. Here we employed a\nwithin-subjects' design, with subjects undergoing DecNef training sequentially\nin opposite directions (up or down regulation of confidence judgements in a\nperceptual task), with the order counterbalanced across subjects. Behavioral\nresults indicated that the manipulation was strongly influenced by the order\nand direction of neurofeedback. We therefore applied nonlinear mathematical\nmodeling to parametrize four main consequences of DecNef: main effect of change\nin behavior, strength of down-regulation effect relative to up-regulation,\nmaintenance of learning over sessions, and anterograde learning interference.\nModeling results revealed that DecNef successfully induced bidirectional\nbehavioral changes in different sessions. Furthermore, up-regulation was more\nsizable, and the effect was largely preserved even after an interval of\none-week. Lastly, the second week effect was diminished as compared to the\nfirst week effect, indicating strong anterograde learning interference. These\nresults suggest reinforcement learning characteristics of DecNef, and provide\nimportant constraints on its application to basic neuroscience, occupational\nand sports trainings, and therapies.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 06:54:01 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["Cortese", "Aurelio", ""], ["Amano", "Kaoru", ""], ["Koizumi", "Ai", ""], ["Lau", "Hakwan", ""], ["Kawato", "Mitsuo", ""]]}, {"id": "1603.03293", "submitter": "Mario Mulansky", "authors": "Mario Mulansky and Thomas Kreuz", "title": "PySpike - A Python library for analyzing spike train synchrony", "comments": "7 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how the brain functions is one of the biggest challenges of our\ntime. The analysis of experimentally recorded neural firing patterns (spike\ntrains) plays a crucial role in addressing this problem. Here, the PySpike\nlibrary is introduced, a Python package for spike train analysis providing\nparameter-free and time-scale independent measures of spike train synchrony. It\nallows to compute similarity and dissimilarity profiles, averaged values and\ndistance matrices. Although mainly focusing on neuroscience, PySpike can also\nbe applied in other contexts like climate research or social sciences. The\npackage is available as Open Source on Github and PyPI.\n", "versions": [{"version": "v1", "created": "Thu, 10 Mar 2016 15:07:06 GMT"}, {"version": "v2", "created": "Sat, 9 Jul 2016 20:21:49 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Mulansky", "Mario", ""], ["Kreuz", "Thomas", ""]]}, {"id": "1603.03828", "submitter": "Stuart Hagler", "authors": "Stuart Hagler, Holly B. Jimison, Misha Pavel", "title": "Assessing Executive Function Using a Computer Game: Computational\n  Modeling of Cognitive Processes", "comments": "11 pages, 4 figures", "journal-ref": "IEEE J Biomed Health Inform. 2014, 18(4): 1442-52", "doi": "10.1109/JBHI.2014.2299793", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Early and reliable detection of cognitive decline is one of the most\nimportant challenges of current healthcare. In this project we developed an\napproach whereby a frequently played computer game can be used to assess a\nvariety of cognitive processes and estimate the results of the pen-and-paper\nTrail-Making Test (TMT) - known to measure executive function, as well as\nvisual pattern recognition, speed of processing, working memory, and\nset-switching ability. We developed a computational model of the TMT based on a\ndecomposition of the test into several independent processes, each\ncharacterized by a set of parameters that can be estimated from play of a\ncomputer game designed to resemble the TMT. An empirical evaluation of the\nmodel suggests that it is possible to use the game data to estimate the\nparameters of the underlying cognitive processes and using the values of the\nparameters to estimate the TMT performance. Cognitive measures and trends in\nthese measures can be used to identify individuals for further assessment, to\nprovide a mechanism for improving the early detection of neurological problems,\nand to provide feedback and monitoring for cognitive interventions in the home.\n", "versions": [{"version": "v1", "created": "Sat, 12 Mar 2016 00:03:45 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Hagler", "Stuart", ""], ["Jimison", "Holly B.", ""], ["Pavel", "Misha", ""]]}, {"id": "1603.03867", "submitter": "Ganesh Bagler Dr", "authors": "Rahul Badhwar and Ganesh Bagler", "title": "A distance constrained synaptic plasticity model of C. elegans neuronal\n  network", "comments": "Main Manuscript (9 pages, 6 Figures), Supplementary Data (11 pages, 7\n  Figures, 3 Tables); Manuscript revised for typos and inclusion of color\n  figures", "journal-ref": "Physica A, 469 (2017), 313-322", "doi": "10.1016/j.physa.2016.11.055", "report-no": "IITJ/SEED/2014/0003", "categories": "q-bio.NC physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain research has been driven by enquiry for principles of brain structure\norganization and its control mechanisms. The neuronal wiring map of C. elegans,\nthe only complete connectome available till date, presents an incredible\nopportunity to learn basic governing principles that drive structure and\nfunction of its neuronal architecture. Despite its apparently simple nervous\nsystem, C. elegans is known to possess complex functions. The neuronal\narchitecture forms an important underlying framework which specifies phenotypic\nfeatures associated to sensation, movement, conditioning and memory. In this\nstudy, with the help of graph theoretical models, we investigated the C.\nelegans neuronal network to identify network features that are critical for its\ncontrol. The 'driver neurons' are associated with important biological\nfunctions such as reproduction, signalling processes and anatomical structural\ndevelopment. We created 1D and 2D network models of C. elegans neuronal system\nto probe the role of features that confer controllability and small world\nnature. The simple 1D ring model is critically poised for the number of feed\nforward motifs, neuronal clustering and characteristic path-length in response\nto synaptic rewiring, indicating optimal rewiring. Using empirically observed\ndistance constraint in the neuronal network as a guiding principle, we created\na distance constrained synaptic plasticity model that simultaneously explains\nsmall world nature, saturation of feed forward motifs as well as observed\nnumber of driver neurons. The distance constrained model suggests optimum long\ndistance synaptic connections as a key feature specifying control of the\nnetwork.\n", "versions": [{"version": "v1", "created": "Sat, 12 Mar 2016 06:40:36 GMT"}, {"version": "v2", "created": "Thu, 4 Aug 2016 17:04:56 GMT"}, {"version": "v3", "created": "Fri, 25 Nov 2016 15:31:24 GMT"}], "update_date": "2016-11-28", "authors_parsed": [["Badhwar", "Rahul", ""], ["Bagler", "Ganesh", ""]]}, {"id": "1603.04023", "submitter": "Greg Stephens", "authors": "Onno D Broekmans, Jarlath B Rodgers, William S Ryu and Greg J Stephens", "title": "Resolving coiled shapes reveals new reorientation behaviors in C.\n  elegans", "comments": "14 pages and 8 figures, including supplementary information", "journal-ref": "eLife 2016;5:e17227", "doi": "10.7554/eLife.17227", "report-no": null, "categories": "q-bio.QM physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We exploit the reduced space of C. elegans postures to develop a novel\ntracking algorithm which captures both simple shapes and also self-occluding\ncoils, an important, yet unexplored, component of worm behavior. We apply our\nalgorithm to show that visually complex, coiled sequences are a superposition\nof two simpler patterns: the body wave dynamics and a head-curvature pulse. We\ndemonstrate the precise coiled dynamics of an escape response and uncover new\nbehaviors in spontaneous, large amplitude coils; deep reorientations occur\nthrough classical Omega-shaped postures and also through larger, new postural\nexcitations which we label here as delta-turns. We find that omega and delta\nturns occur independently, the serpentine analog of a random left-right step,\nsuggesting a distinct triggering mechanism. We also show that omega and delta\nturns display approximately equal rates and adapt to food-free conditions on a\nsimilar timescale, a simple strategy to avoid navigational bias.\n", "versions": [{"version": "v1", "created": "Sun, 13 Mar 2016 12:38:01 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Broekmans", "Onno D", ""], ["Rodgers", "Jarlath B", ""], ["Ryu", "William S", ""], ["Stephens", "Greg J", ""]]}, {"id": "1603.04131", "submitter": "Eve Armstrong", "authors": "Eve Armstrong and Henry D. I. Abarbanel", "title": "Model of the Songbird Nucleus HVC as a Network of Central Pattern\n  Generators", "comments": "20 pages, 9 figures. Submitted to the Journal of Neurophysiology", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a functional architecture of the adult songbird nucleus HVC in\nwhich the core element is a \"functional syllable unit\" (FSU). In this model,\nHVC is organized into FSUs, each of which provides the basis for the production\nof one syllable in vocalization. Within each FSU, the inhibitory neuron\npopulation takes one of two operational states: (A) simultaneous firing wherein\nall inhibitory neurons fire simultaneously, and (B) competitive firing of the\ninhibitory neurons. Switching between these basic modes of activity is\naccomplished via changes in the synaptic strengths among the inhibitory\nneurons. The inhibitory neurons connect to excitatory projection neurons such\nthat during state (A) the activity of projection neurons is suppressed, while\nduring state (B) patterns of sequential firing of projection neurons can occur.\nThe latter state is stabilized by feedback from the projection to the\ninhibitory neurons. Song composition for specific species is distinguished by\nthe manner in which different FSUs are functionally connected to each other.\n  Ours is a computational model built with biophysically based neurons. We\nillustrate that many observations of HVC activity are explained by the dynamics\nof the proposed population of FSUs, and we identify aspects of the model that\nare currently testable experimentally. In addition, and standing apart from the\ncore features of an FSU, we propose that the transition between modes may be\ngoverned by the biophysical mechanism of neuromodulation.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 04:13:02 GMT"}, {"version": "v2", "created": "Fri, 3 Jun 2016 18:21:20 GMT"}, {"version": "v3", "created": "Mon, 18 Jul 2016 14:45:18 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Armstrong", "Eve", ""], ["Abarbanel", "Henry D. I.", ""]]}, {"id": "1603.04173", "submitter": "Rafal Paprocki Mr", "authors": "Temesgen Gebrehiwot, Rafal Paprocki, Artem Lenskiy", "title": "Analysis of Blink Rate Variability during reading and memory testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigated how statistical properties of the blink rate\nvariability changes during two mental tasks: reading a passage and memory\ntesting. To construct time series of inter-blink intervals (blink rate\nvariability) we detected exact blink time in EEG recordings using our blink\ndetection algorithm. We found that among 13 subjects, all subjects blinked less\nduring reading session. Moreover, standard deviation of the blink rate\nvariability is higher during reading. Thus, we conclude that the variability of\ninter-blink intervals decreases during tasks that require concentration and\nintense mental activity.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 09:20:04 GMT"}, {"version": "v2", "created": "Sun, 27 Mar 2016 03:08:32 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Gebrehiwot", "Temesgen", ""], ["Paprocki", "Rafal", ""], ["Lenskiy", "Artem", ""]]}, {"id": "1603.04607", "submitter": "Ruedi Stoop", "authors": "Ruedi Stoop and Florian Gomez", "title": "Auditory power-law activation-avalanches exhibit a fundamental\n  computational ground-state", "comments": "Videos are not included, please ask authors", "journal-ref": null, "doi": "10.1103/PhysRevLett.117.038102", "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cochlea provides a biological information-processing paradigm that we\nonly begin to under- stand in its full complexity. Our work reveals an\ninteracting network of strongly nonlinear dynami- cal nodes, on which even\nsimple sound input triggers subnetworks of activated elements that follow\npower-law size statistics ('avalanches'). From dynamical systems theory,\npower-law size distribu- tions relate to a fundamental ground-state of\nbiological information processing. Learning destroys these power laws. These\nresults strongly modify the models of mammalian sound processing and provide a\nnovel methodological perspective for understanding how the brain processes\ninformation.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2016 09:23:05 GMT"}], "update_date": "2016-08-03", "authors_parsed": [["Stoop", "Ruedi", ""], ["Gomez", "Florian", ""]]}, {"id": "1603.04687", "submitter": "Kanaka Rajan PhD", "authors": "Kanaka Rajan, Christopher D Harvey, David W Tank", "title": "Recurrent Network Models Of Sequence Generation And Memory", "comments": "60 pages, 6 figures", "journal-ref": "Neuron 90, 1-15, April 6, 2016 Elsevier Inc, (2016)", "doi": "10.1016/j.neuron.2016.02.009", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential activation of neurons is a common feature of network activity\nduring a variety of behaviors, including working memory and decision making.\nPrevious network models for sequences and memory emphasized specialized\narchitectures in which a principled mechanism is pre-wired into their\nconnectivity. Here we demonstrate that, starting from random connectivity and\nmodifying a small fraction of connections, a largely disordered recur- rent\nnetwork can produce sequences and implement working memory efficiently. We use\nthis process, called Partial In-Network Training (PINning), to model and match\ncellular resolution imaging data from the posterior parietal cortex during a\nvirtual memory- guided two-alternative forced-choice task. Analysis of the\nconnectivity reveals that sequences propagate by the cooperation between\nrecurrent synaptic interactions and external inputs, rather than through\nfeedforward or asymmetric connections. Together our results suggest that neural\nsequences may emerge through learning from largely unstructured network\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2016 15:00:12 GMT"}], "update_date": "2016-03-16", "authors_parsed": [["Rajan", "Kanaka", ""], ["Harvey", "Christopher D", ""], ["Tank", "David W", ""]]}, {"id": "1603.04721", "submitter": "Claus Metzner", "authors": "Patrick Krauss, Konstantin Tziridis, Achim Schilling, Claus Metzner\n  and Holger Schulze", "title": "Stochastic resonance controlled upregulation of internal noise after\n  hearing loss as a putative correlate of tinnitus-related neuronal\n  hyperactivity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Subjective tinnitus (ST) is generally assumed to be a consequence of hearing\nloss (HL). In animal studies acoustic trauma can lead to behavioral signs of\nST, in human studies ST patients without increased hearing thresholds were\nfound to suffer from so called hidden HL. Additionally, ST is correlated with\npathologically increased spontaneous firing rates and neuronal hyperactivity\n(NH) along the auditory pathway. Homeostatic plasticity (HP) has been proposed\nas a compensation mechanism leading to the development of NH, arguing that\nafter HL initially decreased mean firing rates of neurons are subsequently\nrestored by increased spontaneous rates. However all HP models fundamentally\nlack explanatory power since the function of keeping mean firing rate constant\nremains elusive as does the benefit this might have in terms of information\nprocessing. Furthermore the neural circuitry being able to perform the\ncomparison of preferred with actual mean firing rate remains unclear. Here we\npropose an entirely new interpretation of ST related development of NH in terms\nof information theory. We suggest that stochastic resonance (SR) plays a key\nrole in short- and long-term plasticity within the auditory system and is the\nultimate cause of NH and ST. SR has been found ubiquitous in neuroscience and\nrefers to the phenomenon that sub-threshold, unperceivable signals can be\ntransmitted by adding noise to sensor input. We argue that after HL, SR serves\nto lift signals above the increased hearing threshold, hence subsequently\ndecreasing thresholds again. The increased amount of internal noise is the\ncorrelate of the NH, which finally leads to the development of ST, due to\nneuronal plasticity along the auditory pathway. We demonstrate the plausibility\nof our hypothesis by using a computational model and provide exemplarily\nfindings of human and animal studies that are consistent with our model.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2016 15:27:19 GMT"}], "update_date": "2016-03-16", "authors_parsed": [["Krauss", "Patrick", ""], ["Tziridis", "Konstantin", ""], ["Schilling", "Achim", ""], ["Metzner", "Claus", ""], ["Schulze", "Holger", ""]]}, {"id": "1603.04881", "submitter": "Josef Ladenbauer", "authors": "Florian Aspart, Josef Ladenbauer, Klaus Obermayer", "title": "Extending integrate-and-fire model neurons to account for the effects of\n  weak electric fields and input filtering mediated by the dendrite", "comments": "PLOS Computational Biology (in press)", "journal-ref": null, "doi": "10.1371/journal.pcbi.1005206", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How extracellular electric fields, as generated endogenously or through\ntranscranial brain stimulation, affect the dynamics of large neuronal\npopulations is of great interest but not well understood. To study the\ncollective dynamics of large populations single-compartment (point) model\nneurons have been proven very successful. These models, however, lack the\ndendritic morphology to biophysically account for the effects of electric\nfields, and for changes in synaptic integration due to morphology alone. Here\nwe (i) characterize the response of a canonical spatial (ball-and-stick) model\nneuron to fluctuating synaptic input as well as an oscillatory, weak electric\nfield, and (ii) analytically derive an extension for popular integrate-and-fire\npoint neuron models to accurately reproduce these responses. We obtain distinct\nfilters mediated by the dendrite for inputs at the soma (high-pass filter) or\nat the distal dendritic site (low-pass filter), and find that the electric\nfield induces spike rate resonance in the beta and gamma frequency bands or\neven higher frequencies, depending on the location of synaptic background\ninput. Due to their computational efficiency the extended point models are well\nsuited for application in large populations of coupled neurons with different\nmorphology, exposed to extracellular electric fields.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2016 20:44:36 GMT"}, {"version": "v2", "created": "Thu, 19 May 2016 14:21:31 GMT"}, {"version": "v3", "created": "Fri, 27 May 2016 11:24:05 GMT"}, {"version": "v4", "created": "Wed, 9 Nov 2016 14:14:24 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Aspart", "Florian", ""], ["Ladenbauer", "Josef", ""], ["Obermayer", "Klaus", ""]]}, {"id": "1603.04906", "submitter": "Bisakha Ray", "authors": "Bisakha Ray, Alexander V. Alekseyenko, Sisi Ma, Alexander Statnikov,\n  Constantin Aliferis", "title": "Evaluation and Ensembling of Methods for Reverse Engineering of Brain\n  Connectivity from Imaging Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain science is an evolving research area inviting great enthusiasm with its\npotential for providing insights and thereby, preventing, and treating multiple\nneuronal disorders affecting millions of patients. Discovery of relationships,\nsuch as brain connectivity, is a major goal in basic, translational, and\nclinical science. Algorithms for causal discovery are used in diverse fields\nfor tackling problems similar to the task of reconstruction of neuronal brain\nconnectivity. Our aim is to understand the strengths and limitations of these\nmethods, measure performance and its determinants, and provide insights to\nenhance their performance and applicability. We performed extensive empirical\ntesting and benchmarking of reconstruction performance of several\nstate-of-the-art algorithms along with several ensemble techniques used to\ncombine them. Our experiments used a clear and broadly relevant gold standard\nbased on calcium fluorescence time series recordings of thousands of neurons\nsampled from a previously validated realistic, neuronal model. Correlation,\nentropy-based measures, Cross-Correlation for short time lags, and Generalized\nTransfer Entropy had the best performances with area under ROC curve (AUC) in\nthe range of 0.7-0.8 even for smaller sample sizes of n = 100 to 1,000 and\nconverged quickly (at less than n = 1,000). Ensembles of best-performing\nmethods using random forests and neural networks generated AUC of ~0.9 with n =\n10,000. Several important insights regarding parameter choice and sample size\nwere gained for guiding the experimental design of studies. Our data are also\nsupportive of the feasibility of reliably reconstructing complex neuronal\nconnectivity using existing techniques.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2016 22:25:24 GMT"}], "update_date": "2016-03-17", "authors_parsed": [["Ray", "Bisakha", ""], ["Alekseyenko", "Alexander V.", ""], ["Ma", "Sisi", ""], ["Statnikov", "Alexander", ""], ["Aliferis", "Constantin", ""]]}, {"id": "1603.05261", "submitter": "Richard Betzel", "authors": "Richard F. Betzel, Shi Gu, John D. Medaglia, Fabio Pasqualetti,\n  Danielle S. Bassett", "title": "Optimally controlling the human connectome: the role of network topology", "comments": "23 pages, 6 figures, 9 supplementary figures", "journal-ref": null, "doi": "10.1038/srep30770", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To meet ongoing cognitive demands, the human brain must seamlessly transition\nfrom one brain state to another, in the process drawing on different cognitive\nsystems. How does the brain's network of anatomical connections help facilitate\nsuch transitions? Which features of this network contribute to making one\ntransition easy and another transition difficult? Here, we address these\nquestions using network control theory. We calculate the optimal input signals\nto drive the brain to and from states dominated by different cognitive systems.\nThe input signals allow us to assess the contributions made by different brain\nregions. We show that such contributions, which we measure as energy, are\ncorrelated with regions' weighted degrees. We also show that the network\ncommunicability, a measure of direct and indirect connectedness between brain\nregions, predicts the extent to which brain regions compensate when input to\nanother region is suppressed. Finally, we identify optimal states in which the\nbrain should start (and finish) in order to minimize transition energy. We show\nthat the optimal target states display high activity in hub regions,\nimplicating the brain's rich club. Furthermore, when rich club organization is\ndestroyed, the energy cost associated with state transitions increases\nsignificantly, demonstrating that it is the richness of brain regions that\nmakes them ideal targets.\n", "versions": [{"version": "v1", "created": "Wed, 16 Mar 2016 20:13:56 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Betzel", "Richard F.", ""], ["Gu", "Shi", ""], ["Medaglia", "John D.", ""], ["Pasqualetti", "Fabio", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1603.05343", "submitter": "Roberto D. Pascual-Marqui", "authors": "RD Pascual-Marqui, P Faber, T Kinoshita, Y Kitaura, K Kochi, P Milz, K\n  Nishida, M Yoshimura", "title": "The dual frequency RV-coupling coefficient: a novel measure for\n  quantifying cross-frequency information transactions in the brain", "comments": "technical report, pre-print, 2016-03-16", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ME", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Identifying dynamic transactions between brain regions has become\nincreasingly important. Measurements within and across brain structures,\ndemonstrating the occurrence of bursts of beta/gamma oscillations only during\none specific phase of each theta/alpha cycle, have motivated the need to\nadvance beyond linear and stationary time series models. Here we offer a novel\nmeasure, namely, the \"dual frequency RV-coupling coefficient\", for assessing\ndifferent types of frequency-frequency interactions that subserve information\nflow in the brain. This is a measure of coherence between two complex-valued\nvectors, consisting of the set of Fourier coefficients for two different\nfrequency bands, within or across two brain regions. RV-coupling is expressed\nin terms of instantaneous and lagged components. Furthermore, by using\nnormalized Fourier coefficients (unit modulus), phase-type couplings can also\nbe measured. The dual frequency RV-coupling coefficient is based on previous\nwork: the second order bispectrum, i.e. the dual-frequency coherence (Thomson\n1982; Haykin & Thomson 1998); the RV-coefficient (Escoufier 1973); Gorrostieta\net al (2012); and Pascual-Marqui et al (2011). This paper presents the new\nmeasure, and outlines relevant statistical tests. The novel aspects of the\n\"dual frequency RV-coupling coefficient\" are: (1) it can be applied to two\nmultivariate time series; (2) the method is not limited to single discrete\nfrequencies, and in addition, the frequency bands are treated by means of\nappropriate multivariate statistical methodology; (3) the method makes use of a\nnovel generalization of the RV-coefficient for complex-valued multivariate\ndata; (4) real and imaginary covariance contributions to the RV-coherence are\nobtained, allowing the definition of a \"lagged-coupling\" measure that is\nminimally affected by the low spatial resolution of estimated cortical electric\nneuronal activity.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 03:02:50 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2016 00:52:48 GMT"}], "update_date": "2016-03-21", "authors_parsed": [["Pascual-Marqui", "RD", ""], ["Faber", "P", ""], ["Kinoshita", "T", ""], ["Kitaura", "Y", ""], ["Kochi", "K", ""], ["Milz", "P", ""], ["Nishida", "K", ""], ["Yoshimura", "M", ""]]}, {"id": "1603.05659", "submitter": "Rashid Williams-Garcia", "authors": "Rashid V. Williams-Garcia, John M. Beggs, and Gerardo Ortiz", "title": "Unveiling causal activity of complex networks", "comments": null, "journal-ref": null, "doi": "10.1209/0295-5075/119/18003", "report-no": null, "categories": "q-bio.NC nlin.AO physics.bio-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel tool for analyzing complex network dynamics, allowing\nfor cascades of causally-related events, which we call causal webs (c-webs), to\nbe separated from other non-causally-related events. This tool shows that\ntraditionally-conceived avalanches may contain mixtures of spatially-distinct\nbut temporally-overlapping cascades of events, and dynamical disorder or noise.\nIn contrast, c-webs separate these components, unveiling previously hidden\nfeatures of the network and dynamics. We apply our method to mouse cortical\ndata with resulting statistics which demonstrate for the first time that\nneuronal avalanches are not merely composed of causally-related events.\n", "versions": [{"version": "v1", "created": "Thu, 17 Mar 2016 20:00:05 GMT"}, {"version": "v2", "created": "Mon, 9 May 2016 17:02:06 GMT"}, {"version": "v3", "created": "Fri, 29 Jul 2016 19:15:38 GMT"}, {"version": "v4", "created": "Thu, 9 Feb 2017 20:23:29 GMT"}, {"version": "v5", "created": "Tue, 25 Apr 2017 14:42:48 GMT"}, {"version": "v6", "created": "Tue, 16 May 2017 19:26:49 GMT"}, {"version": "v7", "created": "Sun, 27 Aug 2017 21:08:09 GMT"}], "update_date": "2017-10-11", "authors_parsed": [["Williams-Garcia", "Rashid V.", ""], ["Beggs", "John M.", ""], ["Ortiz", "Gerardo", ""]]}, {"id": "1603.05897", "submitter": "Manlio De Domenico", "authors": "Manlio De Domenico, Shuntaro Sasai and Alex Arenas", "title": "Mapping multiplex hubs in human functional brain network", "comments": "11 pages, 8 figures, 2 tables", "journal-ref": "Front. Neurosci. 10, 326 (2016)", "doi": "10.3389/fnins.2016.00326", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical brain networks consist of many peripheral regions and a few highly\ncentral ones, i.e. hubs, playing key functional roles in cerebral\ninter-regional interactions. Studies have shown that networks, obtained from\nthe analysis of specific frequency components of brain activity, present\npeculiar architectures with unique profiles of region centrality. However, the\nidentification of hubs in networks built from different frequency bands\nsimultaneously is still a challenging problem, remaining largely unexplored.\nHere we identify each frequency component with one layer of a multiplex network\nand face this challenge by exploiting the recent advances in the analysis of\nmultiplex topologies. First, we show that each frequency band carries unique\ntopological information, fundamental to accurately model brain functional\nnetworks. We then demonstrate that hubs in the multiplex network, in general\ndifferent from those ones obtained after discarding or aggregating the measured\nsignals as usual, provide a more accurate map of brain's most important\nfunctional regions, allowing to distinguish between healthy and schizophrenic\npopulations better than conventional network approaches.\n", "versions": [{"version": "v1", "created": "Fri, 18 Mar 2016 15:53:07 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["De Domenico", "Manlio", ""], ["Sasai", "Shuntaro", ""], ["Arenas", "Alex", ""]]}, {"id": "1603.06230", "submitter": "Josh Merel", "authors": "Josh Merel, Ben Shababo, Alex Naka, Hillel Adesnik, Liam Paninski", "title": "Bayesian methods for event analysis of intracellular currents", "comments": null, "journal-ref": null, "doi": "10.1016/j.jneumeth.2016.05.015", "report-no": null, "categories": "q-bio.QM q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Investigation of neural circuit functioning often requires statistical\ninterpretation of events in subthreshold electrophysiological recordings. This\nproblem is non-trivial because recordings may have moderate levels of\nstructured noise and events may have distinct kinetics. In addition, novel\nexperimental designs that combine optical and electrophysiological methods will\ndepend upon statistical tools that combine multimodal data. We present a\nBayesian approach for inferring the timing, strength, and kinetics of\npostsynaptic currents (PSCs) from voltage-clamp recordings on a per event\nbasis. The simple generative model for a single voltage-clamp recording\nflexibly extends to include network-level structure to enable experiments\ndesigned to probe synaptic connectivity. We validate the approach on simulated\nand real data. We also demonstrate that extensions of the basic PSC detection\nalgorithm can handle recordings contaminated with optically evoked currents,\nand we simulate a scenario in which calcium imaging observations, available for\na subset of neurons, can be fused with electrophysiological data to achieve\nhigher temporal resolution. We apply this approach to simulated and real ground\ntruth data to demonstrate its higher sensitivity in detecting small\nsignal-to-noise events and its increased robustness to noise compared to\nstandard methods for detecting PSCs. The new Bayesian event analysis approach\nfor electrophysiological recordings should allow for better estimation of\nphysiological parameters under more variable conditions and help support new\nexperimental designs for circuit mapping.\n", "versions": [{"version": "v1", "created": "Sun, 20 Mar 2016 15:44:40 GMT"}, {"version": "v2", "created": "Wed, 18 May 2016 16:35:52 GMT"}], "update_date": "2016-05-19", "authors_parsed": [["Merel", "Josh", ""], ["Shababo", "Ben", ""], ["Naka", "Alex", ""], ["Adesnik", "Hillel", ""], ["Paninski", "Liam", ""]]}, {"id": "1603.06248", "submitter": "Yuri A. Dabaghian", "authors": "Edward Basso, Mamiko Arai and Yuri Dabaghian", "title": "Gamma synchronization of the hippocampal spatial map---topological model", "comments": "14 pages, 4 figures, 7 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mammalian hippocampus plays a principal role in producing a cognitive map\nof space---an internalized representation of the animal's environment. The\nneuronal mechanisms producing this map depend primarily on the temporal\nstructure of the hippocampal neurons' spiking activity, which is modulated by\nthe oscillatory extracellular electrical field potential. In this paper, we\ndiscuss the integrative effect of the gamma rhythm, one of the principal\ncomponents of these oscillations, on the ability of the place cell ensembles to\nencode a spatial map. Using methods of algebraic topology and statistical\nphysics, we demonstrate that gamma-modulation of neuronal activity generates a\nsynchronized spiking of dynamical cell assemblies, which enables learning a\nspatial map at faster timescales.\n", "versions": [{"version": "v1", "created": "Sun, 20 Mar 2016 17:54:02 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Basso", "Edward", ""], ["Arai", "Mamiko", ""], ["Dabaghian", "Yuri", ""]]}, {"id": "1603.06342", "submitter": "Kieran Fox", "authors": "Kieran C. R. Fox, Matthew L. Dixon, Savannah Nijeboer, Manesh Girn,\n  James L. Floman, Michael Lifshitz, Melissa Ellamil, Peter Sedlmeier, Kalina\n  Christoff", "title": "Functional neuroanatomy of meditation: A review and meta-analysis of 78\n  functional neuroimaging investigations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meditation is a family of mental practices that encompasses a wide array of\ntechniques employing distinctive mental strategies. We systematically reviewed\n78 functional neuroimaging (fMRI and PET) studies of meditation, and used\nactivation likelihood estimation to meta-analyze 257 peak foci from 31\nexperiments involving 527 participants. We found reliably dissociable patterns\nof brain activation and deactivation for four common styles of meditation\n(focused attention, mantra recitation, open monitoring, and\ncompassion/loving-kindness), and suggestive differences for three others\n(visualization, sense-withdrawal, and non-dual awareness practices). Overall,\ndissociable activation patterns are congruent with the psychological and\nbehavioral aims of each practice. Some brain areas are recruited consistently\nacross multiple techniques - including insula, pre/supplementary motor\ncortices, dorsal anterior cingulate cortex, and frontopolar cortex - but\nconvergence is the exception rather than the rule. A preliminary effect-size\nmeta-analysis found medium effects for both activations (d = .59) and\ndeactivations (d = -.74), suggesting potential practical significance. Our\nmeta-analysis supports the neurophysiological dissociability of meditation\npractices, but also raises many methodological concerns and suggests avenues\nfor future research.\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2016 07:28:24 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Fox", "Kieran C. R.", ""], ["Dixon", "Matthew L.", ""], ["Nijeboer", "Savannah", ""], ["Girn", "Manesh", ""], ["Floman", "James L.", ""], ["Lifshitz", "Michael", ""], ["Ellamil", "Melissa", ""], ["Sedlmeier", "Peter", ""], ["Christoff", "Kalina", ""]]}, {"id": "1603.06353", "submitter": "Martijn Arts", "authors": "Martijn Arts, Marius Cordts, Monika Gorin, Marc Spehr and Rudolf\n  Mathar", "title": "A Discontinuous Neural Network for Non-Negative Sparse Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE math.OC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a discontinuous neural network which is used as a\nmodel of the mammalian olfactory system and can more generally be applied to\nsolve non-negative sparse approximation problems. By inherently limiting the\nsystems integrators to having non-negative outputs, the system function becomes\ndiscontinuous since the integrators switch between being inactive and being\nactive. It is shown that the presented network converges to equilibrium points\nwhich are solutions to general non-negative least squares optimization\nproblems. We specify a Caratheodory solution and prove that the network is\nstable, provided that the system matrix has full column-rank. Under a mild\ncondition on the equilibrium point, we show that the network converges to its\nequilibrium within a finite number of switches. Two applications of the neural\nnetwork are shown. Firstly, we apply the network as a model of the olfactory\nsystem and show that in principle it may be capable of performing complex\nsparse signal recovery tasks. Secondly, we generalize the application to\ninclude non-negative sparse approximation problems and compare the recovery\nperformance to a classical non-negative basis pursuit denoising algorithm. We\nconclude that the recovery performance differs only marginally from the\nclassical algorithm, while the neural network has the advantage that no\nperformance critical regularization parameter has to be chosen prior to\nrecovery.\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2016 08:30:43 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Arts", "Martijn", ""], ["Cordts", "Marius", ""], ["Gorin", "Monika", ""], ["Spehr", "Marc", ""], ["Mathar", "Rudolf", ""]]}, {"id": "1603.06401", "submitter": "Souparno Roy", "authors": "Souparno Roy, Ranjan Sengupta, Tarit Guhathakurata, Dipak Ghosh", "title": "Non-classicality in mental states : an experimental study with ambiguous\n  audio (music) stimuli", "comments": "Conference submission;comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.PR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper attempts to address the question that whether the present physical\nor mathematical theories are sufficient to understand the complexities of human\nbrain when it interacts with the external environment in the form of an\nauditory stimulus.There have been efforts reporting that the introduction of\nambiguity in visual stimuli causes effects which can't be explained\nclassically.In this paper,it is investigated whether ambiguity in auditory\nstimuli can introduce any non-classical effects in human brain.Simple\nexperiments were performed on normal subjects where they listened to an\nambiguous auditory signal and responded to a question with 'yes' or 'no'.The\noutcome of the test showed that the classical formula of total probability does\nnot hold true in this case.Results were interesting and indicate that there is\na definite non-classicality in mental states in perception of ambiguous audio\nstimuli.\n", "versions": [{"version": "v1", "created": "Fri, 18 Mar 2016 18:56:33 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Roy", "Souparno", ""], ["Sengupta", "Ranjan", ""], ["Guhathakurata", "Tarit", ""], ["Ghosh", "Dipak", ""]]}, {"id": "1603.06734", "submitter": "Sitabhra Sinha", "authors": "Varsha Sreenivasan, Shakti N. Menon and Sitabhra Sinha", "title": "Emergence of coupling-induced oscillations and broken symmetries in\n  heterogeneously driven nonlinear reaction networks", "comments": "5 pages, 3 figures + 4 pages supplementary information", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many natural systems including the brain comprise coupled non-uniformly\nstimulated elements. In this paper we show that heterogeneously driven networks\nof excitatory-inhibitory units exhibit striking collective phenomena, including\nspontaneous oscillations upon coupling. On varying the coupling strength a\nnovel transition is seen wherein the pattern symmetries of stimulated and\nunstimulated groups undergo mutual exchange. The system exhibits coexisting\nchaotic and non-chaotic attractors - an intriguing result in view of earlier\nreports of varying degrees of chaoticity in the brain.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 10:57:42 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Sreenivasan", "Varsha", ""], ["Menon", "Shakti N.", ""], ["Sinha", "Sitabhra", ""]]}, {"id": "1603.06790", "submitter": "Giovanni Montana", "authors": "A.W. Chung and M.D. Schirmer and M.L. Krishna and G. Ball and P.\n  Aljabar and A.D. Edwards and G. Montana", "title": "Characterising brain network topologies: a dynamic analysis approach\n  using heat kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network theory provides a principled abstraction of the human brain: reducing\na complex system into a simpler representation from which to investigate brain\norganisation. Recent advancement in the neuroimaging field are towards\nrepresenting brain connectivity as a dynamic process in order to gain a deeper\nunderstanding of how the brain is organised for information transport. In this\npaper we propose a network modelling approach based on the heat kernel to\ncapture the process of heat diffusion in complex networks. By applying the heat\nkernel to structural brain networks, we define new features which quantify\nchange in energy flow. Identifying suitable features which can classify\nnetworks between cohorts is useful towards understanding the effect of disease\non brain architecture. We demonstrate the discriminative power of heat kernel\nfeatures in both synthetic and clinical preterm data. By generating an\nextensive range of synthetic networks with varying density and randomisation,\nwe investigate how heat flows in the networks in relation to changes in network\ntopology. We demonstrate that our proposed features provide a metric of network\nefficiency and may be indicative of organisational principles commonly\nassociated with, for example, small-world architecture. In addition, we show\nthe potential of these features to characterise and classify between network\ntopologies. We further demonstrate our methodology in a clinical setting by\napplying it to a large cohort of preterm babies scanned at term equivalent age\nfrom which diffusion networks were computed. We show that our heat kernel\nfeatures are able to successfully predict motor function measured at two years\nof age (sensitivity, specificity, F-score, accuracy = 75.0, 82.5, 78.6, 82.3%,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 13:53:00 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Chung", "A. W.", ""], ["Schirmer", "M. D.", ""], ["Krishna", "M. L.", ""], ["Ball", "G.", ""], ["Aljabar", "P.", ""], ["Edwards", "A. D.", ""], ["Montana", "G.", ""]]}, {"id": "1603.06879", "submitter": "Enrico Chiovetto", "authors": "Enrico Chiovetto, Andrea d'Avella and Martin Giese", "title": "A Unifying Framework for the Identification of Motor Primitives", "comments": "33 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long-standing hypothesis in neuroscience is that the central nervous system\naccomplishes complex motor behaviors through the combination of a small number\nof motor primitives. Many studies in the last couples of decades have\nidentified motor primitives at the kinematic, kinetic, and electromyographic\nlevel, thus supporting modularity at different levels of organization in the\nmotor system. However, these studies relied on heterogeneous definitions of\nmotor primitives and on different algorithms for their identification. Standard\nunsupervised learning algorithms such as principal component analysis,\nindependent component analysis, and non-negative matrix factorization, or more\nadvanced techniques involving the estimation of temporal delays of the relevant\nmixture components have been applied. This plurality of algorithms has made\ndifficult to compare and interpret results obtained across different studies.\nMoreover, how the different definitions of motor primitives relate to each\nother has never been examined systematically. Here we propose a comprehensive\nframework for the definition of different types of motor primitives and a\nsingle algorithm for their identification. By embedding smoothness priors and\nspecific constraints in the underlying generative model, the algorithm can\nidentify many different types of motor primitives. We assessed the\nidentification performance of the algorithm both on simulated data sets, for\nwhich the properties of the primitives and of the corresponding combination\nparameters were known, and on experimental electromyographic and kinematic data\nsets, collected from human subjects accomplishing goal-oriented and rhythmic\nmotor tasks. The identification accuracy of the new algorithm was typically\nequal or better than the accuracy of other unsupervised learning algorithms\nused previously for the identification of the same types of primitives.\n", "versions": [{"version": "v1", "created": "Tue, 22 Mar 2016 17:23:15 GMT"}], "update_date": "2016-03-23", "authors_parsed": [["Chiovetto", "Enrico", ""], ["d'Avella", "Andrea", ""], ["Giese", "Martin", ""]]}, {"id": "1603.07211", "submitter": "Shuo Chen", "authors": "Shuo Chen, F. DuBois Bowman, and Yishi Xing", "title": "Differentially Expressed Functional Connectivity Networks with K-partite\n  Graph Topology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging brain network studies suggest that interactions between various\ndistributed neuronal populations may be characterized by an organized complex\ntopological structure. Many brain diseases are associated with altered\ntopological patterns of brain connectivity. Therefore, a key inquiry of\nconnectivity analysis is to identify network-level differentially expressed\nconnections that have low false positive rates, sufficient statistical power,\nand high reproducibility. In this paper, we propose a novel statistical\napproach to fulfill this goal by leveraging the topological structure of\ndifferentially expressed functional connections or edges in a graphical\nrepresentation. We propose a new algorithm to automatically detect the latent\ntopology of a k-partite graph structure, and we also provide statistical\ninferential techniques to test the detected topology. We evaluate our new\nmethods via extensive numerical studies. We also apply our new approach to\nresting state fMRI data (24 cases and 18 controls) for Parkinson's disease\nresearch. The detected connectivity network biomaker with the k-partite graph\ntopological structure reveals underlying neural features distinguishing\nParkinson's disease patients from healthy control subjects.\n", "versions": [{"version": "v1", "created": "Wed, 23 Mar 2016 14:54:56 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["Chen", "Shuo", ""], ["Bowman", "F. DuBois", ""], ["Xing", "Yishi", ""]]}, {"id": "1603.07758", "submitter": "Subhaneil Lahiri", "authors": "Subhaneil Lahiri, Jascha Sohl-Dickstein and Surya Ganguli", "title": "A universal tradeoff between power, precision and speed in physical\n  communication", "comments": "15 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech cs.IT math.IT physics.bio-ph q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximizing the speed and precision of communication while minimizing power\ndissipation is a fundamental engineering design goal. Also, biological systems\nachieve remarkable speed, precision and power efficiency using poorly\nunderstood physical design principles. Powerful theories like information\ntheory and thermodynamics do not provide general limits on power, precision and\nspeed. Here we go beyond these classical theories to prove that the product of\nprecision and speed is universally bounded by power dissipation in any physical\ncommunication channel whose dynamics is faster than that of the signal.\nMoreover, our derivation involves a novel connection between friction and\ninformation geometry. These results may yield insight into both the engineering\ndesign of communication devices and the structure and function of biological\nsignaling systems.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 21:10:40 GMT"}], "update_date": "2016-03-30", "authors_parsed": [["Lahiri", "Subhaneil", ""], ["Sohl-Dickstein", "Jascha", ""], ["Ganguli", "Surya", ""]]}, {"id": "1603.07759", "submitter": "Eugen Tarnow", "authors": "Eugen Tarnow", "title": "Preliminary Evidence -- Diagnosed Alzheimer's Disease But Not MCI\n  Affects Working Memory Capacity - 0.7 of 2.7 Memory Slots is Lost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it was shown explicitly that free recall consists of two stages: the\nfirst few recalls empty working memory (narrowly defined) and a second stage, a\nreactivation stage, concludes the recall (Tarnow, 2015). It was also shown that\nthe serial position curve changes in mild Alzheimer's disease, lowered total\nrecall and lessened primacy, are similar to second stage recall and different\nfrom recall from working memory. The Tarnow Unchunkable Test (TUT, Tarnow,\n2013) uses double integer items to separate out only the first stage, the\nemptying of working memory, by making it difficult to reactivate items due to\nthe lack of intra-item relationships. Here it is shown that subject TUT selects\nout diagnosed Alzheimer's Disease but not MCI. On average, diagnosed\nAlzheimer's Disease is correlated with a loss of 0.7 memory slots (out of an\naverage of 2.7 slots). The identification of a lost memory slot may have\nimplications for improved stage definitions of Alzheimer's disease and for\nremediation therapy via working memory capacity management. In conjunction with\nthe Alzheimer's disease process map, it may also be useful to identify the\nexact location of working memory.\n", "versions": [{"version": "v1", "created": "Thu, 24 Mar 2016 21:15:03 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Tarnow", "Eugen", ""]]}, {"id": "1603.08432", "submitter": "Lida Kanari", "authors": "Lida Kanari, Pawe{\\l} D{\\l}otko, Martina Scolamiero, Ran Levi, Julian\n  Shillcock, Kathryn Hess, Henry Markram", "title": "Quantifying topological invariants of neuronal morphologies", "comments": "10 pages, 5 figures, conference or other essential info", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.DS math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nervous systems are characterized by neurons displaying a diversity of\nmorphological shapes. Traditionally, different shapes have been qualitatively\ndescribed based on visual inspection and quantitatively described based on\nmorphometric parameters. Neither process provides a solid foundation for\ncategorizing the various morphologies, a problem that is important in many\nfields. We propose a stable topological measure as a standardized descriptor\nfor any tree-like morphology, which encodes its skeletal branching anatomy.\nMore specifically it is a barcode of the branching tree as determined by a\nspherical filtration centered at the root or neuronal soma. This Topological\nMorphology Descriptor (TMD) allows for the discrimination of groups of random\nand neuronal trees at linear computational cost.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 16:32:44 GMT"}], "update_date": "2016-03-29", "authors_parsed": [["Kanari", "Lida", ""], ["D\u0142otko", "Pawe\u0142", ""], ["Scolamiero", "Martina", ""], ["Levi", "Ran", ""], ["Shillcock", "Julian", ""], ["Hess", "Kathryn", ""], ["Markram", "Henry", ""]]}, {"id": "1603.08445", "submitter": "Fabrizio De Vico Fallani", "authors": "Fabrizio De Vico Fallani, Vito Latora and Mario Chavez", "title": "A topological criterion for filtering information in complex brain\n  networks", "comments": null, "journal-ref": "PLOS Computational Biology 13(1): e1005305 (2017)", "doi": "10.1371/journal.pcbi.1005305", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many biological systems, the network of interactions between the elements\ncan only be inferred from experimental measurements. In neuroscience,\nnon-invasive imaging tools are extensively used to derive either structural or\nfunctional brain networks in-vivo. As a result of the inference process, we\nobtain a matrix of values corresponding to an unrealistic fully connected and\nweighted network. To turn this into a useful sparse network, thresholding is\ntypically adopted to cancel a percentage of the weakest connections. The\nstructural properties of the resulting network depend on how much of the\ninferred connectivity is eventually retained. However, how to fix this\nthreshold is still an open issue. We introduce a criterion, the efficiency cost\noptimization (ECO), to select a threshold based on the optimization of the\ntrade-off between the efficiency of a network and its wiring cost. We prove\nanalytically and we confirm through numerical simulations that the connection\ndensity maximizing this trade-off emphasizes the intrinsic properties of a\ngiven network, while preserving its sparsity. Moreover, this density threshold\ncan be determined a-priori, since the number of connections to filter only\ndepends on the network size according to a power-law. We validate this result\non several brain networks, from micro- to macro-scales, obtained with different\nimaging modalities. Finally, we test the potential of ECO in discriminating\nbrain states with respect to alternative filtering methods. ECO advances our\nability to analyze and compare biological networks, inferred from experimental\ndata, in a fast and principled way.\n", "versions": [{"version": "v1", "created": "Mon, 28 Mar 2016 17:19:35 GMT"}, {"version": "v2", "created": "Wed, 23 Nov 2016 21:54:04 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Fallani", "Fabrizio De Vico", ""], ["Latora", "Vito", ""], ["Chavez", "Mario", ""]]}]