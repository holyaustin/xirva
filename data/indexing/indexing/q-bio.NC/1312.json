[{"id": "1312.0125", "submitter": "Hamed Seyed-Allaei", "authors": "Hamed Seyed-allaei", "title": "Phase Diagram of Spiking Neural Networks", "comments": "oscillations are studied in this version", "journal-ref": "Front. Comput. Neurosci., 04 March 2015", "doi": "10.3389/fncom.2015.00019", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In computer simulations of spiking neural networks, often it is assumed that\nevery two neurons of the network are connected by a probability of 2\\%, 20\\% of\nneurons are inhibitory and 80\\% are excitatory. These common values are based\non experiments, observations, and trials and errors, but here, I take a\ndifferent perspective, inspired by evolution, I systematically simulate many\nnetworks, each with a different set of parameters, and then I try to figure out\nwhat makes the common values desirable. I stimulate networks with pulses and\nthen measure their: dynamic range, dominant frequency of population activities,\ntotal duration of activities, maximum rate of population and the occurrence\ntime of maximum rate. The results are organized in phase diagram. This phase\ndiagram gives an insight into the space of parameters -- excitatory to\ninhibitory ratio, sparseness of connections and synaptic weights. This phase\ndiagram can be used to decide the parameters of a model. The phase diagrams\nshow that networks which are configured according to the common values, have a\ngood dynamic range in response to an impulse and their dynamic range is robust\nin respect to synaptic weights, and for some synaptic weights they oscillate in\n$\\alpha$ or $\\beta$ frequencies, even in absence of external stimuli.\n", "versions": [{"version": "v1", "created": "Sat, 30 Nov 2013 16:55:18 GMT"}, {"version": "v2", "created": "Tue, 16 Sep 2014 15:30:47 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Seyed-allaei", "Hamed", ""]]}, {"id": "1312.1104", "submitter": "Isabelle Rivals", "authors": "Brigitte Quenet (ESA), Christian Straus (ER 10 UPMC), Marie-No\\\"elle\n  Fiamma (ER 10 UPMC), Isabelle Rivals (ESA), Thomas Similowski (ER 10 UPMC),\n  Ginette Horcholle-Bossavit (ESA)", "title": "New insights in gill/buccal rhythm spiking activity and CO2 sensitivity\n  in pre- and post-metamorphic tadpoles (Pelophylax ridibundus)", "comments": null, "journal-ref": "Respiratory Physiology & Neurobiology 191 (2014) 26-37", "doi": "10.1016/j.resp.2013.10.013", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Central CO2chemosensitivity is crucial for all air-breathing vertebrates and\nraises the question of itsrole in ventilatory rhythmogenesis. In this study,\nneurograms of ventilatory motor outputs recorded infacial nerve of\npremetamorphic and postmetamorphic tadpole isolated brainstems, under normo-\nandhypercapnia, are investigated using Continuous Wavelet Transform spectral\nanalysis for buccal activityand computation of number and amplitude of spikes\nduring buccal and lung activities. Buccal burstsexhibit fast oscillations\n(20-30 Hz) that are prominent in premetamorphic tadpoles: they result from\nthepresence in periodic time windows of high amplitude spikes. Hypercapnia\nsystematically decreases thefrequency of buccal rhythm in both pre- and\npostmetamorphic tadpoles, by a lengthening of the interburstduration. In\npostmetamorphic tadpoles, hypercapnia reduces buccal burst amplitude and\nunmasks smallfast oscillations. Our results suggest a common effect of the\nhypercapnia on the buccal part of the CentralPattern Generator in all tadpoles\nand a possible effect at the level of the motoneuron recruitment\ninpostmetamorphic tadpoles.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2013 10:57:48 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Quenet", "Brigitte", "", "ESA"], ["Straus", "Christian", "", "ER 10 UPMC"], ["Fiamma", "Marie-No\u00eblle", "", "ER 10 UPMC"], ["Rivals", "Isabelle", "", "ESA"], ["Similowski", "Thomas", "", "ER 10 UPMC"], ["Horcholle-Bossavit", "Ginette", "", "ESA"]]}, {"id": "1312.1206", "submitter": "Andrey Olypher", "authors": "Andrey Olypher, Jean Vaillant", "title": "On the properties of input-to-output transformations in networks of\n  perceptrons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information processing in certain neuronal networks in the brain can be\nconsidered as a map of binary vectors, where ones (spikes) and zeros (no\nspikes) of input neurons are transformed into spikes and no spikes of output\nneurons. A simple but fundamental characteristic of such a map is how it\ntransforms distances between input vectors. In particular what is the mean\ndistance between output vectors given certain distance between input vectors?\nUsing combinatorial approach we found an exact solution to this problem for\nnetworks of perceptrons with binary weights. he resulting formulas allow for\nprecise analysis how network connectivity and neuronal excitability affect the\ntransformation of distances between the vectors of neuronal spiking. As an\napplication, we considered a simple network model of information processing in\nthe hippocampus, a brain area critically implicated in learning and memory, and\nfound a combination of parameters for which the output neurons discriminated\nsimilar and distinct inputs most effectively. A decrease of threshold values of\nthe output neurons, which in biological networks may be associated with\ndecreased inhibition, impaired optimality of discrimination.\n", "versions": [{"version": "v1", "created": "Wed, 4 Dec 2013 15:25:37 GMT"}], "update_date": "2013-12-05", "authors_parsed": [["Olypher", "Andrey", ""], ["Vaillant", "Jean", ""]]}, {"id": "1312.1632", "submitter": "Jake Bouvrie", "authors": "Jake Bouvrie, Jean-Jacques Slotine", "title": "Synchronization and Noise: A Mechanism for Regularization in Neural\n  Systems", "comments": "32 pages, 7 figures. under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To learn and reason in the presence of uncertainty, the brain must be capable\nof imposing some form of regularization. Here we suggest, through theoretical\nand computational arguments, that the combination of noise with synchronization\nprovides a plausible mechanism for regularization in the nervous system. The\nfunctional role of regularization is considered in a general context in which\ncoupled computational systems receive inputs corrupted by correlated noise.\nNoise on the inputs is shown to impose regularization, and when synchronization\nupstream induces time-varying correlations across noise variables, the degree\nof regularization can be calibrated over time. The proposed mechanism is\nexplored first in the context of a simple associative learning problem, and\nthen in the context of a hierarchical sensory coding task. The resulting\nqualitative behavior coincides with experimental data from visual cortex.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 17:58:06 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Bouvrie", "Jake", ""], ["Slotine", "Jean-Jacques", ""]]}, {"id": "1312.1876", "submitter": "Vince Grolmusz", "authors": "Balazs Szalkai, Vince K. Grolmusz, Vince I. Grolmusz, Coalition\n  Against Major Diseases", "title": "Identifying Combinatorial Biomarkers by Association Rule Mining in the\n  CAMD Alzheimer's Database", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The concept of combinatorial biomarkers was conceived around\n2010: it was noticed that simple biomarkers are often inadequate for\nrecognizing and characterizing complex diseases.\n  Methods: Here we present an algorithmic search method for complex biomarkers\nwhich may predict or indicate Alzheimer's disease (AD) and other kinds of\ndementia. We applied data mining techniques that are capable to uncover\nimplication-like logical schemes with detailed quality scoring. Our program\nSCARF is capable of finding multi-factor relevant association rules\nautomatically. The new SCARF program was applied for the Tucson, Arizona based\nCritical Path Institute's CAMD database, containing laboratory and cognitive\ntest data for more than 6000 patients from the placebo arm of clinical trials\nof large pharmaceutical companies, and consequently, the data is much more\nreliable than numerous other databases for dementia.\n  Results: The results suggest connections between liver enzyme-, B12 vitamin-,\nsodium- and cholesterol levels and dementia, and also some hematologic\nparameter-levels and dementia.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 14:55:53 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Szalkai", "Balazs", ""], ["Grolmusz", "Vince K.", ""], ["Grolmusz", "Vince I.", ""], ["Diseases", "Coalition Against Major", ""]]}, {"id": "1312.2838", "submitter": "Steven Frank", "authors": "Steven A. Frank", "title": "Input-output relations in biological systems: measurement, information\n  and the Hill equation", "comments": "Biology Direct 8:31", "journal-ref": null, "doi": "10.1186/1745-6150-8-31", "report-no": null, "categories": "q-bio.MN cond-mat.stat-mech q-bio.CB q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological systems produce outputs in response to variable inputs.\nInput-output relations tend to follow a few regular patterns. For example, many\nchemical processes follow the S-shaped Hill equation relation between input\nconcentrations and output concentrations. That Hill equation pattern\ncontradicts the fundamental Michaelis-Menten theory of enzyme kinetics. I use\nthe discrepancy between the expected Michaelis-Menten process of enzyme\nkinetics and the widely observed Hill equation pattern of biological systems to\nexplore the general properties of biological input-output relations. I start\nwith the various processes that could explain the discrepancy between basic\nchemistry and biological pattern. I then expand the analysis to consider\nbroader aspects that shape biological input-output relations. Key aspects\ninclude the input-output processing by component subsystems and how those\ncomponents combine to determine the system's overall input-output relations.\nThat aggregate structure often imposes strong regularity on underlying\ndisorder. Aggregation imposes order by dissipating information as it flows\nthrough the components of a system. The dissipation of information may be\nevaluated by the analysis of measurement and precision, explaining why certain\ncommon scaling patterns arise so frequently in input-output relations. I\ndiscuss how aggregation, measurement and scale provide a framework for\nunderstanding the relations between pattern and process. The regularity imposed\nby those broader structural aspects sets the contours of variation in biology.\nThus, biological design will also tend to follow those contours. Natural\nselection may act primarily to modulate system properties within those broad\nconstraints.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 15:46:16 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Frank", "Steven A.", ""]]}, {"id": "1312.2950", "submitter": "Marcos A. Trevisan", "authors": "Mar\\'ia Florencia Assaneo, Marcos A. Trevisan", "title": "Revisiting the two-mass model of the vocal folds", "comments": "7 pages, 5 figures", "journal-ref": "Papers in Physics 5, 050004 (2013)", "doi": "10.4279/PIP.050004", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Realistic mathematical modeling of voice production has been recently boosted\nby applications to different fields like bioprosthetics, quality speech\nsynthesis and pathological diagnosis. In this work, we revisit a two-mass model\nof the vocal folds that includes accurate fluid mechanics for the air passage\nthrough the folds and nonlinear properties of the tissue. We present the\nbifurcation diagram for such a system, focusing on the dynamical properties of\ntwo regimes of interest: the onset of oscillations and the normal phonation\nregime. We also show theoretical support to the nonlinear nature of the elastic\nproperties of the folds tissue by comparing theoretical isofrequency curves\nwith reported experimental data.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 13:33:18 GMT"}], "update_date": "2013-12-12", "authors_parsed": [["Assaneo", "Mar\u00eda Florencia", ""], ["Trevisan", "Marcos A.", ""]]}, {"id": "1312.4106", "submitter": "Tomasz Rutkowski", "authors": "Chisaki Nakaizumi, Koichi Mori, Toshie Matsui, Shoji Makino, and\n  Tomasz M. Rutkowski", "title": "Auditory Brain-Computer Interface Paradigm with Head Related Impulse\n  Response-based Spatial Cues", "comments": "The final publication is available at IEEE Xplore\n  http://ieeexplore.ieee.org and the copyright of the final version has been\n  transferred to IEEE (c)2013", "journal-ref": "Proceedings of the 9th International Conference on Signal Image\n  Technology and Internet Based Systems. Kyoto, Japan: IEEE Computer Society;\n  2013. p. 806-811", "doi": "10.1109/SITIS.2013.131", "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The aim of this study is to provide a comprehensive test of head related\nimpulse response (HRIR) for an auditory spatial speller brain-computer\ninterface (BCI) paradigm. The study is conducted with six users in an\nexperimental set up based on five Japanese hiragana vowels. Auditory evoked\npotentials resulted with encouragingly good and stable \"aha-\" or P300-responses\nin real-world online BCI experiments. Our case study indicated that the\nauditory HRIR spatial sound reproduction paradigm could be a viable alternative\nto the established multi-loudspeaker surround sound BCI-speller applications,\nas far as healthy pilot study users are concerned.\n", "versions": [{"version": "v1", "created": "Sun, 15 Dec 2013 04:54:22 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Nakaizumi", "Chisaki", ""], ["Mori", "Koichi", ""], ["Matsui", "Toshie", ""], ["Makino", "Shoji", ""], ["Rutkowski", "Tomasz M.", ""]]}, {"id": "1312.4382", "submitter": "Hideaki Shimazaki", "authors": "Hideaki Shimazaki", "title": "Single-trial estimation of stimulus and spike-history effects on\n  time-varying ensemble spiking activity of multiple neurons: a simulation\n  study", "comments": "12 pages, 3 figures", "journal-ref": "J. Phys.: Conf. Ser. (2013) 473, 012009", "doi": "10.1088/1742-6596/473/1/012009", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech stat.ML", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Neurons in cortical circuits exhibit coordinated spiking activity, and can\nproduce correlated synchronous spikes during behavior and cognition. We\nrecently developed a method for estimating the dynamics of correlated ensemble\nactivity by combining a model of simultaneous neuronal interactions (e.g., a\nspin-glass model) with a state-space method (Shimazaki et al. 2012 PLoS Comput\nBiol 8 e1002385). This method allows us to estimate stimulus-evoked dynamics of\nneuronal interactions which is reproducible in repeated trials under identical\nexperimental conditions. However, the method may not be suitable for detecting\nstimulus responses if the neuronal dynamics exhibits significant variability\nacross trials. In addition, the previous model does not include effects of past\nspiking activity of the neurons on the current state of ensemble activity. In\nthis study, we develop a parametric method for simultaneously estimating the\nstimulus and spike-history effects on the ensemble activity from single-trial\ndata even if the neurons exhibit dynamics that is largely unrelated to these\neffects. For this goal, we model ensemble neuronal activity as a latent process\nand include the stimulus and spike-history effects as exogenous inputs to the\nlatent process. We develop an expectation-maximization algorithm that\nsimultaneously achieves estimation of the latent process, stimulus responses,\nand spike-history effects. The proposed method is useful to analyze an\ninteraction of internal cortical states and sensory evoked activity.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 14:50:26 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Shimazaki", "Hideaki", ""]]}, {"id": "1312.4695", "submitter": "Wiktor Mlynarski", "authors": "Wiktor Mlynarski", "title": "Sparse, complex-valued representations of natural sounds learned with\n  phase and amplitude continuity priors", "comments": "11 + 7 pages This version includes changes suggested by ICLR 2014\n  reviewers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.SD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex-valued sparse coding is a data representation which employs a\ndictionary of two-dimensional subspaces, while imposing a sparse, factorial\nprior on complex amplitudes. When trained on a dataset of natural image\npatches, it learns phase invariant features which closely resemble receptive\nfields of complex cells in the visual cortex. Features trained on natural\nsounds however, rarely reveal phase invariance and capture other aspects of the\ndata. This observation is a starting point of the present work. As its first\ncontribution, it provides an analysis of natural sound statistics by means of\nlearning sparse, complex representations of short speech intervals. Secondly,\nit proposes priors over the basis function set, which bias them towards\nphase-invariant solutions. In this way, a dictionary of complex basis functions\ncan be learned from the data statistics, while preserving the phase invariance\nproperty. Finally, representations trained on speech sounds with and without\npriors are compared. Prior-based basis functions reveal performance comparable\nto unconstrained sparse coding, while explicitely representing phase as a\ntemporal shift. Such representations can find applications in many perceptual\nand machine learning tasks.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 09:12:55 GMT"}, {"version": "v2", "created": "Wed, 18 Dec 2013 10:48:17 GMT"}, {"version": "v3", "created": "Tue, 18 Feb 2014 10:20:25 GMT"}], "update_date": "2014-02-19", "authors_parsed": [["Mlynarski", "Wiktor", ""]]}, {"id": "1312.5212", "submitter": "Steve N'Guyen", "authors": "Steve N'Guyen, Charles Thurat, Beno\\^it Girard", "title": "Saccade learning with concurrent cortical and subcortical basal ganglia\n  loops", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Basal Ganglia is a central structure involved in multiple cortical and\nsubcortical loops. Some of these loops are believed to be responsible for\nsaccade target selection. We study here how the very specific structural\nrelationships of these saccadic loops can affect the ability of learning\nspatial and feature-based tasks.\n  We propose a model of saccade generation with reinforcement learning\ncapabilities based on our previous basal ganglia and superior colliculus\nmodels. It is structured around the interactions of two parallel cortico-basal\nloops and one tecto-basal loop. The two cortical loops separately deal with\nspatial and non-spatial information to select targets in a concurrent way. The\nsubcortical loop is used to make the final target selection leading to the\nproduction of the saccade. These different loops may work in concert or disturb\neach other regarding reward maximization. Interactions between these loops and\ntheir learning capabilities are tested on different saccade tasks.\n  The results show the ability of this model to correctly learn basic target\nselection based on different criteria (spatial or not). Moreover the model\nreproduces and explains training dependent express saccades toward targets\nbased on a spatial criterion.\n  Finally, the model predicts that in absence of prefrontal control, the\nspatial loop should dominate.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2013 16:38:51 GMT"}, {"version": "v2", "created": "Mon, 30 Dec 2013 10:43:17 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["N'Guyen", "Steve", ""], ["Thurat", "Charles", ""], ["Girard", "Beno\u00eet", ""]]}, {"id": "1312.5492", "submitter": "Shinya Kuroda", "authors": "Takuya Koumura, Hidetoshi Urakubo, Kaoru Ohashi, Masashi Fujii and\n  Shinya Kuroda", "title": "Stochasticity in Ca$^{2+}$ increase in spines enables robust and\n  sensitive information coding", "comments": "47 pages, 4 figures, 8 supplementary figures", "journal-ref": null, "doi": "10.1371/journal.pone.0099040", "report-no": null, "categories": "q-bio.MN q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A dendritic spine is a very small structure (~0.1 {\\mu}m$^3$) of a neuron\nthat processes input timing information. Why are spines so small? Here, we\nprovide functional reasons; the size of spines is optimal for information\ncoding. Spines code input timing information by the probability of Ca$^{2+}$\nincreases, which makes robust and sensitive information coding possible. We\ncreated a stochastic simulation model of input timing-dependent Ca$^{2+}$\nincreases in a cerebellar Purkinje cell's spine. Spines used probability coding\nof Ca$^{2+}$ increases rather than amplitude coding for input timing detection\nvia stochastic facilitation by utilizing the small number of molecules in a\nspine volume, where information per volume appeared optimal. Probability coding\nof Ca$^{2+}$ increases in a spine volume was more robust against input\nfluctuation and more sensitive to input numbers than amplitude coding of\nCa$^{2+}$ increases in a cell volume. Thus, stochasticity is a strategy by\nwhich neurons robustly and sensitively code information.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 11:49:19 GMT"}, {"version": "v2", "created": "Tue, 25 Feb 2014 11:55:53 GMT"}], "update_date": "2014-06-18", "authors_parsed": [["Koumura", "Takuya", ""], ["Urakubo", "Hidetoshi", ""], ["Ohashi", "Kaoru", ""], ["Fujii", "Masashi", ""], ["Kuroda", "Shinya", ""]]}, {"id": "1312.6070", "submitter": "Danielle Bassett", "authors": "Christian Lohse, Danielle S. Bassett, Kelvin O. Lim, Jean M. Carlson", "title": "Resolving Structure in Human Brain Organization: Identifying Mesoscale\n  Organization in Weighted Network Representations", "comments": "Comments welcome", "journal-ref": null, "doi": "10.1371/journal.pcbi.1003712", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human brain anatomy and function display a combination of modular and\nhierarchical organization, suggesting the importance of both cohesive\nstructures and variable resolutions in the facilitation of healthy cognitive\nprocesses. However, tools to simultaneously probe these features of brain\narchitecture require further development. We propose and apply a set of methods\nto extract cohesive structures in network representations of brain connectivity\nusing multi-resolution techniques. We employ a combination of soft\nthresholding, windowed thresholding, and resolution in community detection,\nthat enable us to identify and isolate structures associated with different\nweights. One such mesoscale structure is bipartivity, which quantifies the\nextent to which the brain is divided into two partitions with high connectivity\nbetween partitions and low connectivity within partitions. A second,\ncomplementary mesoscale structure is modularity, which quantifies the extent to\nwhich the brain is divided into multiple communities with strong connectivity\nwithin each community and weak connectivity between communities. Our methods\nlead to multi-resolution curves of these network diagnostics over a range of\nspatial, geometric, and structural scales. For statistical comparison, we\ncontrast our results with those obtained for several benchmark null models. Our\nwork demonstrates that multi-resolution diagnostic curves capture complex\norganizational profiles in weighted graphs. We apply these methods to the\nidentification of resolution-specific characteristics of healthy weighted graph\narchitecture and altered connectivity profiles in psychiatric disease.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 18:43:12 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Lohse", "Christian", ""], ["Bassett", "Danielle S.", ""], ["Lim", "Kelvin O.", ""], ["Carlson", "Jean M.", ""]]}, {"id": "1312.6077", "submitter": "Garrison Cottrell", "authors": "Honghao Shan, Garrison Cottrell", "title": "Efficient Visual Coding: From Retina To V2", "comments": "For the ICLR 2014 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human visual system has a hierarchical structure consisting of layers of\nprocessing, such as the retina, V1, V2, etc. Understanding the functional roles\nof these visual processing layers would help to integrate the\npsychophysiological and neurophysiological models into a consistent theory of\nhuman vision, and would also provide insights to computer vision research. One\nclassical theory of the early visual pathway hypothesizes that it serves to\ncapture the statistical structure of the visual inputs by efficiently coding\nthe visual information in its outputs. Until recently, most computational\nmodels following this theory have focused upon explaining the receptive field\nproperties of one or two visual layers. Recent work in deep networks has\neliminated this concern, however, there is till the retinal layer to consider.\nHere we improve on a previously-described hierarchical model Recursive ICA\n(RICA) [1] which starts with PCA, followed by a layer of sparse coding or ICA,\nfollowed by a component-wise nonlinearity derived from considerations of the\nvariable distributions expected by ICA. This process is then repeated. In this\nwork, we improve on this model by using a new version of sparse PCA (sPCA),\nwhich results in biologically-plausible receptive fields for both the sPCA and\nICA/sparse coding. When applied to natural image patches, our model learns\nvisual features exhibiting the receptive field properties of retinal ganglion\ncells/lateral geniculate nucleus (LGN) cells, V1 simple cells, V1 complex\ncells, and V2 cells. Our work provides predictions for experimental\nneuroscience studies. For example, our result suggests that a previous\nneurophysiological study improperly discarded some of their recorded neurons;\nwe predict that their discarded neurons capture the shape contour of objects.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 19:09:38 GMT"}, {"version": "v2", "created": "Thu, 18 Dec 2014 01:03:58 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Shan", "Honghao", ""], ["Cottrell", "Garrison", ""]]}, {"id": "1312.6108", "submitter": "Nan Wang", "authors": "Nan Wang, Dirk Jancke, Laurenz Wiskott", "title": "Modeling correlations in spontaneous activity of visual cortex with\n  centered Gaussian-binary deep Boltzmann machines", "comments": "9 pages, 4 figures, for openreview ICLR2014, 2nd revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spontaneous cortical activity -- the ongoing cortical activities in absence\nof intentional sensory input -- is considered to play a vital role in many\naspects of both normal brain functions and mental dysfunctions. We present a\ncentered Gaussian-binary Deep Boltzmann Machine (GDBM) for modeling the\nactivity in early cortical visual areas and relate the random sampling in GDBMs\nto the spontaneous cortical activity. After training the proposed model on\nnatural image patches, we show that the samples collected from the model's\nprobability distribution encompass similar activity patterns as found in the\nspontaneous activity. Specifically, filters having the same orientation\npreference tend to be active together during random sampling. Our work\ndemonstrates the centered GDBM is a meaningful model approach for basic\nreceptive field properties and the emergence of spontaneous activity patterns\nin early cortical visual areas. Besides, we show empirically that centered\nGDBMs do not suffer from the difficulties during training as GDBMs do and can\nbe properly trained without the layer-wise pretraining.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 20:47:28 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2014 13:46:25 GMT"}, {"version": "v3", "created": "Mon, 17 Feb 2014 16:41:30 GMT"}], "update_date": "2014-02-18", "authors_parsed": [["Wang", "Nan", ""], ["Jancke", "Dirk", ""], ["Wiskott", "Laurenz", ""]]}, {"id": "1312.6115", "submitter": "David Reichert", "authors": "David P. Reichert, Thomas Serre", "title": "Neuronal Synchrony in Complex-Valued Deep Networks", "comments": "ICLR 2014, accepted to conference track. This version: added\n  proceedings note, minor additions", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has recently led to great successes in tasks such as image\nrecognition (e.g Krizhevsky et al., 2012). However, deep networks are still\noutmatched by the power and versatility of the brain, perhaps in part due to\nthe richer neuronal computations available to cortical circuits. The challenge\nis to identify which neuronal mechanisms are relevant, and to find suitable\nabstractions to model them. Here, we show how aspects of spike timing, long\nhypothesized to play a crucial role in cortical information processing, could\nbe incorporated into deep networks to build richer, versatile representations.\n  We introduce a neural network formulation based on complex-valued neuronal\nunits that is not only biologically meaningful but also amenable to a variety\nof deep learning frameworks. Here, units are attributed both a firing rate and\na phase, the latter indicating properties of spike timing. We show how this\nformulation qualitatively captures several aspects thought to be related to\nneuronal synchrony, including gating of information processing and dynamic\nbinding of distributed object representations. Focusing on the latter, we\ndemonstrate the potential of the approach in several simple experiments. Thus,\nneuronal synchrony could be a flexible mechanism that fulfills multiple\nfunctional roles in deep networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 20:59:11 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2013 13:34:08 GMT"}, {"version": "v3", "created": "Mon, 30 Dec 2013 18:42:17 GMT"}, {"version": "v4", "created": "Tue, 18 Feb 2014 01:28:47 GMT"}, {"version": "v5", "created": "Sat, 22 Mar 2014 20:25:27 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Reichert", "David P.", ""], ["Serre", "Thomas", ""]]}, {"id": "1312.6120", "submitter": "Andrew Saxe", "authors": "Andrew M. Saxe, James L. McClelland, Surya Ganguli", "title": "Exact solutions to the nonlinear dynamics of learning in deep linear\n  neural networks", "comments": "Submission to ICLR2014. Revised based on reviewer feedback", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn cs.CV cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the widespread practical success of deep learning methods, our\ntheoretical understanding of the dynamics of learning in deep neural networks\nremains quite sparse. We attempt to bridge the gap between the theory and\npractice of deep learning by systematically analyzing learning dynamics for the\nrestricted case of deep linear neural networks. Despite the linearity of their\ninput-output map, such networks have nonlinear gradient descent dynamics on\nweights that change with the addition of each new hidden layer. We show that\ndeep linear networks exhibit nonlinear learning phenomena similar to those seen\nin simulations of nonlinear networks, including long plateaus followed by rapid\ntransitions to lower error solutions, and faster convergence from greedy\nunsupervised pretraining initial conditions than from random initial\nconditions. We provide an analytical description of these phenomena by finding\nnew exact solutions to the nonlinear dynamics of deep learning. Our theoretical\nanalysis also reveals the surprising finding that as the depth of a network\napproaches infinity, learning speed can nevertheless remain finite: for a\nspecial class of initial conditions on the weights, very deep networks incur\nonly a finite, depth independent, delay in learning speed relative to shallow\nnetworks. We show that, under certain conditions on the training data,\nunsupervised pretraining can find this special class of initial conditions,\nwhile scaled random Gaussian initializations cannot. We further exhibit a new\nclass of random orthogonal initial conditions on weights that, like\nunsupervised pre-training, enjoys depth independent learning times. We further\nshow that these initial conditions also lead to faithful propagation of\ngradients even in deep nonlinear networks, as long as they operate in a special\nregime known as the edge of chaos.\n", "versions": [{"version": "v1", "created": "Fri, 20 Dec 2013 20:24:00 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2014 20:39:04 GMT"}, {"version": "v3", "created": "Wed, 19 Feb 2014 17:26:57 GMT"}], "update_date": "2014-02-20", "authors_parsed": [["Saxe", "Andrew M.", ""], ["McClelland", "James L.", ""], ["Ganguli", "Surya", ""]]}, {"id": "1312.6310", "submitter": "Rembrandt Bakker", "authors": "Rembrandt Bakker, Paul Tiesinga, Rolf K\\\"otter", "title": "The Scalable Brain Atlas: instant web-based access to public brain\n  atlases and related content", "comments": "Rolf K\\\"otter sadly passed away on June 9th, 2010. He co-initiated\n  this project and played a crucial role in the design and quality assurance of\n  the Scalable Brain Atlas", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Scalable Brain Atlas (SBA) is a collection of web services that provide\nunified access to a large collection of brain atlas templates for different\nspecies. Its main component is an atlas viewer that displays brain atlas data\nas a stack of slices in which stereotaxic coordinates and brain regions can be\nselected. These are subsequently used to launch web queries to resources that\nrequire coordinates or region names as input. It supports plugins which run\ninside the viewer and respond when a new slice, coordinate or region is\nselected. It contains 20 atlas templates in six species, and plugins to compute\ncoordinate transformations, display anatomical connectivity and fiducial\npoints, and retrieve properties, descriptions, definitions and 3d\nreconstructions of brain regions. The ambition of SBA is to provide a unified\nrepresentation of all publicly available brain atlases directly in the web\nbrowser, while remaining a responsive and light weight resource that\nspecializes in atlas comparisons, searches, coordinate transformations and\ninteractive displays.\n", "versions": [{"version": "v1", "created": "Sat, 21 Dec 2013 22:03:24 GMT"}, {"version": "v2", "created": "Thu, 11 Dec 2014 15:27:48 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Bakker", "Rembrandt", ""], ["Tiesinga", "Paul", ""], ["K\u00f6tter", "Rolf", ""]]}, {"id": "1312.6336", "submitter": "Sen Pei", "authors": "Sen Pei, Shaoting Tang, Shu Yan, Shijin Jiang, Xiao Zhang, Zhiming\n  Zheng", "title": "How to enhance the dynamic range of excitatory-inhibitory excitable\n  networks", "comments": "7 pages, 9 figures", "journal-ref": "Physical Review E 86 (2), 021909, 2012", "doi": "10.1103/PhysRevE.86.021909", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the collective dynamics of excitatory-inhibitory excitable\nnetworks in response to external stimuli. How to enhance dynamic range, which\nrepresents the ability of networks to encode external stimuli, is crucial to\nmany applications. We regard the system as a two-layer network (E-Layer and\nI-Layer) and explore the criticality and dynamic range on diverse networks.\nInterestingly, we find that phase transition occurs when the dominant\neigenvalue of E-layer's weighted adjacency matrix is exactly one, which is only\ndetermined by the topology of E-Layer. Meanwhile, it is shown that dynamic\nrange is maximized at critical state. Based on theoretical analysis, we propose\nan inhibitory factor for each excitatory node. We suggest that if nodes with\nhigh inhibitory factors are cut out from I-Layer, dynamic range could be\nfurther enhanced. However, because of the sparseness of networks and passive\nfunction of inhibitory nodes, the improvement is relatively small compared\ntooriginal dynamic range. Even so, this provides a strategy to enhance dynamic\nrange.\n", "versions": [{"version": "v1", "created": "Sun, 22 Dec 2013 03:05:19 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Pei", "Sen", ""], ["Tang", "Shaoting", ""], ["Yan", "Shu", ""], ["Jiang", "Shijin", ""], ["Zhang", "Xiao", ""], ["Zheng", "Zhiming", ""]]}, {"id": "1312.6660", "submitter": "Mariano Sigman", "authors": "Ariel D Zylberberg, Luciano Paz, Pieter R Roelfsema, Stanislas\n  Dehaene, Mariano Sigman", "title": "A neuronal device for the control of multi-step computations", "comments": "13 pages, 6 figures", "journal-ref": "Papers in Physics 5, 050006 (2013)", "doi": "10.4279/PIP.050006", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We describe the operation of a neuronal device which embodies the\ncomputational principles of the `paper-and-pencil' machine envisioned by Alan\nTuring. The network is based on principles of cortical organization. We develop\na plausible solution to implement pointers and investigate how neuronal\ncircuits may instantiate the basic operations involved in assigning a value to\na variable (i.e., x=5), in determining whether two variables have the same\nvalue and in retrieving the value of a given variable to be accessible to other\nnodes of the network. We exemplify the collective function of the network in\nsimplified arithmetic and problem solving (blocks-world) tasks.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 13:55:34 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Zylberberg", "Ariel D", ""], ["Paz", "Luciano", ""], ["Roelfsema", "Pieter R", ""], ["Dehaene", "Stanislas", ""], ["Sigman", "Mariano", ""]]}, {"id": "1312.7331", "submitter": "Ziv Williams", "authors": "Ziv M Williams", "title": "Trans-generational effect of trained aversive and appetitive experiences\n  in Drosophila", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Associative learning allows animals to rapidly adapt to changes in the\nenvironment. Whether and what aspects of such acquired traits may be\ntransmittable across generations remains unclear. Using prolonged olfactory\ntraining and subsequent two-forced choice testing in Drosophila melanogaster,\nit is observed that certain aspects of learned behavior were transmitted from\nparents to offspring. Offspring of parents exposed to distinct odors during\nboth aversive and appetitive conditioning displayed a heightened sensitivity to\nthose same odors. The conditioned responses associated with those odors,\nhowever, were not transmitted to the offspring as they displayed a constitutive\npreference to the parent-exposed stimuli irrespective of whether they were\nassociated with aversive or appetitive training. Moreover, the degree to which\nthe offspring preferred the conditioned stimuli markedly varied from\nodor-to-odor. These findings suggest that heightened sensitivities to certain\nsalient stimuli in the environment, but not their associated conditioned\nbehaviors, may be transmittable from parents to offspring. Such\ntrans-generational adaptations may influence animal traits over short\nevolutionary time-scales.\n", "versions": [{"version": "v1", "created": "Fri, 27 Dec 2013 20:22:23 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Williams", "Ziv M", ""]]}, {"id": "1312.7470", "submitter": "Andrey Shilnikov L", "authors": "Jeremy Wojcik, Robert Clewley, Justus Schwabedal and Andrey L.\n  Shilnikov", "title": "Key bifurcations of bursting polyrhythms in 3-cell central pattern\n  generators", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0092918", "report-no": null, "categories": "nlin.CD math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify and describe the key qualitative rhythmic states in various\n3-cell network motifs of a multifunctional central pattern generator (CPG).\nSuch CPGs are neural microcircuits of cells whose synergetic interactions\nproduce multiple states with distinct phase-locked patterns of bursting\nactivity. To study biologically plausible CPG models, we develop a suite of\ncomputational tools that reduce the problem of stability and existence of\nrhythmic patterns in networks to the bifurcation analysis of fixed points and\ninvariant curves of a Poincar\\'e return maps for phase lags between cells.\n  We explore different functional possibilities for motifs involving symmetry\nbreaking and heterogeneity. This is achieved by varying coupling properties of\nthe synapses between the cells and studying the qualitative changes in the\nstructure of the corresponding return maps. Our findings provide a systematic\nbasis for understanding plausible biophysical mechanisms for the regulation of\nrhythmic patterns generated by various CPGs in the context of motor control\nsuch as gait-switching in locomotion. Our analysis does not require knowledge\nof the equations modeling the system and provides a powerful qualitative\napproach to studying detailed models of rhythmic behavior. Thus, our approach\nis applicable to a wide range of biological phenomena beyond motor control.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2013 20:15:32 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Wojcik", "Jeremy", ""], ["Clewley", "Robert", ""], ["Schwabedal", "Justus", ""], ["Shilnikov", "Andrey L.", ""]]}, {"id": "1312.7735", "submitter": "Jens Christian Claussen", "authors": "Arne Weigenand, Thomas Martinetz and Jens Christian Claussen", "title": "The phase response of the cortical slow oscillation", "comments": null, "journal-ref": "Cognitive Neurodynamics 6(4), 367-375 (2012)", "doi": "10.1007/s11571-012-9207-z", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical slow oscillations occur in the mammalian brain during deep sleep and\nhave been shown to contribute to memory consolidation, an effect that can be\nenhanced by electrical stimulation. As the precise underlying working\nmechanisms are not known it is desired to develop and analyze computational\nmodels of slow oscillations and to study the response to electrical stimuli. In\nthis paper we employ the conductance based model of Compte et al. [J\nNeurophysiol 89, 2707] to study the effect of electrical stimulation. The\npopulation response to electrical stimulation depends on the timing of the\nstimulus with respect to the state of the slow oscillation. First, we reproduce\nthe experimental results of electrical stimulation in ferret brain slices by\nShu et al. [Nature 423, 288] from the conductance based model. We then\nnumerically obtain the phase response curve for the conductance based network\nmodel to quantify the network's response to weak stimuli. Our results agree\nwith experiments in vivo and in vitro that show that sensitivity to stimulation\nis weaker in the up than in the down state. However, we also find that within\nthe up state stimulation leads to a shortening of the up state, or phase\nadvance, whereas during the up-down transition a prolongation of up states is\npossible, resulting in a phase delay. Finally, we compute the phase response\ncurve for the simple mean-field model by Ngo et al. [Europhys Lett 89, 68002]\nand find that the qualitative shape of the PRC is preserved, despite its\ndifferent mechanism for the generation of slow oscillations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 15:15:28 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Weigenand", "Arne", ""], ["Martinetz", "Thomas", ""], ["Claussen", "Jens Christian", ""]]}, {"id": "1312.7761", "submitter": "Jens Christian Claussen", "authors": "Felix Njap, Jens Christian Claussen, Andreas Moser, and Ulrich G.\n  Hofmann", "title": "Modeling effect of GABAergic current in a basal ganglia computational\n  model", "comments": null, "journal-ref": "Cogn. Neurodyn. 6(4), 333-341 (2012)", "doi": "10.1007/s11571-012-9203-3", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrical high frequency stimulation (HFS) of deep brain regions is a method\nshown to be clinically effective in different types of movement and\nneurological disorders. In order to shed light on its mode of action a\ncomputational model of the basal ganglia network coupled the HFS as injection\ncurrent into the cells of the subthalamic nucleus (STN). Its overall increased\nactivity rendered a faithful transmission of sensorimotor input through\nthalamo-cortical relay cells possible. Our contribution uses this model by\nRubin and Terman (J Comput Neurosci, 16, 211-223, 2004) as a starting point and\nintegrates recent findings on the importance of the extracellular\nconcentrations of the inhibiting neurotransmitter GABA. We are able to show in\nthis computational study that besides electrical stimulation a high\nconcentration of GABA and its resulting conductivity in STN cells is able to\nre-establish faithful thalamocortical relaying, which otherwise broke down in\nthe simulated parkinsonian state.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 16:17:07 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Njap", "Felix", ""], ["Claussen", "Jens Christian", ""], ["Moser", "Andreas", ""], ["Hofmann", "Ulrich G.", ""]]}, {"id": "1312.7774", "submitter": "Tengiz Zorikov", "authors": "Tengiz Zorikov", "title": "Echo-processing mechanisms in bottlenose dolphins", "comments": "10 pg. 8 fig", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mechanisms of echo-processing were investigated in our experiments,\nconducted on bottlenose dolphins. Hierarchically organized system of\nindependent dimensions, describing echoes in animals perception, was revealed.\nThe rules of discrimination and recognition of echoes in dolphins were\nestablished.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 16:47:08 GMT"}], "update_date": "2014-01-02", "authors_parsed": [["Zorikov", "Tengiz", ""]]}, {"id": "1312.7861", "submitter": "Jens Christian Claussen", "authors": "Jens Christian Claussen and Ulrich G. Hofmann", "title": "Sleep, Neuroengineering and Dynamics", "comments": null, "journal-ref": "Cognitive Neurodynamics 6 (3), 211-214 (2012)", "doi": "10.1007/s11571-012-9204-2", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling of consciousness-related phenomena and neuroengineering are fields\nthat are rapidly growing together. We review recent approaches and developments\nand point out some promising directions of future research: Understanding the\ndynamics of consciousness states and associated oscillations, pathological\noscillations as well as their treatment by stimulation, neuroprosthetics and\nbrain-computer-interface approaches, and stimulation approaches that probe,\ninfluence and strengthen memory consolidation. In all these fields,\ncomputational models connect theory, neurophysiology and neuroengineering\nresearch and pave a way towards medical applications.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 20:44:24 GMT"}], "update_date": "2013-12-31", "authors_parsed": [["Claussen", "Jens Christian", ""], ["Hofmann", "Ulrich G.", ""]]}]