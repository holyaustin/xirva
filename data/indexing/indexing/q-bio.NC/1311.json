[{"id": "1311.0164", "submitter": "Irene Sendi\\~na-Nadal", "authors": "Daniel de Santos-Sierra, Irene Sendi\\~na-Nadal, Inmaculada Leyva, Juan\n  A. Almendral, Sarit Anava, Amir Ayali, David Papo, Stefano Boccaletti", "title": "Emergence of small-world anatomical networks in self-organizing\n  clustered neuronal cultures", "comments": "13 pages, 8 figures", "journal-ref": "PLoS ONE 9(1): e85828 (2014)", "doi": "10.1371/journal.pone.0085828", "report-no": null, "categories": "nlin.AO physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vitro primary cultures of dissociated invertebrate neurons from locust\nganglia are used to experimentally investigate the morphological evolution of\nassemblies of living neurons, as they self-organize from collections of\nseparated cells into elaborated, clustered, networks. At all the different\nstages of the culture's development, identification of neurons' and neurites'\nlocation by means of a dedicated software allows to ultimately extract an\nadjacency matrix from each image of the culture. In turn, a systematic\nstatistical analysis of a group of topological observables grants us the\npossibility of quantifying and tracking the progression of the main network's\ncharacteristics during the self-organization process of the culture. Our\nresults point to the existence of a particular state corresponding to a\nsmall-world network configuration, in which several relevant graph's micro- and\nmeso-scale properties emerge. Finally, we identify the main physical processes\nruling the culture's morphological transformations, and embed them into a\nsimplified growth model qualitatively reproducing the overall set of\nexperimental observations.\n", "versions": [{"version": "v1", "created": "Fri, 1 Nov 2013 12:25:07 GMT"}], "update_date": "2014-02-14", "authors_parsed": [["de Santos-Sierra", "Daniel", ""], ["Sendi\u00f1a-Nadal", "Irene", ""], ["Leyva", "Inmaculada", ""], ["Almendral", "Juan A.", ""], ["Anava", "Sarit", ""], ["Ayali", "Amir", ""], ["Papo", "David", ""], ["Boccaletti", "Stefano", ""]]}, {"id": "1311.0607", "submitter": "Wiktor Mlynarski", "authors": "Wiktor Mlynarski", "title": "Efficient coding of spectrotemporal binaural sounds leads to emergence\n  of the auditory space representation", "comments": "22 pages, 9 figures", "journal-ref": null, "doi": "10.3389/fncom.2014.00026", "report-no": null, "categories": "q-bio.NC cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date a number of studies have shown that receptive field shapes of early\nsensory neurons can be reproduced by optimizing coding efficiency of natural\nstimulus ensembles. A still unresolved question is whether the efficient coding\nhypothesis explains formation of neurons which explicitly represent\nenvironmental features of different functional importance. This paper proposes\nthat the spatial selectivity of higher auditory neurons emerges as a direct\nconsequence of learning efficient codes for natural binaural sounds. Firstly,\nit is demonstrated that a linear efficient coding transform - Independent\nComponent Analysis (ICA) trained on spectrograms of naturalistic simulated\nbinaural sounds extracts spatial information present in the signal. A simple\nhierarchical ICA extension allowing for decoding of sound position is proposed.\nFurthermore, it is shown that units revealing spatial selectivity can be\nlearned from a binaural recording of a natural auditory scene. In both cases a\nrelatively small subpopulation of learned spectrogram features suffices to\nperform accurate sound localization. Representation of the auditory space is\ntherefore learned in a purely unsupervised way by maximizing the coding\nefficiency and without any task-specific constraints. This results imply that\nefficient coding is a useful strategy for learning structures which allow for\nmaking behaviorally vital inferences about the environment.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 08:51:14 GMT"}, {"version": "v2", "created": "Wed, 19 Feb 2014 12:31:44 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Mlynarski", "Wiktor", ""]]}, {"id": "1311.0753", "submitter": "Carsten Allefeld", "authors": "Carsten Allefeld, Chun Siong Soon, Carsten Bogler, Jakob Heinzle,\n  John-Dylan Haynes", "title": "Sequential dependencies between trials in free choice tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In two previous experiments we investigated the neural precursors of\nsubjects' \"free\" choices for one of two options (pressing one of two buttons,\nand choosing between adding and subtracting numbers). In these experiments the\ndistribution of sequence lengths was taken as an approximate indicator of the\nrandomness (or lack of sequential dependency) of the choice sequences. However,\nthis method is limited in its ability to reveal sequential dependencies. Here\nwe present a more detailed individual-subject analysis and conclude that\ndespite of the presence of significant sequential dependencies the subjects'\nbehavior still approximates randomness, as measured by an entropy rate (on\npooled data) of 0.940 bit / trial and 0.965 bit / trial in the two experiments.\nWe also provide the raw single-subject behavioral data.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 16:24:27 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Allefeld", "Carsten", ""], ["Soon", "Chun Siong", ""], ["Bogler", "Carsten", ""], ["Heinzle", "Jakob", ""], ["Haynes", "John-Dylan", ""]]}, {"id": "1311.0778", "submitter": "Urs K\\\"oster", "authors": "Urs K\\\"oster, Bruno Olshausen", "title": "Testing our conceptual understanding of V1 function", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we test our conceptual understanding of V1 function by asking two\nexperimental questions: 1) How do neurons respond to the spatiotemporal\nstructure contained in dynamic, natural scenes? and 2) What is the true range\nof visual responsiveness and predictability of neural responses obtained in an\nunbiased sample of neurons across all layers of cortex? We address these\nquestions by recording responses to natural movie stimuli with 32 channel\nsilicon probes. By simultaneously recording from cells in all layers, and\ntaking all recorded cells, we reduce recording bias that results from \"hunting\"\nfor neural responses evoked from drifting bars and gratings. A nonparametric\nmodel reveals that many cells that are visually responsive do not appear to be\ncaptured by standard receptive field models. Using nonlinear Radial Basis\nFunction kernels in a support vector machine, we can explain the responses of\nsome of these cells better than standard linear and phase-invariant complex\ncell models. This suggests that V1 neurons exhibit more complex and diverse\nresponses than standard models can capture, ranging from simple and complex\ncells strongly driven by their classical receptive fields, to cells with more\nnonlinear receptive fields inferred from the nonparametric and RFB model, and\ncells that are not visually responsive despite robust firing.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 17:25:54 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["K\u00f6ster", "Urs", ""], ["Olshausen", "Bruno", ""]]}, {"id": "1311.0966", "submitter": "Emre Neftci", "authors": "Emre Neftci, Srinjoy Das, Bruno Pedroni, Kenneth Kreutz-Delgado, and\n  Gert Cauwenberghs", "title": "Event-Driven Contrastive Divergence for Spiking Neuromorphic Systems", "comments": "(Under review)", "journal-ref": null, "doi": "10.3389/fnins.2013.00272", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted Boltzmann Machines (RBMs) and Deep Belief Networks have been\ndemonstrated to perform efficiently in a variety of applications, such as\ndimensionality reduction, feature learning, and classification. Their\nimplementation on neuromorphic hardware platforms emulating large-scale\nnetworks of spiking neurons can have significant advantages from the\nperspectives of scalability, power dissipation and real-time interfacing with\nthe environment. However the traditional RBM architecture and the commonly used\ntraining algorithm known as Contrastive Divergence (CD) are based on discrete\nupdates and exact arithmetics which do not directly map onto a dynamical neural\nsubstrate. Here, we present an event-driven variation of CD to train a RBM\nconstructed with Integrate & Fire (I&F) neurons, that is constrained by the\nlimitations of existing and near future neuromorphic hardware platforms. Our\nstrategy is based on neural sampling, which allows us to synthesize a spiking\nneural network that samples from a target Boltzmann distribution. The recurrent\nactivity of the network replaces the discrete steps of the CD algorithm, while\nSpike Time Dependent Plasticity (STDP) carries out the weight updates in an\nonline, asynchronous fashion. We demonstrate our approach by training an RBM\ncomposed of leaky I&F neurons with STDP synapses to learn a generative model of\nthe MNIST hand-written digit dataset, and by testing it in recognition,\ngeneration and cue integration tasks. Our results contribute to a machine\nlearning-driven approach for synthesizing networks of spiking neurons capable\nof carrying out practical, high-level functionality.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 04:53:11 GMT"}, {"version": "v2", "created": "Wed, 6 Nov 2013 19:45:07 GMT"}, {"version": "v3", "created": "Mon, 9 Dec 2013 07:04:28 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Neftci", "Emre", ""], ["Das", "Srinjoy", ""], ["Pedroni", "Bruno", ""], ["Kreutz-Delgado", "Kenneth", ""], ["Cauwenberghs", "Gert", ""]]}, {"id": "1311.1294", "submitter": "Shaista Hussain", "authors": "Shaista Hussain, Arindam Basu, R. Wang and Tara Julia Hamilton", "title": "Delay Learning Architectures for Memory and Classification", "comments": "27 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a neuromorphic spiking neural network, the DELTRON, that can\nremember and store patterns by changing the delays of every connection as\nopposed to modifying the weights. The advantage of this architecture over\ntraditional weight based ones is simpler hardware implementation without\nmultipliers or digital-analog converters (DACs) as well as being suited to\ntime-based computing. The name is derived due to similarity in the learning\nrule with an earlier architecture called Tempotron. The DELTRON can remember\nmore patterns than other delay-based networks by modifying a few delays to\nremember the most 'salient' or synchronous part of every spike pattern. We\npresent simulations of memory capacity and classification ability of the\nDELTRON for different random spatio-temporal spike patterns. The memory\ncapacity for noisy spike patterns and missing spikes are also shown. Finally,\nwe present SPICE simulation results of the core circuits involved in a\nreconfigurable mixed signal implementation of this architecture.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2013 06:10:30 GMT"}, {"version": "v2", "created": "Thu, 27 Feb 2014 07:26:37 GMT"}], "update_date": "2014-02-28", "authors_parsed": [["Hussain", "Shaista", ""], ["Basu", "Arindam", ""], ["Wang", "R.", ""], ["Hamilton", "Tara Julia", ""]]}, {"id": "1311.1345", "submitter": "Marc-Oliver Gewaltig", "authors": "Marc-Oliver Gewaltig", "title": "Self-sustained activity, bursts, and variability in recurrent networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is consensus in the current literature that stable states of\nasynchronous irregular spiking activity require (i) large networks of 10 000 or\nmore neurons and (ii) external background activity or pacemaker neurons. Yet\nalready in 1963, Griffith showed that networks of simple threshold elements can\nbe persistently active at intermediate rates. Here, we extend Griffith's work\nand demonstrate that sparse networks of integrate-and-fire neurons assume\nstable states of self-sustained asynchronous and irregular firing without\nexternal input or pacemaker neurons. These states can be robustly induced by a\nbrief pulse to a small fraction of the neurons, or by short a period of\nirregular input, and last for several minutes. Self-sustained activity states\nemerge when a small fraction of the synapses is strong enough to significantly\ninfluence the firing probability of a neuron, consistent with the recently\nproposed long-tailed distribution of synaptic weights. During self-sustained\nactivity, each neuron exhibits highly irregular firing patterns, similar to\nexperimentally observed activity. Moreover, the interspike interval\ndistribution reveals that neurons switch between discrete states of high and\nlow firing rates. We find that self-sustained activity states can exist even in\nsmall networks of only a thousand neurons. We investigated networks up to 100\n000 neurons. Finally, we discuss the implications of self-sustained activity\nfor learning, memory and signal propagation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2013 10:58:04 GMT"}], "update_date": "2013-11-07", "authors_parsed": [["Gewaltig", "Marc-Oliver", ""]]}, {"id": "1311.1734", "submitter": "Anne Skeldon", "authors": "Anne C. Skeldon, Derk-Jan Dijk and Gianne Derks", "title": "Mathematical models for sleep-wake dynamics: comparison of the\n  two-process model and a mutual inhibition neuronal model", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0103877", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep is essential for the maintenance of the brain and the body, yet many\nfeatures of sleep are poorly understood and mathematical models are an\nimportant tool for probing proposed biological mechanisms. The most well-known\nmathematical model of sleep regulation, the two-process model, models the\nsleep-wake cycle by two oscillators: a circadian oscillator and a homeostatic\noscillator. An alternative, more recent, model considers the mutual inhibition\nof sleep promoting neurons and the ascending arousal system regulated by\nhomeostatic and circadian processes. Here we show there are fundamental\nsimilarities between these two models. The implications are illustrated with\ntwo important sleep-wake phenomena. Firstly, we show that in the two-process\nmodel, transitions between different numbers of daily sleep episodes occur at\ngrazing bifurcations.This provides the theoretical underpinning for numerical\nresults showing that the sleep patterns of many mammals can be explained by the\nmutual inhibition model. Secondly, we show that when sleep deprivation disrupts\nthe sleep-wake cycle, ostensibly different measures of sleepiness in the two\nmodels are closely related. The demonstration of the mathematical similarities\nof the two models is valuable because not only does it allow some features of\nthe two-process model to be interpreted physiologically but it also means that\nknowledge gained from study of the two-process model can be used to inform\nunderstanding of the mutual inhibition model. This is important because the\nmutual inhibition model and its extensions are increasingly being used as a\ntool to understand a diverse range of sleep-wake phenomena such as the design\nof optimal shift-patterns, yet the values it uses for parameters associated\nwith the circadian and homeostatic processes are very different from those that\nhave been experimentally measured in the context of the two-process model.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 16:36:57 GMT"}, {"version": "v2", "created": "Tue, 11 Mar 2014 14:42:36 GMT"}, {"version": "v3", "created": "Mon, 14 Jul 2014 09:15:46 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Skeldon", "Anne C.", ""], ["Dijk", "Derk-Jan", ""], ["Derks", "Gianne", ""]]}, {"id": "1311.1743", "submitter": "Claudius Gros", "authors": "Guillermo A. Luduena, M. Djalali Behzad, Claudius Gros", "title": "Exploration in Free Word Association Networks: Models and Experiment", "comments": "Cognitive Processing, in press", "journal-ref": "Cognitive Processing 15, 195 (2014)", "doi": null, "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Free association is a task that requires a subject to express the first word\nto come to their mind when presented with a certain cue. It is a task which can\nbe used to expose the basic mechanisms by which humans connect memories. In\nthis work we have made use of a publicly available database of free\nassociations to model the exploration of the averaged network of associations\nusing a statistical and the \\emph{ACT-R} model. We performed, in addition, an\nonline experiment asking participants to navigate the averaged network using\ntheir individual preferences for word associations. We have investigated the\nstatistics of word repetitions in this guided association task. We find that\nthe considered models mimic some of the statistical properties, viz the\nprobability of word repetitions, the distance between repetitions and the\ndistribution of association chain lengths, of the experiment, with the\n\\emph{ACT-R} model showing a particularly good fit to the experimental data for\nthe more intricate properties as, for instance, the ratio of repetitions per\nlength of association chains.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 17:02:32 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Luduena", "Guillermo A.", ""], ["Behzad", "M. Djalali", ""], ["Gros", "Claudius", ""]]}, {"id": "1311.1919", "submitter": "Judith Lehnert", "authors": "Caglar Cakan, Judith Lehnert, Eckehard Sch\\\"oll", "title": "Heterogeneous Delays in Neural Networks", "comments": null, "journal-ref": "Eur. Phys. J. B 87, 54 (2014)", "doi": "10.1140/epjb/e2014-40985-7", "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate heterogeneous coupling delays in complex networks of excitable\nelements described by the FitzHugh-Nagumo model. The effects of discrete as\nwell as of uni- and bimodal continuous distributions are studied with a focus\non different topologies, i.e., regular, small-world, and random networks. In\nthe case of two discrete delay times resonance effects play a major role:\nDepending on the ratio of the delay times, various characteristic spiking\nscenarios, such as coherent or asynchronous spiking, arise. For continuous\ndelay distributions different dynamical patterns emerge depending on the width\nof the distribution. For small distribution widths, we find highly synchronized\nspiking, while for intermediate widths only spiking with low degree of\nsynchrony persists, which is associated with traveling disruptions, partial\namplitude death, or subnetwork synchronization, depending sensitively on the\nnetwork topology. If the inhomogeneity of the coupling delays becomes too\nlarge, global amplitude death is induced.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 10:06:19 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2014 08:36:14 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Cakan", "Caglar", ""], ["Lehnert", "Judith", ""], ["Sch\u00f6ll", "Eckehard", ""]]}, {"id": "1311.2013", "submitter": "Vivek Kandiah", "authors": "Vivek Kandiah and Dima L. Shepelyansky", "title": "Google matrix analysis of C.elegans neural network", "comments": "Additional information on the webpage\n  http://www.quantware.ups-tlse.fr/QWLIB/wormgooglematrix/index.html", "journal-ref": null, "doi": "10.1016/j.physleta.2014.04.045", "report-no": "PLA22574", "categories": "physics.soc-ph cs.SI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the structural properties of the neural network of the C.elegans\n(worm) from a directed graph point of view. The Google matrix analysis is used\nto characterize the neuron connectivity structure and node classifications are\ndiscussed and compared with physiological properties of the cells. Our results\nare obtained by a proper definition of neural directed network and subsequent\neigenvector analysis which recovers some results of previous studies. Our\nanalysis highlights particular sets of important neurons constituting the core\nof the neural system. The applications of PageRank, CheiRank and ImpactRank to\ncharacterization of interdependency of neurons are discussed.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 16:14:14 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Kandiah", "Vivek", ""], ["Shepelyansky", "Dima L.", ""]]}, {"id": "1311.2200", "submitter": "Guillaume Drion", "authors": "Guillaume Drion, Alessio Franci, Vincent Seutin and Rodolphe Sepulchre", "title": "Modulation and Robustness of Endogenous Neuronal Spiking", "comments": "18 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal spiking exhibits an exquisite combination of modulation and\nrobustness properties, rarely matched in artificial systems. We exploit the\nparticular interconnection structure of conductance based models to investigate\nthis remarkable property. We find that much of neuronal modulation and\nrobustness can be explained by separating the total transmembrane current into\nthree different components corresponding to the three time scales of neuronal\nbursting. Each equivalent current aggregates many ionic contributions into an\nequivalent voltage-dependent conductance, which defines a key modulation\nparameter. Plugging those equivalent feedback gains in a minimal abstract model\nrecovers many experimental modulation scenarii as modulatory paths in\nelementary two-parameter charts. Likewise, robustness owes to the many possible\nphysiological realizations of a same equivalent conductance, highlighting the\nrole of equivalent conductances as prominent targets for neuromodulation and\nintrinsic homeostasis.\n", "versions": [{"version": "v1", "created": "Sat, 9 Nov 2013 18:50:36 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Drion", "Guillaume", ""], ["Franci", "Alessio", ""], ["Seutin", "Vincent", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "1311.2238", "submitter": "Julie Dethier", "authors": "Julie Dethier, Guillaume Drion, Alessio Franci, Rodolphe Sepulchre", "title": "Modulation of beta oscillations during movement initiation: modeling the\n  ionic basis of a functional switch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use a computational model to propose a physiological mechanism by which\ntransient control of beta oscillations in the indirect pathway of the basal\nganglia is orchestrated at the cellular level. Our model includes a simple and\nrobust mechanism by which a cellular switch (from bursting to tonic) almost\ninstantaneously translates into a functional gating switch (from blocking to\nconducive) in an excitatory-inhibitory network. Applied to the control of beta\noscillations in the basal ganglia, the model shows the modulation of beta\nactivity under the action of a transient depolarization, for instance a\ndopamine signal. The model predicts, by analogy to the thalamocortical circuit,\na novel gating function by which the transfer of cortical spikes through the\nindirect pathway is blocked under the inhibitory drive preceding movement but\nbriefly released at the onset of movement execution.\n", "versions": [{"version": "v1", "created": "Sun, 10 Nov 2013 01:36:51 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Dethier", "Julie", ""], ["Drion", "Guillaume", ""], ["Franci", "Alessio", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "1311.2607", "submitter": "Zachary Kilpatrick PhD", "authors": "Zachary P. Kilpatrick", "title": "Coupling layers regularizes wave propagation in laminar stochastic\n  neural fields", "comments": "14 pages, 11 figures", "journal-ref": null, "doi": "10.1103/PhysRevE.89.022706", "report-no": null, "categories": "nlin.PS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effects of coupling between layers of stochastic neural field\nmodels with laminar structure. In particular, we focus on how the propagation\nof waves of neural activity in each layer is affected by the coupling. Synaptic\nconnectivities within and between each layer are determined by integral kernels\nof an integrodifferential equation describing the temporal evolution of neural\nactivity. Excitatory neural fields, with purely positive connectivities,\nsupport traveling fronts in each layer, whose speeds are increased when\ncoupling between layers is considered. Studying the effects of noise, we find\ncoupling also serves to reduce the variance in the position of traveling\nfronts, as long as the noise sources to each layer are not completely\ncorrelated. Neural fields with asymmetric connectivity support traveling pulses\nwhose speeds are decreased by interlaminar coupling. Again, coupling reduces\nthe variance in traveling pulse position, when noise is considered that is not\ntotally correlated between layers. To derive our stochastic results, we employ\na small-noise expansion, also assuming interlaminar connectivity scales\nsimilarly. Our asymptotic results agree reasonably with accompanying numerical\nsimulations.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 21:12:22 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Kilpatrick", "Zachary P.", ""]]}, {"id": "1311.2643", "submitter": "Mark McDonnell", "authors": "Brett A. Schmerl and Mark D. McDonnell", "title": "Channel noise induced stochastic facilitation in an auditory brainstem\n  neuron model", "comments": "Published by Physical Review E, November 2013 (this version 17 pages\n  total - 10 text, 1 refs, 6 figures/tables); Associated matlab code is\n  available online in the ModelDB repository at\n  http://senselab.med.yale.edu/ModelDB/ShowModel.asp?model=151483", "journal-ref": "Physical Review E, 88: 052722, 2013", "doi": "10.1103/PhysRevE.88.052722", "report-no": null, "categories": "q-bio.NC q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuronal membrane potentials fluctuate stochastically due to conductance\nchanges caused by random transitions between the open and close states of ion\nchannels. Although it has previously been shown that channel noise can\nnontrivially affect neuronal dynamics, it is unknown whether ion-channel noise\nis strong enough to act as a noise source for hypothesised noise-enhanced\ninformation processing in real neuronal systems, i.e. 'stochastic\nfacilitation.' Here, we demonstrate that biophysical models of channel noise\ncan give rise to two kinds of recently discovered stochastic facilitation\neffects in a Hodgkin-Huxley-like model of auditory brainstem neurons. The\nfirst, known as slope-based stochastic resonance (SBSR), enables phasic neurons\nto emit action potentials that can encode the slope of inputs that vary slowly\nrelative to key time-constants in the model. The second, known as inverse\nstochastic resonance (ISR), occurs in tonically firing neurons when small\nlevels of noise inhibit tonic firing and replace it with burst-like dynamics.\nConsistent with previous work, we conclude that channel noise can provide\nsignificant variability in firing dynamics, even for large numbers of channels.\nMoreover, our results show that possible associated computational benefits may\noccur due to channel noise in neurons of the auditory brainstem. This holds\nwhether the firing dynamics in the model are phasic (SBSR can occur due to\nchannel noise) or tonic (ISR can occur due to channel noise).\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 23:00:00 GMT"}, {"version": "v2", "created": "Thu, 5 Dec 2013 11:40:54 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Schmerl", "Brett A.", ""], ["McDonnell", "Mark D.", ""]]}, {"id": "1311.2731", "submitter": "Alessandro Torcini Dr", "authors": "Simona Olmi, Antonio Politi, Alessandro Torcini", "title": "Linear stability in networks of pulse-coupled neurons", "comments": "13 pages, 7 figures, submitted to Frontiers in Computational\n  Neuroscience", "journal-ref": "Front. Comput. Neurosci. 8:8 (2014)", "doi": "10.3389/fncom.2014.00008", "report-no": null, "categories": "cond-mat.dis-nn physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a first step towards the comprehension of neural activity, one should\nfocus on the stability of the various dynamical states. Even the\ncharacterization of idealized regimes, such as a perfectly periodic spiking\nactivity, reveals unexpected difficulties. In this paper we discuss a general\napproach to linear stability of pulse-coupled neural networks for generic\nphase-response curves and post-synaptic response functions. In particular, we\npresent: (i) a mean-field approach developed under the hypothesis of an\ninfinite network and small synaptic conductances; (ii) a \"microscopic\" approach\nwhich applies to finite but large networks. As a result, we find that no matter\nhow large is a neural network, its response to most of the perturbations\ndepends on the system size. There exists, however, also a second class of\nperturbations, whose evolution typically covers an increasingly wide range of\ntime scales. The analysis of perfectly regular, asynchronous, states reveals\nthat their stability depends crucially on the smoothness of both the\nphase-response curve and the transmitted post-synaptic pulse. The general\nvalidity of this scenarion is confirmed by numerical simulations of systems\nthat are not amenable to a perturbative approach.\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 11:02:10 GMT"}], "update_date": "2014-09-08", "authors_parsed": [["Olmi", "Simona", ""], ["Politi", "Antonio", ""], ["Torcini", "Alessandro", ""]]}, {"id": "1311.2961", "submitter": "Donald Forsdyke Dr.", "authors": "Donald R. Forsdyke", "title": "Long-Term Memory: Scaling of Information to Brain Size", "comments": "10 pages, 1 figure; submitted to Biological Theory 20th Feb 2013; a\n  requested revision was submitted 28th July 2013", "journal-ref": "Frontiers in Human Neuroscience (2014) 8, 397", "doi": "10.3389/fnhum.2014.00397", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The material bases of information - paper, computer discs - usually scale\nwith information quantity. Large quantities of information usually require\nlarge material bases. Conventional wisdom has it that human long-term memory\nlocates within brain tissue, and so might be expected to scale with brain size\nwhich, in turn, depends on cranial capacity. Large memories, as in savants,\nshould always require large heads. Small heads should always scale with small\nmemories. While it was previously concluded that neither of these predictions\nwas invariably true, the evidence was weak. Brain size also depends on\nventricle size, which can remain large in some survivors of childhood\nhydrocephaly, occupying 95% of cranial volume. Yet some of these have normal or\nadvanced intelligence, indicating little impairment of long-term memory. This\nparadox challenges the scaling hypothesis. Perhaps we should be looking further\nafield?\n", "versions": [{"version": "v1", "created": "Tue, 12 Nov 2013 21:36:17 GMT"}], "update_date": "2014-06-05", "authors_parsed": [["Forsdyke", "Donald R.", ""]]}, {"id": "1311.3129", "submitter": "Romain Brette", "authors": "Romain Brette", "title": "Subjective physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagine a naive organism who does not know anything about the world. It can\ncapture signals through its sensors and it can make actions. What kind of\nknowledge about the world is accessible to the organism? This situation is\nanalog to that of a physicist trying to understand the world through\nobservations and experiments. In the same way as physics describes the laws of\nthe world obtained in this way by the scientist, I propose to name subjective\nphysics the description of the laws that govern sensory signals and their\nrelationships with actions, as observed from the perspective of the perceptual\nsystem of the organism. In this text, I present the main concepts of subjective\nphysics, illustrated with concrete examples.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 13:48:21 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["Brette", "Romain", ""]]}, {"id": "1311.3211", "submitter": "Mihai Alexandru Petrovici", "authors": "Mihai A. Petrovici, Johannes Bill, Ilja Bytschok, Johannes Schemmel,\n  Karlheinz Meier", "title": "Stochastic inference with deterministic spiking neurons", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.NE physics.bio-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The seemingly stochastic transient dynamics of neocortical circuits observed\nin vivo have been hypothesized to represent a signature of ongoing stochastic\ninference. In vitro neurons, on the other hand, exhibit a highly deterministic\nresponse to various types of stimulation. We show that an ensemble of\ndeterministic leaky integrate-and-fire neurons embedded in a spiking noisy\nenvironment can attain the correct firing statistics in order to sample from a\nwell-defined target distribution. We provide an analytical derivation of the\nactivation function on the single cell level; for recurrent networks, we\nexamine convergence towards stationarity in computer simulations and\ndemonstrate sample-based Bayesian inference in a mixed graphical model. This\nestablishes a rigorous link between deterministic neuron models and functional\nstochastic dynamics on the network level.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 17:04:41 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Petrovici", "Mihai A.", ""], ["Bill", "Johannes", ""], ["Bytschok", "Ilja", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""]]}, {"id": "1311.3586", "submitter": "Richard Naud", "authors": "Richard Naud and Brice Bathellier and Wulfram Gerstner", "title": "Spike timing prediction with active dendrites", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A complete single-neuron model must correctly reproduce the firing of spikes\nand bursts. We present a study of a simplified model of deep pyramidal cells of\nthe cortex with active dendrites. We hypothesized that we can model the soma\nand its apical tuft with only two compartments, without significant loss in the\naccuracy of spike-timing predictions. The model is based on experimentally\nmeasurable impulse-response functions, which transfer the effect of current\ninjected in one compartment to current reaching the other. Each compartment was\nmodeled with a pair of non-linear differential equations and a small number of\nparameters that approximate the Hodgkin-and-Huxley equations. The predictive\npower of this model was tested on electrophysiological experiments where noisy\ncurrent was injected in both the soma and the apical dendrite simultaneously.\nWe conclude that a simple two-compartment model can predict spike times of\npyramidal cells stimulated in the soma and dendrites simultaneously. Our\nresults support that regenerating activity in the dendritic tuft is required to\nproperly account for the dynamics of layer 5 pyramidal cells under in-vivo-like\nconditions.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 17:28:21 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2013 03:20:41 GMT"}], "update_date": "2013-12-04", "authors_parsed": [["Naud", "Richard", ""], ["Bathellier", "Brice", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1311.3859", "submitter": "Yannick Schwartz", "authors": "Yannick Schwartz (INRIA Saclay - Ile de France, NEUROSPIN), Bertrand\n  Thirion (INRIA Saclay - Ile de France, NEUROSPIN), Ga\\\"el Varoquaux (INRIA\n  Saclay - Ile de France, LNAO)", "title": "Mapping cognitive ontologies to and from the brain", "comments": "NIPS (Neural Information Processing Systems), United States (2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging neuroscience links brain activation maps to behavior and cognition\nvia correlational studies. Due to the nature of the individual experiments,\nbased on eliciting neural response from a small number of stimuli, this link is\nincomplete, and unidirectional from the causal point of view. To come to\nconclusions on the function implied by the activation of brain regions, it is\nnecessary to combine a wide exploration of the various brain functions and some\ninversion of the statistical inference. Here we introduce a methodology for\naccumulating knowledge towards a bidirectional link between observed brain\nactivity and the corresponding function. We rely on a large corpus of imaging\nstudies and a predictive engine. Technically, the challenges are to find\ncommonality between the studies without denaturing the richness of the corpus.\nThe key elements that we contribute are labeling the tasks performed with a\ncognitive ontology, and modeling the long tail of rare paradigms in the corpus.\nTo our knowledge, our approach is the first demonstration of predicting the\ncognitive content of completely new brain images. To that end, we propose a\nmethod that predicts the experimental paradigms across different studies.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 14:19:31 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2013 12:26:50 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Schwartz", "Yannick", "", "INRIA Saclay - Ile de France, NEUROSPIN"], ["Thirion", "Bertrand", "", "INRIA Saclay - Ile de France, NEUROSPIN"], ["Varoquaux", "Ga\u00ebl", "", "INRIA\n  Saclay - Ile de France, LNAO"]]}, {"id": "1311.3952", "submitter": "Agnieszka Szymanska", "authors": "Chang Won Lee, Agnieszka A. Szymanska, Shun Chi Wu, A. Lee\n  Swindlehurst, Zoran Nenadic", "title": "A Method for Neuronal Source Identification", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-sensor microelectrodes for extracellular action potential recording\nhave significantly improved the quality of in vivo recorded neuronal signals.\nThese microelectrodes have also been instrumental in the localization of\nneuronal signal sources. However, existing neuron localization methods have\nbeen mostly utilized in vivo, where the true neuron location remains unknown.\nTherefore, these methods could not be experimentally validated. This article\npresents experimental validation of a method capable of estimating both the\nlocation and intensity of an electrical signal source. A four-sensor\nmicroelectrode (tetrode) immersed in a saline solution was used to record\nstimulus patterns at multiple intensity levels generated by a stimulating\nelectrode. The location of the tetrode was varied with respect to the\nstimulator. The location and intensity of the stimulator were estimated using\nthe Multiple Signal Classification (MUSIC) algorithm, and the results were\nquantified by comparison to the true values. The localization results, with an\naccuracy and precision of ~ 10 microns, and ~ 11 microns respectively, imply\nthat MUSIC can resolve individual neuronal sources. Similarly, source intensity\nestimations indicate that this approach can track changes in signal amplitude\nover time. Together, these results suggest that MUSIC can be used to\ncharacterize neuronal signal sources in vivo.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 19:07:41 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Lee", "Chang Won", ""], ["Szymanska", "Agnieszka A.", ""], ["Wu", "Shun Chi", ""], ["Swindlehurst", "A. Lee", ""], ["Nenadic", "Zoran", ""]]}, {"id": "1311.4035", "submitter": "Yasuhiro Mochizuki", "authors": "Yasuhiro Mochizuk and Shigeru Shinomoto", "title": "Analog and digital codes in the brain", "comments": "10 pages, 7 figures", "journal-ref": "Physical Review E (2014) 89:022705", "doi": "10.1103/PhysRevE.89.022705", "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been debated whether information in the brain is coded at the\nrate of neuronal spiking or at the precise timing of single spikes. Although\nthis issue is essential to the understanding of neural signal processing, it is\nnot easily resolved because the two mechanisms are not mutually exclusive. We\nsuggest revising this coding issue so that one hypothesis is uniquely selected\nfor a given spike train. To this end, we decide whether the spike train is\nlikely to transmit a continuously varying analog signal or switching between\nactive and inactive states. The coding hypothesis is selected by comparing the\nlikelihood estimates yielded by empirical Bayes and hidden Markov models on\nindividual data. The analysis method is applicable to generic event sequences,\nsuch as earthquakes, machine noises, human communications, and enhances the\ngain in decoding signals and infers underlying activities.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2013 08:18:02 GMT"}], "update_date": "2014-02-17", "authors_parsed": [["Mochizuk", "Yasuhiro", ""], ["Shinomoto", "Shigeru", ""]]}, {"id": "1311.4206", "submitter": "Moritz Deger", "authors": "Moritz Deger, Tilo Schwalger, Richard Naud, Wulfram Gerstner", "title": "Fluctuations and information filtering in coupled populations of spiking\n  neurons with adaptation", "comments": null, "journal-ref": "Phys. Rev. E 90, 062704 (2014)", "doi": "10.1103/PhysRevE.90.062704", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finite-sized populations of spiking elements are fundamental to brain\nfunction, but also used in many areas of physics. Here we present a theory of\nthe dynamics of finite-sized populations of spiking units, based on a\nquasi-renewal description of neurons with adaptation. We derive an integral\nequation with colored noise that governs the stochastic dynamics of the\npopulation activity in response to time-dependent stimulation and calculate the\nspectral density in the asynchronous state. We show that systems of coupled\npopulations with adaptation can generate a frequency band in which sensory\ninformation is preferentially encoded. The theory is applicable to fully as\nwell as randomly connected networks, and to leaky integrate-and-fire as well as\nto generalized spiking neurons with adaptation on multiple time scales.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2013 19:27:41 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2015 13:52:23 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Deger", "Moritz", ""], ["Schwalger", "Tilo", ""], ["Naud", "Richard", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1311.4672", "submitter": "Yashar Ahmadian", "authors": "Yashar Ahmadian, Francesco Fumarola, Kenneth D. Miller", "title": "Properties of networks with partially structured and partially random\n  connectivity", "comments": "40 pages, 15 figures", "journal-ref": "Y. Ahmadian, F. Fumarola and K. D. Miller, Physical Review E, 91,\n  012820 (2015)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a general formula for the eigenvalue density of large random\n$N\\times N$ matrices of the form $A = M + LJR$, where $M$, $L$ and $R$ are\narbitrary deterministic matrices and $J$ is a random matrix of zero-mean\nindependent and identically distributed elements. For $A$ nonnormal, the\neigenvalues do not suffice to specify the dynamics induced by $A$, so we also\nprovide general formulae for the transient evolution of the magnitude of\nactivity and frequency power spectrum in an $N$-dimensional linear dynamical\nsystem with a coupling matrix given by $A$. These quantities can also be\nthought of as characterizing the stability and the magnitude of the linear\nresponse of a nonlinear network to small perturbations about a fixed point. We\nderive these formulae and work them out analytically for some examples of $M$,\n$L$ and $R$ motivated by neurobiological models. We also argue that the\npersistence as $N\\rightarrow\\infty$ of a finite number of randomly distributed\noutlying eigenvalues outside the support of the eigenvalue density of $A$, as\npreviously observed, arises in regions of the complex plane $\\Omega$ where\nthere are nonzero singular values of $L^{-1} (z\\mathbf{1} - M) R^{-1}$ (for\n$z\\in\\Omega$) that vanish as $N\\rightarrow\\infty$. When such singular values do\nnot exist and $L$ and $R$ are equal to the identity, there is a correspondence\nin the normalized Frobenius norm (but not in the operator norm) between the\nsupport of the spectrum of $A$ for $J$ of norm $\\sigma$ and the\n$\\sigma$-pseudospectrum of $M$.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 09:47:23 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2013 01:53:17 GMT"}, {"version": "v3", "created": "Thu, 15 May 2014 23:00:58 GMT"}, {"version": "v4", "created": "Thu, 13 Nov 2014 23:44:46 GMT"}, {"version": "v5", "created": "Wed, 14 Jan 2015 21:07:16 GMT"}, {"version": "v6", "created": "Mon, 26 Jan 2015 20:28:19 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Ahmadian", "Yashar", ""], ["Fumarola", "Francesco", ""], ["Miller", "Kenneth D.", ""]]}, {"id": "1311.4700", "submitter": "Johann Mart\\'inez", "authors": "J. H. Mart\\'inez, J. M. Pastor, P. Ariza, M. Zanin, D. Papo, F.\n  Maest\\'u, R. Bajo, S. Boccaletti, J. M. Buld\\'u", "title": "Anomalous Consistency in Mild Cognitive Impairment: a complex networks\n  approach", "comments": "13 pages, 6 figure, Extended version acepted to Chaos Solitons &\n  Fractals. Elsevier, the interdisciplinary journal of Nonlinear Science, and\n  Nonequilibrium and Complex Phenomena 2014", "journal-ref": null, "doi": "10.1016/j.chaos.2014.10.013", "report-no": null, "categories": "q-bio.NC nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased variability in performance has been associated with the emergence\nof several neurological and psychiatric pathologies. However, whether and how\nconsistency of neuronal activity may also be indicative of an underlying\npathology is still poorly understood. Here we propose a novel method for\nevaluating consistency from non-invasive brain recordings. We evaluate the\nconsistency of the cortical activity recorded with magnetoencephalography in a\ngroup of subjects diagnosed with Mild Cognitive Impairment (MCI), a condition\nsometimes prodromal of dementia, during the execution of a memory task. We use\nmetrics coming from nonlinear dynamics to evaluate the consistency of cortical\nregions. A representation known as (parenclitic networks) is constructed, where\natypical features are endowed with a network structure, the topological\nproperties of which can be studied at various scales. Pathological conditions\ncorrespond to strongly heterogeneous networks, whereas typical or normative\nconditions are characterized by sparsely connected networks with homogeneous\nnodes. The analysis of this kind of networks allows identifying the extent to\nwhich consistency is affecting the MCI group and the focal points where MCI is\nspecially severe. To the best of our knowledge, these results represent the\nfirst attempt at evaluating the consistency of brain functional activity using\ncomplex networks theory.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 11:27:40 GMT"}, {"version": "v2", "created": "Thu, 30 Oct 2014 14:55:10 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Mart\u00ednez", "J. H.", ""], ["Pastor", "J. M.", ""], ["Ariza", "P.", ""], ["Zanin", "M.", ""], ["Papo", "D.", ""], ["Maest\u00fa", "F.", ""], ["Bajo", "R.", ""], ["Boccaletti", "S.", ""], ["Buld\u00fa", "J. M.", ""]]}, {"id": "1311.4906", "submitter": "Daneng Yang", "authors": "Daneng Yang", "title": "On the Rationality of the Appearance of Consciousness", "comments": "This paper has been withdrawn by the author(s). 5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has been withdrawn by the author(s)\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2013 17:16:43 GMT"}, {"version": "v2", "created": "Fri, 17 Nov 2017 11:35:48 GMT"}], "update_date": "2017-11-20", "authors_parsed": [["Yang", "Daneng", ""]]}, {"id": "1311.5795", "submitter": "Gerrit Ansmann", "authors": "Kaspar A. Schindler, Stephan Bialonski, Marie-Therese Horstmann,\n  Christian E. Elger, Klaus Lehnertz", "title": "Evolving functional network properties and synchronizability during\n  human epileptic seizures", "comments": null, "journal-ref": "Chaos 18, 033119 (2008)", "doi": "10.1063/1.2966112", "report-no": null, "categories": "q-bio.NC physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We assess electrical brain dynamics before, during, and after one-hundred\nhuman epileptic seizures with different anatomical onset locations by\nstatistical and spectral properties of functionally defined networks. We\nobserve a concave-like temporal evolution of characteristic path length and\ncluster coefficient indicative of a movement from a more random toward a more\nregular and then back toward a more random functional topology. Surprisingly,\nsynchronizability was significantly decreased during the seizure state but\nincreased already prior to seizure end. Our findings underline the high\nrelevance of studying complex systems from the view point of complex networks,\nwhich may help to gain deeper insights into the complicated dynamics underlying\nepileptic seizures.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2013 16:07:05 GMT"}], "update_date": "2013-11-25", "authors_parsed": [["Schindler", "Kaspar A.", ""], ["Bialonski", "Stephan", ""], ["Horstmann", "Marie-Therese", ""], ["Elger", "Christian E.", ""], ["Lehnertz", "Klaus", ""]]}, {"id": "1311.5990", "submitter": "Marco Trindade", "authors": "A. J. da Silva, M. A. S. Trindade, D. O. C. Santos, R. F. Lima", "title": "Maximum likelihood q-estimator reveals nonextensivity regulated by\n  extracellular potassium in the mammalian neuromuscular junction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, we demonstrated the existence of nonextensivity in neuromuscular\ntransmission [Phys. Rev. E 84, 041925 (2011)]. In the present letter, we\npropose a general criterion based on the q-calculus foundations and\nnonextensive statistics to estimate the values for both scale factor and\nq-index using the maximum likelihood q-estimation method (MLqE). We next\napplied our theoretical findings to electrophysiological recordings from\nneuromuscular junction (NMJ) where spontaneous miniature end plate potentials\n(MEPP) were analyzed. These calculations were performed in both normal and high\nextracellular potassium concentration, [K+]o. This protocol was assumed to test\nthe validity of the q-index in electrophysiological conditions closely\nresembling physiological stimuli. Surprisingly, the analysis showed a\nsignificant difference between the q-index in high and normal [K+]o, where the\nmagnitude of nonextensivity was increased. Our letter provides a general way to\nobtain the best q-index from the q-Gaussian distribution function. It also\nexpands the validity of Tsallis statistics in a more realistic stimulus\ncondition. Physical and physiological implications of these findings are\ndiscussed in detail.\n", "versions": [{"version": "v1", "created": "Sat, 23 Nov 2013 12:02:39 GMT"}, {"version": "v2", "created": "Sun, 8 Dec 2013 23:01:54 GMT"}, {"version": "v3", "created": "Sun, 22 Dec 2013 23:08:30 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["da Silva", "A. J.", ""], ["Trindade", "M. A. S.", ""], ["Santos", "D. O. C.", ""], ["Lima", "R. F.", ""]]}, {"id": "1311.6345", "submitter": "Pierre-Olivier Amblard", "authors": "Pierre-Olivier Amblard", "title": "A non-parametric efficient evaluation of Partial Directed Coherence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying the flow of information between different areas of the brain can be\nperformed by using the so-called Partial Directed Coherence. This measure is\nusually evaluated by first identifying a multivariate autoregressive model, and\nthen by using Fourier transforms of the impulse responses identified and\napplying appropriate normalizations. Here, we present another route to evaluate\nthe partial directed coherences in multivariate time series. The method\nproposed is non parametric, and utilises the strong spectral factorization of\nthe inverse of the spectral density matrix of the multivariate process. To\nperform the factorization, we have recourse to an algorithm developed by Davis\nand his collaborators. We present simulations as well as an application on a\nreal data set (Local Field Potentials in the sleeping mouse) to illustrate the\nmethodology. A comparison to the usual approach in term of complexity is\ndetailed. For long AR models, the proposed approach is of interest.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 16:04:18 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Amblard", "Pierre-Olivier", ""]]}, {"id": "1311.6406", "submitter": "Frederick Shipley", "authors": "Frederick B. Shipley, Christopher M. Clark, Mark J. Alkema, Andrew M.\n  Leifer", "title": "Simultaneous optogenetic manipulation and calcium imaging in freely\n  moving C. elegans", "comments": null, "journal-ref": "Front. Neural Circuits, 24 March 2014", "doi": "10.3389/fncir.2014.00028", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental goal of systems neuroscience is to probe the dynamics of neural\nactivity that drive behavior. Here we present an instrument to simultaneously\nmanipulate neural activity via Channelrhodopsin, monitor neural response via\nGCaMP3, and observe behavior in freely moving C. elegans. We use the instrument\nto directly observe the relation between sensory stimuli, interneuron activity\nand locomotion in the mechanosensory circuit.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 18:56:04 GMT"}, {"version": "v2", "created": "Tue, 26 Nov 2013 18:25:08 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Shipley", "Frederick B.", ""], ["Clark", "Christopher M.", ""], ["Alkema", "Mark J.", ""], ["Leifer", "Andrew M.", ""]]}, {"id": "1311.6864", "submitter": "Eftychios A. Pnevmatikakis", "authors": "Eftychios A. Pnevmatikakis, Josh Merel, Ari Pakman, Liam Paninski", "title": "Bayesian spike inference from calcium imaging data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present efficient Bayesian methods for extracting neuronal spiking\ninformation from calcium imaging data. The goal of our methods is to sample\nfrom the posterior distribution of spike trains and model parameters (baseline\nconcentration, spike amplitude etc) given noisy calcium imaging data. We\npresent discrete time algorithms where we sample the existence of a spike at\neach time bin using Gibbs methods, as well as continuous time algorithms where\nwe sample over the number of spikes and their locations at an arbitrary\nresolution using Metropolis-Hastings methods for point processes. We provide\nRao-Blackwellized extensions that (i) marginalize over several model parameters\nand (ii) provide smooth estimates of the marginal spike posterior distribution\nin continuous time. Our methods serve as complements to standard point\nestimates and allow for quantification of uncertainty in estimating the\nunderlying spike train and model parameters.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2013 03:59:13 GMT"}], "update_date": "2013-11-28", "authors_parsed": [["Pnevmatikakis", "Eftychios A.", ""], ["Merel", "Josh", ""], ["Pakman", "Ari", ""], ["Paninski", "Liam", ""]]}, {"id": "1311.6950", "submitter": "Sanjiv Dwivedi", "authors": "Sarika Jalan and Sanjiv K. Dwivedi", "title": "Balanced condition in networks leads to Weibull statistics", "comments": "7 pages, 10 figures", "journal-ref": "Phys. Rev. E 89, 062718 (2014)", "doi": "10.1103/PhysRevE.89.062718", "report-no": "10.903/PhysRevE.89.062718", "categories": "q-bio.NC cond-mat.dis-nn nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of the balance in inhibitory and excitatory couplings in the\nbrain has increasingly been realized. Despite the key role played by\ninhibitory-excitatory couplings in the functioning of brain networks, the\nimpact of a balanced condition on the stability properties of underlying\nnetworks remains largely unknown. We investigate properties of the largest\neigenvalues of networks having such couplings, and find that they follow\ncompletely different statistics when in the balanced situation. Based on\nnumerical simulations, we demonstrate that the transition from Weibull to\nFr\\'echet via the Gumbel distribution can be controlled by the variance of the\ncolumn sum of the adjacency matrix, which depends monotonically on the\ndenseness of the underlying network. As a balanced condition is imposed, the\nlargest real part of the eigenvalue emulates a transition to the generalized\nextreme value statistics, independent of the inhibitory connection probability.\nFurthermore, the transition to the Weibull statistics and the small-world\ntransition occur at the same rewiring probability, reflecting a more stable\nsystem.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2013 12:23:57 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Jalan", "Sarika", ""], ["Dwivedi", "Sanjiv K.", ""]]}, {"id": "1311.7128", "submitter": "Guillaume Lajoie", "authors": "Guillaume Lajoie, Jean-Philippe Thivierge and Eric Shea-Brown", "title": "Structured chaos shapes spike-response noise entropy in balanced neural\n  networks", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS nlin.CD physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large networks of sparsely coupled, excitatory and inhibitory cells occur\nthroughout the brain. A striking feature of these networks is that they are\nchaotic. How does this chaos manifest in the neural code? Specifically, how\nvariable are the spike patterns that such a network produces in response to an\ninput signal? To answer this, we derive a bound for the entropy of multi-cell\nspike pattern distributions in large recurrent networks of spiking neurons\nresponding to fluctuating inputs. The analysis is based on results from random\ndynamical systems theory and is complimented by detailed numerical simulations.\nWe find that the spike pattern entropy is an order of magnitude lower than what\nwould be extrapolated from single cells. This holds despite the fact that\nnetwork coupling becomes vanishingly sparse as network size grows -- a\nphenomenon that depends on ``extensive chaos,\" as previously discovered for\nbalanced networks without stimulus drive. Moreover, we show how spike pattern\nentropy is controlled by temporal features of the inputs. Our findings provide\ninsight into how neural networks may encode stimuli in the presence of\ninherently chaotic dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2013 20:56:18 GMT"}, {"version": "v2", "created": "Sat, 22 Feb 2014 14:01:35 GMT"}], "update_date": "2014-02-25", "authors_parsed": [["Lajoie", "Guillaume", ""], ["Thivierge", "Jean-Philippe", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1311.7450", "submitter": "Eli Shlizerman", "authors": "Eli Shlizerman, Jeffrey A. Riffell, J. Nathan Kutz", "title": "Data-driven modeling of the olfactory neural codes and their dynamics in\n  the insect antennal lobe", "comments": null, "journal-ref": null, "doi": "10.3389/fncom.2014.00070", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recordings from neurons in the insects' olfactory primary processing center,\nthe antennal lobe (AL), reveal that the AL is able to process the input from\nchemical receptors into distinct neural activity patterns, called olfactory\nneural codes. These exciting results show the importance of neural codes and\ntheir relation to perception. The next challenge is to \\emph{model the\ndynamics} of neural codes. In our study, we perform multichannel recordings\nfrom the projection neurons in the AL driven by different odorants. We then\nderive a neural network from the electrophysiological data. The network\nconsists of lateral-inhibitory neurons and excitatory neurons, and is capable\nof producing unique olfactory neural codes for the tested odorants.\nSpecifically, we (i) design a projection, an odor space, for the neural\nrecording from the AL, which discriminates between distinct odorants\ntrajectories (ii) characterize scent recognition, i.e., decision-making based\non olfactory signals and (iii) infer the wiring of the neural circuit, the\nconnectome of the AL. We show that the constructed model is consistent with\nbiological observations, such as contrast enhancement and robustness to noise.\nThe study answers a key biological question in identifying how lateral\ninhibitory neurons can be wired to excitatory neurons to permit robust activity\npatterns.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2013 00:24:52 GMT"}], "update_date": "2014-08-27", "authors_parsed": [["Shlizerman", "Eli", ""], ["Riffell", "Jeffrey A.", ""], ["Kutz", "J. Nathan", ""]]}]