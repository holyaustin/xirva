[{"id": "1605.00178", "submitter": "Edward Gibson", "authors": "Edward Gibson and Roger Levy", "title": "An attempted replication of Hackl, Koster-Hale, Varvoutis (2012)", "comments": "21 pages; 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hackl, Koster-Hale & Varvoutis (2012; Journal of Semantics, 29, 145-206; HKV)\nprovide data that suggested that in a null context,\nantecedent-contained-deletion (ACD) relative clause structures modifying a\nquantified object noun phrase are easier to process than those modifying a\ndefinite object NP. HKV argue that this pattern of results supports a\nquantifier-raising (QR) analysis of both ACD structures and quantified NPs in\nobject position: under the account that they advocate, both ACD resolution and\nquantified NPs in object position require movement of the object NP to a higher\nsyntactic position. The processing advantage for quantified object NPs in ACD\nis hypothesized to derive from the fact that - at the point where ACD\nresolution must take place - the quantified NP has already undergone QR whereas\nthis is not the case for definite NPs. Here, we report attempted replications\nof their self-paced reading Experiments 1 and 2. We do not replicate the\ncritical interactions in any of the words immediately following the\ndisambiguating verb in either experiment. Putting these observations together\nwith the observation that it was only post-hoc analysis decisions that were\nresponsible for HKV's observed effects in the first place (Gibson et al.,\nsubmitted), we conclude that the experiments reported by HKV should not be\nviewed as providing evidence for the ACD quantifier raising processing effect.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2016 22:25:04 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Gibson", "Edward", ""], ["Levy", "Roger", ""]]}, {"id": "1605.00223", "submitter": "Ricardo Pio Monti", "authors": "Ricardo Pio Monti, Romy Lorenz, Robert Leech, Christoforos\n  Anagnostopoulos and Giovanni Montana", "title": "Text-mining the NeuroSynth corpus using Deep Boltzmann Machines", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale automated meta-analysis of neuroimaging data has recently\nestablished itself as an important tool in advancing our understanding of human\nbrain function. This research has been pioneered by NeuroSynth, a database\ncollecting both brain activation coordinates and associated text across a large\ncohort of neuroimaging research papers. One of the fundamental aspects of such\nmeta-analysis is text-mining. To date, word counts and more sophisticated\nmethods such as Latent Dirichlet Allocation have been proposed. In this work we\npresent an unsupervised study of the NeuroSynth text corpus using Deep\nBoltzmann Machines (DBMs). The use of DBMs yields several advantages over the\naforementioned methods, principal among which is the fact that it yields both\nword and document embeddings in a high-dimensional vector space. Such\nembeddings serve to facilitate the use of traditional machine learning\ntechniques on the text corpus. The proposed DBM model is shown to learn\nembeddings with a clear semantic structure.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2016 09:01:13 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Monti", "Ricardo Pio", ""], ["Lorenz", "Romy", ""], ["Leech", "Robert", ""], ["Anagnostopoulos", "Christoforos", ""], ["Montana", "Giovanni", ""]]}, {"id": "1605.00562", "submitter": "Mason A. Porter", "authors": "Bernadette J. Stolz, Heather A. Harrington, and Mason A. Porter", "title": "Persistent homology of time-dependent functional networks constructed\n  from coupled time series", "comments": "17 pages (+3 pages in Supplementary Information), 11 figures in many\n  text (many with multiple parts) + others in SI, submitted", "journal-ref": null, "doi": "10.1063/1.4978997", "report-no": null, "categories": "q-bio.QM cond-mat.dis-nn math.AT nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use topological data analysis to study \"functional networks\" that we\nconstruct from time-series data from both experimental and synthetic sources.\nWe use persistent homology with a weight rank clique filtration to gain\ninsights into these functional networks, and we use persistence landscapes to\ninterpret our results. Our first example uses time-series output from networks\nof coupled Kuramoto oscillators. Our second example consists of biological data\nin the form of functional magnetic resonance imaging (fMRI) data that was\nacquired from human subjects during a simple motor-learning task in which\nsubjects were monitored on three days in a five-day period. With these\nexamples, we demonstrate that (1) using persistent homology to study functional\nnetworks provides fascinating insights into their properties and (2) the\nposition of the features in a filtration can sometimes play a more vital role\nthan persistence in the interpretation of topological features, even though\nconventionally the latter is used to distinguish between signal and noise. We\nfind that persistent homology can detect differences in synchronization\npatterns in our data sets over time, giving insight both on changes in\ncommunity structure in the networks and on increased synchronization between\nbrain regions that form loops in a functional network during motor learning.\nFor the motor-learning data, persistence landscapes also reveal that on average\nthe majority of changes in the network loops take place on the second of the\nthree days of the learning process.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 16:49:36 GMT"}, {"version": "v2", "created": "Fri, 22 Jul 2016 21:17:37 GMT"}, {"version": "v3", "created": "Sat, 3 Dec 2016 21:21:41 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Stolz", "Bernadette J.", ""], ["Harrington", "Heather A.", ""], ["Porter", "Mason A.", ""]]}, {"id": "1605.01096", "submitter": "Daniel Toker", "authors": "Daniel Toker and Friedrich Sommer", "title": "Moving Past the Minimum Information Partition: How To Quickly and\n  Accurately Calculate Integrated Information", "comments": "21 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An outstanding challenge with the Integrated Information Theory of\nConsciousness (IIT) is to find a way of rapidly and accurately calculating\nintegrated information from neural data. A number of measures of integrated\ninformation based on time series data have been proposed, but most measures\nrequire finding the Minimum Information Partition of a network, which is\ncomputationally expensive and not practical for real brain data. Here, we\nintroduce a novel partition, the Maximum Modularity Partition, across which to\nquickly calculate integrated information. We also introduce a novel detection\ntask on simulated data to evaluate the performance of integrated information\nmeasures across different partitions. We show that integrated information can\nbe reliably and quickly calculated across the Maximum Modularity Partition, as\nwell as the previously proposed atomic partition, even in relatively large\nnetworks, which constitutes an advance in researchers' ability to empirically\ntest the predictions of IIT in real brain data.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2016 21:26:17 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Toker", "Daniel", ""], ["Sommer", "Friedrich", ""]]}, {"id": "1605.01138", "submitter": "Jiajun Wu", "authors": "Renqiao Zhang, Jiajun Wu, Chengkai Zhang, William T. Freeman, Joshua\n  B. Tenenbaum", "title": "A Comparative Evaluation of Approximate Probabilistic Simulation and\n  Deep Neural Networks as Accounts of Human Physical Scene Understanding", "comments": "Accepted to CogSci 2016 as an oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans demonstrate remarkable abilities to predict physical events in complex\nscenes. Two classes of models for physical scene understanding have recently\nbeen proposed: \"Intuitive Physics Engines\", or IPEs, which posit that people\nmake predictions by running approximate probabilistic simulations in causal\nmental models similar in nature to video-game physics engines, and memory-based\nmodels, which make judgments based on analogies to stored experiences of\npreviously encountered scenes and physical outcomes. Versions of the latter\nhave recently been instantiated in convolutional neural network (CNN)\narchitectures. Here we report four experiments that, to our knowledge, are the\nfirst rigorous comparisons of simulation-based and CNN-based models, where both\napproaches are concretely instantiated in algorithms that can run on raw image\ninputs and produce as outputs physical judgments such as whether a stack of\nblocks will fall. Both approaches can achieve super-human accuracy levels and\ncan quantitatively predict human judgments to a similar degree, but only the\nsimulation-based models generalize to novel situations in ways that people do,\nand are qualitatively consistent with systematic perceptual illusions and\njudgment asymmetries that people show.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 04:26:06 GMT"}, {"version": "v2", "created": "Tue, 4 Oct 2016 01:01:47 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Zhang", "Renqiao", ""], ["Wu", "Jiajun", ""], ["Zhang", "Chengkai", ""], ["Freeman", "William T.", ""], ["Tenenbaum", "Joshua B.", ""]]}, {"id": "1605.01233", "submitter": "Chung Chan", "authors": "Chung Chan, Ali Al-Bashabsheh, Qiaoqiao Zhou, Tarik Kaced and Tie Liu", "title": "Info-Clustering: A Mathematical Theory for Data Clustering", "comments": "In celebration of Claude Shannon's Centenary", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT math.IT q-bio.GN q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate an info-clustering paradigm based on a multivariate information\nmeasure, called multivariate mutual information, that naturally extends\nShannon's mutual information between two random variables to the multivariate\ncase involving more than two random variables. With proper model reductions, we\nshow that the paradigm can be applied to study the human genome and connectome\nin a more meaningful way than the conventional algorithmic approach. Not only\ncan info-clustering provide justifications and refinements to some existing\ntechniques, but it also inspires new computationally feasible solutions.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 11:43:47 GMT"}, {"version": "v2", "created": "Wed, 5 Oct 2016 13:55:22 GMT"}, {"version": "v3", "created": "Sun, 11 Dec 2016 15:57:16 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Chan", "Chung", ""], ["Al-Bashabsheh", "Ali", ""], ["Zhou", "Qiaoqiao", ""], ["Kaced", "Tarik", ""], ["Liu", "Tie", ""]]}, {"id": "1605.01270", "submitter": "Robert Leech", "authors": "Romy Lorenz, Ricardo Pio Monti, Adam Hampshire, Yury Koush,\n  Christoforos Anagnostopoulos, Aldo A Faisal, David Sharp, Giovanni Montana,\n  Robert Leech, Ines R Violante", "title": "Towards tailoring non-invasive brain stimulation using real-time fMRI\n  and Bayesian optimization", "comments": "accepted for oral presentation at PRNI 2016 - 6th International\n  Workshop on Pattern Recognition in Neuroimaging", "journal-ref": "Pattern Recognition in Neuroimaging (PRNI), 2016 International\n  Workshop on", "doi": "10.1109/PRNI.2016.7552338", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-invasive brain stimulation, such as transcranial alternating current\nstimulation (tACS) provides a powerful tool to directly modulate brain\noscillations that mediate complex cognitive processes. While the body of\nevidence about the effect of tACS on behavioral and cognitive performance is\nconstantly growing, those studies fail to address the importance of subject-\nspecific stimulation protocols. With this study here, we set the foundation to\ncombine tACS with a recently presented framework that utilizes real-time fRMI\nand Bayesian optimization in order to identify the most optimal tACS protocol\nfor a given individual. While Bayesian optimization is particularly relevant to\nsuch a scenario, its success depends on two fundamental choices: the choice of\ncovariance kernel for the Gaussian process prior as well as the choice of\nacquisition function that guides the search. Using empirical (functional\nneuroimaging) as well as simulation data, we identified the squared exponential\nkernel and the upper confidence bound acquisition function to work best for our\nproblem. These results will be used to inform our upcoming real- time\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 13:26:30 GMT"}], "update_date": "2017-01-12", "authors_parsed": [["Lorenz", "Romy", ""], ["Monti", "Ricardo Pio", ""], ["Hampshire", "Adam", ""], ["Koush", "Yury", ""], ["Anagnostopoulos", "Christoforos", ""], ["Faisal", "Aldo A", ""], ["Sharp", "David", ""], ["Montana", "Giovanni", ""], ["Leech", "Robert", ""], ["Violante", "Ines R", ""]]}, {"id": "1605.01326", "submitter": "Ramon Ferrer i Cancho", "authors": "Ramon Ferrer-i-Cancho", "title": "Compression and the origins of Zipf's law for word frequencies", "comments": "arguments have been improved; in press in Complexity (Wiley)", "journal-ref": "Complexity 21, 409-411 (2016)", "doi": "10.1002/cplx.21820", "report-no": null, "categories": "cs.CL physics.data-an physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here we sketch a new derivation of Zipf's law for word frequencies based on\noptimal coding. The structure of the derivation is reminiscent of Mandelbrot's\nrandom typing model but it has multiple advantages over random typing: (1) it\nstarts from realistic cognitive pressures (2) it does not require fine tuning\nof parameters and (3) it sheds light on the origins of other statistical laws\nof language and thus can lead to a compact theory of linguistic laws. Our\nfindings suggest that the recurrence of Zipf's law in human languages could\noriginate from pressure for easy and fast communication.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 16:00:59 GMT"}, {"version": "v2", "created": "Wed, 20 Jul 2016 15:14:10 GMT"}], "update_date": "2020-09-24", "authors_parsed": [["Ferrer-i-Cancho", "Ramon", ""]]}, {"id": "1605.01381", "submitter": "Sergey Agapov", "authors": "S.N. Agapov, V.A. Bulanov, A.V. Zakharov, M.S. Sergeeva", "title": "Review of analytical instruments for EEG analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since it was first used in 1926, EEG has been one of the most useful\ninstruments of neuroscience. In order to start using EEG data we need not only\nEEG apparatus, but also some analytical tools and skills to understand what our\ndata mean. This article describes several classical analytical tools and also\nnew one which appeared only several years ago. We hope it will be useful for\nthose researchers who have only started working in the field of cognitive EEG.\n", "versions": [{"version": "v1", "created": "Fri, 4 Mar 2016 12:02:40 GMT"}], "update_date": "2016-05-05", "authors_parsed": [["Agapov", "S. N.", ""], ["Bulanov", "V. A.", ""], ["Zakharov", "A. V.", ""], ["Sergeeva", "M. S.", ""]]}, {"id": "1605.01441", "submitter": "Vince Grolmusz", "authors": "Csaba Kerepesi and Balint Varga and Balazs Szalkai and Vince Grolmusz", "title": "The Dorsal Striatum and the Dynamics of the Consensus Connectomes in the\n  Frontal Lobe of the Human Brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the applications of the graph theory it is unusual that one considers\nnumerous, pairwise different graphs on the very same set of vertices. In the\ncase of human braingraphs or connectomes, however, this is the standard\nsituation: the nodes correspond to anatomically identified cerebral regions,\nand two vertices are connected by an edge if a diffusion MRI-based workflow\nidentifies a fiber of axons, running between the two regions, corresponding to\nthe two vertices. Therefore, if we examine the braingraphs of $n$ subjects,\nthen we have $n$ graphs on the very same, anatomically identified vertex set.\nIt is a natural idea to describe the $k$-frequently appearing edges in these\ngraphs: the edges that are present between the same two vertices in at least\n$k$ out of the $n$ graphs. Based on the NIH-funded large Human Connectome\nProject's public data release, we have reported the construction of the\nBudapest Reference Connectome Server \\url{http://connectome.pitgroup.org} that\ngenerates and visualizes these $k$-frequently appearing edges. We call the\ngraphs of the $k$-frequently appearing edges \"$k$-consensus connectomes\" since\nan edge could be included only if it is present in at least $k$ graphs out of\n$n$. Considering the whole human brain, we have reported a surprising property\nof these consensus connectomes earlier. In the present work we are focusing on\nthe frontal lobe of the brain, and we report here a similarly surprising\ndynamical property of the consensus connectomes when $k$ is gradually changed\nfrom $k=n$ to $k=1$: the connections between the nodes of the frontal lobe are\nseemingly emanating from those nodes that were connected to sub-cortical\nstructures of the dorsal striatum: the caudate nucleus, and the putamen. We\nhypothesize that this dynamic behavior copies the axonal fiber development of\nthe frontal lobe.\n", "versions": [{"version": "v1", "created": "Wed, 4 May 2016 21:24:16 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Kerepesi", "Csaba", ""], ["Varga", "Balint", ""], ["Szalkai", "Balazs", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1605.01592", "submitter": "Alberto Ferrari", "authors": "Alberto Ferrari and Mario Comelli", "title": "A comparison of methods for the analysis of binomial proportion data in\n  behavioral research", "comments": "26 pages, 4 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In behavioral and psychiatric research, data consisting of a per-subject\nproportion of \"successes\" and \"failures\" over a finite number of trials often\narise. This kind of clustered binary data are usually non-normally distributed,\nwhich can cause issues with parameter estimation and predictions if the usual\ngeneral linear model is applied and sample size is small. Here we studied the\nperformances of some of the available analytic methods applicable to the\nanalysis of proportion data; namely linear regression, Poisson regression,\nbeta-binomial regression and Generalized Linear Mixed Models (GLMMs). We report\nthe conclusions from a simulation study evaluating power and Type I error rates\nof these models in scenarios akin to those met by behavioral researchers and\ndiffering in sample size, cluster size and fixed effects parameters; plus, we\ndescribe results from the application of these methods on data from two real\nbehavioral experiments. Our results show that, while GLMMs and beta-binomial\nregression are powerful instruments for the analysis of clustered binary\noutcomes, linear approximation can still provide reliable hypothesis testing in\nthis context. Poisson regression, on the other hand, can suffer heavily from\nmodel misspecification when used to model proportion data. We conclude\nproviding some guidelines for the choice of appropriate analytical instruments,\nsample and cluster size depending on the conditions of the experiment.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 13:50:49 GMT"}, {"version": "v2", "created": "Fri, 6 May 2016 15:47:12 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Ferrari", "Alberto", ""], ["Comelli", "Mario", ""]]}, {"id": "1605.01661", "submitter": "Ramon Ferrer i Cancho", "authors": "R. Ferrer-i-Cancho, D. Lusseau and B. McCowan", "title": "Parallels of human language in the behavior of bottlenose dolphins", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A short review of similarities between dolphins and humans with the help of\nquantitative linguistics and information theory.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 17:38:42 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Ferrer-i-Cancho", "R.", ""], ["Lusseau", "D.", ""], ["McCowan", "B.", ""]]}, {"id": "1605.01784", "submitter": "Sameer Saproo", "authors": "Sameer Saproo, Victor Shih, David C. Jangraw, and Paul Sajda", "title": "Neural mechanisms underlying catastrophic failure in human-machine\n  interaction during aerial navigation", "comments": "Manuscript as initially submitted to Journal of Neural Engineering in\n  March, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective. We investigated the neural correlates of workload buildup in a\nfine visuomotor task called the boundary avoidance task (BAT). The BAT has been\nknown to induce naturally occurring failures of human-machine coupling in high\nperformance aircraft that can potentially lead to a crash; these failures are\ntermed pilot induced oscillations (PIOs). Approach. We recorded EEG and\npupillometry data from human subjects engaged in a flight BAT simulated within\na virtual 3D environment. Main results. We find that workload buildup in a BAT\ncan be successfully decoded from oscillatory features in the\nelectroencephalogram (EEG). Information in delta, theta, alpha, beta, and gamma\nspectral bands of the EEG all contribute to successful decoding, however gamma\nband activity with a lateralized somatosensory topography has the highest\ncontribution, while theta band activity with a frontocentral topography has the\nmost robust contribution in terms of real world usability. We show that the\noutput of the spectral decoder can be used to predict PIO susceptibility. We\nalso find that workload buildup in the task induces pupil dilation, the\nmagnitude of which is significantly correlated with the magnitude of the\ndecoded EEG signals. These results suggest that PIOs may result from the\ndysregulation of cortical networks such as the locus coeruleus (LC) anterior\ncingulate cortex (ACC) circuit. Significance. Our findings may generalize to\nsimilar control failures in other cases of tight man machine coupling where\ngains and latencies in the control system must be inferred and compensated for\nby the human operators. A closed-loop intervention using neurophysiological\ndecoding of workload buildup that targets the LC ACC circuit may positively\nimpact operator performance in such situations.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2016 22:45:29 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Saproo", "Sameer", ""], ["Shih", "Victor", ""], ["Jangraw", "David C.", ""], ["Sajda", "Paul", ""]]}, {"id": "1605.01905", "submitter": "Carina Curto", "authors": "Carina Curto", "title": "What can topology tell us about the neural code?", "comments": "16 pages, 9 figures", "journal-ref": "Bulletin of the AMS, vol. 54, no. 1, pp. 63-78, January 2017", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscience is undergoing a period of rapid experimental progress and\nexpansion. New mathematical tools, previously unknown in the neuroscience\ncommunity, are now being used to tackle fundamental questions and analyze\nemerging data sets. Consistent with this trend, the last decade has seen an\nuptick in the use of topological ideas and methods in neuroscience. In this\ntalk I will survey recent applications of topology in neuroscience, and explain\nwhy topology is an especially natural tool for understanding neural codes.\nNote: This is a write-up of my talk for the Current Events Bulletin, held at\nthe 2016 Joint Math Meetings in Seattle, WA.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2016 12:06:15 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Curto", "Carina", ""]]}, {"id": "1605.02037", "submitter": "Rafal Paprocki Mr", "authors": "Artem Lenskiy, Rafal Paprocki", "title": "Blink Rate Variability during resting and reading sessions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that blinks occur not only to moisturize eyes and as a\ndefensive response to the environment, but are also caused by mental processes.\nIn this paper, we investigate statistical characteristics of blinks and blink\nrate variability of 11 subjects. The subjects are presented with a\nreading/memorization session preceded and followed by a resting session. EEG\nsignals were recorded during these sessions. The signals from the two front\nelectrodes were then analyzed, and times of the blinks were detected. We\ndiscovered that compared to the resting sessions, reading session is\ncharacterized by a lower number of blinks. However, there was no significant\ndifference in standard deviation in the blink rate variability. We also noticed\nthat in terms of complexity measures, the blink rate variability is located\nsomewhere in between white and pink noises, being closer to the white noise\nduring reading. We also found that the average of inter-blink intervals\nincreases during reading/memorization, thus longer inter-blink intervals could\nbe associated with a mental workload.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 05:07:41 GMT"}], "update_date": "2016-05-09", "authors_parsed": [["Lenskiy", "Artem", ""], ["Paprocki", "Rafal", ""]]}, {"id": "1605.02560", "submitter": "Zi Wang", "authors": "Zi Wang, Vyacheslav Karolis, Chiara Nosarti, Giovanni Montana", "title": "Studying the brain from adolescence to adulthood through sparse\n  multi-view matrix factorisations", "comments": "Submitted to the 6th International Workshop on Pattern Recognition in\n  Neuroimaging (PRNI)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Men and women differ in specific cognitive abilities and in the expression of\nseveral neuropsychiatric conditions. Such findings could be attributed to sex\nhormones, brain differences, as well as a number of environmental variables.\nExisting research on identifying sex-related differences in brain structure\nhave predominantly used cross-sectional studies to investigate, for instance,\ndifferences in average gray matter volumes (GMVs). In this article we explore\nthe potential of a recently proposed multi-view matrix factorisation (MVMF)\nmethodology to study structural brain changes in men and women that occur from\nadolescence to adulthood. MVMF is a multivariate variance decomposition\ntechnique that extends principal component analysis to \"multi-view\" datasets,\ni.e. where multiple and related groups of observations are available. In this\napplication, each view represents a different age group. MVMF identifies latent\nfactors explaining shared and age-specific contributions to the observed\noverall variability in GMVs over time. These latent factors can be used to\nproduce low-dimensional visualisations of the data that emphasise age-specific\neffects once the shared effects have been accounted for. The analysis of two\ndatasets consisting of individuals born prematurely as well as healthy controls\nprovides evidence to suggest that the separation between males and females\nbecomes increasingly larger as the brain transitions from adolescence to\nadulthood. We report on specific brain regions associated to these variance\neffects.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 12:40:22 GMT"}], "update_date": "2016-05-10", "authors_parsed": [["Wang", "Zi", ""], ["Karolis", "Vyacheslav", ""], ["Nosarti", "Chiara", ""], ["Montana", "Giovanni", ""]]}, {"id": "1605.02609", "submitter": "Luca Ambrogioni", "authors": "Luca Ambrogioni, Marcel A. J. van Gerven and Eric Maris", "title": "Dynamic Decomposition of Spatiotemporal Neural Signals", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1005540", "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural signals are characterized by rich temporal and spatiotemporal dynamics\nthat reflect the organization of cortical networks. Theoretical research has\nshown how neural networks can operate at different dynamic ranges that\ncorrespond to specific types of information processing. Here we present a data\nanalysis framework that uses a linearized model of these dynamic states in\norder to decompose the measured neural signal into a series of components that\ncapture both rhythmic and non-rhythmic neural activity. The method is based on\nstochastic differential equations and Gaussian process regression. Through\ncomputer simulations and analysis of magnetoencephalographic data, we\ndemonstrate the efficacy of the method in identifying meaningful modulations of\noscillatory signals corrupted by structured temporal and spatiotemporal noise.\nThese results suggest that the method is particularly suitable for the analysis\nand interpretation of complex temporal and spatiotemporal neural signals.\n", "versions": [{"version": "v1", "created": "Mon, 9 May 2016 14:47:53 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Ambrogioni", "Luca", ""], ["van Gerven", "Marcel A. J.", ""], ["Maris", "Eric", ""]]}, {"id": "1605.02869", "submitter": "Xiaoli Wu", "authors": "Qi She, Xiaoli Wu, Beth Jelfs, Adam S. Charles, Rosa H.M.Chan", "title": "An Efficient and Flexible Spike Train Model via Empirical Bayes", "comments": "16 pages, 20 figures, 3 tables", "journal-ref": "IEEE Trans. Signal Processing 69 (2021) 3236-3251", "doi": "10.1109/TSP.2021.3076885", "report-no": null, "categories": "q-bio.QM eess.SP q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Accurate statistical models of neural spike responses can characterize the\ninformation carried by neural populations. But the limited samples of spike\ncounts during recording usually result in model overfitting. Besides, current\nmodels assume spike counts to be Poisson-distributed, which ignores the fact\nthat many neurons demonstrate over-dispersed spiking behaviour. Although the\nNegative Binomial Generalized Linear Model (NB-GLM) provides a powerful tool\nfor modeling over-dispersed spike counts, the maximum likelihood-based standard\nNB-GLM leads to highly variable and inaccurate parameter estimates. Thus, we\npropose a hierarchical parametric empirical Bayes method to estimate the neural\nspike responses among neuronal population. Our method integrates both\nGeneralized Linear Models (GLMs) and empirical Bayes theory, which aims to (1)\nimprove the accuracy and reliability of parameter estimation, compared to the\nmaximum likelihood-based method for NB-GLM and Poisson-GLM; (2) effectively\ncapture the over-dispersion nature of spike counts from both simulated data and\nexperimental data; and (3) provide insight into both neural interactions and\nspiking behaviours of the neuronal populations. We apply our approach to study\nboth simulated data and experimental neural data. The estimation of simulation\ndata indicates that the new framework can accurately predict mean spike counts\nsimulated from different models and recover the connectivity weights among\nneural populations. The estimation based on retinal neurons demonstrate the\nproposed method outperforms both NB-GLM and Poisson-GLM in terms of the\npredictive log-likelihood of held-out data. Codes are available in\nhttps://doi.org/10.5281/zenodo.4704423\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 06:57:16 GMT"}, {"version": "v2", "created": "Sat, 24 Sep 2016 07:39:29 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 01:34:32 GMT"}, {"version": "v4", "created": "Wed, 20 Jan 2021 13:20:57 GMT"}, {"version": "v5", "created": "Thu, 1 Apr 2021 13:14:48 GMT"}, {"version": "v6", "created": "Tue, 27 Apr 2021 05:07:01 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["She", "Qi", ""], ["Wu", "Xiaoli", ""], ["Jelfs", "Beth", ""], ["Charles", "Adam S.", ""], ["Chan", "Rosa H. M.", ""]]}, {"id": "1605.03005", "submitter": "Yoram Burak", "authors": "Neta Ravid Tannenbaum and Yoram Burak", "title": "Shaping neural circuits by high order synaptic interactions", "comments": "Version 2 contains minor revisions. 33 pages, 10 figures, and 5\n  supporting figures. Accepted to PLoS Computational Biology; An earlier\n  version of this work appeared in abstract form (Program No. 260.23. 2015\n  Neuroscience Meeting Planner. Chicago, IL: Society for Neuroscience, 2015.\n  Online.)", "journal-ref": "(2016). PLoS Comput Biol 12(8): e1005056", "doi": "10.1371/journal.pcbi.1005056", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spike timing dependent plasticity (STDP) is believed to play an important\nrole in shaping the structure of neural circuits. Here we show that STDP\ngenerates effective interactions between synapses of different neurons, which\nwere neglected in previous theoretical treatments, and can be described as a\nsum over contributions from structural motifs. These interactions can have a\npivotal influence on the connectivity patterns that emerge under the influence\nof STDP. In particular, we consider two highly ordered forms of structure: wide\nsynfire chains, in which groups of neurons project to each other sequentially,\nand self connected assemblies. We show that high order synaptic interactions\ncan enable the formation of both structures, depending on the form of the STDP\nfunction and the time course of synaptic currents. Furthermore, within a\ncertain regime of biophysical parameters, emergence of the ordered connectivity\noccurs robustly and autonomously in a stochastic network of spiking neurons,\nwithout a need to expose the neural network to structured inputs during\nlearning.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 13:31:58 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2016 08:26:55 GMT"}], "update_date": "2016-08-25", "authors_parsed": [["Tannenbaum", "Neta Ravid", ""], ["Burak", "Yoram", ""]]}, {"id": "1605.03031", "submitter": "Daniele Marinazzo", "authors": "Enrico Amico, Daniele Marinazzo, Carol DiPerri, Lizette Heine, Jitka\n  Annen, Charlotte Martial, Mario Dzemidzic, Steven Laureys, and Joaqu\\'in\n  Go\\~ni", "title": "Mapping the functional connectome traits of levels of consciousness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Examining task-free functional connectivity (FC) in the human brain offers\ninsights on how spontaneous integration and segregation of information relate\nto human cognition, and how this organization may be altered in different\nconditions, and neurological disorders. This is particularly relevant for\npatients in disorders of consciousness (DOC) following severe acquired brain\ndamage and coma, one of the most devastating conditions in modern medical care.\nWe present a novel data-driven methodology, connICA, which implements\nIndependent Component Analysis (ICA) for the extraction of robust independent\nFC patterns (FC-traits) from a set of individual functional connectomes,\nwithout imposing any a priori data stratification into groups. We here apply\nconnICA to investigate associations between network traits derived from\ntask-free FC and cognitive/clinical features that define levels of\nconsciousness. Three main independent FC-traits were identified and linked to\nconsciousness-related clinical features. The first one represents the\nfunctional configuration it is associated to a sedative (sevoflurane), the\noverall effect of the pathology and the level of arousal. The second FC-trait\nreflects the disconnection of the visual and sensory-motor connectivity\npatterns. It also relates to the time since the insult and to the ability of\ncommunicating with the external environment. The third FC-trait isolates the\nconnectivity pattern encompassing the fronto-parietal and the default-mode\nnetwork areas as well as the interaction between left and right hemispheres,\nwhich are also associated to the awareness of the self and its surroundings.\nEach FC-trait represents a distinct functional process with a role in the\ndegradation of conscious states of functional brain networks, shedding further\nlight on the functional subcircuits that get disrupted in severe brain-damage.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 14:24:39 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 22:02:55 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Amico", "Enrico", ""], ["Marinazzo", "Daniele", ""], ["DiPerri", "Carol", ""], ["Heine", "Lizette", ""], ["Annen", "Jitka", ""], ["Martial", "Charlotte", ""], ["Dzemidzic", "Mario", ""], ["Laureys", "Steven", ""], ["Go\u00f1i", "Joaqu\u00edn", ""]]}, {"id": "1605.03060", "submitter": "Matthew Ricci", "authors": "Matthew Ricci, Junkyung Kim, Fredrik Johansson", "title": "A Passage-of-time Model of the Cerebellar Purkinje Cell", "comments": "14 pages, 10 figures; fixed typos on page 6, 7", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cerebellar Purkinje cell controlling eyeblinks can learn, remember and\nreproduce the interstimulus interval in a classical conditioning paradigm.\nGiven temporally separated inputs, the cerebellar Purkinje cell learns to pause\nits tonic inhibition of a motor pathway with high temporal precision so that an\novert blink occurs at the right time. Most models relegate the Purkinje cell's\npassage-of-time representation to afferent granule cells, a subpopulation of\nwhich is supposedly selected for synaptic depression in order to make the\nPurkinje cell pause. However, granule cell models have recently faced two\ncrucial challenges: 1) bypassing granule cells and directly stimulating the\nPurkinje cell's pre-synaptic fibers during training still produces a well-timed\npause, and 2) the Purkinje cell can reproduce the learned pause, invariant to\nthe temporal structure of probe stimulation. Here, we present a passage-of-time\nmodel which is internal to the Purkinje cell and is invariant to probe\nstructure. The model accurately simulates the Purkinje cell learning mechanism\nand makes testable electrophysiological predictions. Importantly, the model is\na numerical proof-of-principle for a biological learning mechanism which does\nnot rely on changes of synaptic strength.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 15:32:03 GMT"}, {"version": "v2", "created": "Thu, 12 May 2016 17:48:13 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["Ricci", "Matthew", ""], ["Kim", "Junkyung", ""], ["Johansson", "Fredrik", ""]]}, {"id": "1605.03090", "submitter": "Yogesh Virkar", "authors": "Yogesh S. Virkar and Woodrow L. Shew and Juan G. Restrepo and Edward\n  Ott", "title": "Metabolite transport through glial networks stabilizes the dynamics of\n  learning", "comments": "8 pages, 5 figures", "journal-ref": "Phys. Rev. E 94, 042310 (2016)", "doi": "10.1103/PhysRevE.94.042310", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and memory are acquired through long-lasting changes in synapses. In\nthe simplest models, such synaptic potentiation typically leads to runaway\nexcitation, but in reality there must exist processes that robustly preserve\noverall stability of the neural system dynamics. How is this accomplished?\nVarious approaches to this basic question have been considered. Here we propose\na particularly compelling and natural mechanism for preserving stability of\nlearning neural systems. This mechanism is based on the global processes by\nwhich metabolic resources are distributed to the neurons by glial cells.\nSpecifically, we introduce and study a model comprised of two interacting\nnetworks: a model neural network interconnected by synapses which undergo\nspike-timing dependent plasticity (STDP); and a model glial network\ninterconnected by gap junctions which diffusively transport metabolic resources\namong the glia and, ultimately, to neural synapses where they are consumed. Our\nmain result is that the biophysical constraints imposed by diffusive transport\nof metabolic resources through the glial network can prevent runaway growth of\nsynaptic strength, both during ongoing activity and during learning. Our\nfindings suggest a previously unappreciated role for glial transport of\nmetabolites in the feedback control stabilization of neural network dynamics\nduring learning.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2016 16:37:30 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Virkar", "Yogesh S.", ""], ["Shew", "Woodrow L.", ""], ["Restrepo", "Juan G.", ""], ["Ott", "Edward", ""]]}, {"id": "1605.03373", "submitter": "Vicente Botella-Soler", "authors": "Vicente Botella-Soler, St\\'ephane Deny, Olivier Marre, Ga\\v{s}per\n  Tka\\v{c}ik", "title": "Nonlinear decoding of a complex movie from the mammalian retina", "comments": "24 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retinal circuitry transforms spatiotemporal patterns of light into spiking\nactivity of ganglion cells, which provide the sole visual input to the brain.\nRecent advances have led to a detailed characterization of retinal activity and\nstimulus encoding by large neural populations. The inverse problem of decoding,\nwhere the stimulus is reconstructed from spikes, has received less attention,\nin particular for complex input movies that should be reconstructed\n\"pixel-by-pixel\". We recorded around a hundred neurons from a dense patch in a\nrat retina and decoded movies of multiple small discs executing\nmutually-avoiding random motions. We constructed nonlinear (kernelized)\ndecoders that improved significantly over linear decoding results, mostly due\nto their ability to reliably separate between neural responses driven by\nlocally fluctuating light signals, and responses at locally constant light\ndriven by spontaneous or network activity. This improvement crucially depended\non the precise, non-Poisson temporal structure of individual spike trains,\nwhich originated in the spike-history dependence of neural responses. Our\nresults suggest a general paradigm in which downstream neural circuitry could\ndiscriminate between spontaneous and stimulus-driven activity on the basis of\nhigher-order statistical structure intrinsic to the incoming spike trains.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 11:05:07 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Botella-Soler", "Vicente", ""], ["Deny", "St\u00e9phane", ""], ["Marre", "Olivier", ""], ["Tka\u010dik", "Ga\u0161per", ""]]}, {"id": "1605.03416", "submitter": "Barco You Mr.", "authors": "Jie You, Xin Yang, Matthias Hub", "title": "Concept based Attention", "comments": "7 pages, 2 figures", "journal-ref": "NeuroSci.Proc.Suppl. 89 (2007) 4-11", "doi": null, "report-no": "CS-5230-481", "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Attention endows animals an ability to concentrate on the most relevant\ninformation among a deluge of distractors at any given time, either through\nvolitionally 'top-down' biasing, or driven by automatically 'bottom-up'\nsaliency of stimuli, in favour of advantageous competition in neural\nmodulations for information processing. Nevertheless, instead of being limited\nto perceive simple features, human and other advanced animals adaptively learn\nthe world into categories and abstract concepts from experiences, imparting the\nworld meanings. This thesis suggests that the high-level cognitive ability of\nhuman is more likely driven by attention basing on abstract perceptions, which\nis defined as concept based attention (CbA).\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 12:51:19 GMT"}], "update_date": "2016-05-13", "authors_parsed": [["You", "Jie", ""], ["Yang", "Xin", ""], ["Hub", "Matthias", ""]]}, {"id": "1605.03482", "submitter": "Roee Gilron", "authors": "Roee Gilron, Jonathan Rosenblatt, Oluwasanmi Koyejo, Russell A.\n  Poldrack, Roy Mukamel", "title": "What's in a pattern? Examining the Type of Signal Multivariate Analysis\n  Uncovers At the Group Level", "comments": "Revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivoxel pattern analysis (MVPA) has gained enormous popularity in the\nneuroimaging community over the past few years. At the group level, most MVPA\nstudies adopt an \"information based\" approach in which the sign of the effect\nof individual subjects is discarded and a non-directional summary statistic is\ncarried over to the second level. This is in contrast to a directional\n\"activation based\" approach typical in univariate group level analysis, in\nwhich both signal magnitude and sign are taken into account. The transition\nfrom examining effects in one voxel at a time vs. several voxels (univariate\nvs. multivariate) has thus tacitly entailed a transition from directional to\nnon-directional signal definition at the group level. While a directional\ngroup-level MVPA approach implies that individuals have similar multivariate\nspatial patterns of activity, in a non-directional approach each individual may\nhave a distinct spatial pattern. Using an experimental dataset, we show that\ndirectional and non-directional group-level MVPA approaches uncover distinct\nbrain regions with only partial overlap. We propose a method to quantify the\ndegree of spatial similarity in activation patterns over subjects. Applied to\nan auditory task, we find higher values in auditory regions compared to control\nregions.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 15:30:51 GMT"}, {"version": "v2", "created": "Tue, 6 Sep 2016 12:49:29 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Gilron", "Roee", ""], ["Rosenblatt", "Jonathan", ""], ["Koyejo", "Oluwasanmi", ""], ["Poldrack", "Russell A.", ""], ["Mukamel", "Roy", ""]]}, {"id": "1605.03553", "submitter": "Kieran Fox", "authors": "Kieran C.R. Fox, Yoona Kang, Michael Lifshitz, Kalina Christoff", "title": "Increasing cognitive-emotional flexibility with meditation and hypnosis:\n  The cognitive neuroscience of de-automatization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meditation and hypnosis both aim to facilitate cognitive-emotional\nflexibility, i.e., the \"de-automatization\" of thought and behavior. However,\nlittle research or theory has addressed how internal thought patterns might\nchange after such interventions, even though alterations in the internal flow\nof consciousness may precede externally observable changes in behavior. This\nchapter outlines three mechanisms by which meditation or hypnosis might alter\nor reduce automatic associations and elaborations of spontaneous thought: by an\noverall reduction of the chaining of thoughts into an associative stream; by\nde-automatizing and diversifying the content of thought chains (i.e.,\nincreasing thought flexibility or variety); and, finally, by re-automatizing\nchains of thought along desired or valued paths (i.e., forming new, voluntarily\nchosen mental habits). The authors discuss behavioral and cognitive\nneuroscientific evidence demonstrating the influence of hypnosis and meditation\non internal cognition and highlight the putative neurobiological basis, as well\nas potential benefits, of these forms of de-automatization.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 19:06:35 GMT"}], "update_date": "2016-05-12", "authors_parsed": [["Fox", "Kieran C. R.", ""], ["Kang", "Yoona", ""], ["Lifshitz", "Michael", ""], ["Christoff", "Kalina", ""]]}, {"id": "1605.03626", "submitter": "Gordon Berman", "authors": "Gordon J. Berman, William Bialek, and Joshua W. Shaevitz", "title": "Predictability and hierarchy in Drosophila behavior", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1607601113", "report-no": null, "categories": "physics.bio-ph cs.IT math.IT q-bio.NC stat.AP", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Even the simplest of animals exhibit behavioral sequences with complex\ntemporal dynamics. Prominent amongst the proposed organizing principles for\nthese dynamics has been the idea of a hierarchy, wherein the movements an\nanimal makes can be understood as a set of nested sub-clusters. Although this\ntype of organization holds potential advantages in terms of motion control and\nneural circuitry, measurements demonstrating this for an animal's entire\nbehavioral repertoire have been limited in scope and temporal complexity. Here,\nwe use a recently developed unsupervised technique to discover and track the\noccurrence of all stereotyped behaviors performed by fruit flies moving in a\nshallow arena. Calculating the optimally predictive representation of the fly's\nfuture behaviors, we show that fly behavior exhibits multiple time scales and\nis organized into a hierarchical structure that is indicative of its underlying\nbehavioral programs and its changing internal states.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2016 21:47:29 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Berman", "Gordon J.", ""], ["Bialek", "William", ""], ["Shaevitz", "Joshua W.", ""]]}, {"id": "1605.03952", "submitter": "Mattia Rigotti", "authors": "Mattia Rigotti and Stefano Fusi", "title": "Estimating the dimensionality of neural responses with fMRI Repetition\n  Suppression", "comments": "Appears in Proceedings of the 5th NIPS Workshop on Machine Learning\n  and Interpretation in Neuroimaging, Montreal, 2015", "journal-ref": null, "doi": null, "report-no": "MLINI/2015/10", "categories": "q-bio.QM q-bio.NC stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel method that exploits fMRI Repetition Suppression (RS-fMRI)\nto measure the dimensionality of the set response vectors, i.e. the dimension\nof the space of linear combinations of neural population activity patterns in\nresponse to specific task conditions. RS-fMRI measures the overlap between\nresponse vectors even in brain areas displaying no discernible average\ndifferential BOLD signal. We show how this property can be used to estimate the\nneural response dimensionality in areas lacking macroscopic spatial patterning.\nThe importance of dimensionality derives from how it relates to a neural\ncircuit's functionality. As we show, the dimensionality of the response vectors\nis predicted to be high in areas involved in multi-stream integration, while it\nis low in areas where inputs from independent sources do not interact or merely\noverlap linearly. Our method can be used to identify and functionally\ncharacterize cortical circuits that integrate multiple independent information\npathways.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2016 19:44:05 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Rigotti", "Mattia", ""], ["Fusi", "Stefano", ""]]}, {"id": "1605.04033", "submitter": "Ari Kahn", "authors": "Ari E. Kahn, Marcelo G. Mattar, Jean M. Vettel, Nicholas F. Wymbs,\n  Scott T. Grafton, and Danielle S. Bassett", "title": "Structural Pathways Supporting Swift Acquisition of New Visuo-Motor\n  Skills", "comments": "11 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human skill learning requires fine-scale coordination of distributed networks\nof brain regions that are directly linked to one another by white matter tracts\nto allow for effective information transmission. Yet how individual differences\nin these anatomical pathways may impact individual differences in learning\nremains far from understood. Here, we test the hypothesis that individual\ndifferences in the organization of structural networks supporting task\nperformance predict individual differences in the rate at which humans learn a\nvisuo-motor skill. Over the course of 6 weeks, twenty-two healthy adult\nsubjects practiced a discrete sequence production task, where they learned a\nsequence of finger movements based on discrete visual cues. We collected\nstructural imaging data during four MRI scanning sessions spaced approximately\ntwo weeks apart, and using deterministic tractography, structural networks were\ngenerated for each participant to identify streamlines that connect cortical\nand sub-cortical brain regions. We observed that increased white matter\nconnectivity linking early visual (but not motor) regions was associated with a\nfaster learning rate. Moreover, we observed that the strength of multi-edge\npaths between motor and visual modules was also correlated with learning rate,\nsupporting the role of polysynaptic connections in successful skill\nacquisition. Our results demonstrate that the combination of diffusion imaging\nand tractography-based connectivity can be used to predict future individual\ndifferences in learning capacity, particularly when combined with methods from\nnetwork science and graph theory.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 02:30:23 GMT"}, {"version": "v2", "created": "Mon, 24 Oct 2016 14:15:20 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Kahn", "Ari E.", ""], ["Mattar", "Marcelo G.", ""], ["Vettel", "Jean M.", ""], ["Wymbs", "Nicholas F.", ""], ["Grafton", "Scott T.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1605.04153", "submitter": "David Dahmen", "authors": "David Dahmen, Markus Diesmann, Moritz Helias", "title": "Distributions of covariances as a window into the operational regime of\n  neuronal networks", "comments": null, "journal-ref": "PNAS 116 (26) 13051-13060 (2019)", "doi": "10.1073/pnas.1818972116", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massively parallel recordings of spiking activity in cortical networks show\nthat covariances vary widely across pairs of neurons. Their low average is well\nunderstood, but an explanation for the wide distribution in relation to the\nstatic (quenched) disorder of the connectivity in recurrent random networks was\nso far elusive. We here derive a finite-size mean-field theory that reduces a\ndisordered to a highly symmetric network with fluctuating auxiliary fields. The\nexposed analytical relation between the statistics of connections and the\nstatistics of pairwise covariances shows that both, average and dispersion of\nthe latter, diverge at a critical coupling. At this point, a network of\nnonlinear units transits from regular to chaotic dynamics. Applying these\nresults to recordings from the mammalian brain suggests its operation close to\nthis edge of criticality.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 12:29:31 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Dahmen", "David", ""], ["Diesmann", "Markus", ""], ["Helias", "Moritz", ""]]}, {"id": "1605.04221", "submitter": "Francesca Mastrogiuseppe", "authors": "Francesca Mastrogiuseppe, Srdjan Ostojic", "title": "Intrinsically-generated fluctuating activity in excitatory-inhibitory\n  networks", "comments": null, "journal-ref": "PLOS Computational Biology 13(4): e1005498 (2017)", "doi": "10.1371/journal.pcbi.1005498", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent networks of non-linear units display a variety of dynamical regimes\ndepending on the structure of their synaptic connectivity. A particularly\nremarkable phenomenon is the appearance of strongly fluctuating, chaotic\nactivity in networks of deterministic, but randomly connected rate units. How\nthis type of intrinsi- cally generated fluctuations appears in more realistic\nnetworks of spiking neurons has been a long standing question. To ease the\ncomparison between rate and spiking networks, recent works investigated the\ndynami- cal regimes of randomly-connected rate networks with segregated\nexcitatory and inhibitory populations, and firing rates constrained to be\npositive. These works derived general dynamical mean field (DMF) equations\ndescribing the fluctuating dynamics, but solved these equations only in the\ncase of purely inhibitory networks. Using a simplified excitatory-inhibitory\narchitecture in which DMF equations are more easily tractable, here we show\nthat the presence of excitation qualitatively modifies the fluctuating activity\ncompared to purely inhibitory networks. In presence of excitation,\nintrinsically generated fluctuations induce a strong increase in mean firing\nrates, a phenomenon that is much weaker in purely inhibitory networks.\nExcitation moreover induces two different fluctuating regimes: for moderate\noverall coupling, recurrent inhibition is sufficient to stabilize fluctuations,\nfor strong coupling, firing rates are stabilized solely by the upper bound\nimposed on activity, even if inhibition is stronger than excitation. These\nresults extend to more general network architectures, and to rate networks\nreceiving noisy inputs mimicking spiking activity. Finally, we show that\nsignatures of the second dynamical regime appear in networks of\nintegrate-and-fire neurons.\n", "versions": [{"version": "v1", "created": "Fri, 13 May 2016 15:43:59 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 13:44:01 GMT"}, {"version": "v3", "created": "Tue, 9 May 2017 13:47:00 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Mastrogiuseppe", "Francesca", ""], ["Ostojic", "Srdjan", ""]]}, {"id": "1605.04463", "submitter": "Carina Curto", "authors": "Katherine Morrison, Anda Degeratu, Vladimir Itskov, and Carina Curto", "title": "Diversity of emergent dynamics in competitive threshold-linear networks:\n  a preliminary report", "comments": "12 pages, 9 figures. Preliminary report", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Threshold-linear networks consist of simple units interacting in the presence\nof a threshold nonlinearity. Competitive threshold-linear networks have long\nbeen known to exhibit multistability, where the activity of the network settles\ninto one of potentially many steady states. In this work, we find conditions\nthat guarantee the absence of steady states, while maintaining bounded\nactivity. These conditions lead us to define a combinatorial family of\ncompetitive threshold-linear networks, parametrized by a simple directed graph.\nBy exploring this family, we discover that threshold-linear networks are\ncapable of displaying a surprisingly rich variety of nonlinear dynamics,\nincluding limit cycles, quasiperiodic attractors, and chaos. In particular,\nseveral types of nonlinear behaviors can co-exist in the same network. Our\nmathematical results also enable us to engineer networks with multiple dynamic\npatterns. Taken together, these theoretical and computational findings suggest\nthat threshold-linear networks may be a valuable tool for understanding the\nrelationship between network connectivity and emergent dynamics.\n", "versions": [{"version": "v1", "created": "Sat, 14 May 2016 20:10:00 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Morrison", "Katherine", ""], ["Degeratu", "Anda", ""], ["Itskov", "Vladimir", ""], ["Curto", "Carina", ""]]}, {"id": "1605.04533", "submitter": "Andreea Ioana Sburlea", "authors": "Andreea Ioana Sburlea, Luis Montesano, Javier Minguez", "title": "Advantages of EEG phase patterns for the detection of gait intention in\n  healthy and stroke subjects", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One use of EEG-based brain-computer interfaces (BCIs) in rehabilitation is\nthe detection of movement intention. In this paper we investigate for the first\ntime the instantaneous phase of movement related cortical potential (MRCP) and\nits application to the detection of gait intention. We demonstrate the utility\nof MRCP phase in two independent datasets, in which 10 healthy subjects and 9\nchronic stroke patients executed a self-initiated gait task in three sessions.\nPhase features were compared to more conventional amplitude and power features.\nThe neurophysiology analysis showed that phase features have higher\nsignal-to-noise ratio than the other features. Also, BCI detectors of gait\nintention based on phase, amplitude, and their combination were evaluated under\nthree conditions: session specific calibration, intersession transfer, and\nintersubject transfer. Results show that the phase based detector is the most\naccurate for session specific calibration (movement intention was correctly\ndetected in 66.5% of trials in healthy subjects, and in 63.3% in stroke\npatients). However, in intersession and intersubject transfer, the detector\nthat combines amplitude and phase features is the most accurate one and the\nonly that retains its accuracy (62.5% in healthy subjects and 59% in stroke\npatients) w.r.t. session specific calibration. Thus, MRCP phase features\nimprove the detection of gait intention and could be used in practice to remove\ntime-consuming BCI recalibration.\n", "versions": [{"version": "v1", "created": "Sun, 15 May 2016 12:21:33 GMT"}], "update_date": "2016-05-17", "authors_parsed": [["Sburlea", "Andreea Ioana", ""], ["Montesano", "Luis", ""], ["Minguez", "Javier", ""]]}, {"id": "1605.04740", "submitter": "Vahid Rostami", "authors": "Vahid Rostami, PierGianLuca Porta Mana, Moritz Helias", "title": "Pairwise maximum-entropy models and their Glauber dynamics: bimodality,\n  bistability, non-ergodicity problems, and their elimination via inhibition", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1005762", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise maximum-entropy models have been used in recent neuroscientific\nliterature to predict the activity of neuronal populations, given only the\ntime-averaged correlations of the neuron activities. This paper provides\nevidence that the pairwise model, applied to experimental recordings, predicts\na bimodal distribution for the population-averaged activity, and for some\npopulation sizes the second mode peaks at high activities, with 90% of the\nneuron population active within time-windows of few milliseconds. This\nbimodality has several undesirable consequences: 1. The presence of two modes\nis unrealistic in view of observed neuronal activity. 2. The prediction of a\nhigh-activity mode is unrealistic on neurobiological grounds. 3. Boltzmann\nlearning becomes non-ergodic, hence the pairwise model found by this method is\nnot the maximum entropy distribution; similarly, solving the inverse problem by\ncommon variants of mean-field approximations has the same problem. 4. The\nGlauber dynamics associated with the model is either unrealistically bistable,\nor does not reflect the distribution of the pairwise model. This bimodality is\nfirst demonstrated for an experimental dataset comprising 159 neuron activities\nrecorded from the motor cortex of macaque monkey. Using a reduced\nmaximum-entropy model, evidence is then provided that this bimodality affects\ntypical neural recordings of population sizes of a couple of hundreds or more\nneurons. As a way to eliminate the bimodality and its ensuing problems, a\nmodified pairwise model is presented, which -- most important -- has an\nassociated pairwise Glauber dynamics. This model avoids bimodality thanks to a\nminimal asymmetric inhibition. It can be interpreted as a\nminimum-relative-entropy model with a particular prior, or as a maximum-entropy\nmodel with an additional constraint.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 11:58:55 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Rostami", "Vahid", ""], ["Mana", "PierGianLuca Porta", ""], ["Helias", "Moritz", ""]]}, {"id": "1605.05291", "submitter": "Jing Wu", "authors": "Jing Wu, Benjamin R. Shuman, Bingni W. Brunton, Katherine M. Steele,\n  Jared D. Olson, Rajesh P.N. Rao, Jeffrey G. Ojemann", "title": "Multistep Model for Predicting Upper-Limb 3D Isometric Force Application\n  from Pre-Movement Electrocorticographic Features", "comments": "4 pages, 3 figures, accepted to EMBC 2016 (38th Annual International\n  Conference of the IEEE Engineering in Medicine and Biology Society)", "journal-ref": null, "doi": "10.1109/EMBC.2016.7591010", "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural correlates of movement planning onset and direction may be present in\nhuman electrocorticography in the signal dynamics of both motor and non-motor\ncortical regions. We use a three-stage model of jPCA reduced-rank hidden Markov\nmodel (jPCA-RR-HMM), regularized shrunken-centroid discriminant analysis (RDA),\nand LASSO regression to extract direction-sensitive planning information and\nmovement onset in an upper-limb 3D isometric force task in a human subject.\nThis mode achieves a relatively high true positive force-onset prediction rate\nof 60% within 250ms, and an above-chance 36% accuracy (17% chance) in\npredicting one of six planned 3D directions of isometric force using\npre-movement signals. We also find direction-distinguishing information up to\n400ms before force onset in the pre-movement signals, captured by electrodes\nplaced over the limb-ipsilateral dorsal premotor regions. This approach can\ncontribute to more accurate decoding of higher-level movement goals, at earlier\ntimescales, and inform sensor placement. Our results also contribute to further\nunderstanding of the spatiotemporal features of human motor planning.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 19:14:03 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Wu", "Jing", ""], ["Shuman", "Benjamin R.", ""], ["Brunton", "Bingni W.", ""], ["Steele", "Katherine M.", ""], ["Olson", "Jared D.", ""], ["Rao", "Rajesh P. N.", ""], ["Ojemann", "Jeffrey G.", ""]]}, {"id": "1605.05335", "submitter": "Cheng Ly", "authors": "Cheng Ly, Gary Marsat", "title": "Variable Synaptic Strengths Controls the Firing Rate Distribution in\n  Feedforward Neural Networks", "comments": "28 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneity of firing rate statistics is known to have severe consequences\non neural coding. Recent experimental recordings in weakly electric fish\nindicate that the distribution-width of superficial pyramidal cell firing rates\n(trial- and time-averaged) in the electrosensory lateral line lobe (ELL)\ndepends on the stimulus, and also that network inputs can mediate changes in\nthe firing rate distribution across the population. We previously developed\ntheoretical methods to understand how two attributes (synaptic and intrinsic\nheterogeneity) interact and alter the firing rate distribution in a population\nof integrate-and-fire neurons with random recurrent coupling. Inspired by our\nexperimental data, we extend these theoretical results to a delayed feedforward\nspiking network that qualitatively capture the changes of firing rate\nheterogeneity observed in in-vivo recordings. We demonstrate how heterogeneous\nneural attributes alter firing rate heterogeneity, accounting for the effect\nwith various sensory stimuli. The model predicts how the strength of the\neffective network connectivity is related to intrinsic heterogeneity in such\ndelayed feedforward networks: the strength of the feedforward input is\npositively correlated with excitability (threshold value for spiking) with low\nfiring rate heterogeneity and is negatively correlated with excitability with\nhigh firing rate heterogeneity. We also show how our theory can be use to\npredict effective neural architecture. We demonstrate that neural attributes do\nnot interact in a simple manner but rather in a complex stimulus-dependent\nfashion to control neural heterogeneity and discuss how it can ultimately shape\npopulation codes.\n", "versions": [{"version": "v1", "created": "Tue, 17 May 2016 20:00:16 GMT"}, {"version": "v2", "created": "Mon, 30 Jan 2017 19:29:29 GMT"}, {"version": "v3", "created": "Wed, 10 May 2017 14:40:51 GMT"}, {"version": "v4", "created": "Fri, 11 Aug 2017 10:34:03 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Ly", "Cheng", ""], ["Marsat", "Gary", ""]]}, {"id": "1605.05644", "submitter": "Diego Paz\\'o", "authors": "Diego Paz\\'o and Ernest Montbri\\'o", "title": "From quasiperiodic partial synchronization to collective chaos in\n  populations of inhibitory neurons with delay", "comments": "5 pages", "journal-ref": "Phys. Rev. Lett. 116, 238101 (2016)", "doi": "10.1103/PhysRevLett.116.238101", "report-no": null, "categories": "nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective chaos is shown to emerge, via a period-doubling cascade, from\nquasiperiodic partial synchronization in a population of identical inhibitory\nneurons with delayed global coupling. This system is thoroughly investigated by\nmeans of an exact model of the macroscopic dynamics, valid in the thermodynamic\nlimit. The collective chaotic state is reproduced numerically with a finite\npopulation, and persists in the presence of weak heterogeneities. Finally, the\nrelationship of the model's dynamics with fast neuronal oscillations is\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 18 May 2016 16:21:55 GMT"}, {"version": "v2", "created": "Wed, 8 Jun 2016 07:23:19 GMT"}], "update_date": "2016-06-09", "authors_parsed": [["Paz\u00f3", "Diego", ""], ["Montbri\u00f3", "Ernest", ""]]}, {"id": "1605.06544", "submitter": "Xaq Pitkow", "authors": "Rajkumar Vasudeva Raju and Xaq Pitkow", "title": "Inference by Reparameterization in Neural Population Codes", "comments": "9 pages, 6 figures, submitted to NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Behavioral experiments on humans and animals suggest that the brain performs\nprobabilistic inference to interpret its environment. Here we present a new\ngeneral-purpose, biologically-plausible neural implementation of approximate\ninference. The neural network represents uncertainty using Probabilistic\nPopulation Codes (PPCs), which are distributed neural representations that\nnaturally encode probability distributions, and support marginalization and\nevidence integration in a biologically-plausible manner. By connecting multiple\nPPCs together as a probabilistic graphical model, we represent multivariate\nprobability distributions. Approximate inference in graphical models can be\naccomplished by message-passing algorithms that disseminate local information\nthroughout the graph. An attractive and often accurate example of such an\nalgorithm is Loopy Belief Propagation (LBP), which uses local marginalization\nand evidence integration operations to perform approximate inference\nefficiently even for complex models. Unfortunately, a subtle feature of LBP\nrenders it neurally implausible. However, LBP can be elegantly reformulated as\na sequence of Tree-based Reparameterizations (TRP) of the graphical model. We\nre-express the TRP updates as a nonlinear dynamical system with both fast and\nslow timescales, and show that this produces a neurally plausible solution. By\ncombining all of these ideas, we show that a network of PPCs can represent\nmultivariate probability distributions and implement the TRP updates to perform\nprobabilistic inference. Simulations with Gaussian graphical models demonstrate\nthat the neural network inference quality is comparable to the direct\nevaluation of LBP and robust to noise, and thus provides a promising mechanism\nfor general probabilistic inference in the population codes of the brain.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2016 21:38:32 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Raju", "Rajkumar Vasudeva", ""], ["Pitkow", "Xaq", ""]]}, {"id": "1605.06708", "submitter": "Agostinho Rosa", "authors": "Andre Rosado and Agostinho C Rosa", "title": "Automatic Detection of Epileptiform Discharges in the EEG", "comments": "6 pages, 7 figures and 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diagnosis of epilepsy generally includes a visual inspection of EEG\nrecorded data by the Neurologist, with the purpose of checking the occurrence\nof transient waveforms called interictal epileptiform discharges. These\nwaveforms have short duration (less than 100 ms), so the inspection process is\nusually time-consuming, particularly for ambulatory long term EEG records.\nTherefore, an automatic detection system of epileptiform discharges can be a\nvaluable tool for a Neurology service. The proposed approach is the development\nof a multi stage detection algorithm, which processes the complete EEG signals\nand applies decision criteria to selected waveforms. It employs EEG analysis\ntechniques such as Wavelet Transform and Mimetic Analysis, complemented with a\nclassification based on Fuzzy Logic. In order to evaluate the algorithm's\nperformance, data were collected from several epileptic patients, with\nepileptiform activity marked by a Neurologist. The average values obtained for\nboth Sensitivity and Specificity were respectively higher than 80 and 70\npercent.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2016 22:49:47 GMT"}], "update_date": "2016-06-08", "authors_parsed": [["Rosado", "Andre", ""], ["Rosa", "Agostinho C", ""]]}, {"id": "1605.06758", "submitter": "Moritz Helias", "authors": "Jannis Schuecker, Sven Goedeke, David Dahmen, Moritz Helias", "title": "Functional methods for disordered neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks of the brain form one of the most complex systems we know.\nMany qualitative features of the emerging collective phenomena, such as\ncorrelated activity, stability, response to inputs, chaotic and regular\nbehavior, can, however, be understood in simple models that are accessible to a\ntreatment in statistical mechanics, or, more precisely, classical statistical\nfield theory.\n  This tutorial presents the fundamentals behind contemporary developments in\nthe theory of neural networks of rate units that are based on methods from\nstatistical mechanics of classical systems with a large number of interacting\ndegrees of freedom. In particular we will focus on a relevant class of systems\nthat have quenched (time independent) disorder. In neural networks, the main\nsource of disorder arises from random synaptic couplings between neurons. These\nsystems are in many respects similar to spin glasses. The tutorial therefore\nalso explains the methods for these disordered systems as far as they are\napplied in neuroscience.\n  The presentation consists of two parts. In the first part we introduce\nstochastic differential equations in the Martin - Siggia - Rose - De Dominicis\n- Janssen path integral formalism. In the second part we employ this language\nto derive the dynamic mean-field theory for deterministic random networks, the\nbasis of the seminal work by Sompolinsky, Crisanti, Sommers 1988, as well as a\nrecent extension to stochastic dynamics.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2016 08:31:39 GMT"}, {"version": "v2", "created": "Wed, 15 Jun 2016 07:44:56 GMT"}], "update_date": "2016-06-16", "authors_parsed": [["Schuecker", "Jannis", ""], ["Goedeke", "Sven", ""], ["Dahmen", "David", ""], ["Helias", "Moritz", ""]]}, {"id": "1605.06925", "submitter": "Lorenz K. Muller", "authors": "Lorenz K. Muller and Giacomo Indiveri", "title": "Neural Sampling by Irregular Gating Inhibition of Spiking Neurons and\n  Attractor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A long tradition in theoretical neuroscience casts sensory processing in the\nbrain as the process of inferring the maximally consistent interpretations of\nimperfect sensory input. Recently it has been shown that Gamma-band inhibition\ncan enable neural attractor networks to approximately carry out such a sampling\nmechanism. In this paper we propose a novel neural network model based on\nirregular gating inhibition, show analytically how it implements a Monte-Carlo\nMarkov Chain (MCMC) sampler, and describe how it can be used to model networks\nof both neural attractors as well as of single spiking neurons. Finally we show\nhow this model applied to spiking neurons gives rise to a new putative\nmechanism that could be used to implement stochastic synaptic weights in\nbiological neural networks and in neuromorphic hardware.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 07:54:46 GMT"}, {"version": "v2", "created": "Thu, 8 Sep 2016 07:13:07 GMT"}, {"version": "v3", "created": "Thu, 31 Aug 2017 08:43:49 GMT"}, {"version": "v4", "created": "Fri, 1 Sep 2017 06:39:55 GMT"}], "update_date": "2017-09-04", "authors_parsed": [["Muller", "Lorenz K.", ""], ["Indiveri", "Giacomo", ""]]}, {"id": "1605.07074", "submitter": "Pedro Antonio Vald\\'es-Hern\\'andez", "authors": "Pedro A. Valdes-Hernandez, Thomas Knoesche", "title": "Initial conditions in the neural field model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spite of the large amount of existing neural models in the literature,\nthere is a lack of a systematic review of the possible effect of choosing\ndifferent initial conditions on the dynamic evolution of neural systems. In\nthis short review we intend to give insights into this topic by discussing some\npublished examples. First, we briefly introduce the different ingredients of a\nneural dynamical model. Secondly, we introduce some concepts used to describe\nthe dynamic behavior of neural models, namely phase space and its portraits,\ntime series, spectra, multistability and bifurcations. We end with an analysis\nof the irreversibility of processes and its implications on the functioning of\nnormal and pathological brains.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 16:15:21 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Valdes-Hernandez", "Pedro A.", ""], ["Knoesche", "Thomas", ""]]}, {"id": "1605.07094", "submitter": "Sebastian Weichwald", "authors": "Sebastian Weichwald, Tatiana Fomina, Bernhard Sch\\\"olkopf, Moritz\n  Grosse-Wentrup", "title": "A note on the expected minimum error probability in equientropic\n  channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT cs.LG math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the channel capacity reflects a theoretical upper bound on the\nachievable information transmission rate in the limit of infinitely many bits,\nit does not characterise the information transfer of a given encoding routine\nwith finitely many bits. In this note, we characterise the quality of a code\n(i. e. a given encoding routine) by an upper bound on the expected minimum\nerror probability that can be achieved when using this code. We show that for\nequientropic channels this upper bound is minimal for codes with maximal\nmarginal entropy. As an instructive example we show for the additive white\nGaussian noise (AWGN) channel that random coding---also a capacity achieving\ncode---indeed maximises the marginal entropy in the limit of infinite messages.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 17:04:57 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 16:55:42 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Weichwald", "Sebastian", ""], ["Fomina", "Tatiana", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Grosse-Wentrup", "Moritz", ""]]}, {"id": "1605.07153", "submitter": "Kieran Fox", "authors": "Kieran C.R. Fox, Manesh Girn, Cameron C. Parro, Kalina Christoff", "title": "Functional neuroimaging of psychedelic experience: An overview of\n  psychological and neural effects and their relevance to research on\n  creativity, daydreaming, and dreaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans have employed an incredible variety of plant-derived substances over\nthe millennia in order to alter consciousness and perception. Among the\ninnumerable narcotics, analgesics, 'ordeal' drugs, and other psychoactive\nsubstances discovered and used in ritualistic contexts by cultures around the\nworld, one class in particular stands out not only for its radical\npsychological effects, but also for the highly charged political and legal\natmosphere that has surrounded it since its widespread adoption about 50 years\nago: so-called psychedelic substances. We review functional neuroimaging\ninvestigations of the neural correlates of the psychedelic experience, and\nhighlight relationships with the psychological and neural bases of creativity,\ndaydreaming, and dreaming.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2016 19:39:19 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Fox", "Kieran C. R.", ""], ["Girn", "Manesh", ""], ["Parro", "Cameron C.", ""], ["Christoff", "Kalina", ""]]}, {"id": "1605.07266", "submitter": "Pengcheng Zhou", "authors": "Pengcheng Zhou, Shanna L. Resendez, Jose Rodriguez-Romaguera, Jessica\n  C. Jimenez, Shay Q. Neufeld, Garret D. Stuber, Rene Hen, Mazen A. Kheirbek,\n  Bernardo L. Sabatini, Robert E. Kass, Liam Paninski", "title": "Efficient and accurate extraction of in vivo calcium signals from\n  microendoscopic video data", "comments": "The image has been compressed for meeting arXiv requirements. A pdf\n  version with higher resolution image can be downloaded here\n  https://zhoupc.github.io/data/zhou2016.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In vivo calcium imaging through microscopes has enabled deep brain imaging of\npreviously inaccessible neuronal populations within the brains of freely moving\nsubjects. However, microendoscopic data suffer from high levels of background\nfluorescence as well as an increased potential for overlapping neuronal\nsignals. Previous methods fail in identifying neurons and demixing their\ntemporal activity because the cellular signals are often submerged in the large\nfluctuating background. Here we develop an efficient method to extract cellular\nsignals with minimal influence from the background. We model the background\nwith two realistic components: (1) one models the constant baseline and slow\ntrends of each pixel, and (2) the other models the fast fluctuations from\nout-of-focus signals and is therefore constrained to have low spatial-frequency\nstructure. This decomposition avoids cellular signals being absorbed into the\nbackground term. After subtracting the background approximated with this model,\nwe use Constrained Nonnegative Matrix Factorization (CNMF, Pnevmatikakis et al.\n(2016)) to better demix neural signals and get their denoised and deconvolved\ntemporal activity. We validate our method on simulated and experimental data,\nwhere it shows fast, reliable, and high quality signal extraction under a wide\nvariety of imaging parameters.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 02:35:09 GMT"}, {"version": "v2", "created": "Thu, 25 May 2017 20:22:54 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Zhou", "Pengcheng", ""], ["Resendez", "Shanna L.", ""], ["Rodriguez-Romaguera", "Jose", ""], ["Jimenez", "Jessica C.", ""], ["Neufeld", "Shay Q.", ""], ["Stuber", "Garret D.", ""], ["Hen", "Rene", ""], ["Kheirbek", "Mazen A.", ""], ["Sabatini", "Bernardo L.", ""], ["Kass", "Robert E.", ""], ["Paninski", "Liam", ""]]}, {"id": "1605.07371", "submitter": "Jan Humplik", "authors": "Jan Humplik, Ga\\v{s}per Tka\\v{c}ik", "title": "Semiparametric energy-based probabilistic models", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic models can be defined by an energy function, where the\nprobability of each state is proportional to the exponential of the state's\nnegative energy. This paper considers a generalization of energy-based models\nin which the probability of a state is proportional to an arbitrary positive,\nstrictly decreasing, and twice differentiable function of the state's energy.\nThe precise shape of the nonlinear map from energies to unnormalized\nprobabilities has to be learned from data together with the parameters of the\nenergy function. As a case study we show that the above generalization of a\nfully visible Boltzmann machine yields an accurate model of neural activity of\nretinal ganglion cells. We attribute this success to the model's ability to\neasily capture distributions whose probabilities span a large dynamic range, a\npossible consequence of latent variables that globally couple the system.\nSimilar features have recently been observed in many datasets, suggesting that\nour new method has wide applicability.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 10:51:13 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Humplik", "Jan", ""], ["Tka\u010dik", "Ga\u0161per", ""]]}, {"id": "1605.07383", "submitter": "Diego Fasoli", "authors": "Diego Fasoli, Anna Cattani, Stefano Panzeri", "title": "From Local Chaos to Critical Slowing Down: A Theory of the Functional\n  Connectivity of Small Neural Circuits", "comments": "24 pages, 5 figures; compiled version of the Supplementary Materials\n  added (12 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional connectivity is a fundamental property of neural networks that\nquantifies the segregation and integration of information between cortical\nareas. Due to mathematical complexity, a theory that could explain how the\nparameters of mesoscopic networks composed of a few tens of neurons affect the\nfunctional connectivity is still to be formulated. Yet, many interesting\nproblems in neuroscience involve the study of networks composed of a small\nnumber of neurons. Based on a recent study of the dynamics of small neural\ncircuits, we combine the analysis of local bifurcations of multi-population\nneural networks of arbitrary size with the analytical calculation of the\nfunctional connectivity. We study the functional connectivity in different\nregimes, showing that external stimuli cause the network to switch from\nasynchronous states characterized by weak correlation and low variability\n(local chaos), to synchronous states characterized by strong correlations and\nwide temporal fluctuations (critical slowing down). Local chaos typically\noccurs in large networks, but here we show that it can also be generated by\nstrong stimuli in small neural circuits. On the other side, critical slowing\ndown is expected to occur when the stimulus moves the network close to a local\nbifurcation. In particular, strongly positive correlations occur at the\nsaddle-node and Andronov-Hopf bifurcations of the network, while strongly\nnegative correlations occur when the network undergoes a spontaneous\nsymmetry-breaking at the branching-point bifurcations. These results prove that\nthe functional connectivity of firing-rate network models is strongly affected\nby the external stimuli even if the anatomical connections are fixed, and\nsuggest an effective mechanism through which biological networks can\ndynamically modulate the encoding and integration of sensory information.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 11:22:08 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 15:42:02 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Fasoli", "Diego", ""], ["Cattani", "Anna", ""], ["Panzeri", "Stefano", ""]]}, {"id": "1605.07977", "submitter": "C\\'elian Bimbard", "authors": "C\\'elian Bimbard, Erwan Ledoux, and Srdjan Ostojic", "title": "Instability to a heterogeneous oscillatory state in randomly connected\n  recurrent networks with delayed interactions", "comments": null, "journal-ref": "Phys. Rev. E 94, 062207 (2016)", "doi": "10.1103/PhysRevE.94.062207", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oscillatory dynamics are ubiquitous in biological networks. Possible sources\nof oscillations are well understood in low-dimensional systems, but have not\nbeen fully explored in high-dimensional networks. Here we study large networks\nconsisting of randomly coupled rate units. We identify a novel type of\nbifurcation in which a continuous part of the eigenvalue spectrum of the linear\nstability matrix crosses the instability line at non-zero-frequency. This\nbifurcation occurs when the interactions are delayed and partially\nanti-symmetric, and leads to a heterogeneous oscillatory state in which\noscillations are apparent in the activity of individual units, but not on the\npopulation-average level.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 17:39:36 GMT"}, {"version": "v2", "created": "Mon, 12 Sep 2016 16:52:24 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["Bimbard", "C\u00e9lian", ""], ["Ledoux", "Erwan", ""], ["Ostojic", "Srdjan", ""]]}, {"id": "1605.08031", "submitter": "Kameron Harris", "authors": "Kameron Decker Harris and Stefan Mihalas and Eric Shea-Brown", "title": "High resolution neural connectivity from incomplete tracing data using\n  nonnegative spline regression", "comments": "Supplement at\n  https://github.com/kharris/high-res-connectivity-nips-2016", "journal-ref": "NIPS, 2016", "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whole-brain neural connectivity data are now available from viral tracing\nexperiments, which reveal the connections between a source injection site and\nelsewhere in the brain. These hold the promise of revealing spatial patterns of\nconnectivity throughout the mammalian brain. To achieve this goal, we seek to\nfit a weighted, nonnegative adjacency matrix among 100 $\\mu$m brain \"voxels\"\nusing viral tracer data. Despite a multi-year experimental effort, injections\nprovide incomplete coverage, and the number of voxels in our data is orders of\nmagnitude larger than the number of injections, making the problem severely\nunderdetermined. Furthermore, projection data are missing within the injection\nsite because local connections there are not separable from the injection\nsignal.\n  We use a novel machine-learning algorithm to meet these challenges and\ndevelop a spatially explicit, voxel-scale connectivity map of the mouse visual\nsystem. Our method combines three features: a matrix completion loss for\nmissing data, a smoothing spline penalty to regularize the problem, and\n(optionally) a low rank factorization. We demonstrate the consistency of our\nestimator using synthetic data and then apply it to newly available Allen Mouse\nBrain Connectivity Atlas data for the visual system. Our algorithm is\nsignificantly more predictive than current state of the art approaches which\nassume regions to be homogeneous. We demonstrate the efficacy of a low rank\nversion on visual cortex data and discuss the possibility of extending this to\na whole-brain connectivity matrix at the voxel scale.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2016 21:16:19 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 17:33:02 GMT"}, {"version": "v3", "created": "Wed, 26 Oct 2016 19:12:02 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Harris", "Kameron Decker", ""], ["Mihalas", "Stefan", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1605.08104", "submitter": "William Lotter", "authors": "William Lotter, Gabriel Kreiman, David Cox", "title": "Deep Predictive Coding Networks for Video Prediction and Unsupervised\n  Learning", "comments": "Code and example video clips can be found here:\n  https://coxlab.github.io/prednet/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While great strides have been made in using deep learning algorithms to solve\nsupervised learning tasks, the problem of unsupervised learning - leveraging\nunlabeled examples to learn about the structure of a domain - remains a\ndifficult unsolved challenge. Here, we explore prediction of future frames in a\nvideo sequence as an unsupervised learning rule for learning about the\nstructure of the visual world. We describe a predictive neural network\n(\"PredNet\") architecture that is inspired by the concept of \"predictive coding\"\nfrom the neuroscience literature. These networks learn to predict future frames\nin a video sequence, with each layer in the network making local predictions\nand only forwarding deviations from those predictions to subsequent network\nlayers. We show that these networks are able to robustly learn to predict the\nmovement of synthetic (rendered) objects, and that in doing so, the networks\nlearn internal representations that are useful for decoding latent object\nparameters (e.g. pose) that support object recognition with fewer training\nviews. We also show that these networks can scale to complex natural image\nstreams (car-mounted camera videos), capturing key aspects of both egocentric\nmovement and the movement of objects in the visual scene, and the\nrepresentation learned in this setting is useful for estimating the steering\nangle. Altogether, these results suggest that prediction represents a powerful\nframework for unsupervised learning, allowing for implicit learning of object\nand scene structure.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2016 23:58:55 GMT"}, {"version": "v2", "created": "Tue, 14 Jun 2016 14:36:09 GMT"}, {"version": "v3", "created": "Tue, 30 Aug 2016 00:08:34 GMT"}, {"version": "v4", "created": "Wed, 31 Aug 2016 16:06:03 GMT"}, {"version": "v5", "created": "Wed, 1 Mar 2017 01:00:54 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Lotter", "William", ""], ["Kreiman", "Gabriel", ""], ["Cox", "David", ""]]}, {"id": "1605.08228", "submitter": "Angelo Valleriani", "authors": "Marco Rusconi, Angelo Valleriani", "title": "Predict or classify: The deceptive role of time-locking in brain signal\n  classification", "comments": "23 pages, 5 figures", "journal-ref": "Scientific Reports 6, 28236 (2016)", "doi": "10.1038/srep28236", "report-no": null, "categories": "q-bio.NC physics.bio-ph stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several experimental studies claim to be able to predict the outcome of\nsimple decisions from brain signals measured before subjects are aware of their\ndecision. Often, these studies use multivariate pattern recognition methods\nwith the underlying assumption that the ability to classify the brain signal is\nequivalent to predict the decision itself. Here we show instead that it is\npossible to correctly classify a signal even if it does not contain any\npredictive information about the decision. We first define a simple stochastic\nmodel that mimics the random decision process between two equivalent\nalternatives, and generate a large number of independent trials that contain no\nchoice-predictive information. The trials are first time-locked to the time\npoint of the final event and then classified using standard machine-learning\ntechniques. The resulting classification accuracy is above chance level long\nbefore the time point of time-locking. We then analyze the same trials using\ninformation theory. We demonstrate that the high classification accuracy is a\nconsequence of time-locking and that its time behavior is simply related to the\nlarge relaxation time of the process. We conclude that when time-locking is a\ncrucial step in the analysis of neural activity patterns, both the emergence\nand the timing of the classification accuracy are affected by structural\nproperties of the network that generates the signal.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 11:17:41 GMT"}, {"version": "v2", "created": "Fri, 10 Jun 2016 12:23:34 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Rusconi", "Marco", ""], ["Valleriani", "Angelo", ""]]}, {"id": "1605.08454", "submitter": "Yuanjun Gao", "authors": "Yuanjun Gao, Evan Archer, Liam Paninski, John P. Cunningham", "title": "Linear dynamical neural population models through nonlinear embeddings", "comments": "NIPS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A body of recent work in modeling neural activity focuses on recovering\nlow-dimensional latent features that capture the statistical structure of\nlarge-scale neural populations. Most such approaches have focused on linear\ngenerative models, where inference is computationally tractable. Here, we\npropose fLDS, a general class of nonlinear generative models that permits the\nfiring rate of each neuron to vary as an arbitrary smooth function of a latent,\nlinear dynamical state. This extra flexibility allows the model to capture a\nricher set of neural variability than a purely linear model, but retains an\neasily visualizable low-dimensional latent space. To fit this class of\nnon-conjugate models we propose a variational inference scheme, along with a\nnovel approximate posterior capable of capturing rich temporal correlations\nacross time. We show that our techniques permit inference in a wide class of\ngenerative models.We also show in application to two neural datasets that,\ncompared to state-of-the-art neural population models, fLDS captures a much\nlarger proportion of neural variability with a small number of latent\ndimensions, providing superior predictive performance and interpretability.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2016 21:25:26 GMT"}, {"version": "v2", "created": "Tue, 25 Oct 2016 19:44:03 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Gao", "Yuanjun", ""], ["Archer", "Evan", ""], ["Paninski", "Liam", ""], ["Cunningham", "John P.", ""]]}, {"id": "1605.08909", "submitter": "Mih\\'aly B\\'anyai", "authors": "Mih\\'aly B\\'anyai, Zsombor Koman, Gerg\\H{o} Orb\\'an", "title": "Response statistics dissect the contributions of different sources of\n  variability to population activity in V1", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Response variability, as measured by fluctuating responses upon repeated\nperformance of trials, is a major component of neural responses, and its\ncharacterization is key to interpret high dimensional population recordings.\nResponse variability and covariability display predictable changes upon changes\nin stimulus and cognitive or behavioral state, providing an opportunity to test\nthe predictive power of models of neural variability. Still, there is little\nagreement on which model to use as a building block for population-level\nanalyses, and models of variability are often treated as a subject of choice.\nWe investigate two competing models, the Doubly Stochastic Poisson (DSP) model\nassuming stochasticity at spike generation, and the Rectified Gaussian (RG)\nmodel that traces variability back to membrane potential variance, to analyze\nstimulus-dependent modulation of response statistics. Using a model of a pair\nof neurons, we demonstrate that the two models predict similar single-cell\nstatistics. However, DSP and RG models have contradicting predictions on the\njoint statistics of spiking responses. In order to test the models against\ndata, we build a population model to simulate stimulus change-related\nmodulations in response statistics. We use unit recordings from the primary\nvisual cortex of monkeys to show that while model predictions for variance are\nqualitatively similar to experimental data, only the RG model's predictions are\ncompatible with joint statistics. These results suggest that models using\nPoisson-like variability might fail to capture important properties of response\nstatistics. We argue that membrane potential-level modelling of stochasticity\nprovides an efficient strategy to model correlations.\n", "versions": [{"version": "v1", "created": "Sat, 28 May 2016 16:05:16 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["B\u00e1nyai", "Mih\u00e1ly", ""], ["Koman", "Zsombor", ""], ["Orb\u00e1n", "Gerg\u0151", ""]]}, {"id": "1605.09023", "submitter": "Caroline Holmes", "authors": "Kyle H. Srivastava, Caroline M. Holmes, Michiel Vellema, Andrea Pack,\n  Coen P. H. Elemans, Ilya Nemenman, and Samuel J. Sober", "title": "Motor control by precisely timed spike patterns", "comments": "48 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in neuroscience is to understand how sequences of\naction potentials (\"spikes\") encode information about sensory signals and motor\noutputs. Although traditional theories of neural coding assume that information\nis conveyed by the total number of spikes fired (spike rate), recent studies of\nsensory and motor activity have shown that far more information is carried by\nthe millisecond-scale timing patterns of action potentials (spike timing).\nHowever, it is unknown whether or how subtle differences in spike timing drive\ndifferences in perception or behavior, leaving it unclear whether the\ninformation carried by spike timing actually plays a causal role in brain\nfunction. Here we demonstrate how a precise spike timing code is read out\ndownstream by the muscles to control behavior. We provide both correlative and\ncausal evidence to show that the nervous system uses millisecond-scale\nvariations in the timing of spikes within multi-spike patterns to regulate a\nrelatively simple behavior - respiration in the Bengalese finch, a songbird.\nThese findings suggest that a fundamental assumption of current theories of\nmotor coding requires revision, and that significant improvements in\napplications, such as neural prosthetic devices, can be achieved by using\nprecise spike timing information.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 16:21:03 GMT"}, {"version": "v2", "created": "Tue, 31 May 2016 01:40:35 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Srivastava", "Kyle H.", ""], ["Holmes", "Caroline M.", ""], ["Vellema", "Michiel", ""], ["Pack", "Andrea", ""], ["Elemans", "Coen P. H.", ""], ["Nemenman", "Ilya", ""], ["Sober", "Samuel J.", ""]]}, {"id": "1605.09073", "submitter": "Yu Hu", "authors": "Yu Hu, Steven L. Brunton, Nicholas Cain, Stefan Mihalas, J. Nathan\n  Kutz, Eric Shea-Brown", "title": "Feedback through graph motifs relates structure and function in complex\n  networks", "comments": "31 pages, 20 figures", "journal-ref": "Phys. Rev. E 98, 062312 (2018)", "doi": "10.1103/PhysRevE.98.062312", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In physics, biology and engineering, network systems abound. How does the\nconnectivity of a network system combine with the behavior of its individual\ncomponents to determine its collective function? We approach this question for\nnetworks with linear time-invariant dynamics by relating internal network\nfeedbacks to the statistical prevalence of connectivity motifs, a set of\nsurprisingly simple and local statistics of connectivity. This results in a\nreduced order model of the network input-output dynamics in terms of motifs\nstructures. As an example, the new formulation dramatically simplifies the\nclassic Erdos-Renyi graph, reducing the overall network behavior to one\nproportional feedback wrapped around the dynamics of a single node. For general\nnetworks, higher-order motifs systematically provide further layers and types\nof feedback to regulate the network response. Thus, the local connectivity\nshapes temporal and spectral processing by the network as a whole, and we show\nhow this enables robust, yet tunable, functionality such as extending the time\nconstant with which networks remember past signals. The theory also extends to\nnetworks composed from heterogeneous nodes with distinct dynamics and\nconnectivity, and patterned input to (and readout from) subsets of nodes. These\nstatistical descriptions provide a powerful theoretical framework to understand\nthe functionality of real-world network systems, as we illustrate with examples\nincluding the mouse brain connectome.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2016 22:58:04 GMT"}, {"version": "v2", "created": "Tue, 18 Dec 2018 16:33:43 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Hu", "Yu", ""], ["Brunton", "Steven L.", ""], ["Cain", "Nicholas", ""], ["Mihalas", "Stefan", ""], ["Kutz", "J. Nathan", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1605.09282", "submitter": "Stephen Hanson", "authors": "S.J. Hanson, D. Mastrovito, C. Hanson, J. Ramsey, and C. Glymour", "title": "Scale-Free Exponents of Resting State provide a Biomarker for Typical\n  and Atypical Brain Activity", "comments": "23 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scale-free networks (SFN) arise from simple growth processes, which can\nencourage efficient, centralized and fault tolerant communication (1). Recently\nits been shown that stable network hub structure is governed by a phase\ntransition at exponents (>2.0) causing a dramatic change in network structure\nincluding a loss of global connectivity, an increasing minimum dominating node\nset, and a shift towards increasing connectivity growth compared to node\ngrowth. Is this SFN shift identifiable in atypical brain activity? The Pareto\nDistribution (P(D)~D^-\\b{eta}) on the hub Degree (D) is a signature of\nscale-free networks. During resting-state, we assess Degree exponents across a\nlarge range of neurotypical and atypical subjects. We use graph complexity\ntheory to provide a predictive theory of the brain network structure. Results.\nWe show that neurotypical resting-state fMRI brain activity possess scale-free\nPareto exponents (1.8 se .01) in a single individual scanned over 66 days as\nwell as in 60 different individuals (1.8 se .02). We also show that 60\nindividuals with Autistic Spectrum Disorder, and 60 individuals with\nSchizophrenia have significantly higher (>2.0) scale-free exponents (2.4 se\n.03, 2.3 se .04), indicating more fractionated and less controllable dynamics\nin the brain networks revealed in resting state. Finally we show that the\nexponent values vary with phenotypic measures of atypical disease severity\nindicating that the global topology of the network itself can provide specific\ndiagnostic biomarkers for atypical brain activity.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 15:38:15 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Hanson", "S. J.", ""], ["Mastrovito", "D.", ""], ["Hanson", "C.", ""], ["Ramsey", "J.", ""], ["Glymour", "C.", ""]]}, {"id": "1605.09312", "submitter": "Jeffrey Herron", "authors": "Jeffrey Herron, Anca Velisar, Mahsa Malekmohammadi, Helen\n  Bronte-Stewart, Howard Jay Chizeck", "title": "A Metric for Evaluating and Comparing Closed-Loop Deep Brain Stimulation\n  Algorithms", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: Closed-loop deep brain stimulation (DBS) may improve current\nclinical DBS treatment for neurological movement disorders, but control\nalgorithms may perform differently across patients. New metrics are needed for\ncomparing and evaluating closed-loop algorithm performance that address the\nspecific needs of closed-loop neuromodulation controllers. Approach: A metric\nis proposed for system performance that includes normalized terms that can be\nused to compare algorithm performance for a patient. This metric was evaluated\nusing two closed-loop control algorithms that were tested in patients with\nParkinson's Disease (PD) who experience rest tremor. Main Results: The metric's\nresulting balance between tremor treatment and power savings varied on a per\npatient and algorithm basis. This was expected given how each trial resulted in\na variable reduction in stimulation power at the cost of additional tremor for\nthe patient when compared to open-loop stimulation. Significance: The proposed\nmetric will aid in clinical evaluation of new algorithms and provide a\nbenchmark for future system designers. This will be important given the growing\npotential applications of dynamically adjusted neural stimulation.\nClinicalTrials.gov Identifier: NCT02384421.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2016 18:15:24 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Herron", "Jeffrey", ""], ["Velisar", "Anca", ""], ["Malekmohammadi", "Mahsa", ""], ["Bronte-Stewart", "Helen", ""], ["Chizeck", "Howard Jay", ""]]}, {"id": "1605.09353", "submitter": "Maria Luisa Saggio", "authors": "Maria Luisa Saggio, Andreas Spiegler, Christophe Bernard, Viktor K.\n  Jirsa", "title": "Fast-slow bursters in the unfolding of a high codimension singularity\n  and the ultra-slow transitions of classes", "comments": "22 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bursting is a phenomenon found in a variety of physical and biological\nsystems. For example, in neuroscience, bursting is believed to play a key role\nin the way information is transferred in the nervous system. In this work, we\npropose a model that, appropriately tuned, can display several types of\nbursting behaviors. The model contains two subsystems acting at different\ntimescales. For the fast subsystem we use the planar unfolding of a high\ncodimension singularity. In its bifurcation diagram, we locate paths that\nunderly the right sequence of bifurcations necessary for bursting. The slow\nsubsystem steers the fast one back and forth along these paths leading to\nbursting behavior. The model is able to produce almost all the classes of\nbursting predicted for systems with a planar fast subsystems. Transitions\nbetween classes can be obtained through an ultra-slow modulation of the model's\nparameters. A detailed exploration of the parameter space allows predicting\npossible transitions. This provides a single framework to understand the\ncoexistence of diverse bursting patterns in physical and biological systems or\nin models.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2016 18:55:42 GMT"}], "update_date": "2016-05-31", "authors_parsed": [["Saggio", "Maria Luisa", ""], ["Spiegler", "Andreas", ""], ["Bernard", "Christophe", ""], ["Jirsa", "Viktor K.", ""]]}]