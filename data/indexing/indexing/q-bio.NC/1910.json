[{"id": "1910.00003", "submitter": "Manouchehr Zaker", "authors": "Manouchehr Zaker", "title": "A memory theoretic approach for investigating the roles of language and\n  intuition in mathematical thinking activities", "comments": "19 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Questions concerning origin of mathematical knowledge and roles of language\nand intuition (imagery) in mathematical thoughts are long standing and widely\ndebated. By introspection, mathematicians usually have some beliefs regarding\nthese questions. But these beliefs are usually in a big contrast with the\nrecent cognitive theoretic findings concerning mathematics. Contemporary\ncognitive science opens new approaches to reformulate the fundamental questions\nconcerning mathematics and helps mathematicians break through the Platonic\nbeliefs about the essence and sources of mathematical knowledge. In this\narticle, we introduce and discuss mathematical thinking activities and\nfundamental processes such as symbolic/formal and visual/spatial ones. Two\ndifferent aspects of mathematics should be separated in mathematical cognition.\nOne aspect considers mathematics as an explicit crystallized knowledge. The\nother aspect considers mathematics as an ongoing and transient mental\nprocessing. The cognitive processes and corresponding tasks involved in these\naspects are different. Ongoing mathematical activities both elementary and\nadvanced, demand working memory resources. Using dual-task techniques, we\ndesign some pilot experiments to differentiate the symbolic/formal and\nvisual/spatial processes. Using this memory theoretic approach, we explain the\ncrucial roles of language-based processes such as verbal articulation and\ninstructive speech and also visuo-spatial intuition such as spatial imagery and\nmental movement in various aspects of mathematics.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2019 09:02:30 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Zaker", "Manouchehr", ""]]}, {"id": "1910.00122", "submitter": "Katarzyna Kozdon Mx", "authors": "Katarzyna Kozdon and Peter Bentley", "title": "Normalisation of Weights and Firing Rates in Spiking Neural Networks\n  with Spike-Timing-Dependent Plasticity", "comments": "Developmental Neural Networks Workshop, The 2019 Conference on\n  Artificial Life (ALife 2019). Newcastle, United Kingdom", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining the ability to fire sparsely is crucial for information encoding\nin neural networks. Additionally, spiking homeostasis is vital for spiking\nneural networks with changing numbers of weights and neurons. We discuss a\nrange of network stabilisation approaches, inspired by homeostatic synaptic\nplasticity mechanisms reported in the brain. These include weight scaling, and\nweight change as a function of the network's spiking activity. We tested\nnormalisation of the sum of weights for all neurons, and by neuron type. We\nexamined how this approach affects firing rate and performance on clustering of\ntime-series data in the form of moving geometric shapes. We found that neuron\ntype-specific normalisation is a promising approach for preventing weight drift\nin spiking neural networks, thus enabling longer training cycles. It can be\nadapted for networks with architectural plasticity.\n", "versions": [{"version": "v1", "created": "Mon, 30 Sep 2019 21:44:55 GMT"}], "update_date": "2019-10-02", "authors_parsed": [["Kozdon", "Katarzyna", ""], ["Bentley", "Peter", ""]]}, {"id": "1910.01244", "submitter": "Jon Gauthier", "authors": "Jon Gauthier and Roger Levy", "title": "Linking artificial and human neural representations of language", "comments": "EMNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What information from an act of sentence understanding is robustly\nrepresented in the human brain? We investigate this question by comparing\nsentence encoding models on a brain decoding task, where the sentence that an\nexperimental participant has seen must be predicted from the fMRI signal evoked\nby the sentence. We take a pre-trained BERT architecture as a baseline sentence\nencoding model and fine-tune it on a variety of natural language understanding\n(NLU) tasks, asking which lead to improvements in brain-decoding performance.\n  We find that none of the sentence encoding tasks tested yield significant\nincreases in brain decoding performance. Through further task ablations and\nrepresentational analyses, we find that tasks which produce syntax-light\nrepresentations yield significant improvements in brain decoding performance.\nOur results constrain the space of NLU models that could best account for human\nneural representations of language, but also suggest limits on the possibility\nof decoding fine-grained syntactic information from fMRI human neuroimaging.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2019 22:36:51 GMT"}], "update_date": "2019-10-04", "authors_parsed": [["Gauthier", "Jon", ""], ["Levy", "Roger", ""]]}, {"id": "1910.01559", "submitter": "Jesus Malo", "authors": "Jesus Malo", "title": "Spatio-Chromatic Information available from different Neural Layers via\n  Gaussianization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How much visual information about the retinal images can be extracted from\nthe different layers of the visual pathway?. Separate subsystems (e.g. opponent\nchannels, spatial filters, nonlinearities of the texture sensors) have been\nsuggested to be organized for optimal information transmission. However, the\nefficiency of these different layers has not been measured when they operate\ntogether on colorimetrically calibrated natural images and using multivariate\ninformation-theoretic units over the joint spatio-chromatic array of responses.\n  In this work we present a statistical tool to address this question in an\nappropriate (multivariate) way. Specifically, we propose an empirical estimate\nof the information transmitted by the system based on a recent Gaussianization\ntechnique that reduces the challenging multivariate PDF estimation problem to a\nset of simpler univariate estimations. Total correlation measured using the\nproposed estimator is consistent with predictions based on the analytical\nJacobian of a standard spatio-chromatic model of the retina-cortex pathway. If\nthe noise at certain representation is proportional to the dynamic range of the\nresponse, and one assumes sensors of equivalent noise level, transmitted\ninformation shows the following trends: (1) progressively deeper\nrepresentations are better in terms of the amount of information about the\ninput, (2) the transmitted information up to the cortical representation\nfollows the PDF of natural scenes over the chromatic and achromatic dimensions\nof the stimulus space, (3) the contribution of spatial transforms to capture\nvisual information is substantially bigger than the contribution of chromatic\ntransforms, and (4) nonlinearities of the responses contribute substantially to\nthe transmitted information but less than the linear transforms.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 15:51:43 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 17:36:31 GMT"}, {"version": "v3", "created": "Mon, 25 May 2020 12:44:57 GMT"}], "update_date": "2020-05-26", "authors_parsed": [["Malo", "Jesus", ""]]}, {"id": "1910.01618", "submitter": "Alexandre Ren\\'e", "authors": "Alexandre Ren\\'e, Andr\\'e Longtin and Jakob H. Macke", "title": "Inference of a mesoscopic population model from population spike trains", "comments": "1st revision: 48 pages, 13 figures Improved statistical validation of\n  results. Rewrite of Section 4.2 to clarify the link between the mesoscopic\n  model and a transport equation. Multiple small improvements to the\n  presentation Original: 46 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand how rich dynamics emerge in neural populations, we require\nmodels exhibiting a wide range of activity patterns while remaining\ninterpretable in terms of connectivity and single-neuron dynamics. However, it\nhas been challenging to fit such mechanistic spiking networks at the single\nneuron scale to empirical population data. To close this gap, we propose to fit\nsuch data at a meso scale, using a mechanistic but low-dimensional and hence\nstatistically tractable model. The mesoscopic representation is obtained by\napproximating a population of neurons as multiple homogeneous `pools' of\nneurons, and modelling the dynamics of the aggregate population activity within\neach pool. We derive the likelihood of both single-neuron and connectivity\nparameters given this activity, which can then be used to either optimize\nparameters by gradient ascent on the log-likelihood, or to perform Bayesian\ninference using Markov Chain Monte Carlo (MCMC) sampling. We illustrate this\napproach using a model of generalized integrate-and-fire neurons for which\nmesoscopic dynamics have been previously derived, and show that both\nsingle-neuron and connectivity parameters can be recovered from simulated data.\nIn particular, our inference method extracts posterior correlations between\nmodel parameters, which define parameter subsets able to reproduce the data. We\ncompute the Bayesian posterior for combinations of parameters using MCMC\nsampling and investigate how the approximations inherent to a mesoscopic\npopulation model impact the accuracy of the inferred single-neuron parameters.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 17:37:42 GMT"}, {"version": "v2", "created": "Sun, 8 Mar 2020 22:40:14 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Ren\u00e9", "Alexandre", ""], ["Longtin", "Andr\u00e9", ""], ["Macke", "Jakob H.", ""]]}, {"id": "1910.01689", "submitter": "Jordan Guerguiev", "authors": "Jordan Guerguiev, Konrad P. Kording, Blake A. Richards", "title": "Spike-based causal inference for weight alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In artificial neural networks trained with gradient descent, the weights used\nfor processing stimuli are also used during backward passes to calculate\ngradients. For the real brain to approximate gradients, gradient information\nwould have to be propagated separately, such that one set of synaptic weights\nis used for processing and another set is used for backward passes. This\nproduces the so-called \"weight transport problem\" for biological models of\nlearning, where the backward weights used to calculate gradients need to mirror\nthe forward weights used to process stimuli. This weight transport problem has\nbeen considered so hard that popular proposals for biological learning assume\nthat the backward weights are simply random, as in the feedback alignment\nalgorithm. However, such random weights do not appear to work well for large\nnetworks. Here we show how the discontinuity introduced in a spiking system can\nlead to a solution to this problem. The resulting algorithm is a special case\nof an estimator used for causal inference in econometrics, regression\ndiscontinuity design. We show empirically that this algorithm rapidly makes the\nbackward weights approximate the forward weights. As the backward weights\nbecome correct, this improves learning performance over feedback alignment on\ntasks such as Fashion-MNIST, SVHN, CIFAR-10 and VOC. Our results demonstrate\nthat a simple learning rule in a spiking network can allow neurons to produce\nthe right backward connections and thus solve the weight transport problem.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 19:07:58 GMT"}, {"version": "v2", "created": "Sun, 2 Feb 2020 01:05:15 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Guerguiev", "Jordan", ""], ["Kording", "Konrad P.", ""], ["Richards", "Blake A.", ""]]}, {"id": "1910.01724", "submitter": "Yiyin Zhou", "authors": "Aurel A. Lazar and Nikul H. Ukani and Yiyin Zhou", "title": "Sparse Identification of Contrast Gain Control in the Fruit Fly\n  Photoreceptor and Amacrine Cell Layer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The fruit fly's natural visual environment is often characterized by light\nintensities ranging across several orders of magnitude and by rapidly varying\ncontrast across space and time. Fruit fly photoreceptors robustly transduce\nand, in conjunction with amacrine cells, process visual scenes and provide the\nresulting signal to downstream targets. Here we model the first step of visual\nprocessing in the photoreceptor-amacrine cell layer. We propose a novel\ndivisive normalization processor (DNP) for modeling the computation taking\nplace in the photoreceptor-amacrine cell layer. The DNP explicitly models the\nphotoreceptor feedforward and temporal feedback processing paths and the\nspatio-temporal feedback path of the amacrine cells. We then formally\ncharacterize the contrast gain control of the DNP and provide sparse\nidentification algorithms that can efficiently identify each the feedforward\nand feedback DNP components. The algorithms presented here are the first\ndemonstration of tractable and robust identification of the components of a\ndivisive normalization processor. The sparse identification algorithms can be\nreadily employed in experimental settings, and their effectiveness is\ndemonstrated with several examples.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 21:20:05 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Lazar", "Aurel A.", ""], ["Ukani", "Nikul H.", ""], ["Zhou", "Yiyin", ""]]}, {"id": "1910.01914", "submitter": "Hicham Janati", "authors": "Hicham Janati, Thomas Bazeille, Bertrand Thirion, Marco Cuturi,\n  Alexandre Gramfort", "title": "Multi-subject MEG/EEG source imaging with sparse multi-task regression", "comments": "version 2. arXiv admin note: text overlap with arXiv:1902.04812", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Magnetoencephalography and electroencephalography (M/EEG) are non-invasive\nmodalities that measure the weak electromagnetic fields generated by neural\nactivity. Estimating the location and magnitude of the current sources that\ngenerated these electromagnetic fields is a challenging ill-posed regression\nproblem known as \\emph{source imaging}. When considering a group study, a\ncommon approach consists in carrying out the regression tasks independently for\neach subject. An alternative is to jointly localize sources for all subjects\ntaken together, while enforcing some similarity between them. By pooling all\nmeasurements in a single multi-task regression, one makes the problem better\nposed, offering the ability to identify more sources and with greater\nprecision. The Minimum Wasserstein Estimates (MWE) promotes focal activations\nthat do not perfectly overlap for all subjects, thanks to a regularizer based\non Optimal Transport (OT) metrics. MWE promotes spatial proximity on the\ncortical mantel while coping with the varying noise levels across subjects. On\nrealistic simulations, MWE decreases the localization error by up to 4 mm per\nsource compared to individual solutions. Experiments on the Cam-CAN dataset\nshow a considerable improvement in spatial specificity in population imaging.\nOur analysis of a multimodal dataset shows how multi-subject source\nlocalization closes the gap between MEG and fMRI for brain mapping.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2019 07:20:29 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2019 08:38:09 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Janati", "Hicham", ""], ["Bazeille", "Thomas", ""], ["Thirion", "Bertrand", ""], ["Cuturi", "Marco", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1910.02058", "submitter": "Markus Frey", "authors": "Markus Frey, Matthias Nau", "title": "Memory efficient brain tumor segmentation using an\n  autoencoder-regularized U-Net", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Early diagnosis and accurate segmentation of brain tumors are imperative for\nsuccessful treatment. Unfortunately, manual segmentation is time consuming,\ncostly and despite extensive human expertise often inaccurate. Here, we present\nan MRI-based tumor segmentation framework using an autoencoder-regularized\n3D-convolutional neural network. We trained the model on manually segmented\nstructural T1, T1ce, T2, and Flair MRI images of 335 patients with tumors of\nvariable severity, size and location. We then tested the model using\nindependent data of 125 patients and successfully segmented brain tumors into\nthree subregions: the tumor core (TC), the enhancing tumor (ET) and the whole\ntumor (WT). We also explored several data augmentations and preprocessing steps\nto improve segmentation performance. Importantly, our model was implemented on\na single NVIDIA GTX1060 graphics unit and hence optimizes tumor segmentation\nfor widely affordable hardware. In sum, we present a memory-efficient and\naffordable solution to tumor segmentation to support the accurate diagnostics\nof oncological brain pathologies.\n", "versions": [{"version": "v1", "created": "Fri, 4 Oct 2019 17:33:07 GMT"}], "update_date": "2019-10-07", "authors_parsed": [["Frey", "Markus", ""], ["Nau", "Matthias", ""]]}, {"id": "1910.02532", "submitter": "Jesse Geerts", "authors": "Jesse P. Geerts, Kimberly L. Stachenfeld, Neil Burgess", "title": "Probabilistic Successor Representations with Kalman Temporal Differences", "comments": "Conference on Cognitive Computational Neuroscience", "journal-ref": null, "doi": "10.32470/CCN.2019.1323-0", "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of Reinforcement Learning (RL) depends on an animal's\nability to assign credit for rewards to the appropriate preceding stimuli. One\naspect of understanding the neural underpinnings of this process involves\nunderstanding what sorts of stimulus representations support generalisation.\nThe Successor Representation (SR), which enforces generalisation over states\nthat predict similar outcomes, has become an increasingly popular model in this\nspace of inquiries. Another dimension of credit assignment involves\nunderstanding how animals handle uncertainty about learned associations, using\nprobabilistic methods such as Kalman Temporal Differences (KTD). Combining\nthese approaches, we propose using KTD to estimate a distribution over the SR.\nKTD-SR captures uncertainty about the estimated SR as well as covariances\nbetween different long-term predictions. We show that because of this, KTD-SR\nexhibits partial transition revaluation as humans do in this experiment without\nadditional replay, unlike the standard TD-SR algorithm. We conclude by\ndiscussing future applications of the KTD-SR as a model of the interaction\nbetween predictive and probabilistic animal reasoning.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2019 21:32:46 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Geerts", "Jesse P.", ""], ["Stachenfeld", "Kimberly L.", ""], ["Burgess", "Neil", ""]]}, {"id": "1910.02768", "submitter": "Chika Koyama", "authors": "Chika Koyama, Taichi Haruna, Satoshi Hagihira, Kazuto Yamashita", "title": "New EEG parameters correlated with sevoflurane concentration in dogs:\n  tau and burst", "comments": "20pages,2 tables, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Electroencephalographic (EEG) indicators for anaesthesia depth\nare being developed. Here, we propose novel EEG parameters created by using two\nkinds of waveforms discriminated by voltage thresholds from a new perspective.\nMethods: Six young-adult beagles and 6 senior beagles were anaesthetised with\nend-tidal sevoflurane (SEV) of 2.0%-4.0% in 0.5% intervals, and 2-channel EEG\n(256 Hz) was recorded. Two events were discriminated: a consecutive part\n({\\tau}) with a peak-to-peak potential difference (Vpp) within 1-6, 8, 12, or\n20 mcrV, and another part (burst) with Vpp outside the threshold. Number of\n{\\tau} (N{\\tau}), mean {\\tau} duration (M{\\tau}), total percentage of {\\tau}\n(SR{\\tau}), mean burst duration (Mbst), and amplitude of burst (Abst) were\nevaluated as anaesthesia depth indicators using Pearsons correlation\ncoefficients (r). Results: When Vpp was near the suppression wave threshold,\nN{\\tau} had the highest correlation with SEV in both groups. As SEV was\nincreased until onset of burst suppression, N{\\tau} decreased, M{\\tau} remained\nunchanged, and Mbst and Abst increased. In the young-adult group, mean |r|\nexceeded 0.95 for N{\\tau} with Vpp of 4-6 mcrV, for Mbst with Vpp of 8-12 mcrV,\nand for Abst with Vpp of 4-12 mcrV. In the senior group, r exceeded 0.90 for\nN{\\tau} with Vpp of 4 mcrV and for Abst with Vpp of 5-12 mcrV. Conclusion: We\ndeveloped new EEG parameters that were almost perfectly correlated with\nvolatile anaesthetic concentrations using traditional bipolar recording. This\nstudy suggests that the effect of anaesthetics on EEG can be investigated from\ntwo directions: pacemaker ({\\tau}) and generator (burst).\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 13:12:29 GMT"}], "update_date": "2019-10-08", "authors_parsed": [["Koyama", "Chika", ""], ["Haruna", "Taichi", ""], ["Hagihira", "Satoshi", ""], ["Yamashita", "Kazuto", ""]]}, {"id": "1910.03349", "submitter": "Jessica Dafflon", "authors": "Jessica Dafflon, Walter H.L Pinaya, Federico Turkheimer, James H.\n  Cole, Robert Leech, Mathew A. Harris, Simon R. Cox, Heather C. Whalley,\n  Andrew M. McIntosh, Peter J. Hellyer", "title": "Analysis of an Automated Machine Learning Approach in Brain Predictive\n  Modelling: A data-driven approach to Predict Brain Age from Cortical\n  Anatomical Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of machine learning (ML) algorithms has significantly increased in\nneuroscience. However, from the vast extent of possible ML algorithms, which\none is the optimal model to predict the target variable? What are the\nhyperparameters for such a model? Given the plethora of possible answers to\nthese questions, in the last years, automated machine learning (autoML) has\nbeen gaining attention. Here, we apply an autoML library called TPOT which uses\na tree-based representation of machine learning pipelines and conducts a\ngenetic-programming based approach to find the model and its hyperparameters\nthat more closely predicts the subject's true age. To explore autoML and\nevaluate its efficacy within neuroimaging datasets, we chose a problem that has\nbeen the focus of previous extensive study: brain age prediction. Without any\nprior knowledge, TPOT was able to scan through the model space and create\npipelines that outperformed the state-of-the-art accuracy for Freesurfer-based\nmodels using only thickness and volume information for anatomical structure. In\nparticular, we compared the performance of TPOT (mean accuracy error (MAE):\n$4.612 \\pm .124$ years) and a Relevance Vector Regression (MAE $5.474 \\pm .140$\nyears). TPOT also suggested interesting combinations of models that do not\nmatch the current most used models for brain prediction but generalise well to\nunseen data. AutoML showed promising results as a data-driven approach to find\noptimal models for neuroimaging applications.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 11:54:43 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Dafflon", "Jessica", ""], ["Pinaya", "Walter H. L", ""], ["Turkheimer", "Federico", ""], ["Cole", "James H.", ""], ["Leech", "Robert", ""], ["Harris", "Mathew A.", ""], ["Cox", "Simon R.", ""], ["Whalley", "Heather C.", ""], ["McIntosh", "Andrew M.", ""], ["Hellyer", "Peter J.", ""]]}, {"id": "1910.03577", "submitter": "Jin Ming", "authors": "Suprateek Kundu, Jin Ming, and Jennifer Stevens", "title": "Dynamic Brain Functional Networks Guided By Anatomical Knowledge", "comments": "45 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the potential of dynamic brain networks as a neuroimaging\nbiomarkers for mental illnesses is being increasingly recognized. However,\nthere are several unmet challenges in developing such biomarkers, including the\nneed for methods to model rapidly changing network states. In one of the first\nsuch efforts, we develop a novel approach for computing dynamic brain\nfunctional connectivity (FC), that is guided by brain structural connectivity\n(SC) computed from diffusion tensor imaging (DTI) data. The proposed approach\ninvolving dynamic Gaussian graphical models decomposes the time course into\nnon-overlapping state phases determined by change points, each having a\ndistinct network. We develop an optimization algorithm to implement the method\nsuch that the estimation of both the change points and the state-phase specific\nnetworks are fully data driven and unsupervised, and guided by SC information.\nThe approach is scalable to large dimensions and extensive simulations\nillustrate its clear advantages over existing methods in terms of network\nestimation accuracy and detecting dynamic network changes. An application of\nthe method to a posttraumatic stress disorder (PTSD) study reveals important\ndynamic resting state connections in regions of the brain previously implicated\nin PTSD. We also illustrate that the dynamic networks computed under the\nproposed method are able to better predict psychological resilience among\ntrauma exposed individuals compared to existing dynamic and stationary\nconnectivity approaches, which highlights its potential as a neuroimaging\nbiomarker.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2019 21:48:27 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Kundu", "Suprateek", ""], ["Ming", "Jin", ""], ["Stevens", "Jennifer", ""]]}, {"id": "1910.03866", "submitter": "Leonie Henschel", "authors": "Leonie Henschel, Sailesh Conjeti, Santiago Estrada, Kersten Diers,\n  Bruce Fischl, Martin Reuter", "title": "FastSurfer -- A fast and accurate deep learning based neuroimaging\n  pipeline", "comments": "Submitted to NeuroImage", "journal-ref": null, "doi": "10.1016/j.neuroimage.2020.117012", "report-no": null, "categories": "eess.IV cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional neuroimage analysis pipelines involve computationally intensive,\ntime-consuming optimization steps, and thus, do not scale well to large cohort\nstudies with thousands or tens of thousands of individuals. In this work we\npropose a fast and accurate deep learning based neuroimaging pipeline for the\nautomated processing of structural human brain MRI scans, replicating\nFreeSurfer's anatomical segmentation including surface reconstruction and\ncortical parcellation. To this end, we introduce an advanced deep learning\narchitecture capable of whole brain segmentation into 95 classes. The network\narchitecture incorporates local and global competition via competitive dense\nblocks and competitive skip pathways, as well as multi-slice information\naggregation that specifically tailor network performance towards accurate\nsegmentation of both cortical and sub-cortical structures. Further, we perform\nfast cortical surface reconstruction and thickness analysis by introducing a\nspectral spherical embedding and by directly mapping the cortical labels from\nthe image to the surface. This approach provides a full FreeSurfer alternative\nfor volumetric analysis (in under 1 minute) and surface-based thickness\nanalysis (within only around 1h runtime). For sustainability of this approach\nwe perform extensive validation: we assert high segmentation accuracy on\nseveral unseen datasets, measure generalizability and demonstrate increased\ntest-retest reliability, and high sensitivity to group differences in dementia.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 09:41:14 GMT"}, {"version": "v2", "created": "Thu, 19 Mar 2020 15:57:59 GMT"}, {"version": "v3", "created": "Fri, 1 May 2020 10:32:33 GMT"}, {"version": "v4", "created": "Fri, 29 May 2020 13:45:00 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Henschel", "Leonie", ""], ["Conjeti", "Sailesh", ""], ["Estrada", "Santiago", ""], ["Diers", "Kersten", ""], ["Fischl", "Bruce", ""], ["Reuter", "Martin", ""]]}, {"id": "1910.03913", "submitter": "Taiping Zeng", "authors": "Taiping Zeng, and Bailu Si", "title": "A Brain-Inspired Compact Cognitive Mapping System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the robot explores the environment, the map grows over time in the\nsimultaneous localization and mapping (SLAM) system, especially for the large\nscale environment. The ever-growing map prevents long-term mapping. In this\npaper, we developed a compact cognitive mapping approach inspired by\nneurobiological experiments. Inspired from neighborhood cells, neighborhood\nfields determined by movement information, i.e. translation and rotation, are\nproposed to describe one of distinct segments of the explored environment. The\nvertices and edges with movement information below the threshold of the\nneighborhood fields are avoided adding to the cognitive map. The optimization\nof the cognitive map is formulated as a robust non-linear least squares\nproblem, which can be efficiently solved by the fast open linear solvers as a\ngeneral problem. According to the cognitive decision-making of familiar\nenvironments, loop closure edges are clustered depending on time intervals, and\nthen parallel computing is applied to perform batch global optimization of the\ncognitive map for ensuring the efficiency of computation and real-time\nperformance. After the loop closure process, scene integration is performed, in\nwhich revisited vertices are removed subsequently to further reduce the size of\nthe cognitive map. A monocular visual SLAM system is developed to test our\napproach in a rat-like maze environment. Our results suggest that the method\nlargely restricts the growth of the size of the cognitive map over time, and\nmeanwhile, the compact cognitive map correctly represents the overall layer of\nthe environment as the standard one. Experiments demonstrate that our method is\nvery suited for compact cognitive mapping to support long-term robot mapping.\nOur approach is simple, but pragmatic and efficient for achieving the compact\ncognitive map.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2019 11:49:50 GMT"}], "update_date": "2019-10-10", "authors_parsed": [["Zeng", "Taiping", ""], ["Si", "Bailu", ""]]}, {"id": "1910.04463", "submitter": "Mojtaba Chehelcheraghi", "authors": "Mojtaba Chehelcheraghi, Chie Nakatani, Cees van Leeuwen", "title": "Increasing the Detectability of Phase-Amplitude Coupling", "comments": "24 Pages 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: In electrical brain signals such as Local Field Potential (LFP)\nand Electroencephalogram (EEG), oscillations emerge as a result of neural\nnetwork activity. The oscillations extend over several frequency bands. Between\ntheir dominant components, various couplings can be observed. Of these,\nPhase-Amplitude Coupling (PAC) is intensively studied in relation to brain\nfunction. In the time-frequency domain, however, PAC measurement faces a\ndilemma in the choice of filter bandwidth. For a frequency m modulating a\nfrequency n, filters narrowly tuned around the latter frequency will miss the\nmodulatory components at frequencies n+m and n-m; wide band tuning will pass\nincreasing levels of noise. New Method: Our CFC measurement uses three\nidentical narrow band filters with center frequencies located on n-m, n, and\nn+m. The method therefore is free from the bandwidth dilemma. Comparison with\nExisting Method(s): The method was tested on diagnostic artificial signals\nmodeled on local field potentials and compared with four established PAC\ndetection algorithms. While the proposed method detected the simulated PAC in\nhigh frequency resolution, the other methods detected with poor frequency\nresolution, or completely missed the PAC. Conclusion: Using the proposed\ntriplet-filter banks instead of wideband filtering allows for high resolution\ndetection of PAC. Moreover, the method successfully detected PAC in wide range\nof modulation frequency. Finally, bandwidth is not chosen subjectively in our\nnew method which makes the comparison of PAC more convenient among different\nstudies.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 10:10:51 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Chehelcheraghi", "Mojtaba", ""], ["Nakatani", "Chie", ""], ["van Leeuwen", "Cees", ""]]}, {"id": "1910.04571", "submitter": "Taiping Zeng", "authors": "Taiping Zeng, XiaoLi Li, and Bailu Si", "title": "Experience Dependent Formation of Global Coherent Representation of\n  Environment by Grid Cells and Head Direction Cells", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The grid firing patterns are thought to provide an efficient intrinsic metric\ncapable of supporting universal spatial metric for mammalian spatial navigation\nin all environments. However, whether spatial representations of grid cells in\nthe entorhinal cortex are determined by local environment cues or form globally\ncoherent patterns remains undetermined. To explore this underlying mechanism,\nhere we proposed a possible theoretical explanation to describe connection\nbetween the neural space and the physical environment and transition from a\nlocal anchored to a global coherent representation according to relationship\nbetween grid phase distance between physical distance in the physical\nenvironment, and tested our method based on simultaneous localization and\nmapping (SLAM) system on a iRat rodent-sized robot platform in a rat-like maze.\nOur robotic exploration experiments show that the grid firing firstly is\ndetermined by local environment cues, and after self-correction with\nexperience-dependence, the regular, continuous grid firing patterns tessellate\nthe explored space. Head direction (HD) cells also show global patterns in our\nexperimental results. Our results support that grid firing patterns do provide\na universal spatial metric for mammalian spatial navigation in complex\nenvironments. The results in this study also provide insights into\nexperience-dependent interactions between path integrative calculation of\nlocation in the entorhinal cortex and learned associations to the external\nsensory cues in the hippocampus, which is likely to be critical understanding\nspatial memory, even episodic memory.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 13:54:19 GMT"}, {"version": "v2", "created": "Fri, 11 Oct 2019 01:35:25 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Zeng", "Taiping", ""], ["Li", "XiaoLi", ""], ["Si", "Bailu", ""]]}, {"id": "1910.04590", "submitter": "Taiping Zeng", "authors": "Taiping Zeng, XiaoLi Li, and Bailu Si", "title": "Learning Sparse Spatial Codes for Cognitive Mapping Inspired by\n  Entorhinal-Hippocampal Neurocircuit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The entorhinal-hippocampal circuit plays a critical role in higher brain\nfunctions, especially spatial cognition. Grid cells in the medial entorhinal\ncortex (MEC) periodically fire with different grid spacing and orientation,\nwhich makes a contribution that place cells in the hippocampus can uniquely\nencode locations in an environment. But how sparse firing granule cells in the\ndentate gyrus are formed from grid cells in the MEC remains to be determined.\nRecently, the fruit fly olfactory circuit provides a variant algorithm (called\nlocality-sensitive hashing) to solve this problem. To investigate how the\nsparse place firing generates in the dentate gyrus can help animals to break\nthe perception ambiguity during environment exploration, we build a\nbiologically relevant, computational model from grid cells to place cells. The\nweight from grid cells to dentate gyrus granule cells is learned by competitive\nHebbian learning. We resorted to the robot system for demonstrating our\ncognitive mapping model on the KITTI odometry benchmark dataset. The\nexperimental results show that our model is able to stably, robustly build a\ncoherent semi-metric topological map in the large-scale outdoor environment.\nThe experimental results suggest that the entorhinal-hippocampal circuit as a\nvariant locality-sensitive hashing algorithm is capable of generating sparse\nencoding for easily distinguishing different locations in the environment. Our\nexperiments also provide theoretical supports that this analogous hashing\nalgorithm may be a general principle of computation in different brain regions\nand species.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:18:08 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Zeng", "Taiping", ""], ["Li", "XiaoLi", ""], ["Si", "Bailu", ""]]}, {"id": "1910.04597", "submitter": "Ben Glocker", "authors": "Ben Glocker, Robert Robinson, Daniel C. Castro, Qi Dou, Ender\n  Konukoglu", "title": "Machine Learning with Multi-Site Imaging Data: An Empirical Study on the\n  Impact of Scanner Effects", "comments": "Presented at the Medical Imaging meets NeurIPS Workshop 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.CV cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is an empirical study to investigate the impact of scanner effects when\nusing machine learning on multi-site neuroimaging data. We utilize structural\nT1-weighted brain MRI obtained from two different studies, Cam-CAN and UK\nBiobank. For the purpose of our investigation, we construct a dataset\nconsisting of brain scans from 592 age- and sex-matched individuals, 296\nsubjects from each original study. Our results demonstrate that even after\ncareful pre-processing with state-of-the-art neuroimaging pipelines a\nclassifier can easily distinguish between the origin of the data with very high\naccuracy. Our analysis on the example application of sex classification\nsuggests that current approaches to harmonize data are unable to remove\nscanner-specific bias leading to overly optimistic performance estimates and\npoor generalization. We conclude that multi-site data harmonization remains an\nopen challenge and particular care needs to be taken when using such data with\nadvanced machine learning methods for predictive modelling.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:24:42 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Glocker", "Ben", ""], ["Robinson", "Robert", ""], ["Castro", "Daniel C.", ""], ["Dou", "Qi", ""], ["Konukoglu", "Ender", ""]]}, {"id": "1910.04844", "submitter": "Kevin Hannay", "authors": "Kevin M. Hannay, Daniel B. Forger, Victoria Booth", "title": "Seasonality and Light Phase-Resetting in the Mammalian Circadian Rhythm", "comments": "17 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the impact of light on the mammalian circadian system using the\ntheory of phase response curves. Using a recently developed ansatz we derive a\nlow-dimensional macroscopic model for the core circadian clock in mammals.\nSignificantly, the variables and parameters in our model have physiological\ninterpretations and may be compared with experimental results. We focus on the\neffect of four key factors which help shape the mammalian phase response to\nlight: heterogeneity in the population of oscillators, the structure of the\ntypical light phase response curve, the fraction of oscillators which receive\ndirect light input and changes in the coupling strengths associated with\nseasonal day-lengths. We find these factors can explain several experimental\nresults and provide insight into the processing of light information in the\nmammalian circadian system. In particular, we find that the sensitivity of the\ncircadian system to light may be modulated by changes in the relative coupling\nforces between the light sensing and non-sensing populations. Finally, we show\nhow seasonal day-length, after-effects to light entrainment and seasonal\nvariations in light sensitivity in the mammalian circadian clock are\ninterrelated.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 20:40:45 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Hannay", "Kevin M.", ""], ["Forger", "Daniel B.", ""], ["Booth", "Victoria", ""]]}, {"id": "1910.04992", "submitter": "Emre Baspinar", "authors": "E. Baspinar, A. Sarti, G. Citti", "title": "A sub-Riemannian model of the visual cortex with frequency and phase", "comments": null, "journal-ref": null, "doi": "10.1186/s13408-020-00089-6", "report-no": null, "categories": "q-bio.NC cs.CV math.AP math.DG math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel model of the primary visual cortex (V1)\nbased on orientation, frequency and phase selective behavior of the V1 simple\ncells. We start from the first level mechanisms of visual perception: receptive\nprofiles. The model interprets V1 as a fiber bundle over the 2-dimensional\nretinal plane by introducing orientation, frequency and phase as intrinsic\nvariables. Each receptive profile on the fiber is mathematically interpreted as\na rotated, frequency modulated and phase shifted Gabor function. We start from\nthe Gabor function and show that it induces in a natural way the model geometry\nand the associated horizontal connectivity modeling the neural connectivity\npatterns in V1. We provide an image enhancement algorithm employing the model\nframework. The algorithm is capable of exploiting not only orientation but also\nfrequency and phase information existing intrinsically in a 2-dimensional input\nimage. We provide the experimental results corresponding to the enhancement\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 06:41:11 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Baspinar", "E.", ""], ["Sarti", "A.", ""], ["Citti", "G.", ""]]}, {"id": "1910.04993", "submitter": "Pascal Helson", "authors": "Pascal Helson (TOSCA, MATHNEURO)", "title": "A Mathematical Analysis of Memory Lifetime in a simple Network Model of\n  Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.ST q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the learning of an external signal by a neural network and the time\nto forget it when this network is submitted to noise. The presentation of an\nexternal stimulus to the recurrent network of binary neurons may change the\nstate of the synapses. Multiple presentations of a unique signal leads to its\nlearning. Then, during the forgetting time, the presentation of other signals\n(noise) may also modify the synaptic weights. We construct an estimator of the\ninitial signal thanks to the synaptic currents and define by this way a\nprobability of error. In our model, these synaptic currents evolve as Markov\nchains. We study the dynamics of these Markov chains and obtain a lower bound\non the number of external stimuli that the network can receive before the\ninitial signal is considered as forgotten (probability of error above a given\nthreshold). Our results hold for finite size networks as well as in the large\nsize asymptotic. Our results are based on a finite time analysis rather than\nlarge time asymptotic. We finally present numerical illustrations of our\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 06:48:21 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 10:31:17 GMT"}, {"version": "v3", "created": "Wed, 10 Jun 2020 15:05:49 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Helson", "Pascal", "", "TOSCA, MATHNEURO"]]}, {"id": "1910.05115", "submitter": "Zakaria Aldeneh", "authors": "Zakaria Aldeneh, Mimansa Jaiswal, Michael Picheny, Melvin McInnis,\n  Emily Mower Provost", "title": "Identifying Mood Episodes Using Dialogue Features from Clinical\n  Interviews", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.SD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipolar disorder, a severe chronic mental illness characterized by\npathological mood swings from depression to mania, requires ongoing symptom\nseverity tracking to both guide and measure treatments that are critical for\nmaintaining long-term health. Mental health professionals assess symptom\nseverity through semi-structured clinical interviews. During these interviews,\nthey observe their patients' spoken behaviors, including both what the patients\nsay and how they say it. In this work, we move beyond acoustic and lexical\ninformation, investigating how higher-level interactive patterns also change\nduring mood episodes. We then perform a secondary analysis, asking if these\ninteractive patterns, measured through dialogue features, can be used in\nconjunction with acoustic features to automatically recognize mood episodes.\nOur results show that it is beneficial to consider dialogue features when\nanalyzing and building automated systems for predicting and monitoring mood.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2019 01:11:53 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Aldeneh", "Zakaria", ""], ["Jaiswal", "Mimansa", ""], ["Picheny", "Michael", ""], ["McInnis", "Melvin", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1910.05176", "submitter": "Camile Bahi", "authors": "Camile Bahi", "title": "Psilocybin based therapy for cancer related distress, a systematic\n  review and meta analysis", "comments": "33 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background : depression and anxiety are common in patients with cancer,\nclassical antidepressant has no proven efficacy on this type of distress\ncompared to placebo. A Psilocybin (serotoninergic hallucinogen) based therapy\nappear to give promising results among recent studies. Aims : to examine if a\nPsilocybin based therapy could be considered for patients with cancer related\ndepression and anxiety and to assume it's safety. To sum up Heffter institute\nwork, as the main institute working on this topic. Method : following PRISMA\n(Preferred Reporting Items for Systematic reviews and Meta Analyses)\nguidelines, a systematic review was conducted, for quantitative and qualitative\nstudies about psilocybin for treating cancer related depression and anxiety.\nPubmed and the Heffter institute databases have been reached for this purpose,\nseparating studies in types : qualitative or quantitative. We studied the\neffects on cancer related depression and anxiety separately and investigated\nthe psychological and neurobiological mechanisms. Results : the four studies\nincluded a total of 105 randomized patients, meta analysis on depression and\nanxiety with pooled Peto odds ratio showed a significant superiority of\nPsilocybin over placebo. The substance appeared to be safe for this type of\npatients. Surprising psychological mechanisms hypothesis have been found out.\nConclusion : psilocybin appear to be potentially useful as a treatment for\ncancer related depression and anxiety. Future research should verify these\nfindings on wider population and eventually seek a way to apply therapy to non\nhospitalized (ambulatory) patients. Keywords : psilocybin, depression, anxiety,\nreview, meta-analysis\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2019 14:16:28 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Bahi", "Camile", ""]]}, {"id": "1910.05271", "submitter": "Elena Kalinina", "authors": "Elena Kalinina, Fabian Pedregosa, Vittorio Iacovella, Emanuele\n  Olivetti, Paolo Avesani", "title": "A Test for Shared Patterns in Cross-modal Brain Activation Analysis", "comments": "5 figures, tables after References (as required by SciRep template)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining the extent to which different cognitive modalities (understood\nhere as the set of cognitive processes underlying the elaboration of a stimulus\nby the brain) rely on overlapping neural representations is a fundamental issue\nin cognitive neuroscience. In the last decade, the identification of shared\nactivity patterns has been mostly framed as a supervised learning problem. For\ninstance, a classifier is trained to discriminate categories (e.g. faces vs.\nhouses) in modality I (e.g. perception) and tested on the same categories in\nmodality II (e.g. imagery). This type of analysis is often referred to as\ncross-modal decoding. In this paper we take a different approach and instead\nformulate the problem of assessing shared patterns across modalities within the\nframework of statistical hypothesis testing. We propose both an appropriate\ntest statistic and a scheme based on permutation testing to compute the\nsignificance of this test while making only minimal distributional assumption.\nWe denote this test cross-modal permutation test (CMPT). We also provide\nempirical evidence on synthetic datasets that our approach has greater\nstatistical power than the cross-modal decoding method while maintaining low\nType I errors (rejecting a true null hypothesis). We compare both approaches on\nan fMRI dataset with three different cognitive modalities (perception, imagery,\nvisual search). Finally, we show how CMPT can be combined with Searchlight\nanalysis to explore spatial distribution of shared activity patterns.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2019 19:33:49 GMT"}], "update_date": "2019-10-14", "authors_parsed": [["Kalinina", "Elena", ""], ["Pedregosa", "Fabian", ""], ["Iacovella", "Vittorio", ""], ["Olivetti", "Emanuele", ""], ["Avesani", "Paolo", ""]]}, {"id": "1910.05378", "submitter": "Amir Dehsarvi", "authors": "Amir Dehsarvi, Stephen L. Smith", "title": "Classification of Resting-State fMRI using Evolutionary Algorithms:\n  Towards a Brain Imaging Biomarker for Parkinson's Disease", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate early diagnosis and monitoring of neurodegenerative conditions is\nessential for effective disease management and delivery of medication and\ntreatment. This research develops automatic methods for detecting brain imaging\npreclinical biomarkers for Parkinson's disease (PD) by considering the novel\napplication of evolutionary algorithms. A fundamental novel element of this\nwork is the use of evolutionary algorithms to both map and predict the\nfunctional connectivity in patients using resting state functional MRI data\ntaken from the PPMI to identify PD progression biomarkers. Specifically,\nCartesian Genetic Programming was used to classify DCM data as well as\ntime-series data. The findings were validated using two other commonly used\nclassification methods (Artificial Neural Networks and Support Vector Machines)\nand by employing k-fold cross-validation. Across DCM and time-series analyses,\nfindings revealed maximum accuracies of 75.21% for early stage (prodromal) PD\npatients versus healthy controls, 85.87% for PD patients versus prodromal PD\npatients, and 92.09% for PD patients versus healthy controls. Prodromal PD\npatients were classified from healthy controls with high accuracy - this is\nnotable and represents the key finding of this research since current methods\nof diagnosing prodromal PD have both low reliability and low accuracy.\nFurthermore, Cartesian Genetic Programming provided comparable performance\naccuracy relative to ANN and SVM. Evolutionary algorithms enable us to decode\nthe classifier in terms of understanding the data inputs that are used, more\neasily than in ANN and SVM. Hence, these findings underscore the relevance of\nboth DCM analyses for classification and CGP as a novel classification tool for\nbrain imaging data with medical implications for disease diagnosis,\nparticularly in early and asymptomatic stages.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2019 19:12:34 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Dehsarvi", "Amir", ""], ["Smith", "Stephen L.", ""]]}, {"id": "1910.05546", "submitter": "Zedong Bi", "authors": "Zedong Bi and Changsong Zhou", "title": "Understanding the computation of time using neural network models", "comments": null, "journal-ref": "PNAS 117 (19) 10530-10540, 2020", "doi": "10.1073/pnas.1921609117", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To maximize future rewards in this ever-changing world, animals must be able\nto discover the temporal structure of stimuli and then anticipate or act\ncorrectly at the right time. How the animals perceive, maintain, and use time\nintervals ranging from hundreds of milliseconds to multi-seconds in working\nmemory? How temporal information is processed concurrently with spatial\ninformation and decision making? Why there are strong neuronal temporal signals\nin tasks in which temporal information is not required? A systematic\nunderstanding of the underlying neural mechanisms is still lacking. Here, we\naddressed these problems using supervised training of recurrent neural network\nmodels. We revealed that neural networks perceive elapsed time through state\nevolution along stereotypical trajectory, maintain time intervals in working\nmemory in the monotonic increase or decrease of the firing rates of\ninterval-tuned neurons, and compare or produce time intervals by scaling state\nevolution speed. Temporal and non-temporal information are coded in subspaces\northogonal with each other, and the state trajectories with time at different\nnon-temporal information are quasi-parallel and isomorphic. Such coding\ngeometry facilitates the decoding generalizability of temporal and non-temporal\ninformation across each other. The network structure exhibits multiple\nfeedforward sequences that mutually excite or inhibit depending on whether\ntheir preferences of non-temporal information are similar or not. We identified\nfour factors that facilitate strong temporal signals in non-timing tasks,\nincluding the anticipation of coming events. Our work discloses fundamental\ncomputational principles of temporal processing, and is supported by and gives\npredictions to a number of experimental phenomena.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 10:07:42 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 12:48:46 GMT"}, {"version": "v3", "created": "Mon, 2 Mar 2020 14:41:37 GMT"}, {"version": "v4", "created": "Tue, 7 Jul 2020 11:58:25 GMT"}], "update_date": "2020-07-08", "authors_parsed": [["Bi", "Zedong", ""], ["Zhou", "Changsong", ""]]}, {"id": "1910.05621", "submitter": "Samuel Goldstein", "authors": "Samuel Goldstein, Zhenhong Hu, Mingzhou Ding", "title": "Decoding Working Memory Load from EEG with LSTM Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Working memory (WM) is a mechanism that temporarily stores and manipulates\ninformation in service of behavioral goals and is a highly dynamic process.\nPrevious studies have considered decoding WM load using EEG but have not\ninvestigated the contribution of sequential information contained in the\ntemporal patterns of the EEG data that can differentiate different WM loads. In\nour study, we develop a novel method of investigating the role of sequential\ninformation in the manipulation and storage of verbal information at various\ntime scales and localize topographically the sources of the sequential\ninformation based decodability. High density EEG (128-channel) were recorded\nfrom twenty subjects performing a Sternberg verbal WM task with varying memory\nloads. Long Short-Term Memory Recurrent Neural Networks (LSTM-RNN) were trained\nto decode memory load during encoding, retention, activity-silent, and\nretrieval periods. Decoding accuracy was compared between ordered data and a\ntemporally shuffled version that retains pattern based information of the data\nbut not temporal relation to assess the contribution of sequential information\nto decoding memory load. The results show that (1) decoding accuracy increases\nwith increase in the length of the EEG time series given to the LSTM for both\nordered and temporally shuffled cases, with the increase being faster for\nordered than temporally shuffled time series, and (2) according to the decoding\nweight maps, the frontal, temporal and some parietal areas are an important\nsource of sequential information based decodability. This study, to our\nknowledge, is the first study applying a LSTM-RNN approach to investigate\ntemporal dynamics in human EEG data in encoding WM load information.\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2019 18:33:46 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Goldstein", "Samuel", ""], ["Hu", "Zhenhong", ""], ["Ding", "Mingzhou", ""]]}, {"id": "1910.05761", "submitter": "Duccio Fanelli", "authors": "Ihusan Adam, Gloria Cecchini, Duccio Fanelli, Thomas Kreuz, Roberto\n  Livi, Matteo di Volo, Anna Letizia Allegra Mascaro, Emilia Conti, Alessandro\n  Scaglione, Ludovico Silvestri, Francesco Saverio Pavone", "title": "Inferring network structure and local dynamics from neuronal patterns\n  with quenched disorder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An inverse procedure is proposed and tested which aims at recovering the a\npriori unknown functional and structural information from global signals of\nliving brains activity. To this end we consider a Leaky-Integrate and Fire\n(LIF) model with short term plasticity neurons, coupled via a directed network.\nNeurons are assigned a specific current value, which is heterogenous across the\nsample, and sets the firing regime in which the neuron is operating in. The aim\nof the method is to recover the distribution of incoming network degrees, as\nwell as the distribution of the assigned currents, from global field\nmeasurements. The proposed approach to the inverse problem implements the\nreductionist Heterogenous Mean-Field approximation. This amounts in turn to\norganizing the neurons in different classes, depending on their associated\ndegree and current. When tested again synthetic data, the method returns\naccurate estimates of the sought distributions, while managing to reproduce and\ninterpolate almost exactly the time series of the supplied global field.\nFinally, we also applied the proposed technique to longitudinal wide-field\nfluorescence microscopy data of cortical functionality in groups of awake\nThy1-GCaMP6f mice. Mice are induced a photothrombotic stroke in the primary\nmotor cortex and their recovery monitored in time. An all-to-all LIF model\nwhich accommodates for currents heterogeneity allows to adequately explain the\nrecorded patterns of activation. Altered distributions in neuron excitability\nare in particular detected, compatible with the phenomenon of hyperexcitability\nin the penumbra region after stroke.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2019 14:23:35 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Adam", "Ihusan", ""], ["Cecchini", "Gloria", ""], ["Fanelli", "Duccio", ""], ["Kreuz", "Thomas", ""], ["Livi", "Roberto", ""], ["di Volo", "Matteo", ""], ["Mascaro", "Anna Letizia Allegra", ""], ["Conti", "Emilia", ""], ["Scaglione", "Alessandro", ""], ["Silvestri", "Ludovico", ""], ["Pavone", "Francesco Saverio", ""]]}, {"id": "1910.05881", "submitter": "Taiping Zeng", "authors": "Taiping Zeng, XiaoLi Li, and Bailu Si", "title": "Bayesian Integration of Multi-resolutional Grid Codes for Spatial\n  Cognition", "comments": "arXiv admin note: text overlap with arXiv:1910.04590", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fourier-like summation of several grid cell modules with different spatial\nfrequencies in the medial entorhinal cortex (MEC) has long been proposed to\nform the contours of place firing fields. Recent experiments largely, but not\ncompletely, support this theory. Place fields are obviously expanded by\ninactivation of dorsal MEC, which fits the hypothesis. However, contrary to the\nprediction, inactivation of ventral MEC is also weakly broaden the spatial\nplace firing patterns. In this study, we derive the model from grid spatial\nfrequencies represented by Gaussian profiles to a 1D place field by Bayesian\ninference, and further provide completely theoretical explanations for\nexpansion of place fields and predictions for alignments of grid components. To\nunderstand the information transform across between neocortex, entorhinal\ncortex, and hippocampus, we propose spatial memory indexing theory from\nhippocampal indexing theory to investigate how neural dynamics work in the\nentorhinal-hippocampal circuit. The inputs of place cells in CA3 are converged\nfrom three grid modules with different grid spacings layer II of MEC by\nBayesian mechanism. We resort to the robot system to test Fourier hypothesis\nand spatial memory indexing theory, and validate our proposed\nentorhinal-hippocampal model. And then we demonstrate its cognitive mapping\ncapability on the KITTI odometry benchmark dataset. Results suggest that our\nmodel provides a rational theoretical explanation for the biological\nexperimental results. Results also show that the proposed model is robust for\nsimultaneous localization and mapping (SLAM) in the large-scale environment.\nOur proposed model theoretically supports for Fourier hypothesis in a general\nBayesian mechanism, which may pertain to other neural systems in addition to\nspatial cognition.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2019 01:43:11 GMT"}], "update_date": "2019-10-15", "authors_parsed": [["Zeng", "Taiping", ""], ["Li", "XiaoLi", ""], ["Si", "Bailu", ""]]}, {"id": "1910.06489", "submitter": "Sneha Aenugu", "authors": "Sneha Aenugu, Abhishek Sharma, Sasikiran Yelamarthi, Hananel Hazan,\n  Philip S. Thomas, Robert Kozma", "title": "Reinforcement learning with a network of spiking agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroscientific theory suggests that dopaminergic neurons broadcast global\nreward prediction errors to large areas of the brain influencing the synaptic\nplasticity of the neurons in those regions. We build on this theory to propose\na multi-agent learning framework with spiking neurons in the generalized linear\nmodel (GLM) formulation as agents, to solve reinforcement learning (RL) tasks.\nWe show that a network of GLM spiking agents connected in a hierarchical\nfashion, where each spiking agent modulates its firing policy based on local\ninformation and a global prediction error, can learn complex action\nrepresentations to solve RL tasks. We further show how leveraging principles of\nmodularity and population coding inspired from the brain can help reduce\nvariance in the learning updates making it a viable optimization technique.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 02:27:18 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 15:12:39 GMT"}, {"version": "v3", "created": "Sun, 10 Nov 2019 22:19:56 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Aenugu", "Sneha", ""], ["Sharma", "Abhishek", ""], ["Yelamarthi", "Sasikiran", ""], ["Hazan", "Hananel", ""], ["Thomas", "Philip S.", ""], ["Kozma", "Robert", ""]]}, {"id": "1910.06659", "submitter": "James McIntosh", "authors": "J. R. McIntosh, J. Yao, Linbi Hong, J. Faller and P. Sajda", "title": "Ballistocardiogram artifact reduction in simultaneous EEG-fMRI using\n  deep learning", "comments": null, "journal-ref": null, "doi": "10.1109/TBME.2020.3004548", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: The concurrent recording of electroencephalography (EEG) and\nfunctional magnetic resonance imaging (fMRI) is a technique that has received\nmuch attention due to its potential for combined high temporal and spatial\nresolution. However, the ballistocardiogram (BCG), a large-amplitude artifact\ncaused by cardiac induced movement contaminates the EEG during EEG-fMRI\nrecordings. Removal of BCG in software has generally made use of linear\ndecompositions of the corrupted EEG. This is not ideal as the BCG signal is\nnon-stationary and propagates in a manner which is non-linearly dependent on\nthe electrocardiogram (ECG). In this paper, we present a novel method for BCG\nartifact suppression using recurrent neural networks (RNNs). Methods: EEG\nsignals were recovered by training RNNs on the nonlinear mappings between ECG\nand the BCG corrupted EEG. We evaluated our model's performance against the\ncommonly used Optimal Basis Set (OBS) method at the level of individual\nsubjects, and investigated generalization across subjects. Results: We show\nthat our algorithm can generate larger average power reduction of the BCG at\ncritical frequencies, while simultaneously improving task relevant EEG based\nclassification. Conclusion: The presented deep learning architecture can be\nused to reduce BCG related artifacts in EEG-fMRI recordings. Significance: We\npresent a deep learning approach that can be used to suppress the BCG artifact\nin EEG-fMRI without the use of additional hardware. This method may have scope\nto be combined with current hardware methods, operate in real-time and be used\nfor direct modeling of the BCG.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 11:19:15 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["McIntosh", "J. R.", ""], ["Yao", "J.", ""], ["Hong", "Linbi", ""], ["Faller", "J.", ""], ["Sajda", "P.", ""]]}, {"id": "1910.06950", "submitter": "Nicha Dvornek", "authors": "Nicha C. Dvornek, Xiaoxiao Li, Juntang Zhuang, James S. Duncan", "title": "Jointly Discriminative and Generative Recurrent Neural Networks for\n  Learning from fMRI", "comments": "10th International Workshop on Machine Learning in Medical Imaging\n  (MLMI 2019)", "journal-ref": null, "doi": "10.1007/978-3-030-32692-0_44", "report-no": null, "categories": "eess.IV cs.LG q-bio.NC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) were designed for dealing with time-series\ndata and have recently been used for creating predictive models from functional\nmagnetic resonance imaging (fMRI) data. However, gathering large fMRI datasets\nfor learning is a difficult task. Furthermore, network interpretability is\nunclear. To address these issues, we utilize multitask learning and design a\nnovel RNN-based model that learns to discriminate between classes while\nsimultaneously learning to generate the fMRI time-series data. Employing the\nlong short-term memory (LSTM) structure, we develop a discriminative model\nbased on the hidden state and a generative model based on the cell state. The\naddition of the generative model constrains the network to learn functional\ncommunities represented by the LSTM nodes that are both consistent with the\ndata generation as well as useful for the classification task. We apply our\napproach to the classification of subjects with autism vs. healthy controls\nusing several datasets from the Autism Brain Imaging Data Exchange. Experiments\nshow that our jointly discriminative and generative model improves\nclassification learning while also producing robust and meaningful functional\ncommunities for better model understanding.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2019 17:43:45 GMT"}], "update_date": "2019-10-16", "authors_parsed": [["Dvornek", "Nicha C.", ""], ["Li", "Xiaoxiao", ""], ["Zhuang", "Juntang", ""], ["Duncan", "James S.", ""]]}, {"id": "1910.07263", "submitter": "Min Yan", "authors": "Min Yan, Wen-Hao Zhang, He Wang, K. Y. Michael Wong", "title": "The Dynamics of Bimodular Continuous Attractor Neural Networks with\n  Static and Moving Stimuli", "comments": "15 pages, 12 figures, journal paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain achieves multisensory integration by combining the information\nreceived from different sensory inputs to yield inferences with higher speed or\nmore accuracy. We consider a bimodular neural network each processing a\nmodality of sensory input and interacting with each other. The dynamics of\nexcitatory and inhibitory couplings between the two modules are studied with\nstatic and moving stimuli. The modules exhibit non-trivial interactive\nbehaviors depending on the input strengths, their disparity and speed (for\nmoving inputs), and the inter-modular couplings. They give rise to a family of\nmodels applicable to causal inference problems in neuroscience. They also\nprovide a model for the experiment of motion-bounce illusion, yielding\nconsistent results and predicting their robustness.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 10:13:49 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Yan", "Min", ""], ["Zhang", "Wen-Hao", ""], ["Wang", "He", ""], ["Wong", "K. Y. Michael", ""]]}, {"id": "1910.07407", "submitter": "Benjamin Cramer", "authors": "Benjamin Cramer, Yannik Stradmann, Johannes Schemmel and Friedemann\n  Zenke", "title": "The Heidelberg spiking datasets for the systematic evaluation of spiking\n  neural networks", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2020.3044364", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spiking neural networks are the basis of versatile and power-efficient\ninformation processing in the brain. Although we currently lack a detailed\nunderstanding of how these networks compute, recently developed optimization\ntechniques allow us to instantiate increasingly complex functional spiking\nneural networks in-silico. These methods hold the promise to build more\nefficient non-von-Neumann computing hardware and will offer new vistas in the\nquest of unraveling brain circuit function. To accelerate the development of\nsuch methods, objective ways to compare their performance are indispensable.\nPresently, however, there are no widely accepted means for comparing the\ncomputational performance of spiking neural networks. To address this issue, we\nintroduce two spike-based classification datasets, broadly applicable to\nbenchmark both software and neuromorphic hardware implementations of spiking\nneural networks. To accomplish this, we developed a general audio-to-spiking\nconversion procedure inspired by neurophysiology. Further, we applied this\nconversion to an existing and a novel speech dataset. The latter is the free,\nhigh-fidelity, and word-level aligned Heidelberg digit dataset that we created\nspecifically for this study. By training a range of conventional and spiking\nclassifiers, we show that leveraging spike timing information within these\ndatasets is essential for good classification accuracy. These results serve as\nthe first reference for future performance comparisons of spiking neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:22:01 GMT"}, {"version": "v2", "created": "Mon, 9 Dec 2019 10:23:34 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 13:30:24 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Cramer", "Benjamin", ""], ["Stradmann", "Yannik", ""], ["Schemmel", "Johannes", ""], ["Zenke", "Friedemann", ""]]}, {"id": "1910.07414", "submitter": "Jan Karbowski", "authors": "Jan Karbowski", "title": "Metabolic constraints on synaptic learning and memory", "comments": "brain, synapses, energy cost of learning and memory, synaptic\n  plasticity, model and estimates", "journal-ref": "Journal of Neurophysiology 122: 1473-1490 (2019)", "doi": "10.1152/jn.00092.2019", "report-no": null, "categories": "q-bio.NC q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dendritic spines, the carriers of long-term memory, occupy a small fraction\nof cortical space, and yet they are the major consumers of brain metabolic\nenergy. What fraction of this energy goes for synaptic plasticity, correlated\nwith learning and memory? It is estimated here based on neurophysiological and\nproteomic data for rat brain that, depending on the level of protein\nphosphorylation, the energy cost of synaptic plasticity constitutes a small\nfraction of the energy used for fast excitatory synaptic transmission,\ntypically $4.0-11.2 \\%$. Next, this study analyzes a metabolic cost of a new\nlearning and its memory trace in relation to the cost of prior memories, using\na class of cascade models of synaptic plasticity. It is argued that these\nmodels must contain bidirectional cyclic motifs, related to protein\nphosphorylation, to be compatible with basic thermodynamic principles. For most\ninvestigated parameters longer memories generally require proportionally more\nenergy to store. The exception are the parameters controlling the speed of\nmolecular transitions (e.g. ATP driven phosphorylation rate), for which memory\nlifetime per invested energy can increase progressively for longer memories.\nFurthermore, in general, a memory trace decouples dynamically from a\ncorresponding synaptic metabolic rate such that the energy expended on a new\nlearning and its memory trace constitutes in most cases only a small fraction\nof the baseline energy associated with prior memories. Taken together, these\nempirical and theoretical results suggest a metabolic efficiency of\nsynaptically stored information.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 15:30:52 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Karbowski", "Jan", ""]]}, {"id": "1910.07451", "submitter": "Jan Karbowski", "authors": "Jan Karbowski", "title": "Deciphering neural circuits for Caenorhabditis elegans behavior by\n  computations and perturbations to genome and connectome", "comments": "Systems Biology of C. elegans worms; Computational Neuroscience;\n  Models", "journal-ref": "Current Opinion in Systems Biology 13: 44-51 (2019)", "doi": "10.1016/j.coisb.2018.09.008", "report-no": null, "categories": "q-bio.NC q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  {\\it Caenorhabditis elegans} nematode worms are the only animals with the\nknown detailed neural connectivity diagram, well characterized genomics, and\nrelatively simple quantifiable behavioral output. With this in mind, many\nresearchers view this animal as the best candidate for a systems biology\napproach, where one can integrate molecular and cellular knowledge to gain\nglobal understanding of worm's behavior. This work reviews some research in\nthis direction, emphasizing computational perspective, and points out some\nsuccesses and challenges to meet this lofty goal.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 16:17:33 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Karbowski", "Jan", ""]]}, {"id": "1910.07640", "submitter": "Yingxin Cao", "authors": "Yeeleng S. Vang, Yingxin Cao, Xiaohui Xie", "title": "A Combined Deep Learning-Gradient Boosting Machine Framework for Fluid\n  Intelligence Prediction", "comments": "Challenge in Adolescent Brain Cognitive Development Neurocognitive\n  Prediction", "journal-ref": "In: Pohl K., Thompson W., Adeli E., Linguraru M. (eds) Adolescent\n  Brain Cognitive Development Neurocognitive Prediction. ABCD-NP 2019. Lecture\n  Notes in Computer Science, vol 11791. Springer, Cham (2019)", "doi": "10.1007/978-3-030-31901-4_1", "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The ABCD Neurocognitive Prediction Challenge is a community driven\ncompetition asking competitors to develop algorithms to predict fluid\nintelligence score from T1-w MRIs. In this work, we propose a deep learning\ncombined with gradient boosting machine framework to solve this task. We train\na convolutional neural network to compress the high dimensional MRI data and\nlearn meaningful image features by predicting the 123 continuous-valued derived\ndata provided with each MRI. These extracted features are then used to train a\ngradient boosting machine that predicts the residualized fluid intelligence\nscore. Our approach achieved mean square error (MSE) scores of 18.4374,\n68.7868, and 96.1806 for the training, validation, and test set respectively.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 22:32:13 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Vang", "Yeeleng S.", ""], ["Cao", "Yingxin", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1910.07916", "submitter": "Chengran Fang", "authors": "Chengran Fang, Van-Dang Nguyen, Demian Wassermann, Jing-Rebecca Li", "title": "Diffusion MRI simulation of realistic neurons with SpinDoctor and the\n  Neuron Module", "comments": "42 pages, 17 figures. arXiv admin note: text overlap with\n  arXiv:1902.01025", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the Neuron Module that we implemented within the\nMatlab-based diffusion MRI simulation toolbox SpinDoctor. SpinDoctor uses\nfinite element discretization and adaptive time integration to solve the\nBloch-Torrey partial differential equation for general diffusion-encoding\nsequences, at multiple b-values and in multiple diffusion directions. In order\nto facilitate the diffusion MRI simulation of realistic neurons by the research\ncommunity, we constructed finite element meshes for a group of 36 pyramidal\nneurons and a group of 29 spindle neurons whose morphological descriptions were\nfound in the publicly available neuron repository NeuroMorpho. We also broke\nthe neurons into the soma and dendrite branches and created finite elements\nmeshes for these cell components. Through the Neuron Module, these neuron and\ncell components finite element meshes can be seamlessly coupled with the\nfunctionalities of SpinDoctor. To illustrate some potential uses of the Neuron\nModule, we show numerical examples of the simulated diffusion MRI signals in\nmultiple diffusion directions from whole neurons as well as from the soma and\ndendrite branches, and include a comparison of the high b-value behavior\nbetween dendrite branches and whole neurons. In addition, we demonstrate that\nthe neuron meshes can be used to perform Monte-Carlo diffusion MRI simulations\nas well. We show that at equivalent accuracy, if only one gradient direction\nneeds to be simulated, SpinDoctor is faster than a GPU implementation of\nMonte-Carlo. Finally, we numerically compute the eigenfunctions and the\neigenvalues of the Bloch-Torrey and the Laplace operators on the neuron\ngeometries using a finite elements discretization, in order to give guidance in\nthe choice of the space and time discretization parameters for both finite\nelements and Monte-Carlo approaches.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2019 12:41:25 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2020 09:29:26 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2020 07:54:03 GMT"}], "update_date": "2020-07-22", "authors_parsed": [["Fang", "Chengran", ""], ["Nguyen", "Van-Dang", ""], ["Wassermann", "Demian", ""], ["Li", "Jing-Rebecca", ""]]}, {"id": "1910.07960", "submitter": "Giacomo Indiveri", "authors": "Llewyn Salt, David Howard, Giacomo Indiveri, Yulia Sandamirskaya", "title": "Parameter Optimization and Learning in a Spiking Neural Network for UAV\n  Obstacle Avoidance targeting Neuromorphic Processors", "comments": null, "journal-ref": null, "doi": "10.1109/TNNLS.2019.2941506", "report-no": null, "categories": "cs.NE cs.ET nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lobula Giant Movement Detector (LGMD) is an identified neuron of the\nlocust that detects looming objects and triggers the insect's escape responses.\nUnderstanding the neural principles and network structure that lead to these\nfast and robust responses can facilitate the design of efficient obstacle\navoidance strategies for robotic applications. Here we present a neuromorphic\nspiking neural network model of the LGMD driven by the output of a neuromorphic\nDynamic Vision Sensor (DVS), which incorporates spiking frequency adaptation\nand synaptic plasticity mechanisms, and which can be mapped onto existing\nneuromorphic processor chips. However, as the model has a wide range of\nparameters, and the mixed signal analogue-digital circuits used to implement\nthe model are affected by variability and noise, it is necessary to optimise\nthe parameters to produce robust and reliable responses. Here we propose to use\nDifferential Evolution (DE) and Bayesian Optimisation (BO) techniques to\noptimise the parameter space and investigate the use of Self-Adaptive\nDifferential Evolution (SADE) to ameliorate the difficulties of finding\nappropriate input parameters for the DE technique. We quantify the performance\nof the methods proposed with a comprehensive comparison of different optimisers\napplied to the model, and demonstrate the validity of the approach proposed\nusing recordings made from a DVS sensor mounted on a UAV.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 15:06:27 GMT"}], "update_date": "2019-10-18", "authors_parsed": [["Salt", "Llewyn", ""], ["Howard", "David", ""], ["Indiveri", "Giacomo", ""], ["Sandamirskaya", "Yulia", ""]]}, {"id": "1910.08112", "submitter": "Kevin Nguyen", "authors": "Kevin P. Nguyen, Cherise Chin Fatt, Alex Treacher, Cooper Mellema,\n  Madhukar H. Trivedi, Albert Montillo", "title": "Anatomically-Informed Data Augmentation for functional MRI with\n  Applications to Deep Learning", "comments": "SPIE Medical Imaging 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.NC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of deep learning to build accurate predictive models from\nfunctional neuroimaging data is often hindered by limited dataset sizes. Though\ndata augmentation can help mitigate such training obstacles, most data\naugmentation methods have been developed for natural images as in computer\nvision tasks such as CIFAR, not for medical images. This work helps to fills in\nthis gap by proposing a method for generating new functional Magnetic Resonance\nImages (fMRI) with realistic brain morphology. This method is tested on a\nchallenging task of predicting antidepressant treatment response from\npre-treatment task-based fMRI and demonstrates a 26% improvement in performance\nin predicting response using augmented images. This improvement compares\nfavorably to state-of-the-art augmentation methods for natural images. Through\nan ablative test, augmentation is also shown to substantively improve\nperformance when applied before hyperparameter optimization. These results\nsuggest the optimal order of operations and support the role of data\naugmentation method for improving predictive performance in tasks using fMRI.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 18:55:10 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Nguyen", "Kevin P.", ""], ["Fatt", "Cherise Chin", ""], ["Treacher", "Alex", ""], ["Mellema", "Cooper", ""], ["Trivedi", "Madhukar H.", ""], ["Montillo", "Albert", ""]]}, {"id": "1910.08336", "submitter": "Noemi Montobbio", "authors": "Noemi Montobbio, Laurent Bonnasse-Gahot, Giovanna Citti, Alessandro\n  Sarti", "title": "KerCNNs: biologically inspired lateral connections for classification of\n  corrupted images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of the art in many computer vision tasks is represented by\nConvolutional Neural Networks (CNNs). Although their hierarchical organization\nand local feature extraction are inspired by the structure of primate visual\nsystems, the lack of lateral connections in such architectures critically\ndistinguishes their analysis from biological object processing. The idea of\nenriching CNNs with recurrent lateral connections of convolutional type has\nbeen put into practice in recent years, in the form of learned recurrent\nkernels with no geometrical constraints. In the present work, we introduce\nbiologically plausible lateral kernels encoding a notion of correlation between\nthe feedforward filters of a CNN: at each layer, the associated kernel acts as\na transition kernel on the space of activations. The lateral kernels are\ndefined in terms of the filters, thus providing a parameter-free approach to\nassess the geometry of horizontal connections based on the feedforward\nstructure. We then test this new architecture, which we call KerCNN, on a\ngeneralization task related to global shape analysis and pattern completion:\nonce trained for performing basic image classification, the network is\nevaluated on corrupted testing images. The image perturbations examined are\ndesigned to undermine the recognition of the images via local features, thus\nrequiring an integration of context information - which in biological vision is\ncritically linked to lateral connectivity. Our KerCNNs turn out to be far more\nstable than CNNs and recurrent CNNs to such degradations, thus validating this\nbiologically inspired approach to reinforce object recognition under\nchallenging conditions.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 10:31:06 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Montobbio", "Noemi", ""], ["Bonnasse-Gahot", "Laurent", ""], ["Citti", "Giovanna", ""], ["Sarti", "Alessandro", ""]]}, {"id": "1910.08415", "submitter": "David Abramian", "authors": "David Abramian, Per Sid\\'en, Hans Knutsson, Mattias Villani, Anders\n  Eklund", "title": "Anatomically informed Bayesian spatial priors for fMRI analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME eess.IV q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing Bayesian spatial priors for functional magnetic resonance imaging\n(fMRI) data correspond to stationary isotropic smoothing filters that may\noversmooth at anatomical boundaries. We propose two anatomically informed\nBayesian spatial models for fMRI data with local smoothing in each voxel based\non a tensor field estimated from a T1-weighted anatomical image. We show that\nour anatomically informed Bayesian spatial models results in posterior\nprobability maps that follow the anatomical structure.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2019 13:35:18 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Abramian", "David", ""], ["Sid\u00e9n", "Per", ""], ["Knutsson", "Hans", ""], ["Villani", "Mattias", ""], ["Eklund", "Anders", ""]]}, {"id": "1910.08423", "submitter": "Betony Adams Ms", "authors": "Betony Adams and Francesco Petruccione", "title": "Quantum effects in the brain: A review", "comments": "The following article will be submitted to AVS Quantum Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the mid-1990s it was proposed that quantum effects in proteins known as\nmicrotubules play a role in the nature of consciousness. The theory was largely\ndismissed due to the fact that quantum effects were thought unlikely to occur\nin biological systems, which are warm and wet and subject to decoherence.\nHowever, the development of quantum biology now suggests otherwise. Quantum\neffects have been implicated in photosynthesis, a process fundamental to life\non earth. They are also possibly at play in other biological processes such as\navian migration and olfaction. The microtubule mechanism of quantum\nconsciousness has been joined by other theories of quantum cognition. It has\nbeen proposed that general anaesthetic, which switches off consciousness, does\nthis through quantum means, measured by changes in electron spin. The\ntunnelling hypothesis developed in the context of olfaction has been applied to\nthe action of neurotransmitters. A recent theory outlines how quantum\nentanglement between phosphorus nuclei might influence the firing of neurons.\nThese, and other theories, have contributed to a growing field of research that\ninvestigates whether quantum effects might contribute to neural processing.\nThis review aims to investigate the current state of this research and how\nfully the theory is supported by convincing experimental evidence. It also aims\nto clarify the biological sites of these proposed quantum effects and how\nprogress made in the wider field of quantum biology might be relevant to the\nspecific case of the brain.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2019 15:03:17 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Adams", "Betony", ""], ["Petruccione", "Francesco", ""]]}, {"id": "1910.08724", "submitter": "Zhongqi Tian", "authors": "Zhong-Qi Kyle Tian and Douglas Zhou", "title": "Design Efficient Exponential Time Differencing method For Hodgkin-Huxley\n  Neural Networks", "comments": null, "journal-ref": null, "doi": "10.3389/fncom.2020.00040", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential time differencing (ETD) method allows using a large time step\nto efficiently evolve the stiff system such as Hodgkin-Huxley (HH) neural\nnetworks.\n  For pulse-coupled HH networks, the synaptic spike times cannot be\npredetermined and are convoluted with neuron's trajectory itself.\n  This presents a challenging issue for the design of an efficient numerical\nsimulation algorithm.\n  The stiffness in the HH equations are quite different between the spike and\nnon-spike regions. Here, we design a second-order adaptive exponential time\ndifferencing algorithm (AETD2) for the numerical evolution of HH neural\nnetworks.\n  Compared with the regular second-order Runge-Kutta method (RK2), our AETD2\nmethod can use time steps one order of magnitude larger and improve\ncomputational efficiency more than ten times while excellently capturing\naccurate traces of membrane potentials of HH neurons. This high accuracy and\nefficiency can be robustly obtained and do not depend on the dynamical regimes,\nconnectivity structure or the network size.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 08:41:15 GMT"}, {"version": "v2", "created": "Sun, 17 Nov 2019 05:33:00 GMT"}, {"version": "v3", "created": "Thu, 21 Nov 2019 13:25:31 GMT"}, {"version": "v4", "created": "Wed, 27 Nov 2019 14:49:11 GMT"}], "update_date": "2020-06-29", "authors_parsed": [["Tian", "Zhong-Qi Kyle", ""], ["Zhou", "Douglas", ""]]}, {"id": "1910.08784", "submitter": "James McIntosh", "authors": "J. R. McIntosh, P. Sajda", "title": "Estimation of phase in EEG rhythms for real-time applications", "comments": null, "journal-ref": null, "doi": "10.1088/1741-2552/ab8683", "report-no": null, "categories": "q-bio.QM eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective. We identify two linked problems related to estimating the phase of\nthe alpha rhythm when the signal after a specific event is unknown (real-time\ncase), or corrupted (offline analysis). We propose methods to estimate the\nphase prior to such events. Approach. Machine learning is used to mimic a\nnon-causal signal-processing chain with a purely causal one. Main results. We\ndemonstrate the ability of these methods to estimate instantaneous phase from\nan electroencephalography signal subjected to very minor pre-processing with\nhigher accuracy than more standard signal-processing methods. Significance.\nPhase estimation of EEG-rhythms is a challenge due to non-stationarity and low\nsignal to noise ratio. The methods presented enable scientists and engineers to\nachieve relatively low error by optimizing causal phase estimation on a\nnon-causally processed signal for a real-time experiments and offline analysis.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 14:56:26 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["McIntosh", "J. R.", ""], ["Sajda", "P.", ""]]}, {"id": "1910.09495", "submitter": "Saeed Reza Kheradpisheh", "authors": "Saeed Reza Kheradpisheh and Timoth\\'ee Masquelier", "title": "S4NN: temporal backpropagation for spiking neural networks with one\n  spike per neuron", "comments": null, "journal-ref": "International Journal of Neural Systems 2020", "doi": "10.1142/S0129065720500276", "report-no": null, "categories": "cs.NE cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new supervised learning rule for multilayer spiking neural\nnetworks (SNNs) that use a form of temporal coding known as rank-order-coding.\nWith this coding scheme, all neurons fire exactly one spike per stimulus, but\nthe firing order carries information. In particular, in the readout layer, the\nfirst neuron to fire determines the class of the stimulus. We derive a new\nlearning rule for this sort of network, named S4NN, akin to traditional error\nbackpropagation, yet based on latencies. We show how approximated error\ngradients can be computed backward in a feedforward network with any number of\nlayers. This approach reaches state-of-the-art performance with supervised\nmulti fully-connected layer SNNs: test accuracy of 97.4% for the MNIST dataset,\nand 99.2% for the Caltech Face/Motorbike dataset. Yet, the neuron model that we\nuse, non-leaky integrate-and-fire, is much simpler than the one used in all\nprevious works. The source codes of the proposed S4NN are publicly available at\nhttps://github.com/SRKH/S4NN.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2019 16:39:42 GMT"}, {"version": "v2", "created": "Thu, 5 Mar 2020 15:43:30 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 09:23:11 GMT"}, {"version": "v4", "created": "Sat, 13 Jun 2020 10:33:19 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kheradpisheh", "Saeed Reza", ""], ["Masquelier", "Timoth\u00e9e", ""]]}, {"id": "1910.09904", "submitter": "Anke Cajar", "authors": "Anke Cajar, Ralf Engbert, Jochen Laubrock", "title": "How spatial frequencies and color drive object search in real-world\n  scenes: A new eye-movement corpus", "comments": "29 pages, 6 figures", "journal-ref": null, "doi": "10.1167/jov.20.7.8", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When studying how people search for objects in scenes, the inhomogeneity of\nthe visual field is often ignored. Due to physiological limitations peripheral\nvision is blurred and mainly uses coarse-grained information (i.e., low spatial\nfrequencies) for selecting saccade targets, whereas high-acuity central vision\nuses fine-grained information (i.e., high spatial frequencies) for analysis of\ndetails. Here we investigated how spatial frequencies and color affect object\nsearch in real-world scenes. Using gaze-contingent filters we attenuated high\nor low frequencies in central or peripheral vision while viewers searched color\nor grayscale scenes. Results showed that peripheral filters and central\nhigh-pass filters hardly affected search accuracy, whereas accuracy dropped\ndrastically with central low-pass filters. Peripheral filtering increased the\ntime to localize the target by decreasing saccade amplitudes and increasing\nnumber and duration of fixations. The use of coarse-grained information in the\nperiphery was limited to color scenes. Central filtering increased the time to\nverify target identity instead, especially with low-pass filters. We conclude\nthat peripheral vision is critical for object localization and central vision\nis critical for object identification. Visual guidance during peripheral object\nlocalization is dominated by low-frequency color information, whereas\nhigh-frequency information, relatively independent of color, is most important\nfor object identification in central vision.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 11:46:12 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 10:05:18 GMT"}, {"version": "v3", "created": "Fri, 20 Mar 2020 13:24:56 GMT"}], "update_date": "2021-01-05", "authors_parsed": [["Cajar", "Anke", ""], ["Engbert", "Ralf", ""], ["Laubrock", "Jochen", ""]]}, {"id": "1910.09984", "submitter": "Joao Pinheiro Neto", "authors": "Joao Pinheiro Neto, Franz Paul Spitzner, Viola Priesemann", "title": "A unified picture of neuronal avalanches arises from the understanding\n  of sampling effects", "comments": "14 pages, 7 figures, Supp. Info. w/ 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech nlin.AO physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, it is still impossible to sample the entire mammalian brain with\nsingle-neuron precision. This forces one to either use spikes (focusing on few\nneurons) or to use coarse-sampled activity (averaging over many neurons, e.g.\nLFP). Naturally, the sampling technique impacts inference about collective\nproperties. Here, we emulate both sampling techniques on a spiking model to\nquantify how they alter observed correlations and signatures of criticality. We\ndiscover a general effect: when the inter-electrode distance is small,\nelectrodes sample overlapping regions in space, which increases the correlation\nbetween the signals. For coarse-sampled activity, this can produce power-law\ndistributions even for non-critical systems. In contrast, spikes enable one to\ndistinguish the underlying dynamics. This explains why coarse measures and\nspikes have produced contradicting results in the past -- that are now all\nconsistent with a slightly subcritical regime.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 13:54:17 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2020 12:27:30 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Neto", "Joao Pinheiro", ""], ["Spitzner", "Franz Paul", ""], ["Priesemann", "Viola", ""]]}, {"id": "1910.10210", "submitter": "Stephen Eglen", "authors": "Patrick W. Keeley, Stephen J. Eglen, Benjamin E. Reese", "title": "From Random to Regular: Variation in the Patterning of Retinal Mosaics", "comments": "11 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The various types of retinal neurons are each positioned at their respective\ndepths within the retina where they are believed to be assembled as orderly\nmosaics, in which like-type neurons minimize proximity to one another. Two\ncommon statistical analyses for assessing the spatial properties of retinal\nmosaics include the nearest neighbor analysis, from which an index of their\n\"regularity\" is commonly calculated, and the density recovery profile derived\nfrom auto-correlation analysis, revealing the presence of an exclusion zone\nindicative of anti-clustering. While each of the spatial statistics derived\nfrom these analyses, the regularity index and the effective radius, can be\nuseful in characterizing such properties of orderly retinal mosaics, they are\nrarely sufficient for conveying the natural variation in the self-spacing\nbehavior of different types of retinal neurons and the extent to which that\nbehavior generates uniform intercellular spacing across the mosaic. We consider\nthe strengths and limitations of different spatial statistical analyses for\nassessing the patterning in retinal mosaics, highlighting a number of\nmisconceptions and their frequent misuse. Rather than being diagnostic criteria\nfor determining simply whether a population is \"regular\", they should be\ntreated as descriptive statistics that convey variation in the factors that\ninfluence neuronal positioning. We subsequently apply multiple spatial\nstatistics to the analysis of eight different mosaics in the mouse retina,\ndemonstrating conspicuous variability in the degree of patterning present, from\nessentially random to notably regular. This variability in patterning has both\na developmental as well as a functional significance, reflecting the rules\ngoverning the positioning of different types of neurons as the architecture of\nthe retina is assembled (abstract truncated).\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2019 19:50:40 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Keeley", "Patrick W.", ""], ["Eglen", "Stephen J.", ""], ["Reese", "Benjamin E.", ""]]}, {"id": "1910.10489", "submitter": "Mohsen Annabestani", "authors": "Fatemeh Hasanzadeh, Mohsen Annabestani, Sahar Moghimi", "title": "Continuous Emotion Recognition during Music Listening Using EEG Signals:\n  A Fuzzy Parallel Cascades Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A controversial issue in artificial intelligence is human emotion\nrecognition. This paper presents a fuzzy parallel cascades (FPC) model for\npredicting the continuous subjective appraisal of the emotional content of\nmusic by time-varying spectral content of EEG signals. The EEG, along with an\nemotional appraisal of 15 subjects, was recorded during listening to seven\nmusical excerpts. The emotional appraisement was recorded along the valence and\narousal emotional axes as a continuous signal. The FPC model was composed of\nparallel cascades with each cascade containing a fuzzy logic-based system. The\nFPC model performance was evaluated by comparing with linear regression (LR),\nsupport vector regression (SVR) and Long Short Term Memory recurrent neural\nnetwork (LSTM RNN) models. The RMSE of the FPC was lower than other models for\nthe estimation of both valence and arousal of all musical excerpts. The lowest\nRMSE was 0.089 which was obtained in estimation of the valence of MS4 by the\nFPC model. The analysis of MI of frontal EEG with the valence confirms the role\nof frontal channels in theta frequency band in emotion recognition. Considering\nthe dynamic variations of musical features during songs, employing a modeling\napproach to predict dynamic variations of the emotional appraisal can be a\nplausible substitute for the classification of musical excerpts into predefined\nlabels.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2019 10:43:05 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Hasanzadeh", "Fatemeh", ""], ["Annabestani", "Mohsen", ""], ["Moghimi", "Sahar", ""]]}, {"id": "1910.10559", "submitter": "Roman Pogodin", "authors": "Roman Pogodin, Dane Corneil, Alexander Seeholzer, Joseph Heng, Wulfram\n  Gerstner", "title": "Working memory facilitates reward-modulated Hebbian learning in\n  recurrent neural networks", "comments": "NeurIPS 2019 workshop \"Real Neurons & Hidden Units: Future directions\n  at the intersection of neuroscience and artificial intelligence\", Vancouver,\n  Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reservoir computing is a powerful tool to explain how the brain learns\ntemporal sequences, such as movements, but existing learning schemes are either\nbiologically implausible or too inefficient to explain animal performance. We\nshow that a network can learn complicated sequences with a reward-modulated\nHebbian learning rule if the network of reservoir neurons is combined with a\nsecond network that serves as a dynamic working memory and provides a\nspatio-temporal backbone signal to the reservoir. In combination with the\nworking memory, reward-modulated Hebbian learning of the readout neurons\nperforms as well as FORCE learning, but with the advantage of a biologically\nplausible interpretation of both the learning rule and the learning paradigm.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2019 13:42:53 GMT"}], "update_date": "2019-10-24", "authors_parsed": [["Pogodin", "Roman", ""], ["Corneil", "Dane", ""], ["Seeholzer", "Alexander", ""], ["Heng", "Joseph", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1910.11182", "submitter": "Christian Benar", "authors": "Christian-G. B\\'enar (INS, AMU), C. Grova, V. Jirsa (INS, AMU), J.\n  Lina (ETS)", "title": "Differences in MEG and EEG power-law scaling explained by a coupling\n  between spatial coherence and frequency: a simulation study", "comments": null, "journal-ref": "Journal of Computational Neuroscience, Springer Verlag, 2019, 47\n  (1), pp.31-41", "doi": "10.1007/s10827-019-00721-9", "report-no": null, "categories": "q-bio.NC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrophysiological signals (electroencephalography, EEG, and\nmagnetoencephalography , MEG), as many natural processes, exhibit\nscale-invariance properties resulting in a power-law (1/f) spectrum.\nInterestingly, EEG and MEG differ in their slopes, which could be explained by\nseveral mechanisms, including non-resistive properties of tissues. Our goal in\nthe present study is to estimate the impact of space/frequency structure of\nsource signals as a putative mechanism to explain spectral scaling properties\nof neuroimaging signals. We performed simulations based on the summed\ncontribution of cortical patches with different sizes (ranging from 0.4 to\n104.2 cm 2). Small patches were attributed signals of high frequencies, whereas\nlarge patches were associated with signals of low frequencies, on a logarithmic\nscale. The tested parameters included i) the space/frequency structure (range\nof patch sizes and frequencies) and ii) the amplitude factor c parametrizing\nthe spatial scale ratios. We found that the space/frequency structure may cause\ndifferences between EEG and MEG scale-free spectra that are compatible with\nreal data findings reported in previous studies. We also found that below a\ncertain spatial scale, there were no more differences between EEG and MEG,\nsuggesting a limit for the resolution of both methods. Our work provides an\nexplanation of experimental findings. This does not rule out other mechanisms\nfor differences between EEG and MEG, but suggests an important role of\nspatio-temporal structure of neural dynamics. This can help the analysis and\ninterpretation of power-law measures in EEG and MEG, and we believe our results\ncan also impact computational modeling of brain dynamics, where different local\nconnectivity structures could be used at different frequencies.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 14:41:02 GMT"}], "update_date": "2019-10-25", "authors_parsed": [["B\u00e9nar", "Christian-G.", "", "INS, AMU"], ["Grova", "C.", "", "INS, AMU"], ["Jirsa", "V.", "", "INS, AMU"], ["Lina", "J.", "", "ETS"]]}, {"id": "1910.11380", "submitter": "Sahar Hojjatinia", "authors": "Sahar Hojjatinia, Mahdi Aliyari Shoorehdeli, Zahra Fatahi, Zeinab\n  Hojjatinia, Abbas Haghparast", "title": "Improving the Izhikevich Model Based on Rat Basolateral Amygdala and\n  Hippocampus Neurons, and Recognizing Their Possible Firing Patterns", "comments": "29 pages, 3 figures, 2 supplemental figures, 2 tables", "journal-ref": "Basic and Clinical Neuroscience 11.1 (2020): 79", "doi": "10.32598/bcn.9.10.435", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introduction- Identifying the potential firing patterns following different\nbrain regions under normal and abnormal conditions increases our understanding\nof events at the level of neural interactions in the brain. The Izhikevich\nmodel is one of the simplest biologically plausible models, i.e. capable of\ncapturing the most recognized firing patterns of neurons. This property makes\nthe model efficient in simulating the large-scale networks of neurons.\nImproving the Izhikevich model for adapting to the neuronal activity of the rat\nbrain with great accuracy would make the model effective for future neural\nnetwork implementations. Methods- Data sampling from two brain regions, the HIP\nand BLA, was performed by the extracellular recordings of male rats, and spike\nsorting was conducted by Plexon offline sorter. Further analyses were performed\nthrough NeuroExplorer and MATLAB. To optimize the Izhikevich model parameters,\na genetic algorithm was used. The process of comparison in each iteration leads\nto the survival of better populations until achieving the optimum solution.\nResults- In the present study, the possible firing patterns of the real single\nneurons of the HIP and BLA were identified. Additionally, an improved\nIzhikevich model was achieved. Accordingly, the real neuronal spiking pattern\nof these regions neurons and the corresponding cases of the Izhikevich neuron\nspiking pattern were adjusted with great accuracy. Conclusion- This study was\nconducted to elevate our knowledge of neural interactions in different\nstructures of the brain and accelerate the quality of future large-scale neural\nnetwork simulations, as well as reducing the modeling complexity. This aim was\nachievable by performing the improved Izhikevich model, and inserting only the\nplausible firing patterns, and eliminating unrealistic ones.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2019 19:04:36 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 00:02:16 GMT"}, {"version": "v3", "created": "Mon, 1 Mar 2021 05:22:10 GMT"}, {"version": "v4", "created": "Sat, 6 Mar 2021 20:36:40 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Hojjatinia", "Sahar", ""], ["Shoorehdeli", "Mahdi Aliyari", ""], ["Fatahi", "Zahra", ""], ["Hojjatinia", "Zeinab", ""], ["Haghparast", "Abbas", ""]]}, {"id": "1910.12492", "submitter": "Leendert Remmelzwaal", "authors": "Leendert A Remmelzwaal, Amit K Mishra, George F R Ellis", "title": "CTNN: Corticothalamic-inspired neural network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sensory predictions by the brain in all modalities take place as a result of\nbottom-up and top-down connections both in the neocortex and between the\nneocortex and the thalamus. The bottom-up connections in the cortex are\nresponsible for learning, pattern recognition, and object classification, and\nhave been widely modelled using artificial neural networks (ANNs). Here, we\npresent a neural network architecture modelled on the top-down corticothalamic\nconnections and the behaviour of the thalamus: a corticothalamic neural network\n(CTNN), consisting of an auto-encoder connected to a difference engine with a\nthreshold. We demonstrate that the CTNN is input agnostic, multi-modal, robust\nduring partial occlusion of one or more sensory inputs, and has significantly\nhigher processing efficiency than other predictive coding models, proportional\nto the number of sequentially similar inputs in a sequence. This increased\nefficiency could be highly significant in more complex implementations of this\narchitecture, where the predictive nature of the cortex will allow most of the\nincoming data to be discarded.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 08:15:25 GMT"}, {"version": "v2", "created": "Mon, 16 Mar 2020 10:07:08 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 08:10:46 GMT"}], "update_date": "2020-04-14", "authors_parsed": [["Remmelzwaal", "Leendert A", ""], ["Mishra", "Amit K", ""], ["Ellis", "George F R", ""]]}, {"id": "1910.12725", "submitter": "Juan Carlos Castro-Palacio", "authors": "Juan Carlos Castro-Palacio, Pedro Fern\\'andez de C\\'ordoba, J. M.\n  Isidro, and Esperanza Navarro-Pardo", "title": "Brain reaction times: Linking individual and collective behaviour\n  through Physics modelling", "comments": "16 pages and 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An individual's reaction time data to visual stimuli have usually been\nrepresented in Experimental Psychology by means of an ex-Gaussian function\n(EGF). In most previous works, researchers have mainly aimed at finding a\nmeaning for the parameters of the EGF function in relation to psychological\nphenomena. We will focus on interpreting the reaction times (RTs) of a group of\nindividuals rather than a single person's RT, which is relevant for the\ndifferent contexts of social sciences. In doing so, the same model as for the\nIdeal Gases (IG) (an inanimate system of non-interacting particles) emerges\nfrom the experimental RT data. Both systems are characterised by a collective\nparameter which is k_BT in the case of the system of particles and what we have\ncalled life span parameter for the system of brains. Similarly, we came across\na Maxwell-Boltzmann-type distribution for the system of brains which provides a\nnatural and more complete characterisation of the collective time response than\nhas ever been provided before. Thus, we are able to know about the behaviour of\na single individual in relation to the coetaneous group to which they belong\nand through the application of a physical law. This leads to a new\nentropy-based methodology for the classification of the individuals forming the\nsystem which emerges from the physical law governing the system of brains. To\nthe best of our knowledge, this is the first work in the literature reporting\non the emergence of a physical theory (IG) from human RT experimental data.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2019 14:48:02 GMT"}, {"version": "v2", "created": "Tue, 19 Nov 2019 06:16:59 GMT"}], "update_date": "2019-11-20", "authors_parsed": [["Castro-Palacio", "Juan Carlos", ""], ["de C\u00f3rdoba", "Pedro Fern\u00e1ndez", ""], ["Isidro", "J. M.", ""], ["Navarro-Pardo", "Esperanza", ""]]}, {"id": "1910.13201", "submitter": "Stefanus Wirdatmadja", "authors": "Stefanus Wirdatmadja, Josep Miquel Jornet, Yevgeni Koucheryavy,\n  Sasitharan Balasubramaniam", "title": "Channel Impulse Analysis of Light Propagation for Point-to-point Nano\n  Communications through Cortical Neurons", "comments": "26 pages, 10 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent Brain-Machine Interfaces have shifted towards miniature devices that\nare constructed from nanoscale components. While these devices can be implanted\ninto the brain, their functionalities can be limited, and will require\ncommunication and networking to enable cooperation. One form of communication\nfor neuron stimulation is the use of light. A number of considerations needs to\nbe taken into account for the propagation and this includes diffraction,\nscattering, absorption, as well as attenuation. These properties are not only\naffected by the medium, but also by the cell's geometric shape. These factor\naffects both the direction and amplitude of the light wave. This paper analyzes\nthe propagation path loss and geometrical gain, channel impulse and frequency\nresponse for light propagation along the neural tissue. The total attenuation\ndepends on the propagation medium loss and geometrical gain, and the channel\nresponse is highly dependent on the quantity of cells along the path.\nAdditionally, the optical properties of the medium also impacts on the time\ndelay at the receiver and the width the location of the detectors. Based on the\nnumerical analysis, spherical cells attenuate approximately 20% of the\ntransmitted power, which is less than the fusiform and pyramidal cells (35% and\n65%, respectively).\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2019 11:16:54 GMT"}, {"version": "v2", "created": "Fri, 1 Nov 2019 17:06:04 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Wirdatmadja", "Stefanus", ""], ["Jornet", "Josep Miquel", ""], ["Koucheryavy", "Yevgeni", ""], ["Balasubramaniam", "Sasitharan", ""]]}, {"id": "1910.13443", "submitter": "Adam Safron", "authors": "Adam Safron", "title": "Multilevel evolutionary developmental optimization (MEDO): A theoretical\n  framework for understanding preferences and selection dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What is motivation and how does it work? Where do goals come from and how do\nthey vary within and between species and individuals? Why do we prefer some\nthings over others? MEDO is a theoretical framework for understanding these\nquestions in abstract terms, as well as for generating and evaluating specific\nhypotheses that seek to explain goal-oriented behavior. MEDO views preferences\nas selective pressures influencing the likelihood of particular outcomes. With\nrespect to biological organisms, these patterns must compete and cooperate in\nshaping system evolution. To the extent that shaping processes are themselves\naltered by experience, this enables feedback relationships where histories of\nreward and punishment can impact future motivation. In this way, various biases\ncan undergo either amplification or attenuation, resulting in preferences and\nbehavioral orientations of varying degrees of inter-temporal and\ninter-situational stability. MEDO specifically models all shaping dynamics in\nterms of natural selection operating on multiple levels--genetic, neural, and\ncultural--and even considers aspects of development to themselves be\nevolutionary processes. Thus, MEDO reflects a kind of generalized Darwinism, in\nthat it assumes that natural selection provides a common principle for\nunderstanding the emergence of complexity within all dynamical systems in which\nreplication, variation, and selection occur. However, MEDO combines this\nevolutionary perspective with economic decision theory, which describes both\nthe preferences underlying individual choices, as well as the preferences\nunderlying choices made by engineers in designing optimized systems. In this\nway, MEDO uses economic decision theory to describe goal-oriented behaviors as\nwell as the interacting evolutionary optimization processes from which they\nemerge. (Please note: this manuscript was written and finalized in 2012.)\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 22:58:17 GMT"}, {"version": "v2", "created": "Sun, 10 Nov 2019 02:18:59 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Safron", "Adam", ""]]}, {"id": "1910.14098", "submitter": "Sahar Hojjatinia", "authors": "Sahar Hojjatinia, Constantino M. Lagoa", "title": "Comparison of Different Spike Sorting Subtechniques Based on Rat Brain\n  Basolateral Amygdala Neuronal Activity", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developing electrophysiological recordings of brain neuronal activity and\ntheir analysis provide a basis for exploring the structure of brain function\nand nervous system investigation. The recorded signals are typically a\ncombination of spikes and noise. High amounts of background noise and\npossibility of electric signaling recording from several neurons adjacent to\nthe recording site have led scientists to develop neuronal signal processing\ntools such as spike sorting to facilitate brain data analysis. Spike sorting\nplays a pivotal role in understanding the electrophysiological activity of\nneuronal networks. This process prepares recorded data for interpretations of\nneurons interactions and understanding the overall structure of brain\nfunctions. Spike sorting consists of three steps: spike detection, feature\nextraction, and spike clustering. There are several methods to implement each\nof spike sorting steps. This paper provides a systematic comparison of various\nspike sorting sub-techniques applied to real extracellularly recorded data from\na rat brain basolateral amygdala. An efficient sorted data resulted from\ncareful choice of spike sorting sub-methods leads to better interpretation of\nthe brain structures connectivity under different conditions, which is a very\nsensitive concept in diagnosis and treatment of neurological disorders. Here,\nspike detection is performed by appropriate choice of threshold level via three\ndifferent approaches. Feature extraction is done through PCA and Kernel PCA\nmethods, which Kernel PCA outperforms. We have applied four different\nalgorithms for spike clustering including K-means, Fuzzy C-means, Bayesian and\nFuzzy maximum likelihood estimation. As one requirement of most clustering\nalgorithms, optimal number of clusters is achieved through validity indices for\neach method. Finally, the sorting results are evaluated using inter-spike\ninterval histograms.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2019 00:44:24 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Hojjatinia", "Sahar", ""], ["Lagoa", "Constantino M.", ""]]}, {"id": "1910.14292", "submitter": "Eva Guttmann-Flury", "authors": "E. Guttmann-Flury, X. Sheng, D. Zhang, and X. Zhu", "title": "Preliminary Results on a New Algorithm for Blink Correction Adaptive to\n  Inter- and Intra-Subject Variability", "comments": null, "journal-ref": null, "doi": "10.1109/ner.2019.8717029", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new preprocessing method to correct blinking artifacts\nin Electroencephalography (EEG) based Brain-Computer Interfaces (BCIs). This\nAlgorithm for Blink Correction (ABC) directly corrects the signal in the time\ndomain without the need for additional Electrooculogram (EOG) electrodes. The\nmain idea is to automatically adapt to the blink's inter- and intra-subject\nvariability by considering the blink's amplitude as a parameter. A simple\nMinimum Distance to Riemannian Mean (MDRM) is applied as the classification\nalgorithm. Preliminary results on three subjects show a mean classification\naccuracy increase of 13.7% using ABC.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 08:00:42 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["Guttmann-Flury", "E.", ""], ["Sheng", "X.", ""], ["Zhang", "D.", ""], ["Zhu", "X.", ""]]}, {"id": "1910.14339", "submitter": "Luis F Seoane PhD", "authors": "Seoane LF, Sol\\'e R", "title": "How Turing parasites expand the computational landscape of digital life", "comments": "17 pages (~11 main text + ~6 appendixes), 7 main figures, 7\n  supporting figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.PE cond-mat.dis-nn nlin.AO nlin.CG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Why are living systems complex? Why does the biosphere contain living beings\nwith complexity features beyond those of the simplest replicators? What kind of\nevolutionary pressures result in more complex life forms? These are key\nquestions that pervade the problem of how complexity arises in evolution. One\nparticular way of tackling this is grounded in an algorithmic description of\nlife: living organisms can be seen as systems that extract and process\ninformation from their surroundings in order to reduce uncertainty. Here we\ntake this computational approach using a simple bit string model of coevolving\nagents and their parasites. While agents try to predict their worlds, parasites\ndo the same with their hosts. The result of this process is that, in order to\nescape their parasites, the host agents expand their computational complexity\ndespite the cost of maintaining it. This, in turn, is followed by increasingly\ncomplex parasitic counterparts. Such arms races display several qualitative\nphases, from monotonous to punctuated evolution or even ecological collapse.\nOur minimal model illustrates the relevance of parasites in providing an active\nmechanism for expanding living complexity beyond simple replicators, suggesting\nthat parasitic agents are likely to be a major evolutionary driver for\nbiological complexity.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2019 10:02:20 GMT"}, {"version": "v2", "created": "Thu, 30 Apr 2020 16:59:48 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 14:24:03 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["LF", "Seoane", ""], ["R", "Sol\u00e9", ""]]}]