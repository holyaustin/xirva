[{"id": "0810.0029", "submitter": "Guillermo Cecchi", "authors": "James R. Kozloski and Guillermo A. Cecchi", "title": "Topological Effects of Synaptic Time Dependent Plasticity", "comments": "26 pages, 5 figures", "journal-ref": "Frontiers in Neural Circuits, March 2010, Volume 4, Article 7", "doi": "10.3389/fncir.2010.00007", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn math-ph math.MP q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the local Spike Timing-Dependent Plasticity (STDP) rule has the\neffect of regulating the trans-synaptic weights of loops of any length within a\nsimulated network of neurons. We show that depending on STDP's polarity,\nfunctional loops are formed or eliminated in networks driven to normal spiking\nconditions by random, partially correlated inputs, where functional loops\ncomprise weights that exceed a non-zero threshold. We further prove that STDP\nis a form of loop-regulating plasticity for the case of a linear network\ncomprising random weights drawn from certain distributions. Thus a notable\nlocal synaptic learning rule makes a specific prediction about synapses in the\nbrain in which standard STDP is present: that under normal spiking conditions,\nthey should participate in predominantly feed-forward connections at all\nscales. Our model implies that any deviations from this prediction would\nrequire a substantial modification to the hypothesized role for standard STDP.\nGiven its widespread occurrence in the brain, we predict that STDP could also\nregulate long range synaptic loops among individual neurons across all brain\nscales, up to, and including, the scale of global brain network topology.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2008 21:16:26 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2009 18:24:48 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2010 23:12:26 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Kozloski", "James R.", ""], ["Cecchi", "Guillermo A.", ""]]}, {"id": "0810.0479", "submitter": "Carsten Allefeld", "authors": "Carsten Allefeld, Harald Atmanspacher, Jiri Wackermann", "title": "Mental States as Macrostates Emerging from EEG Dynamics", "comments": "corrected typos, added journal reference", "journal-ref": "published as: Mental states as macrostates emerging from brain\n  electrical dynamics. Chaos, 19(1):015102, 2009", "doi": "10.1063/1.3072788", "report-no": null, "categories": "physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Correlations between psychological and physiological phenomena form the basis\nfor different medical and scientific disciplines, but the nature of this\nrelation has not yet been fully understood. One conceptual option is to\nunderstand the mental as \"emerging\" from neural processes in the specific sense\nthat psychology and physiology provide two different descriptions of the same\nsystem. Stating these descriptions in terms of coarser- and finer-grained\nsystem states (macro- and microstates), the two descriptions may be equally\nadequate if the coarse-graining preserves the possibility to obtain a dynamical\nrule for the system. To test the empirical viability of our approach, we\ndescribe an algorithm to obtain a specific form of such a coarse-graining from\ndata, and illustrate its operation using a simulated dynamical system. We then\napply the method to an electroencephalographic (EEG) recording, where we are\nable to identify macrostates from the physiological data that correspond to\nmental states of the subject.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2008 16:41:44 GMT"}, {"version": "v2", "created": "Mon, 13 Oct 2008 13:02:07 GMT"}, {"version": "v3", "created": "Wed, 8 Apr 2009 16:45:22 GMT"}], "update_date": "2009-04-08", "authors_parsed": [["Allefeld", "Carsten", ""], ["Atmanspacher", "Harald", ""], ["Wackermann", "Jiri", ""]]}, {"id": "0810.1544", "submitter": "Jonathan Newman", "authors": "J.P. Newman and R.J. Butera", "title": "Mechanism, dynamics, and biological existence of multistability in a\n  large class of bursting neurons", "comments": "24 pages, 8 figures", "journal-ref": "J.P. Newman and R.J. Butera. Mechanism, dynamics, and biological\n  existence of multistability in a large class of bursting neurons. Chaos 20,\n  2010", "doi": "10.1063/1.341399", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multistability, the coexistence of multiple attractors in a dynamical system,\nis explored in bursting nerve cells. A modeling study is performed to show that\na large class of bursting systems, as defined by a shared topology when\nrepresented as dynamical systems, is inherently suited to support\nmultistability. We derive the bifurcation structure and parametric trends\nleading to multistability in these systems. Evidence for the existence of\nmultirhythmic behavior in neurons of the aquatic mollusc Aplysia californica\nthat is consistent with our proposed mechanism is presented. Although these\nexperimental results are preliminary, they indicate that single neurons may be\ncapable of dynamically storing information for longer time scales than\ntypically attributed to nonsynaptic mechanisms.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2008 21:29:06 GMT"}, {"version": "v2", "created": "Sun, 19 Jul 2009 00:33:42 GMT"}, {"version": "v3", "created": "Mon, 28 Jun 2010 03:10:41 GMT"}], "update_date": "2010-06-29", "authors_parsed": [["Newman", "J. P.", ""], ["Butera", "R. J.", ""]]}, {"id": "0810.2152", "submitter": "Kresimir Josic", "authors": "Kresimir Josic, Eric Shea-Brown, Brent Doiron, Jaime de la Rocha", "title": "Stimulus-dependent correlations and population codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The magnitude of correlations between stimulus-driven responses of pairs of\nneurons can itself be stimulus-dependent. We examine how this dependence\nimpacts the information carried by neural populations about the stimuli that\ndrive them. Stimulus-dependent changes in correlations can both carry\ninformation directly and modulate the information separately carried by the\nfiring rates and variances. We use Fisher information to quantify these effects\nand show that, although stimulus dependent correlations often carry little\ninformation directly, their modulatory effects on the overall information can\nbe large. In particular, if the stimulus-dependence is such that correlations\nincrease with stimulus-induced firing rates, this can significantly enhance the\ninformation of the population when the structure of correlations is determined\nsolely by the stimulus. However, in the presence of additional strong spatial\ndecay of correlations, such stimulus-dependence may have a negative impact.\nOpposite relationships hold when correlations decrease with firing rates.\n", "versions": [{"version": "v1", "created": "Mon, 13 Oct 2008 04:45:47 GMT"}], "update_date": "2008-10-14", "authors_parsed": [["Josic", "Kresimir", ""], ["Shea-Brown", "Eric", ""], ["Doiron", "Brent", ""], ["de la Rocha", "Jaime", ""]]}, {"id": "0810.2749", "submitter": "Christoph Kirst", "authors": "Christoph Kirst, Theo Geisel and Marc Timme", "title": "Sequential Desynchronization in Networks of Spiking Neurons with Partial\n  Reset", "comments": null, "journal-ref": "Phys. Rev. Lett. 102, 068101 (2009)", "doi": "10.1103/PhysRevLett.102.068101", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The response of a neuron to synaptic input strongly depends on whether or not\nit has just emitted a spike. We propose a neuron model that after spike\nemission exhibits a partial response to residual input charges and study its\ncollective network dynamics analytically. We uncover a novel desynchronization\nmechanism that causes a sequential desynchronization transition: In globally\ncoupled neurons an increase in the strength of the partial response induces a\nsequence of bifurcations from states with large clusters of synchronously\nfiring neurons, through states with smaller clusters to completely asynchronous\nspiking. We briefly discuss key consequences of this mechanism for more general\nnetworks of biophysical neurons.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2008 18:04:21 GMT"}], "update_date": "2010-06-04", "authors_parsed": [["Kirst", "Christoph", ""], ["Geisel", "Theo", ""], ["Timme", "Marc", ""]]}, {"id": "0810.2872", "submitter": "Matthias Bethge", "authors": "Jan Eichhorn, Fabian Sinz and Matthias Bethge", "title": "Natural Image Coding in V1: How Much Use is Orientation Selectivity?", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1000336", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orientation selectivity is the most striking feature of simple cell coding in\nV1 which has been shown to emerge from the reduction of higher-order\ncorrelations in natural images in a large variety of statistical image models.\nThe most parsimonious one among these models is linear Independent Component\nAnalysis (ICA), whereas second-order decorrelation transformations such as\nPrincipal Component Analysis (PCA) do not yield oriented filters. Because of\nthis finding it has been suggested that the emergence of orientation\nselectivity may be explained by higher-order redundancy reduction. In order to\nassess the tenability of this hypothesis, it is an important empirical question\nhow much more redundancies can be removed with ICA in comparison to PCA, or\nother second-order decorrelation methods. This question has not yet been\nsettled, as over the last ten years contradicting results have been reported\nranging from less than five to more than hundred percent extra gain for ICA.\nHere, we aim at resolving this conflict by presenting a very careful and\ncomprehensive analysis using three evaluation criteria related to redundancy\nreduction: In addition to the multi-information and the average log-loss we\ncompute, for the first time, complete rate-distortion curves for ICA in\ncomparison with PCA. Without exception, we find that the advantage of the ICA\nfilters is surprisingly small. Furthermore, we show that a simple spherically\nsymmetric distribution with only two parameters can fit the data even better\nthan the probabilistic model underlying ICA. Since spherically symmetric models\nare agnostic with respect to the specific filter shapes, we conlude that\norientation selectivity is unlikely to play a critical role for redundancy\nreduction.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2008 19:11:39 GMT"}, {"version": "v2", "created": "Thu, 16 Oct 2008 20:26:01 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Eichhorn", "Jan", ""], ["Sinz", "Fabian", ""], ["Bethge", "Matthias", ""]]}, {"id": "0810.2901", "submitter": "Tatjana Tchumatchenko", "authors": "Tatjana Tchumatchenko, Aleksey Malyshev, Theo Geisel, Maxim Volgushev,\n  Fred Wolf", "title": "Correlations and Synchrony in Threshold Neuron Models", "comments": "5 pages, 10 figures", "journal-ref": null, "doi": "10.1103/PhysRevLett.104.058102", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study how threshold model neurons transfer temporal and interneuronal\ninput correlations to correlations of spikes. We find that the low common input\nregime is governed by firing rate dependent spike correlations which are\nsensitive to the detailed structure of input correlation functions. In the high\ncommon input regime the spike correlations are insensitive to the firing rate\nand exhibit a universal peak shape independent of input correlations. Rate\nheterogeneous pairs driven by common inputs in general exhibit asymmetric spike\ncorrelations. All predictions are confirmed in in vitro experiments with\ncortical neurons driven by synthesized fluctuating input currents.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2008 12:47:43 GMT"}, {"version": "v2", "created": "Mon, 20 Oct 2008 10:45:13 GMT"}, {"version": "v3", "created": "Fri, 17 Jul 2009 14:33:32 GMT"}], "update_date": "2013-05-29", "authors_parsed": [["Tchumatchenko", "Tatjana", ""], ["Malyshev", "Aleksey", ""], ["Geisel", "Theo", ""], ["Volgushev", "Maxim", ""], ["Wolf", "Fred", ""]]}, {"id": "0810.3342", "submitter": "Hideo Hasegawa", "authors": "Hideo Hasegawa (Tokyo Gakugei Univ.)", "title": "Population rate codes carried by mean, fluctuation and synchrony of\n  neuronal firings", "comments": "20 pages, 10 figures, accepted in Physica A (revised version of\n  arXiv:0706.3489)", "journal-ref": "Physica A 388 (2009) 499-513", "doi": "10.1016/j.physa.2008.10.033", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A population of firing neurons is expected to carry information not only by\nmean firing rate but also by fluctuation and synchrony among neurons. In order\nto examine this possibility, we have studied responses of neuronal ensembles to\nthree kinds of inputs: mean-, fluctuation- and synchrony-driven inputs. The\ngeneralized rate-code model including additive and multiplicative noise (H.\nHasegawa, Phys. Rev. E {\\bf 75} (2007) 051904) has been studied by direct\nsimulations (DSs) and the augmented moment method (AMM) in which equations of\nmotion for mean firing rate, fluctuation and synchrony are derived. Results\ncalculated by the AMM are in good agreement with those by DSs. The independent\ncomponent analysis (ICA) of our results has shown that mean firing rate,\nfluctuation (or variability) and synchrony may carry independent information in\nthe population rate-code model. The input-output relation of mean firing rates\nis shown to have higher sensitivity for larger multiplicative noise, as\nrecently observed in prefrontal cortex. A comparison is made between results\nobtained by the integrate-and-fire (IF) model and our rate-code model.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2008 19:32:29 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Hasegawa", "Hideo", "", "Tokyo Gakugei Univ."]]}, {"id": "0810.3983", "submitter": "Bruno. Cessac", "authors": "B. Cessac, H. Rostro, J.C. Vasquez, T. Vi\\'eville", "title": "Statistics of spikes trains, synaptic plasticity and Gibbs distributions", "comments": "6 pages, 1 figure, proceeding of the NeuroComp 2008 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cond-mat.stat-mech math-ph math.MP nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a mathematical framework where the statistics of spikes trains,\nproduced by neural networks evolving under synaptic plasticity, can be\nanalysed.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2008 07:04:06 GMT"}], "update_date": "2008-10-23", "authors_parsed": [["Cessac", "B.", ""], ["Rostro", "H.", ""], ["Vasquez", "J. C.", ""], ["Vi\u00e9ville", "T.", ""]]}, {"id": "0810.3990", "submitter": "Bruno. Cessac", "authors": "Bruno Cessac, Horacio Rostro-Gonz\\'alez, Juan-Carlos Vasquez, Thierry\n  Vi\\'eville", "title": "To which extend is the \"neural code\" a metric ?", "comments": "5 pages 5 figures Proceeding of the conference NeuroComp2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph cs.NE physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here is proposed a review of the different choices to structure spike trains,\nusing deterministic metrics. Temporal constraints observed in biological or\ncomputational spike trains are first taken into account. The relation with\nexisting neural codes (rate coding, rank coding, phase coding, ..) is then\ndiscussed. To which extend the \"neural code\" contained in spike trains is\nrelated to a metric appears to be a key point, a generalization of the\nVictor-Purpura metric family being proposed for temporal constrained causal\nspike trains\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2008 07:34:25 GMT"}], "update_date": "2008-10-23", "authors_parsed": [["Cessac", "Bruno", ""], ["Rostro-Gonz\u00e1lez", "Horacio", ""], ["Vasquez", "Juan-Carlos", ""], ["Vi\u00e9ville", "Thierry", ""]]}, {"id": "0810.3992", "submitter": "Bruno. Cessac", "authors": "Bruno Cessac, Olivier Rochel, Thierry Vi\\'eville", "title": "Introducing numerical bounds to improve event-based neural network\n  simulation", "comments": "submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO cs.NE nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the spike-trains in neural networks are mainly constrained by the\nneural dynamics itself, global temporal constraints (refractoriness, time\nprecision, propagation delays, ..) are also to be taken into account. These\nconstraints are revisited in this paper in order to use them in event-based\nsimulation paradigms.\n  We first review these constraints, and discuss their consequences at the\nsimulation level, showing how event-based simulation of time-constrained\nnetworks can be simplified in this context: the underlying data-structures are\nstrongly simplified, while event-based and clock-based mechanisms can be easily\nmixed. These ideas are applied to punctual conductance-based generalized\nintegrate-and-fire neural networks simulation, while spike-response model\nsimulations are also revisited within this framework.\n  As an outcome, a fast minimal complementary alternative with respect to\nexisting simulation event-based methods, with the possibility to simulate\ninteresting neuron models is implemented and experimented.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2008 08:02:47 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2009 10:55:15 GMT"}], "update_date": "2009-03-20", "authors_parsed": [["Cessac", "Bruno", ""], ["Rochel", "Olivier", ""], ["Vi\u00e9ville", "Thierry", ""]]}, {"id": "0810.4629", "submitter": "Bradly  Alicea", "authors": "Bradly Alicea", "title": "Performance augmentation in hybrid bionic systems: techniques and\n  experiment", "comments": "43 pages, 15 figures, 7 tables. May also be clasified to cs.HC", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in hybrid biological-technological systems (hybrid bionic\nsystems) has made clear the need for evaluating ergonomic fit in such systems,\nespecially as users first become adjusted to using such systems. This training\nis accompanied by physiological adaptation, and can be thought of\ncomputationally as a relative degree of matching between prosthetic devices,\nphysiology, and behavior. Achieving performance augmentation involves two\nfeatures of performance: a specific form of learning, memory, and\nmechanotransduction called sensorimotor learning, and physiological adaptation\nto novel physical information imposed by the augmented environment of hybrid\nbionic systems. A method borrowed from environmental medicine involving\nperturbing the environment for a range of internal physiological conditions was\nused to induce sensorimotor learning and memory associated physiological\nchanges. In addition, features of the adult phenotype were considered as a\nmitigator of learning-related adaptations. Using a series of statistical tests\nand techniques, the results demonstrate than three forms of regulation are at\nwork related to morphological, neural, and muscular control. A discussion of\nthe conceptual relationship between homeostasis and adaptation will then be\ndiscussed in addition to potential applications to performance augmentation\nstrategies.\n", "versions": [{"version": "v1", "created": "Sat, 25 Oct 2008 17:47:38 GMT"}, {"version": "v2", "created": "Mon, 27 Oct 2008 20:42:27 GMT"}, {"version": "v3", "created": "Wed, 22 Apr 2009 01:29:53 GMT"}], "update_date": "2009-04-22", "authors_parsed": [["Alicea", "Bradly", ""]]}, {"id": "0810.5198", "submitter": "Chandrasekar Kuppusamy", "authors": "Jane H. Sheeba, Aneta Stefanovska and Peter V. E. McClintock", "title": "Neuronal synchrony during anaesthesia - A thalamocortical model", "comments": "18 pages, 3 figures", "journal-ref": "Biophys. J., 95(6), 2722-2727, 2008", "doi": "10.1529/biophysj.108.134635", "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing evidence in favour of the temporal-coding hypothesis that\ntemporal correlation of neuronal discharges may serve to bind distributed\nneuronal activity into unique representations and, in particular, that $\\theta$\n(3.5-7.5 Hz) and $\\delta$ ($0.5<$3.5 Hz) oscillations facilitate information\ncoding. The $\\theta$ and $\\delta$ rhythms are shown to be involved in various\nsleep stages, and during an{\\ae}sthesia, and they undergo changes with the\ndepth of an{\\ae}sthesia. We introduce a thalamocortical model of interacting\nneuronal ensembles to describe phase relationships between $\\theta$ and\n$\\delta$ oscillations, especially during deep and light an{\\ae}sthesia.\nAsymmetric and long range interactions among the thalamocortical neuronal\noscillators are taken into account. The model results are compared with the\nexperimental observations of Musizza et al. {\\it J. Physiol. (London)} 2007\n580:315-326. The $\\delta$ and $\\theta$ activities are found to be separately\ngenerated and are governed by the thalamus and cortex respectively. Changes in\nthe degree of intra--ensemble and inter--ensemble synchrony imply that the\nneuronal ensembles inhibit information coding during deep an{\\ae}sthesia and\nfacilitate it during light an{\\ae}sthesia.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2008 05:59:07 GMT"}], "update_date": "2008-10-30", "authors_parsed": [["Sheeba", "Jane H.", ""], ["Stefanovska", "Aneta", ""], ["McClintock", "Peter V. E.", ""]]}, {"id": "0810.5381", "submitter": "Nikesh Dattani", "authors": "Nikesh S. Dattani", "title": "Simulating neurobiological localization of acoustic signals based on\n  temporal and volumetric differentiations", "comments": "26 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The localization of sound sources by the human brain is computationally\nsimulated from a neurobiological perspective. The simulation includes the\nneural representation of temporal differences in acoustic signals between the\nipsilateral and contralateral ears for constant sound intensities (angular\nlocalization), and of volumetric differences in acoustic signals for constant\nazimuthal angles (radial localization). The transmission of the original\nacoustic signal from the environment, through each significant stage of\nintermediate neurons, to the primary auditory cortex, is also simulated. The\nerrors that human brains make in attempting to localize sounds in\nevolutionarily uncommon environments (such as when one ear is in water and one\near is in air) are then mathematically predicted. A basic overview of the\nphysiology behind sound localization in the brain is also provided.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2008 23:10:38 GMT"}], "update_date": "2008-10-31", "authors_parsed": [["Dattani", "Nikesh S.", ""]]}]