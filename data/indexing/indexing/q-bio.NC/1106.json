[{"id": "1106.0758", "submitter": "Giambattista Giacomin", "authors": "Giambattista Giacomin, Khashayar Pakdaman, Xavier Pellegrin,\n  Christophe Poquet", "title": "Transitions in active rotator systems: invariant hyperbolic manifold\n  approach", "comments": "29 pages, 4 figures. Version 2: some changes in introduction, added\n  references", "journal-ref": null, "doi": null, "report-no": null, "categories": "math-ph math.MP nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our main focus is on a general class of active rotators with mean field\ninteractions, that is globally coupled large families of dynamical systems on\nthe unit circle with non-trivial stochastic dynamics. Each isolated system is a\ndiffusion process on a circle, with drift -delta V', where V' is a periodic\nfunction and delta is an intensity parameter. It is well known that the\ninteracting dynamics is accurately described, in the limit of infinitely many\ninteracting components, by a Fokker-Planck PDE and the model reduces for\ndelta=0 to a particular case of the Kuramoto synchronization model, for which\none can show the existence of a stable normally hyperbolic manifold of\nstationary solutions for the corresponding Fokker-Planck equation (we are\ninterested in the case in which this manifold is non-trivial, that happens when\nthe interaction is sufficiently strong, that is in the synchronized regime of\nthe Kuramoto model). We use the robustness of normally hyperbolic structures to\ninfer qualitative and quantitative results on the |delta|< delta0 cases, with\ndelta0 a suitable threshold: as a matter of fact, we obtain an accurate\ndescription of the dynamics on the invariant manifold for delta=0 and we link\nit explicitly to the potential V . This approach allows to have a complete\ndescription of the phase diagram of the active rotators model, at least for\n|delta|< delta0, thus identifying for which values of the parameters (notably,\nnoise intensity and/or coupling strength) the system exhibits periodic pulse\nwaves or stabilizes at a quiescent resting state. Moreover, some of our results\nare very explicit and this brings a new insight into the combined effect of\nactive rotator dynamics, noise and interaction. The links with the literature\non specific systems, notably neuronal models, are discussed in detail.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jun 2011 20:16:52 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2011 16:47:22 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Giacomin", "Giambattista", ""], ["Pakdaman", "Khashayar", ""], ["Pellegrin", "Xavier", ""], ["Poquet", "Christophe", ""]]}, {"id": "1106.0863", "submitter": "Andrea Barreiro", "authors": "Andrea K. Barreiro, Evan L. Thilo, Eric Shea-Brown", "title": "The A-current and Type I / Type II transition determine collective\n  spiking from common input", "comments": "42 pages, 10 figures v1: Submitted June 4, 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mechanisms and impact of correlated, or synchronous, firing among pairs\nand groups of neurons is under intense investigation throughout the nervous\nsystem. A ubiquitous circuit feature that can give rise to such correlations\nconsists of overlapping, or common, inputs to pairs and populations of cells,\nleading to common spike train responses. Here, we use computational tools to\nstudy how the transfer of common input currents into common spike outputs is\nmodulated by the physiology of the recipient cells. We focus on a key\nconductance - gA, for the A-type potassium current - which drives neurons\nbetween \"Type II\" excitability (low gA), and \"Type I\" excitability (high gA).\nRegardless of gA, cells transform common input fluctuations into a ten- dency\nto spike nearly simultaneously. However, this process is more pronounced at low\ngA values, as previously predicted by reduced \"phase\" models. Thus, for a given\nlevel of common input, Type II neurons produce spikes that are relatively more\ncorrelated over short time scales. Over long time scales, the trend reverses,\nwith Type II neurons producing relatively less correlated spike trains. This is\nbecause these cells' increased tendency for simultaneous spiking is balanced by\nopposing tendencies at larger time lags. We demonstrate a novel implication for\nneural signal processing: downstream cells with long time constants are\nselectively driven by Type I cell populations upstream, and those with short\ntime constants by Type II cell populations. Our results are established via\nhigh-throughput numerical simulations, and explained via the cells' filtering\nproperties and nonlinear dynamics.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jun 2011 22:29:34 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Barreiro", "Andrea K.", ""], ["Thilo", "Evan L.", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1106.1105", "submitter": "Bradly  Alicea", "authors": "Bradly Alicea", "title": "Naturally Supervised Learning in Manipulable Technologies", "comments": "27 pages, 12 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The relationship between physiological systems and modern electromechanical\ntechnologies is fast becoming intimate with high degrees of complex\ninteraction. It can be argued that muscular function, limb movements, and touch\nperception serve supervisory functions for movement control in motion and\ntouch-based (e.g. manipulable) devices/interfaces and human-machine interfaces\nin general. To get at this hypothesis requires the use of novel techniques and\nanalyses which demonstrate the multifaceted and regulatory role of adaptive\nphysiological processes in these interactions. Neuromechanics is an approach\nthat unifies the role of physiological function, motor performance, and\nenvironmental effects in determining human performance. A neuromechanical\nperspective will be used to explain the effect of environmental fluctuations on\nsupervisory mechanisms, which leads to adaptive physiological responses. Three\nexperiments are presented using two different types of virtual environment that\nallowed for selective switching between two sets of environmental forces. This\nswitching was done in various ways to maximize the variety of results.\nElectromyography (EMG) and kinematic information contributed to the development\nof human performance-related measures. Both descriptive and specialized\nanalyses were conducted: peak amplitude analysis, loop trace analysis, and the\nanalysis of unmatched muscle power. Results presented here provide a window\ninto performance under a range of conditions. These analyses also demonstrated\nmyriad consequences for force-related fluctuations on dynamic physiological\nregulation. The findings presented here could be applied to the dynamic control\nof touch-based and movement-sensitive human-machine systems. In particular, the\ndesign of systems such as human-robotic systems, touch screen devices, and\nrehabilitative technologies could benefit from this research.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jun 2011 16:01:10 GMT"}, {"version": "v2", "created": "Wed, 14 Mar 2012 13:49:43 GMT"}], "update_date": "2012-03-15", "authors_parsed": [["Alicea", "Bradly", ""]]}, {"id": "1106.2032", "submitter": "Silvia Scarpetta", "authors": "Siliva Scarpetta, Ferdinando Giacco, Antonio de Candia", "title": "Storage capacity of phase-coded patterns in sparse neural networks", "comments": "Accepted for publication in Europhysics Letters", "journal-ref": null, "doi": "10.1209/0295-5075/95/28006", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the storage of multiple phase-coded patterns as stable dynamical\nattractors in recurrent neural networks with sparse connectivity. To determine\nthe synaptic strength of existent connections and store the phase-coded\npatterns, we introduce a learning rule inspired to the spike-timing dependent\nplasticity (STDP). We find that, after learning, the spontaneous dynamics of\nthe network replay one of the stored dynamical patterns, depending on the\nnetwork initialization. We study the network capacity as a function of\ntopology, and find that a small- world-like topology may be optimal, as a\ncompromise between the high wiring cost of long range connections and the\ncapacity increase.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jun 2011 12:24:07 GMT"}], "update_date": "2015-05-28", "authors_parsed": [["Scarpetta", "Siliva", ""], ["Giacco", "Ferdinando", ""], ["de Candia", "Antonio", ""]]}, {"id": "1106.2048", "submitter": "Daniela Andres Dr", "authors": "Daniela Sabrina Andres", "title": "Old equations for a new system: A possible use of Navier-Stokes\n  equations to model the circulation of spikes in the nervous system", "comments": "8 pages, 1 color figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the present work we discuss a possible application of Navier-Stokes-based\nmodels to the quantitative description of the circulation of nervous impulses\nthroughout the nervous system. In previous works we have shown that the\ndischarge from Basal Ganglia neurons from patients with Parkinson's disease\nshare mathematical features with the velocity fields of fluids under turbulence\nregimes. In the present work we try to build the fundaments for a physical\nanalogy between both kinds of systems.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jun 2011 18:30:52 GMT"}], "update_date": "2011-06-13", "authors_parsed": [["Andres", "Daniela Sabrina", ""]]}, {"id": "1106.2250", "submitter": "Rhonda Dzakpasu", "authors": "Mark Niedringhaus, Xin Chen, Katherine Conant, Rhonda Dzakpasu", "title": "Synaptic potentiation facilitates memory-like attractor dynamics in\n  cultured in vitro hippocampal networks", "comments": null, "journal-ref": "Niedringhaus M, Chen X, Conant K, Dzakpasu R (2013) Synaptic\n  Potentiation Facilitates Memory-like Attractor Dynamics in Cultured In Vitro\n  Hippocampal Networks. PLoS ONE 8(3): e57144", "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective rhythmic dynamics from neurons is vital for cognitive functions\nsuch as memory formation but how neurons self-organize to produce such activity\nis not well understood. Attractor-based models have been successfully\nimplemented as a theoretical framework for memory storage in networks of\nneurons. Activity-dependent modification of synaptic transmission is thought to\nbe the physiological basis of learning and memory. The goal of this study is to\ndemonstrate that using a pharmacological perturbation on in vitro networks of\nhippocampal neurons that has been shown to increase synaptic strength follows\nthe dynamical postulates theorized by attractor models. We use a grid of\nextracellular electrodes to study changes in network activity after this\nperturbation and show that there is a persistent increase in overall spiking\nand bursting activity after treatment. This increase in activity appears to\nrecruit more \"errant\" spikes into bursts. Lastly, phase plots indicate a\nconserved activity pattern suggesting that the network is operating in a stable\ndynamical state.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2011 15:49:44 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2012 16:36:22 GMT"}], "update_date": "2013-03-22", "authors_parsed": [["Niedringhaus", "Mark", ""], ["Chen", "Xin", ""], ["Conant", "Katherine", ""], ["Dzakpasu", "Rhonda", ""]]}, {"id": "1106.2265", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "If Experts Converge on the Same Answer are they Less Creative than\n  Beginners? Redefining Creativity in Terms of Adaptive Landscapes", "comments": "19 pages; 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard view that creativity entails both originality and\nappropriateness leads to the paradox that experts who converge on one optimal\nsolution are rated as no more creative than beginners who give many original\nsolutions. This paper asserts that there is no one-size-fits-all definition of\ncreativity; creativity must be assessed relative to the constraints and\naffordances of the task. The flatter the adaptive landscape associated with the\ntask, the greater the extent to which creativity is a function of originality\nonly. For tasks with a single-peaked adaptive landscape, there is a tradeoff\nbetween originality and appropriateness. Only for tasks with rugged adaptive\nlandscapes is creativity positively correlated with both originality and\nappropriateness. It is suggested that the adaptive landscapes associated with\nartistic and scientific pursuits are equally rugged, but for artistic pursuits\ntheir topologies reflect idiosyncratic experiences and emotions (the peaks and\nvalleys are not aligned).\n", "versions": [{"version": "v1", "created": "Sat, 11 Jun 2011 22:42:33 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 00:36:23 GMT"}, {"version": "v3", "created": "Tue, 9 Jul 2019 18:59:02 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1106.2679", "submitter": "Avni Pllana", "authors": "Avni Pllana and Herbert Bauer", "title": "BEM-based SMS-LORETA - an advanced method to localize multiple\n  simultaneously active sources in the cerebral cortex", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the method and performance data of 'Boundary Element Method\n(BEM)'-based SMS-LORETA (Simultaneous Multiple Sources LORETA) are presented.\nAccording to these data the method is capable of locating efficiently multiple\nsimultaneously active neural sources from scalp potential topographies\nautomatically. BEM-based SMS-LORETA is a procedure to fully interpret sLORETA\nsolutions, i.e., with a given scalp potential distribution it gives the number\nof identifiable sources as well as their strength and orientation. Performance\ndata result from numerous analyses of simulated noise-free and\nnoise-contaminated potential distributions (topographies) that have been\nobtained by means of BEM-based forward solutions, where one, two or three\nsimultaneously active dipoles were randomly chosen regarding their positions\nand polarity.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jun 2011 11:37:46 GMT"}], "update_date": "2011-06-15", "authors_parsed": [["Pllana", "Avni", ""], ["Bauer", "Herbert", ""]]}, {"id": "1106.2977", "submitter": "Philip Sabes", "authors": "Timothy Verstynen and Philip N. Sabes", "title": "An analysis of the emergence of adaptive Bayesian priors from Hebbian\n  learning in a simple attractor network model", "comments": "Supplement to Verstynen and Sabes, \"How Each Movement Changes the\n  Next: an Experimental and Theoretical Study of Fast Adaptive Priors in\n  Reaching\", Journal of Neuroscience (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We have recently shown that the statistical properties of goal directed\nreaching in human subjects depends on recent experience in a way that is\nconsistent with the presence of adaptive Bayesian priors (Verstynen and Sabes,\n2011). We also showed that when Hebbian (associative) learning is added to a\nsimple line-attractor network model, the network provides both a good account\nof the experimental data and a good approximation to a normative Bayesian\nestimator. This latter conclusion was based entirely on empirical simulations\nof the network model. Here we study the effects of Hebbian learning on the\nline-attractor model using a combination of analytic and computational\napproaches. Specifically, we find an approximate solution to the network\nsteady-state. We show numerically that the solution approximates Bayesian\nestimation. We next show that the solution contains two opposing terms: one\nthat depends on the distribution of recent network activity and one that\ndepends on the current network inputs. These results provide additional\nintuition for why Hebbian learning mimics adaptive Bayesian estimation in this\ncontext.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jun 2011 14:19:48 GMT"}], "update_date": "2011-06-16", "authors_parsed": [["Verstynen", "Timothy", ""], ["Sabes", "Philip N.", ""]]}, {"id": "1106.3386", "submitter": "Liane Gabora", "authors": "Liane Gabora and Scott Barry Kaufman", "title": "Evolutionary Approaches to Creativity", "comments": "28 pages", "journal-ref": "In J. Kaufman & R. Sternberg (Eds.), The Cambridge handbook of\n  creativity (pp. 279-300). Cambridge, UK: Cambridge University Press. (2010)", "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many species engage in acts that could be called creative. However, human\ncreativity is unique in that it has transformed our planet. Given that the\nanatomy of the human brain is not so different from that of the great apes,\nwhat enables us to be so creative? Recent collaborations at the frontier of\nanthropology, archaeology, psychology, and cognitive science are culminating in\nspeculative but increasingly sophisticated efforts to answer to this question.\nExamining the skeletons of our ancestors gives cues as to anatomical\nconstraints that hindered or made possible various kinds of creative\nexpression. Relics of the past have much to tell us about the thoughts,\nbeliefs, and creative abilities of the people who invented and used them. How\nthe spectacular creativity of humans came about is the first topic addressed in\nthis chapter. Studies at the intersection of creativity and evolution are not\nlimited to investigations into the biological evolution of a highly creative\nspecies. Creative ideas themselves might be said to evolve through culture.\nHuman creativity is distinctive because of the adaptive and open-ended manner\nin which change accumulates. Inventions build on previous ones in ways that\nenhance their utility or aesthetic appeal, or make them applicable in different\nsituations. There is no a priori limit to how a creative idea might unfold. It\nis this proclivity to take an idea and make it our own, or 'put our own spin on\nit', that makes creative ideas evolve. The next section of this chapter\ninvestigates in what sense creative ideas evolve through culture. Finally, we\naddress what forces supported the evolution of creativity. Does being creative\nhelp us live longer, or attract mates? Perhaps creative projects can sometimes\ninterfere with survival and reproductive fitness; are there non-biological\nfactors that compel us to create? This is a third topic addressed in this\nchapter.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jun 2011 05:20:47 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 00:33:53 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 22:06:11 GMT"}, {"version": "v4", "created": "Tue, 9 Jul 2019 19:55:10 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Gabora", "Liane", ""], ["Kaufman", "Scott Barry", ""]]}, {"id": "1106.3600", "submitter": "Liane Gabora", "authors": "Liane Gabora and Apara Ranjan", "title": "How Insight Emerges in a Distributed, Content-addressable Memory", "comments": "17 pages; 2 figures", "journal-ref": "In A. Bristol, O. Vartanian, & J. Kaufman (Eds.), The neuroscience\n  of creativity (pp. 19-43). Cambridge, MA: MIT Press (2013)", "doi": "10.7551/mitpress/9780262019583.003.0002", "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We begin this chapter with the bold claim that it provides a neuroscientific\nexplanation of the magic of creativity. Creativity presents a formidable\nchallenge for neuroscience. Neuroscience generally involves studying what\nhappens in the brain when someone engages in a task that involves responding to\na stimulus, or retrieving information from memory and using it the right way,\nor at the right time. If the relevant information is not already encoded in\nmemory, the task generally requires that the individual make systematic use of\ninformation that is encoded in memory. But creativity is different. It\nparadoxically involves studying how someone pulls out of their brain something\nthat was never put into it! Moreover, it must be something both new and useful,\nor appropriate to the task at hand. The ability to pull out of memory something\nnew and appropriate that was never stored there in the first place is what we\nrefer to as the magic of creativity. Even if we are so fortunate as to\ndetermine which areas of the brain are active and how these areas interact\nduring creative thought, we will not have an answer to the question of how the\nbrain comes up with solutions and artworks that are new and appropriate. On the\nother hand, since the representational capacity of neurons emerges at a level\nthat is higher than that of the individual neurons themselves, the inner\nworkings of neurons is too low a level to explain the magic of creativity. Thus\nwe look to a level that is midway between gross brain regions and neurons.\nSince creativity generally involves combining concepts from different domains,\nor seeing old ideas from new perspectives, we focus our efforts on the neural\nmechanisms underlying the representation of concepts and ideas. Thus we ask\nquestions about the brain at the level that accounts for its representational\ncapacity, i.e. at the level of distributed aggregates of neurons.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2011 00:26:40 GMT"}, {"version": "v2", "created": "Sun, 30 Jun 2019 01:41:58 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 22:03:09 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Gabora", "Liane", ""], ["Ranjan", "Apara", ""]]}, {"id": "1106.3616", "submitter": "Christopher Hillar", "authors": "Christopher J. Hillar, Friedrich T. Sommer", "title": "When can dictionary learning uniquely recover sparse data from\n  subsamples?", "comments": "8 pages, 1 figures; IEEE Trans. Info. Theory, to appear", "journal-ref": null, "doi": "10.1109/TIT.2015.2460238", "report-no": null, "categories": "q-bio.NC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse coding or sparse dictionary learning has been widely used to recover\nunderlying structure in many kinds of natural data. Here, we provide conditions\nguaranteeing when this recovery is universal; that is, when sparse codes and\ndictionaries are unique (up to natural symmetries). Our main tool is a useful\nlemma in combinatorial matrix theory that allows us to derive bounds on the\nsample sizes guaranteeing such uniqueness under various assumptions for how\ntraining data are generated. Whenever the conditions to one of our theorems are\nmet, any sparsity-constrained learning algorithm that succeeds in\nreconstructing the data recovers the original sparse codes and dictionary. We\nalso discuss potential applications to neuroscience and data analysis.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jun 2011 05:06:20 GMT"}, {"version": "v2", "created": "Thu, 17 Nov 2011 13:59:44 GMT"}, {"version": "v3", "created": "Fri, 24 May 2013 03:17:09 GMT"}, {"version": "v4", "created": "Fri, 13 Feb 2015 18:20:53 GMT"}, {"version": "v5", "created": "Fri, 31 Jul 2015 16:34:45 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Hillar", "Christopher J.", ""], ["Sommer", "Friedrich T.", ""]]}, {"id": "1106.4317", "submitter": "Dimitris Vavoulis", "authors": "Dimitrios V. Vavoulis, Volko A. Straub, John A.D. Aston, Jianfeng Feng", "title": "A self-organizing state-space-model approach for parameter estimation in\n  Hodgkin-Huxley-type models of single neurons", "comments": null, "journal-ref": "Vavoulis DV, Straub VA, Aston JAD, Feng J (2012) A Self-Organizing\n  State-Space-Model Approach for Parameter Estimation in Hodgkin-Huxley-Type\n  Models of Single Neurons. PLoS Comput Biol 8(3): e1002401", "doi": "10.1371/journal.pcbi.1002401", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Traditionally, parameter estimation in biophysical neuron and neural network\nmodels usually adopts a global search algorithm, often combined with a local\nsearch method in order to minimize the value of a cost function, which measures\nthe discrepancy between various features of the available experimental data and\nmodel output. In this study, we approach the problem of parameter estimation in\nconductance-based models of single neurons from a different perspective. By\nadopting a hidden-dynamical-systems formalism, we expressed parameter\nestimation as an inference problem in these systems, which can then be tackled\nusing well-established statistical inference methods. The particular method we\nused was Kitagawa's self-organizing state-space model, which was applied on a\nnumber of Hodgkin-Huxley models using simulated or actual electrophysiological\ndata. We showed that the algorithm can be used to estimate a large number of\nparameters, including maximal conductances, reversal potentials, kinetics of\nionic currents and measurement noise, based on low-dimensional experimental\ndata and sufficiently informative priors in the form of pre-defined constraints\nimposed on model parameters. The algorithm remained operational even when very\nnoisy experimental data were used. Importantly, by combining the\nself-organizing state-space model with an adaptive sampling algorithm akin to\nthe Covariance Matrix Adaptation Evolution Strategy we achieved a significant\nreduction in the variance of parameter estimates. The algorithm did not require\nthe explicit formulation of a cost function and it was straightforward to apply\non compartmental models and multiple data sets. Overall, the proposed\nmethodology is particularly suitable for resolving high-dimensional inference\nproblems based on noisy electrophysiological data and, therefore, a potentially\nuseful tool in the construction of biophysical neuron models.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jun 2011 20:04:52 GMT"}, {"version": "v2", "created": "Sat, 29 Oct 2011 23:18:59 GMT"}], "update_date": "2012-03-05", "authors_parsed": [["Vavoulis", "Dimitrios V.", ""], ["Straub", "Volko A.", ""], ["Aston", "John A. D.", ""], ["Feng", "Jianfeng", ""]]}, {"id": "1106.5678", "submitter": "Tobias Potjans", "authors": "Tobias C. Potjans and Markus Diesmann", "title": "The cell-type specific connectivity of the local cortical network\n  explains prominent features of neuronal activity", "comments": "57 pages (including main text and supplemental material), 12 figures,\n  8 supplemental figures, 5 tables, 2 supplemental tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, the cell-type specific connectivity and activity of local\ncortical networks have been characterized experimentally to some detail. In\nparallel, modeling has been established as a tool to relate network structure\nto activity dynamics. While the available connectivity maps have been used in\nvarious computational studies, prominent features of the simulated activity\nsuch as the spontaneous firing rates do not match the experimental findings.\nHere, we show that the inconsistency arises from the incompleteness of the\nconnectivity maps. Our comparison of the most comprehensive maps (Thomson et\nal., 2002; Binzegger et al., 2004) reveals their main discrepancies: the\nlateral sampling range and the specific selection of target cells. Taking them\ninto account, we compile an integrated connectivity map and analyze the unified\nmap by simulations of a full scale model of the local layered cortical network.\nThe simulated spontaneous activity is asynchronous irregular and the cell-type\nspecific spontaneous firing rates are in agreement with in vivo recordings in\nawake animals, including the low rate of layer 2/3 excitatory cells. Similarly,\nthe activation patterns evoked by transient thalamic inputs reproduce recent in\nvivo measurements. The correspondence of simulation results and experiments\nrests on the consideration of specific target type selection and thereby on the\nintegration of a large body of the available connectivity data. The cell-type\nspecific hierarchical input structure and the combination of feed-forward and\nfeedback connections reveal how the interplay of excitation and inhibition\nshapes the spontaneous and evoked activity of the local cortical network.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jun 2011 14:16:30 GMT"}], "update_date": "2011-06-29", "authors_parsed": [["Potjans", "Tobias C.", ""], ["Diesmann", "Markus", ""]]}, {"id": "1106.5862", "submitter": "Hideo Hasegawa", "authors": "Hideo Hasegawa (Tokyo Gakugei Univ.)", "title": "Comment on \"Energy and information in Hodgkin-Huxley neurons\"", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent paper [A. Moujahid, A. d'Anjou, F. J. Torrealdea and F.\nTorrealdea, Phys. Rev. E {\\bf 83}, 031912 (2011)], the authors have calculated\nthe energy consumed in firing neurons by using the Hodgkin-Huxley (HH) model.\nThe energy consumption rate adopted for the HH model yields a {\\it negative}\nenergy consumption meaning an energy transfer from an HH neuron to a source\nwhich is physically strange, although they have interpreted it as a biochemical\nenergy cost. I propose an alternative expression for the power consumption\nwhich leads to a {\\it positive} energy consumed in an HH neuron, presenting\nsome model calculations which are compared to those in their paper.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jun 2011 07:47:03 GMT"}], "update_date": "2011-06-30", "authors_parsed": [["Hasegawa", "Hideo", "", "Tokyo Gakugei Univ."]]}, {"id": "1106.6185", "submitter": "Mark Rowan", "authors": "Mark Rowan", "title": "Effects of Compensation, Connectivity and Tau in a Computational Model\n  of Alzheimer's Disease", "comments": "8 pages, submitted to International Joint Conference on Neural\n  Networks 2011", "journal-ref": "The 2011 International Joint Conference on Neural Networks\n  (IJCNN), (2011) 543--550", "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work updates an existing, simplistic computational model of Alzheimer's\nDisease (AD) to investigate the behaviour of synaptic compensatory mechanisms\nin neural networks with small-world connectivity, and varying methods of\ncalculating compensation. It additionally introduces a method for simulating\ntau neurofibrillary pathology, resulting in a more dramatic damage profile.\nSmall-world connectivity is shown to have contrasting effects on capacity,\nretrieval time, and robustness to damage, whilst the use of more\neasily-obtained remote memories rather than recent memories for synaptic\ncompensation is found to lead to rapid network damage.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2011 11:08:05 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Rowan", "Mark", ""]]}]