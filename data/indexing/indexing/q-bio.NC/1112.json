[{"id": "1112.0213", "submitter": "Andr\\'e Gr\\\"uning", "authors": "Andr\\'e Gr\\\"uning and Ioana Sporea", "title": "Supervised Learning of Logical Operations in Layered Spiking Neural\n  Networks with Spike Train Encoding", "comments": "15 pages, 4 figures", "journal-ref": "Neural Processing Letters October 2012, Volume 36, Issue 2, pp\n  117-134", "doi": "10.1007/s11063-012-9225-1", "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few algorithms for supervised training of spiking neural networks exist that\ncan deal with patterns of multiple spikes, and their computational properties\nare largely unexplored. We demonstrate in a set of simulations that the ReSuMe\nlearning algorithm can be successfully applied to layered neural networks.\nInput and output patterns are encoded as spike trains of multiple precisely\ntimed spikes, and the network learns to transform the input trains into target\noutput trains. This is done by combining the ReSuMe learning algorithm with\nmultiplicative scaling of the connections of downstream neurons.\n  We show in particular that layered networks with one hidden layer can learn\nthe basic logical operations, including Exclusive-Or, while networks without\nhidden layer cannot, mirroring an analogous result for layered networks of rate\nneurons.\n  While supervised learning in spiking neural networks is not yet fit for\ntechnical purposes, exploring computational properties of spiking neural\nnetworks advances our understanding of how computations can be done with spike\ntrains.\n", "versions": [{"version": "v1", "created": "Thu, 1 Dec 2011 15:37:09 GMT"}], "update_date": "2014-02-05", "authors_parsed": [["Gr\u00fcning", "Andr\u00e9", ""], ["Sporea", "Ioana", ""]]}, {"id": "1112.0639", "submitter": "Maurizio De Pitta'", "authors": "Maurizio De Pitt\\`a, Vladislav Volman, Hugues Berry, Eshel Ben-Jacob", "title": "A tale of two stories: astrocyte regulation of synaptic depression and\n  facilitation", "comments": "93 pages, manuscript+supplementary text, 10 main figures, 11\n  supplementary figures, 1 table", "journal-ref": "PLoS Comput. Biol. (2011) 7(12): e1002293", "doi": "10.1371/journal.pcbi.1002293", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short-term presynaptic plasticity designates variations of the amplitude of\nsynaptic information transfer whereby the amount of neurotransmitter released\nupon presynaptic stimulation changes over seconds as a function of the neuronal\nfiring activity. While a consensus has emerged that changes of the synapse\nstrength are crucial to neuronal computations, their modes of expression in\nvivo remain unclear. Recent experimental studies have reported that glial\ncells, particularly astrocytes in the hippocampus, are able to modulate\nshort-term plasticity but the underlying mechanism is poorly understood. Here,\nwe investigate the characteristics of short-term plasticity modulation by\nastrocytes using a biophysically realistic computational model. Mean-field\nanalysis of the model unravels that astrocytes may mediate counterintuitive\neffects. Depending on the expressed presynaptic signaling pathways, astrocytes\nmay globally inhibit or potentiate the synapse: the amount of released\nneurotransmitter in the presence of the astrocyte is transiently smaller or\nlarger than in its absence. But this global effect usually coexists with the\nopposite local effect on paired pulses: with release-decreasing astrocytes most\npaired pulses become facilitated, while paired-pulse depression becomes\nprominent under release-increasing astrocytes. Moreover, we show that the\nfrequency of astrocytic intracellular Ca2+ oscillations controls the effects of\nthe astrocyte on short-term synaptic plasticity. Our model explains several\nexperimental observations yet unsolved, and uncovers astrocytic\ngliotransmission as a possible transient switch between short-term paired-pulse\ndepression and facilitation. This possibility has deep implications on the\nprocessing of neuronal spikes and resulting information transfer at synapses.\n", "versions": [{"version": "v1", "created": "Sat, 3 Dec 2011 09:36:12 GMT"}], "update_date": "2011-12-06", "authors_parsed": [["De Pitt\u00e0", "Maurizio", ""], ["Volman", "Vladislav", ""], ["Berry", "Hugues", ""], ["Ben-Jacob", "Eshel", ""]]}, {"id": "1112.0778", "submitter": "Thomas Wiecki", "authors": "Thomas V. Wiecki and Michael J. Frank", "title": "A computational model of inhibitory control in frontal cortex and basal\n  ganglia", "comments": "3rd submission (now accepted at Psychological Review). Removed\n  switch-DDM and some other data points, restructured some graphics. Added\n  systematic accuracy-RT analysis of speed-accuracy trade-off", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Planning and executing volitional actions in the face of conflicting habitual\nresponses is a critical aspect of human behavior. At the core of the interplay\nbetween these two control systems lies an override mechanism that can suppress\nthe habitual action selection process and allow executive control to take over.\nHere, we construct a neural circuit model informed by behavioral and\nelectrophysiological data collected on various response inhibition paradigms.\nThis model extends a well established model of action selection in the basal\nganglia by including a frontal executive control network which integrates\ninformation about sensory input and task rules to facilitate well-informed\ndecision making via the oculomotor system. Our simulations of the antisaccade,\nSimon and saccade-override task ensue in conflict between a prepotent and\ncontrolled response which causes the network to pause action selection via\nprojections to the subthalamic nucleus. Our model reproduces key behavioral and\nelectrophysiological patterns and their sensitivity to lesions and\npharmacological manipulations. Finally, we show how this network can be\nextended to include the inferior frontal cortex to simulate key qualitative\npatterns of global response inhibition demands as required in the stop-signal\ntask.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2011 17:04:29 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2012 15:09:35 GMT"}, {"version": "v3", "created": "Mon, 3 Dec 2012 13:28:22 GMT"}], "update_date": "2012-12-04", "authors_parsed": [["Wiecki", "Thomas V.", ""], ["Frank", "Michael J.", ""]]}, {"id": "1112.1330", "submitter": "Claudius Gros", "authors": "Claudius Gros", "title": "Emotional control - conditio sine qua non for advanced artificial\n  intelligences?", "comments": "Proceedings of PT-AI 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans dispose of two intertwined information processing pathways, cognitive\ninformation processing via neural firing patterns and diffusive volume control\nvia neuromodulation. The cognitive information processing in the brain is\ntraditionally considered to be the prime neural correlate of human\nintelligence, clinical studies indicate that human emotions intrinsically\ncorrelate with the activation of the neuromodulatory system.\n  We examine here the question: Why do humans dispose of the diffusive\nemotional control system? Is this a coincidence, a caprice of nature, perhaps a\nleftover of our genetic heritage, or a necessary aspect of any advanced\nintelligence, being it biological or synthetic? We argue here that emotional\ncontrol is necessary to solve the motivational problem, viz the selection of\nshort-term utility functions, in the context of an environment where\ninformation, computing power and time constitute scarce resources.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2011 15:59:30 GMT"}], "update_date": "2011-12-07", "authors_parsed": [["Gros", "Claudius", ""]]}, {"id": "1112.2072", "submitter": "Hiroaki Inomata", "authors": "Hiroaki Inomata, Harima Hirohiko, Masanari Itokawa", "title": "Long Brief Pulse Method for Pulse-wave modified Electroconvulsive\n  Therapy", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": "10.5348/ijcri-2012-07-147-CR-8", "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modified-Electroconvulsive Therapy (m-ECT) is administered for the treatment\nof various psychiatric disorders. The Seizure Generalization Hypothesis holds\nthat propagation of the induced seizure throughout the whole brain is essential\nfor the effective ECT intervention. However, we encounter many clinical cases\nwhere, due to high thresholds, seizure is not induced by the maximum dose of\nelectrical charge. Some studies have indicated that the ultrabrief pulse\nmethod, in which pulse width is less than 0.5millisecond (ms), is more\neffective at inducing seizure than conventional brief pulse (0.5ms-2.0ms).\nContrary to the studies, we experienced a case of schizophrenia in which m-ECT\nwith 1.0 and 1.5 ms width pulse (referred to as 'long' brief pulse as 0.5ms\nwidth pulse is the default in Japan) succeeded in inducing seizure, whereas\nultrabrief pulse failed to induce seizure. This case is described in detail.\nMoreover, we discuss the underlying mechanism of this phenomenon.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 11:09:30 GMT"}], "update_date": "2012-09-14", "authors_parsed": [["Inomata", "Hiroaki", ""], ["Hirohiko", "Harima", ""], ["Itokawa", "Masanari", ""]]}, {"id": "1112.2464", "submitter": "Bruno. Cessac", "authors": "J. C. Vasquez, O. Marre, A. G. Palacios, M. J. Berry II, B. Cessac", "title": "Gibbs distribution analysis of temporal correlations structure in retina\n  ganglion cells", "comments": "To appear in J. Physiol. Paris", "journal-ref": "Journal of Physiology Paris, Vol. 106, Issue 3-4, pp 120-127,\n  (2012)", "doi": "10.1016/j.jphysparis.2011.11.001", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method to estimate Gibbs distributions with\n\\textit{spatio-temporal} constraints on spike trains statistics. We apply this\nmethod to spike trains recorded from ganglion cells of the salamander retina,\nin response to natural movies. Our analysis, restricted to a few neurons,\nperforms more accurately than pairwise synchronization models (Ising) or the\n1-time step Markov models (\\cite{marre-boustani-etal:09}) to describe the\nstatistics of spatio-temporal spike patterns and emphasizes the role of higher\norder spatio-temporal interactions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 07:43:33 GMT"}], "update_date": "2013-01-11", "authors_parsed": [["Vasquez", "J. C.", ""], ["Marre", "O.", ""], ["Palacios", "A. G.", ""], ["Berry", "M. J.", "II"], ["Cessac", "B.", ""]]}, {"id": "1112.2588", "submitter": "Alessio Franci", "authors": "Alessio Franci, Guillaume Drion, Vincent Seutin, and Rodolphe\n  Sepulchre", "title": "A Novel Phase Portrait to Understand Neuronal Excitability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fifty years ago, Fitzugh introduced a phase portrait that became famous for a\ntwofold reason: it captured in a physiological way the qualitative behavior of\nHodgkin-Huxley model and it revealed the power of simple dynamical models to\nunfold complex firing patterns. To date, in spite of the enormous progresses in\nqualitative and quantitative neural modeling, this phase portrait has remained\nthe core picture of neuronal excitability. Yet, a major difference between the\nneurophysiology of 1961 and of 2011 is the recognition of the prominent role of\ncalcium channels in firing mechanisms. We show that including this extra\ncurrent in Hodgkin-Huxley dynamics leads to a revision of Fitzugh-Nagumo phase\nportrait that affects in a fundamental way the reduced modeling of neural\nexcitability. The revisited model considerably enlarges the modeling power of\nthe original one. In particular, it captures essential electrophysiological\nsignatures that otherwise require non-physiological alteration or considerable\ncomplexication of the classical model. As a basic illustration, the new model\nis shown to highlight a core dynamical mechanism by which the calcium\nconductance controls the two distinct firing modes of thalamocortical neurons.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 15:32:42 GMT"}], "update_date": "2011-12-13", "authors_parsed": [["Franci", "Alessio", ""], ["Drion", "Guillaume", ""], ["Seutin", "Vincent", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "1112.2630", "submitter": "Leonid Shapiro", "authors": "Leonid A. Shapiro", "title": "Generalized Functions & Experimental Methods of Obtaining Statistical\n  Variable-Quantities Which Fully Determine Preferences in Choice-Rich\n  Environments", "comments": "26 pages, 1 figures, Version 3 (January 19), Version 2 (December 31),\n  Version 1 (December 12), in review process", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preferences of individuals are distributions of elements generated by\ngeneralized functions. Models of economic decision-making derived from such\ndistributions are consistent with results of physiological experiments, and\nexplain any behavioral situations without simplifying assumptions. Quantities\nin such models precisely correspond to experimentally obtainable physiological\nobservables which determine statistical properties of central nervous system as\nit represents different stimuli. Graphical method of consistently and\nquantitatively at-a-glance interpreting or visualizing physiological data\nwithin context of economic models is demonstrated.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 17:19:26 GMT"}, {"version": "v2", "created": "Tue, 3 Jan 2012 20:55:17 GMT"}, {"version": "v3", "created": "Thu, 19 Jan 2012 20:46:53 GMT"}], "update_date": "2012-01-20", "authors_parsed": [["Shapiro", "Leonid A.", ""]]}, {"id": "1112.3138", "submitter": "Dominique Vuillaume", "authors": "F. Alibart, S. Pleutin, O. Bichler, C. Gamrat, T. Serrano-Gotarredona,\n  B. Linares-Barranco and D. Vuillaume", "title": "A memristive nanoparticle/organic hybrid synapstor for neuro-inspired\n  computing", "comments": "A single pdf file, with the full paper and the supplementary\n  information; Adv. Func. Mater., on line Dec. 13 (2011)", "journal-ref": "Adv. Func. Mater., 22, 609-616 (2012)", "doi": "10.1002/adfm.201101935", "report-no": null, "categories": "cond-mat.mes-hall cond-mat.dis-nn cond-mat.mtrl-sci cs.ET q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A large effort is devoted to the research of new computing paradigms\nassociated to innovative nanotechnologies that should complement and/or propose\nalternative solutions to the classical Von Neumann/CMOS association. Among\nvarious propositions, Spiking Neural Network (SNN) seems a valid candidate. (i)\nIn terms of functions, SNN using relative spike timing for information coding\nare deemed to be the most effective at taking inspiration from the brain to\nallow fast and efficient processing of information for complex tasks in\nrecognition or classification. (ii) In terms of technology, SNN may be able to\nbenefit the most from nanodevices, because SNN architectures are intrinsically\ntolerant to defective devices and performance variability. Here we demonstrate\nSpike-Timing-Dependent Plasticity (STDP), a basic and primordial learning\nfunction in the brain, with a new class of synapstor (synapse-transistor),\ncalled Nanoparticle Organic Memory Field Effect Transistor (NOMFET). We show\nthat this learning function is obtained with a simple hybrid material made of\nthe self-assembly of gold nanoparticles and organic semiconductor thin films.\nBeyond mimicking biological synapses, we also demonstrate how the shape of the\napplied spikes can tailor the STDP learning function. Moreover, the experiments\nand modeling show that this synapstor is a memristive device. Finally, these\nsynapstors are successfully coupled with a CMOS platform emulating the pre- and\npost-synaptic neurons, and a behavioral macro-model is developed on usual\ndevice simulator.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2011 08:13:59 GMT"}], "update_date": "2012-02-09", "authors_parsed": [["Alibart", "F.", ""], ["Pleutin", "S.", ""], ["Bichler", "O.", ""], ["Gamrat", "C.", ""], ["Serrano-Gotarredona", "T.", ""], ["Linares-Barranco", "B.", ""], ["Vuillaume", "D.", ""]]}, {"id": "1112.3496", "submitter": "Xiao-Ke Xu", "authors": "Xiaoxi Ji, Wei Cheng, Jie Zhang, Tian Ge, Li Sun, Yufeng Wang,\n  Jianfeng Feng", "title": "Increased Coupling in the Saliency Network is the main cause/effect of\n  Attention Deficit Hyperactivity Disorder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To uncover the underlying mechanisms of mental disorders such as attention\ndeficit hyperactivity disorder (ADHD) for improving both early diagnosis and\ntherapy, it is increasingly recognized that we need a better understanding of\nhow the brain's functional connections are altered. A new brain wide\nassociation study (BWAS) has been developed and used to investigate functional\nconnectivity changes in the brains of patients suffering from ADHD using\nresting state fMRI data. To reliably find out the most significantly altered\nfunctional connectivity links and associate them with ADHD, a meta-analysis on\na cohort of ever reported largest population comprising 249 patients and 253\nhealthy controls is carried out. The greatest change in ADHD patients was the\nincreased coupling of the saliency network involving the anterior cingulate\ngyrus and anterior insula. A voxel-based morphometry analysis was also carried\nout but this revealed no evidence in the ADHD patients for altered grey matter\nvolumes in the regions showing altered functional connectivity. This is the\nfirst evidence for the involvement of the saliency network in ADHD and it\nsuggests that this may reflect increased sensitivity over the integration of\nthe incoming sensory information and his/her own thoughts and the network as a\nswitch is bias towards to the central executive network.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2011 12:09:25 GMT"}], "update_date": "2011-12-16", "authors_parsed": [["Ji", "Xiaoxi", ""], ["Cheng", "Wei", ""], ["Zhang", "Jie", ""], ["Ge", "Tian", ""], ["Sun", "Li", ""], ["Wang", "Yufeng", ""], ["Feng", "Jianfeng", ""]]}, {"id": "1112.3867", "submitter": "Christoph Adami", "authors": "Christoph Adami", "title": "The use of information theory in evolutionary biology", "comments": "25 pages, 7 figures. To appear in \"The Year in Evolutionary Biology\",\n  of the Annals of the NY Academy of Sciences", "journal-ref": "Annals NY Acad. Sciences 1256 (2012) 49-65", "doi": "10.1111/j.1749-6632.2011.06422.x", "report-no": null, "categories": "q-bio.PE cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information is a key concept in evolutionary biology. Information is stored\nin biological organism's genomes, and used to generate the organism as well as\nto maintain and control it. Information is also \"that which evolves\". When a\npopulation adapts to a local environment, information about this environment is\nfixed in a representative genome. However, when an environment changes,\ninformation can be lost. At the same time, information is processed by animal\nbrains to survive in complex environments, and the capacity for information\nprocessing also evolves. Here I review applications of information theory to\nthe evolution of proteins as well as to the evolution of information processing\nin simulated agents that adapt to perform a complex task.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2011 15:59:35 GMT"}], "update_date": "2012-07-25", "authors_parsed": [["Adami", "Christoph", ""]]}, {"id": "1112.3968", "submitter": "Demian Battaglia", "authors": "Demian Battaglia, Annette Witt, Fred Wolf, Theo Geisel", "title": "Dynamic effective connectivity of inter-areal brain circuits", "comments": "53 pages, including 9 main Figures, 4 supporting figures and 1\n  supporting appendix; submitted for publication", "journal-ref": null, "doi": "10.1371/journal.pcbi.1002438", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anatomic connections between brain areas affect information flow between\nneuronal circuits and the synchronization of neuronal activity. However, such\nstructural connectivity does not coincide with effective connectivity, related\nto the more elusive question \"Which areas cause the present activity of which\nothers?\". Effective connectivity is directed and depends flexibly on contexts\nand tasks. Here we show that a dynamic effective connectivity can emerge from\ntransitions in the collective organization of coherent neural activity.\nIntegrating simulation and semi-analytic approaches, we study mesoscale network\nmotifs of interacting cortical areas, modeled as large random networks of\nspiking neurons or as simple rate units. Through a causal analysis of\ntime-series of model neural activity, we show that different dynamical states\ngenerated by a same structural connectivity motif correspond to distinct\neffective connectivity motifs. Such effective motifs can display a dominant\ndirectionality, due to spontaneous symmetry breaking and effective entrainment\nbetween local brain rhythms, although all connections in the considered\nstructural motifs are reciprocal [...] Finally, we analyze how the information\nencoded in spiking patterns of a local neuronal population is propagated across\na fixed structural connectivity motif, demonstrating that changes in the active\neffective connectivity regulate both the efficiency and the directionality of\ninformation transfer [...] Going beyond these early proposals, we advance here\nthat dynamic interactions between brain rhythms provide as well the basis for\nthe self-organized control of this \"communication-through-coherence\", making\nthus possible a fast \"on-demand\" reconfiguration of global information routing\nmodalities.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2011 21:00:42 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Battaglia", "Demian", ""], ["Witt", "Annette", ""], ["Wolf", "Fred", ""], ["Geisel", "Theo", ""]]}, {"id": "1112.4059", "submitter": "Demian Battaglia", "authors": "Demian Battaglia, David Hansel", "title": "Synchronous chaos and broad band gamma rhythm in a minimal multi-layer\n  model of primary visual cortex", "comments": "49 pages, 11 figures, 7 tables", "journal-ref": "Published in PLoS Comput Biol 7(10): e1002176 (2011)", "doi": "10.1371/journal.pcbi.1002176", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visually induced neuronal activity in V1 displays a marked gamma-band\ncomponent which is modulated by stimulus properties. It has been argued that\nsynchronized oscillations contribute to these gamma-band activity [...\nhowever,] even when oscillations are observed, they undergo temporal\ndecorrelation over very few cycles. This is not easily accounted for in\nprevious network modeling of gamma oscillations. We argue here that\ninteractions between cortical layers can be responsible for this fast\ndecorrelation. We study a model of a V1 hypercolumn, embedding a simplified\ndescription of the multi-layered structure of the cortex. When the stimulus\ncontrast is low, the induced activity is only weakly synchronous and the\nnetwork resonates transiently without developing collective oscillations. When\nthe contrast is high, on the other hand, the induced activity undergoes\nsynchronous oscillations with an irregular spatiotemporal structure expressing\na synchronous chaotic state. As a consequence the population activity undergoes\nfast temporal decorrelation, with concomitant rapid damping of the oscillations\nin LFPs autocorrelograms and peak broadening in LFPs power spectra. [...]\nFinally, we argue that the mechanism underlying the emergence of synchronous\nchaos in our model is in fact very general. It stems from the fact that gamma\noscillations induced by local delayed inhibition tend to develop chaos when\ncoupled by sufficiently strong excitation.\n", "versions": [{"version": "v1", "created": "Sat, 17 Dec 2011 14:39:07 GMT"}], "update_date": "2011-12-20", "authors_parsed": [["Battaglia", "Demian", ""], ["Hansel", "David", ""]]}, {"id": "1112.4987", "submitter": "Yuriy Pershin", "authors": "M. Di Ventra and Y. V. Pershin", "title": "Biologically-Inspired Electronics with Memory Circuit Elements", "comments": "To be published in \"Advances in Neuromorphic Memristor Science and\n  Applications\" (Springer), edited by R. Kozma, R. Pino, G. Pazienza", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.mes-hall", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several abilities of biological systems, such as adaptation to natural\nenvironment, or of animals to learn patterns when appropriately trained, are\nfeatures that are extremely useful, if emulated by electronic circuits, in\napplications ranging from robotics to solution of complex optimization\nproblems, traffic control, etc. In this chapter, we discuss several examples of\nbiologically-inspired circuits that take advantage of memory circuit elements,\nnamely, electronic elements whose resistive, capacitive or inductive\ncharacteristics depend on their past dynamics. We provide several illustrations\nof what can be accomplished with these elements including learning circuits and\nrelated adaptive filters, neuromorphic and cellular computing circuits, analog\nmassively-parallel computation architectures, etc. We also give examples of\nexperimental realizations of memory circuit elements and discuss opportunities\nand challenges in this new field.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2011 11:07:16 GMT"}], "update_date": "2011-12-22", "authors_parsed": [["Di Ventra", "M.", ""], ["Pershin", "Y. V.", ""]]}, {"id": "1112.5116", "submitter": "Christoph Adami", "authors": "Nicolas Chaumont and Christoph Adami", "title": "Evolution of sustained foraging in 3D environments with physics", "comments": "18 pages, 15 figures. Supplementary Materials available at\n  http://tinyurl.com/autonomous-foragers-supplement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificially evolving foraging behavior in simulated legged animals has\nproved to be a notoriously difficult task. Here, we co-evolve the morphology\nand controller for virtual organisms in a three-dimensional physically\nrealistic environment to produce goal-directed legged locomotion. We show that\nfollowing and reaching multiple food sources can evolve de novo, by evaluating\neach organism on multiple food sources placed on a basic pattern that is\ngradually randomized across generations. We devised a strategy of evolutionary\n\"staging\", where the best organism from a set of evolutionary experiments using\na particular fitness function is used to seed a new set, with a fitness\nfunction that is progressively altered to better challenge organisms as\nevolution improves them. We find that an organism's efficiency at reaching the\nfirst food source does not predict its ability at finding subsequent ones\nbecause foraging efficiency crucially depends on the position of the last food\nsource reached, an effect illustrated by \"foraging maps\" that capture the\norganism's controller state, body position, and orientation. Our best evolved\nforagers are able to reach multiple food sources over 90% of the time on\naverage, a behavior that is key to any biologically realistic simulation where\na self-sustaining population has to survive by collecting food sources in\nthree-dimensional, physical environments.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2011 18:08:39 GMT"}], "update_date": "2011-12-22", "authors_parsed": [["Chaumont", "Nicolas", ""], ["Adami", "Christoph", ""]]}, {"id": "1112.5449", "submitter": "Marcus Kaiser", "authors": "Marcus Kaiser and Sreedevi Varier", "title": "Evolution and development of Brain Networks: From Caenorhabditis elegans\n  to Homo sapiens", "comments": null, "journal-ref": "Network: Computation in Neural Systems, 2011, Vol. 22, No. 1-4 :\n  Pages 143-147", "doi": "10.3109/0954898X.2011.638968", "report-no": null, "categories": "q-bio.NC physics.soc-ph q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks show a progressive increase in complexity during the time\ncourse of evolution. From diffuse nerve nets in Cnidaria to modular,\nhierarchical systems in macaque and humans, there is a gradual shift from\nsimple processes involving a limited amount of tasks and modalities to complex\nfunctional and behavioral processing integrating different kinds of information\nfrom highly specialized tissue. However, studies in a range of species suggest\nthat fundamental similarities, in spatial and topological features as well as\nin developmental mechanisms for network formation, are retained across\nevolution. 'Small-world' topology and highly connected regions (hubs) are\nprevalent across the evolutionary scale, ensuring efficient processing and\nresilience to internal (e.g. lesions) and external (e.g. environment) changes.\nFurthermore, in most species, even the establishment of hubs, long-range\nconnections linking distant components, and a modular organization, relies on\nsimilar mechanisms. In conclusion, evolutionary divergence leads to greater\ncomplexity while following essential developmental constraints.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2011 20:47:12 GMT"}], "update_date": "2011-12-23", "authors_parsed": [["Kaiser", "Marcus", ""], ["Varier", "Sreedevi", ""]]}, {"id": "1112.5463", "submitter": "Marcus Kaiser", "authors": "Sreedevi Varier and Marcus Kaiser and Rob Forsyth", "title": "Establishing, versus Maintaining, Brain Function: A Neuro-computational\n  Model of Cortical Reorganization after Injury to the Immature Brain", "comments": null, "journal-ref": "Journal of the International Neuropsychological Society,\n  17:1030-1038, 2011", "doi": "10.1017/S1355617711000993", "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effect of age at injury on outcome after acquired brain injury (ABI) has\nbeen the subject of much debate. Many argue that young brains are relatively\ntolerant of injury. A contrasting viewpoint due to Hebb argues that greater\nsystem integrity may be required for the initial establishment of a function\nthan for preservation of an already-established function. A neuro-computational\nmodel of cortical map formation was adapted to examine effects of focal and\ndistributed injury at various stages of development. This neural network model\nrequires a period of training during which it self-organizes to establish\ncortical maps. Injuries were simulated by lesioning the model at various stages\nof this process and network function was monitored as \"development\" progressed\nto completion. Lesion effects are greater for larger, earlier, and distributed\n(multifocal) lesions. The mature system is relatively robust, particularly to\nfocal injury. Activities in recovering systems injured at an early stage show\nchanges that emerge after an asymptomatic interval. Early injuries cause\nqualitative changes in system behavior that emerge after a delay during which\nthe effects of the injury are latent. Functions that are incompletely\nestablished at the time of injury may be vulnerable particularly to multifocal\ninjury.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2011 21:12:09 GMT"}], "update_date": "2011-12-26", "authors_parsed": [["Varier", "Sreedevi", ""], ["Kaiser", "Marcus", ""], ["Forsyth", "Rob", ""]]}, {"id": "1112.5507", "submitter": "Joshua Vogelstein", "authors": "Joshua T. Vogelstein, John M. Conroy, Vince Lyzinski, Louis J.\n  Podrazik, Steven G. Kratzer, Eric T. Harley, Donniell E. Fishkind, R. Jacob\n  Vogelstein, Carey E. Priebe", "title": "Fast Approximate Quadratic Programming for Large (Brain) Graph Matching", "comments": "17 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quadratic assignment problems (QAPs) arise in a wide variety of domains,\nranging from operations research to graph theory to computer vision to\nneuroscience. In the age of big data, graph valued data is becoming more\nprominent, and with it, a desire to run algorithms on ever larger graphs.\nBecause QAP is NP-hard, exact algorithms are intractable. Approximate\nalgorithms necessarily employ an accuracy/efficiency trade-off. We developed a\nfast approximate quadratic assignment algorithm (FAQ). FAQ finds a local optima\nin (worst case) time cubic in the number of vertices, similar to other\napproximate QAP algorithms. We demonstrate empirically that our algorithm is\nfaster and achieves a lower objective value on over 80% of the suite of QAP\nbenchmarks, compared with the previous state-of-the-art. Applying the\nalgorithms to our motivating example, matching C. elegans connectomes\n(brain-graphs), we find that FAQ achieves the optimal performance in record\ntime, whereas none of the others even find the optimum.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2011 02:56:26 GMT"}, {"version": "v2", "created": "Thu, 12 Jul 2012 03:44:51 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2012 04:56:59 GMT"}, {"version": "v4", "created": "Fri, 10 May 2013 01:58:09 GMT"}, {"version": "v5", "created": "Sat, 13 Sep 2014 15:08:28 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Vogelstein", "Joshua T.", ""], ["Conroy", "John M.", ""], ["Lyzinski", "Vince", ""], ["Podrazik", "Louis J.", ""], ["Kratzer", "Steven G.", ""], ["Harley", "Eric T.", ""], ["Fishkind", "Donniell E.", ""], ["Vogelstein", "R. Jacob", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1112.5913", "submitter": "Thiago Mosqueiro", "authors": "T. S. Mosqueiro, C. Akimushkin, L. P. Maia", "title": "Dynamical aspects of Kinouchi-Copelli model: emergence of avalanches at\n  criticality", "comments": "Paper accepted for Brazilian Conference on Dynamics, Control and\n  Applications (oral presentation and poster). 4 pages, 5 figures", "journal-ref": null, "doi": "10.5540/DINCON.2011.001.1.0064", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the behavior of bursts of neural activity in the Kinouchi-Copelli\nmodel, originally conceived to explain information processing issues in sensory\nsystems. We show that, at a critical condition, power-law behavior emerges for\nthe size and duration of the bursts (avalanches), with exponents experimentally\nobserved in real biological systems.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2011 03:25:33 GMT"}], "update_date": "2012-04-05", "authors_parsed": [["Mosqueiro", "T. S.", ""], ["Akimushkin", "C.", ""], ["Maia", "L. P.", ""]]}]