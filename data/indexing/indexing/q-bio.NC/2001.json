[{"id": "2001.00114", "submitter": "Fani Deligianni Dr", "authors": "F. Deligianni, H. Singh, H.N. Modi, S. Jahani, M. Yucel, A. Darzi,\n  D.R. Leff, G.Z. Yang", "title": "Expertise and Task Pressure in fNIRS-based brain Connectomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Acquisition of bimanual motor skills, critical in several applications\nranging from robotic teleoperations to surgery, is associated with a protracted\nlearning curve. Brain connectivity based on functional Near Infrared\nSpectroscopy (fNIRS) data has shown promising results in distinguishing experts\nfrom novice surgeons. However, it is less well understood how expertise-related\ndisparity in brain connectivity is modulated by dynamic temporal demands\nexperienced during a surgical task. In this study, we use fNIRS to examine the\ninterplay between frontal and motor brain regions in a cohort of surgical\nresidents of varying expertise performing a laparoscopic surgical task under\ntemporal demand. The results demonstrate that prefrontal-motor connectivity in\nsenior residents is more resilient to time pressure. Furthermore, certain\nglobal characteristics of brain connectomes, such as the small-world index, may\nbe used to detect the presence of an underlying stressor.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 00:01:04 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Deligianni", "F.", ""], ["Singh", "H.", ""], ["Modi", "H. N.", ""], ["Jahani", "S.", ""], ["Yucel", "M.", ""], ["Darzi", "A.", ""], ["Leff", "D. R.", ""], ["Yang", "G. Z.", ""]]}, {"id": "2001.00122", "submitter": "A. Rebei", "authors": "Adnan Rebei", "title": "Entropic Decision Making", "comments": "84 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using results from neurobiology on perceptual decision making and value-based\ndecision making, the problem of decision making between lotteries is\nreformulated in an abstract space where uncertain prospects are mapped to\ncorresponding active neuronal representations. This mapping allows us to\nmaximize non-extensive entropy in the new space with some constraints instead\nof a utility function. To achieve good agreements with behavioral data, the\nconstraints must include at least constraints on the weighted average of the\nstimulus and on its variance. Both constraints are supported by the\nadaptability of neuronal responses to an external stimulus. By analogy with\nthermodynamic and information engines, we discuss the dynamics of choice\nbetween two lotteries as they are being processed simultaneously in the brain\nby rate equations that describe the transfer of attention between lotteries and\nwithin the various prospects of each lottery. This model is able to give new\ninsights on risk aversion and on behavioral anomalies not accounted for by\nProspect Theory.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 01:37:20 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Rebei", "Adnan", ""]]}, {"id": "2001.00192", "submitter": "James Tee", "authors": "James Tee and Desmond P. Taylor", "title": "A Quantized Representation of Probability in the Brain", "comments": "12 pages, 23 figures, 6 tables. arXiv admin note: substantial text\n  overlap with arXiv:1805.01631", "journal-ref": "IEEE Transactions on Molecular, Biological and Multi-Scale\n  Communications (30 October 2019)", "doi": "10.1109/TMBMC.2019.2950182", "report-no": null, "categories": "q-bio.NC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional and current wisdom assumes that the brain represents probability\nas a continuous number to many decimal places. This assumption seems\nimplausible given finite and scarce resources in the brain. Quantization is an\ninformation encoding process whereby a continuous quantity is systematically\ndivided into a finite number of possible categories. Rounding is a simple\nexample of quantization. We apply this information theoretic concept to develop\na novel quantized (i.e., discrete) probability distortion function. We develop\nthree conjunction probability gambling tasks to look for evidence of quantized\nprobability representations in the brain. We hypothesize that certain ranges of\nprobability will be lumped together in the same indifferent category if a\nquantized representation exists. For example, two distinct probabilities such\nas 0.57 and 0.585 may be treated indifferently. Our extensive data analysis has\nfound strong evidence to support such a quantized representation: 59/76\nparticipants (i.e., 78%) demonstrated a best fit to 4-bit quantized models\ninstead of continuous models. This observation is the major development and\nnovelty of the present work. The brain is very likely to be employing a\nquantized representation of probability. This discovery demonstrates a major\nprecision limitation of the brain's representational and decision-making\nability.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 11:45:26 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Tee", "James", ""], ["Taylor", "Desmond P.", ""]]}, {"id": "2001.00693", "submitter": "Ibrahim Kaya", "authors": "Ibrahim Kaya", "title": "A Brief Summary of EEG Artifact Handling", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.2.25108.04484", "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The applications of Electroencephalogram (EEG) have been extended to out of\nlaboratory and clinics recently due to the advancements in the technical\ncapabilities. There are various advantageous of EEG, making it a preferable\nmethod for a wide range of applications; it is a noninvasive method, it is\nportable, it offers good time resolution and sufficient spatial resolution,\nbesides there are low cost EEG systems available for a commercial use. Since\nthe early uses of EEG, mainly as monitoring of diseases and pathologies, sleep\nstaging and event related potential researches, it has been intertwined with\nundesired signal types which we call as artifacts. These pose great challenges\nin the practice of EEG based methods such as averaging for monitoring and\ndiagnosis of diseases, and single-trial signal analysis for a relatively recent\napplication in brain-computer interfaces. However, many techniques have been\ndeveloped and under study for better detection and mitigation of these adverse\nevents. The main artifact types and their handling are discussed in this brief\nsummary.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2020 02:14:11 GMT"}], "update_date": "2020-01-06", "authors_parsed": [["Kaya", "Ibrahim", ""]]}, {"id": "2001.01680", "submitter": "Mingyuan Meng", "authors": "Mingyuan Meng, Xingyu Yang, Lei Bi, Jinman Kim, Shanlin Xiao, and\n  Zhiyi Yu", "title": "High-parallelism Inception-like Spiking Neural Networks for Unsupervised\n  Feature Learning", "comments": "Published at Neurocomputing", "journal-ref": "Neurocomputing 441(2021), pp. 92-104", "doi": "10.1016/j.neucom.2021.02.027", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spiking Neural Networks (SNNs) are brain-inspired, event-driven machine\nlearning algorithms that have been widely recognized in producing\nultra-high-energy-efficient hardware. Among existing SNNs, unsupervised SNNs\nbased on synaptic plasticity, especially Spike-Timing-Dependent Plasticity\n(STDP), are considered to have great potential in imitating the learning\nprocess of the biological brain. Nevertheless, the existing STDP-based SNNs\nhave limitations in constrained learning capability and/or slow learning speed.\nMost STDP-based SNNs adopted a slow-learning Fully-Connected (FC) architecture\nand used a sub-optimal vote-based scheme for spike decoding. In this paper, we\novercome these limitations with: 1) a design of high-parallelism network\narchitecture, inspired by the Inception module in Artificial Neural Networks\n(ANNs); 2) use of a Vote-for-All (VFA) decoding layer as a replacement to the\nstandard vote-based spike decoding scheme, to reduce the information loss in\nspike decoding and, 3) a proposed adaptive repolarization (resetting) mechanism\nthat accelerates SNNs' learning by enhancing spiking activities. Our\nexperimental results on two established benchmark datasets (MNIST/EMNIST) show\nthat our network architecture resulted in superior performance compared to the\nwidely used FC architecture and a more advanced Locally-Connected (LC)\narchitecture, and that our SNN achieved competitive results with\nstate-of-the-art unsupervised SNNs (95.64%/80.11% accuracy on the MNIST/EMNISE\ndataset) while having superior learning efficiency and robustness against\nhardware damage. Our SNN achieved great classification accuracy with only\nhundreds of training iterations, and random destruction of large numbers of\nsynapses or neurons only led to negligible performance degradation.\n", "versions": [{"version": "v1", "created": "Mon, 2 Dec 2019 17:19:17 GMT"}, {"version": "v2", "created": "Sat, 18 Jan 2020 17:53:25 GMT"}, {"version": "v3", "created": "Sun, 12 Apr 2020 14:25:23 GMT"}, {"version": "v4", "created": "Thu, 4 Jun 2020 16:05:09 GMT"}, {"version": "v5", "created": "Tue, 9 Mar 2021 04:00:23 GMT"}], "update_date": "2021-03-15", "authors_parsed": [["Meng", "Mingyuan", ""], ["Yang", "Xingyu", ""], ["Bi", "Lei", ""], ["Kim", "Jinman", ""], ["Xiao", "Shanlin", ""], ["Yu", "Zhiyi", ""]]}, {"id": "2001.02287", "submitter": "Manoj Srinivasan", "authors": "Geoffrey L. Brown, Nidhi Seethapathi, and Manoj Srinivasan", "title": "Energy optimality predicts curvilinear locomotion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Everyday human locomotion requires changing directions and turning. However,\nwhile straight-line walking behavior is approximately explained by energy\nminimization, we do not yet have a unified theoretical account of\nnon-straight-line (i.e., curvilinear) locomotion, despite its ecological\nimportance. Here, we show that many non-straight-line walking phenomena are\npredicted by including an energy cost for turning. We quantified the cost of\nturning in humans, showing that the metabolic rate of walking increases with\ndecreasing radius for fixed speed. We then used this metabolic cost to\nmathematically predict energy-optimal movement patterns for five tasks of\nvarying complexity: walking in circles, turning in place, walking through an\nangled corridor, walking freely from point to point while having to turn, and\nwalking through doors while maneuvering around obstacles. In these tasks,\nhumans moved at speeds and paths approximately predicted by energy optima.\nThus, we provide a unified theoretical account that predicts diverse\ncurvilinear locomotor phenomena.\n", "versions": [{"version": "v1", "created": "Tue, 7 Jan 2020 21:50:28 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2020 18:58:41 GMT"}], "update_date": "2020-08-19", "authors_parsed": [["Brown", "Geoffrey L.", ""], ["Seethapathi", "Nidhi", ""], ["Srinivasan", "Manoj", ""]]}, {"id": "2001.02621", "submitter": "Massimo Stella", "authors": "Massimo Stella", "title": "Multiplex networks quantify robustness of the mental lexicon to\n  catastrophic concept failures, aphasic degradation and ageing", "comments": "13 pages, 4 figures", "journal-ref": null, "doi": "10.1016/j.physa.2020.124382", "report-no": null, "categories": "physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concepts and their mental associations influence how language is processed\nand used. Networks represent powerful models for exploring such cognitive\nsystem, known as mental lexicon. This study investigates lexicon robustness to\nprogressive word failure with multiplex network attacks. The average lexicon of\nan adult English speaker is built by considering 16000 words connected through\nsemantic free associations and phonological sound similarities. Progressive\nstructural degradation is modelled as random and targeted attacks. Words with\nhigher psycholinguistic features (e.g. frequency, length, age of acquisition,\npolysemy) or network centrality (e.g. closeness, PageRank, betweenness and\ndegree) are targeted first. Aphasia-inspired attacks are introduced here and\ntarget first words named correctly, more or less frequently, by patients with\nanomic aphasia, a pathology disrupting word finding. Robustness is measured as\nconnectedness, fundamental for activation spreading and lexical retrieval, and\nviability, a multi-layer connectivity identifying language kernels. The lexicon\nis resilient to random, aphasia-inspired and psycholinguistic attacks.\nCatastrophic phase transitions happen when phonological and semantic degrees\nare combined, making the lexicon fragile to multidegree attacks. The viable\nkernel is fragile to multi-PageRank and to aphasia-inspired attacks.\nConsequently, connectedness in the lexicon is mediated by hubs, whereas\nviability enables a lexical semantic/phonological interplay and corresponds to\na facilitative naming effect in aphasia. These effects persist also through\nageing, in different network representations of younger and older lexicons.\nThis study indicates the need to prevent failure of high multidegree and viable\nwords in the mental lexicon when pursuing the design of effective language\nrestoration strategies against cognitive impairing.\n", "versions": [{"version": "v1", "created": "Wed, 8 Jan 2020 16:59:22 GMT"}], "update_date": "2020-07-15", "authors_parsed": [["Stella", "Massimo", ""]]}, {"id": "2001.02868", "submitter": "Mihai Bibireata", "authors": "Mihai Bibireata, Valentin M. Slepukhin, Alex J. Levine", "title": "Dynamical phase separation on rhythmogenic neuronal networks", "comments": "14 pages, 15 figures", "journal-ref": "Phys. Rev. E 101, 062307 (2020)", "doi": "10.1103/PhysRevE.101.062307", "report-no": null, "categories": "q-bio.NC nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the dynamics of the preB\\\"{o}tzinger complex, the mammalian\ncentral pattern generator with $N \\sim 10^3$ neurons, which produces a\ncollective metronomic signal that times the inspiration. Our analysis is based\non a simple firing-rate model of excitatory neurons with dendritic adaptation\n(the Feldman Del Negro model [Nat. Rev. Neurosci. 7, 232 (2006), Phys. Rev. E\n2010 :051911]) interacting on a fixed, directed Erd\\H{o}s-R\\'{e}nyi network. In\nthe all-to-all coupled variant of the model, there is spontaneous symmetry\nbreaking in which some fraction of the neurons become stuck in a high\nfiring-rate state, while others become quiescent. This separation into firing\nand non-firing clusters persists into more sparsely connected networks, and is\npartially determined by $k$-cores in the directed graphs. The model has a\nnumber of features of the dynamical phase diagram that violate the predictions\nof mean-field analysis. In particular, we observe in the simulated networks\nthat stable oscillations do not persist in the large-N limit, in contradiction\nto the predictions of mean-field theory. Moreover, we observe that the\noscillations in these sparse networks are remarkably robust in response to\nkilling neurons, surviving until only $\\approx 20 \\%$ of the network remains.\nThis robustness is consistent with experiment.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 07:37:17 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Bibireata", "Mihai", ""], ["Slepukhin", "Valentin M.", ""], ["Levine", "Alex J.", ""]]}, {"id": "2001.02894", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad, Alessandro Selvitella, Liangxiu Han, Daoqiang\n  Zhang", "title": "Supervised Hyperalignment for multi-subject fMRI data alignment", "comments": "IEEE Transactions on Cognitive and Developmental Systems", "journal-ref": null, "doi": "10.1109/TCDS.2020.2965981", "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperalignment has been widely employed in Multivariate Pattern (MVP)\nanalysis to discover the cognitive states in the human brains based on\nmulti-subject functional Magnetic Resonance Imaging (fMRI) datasets. Most of\nthe existing HA methods utilized unsupervised approaches, where they only\nmaximized the correlation between the voxels with the same position in the time\nseries. However, these unsupervised solutions may not be optimum for handling\nthe functional alignment in the supervised MVP problems. This paper proposes a\nSupervised Hyperalignment (SHA) method to ensure better functional alignment\nfor MVP analysis, where the proposed method provides a supervised shared space\nthat can maximize the correlation among the stimuli belonging to the same\ncategory and minimize the correlation between distinct categories of stimuli.\nFurther, SHA employs a generalized optimization solution, which generates the\nshared space and calculates the mapped features in a single iteration, hence\nwith optimum time and space complexities for large datasets. Experiments on\nmulti-subject datasets demonstrate that SHA method achieves up to 19% better\nperformance for multi-class problems over the state-of-the-art HA algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2020 09:17:49 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Selvitella", "Alessandro", ""], ["Han", "Liangxiu", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "2001.03057", "submitter": "Xiaodan Xing", "authors": "Xiaodan Xing, Qingfeng Li, Hao Wei, Minqing Zhang, Yiqiang Zhan, Xiang\n  Sean Zhou, Zhong Xue, and Feng Shi", "title": "DS-GCNs: Connectome Classification Using Dynamic Spectral Graph\n  Convolution Networks with Assistant Task Training", "comments": "Number of pages: 22 Word count in abstract: 252, word count in\n  manuscript: 3910 This manuscript includes 3 tables and 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional Connectivity (FC) matrices measure the regional interactions in\nthe brain and have been widely used in neurological brain disease\nclassification. However, a FC matrix is neither a natural image which contains\nshape and texture information, nor a vector of independent features, which\nrenders the extracting of efficient features from matrices as a challenging\nproblem. A brain network, also named as connectome, could forma a graph\nstructure naturally, the nodes of which are brain regions and the edges are\ninterregional connectivity. Thus, in this study, we proposed novel graph\nconvolutional networks (GCNs) to extract efficient disease-related features\nfrom FC matrices. Considering the time-dependent nature of brain activity, we\ncomputed dynamic FC matrices with sliding-windows and implemented a graph\nconvolution based LSTM (long short term memory) layer to process dynamic\ngraphs. Moreover, the demographics of patients were also used to guide the\nclassification. However, unlike in conventional methods where personal\ninformation, i.e., gender and age were added as extra inputs, we argue that\nthis kind of approach may not actually improve the classification performance,\nfor such personal information given in dataset was usually balanced\ndistributed. In this paper, we proposed to utilize the demographic information\nas extra outputs and to share parameters among three networks predicting\nsubject status, gender and age, which serve as assistant tasks. We tested the\nperformance of the proposed architecture in ADNI II dataset to classify\nAlzheimer's disease patients from normal controls. The classification accuracy,\nsensitivity and specificity reach 0.90, 0.92 and 0.89 on ADNI II dataset.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2019 06:43:29 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Xing", "Xiaodan", ""], ["Li", "Qingfeng", ""], ["Wei", "Hao", ""], ["Zhang", "Minqing", ""], ["Zhan", "Yiqiang", ""], ["Zhou", "Xiang Sean", ""], ["Xue", "Zhong", ""], ["Shi", "Feng", ""]]}, {"id": "2001.03354", "submitter": "Haiping Huang", "authors": "Chan Li and Haiping Huang", "title": "Learning credit assignment", "comments": "5 pages, 4 figures, a generalized BackProp proposed to learn credit\n  assignment from an network ensemble perspective, to appear in Phys Rev Lett\n  (2020)", "journal-ref": "Phys. Rev. Lett. 125, 178301 (2020)", "doi": "10.1103/PhysRevLett.125.178301", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved impressive prediction accuracies in a variety of\nscientific and industrial domains. However, the nested non-linear feature of\ndeep learning makes the learning highly non-transparent, i.e., it is still\nunknown how the learning coordinates a huge number of parameters to achieve a\ndecision making. To explain this hierarchical credit assignment, we propose a\nmean-field learning model by assuming that an ensemble of sub-networks, rather\nthan a single network, are trained for a classification task. Surprisingly, our\nmodel reveals that apart from some deterministic synaptic weights connecting\ntwo neurons at neighboring layers, there exist a large number of connections\nthat can be absent, and other connections can allow for a broad distribution of\ntheir weight values. Therefore, synaptic connections can be classified into\nthree categories: very important ones, unimportant ones, and those of\nvariability that may partially encode nuisance factors. Therefore, our model\nlearns the credit assignment leading to the decision, and predicts an ensemble\nof sub-networks that can accomplish the same task, thereby providing insights\ntoward understanding the macroscopic behavior of deep learning through the lens\nof distinct roles of synaptic weights.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 09:06:46 GMT"}, {"version": "v2", "created": "Sat, 3 Oct 2020 09:35:22 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Li", "Chan", ""], ["Huang", "Haiping", ""]]}, {"id": "2001.03397", "submitter": "Jeff Hanna", "authors": "Jeff Hanna, Cora Kim, Nadia M\\\"uller-Voggel", "title": "External noise removed from magnetoencephalographic signal using\n  Independent Component Analyses of reference channels", "comments": "Accepted for publication in Journal of Neuroscience Methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Many magnetoencephalographs (MEG) contain, in addition to data\nchannels, a set of reference channels positioned relatively far from the head\nthat provide information on magnetic fields not originating from the brain.\nThis information is used to subtract sources of non-neural origin, with either\ngeometrical or least mean squares (LMS) methods. LMS methods in particular tend\nto be biased toward more constant noise sources and are often unable to remove\nintermittent noise.\n  New Method: To better identify and eliminate external magnetic noise, we\npropose performing ICA directly on the MEG reference channels. This in most\ncases produces several components which are clear summaries of external noise\nsources with distinct spatio-temporal patterns. We present two algorithms for\nidentifying and removing such noise components from the data which can in many\ncases significantly improve data quality.\n  Results: We performed simulations using forward models that contained both\nbrain sources and external noise sources. First, traditional LMS-based methods\nwere applied. While this removed a large amount of noise, a significant portion\nstill remained. In many cases, this portion could be removed using the proposed\ntechnique, with little to no false positives.\n  Comparison with existing method(s): The proposed method removes significant\namounts of noise to which existing LMS-based methods tend to be insensitive.\n  Conclusions: The proposed method complements and extends traditional\nreference based noise correction with little extra computational cost and low\nchances of false positives. Any MEG system with reference channels could profit\nfrom its use, particularly in labs with intermittent noise sources.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 11:42:00 GMT"}], "update_date": "2020-01-13", "authors_parsed": [["Hanna", "Jeff", ""], ["Kim", "Cora", ""], ["M\u00fcller-Voggel", "Nadia", ""]]}, {"id": "2001.03614", "submitter": "Claire Meissner-Bernard", "authors": "Claire Meissner-Bernard, Matthias Tsai, Laureline Logiaco, Wulfram\n  Gerstner", "title": "Paradoxical Results of Long-Term Potentiation explained by Voltage-based\n  Plasticity Rule", "comments": null, "journal-ref": "Front. Synaptic Neurosci. (2020) 12:585539", "doi": "10.3389/fnsyn.2020.585539", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments have shown that the same stimulation pattern that causes\nLong-Term Potentiation in proximal synapses, will induce Long-Term Depression\nin distal ones. In order to understand these, and other, surprising\nobservations we use a phenomenological model of Hebbian plasticity at the\nlocation of the synapse. Our computational model describes the Hebbian\ncondition of joint activity of pre- and post-synaptic neuron in a compact form\nas the interaction of the glutamate trace left by a presynaptic spike with the\ntime course of the postsynaptic voltage. We test the model using experimentally\nrecorded dendritic voltage traces in hippocampus and neocortex. We find that\nthe time course of the voltage in the neighborhood of a stimulated synapse is a\nreliable predictor of whether a stimulated synapse undergoes potentiation,\ndepression, or no change. Our model can explain the existence of different --\nat first glance seemingly paradoxical -- outcomes of synaptic potentiation and\ndepression experiments depending on the dendritic location of the synapse and\nthe frequency or timing of the stimulation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2020 18:57:06 GMT"}, {"version": "v2", "created": "Mon, 12 Oct 2020 21:52:02 GMT"}, {"version": "v3", "created": "Wed, 18 Nov 2020 20:03:33 GMT"}], "update_date": "2020-11-20", "authors_parsed": [["Meissner-Bernard", "Claire", ""], ["Tsai", "Matthias", ""], ["Logiaco", "Laureline", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "2001.03761", "submitter": "Marinho Lopes", "authors": "Marinho A. Lopes, Jiaxiang Zhang, Dominik Krzemi\\'nski, Khalid\n  Hamandi, Qi Chen, Lorenzo Livi, and Naoki Masuda", "title": "Recurrence Quantification Analysis of Dynamic Brain Networks", "comments": "77 pages, 11 figures; note: the acknowledgments section is the most\n  complete in this arxiv version (compared to the published version in EJN)", "journal-ref": null, "doi": "10.1111/ejn.14960", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evidence suggests that brain network dynamics is a key determinant of brain\nfunction and dysfunction. Here we propose a new framework to assess the\ndynamics of brain networks based on recurrence analysis. Our framework uses\nrecurrence plots and recurrence quantification analysis to characterize dynamic\nnetworks. For resting-state magnetoencephalographic dynamic functional networks\n(dFNs), we have found that functional networks recur more quickly in people\nwith epilepsy than healthy controls. This suggests that recurrence of dFNs may\nbe used as a biomarker of epilepsy. For stereo electroencephalography data, we\nhave found that dFNs involved in epileptic seizures emerge before seizure\nonset, and recurrence analysis allows us to detect seizures. We further observe\ndistinct dFNs before and after seizures, which may inform neurostimulation\nstrategies to prevent seizures. Our framework can also be used for\nunderstanding dFNs in healthy brain function and in other neurological\ndisorders besides epilepsy.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2020 14:41:34 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2020 11:04:57 GMT"}], "update_date": "2020-09-17", "authors_parsed": [["Lopes", "Marinho A.", ""], ["Zhang", "Jiaxiang", ""], ["Krzemi\u0144ski", "Dominik", ""], ["Hamandi", "Khalid", ""], ["Chen", "Qi", ""], ["Livi", "Lorenzo", ""], ["Masuda", "Naoki", ""]]}, {"id": "2001.03985", "submitter": "Luigi Acerbi", "authors": "Bas van Opheusden, Luigi Acerbi and Wei Ji Ma", "title": "Unbiased and Efficient Log-Likelihood Estimation with Inverse Binomial\n  Sampling", "comments": "Bas van Opheusden and Luigi Acerbi contributed equally to this work", "journal-ref": null, "doi": "10.1371/journal.pcbi.1008483", "report-no": null, "categories": "cs.LG q-bio.NC q-bio.QM stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fate of scientific hypotheses often relies on the ability of a\ncomputational model to explain the data, quantified in modern statistical\napproaches by the likelihood function. The log-likelihood is the key element\nfor parameter estimation and model evaluation. However, the log-likelihood of\ncomplex models in fields such as computational biology and neuroscience is\noften intractable to compute analytically or numerically. In those cases,\nresearchers can often only estimate the log-likelihood by comparing observed\ndata with synthetic observations generated by model simulations. Standard\ntechniques to approximate the likelihood via simulation either use summary\nstatistics of the data or are at risk of producing severe biases in the\nestimate. Here, we explore another method, inverse binomial sampling (IBS),\nwhich can estimate the log-likelihood of an entire data set efficiently and\nwithout bias. For each observation, IBS draws samples from the simulator model\nuntil one matches the observation. The log-likelihood estimate is then a\nfunction of the number of samples drawn. The variance of this estimator is\nuniformly bounded, achieves the minimum variance for an unbiased estimator, and\nwe can compute calibrated estimates of the variance. We provide theoretical\narguments in favor of IBS and an empirical assessment of the method for\nmaximum-likelihood estimation with simulation-based models. As case studies, we\ntake three model-fitting problems of increasing complexity from computational\nand cognitive neuroscience. In all problems, IBS generally produces lower error\nin the estimated parameters and maximum log-likelihood values than alternative\nsampling methods with the same average number of samples. Our results\ndemonstrate the potential of IBS as a practical, robust, and easy to implement\nmethod for log-likelihood evaluation when exact techniques are not available.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 19:51:35 GMT"}, {"version": "v2", "created": "Wed, 7 Oct 2020 19:24:28 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2020 20:08:25 GMT"}], "update_date": "2021-01-27", "authors_parsed": [["van Opheusden", "Bas", ""], ["Acerbi", "Luigi", ""], ["Ma", "Wei Ji", ""]]}, {"id": "2001.04064", "submitter": "Zhaofei Yu", "authors": "Zhaofei Yu and Jian K. Liu and Shanshan Jia and Yichen Zhang and\n  Yajing Zheng and Yonghong Tian and Tiejun Huang", "title": "Towards the Next Generation of Retinal Neuroprosthesis: Visual\n  Computation with Spikes", "comments": "15 pages, 5 figures", "journal-ref": "published 2019", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroprosthesis, as one type of precision medicine device, is aiming for\nmanipulating neuronal signals of the brain in a closed-loop fashion, together\nwith receiving stimulus from the environment and controlling some part of our\nbrain/body. In terms of vision, incoming information can be processed by the\nbrain in millisecond interval. The retina computes visual scenes and then sends\nits output as neuronal spikes to the cortex for further computation. Therefore,\nthe neuronal signal of interest for retinal neuroprosthesis is spike.\nClosed-loop computation in neuroprosthesis includes two stages: encoding\nstimulus to neuronal signal, and decoding it into stimulus. Here we review some\nof the recent progress about visual computation models that use spikes for\nanalyzing natural scenes, including static images and dynamic movies. We\nhypothesize that for a better understanding of computational principles in the\nretina, one needs a hypercircuit view of the retina, in which different\nfunctional network motifs revealed in the cortex neuronal network should be\ntaken into consideration for the retina. Different building blocks of the\nretina, including a diversity of cell types and synaptic connections, either\nchemical synapses or electrical synapses (gap junctions), make the retina an\nideal neuronal network to adapt the computational techniques developed in\nartificial intelligence for modeling of encoding/decoding visual scenes.\nAltogether, one needs a systems approach of visual computation with spikes to\nadvance the next generation of retinal neuroprosthesis as an artificial visual\nsystem.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 05:22:57 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Yu", "Zhaofei", ""], ["Liu", "Jian K.", ""], ["Jia", "Shanshan", ""], ["Zhang", "Yichen", ""], ["Zheng", "Yajing", ""], ["Tian", "Yonghong", ""], ["Huang", "Tiejun", ""]]}, {"id": "2001.04103", "submitter": "Hata Katsuhiko", "authors": "Katsuhiko Hata, Osamu Araki, Osamu Yokoi, Tatsumi Kusakabe, Yoshio\n  Yamamoto, Susumu Ito and Tetsuro Nikuni", "title": "Multicoding in neural information transfer suggested by mathematical\n  analysis of the frequency-dependent synaptic plasticity in vivo", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two elements of neural information processing have primarily been proposed:\nfiring rate and spike timing of neurons. In the case of synaptic plasticity,\nalthough spike-timing-dependent plasticity (STDP) depending on presynaptic and\npostsynaptic spike times had been considered the most common rule, recent\nstudies have shown the inhibitory nature of the brain in vivo for precise spike\ntiming, which is key to the STDP. Thus, the importance of the firing frequency\nin synaptic plasticity in vivo has been recognized again. However, little is\nunderstood about how the frequency-dependent synaptic plasticity (FDP) is\nregulated in vivo. Here, we focused on the presynaptic input pattern, the\nintracellular calcium decay time constants, and the background synaptic\nactivity, which vary depending on neuron types and the anatomical and\nphysiological environment in the brain. By analyzing a calcium-based model, we\nfound that the synaptic weight differs depending on these factors\ncharacteristic in vivo, even if neurons receive the same input rate. This\nfinding suggests the involvement of multifaceted factors other than input\nfrequency in FDP and even neural coding in vivo.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 08:37:40 GMT"}], "update_date": "2020-01-14", "authors_parsed": [["Hata", "Katsuhiko", ""], ["Araki", "Osamu", ""], ["Yokoi", "Osamu", ""], ["Kusakabe", "Tatsumi", ""], ["Yamamoto", "Yoshio", ""], ["Ito", "Susumu", ""], ["Nikuni", "Tetsuro", ""]]}, {"id": "2001.04571", "submitter": "David Zoltowski", "authors": "David M. Zoltowski, Jonathan W. Pillow, and Scott W. Linderman", "title": "Unifying and generalizing models of neural dynamics during\n  decision-making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An open question in systems and computational neuroscience is how neural\ncircuits accumulate evidence towards a decision. Fitting models of\ndecision-making theory to neural activity helps answer this question, but\ncurrent approaches limit the number of these models that we can fit to neural\ndata. Here we propose a unifying framework for modeling neural activity during\ndecision-making tasks. The framework includes the canonical drift-diffusion\nmodel and enables extensions such as multi-dimensional accumulators, variable\nand collapsing boundaries, and discrete jumps. Our framework is based on\nconstraining the parameters of recurrent state-space models, for which we\nintroduce a scalable variational Laplace-EM inference algorithm. We applied the\nmodeling approach to spiking responses recorded from monkey parietal cortex\nduring two decision-making tasks. We found that a two-dimensional accumulator\nbetter captured the trial-averaged responses of a set of parietal neurons than\na single accumulator model. Next, we identified a variable lower boundary in\nthe responses of an LIP neuron during a random dot motion task.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2020 23:57:28 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Zoltowski", "David M.", ""], ["Pillow", "Jonathan W.", ""], ["Linderman", "Scott W.", ""]]}, {"id": "2001.04907", "submitter": "Dmitry Krotov", "authors": "Chaitanya K. Ryali, John J. Hopfield, Leopold Grinberg, Dmitry Krotov", "title": "Bio-Inspired Hashing for Unsupervised Similarity Search", "comments": "Accepted for publication in ICML 2020", "journal-ref": "Proceedings of the International Conference on Machine Learning,\n  2020, pp.8739-8750", "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fruit fly Drosophila's olfactory circuit has inspired a new locality\nsensitive hashing (LSH) algorithm, FlyHash. In contrast with classical LSH\nalgorithms that produce low dimensional hash codes, FlyHash produces sparse\nhigh-dimensional hash codes and has also been shown to have superior empirical\nperformance compared to classical LSH algorithms in similarity search. However,\nFlyHash uses random projections and cannot learn from data. Building on\ninspiration from FlyHash and the ubiquity of sparse expansive representations\nin neurobiology, our work proposes a novel hashing algorithm BioHash that\nproduces sparse high dimensional hash codes in a data-driven manner. We show\nthat BioHash outperforms previously published benchmarks for various hashing\nmethods. Since our learning algorithm is based on a local and biologically\nplausible synaptic plasticity rule, our work provides evidence for the proposal\nthat LSH might be a computational reason for the abundance of sparse expansive\nmotifs in a variety of biological systems. We also propose a convolutional\nvariant BioConvHash that further improves performance. From the perspective of\ncomputer science, BioHash and BioConvHash are fast, scalable and yield\ncompressed binary representations that are useful for similarity search.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:04:59 GMT"}, {"version": "v2", "created": "Tue, 30 Jun 2020 17:29:56 GMT"}], "update_date": "2020-10-09", "authors_parsed": [["Ryali", "Chaitanya K.", ""], ["Hopfield", "John J.", ""], ["Grinberg", "Leopold", ""], ["Krotov", "Dmitry", ""]]}, {"id": "2001.04915", "submitter": "Parul Verma", "authors": "Parul Verma, Achim Kienle, Dietrich Flockerzi, Doraiswami Ramkrishna", "title": "Computational analysis of a 9D model for a small DRG neuron", "comments": null, "journal-ref": null, "doi": "10.1007/s10827-020-00761-6", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Small dorsal root ganglion (DRG) neurons are primary nociceptors which are\nresponsible for sensing pain. Elucidation of their dynamics is essential for\nunderstanding and controlling pain. To this end, we present a numerical\nbifurcation analysis of a small DRG neuron model in this paper. The model is of\nHodgkin-Huxley type and has 9 state variables. It consists of a\nNa$\\mathrm{_v}$1.7 and a Na$\\mathrm{_v}$1.8 sodium channel, a leak channel, a\ndelayed rectifier potassium and an A-type transient potassium channel. The\ndynamics of this model strongly depends on the maximal conductances of the\nvoltage-gated ion channels and the external current, which can be adjusted\nexperimentally. We show that the neuron dynamics are most sensitive to the\nNa$\\mathrm{_v}$1.8 channel maximal conductance ($\\bar{g}_{1.8}$). Numerical\nbifurcation analysis shows that depending on $\\bar{g}_{1.8}$ and the external\ncurrent, different parameter regions can be identified with stable steady\nstates, periodic firing of action potentials, mixed-mode oscillations (MMOs),\nand bistability between stable steady states and stable periodic firing of\naction potentials. We illustrate and discuss the transitions between these\ndifferent regimes. We further analyze the behavior of MMOs. Within this region,\nbifurcation analysis shows a sequence of isolated periodic solution branches\nwith one large action potential and a number of small amplitude peaks per\nperiod. A closer inspection reveals more complex concatenated MMOs in between\nthese periodic MMOs branches, forming Farey sequences. Lastly, we also find\nsmall solution windows with aperiodic oscillations, which seem to be chaotic.\nThe dynamical patterns found here as a function of different parameters contain\ninformation of translational importance as their relation to pain sensation and\nits intensity is a potential source of insight into controlling pain.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 17:19:56 GMT"}], "update_date": "2020-09-08", "authors_parsed": [["Verma", "Parul", ""], ["Kienle", "Achim", ""], ["Flockerzi", "Dietrich", ""], ["Ramkrishna", "Doraiswami", ""]]}, {"id": "2001.05044", "submitter": "Tanner Sorensen", "authors": "Tanner Sorensen, Adam Lammert, Louis Goldstein, Shrikanth Narayanan", "title": "Derivation of Fitts' law from the Task Dynamics model of speech\n  production", "comments": "version before journal submission; 5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitts' law is a linear equation relating movement time to an index of\nmovement difficulty. The recent finding that Fitts' law applies to voluntary\nmovement of the vocal tract raises the question of whether the theory of speech\nproduction implies Fitts' law. The present letter establishes a theoretical\nconnection between Fitts' law and the Task Dynamics model of speech production.\nWe derive a variant of Fitts' law where the intercept and slope are functions\nof the parameters of the Task Dynamics model and the index of difficulty is a\nproduct logarithm, or Lambert W function, rather than a logarithm.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 20:50:22 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 03:36:22 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 15:46:13 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Sorensen", "Tanner", ""], ["Lammert", "Adam", ""], ["Goldstein", "Louis", ""], ["Narayanan", "Shrikanth", ""]]}, {"id": "2001.05057", "submitter": "Michael Kordovan", "authors": "Michael Kordovan, Stefan Rotter", "title": "Spike Train Cumulants for Linear-Nonlinear Poisson Cascade Models", "comments": "45 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.ST physics.bio-ph stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking activity in cortical networks is nonlinear in nature. The\nlinear-nonlinear cascade model, some versions of which are also known as\npoint-process generalized linear model, can efficiently capture the nonlinear\ndynamics exhibited by such networks. Of particular interest in such models are\ntheoretical predictions of spike train statistics. However, due to the\nmoment-closure problem, approximations are inevitable. We suggest here a series\nexpansion that explains how higher-order moments couple to lower-order ones.\nOur approach makes predictions in terms of certain integrals, the so-called\nloop integrals. In previous studies these integrals have been evaluated\nnumerically, but numerical instabilities are sometimes encountered rendering\nthe results unreliable. Analytic solutions are presented here to overcome this\nproblem, and to arrive at more robust evaluations. We were able to deduce these\nanalytic solutions by switching to Fourier space and making use of complex\nanalysis, specifically Cauchy's residue theorem. We formalized the loop\nintegrals and explicitly solved them for specific response functions. To\nquantify the importance of these corrections for spike train cumulants, we\nnumerically simulated spiking networks and compared their sample statistics to\nour theoretical predictions. Our results demonstrate that the magnitude of the\nnonlinear corrections depends on the working point of the nonlinear network\ndynamics, and that it is related to the eigenvalues of the mean-field stability\nmatrix. For our example, the corrections for the firing rates are in the range\nbetween 4 % and 21 % on average. Precise and robust predictions of spike train\nstatistics accounting for nonlinear effects are, for example, highly relevant\nfor theories involving spike-timing dependent plasticity (STDP).\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 21:56:13 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Kordovan", "Michael", ""], ["Rotter", "Stefan", ""]]}, {"id": "2001.05078", "submitter": "Dale Zhou", "authors": "Dale Zhou, Christopher W. Lynn, Zaixu Cui, Rastko Ciric, Graham L.\n  Baum, Tyler M. Moore, David R. Roalf, John A. Detre, Ruben C. Gur, Raquel E.\n  Gur, Theodore D. Satterthwaite, Danielle S. Bassett", "title": "Efficient Coding in the Economics of Human Brain Connectomics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In systems neuroscience, most models posit that brain regions communicate\ninformation under constraints of efficiency. Yet, metabolic and information\ntransfer efficiency across structural networks are not understood. In a large\ncohort of youth, we find metabolic costs associated with structural path\nstrengths supporting information diffusion. Metabolism is balanced with the\ncoupling of structures supporting diffusion and network modularity. To\nunderstand efficient network communication, we develop a theory specifying\nminimum rates of message diffusion that brain regions should transmit for an\nexpected fidelity, and we test five predictions from the theory. We introduce\ncompression efficiency, which quantifies differing trade-offs between lossy\ncompression and communication fidelity in structural networks. Compression\nefficiency evolves with development, heightens when metabolic gradients guide\ndiffusion, constrains network complexity, explains how rich-club hubs integrate\ninformation, and correlates with cortical areal scaling, myelination, and\nspeed-accuracy trade-offs. Our findings elucidate how network structures and\nmetabolic resources support efficient neural communication.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 23:01:06 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Zhou", "Dale", ""], ["Lynn", "Christopher W.", ""], ["Cui", "Zaixu", ""], ["Ciric", "Rastko", ""], ["Baum", "Graham L.", ""], ["Moore", "Tyler M.", ""], ["Roalf", "David R.", ""], ["Detre", "John A.", ""], ["Gur", "Ruben C.", ""], ["Gur", "Raquel E.", ""], ["Satterthwaite", "Theodore D.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "2001.05430", "submitter": "Jason Kamran Jr Eshraghian", "authors": "Jason K. Eshraghian and Seungbum Baek and Wesley Thio and Yulia\n  Sandamirskaya and Herbert H.C. Iu and Wei D. Lu", "title": "A Real-Time Retinomorphic Simulator Using a Conductance-Based Discrete\n  Neuronal Network", "comments": "5 pages, 4 figures, accepted for 2020 IEEE AICAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.IV q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an optimized conductance-based retina microcircuit simulator which\ntransforms light stimuli into a series of graded and spiking action potentials\nthrough photo transduction. We use discrete retinal neuron blocks based on a\ncollation of single-compartment models and morphologically realistic\nformulations, and successfully achieve a biologically real-time simulator. This\nis done by optimizing the numerical methods employed to solve the system of\nover 270 nonlinear ordinary differential equations and parameters. Our\nsimulator includes some of the most recent advances in compartmental modeling\nto include five intrinsic ion currents of each cell whilst ensuring real-time\nperformance, in attaining the ion-current and membrane responses of the\nphotoreceptor rod and cone cells, the bipolar and amacrine cells, their\nlaterally connected electrical and chemical synapses, and the output ganglion\ncell. It exhibits dynamical retinal behavior such as spike-frequency\nadaptation, rebound activation, fast-spiking, and subthreshold responsivity.\nLight stimuli incident at the photoreceptor rod and cone cells is modulated\nthrough the system of differential equations, enabling the user to probe the\nneuronal response at any point in the network. This is in contrast to many\nother retina encoding schemes which prefer to `black-box' the preceding stages\nto the spike train output. Our simulator is made available open source, with\nthe hope that it will benefit neuroscientists and machine learning\npractitioners in better understanding the retina sub-circuitries, how retina\ncells optimize the representation of visual information, and in generating\nlarge datasets of biologically accurate graded and spiking responses.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2019 20:23:13 GMT"}], "update_date": "2020-01-16", "authors_parsed": [["Eshraghian", "Jason K.", ""], ["Baek", "Seungbum", ""], ["Thio", "Wesley", ""], ["Sandamirskaya", "Yulia", ""], ["Iu", "Herbert H. C.", ""], ["Lu", "Wei D.", ""]]}, {"id": "2001.05626", "submitter": "Junhao Liang", "authors": "Junhao Liang, Tianshou Zhou, Changsong Zhou", "title": "Hopf Bifurcation in Mean Field Explains Critical Avalanches in\n  Excitation-Inhibition Balanced Neuronal Networks: A Mechanism for Multiscale\n  Variability", "comments": null, "journal-ref": "Front. Syst. Neurosci.14:580011. (2020)", "doi": "10.3389/fnsys.2020.580011", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical neural circuits display highly irregular spiking in individual\nneurons but variably sized collective firing, oscillations and critical\navalanches at the population level, all of which have functional importance for\ninformation processing. Theoretically, the balance of excitation and inhibition\ninputs is thought to account for spiking irregularity and critical avalanches\nmay originate from an underlying phase transition. However, the theoretical\nreconciliation of these multilevel dynamic aspects in neural circuits remains\nan open question. Herein, we study excitation-inhibition (E-I) balanced\nneuronal network with biologically realistic synaptic kinetics. It can maintain\nirregular spiking dynamics with different levels of synchrony and critical\navalanches emerge near the synchronous transition point. We propose a novel\nsemi-analytical mean-field theory to derive the field equations governing the\nnetwork macroscopic dynamics. It reveals that the E-I balanced state of the\nnetwork manifesting irregular individual spiking is characterized by a\nmacroscopic stable state, which can be either a fixed point or a periodic\nmotion and the transition is predicted by a Hopf bifurcation in the macroscopic\nfield. Furthermore, by analyzing public data, we find the coexistence of\nirregular spiking and critical avalanches in the spontaneous spiking activities\nof mouse cortical slice in vitro, indicating the universality of the observed\nphenomena. Our theory unveils the mechanism that permits complex neural\nactivities in different spatiotemporal scales to coexist and elucidates a\npossible origin of the criticality of neural systems. It also provides a novel\ntool for analyzing the macroscopic dynamics of E-I balanced networks and its\nrelationship to the microscopic counterparts, which can be useful for\nlarge-scale modeling and computation of cortical dynamics.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 03:06:20 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2020 01:42:22 GMT"}, {"version": "v3", "created": "Tue, 17 Mar 2020 08:56:31 GMT"}, {"version": "v4", "created": "Sat, 4 Jul 2020 03:07:40 GMT"}], "update_date": "2021-01-08", "authors_parsed": [["Liang", "Junhao", ""], ["Zhou", "Tianshou", ""], ["Zhou", "Changsong", ""]]}, {"id": "2001.05847", "submitter": "Pablo Lanillos", "authors": "Cansu Sancaktar, Marcel van Gerven, Pablo Lanillos", "title": "End-to-End Pixel-Based Deep Active Inference for Body Perception and\n  Action", "comments": null, "journal-ref": null, "doi": "10.1109/ICDL-EpiRob48136.2020.9278105", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a pixel-based deep active inference algorithm (PixelAI) inspired\nby human body perception and action. Our algorithm combines the free-energy\nprinciple from neuroscience, rooted in variational inference, with deep\nconvolutional decoders to scale the algorithm to directly deal with raw visual\ninput and provide online adaptive inference. Our approach is validated by\nstudying body perception and action in a simulated and a real Nao robot.\nResults show that our approach allows the robot to perform 1) dynamical body\nestimation of its arm using only monocular camera images and 2) autonomous\nreaching to \"imagined\" arm poses in the visual space. This suggests that robot\nand human body perception and action can be efficiently solved by viewing both\nas an active inference problem guided by ongoing sensory input.\n", "versions": [{"version": "v1", "created": "Sat, 28 Dec 2019 12:19:09 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 14:15:16 GMT"}, {"version": "v3", "created": "Fri, 29 May 2020 21:30:12 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Sancaktar", "Cansu", ""], ["van Gerven", "Marcel", ""], ["Lanillos", "Pablo", ""]]}, {"id": "2001.06212", "submitter": "Rolf Bader", "authors": "Rolf Bader", "title": "Neural coincidence detection strategies during perception of multi-pitch\n  musical tones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-pitch perception is investigated in a listening test using 30\nrecordings of musical sounds with two tones played simultaneously, except for\ntwo gong sounds with inharmonic overtone spectrum, judging roughness and\nseparateness as the ability to tell the two tones in each recording apart. 13\nsounds were from a Western guitar playing all 13 intervals in one octave, the\nother sounds were mainly from non-Western instruments comparing familiar with\nunfamiliar instrument sounds for Western listeners. Additionally the sounds\nwere processed in a cochlear model transferring the mechanical basilar membrane\nmotion into neural spikes followed by a post-processing simulating different\ndegrees of coincidence detection. Separateness perception showed a clear\ndistinction between familiar and unfamiliar sounds, while roughness perception\ndid not. By correlating perception with simulation different perception\nstrategies were found. Familiar sounds correlated strongly positive with high\ndegrees of coincidence detection, where only 3-5 periodicities were left, while\nunfamiliar sounds correlated with low coincidence levels. This corresponds to\nan attention to pitch and timbre respectively. Additionally, separateness\nperception shows an opposite correlation between perception and neural\ncorrelates between familiar and unfamiliar sounds. This correlates with the\nperceptional finding of the distinction between familiar and unfamiliar sounds\nwith separateness.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 09:34:26 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Bader", "Rolf", ""]]}, {"id": "2001.06371", "submitter": "Nicola Pedreschi", "authors": "Nicola Pedreschi, Christophe Bernard, Wesley Clawson, Pascale\n  Quilichini, Alain Barrat, Demian Battaglia", "title": "Dynamic core-periphery structure of information sharing networks in the\n  entorhinal cortex and the hippocampus", "comments": "33 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.app-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural computation is associated with the emergence, reconfiguration and\ndissolution of cell assemblies in the context of varying oscillatory states.\nHere, we describe the complex spatio-temporal dynamics of cell assemblies\nthrough temporal network formalism. We use a sliding window approach to extract\nsequences of networks of information sharing among single units in hippocampus\nand enthorinal cortex during anesthesia and study how global and node-wise\nfunctional connectivity properties evolve along time. First, we find that\ninformation sharing networks display, at any time, a core-periphery structure\nin which an integrated core of more tightly functionally interconnected units\nlink to more loosely connected network leaves. However the units participating\nto the core or to the periphery substantially change across time-windows.\nSecond, we find that discrete network states can be defined on top of this\ncontinuously ongoing liquid core-periphery reorganization. Switching between\nnetwork states results in a more abrupt modification of the units belonging to\nthe core and is only loosely linked to transitions between global oscillatory\nstates. Third, we characterize different styles of temporal connectivity that\ncells can exhibit within each state of the sharing network. While inhibitory\ncells tend to be central, we show that, otherwise, anatomical localization only\npoorly influences the patterns of temporal connectivity of the different cells.\nCells can also change temporal connectivity style when the network changes\nstate. Altogether, these findings reveal that the sharing of information\nmediated by the intrinsic dynamics of hippocampal and enthorinal cortex cell\nassemblies have a rich spatiotemporal structure, which could not have been\nidentified by more conventional time- or state-averaged analyses of functional\nconnectivity.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 15:26:01 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Pedreschi", "Nicola", ""], ["Bernard", "Christophe", ""], ["Clawson", "Wesley", ""], ["Quilichini", "Pascale", ""], ["Barrat", "Alain", ""], ["Battaglia", "Demian", ""]]}, {"id": "2001.06408", "submitter": "Martin Biehl", "authors": "Martin Biehl and Felix A. Pollock and Ryota Kanai", "title": "A Technical Critique of Some Parts of the Free Energy Principle", "comments": "20 pages, 1 figure. Martin Biehl and Felix A. Pollock contributed\n  equally to this publication. This version will be published in Entropy. It\n  contains a minor correction (contrary to our previous assertion linearity is\n  not assumed in Step 1) and additional details in response to reviewer's\n  comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We summarize the original formulation of the free energy principle, and\nhighlight some technical issues. We discuss how these issues affect related\nresults involving generalised coordinates and, where appropriate, mention\nconsequences for and reveal, up to now unacknowledged, differences to newer\nformulations of the free energy principle. In particular, we reveal that\nvarious definitions of the \"Markov blanket\" proposed in different works are not\nequivalent. We show that crucial steps in the free energy argument which\ninvolve rewriting the equations of motion of systems with Markov blankets, are\nnot generally correct without additional (previously unstated) assumptions. We\nprove by counterexample that the original free energy lemma, when taken at face\nvalue, is wrong. We show further that this free energy lemma, when it does\nhold, implies equality of variational density and ergodic conditional density.\nThe interpretation in terms of Bayesian inference hinges on this point, and we\nhence conclude that it is not sufficiently justified. Additionally, we\nhighlight that the variational densities presented in newer formulations of the\nfree energy principle and lemma are parameterised by different variables than\nin older works, leading to a substantially different interpretation of the\ntheory. Note that we only highlight some specific problems in the discussed\npublications. These problems do not rule out conclusively that the general\nideas behind the free energy principle are worth pursuing.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2020 06:27:23 GMT"}, {"version": "v2", "created": "Fri, 7 Feb 2020 05:51:01 GMT"}, {"version": "v3", "created": "Sun, 28 Feb 2021 20:27:20 GMT"}], "update_date": "2021-03-02", "authors_parsed": [["Biehl", "Martin", ""], ["Pollock", "Felix A.", ""], ["Kanai", "Ryota", ""]]}, {"id": "2001.06415", "submitter": "Anindita Bhadra", "authors": "Prothama Manna and Anindita Bhadra", "title": "Free-ranging dogs do not distinguish between barks without context", "comments": "6 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Canids display a vast diversity of social organizations, from solitary-living\nto pairs to packs. Domestic dogs have descended from pack-living gray wolf-like\nancestors. Unlike their group living ancestors, free-ranging dogs are\nfacultatively social, preferring to forage solitarily. They are scavengers by\nnature, mostly dependent on human garbage and generosity for their sustenance.\nFree-ranging dogs are highly territorial, often defending their territories\nusing vocalizations. Vocal communication plays a critical role between inter\nand intraspecies and group interaction and maintaining their social dynamics.\nBarking is the most common among the different types of vocalizations of dogs.\nDogs have a broad hearing range and can respond to sounds over long distances.\nDomestic dogs have been shown to have the ability to distinguish between\nbarking in different contexts. Since free-ranging dogs regularly engage in\nvarious kinds of interactions with each other, it is interesting to know\nwhether they are capable of distinguishing between vocalizations of their own\nand other groups. In this study, a playback experiment was used to test if dogs\ncan distinguish between barking of their own group member from a non-group\nmember. Though dogs respond to barking from other groups in territorial\nexchanges, they did not respond differently to the self and other group barking\nin the playback experiments. This suggests a role of context in the\ninteractions between dogs and opens up possibilities for future studies on the\ncomparison of the responses of dogs in playback experiments with their natural\nbehavior through long-term observations.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jan 2020 07:20:07 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Manna", "Prothama", ""], ["Bhadra", "Anindita", ""]]}, {"id": "2001.06605", "submitter": "Joaquin Goni", "authors": "Kausar Abbas, Enrico Amico, Diana Otero Svaldi, Uttara Tipnis, Duy Anh\n  Duong-Tran, Mintao Liu, Meenusree Rajapandian, Jaroslaw Harezlak, Beau M.\n  Ances, Joaqu\\'in Go\\~ni", "title": "GEFF: Graph Embedding for Functional Fingerprinting", "comments": "30 pages; 6 figures; 5 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been well established that Functional Connectomes (FCs), as estimated\nfrom functional MRI (fMRI) data, have an individual fingerprint that can be\nused to identify an individual from a population (subject-identification).\nAlthough identification rate is high when using resting-state FCs, other tasks\nshow moderate to low values. Furthermore, identification rate is\ntask-dependent, and is low when distinct cognitive states, as captured by\ndifferent fMRI tasks, are compared. Here we propose an embedding framework,\nGEFF (Graph Embedding for Functional Fingerprinting), based on group-level\ndecomposition of FCs into eigenvectors. GEFF creates an eigenspace\nrepresentation of a group of subjects using one or more task FCs (Learning\nStage). In the Identification Stage, we compare new instances of FCs from the\nLearning subjects within this eigenspace (validation dataset). The validation\ndataset contains FCs either from the same tasks as the Learning dataset or from\nthe remaining tasks that were not included in Learning. Assessment of\nvalidation FCs within the eigenspace results in significantly increased\nsubject-identification rates for all fMRI tasks tested and potentially\ntask-independent fingerprinting process. It is noteworthy that combining\nresting-state with one fMRI task for GEFF Learning Stage covers most of the\ncognitive space for subject identification. In addition to\nsubject-identification, GEFF was also used for identification of cognitive\nstates, i.e. to identify the task associated to a given FC, regardless of the\nsubject being already in the Learning dataset or not (subject-independent\ntask-identification). In addition, we also show that eigenvectors from the\nLearning Stage can be characterized as task-dominant, subject dominant or\nneither, providing a deeper insight into the extent of variance in functional\nconnectivity across individuals and cognitive states.\n", "versions": [{"version": "v1", "created": "Sat, 18 Jan 2020 05:35:55 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Abbas", "Kausar", ""], ["Amico", "Enrico", ""], ["Svaldi", "Diana Otero", ""], ["Tipnis", "Uttara", ""], ["Duong-Tran", "Duy Anh", ""], ["Liu", "Mintao", ""], ["Rajapandian", "Meenusree", ""], ["Harezlak", "Jaroslaw", ""], ["Ances", "Beau M.", ""], ["Go\u00f1i", "Joaqu\u00edn", ""]]}, {"id": "2001.06845", "submitter": "Andrei Khrennikov Yu", "authors": "Giuseppe Iurato and Andrei Khrennikov", "title": "A comment on paper of Kim et al. on mechanisms of hysteresis in human\n  brain networks: comparing with theoretical m-adic model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This comment is aimed to point out that the recent work due to Kim, et al. in\nwhich the clinical and experiential assessment of a brain network model\nsuggests that asymmetry of synchronization suppression is the key mechanism of\nhysteresis has coupling with our theoretical hysteresis model of\nunconscious-conscious interconnection based on dynamics on m-adic trees.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 15:14:10 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Iurato", "Giuseppe", ""], ["Khrennikov", "Andrei", ""]]}, {"id": "2001.06881", "submitter": "Maurizio De Pitt\\`a", "authors": "Maurizio De Pitt\\`a", "title": "Neuron-Glial Interactions", "comments": "43 pages, 2 figures, 1 table. Accepted for publication in the\n  \"Encyclopedia of Computational Neuroscience,\" D. Jaeger and R. Jung eds.,\n  Springer-Verlag New York, 2020 (2nd edition)", "journal-ref": null, "doi": "10.1007/978-1-4614-7320-6_100691-1", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Although lagging behind classical computational neuroscience, theoretical and\ncomputational approaches are beginning to emerge to characterize different\naspects of neuron-glial interactions. This chapter aims to provide essential\nknowledge on neuron-glial interactions in the mammalian brain, leveraging on\ncomputational studies that focus on structure (anatomy) and function\n(physiology) of such interactions in the healthy brain. Although our\nunderstanding of the need of neuron-glial interactions in the brain is still at\nits infancy, being mostly based on predictions that await for experimental\nvalidation, simple general modeling arguments borrowed from control theory are\nintroduced to support the importance of including such interactions in\ntraditional neuron-based modeling paradigms.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jan 2020 18:30:07 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["De Pitt\u00e0", "Maurizio", ""]]}, {"id": "2001.07092", "submitter": "Grace Lindsay", "authors": "Grace W. Lindsay", "title": "Convolutional Neural Networks as a Model of the Visual System: Past,\n  Present, and Future", "comments": "Review Article to be published in Journal of Cognitive Neuroscience,\n  18 pages, 5 figures plus 8 pages of references", "journal-ref": null, "doi": "10.1162/jocn_a_01544", "report-no": null, "categories": "q-bio.NC cs.CV cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Convolutional neural networks (CNNs) were inspired by early findings in the\nstudy of biological vision. They have since become successful tools in computer\nvision and state-of-the-art models of both neural activity and behavior on\nvisual tasks. This review highlights what, in the context of CNNs, it means to\nbe a good model in computational neuroscience and the various ways models can\nprovide insight. Specifically, it covers the origins of CNNs and the methods by\nwhich we validate them as models of biological vision. It then goes on to\nelaborate on what we can learn about biological vision by understanding and\nexperimenting on CNNs and discusses emerging opportunities for the use of CNNS\nin vision research beyond basic object recognition.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 13:04:37 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2020 11:37:16 GMT"}], "update_date": "2020-02-11", "authors_parsed": [["Lindsay", "Grace W.", ""]]}, {"id": "2001.07203", "submitter": "Lancelot Da Costa", "authors": "Lancelot Da Costa, Thomas Parr, Noor Sajid, Sebastijan Veselic,\n  Victorita Neacsu, Karl Friston", "title": "Active inference on discrete state-spaces: a synthesis", "comments": "36 pages, 5 figures", "journal-ref": "Journal of Mathematical Psychology 2021", "doi": "10.1016/j.jmp.2020.102447", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active inference is a normative principle underwriting perception, action,\nplanning, decision-making and learning in biological or artificial agents. From\nits inception, its associated process theory has grown to incorporate complex\ngenerative models, enabling simulation of a wide range of complex behaviours.\nDue to successive developments in active inference, it is often difficult to\nsee how its underlying principle relates to process theories and practical\nimplementation. In this paper, we try to bridge this gap by providing a\ncomplete mathematical synthesis of active inference on discrete state-space\nmodels. This technical summary provides an overview of the theory, derives\nneuronal dynamics from first principles and relates this dynamics to biological\nprocesses. Furthermore, this paper provides a fundamental building block needed\nto understand active inference for mixed generative models; allowing continuous\nsensations to inform discrete representations. This paper may be used as\nfollows: to guide research towards outstanding challenges, a practical guide on\nhow to implement active inference to simulate experimental behaviour, or a\npointer towards various in-silico neurophysiological responses that may be used\nto make empirical predictions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 18:24:21 GMT"}, {"version": "v2", "created": "Sat, 28 Mar 2020 17:08:31 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Da Costa", "Lancelot", ""], ["Parr", "Thomas", ""], ["Sajid", "Noor", ""], ["Veselic", "Sebastijan", ""], ["Neacsu", "Victorita", ""], ["Friston", "Karl", ""]]}, {"id": "2001.07811", "submitter": "Hiroshi Tamura", "authors": "Yuta Kanda, Kota S Sasaki, Izumi Ohzawa, Hiroshi Tamura", "title": "Deleting object selective units in a fully-connected layer of deep\n  convolutional networks improves classification performance", "comments": "Number of pages: 18; Number of Figures: 6; Number of Tables: 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the primate visual cortices show a wide range of stimulus\nselectivity. Some neurons respond to only a small fraction of stimulus images,\nwhereas others respond to many stimulus images in a non-selective manner. It is\nunclear how stimulus selective and non-selective neurons contribute to visual\nobject recognition. Herein, we examined the relationship between stimulus\nselectivity and the effect of deletion of units on task performance using fully\na connected layer of two types of deep convolutional neural networks (DCNNs).\nDeleting a stimulus selective unit caused slight improvements of task\nperformance, whereas deleting stimulus non-selective units caused a significant\ndecrease in task performance. However, these findings do not imply that\nstimulus selective units have no use for the task. Indeed, better performance\nwas obtained when the networks consisted of both stimulus selective and\nnon-selective units.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 23:33:53 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Kanda", "Yuta", ""], ["Sasaki", "Kota S", ""], ["Ohzawa", "Izumi", ""], ["Tamura", "Hiroshi", ""]]}, {"id": "2001.08028", "submitter": "Lancelot Da Costa", "authors": "Lancelot Da Costa, Thomas Parr, Biswa Sengupta, Karl Friston", "title": "Neural dynamics under active inference: plausibility and efficiency of\n  information processing", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": "10.3390/e23040454", "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active inference is a normative framework for explaining behaviour under the\nfree energy principle -- a theory of self-organisation originating in\nneuroscience. It specifies neuronal dynamics for state-estimation in terms of a\ndescent on (variational) free energy -- a measure of the fit between an\ninternal (generative) model and sensory observations. The free energy gradient\nis a prediction error -- plausibly encoded in the average membrane potentials\nof neuronal populations. Conversely, the expected probability of a state can be\nexpressed in terms of neuronal firing rates. We show that this is consistent\nwith current models of neuronal dynamics and establish face validity by\nsynthesising plausible electrophysiological responses. We then show that these\nneuronal dynamics approximate natural gradient descent, a well-known\noptimisation algorithm from information geometry that follows the steepest\ndescent of the objective in information space. We compare the information\nlength of belief updating in both schemes, a measure of the distance traveled\nin information space that has a direct interpretation in terms of metabolic\ncost. We show that neural dynamics under active inference are metabolically\nefficient and suggest that neural representations in biological agents may\nevolve by approximating steepest descent in information space towards the point\nof optimal inference.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 14:15:05 GMT"}, {"version": "v2", "created": "Sun, 31 Jan 2021 19:29:43 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Da Costa", "Lancelot", ""], ["Parr", "Thomas", ""], ["Sengupta", "Biswa", ""], ["Friston", "Karl", ""]]}, {"id": "2001.08173", "submitter": "Peyman Hosseinzadeh Kassani", "authors": "Peyman Hosseinzadeh Kassani, Li Xiao, Gemeng Zhang, Julia M. Stephen,\n  Tony W. Wilson, Vince D. Calhoun, Yu Ping Wang", "title": "Causality based Feature Fusion for Brain Neuro-Developmental Analysis", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human brain development is a complex and dynamic process that is affected by\nseveral factors such as genetics, sex hormones, and environmental changes. A\nnumber of recent studies on brain development have examined functional\nconnectivity (FC) defined by the temporal correlation between time series of\ndifferent brain regions. We propose to add the directional flow of information\nduring brain maturation. To do so, we extract effective connectivity (EC)\nthrough Granger causality (GC) for two different groups of subjects, i.e.,\nchildren and young adults. The motivation is that the inclusion of causal\ninteraction may further discriminate brain connections between two age groups\nand help to discover new connections between brain regions. The contributions\nof this study are threefold. First, there has been a lack of attention to\nEC-based feature extraction in the context of brain development. To this end,\nwe propose a new kernel-based GC (KGC) method to learn nonlinearity of complex\nbrain network, where a reduced Sine hyperbolic polynomial (RSP) neural network\nwas used as our proposed learner. Second, we used causality values as the\nweight for the directional connectivity between brain regions. Our findings\nindicated that the strength of connections was significantly higher in young\nadults relative to children. In addition, our new EC-based feature outperformed\nFC-based analysis from Philadelphia neurocohort (PNC) study with better\ndiscrimination of the different age groups. Moreover, the fusion of these two\nsets of features (FC + EC) improved brain age prediction accuracy by more than\n4%, indicating that they should be used together for brain development studies.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jan 2020 17:38:42 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Kassani", "Peyman Hosseinzadeh", ""], ["Xiao", "Li", ""], ["Zhang", "Gemeng", ""], ["Stephen", "Julia M.", ""], ["Wilson", "Tony W.", ""], ["Calhoun", "Vince D.", ""], ["Wang", "Yu Ping", ""]]}, {"id": "2001.08332", "submitter": "Megan Morrison", "authors": "Megan Morrison, Charles Fieseler, and J. Nathan Kutz", "title": "Nonlinear control in the nematode C. elegans", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS physics.bio-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent whole-brain calcium imaging recordings of the nematode C. elegans have\ndemonstrated that neural activity is dominated by dynamics on a low-dimensional\nmanifold that can be clustered according to behavioral states. Despite progress\nin modeling the dynamics with linear or locally linear models, it remains\nunclear how a single network of neurons can produce the observed features. In\nparticular, there are multiple clusters, or fixed points, observed in the data\nwhich cannot be characterized by a single linear model. We propose a nonlinear\ncontrol model which is global and parameterized by only four free parameters\nthat match the features displayed by the low-dimensional C. elegans neural\nactivity. In addition to reproducing the average probability distribution of\nthe data, long and short time-scale changes in transition statistics can be\ncharacterized via changes in a single parameter. Some of these macro-scale\ntransitions have experimental correlates to single neuro-modulators that seem\nto act as biological controls, allowing this model to generate testable\nhypotheses about the effect of these neuro-modulators on the global dynamics.\nThe theory provides an elegant characterization of the neuron population\ndynamics in C. elegans. Moreover, the mathematical structure of the nonlinear\ncontrol framework provides a paradigm that can be generalized to more complex\nsystems with an arbitrary number of behavioral states.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 01:35:14 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 20:51:16 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Morrison", "Megan", ""], ["Fieseler", "Charles", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "2001.08346", "submitter": "Charles Fieseler", "authors": "Charles Fieseler, Manuel Zimmer, J. Nathan Kutz", "title": "Unsupervised learning of control signals and their encodings in\n  $\\textit{C. elegans}$ whole-brain recordings", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent whole brain imaging experiments on $\\textit{C. elegans}$ has revealed\nthat the neural population dynamics encode motor commands and stereotyped\ntransitions between behaviors on low dimensional manifolds. Efforts to\ncharacterize the dynamics on this manifold have used piecewise linear models to\ndescribe the entire state space, but it is unknown how a single, global\ndynamical model can generate the observed dynamics. Here, we propose a control\nframework to achieve such a global model of the dynamics, whereby underlying\nlinear dynamics is actuated by sparse control signals. This method learns the\ncontrol signals in an unsupervised way from data, then uses $\\textit{ Dynamic\nMode Decomposition with control}$ (DMDc) to create the first global, linear\ndynamical system that can reconstruct whole-brain imaging data. These control\nsignals are shown to be implicated in transitions between behaviors. In\naddition, we analyze the time-delay encoding of these control signals, showing\nthat these transitions can be predicted from neurons previously implicated in\nbehavioral transitions, but also additional neurons previously unidentified.\nMoreover, our decomposition method allows one to understand the observed\nnonlinear global dynamics instead as linear dynamics with control. The proposed\nmathematical framework is generic and can be generalized to other neurosensory\nsystems, potentially revealing transitions and their encodings in a completely\nunsupervised way.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 02:37:34 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 19:50:02 GMT"}, {"version": "v3", "created": "Mon, 13 Apr 2020 21:33:46 GMT"}], "update_date": "2020-04-15", "authors_parsed": [["Fieseler", "Charles", ""], ["Zimmer", "Manuel", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "2001.08349", "submitter": "Satpreet Harcharan Singh", "authors": "Satpreet H. Singh, Steven M. Peterson, Rajesh P. N. Rao, Bingni W.\n  Brunton", "title": "Investigating naturalistic hand movements by behavior mining in\n  long-term video and neural recordings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent technological advances in brain recording and artificial intelligence\nare propelling a new paradigm in neuroscience beyond the traditional controlled\nexperiment. Rather than focusing on cued, repeated trials, naturalistic\nneuroscience studies neural processes underlying spontaneous behaviors\nperformed in unconstrained settings. However, analyzing such unstructured data\nlacking a priori experimental design remains a significant challenge,\nespecially when the data is multi-modal and long-term. Here we describe an\nautomated approach for analyzing simultaneously recorded long-term,\nnaturalistic electrocorticography (ECoG) and naturalistic behavior video data.\nWe take a behavior-first approach to analyzing the long-term recordings. Using\na combination of computer vision, discrete latent-variable modeling, and string\npattern-matching on the behavioral video data, we find and annotate spontaneous\nhuman upper-limb movement events. We show results from our approach applied to\ndata collected for 12 human subjects over 7--9 days for each subject. Our\npipeline discovers and annotates over 40,000 instances of naturalistic human\nupper-limb movement events in the behavioral videos. Analysis of the\nsimultaneously recorded brain data reveals neural signatures of movement that\ncorroborate prior findings from traditional controlled experiments. We also\nprototype a decoder for a movement initiation detection task to demonstrate the\nefficacy of our pipeline as a source of training data for brain-computer\ninterfacing applications. Our work addresses the unique data analysis\nchallenges in studying naturalistic human behaviors, and contributes methods\nthat may generalize to other neural recording modalities beyond ECoG. We\npublicly release our curated dataset, providing a resource to study\nnaturalistic neural and behavioral variability at a scale not previously\navailable.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 02:41:35 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2020 22:52:49 GMT"}], "update_date": "2020-06-23", "authors_parsed": [["Singh", "Satpreet H.", ""], ["Peterson", "Steven M.", ""], ["Rao", "Rajesh P. N.", ""], ["Brunton", "Bingni W.", ""]]}, {"id": "2001.08369", "submitter": "Takahiro Ezaki", "authors": "Takahiro Ezaki, Yu Himeno, Takamitsu Watanabe, Naoki Masuda", "title": "Modeling state-transition dynamics in brain signals by memoryless\n  Gaussian mixtures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have proposed that one can summarize brain activity into\ndynamics among a relatively small number of hidden states and that such an\napproach is a promising tool for revealing brain function. Hidden Markov models\n(HMMs) are a prevalent approach to inferring such neural dynamics among\ndiscrete brain states. However, the validity of modeling neural time series\ndata with HMMs has not been established. Here, to address this situation and\nexamine the performance of the HMM, we compare the model with the Gaussian\nmixture model (GMM), which is a statistically simpler model than the HMM with\nno assumption of Markovianity, by applying both models to synthetic and\nempirical resting-state functional magnetic resonance imaging (fMRI) data. We\nfind that the GMM allows us to interpret the sequence of the estimated hidden\nstates as a time series obeying some patterns and is often better than HMMs in\nterms of the accuracy and consistency of estimating the time course of the\nhidden state. These results suggest that GMMs can be a model of first choice\nfor investigating hidden-state dynamics in data even if the time series is\napparently not memoryless.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 04:56:53 GMT"}, {"version": "v2", "created": "Fri, 24 Apr 2020 08:31:43 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Ezaki", "Takahiro", ""], ["Himeno", "Yu", ""], ["Watanabe", "Takamitsu", ""], ["Masuda", "Naoki", ""]]}, {"id": "2001.08508", "submitter": "Noam Shemesh", "authors": "Daniel Nunes, Rita Gil, Noam Shemesh", "title": "A rapid-onset diffusion functional MRI signal reflects\n  neuromorphological coupling dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional Magnetic Resonance Imaging (fMRI) has transformed our\nunderstanding of brain function in-vivo. However, the neurovascular coupling\nmechanisms underlying fMRI are somewhat \"distant\" from neural activity.\nInterestingly, evidence from Intrinsic Optical Signals (IOSs) indicates that\nneural activity is also coupled to (sub)cellular morphological modulations.\nDiffusion-weighted functional MRI (dfMRI) experiments have been previously\nproposed to probe such neuromorphological couplings, but the underlying\nmechanisms have remained highly contested. Here, we provide the first direct\nlink between in vivo ultrafast dfMRI signals upon rat forepaw stimulation and\nIOSs in acute slices stimulated optogenetically. We reveal a hitherto\nunreported rapid onset (<100 ms) dfMRI signal which (i) agrees with fast-rising\nIOSs dynamics; (ii) evidences a punctate quantitative correspondence to the\nstimulation period; (iii) and is rather insensitive to a vascular challenge.\nOur findings suggest that neuromorphological coupling can be detected via dfMRI\nsignals, auguring well for future mapping of neural activity more directly.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 13:53:21 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Nunes", "Daniel", ""], ["Gil", "Rita", ""], ["Shemesh", "Noam", ""]]}, {"id": "2001.08805", "submitter": "Jacob George", "authors": "Jacob A. George, Sridharan Radhakrishnan, Mark R. Brinton, and Gregory\n  A. Clark", "title": "Inexpensive and Portable System for Dexterous High-Density Myoelectric\n  Control of Multiarticulate Prostheses", "comments": "IEEE EMBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiarticulate bionic arms are now capable of mimicking the endogenous\nmovements of the human hand. 3D-printing has reduced the cost of prosthetic\nhands themselves, but there is currently no low-cost alternative to dexterous\nelectromyographic (EMG) control systems. To address this need, we developed an\ninexpensive (~$675) and portable EMG control system by integrating low-cost\nmicrocontrollers with an EMG acquisition device. We validated signal\nacquisition by comparing the signal-to-noise ratio (SNR) of our system with\nthat of a high-end research-grade system. We also demonstrate the ability to\nuse the low-cost control system for proportional and independent control of\nvarious prosthetic hands in real-time. We found that the SNR of the low-cost\ncontrol system was statistically no worse than 44% of the SNR of a\nresearch-grade control system. The RMSEs of predicted hand movements (from a\nmodified Kalman filter) were typically a few percent better than, and not more\nthan 6% worse than, RMSEs of a research-grade system for up to six degrees of\nfreedom when only relatively few (six) EMG electrodes were used. However, RMSEs\nwere generally higher than RMSEs of research-grade systems that utilize\nconsiderably more (32) EMG electrodes, guiding future work towards increasing\nelectrode count. Successful instantiation of this low-cost control system\nconstitutes an important step towards the commercialization and wide-spread\navailability of dexterous bionic hands.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:03:24 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["George", "Jacob A.", ""], ["Radhakrishnan", "Sridharan", ""], ["Brinton", "Mark R.", ""], ["Clark", "Gregory A.", ""]]}, {"id": "2001.08807", "submitter": "Jacob George", "authors": "Jacob A. George, Troy N. Tully, Paul C. Colgan, and Gregory A. Clark", "title": "Bilaterally Mirrored Movements Improve the Accuracy and Precision of\n  Training Data for Supervised Learning of Neural or Myoelectric Prosthetic\n  Control", "comments": "IEEE EMBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intuitive control of prostheses relies on training algorithms to correlate\nbiological recordings to motor intent. The quality of the training dataset is\ncritical to run-time performance, but it is difficult to label hand kinematics\naccurately after the hand has been amputated. We quantified the accuracy and\nprecision of labeling hand kinematics for two different approaches: 1) assuming\na participant is perfectly mimicking predetermined motions of a prosthesis\n(mimicked training), and 2) assuming a participant is perfectly mirroring their\ncontralateral hand during identical bilateral movements (mirrored training). We\ncompared these approaches in non-amputee individuals, using an infrared camera\nto track eight different joint angles of the hands in real-time. Aggregate data\nrevealed that mimicked training does not account for biomechanical coupling or\ntemporal changes in hand posture. Mirrored training was significantly more\naccurate and precise at labeling hand kinematics. However, when training a\nmodified Kalman filter to estimate motor intent, the mimicked and mirrored\ntraining approaches were not significantly different. The results suggest that\nthe mirrored training approach creates a more faithful but more complex\ndataset. Advanced algorithms, more capable of learning the complex mirrored\ntraining dataset, may yield better run-time prosthetic control.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:06:23 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["George", "Jacob A.", ""], ["Tully", "Troy N.", ""], ["Colgan", "Paul C.", ""], ["Clark", "Gregory A.", ""]]}, {"id": "2001.08808", "submitter": "Jacob George", "authors": "Jacob A. George, Mark R. Brinton, Paul C. Colgan, Garrison K. Colvin,\n  Sliman J. Bensmaia, and Gregory A. Clark", "title": "Intensity Discriminability of Electrocutaneous and Intraneural\n  Stimulation Pulse Frequency in Intact Individuals and Amputees", "comments": "IEEE EMBC 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrical stimulation of residual nerves can be used to provide amputees\nwith intuitive sensory feedback. An important aspect of this artificial sensory\nfeedback is the ability to convey the magnitude of tactile stimuli. Using\nclassical psychophysical methods, we quantified the just-noticeable differences\nfor electrocutaneous stimulation pulse frequency in both intact participants\nand one transradial amputee. For the transradial amputee, we also quantified\nthe just-noticeable difference of intraneural microstimulation pulse frequency\nvia chronically implanted Utah Slanted Electrode Arrays. We demonstrate that\nintensity discrimination is similar across conditions: intraneural\nmicrostimulation of the residual nerves, electrocutaneous stimulation of the\nreinnervated skin on the residual limb, and electrocutaneous stimulation of\nintact hands. We also show that intensity discrimination performance is\nsignificantly better at lower pulse frequencies than at higher ones - a finding\nthat's unique to electrocutaneous and intraneural stimulation and suggests that\nsupplemental sensory cues may be present at lower pulse frequencies. These\nresults can help guide the implementation of artificial sensory feedback for\nsensorized bionic arms.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2020 21:10:03 GMT"}], "update_date": "2020-01-27", "authors_parsed": [["George", "Jacob A.", ""], ["Brinton", "Mark R.", ""], ["Colgan", "Paul C.", ""], ["Colvin", "Garrison K.", ""], ["Bensmaia", "Sliman J.", ""], ["Clark", "Gregory A.", ""]]}, {"id": "2001.09424", "submitter": "Matteo Fraschini", "authors": "Matteo Demuru and Matteo Fraschini", "title": "EEG fingerprinting: subject specific signature based on the aperiodic\n  component of power spectrum", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last few years, there has been growing interest in the effects\ninduced by individual variability on activation patterns and brain\nconnectivity. The practical implications of individual variability is of basic\nrelevance for both group level and subject level studies. The\nElectroencephalogram (EEG), still represents one of the most used recording\ntechniques to investigate a wide range of brain related features. In this work,\nwe aim to estimate the effect of individual variability on a set of very simple\nand easily interpretable features extracted from the EEG power spectra. In\nparticular, in an identification scenario, we investigated how the aperiodic\n(1/f background) component of the EEG power spectra can accurately identify\nsubjects from a large EEG dataset. The results of this study show that the\naperiodic component of the EEG signal is characterized by strong\nsubject-specific properties, that this feature is consistent across different\nexperimental conditions (eyes-open and eyes-closed) and outperforms the\ncanonically-defined frequency bands. These findings suggest that the simple\nfeatures (slope and offset) extracted from the aperiodic component of the EEG\nsignal are sensitive to individual traits and may help to characterize and make\ninferences at single subject level.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 09:04:26 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Demuru", "Matteo", ""], ["Fraschini", "Matteo", ""]]}, {"id": "2001.09600", "submitter": "Stefano Recanatesi", "authors": "Stefano Recanatesi, Ulises Pereira, Masayoshi Murakami, Zachary\n  Mainen, Luca Mazzucato", "title": "Metastable attractors explain the variable timing of stable behavioral\n  action sequences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural animal behavior displays rich lexical and temporal dynamics, even in\na stable environment. This implies that behavioral variability arises from\nsources within the brain, but the origin and mechanics of these processes\nremain largely unknown. Here, we focus on the observation that the timing of\nself-initiated actions shows large variability even when they are executed in\nstable, well-learned sequences. Could this mix of reliability and stochasticity\narise within the same circuit? We trained rats to perform a stereotyped\nsequence of self-initiated actions and recorded neural ensemble activity in\nsecondary motor cortex (M2), which is known to reflect trial-by-trial action\ntiming fluctuations. Using hidden Markov models we established a robust and\naccurate dictionary between ensemble activity patterns and actions. We then\nshowed that metastable attractors, representing activity patterns with the\nrequisite combination of reliable sequential structure and high transition\ntiming variability, could be produced by reciprocally coupling a high\ndimensional recurrent network and a low dimensional feedforward one.\nTransitions between attractors were generated by correlated variability arising\nfrom the feedback loop between the two networks. This mechanism predicted a\nspecific structure of low-dimensional noise correlations that were empirically\nverified in M2 ensemble dynamics. This work suggests a robust network motif as\na novel mechanism to support critical aspects of animal behavior and\nestablishes a framework for investigating its circuit origins via correlated\nvariability.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 06:29:55 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Recanatesi", "Stefano", ""], ["Pereira", "Ulises", ""], ["Murakami", "Masayoshi", ""], ["Mainen", "Zachary", ""], ["Mazzucato", "Luca", ""]]}, {"id": "2001.09625", "submitter": "Mathieu Desroches", "authors": "Mathieu Desroches, John Rinzel and Serafim Rodrigues", "title": "Towards a new classification of bursting patterns: review & extensions", "comments": "29 pages, 14 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mathematical classification of complex bursting oscillations in\nmultiscale excitable systems, seen for example in physics and neuroscience, has\nbeen the subject of active enquiry since the early 1980s. This classification\nproblem is fundamental as it also establishes analytical and numerical\nfoundations for studying complex temporal behaviours in multiple timescale\nmodels. This manuscript begins by reviewing the seminal works of Rinzel and\nIzhikevich in classifying bursting patterns of excitable cell models. Moreover,\nwe recall an alternative, yet complementary, mathematical classification\napproach by Golubitsky, which together with the Rinzel-Izhikevich proposals\nprovide the state-of-the-art foundations to the classification problem.\nUnexpectedly, while keeping within the Rinzel-Izhikevich framework, we find\nnovel cases of bursting mechanisms not considered before. Moving beyond the\nstate-of-the-art, we identify novel bursting mechanisms that fall outside the\ncurrent classifications. This leads us towards a new classification, which\nrequires the analysis of both the fast and the slow subsystems of an underlying\nslow-fast model. This new classification allows the dynamical dissection of a\nlarger class of bursters. To substantiate this, we add a new class of bursters\nwith at least two slow variables, which we denote folded-node bursters, to\nconvey the idea that the bursts are initiated or annihilated via a folded-node\nsingularity. In fact, there are two main families of folded-node bursters,\ndepending upon the phase of the bursting cycle during which folded-node\ndynamics occurs. If it occurs during the silent phase, we obtain the classical\nfolded-node bursting (or simply folded-node bursting). If it occurs during the\nactive phase, we have cyclic folded-node bursting. We classify both families\nand give examples of minimal systems displaying these novel types of bursting\nbehaviour.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 08:32:48 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Desroches", "Mathieu", ""], ["Rinzel", "John", ""], ["Rodrigues", "Serafim", ""]]}, {"id": "2001.09641", "submitter": "Atsushi Masumori", "authors": "Atsushi Masumori, Lana Sinapayen, Norihiro Maruyama, Takeshi Mita,\n  Douglas Bakkum, Urs Frey, Hirokazu Takahashi, and Takashi Ikegami", "title": "Neural Autopoiesis: Organizing Self-Boundary by Stimulus Avoidance in\n  Biological and Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Living organisms must actively maintain themselves in order to continue\nexisting. Autopoiesis is a key concept in the study of living organisms, where\nthe boundaries of the organism is not static by dynamically regulated by the\nsystem itself. To study the autonomous regulation of self-boundary, we focus on\nneural homeodynamic responses to environmental changes using both biological\nand artificial neural networks. Previous studies showed that embodied cultured\nneural networks and spiking neural networks with spike-timing dependent\nplasticity (STDP) learn an action as they avoid stimulation from outside. In\nthis paper, as a result of our experiments using embodied cultured neurons, we\nfind that there is also a second property allowing the network to avoid\nstimulation: if the agent cannot learn an action to avoid the external stimuli,\nit tends to decrease the stimulus-evoked spikes, as if to ignore the\nuncontrollable-input. We also show such a behavior is reproduced by spiking\nneural networks with asymmetric STDP. We consider that these properties are\nregarded as autonomous regulation of self and non-self for the network, in\nwhich a controllable-neuron is regarded as self, and an uncontrollable-neuron\nis regarded as non-self. Finally, we introduce neural autopoiesis by proposing\nthe principle of stimulus avoidance.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 09:27:50 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Masumori", "Atsushi", ""], ["Sinapayen", "Lana", ""], ["Maruyama", "Norihiro", ""], ["Mita", "Takeshi", ""], ["Bakkum", "Douglas", ""], ["Frey", "Urs", ""], ["Takahashi", "Hirokazu", ""], ["Ikegami", "Takashi", ""]]}, {"id": "2001.09857", "submitter": "Ileana Jelescu", "authors": "Yujian Diao, Ting Yin, Rolf Gruetter, Ileana O. Jelescu", "title": "An optimized pipeline for functional connectivity analysis in the rat\n  brain", "comments": "25 pages, 11 figures", "journal-ref": null, "doi": "10.3389/fnins.2021.602170", "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Resting state functional MRI (rs-fMRI) is a widespread and powerful tool for\ninvestigating functional connectivity and brain disorders. However, functional\nconnectivity analysis can be seriously affected by random and structured noise\nfrom non-neural sources such as physiology. Thus, it is essential to first\nreduce thermal noise and then correctly identify and remove non-neural\nartefacts from rs-fMRI signals through optimized data processing methods.\nHowever, existing tools that correct for these effects have been developed for\nhuman brain and are not readily transposable to rat data. Therefore, the aim of\nthe present study was to establish a data processing pipeline that can robustly\nremove random and structured noise from rat rs-fMRI data. It includes a novel\ndenoising approach based on the Marchenko-Pastur Principle Component Analysis\n(MP-PCA) method, FMRIB's ICA-based Xnoiseifier (FIX) for automatic artefact\nclassification and cleaning, and global signal regression. Our results show\nthat: I) MP-PCA denoising substantially improves the temporal signal-to-noise\nratio; II) the pre-trained FIX classifier achieves a high accuracy in artefact\nclassification; III) both artefact cleaning and global signal regression are\nessential steps in minimizing the within-group variability in control animals\nand identifying functional connectivity changes in a rat model of sporadic\nAlzheimer's disease, as compared to controls.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 15:23:56 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 10:49:59 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Diao", "Yujian", ""], ["Yin", "Ting", ""], ["Gruetter", "Rolf", ""], ["Jelescu", "Ileana O.", ""]]}, {"id": "2001.09928", "submitter": "Angel Caputi", "authors": "Alejo Rodr\\'iguez-Catt\\'aneo, Ana Carolina Pereira, Pedro Aguilera,\n  Angel Caputi", "title": "Unitary recordings in freely-moving pulse weakly electric fish suggest\n  spike timing encoding of electrosensory signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unitary recordings in freely-moving pulse weakly electric fish suggest spike\ntiming encoding of electrosensory signals\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2020 17:35:59 GMT"}], "update_date": "2020-01-28", "authors_parsed": [["Rodr\u00edguez-Catt\u00e1neo", "Alejo", ""], ["Pereira", "Ana Carolina", ""], ["Aguilera", "Pedro", ""], ["Caputi", "Angel", ""]]}, {"id": "2001.10414", "submitter": "Marcus Kaiser", "authors": "Frances Hutchings, Christopher Thornton, Chencheng Zhang, Yujiang\n  Wang, Marcus Kaiser", "title": "Predicting the Impact of Electric Field Stimulation in a Detailed\n  Computational Model of Cortical Tissue", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurostimulation using weak electric fields has generated excitement in\nrecent years due to its potential as a medical intervention. However, study of\nthis stimulation modality has been hampered by inconsistent results and large\nvariability within and between studies. In order to begin addressing this\nvariability we need to properly characterise the impact of the current on the\nunderlying neuron populations. To develop and test a computational model\ncapable of capturing the impact of electric field stimulation on networks of\nneurons. We construct a cortical tissue model with distinct layers and explicit\nneuron morphologies. We then apply a model of electrical stimulation and carry\nout multiple test case simulations. The cortical slice model is compared to\nexperimental literature and shown to capture the main features of the\nelectrophysiological response to stimulation. Namely, the model showed 1) a\nsimilar level of depolarisation in individual pyramidal neurons, 2)\nacceleration of intrinsic oscillations, and 3) retention of the spatial profile\nof oscillations in different layers. We then apply alternative electric fields\nto demonstrate how the model can capture differences in neuronal responses to\nthe electric field. We demonstrate that the tissue response is dependent on\nlayer depth, the angle of the apical dendrite relative to the field, and\nstimulation strength. We present publicly available computational modelling\nsoftware that predicts the neuron network population response to electric field\nstimulation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 15:37:03 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Hutchings", "Frances", ""], ["Thornton", "Christopher", ""], ["Zhang", "Chencheng", ""], ["Wang", "Yujiang", ""], ["Kaiser", "Marcus", ""]]}, {"id": "2001.10437", "submitter": "Carole Aime", "authors": "Nicolas Debons, Dounia Dems (LCMCP-MATBIO), Christophe H\\'elary,\n  Sylvain Le Grill, Lise Picaut, Flore Renaud (LGBC), Nicolas Delsuc (UPMC),\n  Marie-Claire Schanne-Klein (LOB), Thibaud Coradin (MATBIO), Carole Aim\\'e\n  (LCMCP, PASTEUR)", "title": "Differentiation of neural-type cells on multi-scale ordered\n  collagen-silica bionanocomposites", "comments": null, "journal-ref": "Biomaterials Science, Royal Society of Chemistry (RSC), 2020", "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cells respond to biophysical and biochemical signals. We developed a\ncomposite filament from collagen and silica particles modified to interact with\ncollagen and/or present a laminin epitope (IKVAV) crucial for cell-matrix\nadhesion and signal transduction. This combines scaffolding and signaling and\nshows that local tuning of collagen organization enhances cell differentiation.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 16:17:16 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Debons", "Nicolas", "", "LCMCP-MATBIO"], ["Dems", "Dounia", "", "LCMCP-MATBIO"], ["H\u00e9lary", "Christophe", "", "LGBC"], ["Grill", "Sylvain Le", "", "LGBC"], ["Picaut", "Lise", "", "LGBC"], ["Renaud", "Flore", "", "LGBC"], ["Delsuc", "Nicolas", "", "UPMC"], ["Schanne-Klein", "Marie-Claire", "", "LOB"], ["Coradin", "Thibaud", "", "MATBIO"], ["Aim\u00e9", "Carole", "", "LCMCP, PASTEUR"]]}, {"id": "2001.10535", "submitter": "Jinsong Meng", "authors": "Jinsong Meng", "title": "Bridging the Gap Between Consciousness and Matter: Recurrent Out-of-Body\n  Projection of Visual Awareness Revealed by the Law of Non-Identity", "comments": "20 pages, 9 figures, and 1 table. Comments: 21 pages, 9 figures, and\n  1 table: typos corrected, references added, a figure moved from the\n  supplementary part to the main text, typesetting changed from double columns\n  to one column. Comments: 28 pages, 10 figures, and 1 table: style changed to\n  APA, title changed, typos corrected, references added, a figure added", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Consciousness is an explicit outcome of brain activity. However, the link\nbetween consciousness and the material world remains to be explored. We applied\na new logic tool, the non-identity law, to the analysis of the visual dynamics\nrelated to the naturalistic observation of a night-shot still life. We show\nthat visual awareness possesses a postponed, recurrent out-of-body projection\npathway and that the out-of-body projection is superimposed onto the original,\nwhich is reciprocally verified by vision and touch. This suggests that the\nvisual system instinctually not only represents the subjective image\n(brain-generated imagery) but also projects the image back onto the original or\nto a specific place according to the cues of the manipulated afferent messenger\nlight signaling pathway. This finding provides a foundation for understanding\nthe subjectivity and intentionality of consciousness from the perspective of\nvisual awareness and the isomorphic relations between an unknowable original,\nprivate experience, and shareable expression. The result paves the way for\nscientific research on consciousness and facilitates the integration of\nhumanities and natural science.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 18:20:37 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2020 18:55:10 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 14:35:15 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Meng", "Jinsong", ""]]}, {"id": "2001.10605", "submitter": "Yang Chu", "authors": "Yang Chu, Wayne Luk, Dan Goodman", "title": "Learning Absolute Sound Source Localisation With Limited Supervisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE eess.AS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate auditory space map can be learned from auditory experience, for\nexample during development or in response to altered auditory cues such as a\nmodified pinna. We studied neural network models that learn to localise a\nsingle sound source in the horizontal plane using binaural cues based on\nlimited supervisions. These supervisions can be unreliable or sparse in real\nlife. First, a simple model that has unreliable estimation of the sound source\nlocation is built, in order to simulate the unreliable auditory orienting\nresponse of newborns. It is used as a Teacher that acts as a source of\nunreliable supervisions. Then we show that it is possible to learn a continuous\nauditory space map based only on noisy left or right feedbacks from the\nTeacher. Furthermore, reinforcement rewards from the environment are used as a\nsource of sparse supervision. By combining the unreliable innate response and\nthe sparse reinforcement rewards, an accurate auditory space map, which is hard\nto be achieved by either one of these two kind of supervisions, can eventually\nbe learned. Our results show that the auditory space mapping can be calibrated\neven without explicit supervision. Moreover, this study implies a possibly more\ngeneral neural mechanism where multiple sub-modules can be coordinated to\nfacilitate each other's learning process under limited supervisions.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jan 2020 21:59:01 GMT"}], "update_date": "2020-01-30", "authors_parsed": [["Chu", "Yang", ""], ["Luk", "Wayne", ""], ["Goodman", "Dan", ""]]}, {"id": "2001.10696", "submitter": "Mingyuan Meng", "authors": "Mingyuan Meng, Xingyu Yang, Shanlin Xiao, Zhiyi Yu", "title": "Spiking Inception Module for Multi-layer Unsupervised Spiking Neural\n  Networks", "comments": "Published at the 2020 International Joint Conference on Neural\n  Networks (IJCNN); Extended from arXiv:2001.01680", "journal-ref": "2020 International Joint Conference on Neural Networks (IJCNN),\n  Glasgow, United Kingdom, 2020, pp. 1-8", "doi": "10.1109/IJCNN48605.2020.9207161", "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Spiking Neural Network (SNN), as a brain-inspired approach, is attracting\nattention due to its potential to produce ultra-high-energy-efficient hardware.\nCompetitive learning based on Spike-Timing-Dependent Plasticity (STDP) is a\npopular method to train an unsupervised SNN. However, previous unsupervised\nSNNs trained through this method are limited to a shallow network with only one\nlearnable layer and cannot achieve satisfactory results when compared with\nmulti-layer SNNs. In this paper, we eased this limitation by: 1)We proposed a\nSpiking Inception (Sp-Inception) module, inspired by the Inception module in\nthe Artificial Neural Network (ANN) literature. This module is trained through\nSTDP-based competitive learning and outperforms the baseline modules on\nlearning capability, learning efficiency, and robustness. 2)We proposed a\nPooling-Reshape-Activate (PRA) layer to make the Sp-Inception module stackable.\n3)We stacked multiple Sp-Inception modules to construct multi-layer SNNs. Our\nalgorithm outperforms the baseline algorithms on the hand-written digit\nclassification task, and reaches state-of-the-art results on the MNIST dataset\namong the existing unsupervised SNNs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 05:40:29 GMT"}, {"version": "v2", "created": "Fri, 14 Feb 2020 14:27:10 GMT"}, {"version": "v3", "created": "Mon, 11 May 2020 16:04:17 GMT"}, {"version": "v4", "created": "Fri, 5 Jun 2020 13:37:10 GMT"}, {"version": "v5", "created": "Mon, 28 Sep 2020 20:59:08 GMT"}], "update_date": "2020-10-20", "authors_parsed": [["Meng", "Mingyuan", ""], ["Yang", "Xingyu", ""], ["Xiao", "Shanlin", ""], ["Yu", "Zhiyi", ""]]}, {"id": "2001.11080", "submitter": "Pedro Carelli", "authors": "Nastaran Lotfi, Antonio J. Fontenele, Tha\\'is Feliciano, Leandro A. A.\n  Aguiar, Nivaldo A. P. de Vasconcelos, Carina Soares-Cunha, B\\'arbara Coimbra,\n  Ana Jo\\~ao Rodrigues, Nuno Sousa, Mauro Copelli, Pedro V. Carelli", "title": "Signatures of brain criticality unveiled by maximum entropy analysis\n  across cortical states", "comments": null, "journal-ref": "Phys. Rev. E 102, 012408 (2020)", "doi": "10.1103/PhysRevE.102.012408", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been reported that statistical signatures of brain\ncriticality, obtained from distributions of neuronal avalanches, can depend on\nthe cortical state. We revisit these claims with a completely different and\nindependent approach, employing a maximum entropy model to test whether\nsignatures of criticality appear in urethane-anesthetized rats. To account for\nthe spontaneous variation of cortical state, we parse the time series and\nperform the maximum entropy analysis as a function of the variability of the\npopulation spiking activity. To compare data sets with different number of\nneurons, we define a normalized distance to criticality that takes into account\nthe peak and width of the specific heat curve. We found an universal collapse\nof the normalized distance to criticality dependence on the cortical state on\nan animal by animal basis. This indicates a universal dynamics and a critical\npoint at an intermediate value of spiking variability.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2020 20:24:12 GMT"}], "update_date": "2020-08-05", "authors_parsed": [["Lotfi", "Nastaran", ""], ["Fontenele", "Antonio J.", ""], ["Feliciano", "Tha\u00eds", ""], ["Aguiar", "Leandro A. A.", ""], ["de Vasconcelos", "Nivaldo A. P.", ""], ["Soares-Cunha", "Carina", ""], ["Coimbra", "B\u00e1rbara", ""], ["Rodrigues", "Ana Jo\u00e3o", ""], ["Sousa", "Nuno", ""], ["Copelli", "Mauro", ""], ["Carelli", "Pedro V.", ""]]}, {"id": "2001.11432", "submitter": "Lou Zonca", "authors": "Lou Zonca and David Holcman", "title": "Modeling bursting in neuronal networks using facilitation-depression and\n  afterhyperpolarization", "comments": "8 figs", "journal-ref": "Communications in Nonlinear Science and Numerical Simulation\n  Volume 94, March 2021, 105555", "doi": "10.1016/j.cnsns.2020.105555", "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the absence of inhibition, excitatory neuronal networks can alternate\nbetween bursts and interburst intervals (IBI), with heterogeneous length\ndistributions. As this dynamic remains unclear, especially the durations of\neach epoch, we develop here a bursting model based on synaptic depression and\nfacilitation that also accounts for afterhyperpolarization (AHP), which is a\nkey component of IBI. The framework is a novel stochastic three dimensional\ndynamical system perturbed by noise: numerical simulations can reproduce a\nsuccession of bursts and interbursts. Each phase corresponds to an exploration\nof a fraction of the phase-space, which contains three critical points (one\nattractor and two saddles) separated by a two-dimensional stable manifold\n$\\Sigma$. We show here that bursting is defined by long deterministic\nexcursions away from the attractor, while IBI corresponds to escape induced by\nrandom fluctuations. We show that the variability in the burst durations,\ndepends on the distribution of exit points located on $\\Sigma$ that we compute\nusing WKB and the method of characteristics. Finally, to better characterize\nthe role of several parameters such as the network connectivity or the AHP time\nscale, we compute analytically the mean burst and AHP durations in a linear\napproximation. To conclude the distribution of bursting and IBI could result\nfrom synaptic dynamics modulated by AHP.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 16:24:23 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2020 19:51:48 GMT"}], "update_date": "2020-12-17", "authors_parsed": [["Zonca", "Lou", ""], ["Holcman", "David", ""]]}, {"id": "2001.11502", "submitter": "Noslen Hernandez", "authors": "Noslen Hern\\'andez, Aline Duarte, Guilherme Ost, Ricardo Fraiman,\n  Antonio Galves and Claudia D. Vargas", "title": "Retrieving the structure of probabilistic sequences of auditory stimuli\n  from EEG data", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using a new probabilistic approach we model the relationship between\nsequences of auditory stimuli generated by stochastic chains and the\nelectroencephalographic (EEG) data acquired while 19 participants were exposed\nto those stimuli. The structure of the chains generating the stimuli are\ncharacterized by rooted and labeled trees whose leaves, henceforth called\ncontexts, represent the sequences of past stimuli governing the choice of the\nnext stimulus. A classical conjecture claims that the brain assigns\nprobabilistic models to samples of stimuli. If this is true, then the context\ntree generating the sequence of stimuli should be encoded in the brain\nactivity. Using an innovative statistical procedure we show that this context\ntree can effectively be extracted from the EEG data, thus giving support to the\nclassical conjecture.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 18:52:35 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2020 00:15:57 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Hern\u00e1ndez", "Noslen", ""], ["Duarte", "Aline", ""], ["Ost", "Guilherme", ""], ["Fraiman", "Ricardo", ""], ["Galves", "Antonio", ""], ["Vargas", "Claudia D.", ""]]}, {"id": "2001.11582", "submitter": "Jeff Mohl", "authors": "Jeff T. Mohl, Valeria C. Caruso, Surya T. Tokdar, Jennifer M. Groh", "title": "Sensitivity and specificity of a Bayesian single trial analysis for time\n  varying neural signals", "comments": "Accepted for publication in Neurons, Behavior, Data analysis, and\n  Theory", "journal-ref": "Neurons, Behavior, Data Analysis, and Theory, 2020", "doi": "10.1101/690958", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We recently reported the existence of fluctuations in neural signals that may\npermit neurons to code multiple simultaneous stimuli sequentially across time.\nThis required deploying a novel statistical approach to permit investigation of\nneural activity at the scale of individual trials. Here we present tests using\nsynthetic data to assess the sensitivity and specificity of this analysis. We\nfabricated datasets to match each of several potential response patterns\nderived from single-stimulus response distributions. In particular, we\nsimulated dual stimulus trial spike counts that reflected fluctuating mixtures\nof the single stimulus spike counts, stable intermediate averages, single\nstimulus winner-take-all, or response distributions that were outside the range\ndefined by the single stimulus responses (such as summation or suppression). We\nthen assessed how well the analysis recovered the correct response pattern as a\nfunction of the number of simulated trials and the difference between the\nsimulated responses to each \"stimulus\" alone. We found excellent recovery of\nthe mixture, intermediate, and outside categories (>97% percent correct), and\ngood recovery of the single/winner-take-all category (>90% correct) when the\nnumber of trials was >20 and the single-stimulus response rates were 50Hz and\n20Hz respectively. Both larger numbers of trials and greater separation between\nthe single stimulus firing rates improved categorization accuracy. These\nresults provide a benchmark, and guidelines for data collection, for use of\nthis method to investigate coding of multiple items at the individual-trial\ntime scale.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jan 2020 21:59:06 GMT"}], "update_date": "2020-02-03", "authors_parsed": [["Mohl", "Jeff T.", ""], ["Caruso", "Valeria C.", ""], ["Tokdar", "Surya T.", ""], ["Groh", "Jennifer M.", ""]]}, {"id": "2001.11761", "submitter": "Milad Mozafari", "authors": "Milad Mozafari, Leila Reddy, Rufin VanRullen", "title": "Reconstructing Natural Scenes from fMRI Patterns using BigBiGAN", "comments": "Accepted to IEEE IJCNN2020", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9206960", "report-no": null, "categories": "cs.CV cs.HC eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decoding and reconstructing images from brain imaging data is a research area\nof high interest. Recent progress in deep generative neural networks has\nintroduced new opportunities to tackle this problem. Here, we employ a recently\nproposed large-scale bi-directional generative adversarial network, called\nBigBiGAN, to decode and reconstruct natural scenes from fMRI patterns. BigBiGAN\nconverts images into a 120-dimensional latent space which encodes class and\nattribute information together, and can also reconstruct images based on their\nlatent vectors. We computed a linear mapping between fMRI data, acquired over\nimages from 150 different categories of ImageNet, and their corresponding\nBigBiGAN latent vectors. Then, we applied this mapping to the fMRI activity\npatterns obtained from 50 new test images from 50 unseen categories in order to\nretrieve their latent vectors, and reconstruct the corresponding images.\nPairwise image decoding from the predicted latent vectors was highly accurate\n(84%). Moreover, qualitative and quantitative assessments revealed that the\nresulting image reconstructions were visually plausible, successfully captured\nmany attributes of the original images, and had high perceptual similarity with\nthe original content. This method establishes a new state-of-the-art for\nfMRI-based natural image reconstruction, and can be flexibly updated to take\ninto account any future improvements in generative models of natural scene\nimages.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2020 10:46:59 GMT"}, {"version": "v2", "created": "Sun, 17 May 2020 12:12:57 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 20:15:46 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["Mozafari", "Milad", ""], ["Reddy", "Leila", ""], ["VanRullen", "Rufin", ""]]}, {"id": "2001.11825", "submitter": "Alexandros Arvanitakis", "authors": "A.D. Arvanitakis", "title": "Recursion and evolution: Part I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.LG math.LO q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A self-editing algorithm is one that edits its program. The present paper\nstudies evolution of self-editing algorithms that undergo some form of natural\nor artificial selection. We show that such an algorithm may be simply\nprogrammed, by a procedure we call diagonalization, so as to use selection as\nan information, to adjust accordingly its genetic behavior. We provide a lot of\nexamples regarding this principle, including ones that diagonalization is used\nto evolve its own mechanism. (This last one being possible due to self-editing\nproperty and to the general nature of this procedure).\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 11:04:52 GMT"}, {"version": "v2", "created": "Fri, 10 Apr 2020 07:21:56 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Arvanitakis", "A. D.", ""]]}]