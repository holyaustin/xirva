[{"id": "2003.00070", "submitter": "Jacob George", "authors": "Jacob A. George, Anna Neibling, Michael D. Paskett, Gregory A. Clark", "title": "Inexpensive surface electromyography sleeve with consistent electrode\n  placement enables dexterous and stable prosthetic control through deep\n  learning", "comments": "MEC2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dexterity of conventional myoelectric prostheses is limited in part by\nthe small datasets used to train the control algorithms. Variations in surface\nelectrode positioning make it difficult to collect consistent data and to\nestimate motor intent reliably over time. To address these challenges, we\ndeveloped an inexpensive, easy-to-don sleeve that can record robust and\nrepeatable surface electromyography from 32 embedded monopolar electrodes.\nEmbedded grommets are used to consistently align the sleeve with natural skin\nmarkings (e.g., moles, freckles, scars). The sleeve can be manufactured in a\nfew hours for less than $60. Data from seven intact participants show the\nsleeve provides a signal-to-noise ratio of 14, a don-time under 11 seconds, and\nsub-centimeter precision for electrode placement. Furthermore, in a case study\nwith one intact participant, we use the sleeve to demonstrate that neural\nnetworks can provide simultaneous and proportional control of six degrees of\nfreedom, even 263 days after initial algorithm training. We also highlight that\nconsistent recordings, accumulated over time to establish a large dataset,\nsignificantly improve dexterity. These results suggest that deep learning with\na 74-layer neural network can substantially improve the dexterity and stability\nof myoelectric prosthetic control, and that deep-learning techniques can be\nreadily instantiated and further validated through inexpensive sleeves/sockets\nwith consistent recording locations.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 21:24:19 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["George", "Jacob A.", ""], ["Neibling", "Anna", ""], ["Paskett", "Michael D.", ""], ["Clark", "Gregory A.", ""]]}, {"id": "2003.00073", "submitter": "Yufen Chen", "authors": "Yufen Chen, Amy A. Herrold, Virginia Gallagher, Brian Vesci, Jeffrey\n  Mjannes, Leanne R. McCloskey, James L. Reilly, Hans C. Breiter", "title": "Preliminary Report: Cerebral blood flow mediates the relationship\n  between progesterone and perceived stress symptoms among female club athletes\n  after mild traumatic brain injury", "comments": "27pages, 3 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Female athletes are severely understudied in the field of concussion\nresearch, despite higher prevalence for injuries and tendency to have longer\nrecovery time. Hormonal fluctuations due to normal menstrual cycle (MC) or\nhormonal contraceptive (HC) use have been shown to impact both post-injury\nsymptoms and neuroimaging measures, but have not been accounted for in\nconcussion studies. In this preliminary study, we compared arterial spin\nlabeling measured cerebral blood flow (CBF) between concussed female club\nathletes 3-10 days post injury (mTBI) and demographic, HC/MC matched controls\n(CON). We test whether CBF mediates the relationship between progesterone\nlevels in blood and post-injury symptoms, which may be evidence for\nprogesterone`s role in neuroprotection. We found a significant three-way\nrelationship between progesterone, CBF and perceived stress score (PSS) in the\nleft middle temporal gyrus. Higher progesterone was associated with lower (more\nnormative) PSS, as well as higher (more normative) CBF. CBF mediates 100% of\nthe relationship between progesterone and PSS (Sobel`s p-value=0.017). These\nfindings suggest progesterone may have a neuroprotective role after concussion\nand highlight the importance of controlling for the effects of sex hormones in\nfuture concussion studies.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 21:26:02 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Chen", "Yufen", ""], ["Herrold", "Amy A.", ""], ["Gallagher", "Virginia", ""], ["Vesci", "Brian", ""], ["Mjannes", "Jeffrey", ""], ["McCloskey", "Leanne R.", ""], ["Reilly", "James L.", ""], ["Breiter", "Hans C.", ""]]}, {"id": "2003.00783", "submitter": "Michael Munz", "authors": "Cornelia Herbert, Jan Nachtsheim, Michael Munz", "title": "Analysis of Gait-Event-related Brain Potentials During Instructed And\n  Spontaneous Treadmill Walking -- Technical Affordances and used Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the understanding of human gait and to facilitate novel\ndevelopments in gait rehabilitation, the neural correlates of human gait as\nmeasured by means of non-invasive electroencephalography (EEG) have been\ninvestigated recently. Particularly, gait-related event-related brain\npotentials (gERPs) may provide information about the functional role of\ncortical brain regions in human gait control. The purpose of this paper is to\nexplore possible experimental and technical solutions for time-sensitive\nanalysis of human gait-related ERPs during spontaneous and instructed treadmill\nwalking. A solution (HW/SW) for synchronous recording of gait- and EEG data was\ndeveloped, tested and piloted. The solution consists of a custom-made USB\nsynchronization interface, a time-synchronization module and a data merging\nmodule, allowing temporal synchronization of recording devices for\ntime-sensitive extraction of gait markers for analysis of gait-related ERPs and\nfor the training of artificial neural networks. In the present manuscript, the\nhardware and software components were tested with the following devices: A\ntreadmill with an integrated pressure plate for gait analysis (zebris FDM-T)\nand an Acticap non-wireless 32-channel EEG-system (Brain Products GmbH). The\nusability and validity of the developed solution was tested in a pilot study (n\n= 3 healthy participants, n=3 females, mean age = 22.75 years). Recorded EEG\ndata was segmented and analyzed according to the detected gait markers for the\nanalysis of gait-related ERPs. Finally, EEG periods were used to train a deep\nlearning artificial neural network as classifier of gait phases. The results\nobtained in this pilot study, although preliminary, support the feasibility of\nthe solution for the application of gait-related EEG analysis..\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 11:54:47 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Herbert", "Cornelia", ""], ["Nachtsheim", "Jan", ""], ["Munz", "Michael", ""]]}, {"id": "2003.01248", "submitter": "Haoqi Sun", "authors": "Jacob Hogan, Haoqi Sun, Luis Paixao, Mike Westmeijer, Pooja Sikka,\n  Jing Jin, Ryan Tesh, Madalena Cardoso, Sydney S. Cash, Oluwaseun Akeju,\n  Robert Thomas, M. Brandon Westover", "title": "Night-to-Night Variability of Sleep Electroencephalography-Based Brain\n  Age Measurements", "comments": "18 pages, 6 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective Brain Age Index (BAI), calculated from sleep electroencephalography\n(EEG), has been proposed as a biomarker of brain health. This study quantifies\nnight-to-night variability of BAI and establishes probability thresholds for\ninferring underlying brain pathology based on a patient's BAI.\n  Methods 86 patients with multiple nights of consecutive EEG recordings were\nselected from Epilepsy Monitoring Unit patients whose EEGs reported as being\nwithin normal limits. BAI was calculated for each 12-hour segment of patient\ndata using a previously described algorithm, and night-to-night variability in\nBAI was measured.\n  Results The within-patient night-to-night standard deviation in BAI was 7.5\nyears. Estimates of BAI derived by averaging over 2, 3, and 4 nights had\nstandard deviations of 4.7, 3.7, and 3.0 years, respectively.\n  Conclusions Averaging BAI over n nights reduces night-to-night variability of\nBAI by a factor of the square root of n, rendering BAI more suitable as a\nbiomarker of brain health at the individual level.\n  Significance With increasing ease of EEG acquisition including wearable\ntechnology, BAI has the potential to track brain health and detect deviations\nfrom normal physiologic function. In a clinical setting, BAI could be used to\nidentify patients who should undergo further investigation or monitoring.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 23:32:41 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Hogan", "Jacob", ""], ["Sun", "Haoqi", ""], ["Paixao", "Luis", ""], ["Westmeijer", "Mike", ""], ["Sikka", "Pooja", ""], ["Jin", "Jing", ""], ["Tesh", "Ryan", ""], ["Cardoso", "Madalena", ""], ["Cash", "Sydney S.", ""], ["Akeju", "Oluwaseun", ""], ["Thomas", "Robert", ""], ["Westover", "M. Brandon", ""]]}, {"id": "2003.01262", "submitter": "Matthew Leavitt", "authors": "Matthew L. Leavitt and Ari Morcos", "title": "Selectivity considered harmful: evaluating the causal impact of class\n  selectivity in DNNs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The properties of individual neurons are often analyzed in order to\nunderstand the biological and artificial neural networks in which they're\nembedded. Class selectivity-typically defined as how different a neuron's\nresponses are across different classes of stimuli or data samples-is commonly\nused for this purpose. However, it remains an open question whether it is\nnecessary and/or sufficient for deep neural networks (DNNs) to learn class\nselectivity in individual units. We investigated the causal impact of class\nselectivity on network function by directly regularizing for or against class\nselectivity. Using this regularizer to reduce class selectivity across units in\nconvolutional neural networks increased test accuracy by over 2% for ResNet18\ntrained on Tiny ImageNet. For ResNet20 trained on CIFAR10 we could reduce class\nselectivity by a factor of 2.5 with no impact on test accuracy, and reduce it\nnearly to zero with only a small ($\\sim$2%) drop in test accuracy. In contrast,\nregularizing to increase class selectivity significantly decreased test\naccuracy across all models and datasets. These results indicate that class\nselectivity in individual units is neither sufficient nor strictly necessary,\nand can even impair DNN performance. They also encourage caution when focusing\non the properties of single units as representative of the mechanisms by which\nDNNs function.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 00:22:37 GMT"}, {"version": "v2", "created": "Sat, 13 Jun 2020 00:20:47 GMT"}, {"version": "v3", "created": "Wed, 14 Oct 2020 17:31:24 GMT"}], "update_date": "2020-10-15", "authors_parsed": [["Leavitt", "Matthew L.", ""], ["Morcos", "Ari", ""]]}, {"id": "2003.01385", "submitter": "Marc de Kamps", "authors": "Hugh Osborne and Yi Ming Lai and Marc de Kamps", "title": "Models Currently Implemented in MIIND", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.comp-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This is a living document that will be updated when appropriate. MIIND [1, 2]\nis a population-level neural simulator. It is based on population density\ntechniques, just like DIPDE [3]. Contrary to DIPDE, MIIND is agnostic to the\nunderlying neuron model used in its populations so any 1, 2 or 3 dimensional\nmodel can be set up with minimal effort. The resulting populations can then be\ngrouped into large networks, e.g. the Potjans-Diesmann model [4]. The MIIND\nwebsite http://miind.sf.net contains training materials, and helps to set up\nMIIND, either by using virtual machines, a DOCKER image, or directly from\nsource code.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 08:21:58 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 11:26:24 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Osborne", "Hugh", ""], ["Lai", "Yi Ming", ""], ["de Kamps", "Marc", ""]]}, {"id": "2003.01409", "submitter": "Niceto R. Luque", "authors": "Francisco Naveros, Niceto R. Luque, Eduardo Ros, Angelo Arleo", "title": "VOR Adaptation on a Humanoid iCub Robot Using a Spiking Cerebellar Model", "comments": null, "journal-ref": null, "doi": "10.1109/TCYB.2019.2899246", "report-no": null, "categories": "q-bio.NC cs.NE cs.RO cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We embed a spiking cerebellar model within an adaptive real-time (RT) control\nloop that is able to operate a real robotic body (iCub) when performing\ndifferent vestibulo-ocular reflex (VOR) tasks. The spiking neural network\ncomputation, including event- and time-driven neural dynamics, neural activity,\nand spike-timing dependent plasticity (STDP) mechanisms, leads to a\nnondeterministic computation time caused by the neural activity volleys\nencountered during cerebellar simulation. This nondeterministic computation\ntime motivates the integration of an RT supervisor module that is able to\nensure a well-orchestrated neural computation time and robot operation.\nActually, our neurorobotic experimental setup (VOR) benefits from the\nbiological sensory motor delay between the cerebellum and the body to buffer\nthe computational overloads as well as providing flexibility in adjusting the\nneural computation time and RT operation. The RT supervisor module provides for\nincremental countermeasures that dynamically slow down or speed up the\ncerebellar simulation by either halting the simulation or disabling certain\nneural computation features (i.e., STDP mechanisms, spike propagation, and\nneural updates) to cope with the RT constraints imposed by the real robot\noperation. This neurorobotic experimental setup is applied to different\nhorizontal and vertical VOR adaptive tasks that are widely used by the\nneuroscientific community to address cerebellar functioning. We aim to\nelucidate the manner in which the combination of the cerebellar neural\nsubstrate and the distributed plasticity shapes the cerebellar neural activity\nto mediate motor adaptation. This paper underlies the need for a two-stage\nlearning process to facilitate VOR acquisition.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 09:48:15 GMT"}, {"version": "v2", "created": "Tue, 31 Mar 2020 07:26:00 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Naveros", "Francisco", ""], ["Luque", "Niceto R.", ""], ["Ros", "Eduardo", ""], ["Arleo", "Angelo", ""]]}, {"id": "2003.01445", "submitter": "Niceto R. Luque", "authors": "Francisco Naveros, Jesus A. Garrido, Angelo Arleo, Eduardo Ros, Niceto\n  R. Luque", "title": "Exploring vestibulo-ocular adaptation in a closed-loop neuro-robotic\n  experiment using STDP. A simulation study", "comments": null, "journal-ref": null, "doi": "10.1109/IROS.2018.8594019", "report-no": null, "categories": "q-bio.NC cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studying and understanding the computational primitives of our neural system\nrequires for a diverse and complementary set of techniques. In this work, we\nuse the Neuro-robotic Platform (NRP)to evaluate the vestibulo ocular cerebellar\nadaptatIon (Vestibulo-ocular reflex, VOR)mediated by two STDP mechanisms\nlocated at the cerebellar molecular layer and the vestibular nuclei\nrespectively. This simulation study adopts an experimental setup (rotatory\nVOR)widely used by neuroscientists to better understand the contribution of\ncertain specific cerebellar properties (i.e. distributed STDP, neural\nproperties, coding cerebellar topology, etc.)to r-VOR adaptation. The work\nproposes and describes an embodiment solution for which we endow a simulated\nhumanoid robot (iCub)with a spiking cerebellar model by means of the NRP, and\nwe face the humanoid to an r-VOR task. The results validate the adaptive\ncapabilities of the spiking cerebellar model (with STDP)in a perception-action\nclosed-loop (r- VOR)causing the simulated iCub robot to mimic a human behavior.\n", "versions": [{"version": "v1", "created": "Tue, 3 Mar 2020 10:55:42 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Naveros", "Francisco", ""], ["Garrido", "Jesus A.", ""], ["Arleo", "Angelo", ""], ["Ros", "Eduardo", ""], ["Luque", "Niceto R.", ""]]}, {"id": "2003.01513", "submitter": "Javier Sagastuy-Brena", "authors": "Daniel Kunin, Aran Nayebi, Javier Sagastuy-Brena, Surya Ganguli,\n  Jonathan M. Bloom, Daniel L. K. Yamins", "title": "Two Routes to Scalable Credit Assignment without Weight Symmetry", "comments": "ICML 2020 Camera Ready Version, 19 pages including supplementary\n  information, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neural plausibility of backpropagation has long been disputed, primarily\nfor its use of non-local weight transport $-$ the biologically dubious\nrequirement that one neuron instantaneously measure the synaptic weights of\nanother. Until recently, attempts to create local learning rules that avoid\nweight transport have typically failed in the large-scale learning scenarios\nwhere backpropagation shines, e.g. ImageNet categorization with deep\nconvolutional networks. Here, we investigate a recently proposed local learning\nrule that yields competitive performance with backpropagation and find that it\nis highly sensitive to metaparameter choices, requiring laborious tuning that\ndoes not transfer across network architecture. Our analysis indicates the\nunderlying mathematical reason for this instability, allowing us to identify a\nmore robust local learning rule that better transfers without metaparameter\ntuning. Nonetheless, we find a performance and stability gap between this local\nrule and backpropagation that widens with increasing model depth. We then\ninvestigate several non-local learning rules that relax the need for\ninstantaneous weight transport into a more biologically-plausible \"weight\nestimation\" process, showing that these rules match state-of-the-art\nperformance on deep networks and operate effectively in the presence of noisy\nupdates. Taken together, our results suggest two routes towards the discovery\nof neural implementations for credit assignment without weight symmetry:\nfurther improvement of local rules so that they perform consistently across\narchitectures and the identification of biological implementations for\nnon-local learning mechanisms.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 18:39:16 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2020 03:55:29 GMT"}], "update_date": "2020-06-26", "authors_parsed": [["Kunin", "Daniel", ""], ["Nayebi", "Aran", ""], ["Sagastuy-Brena", "Javier", ""], ["Ganguli", "Surya", ""], ["Bloom", "Jonathan M.", ""], ["Yamins", "Daniel L. K.", ""]]}, {"id": "2003.01541", "submitter": "Taban Eslami", "authors": "Taban Eslami, Joseph S. Raiker and Fahad Saeed", "title": "Explainable and Scalable Machine-Learning Algorithms for Detection of\n  Autism Spectrum Disorder using fMRI Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diagnosing Autism Spectrum Disorder (ASD) is a challenging problem, and is\nbased purely on behavioral descriptions of symptomology (DSM-5/ICD-10), and\nrequires informants to observe children with disorder across different settings\n(e.g. home, school). Numerous limitations (e.g., informant discrepancies, lack\nof adherence to assessment guidelines, informant biases) to current diagnostic\npractices have the potential to result in over-, under-, or misdiagnosis of the\ndisorder. Advances in neuroimaging technologies are providing a critical step\ntowards a more objective assessment of the disorder. Prior research provides\nstrong evidence that structural and functional magnetic resonance imaging (MRI)\ndata collected from individuals with ASD exhibit distinguishing characteristics\nthat differ in local and global spatial, and temporal neural-patterns of the\nbrain. Our proposed deep-learning model ASD-DiagNet exhibits consistently high\naccuracy for classification of ASD brain scans from neurotypical scans. We have\nfor the first time integrated traditional machine-learning and deep-learning\ntechniques that allows us to isolate ASD biomarkers from MRI data sets. Our\nmethod, called Auto-ASD-Network, uses a combination of deep-learning and\nSupport Vector Machines (SVM) to classify ASD scans from neurotypical scans.\nSuch interpretable models would help explain the decisions made by\ndeep-learning techniques leading to knowledge discovery for neuroscientists,\nand transparent analysis for clinicians.\n", "versions": [{"version": "v1", "created": "Mon, 2 Mar 2020 18:20:44 GMT"}], "update_date": "2020-03-04", "authors_parsed": [["Eslami", "Taban", ""], ["Raiker", "Joseph S.", ""], ["Saeed", "Fahad", ""]]}, {"id": "2003.01812", "submitter": "Matthew Macauley", "authors": "Matthew Macauley, Nora Youngs", "title": "The case for algebraic biology: from research to education", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though it goes without saying that linear algebra is fundamental to\nmathematical biology, polynomial algebra is less visible. In this article, we\nwill give a brief tour of four diverse biological problems where multivariate\npolynomials play a central role -- a subfield that is sometimes called\n\"algebraic biology.\" Namely, these topics include biochemical reaction\nnetworks, Boolean models of gene regulatory networks, algebraic statistics and\ngenomics, and place fields in neuroscience. After that, we will summarize the\nhistory of discrete and algebraic structures in mathematical biology, from\ntheir early appearances in the late 1960s to the current day. Finally, we will\ndiscuss the role of algebraic biology in the modern classroom and curriculum,\nincluding resources in the literature and relevant software. Our goal is to\nmake this article widely accessible, reaching the mathematical biologist who\nknows no algebra, the algebraist who knows no biology, and especially the\ninterested student who is curious about the synergy between these two seemingly\nunrelated fields.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 18:06:29 GMT"}], "update_date": "2020-03-05", "authors_parsed": [["Macauley", "Matthew", ""], ["Youngs", "Nora", ""]]}, {"id": "2003.01868", "submitter": "Yutaka Hori", "authors": "Shinji Hara, Tetsuya Iwasaki, Yutaka Hori", "title": "Robust Instability Analysis with Application to Neuronal Dynamics", "comments": null, "journal-ref": "Proceedings of the 59th IEEE Conference on Decision and Control,\n  pp. 6156-6161, 2020", "doi": "10.1109/CDC42340.2020.9304320", "report-no": null, "categories": "eess.SY cs.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is concerned with robust instability analysis of linear feedback\nsystems subject to a dynamic uncertainty. The work is motivated by, and\nprovides a basic foundation for, a more challenging problem of analyzing\npersistence of oscillations in nonlinear dynamical systems. We first formalize\nthe problem for SISO LTI systems by introducing a notion of the robust\ninstability radius (RIR). We provide a method for calculating the RIR exactly\nfor a certain class of systems and show that it works well for a class of\nsecond order systems. This result is applied to the FitzHugh-Nagumo model for\nneuronal dynamics, and the effectiveness is confirmed by numerical simulations,\nwhere we properly care for the change of the equilibrium point.\n", "versions": [{"version": "v1", "created": "Wed, 4 Mar 2020 02:50:32 GMT"}, {"version": "v2", "created": "Sun, 3 May 2020 12:36:39 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 15:18:28 GMT"}], "update_date": "2021-01-28", "authors_parsed": [["Hara", "Shinji", ""], ["Iwasaki", "Tetsuya", ""], ["Hori", "Yutaka", ""]]}, {"id": "2003.03091", "submitter": "Taiping Zeng", "authors": "Taiping Zeng, Xiaoli Li, and Bailu Si", "title": "StereoNeuroBayesSLAM: A Neurobiologically Inspired Stereo Visual SLAM\n  System Based on Direct Sparse Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.CV eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a neurobiologically inspired visual simultaneous localization and\nmapping (SLAM) system based on direction sparse method to real-time build\ncognitive maps of large-scale environments from a moving stereo camera. The\ncore SLAM system mainly comprises a Bayesian attractor network, which utilizes\nneural responses of head direction (HD) cells in the hippocampus and grid cells\nin the medial entorhinal cortex (MEC) to represent the head direction and the\nposition of the robot in the environment, respectively. Direct sparse method is\nemployed to accurately and robustly estimate velocity information from a stereo\ncamera. Input rotational and translational velocities are integrated by the HD\ncell and grid cell networks, respectively. We demonstrated our\nneurobiologically inspired stereo visual SLAM system on the KITTI odometry\nbenchmark datasets. Our proposed SLAM system is robust to real-time build a\ncoherent semi-metric topological map from a stereo camera. Qualitative\nevaluation on cognitive maps shows that our proposed neurobiologically inspired\nstereo visual SLAM system outperforms our previous brain-inspired algorithms\nand the neurobiologically inspired monocular visual SLAM system both in terms\nof tracking accuracy and robustness, which is closer to the traditional\nstate-of-the-art one.\n", "versions": [{"version": "v1", "created": "Fri, 6 Mar 2020 09:07:50 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Zeng", "Taiping", ""], ["Li", "Xiaoli", ""], ["Si", "Bailu", ""]]}, {"id": "2003.03289", "submitter": "Kalel Luiz Rossi", "authors": "Kalel Luiz Rossi, Roberto Cesar Budzisnki, Joao Antonio Paludo\n  Silveira, Bruno Rafael Reichert Boaretto, Thiago Lima Prado, Sergio Roberto\n  Lopes, Ulrike Feudel", "title": "Effects of neuronal variability on phase synchronization of neural\n  networks", "comments": "11 pages, 7 figures, to be submitted to Neural Networks journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important idea in neural information processing is the\ncommunication-through-coherence hypothesis, according to which communication\nbetween two brain regions is effective only if they are phase-locked. Also of\nimportance is neuronal variability, a phenomenon in which a single neuron's\ninter-firing times may be highly variable. In this work, we aim to connect\nthese two ideas by studying the effects of that variability on the capability\nof neurons to reach phase synchronization. We simulate a network of\nmodified-Hodgkin-Huxley-bursting neurons possessing a small-world topology.\nFirst, variability is shown to be correlated with the average degree of phase\nsynchronization of the network. Next, restricting to spatial variability -\nwhich measures the deviation of firing times between all neurons in the network\n- we show that it is positively correlated to a behavior we call promiscuity,\nwhich is the tendency of neurons to to have their relative phases change with\ntime. This relation is observed in all cases we tested, regardless of the\ndegree of synchronization or the strength of the inter-neuronal coupling: high\nvariability implies high promiscuity (low duration of phase-locking), even if\nthe network as a whole is synchronized and the coupling is strong. We argue\nthat spatial variability actually generates promiscuity. Therefore, we conclude\nthat variability has a strong influence on both the degree and the manner in\nwhich neurons phase synchronize, which is another reason for its relevance in\nneural communication.\n", "versions": [{"version": "v1", "created": "Thu, 27 Feb 2020 12:59:00 GMT"}], "update_date": "2020-03-09", "authors_parsed": [["Rossi", "Kalel Luiz", ""], ["Budzisnki", "Roberto Cesar", ""], ["Silveira", "Joao Antonio Paludo", ""], ["Boaretto", "Bruno Rafael Reichert", ""], ["Prado", "Thiago Lima", ""], ["Lopes", "Sergio Roberto", ""], ["Feudel", "Ulrike", ""]]}, {"id": "2003.03290", "submitter": "Tiago Azevedo", "authors": "Tiago Azevedo, Luca Passamonti, Pietro Li\\`o, Nicola Toschi", "title": "Towards a predictive spatio-temporal representation of brain data", "comments": "To appear in the Workshop on AI for Affordable Healthcare (AI4AH) at\n  ICLR 2020. 8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.IV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characterisation of the brain as a \"connectome\", in which the connections\nare represented by correlational values across timeseries and as summary\nmeasures derived from graph theory analyses, has been very popular in the last\nyears. However, although this representation has advanced our understanding of\nthe brain function, it may represent an oversimplified model. This is because\nthe typical fMRI datasets are constituted by complex and highly heterogeneous\ntimeseries that vary across space (i.e., location of brain regions). We compare\nvarious modelling techniques from deep learning and geometric deep learning to\npave the way for future research in effectively leveraging the rich spatial and\ntemporal domains of typical fMRI datasets, as well as of other similar\ndatasets. As a proof-of-concept, we compare our approaches in the homogeneous\nand publicly available Human Connectome Project (HCP) dataset on a supervised\nbinary classification task. We hope that our methodological advances relative\nto previous \"connectomic\" measures can ultimately be clinically and\ncomputationally relevant by leading to a more nuanced understanding of the\nbrain dynamics in health and disease. Such understanding of the brain can\nfundamentally reduce the constant specialised clinical expertise in order to\naccurately understand brain variability.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 18:49:45 GMT"}], "update_date": "2020-03-13", "authors_parsed": [["Azevedo", "Tiago", ""], ["Passamonti", "Luca", ""], ["Li\u00f2", "Pietro", ""], ["Toschi", "Nicola", ""]]}, {"id": "2003.03482", "submitter": "Li Songlin", "authors": "Li Songlin, Deng Yangdong, Wang Zhihua", "title": "Grid Cells Are Ubiquitous in Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid cells are believed to play an important role in both spatial and\nnon-spatial cognition tasks. A recent study observed the emergence of grid\ncells in an LSTM for path integration. The connection between biological and\nartificial neural networks underlying the seemingly similarity, as well as the\napplication domain of grid cells in deep neural networks (DNNs), expect further\nexploration. This work demonstrated that grid cells could be replicated in\neither pure vision based or vision guided path integration DNNs for navigation\nunder a proper setting of training parameters. We also show that grid-like\nbehaviors arise in feedforward DNNs for non-spatial tasks. Our findings support\nthat the grid coding is an effective representation for both biological and\nartificial networks.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 01:40:56 GMT"}, {"version": "v2", "created": "Wed, 9 Sep 2020 09:38:15 GMT"}], "update_date": "2020-09-10", "authors_parsed": [["Songlin", "Li", ""], ["Yangdong", "Deng", ""], ["Zhihua", "Wang", ""]]}, {"id": "2003.03626", "submitter": "Jacob George", "authors": "David M. Page, Suzanne M. Wendelken, Tyler S. Davis, David T. Kluger,\n  Douglas T. Hutchinson, Jacob A. George and Gregory A. Clark", "title": "Discrimination Among Multiple Cutaneous and Proprioceptive Hand Percepts\n  Evoked by Nerve Stimulation with Utah Slanted Electrode Arrays in Human\n  Amputees", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: This paper aims to demonstrate functional discriminability among\nrestored hand sensations with different locations, qualities, and intensities\nthat are evoked by microelectrode stimulation of residual afferent fibers in\nhuman amputees. Methods: We implanted a Utah Slanted Electrode Array (USEA) in\nthe median and ulnar residual arm nerves of three transradial amputees and\ndelivered stimulation via different electrodes and at different frequencies to\nproduce various locations, qualities, and intensities of sensation on the\nmissing hand. Blind discrimination trials were performed to determine how well\nsubjects could discriminate among these restored sensations. Results: Subjects\ndiscriminated among restored sensory percepts with varying cutaneous and\nproprioceptive locations, qualities, and intensities in blind trials, including\ndiscrimination among up to 10 different location-intensity combinations (15/30\nsuccesses, p < 0.0005). Variations in the site of stimulation within the nerve,\nvia electrode selection, enabled discrimination among up to 5 locations and\nqualities (35/35 successes, p < 0.0001). Variations in the stimulation\nfrequency enabled discrimination among 4 different intensities at the same\nlocation (13/20 successes, p < 0.005). One subject discriminated among\nsimultaneous, alternating, and isolated stimulation of two different USEA\nelectrodes, as may be desired during multi-sensor closed-loop prosthesis use\n(20/25 successes, p < 0.001). Conclusion: USEA stimulation enables encoding of\na diversity of functionally discriminable sensations with different locations,\nqualities, and intensities. Significance: These percepts provide a potentially\nrich source of sensory feedback that may enhance performance and embodiment\nduring multi-sensor, closed-loop prosthesis use.\n", "versions": [{"version": "v1", "created": "Sat, 7 Mar 2020 18:17:03 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["Page", "David M.", ""], ["Wendelken", "Suzanne M.", ""], ["Davis", "Tyler S.", ""], ["Kluger", "David T.", ""], ["Hutchinson", "Douglas T.", ""], ["George", "Jacob A.", ""], ["Clark", "Gregory A.", ""]]}, {"id": "2003.03829", "submitter": "Giuseppe De Vito", "authors": "Giuseppe de Vito, Valentina Cappello, Ilaria Tonazzini, Marco\n  Cecchini, Vincenzo Piazza", "title": "RP-CARS reveals molecular spatial order anomalies in myelin of an animal\n  model of Krabbe disease", "comments": "19 pages, 7 figures. This is the pre-peer reviewed version of an\n  article that has been published in final form on Journal of Biophotonics", "journal-ref": "Journal of Biophotonics 10 (2017) 385-393", "doi": "10.1002/jbio.201500305", "report-no": null, "categories": "q-bio.NC q-bio.QM q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Krabbe disease (KD) is a rare demyelinating sphingolipidosis, often fatal in\nthe first years of life. It is caused by the inactivation of the\ngalactocerebrosidase (GALC) enzyme that causes an increase in the cellular\nlevels of psychosine considered to be at the origin of the tissue-level\neffects. GALC is inactivated also in the Twitcher (TWI) mouse: a genetic model\nof KD that is providing important insights into the understating of the\npathogenetic process and the development of possible treatments. In this\narticle an innovative optical technique, RP-CARS, is proposed as a tool to\nstudy the degree of order of the CH2 bonds inside the myelin sheaths of\nTWI-mice sciatic-nerve fibres. RP-CARS, a recently developed variation of CARS\nmicroscopy, is able to combine the intrinsic chemical selectivity of CARS\nmicroscopy with molecular-bond-spatial-orientation sensibility. This is the\nfirst time RP-CARS is applied to the study of a genetic model of a pathology,\nleading to the demonstration of a post-onset progressive spatial\ndisorganization of the myelin CH2 bonds. The presented result could be of great\ninterest for a deeper understanding of the pathogenic mechanisms underlying the\nhuman KD and, moreover, it is an additional proof of the experimental validity\nof this microscopy technique.\n", "versions": [{"version": "v1", "created": "Sun, 8 Mar 2020 19:00:00 GMT"}], "update_date": "2020-03-10", "authors_parsed": [["de Vito", "Giuseppe", ""], ["Cappello", "Valentina", ""], ["Tonazzini", "Ilaria", ""], ["Cecchini", "Marco", ""], ["Piazza", "Vincenzo", ""]]}, {"id": "2003.03887", "submitter": "Oliver Cliff", "authors": "Oliver M. Cliff, Leonardo Novelli, Ben D. Fulcher, James M. Shine and\n  Joseph T. Lizier", "title": "Assessing the Significance of Directed and Multivariate Measures of\n  Linear Dependence Between Time Series", "comments": "27 pages, 14 figures, final submission to Phys Rev. Research editors\n  (before copyediting)", "journal-ref": "Phys. Rev. Research 3, 013145 (2021)", "doi": "10.1103/PhysRevResearch.3.013145", "report-no": null, "categories": "stat.ME cs.IT math.IT math.ST physics.data-an q-bio.NC stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring linear dependence between time series is central to our\nunderstanding of natural and artificial systems. Unfortunately, the hypothesis\ntests that are used to determine statistically significant directed or\nmultivariate relationships from time-series data often yield spurious\nassociations (Type I errors) or omit causal relationships (Type II errors).\nThis is due to the autocorrelation present in the analysed time series -- a\nproperty that is ubiquitous across diverse applications, from brain dynamics to\nclimate change. Here we show that, for limited data, this issue cannot be\nmediated by fitting a time-series model alone (e.g., in Granger causality or\nprewhitening approaches), and instead that the degrees of freedom in\nstatistical tests should be altered to account for the effective sample size\ninduced by cross-correlations in the observations. This insight enabled us to\nderive modified hypothesis tests for any multivariate correlation-based\nmeasures of linear dependence between covariance-stationary time series,\nincluding Granger causality and mutual information with Gaussian marginals. We\nuse both numerical simulations (generated by autoregressive models and digital\nfiltering) as well as recorded fMRI-neuroimaging data to show that our tests\nare unbiased for a variety of stationary time series. Our experiments\ndemonstrate that the commonly used $F$- and $\\chi^2$-tests can induce\nsignificant false-positive rates of up to $100\\%$ for both measures, with and\nwithout prewhitening of the signals. These findings suggest that many\ndependencies reported in the scientific literature may have been, and may\ncontinue to be, spuriously reported or missed if modified hypothesis tests are\nnot used when analysing time series.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 02:06:01 GMT"}, {"version": "v2", "created": "Tue, 10 Mar 2020 11:02:18 GMT"}, {"version": "v3", "created": "Wed, 27 Jan 2021 10:13:03 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Cliff", "Oliver M.", ""], ["Novelli", "Leonardo", ""], ["Fulcher", "Ben D.", ""], ["Shine", "James M.", ""], ["Lizier", "Joseph T.", ""]]}, {"id": "2003.03988", "submitter": "Nasir Ahmad", "authors": "Nasir Ahmad, Luca Ambrogioni, Marcel A. J. van Gerven", "title": "Overcoming the Weight Transport Problem via Spike-Timing-Dependent\n  Weight Inference", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a solution to the weight transport problem, which questions the\nbiological plausibility of the backpropagation algorithm. We derive our method\nbased upon a theoretical analysis of the (approximate) dynamics of leaky\nintegrate-and-fire neurons. We show that the use of spike timing alone\noutcompetes existing biologically plausible methods for synaptic weight\ninference in spiking neural network models. Furthermore, our proposed method is\nmore flexible, being applicable to any spiking neuron model, is conservative in\nhow many parameters are required for implementation and can be deployed in an\nonline-fashion with minimal computational overhead. These features, together\nwith its biological plausibility, make it an attractive mechanism underlying\nweight inference at single synapses.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 09:26:23 GMT"}, {"version": "v2", "created": "Wed, 10 Jun 2020 08:19:32 GMT"}, {"version": "v3", "created": "Mon, 2 Nov 2020 09:33:39 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Ahmad", "Nasir", ""], ["Ambrogioni", "Luca", ""], ["van Gerven", "Marcel A. J.", ""]]}, {"id": "2003.04000", "submitter": "Simona Olmi", "authors": "Marco Segneri, Hongjie Bi, Simona Olmi, Alessandro Torcini", "title": "Theta-nested gamma oscillations in next generation neural mass models", "comments": "28 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO nlin.CD physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Theta-nested gamma oscillations have been reported in many areas of the brain\nand are believed to represent a fundamental mechanism to transfer information\nacross spatial and temporal scales. In a series of recent experiments in vitro\nit has been possible to replicate with an optogenetic theta frequency\nstimulation several features of cross-frequency coupling among theta and gamma\nrhythms observed in behaving animals. In order to reproduce the main findings\nof these experiments we have considered a new class of neural mass models able\nto reproduce exactly the macroscopic dynamics of spiking neural networks. In\nthis framework, we have examined two set-ups able to support collective gamma\noscillations: the pyramidal interneuronal network gamma (PING) and the\ninterneuronal network gamma (ING). In both set-ups we observe the emergence of\ntheta-nested gamma oscillations by driving the system with a sinusoidal\ntheta-forcing in proximity of a Hopf bifurcation. These mixed rhythms display\nalways phase amplitude coupling. However 2 different types of nested\noscillations can be identified: one characterized by a perfect phase locking\nbetween theta and gamma rhythms, corresponding to an overall periodic\nbehaviour; another one where the locking is imperfect and the dynamics is\nquasi-periodic or even chaotic. From our analysis it emerges that the locked\nstates are more frequent in the ING set-up. In agreement with the experiments,\nwe find theta-nested gamma oscillations for forcing frequencies in the range\n[1:10] Hz, whose amplitudes grow proportionally to the forcing one and which\nare clearly modulated by the theta phase. At variance with experimental\nfindings, the gamma-power peak does not shift to higher frequencies by\nincreasing the theta frequency. This effect can be obtained, in or model, only\nby incrementing, at the same time, also the noise or the forcing amplitude.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 09:40:21 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Segneri", "Marco", ""], ["Bi", "Hongjie", ""], ["Olmi", "Simona", ""], ["Torcini", "Alessandro", ""]]}, {"id": "2003.04741", "submitter": "Paolo Moretti", "authors": "Ali Safari, Paolo Moretti, Ibai Diez, Jesus M. Cortes, Miguel \\'Angel\n  Mu\\~noz", "title": "Persistence of hierarchical network organization and emergent topologies\n  in models of functional connectivity", "comments": "5 figures. Accepted for publication in Neurocomputing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Functional networks provide a topological description of activity patterns in\nthe brain, as they stem from the propagation of neural activity on the\nunderlying anatomical or structural network of synaptic connections. This\nlatter is well known to be organized in hierarchical and modular way. While it\nis assumed that structural networks shape their functional counterparts, it is\nalso hypothesized that alterations of brain dynamics come with transformations\nof functional connectivity. In this computational study, we introduce a novel\nmethodology to monitor the persistence and breakdown of hierarchical order in\nfunctional networks, generated from computational models of activity spreading\non both synthetic and real structural connectomes. We show that hierarchical\nconnectivity appears in functional networks in a persistent way if the dynamics\nis set to be in the quasi-critical regime associated with optimal processing\ncapabilities and normal brain function, while it breaks down in other\n(supercritical) dynamical regimes, often associated with pathological\nconditions. Our results offer important clues for the study of optimal\nneurocomputing architectures and processes, which are capable of controlling\npatterns of activity and information flow. We conclude that functional\nconnectivity patterns achieve optimal balance between local specialized\nprocessing (i.e. segregation) and global integration by inheriting the\nhierarchical organization of the underlying structural architecture.\n", "versions": [{"version": "v1", "created": "Tue, 10 Mar 2020 13:57:05 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2020 14:32:41 GMT"}, {"version": "v3", "created": "Wed, 10 Feb 2021 10:25:30 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Safari", "Ali", ""], ["Moretti", "Paolo", ""], ["Diez", "Ibai", ""], ["Cortes", "Jesus M.", ""], ["Mu\u00f1oz", "Miguel \u00c1ngel", ""]]}, {"id": "2003.04805", "submitter": "Razvan Marinescu", "authors": "Razvan V. Marinescu", "title": "Modelling the Neuroanatomical Progression of Alzheimer's Disease and\n  Posterior Cortical Atrophy", "comments": "PhD thesis; Defended in Jan 2019 at University College London", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In order to find effective treatments for Alzheimer's disease (AD), we need\nto identify subjects at risk of AD as early as possible. To this end, recently\ndeveloped disease progression models can be used to perform early diagnosis, as\nwell as predict the subjects' disease stages and future evolution. However,\nthese models have not yet been applied to rare neurodegenerative diseases, are\nnot suitable to understand the complex dynamics of biomarkers, work only on\nlarge multimodal datasets, and their predictive performance has not been\nobjectively validated. In this work I developed novel models of disease\nprogression and applied them to estimate the progression of Alzheimer's disease\nand Posterior Cortical atrophy, a rare neurodegenerative syndrome causing\nvisual deficits. My first contribution is a study on the progression of\nPosterior Cortical Atrophy, using models already developed: the Event-based\nModel (EBM) and the Differential Equation Model (DEM). My second contribution\nis the development of DIVE, a novel spatio-temporal model of disease\nprogression that estimates fine-grained spatial patterns of pathology,\npotentially enabling us to understand complex disease mechanisms relating to\npathology propagation along brain networks. My third contribution is the\ndevelopment of Disease Knowledge Transfer (DKT), a novel disease progression\nmodel that estimates the multimodal progression of rare neurodegenerative\ndiseases from limited, unimodal datasets, by transferring information from\nlarger, multimodal datasets of typical neurodegenerative diseases. My fourth\ncontribution is the development of novel extensions for the EBM and the DEM,\nand the development of novel measures for performance evaluation of such\nmodels. My last contribution is the organization of the TADPOLE challenge, a\ncompetition which aims to identify algorithms and features that best predict\nthe evolution of AD.\n", "versions": [{"version": "v1", "created": "Sat, 29 Feb 2020 21:59:52 GMT"}], "update_date": "2020-03-11", "authors_parsed": [["Marinescu", "Razvan V.", ""]]}, {"id": "2003.04890", "submitter": "Giuseppe De Vito", "authors": "Giuseppe De Vito, Paola Parlanti, Roberta Cecchi, Stefano Luin,\n  Valentina Cappello, Ilaria Tonazzini, Vincenzo Piazza", "title": "Effects of fixatives on myelin molecular order probed with RP-CARS\n  microscopy", "comments": "11 pages, 4 figures. This is the peer reviewed version of an article\n  that has been published in final form by Applied Optics. Please note that the\n  copyright statement on the front page of the article allows posting of this\n  manuscript by authors on arXiv, as specified here:\n  https://www.osapublishing.org/submit/review/copyright_permissions.cfm", "journal-ref": "Applied Optics 59 (2020) 1756-1762", "doi": "10.1364/AO.384662", "report-no": null, "categories": "q-bio.TO q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When live imaging is not feasible, sample fixation allows preserving the\nultrastructure of biological samples for subsequent microscopy analysis. This\nprocess could be performed with various methods, each one affecting differently\nthe biological structure of the sample. While these alterations were\nwell-characterized using traditional microscopy, little information is\navailable about the effects of the fixatives on the spatial molecular\norientation of the biological tissue. We tackled this issue by employing\nRotating-Polarization Coherent Anti-Stokes Raman Scattering (RP-CARS)\nmicroscopy to study the effects of different fixatives on the myelin\nsub-micrometric molecular order and micrometric morphology. RP-CARS is a novel\ntechnique derived from CARS microscopy that allows probing spatial orientation\nof molecular bonds while maintaining the intrinsic chemical selectivity of CARS\nmicroscopy. By characterizing the effects of the fixation procedures, the\npresent work represents a useful guide for the choice of the best fixation\ntechnique(s), in particular for polarisation-resolved CARS microscopy. Finally,\nwe show that the combination of paraformaldehyde and glutaraldehyde can be\neffectively employed as a fixative for RP-CARS microscopy, as long as the\neffects on the molecular spatial distribution, here characterized, are taken\ninto account.\n", "versions": [{"version": "v1", "created": "Mon, 9 Mar 2020 19:16:17 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["De Vito", "Giuseppe", ""], ["Parlanti", "Paola", ""], ["Cecchi", "Roberta", ""], ["Luin", "Stefano", ""], ["Cappello", "Valentina", ""], ["Tonazzini", "Ilaria", ""], ["Piazza", "Vincenzo", ""]]}, {"id": "2003.05133", "submitter": "Bulent Karas\\\"ozen", "authors": "B\\\"ulent Karas\\\"ozen", "title": "Model Order Reduction in Neuroscience", "comments": "14 pages, no figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NA math.NA", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The human brain contains approximately $10^9$ neurons, each with\napproximately $10^3$ connections, synapses, with other neurons. Most sensory,\ncognitive and motor functions of our brains depend on the interaction of a\nlarge population of neurons. In recent years, many technologies are developed\nfor recording large numbers of neurons either sequentially or simultaneously.\nAn increase in computational power and algorithmic developments have enabled\nadvanced analyses of neuronal population parallel to the rapid growth of\nquantity and complexity of the recorded neuronal activity. Recent studies made\nuse of dimensionality and model order reduction techniques to extract coherent\nfeatures which are not apparent at the level of individual neurons. It has been\nobserved that the neuronal activity evolves on low-dimensional subspaces. The\naim of model reduction of large-scale neuronal networks is an accurate and fast\nprediction of patterns and their propagation in different areas of the brain.\nSpatiotemporal features of the brain activity are identified on low dimensional\nsubspaces with methods such as dynamic mode decomposition (DMD), proper\northogonal decomposition (POD), discrete empirical interpolation (DEIM) and\ncombined parameter and state reduction. In this paper, we give an overview of\nthe currently used dimensionality reduction and model order reduction\ntechniques in neuroscience.\n  This work will be featured as a chapter in the upcoming Handbook on Model\nOrder Reduction,(P. Benner, S. Grivet-Talocia, A. Quarteroni, G. Rozza, W. H.\nA. Schilders, L. M. Silveira, eds, to appear on DE GRUYTER)\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 06:31:10 GMT"}, {"version": "v2", "created": "Sat, 18 Apr 2020 02:21:36 GMT"}], "update_date": "2020-04-21", "authors_parsed": [["Karas\u00f6zen", "B\u00fclent", ""]]}, {"id": "2003.05171", "submitter": "Peter beim Graben", "authors": "Peter beim Graben, Markus Huber, Werner Meyer, Ronald R\\\"omer and\n  Matthias Wolff", "title": "Vector symbolic architectures for context-free grammars", "comments": "36 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background / introduction. Vector symbolic architectures (VSA) are a viable\napproach for the hyperdimensional representation of symbolic data, such as\ndocuments, syntactic structures, or semantic frames. Methods. We present a\nrigorous mathematical framework for the representation of phrase structure\ntrees and parse trees of context-free grammars (CFG) in Fock space, i.e.\ninfinite-dimensional Hilbert space as being used in quantum field theory. We\ndefine a novel normal form for CFG by means of term algebras. Using a recently\ndeveloped software toolbox, called FockBox, we construct Fock space\nrepresentations for the trees built up by a CFG left-corner (LC) parser.\nResults. We prove a universal representation theorem for CFG term algebras in\nFock space and illustrate our findings through a low-dimensional principal\ncomponent projection of the LC parser states. Conclusions. Our approach could\nleverage the development of VSA for explainable artificial intelligence (XAI)\nby means of hyperdimensional deep neural computation. It could be of\nsignificance for the improvement of cognitive user interfaces and other\napplications of VSA in machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 09:07:02 GMT"}, {"version": "v2", "created": "Fri, 25 Sep 2020 08:34:46 GMT"}], "update_date": "2020-09-28", "authors_parsed": [["Graben", "Peter beim", ""], ["Huber", "Markus", ""], ["Meyer", "Werner", ""], ["R\u00f6mer", "Ronald", ""], ["Wolff", "Matthias", ""]]}, {"id": "2003.05393", "submitter": "Joaquin Goni", "authors": "Kausar Abbas, Mintao Liu, Manasij Venkatesh, Enrico Amico, Alan David\n  Kaplan, Mario Ventresca, Luiz Pessoa, Jaroslaw Harezlak, Joaqu\\'in Go\\~ni", "title": "Geodesic distance on optimally regularized functional connectomes\n  uncovers individual fingerprints", "comments": "39 pages, 7 figures, 4 tables", "journal-ref": "Brain Connectivity, 2021", "doi": "10.1089/brain.2020.0881", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Functional connectomes (FCs), have been shown to provide a\nreproducible individual fingerprint, which has opened the possibility of\npersonalized medicine for neuro/psychiatric disorders. Thus, developing\naccurate ways to compare FCs is essential to establish associations with\nbehavior and/or cognition at the individual-level.\n  Methods: Canonically, FCs are compared using Pearson's correlation\ncoefficient of the entire functional connectivity profiles. Recently, it has\nbeen proposed that the use of geodesic distance is a more accurate way of\ncomparing functional connectomes, one which reflects the underlying\nnon-Euclidean geometry of the data. Computing geodesic distance requires FCs to\nbe positive-definite and hence invertible matrices. As this requirement depends\non the fMRI scanning length and the parcellation used, it is not always\nattainable and sometimes a regularization procedure is required.\n  Results: In the present work, we show that regularization is not only an\nalgebraic operation for making FCs invertible, but also that an optimal\nmagnitude of regularization leads to systematically higher fingerprints. We\nalso show evidence that optimal regularization is dataset-dependent, and varies\nas a function of condition, parcellation, scanning length, and the number of\nframes used to compute the FCs.\n  Discussion: We demonstrate that a universally fixed regularization does not\nfully uncover the potential of geodesic distance on individual fingerprinting,\nand indeed could severely diminish it. Thus, an optimal regularization must be\nestimated on each dataset to uncover the most differentiable across-subject and\nreproducible within-subject geodesic distances between FCs. The resulting\npairwise geodesic distances at the optimal regularization level constitute a\nvery reliable quantification of differences between subjects.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 16:32:29 GMT"}, {"version": "v2", "created": "Sat, 29 Aug 2020 01:23:27 GMT"}, {"version": "v3", "created": "Wed, 31 Mar 2021 15:36:53 GMT"}], "update_date": "2021-04-01", "authors_parsed": [["Abbas", "Kausar", ""], ["Liu", "Mintao", ""], ["Venkatesh", "Manasij", ""], ["Amico", "Enrico", ""], ["Kaplan", "Alan David", ""], ["Ventresca", "Mario", ""], ["Pessoa", "Luiz", ""], ["Harezlak", "Jaroslaw", ""], ["Go\u00f1i", "Joaqu\u00edn", ""]]}, {"id": "2003.05405", "submitter": "Arthur Mensch", "authors": "Kamalaker Dadi (PARIETAL), Ga\\\"el Varoquaux (PARIETAL), Antonia\n  Machlouzarides-Shalit (PARIETAL), Krzysztof J. Gorgolewski, Demian Wassermann\n  (PARIETAL), Bertrand Thirion (PARIETAL), Arthur Mensch (DMA, PARIETAL)", "title": "Fine-grain atlases of functional modes for fMRI analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.SP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population imaging markedly increased the size of functional-imaging\ndatasets, shedding new light on the neural basis of inter-individual\ndifferences. Analyzing these large data entails new scalability challenges,\ncomputational and statistical. For this reason, brain images are typically\nsummarized in a few signals, for instance reducing voxel-level measures with\nbrain atlases or functional modes. A good choice of the corresponding brain\nnetworks is important, as most data analyses start from these reduced signals.\nWe contribute finely-resolved atlases of functional modes, comprising from 64\nto 1024 networks. These dictionaries of functional modes (DiFuMo) are trained\non millions of fMRI functional brain volumes of total size 2.4TB, spanned over\n27 studies and many research groups. We demonstrate the benefits of extracting\nreduced signals on our fine-grain atlases for many classic functional data\nanalysis pipelines: stimuli decoding from 12,334 brain responses, standard GLM\nanalysis of fMRI across sessions and individuals, extraction of resting-state\nfunctional-connectomes biomarkers for 2,500 individuals, data compression and\nmeta-analysis over more than 15,000 statistical maps. In each of these analysis\nscenarii, we compare the performance of our functional atlases with that of\nother popular references, and to a simple voxel-level analysis. Results\nhighlight the importance of using high-dimensional \"soft\" functional atlases,\nto represent and analyse brain activity while capturing its functional\ngradients. Analyses on high-dimensional modes achieve similar statistical\nperformance as at the voxel level, but with much reduced computational cost and\nhigher interpretability. In addition to making them available, we provide\nmeaningful names for these modes, based on their anatomical location. It will\nfacilitate reporting of results.\n", "versions": [{"version": "v1", "created": "Thu, 5 Mar 2020 12:04:12 GMT"}], "update_date": "2020-03-12", "authors_parsed": [["Dadi", "Kamalaker", "", "PARIETAL"], ["Varoquaux", "Ga\u00ebl", "", "PARIETAL"], ["Machlouzarides-Shalit", "Antonia", "", "PARIETAL"], ["Gorgolewski", "Krzysztof J.", "", "PARIETAL"], ["Wassermann", "Demian", "", "PARIETAL"], ["Thirion", "Bertrand", "", "PARIETAL"], ["Mensch", "Arthur", "", "DMA, PARIETAL"]]}, {"id": "2003.05647", "submitter": "Mitsuo Kawato", "authors": "Mitsuo Kawato, Shogo Ohmae, Huu Hoang, Terry Sanger", "title": "50 years since the Marr, Ito, and Albus models of the cerebellum", "comments": "P.4, 5, 8, 10, 14, 16, 18, 22, and some references added", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fifty years have passed since David Marr, Masao Ito, and James Albus proposed\nseminal models of cerebellar functions. These models share the essential\nconcept that parallel-fiber-Purkinje-cell synapses undergo plastic changes,\nguided by climbing-fiber activities during sensorimotor learning. However, they\ndiffer in several important respects, including holistic versus complementary\nroles of the cerebellum, pattern recognition versus control as computational\nobjectives, potentiation versus depression of synaptic plasticity, teaching\nsignals versus error signals transmitted by climbing-fibers, sparse expansion\ncoding by granule cells, and cerebellar internal models. In this review, we\nevaluate the different features of the three models based on recent\ncomputational and experimental studies. While acknowledging that the three\nmodels have greatly advanced our understanding of cerebellar control mechanisms\nin eye movements and classical conditioning, we propose a new direction for\ncomputational frameworks of the cerebellum. That is, hierarchical reinforcement\nlearning with multiple internal models.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 07:38:30 GMT"}, {"version": "v2", "created": "Tue, 24 Mar 2020 09:14:37 GMT"}, {"version": "v3", "created": "Wed, 25 Mar 2020 00:23:31 GMT"}, {"version": "v4", "created": "Mon, 15 Jun 2020 08:21:36 GMT"}], "update_date": "2020-06-16", "authors_parsed": [["Kawato", "Mitsuo", ""], ["Ohmae", "Shogo", ""], ["Hoang", "Huu", ""], ["Sanger", "Terry", ""]]}, {"id": "2003.06038", "submitter": "Tilo Schwalger", "authors": "Bastian Pietras, No\\'e Gallice, Tilo Schwalger", "title": "Low-dimensional firing-rate dynamics for populations of renewal-type\n  spiking neurons", "comments": "24 pages, 7 figures", "journal-ref": "Phys. Rev. E 102, 022407 (2020)", "doi": "10.1103/PhysRevE.102.022407", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The macroscopic dynamics of large populations of neurons can be\nmathematically analyzed using low-dimensional firing-rate or neural-mass\nmodels. However, these models fail to capture spike synchronization effects of\nstochastic spiking neurons such as the non-stationary population response to\nrapidly changing stimuli. Here, we derive low-dimensional firing-rate models\nfor homogeneous populations of general renewal-type neurons, including\nintegrate-and-fire models driven by white noise. Renewal models account for\nneuronal refractoriness and spike synchronization dynamics. The derivation is\nbased on an eigenmode expansion of the associated refractory density equation,\nwhich generalizes previous spectral methods for Fokker-Planck equations to\narbitrary renewal models. We find a simple relation between the eigenvalues,\nwhich determine the characteristic time scales of the firing rate dynamics, and\nthe Laplace transform of the interspike interval density or the survival\nfunction of the renewal process. Analytical expressions for the Laplace\ntransforms are readily available for many renewal models including the leaky\nintegrate-and-fire model. Retaining only the first eigenmode yields already an\nadequate low-dimensional approximation of the firing-rate dynamics that\ncaptures spike synchronization effects and fast transient dynamics at stimulus\nonset. We explicitly demonstrate the validity of our model for a large\nhomogeneous population of Poisson neurons with absolute refractoriness, and\nother renewal models that admit an explicit analytical calculation of the\neigenvalues. The here presented eigenmode expansion provides a systematic\nframework for novel firing-rate models in computational neuroscience based on\nspiking neuron dynamics with refractoriness.\n", "versions": [{"version": "v1", "created": "Thu, 12 Mar 2020 22:10:20 GMT"}, {"version": "v2", "created": "Fri, 20 Mar 2020 17:34:50 GMT"}], "update_date": "2020-08-26", "authors_parsed": [["Pietras", "Bastian", ""], ["Gallice", "No\u00e9", ""], ["Schwalger", "Tilo", ""]]}, {"id": "2003.06105", "submitter": "Kai Qiao", "authors": "Kai Qiao, Jian Chen, Linyuan Wang, Chi Zhang, Li Tong, Bin Yan", "title": "BigGAN-based Bayesian reconstruction of natural images from human brain\n  activity", "comments": "brain decoding; visual reconstruction; generative adversarial network\n  (GAN); Bayesian framework. under review in Neuroscience of Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the visual decoding domain, visually reconstructing presented images given\nthe corresponding human brain activity monitored by functional magnetic\nresonance imaging (fMRI) is difficult, especially when reconstructing viewed\nnatural images. Visual reconstruction is a conditional image generation on fMRI\ndata and thus generative adversarial network (GAN) for natural image generation\nis recently introduced for this task. Although GAN-based methods have greatly\nimproved, the fidelity and naturalness of reconstruction are still\nunsatisfactory due to the small number of fMRI data samples and the instability\nof GAN training. In this study, we proposed a new GAN-based Bayesian visual\nreconstruction method (GAN-BVRM) that includes a classifier to decode\ncategories from fMRI data, a pre-trained conditional generator to generate\nnatural images of specified categories, and a set of encoding models and\nevaluator to evaluate generated images. GAN-BVRM employs the pre-trained\ngenerator of the prevailing BigGAN to generate masses of natural images, and\nselects the images that best matches with the corresponding brain activity\nthrough the encoding models as the reconstruction of the image stimuli. In this\nprocess, the semantic and detailed contents of reconstruction are controlled by\ndecoded categories and encoding models, respectively. GAN-BVRM used the\nBayesian manner to avoid contradiction between naturalness and fidelity from\ncurrent GAN-based methods and thus can improve the advantages of GAN.\nExperimental results revealed that GAN-BVRM improves the fidelity and\nnaturalness, that is, the reconstruction is natural and similar to the\npresented image stimuli.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 04:32:11 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Qiao", "Kai", ""], ["Chen", "Jian", ""], ["Wang", "Linyuan", ""], ["Zhang", "Chi", ""], ["Tong", "Li", ""], ["Yan", "Bin", ""]]}, {"id": "2003.06343", "submitter": "Jesus Garrido", "authors": "Sergio E. Galindo, Pablo Toharia, Oscar D. Robles, Eduardo Ros, Luis\n  Pastor, Jes\\'us A. Garrido", "title": "Simulation, visualization and analysis tools for pattern recognition\n  assessment with spiking neuronal networks", "comments": null, "journal-ref": null, "doi": "10.1016/j.neucom.2020.02.114", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational modeling is becoming a widely used methodology in modern\nneuroscience. However, as the complexity of the phenomena under study\nincreases, the analysis of the results emerging from the simulations\nconcomitantly becomes more challenging. In particular, the configuration and\nvalidation of brain circuits involving learning often require the processing of\nlarge amounts of action potentials and their comparison to the stimulation\nbeing presented to the input of the system. In this study we present a\nsystematic work-flow for the configuration of spiking-neuronal-network-based\nlearning systems including evolutionary algorithms for information transmission\noptimization, advanced visualization tools for the validation of the best\nsuitable configuration and customized scripts for final quantitative evaluation\nof the learning capabilities. By integrating both grouped action potential\ninformation and stimulation-related events, the proposed visualization\nframework provides qualitatively assessment of the evolution of the learning\nprocess in the simulation under study. The proposed work-flow has been used to\nstudy how receptive fields emerge in a network of inhibitory interneurons with\nexcitatory and inhibitory spike-timing dependent plasticity when it is exposed\nto repetitive and partially overlapped stimulation patterns. According to our\nresults, the output population reliably detected the presence of the\nstimulation patterns, even when the fan-in ratio of the interneurons was\nconsiderably restricted.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 15:34:32 GMT"}], "update_date": "2020-03-16", "authors_parsed": [["Galindo", "Sergio E.", ""], ["Toharia", "Pablo", ""], ["Robles", "Oscar D.", ""], ["Ros", "Eduardo", ""], ["Pastor", "Luis", ""], ["Garrido", "Jes\u00fas A.", ""]]}, {"id": "2003.06463", "submitter": "Kanika Bansal", "authors": "Kanika Bansal, Javier O. Garcia, Nina Lauharatanahirun, Sarah F.\n  Muldoon, Paul Sajda, Jean M. Vettel", "title": "Scale-specific dynamics of large-amplitude bursts in EEG capture\n  behaviorally meaningful variability", "comments": null, "journal-ref": null, "doi": "10.1016/j.neuroimage.2021.118425", "report-no": null, "categories": "q-bio.NC nlin.AO physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cascading large-amplitude bursts in neural activity, termed avalanches, are\nthought to provide insight into the complex spatially distributed interactions\nin neural systems. In human neuroimaging, for example, avalanches occurring\nduring resting-state show scale-invariant dynamics, supporting the hypothesis\nthat the brain operates near a critical point that enables long range spatial\ncommunication. In fact, it has been suggested that such scale-invariant\ndynamics, characterized by a power-law distribution in these avalanches, are\nuniversal in neural systems and emerge through a common mechanism. While the\nanalysis of avalanches and subsequent criticality is increasingly seen as a\nframework for using complex systems theory to understand brain function, it is\nunclear how the framework would account for the omnipresent cognitive\nvariability, whether across individuals and/or tasks. To address this, we\nanalyzed avalanches in the EEG activity of healthy humans during rest as well\nas two distinct task conditions that varied in cognitive demands and produced\nbehavioral measures unique to each individual. In both rest and task conditions\nwe observed that avalanche dynamics demonstrate scale-invariant\ncharacteristics, but differ in their specific features, demonstrating\nindividual variability. Using a new metric we call normalized engagement, which\nestimates the likelihood for a brain region to produce high-amplitude bursts,\nwe also investigated regional features of avalanche dynamics. Normalized\nengagement showed not only the expected individual and task dependent\nvariability, but also scale-specificity that correlated with individual\nbehavior. Our findings expand our understanding of avalanche features and are\nsupportive of the emerging theoretical idea that the dynamics of an active\nhuman brain operate close to a critical-like region and not a singular\ncritical-state.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 19:50:10 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Bansal", "Kanika", ""], ["Garcia", "Javier O.", ""], ["Lauharatanahirun", "Nina", ""], ["Muldoon", "Sarah F.", ""], ["Sajda", "Paul", ""], ["Vettel", "Jean M.", ""]]}, {"id": "2003.07209", "submitter": "F. Tito Arecchi", "authors": "Fortunato Tito Arecchi", "title": "Quantum entanglement in the Synchronization of Homoclinic Chaotic Spike\n  Sequences", "comments": "11 pages, three figures. arXiv admin note: substantial text overlap\n  with arXiv:1807.03174, arXiv:1506.00610", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physics deals with Newtonian particles described by position q and momentum\np. The precision of the simultaneous measurement of q and p is limited by the\nuncertainty relation ruled by Planck's constant. From the uncertainty relation\nall quantum consequences emerge, including entanglement. On the other hand,\nHomoclinic Chaos (HC) , that consists of sequences of identical pulses,\nunevenly spaced in time, entails a non-Newtonian description. Synchronization\nof finite HC spike sequences (SFSS) display quantum features ruled by a\nconstant different from hbar, yielding entanglement. As a relevant example, we\ndescribe how brain neurons generate HC voltage pulses. SFSS is the way two\ndifferent words coded as HC pulses compare their content and extract a\nmeaningful sequence by exploiting quantum entanglement that lasts over a\nde-coherence time in the range of human linguistic processes.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 18:24:03 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Arecchi", "Fortunato Tito", ""]]}, {"id": "2003.07394", "submitter": "Marco D'Alessandro", "authors": "Marco D'Alessandro, Stefan T. Radev, Andreas Voss, Luigi Lombardi", "title": "A Bayesian brain model of adaptive behavior: An application to the\n  Wisconsin Card Sorting Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Adaptive behavior emerges through a dynamic interaction between cognitive\nagents and changing environmental demands. The investigation of information\nprocessing underlying adaptive behavior relies on controlled experimental\nsettings in which individuals are asked to accomplish demanding tasks whereby a\nhidden state or an abstract rule has to be learned dynamically. Although\nperformance in such tasks is regularly considered as a proxy for measuring\nhigh-level cognitive processes, the standard approach consists in summarizing\nresponse patterns by simple heuristic scoring measures. With this work, we\npropose and validate a new computational Bayesian model accounting for\nindividual performance in the established Wisconsin Card Sorting Test. We embed\nthe new model within the mathematical framework of Bayesian Brain Theory,\naccording to which beliefs about the hidden environmental states are\ndynamically updated following the logic of Bayesian inference. Our\ncomputational model maps distinct cognitive processes into separable,\nneurobiologically plausible, information-theoretic constructs underlying\nobserved response patterns. We assess model identification and expressiveness\nin accounting for meaningful human performance through extensive simulation\nstudies. We further apply the model to real behavioral data in order to\nhighlight the utility of the proposed model in recovering cognitive dynamics at\nan individual level. Practical and theoretical implications of our\ncomputational modeling approach for clinical and cognitive neuroscience\nresearch are finally discussed, as well as potential future improvements.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:25:51 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2020 21:29:39 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["D'Alessandro", "Marco", ""], ["Radev", "Stefan T.", ""], ["Voss", "Andreas", ""], ["Lombardi", "Luigi", ""]]}, {"id": "2003.07405", "submitter": "Yuzhen Qin", "authors": "Yuzhen Qin, Ming Cao, Brian D.O. Anderson, Danielle S. Bassett, Fabio\n  Pasqualetti", "title": "Mediated Remote Synchronization of Kuramoto-Sakaguchi Oscillators: the\n  Number of Mediators Matters", "comments": null, "journal-ref": null, "doi": "10.1109/LCSYS.2020.3005449", "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical regions without direct neuronal connections have been observed to\nexhibit synchronized dynamics. A recent empirical study has further revealed\nthat such regions that share more common neighbors are more likely to behave\ncoherently. To analytically investigate the underlying mechanisms, we consider\nthat a set of n oscillators, which have no direct connections, are linked\nthrough m intermediate oscillators (called mediators), forming a complete\nbipartite network structure. Modeling the oscillators by the Kuramoto-Sakaguchi\nmodel, we rigorously prove that mediated remote synchronization, i.e.,\nsynchronization between those n oscillators that are not directly connected,\nbecomes more robust as the number of mediators increases. Simulations are also\ncarried out to show that our theoretical findings can be applied to other\ngeneral and complex networks.\n", "versions": [{"version": "v1", "created": "Mon, 16 Mar 2020 18:51:58 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 16:56:29 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Qin", "Yuzhen", ""], ["Cao", "Ming", ""], ["Anderson", "Brian D. O.", ""], ["Bassett", "Danielle S.", ""], ["Pasqualetti", "Fabio", ""]]}, {"id": "2003.07689", "submitter": "Bradly Alicea", "authors": "Stefan Dvoretskii, Ziyi Gong, Ankit Gupta, Jesse Parent, and Bradly\n  Alicea", "title": "Braitenberg Vehicles as Developmental Neurosimulation", "comments": "32 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The connection between brain and behavior is a longstanding issue in the\nareas of behavioral science, artificial intelligence, and neurobiology.\nParticularly in artificial intelligence research, behavior is generated by a\nblack box approximating the brain. As is standard among models of artificial\nand biological neural networks, an analogue of the fully mature brain is\npresented as a blank slate. This model generates outputs and behaviors from a\npriori associations, yet this does not consider the realities of biological\ndevelopment and developmental learning. Our purpose is to model the development\nof an artificial organism that exhibits complex behaviors. We will introduce\nour approach, which is to use Braitenberg Vehicles (BVs) to model the\ndevelopment of an artificial nervous system. The resulting developmental BVs\nwill generate behaviors that range from stimulus responses to group behavior\nthat resembles collective motion. Next, we will situate this work in the domain\nof artificial brain networks. Then we will focus on broader themes such as\nembodied cognition, feedback, and emergence. Our perspective will then be\nexemplified by three software instantiations that demonstrate how a BV-genetic\nalgorithm hybrid model, multisensory Hebbian learning model, and multi-agent\napproaches can be used to approach BV development. We introduce use cases such\nas optimized spatial cognition (vehicle-genetic algorithm hybrid model), hinges\nconnecting behavioral and neural models (multisensory Hebbian learning model),\nand cumulative classification (multi-agent approaches). In conclusion, we will\nrevisit concepts related to our approach and how they might guide future\ndevelopment.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2020 05:00:44 GMT"}], "update_date": "2020-03-18", "authors_parsed": [["Dvoretskii", "Stefan", ""], ["Gong", "Ziyi", ""], ["Gupta", "Ankit", ""], ["Parent", "Jesse", ""], ["Alicea", "Bradly", ""]]}, {"id": "2003.08278", "submitter": "Shi Gu", "authors": "Shikuang Deng, Shi Gu", "title": "Controllability Analysis of Functional Brain Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network control theory has recently emerged as a promising approach for\nunderstanding brain function and dynamics. By operationalizing notions of\ncontrol theory for brain networks, it offers a fundamental explanation for how\nbrain dynamics may be regulated by structural connectivity. While powerful, the\napproach does not currently consider other non-structural explanations of brain\ndynamics. Here we extend the analysis of network controllability by formalizing\nthe evolution of neural signals as a function of effective inter-regional\ncoupling and pairwise signal covariance. We find that functional\ncontrollability characterizes a region's impact on the capacity for the whole\nsystem to shift between states, and significantly predicts individual\ndifference in performance on cognitively demanding tasks including those task\nworking memory, language, and emotional intelligence. When comparing\nmeasurements from functional and structural controllability, we observed\nconsistent relations between average and modal controllability, supporting\nprior work. In the same comparison, we also observed distinct relations between\ncontrollability and synchronizability, reflecting the additional information\nobtained from functional signals. Our work suggests that network control theory\ncan serve as a systematic analysis tool to understand the energetics of brain\nstate transitions, associated cognitive processes, and subsequent behaviors.\n", "versions": [{"version": "v1", "created": "Wed, 18 Mar 2020 15:36:39 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Deng", "Shikuang", ""], ["Gu", "Shi", ""]]}, {"id": "2003.08556", "submitter": "Donghuan Lu", "authors": "Donghuan Lu, Sujun Zhao, Peng Xie, Kai Ma, Lijuan Liu, Yefeng Zheng", "title": "Quality Control of Neuron Reconstruction Based on Deep Learning", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuron reconstruction is essential to generate exquisite neuron connectivity\nmap for understanding brain function. Despite the significant amount of effect\nthat has been made on automatic reconstruction methods, manual tracing by\nwell-trained human annotators is still necessary. To ensure the quality of\nreconstructed neurons and provide guidance for annotators to improve their\nefficiency, we propose a deep learning based quality control method for neuron\nreconstruction in this paper. By formulating the quality control problem into a\nbinary classification task regarding each single point, the proposed approach\novercomes the technical difficulties resulting from the large image size and\ncomplex neuron morphology. Not only it provides the evaluation of\nreconstruction quality, but also can locate exactly where the wrong tracing\nbegins. This work presents one of the first comprehensive studies for\nwhole-brain scale quality control of neuron reconstructions. Experiments on\nfive-fold cross validation with a large dataset demonstrate that the proposed\napproach can detect 74.7% errors with only 1.4% false alerts.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 03:44:29 GMT"}], "update_date": "2020-03-20", "authors_parsed": [["Lu", "Donghuan", ""], ["Zhao", "Sujun", ""], ["Xie", "Peng", ""], ["Ma", "Kai", ""], ["Liu", "Lijuan", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2003.09389", "submitter": "Anirban Das", "authors": "Anirban Das, Manfred Denker, Anna Levina and Lucia Tabacu", "title": "Estimations by stable motions and applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST math.PR q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a nonparametric parameter estimation of confidence intervals when\nthe underlying has large or infinite variance. We explain the method by a\nsimple numerical example and provide an application to estimate the coupling\nstrength in neuronal networks.\n", "versions": [{"version": "v1", "created": "Fri, 20 Mar 2020 16:57:16 GMT"}], "update_date": "2020-03-23", "authors_parsed": [["Das", "Anirban", ""], ["Denker", "Manfred", ""], ["Levina", "Anna", ""], ["Tabacu", "Lucia", ""]]}, {"id": "2003.09976", "submitter": "Connor Brennan", "authors": "Connor Brennan and Alex Proekt", "title": "LOOPER: Inferring computational algorithms enacted by neuronal\n  population dynamics", "comments": "82 pages, 5 figures, 9 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recording simultaneous activity of hundreds of neurons is now possible.\nExisting methods can model such population activity, but do not directly reveal\nthe computations used by the brain. We present a fully unsupervised method that\nmodels neuronal activity and reveals the computational strategy. The method\nconstructs a topological model of neuronal dynamics consisting of\ninterconnected loops. Transitions between loops mark computationally-salient\ndecisions. We accurately model activation of 100s of neurons in the primate\ncortex during a working memory task. Dynamics of a recurrent neural network\n(RNN) trained on the same task are topologically identical suggesting that a\nsimilar computational strategy is used. The RNN trained on a modified dataset,\nhowever, reveals a different topology. This topology predicts specific novel\nstimuli that consistently elicit incorrect responses with near perfect\naccuracy. Thus, our methodology yields a quantitative model of neuronal\nactivity and reveals the computational strategy used to solve the task.\n", "versions": [{"version": "v1", "created": "Sun, 22 Mar 2020 19:44:19 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Brennan", "Connor", ""], ["Proekt", "Alex", ""]]}, {"id": "2003.10073", "submitter": "Hideyoshi Yanagisawa", "authors": "Hideyoshi Yanagisawa", "title": "Information-Theoretic Free Energy as Emotion Potential: Emotional\n  Valence as a Function of Complexity and Novelty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study extends the mathematical model of emotion dimensions that we\npreviously proposed (Yanagisawa, et al. 2019, Front Comput Neurosci) to\nconsider perceived complexity as well as novelty, as a source of arousal\npotential. Berlyne's hedonic function of arousal potential (or the inverse\nU-shaped curve, the so-called Wundt curve) is assumed. We modeled the arousal\npotential as information contents to be processed in the brain after sensory\nstimuli are perceived (or recognized), which we termed sensory surprisal. We\nmathematically demonstrated that sensory surprisal represents free energy, and\nit is equivalent to a summation of information gain (or information from\nnovelty) and perceived complexity (or information from complexity), which are\nthe collative variables forming the arousal potential. We demonstrated\nempirical evidence with visual stimuli (profile shapes of butterfly) supporting\nthe hypothesis that the summation of perceived novelty and complexity shapes\nthe inverse U-shaped beauty function. We discussed the potential of free energy\nas a mathematical principle explaining emotion initiators.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 04:10:23 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Yanagisawa", "Hideyoshi", ""]]}, {"id": "2003.10212", "submitter": "Jerrin Thomas Panachakel", "authors": "Jerrin Thomas Panachakel, Nandagopal Netrakanti Vinayak, Maanvi Nunna,\n  A.G. Ramakrishnan and Kanishka Sharma", "title": "An Improved EEG Acquisition Protocol Facilitates Localized Neural\n  Activation", "comments": "Preprint of the paper presented at ComNet 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work proposes improvements in the electroencephalogram (EEG) recording\nprotocols for motor imagery through the introduction of actual motor movement\nand/or somatosensory cues. The results obtained demonstrate the advantage of\nrequiring the subjects to perform motor actions following the trials of\nimagery. By introducing motor actions in the protocol, the subjects are able to\nperform actual motor planning, rather than just visualizing the motor movement,\nthus greatly improving the ease with which the motor movements can be imagined.\nThis study also probes the added advantage of administering somatosensory cues\nin the subject, as opposed to the conventional auditory/visual cues. These\nchanges in the protocol show promise in terms of the aptness of the spatial\nfilters obtained on the data, on application of the well-known common spatial\npattern (CSP) algorithms. The regions highlighted by the spatial filters are\nmore localized and consistent across the subjects when the protocol is\naugmented with somatosensory stimuli. Hence, we suggest that this may prove to\nbe a better EEG acquisition protocol for detecting brain activation in response\nto intended motor commands in (clinically) paralyzed/locked-in patients.\n", "versions": [{"version": "v1", "created": "Fri, 13 Mar 2020 04:46:40 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Panachakel", "Jerrin Thomas", ""], ["Vinayak", "Nandagopal Netrakanti", ""], ["Nunna", "Maanvi", ""], ["Ramakrishnan", "A. G.", ""], ["Sharma", "Kanishka", ""]]}, {"id": "2003.10433", "submitter": "Jerrin Thomas Panachakel", "authors": "Jerrin Thomas Panachakel, A.G. Ramakrishnan and A.G. Ramakrishnan", "title": "Decoding Imagined Speech using Wavelet Features and Deep Neural Networks", "comments": "Preprint of the paper presented in 2019 IEEE 16th India Council\n  International Conference (INDICON). arXiv admin note: substantial text\n  overlap with arXiv:2003.09374", "journal-ref": null, "doi": "10.1109/INDICON47234.2019.9028925", "report-no": null, "categories": "q-bio.NC cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel approach that uses deep neural networks for\nclassifying imagined speech, significantly increasing the classification\naccuracy. The proposed approach employs only the EEG channels over specific\nareas of the brain for classification, and derives distinct feature vectors\nfrom each of those channels. This gives us more data to train a classifier,\nenabling us to use deep learning approaches. Wavelet and temporal domain\nfeatures are extracted from each channel. The final class label of each test\ntrial is obtained by applying a majority voting on the classification results\nof the individual channels considered in the trial. This approach is used for\nclassifying all the 11 prompts in the KaraOne dataset of imagined speech. The\nproposed architecture and the approach of treating the data have resulted in an\naverage classification accuracy of 57.15%, which is an improvement of around\n35% over the state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 19 Mar 2020 00:36:19 GMT"}], "update_date": "2020-03-24", "authors_parsed": [["Panachakel", "Jerrin Thomas", ""], ["Ramakrishnan", "A. G.", ""], ["Ramakrishnan", "A. G.", ""]]}, {"id": "2003.10514", "submitter": "Yujiang Wang", "authors": "Yujiang Wang, Tobias Ludwig, Bethany Little, Joe H Necus, Gavin\n  Winston, Sjoerd B Vos, Jane de Tisi, John S Duncan, Peter N Taylor, Bruno\n  Mota", "title": "Independent components of human brain morphology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.app-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantification of brain morphology has become an important cornerstone in\nunderstanding brain structure. Measures of cortical morphology such as\nthickness and surface area are frequently used to compare groups of subjects or\ncharacterise longitudinal changes. However, such measures are often treated as\nindependent from each other.\n  A recently described scaling law, derived from a statistical physics model of\ncortical folding, demonstrates that there is a tight covariance between three\ncommonly used cortical morphology measures: cortical thickness, total surface\narea, and exposed surface area.\n  We show that assuming the independence of cortical morphology measures can\nhide features and potentially lead to misinterpretations. Using the scaling\nlaw, we account for the covariance between cortical morphology measures and\nderive novel independent measures of cortical morphology. By applying these new\nmeasures, we show that new information can be gained; in our example we show\nthat distinct morphological alterations underlie healthy ageing compared to\ntemporal lobe epilepsy, even on the coarse level of a whole hemisphere.\n  We thus provide a conceptual framework for characterising cortical morphology\nin a statistically valid and interpretable manner, based on theoretical\nreasoning about the shape of the cortex.\n", "versions": [{"version": "v1", "created": "Mon, 23 Mar 2020 19:53:48 GMT"}], "update_date": "2020-03-25", "authors_parsed": [["Wang", "Yujiang", ""], ["Ludwig", "Tobias", ""], ["Little", "Bethany", ""], ["Necus", "Joe H", ""], ["Winston", "Gavin", ""], ["Vos", "Sjoerd B", ""], ["de Tisi", "Jane", ""], ["Duncan", "John S", ""], ["Taylor", "Peter N", ""], ["Mota", "Bruno", ""]]}, {"id": "2003.11013", "submitter": "Pietro Astolfi", "authors": "Pietro Astolfi, Ruben Verhagen, Laurent Petit, Emanuele Olivetti,\n  Jonathan Masci, Davide Boscaini, Paolo Avesani", "title": "Tractogram filtering of anatomically non-plausible fibers with geometric\n  deep learning", "comments": "Accepted at MICCAI2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tractograms are virtual representations of the white matter fibers of the\nbrain. They are of primary interest for tasks like presurgical planning, and\ninvestigation of neuroplasticity or brain disorders. Each tractogram is\ncomposed of millions of fibers encoded as 3D polylines. Unfortunately, a large\nportion of those fibers are not anatomically plausible and can be considered\nartifacts of the tracking algorithms. Common methods for tractogram filtering\nare based on signal reconstruction, a principled approach, but unable to\nconsider the knowledge of brain anatomy. In this work, we address the problem\nof tractogram filtering as a supervised learning problem by exploiting the\nground truth annotations obtained with a recent heuristic method, which labels\nfibers as either anatomically plausible or non-plausible according to\nwell-established anatomical properties. The intuitive idea is to model a fiber\nas a point cloud and the goal is to investigate whether and how a geometric\ndeep learning model might capture its anatomical properties. Our contribution\nis an extension of the Dynamic Edge Convolution model that exploits the\nsequential relations of points in a fiber and discriminates with high accuracy\nplausible/non-plausible fibers.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 17:56:44 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2020 13:57:11 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Astolfi", "Pietro", ""], ["Verhagen", "Ruben", ""], ["Petit", "Laurent", ""], ["Olivetti", "Emanuele", ""], ["Masci", "Jonathan", ""], ["Boscaini", "Davide", ""], ["Avesani", "Paolo", ""]]}, {"id": "2003.11075", "submitter": "Juan Luis Villarreal-Haro", "authors": "Juan Luis Villarreal-Haro, Alonso Ramirez-Manzanares, and Juan Antonio\n  Pichardo-Corpus", "title": "A Novel Metric Shows the Robustness of the Graph Communities to\n  Brain-Tractography False-Positives", "comments": "Small abstract to ISMRM-2019. Jaccard Index Generalization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the impact of the brain tractography false positives in the brain\nconnectivity graphs. The representative input database for the analysis is the\nset of tractograms from the participants on the ISMRM-2015 Tractography\nChallenge. We propose 2 novel metrics to rank the quality of a tractogram when\nit is compared with known ground truth. The results of this study indicate that\nthe estimation of graph communities is robust to high levels of overestimation\nin the connectivity.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 19:03:46 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Villarreal-Haro", "Juan Luis", ""], ["Ramirez-Manzanares", "Alonso", ""], ["Pichardo-Corpus", "Juan Antonio", ""]]}, {"id": "2003.11147", "submitter": "David Holcman", "authors": "Alexis Tricot, Igor M. Sokolov, and David Holcman", "title": "Voltage distribution in a non-locally but globally electroneutral\n  confined electrolyte medium: applications for nanophysiology", "comments": "8 figs, 36 poages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.soft math.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The distribution of voltage in sub-micron cellular domains remains poorly\nunderstood. In neurons, the voltage results from the difference in ionic\nconcentrations which are continuously maintained by pumps and exchangers.\nHowever, it not clear how electro-neutrality could be maintained by an excess\nof fast moving positive ions that should be counter balanced by slow diffusing\nnegatively charged proteins. Using the theory of electro-diffusion, we study\nhere the voltage distribution in a generic domain, which consists of two\nconcentric disks (resp. ball) in two (resp. three) dimensions, where a negative\ncharge is fixed in the inner domain. When global but not local\nelectro-neutrality is maintained, we solve the Poisson-Nernst-Planck equation\nboth analytically and numerically in dimension 1 (flat) and 2 (cylindrical) and\nfound that the voltage changes considerably on a spatial scale which is much\nlarger than the Debye screening length, which assumes electro-neutrality. The\npresent result suggests that long-range voltage drop changes are expected in\nneuronal microcompartments, probably relevant to explain the activation of far\naway voltage-gated channels located on the surface.\n", "versions": [{"version": "v1", "created": "Tue, 24 Mar 2020 23:23:29 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Tricot", "Alexis", ""], ["Sokolov", "Igor M.", ""], ["Holcman", "David", ""]]}, {"id": "2003.11325", "submitter": "Sang-Yoon  Kim", "authors": "Sang-Yoon Kim and Woochang Lim", "title": "Effect of Diverse Recoding of Granule Cells on Optokinetic Response in A\n  Cerebellar Ring Network with Synaptic Plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a cerebellar ring network for the optokinetic response (OKR), and\ninvestigate the effect of diverse recoding of granule (GR) cells on OKR by\nvarying the connection probability $p_c$ from Golgi to GR cells. For an optimal\nvalue of $p_c^*~(=0.06)$, individual GR cells exhibit diverse spiking patterns\nwhich are in-phase, anti-phase, or complex out-of-phase with respect to their\npopulation-averaged firing activity. Then, these diversely-recoded signals via\nparallel fibers (PFs) from GR cells are effectively depressed by the\nerror-teaching signals via climbing fibers from the inferior olive which are\nalso in-phase ones. Synaptic weights at in-phase PF-Purkinje cell (PC) synapses\nof active GR cells are strongly depressed via strong long-term depression\n(LTD), while those at anti-phase and complex out-of-phase PF-PC synapses are\nweakly depressed through weak LTD. This kind of \"effective\" depression (i.e.,\nstrong/weak LTD) at the PF-PC synapses causes a big modulation in firings of\nPCs, which then exert effective inhibitory coordination on the vestibular\nnucleus (VN) neuron (which evokes OKR). For the firing of the VN neuron, the\nlearning gain degree ${\\cal{L}}_g$, corresponding to the modulation gain ratio,\nincreases with increasing the learning cycle, and it saturates at about the\n300th cycle. By varying $p_c$ from $p_c^*$, we find that a plot of saturated\nlearning gain degree ${\\cal L}_g^*$ versus $p_c$ forms a bell-shaped curve with\na peak at $p_c^*$ (where the diversity degree in spiking patterns of GR cells\nis also maximum). Consequently, the more diverse in recoding of GR cells, the\nmore effective in motor learning for the OKR adaptation.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:10:18 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2020 13:16:54 GMT"}, {"version": "v3", "created": "Wed, 5 Aug 2020 10:09:42 GMT"}, {"version": "v4", "created": "Tue, 11 Aug 2020 01:59:15 GMT"}], "update_date": "2020-08-12", "authors_parsed": [["Kim", "Sang-Yoon", ""], ["Lim", "Woochang", ""]]}, {"id": "2003.11328", "submitter": "Alejandro Tabas", "authors": "Alejandro Tabas, Glad Mihai, Stefan Kiebel, Robert Trampel, and\n  Katharina von Kriegstein", "title": "Predictive coding underlies adaptation in the subcortical sensory\n  pathway", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The subcortical sensory pathways are the fundamental channels for mapping the\noutside world to our minds. Sensory pathways efficiently transmit information\nby adapting neural responses to the local statistics of the sensory input. The\nlongstanding mechanistic explanation for this adaptive behaviour is that\nneuronal habituation scales activity to the local statistics of the stimuli. An\nalternative account is that neural coding is directly driven by expectations of\nthe sensory input. Here we used abstract rules to manipulate expectations\nindependently of local stimulus statistics. The ultra-high-field functional-MRI\ndata show that expectations, and not habituation, are the main driver of the\nresponse amplitude to tones in the human auditory pathway. These results\nprovide first unambiguous evidence of predictive coding and abstract processing\nin a subcortical sensory pathway, indicating that the brain only holds\nsubjective representations of the outside world even at initial points of the\nprocessing hierarchy.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 11:14:56 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["Tabas", "Alejandro", ""], ["Mihai", "Glad", ""], ["Kiebel", "Stefan", ""], ["Trampel", "Robert", ""], ["von Kriegstein", "Katharina", ""]]}, {"id": "2003.11388", "submitter": "Mattia Lorenzo DiFrancesco Dr.", "authors": "Mattia L. DiFrancesco, Elisabetta Colombo, Ermanno D. Papaleo, Jos\\'e\n  Fernando Maya-Vetencourt, Giovanni Manfredi, Guglielmo Lanzani, Fabio\n  Benfenati", "title": "A hybrid P3HT-Graphene interface for efficient photostimulation of\n  neurons", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": "10.1016/j.carbon.2020.02.0430008-6223/2020", "report-no": null, "categories": "q-bio.NC physics.bio-ph q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphene conductive properties have been long exploited in the field of\norganic photovoltaics and optoelectronics by the scientific community\nworldwide. We engineered and characterized a hybrid biointerface in which\ngraphene is coupled with photosensitive polymers, and tested its ability to\nelicit lighttriggered neural activity modulation in primary neurons and blind\nretina explants. We designed such a graphene-based device by modifying a\nphotoactive P3HT-based retinal interface, previously reported to rescue light\nsensitivity in blind rodents, with a CVD graphene layer replacing the\nconductive PEDOT:PSS layer to enhance charge separation. The new graphene-based\ndevice was characterized for its electrochemical features and for the ability\nto photostimulate primary neurons and blind retina explants, while preserving\nbiocompatibility. Light-triggered responses, recorded by patch-clamp in vitro\nor MEA ex vivo, show a stronger light-transduction efficiency when the neurons\nare interfaced with the graphene-based device with respect to the\nPEDOT:PSS-based one. The possibility to ameliorate flexible photo-stimulating\ndevices via the insertion of graphene, paves the way for potential biomedical\napplications of graphenebased neuronal interfaces in the context of retinal\nimplants.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 13:23:39 GMT"}], "update_date": "2020-03-26", "authors_parsed": [["DiFrancesco", "Mattia L.", ""], ["Colombo", "Elisabetta", ""], ["Papaleo", "Ermanno D.", ""], ["Maya-Vetencourt", "Jos\u00e9 Fernando", ""], ["Manfredi", "Giovanni", ""], ["Lanzani", "Guglielmo", ""], ["Benfenati", "Fabio", ""]]}, {"id": "2003.11640", "submitter": "Xavier Hinaut", "authors": "Anthony Strock (Mnemosyne, LaBRI, IMN), Nicolas Rougier (Mnemosyne,\n  LaBRI, IMN), Xavier Hinaut (Mnemosyne, LaBRI, IMN)", "title": "Transfer between long-term and short-term memory using Conceptors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG nlin.AO q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a recurrent neural network model of working memory combining\nshort-term and long-term components. e short-term component is modelled using a\ngated reservoir model that is trained to hold a value from an input stream when\na gate signal is on. e long-term component is modelled using conceptors in\norder to store inner temporal patterns (that corresponds to values). We combine\nthese two components to obtain a model where information can go from long-term\nmemory to short-term memory and vice-versa and we show how standard operations\non conceptors allow to combine long-term memories and describe their effect on\nshort-term memory.\n", "versions": [{"version": "v1", "created": "Wed, 11 Mar 2020 09:13:58 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Strock", "Anthony", "", "Mnemosyne, LaBRI, IMN"], ["Rougier", "Nicolas", "", "Mnemosyne,\n  LaBRI, IMN"], ["Hinaut", "Xavier", "", "Mnemosyne, LaBRI, IMN"]]}, {"id": "2003.11660", "submitter": "Eli Shlizerman", "authors": "Yang Zheng, Eli Shlizerman", "title": "R-FORCE: Robust Learning for Random Recurrent Neural Networks", "comments": "Github Repository: https://github.com/shlizee/R-FORCE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random Recurrent Neural Networks (RRNN) are the simplest recurrent networks\nto model and extract features from sequential data. The simplicity however\ncomes with a price; RRNN are known to be susceptible to diminishing/exploding\ngradient problem when trained with gradient-descent based optimization. To\nenhance robustness of RRNN, alternative training approaches have been proposed.\nSpecifically, FORCE learning approach proposed a recursive least squares\nalternative to train RRNN and was shown to be applicable even for the\nchallenging task of target-learning, where the network is tasked with\ngenerating dynamic patterns with no guiding input. While FORCE training\nindicates that solving target-learning is possible, it appears to be effective\nonly in a specific regime of network dynamics (edge-of-chaos). We thereby\ninvestigate whether initialization of RRNN connectivity according to a tailored\ndistribution can guarantee robust FORCE learning. We are able to generate such\ndistribution by inference of four generating principles constraining the\nspectrum of the network Jacobian to remain in stability region. This\ninitialization along with FORCE learning provides a robust training method,\ni.e., Robust-FORCE (R-FORCE). We validate R-FORCE performance on various target\nfunctions for a wide range of network configurations and compare with\nalternative methods. Our experiments indicate that R-FORCE facilitates\nsignificantly more stable and accurate target-learning for a wide class of\nRRNN. Such stability becomes critical in modeling multi-dimensional sequences\nas we demonstrate on modeling time-series of human body joints during physical\nmovements.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 22:08:03 GMT"}], "update_date": "2020-03-28", "authors_parsed": [["Zheng", "Yang", ""], ["Shlizerman", "Eli", ""]]}, {"id": "2003.11668", "submitter": "Marc Howard", "authors": "Marc W. Howard and Michael E. Hasselmo", "title": "Cognitive computation using neural representations of time and space in\n  the Laplace domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory for the past makes use of a record of what happened when---a function\nover past time. Time cells in the hippocampus and temporal context cells in the\nentorhinal cortex both code for events as a function of past time, but with\nvery different receptive fields. Time cells in the hippocampus can be\nunderstood as a compressed estimate of events as a function of the past.\nTemporal context cells in the entorhinal cortex can be understood as the\nLaplace transform of that function, respectively. Other functional cell types\nin the hippocampus and related regions, including border cells, place cells,\ntrajectory coding, splitter cells, can be understood as coding for functions\nover space or past movements or their Laplace transforms. More abstract\nquantities, like distance in an abstract conceptual space or numerosity could\nalso be mapped onto populations of neurons coding for the Laplace transform of\nfunctions over those variables. Quantitative cognitive models of memory and\nevidence accumulation can also be specified in this framework allowing\nconstraints from both behavior and neurophysiology. More generally, the\ncomputational power of the Laplace domain could be important for efficiently\nimplementing data-independent operators, which could serve as a basis for\nneural models of a very broad range of cognitive computations.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 22:40:49 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Howard", "Marc W.", ""], ["Hasselmo", "Michael E.", ""]]}, {"id": "2003.11797", "submitter": "Kai Qiao", "authors": "Kai Qiao, Chi Zhang, Jian Chen, Linyuan Wang, Li Tong, Bin Yan", "title": "Neural encoding and interpretation for high-level visual cortices based\n  on fMRI using image caption features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On basis of functional magnetic resonance imaging (fMRI), researchers are\ndevoted to designing visual encoding models to predict the neuron activity of\nhuman in response to presented image stimuli and analyze inner mechanism of\nhuman visual cortices. Deep network structure composed of hierarchical\nprocessing layers forms deep network models by learning features of data on\nspecific task through big dataset. Deep network models have powerful and\nhierarchical representation of data, and have brought about breakthroughs for\nvisual encoding, while revealing hierarchical structural similarity with the\nmanner of information processing in human visual cortices. However, previous\nstudies almost used image features of those deep network models pre-trained on\nclassification task to construct visual encoding models. Except for deep\nnetwork structure, the task or corresponding big dataset is also important for\ndeep network models, but neglected by previous studies. Because image\nclassification is a relatively fundamental task, it is difficult to guide deep\nnetwork models to master high-level semantic representations of data, which\ncauses into that encoding performance for high-level visual cortices is\nlimited. In this study, we introduced one higher-level vision task: image\ncaption (IC) task and proposed the visual encoding model based on IC features\n(ICFVEM) to encode voxels of high-level visual cortices. Experiment\ndemonstrated that ICFVEM obtained better encoding performance than previous\ndeep network models pre-trained on classification task. In addition, the\ninterpretation of voxels was realized to explore the detailed characteristics\nof voxels based on the visualization of semantic words, and comparative\nanalysis implied that high-level visual cortices behaved the correlative\nrepresentation of image content.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 08:47:21 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Qiao", "Kai", ""], ["Zhang", "Chi", ""], ["Chen", "Jian", ""], ["Wang", "Linyuan", ""], ["Tong", "Li", ""], ["Yan", "Bin", ""]]}, {"id": "2003.11859", "submitter": "Chiara De Luca", "authors": "Bruno Golosio, Chiara De Luca, Cristiano Capone, Elena Pastorelli,\n  Giovanni Stegel, Gianmarco Tiddia, Giulia De Bonis and Pier Stanislao\n  Paolucci", "title": "Thalamo-cortical spiking model of incremental learning combining\n  perception, context and NREM-sleep-mediated noise-resilience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain exhibits capabilities of fast incremental learning from few noisy\nexamples, as well as the ability to associate similar memories in\nautonomously-created categories and to combine contextual hints with sensory\nperceptions. Together with sleep, these mechanisms are thought to be key\ncomponents of many high-level cognitive functions. Yet, little is known about\nthe underlying processes and the specific roles of different brain states. In\nthis work, we exploited the combination of context and perception in a\nthalamo-cortical model based on a soft winner-take-all circuit of excitatory\nand inhibitory spiking neurons. After calibrating this model to express awake\nand deep-sleep states with features comparable with biological measures, we\ndemonstrate the model capability of fast incremental learning from few\nexamples, its resilience when proposed with noisy perceptions and contextual\nsignals, and an improvement in visual classification after sleep due to induced\nsynaptic homeostasis and association of similar memories.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 12:18:35 GMT"}, {"version": "v2", "created": "Tue, 26 Jan 2021 07:42:16 GMT"}, {"version": "v3", "created": "Fri, 19 Mar 2021 10:30:45 GMT"}], "update_date": "2021-03-22", "authors_parsed": [["Golosio", "Bruno", ""], ["De Luca", "Chiara", ""], ["Capone", "Cristiano", ""], ["Pastorelli", "Elena", ""], ["Stegel", "Giovanni", ""], ["Tiddia", "Gianmarco", ""], ["De Bonis", "Giulia", ""], ["Paolucci", "Pier Stanislao", ""]]}, {"id": "2003.11864", "submitter": "Meltem Civas", "authors": "Ozgur B. Akan, Hamideh Ramezani, Meltem Civas, Oktay Cetinkaya,\n  Bilgesu A. Bilgin, Naveed A. Abbasi", "title": "Information and Communication Theoretical Understanding and Treatment of\n  Spinal Cord Injuries: State-of-the-art and Research Challenges", "comments": "IEEE Reviews in Biomedical Engineering", "journal-ref": null, "doi": "10.1109/RBME.2021.3056455", "report-no": null, "categories": "q-bio.NC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the various key networks in the human body, the nervous system occupies\ncentral importance. The debilitating effects of spinal cord injuries (SCI)\nimpact a significant number of people throughout the world, and to date, there\nis no satisfactory method to treat them. In this paper, we review the major\ntreatment techniques for SCI that include promising solutions based on\ninformation and communication technology (ICT) and identify the key\ncharacteristics of such systems. We then introduce two novel ICT-based\ntreatment approaches for SCI. The first proposal is based on neural interface\nsystems (NIS) with enhanced feedback, where the external machines are\ninterfaced with the brain and the spinal cord such that the brain signals are\ndirectly routed to the limbs for movement. The second proposal relates to the\ndesign of self-organizing artificial neurons (ANs) that can be used to replace\nthe injured or dead biological neurons. Apart from SCI treatment, the proposed\nmethods may also be utilized as enabling technologies for neural interface\napplications by acting as bio-cyber interfaces between the nervous system and\nmachines. Furthermore, under the framework of Internet of Bio- Nano Things\n(IoBNT), experience gained from SCI treatment techniques can be transferred to\nnano communication research.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 12:32:46 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 16:50:07 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Akan", "Ozgur B.", ""], ["Ramezani", "Hamideh", ""], ["Civas", "Meltem", ""], ["Cetinkaya", "Oktay", ""], ["Bilgin", "Bilgesu A.", ""], ["Abbasi", "Naveed A.", ""]]}, {"id": "2003.11996", "submitter": "Johannes Schemmel", "authors": "Johannes Schemmel, Sebastian Billaudelle, Phillip Dauer, Johannes Weis", "title": "Accelerated Analog Neuromorphic Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the concepts behind the BrainScales (BSS) accelerated\nanalog neuromorphic computing architecture. It describes the second-generation\nBrainScales-2 (BSS-2) version and its most recent in-silico realization, the\nHICANN-X Application Specific Integrated Circuit (ASIC), as it has been\ndeveloped as part of the neuromorphic computing activities within the European\nHuman Brain Project (HBP). While the first generation is implemented in an\n180nm process, the second generation uses 65nm technology. This allows the\nintegration of a digital plasticity processing unit, a highly-parallel micro\nprocessor specially built for the computational needs of learning in an\naccelerated analog neuromorphic systems. The presented architecture is based\nupon a continuous-time, analog, physical model implementation of neurons and\nsynapses, resembling an analog neuromorphic accelerator attached to build-in\ndigital compute cores. While the analog part emulates the spike-based dynamics\nof the neural network in continuous-time, the latter simulates biological\nprocesses happening on a slower time-scale, like structural and parameter\nchanges. Compared to biological time-scales, the emulation is highly\naccelerated, i.e. all time-constants are several orders of magnitude smaller\nthan in biology. Programmable ion channel emulation and inter-compartmental\nconductances allow the modeling of nonlinear dendrites, back-propagating\naction-potentials as well as NMDA and Calcium plateau potentials. To extend the\nusability of the analog accelerator, it also supports vector-matrix\nmultiplication. Thereby, BSS-2 supports inference of deep convolutional\nnetworks as well as local-learning with complex ensembles of spiking neurons\nwithin the same substrate.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 16:00:55 GMT"}], "update_date": "2020-03-27", "authors_parsed": [["Schemmel", "Johannes", ""], ["Billaudelle", "Sebastian", ""], ["Dauer", "Phillip", ""], ["Weis", "Johannes", ""]]}, {"id": "2003.12128", "submitter": "Ruben van Bergen", "authors": "Ruben S. van Bergen, Nikolaus Kriegeskorte", "title": "Going in circles is the way forward: the role of recurrence in visual\n  inference", "comments": null, "journal-ref": null, "doi": "10.1016/j.conb.2020.11.009", "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biological visual systems exhibit abundant recurrent connectivity.\nState-of-the-art neural network models for visual recognition, by contrast,\nrely heavily or exclusively on feedforward computation. Any finite-time\nrecurrent neural network (RNN) can be unrolled along time to yield an\nequivalent feedforward neural network (FNN). This important insight suggests\nthat computational neuroscientists may not need to engage recurrent\ncomputation, and that computer-vision engineers may be limiting themselves to a\nspecial case of FNN if they build recurrent models. Here we argue, to the\ncontrary, that FNNs are a special case of RNNs and that computational\nneuroscientists and engineers should engage recurrence to understand how brains\nand machines can (1) achieve greater and more flexible computational depth, (2)\ncompress complex computations into limited hardware, (3) integrate priors and\npriorities into visual inference through expectation and attention, (4) exploit\nsequential dependencies in their data for better inference and prediction, and\n(5) leverage the power of iterative computation.\n", "versions": [{"version": "v1", "created": "Thu, 26 Mar 2020 19:53:05 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2020 19:27:18 GMT"}, {"version": "v3", "created": "Mon, 16 Nov 2020 13:33:25 GMT"}], "update_date": "2020-12-09", "authors_parsed": [["van Bergen", "Ruben S.", ""], ["Kriegeskorte", "Nikolaus", ""]]}, {"id": "2003.12353", "submitter": "Naoya Arakawa", "authors": "Naoya Arakawa", "title": "Planning with Brain-inspired AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This article surveys engineering and neuroscientific models of planning as a\ncognitive function, which is regarded as a typical function of fluid\nintelligence in the discussion of general intelligence. It aims to present\nexisting planning models as references for realizing the planning function in\nbrain-inspired AI or artificial general intelligence (AGI). It also proposes\nthemes for the research and development of brain-inspired AI from the viewpoint\nof tasks and architecture.\n", "versions": [{"version": "v1", "created": "Wed, 25 Mar 2020 02:17:08 GMT"}], "update_date": "2020-03-30", "authors_parsed": [["Arakawa", "Naoya", ""]]}, {"id": "2003.12670", "submitter": "Michael Taynnan Barros", "authors": "Michael Taynnan Barros, Harun Siljak, Peter Mullen, Constantinos\n  Papadias, Jari Hyttinen and Nicola Marchetti", "title": "Objective Multi-variable Classification and Inference of Biological\n  Neuronal Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.OH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of biological neuron types and networks poses challenges to\nthe full understanding of the brain's organisation and functioning. In this\npaper, we develop a novel objective classification model of biological neuronal\ntypes and networks based on the communication metrics of neurons. This presents\nadvantages against the existing approaches since the mutual information or the\ndelay between neurons obtained from spike trains are more abundant data compare\nto conventional morphological data. We firstly designed two open-access\nsupporting computational platforms of various neuronal circuits from the Blue\nBrain Project realistic models, named Neurpy and Neurgen. Then we investigate\nhow the concept of network tomography could be achieved with cortical neuronal\ncircuits for morphological, topological and electrical classification of\nneurons. We extract the simulated data to many different classifiers (including\nSVM, Decision Trees, Random Forest, and Artificial Neuron Networks) classifying\nthe specific cell type (and sub-group types) achieving accuracies of up to\n70\\%. Inference of biological network structures using network tomography\nreached up to 65\\% of accuracy. We also analysed recall, precision and F1score\nof the classification of five layers, 25 cell m-types, and 14 cell e-types. Our\nresearch not only contributes to existing classification efforts but sets the\nroad-map for future usage of cellular-scaled brain-machine interfaces for\nin-vivo objective classification of neurons as a sensing mechanism of the\nbrain's structure.\n", "versions": [{"version": "v1", "created": "Sat, 28 Mar 2020 00:25:49 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Barros", "Michael Taynnan", ""], ["Siljak", "Harun", ""], ["Mullen", "Peter", ""], ["Papadias", "Constantinos", ""], ["Hyttinen", "Jari", ""], ["Marchetti", "Nicola", ""]]}, {"id": "2003.12928", "submitter": "Bingchuan Liu", "authors": "Bingchuan Liu, Xinyi Yan, Xiaogang Chen, Yijun Wang, and Xiaorong Gao", "title": "tACS Facilitates Flickering Driving by Boosting Steady-State Visual\n  Evoked Potentials", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has become of increasing interest in transcranial alternating current\nstimulation (tACS) since its inception nearly a decade ago. tACS in modulating\nbrain state is an active area of research and has been demonstrated effective\nin various neuropsychological and clinical domains. In the visual domain, much\neffort has been dedicated to brain rhythms and rhythmic stimulation, i.e.,\ntACS. However, little is known about the interplay between the rhythmic\nstimulation and visual stimulation. Here, we used steady-state visual evoked\npotential (SSVEP), induced by flickering driving as a widely used technique for\nfrequency-tagging, to investigate the aftereffect of tACS in healthy human\nsubjects. Seven blocks of 64-channel electroencephalogram were recorded before\nand after the administration of 20-min 10-Hz tACS, while subjects performed\nseveral blocks of SSVEP tasks. We characterized the physiological properties of\ntACS aftereffect by comparing and validating the temporal, spatial,\nspatiotemporal and signal-to-noise ratio (SNR) patterns between and within\nblocks in real tACS and sham tACS. Our result revealed that tACS boosted the\n10-Hz SSVEP significantly. Besides, the aftereffect on SSVEP was mitigated with\ntime and lasted up to 5 min. Our results demonstrate the feasibility of\nfacilitating the flickering driving by external rhythmic stimulation and open a\nnew possibility to alter the brain state in a direction by noninvasive\ntranscranial brain stimulation.\n", "versions": [{"version": "v1", "created": "Sun, 29 Mar 2020 02:37:13 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Liu", "Bingchuan", ""], ["Yan", "Xinyi", ""], ["Chen", "Xiaogang", ""], ["Wang", "Yijun", ""], ["Gao", "Xiaorong", ""]]}, {"id": "2003.13247", "submitter": "Nicolas Torres", "authors": "Delphine Salort (LCQB), Nicolas Torres (LJLL (UMR\\_7598))", "title": "Dynamics of neural networks with elapsed time model and learning\n  processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and study a new model of interacting neural networks,\nincorporating the spatial dimension (e.g. position of neurons across the\ncortex) and some learning processes. The dynamic of each neural network is\ndescribed via the elapsed time model, that is, the neurons are described by the\nelapsed time since their last discharge and the chosen learning processes are\nessentially inspired from the Hebbian rule. We then obtain a system of\nintegro-differential equations, from which we analyze the convergence to\nstationary states by the means of entropy method and Doeblin's theory in the\ncase of weak interconnections. We also consider the situation where neural\nactivity is faster than the learning process and give conditions where one can\napproximate the dynamics by a solution with a similar profile of a steady\nstate. For stronger interconnections, we present some numerical simulations to\nobserve how the parameters of the system can give different behaviors and\npattern formations.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 07:41:46 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2020 07:15:48 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Salort", "Delphine", "", "LCQB"], ["Torres", "Nicolas", "", "LJLL"]]}, {"id": "2003.13365", "submitter": "Alberto Vergani Dr", "authors": "Alberto Arturo Vergani and Christian Robert Huyck", "title": "Critical Limits in a Bump Attractor Network of Spiking Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE nlin.PS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A bump attractor network is a model that implements a competitive neuronal\nprocess emerging from a spike pattern related to an input source. Since the\nbump network could behave in many ways, this paper explores some critical\nlimits of the parameter space using various positive and negative weights and\nan increasing size of the input spike sources The neuromorphic simulation of\nthe bumpattractor network shows that it exhibits a stationary, a splitting and\na divergent spike pattern, in relation to different sets of weights and input\nwindows. The balance between the values of positive and negative weights is\nimportant in determining the splitting or diverging behaviour of the spike\ntrain pattern and in defining the minimal firing conditions.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 11:54:33 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Vergani", "Alberto Arturo", ""], ["Huyck", "Christian Robert", ""]]}, {"id": "2003.13825", "submitter": "Daniel Levenstein", "authors": "Daniel Levenstein, Veronica A. Alvarez, Asohan Amarasingham, Habiba\n  Azab, Richard C. Gerkin, Andrea Hasenstaub, Ramakrishnan Iyer, Renaud B.\n  Jolivet, Sarah Marzen, Joseph D. Monaco, Astrid A. Prinz, Salma Quraishi,\n  Fidel Santamaria, Sabyasachi Shivkumar, Matthew F. Singh, David B. Stockton,\n  Roger Traub, Horacio G. Rotstein, Farzan Nadim, A. David Redish", "title": "On the role of theory and modeling in neuroscience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, the field of neuroscience has gone through rapid\nexperimental advances and extensive use of quantitative and computational\nmethods. This accelerating growth has created a need for methodological\nanalysis of the role of theory and the modeling approaches currently used in\nthis field. Toward that end, we start from the general view that the primary\nrole of science is to solve empirical problems, and that it does so by\ndeveloping theories that can account for phenomena within their domain of\napplication. We propose a commonly-used set of terms - descriptive,\nmechanistic, and normative - as methodological designations that refer to the\nkind of problem a theory is intended to solve. Further, we find that models of\neach kind play distinct roles in defining and bridging the multiple levels of\nabstraction necessary to account for any neuroscientific phenomenon. We then\ndiscuss how models play an important role to connect theory and experiment, and\nnote the importance of well-defined translation functions between them.\nFurthermore, we describe how models themselves can be used as a form of\nexperiment to test and develop theories. This report is the summary of a\ndiscussion initiated at the conference Present and Future Theoretical\nFrameworks in Neuroscience, which we hope will contribute to a much-needed\ndiscussion in the neuroscientific community.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 21:21:59 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2020 12:40:28 GMT"}], "update_date": "2020-04-02", "authors_parsed": [["Levenstein", "Daniel", ""], ["Alvarez", "Veronica A.", ""], ["Amarasingham", "Asohan", ""], ["Azab", "Habiba", ""], ["Gerkin", "Richard C.", ""], ["Hasenstaub", "Andrea", ""], ["Iyer", "Ramakrishnan", ""], ["Jolivet", "Renaud B.", ""], ["Marzen", "Sarah", ""], ["Monaco", "Joseph D.", ""], ["Prinz", "Astrid A.", ""], ["Quraishi", "Salma", ""], ["Santamaria", "Fidel", ""], ["Shivkumar", "Sabyasachi", ""], ["Singh", "Matthew F.", ""], ["Stockton", "David B.", ""], ["Traub", "Roger", ""], ["Rotstein", "Horacio G.", ""], ["Nadim", "Farzan", ""], ["Redish", "A. David", ""]]}, {"id": "2003.13850", "submitter": "KongFatt Wong-Lin", "authors": "Ifeatu Ezenwe, Alok Joshi and KongFatt Wong-Lin", "title": "Genetic Algorithmic Parameter Optimisation of a Recurrent Spiking Neural\n  Network Model", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are complex algorithms that loosely model the behaviour of\nthe human brain. They play a significant role in computational neuroscience and\nartificial intelligence. The next generation of neural network models is based\non the spike timing activity of neurons: spiking neural networks (SNNs).\nHowever, model parameters in SNNs are difficult to search and optimise.\nPrevious studies using genetic algorithm (GA) optimisation of SNNs were focused\nmainly on simple, feedforward, or oscillatory networks, but not much work has\nbeen done on optimising cortex-like recurrent SNNs. In this work, we\ninvestigated the use of GAs to search for optimal parameters in recurrent SNNs\nto reach targeted neuronal population firing rates, e.g. as in experimental\nobservations. We considered a cortical column based SNN comprising 1000\nIzhikevich spiking neurons for computational efficiency and biologically\nrealism. The model parameters explored were the neuronal biased input currents.\nFirst, we found for this particular SNN, the optimal parameter values for\ntargeted population averaged firing activities, and the convergence of\nalgorithm by ~100 generations. We then showed that the GA optimal population\nsize was within ~16-20 while the crossover rate that returned the best fitness\nvalue was ~0.95. Overall, we have successfully demonstrated the feasibility of\nimplementing GA to optimise model parameters in a recurrent cortical based SNN.\n", "versions": [{"version": "v1", "created": "Mon, 30 Mar 2020 22:44:04 GMT"}, {"version": "v2", "created": "Wed, 27 May 2020 23:43:06 GMT"}], "update_date": "2020-05-29", "authors_parsed": [["Ezenwe", "Ifeatu", ""], ["Joshi", "Alok", ""], ["Wong-Lin", "KongFatt", ""]]}, {"id": "2003.14091", "submitter": "Meiyun Xia", "authors": "Meiyun Xia, Pengfei Xu, Yuanbin Yang, Wenyu Jiang, Zehua Wang, Xiaolei\n  Gu, Mingxi Yang, Deyu Li, Shuyu Li, Guijun Dong, Ling Wang, Daifa Wang", "title": "Frontoparietal Connectivity Neurofeedback Training for Promotion of\n  Working Memory: An fNIRS Study in Healthy Male Participants", "comments": null, "journal-ref": null, "doi": "10.1109/ACCESS.2021.3074220", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurofeedback cognitive training is a promising tool used to promote\ncognitive functions effectively and efficiently. In this study, we investigated\na novel functional near-infrared spectroscopy (fNIRS)-based frontoparietal\nfunctional connectivity (FC) neurofeedback training paradigm related to working\nmemory, involving healthy adults. Compared with conventional cognitive training\nstudies, we chose the frontoparietal network, a key brain region for cognitive\nfunction modulation, as neurofeedback, yielding a strong targeting effect. In\nthe experiment, 10 participants (test group) received three cognitive training\nsessions of 15 min using fNIRS-based frontoparietal FC as neurofeedback, and\nanother 10 participants served as the control group. Frontoparietal FC was\nsignificantly increased in the test group (p D 0.03), and the cognitive\nfunctions (memory and attention) were significantly promoted compared with the\ncontrol group (accuracy of 3-back test: p D 0.0005, reaction time of 3-back\ntest: p D 0.0009). After additional validations on long-term training effect\nand on different patient populations, the proposed method exhibited\nconsiderable potential to be developed as a fast, effective, and widespread\ntraining approach for cognitive function enhancement.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2020 10:57:31 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 11:00:51 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Xia", "Meiyun", ""], ["Xu", "Pengfei", ""], ["Yang", "Yuanbin", ""], ["Jiang", "Wenyu", ""], ["Wang", "Zehua", ""], ["Gu", "Xiaolei", ""], ["Yang", "Mingxi", ""], ["Li", "Deyu", ""], ["Li", "Shuyu", ""], ["Dong", "Guijun", ""], ["Wang", "Ling", ""], ["Wang", "Daifa", ""]]}]