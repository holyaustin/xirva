[{"id": "1808.00367", "submitter": "Faramarz Faghihi", "authors": "Faramarz Faghihi, Homa Samani, Ahmed A.Moustafa", "title": "Pattern Separation in a Spiking Neural Network of Hippocampus Robust to\n  Imbalanced Excitation/Inhibition", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Efficient pattern separation in dentate gyrus plays an important role in\nstoring information in the hippocampus. Current knowledge of the structure and\nfunction of the hippocampus, entorhinal cortex and dentate gyrus, in pattern\nseparation are incorporated in our model. A three-layer feedforward spiking\nneural network inspired by the rodent hippocampus an equipped with simplified\nsynaptic and molecular mechanisms is developed. The aim of the study is to make\nan spiking neural network capable of pattern separation in imbalanced\nexcitation/inhibition ratios caused by different levels of stimulations or\nnetwork damage. This work present a novel theory on the cellular mechanisms of\nrobustness to damges to synapses and connectivity of neurons in dentate gyrus\nthat results in imbalanced excitation-inhibition activity of neurons. This\nspiking neural network uses simplified molecular and cellular hypothetical\nmechanisms and demonstrates efficient storing of information in different\nlevels of stimulation and can be implemented in cognitive robotics.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 15:20:02 GMT"}], "update_date": "2018-08-02", "authors_parsed": [["Faghihi", "Faramarz", ""], ["Samani", "Homa", ""], ["Moustafa", "Ahmed A.", ""]]}, {"id": "1808.00546", "submitter": "Stefan Balint", "authors": "Agneta M. Balint and Stefan Balint", "title": "If the charged particle transport phenomenon in electrical circuits or\n  in biological neurons is described using Riemann-Liouville or Caputo\n  fractional order derivatives, then objectivity is lost", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the objectivity of the description of charged particles\ntransport in electrical circuits, in biological neurons and biological\nneuron-networks is discussed. It is shown that the use of Riemann-Liouville or\nCaputo fractional order derivatives leads to the loose of the description\nobjectivity.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 09:12:13 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Balint", "Agneta M.", ""], ["Balint", "Stefan", ""]]}, {"id": "1808.00675", "submitter": "Zhaofei Yu", "authors": "Zhaofei Yu, Yonghong Tian, Tiejun Huang, Jian K. Liu", "title": "Winner-Take-All as Basic Probabilistic Inference Unit of Neuronal\n  Circuits", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental observations of neuroscience suggest that the brain is working a\nprobabilistic way when computing information with uncertainty. This processing\ncould be modeled as Bayesian inference. However, it remains unclear how\nBayesian inference could be implemented at the level of neuronal circuits of\nthe brain. In this study, we propose a novel general-purpose neural\nimplementation of probabilistic inference based on a ubiquitous network of\ncortical microcircuits, termed winner-take-all (WTA) circuit. We show that each\nWTA circuit could encode the distribution of states defined on a variable. By\nconnecting multiple WTA circuits together, the joint distribution can be\nrepresented for arbitrary probabilistic graphical models. Moreover, we prove\nthat the neural dynamics of WTA circuit is able to implement one of the most\npowerful inference methods in probabilistic graphical models, mean-field\ninference. We show that the synaptic drive of each spiking neuron in the WTA\ncircuit encodes the marginal probability of the variable in each state, and the\nfiring probability (or firing rate) of each neuron is proportional to the\nmarginal probability. Theoretical analysis and experimental results demonstrate\nthat the WTA circuits can get comparable inference result as mean-field\napproximation. Taken together, our results suggest that the WTA circuit could\nbe seen as the minimal inference unit of neuronal circuits.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 05:56:30 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Yu", "Zhaofei", ""], ["Tian", "Yonghong", ""], ["Huang", "Tiejun", ""], ["Liu", "Jian K.", ""]]}, {"id": "1808.00756", "submitter": "Lee Susman", "authors": "Lee Susman, Naama Brenner and Omri Barak", "title": "Stable memory with unstable synapses", "comments": "In review with Nature Communications. 30 pages, including appendix", "journal-ref": null, "doi": "10.1038/s41467-019-12306-2", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  What is the physiological basis of long-term memory? The prevailing view in\nneuroscience attributes changes in synaptic efficacy to memory acquisition.\nThis view implies that stable memories correspond to stable connectivity\npatterns. However, an increasing body of experimental evidence points to\nsignificant, activity-independent dynamics in synaptic strengths. Motivated by\nthese observations, we explore the possibility of memory storage within a\nglobal component of network connectivity, while individual connections\nfluctuate. We find a simple and general principle, stemming from stability\narguments, that links eigenvalues in the complex plane to memories.\nSpecifically, imaginary-coded memories are more resilient to noise and\nhomeostatic plasticity than their real-coded counterparts. Memory\nrepresentations are stored as time-varying attractors in neural state-space and\nsupport associative retrieval of learned information. Our results suggest a\nlink between the properties of learning rules and those of network-level memory\nrepresentations, and point at measurable signatures to be sought in\nexperimental data.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 11:08:56 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 08:48:43 GMT"}, {"version": "v3", "created": "Sun, 24 Feb 2019 15:26:16 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Susman", "Lee", ""], ["Brenner", "Naama", ""], ["Barak", "Omri", ""]]}, {"id": "1808.00762", "submitter": "Don Krieger", "authors": "Don Krieger, Paul Shepard, Walter Schneider, Sue Beers, Anthony\n  Kontos, Michael Collins, David O. Okonkwo", "title": "MEG-Derived Functional Tractography, Results for Normal and Concussed\n  Cohorts", "comments": "3 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measures of neuroelectric activity from each of 18 automatically identified\nwhite matter tracts were extracted from resting MEG recordings from a\nnormative, n=588, and a chronic TBI, traumatic brain injury, n=63, cohort, 60\nof whose TBIs were mild. Activity in the TBI cohort was significantly reduced\ncompared with the norms for ten of the tracts, p < 10-6 for each. Significantly\nreduced activity (p < 10-3) was seen in more than one tract in seven mTBI\nindividuals and one member of the normative cohort.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2018 11:40:50 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 13:43:53 GMT"}], "update_date": "2018-08-31", "authors_parsed": [["Krieger", "Don", ""], ["Shepard", "Paul", ""], ["Schneider", "Walter", ""], ["Beers", "Sue", ""], ["Kontos", "Anthony", ""], ["Collins", "Michael", ""], ["Okonkwo", "David O.", ""]]}, {"id": "1808.01058", "submitter": "Jyothi Swaroop Guntupalli", "authors": "Dileep George, Alexander Lavin, J. Swaroop Guntupalli, David Mely,\n  Nick Hay, Miguel Lazaro-Gredilla", "title": "Cortical Microcircuits from a Generative Vision Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding the information processing roles of cortical circuits is an\noutstanding problem in neuroscience and artificial intelligence. The\ntheoretical setting of Bayesian inference has been suggested as a framework for\nunderstanding cortical computation. Based on a recently published generative\nmodel for visual inference (George et al., 2017), we derive a family of\nanatomically instantiated and functional cortical circuit models. In contrast\nto simplistic models of Bayesian inference, the underlying generative model's\nrepresentational choices are validated with real-world tasks that required\nefficient inference and strong generalization. The cortical circuit model is\nderived by systematically comparing the computational requirements of this\nmodel with known anatomical constraints. The derived model suggests precise\nfunctional roles for the feedforward, feedback and lateral connections observed\nin different laminae and columns, and assigns a computational role for the path\nthrough the thalamus.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 01:20:08 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["George", "Dileep", ""], ["Lavin", "Alexander", ""], ["Guntupalli", "J. Swaroop", ""], ["Mely", "David", ""], ["Hay", "Nick", ""], ["Lazaro-Gredilla", "Miguel", ""]]}, {"id": "1808.01279", "submitter": "Charles Delahunt", "authors": "Charles B Delahunt, Pedro D Maia, J. Nathan Kutz", "title": "Built to Last: Functional and structural mechanisms in the moth\n  olfactory network mitigate effects of neural injury", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most organisms suffer neuronal damage throughout their lives, which can\nimpair performance of core behaviors. Their neural circuits need to maintain\nfunction despite injury, which in particular requires preserving key system\noutputs. In this work, we explore whether and how certain structural and\nfunctional neuronal network motifs act as injury mitigation mechanisms.\nSpecifically, we examine how (i) Hebbian learning, (ii) high levels of noise,\nand (iii) parallel inhibitory and excitatory connections contribute to the\nrobustness of the olfactory system in the Manduca sexta moth. We simulate\ninjuries on a detailed computational model of the moth olfactory network\ncalibrated to in vivo data. The injuries are modeled on focal axonal swellings,\na ubiquitous form of axonal pathology observed in traumatic brain injuries and\nother brain disorders. Axonal swellings effectively compromise spike train\npropagation along the axon, reducing the effective neural firing rate delivered\nto downstream neurons. All three of the network motifs examined significantly\nmitigate the effects of injury on readout neurons, either by reducing injury's\nimpact on readout neuron responses or by restoring these responses to\npre-injury levels. These motifs may thus be partially explained by their value\nas adaptive mechanisms to minimize the functional effects of neural injury.\nMore generally, robustness to injury is a vital design principle to consider\nwhen analyzing neural systems.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2018 17:58:45 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 01:03:51 GMT"}, {"version": "v3", "created": "Fri, 11 Sep 2020 22:38:58 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Delahunt", "Charles B", ""], ["Maia", "Pedro D", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1808.01503", "submitter": "Vijay Balasubramanian", "authors": "Eli Pollock, Niral Desai, Xue-Xin Wei, Vijay Balasubramanian", "title": "Dynamic self-organized error-correction of grid cells by border cells", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid cells in the entorhinal cortex are believed to establish their regular,\nspatially correlated firing patterns by path integration of the animal's\nmotion. Mechanisms for path integration, e.g. in attractor network models,\npredict stochastic drift of grid responses, which is not observed\nexperimentally. We demonstrate a biologically plausible mechanism of dynamic\nself-organization by which border cells, which fire at environmental\nboundaries, can correct such drift in grid cells. In our model,\nexperience-dependent Hebbian plasticity during exploration allows border cells\nto learn connectivity to grid cells. Border cells in this learned network reset\nthe phase of drifting grids. This error-correction mechanism is robust to\nenvironmental shape and complexity, including enclosures with interior\nbarriers, and makes distinctive predictions for environmental deformation\nexperiments. Our work demonstrates how diverse cell types in the entorhinal\ncortex could interact dynamically and adaptively to achieve robust path\nintegration.\n", "versions": [{"version": "v1", "created": "Sat, 4 Aug 2018 16:17:44 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Pollock", "Eli", ""], ["Desai", "Niral", ""], ["Wei", "Xue-Xin", ""], ["Balasubramanian", "Vijay", ""]]}, {"id": "1808.01612", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley and Adam Reeves", "title": "Colour for behavioural success", "comments": null, "journal-ref": "2018, i-Perception, 9(2), 2041669518767171", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Colour information not only helps sustain the survival of animal species by\nguiding sexual selection and foraging behaviour, but also is an important\nfactor in the cultural and technological development of our own species. This\nis illustrated by examples from the visual arts and from state-of-the-art\nimaging technology, where the strategic use of colour has become a powerful\ntool for guiding the planning and execution of interventional procedures. The\nfunctional role of colour information in terms of its potential benefits to\nbehavioural success across the species is addressed in the introduction here to\nclarify why colour perception may have evolved to generate behavioural success.\nIt is argued that evolutionary and environmental pressures influence not only\ncolour trait production in the different species, but also their ability to\nprocess and exploit colour information for goal-specific purposes. We then leap\nstraight to the human primate with insight from current research on the\nfacilitating role of colour cues on performance training with precision\ntechnology for image-guided surgical planning and intervention. It is shown\nthat local colour cues in 2D images generated by a surgical fisheye camera help\nindividuals become more precise rapidly across a limited number of trial sets\nin simulator training for specific manual gestures with a tool. The\nprogressively facilitating effect of a local colour cue on performance\nevolution in a video controlled simulator task can be explained in terms of\ncolour-based figure-ground segregation guiding attention towards local image\nparts, with an immediate cost on performance time, and a lasting long-term\nbenefit in terms of greater task precision.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 13:20:57 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Dresp-Langley", "Birgitta", ""], ["Reeves", "Adam", ""]]}, {"id": "1808.01640", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley", "title": "Principles of perceptual grouping: implications for image-guided surgery", "comments": null, "journal-ref": "2015, Frontiers in Psychology, 6, 1565", "doi": null, "report-no": null, "categories": "cs.HC eess.IV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gestalt theory has provided perceptual science with a conceptual framework\nwhich has inspired researchers ever since, taking the field of perceptual\norganization into the 21st century. This opinion article discusses the\nimportance of rules of perceptual organization for the testing and design of\nvisual interface technology. It is argued that major Gestalt principles, such\nas the law of good continuation or the principle of Praegnanz (suggested\ntranslation: salience), taken as examples here, are important to our\nunderstanding of visual image processing by a human observer. Perceptual\nintegration of contrast information across collinear space, and the\norganization of objects in the 2D image plane into figure and ground are of a\nparticular importance here. Visual interfaces for image-guided surgery\nillustrate the criticality of these two types of perceptual processes for\nreliable decision making and action. It is concluded that Gestalt theory\ncontinues to generate powerful concepts and insights for perceptual science\nplaced within the context of major technological challenges of today.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 16:04:25 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Dresp-Langley", "Birgitta", ""]]}, {"id": "1808.01642", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad and Daoqiang Zhang", "title": "Multi-Objective Cognitive Model: a supervised approach for multi-subject\n  fMRI analysis", "comments": "Neuroinformatics, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG math.OC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to decode the human brain, Multivariate Pattern (MVP) classification\ngenerates cognitive models by using functional Magnetic Resonance Imaging\n(fMRI) datasets. As a standard pipeline in the MVP analysis, brain patterns in\nmulti-subject fMRI dataset must be mapped to a shared space and then a\nclassification model is generated by employing the mapped patterns. However,\nthe MVP models may not provide stable performance on a new fMRI dataset because\nthe standard pipeline uses disjoint steps for generating these models. Indeed,\neach step in the pipeline includes an objective function with independent\noptimization approach, where the best solution of each step may not be optimum\nfor the next steps. For tackling the mentioned issue, this paper introduces the\nMulti-Objective Cognitive Model (MOCM) that utilizes an integrated objective\nfunction for MVP analysis rather than just using those disjoint steps. For\nsolving the integrated problem, we proposed a customized multi-objective\noptimization approach, where all possible solutions are firstly generated, and\nthen our method ranks and selects the robust solutions as the final results.\nEmpirical studies confirm that the proposed method can generate superior\nperformance in comparison with other techniques.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 16:19:56 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1808.01805", "submitter": "Paola Sessa", "authors": "Arianna Schiano Lomoriello, Federica Meconi, Irene Rinaldi, and Paola\n  Sessa", "title": "Out of sight out of mind: Perceived physical distance between the\n  observer and someone in pain shapes observer's neural empathic reactions", "comments": "42 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social and affective relations may shape empathy to others' affective states.\nPrevious studies also revealed that people tend to form very different mental\nrepresentations of stimuli on the basis of their physical distance. In this\nregard, embodied cognition proposes that different physical distances between\nindividuals activate different interpersonal processing modes, such that close\nphysical distance tends to activate the interpersonal processing mode typical\nof socially and affectively close relationships. In Experiment 1, two groups of\nparticipants were administered a pain decision task involving upright and\ninverted face stimuli painfully or neutrally stimulated, and we monitored their\nneural empathic reactions by means of event-related potentials (ERPs)\ntechnique. Crucially, participants were presented with face stimuli of one of\ntwo possible sizes in order to manipulate retinal size and perceived physical\ndistance, roughly corresponding to the close and far portions of social\ndistance. ERPs modulations compatible with an empathic reaction were observed\nonly for the group exposed to face stimuli appearing to be at a close social\ndistance from the participants. This reaction was absent in the group exposed\nto smaller stimuli corresponding to face stimuli observed from a far social\ndistance. In Experiment 2, one different group of participants was engaged in a\nmatch-to-sample task involving the two-size upright face stimuli of Experiment\n1 to test whether the modulation of neural empathic reaction observed in\nExperiment 1 could be ascribable to differences in the ability to identify\nfaces of the two different sizes. Results suggested that face stimuli of the\ntwo sizes could be equally identifiable. In line with the Construal Level and\nEmbodied Simulation theoretical frameworks, we conclude that perceived physical\ndistance may shape empathy as well as social and affective distance.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 10:06:19 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Lomoriello", "Arianna Schiano", ""], ["Meconi", "Federica", ""], ["Rinaldi", "Irene", ""], ["Sessa", "Paola", ""]]}, {"id": "1808.01893", "submitter": "Cinzia Di Giusto", "authors": "Elisabetta De Maria (C&A), Cinzia Di Giusto (C&A), Laetitia Laversa\n  (C&A)", "title": "Spiking Neural Networks modelled as Timed Automata with parameter\n  learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.FL q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel approach to automatically infer parameters\nof spiking neural networks. Neurons are modelled as timed automata waiting for\ninputs on a number of different channels (synapses), for a given amount of time\n(the accumulation period). When this period is over, the current potential\nvalue is computed considering current and past inputs. If this potential\novercomes a given threshold, the automaton emits a broadcast signal over its\noutput channel , otherwise it restarts another accumulation period. After each\nemission, the automaton remains inactive for a fixed refractory period. Spiking\nneural networks are formalised as sets of automata, one for each neuron,\nrunning in parallel and sharing channels according to the network structure.\nSuch a model is formally validated against some crucial properties defined via\nproper temporal logic formulae. The model is then exploited to find an\nassignment for the synaptical weights of neural networks such that they can\nreproduce a given behaviour. The core of this approach consists in identifying\nsome correcting actions adjusting synaptical weights and back-propagating them\nuntil the expected behaviour is displayed. A concrete case study is discussed.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2018 08:19:31 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["De Maria", "Elisabetta", "", "C&A"], ["Di Giusto", "Cinzia", "", "C&A"], ["Laversa", "Laetitia", "", "C&A"]]}, {"id": "1808.02157", "submitter": "Garren Gaut", "authors": "Garren Gaut, Xiangrui Li, Zhong-Lin Lu, and Mark Steyvers", "title": "Experimental Design Modulates Variance in BOLD Activation: The Variance\n  Design General Linear Model", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Typical fMRI studies have focused on either the mean trend in the\nblood-oxygen-level-dependent (BOLD) time course or functional connectivity\n(FC). However, other statistics of the neuroimaging data may contain important\ninformation. Despite studies showing links between the variance in the BOLD\ntime series (BV) and age and cognitive performance, a formal framework for\ntesting these effects has not yet been developed. We introduce the Variance\nDesign General Linear Model (VDGLM), a novel framework that facilitates the\ndetection of variance effects. We designed the framework for general use in any\nfMRI study by modeling both mean and variance in BOLD activation as a function\nof experimental design. The flexibility of this approach allows the VDGLM to i)\nsimultaneously make inferences about a mean or variance effect while\ncontrolling for the other and ii) test for variance effects that could be\nassociated with multiple conditions and/or noise regressors. We demonstrate the\nuse of the VDGLM in a working memory application and show that engagement in a\nworking memory task is associated with whole-brain decreases in BOLD variance.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2018 23:57:26 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Gaut", "Garren", ""], ["Li", "Xiangrui", ""], ["Lu", "Zhong-Lin", ""], ["Steyvers", "Mark", ""]]}, {"id": "1808.02379", "submitter": "Andrei Khrennikov Yu", "authors": "Andrei Khrennikov", "title": "Classical versus quantum probability: Comments on the paper \"On\n  universality of classical probability with contextually labeled random\n  variables\" by E. Dzhafarov and M. Kon", "comments": null, "journal-ref": "J. Math. Psychology, 89, 2019, 87-92", "doi": null, "report-no": null, "categories": "math.PR q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Dzhafarov and Kon published the paper advertising the possibility to\nuse the coupling technique of classical probability theory to model\nincompatible observables in quantum physics and quantum-like models of\npsychology. Here I present comments on this paper by stressing advantages and\ndisadvantages.\n", "versions": [{"version": "v1", "created": "Sun, 5 Aug 2018 16:35:19 GMT"}, {"version": "v2", "created": "Wed, 22 Aug 2018 10:26:10 GMT"}, {"version": "v3", "created": "Tue, 2 Oct 2018 18:20:23 GMT"}, {"version": "v4", "created": "Mon, 29 Oct 2018 16:17:36 GMT"}], "update_date": "2019-09-24", "authors_parsed": [["Khrennikov", "Andrei", ""]]}, {"id": "1808.02788", "submitter": "Oleg Kanakov", "authors": "Oleg Kanakov, Susanna Gordleeva, Anastasia Ermolaeva, Sarika Jalan,\n  Alexey Zaikin", "title": "Astrocyte-induced positive integrated information in neuroglial\n  ensembles", "comments": null, "journal-ref": "Phys. Rev. E 99, 012418 (2019)", "doi": "10.1103/PhysRevE.99.012418", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Integrated Information is a quantitative measure from information theory\nhow tightly all parts of a system are interconnected in terms of information\nexchange. In this study we show that astrocyte, playing an important role in\nregulation of information transmission between neurons, may contribute to a\ngeneration of positive Integrated Information in neuronal ensembles.\nAnalytically and numerically we show that the presence of astrocyte may be\nessential for this information attribute in neuro-astrocytic ensembles.\nMoreover, the proposed \"spiking-bursting\" mechanism of generating positive\nIntegrated Information is shown to be generic and not limited to neuroglial\nnetworks, and is given a complete analytic description.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 14:14:11 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Kanakov", "Oleg", ""], ["Gordleeva", "Susanna", ""], ["Ermolaeva", "Anastasia", ""], ["Jalan", "Sarika", ""], ["Zaikin", "Alexey", ""]]}, {"id": "1808.03166", "submitter": "Jos\\'e Halloy", "authors": "Leo Cazenille, Nicolas Bredeche and Jos\\'e Halloy", "title": "Evolutionary optimisation of neural network models for fish collective\n  behaviours in mixed groups of robots and zebrafish", "comments": "10 pages, 4 figures", "journal-ref": "Lecture Notes in Computer Science, vol 10928. Springer, Cham, 2018", "doi": "10.1007/978-3-319-95972-6_10", "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animal and robot social interactions are interesting both for ethological\nstudies and robotics. On the one hand, the robots can be tools and models to\nanalyse animal collective behaviours, on the other hand, the robots and their\nartificial intelligence are directly confronted and compared to the natural\nanimal collective intelligence. The first step is to design robots and their\nbehavioural controllers that are capable of socially interact with animals.\nDesigning such behavioural bio-mimetic controllers remains an important\nchallenge as they have to reproduce the animal behaviours and have to be\ncalibrated on experimental data. Most animal collective behavioural models are\ndesigned by modellers based on experimental data. This process is long and\ncostly because it is difficult to identify the relevant behavioural features\nthat are then used as a priori knowledge in model building. Here, we want to\nmodel the fish individual and collective behaviours in order to develop robot\ncontrollers. We explore the use of optimised black-box models based on\nartificial neural networks (ANN) to model fish behaviours. While the ANN may\nnot be biomimetic but rather bio-inspired, they can be used to link perception\nto motor responses. These models are designed to be implementable as robot\ncontrollers to form mixed-groups of fish and robots, using few a priori\nknowledge of the fish behaviours. We present a methodology with multilayer\nperceptron or echo state networks that are optimised through evolutionary\nalgorithms to model accurately the fish individual and collective behaviours in\na bounded rectangular arena. We assess the biomimetism of the generated models\nand compare them to the fish experimental behaviours.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 13:54:23 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Cazenille", "Leo", ""], ["Bredeche", "Nicolas", ""], ["Halloy", "Jos\u00e9", ""]]}, {"id": "1808.03357", "submitter": "Adam Kohan", "authors": "Adam A. Kohan, Edward A. Rietman, Hava T. Siegelmann", "title": "Error Forward-Propagation: Reusing Feedforward Connections to Propagate\n  Errors in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Error Forward-Propagation, a biologically plausible mechanism to\npropagate error feedback forward through the network. Architectural constraints\non connectivity are virtually eliminated for error feedback in the brain;\nsystematic backward connectivity is not used or needed to deliver error\nfeedback. Feedback as a means of assigning credit to neurons earlier in the\nforward pathway for their contribution to the final output is thought to be\nused in learning in the brain. How the brain solves the credit assignment\nproblem is unclear. In machine learning, error backpropagation is a highly\nsuccessful mechanism for credit assignment in deep multilayered networks.\nBackpropagation requires symmetric reciprocal connectivity for every neuron.\nFrom a biological perspective, there is no evidence of such an architectural\nconstraint, which makes backpropagation implausible for learning in the brain.\nThis architectural constraint is reduced with the use of random feedback\nweights. Models using random feedback weights require backward connectivity\npatterns for every neuron, but avoid symmetric weights and reciprocal\nconnections. In this paper, we practically remove this architectural\nconstraint, requiring only a backward loop connection for effective error\nfeedback. We propose reusing the forward connections to deliver the error\nfeedback by feeding the outputs into the input receiving layer. This mechanism,\nError Forward-Propagation, is a plausible basis for how error feedback occurs\ndeep in the brain independent of and yet in support of the functionality\nunderlying intricate network architectures. We show experimentally that\nrecurrent neural networks with two and three hidden layers can be trained using\nError Forward-Propagation on the MNIST and Fashion MNIST datasets, achieving\n$1.90\\%$ and $11\\%$ generalization errors respectively.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 21:52:10 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Kohan", "Adam A.", ""], ["Rietman", "Edward A.", ""], ["Siegelmann", "Hava T.", ""]]}, {"id": "1808.03359", "submitter": "Ekkehard Ullner", "authors": "Antonio Politi, Ekkehard Ullner, and Alessandro Torcini", "title": "Collective irregular dynamics in balanced networks of leaky\n  integrate-and-fire neurons", "comments": "12 pages, 13 figures", "journal-ref": "Eur. Phys. J. Special Topics 227, 1185 (2018)", "doi": "10.1140/epjst/e2018-00079-7", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extensively explore networks of weakly unbalanced, leaky\nintegrate-and-fire (LIF) neurons for different coupling strength, connectivity,\nand by varying the degree of refractoriness, as well as the delay in the spike\ntransmission. We find that the neural network does not only exhibit a\nmicroscopic (single-neuron) stochastic-like evolution, but also a collective\nirregular dynamics (CID). Our analysis is based on the computation of a\nsuitable order parameter, typically used to characterize synchronization\nphenomena and on a detailed scaling analysis (i.e. simulations of different\nnetwork sizes). As a result, we can conclude that CID is a true thermodynamic\nphase, intrinsically different from the standard asynchronous regime.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2018 22:03:32 GMT"}], "update_date": "2018-12-14", "authors_parsed": [["Politi", "Antonio", ""], ["Ullner", "Ekkehard", ""], ["Torcini", "Alessandro", ""]]}, {"id": "1808.03630", "submitter": "Jeffrey Craley", "authors": "Jeff Craley, Emily Johnson, Archana Venkataraman", "title": "A Novel Method for Epileptic Seizure Detection Using Coupled Hidden\n  Markov Models", "comments": "To appear in MICCAI 2018 Proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel Coupled Hidden Markov Model to detect epileptic seizures\nin multichannel electroencephalography (EEG) data. Our model defines a network\nof seizure propagation paths to capture both the temporal and spatial evolution\nof epileptic activity. To address the intractability introduced by the coupled\ninteractions, we derive a variational inference procedure to efficiently infer\nthe seizure evolution from spectral patterns in the EEG data. We validate our\nmodel on EEG aquired under clinical conditions in the Epilepsy Monitoring Unit\nof the Johns Hopkins Hospital. Using 5-fold cross validation, we demonstrate\nthat our model outperforms three baseline approaches which rely on a classical\ndetection framework. Our model also demonstrates the potential to localize\nseizure onset zones in focal epilepsy.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 17:30:08 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Craley", "Jeff", ""], ["Johnson", "Emily", ""], ["Venkataraman", "Archana", ""]]}, {"id": "1808.03875", "submitter": "Andrew Glennerster", "authors": "Andrew Glennerster and Jenny C.A. Read", "title": "A single coordinate framework for optic flow and binocular disparity", "comments": "65 pages; 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optic flow is two dimensional, but no special qualities are attached to one\nor other of these dimensions. For binocular disparity, on the other hand, the\nterms 'horizontal' and 'vertical' disparities are commonly used. This is odd,\nsince binocular disparity and optic flow describe essentially the same thing.\nThe difference is that, generally, people tend to fixate relatively close to\nthe direction of heading as they move, meaning that fixation is close to the\noptic flow epipole, whereas, for binocular vision, fixation is close to the\nhead-centric midline, i.e. approximately 90 degrees from the binocular epipole.\nFor fixating animals, some separations of flow may lead to simple algorithms\nfor the judgement of surface structure and the control of action. We consider\nthe following canonical flow patterns that sum to produce overall flow: (i)\n'towards' flow, the component of translational flow produced by approaching (or\nretreating from) the fixated object, which produces pure radial flow on the\nretina; (ii) 'sideways' flow, the remaining component of translational flow,\nwhich is produced by translation of the optic centre orthogonal to the\ncyclopean line of sight and (iii) 'vergence' flow, rotational flow produced by\na counter-rotation of the eye in order to maintain fixation. A general flow\npattern could also include (iv) 'cyclovergence' flow, produced by rotation of\none eye relative to the other about the line of sight. We consider some\npractical advantages of dividing up flow in this way when an observer fixates\nas they move. As in some previous treatments, we suggest that there are certain\ntasks for which it is sensible to consider 'towards' flow as one component and\n'sideways' + 'vergence' flow as another.\n", "versions": [{"version": "v1", "created": "Sat, 11 Aug 2018 22:50:52 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Glennerster", "Andrew", ""], ["Read", "Jenny C. A.", ""]]}, {"id": "1808.03958", "submitter": "Zhaofei Yu", "authors": "Shanshan Jia and Zhaofei Yu and Arno Onken and Yonghong Tian and\n  Tiejun Huang and Jian K. Liu", "title": "Neural System Identification with Spike-triggered Non-negative Matrix\n  Factorization", "comments": "updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neuronal circuits formed in the brain are complex with intricate connection\npatterns. Such complexity is also observed in the retina as a relatively simple\nneuronal circuit. A retinal ganglion cell receives excitatory inputs from\nneurons in previous layers as driving forces to fire spikes. Analytical methods\nare required that can decipher these components in a systematic manner.\nRecently a method termed spike-triggered non-negative matrix factorization\n(STNMF) has been proposed for this purpose. In this study, we extend the scope\nof the STNMF method. By using the retinal ganglion cell as a model system, we\nshow that STNMF can detect various computational properties of upstream bipolar\ncells, including spatial receptive field, temporal filter, and transfer\nnonlinearity. In addition, we recover synaptic connection strengths from the\nweight matrix of STNMF. Furthermore, we show that STNMF can separate spikes of\na ganglion cell into a few subsets of spikes where each subset is contributed\nby one presynaptic bipolar cell. Taken together, these results corroborate that\nSTNMF is a useful method for deciphering the structure of neuronal circuits.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2018 15:37:40 GMT"}, {"version": "v2", "created": "Sat, 29 Sep 2018 05:09:10 GMT"}, {"version": "v3", "created": "Fri, 1 Feb 2019 03:02:36 GMT"}, {"version": "v4", "created": "Sun, 1 Mar 2020 12:14:30 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Jia", "Shanshan", ""], ["Yu", "Zhaofei", ""], ["Onken", "Arno", ""], ["Tian", "Yonghong", ""], ["Huang", "Tiejun", ""], ["Liu", "Jian K.", ""]]}, {"id": "1808.04196", "submitter": "Anirban Das", "authors": "Anirban Das and Anna Levina", "title": "Critical neuronal models with relaxed timescales separation", "comments": null, "journal-ref": "Phys. Rev. X 9, 021062 (2019)", "doi": "10.1103/PhysRevX.9.021062", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power laws in nature are considered to be signatures of complexity. The\ntheory of self-organized criticality (SOC) was proposed to explain their\norigins. A longstanding principle of SOC is the \\emph{separation of timescales}\naxiom. It dictates that external input is delivered to the system at a much\nslower rate compared to the timescale of internal dynamics. The statistics of\nneural avalanches in the brain was demonstrated to follow a power law,\nindicating closeness to a critical state. Moreover, criticality was shown to be\na beneficial state for various computations leading to the hypothesis, that the\nbrain is a SOC system. However, for neuronal systems that are constantly\nbombarded by incoming signals, separation of timescales assumption is\nunnatural. Recently it was experimentally demonstrated that a proper correction\nof the avalanche detection algorithm to account for the increased drive during\ntask performance leads to a change of the power-law exponent from $1.5$ to\napproximately $1.3$, but there is so far no theoretical explanation for this\nchange. Here we investigate the importance of timescales separation, by partly\nabandoning it in various models. We achieve it by allowing for external input\nduring the avalanche, without compromising the separation of avalanches. We\ndevelop an analytic treatment and provide numerical simulations of a simple\nneuronal model.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 06:47:39 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Das", "Anirban", ""], ["Levina", "Anna", ""]]}, {"id": "1808.04262", "submitter": "Anvar Kurmukov", "authors": "Anvar Kurmukov and Ayagoz Mussabayeva and Yulia Denisova and Daniel\n  Moyer and Boris Gutman", "title": "Connectivity-Driven Brain Parcellation via Consensus Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two related methods for deriving connectivity-based brain atlases\nfrom individual connectomes. The proposed methods exploit a previously proposed\ndense connectivity representation, termed continuous connectivity, by first\nperforming graph-based hierarchical clustering of individual brains, and\nsubsequently aggregating the individual parcellations into a consensus\nparcellation. The search for consensus minimizes the sum of cluster membership\ndistances, effectively estimating a pseudo-Karcher mean of individual\nparcellations. We assess the quality of our parcellations using (1)\nKullback-Liebler and Jensen-Shannon divergence with respect to the dense\nconnectome representation, (2) inter-hemispheric symmetry, and (3) performance\nof the simplified connectome in a biological sex classification task. We find\nthat the parcellation based-atlas computed using a greedy search at a\nhierarchical depth 3 outperforms all other parcellation-based atlases as well\nas the standard Dessikan-Killiany anatomical atlas in all three assessments.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2018 08:54:31 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Kurmukov", "Anvar", ""], ["Mussabayeva", "Ayagoz", ""], ["Denisova", "Yulia", ""], ["Moyer", "Daniel", ""], ["Gutman", "Boris", ""]]}, {"id": "1808.04389", "submitter": "Marco Reisert", "authors": "Marco Reisert, Valerij G. Kiselev, Bibek Dhital", "title": "A Unique Analytical Solution of the White Matter Standard Model using\n  Linear and Planar Encodings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion-weighted magnetic resonance imaging in brain white matter probes\ntissue microstructure and allows for the estimation of compartmental diffusion\nparameters. Recently, it became apparent that traditional single-direction\ndiffusion encodings are not fully sufficient to resolve the white matter\ncompartmental diffusivities. Multiple diffusion encodings have been suggested\nto make the problem less ambiguous, however, it still remained unclear whether\nsuch protocols would completely solve the problem. Here, we constructively\nprove that a combination of linear and planar diffusion encodings is enough to\ndetermine the parameters of the three compartment white matter model.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 18:18:28 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 09:09:20 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Reisert", "Marco", ""], ["Kiselev", "Valerij G.", ""], ["Dhital", "Bibek", ""]]}, {"id": "1808.04499", "submitter": "Zhiqin Xu", "authors": "Zhi-Qin John Xu, Douglas Zhou, David Cai", "title": "Dynamical and Coupling Structure of Pulse-Coupled Networks in Maximum\n  Entropy Analysis", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": "10.3390/e21010076", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximum entropy principle (MEP) analysis with few non-zero effective\ninteractions successfully characterizes the distribution of dynamical states of\npulse-coupled networks in many experiments, e.g., in neuroscience. To better\nunderstand the underlying mechanism, we found a relation between the dynamical\nstructure, i.e., effective interactions in MEP analysis, and the coupling\nstructure of pulse-coupled network to understand how a sparse coupling\nstructure could lead to a sparse coding by effective interactions. This\nrelation quantitatively displays how the dynamical structure is closely related\nto the coupling structure.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2018 01:00:30 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Xu", "Zhi-Qin John", ""], ["Zhou", "Douglas", ""], ["Cai", "David", ""]]}, {"id": "1808.05002", "submitter": "Arkady Zgonnikov", "authors": "Takashi Suzuki, Ihor Lubashevsky, Arkady Zgonnikov", "title": "Complexity of human response delay in intermittent control: The case of\n  virtual stick balancing", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Response delay is an inherent and essential part of human actions. In the\ncontext of human balance control, the response delay is traditionally modeled\nusing the formalism of delay-differential equations, which adopts the\napproximation of fixed delay. However, experimental studies revealing\nsubstantial variability, adaptive anticipation, and non-stationary dynamics of\nresponse delay provide evidence against this approximation. In this paper, we\ncall for development of principally new mathematical formalism describing human\nresponse delay. To support this, we present the experimental data from a simple\nvirtual stick balancing task. Our results demonstrate that human response delay\nis a widely distributed random variable with complex properties, which can\nexhibit oscillatory and adaptive dynamics characterized by long-range\ncorrelations. Given this, we argue that the fixed-delay approximation ignores\nessential properties of human response, and conclude with possible directions\nfor future developments of new mathematical notions describing human control.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 09:01:10 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 11:49:00 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Suzuki", "Takashi", ""], ["Lubashevsky", "Ihor", ""], ["Zgonnikov", "Arkady", ""]]}, {"id": "1808.05137", "submitter": "Daniele Faccio", "authors": "Alessandro Boccolini, Alessandro Fedrizzi, Daniele Faccio", "title": "Ghost imaging with the human eye", "comments": null, "journal-ref": null, "doi": "10.1364/OE.27.009258", "report-no": null, "categories": "q-bio.NC cs.CV physics.optics", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computational ghost imaging relies on the decomposition of an image into\npatterns that are summed together with weights that measure the overlap of each\npattern with the scene being imaged. These tasks rely on a computer. Here we\ndemonstrate that the computational integration can be performed directly with\nthe human eye. We use this human ghost imaging technique to evaluate the\ntemporal response of the eye and establish the image persistence time to be\naround 20 ms followed by a further 20 ms exponential decay. These persistence\ntimes are in agreement with previous studies but can now potentially be\nextended to include a more precise characterisation of visual stimuli and\nprovide a new experimental tool for the study of visual perception.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 17:04:53 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Boccolini", "Alessandro", ""], ["Fedrizzi", "Alessandro", ""], ["Faccio", "Daniele", ""]]}, {"id": "1808.05143", "submitter": "Vernon Lawhern", "authors": "Amelia J. Solon, Stephen M. Gordon, Jonathan R. McDaniel, Vernon J.\n  Lawhern", "title": "Collaborative Brain-Computer Interface for Human Interest Detection in\n  Complex and Dynamic Settings", "comments": "6 pages, 6 figures", "journal-ref": "2018 IEEE International Conference on Systems, Man and\n  Cybernetics, pp. 970-975", "doi": "10.1109/SMC.2018.00172", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can fluidly adapt their interest in complex environments in ways that\nmachines cannot. Here, we lay the groundwork for a real-world system that\npassively monitors and merges neural correlates of visual interest across team\nmembers via Collaborative Brain Computer Interface (cBCI). When group interest\nis detected and co-registered in time and space, it can be used to model the\ntask relevance of items in a dynamic, natural environment. Previous work in\ncBCIs focuses on static stimuli, stimulus- or response- locked analyses, and\noften within-subject and experiment model training. The contributions of this\nwork are twofold. First, we test the utility of cBCI on a scenario that more\nclosely resembles natural conditions, where subjects visually scanned a video\nfor target items in a virtual environment. Second, we use an\nexperiment-agnostic deep learning model to account for the real-world use case\nwhere no training set exists that exactly matches the end-users task and\ncircumstances. With our approach we show improved performance as the number of\nsubjects in the cBCI ensemble grows, and the potential to reconstruct\nground-truth target occurrence in an otherwise noisy and complex environment.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 15:31:14 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Solon", "Amelia J.", ""], ["Gordon", "Stephen M.", ""], ["McDaniel", "Jonathan R.", ""], ["Lawhern", "Vernon J.", ""]]}, {"id": "1808.05148", "submitter": "Youngmin Park", "authors": "Youngmin Park, G. Bard Ermentrout", "title": "A multiple timescales approach to bridging spiking- and population-level\n  dynamics", "comments": "40 pages, 12 figures, 4 tables. Accepted for publication in Chaos", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A rigorous bridge between spiking-level and macroscopic quantities is an\non-going and well-developed story for asynchronously firing neurons, but focus\nhas shifted to include neural populations exhibiting varying synchronous\ndynamics. Recent literature has used the Ott--Antonsen ansatz (2008) to great\neffect, allowing a rigorous derivation of an order parameter for large\noscillator populations. The ansatz has been successfully applied using several\nmodels including networks of Kuramoto oscillators, theta models, and\nintegrate-and-fire neurons, along with many types of network topologies. In the\npresent study, we take a converse approach: given the mean field dynamics of\nslow synapses, predict the synchronization properties of finite neural\npopulations. The slow synapse assumption is amenable to averaging theory and\nthe method of multiple timescales. Our proposed theory applies to two\nheterogeneous populations of N excitatory n-dimensional and N inhibitory\nm-dimensional oscillators with homogeneous synaptic weights. We then\ndemonstrate our theory using two examples. In the first example we take a\nnetwork of excitatory and inhibitory theta neurons and consider the case with\nand without heterogeneous inputs. In the second example we use Traub models\nwith calcium for the excitatory neurons and Wang-Buzs{\\'a}ki models for the\ninhibitory neurons. We accurately predict phase drift and phase locking in each\nexample even when the slow synapses exhibit non-trivial mean-field dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 15:34:38 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Park", "Youngmin", ""], ["Ermentrout", "G. Bard", ""]]}, {"id": "1808.05284", "submitter": "Matjaz Perc", "authors": "Abdorreza Goodarzinick, Mohammad D. Niry, Alireza Valizadeh, Matjaz\n  Perc", "title": "Robustness of functional networks at criticality against structural\n  defects", "comments": "7 two-column pages, 8 figures; accepted for publication in Physical\n  Review E", "journal-ref": "Phys. Rev. E 98, 022312 (2018)", "doi": "10.1103/PhysRevE.98.022312", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness of dynamical properties of neuronal networks against\nstructural damages is a central problem in computational and experimental\nneuroscience. Research has shown that the cortical network of a healthy brain\nworks near a critical state, and moreover, that functional neuronal networks\noften have scale-free and small-world properties. In this work, we study how\nthe robustness of simple functional networks at criticality is affected by\nstructural defects. In particular, we consider a 2D Ising model at the critical\ntemperature and investigate how its functional network changes with the\nincreasing degree of structural defects. We show that the scale-free and\nsmall-world properties of the functional network at criticality are robust\nagainst large degrees of structural lesions while the system remains below the\npercolation limit. Although the Ising model is only a conceptual description of\na two-state neuron, our research reveals fundamental robustness properties of\nfunctional networks derived from classical statistical mechanics models.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2018 21:10:33 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Goodarzinick", "Abdorreza", ""], ["Niry", "Mohammad D.", ""], ["Valizadeh", "Alireza", ""], ["Perc", "Matjaz", ""]]}, {"id": "1808.05464", "submitter": "Dongrui Wu", "authors": "He He and Dongrui Wu", "title": "Transfer Learning for Brain-Computer Interfaces: A Euclidean Space Data\n  Alignment Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: This paper targets a major challenge in developing practical\nEEG-based brain-computer interfaces (BCIs): how to cope with individual\ndifferences so that better learning performance can be obtained for a new\nsubject, with minimum or even no subject-specific data? Methods: We propose a\nnovel approach to align EEG trials from different subjects in the Euclidean\nspace to make them more similar, and hence improve the learning performance for\na new subject. Our approach has three desirable properties: 1) it aligns the\nEEG trials directly in the Euclidean space, and any signal processing, feature\nextraction and machine learning algorithms can then be applied to the aligned\ntrials; 2) its computational cost is very low; and, 3) it is unsupervised and\ndoes not need any label information from the new subject. Results: Both offline\nand simulated online experiments on motor imagery classification and\nevent-related potential classification verified that our proposed approach\noutperformed a state-of-the-art Riemannian space data alignment approach, and\nseveral approaches without data alignment. Conclusion: The proposed Euclidean\nspace EEG data alignment approach can greatly facilitate transfer learning in\nBCIs. Significance: Our proposed approach is effective, efficient, and easy to\nimplement. It could be an essential pre-processing step for EEG-based BCIs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2018 23:06:43 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 08:36:27 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["He", "He", ""], ["Wu", "Dongrui", ""]]}, {"id": "1808.05577", "submitter": "Stefano B. Blumberg", "authors": "Stefano B. Blumberg, Ryutaro Tanno, Iasonas Kokkinos, Daniel C.\n  Alexander", "title": "Deeper Image Quality Transfer: Training Low-Memory Neural Networks for\n  3D Images", "comments": "Accepted in: MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the memory demands that come with the processing of\n3-dimensional, high-resolution, multi-channeled medical images in deep\nlearning. We exploit memory-efficient backpropagation techniques, to reduce the\nmemory complexity of network training from being linear in the network's depth,\nto being roughly constant $ - $ permitting us to elongate deep architectures\nwith negligible memory increase. We evaluate our methodology in the paradigm of\nImage Quality Transfer, whilst noting its potential application to various\ntasks that use deep learning. We study the impact of depth on accuracy and show\nthat deeper models have more predictive power, which may exploit larger\ntraining sets. We obtain substantially better results than the previous\nstate-of-the-art model with a slight memory increase, reducing the\nroot-mean-squared-error by $ 13\\% $. Our code is publicly available.\n", "versions": [{"version": "v1", "created": "Thu, 16 Aug 2018 16:42:10 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Blumberg", "Stefano B.", ""], ["Tanno", "Ryutaro", ""], ["Kokkinos", "Iasonas", ""], ["Alexander", "Daniel C.", ""]]}, {"id": "1808.06578", "submitter": "Paul Smolen", "authors": "Paul Smolen, Douglas A. Baxter, John H. Byrne", "title": "Paradoxical LTP maintenance with inhibition of protein synthesis and the\n  proteasome suggests a novel protein synthesis requirement for early LTP\n  reversal", "comments": "23 pages, 5 figures. Accepted to Journal of Theoretical Biology", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The transition from early long-term potentiation (E-LTP) to late LTP (L-LTP)\ninvolves protein synthesis and degradation. L-LTP is blocked by inhibiting\neither protein synthesis or proteasome-dependent degradation prior to and\nduring a tetanic stimulus, but paradoxically, L-LTP is not blocked when\nsynthesis and degradation are inhibited simultaneously, suggesting\ncounter-acting positive and negative proteins regulate L-LTP. To investigate\nthis paradox, we modeled LTP at the Schaffer collateral synapse. Nine\ndifferential equations describe the levels of positive and negative regulator\nproteins (PP and NP) and transitions among five discrete synaptic states, a\nbasal state (BAS), three E-LTP states (EP1, EP2, ED), and a L-LTP state (LP). A\nstimulus initiates the transition from BAS to EP1 and from EP1 to EP2,\ninitiates the synthesis of PP and NP, and activates the ubiquitin-proteasome\nsystem (UPS). UPS mediates transitions of EP1 and EP2 to ED and the degradation\nof NP. The conversion of E-LTP to L-LTP is mediated by a PP-dependent\ntransition from ED to LP. NP mediates reversal of EP2 to BAS. This model\nsimulates empirical observations: 1) normal L-LTP, 2) block by either\nproteasome inhibitor or protein synthesis inhibitor alone, and 3) preservation\nof L-LTP when both inhibitors are applied together. Elements of this abstract\nmodel can be correlated with specific molecules and processes. Moreover, the\nmodel makes testable predictions, such as a unique synaptic state ED that\nprecedes the transition to L-LTP, and a time window for the action of the UPS\n(during the transitions from EP1 and EP2 to ED). Tests of these predictions\nwill provide insights into the processes of long-term synaptic plasticity.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2018 17:39:15 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Smolen", "Paul", ""], ["Baxter", "Douglas A.", ""], ["Byrne", "John H.", ""]]}, {"id": "1808.06889", "submitter": "C.C. Alan Fung", "authors": "Chi Chung Alan Fung and Tomoki Fukai", "title": "Discrete-attractor-like Tracking in Continuous Attractor Neural Networks", "comments": "5 pages, 4 figures", "journal-ref": "Phys. Rev. Lett. 122, 018102 (2019)", "doi": "10.1103/PhysRevLett.122.018102", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continuous attractor neural networks generate a set of smoothly connected\nattractor states. In memory systems of the brain, these attractor states may\nrepresent continuous pieces of information such as spatial locations and head\ndirections of animals. However, during the replay of previous experiences,\nhippocampal neurons show a discontinuous sequence in which discrete transitions\nof neural state are phase-locked with the slow-gamma (30-40 Hz) oscillation.\nHere, we explored the underlying mechanisms of the discontinuous sequence\ngeneration. We found that a continuous attractor neural network has several\nphases depending on the interactions between external input and local\ninhibitory feedback. The discrete-attractor-like behavior naturally emerges in\none of these phases without any discreteness assumption. We propose that the\ndynamics of continuous attractor neural networks is the key to generate\ndiscontinuous state changes phase-locked to the brain rhythm.\n", "versions": [{"version": "v1", "created": "Tue, 21 Aug 2018 13:25:09 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Fung", "Chi Chung Alan", ""], ["Fukai", "Tomoki", ""]]}, {"id": "1808.07021", "submitter": "Silvia Vitali", "authors": "Silvia Vitali, Francesco Mainardi and Gastone Castellani", "title": "Emergence of Fractional Kinetics in Spiny Dendrites", "comments": "8 pages", "journal-ref": "Fractal and Fractional MDPI 2018, 2, 6", "doi": "10.3390/fractalfract2010006", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fractional extensions of the cable equation have been proposed in the\nliterature to describe transmembrane potential in spiny dendrites. The\nanomalous behavior has been related in the literature to the geometrical\nproperties of the system, in particular, the density of spines, by experiments,\ncomputer simulations, and in comb-like models.~The same PDE can be related to\nmore than one stochastic process leading to anomalous diffusion behavior. The\ntime-fractional diffusion equation can be associated to a continuous time\nrandom walk (CTRW) with power-law waiting time probability or to a special case\nof the Erd\\'ely-Kober fractional diffusion, described by the ggBm. In this\nwork, we show that time fractional generalization of the cable equation arises\nnaturally in the CTRW by considering a superposition of Markovian processes and\nin a {\\it ggBm-like} construction of the random variable.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2018 14:13:27 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Vitali", "Silvia", ""], ["Mainardi", "Francesco", ""], ["Castellani", "Gastone", ""]]}, {"id": "1808.07692", "submitter": "Qinbing Fu", "authors": "Qinbing Fu and Nicola Bellotto and Shigang Yue", "title": "A Directionally Selective Neural Network with Separated ON and OFF\n  Pathways for Translational Motion Perception in a Visually Cluttered\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With respect to biological findings underlying fly's physiology in the past\ndecade, we present a directionally selective neural network, with a\nfeed-forward structure and entirely low-level visual processing, so as to\nimplement direction selective neurons in the fly's visual system, which are\nmainly sensitive to wide-field translational movements in four cardinal\ndirections. In this research, we highlight the functionality of ON and OFF\npathways, separating motion information for parallel computation corresponding\nto light-on and light-off selectivity. Through this modeling study, we\ndemonstrate several achievements compared with former bio-plausible\ntranslational motion detectors, like the elementary motion detectors. First, we\nthoroughly mimic the fly's preliminary motion-detecting pathways with newly\nrevealed fly's physiology. Second, we improve the speed response to moving\ndark/light features via the design of ensembles of same polarity cells in the\ndual-pathways. Moreover, we alleviate the impact of irrelevant motion in a\nvisually cluttered environment like the shifting of background and windblown\nvegetation, via the modeling of spatiotemporal dynamics. We systematically\ntested the DSNN against stimuli ranging from synthetic and real-world scenes,\nto notably a visual modality of a ground micro robot. The results demonstrated\nthat the DSNN outperforms former bio-plausible translational motion detectors.\nImportantly, we verified its computational simplicity and effectiveness\nbenefiting the building of neuromorphic vision sensor for robots.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 10:44:35 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Fu", "Qinbing", ""], ["Bellotto", "Nicola", ""], ["Yue", "Shigang", ""]]}, {"id": "1808.07850", "submitter": "Jorge F. Mejias", "authors": "R. R. Deza, J. I. Deza, N. Martinez, J. F. Mejias, H. S. Wio", "title": "A nonequilibrium-potential approach to competition in neural populations", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Energy landscapes are a useful aid for the understanding of dynamical\nsystems, and a valuable tool for their analysis. For a broad class of rate\nmodels of neural networks, we derive a global Lyapunov function which provides\nan energy landscape without any symmetry constraint. This newly obtained\n`nonequilibrium potential' (NEP) predicts with high accuracy the outcomes of\nthe dynamics in the globally stable cases studied here. Common features of the\nmodels in this class are bistability --with implications for working memory and\nslow neural oscillations --and `population burst', also relevant in\nneuroscience. Instead, limit cycles are not found. Their nonexistence can be\nproven by resort to the Bendixson--Dulac theorem, at least when the NEP remains\npositive and in the (also generic) singular limit of these models. Hopefully,\nthis NEP will help understand average neural network dynamics from a more\nformal standpoint, and will also be of help in the description of large\nheterogeneous neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 17:18:53 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Deza", "R. R.", ""], ["Deza", "J. I.", ""], ["Martinez", "N.", ""], ["Mejias", "J. F.", ""], ["Wio", "H. S.", ""]]}, {"id": "1808.08296", "submitter": "Xiaoxiao Li", "authors": "Xiaoxiao Li, Nicha C. Dvornek, Juntang Zhuang, Pamela Ventola and\n  James S. Duncan", "title": "Brain Biomarker Interpretation in ASD Using Deep Learning and fMRI", "comments": "8 pagers, accepted by MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism spectrum disorder (ASD) is a complex neurodevelopmental disorder.\nFinding the biomarkers associated with ASD is extremely helpful to understand\nthe underlying roots of the disorder and can lead to earlier diagnosis and more\ntargeted treatment. Although Deep Neural Networks (DNNs) have been applied in\nfunctional magnetic resonance imaging (fMRI) to identify ASD, understanding the\ndata-driven computational decision making procedure has not been previously\nexplored. Therefore, in this work, we address the problem of interpreting\nreliable biomarkers associated with identifying ASD; specifically, we propose a\n2-stage method that classifies ASD and control subjects using fMRI images and\ninterprets the saliency features activated by the classifier. First, we trained\nan accurate DNN classifier. Then, for detecting the biomarkers, different from\nthe DNN visualization works in computer vision, we take advantage of the\nanatomical structure of brain fMRI and develop a frequency-normalized sampling\nmethod to corrupt images. Furthermore, in the ASD vs. control subjects\nclassification scenario, we provide a new approach to detect and characterize\nimportant brain features into three categories. The biomarkers we found by the\nproposed method are robust and consistent with previous findings in the\nliterature. We also validate the detected biomarkers by neurological function\ndecoding and comparing with the DNN activation maps.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2018 06:24:56 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Li", "Xiaoxiao", ""], ["Dvornek", "Nicha C.", ""], ["Zhuang", "Juntang", ""], ["Ventola", "Pamela", ""], ["Duncan", "James S.", ""]]}, {"id": "1808.08306", "submitter": "Martin Frasch", "authors": "Martin G Frasch, Chao Shen, Hau-Tieng Wu, Alexander Mueller, Emily\n  Neuhaus, Raphael A. Bernier, Dana Kamara and Theodore P. Beauchaine", "title": "Can a composite heart rate variability biomarker shed new insights about\n  autism spectrum disorder in school-aged children?", "comments": null, "journal-ref": "Journal of Autism and Developmental Disorders, 2020", "doi": "10.1007/s10803-020-04467-7", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  High-frequency heart rate variability (HRV) has identified parasympathetic\nnervous system alterations in autism spectrum disorder (ASD). In a cohort of\nschool-aged children with and without ASD, we test a set of alternative linear\nand nonlinear HRV measures, including phase rectified signal averaging, applied\nto a segment of resting ECG, for associations with ASD vs. other psychiatric\nconditions. Using machine learning, we identify HRV measures derived from time,\nfrequency, and geometric signal-analytical domains that (1) identify children\nwith ASD relative to peers with receiver operating curve area of .89, and (2)\ndifferentiate such children from those with conduct problems or depression.\nDespite the small cohort and lack of prospective external validation, these\npreliminary results warrant larger prospective validation studies.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2018 20:49:30 GMT"}, {"version": "v2", "created": "Fri, 20 Sep 2019 21:14:24 GMT"}], "update_date": "2020-04-27", "authors_parsed": [["Frasch", "Martin G", ""], ["Shen", "Chao", ""], ["Wu", "Hau-Tieng", ""], ["Mueller", "Alexander", ""], ["Neuhaus", "Emily", ""], ["Bernier", "Raphael A.", ""], ["Kamara", "Dana", ""], ["Beauchaine", "Theodore P.", ""]]}, {"id": "1808.08565", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley", "title": "Affine Geometry, Visual Sensation, and Preference for Symmetry of Things\n  in a Thing", "comments": null, "journal-ref": "2016, Symmetry, 8, 127", "doi": "10.3390/sym8110127", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolution and geometry generate complexity in similar ways. Evolution drives\nnatural selection while geometry may capture the logic of this selection and\nexpress it visually, in terms of specific generic properties representing some\nkind of advantage. Geometry is ideally suited for expressing the logic of\nevolutionary selection for symmetry, which is found in the shape curves of vein\nsystems and other natural objects such as leaves, cell membranes, or tunnel\nsystems built by ants. The topology and geometry of symmetry is controlled by\nnumerical parameters, which act in analogy with a biological organism's DNA.\nThe introductory part of this paper reviews findings from experiments\nillustrating the critical role of two-dimensional design parameters and shape\nsymmetry for visual or tactile shape sensation, and for perception-based\ndecision making in populations of experts and non-experts. Thereafter, results\nfrom a pilot study on the effects of fractal symmetry, referred to herein as\nthe symmetry of things in a thing, on aesthetic judgments and visual preference\nare presented. In a first experiment (psychophysical scaling procedure),\nnon-expert observers had to rate (scale from 0 to 10) the perceived\nattractiveness of a random series of 2D fractal trees with varying degrees of\nfractal symmetry. In a second experiment (two-alternative forced choice\nprocedure), they had to express their preference for one of two shapes from the\nseries. The shape pairs were presented successively in random order. Results\nshow that the smallest possible fractal deviation from \"symmetry of things in a\nthing\" significantly reduces the perceived attractiveness of such shapes. The\npotential of future studies where different levels of complexity of fractal\npatterns are weighed against different degrees of symmetry is pointed out in\nthe conclusion.\n", "versions": [{"version": "v1", "created": "Sun, 26 Aug 2018 14:45:24 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Dresp-Langley", "Birgitta", ""]]}, {"id": "1808.08750", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, Carlos R. Medina Temme, Jonas Rauber, Heiko H.\n  Sch\\\"utt, Matthias Bethge, Felix A. Wichmann", "title": "Generalisation in humans and deep neural networks", "comments": "Added optimal probability aggregation method to appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the robustness of humans and current convolutional deep neural\nnetworks (DNNs) on object recognition under twelve different types of image\ndegradations. First, using three well known DNNs (ResNet-152, VGG-19,\nGoogLeNet) we find the human visual system to be more robust to nearly all of\nthe tested image manipulations, and we observe progressively diverging\nclassification error-patterns between humans and DNNs when the signal gets\nweaker. Secondly, we show that DNNs trained directly on distorted images\nconsistently surpass human performance on the exact distortion types they were\ntrained on, yet they display extremely poor generalisation abilities when\ntested on other distortion types. For example, training on salt-and-pepper\nnoise does not imply robustness on uniform white noise and vice versa. Thus,\nchanges in the noise distribution between training and testing constitutes a\ncrucial challenge to deep learning vision systems that can be systematically\naddressed in a lifelong machine learning approach. Our new dataset consisting\nof 83K carefully measured human psychophysical trials provide a useful\nreference for lifelong robustness against image degradations set by the human\nvisual system.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 09:17:57 GMT"}, {"version": "v2", "created": "Fri, 21 Dec 2018 16:26:58 GMT"}, {"version": "v3", "created": "Fri, 23 Oct 2020 09:05:30 GMT"}], "update_date": "2020-10-26", "authors_parsed": [["Geirhos", "Robert", ""], ["Temme", "Carlos R. Medina", ""], ["Rauber", "Jonas", ""], ["Sch\u00fctt", "Heiko H.", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""]]}, {"id": "1808.08820", "submitter": "Jianqiang Lin", "authors": "J. Lin, S. Guha, S. Ramanathan", "title": "Vanadium dioxide circuits emulate neurological disorders", "comments": "25 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information in the central nervous system (CNS) is conducted via electrical\nsignals known as action potentials and is encoded in time. Several neurological\ndisorders including depression, Attention Deficit Hyperactivity Disorder\n(ADHD), originate in faulty brain signaling frequencies. Here, we present a\nHodgkin-Huxley model analog for a strongly correlated VO2 artificial neuron\nsystem that undergoes an electrically-driven insulator-metal transition. We\ndemonstrate that tuning of the insulating phase resistance in VO2 threshold\nswitch circuits can enable direct mimicry of neuronal origins of disorders in\nthe central nervous system. The results introduce use of circuits based on\nquantum materials as complementary to model animal studies for neuroscience,\nespecially when precise measurements of local electrical properties or\ncompeting parallel paths for conduction in complex neural circuits can be a\nchallenge to identify onset of breakdown or diagnose early symptoms of disease.\n", "versions": [{"version": "v1", "created": "Mon, 27 Aug 2018 12:40:31 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Lin", "J.", ""], ["Guha", "S.", ""], ["Ramanathan", "S.", ""]]}, {"id": "1808.10315", "submitter": "Dmitry Petrov", "authors": "Dmitry Petrov, Boris A. Gutman Egor Kuznetsov, Theo G.M. van Erp,\n  Jessica A. Turner, Lianne Schmaal, Dick Veltman, Lei Wang, Kathryn Alpert,\n  Dmitry Isaev, Artemis Zavaliangos-Petropulu, Christopher R.K. Ching, Vince\n  Calhoun, David Glahn, Theodore D. Satterthwaite, Ole Andreas Andreassen,\n  Stefan Borgwardt, Fleur Howells, Nynke Groenewold, Aristotle Voineskos,\n  Joaquim Radua, Steven G. Potkin, Benedicto Crespo-Facorro, Diana\n  Tordesillas-Gutierrez, Li Shen, Irina Lebedeva, Gianfranco Spalletta, Gary\n  Donohoe, Peter Kochunov, Pedro G.P. Rosa, Anthony James, Udo Dannlowski,\n  Bernhard T. Baune, Andre Aleman, Ian H. Gotlib, Henrik Walter, Martin Walter,\n  Jair C. Soares, Stefan Ehrlich, Ruben C. Gur, N. Trung Doan, Ingrid Agartz,\n  Lars T. Westlye, Fabienne Harrisberger, Anita Riecher-Rossler, Anne Uhlmann,\n  Dan J. Stein, Erin W. Dickie, Edith Pomarol-Clotet, Paola Fuentes-Claramonte,\n  Erick Jorge Canales-Rodriguez, Raymond Salvador, Alexander J. Huang, Roberto\n  Roiz-Santianez, Shan Cong, Alexander Tomyshev, Fabrizio Piras, Daniela\n  Vecchio, Nerisa Banaj, Valentina Ciullo, Elliot Hong, Geraldo Busatto, Marcus\n  V. Zanetti, Mauricio H. Serpa, Simon Cervenka, Sinead Kelly, Dominik\n  Grotegerd, Matthew D. Sacchet, Ilya M. Veer, Meng Li, Mon-Ju Wu, Benson\n  Irungu, Esther Walton, Paul M. Thompson", "title": "Deep Learning for Quality Control of Subcortical Brain 3D Shape Models", "comments": "Accepted to Shape in Medical Imaging (ShapeMI) workshop at MICCAI\n  2018. arXiv admin note: substantial text overlap with arXiv:1707.06353", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several deep learning models for assessing the morphometric\nfidelity of deep grey matter region models extracted from brain MRI. We test\nthree different convolutional neural net architectures (VGGNet, ResNet and\nInception) over 2D maps of geometric features. Further, we present a novel\ngeometry feature augmentation technique based on a parametric spherical\nmapping. Finally, we present an approach for model decision visualization,\nallowing human raters to see the areas of subcortical shapes most likely to be\ndeemed of failing quality by the machine. Our training data is comprised of\n5200 subjects from the ENIGMA Schizophrenia MRI cohorts, and our test dataset\ncontains 1500 subjects from the ENIGMA Major Depressive Disorder cohorts. Our\nfinal models reduce human rater time by 46-70%. ResNet outperforms VGGNet and\nInception for all of our predictive tasks.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2018 14:31:48 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 08:12:34 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Petrov", "Dmitry", ""], ["Kuznetsov", "Boris A. Gutman Egor", ""], ["van Erp", "Theo G. M.", ""], ["Turner", "Jessica A.", ""], ["Schmaal", "Lianne", ""], ["Veltman", "Dick", ""], ["Wang", "Lei", ""], ["Alpert", "Kathryn", ""], ["Isaev", "Dmitry", ""], ["Zavaliangos-Petropulu", "Artemis", ""], ["Ching", "Christopher R. K.", ""], ["Calhoun", "Vince", ""], ["Glahn", "David", ""], ["Satterthwaite", "Theodore D.", ""], ["Andreassen", "Ole Andreas", ""], ["Borgwardt", "Stefan", ""], ["Howells", "Fleur", ""], ["Groenewold", "Nynke", ""], ["Voineskos", "Aristotle", ""], ["Radua", "Joaquim", ""], ["Potkin", "Steven G.", ""], ["Crespo-Facorro", "Benedicto", ""], ["Tordesillas-Gutierrez", "Diana", ""], ["Shen", "Li", ""], ["Lebedeva", "Irina", ""], ["Spalletta", "Gianfranco", ""], ["Donohoe", "Gary", ""], ["Kochunov", "Peter", ""], ["Rosa", "Pedro G. P.", ""], ["James", "Anthony", ""], ["Dannlowski", "Udo", ""], ["Baune", "Bernhard T.", ""], ["Aleman", "Andre", ""], ["Gotlib", "Ian H.", ""], ["Walter", "Henrik", ""], ["Walter", "Martin", ""], ["Soares", "Jair C.", ""], ["Ehrlich", "Stefan", ""], ["Gur", "Ruben C.", ""], ["Doan", "N. Trung", ""], ["Agartz", "Ingrid", ""], ["Westlye", "Lars T.", ""], ["Harrisberger", "Fabienne", ""], ["Riecher-Rossler", "Anita", ""], ["Uhlmann", "Anne", ""], ["Stein", "Dan J.", ""], ["Dickie", "Erin W.", ""], ["Pomarol-Clotet", "Edith", ""], ["Fuentes-Claramonte", "Paola", ""], ["Canales-Rodriguez", "Erick Jorge", ""], ["Salvador", "Raymond", ""], ["Huang", "Alexander J.", ""], ["Roiz-Santianez", "Roberto", ""], ["Cong", "Shan", ""], ["Tomyshev", "Alexander", ""], ["Piras", "Fabrizio", ""], ["Vecchio", "Daniela", ""], ["Banaj", "Nerisa", ""], ["Ciullo", "Valentina", ""], ["Hong", "Elliot", ""], ["Busatto", "Geraldo", ""], ["Zanetti", "Marcus V.", ""], ["Serpa", "Mauricio H.", ""], ["Cervenka", "Simon", ""], ["Kelly", "Sinead", ""], ["Grotegerd", "Dominik", ""], ["Sacchet", "Matthew D.", ""], ["Veer", "Ilya M.", ""], ["Li", "Meng", ""], ["Wu", "Mon-Ju", ""], ["Irungu", "Benson", ""], ["Walton", "Esther", ""], ["Thompson", "Paul M.", ""]]}, {"id": "1808.10806", "submitter": "Zsigmond Benk\\H{o}", "authors": "Zsigmond Benk\\H{o}, \\'Ad\\'am Zlatniczki, Marcell Stippinger, D\\'aniel\n  Fab\\'o, Andr\\'as S\\'olyom, Lor\\'and Er\\H{o}ss, Andr\\'as Telcs, Zolt\\'an\n  Somogyv\\'ari", "title": "Complete Inference of Causal Relations between Dynamical Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From philosophers of ancient times to modern economists, biologists and other\nresearchers are engaged in revealing causal relations. The most challenging\nproblem is inferring the type of the causal relationship: whether it is uni- or\nbi-directional or only apparent - implied by a hidden common cause only. Modern\ntechnology provides us tools to record data from complex systems such as the\necosystem of our planet or the human brain, but understanding their functioning\nneeds detection and distinction of causal relationships of the system\ncomponents without interventions. Here we present a new method, which\ndistinguishes and assigns probabilities to the presence of all the possible\ncausal relations between two or more time series from dynamical systems. The\nnew method is validated on synthetic datasets and applied to EEG\n(electroencephalographic) data recorded in epileptic patients. Given the\nuniversality of our method, it may find application in many fields of science.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 15:25:19 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2018 12:38:17 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 14:12:37 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Benk\u0151", "Zsigmond", ""], ["Zlatniczki", "\u00c1d\u00e1m", ""], ["Stippinger", "Marcell", ""], ["Fab\u00f3", "D\u00e1niel", ""], ["S\u00f3lyom", "Andr\u00e1s", ""], ["Er\u0151ss", "Lor\u00e1nd", ""], ["Telcs", "Andr\u00e1s", ""], ["Somogyv\u00e1ri", "Zolt\u00e1n", ""]]}, {"id": "1808.10852", "submitter": "Theerawit Wilaiprasitporn", "authors": "Patcharin Cheng, Phairot Autthasan, Boriwat Pijarana, Ekapol\n  Chuangsuwanich and Theerawit Wilaiprasitporn", "title": "Towards Asynchronous Motor Imagery-Based Brain-Computer Interfaces: a\n  joint training scheme using deep learning", "comments": null, "journal-ref": "TENCON 2018 - 2018 IEEE Region 10 Conference", "doi": "10.1109/TENCON.2018.8650546", "report-no": null, "categories": "eess.SP cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the deep learning (DL) approach is applied to a joint training\nscheme for asynchronous motor imagery-based Brain-Computer Interface (BCI). The\nproposed DL approach is a cascade of one-dimensional convolutional neural\nnetworks and fully-connected neural networks (CNN-FC). The focus is mainly on\nthree types of brain responses: non-imagery EEG (\\textit{background EEG}),\n(\\textit{pure imagery}) EEG, and EEG during the transitional period between\nbackground EEG and pure imagery (\\textit{transitional imagery}). The study of\ntransitional imagery signals should provide greater insight into real-world\nscenarios. It may be inferred that pure imagery and transitional EEG are high\nand low power EEG imagery, respectively. Moreover, the results from the CNN-FC\nare compared to the conventional approach for motor imagery-BCI, namely the\ncommon spatial pattern (CSP) for feature extraction and support vector machine\n(SVM) for classification (CSP-SVM). Under a joint training scheme, pure and\ntransitional imagery are treated as the same class, while background EEG is\nanother class. Ten-fold cross-validation is used to evaluate whether the joint\ntraining scheme significantly improves the performance task of classifying pure\nand transitional imagery signals from background EEG. Using sparse of just a\nfew electrode channels ($C_{z}$, $C_{3}$ and $C_{4}$), mean accuracy reaches\n71.52 % and 70.27 % for CNN-FC and CSP-SVM, respectively. On the other hand,\nmean accuracy without the joint training scheme achieve only 62.68 % and 52.41\n% for CNN-FC and CSP-SVM, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2018 17:30:05 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Cheng", "Patcharin", ""], ["Autthasan", "Phairot", ""], ["Pijarana", "Boriwat", ""], ["Chuangsuwanich", "Ekapol", ""], ["Wilaiprasitporn", "Theerawit", ""]]}]