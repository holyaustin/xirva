[{"id": "1712.00190", "submitter": "Muaz Niazi", "authors": "Ayesha Muqaddas, Muaz A. Niazi", "title": "Modeling the Multiple Sclerosis Brain Disease Using Agents: What Works\n  and What Doesn't?", "comments": "69 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.SE cs.SI nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain is one of the most complex living structures in the known\nUniverse. It consists of billions of neurons and synapses. Due to its intrinsic\ncomplexity, it can be a formidable task to accurately depict brain's structure\nand functionality. In the past, numerous studies have been conducted on\nmodeling brain disease, structure, and functionality. Some of these studies\nhave employed Agent-based approaches including multiagent-based simulation\nmodels as well as brain complex networks. While these models have all been\ndeveloped using agent-based computing, however, to our best knowledge, none of\nthem have employed the use of Agent-Oriented Software Engineering (AOSE)\nmethodologies in developing the brain or disease model. This is a problem\nbecause without due process, developed models can miss out on important\nrequirements. AOSE has the unique capability of merging concepts from\nmultiagent systems, agent-based modeling, artificial intelligence, besides\nconcepts from distributed systems. AOSE involves the various tested software\nengineering principles in various phases of the model development ranging from\nanalysis, design, implementation, and testing phases. In this paper, we employ\nthe use of three different AOSE methodologies for modeling the Multiple\nSclerosis brain disease namely GAIA, TROPOS, and MASE. After developing the\nmodels, we further employ the use of Exploratory Agent-based Modeling (EABM) to\ndevelop an actual model replicating previous results as a proof of concept. The\nkey objective of this study is to demonstrate and explore the viability and\neffectiveness of AOSE methodologies in the development of complex brain\nstructure and cognitive process models. Our key finding include demonstration\nthat AOSE methodologies can be considerably helpful in modeling various living\ncomplex systems, in general, and the human brain, in particular.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 04:44:14 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Muqaddas", "Ayesha", ""], ["Niazi", "Muaz A.", ""]]}, {"id": "1712.00306", "submitter": "Rodrigo Felipe de Oliveira Pena", "authors": "Rodrigo F.O. Pena, Cesar C. Ceballos, Vinicius Lima, and Antonio C.\n  Roque", "title": "Interplay of activation kinetics and the derivative conductance\n  determines resonance properties of neurons", "comments": "11 pages, 9 figures", "journal-ref": "Phys. Rev. E 97, 042408 (2018)", "doi": "10.1103/PhysRevE.97.042408", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a neuron with hyperpolarization activated current ($I_h$), the correct\ninput frequency leads to an enhancement of the output response. This behavior\nis known as resonance and is well described by the neuronal impedance. In a\nsimple neuron model we derive equations for the neuron's resonance and we link\nits frequency and existence with the biophysical properties of $I_h$. For a\nsmall voltage change, the component of the ratio of current change to voltage\nchange ($dI/dV$) due to the voltage-dependent conductance change ($dg/dV$) is\nknown as derivative conductance ($G_h^{Der}$). We show that both $G_h^{Der}$\nand the current activation kinetics (characterized by the activation time\nconstant $\\tau_h$) are mainly responsible for controlling the frequency and\nexistence of resonance. The increment of both factors ($G_h^{Der}$ and\n$\\tau_h$) greatly contributes to the appearance of resonance. We also\ndemonstrate that resonance is voltage dependent due to the voltage dependence\nof $G_h^{Der}$. Our results have important implications and can be used to\npredict and explain resonance properties of neurons with the $I_h$ current.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 13:21:16 GMT"}, {"version": "v2", "created": "Sat, 9 Dec 2017 13:19:56 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 18:38:47 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Pena", "Rodrigo F. O.", ""], ["Ceballos", "Cesar C.", ""], ["Lima", "Vinicius", ""], ["Roque", "Antonio C.", ""]]}, {"id": "1712.00359", "submitter": "Olha Shchur", "authors": "Alexander Vidybida, Olha Shchur", "title": "Relation between firing statistics of spiking neuron with delayed fast\n  inhibitory feedback and without feedback", "comments": "13 pages, 2 figures", "journal-ref": "Fluctuation and Noise Letters, Vol. 17, No. 01, 1850005 (2018)", "doi": "10.1142/S0219477518500050", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a class of spiking neuronal models, defined by a set of\nconditions typical for basic threshold-type models, such as the leaky\nintegrate-and-fire or the binding neuron model and also for some artificial\nneurons. A neuron is fed with a Poisson process. Each output impulse is applied\nto the neuron itself after a finite delay $\\Delta$. This impulse acts as being\ndelivered through a fast Cl-type inhibitory synapse. We derive a general\nrelation which allows calculating exactly the probability density function\n(pdf) $p(t)$ of output interspike intervals of a neuron with feedback based on\nknown pdf $p^0(t)$ for the same neuron without feedback and on the properties\nof the feedback line (the $\\Delta$ value). Similar relations between\ncorresponding moments are derived. Furthermore, we prove that initial segment\nof pdf $p^0(t)$ for a neuron with a fixed threshold level is the same for any\nneuron satisfying the imposed conditions and is completely determined by the\ninput stream. For the Poisson input stream, we calculate that initial segment\nexactly and, based on it, obtain exactly the initial segment of pdf $p(t)$ for\na neuron with feedback. That is the initial segment of $p(t)$ is\nmodel-independent as well. The obtained expressions are checked by means of\nMonte Carlo simulation. The course of $p(t)$ has a pronounced peculiarity,\nwhich makes it impossible to approximate $p(t)$ by Poisson or another simple\nstochastic process.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 15:21:27 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 11:16:30 GMT"}, {"version": "v3", "created": "Wed, 3 Oct 2018 07:14:28 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Vidybida", "Alexander", ""], ["Shchur", "Olha", ""]]}, {"id": "1712.00462", "submitter": "Johann H. Mart\\'inez", "authors": "Johann H. Mart\\'inez, Mar\\'ia E. L\\'opez, Pedro Ariza, Mario Chavez,\n  Jos\\'e A. Pineda-Pardo, David L\\'opez-Sanz, Pedro Gil, Fernando Maest\\'u and\n  Javier M. Buld\\'u", "title": "Functional brain networks reveal the existence of cognitive reserve and\n  the interplay between network topology and dynamics", "comments": "Main manuscript: 23 pages including references, 20 pages text, 8\n  figures and supplementary information included", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated how the organization of functional brain networks was related\nto cognitive reserve (CR) during a memory task in healthy aging. We obtained\nthe magnetoencephalographic functional networks of 20 elders with a high or low\nCR level to analyse the differences at network features. We reported a negative\ncorrelation between synchronization of the whole network and CR, and observed\ndifferences both at the node and at the network level in: the average shortest\npath and the network outreach. Individuals with high CR required functional\nnetworks with lower links to successfully carry out the memory task. These\nresults may indicate that those individuals with low CR level exhibited a dual\npattern of compensation and network impairment, since their functioning was\nmore energetically costly to perform the task as the high CR group.\nAdditionally, we evaluated how the dynamical properties of the different brain\nregions were correlated to the network parameters obtaining that entropy was\npositively correlated with the strength and clustering coefficient, while\ncomplexity behaved conversely. Consequently, highly connected nodes of the\nfunctional networks showed a more stochastic and less complex signal. We\nconsider that network approach may be a relevant tool to better understand\nbrain functioning in aging.\n", "versions": [{"version": "v1", "created": "Fri, 1 Dec 2017 19:09:32 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Mart\u00ednez", "Johann H.", ""], ["L\u00f3pez", "Mar\u00eda E.", ""], ["Ariza", "Pedro", ""], ["Chavez", "Mario", ""], ["Pineda-Pardo", "Jos\u00e9 A.", ""], ["L\u00f3pez-Sanz", "David", ""], ["Gil", "Pedro", ""], ["Maest\u00fa", "Fernando", ""], ["Buld\u00fa", "Javier M.", ""]]}, {"id": "1712.00683", "submitter": "Peter Helfer", "authors": "Peter Helfer and Thomas R. Shultz", "title": "Coupled feedback loops maintain synaptic long-term potentiation: A\n  computational model of PKMzeta synthesis and AMPA receptor trafficking", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1006147", "report-no": null, "categories": "q-bio.NC q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In long-term potentiation (LTP), one of the most studied types of neural\nplasticity, synaptic strength is persistently increased in response to\nstimulation. Although a number of different proteins have been implicated in\nthe sub-cellular molecular processes underlying induction and maintenance of\nLTP, the precise mechanisms remain unknown. A particular challenge is to\ndemonstrate that a proposed molecular mechanism can provide the level of\nstability needed to maintain memories for months or longer, in spite of the\nfact that many of the participating molecules have much shorter life spans.\nHere we present a computational model that combines simulations of several\nbiochemical reactions that have been suggested in the LTP literature and show\nthat the resulting system does exhibit the required stability. At the core of\nthe model are two interlinked feedback loops of molecular reactions, one\ninvolving the atypical protein kinase PKM{\\zeta} and its messenger RNA, the\nother involving PKM{\\zeta} and GluA2-containing AMPA receptors. We demonstrate\nthat robust bistability - stable equilibria both in the synapse's potentiated\nand unpotentiated states - can arise from a set of simple molecular reactions.\nThe model is able to account for a wide range of empirical results, including\ninduction and maintenance of late-phase LTP, cellular memory reconsolidation\nand the effects of different pharmaceutical interventions.\n", "versions": [{"version": "v1", "created": "Sat, 2 Dec 2017 23:54:01 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 20:55:55 GMT"}, {"version": "v3", "created": "Mon, 30 Apr 2018 23:12:38 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Helfer", "Peter", ""], ["Shultz", "Thomas R.", ""]]}, {"id": "1712.01277", "submitter": "Umberto Michieli", "authors": "Giulia Cisotto, Umberto Michieli, Leonardo Badia", "title": "A coherence study on EEG and EMG signals", "comments": "5 pages, 6 figures. Submitted and accepted at Global Wireless Summit\n  (GWS) 2016 at Aarhus University, Denmark.\n  http://www.riverpublishers.com/search_ebook.php?val=gws&type=research&Search=Search,\n  Proceedings of the Global Wireless Summit 2016. Editor: Peter Lindgren,\n  Aarhus University, Denmark. e-ISBN: 9788793609297", "journal-ref": "Proceedings of the Global Wireless Summit, 2016. Editor: Peter\n  Lindgren, Aarhus University, Denmark", "doi": null, "report-no": null, "categories": "physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this study is to investigate bursts- related EEG signals in a\nfocal hand dystonia patient. Despite of considering time domain and frequency\ndomain techniques as mutually exclusive analysis, in this contribution we have\ntaken advantage from both of them: particularly, in the frequency domain,\ncoherence was used to identify the most likely frequency bands of interaction\nbetween brain and muscles, then, in the time domain, cross-correlation was\nexploited to verify the physiological reliability of such a relationship in\nterms of signal transmission delay from the centre to the periphery. Our\npreliminary results suggest - in line with recent literature - that activity in\nthe high beta band (around 30 Hz) could represent an electroencephalographic\ncorrelate for the pathological electromyographic bursts affecting the focal\nhand dystonia condition. Even though a future study on a larger sample is\nneeded to statistically support these preliminary findings, this contribution\nallows to think of new kinds of rehabilitation from focal hand dystonia that\ncould target the actual electroencephalographic correlate of the pathology,\ni.e. phenotypically expressed by bursts, with the consequence of a relevant\nfunctional improvement.\n", "versions": [{"version": "v1", "created": "Mon, 4 Dec 2017 12:18:02 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Cisotto", "Giulia", ""], ["Michieli", "Umberto", ""], ["Badia", "Leonardo", ""]]}, {"id": "1712.01626", "submitter": "Pierre-Yves Oudeyer", "authors": "Pierre-Yves Oudeyer (Flowers)", "title": "Autonomous development and learning in artificial intelligence and\n  robotics: Scaling up deep learning to human--like learning", "comments": null, "journal-ref": "Behavioral and Brain Sciences, Cambridge University Press (CUP),\n  2017, 40", "doi": "10.1017/S0140525X17000243", "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous lifelong development and learning is a fundamental capability of\nhumans, differentiating them from current deep learning systems. However, other\nbranches of artificial intelligence have designed crucial ingredients towards\nautonomous learning: curiosity and intrinsic motivation, social learning and\nnatural interaction with peers, and embodiment. These mechanisms guide\nexploration and autonomous choice of goals, and integrating them with deep\nlearning opens stimulating perspectives. Deep learning (DL) approaches made\ngreat advances in artificial intelligence, but are still far away from human\nlearning. As argued convincingly by Lake et al., differences include human\ncapabilities to learn causal models of the world from very little data,\nleveraging compositional representations and priors like intuitive physics and\npsychology. However, there are other fundamental differences between current DL\nsystems and human learning, as well as technical ingredients to fill this gap,\nthat are either superficially, or not adequately, discussed by Lake et al.\nThese fundamental mechanisms relate to autonomous development and learning.\nThey are bound to play a central role in artificial intelligence in the future.\nCurrent DL systems require engineers to manually specify a task-specific\nobjective function for every new task, and learn through off-line processing of\nlarge training databases. On the contrary, humans learn autonomously open-ended\nrepertoires of skills, deciding for themselves which goals to pursue or value,\nand which skills to explore, driven by intrinsic motivation/curiosity and\nsocial learning through natural interaction with peers. Such learning processes\nare incremental, online, and progressive. Human child development involves a\nprogressive increase of complexity in a curriculum of learning where skills are\nexplored, acquired, and built on each other, through particular ordering and\ntiming. Finally, human learning happens in the physical world, and through\nbodily and physical experimentation, under severe constraints on energy, time,\nand computational resources. In the two last decades, the field of\nDevelopmental and Cognitive Robotics (Cangelosi and Schlesinger, 2015, Asada et\nal., 2009), in strong interaction with developmental psychology and\nneuroscience, has achieved significant advances in computational\n", "versions": [{"version": "v1", "created": "Tue, 5 Dec 2017 14:03:56 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Oudeyer", "Pierre-Yves", "", "Flowers"]]}, {"id": "1712.02142", "submitter": "Xi Wang", "authors": "Xi Wang and Marc Alexa", "title": "Maps of Visual Importance", "comments": "42 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of an element in a visual stimulus is commonly associated with\nthe fixations during a free-viewing task. We argue that fixations are not\nalways correlated with attention or awareness of visual objects. We suggest to\nfilter the fixations recorded during exploration of the image based on the\nfixations recorded during recalling the image against a neutral background.\nThis idea exploits that eye movements are a spatial index into the memory of a\nvisual stimulus. We perform an experiment in which we record the eye movements\nof 30 observers during the presentation and recollection of 100 images. The\nlocations of fixations during recall are only qualitatively related to the\nfixations during exploration. We develop a deformation mapping technique to\nalign the fixations from recall with the fixation during exploration. This\nallows filtering the fixations based on proximity and a threshold on proximity\nprovides a convenient slider to control the amount of filtering. Analyzing the\nspatial histograms resulting from the filtering procedure as well as the set of\nremoved fixations shows that certain types of scene elements, which could be\nconsidered irrelevant, are removed. In this sense, they provide a measure of\nimportance of visual elements for human observers.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 11:46:02 GMT"}], "update_date": "2017-12-07", "authors_parsed": [["Wang", "Xi", ""], ["Alexa", "Marc", ""]]}, {"id": "1712.02449", "submitter": "Giuseppe Pica", "authors": "Giuseppe Pica, Eugenio Piasini, Houman Safaai, Caroline A. Runyan,\n  Mathew E. Diamond, Tommaso Fellin, Christoph Kayser, Christopher D. Harvey,\n  Stefano Panzeri", "title": "Quantifying how much sensory information in a neural code is relevant\n  for behavior", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 30, 3689--3699,\n  2017", "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT math.IT physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Determining how much of the sensory information carried by a neural code\ncontributes to behavioral performance is key to understand sensory function and\nneural information flow. However, there are as yet no analytical tools to\ncompute this information that lies at the intersection between sensory coding\nand behavioral readout. Here we develop a novel measure, termed the\ninformation-theoretic intersection information $I_{II}(S;R;C)$, that quantifies\nhow much of the sensory information carried by a neural response R is used for\nbehavior during perceptual discrimination tasks. Building on the Partial\nInformation Decomposition framework, we define $I_{II}(S;R;C)$ as the part of\nthe mutual information between the stimulus S and the response R that also\ninforms the consequent behavioral choice C. We compute $I_{II}(S;R;C)$ in the\nanalysis of two experimental cortical datasets, to show how this measure can be\nused to compare quantitatively the contributions of spike timing and spike\nrates to task performance, and to identify brain areas or neural populations\nthat specifically transform sensory information into choice.\n", "versions": [{"version": "v1", "created": "Wed, 6 Dec 2017 23:55:56 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["Pica", "Giuseppe", ""], ["Piasini", "Eugenio", ""], ["Safaai", "Houman", ""], ["Runyan", "Caroline A.", ""], ["Diamond", "Mathew E.", ""], ["Fellin", "Tommaso", ""], ["Kayser", "Christoph", ""], ["Harvey", "Christopher D.", ""], ["Panzeri", "Stefano", ""]]}, {"id": "1712.02626", "submitter": "Vitor Manuel Dinis Pereira", "authors": "Vitor Manuel Dinis Pereira", "title": "Occipital and left temporal EEG correlates of phenomenal consciousness", "comments": "25 pages, 30 figures, chapter book, (2015).Tran, Q-N. and Arabnia,\n  H.R. (eds.). Emerging Trends in Computational Biology, Bioinformatics, and\n  Systems Biology. Elsevier/Morgan Kaufmann", "journal-ref": null, "doi": "10.1016/b978-0-12-802508-6.00018-1", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the first section, Introduction, we present our experimental design. In\nthe second section, we characterize the grand average occipital and temporal\nelectrical activity correlated with a contrast in access. In the third section,\nwe characterize the grand average occipital and temporal electrical activity\ncorrelated with a contrast in phenomenology and conclude characterizing the\ngrand average occipital and temporal electrical activity co-occurring with\nunconsciousness.\n", "versions": [{"version": "v1", "created": "Sun, 5 Nov 2017 00:43:09 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2020 14:58:08 GMT"}, {"version": "v3", "created": "Sat, 26 Dec 2020 17:16:19 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Pereira", "Vitor Manuel Dinis", ""]]}, {"id": "1712.02898", "submitter": "Alexei Koulakov", "authors": "Sergey Shuvaev, Hamza Giaffar, and Alexei A. Koulakov", "title": "Representations of Sound in Deep Learning of Audio Features from Music", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.CV eess.AS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The work of a single musician, group or composer can vary widely in terms of\nmusical style. Indeed, different stylistic elements, from performance medium\nand rhythm to harmony and texture, are typically exploited and developed across\nan artist's lifetime. Yet, there is often a discernable character to the work\nof, for instance, individual composers at the perceptual level - an experienced\nlistener can often pick up on subtle clues in the music to identify the\ncomposer or performer. Here we suggest that a convolutional network may learn\nthese subtle clues or features given an appropriate representation of the\nmusic. In this paper, we apply a deep convolutional neural network to a large\naudio dataset and empirically evaluate its performance on audio classification\ntasks. Our trained network demonstrates accurate performance on such\nclassification tasks when presented with 5 s examples of music obtained by\nsimple transformations of the raw audio waveform. A particularly interesting\nexample is the spectral representation of music obtained by application of a\nlogarithmically spaced filter bank, mirroring the early stages of auditory\nsignal transduction in mammals. The most successful representation of music to\nfacilitate discrimination was obtained via a random matrix transform (RMT).\nNetworks based on logarithmic filter banks and RMT were able to correctly guess\nthe one composer out of 31 possibilities in 68 and 84 percent of cases\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 8 Dec 2017 00:37:23 GMT"}], "update_date": "2017-12-11", "authors_parsed": [["Shuvaev", "Sergey", ""], ["Giaffar", "Hamza", ""], ["Koulakov", "Alexei A.", ""]]}, {"id": "1712.04195", "submitter": "Yoshihiro Nagano", "authors": "Yoshihiro Nagano, Ryo Karakida and Masato Okada", "title": "Concept Formation and Dynamics of Repeated Inference in Deep Generative\n  Models", "comments": "20 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep generative models are reported to be useful in broad applications\nincluding image generation. Repeated inference between data space and latent\nspace in these models can denoise cluttered images and improve the quality of\ninferred results. However, previous studies only qualitatively evaluated image\noutputs in data space, and the mechanism behind the inference has not been\ninvestigated. The purpose of the current study is to numerically analyze\nchanges in activity patterns of neurons in the latent space of a deep\ngenerative model called a \"variational auto-encoder\" (VAE). What kinds of\ninference dynamics the VAE demonstrates when noise is added to the input data\nare identified. The VAE embeds a dataset with clear cluster structures in the\nlatent space and the center of each cluster of multiple correlated data points\n(memories) is referred as the concept. Our study demonstrated that transient\ndynamics of inference first approaches a concept, and then moves close to a\nmemory. Moreover, the VAE revealed that the inference dynamics approaches a\nmore abstract concept to the extent that the uncertainty of input data\nincreases due to noise. It was demonstrated that by increasing the number of\nthe latent variables, the trend of the inference dynamics to approach a concept\ncan be enhanced, and the generalization ability of the VAE can be improved.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 09:55:11 GMT"}], "update_date": "2017-12-13", "authors_parsed": [["Nagano", "Yoshihiro", ""], ["Karakida", "Ryo", ""], ["Okada", "Masato", ""]]}, {"id": "1712.04329", "submitter": "Emre Baspinar", "authors": "Emre Baspinar and Giovanna Citti and Alessandro Sarti", "title": "A geometric model of multi-scale orientation preference maps via Gabor\n  functions", "comments": null, "journal-ref": "Math Imaging Vis (2018) 60: 900", "doi": "10.1007/s10851-018-0803-3", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new model for the generation of orientation\npreference maps in the primary visual cortex (V1), considering both orientation\nand scale features. First we undertake to model the functional architecture of\nV1 by interpreting it as a principal fiber bundle over the 2-dimensional\nretinal plane by introducing intrinsic variables orientation and scale. The\nintrinsic variables constitute a fiber on each point of the retinal plane and\nthe set of receptive profiles of simple cells is located on the fiber. Each\nreceptive profile on the fiber is mathematically interpreted as a rotated Gabor\nfunction derived from an uncertainty principle. The visual stimulus is lifted\nin a 4-dimensional space, characterized by coordinate variables, position,\norientation and scale, through a linear filtering of the stimulus with Gabor\nfunctions. Orientation preference maps are then obtained by mapping the\norientation value found from the lifting of a noise stimulus onto the\n2-dimensional retinal plane. This corresponds to a Bargmann transform in the\nreducible representation of the $\\text{SE}(2)=\\mathbb{R}^2\\times S^1$ group. A\ncomparison will be provided with a previous model based on the Bargman\ntransform in the irreducible representation of the $\\text{SE}(2)$ group,\noutlining that the new model is more physiologically motivated. Then we present\nsimulation results related to the construction of the orientation preference\nmap by using Gabor filters with different scales and compare those results to\nthe relevant neurophysiological findings in the literature.\n", "versions": [{"version": "v1", "created": "Tue, 12 Dec 2017 14:56:53 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Baspinar", "Emre", ""], ["Citti", "Giovanna", ""], ["Sarti", "Alessandro", ""]]}, {"id": "1712.04602", "submitter": "David Schwartz M", "authors": "David M. Schwartz and O. Ozan Koyluoglu", "title": "On the organization of grid and place cells: Neural de-noising via\n  subspace learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT cs.LG cs.NE math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Place cells in the hippocampus are active when an animal visits a certain\nlocation (referred to as a place field) within an environment. Grid cells in\nthe medial entorhinal cortex (MEC) respond at multiple locations, with firing\nfields that form a periodic and hexagonal tiling of the environment. The joint\nactivity of grid and place cell populations, as a function of location, forms a\nneural code for space. An ensemble of codes is generated by varying grid and\nplace cell population parameters. For each code in this ensemble, codewords are\ngenerated by stimulating a network with a discrete set of locations. In this\nmanuscript, we develop an understanding of the relationships between coding\ntheoretic properties of these combined populations and code construction\nparameters. These relationships are revisited by measuring the performances of\nbiologically realizable algorithms implemented by networks of place and grid\ncell populations, as well as constraint neurons, which perform de-noising\noperations. Objectives of this work include the investigation of coding\ntheoretic limitations of the mammalian neural code for location and how\ncommunication between grid and place cell networks may improve the accuracy of\neach population's representation. Simulations demonstrate that de-noising\nmechanisms analyzed here can significantly improve fidelity of this neural\nrepresentation of space. Further, patterns observed in connectivity of each\npopulation of simulated cells suggest that\ninter-hippocampal-medial-entorhinal-cortical connectivity decreases downward\nalong the dorsoventral axis.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 03:48:27 GMT"}, {"version": "v2", "created": "Tue, 15 May 2018 21:07:55 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Schwartz", "David M.", ""], ["Koyluoglu", "O. Ozan", ""]]}, {"id": "1712.04987", "submitter": "Kevin O'Regan", "authors": "Aurora Rizza, Alexander V. Terekhov, Guglielmo Montone, Marta Olivetti\n  Belardinelli, J. Kevin O'Regan", "title": "Why early tactile speech aids may have failed: no perceptual integration\n  of tactile and auditory signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tactile speech aids, though extensively studied in the 1980s and 90s, never\nbecame a commercial success. A hypothesis to explain this failure might be that\nit is difficult to obtain true perceptual integration of a tactile signal with\ninformation from auditory speech: exploitation of tactile cues from a tactile\naid might require cognitive effort and so prevent speech understanding at the\nhigh rates typical of everyday speech. To test this hypothesis, we attempted to\ncreate true perceptual integration of tactile with auditory information in what\nmight be considered the simplest situation encountered by a hearing-impaired\nlistener. We created an auditory continuum between the syllables BA and VA, and\ntrained participants to associate BA to one tactile stimulus VA to another\ntactile stimulus. After training, we tested if auditory discrimination along\nthe continuum between the two syllables could be biased by incongruent tactile\nstimulation. We found that such a bias occurred only when the tactile stimulus\nwas above its previously measured tactile discrimination threshold. Such a\npattern is compatible with the idea that the effect is due to a cognitive or\ndecisional strategy, rather than to truly perceptual integration. We therefore\nran a further study, where we created a tactile version of the McGurk effect.\nWe extensively trained two Subjects over six days to associate four recorded\nauditory syllables with four corresponding apparent motion tactile patterns. In\na subsequent test, we presented stimulation that was either congruent or\nincongruent with the learnt association, and asked Subjects to report the\nsyllable they perceived. We found no analog to the McGurk effect. These\nfindings strengthen our hypothesis according to which tactile aids failed\nbecause integration of tactile cues with auditory speech occurred at a\ncognitive or decisional level, rather than truly at a perceptual level\n", "versions": [{"version": "v1", "created": "Tue, 28 Nov 2017 09:30:34 GMT"}], "update_date": "2017-12-15", "authors_parsed": [["Rizza", "Aurora", ""], ["Terekhov", "Alexander V.", ""], ["Montone", "Guglielmo", ""], ["Belardinelli", "Marta Olivetti", ""], ["O'Regan", "J. Kevin", ""]]}, {"id": "1712.05197", "submitter": "Francisco Raposo", "authors": "Francisco Raposo, David Martins de Matos, Ricardo Ribeiro, Suhua Tang,\n  Yi Yu", "title": "Towards Deep Modeling of Music Semantics using EEG Regularizers", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SD eess.AS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling of music audio semantics has been previously tackled through\nlearning of mappings from audio data to high-level tags or latent unsupervised\nspaces. The resulting semantic spaces are theoretically limited, either because\nthe chosen high-level tags do not cover all of music semantics or because audio\ndata itself is not enough to determine music semantics. In this paper, we\npropose a generic framework for semantics modeling that focuses on the\nperception of the listener, through EEG data, in addition to audio data. We\nimplement this framework using a novel end-to-end 2-view Neural Network (NN)\narchitecture and a Deep Canonical Correlation Analysis (DCCA) loss function\nthat forces the semantic embedding spaces of both views to be maximally\ncorrelated. We also detail how the EEG dataset was collected and use it to\ntrain our proposed model. We evaluate the learned semantic space in a transfer\nlearning context, by using it as an audio feature extractor in an independent\ndataset and proxy task: music audio-lyrics cross-modal retrieval. We show that\nour embedding model outperforms Spotify features and performs comparably to a\nstate-of-the-art embedding model that was trained on 700 times more data. We\nfurther discuss improvements to the model that are likely to improve its\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 14 Dec 2017 12:27:11 GMT"}, {"version": "v2", "created": "Fri, 15 Dec 2017 15:57:29 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Raposo", "Francisco", ""], ["de Matos", "David Martins", ""], ["Ribeiro", "Ricardo", ""], ["Tang", "Suhua", ""], ["Yu", "Yi", ""]]}, {"id": "1712.05284", "submitter": "Miguel Aguilera", "authors": "Miguel Aguilera and Manuel G. Bedia", "title": "Adaptation to criticality through organizational invariance in embodied\n  agents", "comments": "arXiv admin note: substantial text overlap with arXiv:1704.05255", "journal-ref": "Aguilera, M., & Bedia, M. G. (2018). Adaptation to criticality\n  through organizational invariance in embodied agents. Scientific reports,\n  8(1), 7723", "doi": "10.1038/s41598-018-25925-4", "report-no": null, "categories": "nlin.AO cond-mat.dis-nn cond-mat.stat-mech cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many biological and cognitive systems do not operate deep within one or other\nregime of activity. Instead, they are poised at critical points located at\nphase transitions in their parameter space. The pervasiveness of criticality\nsuggests that there may be general principles inducing this behaviour, yet\nthere is no well-founded theory for understanding how criticality is generated\nat a wide span of levels and contexts. In order to explore how criticality\nmight emerge from general adaptive mechanisms, we propose a simple learning\nrule that maintains an internal organizational structure from a specific family\nof systems at criticality. We implement the mechanism in artificial embodied\nagents controlled by a neural network maintaining a correlation structure\nrandomly sampled from an Ising model at critical temperature. Agents are\nevaluated in two classical reinforcement learning scenarios: the Mountain Car\nand the Acrobot double pendulum. In both cases the neural controller appears to\nreach a point of criticality, which coincides with a transition point between\ntwo regimes of the agent's behaviour. These results suggest that adaptation to\ncriticality could be used as a general adaptive mechanism in some\ncircumstances, providing an alternative explanation for the pervasive presence\nof criticality in biological and cognitive systems.\n", "versions": [{"version": "v1", "created": "Wed, 13 Dec 2017 10:07:49 GMT"}, {"version": "v2", "created": "Fri, 16 Feb 2018 15:14:25 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 10:04:00 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Aguilera", "Miguel", ""], ["Bedia", "Manuel G.", ""]]}, {"id": "1712.05784", "submitter": "Gordon Berman", "authors": "Gordon J. Berman", "title": "Measuring behavior across scales", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.bio-ph q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The need for high-throughput, precise, and meaningful methods for measuring\nbehavior has been amplified by our recent successes in measuring and\nmanipulating neural circuitry. The largest challenges associated with moving in\nthis direction, however, are not technical but are instead conceptual: what\nnumbers should one put on the movements an animal is performing (or not\nperforming)? In this review, I will describe how theoretical and data\nanalytical ideas are interfacing with recently-developed computational and\nexperimental methodologies to answer these questions across a variety of\ncontexts, length scales, and time scales. I will attempt to highlight\ncommonalities between approaches and areas where further advances are necessary\nto place behavior on the same quantitative footing as other scientific fields.\n", "versions": [{"version": "v1", "created": "Fri, 15 Dec 2017 18:39:34 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Berman", "Gordon J.", ""]]}, {"id": "1712.06353", "submitter": "Christoph Metzner", "authors": "Christoph Metzner, Tuomo M\\\"aki-Marttunen, Bartosz Zurowski and Volker\n  Steuber", "title": "Modules for Automated Validation and Comparison of Models of\n  Neurophysiological and Neurocognitive Biomarkers of Psychiatric Disorders:\n  ASSRUnit - A Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The characterisation of biomarkers and endophenotypic measures has been a\ncentral goal of research in psychiatry over the last years. While most of this\nresearch has focused on the identification of biomarkers and endophenotypes,\nusing various experimental approaches, it has been recognised that their\ninstantiations, through computational models, have a great potential to help us\nunderstand and interpret these experimental results. However, the enormous\nincrease in available neurophysiological and neurocognitive as well as\ncomputational data also poses new challenges. How can a researcher stay on top\nof the experimental literature? How can computational modelling data be\nefficiently compared to experimental data? How can computational modelling most\neffectively inform experimentalists? Recently, a general scientific framework\nfor the generation of executable tests that automatically compare model results\nto experimental observations, SciUnit, has been proposed. Here we exploit this\nframework for research in psychiatry to address the challenges mentioned above.\nWe extend the SciUnit framework by adding an experimental database, which\ncontains a comprehensive collection of relevant experimental observations, and\na prediction database, which contains a collection of predictions generated by\ncomputational models. Together with appropriately designed SciUnit tests and\nmethods to mine and visualise the databases, model data and test results, this\nextended framework has the potential to greatly facilitate the use of\ncomputational models in psychiatry. As an initial example we present ASSRUnit,\na module for auditory steady-state response deficits in psychiatric disorders.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 11:58:35 GMT"}], "update_date": "2017-12-19", "authors_parsed": [["Metzner", "Christoph", ""], ["M\u00e4ki-Marttunen", "Tuomo", ""], ["Zurowski", "Bartosz", ""], ["Steuber", "Volker", ""]]}, {"id": "1712.06426", "submitter": "Laurens Michiels van Kessenich", "authors": "L. Michiels van Kessenich, M. Lukovi\\'c, L. de Arcangelis and H. J.\n  Herrmann", "title": "Critical neural networks with short and long term plasticity", "comments": "8 pages, 7 figures", "journal-ref": "Phys. Rev. E 97, 032312 (2018)", "doi": "10.1103/PhysRevE.97.032312", "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years self organised critical neuronal models have provided\ninsights regarding the origin of the experimentally observed avalanching\nbehaviour of neuronal systems. It has been shown that dynamical synapses, as a\nform of short-term plasticity, can cause critical neuronal dynamics. Whereas\nlong-term plasticity, such as hebbian or activity dependent plasticity, have a\ncrucial role in shaping the network structure and endowing neural systems with\nlearning abilities. In this work we provide a model which combines both\nplasticity mechanisms, acting on two different time-scales. The measured\navalanche statistics are compatible with experimental results for both the\navalanche size and duration distribution with biologically observed percentages\nof inhibitory neurons. The time-series of neuronal activity exhibits temporal\nbursts leading to 1/f decay in the power spectrum. The presence of long-term\nplasticity gives the system the ability to learn binary rules such as XOR,\nproviding the foundation of future research on more complicated tasks such as\npattern recognition.\n", "versions": [{"version": "v1", "created": "Mon, 18 Dec 2017 14:39:28 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["van Kessenich", "L. Michiels", ""], ["Lukovi\u0107", "M.", ""], ["de Arcangelis", "L.", ""], ["Herrmann", "H. J.", ""]]}, {"id": "1712.06745", "submitter": "Jun Kitazono", "authors": "Jun Kitazono, Ryota Kanai and Masafumi Oizumi", "title": "Efficient Algorithms for Searching the Minimum Information Partition in\n  Integrated Information Theory", "comments": null, "journal-ref": null, "doi": "10.3390/e20030173", "report-no": null, "categories": "q-bio.NC cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to integrate information in the brain is considered to be an\nessential property for cognition and consciousness. Integrated Information\nTheory (IIT) hypothesizes that the amount of integrated information ($\\Phi$) in\nthe brain is related to the level of consciousness. IIT proposes that to\nquantify information integration in a system as a whole, integrated information\nshould be measured across the partition of the system at which information loss\ncaused by partitioning is minimized, called the Minimum Information Partition\n(MIP). The computational cost for exhaustively searching for the MIP grows\nexponentially with system size, making it difficult to apply IIT to real neural\ndata. It has been previously shown that if a measure of $\\Phi$ satisfies a\nmathematical property, submodularity, the MIP can be found in a polynomial\norder by an optimization algorithm. However, although the first version of\n$\\Phi$ is submodular, the later versions are not. In this study, we empirically\nexplore to what extent the algorithm can be applied to the non-submodular\nmeasures of $\\Phi$ by evaluating the accuracy of the algorithm in simulated\ndata and real neural data. We find that the algorithm identifies the MIP in a\nnearly perfect manner even for the non-submodular measures. Our results show\nthat the algorithm allows us to measure $\\Phi$ in large systems within a\npractical amount of time.\n", "versions": [{"version": "v1", "created": "Tue, 19 Dec 2017 01:44:58 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 09:38:30 GMT"}], "update_date": "2018-04-04", "authors_parsed": [["Kitazono", "Jun", ""], ["Kanai", "Ryota", ""], ["Oizumi", "Masafumi", ""]]}, {"id": "1712.07369", "submitter": "Haichun Liu", "authors": "Yumeng Ye, Haichun Liu, TianHong Zhang, Changchun Pan, Genke Yang,\n  JiJun Wang, Robert C. Qiu", "title": "Improvement of Resting-state EEG Analysis Process with Spectrum\n  Weight-Voting based on LES", "comments": "9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  EEG is a non-invasive technique for recording brain bioelectric activity,\nwhich has potential applications in various fields such as human-computer\ninteraction and neuroscience. However, there are many difficulties in analyzing\nEEG data, including its complex composition, low amplitude as well as low\nsignal-to-noise ratio. Some of the existing methods of analysis are based on\nfeature extraction and machine learning to differentiate the phase of\nschizophrenia that samples belong to. However, medical research requires the\nuse of machine learning not only to give more accurate classification results,\nbut also to give the results that can be applied to pathological studies. The\nmain purpose of this study is to obtain the weight values as the representation\nof influence of each frequency band on the classification of schizophrenia\nphases on the basis of a more effective classification method using the LES\nfeature extraction, and then the weight values are processed and applied to\nimprove the accuracy of machine learning classification. We propose a method\ncalled weight-voting to obtain the weights of sub-bands features by using\nresults of classification for voting to fit the actual categories of EEG data,\nand using weights for reclassification. Through this method, we can first\nobtain the influence of each band in distinguishing three schizophrenia phases,\nand analyze the effect of band features on the risk of schizophrenia\ncontributing to the study of psychopathology. Our results show that there is a\nhigh correlation between the change of weight of low gamma band and the\ndifference between HC, CHR and FES. If the features revised according to\nweights are used for reclassification, the accuracy of result will be improved\ncompared with the original classifier, which confirms the role of the band\nweight distribution.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 09:10:33 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 13:08:15 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Ye", "Yumeng", ""], ["Liu", "Haichun", ""], ["Zhang", "TianHong", ""], ["Pan", "Changchun", ""], ["Yang", "Genke", ""], ["Wang", "JiJun", ""], ["Qiu", "Robert C.", ""]]}, {"id": "1712.07417", "submitter": "Peter beim Graben", "authors": "Peter beim Graben and Reinhard Blutner", "title": "Quantum approaches to music cognition", "comments": "Submitted ms, 38 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum cognition emerged as an important discipline of mathematical\npsychology during the last two decades. Using abstract analogies between mental\nphenomena and the formal framework of physical quantum theory, quantum\ncognition demonstrated its ability to resolve several puzzles from cognitive\npsychology. Until now, quantum cognition essentially exploited ideas from\nprojective (Hilbert space) geometry, such as quantum probability or quantum\nsimilarity. However, many powerful tools provided by physical quantum theory,\ne.g., symmetry groups have not been utilized in the field of quantum cognition\nresearch sofar. Inspired by seminal work by Guerino Mazzola on the symmetries\nof tonal music, our study aims at elucidating and reconciling static and\ndynamic tonal attraction phenomena in music psychology within the quantum\ncognition framework. Based on the fundamental principles of octave equivalence,\nfifth similarity and transposition symmetry of tonal music that are reflected\nby the structure of the circle of fifths, we develop different wave function\ndescriptions over this underlying tonal space. We present quantum models for\nstatic and dynamic tonal attraction and compare them with traditional\ncomputational models in musicology. Our approach replicates and also improves\npredictions based on symbolic models of music perception.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 11:19:00 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2018 08:33:00 GMT"}, {"version": "v3", "created": "Fri, 19 Oct 2018 08:14:04 GMT"}, {"version": "v4", "created": "Fri, 18 Jan 2019 12:44:29 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Graben", "Peter beim", ""], ["Blutner", "Reinhard", ""]]}, {"id": "1712.07443", "submitter": "Eli Kinney-Lang", "authors": "Eli Kinney-Lang, Loukianos Spyrou, Ahmed Ebied, Richard FM Chin,\n  Javier Escudero", "title": "Tensor-driven extraction of developmental features from varying\n  paediatric EEG datasets", "comments": "16 pages, 6 figures, pre-print, under consideration for publication.\n  Reduced figure resolution due to size limit-please contact corresponding\n  author for full figure resolution", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective. Consistently changing physiological properties in developing\nchildren's brains challenges new data heavy technologies, like brain-computer\ninterfaces (BCI). Advancing signal processing methods in such technologies to\nbe more sensitive to developmental changes could help improve their function\nand usability in paediatric populations. Taking advantage of the\nmulti-dimensional structure of EEG data through tensor analysis offers a\nframework to extract relevant developmental features present in paediatric\nresting-state EEG datasets. Methods. Three paediatric datasets from varying\ndevelopmental states and populations were analyzed using a developed two-step\nconstrained Parallel Factor (PARAFAC) tensor decomposition. The datasets\nincluded the Muir Maxwell Epilepsy Centre, Children's Hospital Boston-MIT and\nthe Child Mind Institute, outlining two impaired and one healthy population,\nrespectively. Within dataset cross-validation used support vector machines\n(SVM) for classification of out-of-fold data predicting subject age as a proxy\nmeasure of development. t-distributed Stochastic Neighbour Embedding (t-SNE)\nmaps complemented classification analysis through visualization of the\nhigh-dimensional feature structures. Main Results. Development-sensitive\nfeatures were successfully identified for the developmental conditions of each\ndataset. SVM classification accuracy and misclassification costs were improved\nsignificantly for both healthy and impaired paediatric populations. t-SNE maps\nrevealed suitable tensor factorization was key in extracting developmental\nfeatures. Significance. The described methods are a promising tool for\nincorporating the unique developmental features present throughout childhood\nEEG into new technologies like BCI and its applications.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 12:28:22 GMT"}], "update_date": "2017-12-21", "authors_parsed": [["Kinney-Lang", "Eli", ""], ["Spyrou", "Loukianos", ""], ["Ebied", "Ahmed", ""], ["Chin", "Richard FM", ""], ["Escudero", "Javier", ""]]}, {"id": "1712.07843", "submitter": "Matej Hoffmann", "authors": "Matej Hoffmann", "title": "The role of self-touch experience in the formation of the self", "comments": "4 pages", "journal-ref": "The Development of the Self Workshop at IEEE ICDL-EpiRob 2017", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human self has many facets: there is the physical body and then there are\ndifferent concepts or representations supported by processes in the brain such\nas the ecological, social, temporal, conceptual, and experiential self. The\nmechanisms of operation and formation of the self are, however, largely\nunknown. The basis is constituted by the ecological or sensorimotor self that\ndeals with the configuration of the body in space and its action possibilities.\nThis self is prereflective, prelinguistic, and initially perhaps even largely\nindependent of visual inputs. Instead, somatosensory (tactile and\nproprioceptive) information both before and after birth may play a key part. In\nthis paper, we propose that self-touch experience may be a fundamental\nmechanisms to bootstrap the formation of the sensorimotor self and perhaps even\nbeyond. We will investigate this from the perspectives of phenomenology,\ndevelopmental psychology, and neuroscience. In light of the evidence from fetus\nand infant development, we will speculate about the possible mechanisms that\nmay drive the formation of first body representations drawing on self-touch\nexperience.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 09:19:00 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Hoffmann", "Matej", ""]]}, {"id": "1712.08041", "submitter": "Payel Das", "authors": "Ravi Tejwani, Adam Liska, Hongyuan You, Jenna Reinen, and Payel Das", "title": "Autism Classification Using Brain Functional Connectivity Dynamics and\n  Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of the present study is to identify autism using machine learning\ntechniques and resting-state brain imaging data, leveraging the temporal\nvariability of the functional connections (FC) as the only information. We\nestimated and compared the FC variability across brain regions between typical,\nhealthy subjects and autistic population by analyzing brain imaging data from a\nworld-wide multi-site database known as ABIDE (Autism Brain Imaging Data\nExchange). Our analysis revealed that patients diagnosed with autism spectrum\ndisorder (ASD) show increased FC variability in several brain regions that are\nassociated with low FC variability in the typical brain. We then used the\nenhanced FC variability of brain regions as features for training machine\nlearning models for ASD classification and achieved 65% accuracy in\nidentification of ASD versus control subjects within the dataset. We also used\nnode strength estimated from number of functional connections per node averaged\nover the whole scan as features for ASD classification.The results reveal that\nthe dynamic FC measures outperform or are comparable with the static FC\nmeasures in predicting ASD.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 16:08:16 GMT"}], "update_date": "2017-12-22", "authors_parsed": [["Tejwani", "Ravi", ""], ["Liska", "Adam", ""], ["You", "Hongyuan", ""], ["Reinen", "Jenna", ""], ["Das", "Payel", ""]]}, {"id": "1712.08180", "submitter": "Pantea Moghimi", "authors": "Pantea Moghimi, Kelvin O. Lim, Theoden I. Netoff", "title": "Construction and Evaluation of Hierarchical Parcellation of the Brain\n  using fMRI with Prewhitening", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Brain atlases are a ubiquitous tool used for analyzing and interpreting brain\nimaging datasets. Traditionally, brain atlases divided the brain into regions\nseparated by anatomical landmarks. In the last decade, several attempts have\nbeen made to parcellate the brain into regions with distinct functional\nactivity using fMRI. To construct a brain atlas using fMRI, data driven\nalgorithms are used to group voxels with similar functional activity together\nto form regions. Hierarchical clustering is one parcellation method that has\nbeen used for functional parcellation of the brain, resulting in parcellations\nthat align well with cytoarchitectonic divisions of the brain. However, few\nrigorous data driven evaluations of the method have been performed. Moreover,\nthe effect of removing autocorrelation trends from fMRI time series\n(prewhitening) on the structure of the resultant atlas has not been previously\nexplored. In this paper, we use hierarchical clustering to produce functional\nparcellations of the brain using hierarchical clustering. We use both\nprewhitened and raw fMRI time series to construct the atlas. The resultant\natlases were then evaluated for their homogeneity, separation between regions,\nreproducibility across subjects, and reproducibility across scans.\n", "versions": [{"version": "v1", "created": "Thu, 21 Dec 2017 19:22:57 GMT"}, {"version": "v2", "created": "Wed, 7 Feb 2018 15:32:26 GMT"}], "update_date": "2018-02-08", "authors_parsed": [["Moghimi", "Pantea", ""], ["Lim", "Kelvin O.", ""], ["Netoff", "Theoden I.", ""]]}, {"id": "1712.08336", "submitter": "Shankha Sanyal", "authors": "Sayan Nag, Shankha Sanyal, Archi Banerjee, Ranjan Sengupta and Dipak\n  Ghosh", "title": "Music of Brain and Music on Brain: A Novel EEG Sonification approach", "comments": "6 pages, 4 figures; Presented in the International Symposium on\n  Frontiers of Research in speech and Music (FRSM)-2017, held at NIT, Rourkela\n  in 15-16 December 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.SD eess.AS physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can we hear the sound of our brain? Is there any technique which can enable\nus to hear the neuro-electrical impulses originating from the different lobes\nof brain? The answer to all these questions is YES. In this paper we present a\nnovel method with which we can sonify the Electroencephalogram (EEG) data\nrecorded in rest state as well as under the influence of a simplest acoustical\nstimuli - a tanpura drone. The tanpura drone has a very simple yet very complex\nacoustic features, which is generally used for creation of an ambiance during a\nmusical performance. Hence, for this pilot project we chose to study the\ncorrelation between a simple acoustic stimuli (tanpura drone) and sonified EEG\ndata. Till date, there have been no study which deals with the direct\ncorrelation between a bio-signal and its acoustic counterpart and how that\ncorrelation varies under the influence of different types of stimuli. This is\nthe first of its kind study which bridges this gap and looks for a direct\ncorrelation between music signal and EEG data using a robust mathematical\nmicroscope called Multifractal Detrended Cross Correlation Analysis (MFDXA).\nFor this, we took EEG data of 10 participants in 2 min 'rest state' (i.e. with\nwhite noise) and in 2 min 'tanpura drone' (musical stimulus) listening\ncondition. Next, the EEG signals from different electrodes were sonified and\nMFDXA technique was used to assess the degree of correlation (or the cross\ncorrelation coefficient) between tanpura signal and EEG signals. The variation\nof {\\gamma}x for different lobes during the course of the experiment also\nprovides major interesting new information. Only music stimuli has the ability\nto engage several areas of the brain significantly unlike other stimuli (which\nengages specific domains only).\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 08:30:47 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Nag", "Sayan", ""], ["Sanyal", "Shankha", ""], ["Banerjee", "Archi", ""], ["Sengupta", "Ranjan", ""], ["Ghosh", "Dipak", ""]]}, {"id": "1712.08547", "submitter": "Hwayeon Ryu", "authors": "Hwayeon Ryu, Sue Ann Campbell", "title": "Geometric Analysis of Synchronization in Neuronal Networks with Global\n  Inhibition and Coupling Delays", "comments": "43 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study synaptically coupled neuronal networks to identify the role of\ncoupling delays in network's synchronized behaviors. We consider a network of\nexcitable, relaxation oscillator neurons where two distinct populations, one\nexcitatory and one inhibitory, are coupled and interact with each other. The\nexcitatory population is uncoupled, while the inhibitory population is tightly\ncoupled. A geometric singular perturbation analysis yields existence and\nstability conditions for synchronization states under different firing patterns\nbetween the two populations, along with formulas for the periods of such\nsynchronous solutions. Our results demonstrate that the presence of coupling\ndelays in the network promotes synchronization. Numerical simulations are\nconducted to supplement and validate analytical results. We show the results\ncarry over to a model for spindle sleep rhythms in thalamocortical networks,\none of the biological systems which motivated our study. The analysis helps to\nexplain how coupling delays in either excitatory or inhibitory synapses\ncontribute to producing synchronized rhythms.\n", "versions": [{"version": "v1", "created": "Fri, 22 Dec 2017 16:15:58 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 05:05:32 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Ryu", "Hwayeon", ""], ["Campbell", "Sue Ann", ""]]}, {"id": "1712.09206", "submitter": "Priyadarshini Panda", "authors": "Priyadarshini Panda, and Kaushik Roy", "title": "Chaos-guided Input Structuring for Improved Learning in Recurrent Neural\n  Networks", "comments": "11 pages with 5 figures including supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anatomical studies demonstrate that brain reformats input information to\ngenerate reliable responses for performing computations. However, it remains\nunclear how neural circuits encode complex spatio-temporal patterns. We show\nthat neural dynamics are strongly influenced by the phase alignment between the\ninput and the spontaneous chaotic activity. Input structuring along the\ndominant chaotic projections causes the chaotic trajectories to become stable\nchannels (or attractors), hence, improving the computational capability of a\nrecurrent network. Using mean field analysis, we derive the impact of input\nstructuring on the overall stability of attractors formed. Our results indicate\nthat input alignment determines the extent of intrinsic noise suppression and\nhence, alters the attractor state stability, thereby controlling the network's\ninference ability.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 08:29:32 GMT"}, {"version": "v2", "created": "Wed, 17 Jan 2018 15:53:23 GMT"}, {"version": "v3", "created": "Sun, 18 Feb 2018 18:58:48 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Panda", "Priyadarshini", ""], ["Roy", "Kaushik", ""]]}, {"id": "1712.09479", "submitter": "Yunxiang Ge", "authors": "Yunxiang Ge, Yu Pan and Weibei Dou", "title": "Analysis of BOLD fMRI Signal Preprocessing Pipeline on Different\n  Datasets while Reducing False Positive Rates", "comments": "ICBIBE 2018 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technology of functional Magnetic Resonance Imaging (fMRI) based on Blood\nOxygen Level Dependent (BOLD) signal has been widely used in clinical\ntreatments and brain function researches. The BOLD signal has to be\npreprocessed before being analyzed using either functional connectivity\nmeasurements or statistical methods. Current researches show that data\npreprocessing steps may influence the results of analysis, yet there is no\nconsensus on preprocessing method. In this paper, an evaluation method is\nproposed for analyzing the preprocessing pipeline of resting state BOLD fMRI\n(rs-BOLD fMRI) data under putative task experiment designs to cast some lights\non the preprocessing stage, covering both first and second level analysis. The\nchoices of preprocessing parameters and steps are altered to investigate\npreprocessing pipelines while observing statistical analysis results, trying to\nreduce false positives as reported by Eklund et al. in their 2016 PNAS paper.\nAll of the experiment data are separated into 7 datasets, consisting of 220\nhealthy control samples and 136 patient data that are from 38 incomplete Spinal\nCord Injury (SCI) patients and 16 Cerebral Stroke (CS) patients, including\nmultiple scans of some patients at different time. These data were acquired\nfrom two different MRI scanners, which may cause difference in analysis\nresults. The evaluation result shows that it has little effect to change\nparameters in each steps of the classical preprocessing pipeline, which\nconsists head motion correction, normalization and smoothing. Removing time\npoints and the following detrend step can reduce false positives. However,\ncovariates regression and filtering has complicated effects on the data. Note\nthat for single subject analysis, false positives declined consistently after\nfiltering. The result of patient data and healthy controls data which are\nscanned under the same machine with ...\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 02:20:25 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Ge", "Yunxiang", ""], ["Pan", "Yu", ""], ["Dou", "Weibei", ""]]}, {"id": "1712.09644", "submitter": "William Mayner", "authors": "William G. P. Mayner, William Marshall, Larissa Albantakis, Graham\n  Findlay, Robert Marchman, Giulio Tononi", "title": "PyPhi: A toolbox for integrated information theory", "comments": "22 pages, 4 figures, 6 pages of appendices. Supporting information\n  \"S1 Calculating Phi\" can be found in the ancillary files", "journal-ref": "PLOS Computational Biology 14(7): e1006343. 2018", "doi": "10.1371/journal.pcbi.1006343", "report-no": null, "categories": "q-bio.NC cs.AI q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Integrated information theory provides a mathematical framework to fully\ncharacterize the cause-effect structure of a physical system. Here, we\nintroduce PyPhi, a Python software package that implements this framework for\ncausal analysis and unfolds the full cause-effect structure of discrete\ndynamical systems of binary elements. The software allows users to easily study\nthese structures, serves as an up-to-date reference implementation of the\nformalisms of integrated information theory, and has been applied in research\non complexity, emergence, and certain biological questions. We first provide an\noverview of the main algorithm and demonstrate PyPhi's functionality in the\ncourse of analyzing an example system, and then describe details of the\nalgorithm's design and implementation.\n  PyPhi can be installed with Python's package manager via the command 'pip\ninstall pyphi' on Linux and macOS systems equipped with Python 3.4 or higher.\nPyPhi is open-source and licensed under the GPLv3; the source code is hosted on\nGitHub at https://github.com/wmayner/pyphi . Comprehensive and\ncontinually-updated documentation is available at https://pyphi.readthedocs.io/\n. The pyphi-users mailing list can be joined at\nhttps://groups.google.com/forum/#!forum/pyphi-users . A web-based graphical\ninterface to the software is available at\nhttp://integratedinformationtheory.org/calculate.html .\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 18:01:12 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 17:45:30 GMT"}, {"version": "v3", "created": "Wed, 27 Jun 2018 09:52:27 GMT"}], "update_date": "2018-08-16", "authors_parsed": [["Mayner", "William G. P.", ""], ["Marshall", "William", ""], ["Albantakis", "Larissa", ""], ["Findlay", "Graham", ""], ["Marchman", "Robert", ""], ["Tononi", "Giulio", ""]]}, {"id": "1712.09771", "submitter": "Meysam Golmohammadi", "authors": "Meysam Golmohammadi, Amir Hossein Harati Nejad Torbati, Silvia Lopez\n  de Diego, Iyad Obeid, and Joseph Picone", "title": "Automatic Analysis of EEGs Using Big Data and Hybrid Deep Learning\n  Architectures", "comments": "Under review in Journal of Clinical Neurophysiology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: A clinical decision support tool that automatically interprets\nEEGs can reduce time to diagnosis and enhance real-time applications such as\nICU monitoring. Clinicians have indicated that a sensitivity of 95% with a\nspecificity below 5% was the minimum requirement for clinical acceptance. We\npropose a highperformance classification system based on principles of big data\nand machine learning. Methods: A hybrid machine learning system that uses\nhidden Markov models (HMM) for sequential decoding and deep learning networks\nfor postprocessing is proposed. These algorithms were trained and evaluated\nusing the TUH EEG Corpus, which is the world's largest publicly available\ndatabase of clinical EEG data. Results: Our approach delivers a sensitivity\nabove 90% while maintaining a specificity below 5%. This system detects three\nevents of clinical interest: (1) spike and/or sharp waves, (2) periodic\nlateralized epileptiform discharges, (3) generalized periodic epileptiform\ndischarges. It also detects three events used to model background noise: (1)\nartifacts, (2) eye movement (3) background. Conclusions: A hybrid HMM/deep\nlearning system can deliver a low false alarm rate on EEG event detection,\nmaking automated analysis a viable option for clinicians. Significance: The TUH\nEEG Corpus enables application of highly data consumptive machine learning\nalgorithms to EEG analysis. Performance is approaching clinical acceptance for\nreal-time applications.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 06:22:28 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Golmohammadi", "Meysam", ""], ["Torbati", "Amir Hossein Harati Nejad", ""], ["de Diego", "Silvia Lopez", ""], ["Obeid", "Iyad", ""], ["Picone", "Joseph", ""]]}, {"id": "1712.09776", "submitter": "Meysam Golmohammadi", "authors": "Meysam Golmohammadi, Saeedeh Ziyabari, Vinit Shah, Silvia Lopez de\n  Diego, Iyad Obeid, and Joseph Picone", "title": "Deep Architectures for Automated Seizure Detection in Scalp EEGs", "comments": "nder review in International Conference on Machine Learning,\n  Stockholm, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated seizure detection using clinical electroencephalograms is a\nchallenging machine learning problem because the multichannel signal often has\nan extremely low signal to noise ratio. Events of interest such as seizures are\neasily confused with signal artifacts (e.g, eye movements) or benign variants\n(e.g., slowing). Commercially available systems suffer from unacceptably high\nfalse alarm rates. Deep learning algorithms that employ high dimensional models\nhave not previously been effective due to the lack of big data resources. In\nthis paper, we use the TUH EEG Seizure Corpus to evaluate a variety of hybrid\ndeep structures including Convolutional Neural Networks and Long Short-Term\nMemory Networks. We introduce a novel recurrent convolutional architecture that\ndelivers 30% sensitivity at 7 false alarms per 24 hours. We have also evaluated\nour system on a held-out evaluation set based on the Duke University Seizure\nCorpus and demonstrate that performance trends are similar to the TUH EEG\nSeizure Corpus. This is a significant finding because the Duke corpus was\ncollected with different instrumentation and at different hospitals. Our work\nshows that deep learning architectures that integrate spatial and temporal\ncontexts are critical to achieving state of the art performance and will enable\na new generation of clinically-acceptable technology.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 06:31:22 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Golmohammadi", "Meysam", ""], ["Ziyabari", "Saeedeh", ""], ["Shah", "Vinit", ""], ["de Diego", "Silvia Lopez", ""], ["Obeid", "Iyad", ""], ["Picone", "Joseph", ""]]}, {"id": "1712.10062", "submitter": "Aditya Gilra", "authors": "Marco Martinolli, Wulfram Gerstner and Aditya Gilra", "title": "Multi-timescale memory dynamics in a reinforcement learning network with\n  attention-gated memory", "comments": null, "journal-ref": "Frontiers in Computational Neuroscience, 12 July 2018 |\n  https://doi.org/10.3389/fncom.2018.00050", "doi": "10.3389/fncom.2018.00050", "report-no": null, "categories": "q-bio.NC cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning and memory are intertwined in our brain and their relationship is at\nthe core of several recent neural network models. In particular, the\nAttention-Gated MEmory Tagging model (AuGMEnT) is a reinforcement learning\nnetwork with an emphasis on biological plausibility of memory dynamics and\nlearning. We find that the AuGMEnT network does not solve some hierarchical\ntasks, where higher-level stimuli have to be maintained over a long time, while\nlower-level stimuli need to be remembered and forgotten over a shorter\ntimescale. To overcome this limitation, we introduce hybrid AuGMEnT, with leaky\nor short-timescale and non-leaky or long-timescale units in memory, that allow\nto exchange lower-level information while maintaining higher-level one, thus\nsolving both hierarchical and distractor tasks.\n", "versions": [{"version": "v1", "created": "Thu, 28 Dec 2017 21:26:43 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Martinolli", "Marco", ""], ["Gerstner", "Wulfram", ""], ["Gilra", "Aditya", ""]]}, {"id": "1712.10158", "submitter": "Aditya Gilra", "authors": "Aditya Gilra and Wulfram Gerstner", "title": "Non-linear motor control by local learning in spiking neural networks", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80:1773-1782, 2018", "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG cs.NE cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning weights in a spiking neural network with hidden neurons, using\nlocal, stable and online rules, to control non-linear body dynamics is an open\nproblem. Here, we employ a supervised scheme, Feedback-based Online Local\nLearning Of Weights (FOLLOW), to train a network of heterogeneous spiking\nneurons with hidden layers, to control a two-link arm so as to reproduce a\ndesired state trajectory. The network first learns an inverse model of the\nnon-linear dynamics, i.e. from state trajectory as input to the network, it\nlearns to infer the continuous-time command that produced the trajectory.\nConnection weights are adjusted via a local plasticity rule that involves\npre-synaptic firing and post-synaptic feedback of the error in the inferred\ncommand. We choose a network architecture, termed differential feedforward,\nthat gives the lowest test error from different feedforward and recurrent\narchitectures. The learned inverse model is then used to generate a\ncontinuous-time motor command to control the arm, given a desired trajectory.\n", "versions": [{"version": "v1", "created": "Fri, 29 Dec 2017 09:21:34 GMT"}], "update_date": "2019-02-19", "authors_parsed": [["Gilra", "Aditya", ""], ["Gerstner", "Wulfram", ""]]}, {"id": "1712.10280", "submitter": "Hongbo Jia", "authors": "Hongbo Jia", "title": "First Draft on the xInf Model for Universal Physical Computation and\n  Reverse Engineering of Natural Intelligence", "comments": "32 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Turing Machines are universal computing machines in theory. It has been a\nlong debate whether Turing Machines can simulate the consciousness mind\nbehaviors in the materialistic universe. Three different hypotheses come out of\nsuch debate, in short:(A) Can; (B) Cannot; (C) Super-Turing machines can.\nBecause Turing Machines or other kinds of theoretical computing models are\nabstract objects while behaviors are real observables, this debate involves at\nleast three distinct fields of science and technology: physics, computer\nengineering, and experimental neuroscience. However, the languages used in\nthese different fields are highly heterogeneous and not easily interpretable\nfor each other, making it very difficult to reach partial agreements regarding\nthis debate, Therefore, the main goal of this manuscript is to establish a\nproper language that can translate among those different fields. First, I\npropose a theoretical model for analyzing how theoretical computing machines\nwould physically run in physical time. This model, termed as the xInf, is at\nfirst place Turing-complete in theory, and depending on the properties of\nphysical time, it can be either Turing-equivalent or Super-Turing in the\nphysical universe. The xInf Model is demonstrated to be a suitable universal\nlanguage to translate among physics, computer engineering, and neuroscience.\nFinally, I propose a conjecture that there exists a Minimal Complete Set of\nrules in the xInf Model that enables the construction of a physical machine\nusing inorganic materials that can pass the Turing Test in physical time. I\ncannot demonstrate whether such a conjecture to be testified or falsified on\npaper using finite-order logic, my only solution is physical time itself, i.e.\nan evolutionary competition will eventually tell the conclusion.\n", "versions": [{"version": "v1", "created": "Tue, 26 Dec 2017 23:36:43 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Jia", "Hongbo", ""]]}]