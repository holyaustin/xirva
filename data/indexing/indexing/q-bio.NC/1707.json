[{"id": "1707.00142", "submitter": "Haifei Yang", "authors": "Haifei Yang, Lu Shi, Feng Liu, Yanmeng Zhang, Baohua Liu, Yangyang Li,\n  Zhongyuan Shi and Shuyao Zhou", "title": "EEG and ECG changes during deep-sea manned submersible operation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Deep-sea manned submersible operation could induce mental\nworkload and influence neurophysiological measures. Psychophysiological\nresponses to submersible operation are not well known. The main aim of this\nstudy was to investigate changes in EEG and ECG components and subjective\nmental stress of pilots during submersible operation. Methods: There were 6\nexperienced submersible pilots who performed a 3 h submersible operation task\ncomposed of 5 subtasks. Electroencephalogram (EEG) and electrocardiogram (ECG)\nwas recorded before the operation task, after 1.5 h and 2.5 h operation, and\nafter the task. Subjective ratings of mental stress were also conducted at\nthese time points. Results: HR and scores on subjective stressed scale\nincreased during the task compared to baseline (P<0.05). LF/HF ratio at 1.5 h\nwere higher than those at Baseline (P<0.05) and 2.5 h (P<0.05). Relative theta\npower at the Cz site increased (P<0.01) and relative alpha power decreased\n(P<0.01) at 2.5 h compared to values at Baseline. Alpha attenuation coefficient\n(AAC, ratio of mean alpha power during eyes closed versus eyes open) at 2.5 h\nand after the task were lower compared to baseline and 1.5 h (P<0.05 or less).\nConclusions: Submersible operation resulted in an increased HR in association\nwith mental stress, alterations in autonomic activity and EEG changes that\nexpressed variations in mental workload. Brain arousal level declined during\nthe later operation period.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 11:49:47 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Yang", "Haifei", ""], ["Shi", "Lu", ""], ["Liu", "Feng", ""], ["Zhang", "Yanmeng", ""], ["Liu", "Baohua", ""], ["Li", "Yangyang", ""], ["Shi", "Zhongyuan", ""], ["Zhou", "Shuyao", ""]]}, {"id": "1707.00180", "submitter": "Melanie Weber", "authors": "Melanie Weber, Johannes Stelzer, Emil Saucan, Alexander Naitsat,\n  Gabriele Lohmann and J\\\"urgen Jost", "title": "Curvature-based Methods for Brain Network Analysis", "comments": "Under Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.DM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain forms functional networks on all spatial scales. Modern fMRI\nscanners allow to resolve functional brain data in high resolutions, allowing\nto study large-scale networks that relate to cognitive processes. The analysis\nof such networks forms a cornerstone of experimental neuroscience. Due to the\nimmense size and complexity of the underlying data sets, efficient evaluation\nand visualization remain a challenge for data analysis. In this study, we\ncombine recent advances in experimental neuroscience and applied mathematics to\nperform a mathematical characterization of complex networks constructed from\nfMRI data. We use task-related edge densities [Lohmann et al., 2016] for\nconstructing networks of task-related changes in synchronization. This\nconstruction captures the dynamic formation of patterns of neuronal activity\nand therefore represents efficiently the connectivity structure between brain\nregions. Using geometric methods that utilize Forman-Ricci curvature as an\nedge-based network characteristic [Weber et al., 2017], we perform a\nmathematical analysis of the resulting complex networks. We motivate the use of\nedge-based characteristics to evaluate the network structure with geometric\nmethods. The geometric features could aid in understanding the connectivity and\ninterplay of brain regions in cognitive processes.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 17:55:28 GMT"}, {"version": "v2", "created": "Mon, 13 May 2019 16:03:12 GMT"}], "update_date": "2019-05-14", "authors_parsed": [["Weber", "Melanie", ""], ["Stelzer", "Johannes", ""], ["Saucan", "Emil", ""], ["Naitsat", "Alexander", ""], ["Lohmann", "Gabriele", ""], ["Jost", "J\u00fcrgen", ""]]}, {"id": "1707.00375", "submitter": "Dmitry Kalika", "authors": "Dmitry Kalika, Leslie M. Collins, Chandra S. Throckmorton, Boyla O.\n  Mainsah", "title": "Adaptive Stimulus Selection in ERP-Based Brain-Computer Interfaces by\n  Maximizing Expected Discrimination Gain", "comments": "This paper has been accepted for the 2017 IEEE International\n  Conference on Systems, Man and Cybernetics (SMC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain-computer interfaces (BCIs) can provide an alternative means of\ncommunication for individuals with severe neuromuscular limitations. The\nP300-based BCI speller relies on eliciting and detecting transient\nevent-related potentials (ERPs) in electroencephalography (EEG) data, in\nresponse to a user attending to rarely occurring target stimuli amongst a\nseries of non-target stimuli. However, in most P300 speller implementations,\nthe stimuli to be presented are randomly selected from a limited set of options\nand stimulus selection and presentation are not optimized based on previous\nuser data. In this work, we propose a data-driven method for stimulus selection\nbased on the expected discrimination gain metric. The data-driven approach\nselects stimuli based on previously observed stimulus responses, with the aim\nof choosing a set of stimuli that will provide the most information about the\nuser's intended target character. Our approach incorporates knowledge of\nphysiological and system constraints imposed due to real-time BCI\nimplementation. Simulations were performed to compare our stimulus selection\napproach to the row-column paradigm, the conventional stimulus selection method\nfor P300 spellers. Results from the simulations demonstrated that our adaptive\nstimulus selection approach has the potential to significantly improve\nperformance from the conventional method: up to 34% improvement in accuracy and\n43% reduction in the mean number of stimulus presentations required to spell a\ncharacter in a 72-character grid. In addition, our greedy approach to stimulus\nselection provides the flexibility to accommodate design constraints.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 01:08:08 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Kalika", "Dmitry", ""], ["Collins", "Leslie M.", ""], ["Throckmorton", "Chandra S.", ""], ["Mainsah", "Boyla O.", ""]]}, {"id": "1707.00664", "submitter": "Alessio Franci", "authors": "Alessio Franci, Guillaume Drion, Rodolphe Sepulchre", "title": "Robust and tunable bursting requires slow positive feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We highlight that the robustness and tunability of a bursting model\ncritically relies on currents that provide slow positive feedback to the\nmembrane potential. Such currents have the ability of making the total\nconductance of the circuit negative in a time scale that is termed slow because\nintermediate between the fast time scale of the spike upstroke and the\nultraslow time scale of even slower adaptation currents. We discuss how such\ncurrents can be assessed either in voltage-clamp experiments or in\ncomputational models. We show that, while frequent in the literature,\nmathematical and computational models of bursting that lack the slow negative\nconductance are fragile and rigid. Our results suggest that modeling the slow\nnegative conductance of cellular models is important when studying the\nneuromodulation of rhythmic circuits at any broader scale.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 17:29:04 GMT"}, {"version": "v2", "created": "Fri, 26 Jan 2018 15:56:43 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Franci", "Alessio", ""], ["Drion", "Guillaume", ""], ["Sepulchre", "Rodolphe", ""]]}, {"id": "1707.00759", "submitter": "Dante Chialvo", "authors": "Ignacio Cifre, Mahdi Zarepour, Silvina G Horovitz, Sergio Cannas,\n  Dante R Chialvo", "title": "On why a few points suffice to describe spatiotemporal large-scale brain\n  dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An heuristic signal processing scheme recently introduced shows how brain\nsignals can be efficiently represented by a sparse spatiotemporal point\nprocess. The approach has been validated already for different relevant\nconditions demonstrating that preserves and compress a surprisingly large\nfraction of the signal information. In this paper the conditions for such\ncompression to succeed are investigated as well as the underlying reasons for\nsuch good performance. The results show that the key lies in the correlation\nproperties of the time series under consideration. It is found that signals\nwith long range correlations are particularly suitable for this type of\ncompression, where inflection points contain most of the information. Since\nthis type of correlation is ubiquitous in signals trough out nature including\nmusic, weather patterns, biological signals, etc., we expect that this type of\napproach to be an useful tool for their analysis.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 21:12:33 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Cifre", "Ignacio", ""], ["Zarepour", "Mahdi", ""], ["Horovitz", "Silvina G", ""], ["Cannas", "Sergio", ""], ["Chialvo", "Dante R", ""]]}, {"id": "1707.00772", "submitter": "Timoth\\'ee Proix Ph.D.", "authors": "Timoth\\'ee Proix, Viktor K. Jirsa, Fabrice Bartolomei, Maxime Guye,\n  Wilson Truccolo", "title": "Predicting the spatiotemporal diversity of seizure propagation and\n  termination in human focal epilepsy", "comments": "10 pages + 9 pages Supporting Information (SI), 7 figures, 1 SI\n  table, 7 SI figures", "journal-ref": null, "doi": "10.1038/s41467-018-02973-y", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that seizures can spread and terminate across brain\nareas via a rich diversity of spatiotemporal patterns. In particular, while the\nlocation of the seizure onset area is usually in-variant across seizures in a\nsame patient, the source of traveling (2-3 Hz) spike-and-wave discharges (SWDs)\nduring seizures can either move with the slower propagating ictal wavefront or\nremain stationary at the seizure onset area. In addition, although most focal\nseizures terminate quasi-synchronously across brain areas, some evolve into\ndistinct ictal clusters and terminate asynchronously. To provide a unifying\nperspective on the observed diversity of spatiotemporal dynamics for seizure\nspread and termination, we introduce here the Epileptor neural field model. Two\nmechanisms play an essential role. First, while the slow ictal wavefront\npropagates as a front in excitable neural media, the faster SWDs propagation\nresults from coupled-oscillator dynamics. Second, multiple time scales interact\nduring seizure spread, allowing for low-voltage fast-activity (>10 Hz) to\nhamper seizure spread and for SWD propagation to affect the way a seizure\nterminates. These dynamics, together with variations in short and long-range\nconnectivity strength, play a central role on seizure spread, maintenance and\ntermination. We demonstrate how Epileptor field models incorporating the above\nmechanisms predict the previously reported diversity in seizure spread\npatterns. Furthermore, we confirm the predictions for synchronous or\nasynchronous (clustered) seizure termination in human seizures recorded via\nstereotactic EEG. Our new insights into seizure spatiotemporal dynamics may\nalso contribute to the development of new closed-loop neuromodulation therapies\nfor focal epilepsy.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 22:08:12 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Proix", "Timoth\u00e9e", ""], ["Jirsa", "Viktor K.", ""], ["Bartolomei", "Fabrice", ""], ["Guye", "Maxime", ""], ["Truccolo", "Wilson", ""]]}, {"id": "1707.01346", "submitter": "Catherine Reason", "authors": "Catherine M Reason", "title": "Comment on the paper Quantum mechanics needs no consciousness by Yu and\n  Nikolic (2011)", "comments": "Dr Yu and Dr Nikolic have both seen this article. Shan Yu has said he\n  is happy for the comment to be posted in its current form but wishes it to be\n  known that he does not agree with my conclusions", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a brief comment on the paper \"Quantum mechanics needs no\nconsciousness\" by Shan Yu and Danko Nikolic [1]. Yu and Nikolic argue that the\n\"consciousness causes collapse hypothesis\" interpretation of quantum mechanics,\nor CCCH, can be falsified by a particular experimental setup. This claim is\nincorrect and the cause of the error appears to be a confusion over where and\nwhen a collapse can be assumed to occur.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 12:13:53 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Reason", "Catherine M", ""]]}, {"id": "1707.01375", "submitter": "Luo-Luo Jiang", "authors": "Jia Quan Shen, Luo-Luo Jiang", "title": "Loss impresses human beings more than gain in the decision-making game", "comments": "11pages, 5 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What happen in the brain when human beings play games with computers? Here a\nsimple zero-sum game was conducted to investigate how people make decision via\ntheir brain even they know that their opponent is a computer. There are two\nchoices (a low or high number) for people and also two strategies for the\ncomputer (red color or green color). When the number selected by the human\nsubject meet the red color, the person loses the score which is equal to the\nnumber. On the contrary, the person gains the number of score if the computer\nchooses a green color for the number selected by the human being. Both the\nhuman subject and the computer give their choice at the same time, and subjects\nhave been told that the computer make its decision randomly on the red color or\ngreen color. During the experiments, the signal of electroencephalograph (EEG)\nobtained from brain of subjects was recorded. From the analysis of EEG, we find\nthat people mind the loss more than the gain, and the phenomenon becoming\nobvious when the gap between loss and gain grows. In addition, the signal of\nEEG is clearly distinguishable before making different decisions. It is\nobserved that significant negative waves in the entire brain region when the\nparticipant has a greater expectation for the outcome, and these negative waves\nare mainly concentrated in the forebrain region in the brain of human beings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 12:57:52 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Shen", "Jia Quan", ""], ["Jiang", "Luo-Luo", ""]]}, {"id": "1707.01446", "submitter": "Xerxes D. Arsiwalla", "authors": "Xerxes D. Arsiwalla, Pedro A.M. Mediano, Paul F.M.J. Verschure", "title": "Spectral Modes of Network Dynamics Reveal Increased Informational\n  Complexity Near Criticality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  What does the informational complexity of dynamical networked systems tell us\nabout intrinsic mechanisms and functions of these complex systems? Recent\ncomplexity measures such as integrated information have sought to\noperationalize this problem taking a whole-versus-parts perspective, wherein\none explicitly computes the amount of information generated by a network as a\nwhole over and above that generated by the sum of its parts during state\ntransitions. While several numerical schemes for estimating network integrated\ninformation exist, it is instructive to pursue an analytic approach that\ncomputes integrated information as a function of network weights. Our\nformulation of integrated information uses a Kullback-Leibler divergence\nbetween the multi-variate distribution on the set of network states versus the\ncorresponding factorized distribution over its parts. Implementing stochastic\nGaussian dynamics, we perform computations for several prototypical network\ntopologies. Our findings show increased informational complexity near\ncriticality, which remains consistent across network topologies. Spectral\ndecomposition of the system's dynamics reveals how informational complexity is\ngoverned by eigenmodes of both, the network's covariance and adjacency\nmatrices. We find that as the dynamics of the system approach criticality, high\nintegrated information is exclusively driven by the eigenmode corresponding to\nthe leading eigenvalue of the covariance matrix, while sub-leading modes get\nsuppressed. The implication of this result is that it might be favorable for\ncomplex dynamical networked systems such as the human brain or communication\nsystems to operate near criticality so that efficient information integration\nmight be achieved.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 15:48:48 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Arsiwalla", "Xerxes D.", ""], ["Mediano", "Pedro A. M.", ""], ["Verschure", "Paul F. M. J.", ""]]}, {"id": "1707.01484", "submitter": "Xerxes D. Arsiwalla", "authors": "Ivan Herreros, Xerxes D. Arsiwalla, Cosimo Della Santina, Jordi-Ysard\n  Puigbo, Antonio Bicchi, Paul Verschure", "title": "Cerebellar-Inspired Learning Rule for Gain Adaptation of Feedback\n  Controllers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cs.SY nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does our nervous system successfully acquire feedback control strategies\nin spite of a wide spectrum of response dynamics from different\nmusculo-skeletal systems? The cerebellum is a crucial brain structure in\nenabling precise motor control in animals. Recent advances suggest that\nsynaptic plasticity of cerebellar Purkinje cells involves molecular mechanisms\nthat mimic the dynamics of the efferent motor system that they control allowing\nthem to match the timing of their learning rule to behavior. Counter-Factual\nPredictive Control (CFPC) is a cerebellum-based feed-forward control scheme\nthat exploits that principle for acquiring anticipatory actions. CFPC extends\nthe classical Widrow-Hoff/Least Mean Squares by inserting a forward model of\nthe downstream closed-loop system in its learning rule. Here we apply that same\ninsight to the problem of learning the gains of a feedback controller. To that\nend, we frame a Model-Reference Adaptive Control (MRAC) problem and derive an\nadaptive control scheme treating the gains of a feedback controller as if they\nwere the weights of an adaptive linear unit. Our results demonstrate that\nrather than being exclusively confined to cerebellar learning, the approach of\ncontrolling plasticity with a forward model of the subsystem controlled, an\napproach that we term as Model-Enhanced Least Mean Squares (ME-LMS), can\nprovide a solution to wide set of adaptive control problems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 17:34:14 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Herreros", "Ivan", ""], ["Arsiwalla", "Xerxes D.", ""], ["Della Santina", "Cosimo", ""], ["Puigbo", "Jordi-Ysard", ""], ["Bicchi", "Antonio", ""], ["Verschure", "Paul", ""]]}, {"id": "1707.01585", "submitter": "Daniel Fraiman", "authors": "Daniel Fraiman and Ricardo Fraiman", "title": "Statistical comparison of (brain) networks", "comments": "Three references added. A new paragraph was added in the\n  Resting-state fMRI functional networks section", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of random networks in a neuroscientific context has developed\nextensively over the last couple of decades. By contrast, techniques for the\nstatistical analysis of these networks are less developed. In this paper, we\nfocus on the statistical comparison of brain networks in a nonparametric\nframework and discuss the associated detection and identification problems. We\ntested network differences between groups with an analysis of variance (ANOVA)\ntest we developed specifically for networks. We also propose and analyse the\nbehaviour of a new statistical procedure designed to identify different\nsubnetworks. As an example, we show the application of this tool in\nresting-state fMRI data obtained from the Human Connectome Project. Finally, we\ndiscuss the potential bias in neuroimaging findings that is generated by some\nbehavioural and brain structure variables. Our method can also be applied to\nother kind of networks such as protein interaction networks, gene networks or\nsocial networks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 21:26:58 GMT"}, {"version": "v2", "created": "Sun, 9 Jul 2017 22:12:41 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Fraiman", "Daniel", ""], ["Fraiman", "Ricardo", ""]]}, {"id": "1707.01746", "submitter": "Ilja Bytschok", "authors": "Ilja Bytschok, Dominik Dold, Johannes Schemmel, Karlheinz Meier and\n  Mihai A. Petrovici", "title": "Spike-based probabilistic inference with correlated noise", "comments": "3 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A steadily increasing body of evidence suggests that the brain performs\nprobabilistic inference to interpret and respond to sensory input and that\ntrial-to-trial variability in neural activity plays an important role. The\nneural sampling hypothesis interprets stochastic neural activity as sampling\nfrom an underlying probability distribution and has been shown to be compatible\nwith biologically observed firing patterns. In many studies, uncorrelated noise\nis used as a source of stochasticity, discounting the fact that cortical\nneurons may share a significant portion of their presynaptic partners, which\nimpacts their computation. This is relevant in biology and for implementations\nof neural networks where bandwidth constraints limit the amount of independent\nnoise. When receiving correlated noise, the resulting correlations cannot be\ndirectly countered by changes in synaptic weights $W$. We show that this is\ncontingent on the chosen coding: when changing the state space from\n$z\\in\\{0,1\\}$ to $z'\\in\\{-1,1\\}$, correlated noise has the exact same effect as\nchanges in $W'$. The translation of the problem to the $\\{-1,1\\}$ space allows\nto find a weight configuration that compensates for the induced correlations.\nFor an artificial embedding of sampling networks, this allows a straightforward\ntransfer between platforms with different bandwidth constraints. The existence\nof the mapping is important for learning. Since in the $\\{-1,1\\}$-coding the\ncorrelated noise can be compensated by parameter changes and the probability\ndistribution can be kept invariant when changing the coding, the distribution\nwill be found in the $\\{0,1\\}$-coding as well during learning, as demonstrated\nin simulations. Conclusively, sampling spiking networks are impervious to noise\ncorrelations when trained. If such computation happens in cortex, network\nplasticity does not need to take account of shared noise inputs.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 12:30:44 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Bytschok", "Ilja", ""], ["Dold", "Dominik", ""], ["Schemmel", "Johannes", ""], ["Meier", "Karlheinz", ""], ["Petrovici", "Mihai A.", ""]]}, {"id": "1707.01806", "submitter": "Manuel Baltieri Mr", "authors": "Manuel Baltieri, Christopher L. Buckley", "title": "An active inference implementation of phototaxis", "comments": "8 pages, 3 figures, accepted at ECAL (European Conference on\n  Artificial Life) 2017, Lyon, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Active inference is emerging as a possible unifying theory of perception and\naction in cognitive and computational neuroscience. On this theory, perception\nis a process of inferring the causes of sensory data by minimising the error\nbetween actual sensations and those predicted by an inner \\emph{generative}\n(probabilistic) model. Action on the other hand is drawn as a process that\nmodifies the world such that the consequent sensory input meets expectations\nencoded in the same internal model. These two processes, inferring properties\nof the world and inferring actions needed to meet expectations, close the\nsensory/motor loop and suggest a deep symmetry between action and perception.\nIn this work we present a simple agent-based model inspired by this new theory\nthat offers insights on some of its central ideas. Previous implementations of\nactive inference have typically examined a \"perception-oriented\" view of this\ntheory, assuming that agents are endowed with a detailed generative model of\ntheir surrounding environment. In contrast, we present an \"action-oriented\"\nsolution showing how adaptive behaviour can emerge even when agents operate\nwith a simple model which bears little resemblance to their environment. We\nexamine how various parameters of this formulation allow phototaxis and present\nan example of a different, \"pathological\" behaviour.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 14:17:19 GMT"}], "update_date": "2017-07-07", "authors_parsed": [["Baltieri", "Manuel", ""], ["Buckley", "Christopher L.", ""]]}, {"id": "1707.01962", "submitter": "Kamesh Krishnamurthy", "authors": "Kamesh Krishnamurthy, Ann M Hermundstad, Thierry Mora, Aleksandra M\n  Walczak, Vijay Balasubramanian", "title": "Disorder and the neural representation of complex odors: smelling in the\n  real world", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Animals smelling in the real world use a small number of receptors to sense a\nvast number of natural molecular mixtures, and proceed to learn arbitrary\nassociations between odors and valences. Here, we propose a new interpretation\nof how the architecture of olfactory circuits is adapted to meet these immense\ncomplementary challenges. First, the diffuse binding of receptors to many\nmolecules compresses a vast odor space into a tiny receptor space, while\npreserving similarity. Next, lateral interactions \"densify\" and decorrelate the\nresponse, enhancing robustness to noise. Finally, disordered projections from\nthe periphery to the central brain reconfigure the densely packed information\ninto a format suitable for flexible learning of associations and valences. We\ntest our theory empirically using data from Drosophila. Our theory suggests\nthat the neural processing of olfactory information differs from the other\nsenses in its fundamental use of disorder.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 20:52:50 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Krishnamurthy", "Kamesh", ""], ["Hermundstad", "Ann M", ""], ["Mora", "Thierry", ""], ["Walczak", "Aleksandra M", ""], ["Balasubramanian", "Vijay", ""]]}, {"id": "1707.02324", "submitter": "Guillaume Pernelle", "authors": "Guillaume Pernelle, Wilten Nicola, Claudia Clopath", "title": "Gap junction plasticity as a mechanism to regulate network-wide\n  oscillations", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1006025", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical oscillations are thought to be involved in many cognitive functions\nand processes. Several mechanisms have been proposed to regulate oscillations.\nOne prominent but understudied mechanism is gap-junctional coupling. Gap\njunctions are ubiquitous in cortex between GABAergic interneurons. Moreover,\nrecent experiments indicate their strength can be modified in an\nactivity-dependent manner, similar to chemical synapses. We hypothesized that\nactivity-dependent gap junction plasticity acts as a mechanism to regulate\noscillations in the cortex. We developed a computational model of gap junction\nplasticity in a recurrent cortical network. We showed that gap junction\nplasticity can serve as a homeostatic mechanism for oscillations by maintaining\na tight balance between two network states: asynchronous irregular activity and\nsynchronized oscillations. This homeostatic mechanism allows for robust\ncommunication between neuronal assemblies through two different mechanisms:\ntransient oscillations and frequency modulation. This implies a direct\nfunctional role for gap junction plasticity in information transmission in\ncortex.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 18:28:19 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Pernelle", "Guillaume", ""], ["Nicola", "Wilten", ""], ["Clopath", "Claudia", ""]]}, {"id": "1707.02365", "submitter": "Joaquin Goni", "authors": "Enrico Amico, Joaqu\\'in Go\\~ni", "title": "The quest for identifiability in human functional connectomes", "comments": "31 pages, 11 figures", "journal-ref": "Scientific Reports, 2018", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The evaluation of the individual 'fingerprint' of a human functional\nconnectome (FC) is becoming a promising avenue for neuroscientific research,\ndue to its enormous potential inherent to drawing single subject inferences\nfrom functional connectivity profiles. Here we show that the individual\nfingerprint of a human functional connectome can be maximized from a\nreconstruction procedure based on group-wise decomposition in a finite number\nof brain connectivity modes. We use data from the Human Connectome Project to\ndemonstrate that the optimal reconstruction of the individual FCs through\nconnectivity eigenmodes maximizes subject identifiability across resting-state\nand all seven tasks evaluated. The identifiability of the optimally\nreconstructed individual connectivity profiles increases both at the global and\nedgewise level, also when the reconstruction is imposed on additional\nfunctional data of the subjects. Furthermore, reconstructed FC data provide\nmore robust associations with task-behavioral measurements. Finally, we extend\nthis approach to also map the most task-sensitive functional connections.\nResults show that is possible to maximize individual fingerprinting in the\nfunctional connectivity domain regardless of the task, a crucial next step in\nthe area of brain connectivity towards individualized connectomics.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 21:34:14 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 20:54:45 GMT"}, {"version": "v3", "created": "Thu, 12 Apr 2018 16:14:19 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Amico", "Enrico", ""], ["Go\u00f1i", "Joaqu\u00edn", ""]]}, {"id": "1707.02932", "submitter": "Farhad Shahbazi", "authors": "Mohammad Sharifi, Hamed Farahani, Farhad Shahbazi, Masood Sharifi,\n  Christofer T. Kello, and Marzieh Zare", "title": "Complexity of eye fixation duration time series in reading of Persian\n  texts: A multifractal detrended fluctuation analysis", "comments": "7 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing evidence that cognitive processes may have fractal\nstructures as a signature of complexity. It is an an ongoing topic of research\nto study the class of complexity and how it may differ as a function of\ncognitive variables. Here, we explore the eye movement trajectories generated\nduring reading different Persian texts. Features of eye movement trajectories\nwere recorded during reading Persian texts using an eye tracker. We show that\nfixation durations, as the main components of eye movements reflecting\ncognitive processing, exhibits multifractal behavior. This indicates that\nmultiple exponents are needed to capture the neural and cognitive processes\ninvolved in decoding symbols to derive meaning. We test whether multifractal\nbehavior varies as a function of two different fonts, familiarity of the text\nfor readers, and reading silently or aloud, and goal-oriented versus\nnon-goal-oriented reading. We find that, while mean fixation duration is\naffected by some of these factors, the multifractal pattern in time series of\neye fixation durations did not change significantly. Our results suggest that\nmultifractal dynamics may be intrinsic to the reading process.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 16:34:00 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Sharifi", "Mohammad", ""], ["Farahani", "Hamed", ""], ["Shahbazi", "Farhad", ""], ["Sharifi", "Masood", ""], ["Kello", "Christofer T.", ""], ["Zare", "Marzieh", ""]]}, {"id": "1707.03046", "submitter": "Funda Yildirim", "authors": "Funda Yildirim, Joana Carvalho, Frans W. Cornelissen", "title": "A second-order orientation-contrast stimulus for\n  population-receptive-field-based retinotopic mapping", "comments": "Yildirim, F., et al., A second-order orientation-contrast stimulus\n  for population-receptive-field-based retinotopic mapping, NeuroImage (2017)", "journal-ref": null, "doi": "10.1016/j.neuroimage.2017.06.073", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual field or retinotopic mapping is one of the most frequently used\nparadigms in fMRI. It uses activity evoked by position-varying high luminance\ncontrast visual patterns presented throughout the visual field for determining\nthe spatial organization of cortical visual areas. While the advantage of using\nhigh luminance contrast is that it tends to drive a wide range of neural\npopulations - thus resulting in high signal-to-noise BOLD responses - this may\nalso be a limitation, especially for approaches that attempt to squeeze more\ninformation out of the BOLD response, such as population receptive field (pRF)\nmapping. In that case, more selective stimulation of a subset of neurons -\ndespite reduced signals - could result in better characterization of pRF\nproperties. Here, we used a second-order stimulus based on local differences in\norientation texture - to which we refer as orientation contrast - to perform\nretinotopic mapping. Participants in our experiment viewed arrays of Gabor\npatches composed of a foreground (a bar) and a background. These could only be\ndistinguished on the basis of a difference in patch orientation. In our\nanalyses, we compare the pRF properties obtained using this new orientation\ncontrast-based retinotopy (OCR) to those obtained using classic luminance\ncontrast-based retinotopy (LCR). Specifically, in higher order cortical visual\nareas such as LO, our novel approach resulted in non-trivial reductions in\nestimated population receptive field size of around 30%. We discuss how OCR -\nby limiting receptive field scatter and reducing BOLD displacement - may result\nin more accurate pRF localization as well. We conclude that using our approach,\nit is possible to selectively target particular neuronal populations, opening\nthe way to use pRF modeling to dissect the response properties of more\nclearly-defined neuronal populations in different visual areas.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 20:12:22 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Yildirim", "Funda", ""], ["Carvalho", "Joana", ""], ["Cornelissen", "Frans W.", ""]]}, {"id": "1707.03321", "submitter": "Stanislas Chambon", "authors": "Stanislas Chambon, Mathieu Galtier, Pierrick Arnal, Gilles Wainrib and\n  Alexandre Gramfort", "title": "A deep learning architecture for temporal sleep stage classification\n  using multivariate and multimodal time series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sleep stage classification constitutes an important preliminary exam in the\ndiagnosis of sleep disorders. It is traditionally performed by a sleep expert\nwho assigns to each 30s of signal a sleep stage, based on the visual inspection\nof signals such as electroencephalograms (EEG), electrooculograms (EOG),\nelectrocardiograms (ECG) and electromyograms (EMG). We introduce here the first\ndeep learning approach for sleep stage classification that learns end-to-end\nwithout computing spectrograms or extracting hand-crafted features, that\nexploits all multivariate and multimodal Polysomnography (PSG) signals (EEG,\nEMG and EOG), and that can exploit the temporal context of each 30s window of\ndata. For each modality the first layer learns linear spatial filters that\nexploit the array of sensors to increase the signal-to-noise ratio, and the\nlast layer feeds the learnt representation to a softmax classifier. Our model\nis compared to alternative automatic approaches based on convolutional networks\nor decisions trees. Results obtained on 61 publicly available PSG records with\nup to 20 EEG channels demonstrate that our network architecture yields\nstate-of-the-art performance. Our study reveals a number of insights on the\nspatio-temporal distribution of the signal of interest: a good trade-off for\noptimal classification performance measured with balanced accuracy is to use 6\nEEG with 2 EOG (left and right) and 3 EMG chin channels. Also exploiting one\nminute of data before and after each data segment offers the strongest\nimprovement when a limited number of channels is available. As sleep experts,\nour system exploits the multivariate and multimodal nature of PSG signals in\norder to deliver state-of-the-art classification performance with a small\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 08:29:36 GMT"}, {"version": "v2", "created": "Mon, 27 Nov 2017 09:37:28 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Chambon", "Stanislas", ""], ["Galtier", "Mathieu", ""], ["Arnal", "Pierrick", ""], ["Wainrib", "Gilles", ""], ["Gramfort", "Alexandre", ""]]}, {"id": "1707.03354", "submitter": "Sarah Fineberg", "authors": "Sarah K Fineberg, Dylan Stahl, Philip Corlett", "title": "Computational Psychiatry in Borderline Personality Disorder", "comments": null, "journal-ref": "Current Behavioral Neuroscience Reports, March 2017, Vol 4, Issue\n  1, pp31-40", "doi": "10.1007/s40473-017-0104-y", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purpose of review: We review the literature on the use and potential use of\ncomputational psychiatry methods in Borderline Personality Disorder.\n  Recent findings: Computational approaches have been used in psychiatry to\nincrease our understanding of the molecular, circuit, and behavioral basis of\nmental illness. This is of particular interest in BPD, where the collection of\necologically valid data, especially in interpersonal settings, is becoming more\ncommon and more often subject to quantification. Methods that test learning and\nmemory in social contexts, collect data from real-world settings, and relate\nbehavior to molecular and circuit networks are yielding data of particular\ninterest.\n  Summary: Research in BPD should focus on collaborative efforts to design and\ninterpret experiments with direct relevance to core BPD symptoms and potential\nfor translation to the clinic.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 16:33:42 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 15:43:24 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Fineberg", "Sarah K", ""], ["Stahl", "Dylan", ""], ["Corlett", "Philip", ""]]}, {"id": "1707.03536", "submitter": "Seyedemahya Safavi", "authors": "Seyede Mahya Safavi, Beth Lopour, Pai H. Chou", "title": "Application of Dictionary Learning in Alleviating Computational Burden\n  of EEG Source Localization", "comments": "I just don't think this version of my draft is ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Two techniques are proposed to alleviate the computational burden of MUltiple\nSIgnal Classification (MUSIC) algorithm applied to Electroencephalogram (EEG)\nsource localization. A significant reduction was achieved by parsing the cortex\nsurface into smaller regions and nominating only a few regions for the\nexhaustive search inherent in the MUSIC algorithm. The nomination procedure\ninvolves a dictionary learning phase in which each region is assigned an atom\nmatrix. Moreover, a dimensionality reduction step provided by excluding some of\nthe electrodes is designed such that the Cramer-Rao bound of localization is\nmaintained. It is shown by simulation that computational complexity of the\nMUSIC-based localization can be reduced by up to $80\\%$.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 04:22:46 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 22:24:02 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Safavi", "Seyede Mahya", ""], ["Lopour", "Beth", ""], ["Chou", "Pai H.", ""]]}, {"id": "1707.03591", "submitter": "Sebastiano Stramaglia", "authors": "Sebastiano Stramaglia, Iege Bassez, Luca Faes, Daniele Marinazzo", "title": "Multiscale Granger causality analysis by \\`a trous wavelet transform", "comments": "4 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since interactions in neural systems occur across multiple temporal scales,\nit is likely that information flow will exhibit a multiscale structure, thus\nrequiring a multiscale generalization of classical temporal precedence\ncausality analysis like Granger's approach. However, the computation of\nmultiscale measures of information dynamics is complicated by theoretical and\npractical issues such as filtering and undersampling: to overcome these\nproblems, we propose a wavelet-based approach for multiscale Granger causality\n(GC) analysis, which is characterized by the following properties: (i) only the\ncandidate driver variable is wavelet transformed (ii) the decomposition is\nperformed using the \\`a trous wavelet transform with cubic B-spline filter. We\nmeasure GC, at a given scale, by including the wavelet coefficients of the\ndriver times series, at that scale, in the regression model of the target. To\nvalidate our method, we apply it to publicly available scalp EEG signals, and\nwe find that the condition of closed eyes, at rest, is characterized by an\nenhanced GC among channels at slow scales w.r.t. eye open condition, whilst the\nstandard Granger causality is not significantly different in the two\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 08:20:55 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Stramaglia", "Sebastiano", ""], ["Bassez", "Iege", ""], ["Faes", "Luca", ""], ["Marinazzo", "Daniele", ""]]}, {"id": "1707.03812", "submitter": "Maciej Jedynak PhD", "authors": "Maciej Jedynak, Antonio J. Pons and Jordi Garcia-Ojalvo", "title": "Collective excitability in a mesoscopic neuronal model of epileptic\n  activity", "comments": "8 pages, 7 figures", "journal-ref": "Phys. Rev. E 97, 012204 (2018)", "doi": "10.1103/PhysRevE.97.012204", "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain can be understood as a collection of interacting neuronal\noscillators, but the extent to which its sustained activity is due to coupling\namong brain areas is still unclear. Here we study the joint dynamics of two\ncortical columns described by Jansen-Rit neural mass models, and show that\ncoupling between the columns gives rise to stochastic initiations of sustained\ncollective activity, which can be interpreted as epileptic events. For large\nenough coupling strengths, termination of these events results mainly from the\nemergence of synchronization between the columns, and thus is controlled by\ncoupling instead of noise. Stochastic triggering and noise-independent\ndurations are characteristic of excitable dynamics, and thus we interpret our\nresults in terms of collective excitability.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 17:39:46 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Jedynak", "Maciej", ""], ["Pons", "Antonio J.", ""], ["Garcia-Ojalvo", "Jordi", ""]]}, {"id": "1707.04129", "submitter": "Gerard Rinkus", "authors": "Gerard J. Rinkus", "title": "A cortical sparse distributed coding model linking mini- and\n  macrocolumn-scale functionality", "comments": "13 pages, 5 figures", "journal-ref": "Frontiers in Neuroanatomy (2010) 4:17", "doi": "10.3389/fnana.2010.00017", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  No generic function for the minicolumn, i.e., one that would apply equally\nwell to all cortical areas and species, has yet been proposed. I propose that\nthe minicolumn does have a generic functionality, which only becomes clear when\nseen in the context of the function of the higher-level, subsuming unit, the\nmacrocolumn. I propose that: a) a macrocolumn's function is to store sparse\ndistributed representations of its inputs and to be a recognizer of those\ninputs; and b) the generic function of the minicolumn is to enforce\nmacrocolumnar code sparseness. The minicolumn, defined here as a physically\nlocalized pool of ~20 L2/3 pyramidals, does this by acting as a winner-take-all\n(WTA) competitive module, implying that macrocolumnar codes consist of ~70\nactive L2/3 cells, assuming ~70 minicolumns per macrocolumn. I describe an\nalgorithm for activating these codes during both learning and retrievals, which\ncauses more similar inputs to map to more highly intersecting codes, a property\nwhich yields ultra-fast (immediate, first-shot) storage and retrieval. The\nalgorithm achieves this by adding an amount of randomness (noise) into the code\nselection process, which is inversely proportional to an input's familiarity. I\npropose a possible mapping of the algorithm onto cortical circuitry, and adduce\nevidence for a neuromodulatory implementation of this familiarity-contingent\nnoise mechanism. The model is distinguished from other recent columnar cortical\ncircuit models in proposing a generic minicolumnar function in which a group of\ncells within the minicolumn, the L2/3 pyramidals, compete (WTA) to be part of\nthe sparse distributed macrocolumnar code.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 13:56:51 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Rinkus", "Gerard J.", ""]]}, {"id": "1707.04192", "submitter": "Marco Lehmann", "authors": "Marco Lehmann, He Xu, Vasiliki Liakoni, Michael Herzog, Wulfram\n  Gerstner, Kerstin Preuschoff", "title": "One-shot learning and behavioral eligibility traces in sequential\n  decision making", "comments": null, "journal-ref": "eLife 2019; 8:e47463", "doi": "10.7554/eLife.47463", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many daily tasks we make multiple decisions before reaching a goal. In\norder to learn such sequences of decisions, a mechanism to link earlier actions\nto later reward is necessary. Reinforcement learning theory suggests two\nclasses of algorithms solving this credit assignment problem: In classic\ntemporal-difference learning, earlier actions receive reward information only\nafter multiple repetitions of the task, whereas models with eligibility traces\nreinforce entire sequences of actions from a single experience (one-shot). Here\nwe asked whether humans use eligibility traces. We developed a novel paradigm\nto directly observe which actions and states along a multi-step sequence are\nreinforced after a single reward. By focusing our analysis on those states for\nwhich RL with and without eligibility trace make qualitatively distinct\npredictions, we find direct behavioral (choice probability) and physiological\n(pupil dilation) signatures of reinforcement learning with eligibility trace\nacross multiple sensory modalities.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 16:04:34 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2019 15:22:49 GMT"}, {"version": "v3", "created": "Tue, 12 Nov 2019 10:00:22 GMT"}], "update_date": "2019-11-13", "authors_parsed": [["Lehmann", "Marco", ""], ["Xu", "He", ""], ["Liakoni", "Vasiliki", ""], ["Herzog", "Michael", ""], ["Gerstner", "Wulfram", ""], ["Preuschoff", "Kerstin", ""]]}, {"id": "1707.04484", "submitter": "Leonardo L. Gollo", "authors": "Leonardo L. Gollo", "title": "Coexistence of critical sensitivity and subcritical specificity can\n  yield optimal population coding", "comments": "7 pages, 4 figures", "journal-ref": "J. R. Soc. Interface 14:20170207 (2017)", "doi": "10.1098/rsif.2017.0207", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vicinity of phase transitions selectively amplifies weak stimuli,\nyielding optimal sensitivity to distinguish external input. Along with this\nenhanced sensitivity, enhanced levels of fluctuations at criticality reduce the\nspecificity of the response. Given that the specificity of the response is\nlargely compromised when the sensitivity is maximal, the overall benefit of\ncriticality for signal processing remains questionable. Here it is shown that\nthis impasse can be solved by heterogeneous systems incorporating functional\ndiversity, in which critical and subcritical components coexist. The subnetwork\nof critical elements has optimal sensitivity, and the subnetwork of subcritical\nelements has enhanced specificity. Combining segregated features extracted from\nthe different subgroups, the resulting collective response can maximise the\ntradeoff between sensitivity and specificity measured by the\ndynamic-range-to-noise-ratio. Although numerous benefits can be observed when\nthe entire system is critical, our results highlight that optimal performance\nis obtained when only a small subset of the system is at criticality.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 12:34:47 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Gollo", "Leonardo L.", ""]]}, {"id": "1707.04582", "submitter": "Gregory Barello", "authors": "Takafumi Arakaki, G. Barello, Yashar Ahmadian", "title": "Capturing the diversity of biological tuning curves using generative\n  adversarial networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning curves characterizing the response selectivities of biological neurons\noften exhibit large degrees of irregularity and diversity across neurons.\nTheoretical network models that feature heterogeneous cell populations or\nrandom connectivity also give rise to diverse tuning curves. However, a general\nframework for fitting such models to experimentally measured tuning curves is\nlacking. We address this problem by proposing to view mechanistic network\nmodels as generative models whose parameters can be optimized to fit the\ndistribution of experimentally measured tuning curves. A major obstacle for\nfitting such models is that their likelihood function is not explicitly\navailable or is highly intractable to compute. Recent advances in machine\nlearning provide ways for fitting generative models without the need to\nevaluate the likelihood and its gradient. Generative Adversarial Networks (GAN)\nprovide one such framework which has been successful in traditional machine\nlearning tasks. We apply this approach in two separate experiments, showing how\nGANs can be used to fit commonly used mechanistic models in theoretical\nneuroscience to datasets of measured tuning curves. This fitting procedure\navoids the computationally expensive step of inferring latent variables, e.g.\nthe biophysical parameters of individual cells or the particular realization of\nthe full synaptic connectivity matrix, and directly learns model parameters\nwhich characterize the statistics of connectivity or of single-cell properties.\nAnother strength of this approach is that it fits the entire, joint\ndistribution of experimental tuning curves, instead of matching a few summary\nstatistics picked a priori by the user. More generally, this framework opens\nthe door to fitting theoretically motivated dynamical network models directly\nto simultaneously or non-simultaneously recorded neural responses.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 17:56:50 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 18:44:38 GMT"}, {"version": "v3", "created": "Wed, 19 Jul 2017 16:52:01 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Arakaki", "Takafumi", ""], ["Barello", "G.", ""], ["Ahmadian", "Yashar", ""]]}, {"id": "1707.04648", "submitter": "Jan H. Kirchner", "authors": "Jan H. Kirchner", "title": "Large Deviation Theory for Parameter Estimation in Simple Neuron Models", "comments": "Bachelor thesis completed in compliance with the requirements of the\n  BSc. Cognitive Science of the University of Osnabr\\\"uck and under the\n  supervision of Johannes Leugering and Prof. Gordon Pipa", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To investigate the complex dynamics of a biological neuron that is subject to\nsmall random perturbations we can use stochastic neuron models. While many\ntechniques have already been developed to study properties of such models,\nespecially the analysis of the (expected) first-passage time or (E)FPT remains\ndifficult. In this thesis I apply the large deviation theory (LDT), which is\nalready well-established in physics and finance, to the problem of determining\nthe EFPT of the mean-reverting Ornstein-Uhlenbeck (OU) process. The OU process\ninstantiates the Stochastic Leaky Integrate and Fire model and thus serves as\nan example of a biologically inspired mathematical neuron model. I derive\nseveral classical results using much simpler mathematics than the original\npublications from neuroscience and I provide a few conceivable interpretations\nand perspectives on these derivations. Using these results I explore some\npossible applications for parameter estimation and I provide an additional\nmathematical justification for using a Poisson process as a small-noise\napproximation of the full model. Finally I perform several simulations to\nverify these results and to reveal systematic biases of this estimator.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 21:47:00 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Kirchner", "Jan H.", ""]]}, {"id": "1707.05157", "submitter": "Ido Kanter", "authors": "Amir Goldental, Herut Uzan, Shira Sardi and Ido Kanter", "title": "Oscillations in networks of networks stem from adaptive nodes with\n  memory", "comments": "17 pages, 4 figures", "journal-ref": "Scientific Reports 7, Article number: 2700 (2017)", "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analytical framework that allows the quantitative study of\nstatistical dynamic properties of networks with adaptive nodes that have memory\nand is used to examine the emergence of oscillations in networks with response\nfailures. The frequency of the oscillations was quantitatively found to\nincrease with the excitability of the nodes and with the average degree of the\nnetwork and to decrease with delays between nodes. For networks of networks,\ndiverse cluster oscillation modes were found as a function of the topology.\nAnalytical results are in agreement with large-scale simulations and open the\nhorizon for understanding network dynamics composed of finite memory nodes as\nwell as their different phases of activity.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 13:45:17 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Goldental", "Amir", ""], ["Uzan", "Herut", ""], ["Sardi", "Shira", ""], ["Kanter", "Ido", ""]]}, {"id": "1707.05182", "submitter": "Robert Legenstein", "authors": "Robert Legenstein, Zeno Jonke, Stefan Habenschuss and Wolfgang Maass", "title": "A probabilistic model for learning in cortical microcircuit motifs with\n  data-based divisive inhibition", "comments": "24 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous theoretical studies on the interaction of excitatory and inhibitory\nneurons proposed to model this cortical microcircuit motif as a so-called\nWinner-Take-All (WTA) circuit. A recent modeling study however found that the\nWTA model is not adequate for data-based softer forms of divisive inhibition as\nfound in a microcircuit motif in cortical layer 2/3. We investigate here\nthrough theoretical analysis the role of such softer divisive inhibition for\nthe emergence of computational operations and neural codes under spike-timing\ndependent plasticity (STDP). We show that in contrast to WTA models - where the\nnetwork activity has been interpreted as probabilistic inference in a\ngenerative mixture distribution - this network dynamics approximates inference\nin a noisy-OR-like generative model that explains the network input based on\nmultiple hidden causes. Furthermore, we show that STDP optimizes the parameters\nof this model by approximating online the expectation maximization (EM)\nalgorithm. This theoretical analysis corroborates a preceding modelling study\nwhich suggested that the learning dynamics of this layer 2/3 microcircuit motif\nextracts a specific modular representation of the input and thus performs blind\nsource separation on the input statistics.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 14:33:14 GMT"}], "update_date": "2018-03-27", "authors_parsed": [["Legenstein", "Robert", ""], ["Jonke", "Zeno", ""], ["Habenschuss", "Stefan", ""], ["Maass", "Wolfgang", ""]]}, {"id": "1707.05193", "submitter": "Birgitta Dresp-Langley", "authors": "Birgitta Dresp-Langley", "title": "A temporal access code to consciousness?", "comments": "39 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While questions of a functional localization of consciousness in the brain\nhave been the subject of myriad studies, the idea of a temporal access code as\na specific brain mechanism for consciousness has remained a neglected\npossibility. Dresp-Langley and Durup (2009, 2012) proposed a theoretical\napproach in terms of a temporal access mechanism for consciousness based on its\ntwo universally recognized properties. Consciousness is limited in processing\ncapacity and described by a unique processing stream across a single dimension,\nwhich is time. The time ordering function of conscious states is highlighted\nand neurobiological theories of the temporal brain activities likely to\nunderlie such function are discussed, and the properties of the code model are\nthen introduced. Spatial information is integrated into provisory topological\nmaps at non-conscious levels through adaptive resonant matching, but does not\nform part of the temporal access code as such. The latter, de-correlated from\nthe spatial code, operates without any need for firing synchrony on the sole\nbasis of temporal coincidence probabilities in dedicated resonant circuits\nthrough progressively non-arbitrary selection of specific temporal activity\npatterns in the continuously developing brain.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 16:01:55 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Dresp-Langley", "Birgitta", ""]]}, {"id": "1707.05639", "submitter": "Erkki Somersalo Dr.", "authors": "Daniela Calvetti, Annalisa Pascarella, Francesca Pitolli, Erkki\n  Somersalo, Barbara Vantaggi", "title": "Brain activity mapping from MEG data via a hierarchical Bayesian\n  algorithm with automatic depth weighting: sensitivity and specificity\n  analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recently proposed IAS MEG inverse solver algorithm, based on the coupling\nof a hierarchical Bayesian model with computationally efficient Krylov subspace\nlinear solver, has been shown to perform well for both superficial and deep\nbrain sources. However, a systematic study of its sensitivity and specificity\nas a function of the activity location is still missing. We propose novel\nstatistical protocols to quantify the performance of MEG inverse solvers,\nfocusing in particular on their sensitivity and specificity in identifying\nactive brain regions. We use these protocols for a systematic study of the\nsensitivity and specificity of the IAS MEG inverse solver, comparing the\nperformance with three standard inversion methods, wMNE, dSPM, and sLORETA. To\navoid the bias of anecdotal tests towards a particular algorithm, the proposed\nprotocols are Monte Carlo sampling based, generating an ensemble of activity\npatches in each brain region identified in a given atlas. The sensitivity is\nmeasured by how much, on average, the reconstructed activity is concentrated in\nthe brain region of the simulated active patch. The specificity analysis is\nbased on Bayes factors, interpreting the estimated current activity as data for\ntesting the hypothesis that the active brain region is correctly identified,\nvs. the hypothesis of any erroneous attribution. The methodology allows the\npresence of a single or several simultaneous activity regions, without assuming\nthe knowledge of the number of active regions. The testing protocols suggest\nthat the IAS solver performs well in terms of sensitivity and specificity both\nwith cortical and subcortical activity estimation.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jul 2017 17:17:08 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Calvetti", "Daniela", ""], ["Pascarella", "Annalisa", ""], ["Pitolli", "Francesca", ""], ["Somersalo", "Erkki", ""], ["Vantaggi", "Barbara", ""]]}, {"id": "1707.05649", "submitter": "Konstantinos Michmizos", "authors": "Leo Kozachkov and Konstantinos P. Michmizos", "title": "Sequence learning in Associative Neuronal-Astrocytic Network", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The neuronal paradigm of studying the brain has left us with limitations in\nboth our understanding of how neurons process information to achieve biological\nintelligence and how such knowledge may be translated into artificial\nintelligence and its most brain-derived branch, neuromorphic computing.\nOverturning our fundamental assumptions of how the brain works, the recent\nexploration of astrocytes is revealing that these long-neglected brain cells\ndynamically regulate learning by interacting with neuronal activity at the\nsynaptic level. Following recent experimental evidence, we designed an\nassociative, Hopfield-type, neuronal-astrocytic network and analyzed the\ndynamics of the interaction between neurons and astrocytes. We show that\nastrocytes were sufficient to trigger transitions between learned memories in\nthe neuronal component of the network. Further, we mathematically derived the\ntiming of the transitions that was governed by the dynamics of the\ncalcium-dependent slow-currents in the astrocytic processes. Overall, we\nprovide a brain-morphic mechanism for sequence learning that is inspired by,\nand aligns with, recent experimental findings. To evaluate our model, we\nemulated astrocytic atrophy and showed that memory recall becomes significantly\nimpaired after a critical point of affected astrocytes was reached. This\nbrain-inspired and brain-validated approach supports our ongoing efforts to\nincorporate non-neuronal computing elements in neuromorphic information\nprocessing.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 18:16:27 GMT"}, {"version": "v2", "created": "Sun, 10 May 2020 18:18:45 GMT"}], "update_date": "2020-05-12", "authors_parsed": [["Kozachkov", "Leo", ""], ["Michmizos", "Konstantinos P.", ""]]}, {"id": "1707.05713", "submitter": "Youngmin Park", "authors": "Youngmin Park, Stewart Heitmann, and G. Bard Ermentrout", "title": "The Utility of Phase Models in Studying Neural Synchronization", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synchronized neural spiking is associated with many cognitive functions and\nthus, merits study for its own sake. The analysis of neural synchronization\nnaturally leads to the study of repetitive spiking and consequently to the\nanalysis of coupled neural oscillators. Coupled oscillator theory thus informs\nthe synchronization of spiking neuronal networks. A crucial aspect of coupled\noscillator theory is the phase response curve (PRC), which describes the impact\nof a perturbation to the phase of an oscillator. In neural terms, the\nperturbation represents an incoming synaptic potential which may either advance\nor retard the timing of the next spike. The phase response curves and the form\nof coupling between reciprocally coupled oscillators defines the phase\ninteraction function, which in turn predicts the synchronization outcome\n(in-phase versus anti-phase) and the rate of convergence. We review the two\nclasses of PRC and demonstrate the utility of the phase model in predicting\nsynchronization in reciprocally coupled neural models. In addition, we compare\nthe rate of convergence for all combinations of reciprocally coupled Class I\nand Class II oscillators. These findings predict the general synchronization\noutcomes of broad classes of neurons under both inhibitory and excitatory\nreciprocal coupling.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 15:57:51 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Park", "Youngmin", ""], ["Heitmann", "Stewart", ""], ["Ermentrout", "G. Bard", ""]]}, {"id": "1707.05952", "submitter": "Leonardo L. Gollo", "authors": "Luca Cocchi, Leonardo L. Gollo, Andrew Zalesky, Michael Breakspear", "title": "Criticality in the brain: A synthesis of neurobiology, models and\n  cognition", "comments": "44 pages, 5 figures", "journal-ref": "Progress in Neurobiology 158: 132-152 (2017)", "doi": "10.1016/j.pneurobio.2017.07.002", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive function requires the coordination of neural activity across many\nscales, from neurons and circuits to large-scale networks. As such, it is\nunlikely that an explanatory framework focused upon any single scale will yield\na comprehensive theory of brain activity and cognitive function. Modelling and\nanalysis methods for neuroscience should aim to accommodate multiscale\nphenomena. Emerging research now suggests that multi-scale processes in the\nbrain arise from so-called critical phenomena that occur very broadly in the\nnatural world. Criticality arises in complex systems perched between order and\ndisorder, and is marked by fluctuations that do not have any privileged spatial\nor temporal scale. We review the core nature of criticality, the evidence\nsupporting its role in neural systems and its explanatory potential in brain\nhealth and disease.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 06:32:34 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Cocchi", "Luca", ""], ["Gollo", "Leonardo L.", ""], ["Zalesky", "Andrew", ""], ["Breakspear", "Michael", ""]]}, {"id": "1707.05961", "submitter": "Olivier Colliot", "authors": "Emilie Gerardin, Ga\\\"el Ch\\'etelat, Marie Chupin, R\\'emi Cuingnet,\n  B\\'eatrice Desgranges, Ho-Sung Kim, Marc Niethammer, Bruno Dubois, St\\'ephane\n  Leh\\'ericy, Line Garnero, Francis Eustache, Olivier Colliot", "title": "Multidimensional classification of hippocampal shape features\n  discriminates Alzheimer's disease and mild cognitive impairment from normal\n  aging", "comments": "Data used in the preparation of this article were obtained from the\n  Alzheimer's Disease Neuroimaging Initiative (ADNI) database", "journal-ref": "NeuroImage, 47 (4), pp.1476-86, 2009", "doi": "10.1016/j.neuroimage.2009.05.036", "report-no": null, "categories": "cs.CV q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new method to automatically discriminate between patients with\nAlzheimer's disease (AD) or mild cognitive impairment (MCI) and elderly\ncontrols, based on multidimensional classification of hippocampal shape\nfeatures. This approach uses spherical harmonics (SPHARM) coefficients to model\nthe shape of the hippocampi, which are segmented from magnetic resonance images\n(MRI) using a fully automatic method that we previously developed. SPHARM\ncoefficients are used as features in a classification procedure based on\nsupport vector machines (SVM). The most relevant features for classification\nare selected using a bagging strategy. We evaluate the accuracy of our method\nin a group of 23 patients with AD (10 males, 13 females, age $\\pm$\nstandard-deviation (SD) = 73 $\\pm$ 6 years, mini-mental score (MMS) = 24.4\n$\\pm$ 2.8), 23 patients with amnestic MCI (10 males, 13 females, age $\\pm$ SD =\n74 $\\pm$ 8 years, MMS = 27.3 $\\pm$ 1.4) and 25 elderly healthy controls (13\nmales, 12 females, age $\\pm$ SD = 64 $\\pm$ 8 years), using leave-one-out\ncross-validation. For AD vs controls, we obtain a correct classification rate\nof 94%, a sensitivity of 96%, and a specificity of 92%. For MCI vs controls, we\nobtain a classification rate of 83%, a sensitivity of 83%, and a specificity of\n84%. This accuracy is superior to that of hippocampal volumetry and is\ncomparable to recently published SVM-based whole-brain classification methods,\nwhich relied on a different strategy. This new method may become a useful tool\nto assist in the diagnosis of Alzheimer's disease.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 07:33:02 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Gerardin", "Emilie", ""], ["Ch\u00e9telat", "Ga\u00ebl", ""], ["Chupin", "Marie", ""], ["Cuingnet", "R\u00e9mi", ""], ["Desgranges", "B\u00e9atrice", ""], ["Kim", "Ho-Sung", ""], ["Niethammer", "Marc", ""], ["Dubois", "Bruno", ""], ["Leh\u00e9ricy", "St\u00e9phane", ""], ["Garnero", "Line", ""], ["Eustache", "Francis", ""], ["Colliot", "Olivier", ""]]}, {"id": "1707.06038", "submitter": "Guillem Via", "authors": "Guillem Via", "title": "Oscillations and irregular persistent firing patterns in a homogeneous\n  network of excitatory stochastic neurons with gap junctions in the mean-field\n  limit", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue the work of a series of previous studies of a mathematical model\nthat describes the mean-field limit behavior of a homogeneous network of\nexcitatory point spiking neurons. Contrary to other models, here noise is\nintrinsic to the neurons through a membrane-potential dependent spiking rate\nprobability, that we assume to be given by a power law. This allows one to\ncollapse several sources of neural noise into a single function, which aids for\na more treatable mathematical and comptuational analysis. In particular, we\ngive pseudo-analytical expressions for the invariant distributions of membrane\npotentials across the population and study their stability computationally. The\nneurons are assumed to be connected both by chemical and possibly electrical\n(gap junction) synapses and can also undergo a leakage of ions with the\nextracellular medium. The distributions are of compact support whenever leakage\nor gap junction rates are non-zero and an infinite discontinuity appears at the\nmaximum potential in the population. This happens invariably for the leakage\n(with no gap junctions) and gap junction (without leakage) cases. However,\nthese discontinuous distributions might only be stable for linear spiking rate\nfunctions. It was recently shown how the network can present highly synchronous\nstates of global oscillations in its activity when leakage is not present and\ngap junctions are strong enough. Here we confirm how oscillations persist also\nwhen weak leakage is considered. Thus, these dendritic (rather than axonal) gap\njunctions could play a role in the high levels of neural synchrony necessary\nfor the development of neural systems at young ages. The model, thus, presents\na rich phenomenology and capability to reproduce several biological features of\nneural networks despite of its mathematical simplicity, hence presenting a\npowerful tool for high performance computing.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 12:08:40 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Via", "Guillem", ""]]}, {"id": "1707.06314", "submitter": "Aleksander Klibisz", "authors": "Aleksander Klibisz, Derek Rose, Matthew Eicholtz, Jay Blundon, and\n  Stanislav Zakharenko", "title": "Fast, Simple Calcium Imaging Segmentation with Fully Convolutional\n  Networks", "comments": "Accepted to 3rd Workshop on Deep Learning in Medical Image Analysis\n  (http://cs.adelaide.edu.au/~dlmia3/)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calcium imaging is a technique for observing neuron activity as a series of\nimages showing indicator fluorescence over time. Manually segmenting neurons is\ntime-consuming, leading to research on automated calcium imaging segmentation\n(ACIS). We evaluated several deep learning models for ACIS on the Neurofinder\ncompetition datasets and report our best model: U-Net2DS, a fully convolutional\nnetwork that operates on 2D mean summary images. U-Net2DS requires minimal\ndomain-specific pre/post-processing and parameter adjustment, and predictions\nare made on full $512\\times512$ images at $\\approx$9K images per minute. It\nranks third in the Neurofinder competition ($F_1=0.569$) and is the best model\nto exclusively use deep learning. We also demonstrate useful segmentations on\ndata from outside the competition. The model's simplicity, speed, and quality\nresults make it a practical choice for ACIS and a strong baseline for more\ncomplex models in the future.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 22:27:29 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Klibisz", "Aleksander", ""], ["Rose", "Derek", ""], ["Eicholtz", "Matthew", ""], ["Blundon", "Jay", ""], ["Zakharenko", "Stanislav", ""]]}, {"id": "1707.06501", "submitter": "Ido Kanter", "authors": "Roni Vardi, Amir Goldental, Anton Sheinin, Shira Sardi and Ido Kanter", "title": "Fast Reversible Learning based on Neurons functioning as Anisotropic\n  Multiplex Hubs", "comments": "6 pages, 4 figures", "journal-ref": "EPL 118 (2017) 46002", "doi": "10.1209/0295-5075/118/46002", "report-no": null, "categories": "q-bio.NC nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are composed of neurons and synapses, which are responsible\nfor learning in a slow adaptive dynamical process. Here we experimentally show\nthat neurons act like independent anisotropic multiplex hubs, which relay and\nmute incoming signals following their input directions. Theoretically, the\nobserved information routing enriches the computational capabilities of neurons\nby allowing, for instance, equalization among different information routes in\nthe network, as well as high-frequency transmission of complex time-dependent\nsignals constructed via several parallel routes. In addition, this kind of hubs\nadaptively eliminate very noisy neurons from the dynamics of the network,\npreventing masking of information transmission. The timescales for these\nfeatures are several seconds at most, as opposed to the imprint of information\nby the synaptic plasticity, a process which exceeds minutes. Results open the\nhorizon to the understanding of fast and adaptive learning realities in higher\ncognitive functionalities of the brain.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 13:43:28 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Vardi", "Roni", ""], ["Goldental", "Amir", ""], ["Sheinin", "Anton", ""], ["Sardi", "Shira", ""], ["Kanter", "Ido", ""]]}, {"id": "1707.06539", "submitter": "Ido Kanter", "authors": "Shira Sardi, Amir Goldental, Hamutal Amir, Roni Vardi and Ido Kanter", "title": "Vitality of Neural Networks under Reoccurring Catastrophic Failures", "comments": "22 pages, 7 figures", "journal-ref": "Scientific Reports 6, Article number: 31674 (2016)", "doi": "10.1038/srep31674", "report-no": null, "categories": "q-bio.NC nlin.AO physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Catastrophic failures are complete and sudden collapses in the activity of\nlarge networks such as economics, electrical power grids and computer networks,\nwhich typically require a manual recovery process. Here we experimentally show\nthat excitatory neural networks are governed by a non-Poissonian reoccurrence\nof catastrophic failures, where their repetition time follows a multimodal\ndistribution characterized by a few tenths of a second and tens of seconds\ntimescales. The mechanism underlying the termination and reappearance of\nnetwork activity is quantitatively shown here to be associated with nodal\ntime-dependent features, neuronal plasticity, where hyperactive nodes damage\nthe response capability of their neighbors. It presents a complementary\nmechanism for the emergence of Poissonian catastrophic failures from damage\nconductivity. The effect that hyperactive nodes degenerate their neighbors\nrepresents a type of local competition which is a common feature in the\ndynamics of real-world complex networks, whereas their spontaneous recoveries\nrepresent a vitality which enhances reliable functionality.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 14:27:25 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Sardi", "Shira", ""], ["Goldental", "Amir", ""], ["Amir", "Hamutal", ""], ["Vardi", "Roni", ""], ["Kanter", "Ido", ""]]}, {"id": "1707.06549", "submitter": "Ido Kanter", "authors": "Roni Vardi, Amir Goldental, Shira Sardi, Anton Sheinin and Ido Kanter", "title": "Simultaneous multi-patch-clamp and extracellular-array recordings:\n  Single neuron reflects network activity", "comments": "36 pages, 9 figures", "journal-ref": "Scientific Reports 6, Article number: 36228 (2016)", "doi": "10.1038/srep36228", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing number of recording electrodes enhances the capability of\ncapturing the network's cooperative activity, however, using too many monitors\nmight alter the properties of the measured neural network and induce noise.\nUsing a technique that merges simultaneous multi-patch-clamp and\nmulti-electrode array recordings of neural networks in-vitro, we show that the\nmembrane potential of a single neuron is a reliable and super-sensitive probe\nfor monitoring such cooperative activities and their detailed rhythms.\nSpecifically, the membrane potential and the spiking activity of a single\nneuron are either highly correlated or highly anti-correlated with the\ntime-dependent macroscopic activity of the entire network. This surprising\nobservation also sheds light on the cooperative origin of neuronal burst in\ncultured networks. Our findings present an alternative flexible approach to the\ntechnique based on a massive tiling of networks by large-scale arrays of\nelectrodes to monitor their activity.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 14:37:23 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Vardi", "Roni", ""], ["Goldental", "Amir", ""], ["Sardi", "Shira", ""], ["Sheinin", "Anton", ""], ["Kanter", "Ido", ""]]}, {"id": "1707.07247", "submitter": "Baohua Zhou", "authors": "Baohua Zhou, David Hofmann, Itai Pinkoviezky, Samuel J. Sober, and\n  Ilya Nemenman", "title": "Chance, long tails, and inference: a non-Gaussian, Bayesian theory of\n  vocal learning in songbirds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditional theories of sensorimotor learning posit that animals use sensory\nerror signals to find the optimal motor command in the face of Gaussian sensory\nand motor noise. However, most such theories cannot explain common behavioral\nobservations, for example that smaller sensory errors are more readily\ncorrected than larger errors and that large abrupt (but not gradually\nintroduced) errors lead to weak learning. Here we propose a new theory of\nsensorimotor learning that explains these observations. The theory posits that\nthe animal learns an entire probability distribution of motor commands rather\nthan trying to arrive at a single optimal command, and that learning arises via\nBayesian inference when new sensory information becomes available. We test this\ntheory using data from a songbird, the Bengalese finch, that is adapting the\npitch (fundamental frequency) of its song following perturbations of auditory\nfeedback using miniature headphones. We observe the distribution of the sung\npitches to have long, non-Gaussian tails, which, within our theory, explains\nthe observed dynamics of learning. Further, the theory makes surprising\npredictions about the dynamics of the shape of the pitch distribution, which we\nconfirm experimentally.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jul 2017 04:43:54 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Zhou", "Baohua", ""], ["Hofmann", "David", ""], ["Pinkoviezky", "Itai", ""], ["Sober", "Samuel J.", ""], ["Nemenman", "Ilya", ""]]}, {"id": "1707.07932", "submitter": "Hongyoon Choi Dr", "authors": "Hongyoon Choi", "title": "Functional connectivity patterns of autism spectrum disorder identified\n  by deep feature learning", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism spectrum disorder (ASD) is regarded as a brain disease with globally\ndisrupted neuronal networks. Even though fMRI studies have revealed abnormal\nfunctional connectivity in ASD, they have not reached a consensus of the\ndisrupted patterns. Here, a deep learning-based feature extraction method\nidentifies multivariate and nonlinear functional connectivity patterns of ASD.\nResting-state fMRI data of 972 subjects (465 ASD 507 normal controls) acquired\nfrom the Autism Brain Imaging Data Exchange were used. A functional\nconnectivity matrix of each subject was generated using 90 predefined brain\nregions. As a data-driven feature extraction method without prior knowledge\nsuch as subjects diagnosis, variational autoencoder (VAE) summarized the\nfunctional connectivity matrix into 2 features. Those feature values of ASD\npatients were statistically compared with those of controls. A feature was\nsignificantly different between ASD and normal controls. The extracted features\nwere visualized by VAE-based generator which can produce virtual functional\nconnectivity matrices. The ASD-related feature was associated with\nfrontoparietal connections, interconnections of the dorsal medial frontal\ncortex and corticostriatal connections. It also showed a trend of negative\ncorrelation with full-scale IQ. A data-driven feature extraction based on deep\nlearning could identify complex patterns of functional connectivity of ASD.\nThis approach will help discover complex patterns of abnormalities in brain\nconnectivity in various brain disorders.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 11:59:33 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Choi", "Hongyoon", ""]]}, {"id": "1707.08077", "submitter": "Josef Faller", "authors": "Josef Faller, Linbi Hong, Jennifer Cummings and Paul Sajda", "title": "A comparison of single-trial EEG classification and EEG-informed fMRI\n  across three MR compatible EEG recording systems", "comments": "1 Page, IEEE EMBS Conference 2017, Korea", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simultaneously recorded electroencephalography (EEG) and functional magnetic\nresonance imaging (fMRI) can be used to non-invasively measure the\nspatiotemporal dynamics of the human brain. One challenge is dealing with the\nartifacts that each modality introduces into the other when the two are\nrecorded concurrently, for example the ballistocardiogram (BCG). We conducted a\npreliminary comparison of three different MR compatible EEG recording systems\nand assessed their performance in terms of single-trial classification of the\nEEG when simultaneously collecting fMRI. We found tradeoffs across all three\nsystems, for example varied ease of setup and improved classification accuracy\nwith reference electrodes (REF) but not for pulse artifact subtraction (PAS) or\nreference layer adaptive filtering (RLAF).\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 16:34:42 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Faller", "Josef", ""], ["Hong", "Linbi", ""], ["Cummings", "Jennifer", ""], ["Sajda", "Paul", ""]]}, {"id": "1707.08240", "submitter": "Peter Taylor", "authors": "Peter N Taylor, Nishant Sinha, Yujiang Wang, Sjoerd B Vos, Jane de\n  Tisi, Anna Miserocchi, Andrew W McEvoy, Gavin P Winston, John S Duncan", "title": "The impact of epilepsy surgery on the structural connectome and its\n  relation to outcome", "comments": null, "journal-ref": "NeuroImage.Clinical 18 (2018) 202-214", "doi": "10.1016/j.nicl.2018.01.028", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal lobe surgical resection brings seizure remission in up to 80% of\npatients, with long-term complete seizure freedom in 41%. However, it is\nunclear how surgery impacts on the structural white matter network, and how the\nnetwork changes relate to seizure outcome. We used white matter fibre\ntractography on preoperative diffusion MRI to generate a structural white\nmatter network, and postoperative T1-weighted MRI to retrospectively infer the\nimpact of surgical resection on this network. We then applied graph theory and\nmachine learning to investigate the properties of change between the\npreoperative and predicted postoperative networks. Temporal lobe surgery had a\nmodest impact on global network efficiency, despite the disruption caused. This\nwas due to alternative shortest paths in the network leading to widespread\nincreases in betweenness centrality post-surgery. Measurements of network\nchange could retrospectively predict seizure outcomes with 79% accuracy and 65%\nspecificity, which is twice as high as the empirical distribution. Fifteen\nconnections which changed due to surgery were identified as useful for\nprediction of outcome, eight of which connected to the ipsilateral temporal\npole. Our results suggest that the use of network change metrics may have\nclinical value for predicting seizure outcome. This approach could be used to\nprospectively predict outcomes given a suggested resection mask using\npreoperative data only.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 22:18:09 GMT"}, {"version": "v2", "created": "Fri, 23 Mar 2018 19:05:12 GMT"}], "update_date": "2020-09-30", "authors_parsed": [["Taylor", "Peter N", ""], ["Sinha", "Nishant", ""], ["Wang", "Yujiang", ""], ["Vos", "Sjoerd B", ""], ["de Tisi", "Jane", ""], ["Miserocchi", "Anna", ""], ["McEvoy", "Andrew W", ""], ["Winston", "Gavin P", ""], ["Duncan", "John S", ""]]}, {"id": "1707.08337", "submitter": "Daniel Mart\\'i", "authors": "Daniel Mart\\'i, Nicolas Brunel, Srdjan Ostojic", "title": "Correlations between synapses in pairs of neurons slow down dynamics in\n  randomly connected neural networks", "comments": "17 pages, 7 figures", "journal-ref": "Phys. Rev. E 97, 062314 (2018)", "doi": "10.1103/PhysRevE.97.062314", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks of randomly connected neurons are among the most popular models in\ntheoretical neuroscience. The connectivity between neurons in the cortex is\nhowever not fully random, the simplest and most prominent deviation from\nrandomness found in experimental data being the overrepresentation of\nbidirectional connections among pyramidal cells. Using numerical and analytical\nmethods, we investigated the effects of partially symmetric connectivity on\ndynamics in networks of rate units. We considered the two dynamical regimes\nexhibited by random neural networks: the weak-coupling regime, where the firing\nactivity decays to a single fixed point unless the network is stimulated, and\nthe strong-coupling or chaotic regime, characterized by internally generated\nfluctuating firing rates. In the weak-coupling regime, we computed analytically\nfor an arbitrary degree of symmetry the auto-correlation of network activity in\npresence of external noise. In the chaotic regime, we performed simulations to\ndetermine the timescale of the intrinsic fluctuations. In both cases, symmetry\nincreases the characteristic asymptotic decay time of the autocorrelation\nfunction and therefore slows down the dynamics in the network.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 09:41:25 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 20:36:52 GMT"}, {"version": "v3", "created": "Fri, 6 Jul 2018 08:17:33 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Mart\u00ed", "Daniel", ""], ["Brunel", "Nicolas", ""], ["Ostojic", "Srdjan", ""]]}, {"id": "1707.09046", "submitter": "Ali Yousefi", "authors": "Ali Yousefi, Theodore W. Berger", "title": "Time Divergence-Convergence Learning Scheme in Multi-Layer Dynamic\n  Synapse Neural Networks", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new learning scheme called time divergence-convergence (TDC) is proposed\nfor two-layer dynamic synapse neural networks (DSNN). DSNN is an artificial\nneural network model, in which the synaptic transmission is modeled by a\ndynamic process and the information between neurons are transmitted through\nspike timing. In TDC, the intra-layer neurons of a DSNN are trained to map\ninput spike trains to a higher dimension of spike trains called a\nfeature-domain, and the output neurons are trained to build the desired spike\ntrains by processing the spike timing of intralayer neurons. The DSNN\nperformance was examined in a jittered spike train classification task which\nshows more than 92\\% accuracy in classifying different spike trains. The DSNN\nperformance is comparable with the recurrent multi-layer neural networks and\nsurpasses a single-layer DSNN with a 22\\% margin. Synaptic dynamics have been\nproposed as the neural substrate for sub-second temporal processing; we can\nutilize TDC to train a DSNN to perform diverse forms of sub-second temporal\nprocessing. The TDC learning proposed here is scalable in terms of the synaptic\nadaptation of deeper layers of multi-layer DSNNs. The DSNN along with TDC\nlearning proposed here can be used in to replicate the processing observed in\nneural circuitry and in pattern recognition tasks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 23:35:17 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Yousefi", "Ali", ""], ["Berger", "Theodore W.", ""]]}, {"id": "1707.09379", "submitter": "Markos Maniatis", "authors": "M. Maniatis", "title": "Illusions - a model of mind", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing that all mental processes have to be unfree and passive, we\ndevelop a model of behavior and perceptions. We shall see how misleading our\nintuition is and shall understand how consciousness arises.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 19:04:08 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Maniatis", "M.", ""]]}, {"id": "1707.09426", "submitter": "Hong Hsi Lee", "authors": "Hong-Hsi Lee, Els Fieremans, Dmitry S. Novikov", "title": "What dominates the time dependence of diffusion transverse to axons:\n  Intra- or extra-axonal water?", "comments": null, "journal-ref": null, "doi": "10.1016/j.neuroimage.2017.12.038", "report-no": null, "categories": "physics.bio-ph physics.med-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brownian motion of water molecules provides an essential length scale, the\ndiffusion length, commensurate with cell dimensions in biological tissues.\nMeasuring the diffusion coefficient as a function of diffusion time makes in\nvivo diffusion MRI uniquely sensitive to the cellular features about three\norders of magnitude below imaging resolution. However, there is a longstanding\ndebate, regarding which contribution --- intra- or extra-cellular --- is more\nrelevant in the overall time-dependence of the diffusion metrics. Here we\nresolve this debate in the human brain white matter. By varying not just the\ndiffusion time, but also the gradient pulse duration of a standard diffusion\npulse sequence, we identify a functional form of the measured time-dependent\ndiffusion coefficient transverse to white matter tracts in 5 healthy\nvolunteers. This specific functional form is shown to originate from the\nextra-axonal space, and provides estimates of the fiber packing correlation\nlength for axons in a bundle. Our results offer a metric for the outer axonal\ndiameter, a promising candidate marker for demyelination in neurodegenerative\ndiseases. From the methodological perspective, our analysis demonstrates how\ncompeting models, which describe different physics yet interpolate standard\nmeasurements equally well, can be distinguished based on their prediction for\nan independent \"orthogonal\" measurement.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 21:55:41 GMT"}], "update_date": "2017-12-25", "authors_parsed": [["Lee", "Hong-Hsi", ""], ["Fieremans", "Els", ""], ["Novikov", "Dmitry S.", ""]]}, {"id": "1707.09775", "submitter": "Endel Poder", "authors": "Endel Poder", "title": "Capacity limitations of visual search in deep convolutional neural\n  networks", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks follow roughly the architecture of\nbiological visual systems and have shown a performance comparable to human\nobservers in object recognition tasks. In this study, I tested three pretrained\ndeep neural networks in visual search for simple visual features, and for\nfeature configurations. The results reveal a qualitative difference from human\nperformance. It appears that there is no clear difference between searches for\nsimple features that pop out in experiments with humans, and for feature\nconfigurations that exhibit strict capacity limitations in human vision. Both\ntypes of stimuli reveal comparable capacity limitations in the neural networks\ntested here.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 09:14:14 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 09:53:06 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Poder", "Endel", ""]]}]