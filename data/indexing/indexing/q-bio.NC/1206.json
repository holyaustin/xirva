[{"id": "1206.0094", "submitter": "Peter Csermely", "authors": "David M. Gyurko, Csaba Soti, Attila Stetak and Peter Csermely", "title": "System level mechanisms of adaptation, learning, memory formation and\n  evolvability: the role of chaperone and other networks", "comments": "19 pages, 2 Figures, 1 Table, 173 references", "journal-ref": "Current Protein and Peptide Science (2014) 15: 171-188", "doi": "10.2174/1389203715666140331110522", "report-no": null, "categories": "q-bio.MN physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, network approaches became a powerful tool to describe\nprotein structure and dynamics. Here, we describe first the protein structure\nnetworks of molecular chaperones, then characterize chaperone containing\nsub-networks of interactomes called as chaperone-networks or chaperomes. We\nreview the role of molecular chaperones in short-term adaptation of cellular\nnetworks in response to stress, and in long-term adaptation discussing their\nputative functions in the regulation of evolvability. We provide a general\noverview of possible network mechanisms of adaptation, learning and memory\nformation. We propose that changes of network rigidity play a key role in\nlearning and memory formation processes. Flexible network topology provides\n\"learning competent\" state. Here, networks may have much less modular\nboundaries than locally rigid, highly modular networks, where the learnt\ninformation has already been consolidated in a memory formation process. Since\nmodular boundaries are efficient filters of information, in the \"learning\ncompetent\" state information filtering may be much smaller, than after memory\nformation. This mechanism restricts high information transfer to the \"learning\ncompetent\" state. After memory formation, modular boundary-induced segregation\nand information filtering protect the stored information. The flexible networks\nof young organisms are generally in a \"learning competent\" state. On the\ncontrary, locally rigid networks of old organisms have lost their \"learning\ncompetent\" state, but store and protect their learnt information efficiently.\nWe anticipate that the above mechanism may operate at the level of both\nprotein-protein interaction and neuronal networks.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 06:34:03 GMT"}, {"version": "v2", "created": "Sun, 9 Jun 2013 15:16:38 GMT"}, {"version": "v3", "created": "Fri, 25 Apr 2014 10:32:43 GMT"}], "update_date": "2014-04-28", "authors_parsed": [["Gyurko", "David M.", ""], ["Soti", "Csaba", ""], ["Stetak", "Attila", ""], ["Csermely", "Peter", ""]]}, {"id": "1206.0166", "submitter": "Matthias Rybarsch", "authors": "Matthias Rybarsch and Stefan Bornholdt", "title": "Avalanches in self-organized critical neural networks: A minimal model\n  for the neural SOC universality class", "comments": "17 pages, 5 figures", "journal-ref": "PLoS ONE 9(4): e93090 (2014)", "doi": "10.1371/journal.pone.0093090", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain keeps its overall dynamics in a corridor of intermediate activity\nand it has been a long standing question what possible mechanism could achieve\nthis task. Mechanisms from the field of statistical physics have long been\nsuggesting that this homeostasis of brain activity could occur even without a\ncentral regulator, via self-organization on the level of neurons and their\ninteractions, alone. Such physical mechanisms from the class of self-organized\ncriticality exhibit characteristic dynamical signatures, similar to seismic\nactivity related to earthquakes. Measurements of cortex rest activity showed\nfirst signs of dynamical signatures potentially pointing to self-organized\ncritical dynamics in the brain. Indeed, recent more accurate measurements\nallowed for a detailed comparison with scaling theory of non-equilibrium\ncritical phenomena, proving the existence of criticality in cortex dynamics. We\nhere compare this new evaluation of cortex activity data to the predictions of\nthe earliest physics spin model of self-organized critical neural networks. We\nfind that the model matches with the recent experimental data and its\ninterpretation in terms of dynamical signatures for criticality in the brain.\nThe combination of signatures for criticality, power law distributions of\navalanche sizes and durations, as well as a specific scaling relationship\nbetween anomalous exponents, defines a universality class characteristic of the\nparticular critical phenomenon observed in the neural experiments. The spin\nmodel is a candidate for a minimal model of a self-organized critical adaptive\nnetwork for the universality class of neural criticality. As a prototype model,\nit provides the background for models that include more biological details, yet\nshare the same universality class characteristic of the homeostasis of activity\nin the brain.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 12:40:02 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2013 13:10:39 GMT"}, {"version": "v3", "created": "Tue, 7 Oct 2014 10:20:19 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Rybarsch", "Matthias", ""], ["Bornholdt", "Stefan", ""]]}, {"id": "1206.0311", "submitter": "Pamela Reinagel", "authors": "Pamela Reinagel, Emily Mankin, and Adam Calhoun", "title": "Speed and accuracy in a visual motion discrimination task as performed\n  by rats", "comments": "Content is identical to a poster presented at the 2009 Society for\n  Neuroscience meeting: Reinagel P, Mankin E, and Calhoun A (2009) Speed and\n  accuracy in a visual motion discrimination task as performed by rats. Program\n  No. 281.12. 2009 Neuroscience Meeting Planner. Chicago, IL: Society for\n  Neuroscience, 2009. Online", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We find that rats, like primates and humans, perform better on the random dot\nmotion task when they take more time to respond. We provide evidence that this\nimprovement is due to stimulus integration. Rats increase their response\nlatency modestly as a function of trial difficulty. Rats can modulate response\nlatency more strongly on a trial by trial basis, apparently on the basis of\nreward-related parameters.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 21:26:53 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Reinagel", "Pamela", ""], ["Mankin", "Emily", ""], ["Calhoun", "Adam", ""]]}, {"id": "1206.0324", "submitter": "Swagatam Mukhopadhyay", "authors": "Swagatam Mukhopadhyay, Pascal Grange, Anirvan M. Sengupta and Partha\n  P. Mitra", "title": "What does the Allen Gene Expression Atlas tell us about mouse brain\n  evolution?", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.GN q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use the Allen Gene Expression Atlas (AGEA) and the OMA ortholog dataset to\ninvestigate the evolution of mouse-brain neuroanatomy from the standpoint of\nthe molecular evolution of brain-specific genes. For each such gene, using the\nphylogenetic tree for all fully sequenced species and the presence of orthologs\nof the gene in these species, we construct and assign a discrete measure of\nevolutionary age. The gene expression profile of all gene of similar age,\nrelative to the average gene expression profile, distinguish regions of the\nbrain that are over-represented in the corresponding evolutionary timescale. We\nargue that the conclusions one can draw on evolution of twelve major brain\nregions from such a molecular level analysis supplements existing knowledge of\nmouse brain evolution and introduces new quantitative tools, especially for\ncomparative studies, when AGEA-like data sets for other species become\navailable. Using the functional role of the genes representational of a certain\nevolutionary timescale and brain region we compare and contrast, wherever\npossible, our observations with existing knowledge in evolutionary\nneuroanatomy.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jun 2012 22:54:52 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Mukhopadhyay", "Swagatam", ""], ["Grange", "Pascal", ""], ["Sengupta", "Anirvan M.", ""], ["Mitra", "Partha P.", ""]]}, {"id": "1206.0380", "submitter": "Georgi Medvedev S.", "authors": "Pawel Hitczenko and Georgi S. Medvedev", "title": "The Poincare map of randomly perturbed periodic motion", "comments": null, "journal-ref": null, "doi": "10.1007/s00332-013-9170-9", "report-no": null, "categories": "math.DS math.PR nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A system of autonomous differential equations with a stable limit cycle and\nperturbed by small white noise is analyzed in this work. In the vicinity of the\nlimit cycle of the unperturbed deterministic system, we define, construct, and\nanalyze the Poincare map of the randomly perturbed periodic motion. We show\nthat the time of the first exit from a small neighborhood of the fixed point of\nthe map, which corresponds to the unperturbed periodic orbit, is well\napproximated by the geometric distribution. The parameter of the geometric\ndistribution tends zero together with the noise intensity. Therefore, our\nresult can be interpreted as an estimate of stability of periodic motion to\nrandom perturbations.\n  In addition, we show that the geometric distribution of the first exit times\ntranslates into statistical properties of solutions of important differential\nequation models in applications. To this end, we demonstrate three examples\nfrom mathematical neuroscience featuring complex oscillatory patterns\ncharacterized by the geometric distribution. We show that in each of these\nmodels the statistical properties of emerging oscillations are fully explained\nby the general properties of randomly perturbed periodic motions identified in\nthis paper.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2012 13:22:50 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Hitczenko", "Pawel", ""], ["Medvedev", "Georgi S.", ""]]}, {"id": "1206.0560", "submitter": "Alberto  Mazzoni", "authors": "Alberto Mazzoni, Nikos K. Logothetis and Stefano Panzeri", "title": "The information content of Local Field Potentials: experiments and\n  models", "comments": "To appear in Quian Quiroga and Panzeri (Eds) Principles of Neural\n  Coding, CRC Press, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The LFPs is a broadband signal that captures variations of neural population\nactivity over a wide range of time scales. The range of time scales available\nin LFPs is particularly interesting from the neural coding point of view\nbecause it opens up the possibility to investigate whether there are privileged\ntime scales for information processing, a question that has been hotly debated\nover the last one or two decades.It is possible that information is represented\nby only a small number of specific frequency ranges, each carrying a separate\ncontribution to the information representation. To shed light on this issue, it\nis important to quantify the information content of each frequency range of\nneural activity, and understand which ranges carry complementary or similar\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 09:35:41 GMT"}], "update_date": "2012-06-05", "authors_parsed": [["Mazzoni", "Alberto", ""], ["Logothetis", "Nikos K.", ""], ["Panzeri", "Stefano", ""]]}, {"id": "1206.0637", "submitter": "Johann Summhammer", "authors": "Johann Summhammer, Vahid Salari and Gustav Bernroider", "title": "A Quantum-mechanical description of ion motion within the confining\n  potentials of voltage gated ion channels", "comments": "12 pages, 8 figures", "journal-ref": "Journal of Integrative Neuroscience 11, No.2 (2012), 123-135", "doi": "10.1142/S0219635212500094", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voltage gated channel proteins cooperate in the transmission of membrane\npotentials between nerve cells. With the recent progress in atomic-scaled\nbiological chemistry it has now become established that these channel proteins\nprovide highly correlated atomic environments that may maintain electronic\ncoherences even at warm temperatures. Here we demonstrate solutions of the\nSchr\\\"{o}dinger equation that represent the interaction of a single potassium\nion within the surrounding carbonyl dipoles in the Berneche-Roux model of the\nbacterial \\textit{KcsA} model channel. We show that, depending on the\nsurrounding carbonyl derived potentials, alkali ions can become highly\ndelocalized in the filter region of proteins at warm temperatures. We provide\nestimations about the temporal evolution of the kinetic energy of ions\ndepending on their interaction with other ions, their location within the\noxygen cage of the proteins filter region and depending on different\noscillation frequencies of the surrounding carbonyl groups. Our results provide\nthe first evidence that quantum mechanical properties are needed to explain a\nfundamental biological property such as ion-selectivity in trans-membrane\nion-currents and the effect on gating kinetics and shaping of classical\nconductances in electrically excitable cells.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2012 14:50:03 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Summhammer", "Johann", ""], ["Salari", "Vahid", ""], ["Bernroider", "Gustav", ""]]}, {"id": "1206.1108", "submitter": "Marko Puljic", "authors": "Robert Kozma, Marko Puljic, and Walter J. Freeman", "title": "Thermodynamic Model of Criticality in the Cortex Based On EEG/ECOG Data", "comments": "Criticality in Neural Systems, 2012 (book chapter)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Criticality in the cortex emerges from the seemingly random interaction of\nmicroscopic components and produces higher cognitive functions at mesoscopic\nand macroscopic scales. Random graphs and percolation theory provide natural\nmeans to de- scribe critical regions in the behavior of the cortex and they are\nproposed here as novel mathematical tools helping us deciphering the language\nof the brain.\n", "versions": [{"version": "v1", "created": "Wed, 6 Jun 2012 02:30:44 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Kozma", "Robert", ""], ["Puljic", "Marko", ""], ["Freeman", "Walter J.", ""]]}, {"id": "1206.1428", "submitter": "Charl Botha", "authors": "Hanspeter Pfister, Verena Kaynig, Charl P. Botha, Stefan Bruckner,\n  Vincent J. Dercksen, Hans-Christian Hege and Jos B. T. M. Roerdink", "title": "Visualization in Connectomics", "comments": "Improved definition of diffusion PDF. Integrated reviewer comments:\n  Added figures showing DTI tractography and glyphs, fMRI connectivity vis, EM\n  reconstruction of neuronal structures, Brainbow image. Typos and grammar\n  errors fixed. Description of connectivity matrix added", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connectomics is a field of neuroscience that analyzes neuronal connections. A\nconnectome is a complete map of a neuronal system, comprising all neuronal\nconnections between its structures. The term \"connectome\" is close to the word\n\"genome\" and implies completeness of all neuronal connections, in the same way\nas a genome is a complete listing of all nucleotide sequences. The goal of\nconnectomics is to create a complete representation of the brain's wiring. Such\na representation is believed to increase our understanding of how functional\nbrain states emerge from their underlying anatomical structure. Furthermore, it\ncan provide important information for the cure of neuronal dysfunctions like\nschizophrenia or autism. In this paper, we review the current state-of-the-art\nof visualization and image processing techniques in the field of connectomics\nand describe some remaining challenges.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jun 2012 09:17:34 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2012 12:19:28 GMT"}], "update_date": "2012-08-08", "authors_parsed": [["Pfister", "Hanspeter", ""], ["Kaynig", "Verena", ""], ["Botha", "Charl P.", ""], ["Bruckner", "Stefan", ""], ["Dercksen", "Vincent J.", ""], ["Hege", "Hans-Christian", ""], ["Roerdink", "Jos B. T. M.", ""]]}, {"id": "1206.1800", "submitter": "Xaq Pitkow", "authors": "Xaq Pitkow", "title": "Compressive neural representation of sparse, high-dimensional\n  probabilities", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper shows how sparse, high-dimensional probability distributions could\nbe represented by neurons with exponential compression. The representation is a\nnovel application of compressive sensing to sparse probability distributions\nrather than to the usual sparse signals. The compressive measurements\ncorrespond to expected values of nonlinear functions of the probabilistically\ndistributed variables. When these expected values are estimated by sampling,\nthe quality of the compressed representation is limited only by the quality of\nsampling. Since the compression preserves the geometric structure of the space\nof sparse probability distributions, probabilistic computation can be performed\nin the compressed domain. Interestingly, functions satisfying the requirements\nof compressive sensing can be implemented as simple perceptrons. If we use\nperceptrons as a simple model of feedforward computation by neurons, these\nresults show that the mean activity of a relatively small number of neurons can\naccurately represent a high-dimensional joint distribution implicitly, even\nwithout accounting for any noise correlations. This comprises a novel\nhypothesis for how neurons could encode probabilities in the brain.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 15:52:50 GMT"}], "update_date": "2012-06-11", "authors_parsed": [["Pitkow", "Xaq", ""]]}, {"id": "1206.1864", "submitter": "Tobias Reichenbach", "authors": "Tobias Reichenbach and A. J. Hudspeth", "title": "Discrimination of low-frequency tones employs temporal fine structure", "comments": "12 pages, 3 figures", "journal-ref": "PLoS ONE 7, e45579 (2012)", "doi": "10.1371/journal.pone.0045579", "report-no": null, "categories": "q-bio.NC physics.bio-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An auditory neuron can preserve the temporal fine structure of a\nlow-frequency tone by phase-locking its response to the stimulus. Apart from\nsound localization, however, little is known about the role of this temporal\ninformation for signal processing in the brain. Through psychoacoustic studies\nwe provide direct evidence that humans employ temporal fine structure to\ndiscriminate between frequencies. To this end we construct tones that are based\non a single frequency but in which, through the concatenation of wavelets, the\nphase changes randomly every few cycles. We then test the frequency\ndiscrimination of these phase-changing tones, of control tones without phase\nchanges, and of short tones that consist of a single wavelets. For carrier\nfrequencies below a few kilohertz we find that phase changes systematically\nworsen frequency discrimination. No such effect appears for higher carrier\nfrequencies at which temporal information is not available in the central\nauditory system.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 20:07:16 GMT"}], "update_date": "2012-09-21", "authors_parsed": [["Reichenbach", "Tobias", ""], ["Hudspeth", "A. J.", ""]]}, {"id": "1206.1865", "submitter": "Tobias Reichenbach", "authors": "Tobias Reichenbach and A. J. Hudspeth", "title": "Frequency decoding of periodically timed action potentials through\n  distinct activity patterns in a random neural network", "comments": "16 pages, 5 figures, and supplementary information", "journal-ref": null, "doi": "10.1088/1367-2630/14/11/113022", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequency discrimination is a fundamental task of the auditory system. The\nmammalian inner ear, or cochlea, provides a place code in which different\nfrequencies are detected at different spatial locations. However, a temporal\ncode based on spike timing is also available: action potentials evoked in an\nauditory-nerve fiber by a low-frequency tone occur at a preferred phase of the\nstimulus-they exhibit phase locking-and thus provide temporal information about\nthe tone's frequency. In an accompanying psychoacoustic study, and in agreement\nwith previous experiments, we show that humans employ this temporal information\nfor discrimination of low frequencies. How might such temporal information be\nread out in the brain? Here we demonstrate that recurrent random neural\nnetworks in which connections between neurons introduce characteristic time\ndelays, and in which neurons require temporally coinciding inputs for spike\ninitiation, can perform sharp frequency discrimination when stimulated with\nphase-locked inputs. Although the frequency resolution achieved by such\nnetworks is limited by the noise in phase locking, the resolution for realistic\nvalues reaches the tiny frequency difference of 0.2% that has been measured in\nhumans.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jun 2012 20:09:44 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Reichenbach", "Tobias", ""], ["Hudspeth", "A. J.", ""]]}, {"id": "1206.2081", "submitter": "Christopher Hillar", "authors": "Christopher Hillar, Ngoc Tran, Kilian Koepsell", "title": "Robust exponential binary pattern storage in Little-Hopfield networks", "comments": "This paper has been withdrawn by the authors. preliminary early draft\n  unsuitable for viewing and attribution, instead, see: arXiv:1411.4625", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.CO math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Little-Hopfield network is an auto-associative computational model of\nneural memory storage and retrieval. This model is known to robustly store\ncollections of randomly generated binary patterns as stable-states of the\nnetwork dynamics. However, the number of binary memories so storable scales\nlinearly in the number of neurons, and it has been a long-standing open problem\nwhether robust exponential storage of binary patterns was possible in such a\nnetwork memory model. In this note, we design simple families of\nLittle-Hopfield networks that provably solve this problem affirmatively. As a\nbyproduct, we produce a set of novel (nonlinear) binary codes with an\nefficient, highly parallelizable denoising mechanism.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jun 2012 02:15:22 GMT"}, {"version": "v2", "created": "Wed, 19 Jun 2013 19:29:37 GMT"}, {"version": "v3", "created": "Wed, 29 Apr 2015 19:20:42 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Hillar", "Christopher", ""], ["Tran", "Ngoc", ""], ["Koepsell", "Kilian", ""]]}, {"id": "1206.3108", "submitter": "Alfonso P\\'erez-Escudero", "authors": "Sara Arganda, Alfonso P\\'erez-Escudero, Gonzalo G. de Polavieja", "title": "A common rule for decision-making in animal collectives across species", "comments": null, "journal-ref": "Proc Natl Acad Sci USA vol. 109 no. 50 20508-20513 (2012)", "doi": "10.1073/pnas.1210664109", "report-no": null, "categories": "q-bio.PE q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A diversity of decision-making systems has been observed in animal\ncollectives. In some species, choices depend on the differences of the numbers\nof animals that have chosen each of the available options, while in other\nspecies on the relative differences (a behavior known as Weber's law) or follow\nmore complex rules. We here show that this diversity of decision systems\ncorresponds to a single rule of decision-making in collectives. We first\nobtained a decision rule based on Bayesian estimation that uses the information\nprovided by the behaviors of the other individuals to improve the estimation of\nthe structure of the world. We then tested this rule in decision experiments\nusing zebrafish (Danio rerio), and in existing rich datasets of argentine ants\n(Linepithema humile) and sticklebacks (Gasterosteus aculeatus), showing that a\nunified model across species can quantitatively explain the diversity of\ndecision systems. Further, these results show that the different counting\nsystems used by animals, including humans, can emerge from the common principle\nof using social information to make good decisions.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jun 2012 13:57:28 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2012 17:56:38 GMT"}, {"version": "v3", "created": "Wed, 12 Dec 2012 07:00:59 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Arganda", "Sara", ""], ["P\u00e9rez-Escudero", "Alfonso", ""], ["de Polavieja", "Gonzalo G.", ""]]}, {"id": "1206.3537", "submitter": "Yu Hu", "authors": "Yu Hu, James Trousdale, Kresimir Josic, Eric Shea-Brown", "title": "Motif Statistics and Spike Correlations in Neuronal Networks", "comments": null, "journal-ref": null, "doi": "10.1088/1742-5468/2013/03/P03012", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motifs are patterns of subgraphs of complex networks. We studied the impact\nof such patterns of connectivity on the level of correlated, or synchronized,\nspiking activity among pairs of cells in a recurrent network model of integrate\nand fire neurons. For a range of network architectures, we find that the\npairwise correlation coefficients, averaged across the network, can be closely\napproximated using only three statistics of network connectivity. These are the\noverall network connection probability and the frequencies of two second-order\nmotifs: diverging motifs, in which one cell provides input to two others, and\nchain motifs, in which two cells are connected via a third intermediary cell.\nSpecifically, the prevalence of diverging and chain motifs tends to increase\ncorrelation. Our method is based on linear response theory, which enables us to\nexpress spiking statistics using linear algebra, and a resumming technique,\nwhich extrapolates from second order motifs to predict the overall effect of\ncoupling on network correlation. Our motif-based results seek to isolate the\neffect of network architecture perturbatively from a known network state.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jun 2012 18:34:43 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Hu", "Yu", ""], ["Trousdale", "James", ""], ["Josic", "Kresimir", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1206.3666", "submitter": "Tayfun G\\\"urel", "authors": "Tayfun G\\\"urel, Carsten Mehring", "title": "Unsupervised adaptation of brain machine interface decoders", "comments": "28 pages, 13 figures, submitted to Frontiers in Neuroprosthetics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The performance of neural decoders can degrade over time due to\nnonstationarities in the relationship between neuronal activity and behavior.\nIn this case, brain-machine interfaces (BMI) require adaptation of their\ndecoders to maintain high performance across time. One way to achieve this is\nby use of periodical calibration phases, during which the BMI system (or an\nexternal human demonstrator) instructs the user to perform certain movements or\nbehaviors. This approach has two disadvantages: (i) calibration phases\ninterrupt the autonomous operation of the BMI and (ii) between two calibration\nphases the BMI performance might not be stable but continuously decrease. A\nbetter alternative would be that the BMI decoder is able to continuously adapt\nin an unsupervised manner during autonomous BMI operation, i.e. without knowing\nthe movement intentions of the user.\n  In the present article, we present an efficient method for such unsupervised\ntraining of BMI systems for continuous movement control. The proposed method\nutilizes a cost function derived from neuronal recordings, which guides a\nlearning algorithm to evaluate the decoding parameters. We verify the\nperformance of our adaptive method by simulating a BMI user with an optimal\nfeedback control model and its interaction with our adaptive BMI decoder. The\nsimulation results show that the cost function and the algorithm yield fast and\nprecise trajectories towards targets at random orientations on a 2-dimensional\ncomputer screen. For initially unknown and non-stationary tuning parameters,\nour unsupervised method is still able to generate precise trajectories and to\nkeep its performance stable in the long term. The algorithm can optionally work\nalso with neuronal error signals instead or in conjunction with the proposed\nunsupervised adaptation.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 13:35:21 GMT"}], "update_date": "2012-06-19", "authors_parsed": [["G\u00fcrel", "Tayfun", ""], ["Mehring", "Carsten", ""]]}, {"id": "1206.3697", "submitter": "Paul Smolen", "authors": "Paul Smolen, Douglas A. Baxter, John H. Byrne", "title": "Molecular Constraints on Synaptic Tagging and Maintenance of Long-Term\n  Potentiation: A Predictive Model", "comments": "v3. Minor text edits to reflect published version", "journal-ref": "PLoS Comput Biol 8(8): e1002620, 2012", "doi": "10.1371/journal.pcbi.1002620", "report-no": null, "categories": "q-bio.NC q-bio.MN q-bio.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Protein synthesis-dependent, late long-term potentiation (LTP) and depression\n(LTD) at glutamatergic hippocampal synapses are well characterized examples of\nlong-term synaptic plasticity. Persistent increased activity of the enzyme\nprotein kinase M (PKM) is thought essential for maintaining LTP. Additional\nspatial and temporal features that govern LTP and LTD induction are embodied in\nthe synaptic tagging and capture (STC) and cross capture hypotheses. Only\nsynapses that have been \"tagged\" by an stimulus sufficient for LTP and learning\ncan \"capture\" PKM. A model was developed to simulate the dynamics of key\nmolecules required for LTP and LTD. The model concisely represents\nrelationships between tagging, capture, LTD, and LTP maintenance. The model\nsuccessfully simulated LTP maintained by persistent synaptic PKM, STC, LTD, and\ncross capture, and makes testable predictions concerning the dynamics of PKM.\nThe maintenance of LTP, and consequently of at least some forms of long-term\nmemory, is predicted to require continual positive feedback in which PKM\nenhances its own synthesis only at potentiated synapses. This feedback\nunderlies bistability in the activity of PKM. Second, cross capture requires\nthe induction of LTD to induce dendritic PKM synthesis, although this may\nrequire tagging of a nearby synapse for LTP. The model also simulates the\neffects of PKM inhibition, and makes additional predictions for the dynamics of\nCaM kinases. Experiments testing the above predictions would significantly\nadvance the understanding of memory maintenance.\n", "versions": [{"version": "v1", "created": "Sat, 16 Jun 2012 19:11:27 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2012 23:36:22 GMT"}, {"version": "v3", "created": "Fri, 3 Aug 2012 20:13:55 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Smolen", "Paul", ""], ["Baxter", "Douglas A.", ""], ["Byrne", "John H.", ""]]}, {"id": "1206.3963", "submitter": "Jaroslav Hlinka", "authors": "Jaroslav Hlinka, David Hartman and Milan Palu\\v{s}", "title": "Small-world topology of functional connectivity in randomly connected\n  dynamical systems", "comments": "The following article has been submitted to Chaos: An\n  interdisciplinary journal of nonlinear science. After it is published, it\n  will be found at http://chaos.aip.org/", "journal-ref": "Chaos, (2012), vol. 22, no. 3, pp. 033107", "doi": "10.1063/1.4732541", "report-no": null, "categories": "cs.SI physics.data-an physics.soc-ph q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Characterization of real-world complex systems increasingly involves the\nstudy of their topological structure using graph theory. Among global network\nproperties, small-world property, consisting in existence of relatively short\npaths together with high clustering of the network, is one of the most\ndiscussed and studied. When dealing with coupled dynamical systems, links among\nunits of the system are commonly quantified by a measure of pairwise\nstatistical dependence of observed time series (functional connectivity). We\nargue that the functional connectivity approach leads to upwardly biased\nestimates of small-world characteristics (with respect to commonly used random\ngraph models) due to partial transitivity of the accepted functional\nconnectivity measures such as the correlation coefficient. In particular, this\nmay lead to observation of small-world characteristics in connectivity graphs\nestimated from generic randomly connected dynamical systems. The ubiquity and\nrobustness of the phenomenon is documented by an extensive parameter study of\nits manifestation in a multivariate linear autoregressive process, with\ndiscussion of the potential relevance for nonlinear processes and measures.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 15:23:37 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Hlinka", "Jaroslav", ""], ["Hartman", "David", ""], ["Palu\u0161", "Milan", ""]]}, {"id": "1206.4082", "submitter": "Pamela Reinagel", "authors": "Claire B. Discenza and Pamela Reinagel", "title": "Dorsal lateral geniculate substructure in the Long-Evans rat: A cholera\n  toxin B-subunit study", "comments": null, "journal-ref": "Front. Neuroanat. 6:40 (2012)", "doi": "10.3389/fnana.2012.00040", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study describes the substructure of the dorsal lateral geniculate\nnucleus of the thalamus of the pigmented rat (Rattus norvegicus) based on the\neye-of-origin of its retinal ganglion cell inputs. We made monocular\nintra-ocular injections of the B-subunit of cholera toxin (CTB), a sensitive\nanterograde tracer, in three adult male Long-Evans rats. In four additional\nsubjects, we injected fluorophor-conjugated CTB in both eyes, using a different\nfluorophor in each eye. Brains of these subjects were fixed and sectioned, and\nthe labeled retinal ganglion cell termini were imaged with wide-field\nsub-micron resolution slide scanners. Retinal termination zones were traced to\nreconstruct a three dimensional model of the ipsilateral and contralateral\nretinal termination zones in the dLGN on both sides of the brain. The dLGN\nvolume was 1.58 \\pm0.094 mm^{3}, comprising 70 \\pm 3% the volume of the entire\nretinorecipient LGN. We find the retinal terminals to be well-segregated by eye\nof origin. We consistently found three or four spatially separated\nipsilateral-recipient zones within each dLGN, rather than the single compact\nzone expected. It remains to be determined whether these subdomains represent\ndistinct functional sublaminae.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jun 2012 21:38:05 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["Discenza", "Claire B.", ""], ["Reinagel", "Pamela", ""]]}, {"id": "1206.4358", "submitter": "Danielle Bassett", "authors": "Danielle S. Bassett, Mason A. Porter, Nicholas F. Wymbs, Scott T.\n  Grafton, Jean M. Carlson, Peter J. Mucha", "title": "Robust Detection of Dynamic Community Structure in Networks", "comments": "18 pages, 11 figures", "journal-ref": "Chaos, 2013, 23, 1", "doi": "10.1063/1.4790830", "report-no": null, "categories": "physics.data-an cond-mat.dis-nn cs.SI physics.bio-ph physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe techniques for the robust detection of community structure in\nsome classes of time-dependent networks. Specifically, we consider the use of\nstatistical null models for facilitating the principled identification of\nstructural modules in semi-decomposable systems. Null models play an important\nrole both in the optimization of quality functions such as modularity and in\nthe subsequent assessment of the statistical validity of identified community\nstructure. We examine the sensitivity of such methods to model parameters and\nshow how comparisons to null models can help identify system scales. By\nconsidering a large number of optimizations, we quantify the variance of\nnetwork diagnostics over optimizations (`optimization variance') and over\nrandomizations of network structure (`randomization variance'). Because the\nmodularity quality function typically has a large number of nearly-degenerate\nlocal optima for networks constructed using real data, we develop a method to\nconstruct representative partitions that uses a null model to correct for\nstatistical noise in sets of partitions. To illustrate our results, we employ\nensembles of time-dependent networks extracted from both nonlinear oscillators\nand empirical neuroscience data.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2012 23:04:21 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2013 22:39:50 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Bassett", "Danielle S.", ""], ["Porter", "Mason A.", ""], ["Wymbs", "Nicholas F.", ""], ["Grafton", "Scott T.", ""], ["Carlson", "Jean M.", ""], ["Mucha", "Peter J.", ""]]}, {"id": "1206.4386", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "An Evolutionary Framework for Culture: Selectionism versus Communal\n  Exchange", "comments": "18 pages; 2 tables and 11 figures embedded in text", "journal-ref": "Physics of Life Reviews, 10(2), 117-145 (2013)", "doi": "10.1016/j.plrev.2013.03.006", "report-no": null, "categories": "q-bio.PE nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dawkins' replicator-based conception of evolution has led to widespread\nmis-application selectionism across the social sciences because it does not\naddress the paradox that inspired the theory of natural selection in the first\nplace: how do organisms accumulate change when traits acquired over their\nlifetime are obliterated? This is addressed by von Neumann's concept of a\nself-replicating automaton (SRA). A SRA consists of a self-assembly code that\nis used in two distinct ways: (1) actively deciphered during development to\nconstruct a self-similar replicant, and (2) passively copied to the replicant\nto ensure that it can reproduce. Information that is acquired over a lifetime\nis not transmitted to offspring, whereas information that is inherited during\ncopying is transmitted. In cultural evolution there is no mechanism for\ndiscarding acquired change. Acquired change can accumulate orders of magnitude\nfaster than, and quickly overwhelm, inherited change due to differential\nreplication of variants in response to selection. This prohibits a selectionist\nbut not an evolutionary framework for culture. Recent work on the origin of\nlife suggests that early life evolved through a non-Darwinian process referred\nto as communal exchange that does not involve a self-assembly code, and that\nnatural selection emerged from this more haphazard, ancestral evolutionary\nprocess. It is proposed that communal exchange provides a more appropriate\nevolutionary framework for culture than selectionism. This is supported by a\ncomputational model of cultural evolution and a network-based program for\ndocumenting material cultural history, and it is consistent with high levels of\nhuman cooperation.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 05:38:06 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2013 17:06:46 GMT"}, {"version": "v3", "created": "Sun, 30 Jun 2019 01:51:37 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1206.4469", "submitter": "Jorge Hidalgo", "authors": "Jorge Hidalgo, Luis F. Seoane, Jesus M. Cortes, Miguel A. Munoz", "title": "Stochastic Amplification of Fluctuations in Cortical Up-states", "comments": "main text: 24 pages, 3 figures; supporting information: 16 pages, 7\n  figures. Accepted for publication in PLoS ONE", "journal-ref": null, "doi": "10.1371/journal.pone.0040710", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech physics.bio-ph physics.comp-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical neurons are bistable; as a consequence their local field potentials\ncan fluctuate between quiescent and active states, generating slow 0.5-2 Hz\noscillations which are widely known as transitions between Up and Down States.\nDespite a large number of studies on Up-Down transitions, deciphering its\nnature, mechanisms and function are still today challenging tasks. In this\npaper we focus on recent experimental evidence, showing that a class of\nspontaneous oscillations can emerge within the Up states. In particular, a\nnon-trivial peak around 20 Hz appears in their associated power-spectra, what\nproduces an enhancement of the activity power for higher frequencies (in the\n30-90 Hz band). Moreover, this rhythm within Ups seems to be an emergent or\ncollective phenomenon given that individual neurons do not lock to it as they\nremain mostly unsynchronized. Remarkably, similar oscillations (and the\nconcomitant peak in the spectrum) do not appear in the Down states. Here we\nshed light on these findings by using different computational models for the\ndynamics of cortical networks in presence of different levels of physiological\ncomplexity. Our conclusion, supported by both theory and simulations, is that\nthe collective phenomenon of \"stochastic amplification of fluctuations\"\n-previously described in other contexts such as Ecology and Epidemiology--\nexplains in an elegant and parsimonious manner, beyond model-dependent details,\nthis extra-rhythm emerging only in the Up states but not in the Downs.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jun 2012 12:10:24 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Hidalgo", "Jorge", ""], ["Seoane", "Luis F.", ""], ["Cortes", "Jesus M.", ""], ["Munoz", "Miguel A.", ""]]}, {"id": "1206.4812", "submitter": "Gilles Wainrib", "authors": "Mathieu Galtier, Gilles Wainrib", "title": "A biological gradient descent for prediction through a combination of\n  STDP and homeostatic plasticity", "comments": "36 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying, formalizing and combining biological mechanisms which implement\nknown brain functions, such as prediction, is a main aspect of current research\nin theoretical neuroscience. In this letter, the mechanisms of Spike Timing\nDependent Plasticity (STDP) and homeostatic plasticity, combined in an original\nmathematical formalism, are shown to shape recurrent neural networks into\npredictors. Following a rigorous mathematical treatment, we prove that they\nimplement the online gradient descent of a distance between the network\nactivity and its stimuli. The convergence to an equilibrium, where the network\ncan spontaneously reproduce or predict its stimuli, does not suffer from\nbifurcation issues usually encountered in learning in recurrent neural\nnetworks.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 09:13:39 GMT"}, {"version": "v2", "created": "Tue, 11 Jun 2013 16:11:01 GMT"}], "update_date": "2013-06-12", "authors_parsed": [["Galtier", "Mathieu", ""], ["Wainrib", "Gilles", ""]]}, {"id": "1206.4841", "submitter": "Gerhard Schmid", "authors": "Xue Ao, Peter Hanggi and Gerhard Schmid", "title": "In-phase and anti-phase synchronization in noisy Hodgkin-Huxley neurons", "comments": null, "journal-ref": "Mathemathical Biosciences 245, 49 (2013)", "doi": "10.1016/j.mbs.2013.02.007", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We numerically investigate the influence of intrinsic channel noise on the\ndynamical response of delay-coupling in neuronal systems. The stochastic\ndynamics of the spiking is modeled within a stochastic modification of the\nstandard Hodgkin-Huxley model wherein the delay-coupling accounts for the\nfinite propagation time of an action potential along the neuronal axon. We\nquantify this delay-coupling of the Pyragas-type in terms of the difference\nbetween corresponding presynaptic and postsynaptic membrane potentials. For an\nelementary neuronal network consisting of two coupled neurons we detect\ncharacteristic stochastic synchronization patterns which exhibit multiple\nphase-flip bifurcations: The phase-flip bifurcations occur in form of alternate\ntransitions from an in-phase spiking activity towards an anti-phase spiking\nactivity. Interestingly, these phase-flips remain robust in strong channel\nnoise and in turn cause a striking stabilization of the spiking frequency.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 11:38:53 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2013 14:25:30 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Ao", "Xue", ""], ["Hanggi", "Peter", ""], ["Schmid", "Gerhard", ""]]}, {"id": "1206.4862", "submitter": "Matjaz Perc", "authors": "Daqing Guo, Qingyun Wang, Matjaz Perc", "title": "Complex synchronous behavior in interneuronal networks with delayed\n  inhibitory and fast electrical synapses", "comments": "8 two-column pages, 7 figures; accepted for publication in Physical\n  Review E", "journal-ref": "Phys. Rev. E 85 (2012) 061905", "doi": "10.1103/PhysRevE.85.061905", "report-no": null, "categories": "q-bio.NC nlin.PS physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks of fast-spiking interneurons are crucial for the generation of\nneural oscillations in the brain. Here we study the synchronous behavior of\ninterneuronal networks that are coupled by delayed inhibitory and fast\nelectrical synapses. We find that both coupling modes play a crucial role by\nthe synchronization of the network. In addition, delayed inhibitory synapses\naffect the emerging oscillatory patterns. By increasing the inhibitory synaptic\ndelay, we observe a transition from regular to mixed oscillatory patterns at a\ncritical value. We also examine how the unreliability of inhibitory synapses\ninfluences the emergence of synchronization and the oscillatory patterns. We\nfind that low levels of reliability tend to destroy synchronization, and\nmoreover, that interneuronal networks with long inhibitory synaptic delays\nrequire a minimal level of reliability for the mixed oscillatory pattern to be\nmaintained.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jun 2012 13:08:32 GMT"}], "update_date": "2012-06-22", "authors_parsed": [["Guo", "Daqing", ""], ["Wang", "Qingyun", ""], ["Perc", "Matjaz", ""]]}, {"id": "1206.5771", "submitter": "Christoph Adami", "authors": "Lars Marstaller, Arend Hintze, and Christoph Adami", "title": "The evolution of representation in simple cognitive networks", "comments": "36 pages, 10 figures, one Table", "journal-ref": "Neural Computation 25 (2013) 2079-2107", "doi": "10.1162/NECO_a_00475", "report-no": null, "categories": "q-bio.NC cs.NE q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representations are internal models of the environment that can provide\nguidance to a behaving agent, even in the absence of sensory information. It is\nnot clear how representations are developed and whether or not they are\nnecessary or even essential for intelligent behavior. We argue here that the\nability to represent relevant features of the environment is the expected\nconsequence of an adaptive process, give a formal definition of representation\nbased on information theory, and quantify it with a measure R. To measure how R\nchanges over time, we evolve two types of networks---an artificial neural\nnetwork and a network of hidden Markov gates---to solve a categorization task\nusing a genetic algorithm. We find that the capacity to represent increases\nduring evolutionary adaptation, and that agents form representations of their\nenvironment during their lifetime. This ability allows the agents to act on\nsensorial inputs in the context of their acquired representations and enables\ncomplex and context-dependent behavior. We examine which concepts (features of\nthe environment) our networks are representing, how the representations are\nlogically encoded in the networks, and how they form as an agent behaves to\nsolve a task. We conclude that R should be able to quantify the representations\nwithin any cognitive system, and should be predictive of an agent's long-term\nadaptive success.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 19:03:04 GMT"}, {"version": "v2", "created": "Tue, 6 Aug 2013 17:27:01 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Marstaller", "Lars", ""], ["Hintze", "Arend", ""], ["Adami", "Christoph", ""]]}, {"id": "1206.5811", "submitter": "Andrey Dovzhenok", "authors": "Andrey Dovzhenok, Leonid L. Rubchinsky", "title": "On the Origin of Tremor in Parkinson's Disease", "comments": "21 pages, 8 figures, submitted to PLoS One", "journal-ref": "(2012) PLoS ONE 7(7): e41598", "doi": "10.1371/journal.pone.0041598", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exact origin of tremor in Parkinson's disease remains unknown. We explain\nwhy the existing data converge on the basal ganglia-thalamo-cortical loop as a\ntremor generator and consider a conductance-based model of subthalamo-pallidal\ncircuits embedded into a simplified representation of the basal\nganglia-thalamo-cortical circuit to investigate the dynamics of this loop. We\nshow how variation of the strength of dopamine-modulated connections in the\nbasal ganglia-thalamo-cortical loop (representing the decreasing dopamine level\nin Parkinson's disease) leads to the occurrence of tremor-like burst firing.\nThese tremor-like oscillations are suppressed when the connections are\nmodulated back to represent a higher dopamine level (as it would be the case in\ndopaminergic therapy), as well as when the basal ganglia-thalamo-cortical loop\nis broken (as would be the case for ablative anti-parkinsonian surgeries).\nThus, the proposed model provides an explanation for the basal\nganglia-thalamo-cortical loop mechanism of tremor generation. The strengthening\nof the loop leads to tremor oscillations, while the weakening or disconnection\nof the loop suppresses them. The loop origin of parkinsonian tremor also\nsuggests that new tremor-suppression therapies may have anatomical targets in\ndifferent cortical and subcortical areas as long as they are within the basal\nganglia-thalamo-cortical loop.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 20:00:33 GMT"}], "update_date": "2012-08-13", "authors_parsed": [["Dovzhenok", "Andrey", ""], ["Rubchinsky", "Leonid L.", ""]]}, {"id": "1206.6129", "submitter": "Marcelo Magnasco", "authors": "Thibaud Taillefumier and Marcelo O. Magnasco", "title": "A phase transition in the first passage of a Brownian process through a\n  fluctuating boundary: implications for neural coding", "comments": null, "journal-ref": null, "doi": "10.1073/pnas.1212479110", "report-no": null, "categories": "q-bio.NC math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the first time a fluctuating quantity reaches a given boundary is a\ndeceptively simple-looking problem of vast practical importance in physics,\nbiology, chemistry, neuroscience, economics and industry. Problems in which the\nbound to be traversed is itself a fluctuating function of time include widely\nstudied settings in neural coding, such as neuronal integrators with irregular\ninputs and internal noise. We show that the probability p(t) that a\nGauss-Markov process will first exceed the boundary at time t suffers a phase\ntransition as a function of the roughness of the boundary, as measured by its\nH\\\"older exponent H, with critical value Hc = 1/2. For smoother boundaries, H >\n1/2, the probability density is a continuous func- tion of time. For rougher\nboundaries, H < 1/2, the probability is concentrated on a Cantor-like set of\nzero measure: the probability density becomes divergent, almost everywhere\neither zero or infin- ity. The critical point Hc = 1/2 corresponds to a\nwidely-studied case in the theory of neural coding, where the external input\nintegrated by a model neuron is a white-noise process, such as uncorrelated but\nprecisely balanced excitatory and inhibitory inputs. We argue this transition\ncorresponds to a sharp boundary between rate codes, in which the neural firing\nprobability varies smoothly, and temporal codes, in which the neuron fires at\nsharply-defined times regardless of the intensity of internal noise.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jun 2012 21:48:53 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Taillefumier", "Thibaud", ""], ["Magnasco", "Marcelo O.", ""]]}, {"id": "1206.6286", "submitter": "Lester Ingber", "authors": "Lester Ingber", "title": "Statistical mechanics of neocortical interactions: large-scale EEG\n  influences on molecular processes", "comments": "Accepted for publication in Journal of Theoretical Biology", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent calculations further supports the premise that large-scale synchronous\nfirings of neurons may affect molecular processes. The context is scalp\nelectroencephalography (EEG) during short-term memory (STM) tasks. The\nmechanism considered is $\\mathbf{\\Pi} = \\mathbf{p} + q \\mathbf{A}$ (SI units)\ncoupling, where $\\mathbf{p}$ is the momenta of free $\\mathrm{Ca}^{2+}$ waves\n$q$ the charge of $\\mathrm{Ca}^{2+}$ in units of the electron charge, and\n$\\mathbf{A}$ the magnetic vector potential of current $\\mathbf{I}$ from\nneuronal minicolumnar firings considered as wires, giving rise to EEG. Data has\nprocessed using multiple graphs to identify sections of data to which\nspline-Laplacian transformations are applied, to fit the statistical mechanics\nof neocortical interactions (SMNI) model to EEG data, sensitive to synaptic\ninteractions subject to modification by $\\mathrm{Ca}^{2+}$ waves.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2012 21:02:44 GMT"}, {"version": "v2", "created": "Mon, 6 Aug 2012 15:00:20 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2012 14:43:39 GMT"}, {"version": "v4", "created": "Fri, 10 May 2013 22:02:16 GMT"}, {"version": "v5", "created": "Sun, 6 Dec 2015 00:49:44 GMT"}, {"version": "v6", "created": "Tue, 2 Feb 2016 17:12:30 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Ingber", "Lester", ""]]}]