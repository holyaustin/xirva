[{"id": "1507.00125", "submitter": "Stephanie Elizabeth Palmer", "authors": "Jared Salisbury, Stephanie E. Palmer", "title": "Optimal prediction and natural scene statistics in the retina", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all neural computations involve making predictions. Whether an\norganism is trying to catch prey, avoid predators, or simply move through a\ncomplex environment, the data it collects through its senses can guide its\nactions only to the extent that it can extract from these data information\nabout the future state of the world. An essential aspect of the problem in all\nthese forms is that not all features of the past carry predictive power. Since\nthere are costs associated with representing and transmitting information, a\nnatural hypothesis is that sensory systems have developed coding strategies\nthat are optimized to minimize these costs, keeping only a limited number of\nbits of information about the past and ensuring that these bits are maximally\ninformative about the future. Another important feature of the prediction\nproblem is that the physics of the world is diverse enough to contain a wide\nrange of possible statistical ensembles, yet not all motion is probable. Thus,\nthe brain might not be a generalized predictive machine; it might have evolved\nto specifically solve the prediction problems most common in the natural\nenvironment. This paper reviews recent results on predictive coding and optimal\npredictive information in the retina and suggests approaches for quantifying\nprediction in response to natural motion.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 06:59:14 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Salisbury", "Jared", ""], ["Palmer", "Stephanie E.", ""]]}, {"id": "1507.00189", "submitter": "Anna Cattani", "authors": "Anna Cattani, Sergio Solinas, Claudio Canuto", "title": "A hybrid model for large neural network description", "comments": "18 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the present paper is to efficiently describe the membrane\npotential dynamics of neural populations formed by species having a high\ndensity difference in specific brain areas. We propose a hybrid model whose\nmain ingredients are a conductance-based model (ODE system) and its continuous\ncounterpart (PDE system) obtained through a limit process in which the number\nof neurons confined in a bounded region of the brain is sent to infinity.\nSpecifically, in the discrete model each cell of the low-density populations is\nindividually described by a set of time-dependent variables, whereas in the\ncontinuum model the high-density populations are described as a whole by a\nsmall set of continuous variables depending on space and time. Communications\namong populations, which translate into interactions among the discrete and the\ncontinuous models, are the essence of the hybrid model we present here. Such an\napproach has been validated reconstructing the ensemble activity of the\ngranular layer network of the Cerebellum, leading to a computational cost\nreduction. The hybrid model reproduced interesting dynamics such as local\nmicrocircuit synchronization, travelling waves, center-surround and\ntime-windowing.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 11:14:00 GMT"}, {"version": "v2", "created": "Mon, 5 Oct 2015 10:08:26 GMT"}], "update_date": "2015-10-06", "authors_parsed": [["Cattani", "Anna", ""], ["Solinas", "Sergio", ""], ["Canuto", "Claudio", ""]]}, {"id": "1507.00235", "submitter": "Stefano Fusi", "authors": "Daniel Mart\\'i, Mattia Rigotti, Mingoo Seok, Stefano Fusi", "title": "Energy-efficient neuromorphic classifiers", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuromorphic engineering combines the architectural and computational\nprinciples of systems neuroscience with semiconductor electronics, with the aim\nof building efficient and compact devices that mimic the synaptic and neural\nmachinery of the brain. Neuromorphic engineering promises extremely low energy\nconsumptions, comparable to those of the nervous system. However, until now the\nneuromorphic approach has been restricted to relatively simple circuits and\nspecialized functions, rendering elusive a direct comparison of their energy\nconsumption to that used by conventional von Neumann digital machines solving\nreal-world tasks. Here we show that a recent technology developed by IBM can be\nleveraged to realize neuromorphic circuits that operate as classifiers of\ncomplex real-world stimuli. These circuits emulate enough neurons to compete\nwith state-of-the-art classifiers. We also show that the energy consumption of\nthe IBM chip is typically 2 or more orders of magnitude lower than that of\nconventional digital machines when implementing classifiers with comparable\nperformance. Moreover, the spike-based dynamics display a trade-off between\nintegration time and accuracy, which naturally translates into algorithms that\ncan be flexibly deployed for either fast and approximate classifications, or\nmore accurate classifications at the mere expense of longer running times and\nhigher energy costs. This work finally proves that the neuromorphic approach\ncan be efficiently used in real-world applications and it has significant\nadvantages over conventional digital devices when energy consumption is\nconsidered.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 13:52:07 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Mart\u00ed", "Daniel", ""], ["Rigotti", "Mattia", ""], ["Seok", "Mingoo", ""], ["Fusi", "Stefano", ""]]}, {"id": "1507.00327", "submitter": "Vince Grolmusz", "authors": "Csaba Kerepesi and Bal\\'azs Szalkai and B\\'alint Varga and Vince\n  Grolmusz", "title": "Comparative Connectomics: Mapping the Inter-Individual Variability of\n  Connections within the Regions of the Human Brain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human braingraph, or connectome is a description of the connections of\nthe brain: the nodes of the graph correspond to small areas of the gray matter,\nand two nodes are connected by an edge if a diffusion MRI-based workflow finds\nfibers between those brain areas. We have constructed 1015-vertex graphs from\nthe diffusion MRI brain images of 395 human subjects and compared the\nindividual graphs with respect to several different areas of the brain. The\ninter-individual variability of the graphs within different brain regions was\ndiscovered and described. We have found that the frontal and the limbic lobes\nare more conservative, while the edges in the temporal and occipital lobes are\nmore diverse. Interestingly, a \"hybrid\" conservative and diverse distribution\nwas found in the paracentral lobule and the fusiform gyrus. Smaller cortical\nareas were also evaluated: precentral gyri were found to be more conservative,\nand the postcentral and the superior temporal gyri to be very diverse.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 19:39:51 GMT"}], "update_date": "2015-07-02", "authors_parsed": [["Kerepesi", "Csaba", ""], ["Szalkai", "Bal\u00e1zs", ""], ["Varga", "B\u00e1lint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1507.00368", "submitter": "Piotr S{\\l}owi\\'nski", "authors": "Piotr S{\\l}owi\\'nski, Chao Zhai, Francesco Alderisio, Robin Salesse,\n  Mathieu Gueugnon, Ludovic Marin, Benoit G. Bardy, Mario di Bernardo, and\n  Krasimira Tsaneva-Atanasova", "title": "Dynamic similarity promotes interpersonal coordination in joint-action", "comments": null, "journal-ref": "J. R. Soc. Interface 2016, 13, 20151093", "doi": "10.1098/rsif.2015.1093", "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human movement has been studied for decades and dynamic laws of motion that\nare common to all humans have been derived. Yet, every individual moves\ndifferently from everyone else (faster/slower, harder/smoother etc). We propose\nhere an index of such variability, namely an individual motor signature (IMS)\nable to capture the subtle differences in the way each of us moves. We show\nthat the IMS of a person is time-invariant and that it significantly differs\nfrom those of other individuals. This allows us to quantify the dynamic\nsimilarity, a measure of rapport between dynamics of different individuals'\nmovements, and demonstrate that it facilitates coordination during interaction.\nWe use our measure to confirm a key prediction of the theory of similarity that\ncoordination between two individuals performing a joint-action task is higher\nif their motions share similar dynamic features. Furthermore, we use a virtual\navatar driven by an interactive cognitive architecture based on feedback\ncontrol theory to explore the effects of different kinematic features of the\navatar motion on the coordination with human players.\n", "versions": [{"version": "v1", "created": "Wed, 1 Jul 2015 20:41:07 GMT"}, {"version": "v2", "created": "Tue, 22 Dec 2015 08:16:07 GMT"}], "update_date": "2016-03-24", "authors_parsed": [["S\u0142owi\u0144ski", "Piotr", ""], ["Zhai", "Chao", ""], ["Alderisio", "Francesco", ""], ["Salesse", "Robin", ""], ["Gueugnon", "Mathieu", ""], ["Marin", "Ludovic", ""], ["Bardy", "Benoit G.", ""], ["di Bernardo", "Mario", ""], ["Tsaneva-Atanasova", "Krasimira", ""]]}, {"id": "1507.01390", "submitter": "Rajani Raman", "authors": "Rajani Raman, Sandip Sarkar", "title": "Predictive coding: A Possible Explanation of Filling-in at the blind\n  spot", "comments": "23 pages, 9 figures", "journal-ref": null, "doi": "10.1371/journal.pone.0151194", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Filling-in at the blind-spot is a perceptual phenomenon in which the visual\nsystem fills the informational void, which arises due to the absence of retinal\ninput corresponding to the optic disc, with surrounding visual attributes.\nThough there are enough evidence to conclude that some kind of neural\ncomputation is involved in filling-in at the blind spot especially in the early\nvisual cortex, the knowledge of the actual computational mechanism is far from\ncomplete. We have investigated the bar experiments and the associated\nfilling-in phenomenon in the light of the hierarchical predictive coding\nframework, where the blind-spot was represented by the absence of early\nfeed-forward connection. We recorded the responses of predictive estimator\nneurons at the blind-spot region in the V1 area of our three level (LGN-V1-V2)\nmodel network. These responses are in agreement with the results of earlier\nphysiological studies and using the generative model we also showed that these\nresponse profiles indeed represent the filling-in completion. These demonstrate\nthat predictive coding framework could account for the filling-in phenomena\nobserved in several psychophysical and physiological experiments involving bar\nstimuli. These results suggest that the filling-in could naturally arise from\nthe computational principle of hierarchical predictive coding (HPC) of natural\nimages.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 11:20:31 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Raman", "Rajani", ""], ["Sarkar", "Sandip", ""]]}, {"id": "1507.01497", "submitter": "Neil Rabinowitz", "authors": "Neil C. Rabinowitz and Robbe L. T. Goris and Johannes Ball\\'e and Eero\n  P. Simoncelli", "title": "A model of sensory neural responses in the presence of unknown\n  modulatory inputs", "comments": "9 pages, 5 figures. minor changes since v1: added extra references,\n  connections to previous models, links to GLMs, complexity measures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural responses are highly variable, and some portion of this variability\narises from fluctuations in modulatory factors that alter their gain, such as\nadaptation, attention, arousal, expected or actual reward, emotion, and local\nmetabolic resource availability. Regardless of their origin, fluctuations in\nthese signals can confound or bias the inferences that one derives from spiking\nresponses. Recent work demonstrates that for sensory neurons, these effects can\nbe captured by a modulated Poisson model, whose rate is the product of a\nstimulus-driven response function and an unknown modulatory signal. Here, we\nextend this model, by incorporating explicit modulatory elements that are known\n(specifically, spike-history dependence, as in previous models), and by\nconstraining the remaining latent modulatory signals to be smooth in time. We\ndevelop inference procedures for fitting the entire model, including\nhyperparameters, via evidence optimization, and apply these to simulated data,\nand to responses of ferret auditory midbrain and cortical neurons to complex\nsounds. We show that integrating out the latent modulators yields better (or\nmore readily-interpretable) receptive field estimates than a standard Poisson\nmodel. Conversely, integrating out the stimulus dependence yields estimates of\nthe slowly-varying latent modulators.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jul 2015 15:31:20 GMT"}, {"version": "v2", "created": "Tue, 7 Jul 2015 01:28:39 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Rabinowitz", "Neil C.", ""], ["Goris", "Robbe L. T.", ""], ["Ball\u00e9", "Johannes", ""], ["Simoncelli", "Eero P.", ""]]}, {"id": "1507.01891", "submitter": "Irina Malkina-Pykh G.", "authors": "Irina Malkina-Pykh", "title": "Predicting and increasing subjective well-being: response function model\n  and rhythmic movement therapy", "comments": null, "journal-ref": null, "doi": "10.13140/2.1.4118.0968", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. The objective of the present study was to apply the nonlinear\nresponse function model of subjective well-being (RFSWB model) to evaluate the\noutcome of rhythmic movement therapy (RMT) for increasing subjective well-being\nand to analyze whether intervention-related changes in several psychological\nvariables were mechanisms underlying SWB increase in subjects participating in\nRMT group. Methods. A total of 273 subjects (54 males and 219 females, mean age\nwas 37.3(SD=10.5) years) were selected at random in nonclinical population and\nassessed with the appropriate surveys and questionnaires. The RMT program was\nproposed to the 105 subjects (24 males, 81 females, and mean age 37.6(SD=11.7)\nyears) with very low, low and medium SWB level. Control group was included.\nFindings. Results revealed that: a) substantial changes in SWB and underlying\npsychological state were observed among the participants as a result of RMT\nintervention; b) RFSWB model predicts the changes in SWB after RMT intervention\nsatisfactorily and can help to identify the reliable predictors of success.\n", "versions": [{"version": "v1", "created": "Sun, 5 Jul 2015 09:42:32 GMT"}], "update_date": "2015-07-08", "authors_parsed": [["Malkina-Pykh", "Irina", ""]]}, {"id": "1507.02716", "submitter": "Pierre Sacr\\'e", "authors": "Pierre Sacr\\'e, Sridevi V. Sarma, Yun Guan, William S. Anderson", "title": "Electrical neurostimulation for chronic pain: on selective relay of\n  sensory neural activities in myelinated nerve fibers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chronic pain affects about 100 million adults in the US. Despite their great\nneed, neuropharmacology and neurostimulation therapies for chronic pain have\nbeen associated with suboptimal efficacy and limited long-term success, as\ntheir mechanisms of action are unclear. Yet current computational models of\npain transmission suffer from several limitations. In particular, dorsal column\nmodels do not include the fundamental underlying sensory activity traveling in\nthese nerve fibers. We developed a (simple) simulation test bed of electrical\nneurostimulation of myelinated nerve fibers with underlying sensory activity.\nThis paper reports our findings so far. Interactions between stimulation-evoked\nand underlying activities are mainly due to collisions of action potentials and\nlosses of excitability due to the refractory period following an action\npotential. In addition, intuitively, the reliability of sensory activity\ndecreases as the stimulation frequency increases. This first step opens the\ndoor to a better understanding of pain transmission and its modulation by\nneurostimulation therapies.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jul 2015 21:11:41 GMT"}], "update_date": "2015-07-13", "authors_parsed": [["Sacr\u00e9", "Pierre", ""], ["Sarma", "Sridevi V.", ""], ["Guan", "Yun", ""], ["Anderson", "William S.", ""]]}, {"id": "1507.03254", "submitter": "Matjaz Perc", "authors": "Igor Franovi\\'c, Matjaz Perc, Kristina Todorovi\\'c, Sr{\\dj}an\n  Kosti\\'c, Nikola Buri\\'c", "title": "Activation process in excitable systems with multiple noise sources:\n  Large number of units", "comments": "14 two-column pages, 9 figures; accepted for publication in Physical\n  Review E", "journal-ref": "Phys. Rev. E 92 (2015) 062912", "doi": "10.1103/PhysRevE.92.062912", "report-no": null, "categories": "nlin.CD physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the activation process in large assemblies of type II excitable\nunits whose dynamics is influenced by two independent noise terms. The\nmean-field approach is applied to explicitly demonstrate that the assembly of\nexcitable units can itself exhibit macroscopic excitable behavior. In order to\nfacilitate the comparison between the excitable dynamics of a single unit and\nan assembly, we introduce three distinct formulations of the assembly\nactivation event. Each formulation treats different aspects of the relevant\nphenomena, including the threshold-like behavior and the role of coherence of\nindividual spikes. Statistical properties of the assembly activation process,\nsuch as the mean time-to-first pulse and the associated coefficient of\nvariation, are found to be qualitatively analogous for all three formulations,\nas well as to resemble the results for a single unit. These analogies are shown\nto derive from the fact that global variables undergo a stochastic bifurcation\nfrom the stochastically stable fixed point to continuous oscillations. Local\nactivation processes are analyzed in the light of the competition between the\nnoise-led and the relaxation-driven dynamics. We also briefly report on a\nsystem-size anti-resonant effect displayed by the mean time-to-first pulse.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2015 17:40:03 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 20:18:01 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Franovi\u0107", "Igor", ""], ["Perc", "Matjaz", ""], ["Todorovi\u0107", "Kristina", ""], ["Kosti\u0107", "Sr\u0111an", ""], ["Buri\u0107", "Nikola", ""]]}, {"id": "1507.03260", "submitter": "Matjaz Perc", "authors": "Igor Franovi\\'c, Kristina Todorovi\\'c, Matjaz Perc, Neboj\\v{s}a\n  Vasovi\\'c, Nikola Buri\\'c", "title": "Activation process in excitable systems with multiple noise sources: One\n  and two interacting units", "comments": "18 two-column pages, 9 figures; accepted for publication in Physical\n  Review E", "journal-ref": "Phys. Rev. E 92 (2015) 062911", "doi": "10.1103/PhysRevE.92.062911", "report-no": null, "categories": "nlin.CD physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the coaction of two distinct noise sources on the activation\nprocess of a single and two interacting excitable units, which are\nmathematically described by the Fitzhugh-Nagumo equations. We determine the\nmost probable activation paths around which the corresponding stochastic\ntrajectories are clustered. The key point lies in introducing appropriate\nboundary conditions that are relevant for a class II excitable unit, which can\nbe immediately generalized also to scenarios involving two coupled units. We\nanalyze the effects of the two noise sources on the statistical features of the\nactivation process, in particular demonstrating how these are modified due to\nthe linear/nonlinear form of interactions. Universal properties of the\nactivation process are qualitatively discussed in the light of a stochastic\nbifurcation that underlies the transition from a stochastically stable fixed\npoint to continuous oscillations.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jul 2015 18:29:15 GMT"}, {"version": "v2", "created": "Tue, 24 Nov 2015 20:15:48 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Franovi\u0107", "Igor", ""], ["Todorovi\u0107", "Kristina", ""], ["Perc", "Matjaz", ""], ["Vasovi\u0107", "Neboj\u0161a", ""], ["Buri\u0107", "Nikola", ""]]}, {"id": "1507.03311", "submitter": "Sang-Yoon  Kim", "authors": "Sang-Yoon Kim and Woochang Lim", "title": "Effect of Inter-Modular Connection on Fast Sparse Synchronization in\n  Clustered Small-World Neural Networks", "comments": null, "journal-ref": "Phys. Rev. E 92, 052716 (2015)", "doi": "10.1103/PhysRevE.92.052716", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a clustered network with small-world sub-networks of inhibitory\nfast spiking interneurons, and investigate the effect of inter-modular\nconnection on emergence of fast sparsely synchronized rhythms by varying both\nthe inter-modular coupling strength $J_{inter}$ and the average number of\ninter-modular links per interneuron $M_{syn}^{(inter)}$. In contrast to the\ncase of non-clustered networks, two kinds of sparsely synchronized states such\nas modular and global synchronization are found. For the case of modular sparse\nsynchronization, the population behavior reveals the modular structure, because\nthe intra-modular dynamics of sub-networks make some mismatching. On the other\nhand, in the case of global sparse synchronization, the population behavior is\nglobally identical, independently of the cluster structure, because the\nintra-modular dynamics of sub-networks make perfect matching. We introduce a\nrealistic cross-correlation modularity measure, representing the\nmatching-degree between the instantaneous sub-population spike rates of the\nsub-networks, and examine whether the sparse synchronization is global or\nmodular. Furthermore, we characterize the modular and global sparse\nsynchronization by employing the realistic sub- and whole-population order\nparameters and statistical-mechanical measures. The roles of $J_{inter}$ and\n$M_{syn}^{(inter)}$ are thus found as follows. For large $J_{inter}$, due to\nstrong inhibition it plays a destructive role to \"spoil\" the pacing between\nspikes, while for small $J_{inter}$ it plays a constructive role to \"favor\" the\npacing between spikes. In contrast, $M_{syn}^{(inter)}$ seems to play a role\njust to favor the pacing between spikes. With increasing $M_{syn}^{(inter)}$,\nthe pacing degree between spikes increases monotonically thanks to the increase\nin the degree of effectiveness of global communication between spikes.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jul 2015 02:42:16 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 06:48:08 GMT"}], "update_date": "2015-12-02", "authors_parsed": [["Kim", "Sang-Yoon", ""], ["Lim", "Woochang", ""]]}, {"id": "1507.03730", "submitter": "Robert Miller", "authors": "Robert Miller, Stefan Scherbaum, Daniel W. Heck, Thomas Goschke,\n  Soeren Enge", "title": "On the relation between the (censored) shifted Wald and the Wiener\n  distribution as measurement models for choice response times", "comments": "37 pages, 4 figures, 3 tables", "journal-ref": null, "doi": "10.1177/0146621617710465", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring processes or constructs from performance data is a major hallmark\nof cognitive psychometrics. Particularly, diffusion modeling of response times\n(RTs) from correct and erroneous responses using the Wiener distribution has\nbecome a popular measurement tool because it provides a set of psychologically\ninterpretable parameters. However, an important precondition to identify all of\nthese parameters is a sufficient number of RTs from erroneous responses. In the\npresent article, we show by simulation that the parameters of the Wiener\ndistribution can be recovered from tasks yielding very high or even perfect\nresponse accuracies using the shifted Wald distribution. Specifically, we argue\nthat error RTs can be modeled as correct RTs that have undergone censoring by\nusing techniques from parametric survival analysis. We illustrate our reasoning\nby fitting the Wiener and (censored) shifted Wald distribution to RTs from six\nparticipants who completed a Go/No-go task. In accordance with our simulations,\ndiffusion modeling using the Wiener and the shifted Wald distribution yielded\nidentical parameter estimates when the number of erroneous responses was\npredicted to be low. Moreover, the modeling of error RTs as censored correct\nRTs substantially improved the recovery of these diffusion parameters when\npremature trial timeout was introduced to increase the number of omission\nerrors. Thus, the censored shifted Wald distribution provides a suitable means\nfor diffusion modeling in situations when the Wiener distribution cannot be\nfitted without parametric constraints.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2015 06:21:57 GMT"}, {"version": "v2", "created": "Tue, 21 Feb 2017 15:19:01 GMT"}, {"version": "v3", "created": "Mon, 28 Aug 2017 20:36:31 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Miller", "Robert", ""], ["Scherbaum", "Stefan", ""], ["Heck", "Daniel W.", ""], ["Goschke", "Thomas", ""], ["Enge", "Soeren", ""]]}, {"id": "1507.03751", "submitter": "Manfred Harringer", "authors": "Manfred Harringer", "title": "Closed Curves and Elementary Visual Object Identification", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For two closed curves on a plane (discrete version) and local criteria for\nsimilarity of points on the curves one gets a potential, which describes the\nsimilarity between curve points. This is the base for a global similarity\nmeasure of closed curves (Fr\\'echet distance). I use borderlines of handwritten\ndigits to demonstrate an area of application. I imagine, measuring the\nsimilarity of closed curves is an essential and elementary task performed by a\nvisual system. This approach to similarity measures may be used by visual\nsystems.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2015 07:57:39 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Harringer", "Manfred", ""]]}, {"id": "1507.03881", "submitter": "David Breuer", "authors": "David Breuer, Marc Timme, Raoul-Martin Memmesheimer", "title": "Statistical physics of neural systems with non-additive dendritic\n  coupling", "comments": null, "journal-ref": "Phys Rev X, 2014, 4(1):011053", "doi": "10.1103/PhysRevX.4.011053", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How neurons process their inputs crucially determines the dynamics of\nbiological and artificial neural networks. In such neural and neural-like\nsystems, synaptic input is typically considered to be merely transmitted\nlinearly or sublinearly by the dendritic compartments. Yet, single-neuron\nexperiments report pronounced supralinear dendritic summation of sufficiently\nsynchronous and spatially close-by inputs. Here, we provide a statistical\nphysics approach to study the impact of such non-additive dendritic processing\non single neuron responses and the performance of associative memory tasks in\nartificial neural networks. First, we compute the effect of random input to a\nneuron incorporating nonlinear dendrites. This approach is independent of the\ndetails of the neuronal dynamics. Second, we use those results to study the\nimpact of dendritic nonlinearities on the network dynamics in a paradigmatic\nmodel for associative memory, both numerically and analytically. We find that\ndendritic nonlinearities maintain network convergence and increase the\nrobustness of memory performance against noise. Interestingly, an intermediate\nnumber of dendritic branches is optimal for memory functionality.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jul 2015 15:15:16 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Breuer", "David", ""], ["Timme", "Marc", ""], ["Memmesheimer", "Raoul-Martin", ""]]}, {"id": "1507.04294", "submitter": "Zachary Kilpatrick PhD", "authors": "Daniel B Poll, Khanh Nguyen, and Zachary P Kilpatrick", "title": "Sensory feedback in a bump attractor model of path integration", "comments": "24 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mammalian spatial navigation system makes use of several different\nsensory information channels. This information is then converted into a neural\ncode that represents the animal's current position in space by engaging place\ncell, grid cell, and head direction cell networks. In particular, sensory\nlandmark (allothetic) cues can be utilized in concert with an animal's\nknowledge of its own velocity (idiothetic) cues to generate a more accurate\nrepresentation of position than (idiothetic) path integration provides on its\nown (Battaglia et al, 2004). We develop a computational model that merges path\nintegration with information from external sensory cues that provide a reliable\nrepresentation of spatial position along an annular track. Starting with a\ncontinuous bump attractor model, we allow for the possibility of synaptic\nspatial heterogeneity that would break the translation symmetry of space. We\nuse asymptotic analysis to reduce the bump attractor model to a single scalar\nequation whose potential represents the impact of heterogeneity. Such\nheterogeneity causes errors to build up when the network performs path\nintegration, but these errors can be corrected by an external control signal\nrepresenting the effects of sensory cues. We demonstrate that there is an\noptimal strength and decay rate of the control signal when cues are placed both\nperiodically and randomly. A similar analysis is performed when errors in path\nintegration arise from dynamic noise fluctuations. Again, there is an optimal\nstrength and decay of discrete control that minimizes the path integration\nerror.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jul 2015 16:49:51 GMT"}], "update_date": "2015-07-16", "authors_parsed": [["Poll", "Daniel B", ""], ["Nguyen", "Khanh", ""], ["Kilpatrick", "Zachary P", ""]]}, {"id": "1507.04552", "submitter": "R.K. Brojen Singh", "authors": "Sanjeet Maisnam and R.K. Brojen Singh", "title": "Generalization of neuron network model with delay feedback", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present generalized delayed neural network (DNN) model with positive delay\nfeedback and neuron history. The local stability analysis around trivial local\nequilibria of delayed neural networks has applied and determine the conditions\nfor the existence of zero root. We develop few innovative delayed neural\nnetwork models in different dimensions through transformation and extension of\nsome existing models. We found that zero root can have multiplicity two under\ncertain conditions. We further show how the characteristic equation can have\nzero root and its multiplicity is dependent on the conditions undertaken.\nFinally, we generalize the neural network of $N$ neurons through which we\ndetermine the general form of Jacobian of the linear form and corresponding\ncharacteristic equation of the system.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jul 2015 12:54:14 GMT"}], "update_date": "2015-07-17", "authors_parsed": [["Maisnam", "Sanjeet", ""], ["Singh", "R. K. Brojen", ""]]}, {"id": "1507.04971", "submitter": "Eugene Postnikov", "authors": "Eugene B. Postnikov, Elena A. Lebedeva, Anastasia I. Lavrova", "title": "Computational implementation of the inverse continuous wavelet transform\n  without a requirement of the admissibility condition", "comments": "18 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.FA math.NA q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, it has been proven [R. Soc. Open Sci. 1 (2014) 140124] that the\ncontinuous wavelet transform with non-admissible kernels (approximate wavelets)\nallows for an existence of the exact inverse transform. Here we consider the\ncomputational possibility for the realization of this approach. We provide\nmodified simpler explanation of the reconstruction formula, restricted on the\npractical case of real valued finite (or periodic/periodized) samples and the\nstandard (restricted) Morlet wavelet as a practically important example of an\napproximate wavelet. The provided examples of applications includes the test\nfunction and the non-stationary electro-physical signals arising in the problem\nof neuroscience.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2015 13:41:59 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Postnikov", "Eugene B.", ""], ["Lebedeva", "Elena A.", ""], ["Lavrova", "Anastasia I.", ""]]}, {"id": "1507.05018", "submitter": "Carolina Eu\\'an Campos", "authors": "Carolina Euan, Hernando Ombao and Joaquin Ortega", "title": "Spectral Synchronicity in Brain Signals", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain activity following stimulus presentation and during resting state are\noften the result of highly coordinated responses of large numbers of neurons\nboth locally and globally. Coordinated activity of neurons can give rise to\noscillations which are captured by electroencephalograms (EEG). In this paper,\nwe examine EEGs as this is the primary data being used by our collaborators who\nare studying coordination of neuronal response during the execution of tasks\nsuch as learning, and memory formation, retention and retrieval. In this paper,\nwe develop the spectral merger clustering (SMC) method that identifies\nsynchronized brain regions during resting state in a sense that these regions\nshare similar oscillations or waveforms. The SMC method, produces clusters of\nEEGs which serve as a proxy for segmenting the brain cortical surface since the\nEEGs capture neuronal activity over a locally distributed region on the\ncortical surface. The extent of desynchronicity between a pair of EEGs is\nmeasured using the total variation distance (TVD) which gives the largest\npossible difference between the spectral densities of the pair of EEGs. We\nconsidered the spectral merger algorithm for clustering EEGs, which updates the\nspectral estimate of the cluster from a weighted average of the spectral\nestimate obtained from each EEG in the cluster. Numerical experiments suggest\nthat the SMC method performs very well in producing the correct clusters. When\napplied to resting state EEG data, the method showed how some regions, though\nnot contiguously connected on the cortical surface, are spectrally synchronized\nduring resting state. Moreover, the method demonstrates that brain\norganization, as expressed in cluster formation, evolves over resting state.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jul 2015 16:17:48 GMT"}], "update_date": "2015-07-20", "authors_parsed": [["Euan", "Carolina", ""], ["Ombao", "Hernando", ""], ["Ortega", "Joaquin", ""]]}, {"id": "1507.05249", "submitter": "Leonardo L. Gollo", "authors": "Leonardo L. Gollo, Mauro Copelli, James A. Roberts", "title": "Diversity improves performance in excitable networks", "comments": "17 pages, 7 figures", "journal-ref": "PeerJ 4:e1912 (2016)", "doi": "10.7717/peerj.1912", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn cond-mat.stat-mech nlin.CG physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As few real systems comprise indistinguishable units, diversity is a hallmark\nof nature. Diversity among interacting units shapes properties of collective\nbehavior such as synchronization and information transmission. However, the\nbenefits of diversity on information processing at the edge of a phase\ntransition, ordinarily assumed to emerge from identical elements, remain\nlargely unexplored. Analyzing a general model of excitable systems with\nheterogeneous excitability, we find that diversity can greatly enhance optimal\nperformance (by two orders of magnitude) when distinguishing incoming inputs.\nHeterogeneous systems possess a subset of specialized elements whose capability\ngreatly exceeds that of the nonspecialized elements. Nonetheless, the behavior\nof the whole network can outperform all subgroups. We also find that diversity\ncan yield multiple percolation, with performance optimized at tricriticality.\nOur results are robust in specific and more realistic neuronal systems\ncomprising a combination of excitatory and inhibitory units, and indicate that\ndiversity-induced amplification can be harnessed by neuronal systems for\nevaluating stimulus intensities.\n", "versions": [{"version": "v1", "created": "Sun, 19 Jul 2015 06:38:14 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Gollo", "Leonardo L.", ""], ["Copelli", "Mauro", ""], ["Roberts", "James A.", ""]]}, {"id": "1507.05869", "submitter": "Ali Faisal", "authors": "Ali Faisal, Anni Nora, Jaeho Seol, Hanna Renvall, Riitta Salmelin", "title": "Kernel convolution model for decoding sounds from time-varying neural\n  responses", "comments": "4 pages, Accepted at IEEE International Workshop on Pattern\n  Recognition in Neuroimaging, Stanford, June 2015", "journal-ref": null, "doi": "10.1109/PRNI.2015.10", "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we present a kernel based convolution model to characterize\nneural responses to natural sounds by decoding their time-varying acoustic\nfeatures. The model allows to decode natural sounds from high-dimensional\nneural recordings, such as magnetoencephalography (MEG), that track timing and\nlocation of human cortical signalling noninvasively across multiple channels.\nWe used the MEG responses recorded from subjects listening to acoustically\ndifferent environmental sounds. By decoding the stimulus frequencies from the\nresponses, our model was able to accurately distinguish between two different\nsounds that it had never encountered before with 70% accuracy. Convolution\nmodels typically decode frequencies that appear at a certain time point in the\nsound signal by using neural responses from that time point until a certain\nfixed duration of the response. Using our model, we evaluated several fixed\ndurations (time-lags) of the neural responses and observed auditory MEG\nresponses to be most sensitive to spectral content of the sounds at time-lags\nof 250 ms to 500 ms. The proposed model should be useful for determining what\naspects of natural sounds are represented by high-dimensional neural responses\nand may reveal novel properties of neural signals.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 15:25:37 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Faisal", "Ali", ""], ["Nora", "Anni", ""], ["Seol", "Jaeho", ""], ["Renvall", "Hanna", ""], ["Salmelin", "Riitta", ""]]}, {"id": "1507.05970", "submitter": "Pengsheng Zheng", "authors": "Pengsheng Zheng", "title": "Chaotic Neuronal Oscillations in Spontaneous Cortical-Subcortical\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oscillatory activities are widely observed in specific frequency bands of\nrecorded field potentials in different brain regions, and play critical roles\nin processing neural information. Understanding the structure of these\noscillatory activities is essential for understanding the brain function. So\nfar many details remain elusive about their rhythmic structures and how these\noscillations are generated. We show that many oscillatory activities in\nspontaneous cortical-subcortical networks, such as delta, spindle, gamma,\nhigh-gamma and sharp wave ripple bands in different brain regions, are genuine\nchaotic time series which can be reconstructed as chaotic attractors through\nappropriately selected embedding delay and dimension. The reconstructed\nattractors are approximated by a simple radial basis function enabling high\nprecision short-term prediction. Simultaneously recorded oscillatory activities\nin multiple brain regions differ greatly in term of temporal phase and\namplitude but can be approximated by the same function. Our results suggest\nthat neural oscillations are produced by deterministic chaotic systems. The\noccurrence of neural oscillation events is predetermined, and the brain\npossibly knows when and where the information will be processed and transferred\nin the future time as a result of the deterministic dynamic.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jul 2015 20:05:42 GMT"}], "update_date": "2015-07-23", "authors_parsed": [["Zheng", "Pengsheng", ""]]}, {"id": "1507.06262", "submitter": "Ziv Williams", "authors": "Ziv Williams", "title": "Lamarckian inheritance following sensorimotor training and its neural\n  basis in Drosophila", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jean-Baptiste Lamarck was among first to suggest that certain acquired traits\nmay be heritable from parents to offspring. In this study, I examine whether\nand what aspects of sensorimotor conditioning by parents prior to conception\nmay influence the behavior of subsequent generations in Drosophila. Using\ngenetic and anatomic techniques, I find that both first- and second-generation\noffspring of parents who underwent prolonged olfactory training over multiple\ndays displayed a distinct response bias to the same specific trained odors. The\noffspring displayed an enhanced anemotactic approach response to the trained\nodors, however, and did not differentiate between orders based on whether\nparental training was aversive or appetitive. Consequently, disruption of both\nolfactory-receptor and dorsal-paired-medial neuron input into the mushroom\nbodies abolished this change in offspring response, but disrupting synaptic\noutput from a/b neurons of the mushroom body themselves had little effect on\nbehavior even though they remained necessary for enacting newly trained\nconditioned responses. These observations identify a unique transgenerational\ndissociation between parentally-trained conditioned and unconditioned sensory\nstimuli, and provide a putative neural basis for how sensorimotor experiences\nin insects may bias the behavior of subsequent generations.\n", "versions": [{"version": "v1", "created": "Wed, 22 Jul 2015 17:34:12 GMT"}], "update_date": "2015-07-23", "authors_parsed": [["Williams", "Ziv", ""]]}, {"id": "1507.07270", "submitter": "Ilan Golani", "authors": "A.Gomez-Marin, E. Oron, A.Gakamsky, D. Valente, Y. Benjamini, I.\n  Golani", "title": "Searching for behavioral homologies: Shared generative rules for\n  expansion and narrowing down of the locomotor repertoire in Arthropods and\n  Vertebrates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use immobility as an origin and reference for the measurement of locomotor\nbehavior; speed, the direction of walking and the direction of facing as the\nthree degrees of freedom shaping fly locomotor behavior, and cocaine as the\nparameter inducing a progressive transition in and out of immobility. In this\nway we expose and quantify the generative rules that shape fruit fly locomotor\nbehavior, which consist of a gradual narrowing down of the fly's locomotor\nfreedom of movement during the transition into immobility and a precisely\nopposite expansion of freedom during the transition from immobility to normal\nbehavior. The same generative rules of narrowing down and expansion apply to\nvertebrate behavior in a variety of contexts, Recent claims for deep homology\nbetween the vertebrate basal ganglia and the arthropod central complex, and\nneurochemical processes explaining the expansion of locomotor behavior in\nvertebrates could guide the search for equivalent neurochemical processes that\nmediate locomotor narrowing down and expansion in arthropods. We argue that a\nmethodology for isolating relevant measures and quantifying generative rules\nhaving a potential for discovering candidate behavioral homologies is already\navailable and we specify some of its essential features.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2015 00:39:34 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Gomez-Marin", "A.", ""], ["Oron", "E.", ""], ["Gakamsky", "A.", ""], ["Valente", "D.", ""], ["Benjamini", "Y.", ""], ["Golani", "I.", ""]]}, {"id": "1507.07317", "submitter": "Alain Destexhe", "authors": "Jean-Marie Gomes, Claude Bedard, Silvana Valtcheva, Matthew Nelson,\n  Vitalia Khokhlova, Pierre Pouget, Laurent Venance, Thierry Bal and Alain\n  Destexhe", "title": "Intracellular impedance measurements reveal non-ohmic properties of the\n  extracellular medium around neurons", "comments": "32 pages, 9 figures", "journal-ref": "Biophysical Journal 110: 234-246, 2016", "doi": "10.1016/j.bpj.2015.11.019", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The electrical properties of extracellular space around neurons are important\nto understand the genesis of extracellular potentials, as well as for\nlocalizing neuronal activity from extracellular recordings. However, the exact\nnature of these extracellular properties is still uncertain. We introduce a\nmethod to measure the impedance of the tissue, and which preserves the intact\ncell-medium interface, using whole-cell patch-clamp recordings in vivo and in\nvitro. We find that neural tissue has marked non-ohmic and frequency-filtering\nproperties, which are not consistent with a resistive (ohmic) medium, as often\nassumed. In contrast, using traditional metal electrodes provides very\ndifferent results, more consistent with a resistive medium. The amplitude and\nphase profiles of the measured impedance are consistent with the contribution\nof ionic diffusion. We also show that the impact of such frequency-filtering\nproperties is possibly important on the genesis of local field potentials, as\nwell as on the cable properties of neurons. The present results show non-ohmic\nproperties of the extracellular medium around neurons, and suggest that source\nestimation methods, as well as the cable properties of neurons, which all\nassume ohmic extracellular medium, may need to be re-evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2015 07:14:25 GMT"}, {"version": "v2", "created": "Sat, 31 Oct 2015 11:14:24 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2015 22:07:33 GMT"}], "update_date": "2017-01-03", "authors_parsed": [["Gomes", "Jean-Marie", ""], ["Bedard", "Claude", ""], ["Valtcheva", "Silvana", ""], ["Nelson", "Matthew", ""], ["Khokhlova", "Vitalia", ""], ["Pouget", "Pierre", ""], ["Venance", "Laurent", ""], ["Bal", "Thierry", ""], ["Destexhe", "Alain", ""]]}, {"id": "1507.07422", "submitter": "Raul Fernandez Rojas", "authors": "Raul Fernandez Rojas, Xu Huang, Keng Liang Ou, Dat Tran, and Sheikh\n  Md. Rabiul Islam", "title": "Analysis of Pain Hemodynamic Response Using Near-Infrared Spectroscopy\n  (NIRS)", "comments": "11 pages, 11 figures", "journal-ref": "The International Journal of Multimedia & Its Applications (IJMA)\n  Vol. 7, No. 2, April 2015", "doi": "10.5121/ijma.2015.7203", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent advances in brain research, understanding the various signals\nfor pain and pain intensities in the brain cortex is still a complex task due\nto temporal and spatial variations of brain hemodynamics. In this paper we have\ninvestigated pain based on cerebral hemodynamics via near-infrared spectroscopy\n(NIRS). This study presents a pain stimulation experiment that uses three\nacupuncture manipulation techniques to safely induce pain in healthy subjects.\nAcupuncture pain response was presented and hemodynamic pain signal analysis\nshowed the presence of dominant channels and their relationship among\nsurrounding channels, which contribute the further pain research area.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jul 2015 01:05:16 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Rojas", "Raul Fernandez", ""], ["Huang", "Xu", ""], ["Ou", "Keng Liang", ""], ["Tran", "Dat", ""], ["Islam", "Sheikh Md. Rabiul", ""]]}, {"id": "1507.07580", "submitter": "Stefano Fusi", "authors": "Marcus K. Benna and Stefano Fusi", "title": "Computational principles of biological memory", "comments": "21 pages + 46 pages of suppl. info", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memories are stored, retained, and recollected through complex, coupled\nprocesses operating on multiple timescales. To understand the computational\nprinciples behind these intricate networks of interactions we construct a broad\nclass of synaptic models that efficiently harnesses biological complexity to\npreserve numerous memories. The memory capacity scales almost linearly with the\nnumber of synapses, which is a substantial improvement over the square root\nscaling of previous models. This was achieved by combining multiple dynamical\nprocesses that initially store memories in fast variables and then\nprogressively transfer them to slower variables. Importantly, the interactions\nbetween fast and slow variables are bidirectional. The proposed models are\nrobust to parameter perturbations and can explain several properties of\nbiological memory, including delayed expression of synaptic modifications,\nmetaplasticity, and spacing effects.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jul 2015 20:29:33 GMT"}], "update_date": "2015-07-29", "authors_parsed": [["Benna", "Marcus K.", ""], ["Fusi", "Stefano", ""]]}, {"id": "1507.07629", "submitter": "Garrick Orchard", "authors": "Garrick Orchard and Ajinkya Jayawant and Gregory Cohen and Nitish\n  Thakor", "title": "Converting Static Image Datasets to Spiking Neuromorphic Datasets Using\n  Saccades", "comments": "10 pages, 6 figures in Frontiers in Neuromorphic Engineering, special\n  topic on Benchmarks and Challenges for Neuromorphic Engineering, 2015 (under\n  review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating datasets for Neuromorphic Vision is a challenging task. A lack of\navailable recordings from Neuromorphic Vision sensors means that data must\ntypically be recorded specifically for dataset creation rather than collecting\nand labelling existing data. The task is further complicated by a desire to\nsimultaneously provide traditional frame-based recordings to allow for direct\ncomparison with traditional Computer Vision algorithms. Here we propose a\nmethod for converting existing Computer Vision static image datasets into\nNeuromorphic Vision datasets using an actuated pan-tilt camera platform. Moving\nthe sensor rather than the scene or image is a more biologically realistic\napproach to sensing and eliminates timing artifacts introduced by monitor\nupdates when simulating motion on a computer monitor. We present conversion of\ntwo popular image datasets (MNIST and Caltech101) which have played important\nroles in the development of Computer Vision, and we provide performance metrics\non these datasets using spike-based recognition algorithms. This work\ncontributes datasets for future use in the field, as well as results from\nspike-based algorithms against which future works can compare. Furthermore, by\nconverting datasets already popular in Computer Vision, we enable more direct\ncomparison with frame-based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2015 03:23:25 GMT"}], "update_date": "2015-10-20", "authors_parsed": [["Orchard", "Garrick", ""], ["Jayawant", "Ajinkya", ""], ["Cohen", "Gregory", ""], ["Thakor", "Nitish", ""]]}, {"id": "1507.07668", "submitter": "Longfei Wang", "authors": "Chi Zhang, Li-Wei Liu, Long-Fei Wang, Yuan Yue and Lian-Chun Yu", "title": "Optimal Size for Maximal Energy Efficiency in Information Processing of\n  Biological Systems Due to Bistability", "comments": "5 pages, 3 figures, submitted to Chinese Physics Letter", "journal-ref": null, "doi": "10.1088/0256-307X/32/11/110501", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy efficiency is closely related to the evolution of biological systems\nand is important to their information processing. In this paper, we calculated\nthe excitation probability of a simple model of a bistable biological unit in\nresponse to pulsatile inputs, and its spontaneous excitation rate due to noise\nperturbation. Then we analytically calculated the mutual information, energy\ncost, and energy efficiency of an array of these bistable units. We found that\nthe optimal number of units could maximize this array's energy efficiency in\nencoding pulse inputs, which depends on the fixed energy cost. We conclude that\ndemand for energy efficiency in biological systems may strongly influence the\nsize of these systems under the pressure of natural selection.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2015 07:18:50 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Zhang", "Chi", ""], ["Liu", "Li-Wei", ""], ["Wang", "Long-Fei", ""], ["Yue", "Yuan", ""], ["Yu", "Lian-Chun", ""]]}, {"id": "1507.07800", "submitter": "Jonathan Heras", "authors": "Gadea Mata and J\\'onathan Heras and Miguel Morales and Ana Romero and\n  Julio Rubio", "title": "SynapCountJ --- a Tool for Analyzing Synaptic Densities in Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quantification of synapses is instrumental to measure the evolution of\nsynaptic densities of neurons under the effect of some physiological\nconditions, neuronal diseases or even drug treatments. However, the manual\nquantification of synapses is a tedious, error-prone, time-consuming and\nsubjective task; therefore, tools that might automate this process are\ndesirable. In this paper, we present SynapCountJ, an ImageJ plugin, that can\nmeasure synaptic density of individual neurons obtained by immunofluorescence\ntechniques, and also can be applied for batch processing of neurons that have\nbeen obtained in the same experiment or using the same setting. The procedure\nto quantify synapses implemented in SynapCountJ is based on the colocalization\nof three images of the same neuron (the neuron marked with two antibody markers\nand the structure of the neuron) and is inspired by methods coming from\nComputational Algebraic Topology. SynapCountJ provides a procedure to\nsemi-automatically quantify the number of synapses of neuron cultures; as a\nresult, the time required for such an analysis is greatly reduced.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2015 15:12:42 GMT"}], "update_date": "2015-07-29", "authors_parsed": [["Mata", "Gadea", ""], ["Heras", "J\u00f3nathan", ""], ["Morales", "Miguel", ""], ["Romero", "Ana", ""], ["Rubio", "Julio", ""]]}, {"id": "1507.07813", "submitter": "Yuval Harel", "authors": "Yuval Harel, Ron Meir, Manfred Opper", "title": "An Analytically Tractable Bayesian Approximation to Optimal Point\n  Process Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The process of dynamic state estimation (filtering) based on point process\nobservations is in general intractable. Numerical sampling techniques are often\npractically useful, but lead to limited conceptual insight about optimal\nencoding/decoding strategies, which are of significant relevance to\nComputational Neuroscience. We develop an analytically tractable Bayesian\napproximation to optimal filtering based on point process observations, which\nallows us to introduce distributional assumptions about sensory cell\nproperties, that greatly facilitates the analysis of optimal encoding in\nsituations deviating from common assumptions of uniform coding. The analytic\nframework leads to insights which are difficult to obtain from numerical\nalgorithms, and is consistent with experiments about the distribution of tuning\ncurve centers. Interestingly, we find that the information gained from the\nabsence of spikes may be crucial to performance.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2015 15:35:54 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Harel", "Yuval", ""], ["Meir", "Ron", ""], ["Opper", "Manfred", ""]]}, {"id": "1507.07879", "submitter": "Victor Hernandez-Urbina", "authors": "Victor Hernandez-Urbina, J. Michael Herrmann", "title": "Small-world structure induced by spike-timing-dependent plasticity in\n  networks with critical dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The small-world property in the context of complex networks implies\nstructural benefits to the processes taking place within a network, such as\noptimal information transmission and robustness. In this paper, we study a\nmodel network of integrate-and-fire neurons that are subject to\nactivity-dependent synaptic plasticity. We find the learning rule that gives\nrise to a small-world structure when the collective dynamics of the system\nreaches a critical state which is characterised by power-law distributions of\nactivity clusters. Moreover, by analysing the motif profile of the networks, we\nobserve that bidirectional connectivity is impaired by the effects of this type\nof plasticity.\n", "versions": [{"version": "v1", "created": "Tue, 28 Jul 2015 18:05:55 GMT"}], "update_date": "2015-08-03", "authors_parsed": [["Hernandez-Urbina", "Victor", ""], ["Herrmann", "J. Michael", ""]]}, {"id": "1507.08008", "submitter": "Longfei Wang", "authors": "Long-Fei Wang, Fei Jia, Xiao-Zhi Liu, Ya-lei Song and Lian-Chun Yu", "title": "Temperature Effects on Information Capacity and Energy Efficiency of\n  Hodgkin-Huxley Neuron", "comments": "5 pages, 3 figures, submitted to Chinese Physics Letters", "journal-ref": "Chin. Phys. Lett. 32, 108701 (2015)", "doi": "10.1088/0256-307X/32/10/108701", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent experimental and theoretical studies show that energy efficiency,\nwhich measures the amount of information processed by a neuron with per unit of\nenergy consumption, plays an important role in the evolution of neural systems.\nHere, we calculated the information rates and energy efficiencies of the\nHodgkin-Huxley (HH) neuron model at different temperatures in a noisy\nenvironment. We found that both the information rate and energy efficiency are\nmaximized by certain temperatures. Though the information rate and energy\nefficiency cannot be maximized simultaneously, the neuron holds a high\ninformation processing capacity at the temperature corresponding to maximal\nenergy efficiency. Our results support the idea that the energy efficiency is a\nselective pressure that influences the evolution of nervous systems.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 02:43:00 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Wang", "Long-Fei", ""], ["Jia", "Fei", ""], ["Liu", "Xiao-Zhi", ""], ["Song", "Ya-lei", ""], ["Yu", "Lian-Chun", ""]]}, {"id": "1507.08183", "submitter": "Matteo di Volo", "authors": "M. di Volo, R. Burioni, M. Casartelli, R. Livi and A. Vezzani", "title": "Neural networks with excitatory and inhibitory components: direct and\n  inverse problems by a mean-field approach", "comments": null, "journal-ref": "Phys. Rev. E 93, 012305 (2016)", "doi": "10.1103/PhysRevE.93.012305", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the dynamics of networks with inhibitory and excitatory\nleaky-integrate-and-fire neurons with short-term synaptic plasticity in the\npresence of depressive and facilitating mechanisms. The dynamics is analyzed by\na Heterogeneous Mean-Field approximation, that allows to keep track of the\neffects of structural disorder in the network. We describe the complex behavior\nof different classes of excitatory and inhibitory components, that give rise to\na rich dynamical phase-diagram as a function of the fraction of inhibitory\nneurons. By the same mean field approach, we study and solve a global inverse\nproblem: reconstructing the degree probability distributions of the inhibitory\nand excitatory components and the fraction of inhibitory neurons from the\nknowledge of the average synaptic activity field. This approach unveils new\nperspectives in the numerical study of neural network dynamics and in the\npossibility of using these models as testbed for the analysis of experimental\ndata.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 15:26:48 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["di Volo", "M.", ""], ["Burioni", "R.", ""], ["Casartelli", "M.", ""], ["Livi", "R.", ""], ["Vezzani", "A.", ""]]}, {"id": "1507.08269", "submitter": "Lianchun Yu", "authors": "Lianchun Yu, Longfei Wang, Fei Jia, Duojie Jia", "title": "Stimulus-Dependent Frequency Modulation of Information Transmission in\n  Neural Systems", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural oscillations are universal phenomena and can be observed at different\nlevels of neural systems, from single neuron to macroscopic brain. The\nfrequency of those oscillations are related to the brain functions. However,\nlittle is know about how the oscillating frequency of neural system affects\nneural information transmission in them. In this paper, we investigated how the\nsignal processing in single neuron is modulated by subthreshold membrane\npotential oscillation generated by upstream rhythmic neural activities. We\nfound that the high frequency oscillations facilitate the transferring of\nstrong signals, whereas slow oscillations the weak signals. Though the capacity\nof information convey for weak signal is low in single neuron, it is greatly\nenhanced when weak signals are transferred by multiple pathways with different\noscillation phases. We provided a simple phase plane analysis to explain the\nmechanism for this stimulus-dependent frequency modulation in the leakage\nintegrate-and-fire neuron model. Those results provided a basic understanding\nof how the brain could modulate its information processing simply through\noscillating frequency.\n", "versions": [{"version": "v1", "created": "Fri, 13 Feb 2015 07:02:48 GMT"}], "update_date": "2015-07-30", "authors_parsed": [["Yu", "Lianchun", ""], ["Wang", "Longfei", ""], ["Jia", "Fei", ""], ["Jia", "Duojie", ""]]}, {"id": "1507.08276", "submitter": "Lianchun Yu", "authors": "Lianchun Yu, Chi Zhang, Liwei Liu, Yuguo Yu", "title": "Energy-efficient population coding constrains network size of a neuronal\n  array system", "comments": "21 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we consider the open issue of how the energy efficiency of neural\ninformation transmission process in a general neuronal array constrains the\nnetwork size, and how well this network size ensures the neural information\nbeing transmitted reliably in a noisy environment. By direct mathematical\nanalysis, we have obtained general solutions proving that there exists an\noptimal neuronal number in the network with which the average coding energy\ncost (defined as energy consumption divided by mutual information) per neuron\npasses through a global minimum for both subthreshold and superthreshold\nsignals. Varying with increases in background noise intensity, the optimal\nneuronal number decreases for subthreshold and increases for suprathreshold\nsignals. The existence of an optimal neuronal number in an array network\nreveals a general rule for population coding stating that the neuronal number\nshould be large enough to ensure reliable information transmission robust to\nthe noisy environment but small enough to minimize energy cost.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 03:01:20 GMT"}], "update_date": "2015-07-31", "authors_parsed": [["Yu", "Lianchun", ""], ["Zhang", "Chi", ""], ["Liu", "Liwei", ""], ["Yu", "Yuguo", ""]]}, {"id": "1507.08282", "submitter": "Simon DeDeo", "authors": "Torrin M. Liddell and Simon DeDeo", "title": "Common Knowledge on Networks", "comments": "25 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.SI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common knowledge of intentions is crucial to basic social tasks ranging from\ncooperative hunting to oligopoly collusion, riots, revolutions, and the\nevolution of social norms and human culture. Yet little is known about how\ncommon knowledge leaves a trace on the dynamics of a social network. Here we\nshow how an individual's network properties---primarily local clustering and\nbetweenness centrality---provide strong signals of the ability to successfully\nparticipate in common knowledge tasks. These signals are distinct from those\nexpected when practices are contagious, or when people use less-sophisticated\nheuristics that do not yield true coordination. This makes it possible to infer\ndecision rules from observation. We also find that tasks that require common\nknowledge can yield significant inequalities in success, in contrast to the\nrelative equality that results when practices spread by contagion alone.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jul 2015 20:06:55 GMT"}], "update_date": "2015-07-31", "authors_parsed": [["Liddell", "Torrin M.", ""], ["DeDeo", "Simon", ""]]}, {"id": "1507.08376", "submitter": "Li Chen", "authors": "Li Chen, Joshua T. Vogelstein, Vince Lyzinski, Carey E. Priebe", "title": "A Joint Graph Inference Case Study: the C.elegans Chemical and\n  Electrical Connectomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate joint graph inference for the chemical and electrical\nconnectomes of the \\textit{Caenorhabditis elegans} roundworm. The\n\\textit{C.elegans} connectomes consist of $253$ non-isolated neurons with known\nfunctional attributes, and there are two types of synaptic connectomes,\nresulting in a pair of graphs. We formulate our joint graph inference from the\nperspectives of seeded graph matching and joint vertex classification. Our\nresults suggest that connectomic inference should proceed in the joint space of\nthe two connectomes, which has significant neuroscientific implications.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2015 04:57:43 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2015 16:10:31 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["Chen", "Li", ""], ["Vogelstein", "Joshua T.", ""], ["Lyzinski", "Vince", ""], ["Priebe", "Carey E.", ""]]}, {"id": "1507.08505", "submitter": "Hans Colonius", "authors": "Hans Colonius and Adele Diederich", "title": "Measures of multisensory integration based on dependent probability\n  summation: from spike counts to reaction times", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A single neuron is categorized as\"multisensory\" if there is a statistically\nsignificant difference between the response evoked by an audio-visual stimulus\ncombination and that evoked by the most effective of its components\nindividually. Crossmodal enhancement is commonly expressed as a proportion of\nthe strongest unisensory response. However, being responsive to multiple\nsensory modalities does not guarantee that a neuron has actually engaged in\nintegrating its multiple sensory inputs, rather than simply responding to the\nmost salient stimulus. Here, we propose an alternative index measuring by how\nmuch the crossmodal response surpasses the level obtainable by optimally\ncombining the unisensory responses. Optimality is defined by probability\nsummation combining the unisensory responses under maximal negative stochastic\ndependence. The new index is analogous to measuring crossmodal enhancement by\nthe amount of violation of the \"race model inequality\", which is widely used in\nreaction time studies of multisensory integration. Neurons previously labeled\nas \"multisensory\" may lose that property since the new index tends to be\nsmaller than the traditional one. This is exemplified with a data set collected\nfrom single SC neurons. The new easy-to-compute index does not require any\nspecific distributional assumption. It is sensitive to the variability in the\ndata, in contrast to the traditional index which, by definition, only depends\non the means of the uni- and crossmodal response distributions.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jul 2015 13:53:35 GMT"}, {"version": "v2", "created": "Sun, 7 Aug 2016 23:01:45 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Colonius", "Hans", ""], ["Diederich", "Adele", ""]]}, {"id": "1507.08736", "submitter": "Stephen Odaibo", "authors": "Stephen G. Odaibo", "title": "A Sinc Wavelet Describes the Receptive Fields of Neurons in the Motion\n  Cortex", "comments": "This work was presented in part at the 44th Annual Meeting of the\n  Society for Neuroscience in Washington, DC", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.IT math.IT physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual perception results from a systematic transformation of the information\nflowing through the visual system. In the neuronal hierarchy, the response\nproperties of single neurons are determined by neurons located one level below,\nand in turn, determine the responses of neurons located one level above.\nTherefore in modeling receptive fields, it is essential to ensure that the\nresponse properties of neurons in a given level can be generated by combining\nthe response models of neurons in its input levels. However, existing response\nmodels of neurons in the motion cortex do not inherently yield the temporal\nfrequency filtering gradient (TFFG) property that is known to emerge along the\nprimary visual cortex (V1) to middle temporal (MT) motion processing stream.\nTFFG is the change from predominantly lowpass to predominantly bandpass\ntemporal frequency filtering character along the V1 to MT pathway (Foster et al\n1985; DeAngelis et al 1993; Hawken et al 1996). We devised a new model, the\nsinc wavelet model (Odaibo, 2014), which logically and efficiently generates\nthe TFFG. The model replaces the Gabor function's sine wave carrier with a sinc\n(sin(x)/x) function, and has the same or fewer number of parameters as existing\nmodels. Because of its logical consistency with the emergent network property\nof TFFG, we conclude that the sinc wavelet is a better model for the receptive\nfields of motion cortex neurons. This model will provide new physiological\ninsights into how the brain represents visual information.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2015 02:55:54 GMT"}], "update_date": "2015-08-03", "authors_parsed": [["Odaibo", "Stephen G.", ""]]}, {"id": "1507.08747", "submitter": "Kavita Vemuri", "authors": "Kavita Vemuri, Kulvinder Bisla, SaiKrishna Mulpuru, Srinivasa\n  Varadarajan", "title": "Does normal pupil diameter differences in population underlie the color\n  selection of the #dress?", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": "10.1364/JOSAA.33.00A137", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The fundamental question that arises from the color composition of the #dress\nis: 'What are the phenomena that underlie the individual differences in colors\nreported given all other conditions like light and device for display being\nidentical?'. The main color camps are blue/black (b/b) and white/gold (w/g) and\na survey of 384 participants showed near equal distribution. We looked at pupil\nsize differences in the sample population of 53 from the two groups plus a\ngroup who switched (w/g to b/b). Our results show that w/g and switch\npopulation had significantly ( w/g <b/b, p-value = 0.0086) lower pupil size\nthan b/b camp. A standard infinity focus experiment was then conducted on 18\nparticipants from each group to check if there is bimodality in the population\nand we again found statistically significant difference (w/g < b/b , p-value =\n0.0132). Six participants, half from the w/g camp, were administered dilation\ndrops that increased the pupil size by 3-4mm to check if increase in retinal\nilluminance will trigger a change in color in the w/g group, but the\nparticipants did not report a switch. The results suggest a population\ndifference in normal pupil-size in the three groups.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2015 04:17:42 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 08:45:46 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Vemuri", "Kavita", ""], ["Bisla", "Kulvinder", ""], ["Mulpuru", "SaiKrishna", ""], ["Varadarajan", "Srinivasa", ""]]}, {"id": "1507.08817", "submitter": "Ewa Gudowska-Nowak", "authors": "E. Gudowska-Nowak, J.K. Ochab, K. Oles, E. Beldzik, D.R. Chialvo, A.\n  Domagalik, M. Fafrowicz, T. Marek, M.A. Nowak, H. Oginska, J. Szwed,\n  J.Tyburczyk", "title": "Seeking for a fingerprint: analysis of point processes in actigraphy\n  recording", "comments": "Communicated at UPON2015, 14-17 July 2015, Barcelona. 21 pages, 11\n  figures; updated: figures 4-7, text revised, expanded Sec. 1,3,5", "journal-ref": null, "doi": "10.1088/1742-5468/2016/05/054034", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motor activity of humans displays complex temporal fluctuations which can be\ncharacterized by scale-invariant statistics, thus documenting that structure\nand fluctuations of such kinetics remain similar over a broad range of time\nscales. Former studies on humans regularly deprived of sleep or suffering from\nsleep disorders predicted change in the invariant scale parameters with respect\nto those representative for healthy subjects. In this study we investigate the\nsignal patterns from actigraphy recordings by means of characteristic measures\nof fractional point processes. We analyse spontaneous locomotor activity of\nhealthy individuals recorded during a week of regular sleep and a week of\nchronic partial sleep deprivation. Behavioural symptoms of lack of sleep can be\nevaluated by analysing statistics of duration times during active and resting\nstates, and alteration of behavioural organization can be assessed by analysis\nof power laws detected in the event count distribution, distribution of waiting\ntimes between consecutive movements and detrended fluctuation analysis of\nrecorded time series. We claim that among different measures characterizing\ncomplexity of the actigraphy recordings and their variations implied by chronic\nsleep distress, the exponents characterizing slopes of survival functions in\nresting states are the most effective biomarkers distinguishing between healthy\nand sleep-deprived groups.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2015 10:14:32 GMT"}, {"version": "v2", "created": "Sun, 1 Nov 2015 18:35:41 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2016 12:48:11 GMT"}], "update_date": "2016-06-22", "authors_parsed": [["Gudowska-Nowak", "E.", ""], ["Ochab", "J. K.", ""], ["Oles", "K.", ""], ["Beldzik", "E.", ""], ["Chialvo", "D. R.", ""], ["Domagalik", "A.", ""], ["Fafrowicz", "M.", ""], ["Marek", "T.", ""], ["Nowak", "M. A.", ""], ["Oginska", "H.", ""], ["Szwed", "J.", ""], ["Tyburczyk", "J.", ""]]}, {"id": "1507.08973", "submitter": "Thomas Miconi", "authors": "Thomas Miconi", "title": "Training recurrent neural networks with sparse, delayed rewards for\n  flexible decision tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks in the chaotic regime exhibit complex dynamics\nreminiscent of high-level cortical activity during behavioral tasks. However,\nexisting training methods for such networks are either biologically\nimplausible, or require a real-time continuous error signal to guide the\nlearning process. This is in contrast with most behavioral tasks, which only\nprovide time-sparse, delayed rewards. Here we show that a biologically\nplausible reward-modulated Hebbian learning algorithm, previously used in\nfeedforward models of birdsong learning, can train recurrent networks based\nsolely on delayed, phasic reward signals at the end of each trial. The method\nrequires no dedicated feedback or readout networks: the whole network\nconnectivity is subject to learning, and the network output is read from one\narbitrarily chosen network cell. We use this method to successfully train a\nnetwork on a delayed nonmatch to sample task (which requires memory, flexible\nassociations, and non-linear mixed selectivities). Using decoding techniques,\nwe show that the resulting networks exhibit dynamic coding of task-relevant\ninformation, with neural encodings of various task features fluctuating widely\nover the course of a trial. Furthermore, network activity moves from a\nstimulus-specific representation to a response-specific representation during\nresponse time, in accordance with neural recordings in behaving animals for\nsimilar tasks. We conclude that recurrent neural networks, trained with\nreward-modulated Hebbian learning, offer a plausible model of cortical dynamics\nduring learning and performance of flexible association.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2015 18:43:28 GMT"}, {"version": "v2", "created": "Tue, 8 Dec 2015 00:48:54 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Miconi", "Thomas", ""]]}]