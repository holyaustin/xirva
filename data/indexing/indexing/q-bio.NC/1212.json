[{"id": "1212.0031", "submitter": "Carina Curto", "authors": "Carina Curto and Anda Degeratu and Vladimir Itskov", "title": "Encoding binary neural codes in networks of threshold-linear neurons", "comments": "35 pages, 5 figures. Minor revisions only. Accepted to Neural\n  Computation", "journal-ref": "Neural Computation, Vol 25, pp. 2858-2903, 2013", "doi": null, "report-no": null, "categories": "q-bio.NC math.CO math.MG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networks of neurons in the brain encode preferred patterns of neural activity\nvia their synaptic connections. Despite receiving considerable attention, the\nprecise relationship between network connectivity and encoded patterns is still\npoorly understood. Here we consider this problem for networks of\nthreshold-linear neurons whose computational function is to learn and store a\nset of binary patterns (e.g., a neural code) as \"permitted sets\" of the\nnetwork. We introduce a simple Encoding Rule that selectively turns \"on\"\nsynapses between neurons that co-appear in one or more patterns. The rule uses\nsynapses that are binary, in the sense of having only two states (\"on\" or\n\"off\"), but also heterogeneous, with weights drawn from an underlying synaptic\nstrength matrix S. Our main results precisely describe the stored patterns that\nresult from the Encoding Rule -- including unintended \"spurious\" states -- and\ngive an explicit characterization of the dependence on S. In particular, we\nfind that binary patterns are successfully stored in these networks when the\nexcitatory connections between neurons are geometrically balanced -- i.e., they\nsatisfy a set of geometric constraints. Furthermore, we find that certain types\nof neural codes are \"natural\" in the context of these networks, meaning that\nthe full code can be accurately learned from a highly undersampled set of\npatterns. Interestingly, many commonly observed neural codes in cortical and\nhippocampal areas are natural in this sense. As an application, we construct\nnetworks that encode hippocampal place field codes nearly exactly, following\npresentation of only a small fraction of patterns. To obtain our results, we\nprove new theorems using classical ideas from convex and distance geometry,\nsuch as Cayley-Menger determinants, revealing a novel connection between these\nareas of mathematics and coding properties of neural networks.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2012 22:43:11 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2013 22:45:57 GMT"}, {"version": "v3", "created": "Thu, 16 May 2013 20:44:24 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Curto", "Carina", ""], ["Degeratu", "Anda", ""], ["Itskov", "Vladimir", ""]]}, {"id": "1212.0076", "submitter": "Zachary Kilpatrick PhD", "authors": "Zachary P Kilpatrick", "title": "Short term synaptic depression improves information transfer in\n  perceptual multistability", "comments": "26 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.DS nlin.PS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competitive neural networks are often used to model the dynamics of\nperceptual bistability. Switching between percepts can occur through\nfluctuations and/or a slow adaptive process. Here, we analyze switching\nstatistics in competitive networks with short term synaptic depression and\nnoise. We start by analyzing a ring model that yields spatially structured\nsolutions and complement this with a study of a space-free network whose\npopulations are coupled with mutual inhibition. Dominance times arising from\ndepression driven switching can be approximated using a separation of\ntimescales in the ring and space-free model. For purely noise-driven switching,\nwe use energy arguments to justify how dominance times are exponentially\nrelated to input strength. We also show that a combination of depression and\nnoise generates realistic distributions of dominance times. Unimodal functions\nof dominance times are more easily differentiated from one another using\nBayesian sampling, suggesting synaptic depression induced switching transfers\nmore information about stimuli than noise-driven switching. Finally, we analyze\na competitive network model of perceptual tristability, showing depression\ngenerates a memory of previous percepts based on the ordering of percepts.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 07:10:50 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2012 03:15:35 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Kilpatrick", "Zachary P", ""]]}, {"id": "1212.0083", "submitter": "Laurent Bougrain", "authors": "Laurent Bougrain (INRIA Nancy - Grand Est / LORIA), Olivier Rochel\n  (INRIA), Octave Boussaton (INRIA Nancy - Grand Est / LORIA), Lionel Havet\n  (INRIA Nancy - Grand Est / LORIA)", "title": "From the decoding of cortical activities to the control of a JACO\n  robotic arm: a whole processing chain", "comments": null, "journal-ref": "CAR - Control Architecture of Robots - 2012 (2012)", "doi": null, "report-no": null, "categories": "cs.NE cs.HC cs.RO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a complete processing chain for decoding intracranial\ndata recorded in the cortex of a monkey and replicates the associated movements\non a JACO robotic arm by Kinova. We developed specific modules inside the\nOpenViBE platform in order to build a Brain-Machine Interface able to read the\ndata, compute the position of the robotic finger and send this position to the\nrobotic arm. More pre- cisely, two client/server protocols have been tested to\ntransfer the finger positions: VRPN and a light protocol based on TCP/IP\nsockets. According to the requested finger position, the server calls the\nassoci- ated functions of an API by Kinova to move the fin- gers properly.\nFinally, we monitor the gap between the requested and actual fingers positions.\nThis chain can be generalized to any movement of the arm or wrist.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 08:27:24 GMT"}], "update_date": "2012-12-05", "authors_parsed": [["Bougrain", "Laurent", "", "INRIA Nancy - Grand Est / LORIA"], ["Rochel", "Olivier", "", "INRIA"], ["Boussaton", "Octave", "", "INRIA Nancy - Grand Est / LORIA"], ["Havet", "Lionel", "", "INRIA Nancy - Grand Est / LORIA"]]}, {"id": "1212.0469", "submitter": "Po T. Wang", "authors": "Po T. Wang, Christine E. King, An H. Do, Zoran Nenadic", "title": "Pushing the Communication Speed Limit of a Noninvasive BCI Speller", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Electroencephalogram (EEG) based brain-computer interfaces (BCI) may provide\na means of communication for those affected by severe paralysis. However, the\nrelatively low information transfer rates (ITR) of these systems, currently\nlimited to 1 bit/sec, present a serious obstacle to their widespread adoption\nin both clinical and non-clinical applications. Here, we report on the\ndevelopment of a novel noninvasive BCI communication system that achieves ITRs\nthat are severalfold higher than those previously reported with similar\nsystems. Using only 8 EEG channels, 6 healthy subjects with little to no prior\nBCI experience selected characters from a virtual keyboard with sustained,\nerror-free, online ITRs in excess of 3 bit/sec. By factoring in the time spent\nto notify the subjects of their selection, practical, error-free typing rates\nas high as 12.75 character/min were achieved, which allowed subjects to\ncorrectly type a 44-character sentence in less than 3.5 minutes. We hypothesize\nthat ITRs can be further improved by optimizing the parameters of the\ninterface, while practical typing rates can be significantly improved by\nshortening the selection notification time. These results provide compelling\nevidence that the ITR limit of noninvasive BCIs has not yet been reached and\nthat further investigation into this matter is both justified and necessary.\n", "versions": [{"version": "v1", "created": "Mon, 3 Dec 2012 17:59:52 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2013 17:02:21 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Wang", "Po T.", ""], ["King", "Christine E.", ""], ["Do", "An H.", ""], ["Nenadic", "Zoran", ""]]}, {"id": "1212.0592", "submitter": "Jose Acacio de Barros", "authors": "C. G. Carvalhaes and J. Acacio de Barros and M. Perreau-Guimar\\~aes\n  and P. Suppes", "title": "The joint use of the tangential electric field and surface Laplacian in\n  EEG classification", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": "10.1007/s10548-013-0305-y", "report-no": null, "categories": "q-bio.NC physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the use of the scalp electric field to decode\nEEG-recorded brain processes. Instead of using bipolar measurements, the scalp\nelectric field is described as a 3-vector field whose orthogonal components are\nobtained from the data through spline differentiation. The method was tested in\nthe context of brainwave recognition with experiments involving brain\nrepresentation of spoken phonemes, visual images, and mental images. The\npractical effect of improvements in recognition rates was assessed by\nestimating effect sizes and confidence intervals, the results suggesting a good\nprospect for other applications.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 00:36:51 GMT"}, {"version": "v2", "created": "Tue, 9 Jul 2013 22:10:55 GMT"}], "update_date": "2013-07-11", "authors_parsed": [["Carvalhaes", "C. G.", ""], ["de Barros", "J. Acacio", ""], ["Perreau-Guimar\u00e3es", "M.", ""], ["Suppes", "P.", ""]]}, {"id": "1212.0621", "submitter": "Jasmine A. Nirody", "authors": "Jasmine A. Nirody", "title": "Development of spatial coarse-to-fine processing in the visual pathway", "comments": "20 pages, 7 figures; substantial restructuring from previous version", "journal-ref": null, "doi": "10.1186/1471-2202-14-S1-P294", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sequential analysis of information in a coarse-to-fine manner is a\nfundamental mode of processing in the visual pathway. Spatial frequency (SF)\ntuning, arguably the most fundamental feature of spatial vision, provides\nparticular intuition within the coarse-to-fine framework: low spatial\nfrequencies convey global information about an image (e.g., general\norientation), while high spatial frequencies carry more detailed information\n(e.g., edges). In this paper, we study the development of cortical spatial\nfrequency tuning. As feedforward input from the lateral geniculate nucleus\n(LGN) has been shown to have significant influence on cortical coarse-to-fine\nprocessing, we present a firing-rate based thalamocortical model which includes\nboth feedforward and feedback components. We analyze the relationship between\nvarious model parameters (including cortical feedback strength) and responses.\nWe confirm the importance of the antagonistic relationship between the center\nand surround responses in thalamic relay cell receptive fields (RFs), and\nfurther characterize how specific structural LGN RF parameters affect cortical\ncoarse-to-fine processing. Our results also indicate that the effect of\ncortical feedback on spatial frequency tuning is age-dependent: in particular,\ncortical feedback more strongly affects coarse-to-fine processing in kittens\nthan in adults. We use our results to propose an experimentally testable\nhypothesis for the function of the extensive feedback in the corticothalamic\ncircuit.\n", "versions": [{"version": "v1", "created": "Tue, 4 Dec 2012 06:17:36 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2013 01:19:05 GMT"}, {"version": "v3", "created": "Tue, 16 Jul 2013 23:31:16 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Nirody", "Jasmine A.", ""]]}, {"id": "1212.0758", "submitter": "Andrei Khrennikov", "authors": "Irina Basieva and Andrei Khrennikov", "title": "Observables Generalizing Positive Operator Valued Measures", "comments": "arXiv admin note: text overlap with arXiv:0711.1366", "journal-ref": null, "doi": "10.1063/1.4773120", "report-no": null, "categories": "quant-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss a generalization of POVM which is used in quantum-like modeling of\nmental processing.\n", "versions": [{"version": "v1", "created": "Sat, 1 Dec 2012 11:25:43 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Basieva", "Irina", ""], ["Khrennikov", "Andrei", ""]]}, {"id": "1212.1096", "submitter": "Henry Tuckwell", "authors": "Henry C. Tuckwell and Nicholas J. Penington", "title": "Computational modeling of spike generation in serotonergic neurons of\n  the dorsal raphe nucleu", "comments": "The abstract has been truncated", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider here a single-compartment model of these neurons which is capable\nof describing many of the known features of spike generation, particularly the\nslow rhythmic pacemaking activity often observed in these cells in a variety of\nspecies. Included in the model are ten kinds of voltage dependent ion channels\nas well as calcium-dependent potassium current. Calcium dynamics includes\nbuffering and pumping. In sections 3-9, each component is considered in detail\nand parameters estimated from voltage clamp data where possible. In the next\ntwo sections simplified versions of some components are employed to explore the\neffects of various parameters on spiking, using a systematic approach, ending\nup with the following eleven components: a fast sodium current $I_{Na}$, a\ndelayed rectifier potassium current $I_{KDR}$, a transient potassium current\n$I_A$, a low-threshold calcium current $I_T$, two high threshold calcium\ncurrents $I_L$ and $I_N$, small and large conductance potassium currents\n$I_{SK}$ and $I_{BK}$, a hyperpolarization-activated cation current $I_H$, a\nleak current $I_{Leak}$ and intracellular calcium ion concentration $Ca_i$.\nAttention is focused on the properties usually associated with these neurons,\nparticularly long duration of action potential, pacemaker-like spiking and the\nramp-like return to threshold after a spike. In some cases the membrane\npotential trajectories display doublets or have kinks or notches as have been\nreported in some experimental studies. The computed time courses of $I_A$ and\n$I_T$ during the interspike interval support the generally held view of a\ncompetition between them in influencing the frequency of spiking. Spontaneous\nspiking could be obtained with small changes in a few parameters from their\nvalues with driven spiking.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 17:00:52 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Tuckwell", "Henry C.", ""], ["Penington", "Nicholas J.", ""]]}, {"id": "1212.1135", "submitter": "Henry Tuckwell", "authors": "Henry C. Tuckwell", "title": "Biophysical properties and computational modeling of calcium spikes in\n  serotonergic neurons of the dorsal raphe nucleus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serotonergic neurons of the dorsal raphe nuclei, with their extensive\ninnervation of nearly the whole brain have important modulatory effects on many\ncognitive and physiological processes. They play important roles in clinical\ndepression and other psychiatric disorders. In order to quantify the effects of\nserotonergic transmission on target cells it is desirable to construct\ncomputational models and to this end these it is necessary to have details of\nthe biophysical and spike properties of the serotonergic neurons. Here several\nbasic properties are reviewed with data from several studies since the 1960s to\nthe present. The quantities included are input resistance, resting membrane\npotential, membrane time constant, firing rate, spike duration, spike and\nafterhyperpolarization (AHP) amplitude, spike threshold, cell capacitance, soma\nand somadendritic areas. The action potentials of these cells are normally\ntriggered by a combination of sodium and calcium currents which may result in\nautonomous pacemaker activity. We here analyse the mechanisms of high-threshold\ncalcium spikes which have been demonstrated in these cells the presence of TTX.\nThe parameters for calcium dynamics required to give calcium spikes are quite\ndifferent from those for regular spiking which suggests the involvement of\nrestricted parts of the soma-dendritic surface as has been found, for example,\nin hippocampal neurons.\n", "versions": [{"version": "v1", "created": "Wed, 5 Dec 2012 19:33:29 GMT"}], "update_date": "2012-12-06", "authors_parsed": [["Tuckwell", "Henry C.", ""]]}, {"id": "1212.3078", "submitter": "Yoichiro Hashizume", "authors": "Yoichiro Hashizume and Osamu Araki", "title": "Analytical Condition for Synchrony in a Neural Network with Two Periodic\n  Inputs", "comments": "7 pages,4 figures,(accepted by Physical Review E)", "journal-ref": "Phys. Rev. E 87, 012713 (2013)", "doi": "10.1103/PhysRevE.87.012713", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we apply a mean field theory to the neural network model with\ntwo periodic inputs in order to clarify the conditions of synchronies. This\nmean field theory yields a self-consistent condition for the synchrony and\nenables us to study the effects of synaptic connections for the behavior of\nneural networks. Then, we have obtained a condition of synaptic connections for\nthe synchrony with the cycle time $T$. The neurons in neural networks receive\nsensory inputs and top-down inputs from outside of the network. When the\nnetwork neurons receive two or more inputs, their synchronization depends on\nthe conditions of inputs. We have also analyzed this case using the mean field\ntheory. As a result, we clarified the following points: (1) The stronger\nsynaptic connections enhance the shorter synchrony cycle of neurons. (2) The\ncycle of the synchrony becomes longer as the cycle of external inputs becomes\nlonger. (3) The relationships among synaptic weights, the properties of input\ntrains, and the cycle of synchrony are expressed by one equation, and there are\ntwo areas for asynchrony. In association with the third point, the yielded\nequation is so simple for calculation that they can easily provide us feasible\nand infeasible conditions for synchrony.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 07:58:24 GMT"}], "update_date": "2013-04-16", "authors_parsed": [["Hashizume", "Yoichiro", ""], ["Araki", "Osamu", ""]]}, {"id": "1212.3106", "submitter": "Matthias Rybarsch", "authors": "Matthias Rybarsch, Stefan Bornholdt", "title": "Self-organized criticality in neural network models", "comments": "In \"Criticality in Neural Systems\", Niebur E, Plenz D, Schuster HG\n  (eds.) 2013 (in press)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.dis-nn nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has long been argued that neural networks have to establish and maintain a\ncertain intermediate level of activity in order to keep away from the regimes\nof chaos and silence. Strong evidence for criticality has been observed in\nterms of spatio-temporal activity avalanches first in cultures of rat cortex by\nBeggs and Plenz (2003) and subsequently in many more experimental setups. These\nfindings sparked intense research on theoretical models for criticality and\navalanche dynamics in neural networks, where usually some dynamical order\nparameter is fed back onto the network topology by adapting the synaptic\ncouplings. We here give an overview of existing theoretical models of dynamical\nnetworks. While most models emphasize biological and neurophysiological detail,\nour path here is different: we pick up the thread of an early self-organized\ncritical neural network model by Bornholdt and Roehl (2001) and test its\napplicability in the light of experimental data. Keeping the simplicity of\nearly models, and at the same time lifting the drawback of a spin formulation\nwith respect to the biological system, we here study an improved model\n(Rybarsch and Bornholdt, 2012b) and show that it adapts to criticality\nexhibiting avalanche statistics that compare well with experimental data\nwithout the need for parameter tuning.\n", "versions": [{"version": "v1", "created": "Thu, 13 Dec 2012 10:07:11 GMT"}], "update_date": "2012-12-14", "authors_parsed": [["Rybarsch", "Matthias", ""], ["Bornholdt", "Stefan", ""]]}, {"id": "1212.3470", "submitter": "R. A. J. van Elburg", "authors": "Ronald A. J. van Elburg, Oltman O. de Wiljes, Michael Biehl, Fred A.\n  Keijzer", "title": "A Behavioural Perspective on the Early Evolution of Nervous Systems: A\n  Computational Model of Excitable Myoepithelia", "comments": "32 pages, 8 figures and 8 model tables", "journal-ref": null, "doi": "10.3389/fncom.2015.00110", "report-no": null, "categories": "q-bio.NC nlin.PS q-bio.PE q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How the very first nervous systems evolved remains a fundamental open\nquestion. Molecular and genomic techniques have revolutionized our knowledge of\nthe molecular ingredients behind this transition but not yet provided a clear\npicture of the morphological and tissue changes involved. Here we focus on a\nbehavioural perspective that centres on movement by muscle contraction.\nBuilding on the finding that molecules for chemical neural signalling predate\nmulticellular animals, we investigate a gradual evolutionary scenario for\nnervous systems that consists of two stages: A) Chemically transmission of\nelectrical activity between adjacent cells provided a primitive form of muscle\ncoordination in a contractile epithelial tissue. B) This primitive form of\ncoordination was subsequently improved upon by evolving the axodendritic\nprocesses of modern neurons. We use computer simulations to investigate the\nfirst stage. The simulations show that chemical transmission across a\ncontractile sheet can indeed produce useful body scale patterns, but only for\nsmall-sized animals. For larger animals the noise in chemical neural signalling\ninterferes. Our results imply that a two-stage scenario is a viable approach to\nnervous system evolution. The first stage could provide an initial behavioural\nadvantage, as well as a clear scaffold for subsequent improvements in\nbehavioural coordination.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 13:40:43 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["van Elburg", "Ronald A. J.", ""], ["de Wiljes", "Oltman O.", ""], ["Biehl", "Michael", ""], ["Keijzer", "Fred A.", ""]]}, {"id": "1212.3549", "submitter": "Joel Zylberberg", "authors": "Joel Zylberberg and Eric Shea-Brown", "title": "Input nonlinearities can shape beyond-pairwise correlations and improve\n  information transmission by neural populations", "comments": "Matches the version to appear in Physical Review E. Main paper is 10\n  pages long with 4 figures. The .pdf includes a 14-page appendix with an\n  additional figure", "journal-ref": "Phys. Rev. E 92, 062707 (2015)", "doi": "10.1103/PhysRevE.92.062707", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While recent recordings from neural populations show beyond-pairwise, or\nhigher-order correlations (HOC), we have little understanding of how HOC arise\nfrom network interactions and of how they impact encoded information. Here, we\nshow that input nonlinearities imply HOC in spin-glass-type statistical models.\nWe then discuss one such model with parameterized pairwise- and higher-order\ninteractions, revealing conditions under which beyond-pairwise interactions\nincrease the mutual information between a given stimulus type and the\npopulation responses. For jointly Gaussian stimuli, coding performance is\nimproved by shaping output HOC only when neural firing rates are constrained to\nbe low. For stimuli with skewed probability distributions (like natural image\nluminances), performance improves for all firing rates. Our work suggests\nsurprising connections between nonlinear integration of neural inputs, stimulus\nstatistics, and normative theories of population coding. Moreover, it suggests\nthat the inclusion of beyond-pairwise interactions could improve the\nperformance of Boltzmann machines for machine learning and signal processing\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 18:06:38 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2013 17:03:27 GMT"}, {"version": "v3", "created": "Tue, 8 Sep 2015 23:20:48 GMT"}, {"version": "v4", "created": "Fri, 20 Nov 2015 17:46:46 GMT"}], "update_date": "2015-12-15", "authors_parsed": [["Zylberberg", "Joel", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1212.3577", "submitter": "Bruno. Cessac", "authors": "Rodrigo Cofr\\'e and Bruno Cessac", "title": "Dynamics and spike trains statistics in conductance-based\n  Integrate-and-Fire neural networks with chemical and electric synapses", "comments": "42 pages, 1 figure, submitted", "journal-ref": null, "doi": "10.1016/j.chaos.2012.12.006", "report-no": "Chaos, Solitons & Fractals, Volume 50, May 2013, Pages 13-31", "categories": "physics.bio-ph math-ph math.MP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the effect of electric synapses (gap junctions) on collective\nneuronal dynamics and spike statistics in a conductance-based\nIntegrate-and-Fire neural network, driven by a Brownian noise, where\nconductances depend upon spike history. We compute explicitly the time\nevolution operator and show that, given the spike-history of the network and\nthe membrane potentials at a given time, the further dynamical evolution can be\nwritten in a closed form. We show that spike train statistics is described by a\nGibbs distribution whose potential can be approximated with an explicit\nformula, when the noise is weak. This potential form encompasses existing\nmodels for spike trains statistics analysis such as maximum entropy models or\nGeneralized Linear Models (GLM). We also discuss the different types of\ncorrelations: those induced by a shared stimulus and those induced by neurons\ninteractions.\n", "versions": [{"version": "v1", "created": "Fri, 14 Dec 2012 20:09:34 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Cofr\u00e9", "Rodrigo", ""], ["Cessac", "Bruno", ""]]}, {"id": "1212.3647", "submitter": "Justin Kinney", "authors": "Justin B. Kinney, Gurinder S. Atwal", "title": "Parametric inference in the large data limit using maximally informative\n  models", "comments": "To appear in Neural Computation", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM math.ST q-bio.MN q-bio.NC stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by data-rich experiments in transcriptional regulation and sensory\nneuroscience, we consider the following general problem in statistical\ninference. When exposed to a high-dimensional signal S, a system of interest\ncomputes a representation R of that signal which is then observed through a\nnoisy measurement M. From a large number of signals and measurements, we wish\nto infer the \"filter\" that maps S to R. However, the standard method for\nsolving such problems, likelihood-based inference, requires perfect a priori\nknowledge of the \"noise function\" mapping R to M. In practice such noise\nfunctions are usually known only approximately, if at all, and using an\nincorrect noise function will typically bias the inferred filter. Here we show\nthat, in the large data limit, this need for a pre-characterized noise function\ncan be circumvented by searching for filters that instead maximize the mutual\ninformation I[M;R] between observed measurements and predicted representations.\nMoreover, if the correct filter lies within the space of filters being\nexplored, maximizing mutual information becomes equivalent to simultaneously\nmaximizing every dependence measure that satisfies the Data Processing\nInequality. It is important to note that maximizing mutual information will\ntypically leave a small number of directions in parameter space unconstrained.\nWe term these directions \"diffeomorphic modes\" and present an equation that\nallows these modes to be derived systematically. The presence of diffeomorphic\nmodes reflects a fundamental and nontrivial substructure within parameter\nspace, one that is obscured by standard likelihood-based inference.\n", "versions": [{"version": "v1", "created": "Sat, 15 Dec 2012 01:29:33 GMT"}, {"version": "v2", "created": "Tue, 20 Aug 2013 04:03:31 GMT"}, {"version": "v3", "created": "Fri, 25 Oct 2013 17:54:28 GMT"}, {"version": "v4", "created": "Fri, 13 Dec 2013 14:53:44 GMT"}], "update_date": "2013-12-16", "authors_parsed": [["Kinney", "Justin B.", ""], ["Atwal", "Gurinder S.", ""]]}, {"id": "1212.3765", "submitter": "Mohammad Bavandpour", "authors": "Hamid Soleimani, Arash Ahmadi and Mohammad Bavandpour", "title": "Biologically Inspired Spiking Neurons : Piecewise Linear Models and\n  Digital Implementation", "comments": "14 pages, 16 figures", "journal-ref": "IEEE Transactions On Circuits And Systems I: Regular Papers, Vol.\n  59, NO. 12, December 2012", "doi": "10.1109/TCSI.2012.2206463", "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  There has been a strong push recently to examine biological scale simulations\nof neuromorphic algorithms to achieve stronger inference capabilities. This\npaper presents a set of piecewise linear spiking neuron models, which can\nreproduce different behaviors, similar to the biological neuron, both for a\nsingle neuron as well as a network of neurons. The proposed models are\ninvestigated, in terms of digital implementation feasibility and costs,\ntargeting large scale hardware implementation. Hardware synthesis and physical\nimplementations on FPGA show that the proposed models can produce precise\nneural behaviors with higher performance and considerably lower implementation\ncosts compared with the original model. Accordingly, a compact structure of the\nmodels which can be trained with supervised and unsupervised learning\nalgorithms has been developed. Using this structure and based on a spike rate\ncoding, a character recognition case study has been implemented and tested.\n", "versions": [{"version": "v1", "created": "Sun, 16 Dec 2012 09:05:02 GMT"}], "update_date": "2012-12-18", "authors_parsed": [["Soleimani", "Hamid", ""], ["Ahmadi", "Arash", ""], ["Bavandpour", "Mohammad", ""]]}, {"id": "1212.3908", "submitter": "Alireza Valizadeh", "authors": "Sadjad Sadeghi and Alireza Valizadeh", "title": "Synchronization of delayed coupled neurons in presence of inhomogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In principle, while coupled limit cycle oscillators can overcome mismatch in\nintrinsic rates and match their frequencies, but zero phase lag synchronization\nis just achievable in the limit of zero mismatch, i.e., with identical\noscillators. Delay in communication, on the other hand, can exert phase shift\nin the activity of the coupled oscillators. In this study, we address the\nquestion of how phase locked, and in particular zero phase lag synchronization,\ncan be achieved for a heterogeneous system of two delayed coupled neurons. We\nhave analytically studied the possibility of inphase synchronization and near\ninphase synchronization when the neurons are not identical or the connections\nare not exactly symmetric. We have shown that while any single source of\ninhomogeneity can violate isochronous synchrony, multiple sources of\ninhomogeneity can compensate for each other and maintain synchrony. Numeric\nstudies on biologically plausible models also support the analytic results.\n", "versions": [{"version": "v1", "created": "Mon, 17 Dec 2012 07:18:56 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2012 16:47:22 GMT"}, {"version": "v3", "created": "Sun, 10 Feb 2013 11:32:50 GMT"}], "update_date": "2013-02-12", "authors_parsed": [["Sadeghi", "Sadjad", ""], ["Valizadeh", "Alireza", ""]]}, {"id": "1212.4201", "submitter": "Carina Curto", "authors": "Carina Curto, Vladimir Itskov, Alan Veliz-Cuba and Nora Youngs", "title": "The neural ring: an algebraic tool for analyzing the intrinsic structure\n  of neural codes", "comments": "Minor revisions. 35 pages, 7 figures, and 1 table. Accepted to\n  Bulletin of Mathematical Biology", "journal-ref": "Bulletin of Mathematical Biology, Volume 75, Issue 9, pp.\n  1571-1611, 2013", "doi": null, "report-no": null, "categories": "q-bio.NC math.AC math.AG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neurons in the brain represent external stimuli via neural codes. These codes\noften arise from stereotyped stimulus-response maps, associating to each neuron\na convex receptive field. An important problem confronted by the brain is to\ninfer properties of a represented stimulus space without knowledge of the\nreceptive fields, using only the intrinsic structure of the neural code. How\ndoes the brain do this? To address this question, it is important to determine\nwhat stimulus space features can - in principle - be extracted from neural\ncodes. This motivates us to define the neural ring and a related neural ideal,\nalgebraic objects that encode the full combinatorial data of a neural code. Our\nmain finding is that these objects can be expressed in a \"canonical form\" that\ndirectly translates to a minimal description of the receptive field structure\nintrinsic to the code. We also find connections to Stanley-Reisner rings, and\nuse ideas similar to those in the theory of monomial ideals to obtain an\nalgorithm for computing the primary decomposition of pseudo-monomial ideals.\nThis allows us to algorithmically extract the canonical form associated to any\nneural code, providing the groundwork for inferring stimulus space features\nfrom neural activity alone.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 00:23:54 GMT"}, {"version": "v2", "created": "Tue, 21 May 2013 23:27:31 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Curto", "Carina", ""], ["Itskov", "Vladimir", ""], ["Veliz-Cuba", "Alan", ""], ["Youngs", "Nora", ""]]}, {"id": "1212.4239", "submitter": "Yu Hu", "authors": "Yu Hu, James Trousdale, Kre\\v{s}imir Josi\\'c and Eric Shea-Brown", "title": "Local paths to global coherence: cutting networks down to size", "comments": "34 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math-ph math.DS math.MP math.ST q-bio.QM stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How does connectivity impact network dynamics? We address this question by\nlinking network characteristics on two scales. On the global scale we consider\nthe coherence of overall network dynamics. We show that such \\emph{global\ncoherence} in activity can often be predicted from the \\emph{local structure}\nof the network. To characterize local network structure we use \"motif\ncumulants,\" a measure of the deviation of pathway counts from those expected in\na minimal probabilistic network model.\n  We extend previous results in three ways. First, we give a new combinatorial\nformulation of motif cumulants that relates to the allied concept in\nprobability theory. Second, we show that the link between global network\ndynamics and local network architecture is strongly affected by heterogeneity\nin network connectivity. However, we introduce a network-partitioning method\nthat recovers a tight relationship between architecture and dynamics. Third,\nfor a particular set of models we generalize the underlying theory to treat\ndynamical coherence at arbitrary orders (i.e. triplet correlations, and\nbeyond). We show that at any order only a highly restricted set of motifs\nimpact dynamical correlations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Dec 2012 06:36:34 GMT"}, {"version": "v2", "created": "Sat, 24 Aug 2013 06:00:09 GMT"}, {"version": "v3", "created": "Wed, 11 Dec 2013 23:05:11 GMT"}], "update_date": "2013-12-13", "authors_parsed": [["Hu", "Yu", ""], ["Trousdale", "James", ""], ["Josi\u0107", "Kre\u0161imir", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1212.5054", "submitter": "Claudius Gros", "authors": "Mathias Linkerhand, Claudius Gros", "title": "Generating functionals for autonomous latching dynamics in attractor\n  relict networks", "comments": "replaced two figures which were not showing up properly", "journal-ref": "Scientific Reports, Vol 3, 2042 (2013)", "doi": null, "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Well characterized sequences of dynamical states play an important role for\nmotor control and associative neural computation in the brain. Autonomous\ndynamics involving sequences of transiently stable states have been termed\nassociative latching in the context of grammar generation. We propose that\ngenerating functionals allow for a systematic construction of dynamical\nnetworks with well characterized dynamical behavior, such as regular or\nintermittent bursting latching dynamics.\n  Coupling local, slowly adapting variables to an attractor network allows to\ndestabilize all attractors, turning them into attractor ruins. The resulting\nattractor relict network may show ongoing autonomous latching dynamics. We\npropose to use two generating functionals for the construction of attractor\nrelict networks. The first functional is a simple Hopfield energy functional,\nknown to generate a neural attractor network. The second generating functional,\nwhich we denote polyhomeostatic optimization, is based on\ninformation-theoretical principles, encoding the information content of the\nneural firing statistics. Polyhomeostatic optimization destabilizes the\nattractors of the Hopfield network inducing latching dynamics.\n  We investigate the influence of stress, in terms of conflicting optimization\ntargets, on the resulting dynamics. Objective function stress is absent when\nthe target level for the mean of neural activities is identical for the two\ngenerating functionals and the resulting latching dynamics is then found to be\nregular. Objective function stress is present when the respective target\nactivity levels differ, inducing intermittent bursting latching dynamics. We\npropose that generating functionals may be useful quite generally for the\ncontrolled construction of complex dynamical systems.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 14:30:48 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2013 14:50:55 GMT"}], "update_date": "2013-07-15", "authors_parsed": [["Linkerhand", "Mathias", ""], ["Gros", "Claudius", ""]]}, {"id": "1212.5188", "submitter": "Carina Curto", "authors": "Carina Curto, Vladimir Itskov, Katherine Morrison, Zachary Roth, and\n  Judy L. Walker", "title": "Combinatorial neural codes from a mathematical coding theory perspective", "comments": "26 pages, 8 figures", "journal-ref": "Neural Computation, Vol 25(7), pp. 1891-1925, 2013", "doi": null, "report-no": null, "categories": "q-bio.NC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shannon's seminal 1948 work gave rise to two distinct areas of research:\ninformation theory and mathematical coding theory. While information theory has\nhad a strong influence on theoretical neuroscience, ideas from mathematical\ncoding theory have received considerably less attention. Here we take a new\nlook at combinatorial neural codes from a mathematical coding theory\nperspective, examining the error correction capabilities of familiar receptive\nfield codes (RF codes). We find, perhaps surprisingly, that the high levels of\nredundancy present in these codes does not support accurate error correction,\nalthough the error-correcting performance of RF codes \"catches up\" to that of\nrandom comparison codes when a small tolerance to error is introduced. On the\nother hand, RF codes are good at reflecting distances between represented\nstimuli, while the random comparison codes are not. We suggest that a\ncompromise in error-correcting capability may be a necessary price to pay for a\nneural code whose structure serves not only error correction, but must also\nreflect relationships between stimuli.\n", "versions": [{"version": "v1", "created": "Thu, 20 Dec 2012 18:57:30 GMT"}], "update_date": "2015-02-25", "authors_parsed": [["Curto", "Carina", ""], ["Itskov", "Vladimir", ""], ["Morrison", "Katherine", ""], ["Roth", "Zachary", ""], ["Walker", "Judy L.", ""]]}, {"id": "1212.5550", "submitter": "Jose Soares Andrade Jr.", "authors": "H. F. Credidio, E. N. Teixeira, S. D. S. Reis, A. A. Moreira, J. S.\n  Andrade Jr", "title": "Statistical patterns of visual search for hidden objects", "comments": "9 pages, 5 figures", "journal-ref": "Sci. Rep. 2, 920 (2012)", "doi": "10.1038/srep00920", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The movement of the eyes has been the subject of intensive research as a way\nto elucidate inner mechanisms of cognitive processes. A cognitive task that is\nrather frequent in our daily life is the visual search for hidden objects. Here\nwe investigate through eye-tracking experiments the statistical properties\nassociated with the search of target images embedded in a landscape of\ndistractors. Specifically, our results show that the twofold process of eye\nmovement, composed of sequences of fixations (small steps) intercalated by\nsaccades (longer jumps), displays characteristic statistical signatures. While\nthe saccadic jumps follow a log normal distribution of distances, which is\ntypical of multiplicative processes, the lengths of the smaller steps in the\nfixation trajectories are consistent with a power-law distribution. Moreover,\nthe present analysis reveals a clear transition between a directional serial\nsearch to an isotropic random movement as the difficulty level of the searching\ntask is increased.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 18:44:28 GMT"}], "update_date": "2012-12-24", "authors_parsed": [["Credidio", "H. F.", ""], ["Teixeira", "E. N.", ""], ["Reis", "S. D. S.", ""], ["Moreira", "A. A.", ""], ["Andrade", "J. S.", "Jr"]]}, {"id": "1212.5619", "submitter": "Martin Nawrot", "authors": "Anneke Meyer, Giovanni Galizia, Martin P. Nawrot", "title": "Odor response features of projection neurons and local interneurons in\n  the honeybee antennal lobe", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Local computation in microcircuits is an essential feature of distributed\ninformation processing in vertebrate and invertebrate brains. The insect\nantennal lobe represents a spatially confined local network that processes\nhigh-dimensional and redundant peripheral input to compute an efficient odor\ncode. Social insects can rely on a particularly rich olfactory receptor\nrepertoire and they exhibit complex odor-guided behaviors. This corresponds\nwith a high anatomical complexity of their AL network. In the honeybee, a large\nnumber of glomeruli that receive sensory input are interconnected by a dense\nnetwork of local interneurons (LNs). Uniglomerular projection neurons (PNs)\nintegrate sensory and recurrent network input into an efficient spatio-temporal\nodor code. To investigate the specific computational roles of LNs and PNs we\nmeasured eleven features of sub- and suprathreshold single cell responses to in\nvivo odor stimulation. Using a semi-supervised cluster analysis we identified a\ncombination of five characteristic features that enabled the accurate\nseparation of morphologically identified LNs and PNs. The two clusters differed\nsignificantly in all five features. In the absence of stimulation PNs showed a\nhigher subthreshold activation, assumed higher peak response rates and more\nregular spiking pattern. LNs reacted considerably faster to the onset of a\nstimulus and their responses were more reliable across stimulus repetitions. We\ndiscuss possible mechanisms that can explain our results, and we interpret\ncell-type specific characteristics with respect to their functional relevance.\n", "versions": [{"version": "v1", "created": "Fri, 21 Dec 2012 22:09:04 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Meyer", "Anneke", ""], ["Galizia", "Giovanni", ""], ["Nawrot", "Martin P.", ""]]}, {"id": "1212.6146", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Sparse Hopfield network reconstruction with $\\ell_{1}$ regularization", "comments": "9 pages, 3 figures, Eur. Phys. J. B (in press)", "journal-ref": "Eur. Phys. J. B (2013) 86: 484", "doi": "10.1140/epjb/e2013-40502-8", "report-no": null, "categories": "cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an efficient strategy to infer sparse Hopfield network based on\nmagnetizations and pairwise correlations measured through Glauber samplings.\nThis strategy incorporates the $\\ell_{1}$ regularization into the Bethe\napproximation by a quadratic approximation to the log-likelihood, and is able\nto further reduce the inference error of the Bethe approximation without the\nregularization. The optimal regularization parameter is observed to be of the\norder of $M^{-\\nu}$ where $M$ is the number of independent samples. The value\nof the scaling exponent depends on the performance measure. $\\nu\\simeq0.5001$\nfor root mean squared error measure while $\\nu\\simeq0.2743$ for\nmisclassification rate measure. The efficiency of this strategy is demonstrated\nfor the sparse Hopfield model, but the method is generally applicable to other\ndiluted mean field models. In particular, it is simple in implementation\nwithout heavy computational cost.\n", "versions": [{"version": "v1", "created": "Wed, 26 Dec 2012 09:14:39 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2012 03:53:43 GMT"}, {"version": "v3", "created": "Thu, 2 May 2013 03:59:33 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2013 08:00:02 GMT"}], "update_date": "2013-11-28", "authors_parsed": [["Huang", "Haiping", ""]]}]