[{"id": "1612.00644", "submitter": "Peter Zeidman", "authors": "Peter Zeidman, Edward Harry Silson, Dietrich Samuel Schwarzkopf, Chris\n  Ian Baker, Will Penny", "title": "Bayesian Population Receptive Field Modelling", "comments": "30 pages, 10 figures. Code available at\n  https://github.com/pzeidman/BayespRF", "journal-ref": null, "doi": "10.1016/j.neuroimage.2017.09.008", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a probabilistic (Bayesian) framework and associated software\ntoolbox for mapping population receptive fields (pRFs) based on fMRI data. This\ngeneric approach is intended to work with stimuli of any dimension and is\ndemonstrated and validated in the context of 2D retinotopic mapping. The\nframework enables the experimenter to specify generative (encoding) models of\nfMRI timeseries, in which experimental manipulations enter a pRF model of\nneural activity, which in turns drives a nonlinear model of neurovascular\ncoupling and Blood Oxygenation Level Dependent (BOLD) response. The neuronal\nand haemodynamic parameters are estimated together on a voxel-by-voxel or\nregion-of-interest basis using a Bayesian estimation algorithm (variational\nLaplace). This offers several novel contributions to receptive field modelling.\nThe variance / covariance of parameters are estimated, enabling receptive\nfields to be plotted while properly representing uncertainty about pRF size and\nlocation. Variability in the haemodynamic response across the brain is\naccounted for. Furthermore, the framework introduces formal hypothesis testing\nto pRF analysis, enabling competing models to be evaluated based on their model\nevidence (approximated by the variational free energy), which represents the\noptimal tradeoff between accuracy and complexity. Using simulations and\nempirical data, we found that parameters typically used to represent pRF size\nand neuronal scaling are strongly correlated, which should be taken into\naccount when making inferences. We used the framework to compare the evidence\nfor six variants of pRF model using 7T functional MRI data and we found a\ncircular Difference of Gaussians (DoG) model to be the best explanation for our\ndata overall. We hope this framework will prove useful for mapping stimulus\nspaces with any number of dimensions onto the anatomy of the brain.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 11:48:17 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Zeidman", "Peter", ""], ["Silson", "Edward Harry", ""], ["Schwarzkopf", "Dietrich Samuel", ""], ["Baker", "Chris Ian", ""], ["Penny", "Will", ""]]}, {"id": "1612.00667", "submitter": "Santi Puch", "authors": "Santi Puch, Asier Aduriz, Adri\\`a Casamitjana, Veronica Vilaplana,\n  Paula Petrone, Gr\\'egory Operto, Raffaele Cacciaglia, Stavros Skouras, Carles\n  Falcon, Jos\\'e Luis Molinuevo, Juan Domingo Gispert", "title": "Voxelwise nonlinear regression toolbox for neuroimage analysis:\n  Application to aging and neurodegenerative disease modeling", "comments": "4 pages + 1 page for acknowledgements and references. NIPS 2016\n  Workshop on Machine Learning for Health (NIPS ML4HC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a new neuroimaging analysis toolbox that allows for the\nmodeling of nonlinear effects at the voxel level, overcoming limitations of\nmethods based on linear models like the GLM. We illustrate its features using a\nrelevant example in which distinct nonlinear trajectories of Alzheimer's\ndisease related brain atrophy patterns were found across the full biological\nspectrum of the disease. The open-source toolbox presented in this paper is\navailable at https://github.com/imatge-upc/VNeAT.\n", "versions": [{"version": "v1", "created": "Fri, 2 Dec 2016 12:59:11 GMT"}, {"version": "v2", "created": "Sun, 5 Mar 2017 10:58:16 GMT"}, {"version": "v3", "created": "Tue, 18 Apr 2017 20:12:16 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Puch", "Santi", ""], ["Aduriz", "Asier", ""], ["Casamitjana", "Adri\u00e0", ""], ["Vilaplana", "Veronica", ""], ["Petrone", "Paula", ""], ["Operto", "Gr\u00e9gory", ""], ["Cacciaglia", "Raffaele", ""], ["Skouras", "Stavros", ""], ["Falcon", "Carles", ""], ["Molinuevo", "Jos\u00e9 Luis", ""], ["Gispert", "Juan Domingo", ""]]}, {"id": "1612.00703", "submitter": "Marzieh Haghighi", "authors": "Marzieh Haghighi and Mohammad Moghadamfalahi and Murat Akcakaya and\n  Deniz Erdogmus", "title": "EEG-assisted Modulation of Sound Sources in the Auditory Scene", "comments": null, "journal-ref": "Biomedical Signal Processing and Control 39 (2018): 263-270", "doi": "10.1016/j.bspc.2017.08.008", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Noninvasive EEG (electroencephalography) based auditory attention detection\ncould be useful for improved hearing aids in the future. This work is a novel\nattempt to investigate the feasibility of online modulation of sound sources by\nprobabilistic detection of auditory attention, using a noninvasive EEG-based\nbrain computer interface. Proposed online system modulates the upcoming sound\nsources through gain adaptation which employs probabilistic decisions (soft\ndecisions) from a classifier trained on offline calibration data. In this work,\ncalibration EEG data were collected in sessions where the participants listened\nto two sound sources (one attended and one unattended). Cross-correlation\ncoefficients between the EEG measurements and the attended and unattended sound\nsource envelope (estimates) are used to show differences in sharpness and\ndelays of neural responses for attended versus unattended sound source. Salient\nfeatures to distinguish attended sources from the unattended ones in the\ncorrelation patterns have been identified, and later they have been used to\ntrain an auditory attention classifier. Compared to the existing results in the\nliterature, in this paper we have two main contributions. First, using the\nauditory attention classifier, we have shown high offline detection performance\nwith single channel EEG measurements of shorter duration compared to the\nexisting approaches in the literature which employ large number of channels\nwith longer EEG measurements. Second, using the classifier trained offline in\nthe calibration session, we have shown the performance of the online sound\nsource modulation system. We observe that online sound source modulation system\nis able to keep the level of attended sound source higher than the unattended\nsource.\n  Keywords: auditory BCI, cocktail party problem, auditory attention\nclassification\n", "versions": [{"version": "v1", "created": "Sat, 26 Nov 2016 03:51:19 GMT"}, {"version": "v2", "created": "Tue, 28 Nov 2017 18:50:37 GMT"}], "update_date": "2017-11-29", "authors_parsed": [["Haghighi", "Marzieh", ""], ["Moghadamfalahi", "Mohammad", ""], ["Akcakaya", "Murat", ""], ["Erdogmus", "Deniz", ""]]}, {"id": "1612.01150", "submitter": "Richard Granger", "authors": "A Rodriguez, R Granger", "title": "The grammar of mammalian brain capacity", "comments": "18 pages, 2 figures, 2 tables", "journal-ref": "Theoretical Computer Science 633 (2016) 100-111", "doi": "10.1016/j.tcs.2016.03.021", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Uniquely human abilities may arise from special-purpose brain circuitry, or\nfrom concerted general capacity increases due to our outsized brains. We\nforward a novel hypothesis of the relation between computational capacity and\nbrain size, linking mathematical formalisms of grammars with the allometric\nincreases in cortical-subcortical ratios that arise in large brains. In sum, i)\nthalamocortical loops compute formal grammars; ii) successive cortical regions\ndescribe grammar rewrite rules of increasing size; iii) cortical-subcortical\nratios determine the quantity of stacks in single-stack pushdown grammars; iii)\nquantitative increase of stacks yields grammars with qualitatively increased\ncomputational power. We arrive at the specific conjecture that human brain\ncapacity is equivalent to that of indexed grammars, far short of full\nTuring-computable (recursively enumerable) systems. The work provides a\ncandidate explanatory account of a range of existing human and animal data,\naddressing longstanding questions of how repeated similar brain algorithms can\nbe successfully applied to apparently dissimilar computational tasks (e.g.,\nperceptual versus cognitive, phonological versus syntactic); and how\nquantitative increases to brains can confer qualitative changes to their\ncomputational repertoire.\n", "versions": [{"version": "v1", "created": "Sun, 4 Dec 2016 17:40:44 GMT"}], "update_date": "2016-12-06", "authors_parsed": [["Rodriguez", "A", ""], ["Granger", "R", ""]]}, {"id": "1612.01229", "submitter": "Jeffrey Herron", "authors": "Jeffrey A. Herron, Margaret C. Thompson, Timothy Brown, Howard J.\n  Chizeck, Jeffrey G. Ojemann, and Andrew L. Ko", "title": "Cortical Brain Computer Interface for Closed-Loop Deep Brain Stimulation", "comments": null, "journal-ref": null, "doi": "10.1109/TNSRE.2017.2705661", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Essential Tremor is the most common neurological movement disorder. This\nprogressive disease causes uncontrollable rhythmic motions -most often\naffecting the patient's dominant upper extremity- that occur during volitional\nmovement and make it difficult for the patient to perform everyday tasks.\nMedication may also become ineffective as the disorder progresses. For many\npatients, deep brain stimulation (DBS) of the thalamus is an effective means of\ntreating this condition when medication fails. In current use, however,\nclinicians set the patient's stimulator to apply stimulation at all times-\nwhether it is needed or not. This practice leads to excess power use, and more\nrapid depletion of batteries that require surgical replacement. In the work\ndescribed here, for the first time, neural sensing of movement (using\nchronically-implanted cortical electrodes) is used to enable or disable\nstimulation for tremor. Therapeutic stimulation is delivered only when the\npatient is actively using their effected limb, thereby reducing the total\nstimulation applied, and potentially extending the lifetime of\nsurgically-implanted batteries. This work, which involves both implanted and\nexternal subsystems, paves the way for the future fully-implanted closed-loop\ndeep brain stimulators.\n", "versions": [{"version": "v1", "created": "Mon, 5 Dec 2016 02:35:29 GMT"}, {"version": "v2", "created": "Thu, 1 Jun 2017 12:18:52 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Herron", "Jeffrey A.", ""], ["Thompson", "Margaret C.", ""], ["Brown", "Timothy", ""], ["Chizeck", "Howard J.", ""], ["Ojemann", "Jeffrey G.", ""], ["Ko", "Andrew L.", ""]]}, {"id": "1612.01717", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Statistical mechanics of unsupervised feature learning in a restricted\n  Boltzmann machine with binary synapses", "comments": "24 pages, 9 figures, results added", "journal-ref": "J. Stat. Mech. (2017) 053302", "doi": "10.1088/1742-5468/aa6ddc", "report-no": null, "categories": "cs.LG cond-mat.dis-nn cond-mat.stat-mech cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Revealing hidden features in unlabeled data is called unsupervised feature\nlearning, which plays an important role in pretraining a deep neural network.\nHere we provide a statistical mechanics analysis of the unsupervised learning\nin a restricted Boltzmann machine with binary synapses. A message passing\nequation to infer the hidden feature is derived, and furthermore, variants of\nthis equation are analyzed. A statistical analysis by replica theory describes\nthe thermodynamic properties of the model. Our analysis confirms an entropy\ncrisis preceding the non-convergence of the message passing equation,\nsuggesting a discontinuous phase transition as a key characteristic of the\nrestricted Boltzmann machine. Continuous phase transition is also confirmed\ndepending on the embedded feature strength in the data. The mean-field result\nunder the replica symmetric assumption agrees with that obtained by running\nmessage passing algorithms on single instances of finite sizes. Interestingly,\nin an approximate Hopfield model, the entropy crisis is absent, and a\ncontinuous phase transition is observed instead. We also develop an iterative\nequation to infer the hyper-parameter (temperature) hidden in the data, which\nin physics corresponds to iteratively imposing Nishimori condition. Our study\nprovides insights towards understanding the thermodynamic properties of the\nrestricted Boltzmann machine learning, and moreover important theoretical basis\nto build simplified deep networks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Dec 2016 09:17:14 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 04:47:07 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1612.02120", "submitter": "Yaron Meirovitch", "authors": "Yaron Meirovitch, Alexander Matveev, Hayk Saribekyan, David Budden,\n  David Rolnick, Gergely Odor, Seymour Knowles-Barley, Thouis Raymond Jones,\n  Hanspeter Pfister, Jeff William Lichtman, Nir Shavit", "title": "A Multi-Pass Approach to Large-Scale Connectomics", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of connectomics faces unprecedented \"big data\" challenges. To\nreconstruct neuronal connectivity, automated pixel-level segmentation is\nrequired for petabytes of streaming electron microscopy data. Existing\nalgorithms provide relatively good accuracy but are unacceptably slow, and\nwould require years to extract connectivity graphs from even a single cubic\nmillimeter of neural tissue. Here we present a viable real-time solution, a\nmulti-pass pipeline optimized for shared-memory multicore systems, capable of\nprocessing data at near the terabyte-per-hour pace of multi-beam electron\nmicroscopes. The pipeline makes an initial fast-pass over the data, and then\nmakes a second slow-pass to iteratively correct errors in the output of the\nfast-pass. We demonstrate the accuracy of a sparse slow-pass reconstruction\nalgorithm and suggest new methods for detecting morphological errors. Our\nfast-pass approach provided many algorithmic challenges, including the design\nand implementation of novel shallow convolutional neural nets and the\nparallelization of watershed and object-merging techniques. We use it to\nreconstruct, from image stack to skeletons, the full dataset of Kasthuri et al.\n(463 GB capturing 120,000 cubic microns) in a matter of hours on a single\nmulticore machine rather than the weeks it has taken in the past on much larger\ndistributed systems.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 05:46:24 GMT"}], "update_date": "2016-12-12", "authors_parsed": [["Meirovitch", "Yaron", ""], ["Matveev", "Alexander", ""], ["Saribekyan", "Hayk", ""], ["Budden", "David", ""], ["Rolnick", "David", ""], ["Odor", "Gergely", ""], ["Knowles-Barley", "Seymour", ""], ["Jones", "Thouis Raymond", ""], ["Pfister", "Hanspeter", ""], ["Lichtman", "Jeff William", ""], ["Shavit", "Nir", ""]]}, {"id": "1612.02189", "submitter": "Evrim Acar", "authors": "Evrim Acar, Yuri Levin-Schwartz, Vince D. Calhoun and T\\\"ulay Adal{\\i}", "title": "Tensor-Based Fusion of EEG and FMRI to Understand Neurological Changes\n  in Schizophrenia", "comments": null, "journal-ref": null, "doi": "10.1109/ISCAS.2017.8050303", "report-no": null, "categories": "stat.AP q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging modalities such as functional magnetic resonance imaging (fMRI)\nand electroencephalography (EEG) provide information about neurological\nfunctions in complementary spatiotemporal resolutions; therefore, fusion of\nthese modalities is expected to provide better understanding of brain activity.\nIn this paper, we jointly analyze fMRI and multi-channel EEG signals collected\nduring an auditory oddball task with the goal of capturing brain activity\npatterns that differ between patients with schizophrenia and healthy controls.\nRather than selecting a single electrode or matricizing the third-order tensor\nthat can be naturally used to represent multi-channel EEG signals, we preserve\nthe multi-way structure of EEG data and use a coupled matrix and tensor\nfactorization (CMTF) model to jointly analyze fMRI and EEG signals. Our\nanalysis reveals that (i) joint analysis of EEG and fMRI using a CMTF model can\ncapture meaningful temporal and spatial signatures of patterns that behave\ndifferently in patients and controls, and (ii) these differences and the\ninterpretability of the associated components increase by including multiple\nelectrodes from frontal, motor and parietal areas, but not necessarily by\nincluding all electrodes in the analysis.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 10:40:16 GMT"}], "update_date": "2020-12-23", "authors_parsed": [["Acar", "Evrim", ""], ["Levin-Schwartz", "Yuri", ""], ["Calhoun", "Vince D.", ""], ["Adal\u0131", "T\u00fclay", ""]]}, {"id": "1612.02243", "submitter": "Ruggero G. Bettinardi", "authors": "Ruggero G. Bettinardi, Gustavo Deco, Vasilis M. Karlaftis, Timothy J.\n  Van Hartevelt, Henrique M. Fernandes, Zoe Kourtzi, Morten L. Kringelbach and\n  Gorka Zamora-L\\'opez", "title": "How structure sculpts function: unveiling the contribution of anatomical\n  connectivity to the brain's spontaneous correlation structure", "comments": null, "journal-ref": "Chaos 27, 047409 (2017)", "doi": "10.1063/1.4980099", "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Intrinsic brain activity is characterized by highly structured co-activations\nbetween different regions, whose origin is still under debate. In this paper,\nwe address the question whether it is possible to unveil how the underlying\nanatomical connectivity shape the brain's spontaneous correlation structure. We\nstart from the assumption that in order for two nodes to exhibit large\ncovariation, they must be exposed to similar input patterns from the entire\nnetwork. We then acknowledge that information rarely spreads only along an\nunique route, but rather travels along all possible paths. In real networks the\nstrength of local perturbations tends to decay as they propagate away from the\nsources, leading to a progressive attenuation of the original information\ncontent and, thus, of their influence. We use these notions to derive a novel\nanalytical measure, $\\mathcal{T}$ , which quantifies the similarity of the\nwhole-network input patterns arriving at any two nodes only due to the\nunderlying topology, in what is a generalization of the matching index. We show\nthat this measure of topological similarity can indeed be used to predict the\ncontribution of network topology to the expected correlation structure, thus\nunveiling the mechanism behind the tight but elusive relationship between\nstructure and function in complex networks. Finally, we use this measure to\ninvestigate brain connectivity, showing that information about the topology\ndefined by the complex fabric of brain axonal pathways specifies to a large\nextent the time-average functional connectivity observed at rest.\n", "versions": [{"version": "v1", "created": "Wed, 7 Dec 2016 13:47:58 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Bettinardi", "Ruggero G.", ""], ["Deco", "Gustavo", ""], ["Karlaftis", "Vasilis M.", ""], ["Van Hartevelt", "Timothy J.", ""], ["Fernandes", "Henrique M.", ""], ["Kourtzi", "Zoe", ""], ["Kringelbach", "Morten L.", ""], ["Zamora-L\u00f3pez", "Gorka", ""]]}, {"id": "1612.02572", "submitter": "Giovanni Montana", "authors": "James H Cole, Rudra PK Poudel, Dimosthenis Tsagkrasoulis, Matthan WA\n  Caan, Claire Steves, Tim D Spector, Giovanni Montana", "title": "Predicting brain age with deep learning from raw imaging data results in\n  a reliable and heritable biomarker", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CV cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning analysis of neuroimaging data can accurately predict\nchronological age in healthy people and deviations from healthy brain ageing\nhave been associated with cognitive impairment and disease. Here we sought to\nfurther establish the credentials of \"brain-predicted age\" as a biomarker of\nindividual differences in the brain ageing process, using a predictive\nmodelling approach based on deep learning, and specifically convolutional\nneural networks (CNN), and applied to both pre-processed and raw T1-weighted\nMRI data. Firstly, we aimed to demonstrate the accuracy of CNN brain-predicted\nage using a large dataset of healthy adults (N = 2001). Next, we sought to\nestablish the heritability of brain-predicted age using a sample of monozygotic\nand dizygotic female twins (N = 62). Thirdly, we examined the test-retest and\nmulti-centre reliability of brain-predicted age using two samples\n(within-scanner N = 20; between-scanner N = 11). CNN brain-predicted ages were\ngenerated and compared to a Gaussian Process Regression (GPR) approach, on all\ndatasets. Input data were grey matter (GM) or white matter (WM) volumetric maps\ngenerated by Statistical Parametric Mapping (SPM) or raw data. Brain-predicted\nage represents an accurate, highly reliable and genetically-valid phenotype,\nthat has potential to be used as a biomarker of brain ageing. Moreover, age\npredictions can be accurately generated on raw T1-MRI data, substantially\nreducing computation time for novel data, bringing the process closer to giving\nreal-time information on brain health in clinical settings.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 09:26:08 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Cole", "James H", ""], ["Poudel", "Rudra PK", ""], ["Tsagkrasoulis", "Dimosthenis", ""], ["Caan", "Matthan WA", ""], ["Steves", "Claire", ""], ["Spector", "Tim D", ""], ["Montana", "Giovanni", ""]]}, {"id": "1612.02807", "submitter": "Thierry Mora", "authors": "Ulisse Ferrari, Tomoyuki Obuchi, Thierry Mora", "title": "Random versus maximum entropy models of neural population activity", "comments": null, "journal-ref": "Phys. Rev. E 95, 042321 (2017)", "doi": "10.1103/PhysRevE.95.042321", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The principle of maximum entropy provides a useful method for inferring\nstatistical mechanics models from observations in correlated systems, and is\nwidely used in a variety of fields where accurate data are available. While the\nassumptions underlying maximum entropy are intuitive and appealing, its\nadequacy for describing complex empirical data has been little studied in\ncomparison to alternative approaches. Here data from the collective spiking\nactivity of retinal neurons is reanalysed. The accuracy of the maximum entropy\ndistribution constrained by mean firing rates and pairwise correlations is\ncompared to a random ensemble of distributions constrained by the same\nobservables. In general, maximum entropy approximates the true distribution\nbetter than the typical or mean distribution from that ensemble. This advantage\nimproves with population size, with groups as small as 8 being almost always\nbetter described by maximum entropy. Failure of maximum entropy to outperform\nrandom models is found to be associated with strong correlations in the\npopulation.\n", "versions": [{"version": "v1", "created": "Thu, 8 Dec 2016 20:44:59 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Ferrari", "Ulisse", ""], ["Obuchi", "Tomoyuki", ""], ["Mora", "Thierry", ""]]}, {"id": "1612.03214", "submitter": "Thomas Mesnard", "authors": "Thomas Mesnard, Wulfram Gerstner, Johanni Brea", "title": "Towards deep learning with spiking neurons in energy based models with\n  contrastive Hebbian plasticity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In machine learning, error back-propagation in multi-layer neural networks\n(deep learning) has been impressively successful in supervised and\nreinforcement learning tasks. As a model for learning in the brain, however,\ndeep learning has long been regarded as implausible, since it relies in its\nbasic form on a non-local plasticity rule. To overcome this problem,\nenergy-based models with local contrastive Hebbian learning were proposed and\ntested on a classification task with networks of rate neurons. We extended this\nwork by implementing and testing such a model with networks of leaky\nintegrate-and-fire neurons. Preliminary results indicate that it is possible to\nlearn a non-linear regression task with hidden layers, spiking neurons and a\nlocal synaptic plasticity rule.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2016 23:17:11 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Mesnard", "Thomas", ""], ["Gerstner", "Wulfram", ""], ["Brea", "Johanni", ""]]}, {"id": "1612.03270", "submitter": "Tsung-Ren Huang", "authors": "Tsung-Ren Huang", "title": "Hebbian Plasticity for Improving Perceptual Decisions", "comments": "7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shibata et al. reported that humans could learn to repeatedly evoke a\nstimulus-associated functional magnetic resonance imaging (fMRI) activity\npattern in visual areas V1/V2 through which visual perceptual learning was\nachieved without stimulus presentation. Contrary to their attribution of visual\nimprovements to neuroplasticity in adult V1/V2, our Hebbian learning\ninterpretation of these data explains the attainment of better perceptual\ndecisions without plastic V1/V2.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 08:32:35 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Huang", "Tsung-Ren", ""]]}, {"id": "1612.03314", "submitter": "Hugues Mounier Mr", "authors": "Hugues Mounier", "title": "Differential flatness for neuroscience population dynamics -- A\n  preliminary study", "comments": "83 pages, 8 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present document is devoted to structural properties of neural population\ndynamics and especially their differential flatness. Several applications of\ndifferential flatness in the present context can be envisioned, among which:\ntrajectory tracking, feedforward to feedback switching, cyclic character,\npositivity and boundedness.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2016 16:22:51 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Mounier", "Hugues", ""]]}, {"id": "1612.03428", "submitter": "Nicolas Honnorat", "authors": "Nicolas Honnorat and Christos Davatzikos", "title": "Riccati-regularized Precision Matrices for Neuroimaging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME math.OC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of graph theory in neuroimaging has pro- vided invaluable\ntools for the study of brain connectivity. These methods require the definition\nof a graph, which is typically derived by estimating the effective connectivity\nbetween brain regions through the optimization of an ill-posed inverse problem.\nConsiderable efforts have been devoted to the development of methods extracting\nsparse connectivity graphs. The present paper aims at highlighting the benefits\nof an alternative ap- proach. We investigate low-rank L2 regularized matrices\nrecently intro- duced under the denomination of Riccati regularized precision\nmatrices. We demonstrate their benefits for the analysis of cortical thickness\nmap and for the extraction of functional biomarkers from resting state fMRI\nscans. In addition, we explain how speed and result quality can be further\nimproved with random projections. The promising results obtained using the\nHuman Connectome Project dataset as well as the numerous possi- ble extensions\nand applications suggest that Riccati precision matrices might usefully\ncomplement current sparse approaches.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2016 16:04:30 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Honnorat", "Nicolas", ""], ["Davatzikos", "Christos", ""]]}, {"id": "1612.03480", "submitter": "Cengiz Pehlevan", "authors": "Yuansi Chen, Cengiz Pehlevan, Dmitri B. Chklovskii", "title": "Self-calibrating Neural Networks for Dimensionality Reduction", "comments": "2016 Asilomar Conference on Signals, Systems and Computers", "journal-ref": null, "doi": "10.1109/ACSSC.2016.7869625", "report-no": null, "categories": "cs.LG cs.NE q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, a novel family of biologically plausible online algorithms for\nreducing the dimensionality of streaming data has been derived from the\nsimilarity matching principle. In these algorithms, the number of output\ndimensions can be determined adaptively by thresholding the singular values of\nthe input data matrix. However, setting such threshold requires knowing the\nmagnitude of the desired singular values in advance. Here we propose online\nalgorithms where the threshold is self-calibrating based on the singular values\ncomputed from the existing observations. To derive these algorithms from the\nsimilarity matching cost function we propose novel regularizers. As before,\nthese online algorithms can be implemented by Hebbian/anti-Hebbian neural\nnetworks in which the learning rule depends on the chosen regularizer. We\ndemonstrate both mathematically and via simulation the effectiveness of these\nonline algorithms in various settings.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2016 21:15:05 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Chen", "Yuansi", ""], ["Pehlevan", "Cengiz", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1612.03483", "submitter": "Cengiz Pehlevan", "authors": "Reza Abbasi-Asl, Cengiz Pehlevan, Bin Yu, and Dmitri B. Chklovskii", "title": "Do retinal ganglion cells project natural scenes to their principal\n  subspace and whiten them?", "comments": "2016 Asilomar Conference on Signals, Systems and Computers", "journal-ref": null, "doi": "10.1109/ACSSC.2016.7869658", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several theories of early sensory processing suggest that it whitens sensory\nstimuli. Here, we test three key predictions of the whitening theory using\nrecordings from 152 ganglion cells in salamander retina responding to natural\nmovies. We confirm the previous finding that firing rates of ganglion cells are\nless correlated compared to natural scenes, although significant correlations\nremain. We show that while the power spectrum of ganglion cells decays less\nsteeply than that of natural scenes, it is not completely flattened. Finally,\nwe find evidence that only the top principal components of the visual stimulus\nare transmitted.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2016 21:28:23 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Abbasi-Asl", "Reza", ""], ["Pehlevan", "Cengiz", ""], ["Yu", "Bin", ""], ["Chklovskii", "Dmitri B.", ""]]}, {"id": "1612.03590", "submitter": "Qiulei Dong", "authors": "Qiulei Dong and Zhanyi Hu", "title": "Statistics of Visual Responses to Object Stimuli from Primate AIT\n  Neurons to DNN Neurons", "comments": null, "journal-ref": "Neural Computation, 30, 447-476 (2018)", "doi": "10.1162/NECO_a_01039", "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cadieu et al. (Cadieu,2014) reported that deep neural networks(DNNs) could\nrival the representation of primate inferotemporal cortex for object\nrecognition. Lehky et al. (Lehky,2011) provided a statistical analysis on\nneural responses to object stimuli in primate AIT cortex. They found the\nintrinsic dimensionality of object representations in AIT cortex is around 100\n(Lehky,2014). Considering the outstanding performance of DNNs in object\nrecognition, it is worthwhile investigating whether the responses of DNN\nneurons have similar response statistics to those of AIT neurons. Following\nLehky et al.'s works, we analyze the response statistics to image stimuli and\nthe intrinsic dimensionality of object representations of DNN neurons. Our\nfindings show in terms of kurtosis and Pareto tail index, the response\nstatistics on single-neuron selectivity and population sparseness of DNN\nneurons are fundamentally different from those of IT neurons except some\nspecial cases. By increasing the number of neurons and stimuli, the conclusions\ncould alter substantially. In addition, with the ascendancy of the\nconvolutional layers of DNNs, the single-neuron selectivity and population\nsparseness of DNN neurons increase, indicating the last convolutional layer is\nto learn features for object representations, while the following\nfully-connected layers are to learn categorization features. It is also found\nthat a sufficiently large number of stimuli and neurons are necessary for\nobtaining a stable dimensionality. To our knowledge, this is the first work to\nanalyze the response statistics of DNN neurons comparing with AIT neurons, and\nour results provide not only some insights into the discrepancy of DNN neurons\nwith respect to IT neurons in object representation, but also shed some light\non possible outcomes of IT neurons when the number of recorded neurons and\nstimuli is beyond the level in (Lehky,2011,2014).\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 10:13:15 GMT"}, {"version": "v2", "created": "Fri, 20 Jan 2017 02:23:42 GMT"}], "update_date": "2019-06-07", "authors_parsed": [["Dong", "Qiulei", ""], ["Hu", "Zhanyi", ""]]}, {"id": "1612.03640", "submitter": "Hubert Cecotti", "authors": "Hubert Cecotti and Bertrand Rivet", "title": "Toward improving the visual stimulus meaning for increasing the P300\n  detection", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The P300 speller is a well known Brain-Computer Interface paradigm that has\nbeen used for over two decades. A new P300 speller paradigm (XP300) is\nproposed. It includes several characteristics: (i) the items are not\nintensified by using rows and columns, (ii) the order of the visual stimuli is\npseudo-random, (iii) a visual feedback is added on each item to increase the\nstimulus meaning, which is the main novelty. XP300 has been tested on ten\nhealthy subjects on copy spelling mode, with only eight sensors. It has been\ncompared with the classical P300 paradigm (CP300). With five repetitions, the\naverage recognition rate across subjects is 85.25% for XP300 and 77.25% for\nCP300. Single-trial detection is significantly higher with XP300 by comparing\nthe AUC (Area Under Curve) of the ROC (Receiver Operating Characteristic)\ncurve. The mean AUC is 0.86 for XP300, 0.80 for CP300. More importantly, XP300\nhas also been judged as more convenient and user-friendly than CP300, hence\nbeing able to allow longer sessions.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 12:17:50 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Cecotti", "Hubert", ""], ["Rivet", "Bertrand", ""]]}, {"id": "1612.03649", "submitter": "Francesco Fumarola", "authors": "Francesco Fumarola", "title": "Hierarchical searching in episodic memory", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An analysis of free-recall datasets from two independent experiments allows\nto identify two anomalous instances of non-monotonicity in free recall: a\nmaximum in the dependence of the inter-response intervals on the\nserial-position lags, and a minimum in the rate of contiguous recall near the\nbeginning of the recall process. Both effects, it is argued, may stem from a\nhierarchical search protocol in the space of memories. An elementary\nrandom-walk model on binary strings is used to test this hypothesis.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 12:42:35 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 17:59:43 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Fumarola", "Francesco", ""]]}, {"id": "1612.03760", "submitter": "Daniele Marinazzo", "authors": "Javier Rasero, Mario Pellicoro, Leonardo Angelini, Jesus M. Cortes,\n  Daniele Marinazzo, and Sebastiano Stramaglia", "title": "Consensus clustering approach to group brain connectivity matrices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach rooted on the notion of consensus clustering, a strategy\ndeveloped for community detection in complex networks, is proposed to cope with\nthe heterogeneity that characterizes connectivity matrices in health and\ndisease. The method can be summarized as follows:\n  (i) define, for each node, a distance matrix for the set of subjects by\ncomparing the connectivity pattern of that node in all pairs of subjects; (ii)\ncluster the distance matrix for each node; (iii) build the consensus network\nfrom the corresponding partitions; (iv) extract groups of subjects by finding\nthe communities of the consensus network thus obtained.\n  Differently from the previous implementations of consensus clustering, we\nthus propose to use the consensus strategy to combine the information arising\nfrom the connectivity patterns of each node. The proposed approach may be seen\neither as an exploratory technique or as an unsupervised pre-training step to\nhelp the subsequent construction of a supervised classifier. Applications on a\ntoy model and two real data sets, show the effectiveness of the proposed\nmethodology, which represents heterogeneity of a set of subjects in terms of a\nweighted network, the consensus matrix.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 16:10:05 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 12:56:16 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Rasero", "Javier", ""], ["Pellicoro", "Mario", ""], ["Angelini", "Leonardo", ""], ["Cortes", "Jesus M.", ""], ["Marinazzo", "Daniele", ""], ["Stramaglia", "Sebastiano", ""]]}, {"id": "1612.04234", "submitter": "Kazuhisa Shibata", "authors": "Kazuhisa Shibata, Yuka Sasaki, Takeo Watanabe, Mitsuo Kawato", "title": "Response to Comment on 'Perceptual Learning Incepted by Decoded fMRI\n  Neurofeedback Without Stimulus Presentation'; How can a decoded neurofeedback\n  method (DecNef) lead to successful reinforcement and visual perceptual\n  learning?", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Huang (arXiv:1612.03270) argues that the perceptual learning induced by our\ndecoded neurofeedback method (DecNef) can be explained by Hebbian synaptic\nplasticity of connections between V1/V2 and V3/V4 rather than that within\nV1/V2, and that reinforcement learning at a cellular level should not be\npossible, and thus challenges our conclusions. In this reply, first, we show\nthat Huang's model is not compatible with our data which strongly suggest\nplasticity within V1/V2. Second, the results of our new analysis show that\nspontaneous activity is not random but largely accounted for by low-dimensional\ncomponents. These and other results indicate that learning to induce a\nstimulus-associated template voxel pattern in V1/V2 within as few as 100 trials\nis likely to be accomplished by hyper-resolution and sub-voxel level control by\nDecNef.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 15:34:21 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Shibata", "Kazuhisa", ""], ["Sasaki", "Yuka", ""], ["Watanabe", "Takeo", ""], ["Kawato", "Mitsuo", ""]]}, {"id": "1612.04295", "submitter": "Esmaeil Seraj", "authors": "Esmaeil Seraj", "title": "Cerebral Synchrony Assessment Tutorial: A General Review on Cerebral\n  Signals' Synchronization Estimation Concepts and Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The human brain is ultimately responsible for all thoughts and movements that\nthe body produces. This allows humans to successfully interact with their\nenvironment. If the brain is not functioning properly many abilities of human\ncan be damaged. The goal of cerebral signal analysis is to learn about brain\nfunction. The idea that distinct areas of the brain are responsible for\nspecific tasks, the functional segregation, is a key aspect of brain function.\nFunctional integration is an important feature of brain function, it is the\nconcordance of multiple segregated brain areas to produce a unified response.\nThere is an amplified feedback mechanism in the brain called reentry which\nrequires specific timing relations. This specific timing requires neurons\nwithin an assembly to synchronize their firing rates. This has led to increased\ninterest and use of phase variables, particularly their synchronization, to\nmeasure connectivity in cerebral signals. Herein, we propose a comprehensive\nreview on concepts and methods previously presented for assessing cerebral\nsynchrony, with focus on phase synchronization, as a tool for brain\nconnectivity evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2016 14:39:42 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 02:13:07 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Seraj", "Esmaeil", ""]]}, {"id": "1612.04345", "submitter": "Daniel Mirman", "authors": "Daniel Mirman, Jon-Frederick Landrigan, Spiro Kokolis, Sean Verillo,\n  Casey Ferrara, Dorian Pustina", "title": "Corrections for multiple comparisons in voxel-based lesion-symptom\n  mapping", "comments": "20 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voxel-based lesion-symptom mapping (VLSM) is an important method for basic\nand translational human neuroscience research. VLSM leverages modern\nneuroimaging analysis techniques to build on the classic approach of examining\nthe relationship between location of brain damage and cognitive deficits.\nTesting an association between deficit severity and lesion status in each voxel\ninvolves very many individual tests and requires statistical correction for\nmultiple comparisons. Several strategies have been adapted from analysis of\nfunctional neuroimaging data, though VLSM faces a more difficult trade-off\nbetween avoiding false positives and statistical power (missing true effects).\nNon-parametric, permutation-based methods are generally preferable because they\ndo not make assumptions that are likely to be violated by skewed distributions\nof behavioral deficit (symptom) scores and by the necessary spatial contiguity\nof stroke lesions. We used simulated and real deficit scores from a sample of\napproximately 100 individuals with left hemisphere stroke to evaluate two such\npermutation-based approaches. Using permutation to set a minimum cluster size\nidentified a region that systematically extended well beyond the true region,\neven under the most conservative settings tested here, making it ill-suited to\nidentifying brain-behavior relationships. In contrast, generalizing the\nstandard permutation-based family-wise error correction approach provided a\nprincipled way to balance false positives and false negatives. An\nimplementation of this continuous permutation-based FWER correction method is\navailable at https://gist.github.com/dmirman/05a92e0e9e0027f6fe6e528c648143d7\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 20:29:00 GMT"}, {"version": "v2", "created": "Wed, 14 Dec 2016 16:52:37 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Mirman", "Daniel", ""], ["Landrigan", "Jon-Frederick", ""], ["Kokolis", "Spiro", ""], ["Verillo", "Sean", ""], ["Ferrara", "Casey", ""], ["Pustina", "Dorian", ""]]}, {"id": "1612.04423", "submitter": "Bethany Lusch", "authors": "Bethany Lusch, Jake Weholt, Pedro D. Maia, J. Nathan Kutz", "title": "Modeling cognitive deficits following neurodegenerative diseases and\n  traumatic brain injuries with deep convolutional neural networks", "comments": "13 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate diagnosis and assessment of neurodegenerative disease and\ntraumatic brain injuries (TBI) remain open challenges. Both cause cognitive and\nfunctional deficits due to focal axonal swellings (FAS), but it is difficult to\ndeliver a prognosis due to our limited ability to assess damaged neurons at a\ncellular level in vivo. We simulate the effects of neurodegenerative disease\nand TBI using convolutional neural networks (CNNs) as our model of cognition.\nWe utilize biophysically relevant statistical data on FAS to damage the\nconnections in CNNs in a functionally relevant way. We incorporate energy\nconstraints on the brain by pruning the CNNs to be less over-engineered.\nQualitatively, we demonstrate that damage leads to human-like mistakes. Our\nexperiments also provide quantitative assessments of how accuracy is affected\nby various types and levels of damage. The deficit resulting from a fixed\namount of damage greatly depends on which connections are randomly injured,\nproviding intuition for why it is difficult to predict impairments. There is a\nlarge degree of subjectivity when it comes to interpreting cognitive deficits\nfrom complex systems such as the human brain. However, we provide important\ninsight and a quantitative framework for disorders in which FAS are implicated.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2016 22:50:56 GMT"}], "update_date": "2016-12-15", "authors_parsed": [["Lusch", "Bethany", ""], ["Weholt", "Jake", ""], ["Maia", "Pedro D.", ""], ["Kutz", "J. Nathan", ""]]}, {"id": "1612.04471", "submitter": "Justin Chapman", "authors": "Justin J. Chapman, James A. Roberts, Vinh T. Nguyen, Michael\n  Breakspear", "title": "Quantification of free-living activity patterns using accelerometry in\n  adults with mental illness", "comments": "24 pages; 4,486 words. PDF document with figures embedded: Five (5)\n  tables are referred to in the text, two of which are supplementary; Seven (7)\n  figures are referred to in the text, one of which is supplementary", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical activity is disrupted in many psychiatric disorders. Advances in\neveryday technologies (e.g. accelerometers in smart phones) opens exciting\npossibilities for non-intrusive acquisition of activity data. Successful\nexploitation of this opportunity requires the validation of analytical methods\nthat can capture the full movement spectrum. The study aim was to demonstrate\nan analytical approach to characterise accelerometer-derived activity patterns.\nHere, we use statistical methods to characterise accelerometer-derived activity\npatterns from a heterogeneous sample of 99 community-based adults with mental\nillnesses. Diagnoses were screened using the Mini international\nNeuropsychiatric Interview, and participants wore accelerometers for one week.\nWe studies the relative ability of simple (exponential), complex\n(heavy-tailed), and composite models to explain patterns of activity and\ninactivity. Activity during wakefulness was a composite of brief random\n(exponential) movements and complex (heavy-tailed) processes, whereas movement\nduring sleep lacked the heavy-tailed component. In contrast, inactivity\nfollowed a heavy-tailed process, lacking the random component. Activity\npatterns differed in nature between those with a diagnosis of bipolar disorder\nand a primary psychotic disorder. These results show the potential of complex\nmodels to quntify the rich nature of human movement captured by accelerometry\nduring wake and sleep, and the interaction with diagnosis and health.\n", "versions": [{"version": "v1", "created": "Wed, 14 Dec 2016 03:29:29 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Chapman", "Justin J.", ""], ["Roberts", "James A.", ""], ["Nguyen", "Vinh T.", ""], ["Breakspear", "Michael", ""]]}, {"id": "1612.05226", "submitter": "Ludmila Brochini", "authors": "Ludmila Brochini, Antonio Galves, Pierre Hodara, Guilherme Ost and\n  Christophe Pouzat", "title": "Estimation of neuronal interaction graph from spike train data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main current issues in Neurobiology concerns the understanding of\ninterrelated spiking activity among multineuronal ensembles and differences\nbetween stimulus-driven and spontaneous activity in neurophysiological\nexperiments. Multi electrode array recordings that are now commonly used\nmonitor neuronal activity in the form of spike trains from many well identified\nneurons. A basic question when analyzing such data is the identification of the\ndirected graph describing \"synaptic coupling\" between neurons. In this article\nwe deal with this matter working with a high quality multielectrode array\nrecording dataset (Pouzat et al., 2015) from the first olfactory relay of the\nlocust, $Schistocerca$ $americana$. From a mathematical point of view this\npaper presents two novelties. First we propose a procedure allowing to deal\nwith the small sample sizes met in actual datasets. Moreover we address the\nsensitive case of partially observed networks. Our starting point is the\nprocedure introduced in Duarte et al. (2016). We evaluate the performance of\nboth original and improved procedures through simulation studies, which are\nalso used for parameter tuning and for exploring the effect of recording only a\nsmall subset of the neurons of a network.\n", "versions": [{"version": "v1", "created": "Thu, 15 Dec 2016 20:30:15 GMT"}, {"version": "v2", "created": "Wed, 11 Oct 2017 22:48:13 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Brochini", "Ludmila", ""], ["Galves", "Antonio", ""], ["Hodara", "Pierre", ""], ["Ost", "Guilherme", ""], ["Pouzat", "Christophe", ""]]}, {"id": "1612.05321", "submitter": "Hannah Choi", "authors": "Hannah Choi, Anitha Pasupathy, Eric Shea-Brown", "title": "Predictive coding in area V4: dynamic shape discrimination under partial\n  occlusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primate visual system has an exquisite ability to discriminate partially\noccluded shapes. Recent electrophysiological recordings suggest that response\ndynamics in intermediate visual cortical area V4, shaped by feedback from\nprefrontal cortex (PFC), may play a key role. To probe the algorithms that may\nunderlie these findings, we build and test a model of V4 and PFC interactions\nbased on a hierarchical predictive coding framework. We propose that\nprobabilistic inference occurs in two steps. Initially, V4 responses are driven\nsolely by bottom-up sensory input and are thus strongly influenced by the level\nof occlusion. After a delay, V4 responses combine both feedforward input and\nfeedback signals from the PFC; the latter reflect predictions made by PFC about\nthe visual stimulus underlying V4 activity. We find that this model captures\nkey features of V4 and PFC dynamics observed in experiments. Specifically, PFC\nresponses are strongest for occluded stimuli and delayed responses in V4 are\nless sensitive to occlusion, supporting our hypothesis that the feedback\nsignals from PFC underlie robust discrimination of occluded shapes. Thus, our\nstudy proposes that area V4 and PFC participate in hierarchical inference, with\nfeedback signals encoding top-down predictions about occluded shapes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 00:31:58 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Choi", "Hannah", ""], ["Pasupathy", "Anitha", ""], ["Shea-Brown", "Eric", ""]]}, {"id": "1612.05660", "submitter": "Luis David Garcia Puente", "authors": "Rebecca Garcia, Luis David Garc\\'ia Puente, Ryan Kruse, Jessica Liu,\n  Dane Miyata, Ethan Petersen, Kaitlyn Phillipson, and Anne Shiu", "title": "Gr\\\"obner Bases of Neural Ideals", "comments": "13 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC math.AC math.AG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The brain processes information about the environment via neural codes. The\nneural ideal was introduced recently as an algebraic object that can be used to\nbetter understand the combinatorial structure of neural codes. Every neural\nideal has a particular generating set, called the canonical form, that directly\nencodes a minimal description of the receptive field structure intrinsic to the\nneural code. On the other hand, for a given monomial order, any polynomial\nideal is also generated by its unique (reduced) Gr\\\"obner basis with respect to\nthat monomial order. How are these two types of generating sets -- canonical\nforms and Gr\\\"obner bases -- related? Our main result states that if the\ncanonical form of a neural ideal is a Gr\\\"obner basis, then it is the universal\nGr\\\"obner basis (that is, the union of all reduced Gr\\\"obner bases).\nFurthermore, we prove that this situation -- when the canonical form is a\nGr\\\"obner basis -- occurs precisely when the universal Gr\\\"obner basis contains\nonly pseudo-monomials (certain generalizations of monomials). Our results\nmotivate two questions: (1)~When is the canonical form a Gr\\\"obner basis?\n(2)~When the universal Gr\\\"obner basis of a neural ideal is {\\em not} a\ncanonical form, what can the non-pseudo-monomial elements in the basis tell us\nabout the receptive fields of the code? We give partial answers to both\nquestions. Along the way, we develop a representation of pseudo-monomials as\nhypercubes in a Boolean lattice.\n", "versions": [{"version": "v1", "created": "Fri, 16 Dec 2016 21:23:02 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 21:23:41 GMT"}, {"version": "v3", "created": "Fri, 20 Apr 2018 20:27:30 GMT"}], "update_date": "2018-04-24", "authors_parsed": [["Garcia", "Rebecca", ""], ["Puente", "Luis David Garc\u00eda", ""], ["Kruse", "Ryan", ""], ["Liu", "Jessica", ""], ["Miyata", "Dane", ""], ["Petersen", "Ethan", ""], ["Phillipson", "Kaitlyn", ""], ["Shiu", "Anne", ""]]}, {"id": "1612.06357", "submitter": "Jonas Haslbeck", "authors": "Jonas M B Haslbeck and Eiko I Fried", "title": "How Predictable are Symptoms in Psychopathological Networks? A\n  Reanalysis of 18 Published Datasets", "comments": "24 pages, 1 table, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background Network analyses on psychopathological data focus on the network\nstructure and its derivatives such as node centrality. One conclusion one can\ndraw from centrality measures is that the node with the highest centrality is\nlikely to be the node that is determined most by its neighboring nodes.\nHowever, centrality is a relative measure: knowing that a node is highly\ncentral gives no information about the extent to which it is determined by its\nneighbors. Here we provide an absolute measure of determination (or\ncontrollability) of a node - its predictability. We introduce predictability,\nestimate the predictability of all nodes in 18 prior empirical network papers\non psychopathology, and statistically relate it to centrality.\n  Methods We carried out a literature review and collected 25 datasets from 18\npublished papers in the field (several mood and anxiety disorders, substance\nabuse, psychosis, autism, and transdiagnostic data). We fit state-of-the-art\nnet- work models to all datasets, and computed the predictability of all nodes.\n  Results Predictability was unrelated to sample size, moderately high in most\nsymptom networks, and differed considerable both within and between datasets.\nPredictability was higher in community than clinical samples, highest for mood\nand anxiety disorders, and lowest for psychosis.\n  Conclusions Predictability is an important additional characterization of\nsymptom networks because it gives an absolute measure of the controllability of\neach node. It allows conclusions about how self-determined a symptom network\nis, and may help to inform intervention strategies. Limitations of\npredictability along with future directions are discussed.\n", "versions": [{"version": "v1", "created": "Mon, 28 Nov 2016 23:05:24 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 08:32:15 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Haslbeck", "Jonas M B", ""], ["Fried", "Eiko I", ""]]}, {"id": "1612.06719", "submitter": "Tom De Smedt", "authors": "Tom De Smedt, Lieven Menschaert, Pieter Heremans, Ludivine Lechat,\n  Ga\\\"elle Dhooghe", "title": "An EEG study of creativity in expert classical musicians", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous research has shown positive correlations between EEG alpha activity\nand performing creative tasks. In this study, expert classical musicians (n=4)\nwere asked to play their instrument while being monitored with a wireless EEG\nheadset. Data was collected during two rehearsal types: (a) in their regular,\nfixed ensemble;; (b) in an improvised, mixed ensemble with unfamiliar musicians\nand less rehearsal time. A positive correlation was found between alpha power\nand the improvised setup (p<0.01, d=0.4). A positive correlation was also found\nbetween alpha power and more intense play (p<0.01, d=0.2). There was a negative\ncorrelation between alpha power and arousal due to stress, e.g., frowning after\nplaying a false note (p<0.01, d=0.6). Finally, the real-time capabilities of\nwireless EEG monitoring were explored with a data visualisation during live\nperformance on stage.\n", "versions": [{"version": "v1", "created": "Sun, 18 Dec 2016 22:45:04 GMT"}], "update_date": "2016-12-21", "authors_parsed": [["De Smedt", "Tom", ""], ["Menschaert", "Lieven", ""], ["Heremans", "Pieter", ""], ["Lechat", "Ludivine", ""], ["Dhooghe", "Ga\u00eblle", ""]]}, {"id": "1612.06881", "submitter": "Hongyu Meng", "authors": "John Hongyu Meng, Hermann Riecke", "title": "Independent Noise Synchronizing Networks of Oscillator Networks", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Oscillators coupled in a network can synchronize with each other to yield a\ncoherent population rhythm. If multiple such networks are coupled together, the\nquestion arises whether these rhythms will synchronize. We investigate the\nimpact of noise on this synchronization for strong inhibitory pulse-coupling\nand find that increasing the noise can synchronize the population rhythms, even\nif the noisy inputs to different oscillators are completely uncorrelated.\nReducing the system to a phenomenological iterated map we show that this\nsynchronization of the rhythms arises from the noise-induced phase\nheterogeneity of the oscillators. The synchronization of population rhythms is\nexpected to be particularly relevant for brain rhythms.\n", "versions": [{"version": "v1", "created": "Tue, 20 Dec 2016 21:19:10 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Meng", "John Hongyu", ""], ["Riecke", "Hermann", ""]]}, {"id": "1612.06975", "submitter": "Bryan Tripp", "authors": "Bryan Tripp", "title": "Similarities and differences between stimulus tuning in the\n  inferotemporal visual cortex and convolutional networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) trained for object classification\nhave a number of striking similarities with the primate ventral visual stream.\nIn particular, activity in early, intermediate, and late layers is closely\nrelated to activity in V1, V4, and the inferotemporal cortex (IT). This study\nfurther compares activity in late layers of object-classification CNNs to\nactivity patterns reported in the IT electrophysiology literature. There are a\nnumber of close similarities, including the distributions of population\nresponse sparseness across stimuli, and the distribution of size tuning\nbandwidth. Statisics of scale invariance, responses to clutter and occlusion,\nand orientation tuning are less similar. Statistics of object selectivity are\nquite different. These results agree with recent studies that highlight strong\nparallels between object-categorization CNNs and the ventral stream, and also\nhighlight differences that could perhaps be reduced in future CNNs.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 05:30:11 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Tripp", "Bryan", ""]]}, {"id": "1612.07106", "submitter": "Xerxes D. Arsiwalla", "authors": "Xerxes D. Arsiwalla and Paul Verschure", "title": "The Global Dynamical Complexity of the Human Brain Network", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": "10.1007/s41109-016-0018-8", "report-no": null, "categories": "q-bio.NC cs.IT math.DS math.IT physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How much information do large brain networks integrate as a whole over the\nsum of their parts? Can the dynamical complexity of such networks be globally\nquantified in an information-theoretic way and be meaningfully coupled to brain\nfunction? Recently, measures of dynamical complexity such as integrated\ninformation have been proposed. However, problems related to the normalization\nand Bell number of partitions associated to these measures make these\napproaches computationally infeasible for large-scale brain networks. Our goal\nin this work is to address this problem. Our formulation of network integrated\ninformation is based on the Kullback-Leibler divergence between the\nmultivariate distribution on the set of network states versus the corresponding\nfactorized distribution over its parts. We find that implementing the maximum\ninformation partition optimizes computations. These methods are well-suited for\nlarge networks with linear stochastic dynamics. We compute the integrated\ninformation for both, the system's attractor states, as well as non-stationary\ndynamical states of the network. We then apply this formalism to brain networks\nto compute the integrated information for the human brain's connectome.\nCompared to a randomly re-wired network, we find that the specific topology of\nthe brain generates greater information complexity.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 13:44:31 GMT"}], "update_date": "2016-12-22", "authors_parsed": [["Arsiwalla", "Xerxes D.", ""], ["Verschure", "Paul", ""]]}, {"id": "1612.07183", "submitter": "Pablo Villegas G\\'ongora", "authors": "Serena di Santo, Pablo Villegas, Rafaella Burioni, and Miguel A.\n  Mu\\~noz", "title": "A simple unified view of branching process statistics: random walks in\n  balanced logarithmic potentials", "comments": "6 pages, 3 figures, 1 table", "journal-ref": "Phys. Rev. E 95, 032115 (2017)", "doi": "10.1103/PhysRevE.95.032115", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the problem of deriving the mean-field values of avalanche\ncritical exponents in systems with absorbing states. These are well-known to\ncoincide with those of an un-biased branching process. Here, we show that for\nat least 4 different universality classes (directed percolation, dynamical\npercolation, the voter model or compact directed percolation class, and the\nManna class of stochastic sandpiles) this common result can be obtained by\nmapping the corresponding Langevin equations describing each of these classes\ninto a random walker confined close to the origin by a logarithmic potential.\nMany of the results derived here appear in the literature as independently\nderived for individual universality classes or for the branching process.\nHowever, the emergence of non-universal continuously-varying exponent values\n--which, as shown here, stems fro the presence of small external driving, that\nmight induce avalanche merging-- has not been noticed (or emphasized) in the\npast. We believe that a simple an unified perspective as the one presented here\ncan (i) help to clarify the overall picture, (ii) underline the\nsuper-universality of the behavior as well as the dependence on external\ndriving, and (iii) help avoiding the common existing confusion between\nun-biased branching processes (equivalent to a random walker in a balanced\nlogarithmic potential) and standard (un-confined) random walkers.\n", "versions": [{"version": "v1", "created": "Wed, 21 Dec 2016 15:27:11 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2017 11:45:25 GMT"}, {"version": "v3", "created": "Tue, 21 Feb 2017 16:28:06 GMT"}], "update_date": "2017-03-15", "authors_parsed": [["di Santo", "Serena", ""], ["Villegas", "Pablo", ""], ["Burioni", "Rafaella", ""], ["Mu\u00f1oz", "Miguel A.", ""]]}, {"id": "1612.07712", "submitter": "Thierry Mora", "authors": "Ulisse Ferrari, Christophe Gardella, Olivier Marre, Thierry Mora", "title": "Closed-loop estimation of retinal network sensitivity reveals signature\n  of efficient coding", "comments": null, "journal-ref": "eNeuro 4 (6) ENEURO.0166-17.2017 (2018)", "doi": "10.1523/ENEURO.0166-17.2017", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to the theory of efficient coding, sensory systems are adapted to\nrepresent natural scenes with high fidelity and at minimal metabolic cost.\nTesting this hypothesis for sensory structures performing non-linear\ncomputations on high dimensional stimuli is still an open challenge. Here we\ndevelop a method to characterize the sensitivity of the retinal network to\nperturbations of a stimulus. Using closed-loop experiments, we explore\nselectively the space of possible perturbations around a given stimulus. We\nthen show that the response of the retinal population to these small\nperturbations can be described by a local linear model. Using this model, we\ncomputed the sensitivity of the neural response to arbitrary temporal\nperturbations of the stimulus, and found a peak in the sensitivity as a\nfunction of the frequency of the perturbations. Based on a minimal theory of\nsensory processing, we argue that this peak is set to maximize information\ntransmission. Our approach is relevant to testing the efficient coding\nhypothesis locally in any context where no reliable encoding model is known.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 17:23:31 GMT"}, {"version": "v2", "created": "Mon, 23 Jan 2017 16:24:33 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Ferrari", "Ulisse", ""], ["Gardella", "Christophe", ""], ["Marre", "Olivier", ""], ["Mora", "Thierry", ""]]}, {"id": "1612.07772", "submitter": "Shi Gu", "authors": "Shi Gu, Muzhi Yang, John D. Medaglia, Ruben C. Gur, Raquel E. Gur,\n  Theodore D. Satterthwaite, Danielle S. Bassett", "title": "Functional Hypergraph Uncovers Novel Covariant Structures over\n  Neurodevelopment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain development during adolescence is marked by substantial changes in\nbrain structure and function, leading to a stable network topology in\nadulthood. However, most prior work has examined the data through the lens of\nbrain areas connected to one another in large-scale functional networks. Here,\nwe apply a recently-developed hypergraph approach that treats network\nconnections (edges) rather than brain regions as the unit of interest, allowing\nus to describe functional network topology from a fundamentally different\nperspective. Capitalizing on a sample of 780 youth imaged as part of the\nPhiladelphia Neurodevelopmental Cohort, this hypergraph representation of\nresting-state functional MRI data reveals three distinct classes of\nsub-networks (hyperedges): clusters, bridges, and stars, which represent\nspatially distributed, bipartite, and focal architectures, respectively.\nCluster hyperedges show a strong resemblance to the functional modules of the\nbrain including somatomotor, visual, default mode, and salience systems. In\ncontrast, star hyperedges represent highly localized subnetworks centered on a\nsmall set of regions, and are distributed across the entire cortex. Finally,\nbridge hyperedges link clusters and stars in a core-periphery organization.\nNotably, developmental changes within hyperedges are ordered in a similar\ncore-periphery fashion, with the greatest developmental effects occurring in\nnetworked hyperedges within the functional core. Taken together, these results\nemphasize that the network organization of human brain emerges across multiple\nscales and evolves substantially through the adolescent period.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2016 20:06:21 GMT"}, {"version": "v2", "created": "Fri, 23 Dec 2016 03:47:14 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Gu", "Shi", ""], ["Yang", "Muzhi", ""], ["Medaglia", "John D.", ""], ["Gur", "Ruben C.", ""], ["Gur", "Raquel E.", ""], ["Satterthwaite", "Theodore D.", ""], ["Bassett", "Danielle S.", ""]]}, {"id": "1612.07846", "submitter": "Daniel Durstewitz", "authors": "Daniel Durstewitz", "title": "A State Space Approach for Piecewise-Linear Recurrent Neural Networks\n  for Reconstructing Nonlinear Dynamics from Neural Measurements", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pcbi.1005542", "report-no": null, "categories": "q-bio.NC cs.NE q-bio.QM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computational properties of neural systems are often thought to be\nimplemented in terms of their network dynamics. Hence, recovering the system\ndynamics from experimentally observed neuronal time series, like multiple\nsingle-unit (MSU) recordings or neuroimaging data, is an important step toward\nunderstanding its computations. Ideally, one would not only seek a state space\nrepresentation of the dynamics, but would wish to have access to its governing\nequations for in-depth analysis. Recurrent neural networks (RNNs) are a\ncomputationally powerful and dynamically universal formal framework which has\nbeen extensively studied from both the computational and the dynamical systems\nperspective. Here we develop a semi-analytical maximum-likelihood estimation\nscheme for piecewise-linear RNNs (PLRNNs) within the statistical framework of\nstate space models, which accounts for noise in both the underlying latent\ndynamics and the observation process. The Expectation-Maximization algorithm is\nused to infer the latent state distribution, through a global Laplace\napproximation, and the PLRNN parameters iteratively. After validating the\nprocedure on toy examples, the approach is applied to MSU recordings from the\nrodent anterior cingulate cortex obtained during performance of a classical\nworking memory task, delayed alternation. A model with 5 states turned out to\nbe sufficient to capture the essential computational dynamics underlying task\nperformance, including stimulus-selective delay activity. The estimated models\nwere rarely multi-stable, but rather were tuned to exhibit slow dynamics in the\nvicinity of a bifurcation point. In summary, the present work advances a\nsemi-analytical (thus reasonably fast) maximum-likelihood estimation framework\nfor PLRNNs that may enable to recover the relevant dynamics underlying observed\nneuronal time series, and directly link them to computational properties.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 01:01:52 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Durstewitz", "Daniel", ""]]}, {"id": "1612.07929", "submitter": "Joaquin Torres", "authors": "M. Uzuntarla, J.J. Torres, P. So, M. Ozer, E. Barreto", "title": "Double Inverse Stochastic Resonance with Dynamic Synapses", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": "10.1103/PhysRevE.95.012404", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the behavior of a model neuron that receives a\nbiophysically-realistic noisy post-synaptic current based on uncorrelated\nspiking activity from a large number of afferents. We show that, with static\nsynapses, such noise can give rise to inverse stochastic resonance (ISR) as a\nfunction of the presynaptic firing rate. We compare this to the case with\ndynamic synapses that feature short-term synaptic plasticity, and show that the\ninterval of presynaptic firing rate over which ISR exists can be extended or\ndiminished. We consider both short-term depression and facilitation.\nInterestingly, we find that a double inverse stochastic resonance (DISR), with\ntwo distinct wells centered at different presynaptic firing rates, can appear.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 10:44:29 GMT"}], "update_date": "2017-02-01", "authors_parsed": [["Uzuntarla", "M.", ""], ["Torres", "J. J.", ""], ["So", "P.", ""], ["Ozer", "M.", ""], ["Barreto", "E.", ""]]}, {"id": "1612.08059", "submitter": "Danielle Bassett", "authors": "Danielle S. Bassett, Ankit N. Khambhati, Scott T. Grafton", "title": "Emerging Frontiers of Neuroengineering: A Network Science of Brain\n  Connectivity", "comments": "17 pages, 6 figures. Manuscript accepted to the journal \"Annual\n  Review of Biomedical Engineering\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroengineering is faced with unique challenges in repairing or replacing\ncomplex neural systems that are composed of many interacting parts. These\ninteractions form intricate patterns over large spatiotemporal scales, and\nproduce emergent behaviors that are difficult to predict from individual\nelements. Network science provides a particularly appropriate framework in\nwhich to study and intervene in such systems, by treating neural elements\n(cells, volumes) as nodes in a graph and neural interactions (synapses, white\nmatter tracts) as edges in that graph. Here, we review the emerging discipline\nof network neuroscience, which uses and develops tools from graph theory to\nbetter understand and manipulate neural systems, from micro- to macroscales. We\npresent examples of how human brain imaging data is being modeled with network\nanalysis and underscore potential pitfalls. We then highlight current\ncomputational and theoretical frontiers, and emphasize their utility in\ninforming diagnosis and monitoring, brain-machine interfaces, and brain\nstimulation. A flexible and rapidly evolving enterprise, network neuroscience\nprovides a set of powerful approaches and fundamental insights critical to the\nneuroengineer's toolkit.\n", "versions": [{"version": "v1", "created": "Fri, 23 Dec 2016 18:28:12 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Bassett", "Danielle S.", ""], ["Khambhati", "Ankit N.", ""], ["Grafton", "Scott T.", ""]]}, {"id": "1612.08392", "submitter": "Muhammad Yousefnezhad", "authors": "Muhammad Yousefnezhad, Daoqiang Zhang", "title": "Multi-Region Neural Representation: A novel model for decoding visual\n  stimuli in human brains", "comments": "Accepted in SIAM International Conference on Data Mininig (SDM),\n  Houston, Texas, USA, April/27-29, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multivariate Pattern (MVP) classification holds enormous potential for\ndecoding visual stimuli in the human brain by employing task-based fMRI data\nsets. There is a wide range of challenges in the MVP techniques, i.e.\ndecreasing noise and sparsity, defining effective regions of interest (ROIs),\nvisualizing results, and the cost of brain studies. In overcoming these\nchallenges, this paper proposes a novel model of neural representation, which\ncan automatically detect the active regions for each visual stimulus and then\nutilize these anatomical regions for visualizing and analyzing the functional\nactivities. Therefore, this model provides an opportunity for neuroscientists\nto ask this question: what is the effect of a stimulus on each of the detected\nregions instead of just study the fluctuation of voxels in the manually\nselected ROIs. Moreover, our method introduces analyzing snapshots of brain\nimage for decreasing sparsity rather than using the whole of fMRI time series.\nFurther, a new Gaussian smoothing method is proposed for removing noise of\nvoxels in the level of ROIs. The proposed method enables us to combine\ndifferent fMRI data sets for reducing the cost of brain studies. Experimental\nstudies on 4 visual categories (words, consonants, objects and nonsense photos)\nconfirm that the proposed method achieves superior performance to\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2016 14:37:57 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Yousefnezhad", "Muhammad", ""], ["Zhang", "Daoqiang", ""]]}, {"id": "1612.08457", "submitter": "Boris Barbour", "authors": "Boris Barbour", "title": "Analysis of claims that the brain extracellular impedance is high and\n  non-resistive", "comments": "6 pages", "journal-ref": null, "doi": "10.1016/j.bpj.2017.05.054", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerous measurements in the brain of the impedance between two extracellular\nelectrodes have shown that it is approximately resistive in the range of\nbiological interest, $<10\\,$kHz, and has a value close to that expected from\nthe conductivity of physiological saline and the extracellular volume fraction\nin brain tissue. Recent work from the group of Claude B\\'edard and Alain\nDestexhe has claimed that the impedance of the extracellular space is some\nthree orders of magnitude greater than these values and also displays a\n$1/\\sqrt{f}$ frequency dependence (above a low-frequency corner frequency).\nTheir measurements were performed between an intracellular electrode and an\nextracellular electrode. It is argued that they incorrectly extracted the\nextracellular impedance because of an inaccurate representation of the large,\nconfounding impedance of the neuronal membrane. In conclusion, no compelling\nevidence has been provided to undermine the well established and physically\nplausible consensus that the brain extracellular impedance is low and\napproximately resistive\n", "versions": [{"version": "v1", "created": "Mon, 26 Dec 2016 23:09:41 GMT"}, {"version": "v2", "created": "Wed, 28 Dec 2016 02:07:56 GMT"}, {"version": "v3", "created": "Sat, 31 Dec 2016 22:04:40 GMT"}, {"version": "v4", "created": "Tue, 3 Jan 2017 07:37:02 GMT"}, {"version": "v5", "created": "Sun, 26 Mar 2017 21:58:42 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Barbour", "Boris", ""]]}, {"id": "1612.08642", "submitter": "Jaime Delgado Saa", "authors": "Jaime Fernando Delgado Saa, Mujdat Cetin", "title": "Bayesian Nonparametric Models for Synchronous Brain-Computer Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  A brain-computer interface (BCI) is a system that aims for establishing a\nnon-muscular communication path for subjects who had suffer from a\nneurodegenerative disease. Many BCI systems make use of the phenomena of\nevent-related synchronization and de-synchronization of brain waves as a main\nfeature for classification of different cognitive tasks. However, the temporal\ndynamics of the electroencephalographic (EEG) signals contain additional\ninformation that can be incorporated into the inference engine in order to\nimprove the performance of the BCIs. This information about the dynamics of the\nsignals have been exploited previously in BCIs by means of generative and\ndiscriminative methods. In particular, hidden Markov models (HMMs) have been\nused in previous works. These methods have the disadvantage that the model\nparameters such as the number of hidden states and the number of Gaussian\nmixtures need to be fix \"a priori\". In this work, we propose a Bayesian\nnonparametric model for brain signal classification that does not require \"a\npriori\" selection of the number of hidden states and the number of Gaussian\nmixtures of a HMM. The results show that the proposed model outperform other\nmethods based on HMM as well as the winner algorithm of the BCI competition IV.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 14:17:20 GMT"}], "update_date": "2016-12-28", "authors_parsed": [["Saa", "Jaime Fernando Delgado", ""], ["Cetin", "Mujdat", ""]]}, {"id": "1612.08780", "submitter": "Hosein M. Golshan", "authors": "Hosein M. Golshan, Adam O. Hebb, Sara J. Hanrahan, Joshua Nedrud,\n  Mohammad H. Mahoor", "title": "An FFT-based Synchronization Approach to Recognize Human Behaviors using\n  STN-LFP Signal", "comments": "IEEE Conf on ICASSP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of human behavior is key to developing closed-loop Deep Brain\nStimulation (DBS) systems, which may be able to decrease the power consumption\nand side effects of the existing systems. Recent studies have shown that the\nLocal Field Potential (LFP) signals from both Subthalamic Nuclei (STN) of the\nbrain can be used to recognize human behavior. Since the DBS leads implanted in\neach STN can collect three bipolar signals, the selection of a suitable pair of\nLFPs that achieves optimal recognition performance is still an open problem to\naddress. Considering the presence of synchronized aggregate activity in the\nbasal ganglia, this paper presents an FFT-based synchronization approach to\nautomatically select a relevant pair of LFPs and use the pair together with an\nSVM-based MKL classifier for behavior recognition purposes. Our experiments on\nfive subjects show the superiority of the proposed approach compared to other\nmethods used for behavior classification.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 01:08:56 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Golshan", "Hosein M.", ""], ["Hebb", "Adam O.", ""], ["Hanrahan", "Sara J.", ""], ["Nedrud", "Joshua", ""], ["Mahoor", "Mohammad H.", ""]]}, {"id": "1612.08935", "submitter": "Leenoy Meshulam", "authors": "Leenoy Meshulam, Jeffrey L. Gauthier, Carlos D. Brody, David W. Tank,\n  and William Bialek", "title": "Collective behavior of place and non-place neurons in the hippocampal\n  network", "comments": null, "journal-ref": null, "doi": "10.1016/j.neuron.2017.10.027", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussions of the hippocampus often focus on place cells, but many neurons\nare not place cells in any given environment. Here we describe the collective\nactivity in such mixed populations, treating place and non-place cells on the\nsame footing. We start with optical imaging experiments on CA1 in mice as they\nrun along a virtual linear track, and use maximum entropy methods to\napproximate the distribution of patterns of activity in the population,\nmatching the correlations between pairs of cells but otherwise assuming as\nlittle structure as possible. We find that these simple models accurately\npredict the activity of each neuron from the state of all the other neurons in\nthe network, regardless of how well that neuron codes for position. These and\nother results suggest that place cells are not a distinct sub-network, but part\nof a larger system that encodes, collectively, more than just place\ninformation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Dec 2016 17:30:54 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Meshulam", "Leenoy", ""], ["Gauthier", "Jeffrey L.", ""], ["Brody", "Carlos D.", ""], ["Tank", "David W.", ""], ["Bialek", "William", ""]]}, {"id": "1612.09268", "submitter": "Sidarta Ribeiro", "authors": "Natalia Bezerra Mota, Sylvia Pinheiro, Mariano Sigman, Diego Fernandez\n  Slezak, Guillermo Cecchi, Mauro Copelli, Sidarta Ribeiro", "title": "The ontogeny of discourse structure mimics the development of literature", "comments": "Natalia Bezerra Mota and Sylvia Pinheiro: Equal contribution Sidarta\n  Ribeiro and Mauro Copelli: Corresponding authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discourse varies with age, education, psychiatric state and historical epoch,\nbut the ontogenetic and cultural dynamics of discourse structure remain to be\nquantitatively characterized. To this end we investigated word graphs obtained\nfrom verbal reports of 200 subjects ages 2-58, and 676 literary texts spanning\n~5,000 years. In healthy subjects, lexical diversity, graph size, and\nlong-range recurrence departed from initial near-random levels through a\nmonotonic asymptotic increase across ages, while short-range recurrence showed\na corresponding decrease. These changes were explained by education and suggest\na hierarchical development of discourse structure: short-range recurrence and\nlexical diversity stabilize after elementary school, but graph size and\nlong-range recurrence only stabilize after high school. This gradual maturation\nwas blurred in psychotic subjects, who maintained in adulthood a near-random\nstructure. In literature, monotonic asymptotic changes over time were\nremarkable: While lexical diversity, long-range recurrence and graph size\nincreased away from near-randomness, short-range recurrence declined, from\nabove to below random levels. Bronze Age texts are structurally similar to\nchildish or psychotic discourses, but subsequent texts converge abruptly to the\nhealthy adult pattern around the onset of the Axial Age (800-200 BC), a period\nof pivotal cultural change. Thus, individually as well as historically,\ndiscourse maturation increases the range of word recurrence away from\nrandomness.\n", "versions": [{"version": "v1", "created": "Tue, 27 Dec 2016 21:58:42 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Mota", "Natalia Bezerra", ""], ["Pinheiro", "Sylvia", ""], ["Sigman", "Mariano", ""], ["Slezak", "Diego Fernandez", ""], ["Cecchi", "Guillermo", ""], ["Copelli", "Mauro", ""], ["Ribeiro", "Sidarta", ""]]}, {"id": "1612.09522", "submitter": "Daniel Chicharro", "authors": "Daniel Chicharro and Stefano Panzeri", "title": "Redundancy and synergy in dual decompositions of mutual information gain\n  and information loss", "comments": null, "journal-ref": null, "doi": "10.3390/e19020071", "report-no": null, "categories": "physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Williams and Beer (2010) proposed a nonnegative mutual information\ndecomposition, based on the construction of information gain lattices, which\nallows separating the information that a set of variables contains about\nanother into components interpretable as the unique information of one\nvariable, or redundant and synergy components. In this work we extend the\nframework of Williams and Beer (2010) focusing on the lattices that underpin\nthe decomposition. We generalize the type of constructible lattices and examine\nthe relations between the terms in different lattices, for example relating\nbivariate and trivariate decompositions. We point out that, in information gain\nlattices, redundancy components are invariant across decompositions, but unique\nand synergy components are decomposition-dependent. Exploiting the connection\nbetween different lattices we propose a procedure to construct, in the general\nmultivariate case, information decompositions from measures of synergy or\nunique information. We introduce an alternative type of mutual information\ndecompositions based on information loss lattices, with the role and invariance\nproperties of redundancy and synergy components exchanged with respect to gain\nlattices. We study the correspondence between information gain and information\nloss lattices and we define dual decompositions that allow overcoming the\nintrinsic asymmetry between invariant and decomposition-dependent components,\nwhich hinders the consistent joint characterization of synergy and redundancy.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 16:25:29 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Chicharro", "Daniel", ""], ["Panzeri", "Stefano", ""]]}]