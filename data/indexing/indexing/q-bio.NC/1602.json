[{"id": "1602.00236", "submitter": "Gustau Camps-Valls", "authors": "Valero Laparra, Sandra Jim\\'enez, Gustavo Camps-Valls, Jes\\'us Malo", "title": "Nonlinearities and Adaptation of Color Vision from Sequential Principal\n  Curves Analysis", "comments": null, "journal-ref": "Neural Comput. 2012 Oct;24(10):2751-88", "doi": "10.1162/NECO_a_00342", "report-no": null, "categories": "stat.ML q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mechanisms of human color vision are characterized by two phenomenological\naspects: the system is nonlinear and adaptive to changing environments.\nConventional attempts to derive these features from statistics use separate\narguments for each aspect. The few statistical approaches that do consider both\nphenomena simultaneously follow parametric formulations based on empirical\nmodels. Therefore, it may be argued that the behavior does not come directly\nfrom the color statistics but from the convenient functional form adopted. In\naddition, many times the whole statistical analysis is based on simplified\ndatabases that disregard relevant physical effects in the input signal, as for\ninstance by assuming flat Lambertian surfaces. Here we address the simultaneous\nstatistical explanation of (i) the nonlinear behavior of achromatic and\nchromatic mechanisms in a fixed adaptation state, and (ii) the change of such\nbehavior. Both phenomena emerge directly from the samples through a single\ndata-driven method: the Sequential Principal Curves Analysis (SPCA) with local\nmetric. SPCA is a new manifold learning technique to derive a set of sensors\nadapted to the manifold using different optimality criteria. A new database of\ncolorimetrically calibrated images of natural objects under these illuminants\nwas collected. The results obtained by applying SPCA show that the\npsychophysical behavior on color discrimination thresholds, discount of the\nilluminant and corresponding pairs in asymmetric color matching, emerge\ndirectly from realistic data regularities assuming no a priori functional form.\nThese results provide stronger evidence for the hypothesis of a statistically\ndriven organization of color sensors. Moreover, the obtained results suggest\nthat color perception at this low abstraction level may be guided by an error\nminimization strategy rather than by the information maximization principle.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 12:33:18 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Laparra", "Valero", ""], ["Jim\u00e9nez", "Sandra", ""], ["Camps-Valls", "Gustavo", ""], ["Malo", "Jes\u00fas", ""]]}, {"id": "1602.00258", "submitter": "Luca Puviani", "authors": "Luca Puviani, Sidita Rama", "title": "Placebo Response is Driven by UCS Revaluation: Evidence,\n  Neurophysiological Consequences and a Quantitative Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite growing scientific interest in the placebo effect and increasing\nunderstanding of neurobiological mechanisms, theoretical modeling of the\nplacebo response remains poorly developed. The most extensively accepted\ntheories are expectation and conditioning, involving both conscious and\nunconscious information processing. However, it is not completely understood\nhow these mechanisms can shape the placebo response. We focus here on neural\nprocesses which can account for key properties of the response to substance\nintake. It is shown that placebo response can be conceptualized as a reaction\nof a distributed neural system within the central nervous system. Such a\nreaction represents an integrated component of the response to open substance\nadministration (or to substance intake) and is updated through \"unconditioned\nstimulus (UCS) revaluation\" learning. The analysis leads to a theorem, which\nproves the existence of two distinct quantities coded within the brain, these\nare the expected or prediction outcome and the reactive response. We show that\nthe reactive response is updated automatically by implicit revaluation lerning,\nwhile the expected outcome can also be modulated through conscious information\nprocessing. Conceptualizing the response to substance intake in terms of UCS\nrevaluation learning leads to the theoretical formulation of a potential\nneuropharmacological treatment for increasing unlimitedly the effectiveness of\na given drug.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 15:12:57 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Puviani", "Luca", ""], ["Rama", "Sidita", ""]]}, {"id": "1602.00579", "submitter": "Antonio Galves", "authors": "A. Duarte, R. Fraiman, A. Galves, G. Ost and C. Vargas", "title": "Context tree selection for functional data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It has been repeatedly conjectured that the brain retrieves statistical\nregularities from stimuli. Here we present a new statistical approach allowing\nto address this conjecture. This approach is based on a new class of stochastic\nprocesses driven by chains with memory of variable length. It leads to a new\nexperimental protocol in which sequences of auditory stimuli generated by a\nstochastic chain are presented to volunteers while electroencephalographic\n(EEG) data is recorded from their scalp. A new statistical model selection\nprocedure for functional data is introduced and proved to be consistent.\nApplied to samples of EEG data collected using our experimental protocol it\nproduces results supporting the conjecture that the brain effectively\nidentifies the structure of the chain generating the sequence of stimuli.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 16:18:00 GMT"}, {"version": "v2", "created": "Mon, 18 Dec 2017 20:32:37 GMT"}, {"version": "v3", "created": "Thu, 11 Jan 2018 21:47:24 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Duarte", "A.", ""], ["Fraiman", "R.", ""], ["Galves", "A.", ""], ["Ost", "G.", ""], ["Vargas", "C.", ""]]}, {"id": "1602.00587", "submitter": "Marek Czachor", "authors": "Marek Czachor", "title": "Information processing and Fechner's problem as a choice of arithmetic", "comments": "To appear in \"Information Studies and Transdisciplinarity\", ed. M.\n  Burgin, World Scientific (2016)", "journal-ref": "M. Burgin and W. Hofkirchner (eds.), Information Studies and the\n  Quest for Interdisciplinarity: Unity Through Diversity, pp. 363-372, World\n  Scientific, Singapore (2017)", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fechner's law and its modern generalizations can be regarded as\nmanifestations of alternative forms of arithmetic, coexisting at stimulus and\nsensation levels. The world of sensations may be thus described by a\ngeneralization of the standard mathematical calculus.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2016 10:02:01 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2016 12:35:49 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Czachor", "Marek", ""]]}, {"id": "1602.00681", "submitter": "Yuri A. Dabaghian", "authors": "Andrey Babichev and Yuri Dabaghian", "title": "Persistent memories in transient networks", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial awareness in mammals is based on an internalized representation of\nthe environment, encoded by large networks of spiking neurons. While such\nrepresentations can last for a long time, the underlying neuronal network is\ntransient: neuronal cells die every day, synaptic connections appear and\ndisappear, the networks constantly change their architecture due to various\nforms of synaptic and structural plasticity. How can a network with a dynamic\narchitecture encode a stable map of space? We address this question using a\nphysiological model of a \"flickering\" neuronal network and demonstrate that it\ncan maintain a robust topological representation of space.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 08:25:30 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Babichev", "Andrey", ""], ["Dabaghian", "Yuri", ""]]}, {"id": "1602.00808", "submitter": "Fotini Pallikari", "authors": "Fotini Pallikari", "title": "The balancing effect in brain-machine interaction", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The meta analysis of Intangible Brain Machine Interaction (IMMI) data with\nrandom number generators is re-evaluated through the application of rigorous\nand recognized mathematical tools. The current analysis shows that the\nstatistical average of the true RNG-IMMI data is not shifted from chance by\ndirect mental intervention, thus refuting the IMMI hypothesis. A facet of this\ngeneral statistical behavior of true RNG-IMMI data is the statistical balancing\nof scores observed in IMMI tests where binary testing conditions are adopted.\nThe actual dynamics that had been supporting the elusive IMMI effect are shown\nto be related to the psychology of experimenters. The implications of the\nrefutation of the IMMI hypothesis especially on associated phenomena are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 07:09:42 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Pallikari", "Fotini", ""]]}, {"id": "1602.00933", "submitter": "Sean Simpson", "authors": "Sean L. Simpson and Paul J. Laurienti", "title": "Disentangling Brain Graphs: A Note on the Conflation of Network and\n  Connectivity Analyses", "comments": "In Press, Brain Connectivity 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM q-bio.NC stat.AP stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the human brain remains the Holy Grail in biomedical science,\nand arguably in all of the sciences. Our brains represent the most complex\nsystems in the world (and some contend the universe) comprising nearly one\nhundred billion neurons with septillions of possible connections between them.\nThe structure of these connections engenders an efficient hierarchical system\ncapable of consciousness, as well as complex thoughts, feelings, and behaviors.\nBrain connectivity and network analyses have exploded over the last decade due\nto their potential in helping us understand both normal and abnormal brain\nfunction. Functional connectivity (FC) analysis examines functional\nassociations between time series pairs in specified brain voxels or regions.\nBrain network analysis serves as a distinct subfield of connectivity analysis\nin which associations are quantified for all time series pairs to create an\ninterconnected representation of the brain (a brain network), which allows\nstudying its systemic properties. While connectivity analyses underlie network\nanalyses, the subtle distinction between the two research areas has generally\nbeen overlooked in the literature, with them often being referred to\nsynonymously. However, developing more useful analytic methods and allowing for\nmore precise biological interpretations requires distinguishing these two\ncomplementary domains.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 14:11:40 GMT"}], "update_date": "2016-02-03", "authors_parsed": [["Simpson", "Sean L.", ""], ["Laurienti", "Paul J.", ""]]}, {"id": "1602.01056", "submitter": "Jennifer Schloss", "authors": "J. F. Barry, M. J. Turner, J. M. Schloss, D. R. Glenn, Y. Song, M. D.\n  Lukin, H. Park, R. L. Walsworth", "title": "Optical magnetic detection of single-neuron action potentials using\n  quantum defects in diamond", "comments": "23 pages, 12 figures, 2 tables", "journal-ref": "PNAS 2016 113 (49) 14133-14138; November 22, 2016", "doi": "10.1073/pnas.1601513113", "report-no": null, "categories": "quant-ph cond-mat.mes-hall physics.atom-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge for neuroscience is noninvasive, label-free sensing of action\npotential (AP) dynamics in whole organisms with single-neuron resolution. Here,\nwe present a new approach to this problem: using nitrogen-vacancy (NV) quantum\ndefects in diamond to measure the time-dependent magnetic fields produced by\nsingle-neuron APs. Our technique has a unique combination of features: (i) it\nis noninvasive, as the light that probes the NV sensors stays within the\nbiocompatible diamond chip and does not enter the organism, enabling activity\nmonitoring over extended periods; (ii) it is label-free and should be widely\napplicable to most organisms; (iii) it provides high spatial and temporal\nresolution, allowing precise measurement of the AP waveforms and conduction\nvelocities of individual neurons; (iv) it directly determines AP propagation\ndirection through the inherent sensitivity of NVs to the associated AP magnetic\nfield vector; (v) it is applicable to neurons located within optically opaque\ntissue or whole organisms, through which magnetic fields pass largely\nunperturbed; and (vi) it is easy-to-use, scalable, and can be integrated with\nexisting techniques such as wide-field and superresolution imaging. We\ndemonstrate our method using excised single neurons from two invertebrate\nspecies, marine worm and squid; and then by single-neuron AP magnetic sensing\nexterior to whole, live, opaque marine worms for extended periods with no\nadverse effect. The results lay the groundwork for real-time, noninvasive 3D\nmagnetic mapping of functional neuronal networks, ultimately with synapse-scale\n(~10 nm) resolution and circuit-scale (~1 cm) field-of-view.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 19:38:07 GMT"}], "update_date": "2016-12-26", "authors_parsed": [["Barry", "J. F.", ""], ["Turner", "M. J.", ""], ["Schloss", "J. M.", ""], ["Glenn", "D. R.", ""], ["Song", "Y.", ""], ["Lukin", "M. D.", ""], ["Park", "H.", ""], ["Walsworth", "R. L.", ""]]}, {"id": "1602.01815", "submitter": "Michael Schmuker", "authors": "Michael Schmuker, Viktor Bahr, Ram\\'on Huerta", "title": "Exploiting plume structure to decode gas source distance using\n  metal-oxide gas sensors", "comments": "41 pages, 20 figures", "journal-ref": "Sensors and Actuators B: Chemical 235:636-646 (2016)", "doi": "10.1016/j.snb.2016.05.098", "report-no": null, "categories": "q-bio.NC physics.data-an stat.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Estimating the distance of a gas source is important in many applications of\nchemical sensing, like e.g. environmental monitoring, or chemically-guided\nrobot navigation. If an estimation of the gas concentration at the source is\navailable, source proximity can be estimated from the time-averaged gas\nconcentration at the sensing site. However, in turbulent environments, where\nfast concentration fluctuations dominate, comparably long measurements are\nrequired to obtain a reliable estimate. A lesser known feature that can be\nexploited for distance estimation in a turbulent environment lies in the\nrelationship between source proximity and the temporal variance of the local\ngas concentration - the farther the source, the more intermittent are gas\nencounters. However, exploiting this feature requires measurement of changes in\ngas concentration on a comparably fast time scale, that have up to now only\nbeen achieved using photo-ionisation detectors. Here, we demonstrate that by\nappropriate signal processing, off-the-shelf metal-oxide sensors are capable of\nextracting rapidly fluctuating features of gas plumes that strongly correlate\nwith source distance. We show that with a straightforward analysis method it is\npossible to decode events of large, consistent changes in the measured signal,\nso-called 'bouts'. The frequency of these bouts predicts the distance of a gas\nsource in wind-tunnel experiments with good accuracy. In addition, we found\nthat the variance of bout counts indicates cross-wind offset to the centreline\nof the gas plume. Our results offer an alternative approach to estimating gas\nsource proximity that is largely independent of gas concentration, using\noff-the-shelf metal-oxide sensors. The analysis method we employ demands very\nfew computational resources and is suitable for low-power microcontrollers.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 13:28:08 GMT"}, {"version": "v2", "created": "Wed, 18 May 2016 10:20:09 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Schmuker", "Michael", ""], ["Bahr", "Viktor", ""], ["Huerta", "Ram\u00f3n", ""]]}, {"id": "1602.01889", "submitter": "Furong Huang", "authors": "Furong Huang, Animashree Anandkumar, Christian Borgs, Jennifer Chayes,\n  Ernest Fraenkel, Michael Hawrylycz, Ed Lein, Alessandro Ingrosso, Srinivas\n  Turaga", "title": "Discovering Neuronal Cell Types and Their Gene Expression Profiles Using\n  a Spatial Point Process Mixture Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cataloging the neuronal cell types that comprise circuitry of individual\nbrain regions is a major goal of modern neuroscience and the BRAIN initiative.\nSingle-cell RNA sequencing can now be used to measure the gene expression\nprofiles of individual neurons and to categorize neurons based on their gene\nexpression profiles. While the single-cell techniques are extremely powerful\nand hold great promise, they are currently still labor intensive, have a high\ncost per cell, and, most importantly, do not provide information on spatial\ndistribution of cell types in specific regions of the brain. We propose a\ncomplementary approach that uses computational methods to infer the cell types\nand their gene expression profiles through analysis of brain-wide single-cell\nresolution in situ hybridization (ISH) imagery contained in the Allen Brain\nAtlas (ABA). We measure the spatial distribution of neurons labeled in the ISH\nimage for each gene and model it as a spatial point process mixture, whose\nmixture weights are given by the cell types which express that gene. By fitting\na point process mixture model jointly to the ISH images, we infer both the\nspatial point process distribution for each cell type and their gene expression\nprofile. We validate our predictions of cell type-specific gene expression\nprofiles using single cell RNA sequencing data, recently published for the\nmouse somatosensory cortex. Jointly with the gene expression profiles, cell\nfeatures such as cell size, orientation, intensity and local density level are\ninferred per cell type.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 23:52:18 GMT"}, {"version": "v2", "created": "Sat, 11 Jun 2016 01:45:12 GMT"}], "update_date": "2016-06-14", "authors_parsed": [["Huang", "Furong", ""], ["Anandkumar", "Animashree", ""], ["Borgs", "Christian", ""], ["Chayes", "Jennifer", ""], ["Fraenkel", "Ernest", ""], ["Hawrylycz", "Michael", ""], ["Lein", "Ed", ""], ["Ingrosso", "Alessandro", ""], ["Turaga", "Srinivas", ""]]}, {"id": "1602.02945", "submitter": "Adeel Razi", "authors": "Adeel Razi and Karl Friston", "title": "The connected brain: Causality, models and intrinsic dynamics", "comments": "52 pages, Feature Article, Accepted, IEEE Signal Processing Magazine", "journal-ref": null, "doi": "10.1109/MSP.2015.2482121", "report-no": null, "categories": "q-bio.NC math.DS stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, there have been several concerted international efforts - the BRAIN\ninitiative, European Human Brain Project and the Human Connectome Project, to\nname a few - that hope to revolutionize our understanding of the connected\nbrain. Over the past two decades, functional neuroimaging has emerged as the\npredominant technique in systems neuroscience. This is foreshadowed by an ever\nincreasing number of publications on functional connectivity, causal modeling,\nconnectomics, and multivariate analyses of distributed patterns of brain\nresponses. In this article, we summarize pedagogically the (deep) history of\nbrain mapping. We will highlight the theoretical advances made in the (dynamic)\ncausal modelling of brain function - that may have escaped the wider audience\nof this article - and provide a brief overview of recent developments and\ninteresting clinical applications. We hope that this article will engage the\nsignal processing community by showcasing the inherently multidisciplinary\nnature of this important topic and the intriguing questions that are being\naddressed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 11:54:38 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Razi", "Adeel", ""], ["Friston", "Karl", ""]]}, {"id": "1602.02974", "submitter": "David Zwicker", "authors": "David Zwicker, Arvind Murugan, Michael P. Brenner", "title": "Receptor arrays optimized for natural odor statistics", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": "10.1073/pnas.1600357113", "report-no": null, "categories": "physics.bio-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural odors typically consist of many molecules at different\nconcentrations. It is unclear how the numerous odorant molecules and their\npossible mixtures are discriminated by relatively few olfactory receptors.\nUsing an information-theoretic model, we show that a receptor array is optimal\nfor this task if it achieves two possibly conflicting goals: (i) each receptor\nshould respond to half of all odors and (ii) the response of different\nreceptors should be uncorrelated when averaged over odors presented with\nnatural statistics. We use these design principles to predict statistics of the\naffinities between receptors and odorant molecules for a broad class of odor\nstatistics. We also show that optimal receptor arrays can be tuned to either\nresolve concentrations well or distinguish mixtures reliably. Finally, we use\nour results to predict properties of experimentally measured receptor arrays.\nOur work can thus be used to better understand natural olfaction and it also\nsuggests ways to improve artificial sensor arrays.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 13:25:01 GMT"}], "update_date": "2016-08-26", "authors_parsed": [["Zwicker", "David", ""], ["Murugan", "Arvind", ""], ["Brenner", "Michael P.", ""]]}, {"id": "1602.03008", "submitter": "Vince Grolmusz", "authors": "Balazs Szalkai and Balint Varga and Vince Grolmusz", "title": "Mapping Correlations of Psychological and Connectomical Properties of\n  the Dataset of the Human Connectome Project with the Maximum Spanning Tree\n  Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyzed correlations between more than 700 psychological-, anatomical-\nand connectome--properties, originated from the Human Connectome Project's\n(HCP) 500-subject dataset. Apart from numerous natural correlations, which\ndescribe parameters computable or approximable from one another, we have\ndiscovered numerous significant correlations in the dataset, never described\nbefore. We also have found correlations described very recently independently\nfrom the HCP-dataset: e.g., between gambling behavior and the number of the\nconnections leaving the insula.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 14:49:17 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Szalkai", "Balazs", ""], ["Varga", "Balint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1602.03379", "submitter": "Anupam Mitra", "authors": "Anupam Mitra, Anagh Pathak, Kaushik Majumdar", "title": "Comparison of feature extraction and dimensionality reduction methods\n  for single channel extracellular spike sorting", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spikes in the membrane electrical potentials of neurons play a major role in\nthe functioning of nervous systems of animals. Obtaining the spikes from\ndifferent neurons has been a challenging problem for decades. Several schemes\nhave been proposed for spike sorting to isolate the spikes of individual\nneurons from electrical recordings in extracellular media. However, there is\nmuch scope for improvement in the accuracies obtained using the prevailing\nmethods of spike sorting. To determine more effective spike sorting strategies\nusing well known methods, we compared different types of signal features and\ntechniques for dimensionality reduction in feature space. We tried to determine\nan optimum or near optimum feature extraction and dimensionality reduction\nmethods and an optimum or near optimum number of features for spike sorting. We\nassessed relative performance of well known methods on simulated recordings\nspecially designed for development and benchmarking of spike sorting schemes,\nwith varying number of spike classes and the well established method of\n$k$-means clustering of selected features. We found that almost all well known\nmethods performed quite well. Nevertheless, from spike waveforms of 64 samples,\nsampled at 24 kHz, using principal component analysis (PCA) to select around 46\nto 55 features led to the better spike sorting performance than most other\nmethods (Wilcoxon signed rank sum test, $p < 0.001$).\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 14:21:34 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Mitra", "Anupam", ""], ["Pathak", "Anagh", ""], ["Majumdar", "Kaushik", ""]]}, {"id": "1602.03493", "submitter": "Pierre Sacr\\'e", "authors": "Pierre Sacr\\'e, Matthew S.D. Kerr, Sandya Subramanian, Kevin Kahn,\n  Jorge Gonzalez-Martinez, Matthew A. Johnson, John T. Gale and Sridevi V.\n  Sarma", "title": "Winning versus losing during gambling and its neural correlates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans often make decisions which maximize an internal utility function. For\nexample, humans often maximize their expected reward when gambling and this is\nconsidered as a \"rational\" decision. However, humans tend to change their\nbetting strategies depending on how they \"feel\". If someone has experienced a\nlosing streak, they may \"feel\" that they are more likely to win on the next\nhand even though the odds of the game have not changed. That is, their\ndecisions are driven by their emotional state. In this paper, we investigate\nhow the human brain responds to wins and losses during gambling. Using a\ncombination of local field potential recordings in human subjects performing a\nfinancial decision-making task, spectral analyses, and non-parametric cluster\nstatistics, we investigated whether neural responses in different cognitive and\nlimbic brain areas differ between wins and losses after decisions are made. In\neleven subjects, the neural activity modulated significantly between win and\nloss trials in one brain region: the anterior insula ($p=0.01$). In particular,\ngamma activity (30-70 Hz) increased in the anterior insula when subjects just\nrealized that they won. Modulation of metabolic activity in the anterior insula\nhas been observed previously in functional magnetic resonance imaging studies\nduring decision making and when emotions are elicited. However, our study is\nable to characterize temporal dynamics of electrical activity in this brain\nregion at the millisecond resolution while decisions are made and after\noutcomes are revealed.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 19:26:32 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Sacr\u00e9", "Pierre", ""], ["Kerr", "Matthew S. D.", ""], ["Subramanian", "Sandya", ""], ["Kahn", "Kevin", ""], ["Gonzalez-Martinez", "Jorge", ""], ["Johnson", "Matthew A.", ""], ["Gale", "John T.", ""], ["Sarma", "Sridevi V.", ""]]}, {"id": "1602.03764", "submitter": "Carmen Oana Tarniceriu", "authors": "Gr\\'egory Dumont, Jacques Henry and Carmen Oana Tarniceriu", "title": "Theoretical connections between mathematical neuronal models\n  corresponding to different expressions of noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying the right tools to express the stochastic aspects of neural\nactivity has proven to be one of the biggest challenges in computational\nneuroscience. Even if there is no definitive answer to this issue, the most\ncommon procedure to express this randomness is the use of stochastic models. In\naccordance with the origin of variability, the sources of randomness are\nclassified as intrinsic or extrinsic and give rise to distinct mathematical\nframeworks to track down the dynamics of the cell. While the external\nvariability is generally treated by the use of a Wiener process in models such\nas the Integrate-and-Fire model, the internal variability is mostly expressed\nvia a random firing process. In this paper, we investigate how those distinct\nexpressions of variability can be related. To do so, we examine the probability\ndensity functions to the corresponding stochastic models and investigate in\nwhat way they can be mapped one to another via integral transforms. Our\ntheoretical findings offer a new insight view into the particular categories of\nvariability and it confirms that, despite their contrasting nature, the\nmathematical formalization of internal and external variability are strikingly\nsimilar.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 15:40:09 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Dumont", "Gr\u00e9gory", ""], ["Henry", "Jacques", ""], ["Tarniceriu", "Carmen Oana", ""]]}, {"id": "1602.04019", "submitter": "Anders Sandberg", "authors": "Anders Sandberg", "title": "Energetics of the brain and AI", "comments": null, "journal-ref": null, "doi": null, "report-no": "STR 2016-2", "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Does the energy requirements for the human brain give energy constraints that\ngive reason to doubt the feasibility of artificial intelligence? This report\nwill review some relevant estimates of brain bioenergetics and analyze some of\nthe methods of estimating brain emulation energy requirements. Turning to AI,\nthere are reasons to believe the energy requirements for de novo AI to have\nlittle correlation with brain (emulation) energy requirements since cost could\ndepend merely of the cost of processing higher-level representations rather\nthan billions of neural firings. Unless one thinks the human way of thinking is\nthe most optimal or most easily implementable way of achieving software\nintelligence, we should expect de novo AI to make use of different, potentially\nvery compressed and fast, processes.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 11:32:59 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Sandberg", "Anders", ""]]}, {"id": "1602.04129", "submitter": "Carlo Baldassi", "authors": "Carlo Baldassi, Federica Gerace, Carlo Lucibello, Luca Saglietti,\n  Riccardo Zecchina", "title": "Learning may need only a few bits of synaptic precision", "comments": "38 pages (main text: 16 pages), 5 figures;\n  http://link.aps.org/doi/10.1103/PhysRevE.93.052313", "journal-ref": "Phys. Rev. E 93, 052313 (2016)", "doi": "10.1103/PhysRevE.93.052313", "report-no": null, "categories": "cond-mat.dis-nn q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning in neural networks poses peculiar challenges when using discretized\nrather then continuous synaptic states. The choice of discrete synapses is\nmotivated by biological reasoning and experiments, and possibly by hardware\nimplementation considerations as well. In this paper we extend a previous large\ndeviations analysis which unveiled the existence of peculiar dense regions in\nthe space of synaptic states which accounts for the possibility of learning\nefficiently in networks with binary synapses. We extend the analysis to\nsynapses with multiple states and generally more plausible biological features.\nThe results clearly indicate that the overall qualitative picture is unchanged\nwith respect to the binary case, and very robust to variation of the details of\nthe model. We also provide quantitative results which suggest that the\nadvantages of increasing the synaptic precision (i.e.~the number of internal\nsynaptic states) rapidly vanish after the first few bits, and therefore that,\nfor practical applications, only few bits may be needed for near-optimal\nperformance, consistently with recent biological findings. Finally, we\ndemonstrate how the theoretical analysis can be exploited to design efficient\nalgorithmic search strategies.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 17:27:15 GMT"}, {"version": "v2", "created": "Fri, 27 May 2016 18:45:51 GMT"}], "update_date": "2016-06-01", "authors_parsed": [["Baldassi", "Carlo", ""], ["Gerace", "Federica", ""], ["Lucibello", "Carlo", ""], ["Saglietti", "Luca", ""], ["Zecchina", "Riccardo", ""]]}, {"id": "1602.04742", "submitter": "Oleg Sinyavskiy", "authors": "Oleg Y. Sinyavskiy", "title": "Training of spiking neural networks based on information theoretic costs", "comments": "A doctoral thesis, 111 pages, 55 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking neural network is a type of artificial neural network in which\nneurons communicate between each other with spikes. Spikes are identical\nBoolean events characterized by the time of their arrival. A spiking neuron has\ninternal dynamics and responds to the history of inputs as opposed to the\ncurrent inputs only. Because of such properties a spiking neural network has\nrich intrinsic capabilities to process spatiotemporal data. However, because\nthe spikes are discontinuous 'yes or no' events, it is not trivial to apply\ntraditional training procedures such as gradient descend to the spiking\nneurons. In this thesis we propose to use stochastic spiking neuron models in\nwhich probability of a spiking output is a continuous function of parameters.\nWe formulate several learning tasks as minimization of certain\ninformation-theoretic cost functions that use spiking output probability\ndistributions. We develop a generalized description of the stochastic spiking\nneuron and a new spiking neuron model that allows to flexibly process rich\nspatiotemporal data. We formulate and derive learning rules for the following\ntasks:\n  - a supervised learning task of detecting a spatiotemporal pattern as a\nminimization of the negative log-likelihood (the surprisal) of the neuron's\noutput\n  - an unsupervised learning task of increasing the stability of neurons output\nas a minimization of the entropy\n  - a reinforcement learning task of controlling an agent as a modulated\noptimization of filtered surprisal of the neuron's output.\n  We test the derived learning rules in several experiments such as\nspatiotemporal pattern detection, spatiotemporal data storing and recall with\nautoassociative memory, combination of supervised and unsupervised learning to\nspeed up the learning process, adaptive control of simple virtual agents in\nchanging environments.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 17:21:00 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Sinyavskiy", "Oleg Y.", ""]]}, {"id": "1602.04776", "submitter": "Vince Grolmusz", "authors": "Bal\\'azs Szalkai and Csaba Kerepesi and B\\'alint Varga and Vince\n  Grolmusz", "title": "Parameterizable Consensus Connectomes from the Human Connectome Project:\n  The Budapest Reference Connectome Server v3.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Connections of the living human brain, on a macroscopic scale, can be mapped\nby a diffusion MR imaging based workflow. Since the same anatomic regions can\nbe corresponded between distinct brains, one can compare the presence or the\nabsence of the edges, connecting the very same two anatomic regions, among\nmultiple cortices. Previously, we have constructed the consensus braingraphs on\n1015 vertices first in five, then in 96 subjects in the Budapest Reference\nConnectome Server v1.0 and v2.0, respectively. Here we report the construction\nof the version 3.0 of the server, generating the common edges of the\nconnectomes of variously parameterizable subsets of the 1015-vertex connectomes\nof 477 subjects of the Human Connectome Project's 500-subject release. The\nconsensus connectomes are downloadable in csv and GraphML formats, and they are\nalso visualized on the server's page. The consensus connectomes of the server\ncan be considered as the \"average, healthy\" human connectome since all of their\nconnections are present in at least $k$ subjects, where the default value of\n$k=209$, but it can also be modified freely at the web server. The webserver is\navailable at \\url{http://connectome.pitgroup.org}.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 19:38:43 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Szalkai", "Bal\u00e1zs", ""], ["Kerepesi", "Csaba", ""], ["Varga", "B\u00e1lint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1602.05063", "submitter": "Robin Ince", "authors": "Robin A. A. Ince", "title": "Measuring multivariate redundant information with pointwise common\n  change in surprisal", "comments": "v3: revisions based on review process at Entropy (expand game-theory\n  and max-ent motivation), v2: add game-theoretic operational definition for\n  maximum entropy constraints; remove thresholding and normalisation of values\n  on lattice", "journal-ref": "Entropy 2017, 19(7), 318", "doi": "10.3390/e19070318", "report-no": null, "categories": "cs.IT math.IT math.ST q-bio.NC q-bio.QM stat.ME stat.TH", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The problem of how to properly quantify redundant information is an open\nquestion that has been the subject of much recent research. Redundant\ninformation refers to information about a target variable S that is common to\ntwo or more predictor variables Xi. It can be thought of as quantifying\noverlapping information content or similarities in the representation of S\nbetween the Xi. We present a new measure of redundancy which measures the\ncommon change in surprisal shared between variables at the local or pointwise\nlevel. We provide a game-theoretic operational definition of unique\ninformation, and use this to derive constraints which are used to obtain a\nmaximum entropy distribution. Redundancy is then calculated from this maximum\nentropy distribution by counting only those local co-information terms which\nadmit an unambiguous interpretation as redundant information. We show how this\nredundancy measure can be used within the framework of the Partial Information\nDecomposition (PID) to give an intuitive decomposition of the multivariate\nmutual information into redundant, unique and synergistic contributions. We\ncompare our new measure to existing approaches over a range of example systems,\nincluding continuous Gaussian variables. Matlab code for the measure is\nprovided, including all considered examples.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 15:57:36 GMT"}, {"version": "v2", "created": "Tue, 2 May 2017 10:32:28 GMT"}, {"version": "v3", "created": "Thu, 13 Jul 2017 16:54:30 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Ince", "Robin A. A.", ""]]}, {"id": "1602.05092", "submitter": "Andrea Barreiro", "authors": "Andrea K. Barreiro and J. Nathan Kutz and Eli Shlizerman", "title": "Symmetries constrain dynamics in a family of balanced neural networks", "comments": "In review; submitted 1/21/2016 Revision submitted 9/24/16", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine a family of random firing-rate neural networks in which we enforce\nthe neurobiological constraint of Dale's Law --- each neuron makes either\nexcitatory or inhibitory connections onto its post-synaptic targets. We find\nthat this constrained system may be described as a perturbation from a system\nwith non-trivial symmetries. We analyze the symmetric system using the tools of\nequivariant bifurcation theory, and demonstrate that the symmetry-implied\nstructures remain evident in the perturbed system. In comparison, spectral\ncharacteristics of the network coupling matrix are relatively uninformative\nabout the behavior of the constrained system.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 16:50:15 GMT"}, {"version": "v2", "created": "Sat, 24 Sep 2016 22:06:12 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Barreiro", "Andrea K.", ""], ["Kutz", "J. Nathan", ""], ["Shlizerman", "Eli", ""]]}, {"id": "1602.05220", "submitter": "Chris Eliasmith", "authors": "Chris Eliasmith and Jan Gosmann and Xuan Choo", "title": "BioSpaun: A large-scale behaving brain model with complex neurons", "comments": "17 pages 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a large-scale functional brain model that includes detailed,\nconductance-based, compartmental models of individual neurons. We call the\nmodel BioSpaun, to indicate the increased biological plausibility of these\nneurons, and because it is a direct extension of the Spaun model\n\\cite{Eliasmith2012b}. We demonstrate that including these detailed\ncompartmental models does not adversely affect performance across a variety of\ntasks, including digit recognition, serial working memory, and counting. We\nthen explore the effects of applying TTX, a sodium channel blocking drug, to\nthe model. We characterize the behavioral changes that result from this\nmolecular level intervention. We believe this is the first demonstration of a\nlarge-scale brain model that clearly links low-level molecular interventions\nand high-level behavior.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 22:09:07 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Eliasmith", "Chris", ""], ["Gosmann", "Jan", ""], ["Choo", "Xuan", ""]]}, {"id": "1602.05506", "submitter": "Sergio Lopes", "authors": "Thiago de Lima Prado, Gustavo Zampier dos Santos Lima, Bruno\n  Lob\\~ao-Soares, George Carlos do Nascimento, Gilberto Corso, Sergio Roberto\n  Lopes", "title": "Stationarity breaking in coupled physical systems revealed by recurrence\n  analysis", "comments": "After the review process, the authors do not agree that the paper\n  should be submitted to the arXv. So no future version of the text will be\n  uploaded", "journal-ref": null, "doi": null, "report-no": null, "categories": "nlin.AO nlin.CD q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this letter we explore how recurrence quantifier, the determinism\n($\\Delta$), can reveal stationarity breaking and coupling between physical\nsystems. We demonstrate that it is possible to detect small variations in a\ndynamical system based only on temporal signal displayed by another system\ncoupled to it. To introduce basic ideas, we consider a well known dynamical\nsystem composed of two master-slave coupled Lorenz oscillators. We start\nevidencing that due to the sensitivity of $\\Delta$ computed from temporal time\nseries of slave oscillator, its is possible to detect the stationary breaking\nimposed in the master oscillator. As a second example, the method is carried\nout in a real physiological data acquired from accelerometer sensors\n($\\mathrm{A_{cc}}$) and used to detect micro arousal phenomenology (described\nby a sharp burst in $\\mathrm{A_{cc}}$ signal) during sleep periods in mice.\nMoreover, we show for the first time that making use of recurrence quantifier\nit is possible to infer a coupling between electric signals from hippocampus\nand \"locomotor brain areas\" of mice, based only on non invasive data from\n$\\mathrm{A_{cc}}$. Our results suggest new possibilities of analysis of coupled\nsystems making use of accessible time series. Our second example supports an\ninterpretation of an internal coupling detectable as a stationarity breaking in\n$\\mathrm{A_{cc}}$ that occurs some seconds before micro arousal processes\nduring sleep periods in rodents, contributing to the idea that micro arousals\nare elements of sleep taking part in the regulation of sleep process. Such a\ncharacterization of micro arousals can improve our knowledge about sleep\nfostering tools of sleep diagnose and pharmacology research for mammals in\ngeneral.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 17:45:41 GMT"}, {"version": "v2", "created": "Tue, 5 Apr 2016 01:35:30 GMT"}], "update_date": "2016-04-06", "authors_parsed": [["Prado", "Thiago de Lima", ""], ["Lima", "Gustavo Zampier dos Santos", ""], ["Lob\u00e3o-Soares", "Bruno", ""], ["Nascimento", "George Carlos do", ""], ["Corso", "Gilberto", ""], ["Lopes", "Sergio Roberto", ""]]}, {"id": "1602.05925", "submitter": "Scott Purdy", "authors": "Scott Purdy", "title": "Encoding Data for HTM Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hierarchical Temporal Memory (HTM) is a biologically inspired machine\nintelligence technology that mimics the architecture and processes of the\nneocortex. In this white paper we describe how to encode data as Sparse\nDistributed Representations (SDRs) for use in HTM systems. We explain several\nexisting encoders, which are available through the open source project called\nNuPIC, and we discuss requirements for creating encoders for new types of data.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 19:56:39 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Purdy", "Scott", ""]]}, {"id": "1602.06057", "submitter": "Raghavendra Singh", "authors": "Raghavendra Singh", "title": "Uniresolution representations of white-matter data from CoCoMac", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tracing data as collated by CoCoMac, a seminal neuroinformatics database, is\nat multiple resolutions -- white matter tracts were studied for areas and their\nsubdivisions by different reports. Network theoretic analysis of this\nmulti-resolution data often assumes that the data at various resolutions is\nequivalent, which may not be correct. In this paper we propose three methods to\nresolve the multi-resolution issue such that the resultant networks have\nconnectivity data at only one resolution. The different resultant networks are\ncompared in terms of their network analysis metrics and degree distributions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2016 07:09:33 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Singh", "Raghavendra", ""]]}, {"id": "1602.06238", "submitter": "Byungjoon Min", "authors": "Kevin Roth, Flaviano Morone, Byungjoon Min, Hern\\'an A. Makse", "title": "Emergence of Robustness in Network of Networks", "comments": "5 pages, 2 figures", "journal-ref": "Phys. Rev. E 95, 062308 (2017)", "doi": "10.1103/PhysRevE.95.062308", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of interdependent networks of networks (NoN) has been introduced\nrecently in the context of brain activation to identify the neural collective\ninfluencers in the brain NoN. Here we develop a new approach to derive an exact\nexpression for the random percolation transition in Erd\\\"{o}s-R\\'enyi NoN.\nAnalytical calculations are in excellent agreement with numerical simulations\nand highlight the robustness of the NoN against random node failures.\nInterestingly, the phase diagram of the model unveils particular patterns of\ninterconnectivity for which the NoN is most vulnerable. Our results help to\nunderstand the emergence of robustness in such interdependent architectures.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 16:34:39 GMT"}, {"version": "v2", "created": "Mon, 20 Jun 2016 16:08:12 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Roth", "Kevin", ""], ["Morone", "Flaviano", ""], ["Min", "Byungjoon", ""], ["Makse", "Hern\u00e1n A.", ""]]}, {"id": "1602.06630", "submitter": "Haiping Huang", "authors": "Haiping Huang and Taro Toyoizumi", "title": "Clustering of neural codewords revealed by a first-order phase\n  transition", "comments": "14 pages, 5 figures in main text plus Supplemental Material (7 pages)", "journal-ref": "Phys. Rev. E 93, 062416 (2016)", "doi": "10.1103/PhysRevE.93.062416", "report-no": null, "categories": "q-bio.NC cond-mat.stat-mech physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A network of neurons in the central nervous system collectively represents\ninformation by its spiking activity states. Typically observed states, i.e.,\ncodewords, occupy only a limited portion of the state space due to constraints\nimposed by network interactions. Geometrical organization of codewords in the\nstate space, critical for neural information processing, is poorly understood\ndue to its high dimensionality. Here, we explore the organization of neural\ncodewords using retinal data by computing the entropy of codewords as a\nfunction of Hamming distance from a particular reference codeword.\nSpecifically, we report that the retinal codewords in the state space are\ndivided into multiple distinct clusters separated by entropy-gaps, and that\nthis structure is shared with well-known associative memory networks in a\nrecallable phase. Our analysis also elucidates a special nature of the\nall-silent state. The all-silent state is surrounded by the densest cluster of\ncodewords and located within a reachable distance from most codewords. This\ncodeword-space structure quantitatively predicts typical deviation of a\nstate-trajectory from its initial state. Altogether, our findings reveal a\nnon-trivial heterogeneous structure of the codeword-space that shapes\ninformation representation in a biological network.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 02:26:00 GMT"}], "update_date": "2016-06-30", "authors_parsed": [["Huang", "Haiping", ""], ["Toyoizumi", "Taro", ""]]}, {"id": "1602.06827", "submitter": "Carmen Alonso-Montes", "authors": "C. Alonso-Montes, I. Diez, L. Remaki, I. Escudero, B. Mateos, Y.\n  Rosseel, D. Marinazzo, S. Stramaglia, J. Cortes", "title": "Lagged and instantaneous dynamical influences related to brain\n  structural connectivity", "comments": "Accepted and published in Frontiers in Psychology in its current\n  form. 27 pages, 1 table, 5 figures, 2 suppl. figures", "journal-ref": "Published Frontiers in Psychology 6:1024, 2015", "doi": "10.3389/fpsyg.2015.01024", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary neuroimaging methods can shed light on the basis of human neural\nand cognitive specializations, with important implications for neuroscience and\nmedicine. Different MRI acquisitions provide different brain networks at the\nmacroscale; whilst diffusion-weighted MRI (dMRI) provides a structural\nconnectivity (SC) coincident with the bundles of parallel fibers between brain\nareas, functional MRI (fMRI) accounts for the variations in the\nblood-oxygenation-level-dependent T2* signal, providing functional connectivity\n(FC).Understanding the precise relation between FC and SC, that is, between\nbrain dynamics and structure, is still a challenge for neuroscience. To\ninvestigate this problem, we acquired data at rest and built the corresponding\nSC (with matrix elements corresponding to the fiber number between brain areas)\nto be compared with FC connectivity matrices obtained by 3 different methods:\ndirected dependencies by an exploratory version of structural equation modeling\n(eSEM), linear correlations (C) and partial correlations (PC). We also\nconsidered the possibility of using lagged correlations in time series; so, we\ncompared a lagged version of eSEM and Granger causality (GC). Our results were\ntwo-fold: firstly, eSEM performance in correlating with SC was comparable to\nthose obtained from C and PC, but eSEM (not C nor PC) provides information\nabout directionality of the functional interactions. Second, interactions on a\ntime scale much smaller than the sampling time, captured by instantaneous\nconnectivity methods, are much more related to SC than slow directed influences\ncaptured by the lagged analysis. Indeed the performance in correlating with SC\nwas much worse for GC and for the lagged version of eSEM. We expect these\nresults to supply further insights to the interplay between SC and functional\npatterns, an important issue in the study of brain physiology and function.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 15:44:06 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Alonso-Montes", "C.", ""], ["Diez", "I.", ""], ["Remaki", "L.", ""], ["Escudero", "I.", ""], ["Mateos", "B.", ""], ["Rosseel", "Y.", ""], ["Marinazzo", "D.", ""], ["Stramaglia", "S.", ""], ["Cortes", "J.", ""]]}, {"id": "1602.07100", "submitter": "Koen Haak", "authors": "Koen V. Haak, Andre F. Marquand, Christian F. Beckmann", "title": "Connectopic mapping with resting-state fMRI", "comments": null, "journal-ref": null, "doi": "10.1016/j.neuroimage.2017.06.075", "report-no": null, "categories": "q-bio.QM q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain regions are often topographically connected: nearby locations within\none brain area connect with nearby locations in another area. Mapping these\nconnection topographies, or 'connectopies' in short, is crucial for\nunderstanding how information is processed in the brain. Here, we propose\nprincipled, fully data-driven methods for mapping connectopies using functional\nmagnetic resonance imaging (fMRI) data acquired at rest by combining spectral\nembedding of voxel-wise connectivity 'fingerprints' with a novel approach to\nspatial statistical inference. We applied the approach in human primary motor\nand visual cortex, and show that it can trace biologically plausible,\noverlapping connectopies in individual subjects that follow these regions'\nsomatotopic and retinotopic maps. As a generic mechanism to perform inference\nover connectopies, the new spatial statistics approach enables rigorous\nstatistical testing of hypotheses regarding the fine-grained spatial profile of\nfunctional connectivity and whether that profile is different between subjects\nor between experimental conditions. The combined framework offers a fundamental\nalternative to existing approaches to investigating functional connectivity in\nthe brain, from voxel- or seed-pair wise characterizations of functional\nassociation, towards a full, multivariate characterization of spatial\ntopography.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 09:35:34 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 09:39:28 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Haak", "Koen V.", ""], ["Marquand", "Andre F.", ""], ["Beckmann", "Christian F.", ""]]}, {"id": "1602.07311", "submitter": "Andreas Spiegler", "authors": "Andreas Spiegler, Enrique C.A. Hansen, Christophe Bernard, Anthony R.\n  McIntosh, Viktor K. Jirsa", "title": "Selective activation of resting state networks following focal\n  stimulation in a connectome- based network model of the human brain", "comments": "25 pages (in total), 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imaging studies suggest that the functional connectivity patterns of resting\nstate networks (RS-networks) reflect underlying structural connectivity (SC).\nIf the connectome constrains how brain areas are functionally connected, the\nstimulation of specific brain areas should produce a characteristic wave of\nactivity ultimately resolving into RS-networks. To systematically test this\nhypothesis, we use a connectome-based network model of the human brain with\ndetailed realistic SC. We systematically activate all possible thalamic and\ncortical areas with focal stimulation patterns and confirm that the stimulation\nof specific areas evokes network patterns that closely resemble RS-networks.\nFor some sites, one or no RS-network is engaged, whereas for other sites more\nthan one RS-network may evolve. Our results confirm that the brain is operating\nat the edge of criticality, wherein stimulation produces a cascade of\nfunctional network recruitments, collapsing onto a smaller subspace that is\nconstrained in part by the anatomical local and long-range SCs. We suggest that\ninformation flow, and subsequent cognitive processing, follows specific routes\nimposed by connectome features, and that these routes explain the emergence of\nRS-networks. Since brain stimulation can be used to diagnose/treat neurological\ndisorders, we provide a look-up table showing which areas need to be stimulated\nto activate specific RS-networks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 21:03:04 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Spiegler", "Andreas", ""], ["Hansen", "Enrique C. A.", ""], ["Bernard", "Christophe", ""], ["McIntosh", "Anthony R.", ""], ["Jirsa", "Viktor K.", ""]]}, {"id": "1602.07389", "submitter": "Alison Weber", "authors": "Alison I. Weber and Jonathan W. Pillow", "title": "Capturing the dynamical repertoire of single neurons with generalized\n  linear models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key problem in computational neuroscience is to find simple, tractable\nmodels that are nevertheless flexible enough to capture the response properties\nof real neurons. Here we examine the capabilities of recurrent point process\nmodels known as Poisson generalized linear models (GLMs). These models are\ndefined by a set of linear filters, a point nonlinearity, and conditionally\nPoisson spiking. They have desirable statistical properties for fitting and\nhave been widely used to analyze spike trains from electrophysiological\nrecordings. However, the dynamical repertoire of GLMs has not been\nsystematically compared to that of real neurons. Here we show that GLMs can\nreproduce a comprehensive suite of canonical neural response behaviors,\nincluding tonic and phasic spiking, bursting, spike rate adaptation, type I and\ntype II excitation, and two forms of bistability. GLMs can also capture\nstimulus-dependent changes in spike timing precision and reliability that mimic\nthose observed in real neurons, and can exhibit varying degrees of\nstochasticity, from virtually deterministic responses to greater-than-Poisson\nvariability. These results show that Poisson GLMs can exhibit a wide range of\ndynamic spiking behaviors found in real neurons, making them well suited for\nqualitative dynamical as well as quantitative statistical studies of\nsingle-neuron and population response properties.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 04:20:13 GMT"}, {"version": "v2", "created": "Thu, 23 Mar 2017 21:03:33 GMT"}, {"version": "v3", "created": "Fri, 7 Jul 2017 20:22:20 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Weber", "Alison I.", ""], ["Pillow", "Jonathan W.", ""]]}, {"id": "1602.07625", "submitter": "Gorka Zamora-L\\'opez", "authors": "Gorka Zamora-L\\'opez, Yuhan Chen, Gustavo Deco, Morten L. Kringelbach,\n  and Changsong Zhou", "title": "Functional complexity emerging from anatomical constraints in the brain:\n  the significance of network modularity and rich-clubs", "comments": null, "journal-ref": "Scientific Reports 2016", "doi": "10.1038/srep38424", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large-scale structural ingredients of the brain and neural connectomes\nhave been identified in recent years. These are, similar to the features found\nin many other real networks: the arrangement of brain regions into modules and\nthe presence of highly connected regions (hubs) forming rich-clubs. Here, we\nexamine how modules and hubs shape the collective dynamics on networks and we\nfind that both ingredients lead to the emergence of complex dynamics. Comparing\nthe connectomes of C. elegans, cats, macaques and humans to surrogate networks\nin which either modules or hubs are destroyed, we find that functional\ncomplexity always decreases in the perturbed networks. A comparison between\nsimulated and empirically obtained resting-state functional connectivity\nindicates that the human brain, at rest, lies in a dynamical state that\nreflects the largest complexity its anatomical connectome can host. Last, we\ngeneralise the topology of neural connectomes into a new hierarchical network\nmodel that successfully combines modular organisation with rich-club forming\nhubs. This is achieved by centralising the cross-modular connections through a\npreferential attachment rule. Our network model hosts more complex dynamics\nthan other hierarchical models widely used as benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 18:10:43 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 22:36:28 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["Zamora-L\u00f3pez", "Gorka", ""], ["Chen", "Yuhan", ""], ["Deco", "Gustavo", ""], ["Kringelbach", "Morten L.", ""], ["Zhou", "Changsong", ""]]}, {"id": "1602.07642", "submitter": "Olga Vasieva", "authors": "Olga Vasieva, Sultan Cetiner, Abigail Savage, Gerald G. Schumann,\n  Vivien J Bubb, John P Quinn", "title": "Primate specific retrotransposons, SVAs, in the evolution of networks\n  that alter brain function", "comments": "Main body: 22 pages, 5 figures, 2 tables, pages 22-48- Supplemmentary\n  material (5 tables)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.GN q-bio.MN q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hominid-specific non-LTR retrotransposon termed SINE VNTR Alu (SVA) is\nthe youngest of the transposable elements in the human genome. The propagation\nof the most ancient SVA type A took place about thirteen millions years ago\nago, and the youngest SVA types appeared in the human genome after the\nchimpanzee divergence. Functional enrichment analysis of genes associated with\nSVA insertions demonstrated their strong link to multiple ontological\ncategories attributed to brain function and the disorders. SVA types that\nexpanded their presence in the human genome at different stages of hominoid\nlife history were also associated with progressively evolving behavioural\nfeatures that indicated a potential impact of SVA propagation on a cognitive\nability of a modern human. The SVA-associated genes were highly cross-linked in\nfunctional networks suggesting an accumulative impact of functional alterations\npotentially caused by SVA insertions. Our analysis uncovered a potential role\nof SVAs in evolution of human CNS and especially emergence of functional trends\nrelevant to social and parental behaviour. It also supports models which\nexplain in part how brain function can be modulated by both the immune and\nreproductive systems based on the gene expression patterns and gene pathways\npotentially altered by SVA insertions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2016 19:20:00 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2016 19:14:13 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Vasieva", "Olga", ""], ["Cetiner", "Sultan", ""], ["Savage", "Abigail", ""], ["Schumann", "Gerald G.", ""], ["Bubb", "Vivien J", ""], ["Quinn", "John P", ""]]}, {"id": "1602.08299", "submitter": "Haiping Huang", "authors": "Haiping Huang", "title": "Theory of population coupling and applications to describe high order\n  correlations in large populations of interacting neurons", "comments": "14 pages, 8 figures, Journal of Statistical Mechanics: Theory and\n  Experiment (in press)", "journal-ref": "J. Stat. Mech. (2017) 033501", "doi": "10.1088/1742-5468/aa5dc8", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand the collective spiking activity in neuronal populations, it is\nessential to reveal basic circuit variables responsible for these emergent\nfunctional states. Here, I develop a mean field theory for the population\ncoupling recently proposed in the studies of visual cortex of mouse and monkey,\nrelating the individual neuron activity to the population activity, and extend\nthe original form to the second order, relating neuron-pair's activity to the\npopulation activity, to explain the high order correlations observed in the\nneural data. I test the computational framework on the salamander retinal data\nand the cortical spiking data of behaving rats. For the retinal data, the\noriginal form of population coupling and its advanced form can explain a\nsignificant fraction of two-cell correlations and three-cell correlations,\nrespectively. For the cortical data, the performance becomes much better, and\nthe second order population coupling reveals non-local effects in local\ncortical circuits.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 12:50:58 GMT"}, {"version": "v2", "created": "Tue, 21 Jun 2016 08:38:30 GMT"}, {"version": "v3", "created": "Wed, 1 Feb 2017 01:21:09 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Huang", "Haiping", ""]]}, {"id": "1602.08417", "submitter": "Nicolas Gauvrit", "authors": "Nicolas Gauvrit and Fabien Mathy", "title": "Mathematical transcription of the \"Time-Based Resource Sharing\" theory\n  of working memory", "comments": "21 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The time-based resource sharing (TBRS) model is a prominent model of working\nmemory that is both predictive and simple. The TBRS is the mainstream\ndecay-based model and the most susceptible to competition with\ninterference-based models. A connectionist implementation of the TBRS, the\nTBRS*, has recently been developed. However, the TBRS* is an enriched version\nof the TBRS, making it difficult to test the general characteristics resulting\nfrom the TBRS assumptions. Here, we describe a novel model, the TBRS2, built to\nbe more transparent and simple than the TBRS*. The TBRS2 is minimalist and\nallows only a few parameters. It is a straightforward mathematical\ntranscription of the TBRS that focuses exclusively on the activation level of\nmemory items as a function of time. Its simplicity makes it possible to derive\nseveral theorems from the original TBRS and allows several variants of the\nrefreshing process to be tested without relying on particular architectures.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jan 2016 16:05:53 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Gauvrit", "Nicolas", ""], ["Mathy", "Fabien", ""]]}, {"id": "1602.08486", "submitter": "Garrison Cottrell", "authors": "Honghao Shan, Matthew H. Tong, Garrison W. Cottrell", "title": "A Single Model Explains both Visual and Auditory Precortical Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Precortical neural systems encode information collected by the senses, but\nthe driving principles of the encoding used have remained a subject of debate.\nWe present a model of retinal coding that is based on three constraints:\ninformation preservation, minimization of the neural wiring, and response\nequalization. The resulting novel version of sparse principal components\nanalysis successfully captures a number of known characteristics of the retinal\ncoding system, such as center-surround receptive fields, color opponency\nchannels, and spatiotemporal responses that correspond to magnocellular and\nparvocellular pathways. Furthermore, when trained on auditory data, the same\nmodel learns receptive fields well fit by gammatone filters, commonly used to\nmodel precortical auditory coding. This suggests that efficient coding may be a\nunifying principle of precortical encoding across modalities.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 10:17:53 GMT"}, {"version": "v2", "created": "Thu, 7 Apr 2016 19:19:11 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Shan", "Honghao", ""], ["Tong", "Matthew H.", ""], ["Cottrell", "Garrison W.", ""]]}, {"id": "1602.08530", "submitter": "Vijay Singh", "authors": "Vijay Singh, Martin Tchernookov, Ilya Nemenman", "title": "Extrinsic and intrinsic correlations in molecular information\n  transmission", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": "10.1103/PhysRevE.94.022425", "report-no": null, "categories": "q-bio.NC physics.bio-ph q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cells measure concentrations of external ligands by capturing ligand\nmolecules with cell surface receptors. The numbers of molecules captured by\ndifferent receptors co-vary because they depend on the same extrinsic ligand\nfluctuations. However, these numbers also counter-vary due to the intrinsic\nstochasticity of chemical processes because a single molecule randomly captured\nby a receptor cannot be captured by another. Such structure of receptor\ncorrelations is generally believed to lead to an increase in information about\nthe external signal compared to the case of independent receptors. We analyze a\nsolvable model of two molecular receptors and show that, contrary to this\nwidespread expectation, the correlations have a small and negative effect on\nthe information about the ligand concentration. Further, we show that\nmeasurements that average over multiple receptors are almost as informative as\nthose that track the states of every individual one.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 23:46:03 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Singh", "Vijay", ""], ["Tchernookov", "Martin", ""], ["Nemenman", "Ilya", ""]]}, {"id": "1602.08881", "submitter": "Christopher Buckley", "authors": "Christopher L. Buckley, Satohiro Tajima, Toru Yanagawa, Kana Takakura,\n  Yasuo Nagasaka, Naotaka Fujii, and Taro Toyoizumi", "title": "Brain State Control by Closed-Loop Environmental Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Brain state regulates sensory processing and motor control for adaptive\nbehavior. Internal mechanisms of brain state control are well studied, but the\nrole of external modulation from the environment is not well understood. Here,\nwe examined the role of closed-loop environmental (CLE) feedback, in comparison\nto open-loop sensory input, on brain state and behavior in diverse vertebrate\nsystems. In fictively swimming zebrafish, CLE feedback for optomotor stability\ncontrolled brain state by reducing coherent neuronal activity. The role of CLE\nfeedback in brain state was also shown in a model of rodent active whisking,\nwhere brief interruptions in this feedback enhanced signal-to-noise ratio for\ndetecting touch. Finally, in monkey visual fixation, artificial CLE feedback\nsuppressed stimulus-specific neuronal activity and improved behavioral\nperformance. Our findings show that the environment mediates continuous\nclosed-loop feedback that controls neuronal gain, regulating brain state, and\nthat brain function is an emergent property of brain-environment interactions.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 09:35:07 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Buckley", "Christopher L.", ""], ["Tajima", "Satohiro", ""], ["Yanagawa", "Toru", ""], ["Takakura", "Kana", ""], ["Nagasaka", "Yasuo", ""], ["Fujii", "Naotaka", ""], ["Toyoizumi", "Taro", ""]]}]