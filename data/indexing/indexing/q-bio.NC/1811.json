[{"id": "1811.00231", "submitter": "Benjamin Lansdell", "authors": "Benjamin James Lansdell and Konrad Paul Kording", "title": "Towards learning-to-learn", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In good old-fashioned artificial intelligence (GOFAI), humans specified\nsystems that solved problems. Much of the recent progress in AI has come from\nreplacing human insights by learning. However, learning itself is still usually\nbuilt by humans -- specifically the choice that parameter updates should follow\nthe gradient of a cost function. Yet, in analogy with GOFAI, there is no reason\nto believe that humans are particularly good at defining such learning systems:\nwe may expect learning itself to be better if we learn it. Recent research in\nmachine learning has started to realize the benefits of that strategy. We\nshould thus expect this to be relevant for neuroscience: how could the correct\nlearning rules be acquired? Indeed, cognitive science has long shown that\nhumans learn-to-learn, which is potentially responsible for their impressive\nlearning abilities. Here we discuss ideas across machine learning,\nneuroscience, and cognitive science that matter for the principle of\nlearning-to-learn.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 05:07:49 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 14:33:21 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2019 15:45:11 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Lansdell", "Benjamin James", ""], ["Kording", "Konrad Paul", ""]]}, {"id": "1811.00688", "submitter": "Ruochen Yang", "authors": "Ruochen Yang, Gaurav Gupta, Paul Bogdan", "title": "Data-driven Perception of Neuron Point Process with Unknown Unknowns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identification of patterns from discrete data time-series for statistical\ninference, threat detection, social opinion dynamics, brain activity prediction\nhas received recent momentum. In addition to the huge data size, the associated\nchallenges are, for example, (i) missing data to construct a closed\ntime-varying complex network, and (ii) contribution of unknown sources which\nare not probed. Towards this end, the current work focuses on statistical\nneuron system model with multi-covariates and unknown inputs. Previous research\nof neuron activity analysis is mainly limited with effects from the spiking\nhistory of target neuron and the interaction with other neurons in the system\nwhile ignoring the influence of unknown stimuli. We propose to use unknown\nunknowns, which describes the effect of unknown stimuli, undetected neuron\nactivities and all other hidden sources of error. The maximum likelihood\nestimation with the fixed-point iteration method is implemented. The\nfixed-point iterations converge fast, and the proposed methods can be\nefficiently parallelized and offer computational advantage especially when the\ninput spiking trains are over long time-horizon. The developed framework\nprovides an intuition into the meaning of having extra degrees-of-freedom in\nthe data to support the need for unknowns. The proposed algorithm is applied to\nsimulated spike trains and on real-world experimental data of mouse\nsomatosensory, mouse retina and cat retina. The model shows a successful\nincreasing of system likelihood with respect to the conditional intensity\nfunction, and it also reveals the convergence with iterations. Results suggest\nthat the neural connection model with unknown unknowns can efficiently estimate\nthe statistical properties of the process by increasing the network likelihood.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 00:42:25 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 06:12:36 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Yang", "Ruochen", ""], ["Gupta", "Gaurav", ""], ["Bogdan", "Paul", ""]]}, {"id": "1811.00738", "submitter": "Quanying Liu", "authors": "Quanying Liu, Yorie Nakahira, Ahkeel Mohideen, Adam Dai, Sunghoon\n  Choi, Angelina Pan, Dimitar M. Ho, John C. Doyle", "title": "WheelCon: A wheel control-based gaming platform for studying human\n  sensorimotor control", "comments": "20 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Feedback control theory has been extensively implemented to theoretically\nmodel human sensorimotor control. However, experimental platforms capable of\nmanipulating important components of multiple feedback loops lack development.\nThis paper describes the WheelCon, which is an open source platform aimed at\nresolving such insufficiencies. WheelCon enables safely simulation of the\ncanonical sensorimotor task such as riding a mountain bike down a steep,\ntwisting, bumpy trail etc., with provided only a computer, standard display,\nand an inexpensive gaming steering wheel with a force feedback motor. The\nplatform provides flexibility, as will be demonstrated in the demos provided,\nso that researchers may manipulate the disturbances, delay, and quantization\n(data rate) in the layered feedback loops, including a high-level advanced plan\nlayer and a low-level delayed reflex layer. In this paper, we illustrate\nWheelCon's graphical user interface (GUI), the input and output of existing\ndemos, and how to design new games. In addition, we present the basic feedback\nmodel, and we show the testing results from our demo games which align well\nwith prediction from the model. In short, the platform is featured as cheap,\nsimple to use, and flexible to program for effective sensorimotor neuroscience\nresearch and control engineering education.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 05:00:15 GMT"}, {"version": "v2", "created": "Mon, 25 Feb 2019 21:00:42 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Liu", "Quanying", ""], ["Nakahira", "Yorie", ""], ["Mohideen", "Ahkeel", ""], ["Dai", "Adam", ""], ["Choi", "Sunghoon", ""], ["Pan", "Angelina", ""], ["Ho", "Dimitar M.", ""], ["Doyle", "John C.", ""]]}, {"id": "1811.00875", "submitter": "Sandro Sozzo", "authors": "Sandro Sozzo", "title": "Quantum Structures in Human Decision-making: Towards Quantum Expected\n  Utility", "comments": "13 pages, 1 figure, standard LateX", "journal-ref": null, "doi": "10.1007/s10773-019-04022-w", "report-no": null, "categories": "cs.AI econ.GN q-bio.NC q-fin.EC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  {\\it Ellsberg thought experiments} and empirical confirmation of Ellsberg\npreferences pose serious challenges to {\\it subjective expected utility theory}\n(SEUT). We have recently elaborated a quantum-theoretic framework for human\ndecisions under uncertainty which satisfactorily copes with the Ellsberg\nparadox and other puzzles of SEUT. We apply here the quantum-theoretic\nframework to the {\\it Ellsberg two-urn example}, showing that the paradox can\nbe explained by assuming a state change of the conceptual entity that is the\nobject of the decision ({\\it decision-making}, or {\\it DM}, {\\it entity}) and\nrepresenting subjective probabilities by quantum probabilities. We also model\nthe empirical data we collected in a DM test on human participants within the\ntheoretic framework above. The obtained results are relevant, as they provide a\nline to model real life, e.g., financial and medical, decisions that show the\nsame empirical patterns as the two-urn experiment.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 12:29:51 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Sozzo", "Sandro", ""]]}, {"id": "1811.00915", "submitter": "Matthias Eberlein", "authors": "Matthias Eberlein, Raphael Hildebrand, Ronald Tetzlaff, Nico Hoffmann,\n  Levin Kuhlmann, Benjamin Brinkmann and Jens M\\\"uller", "title": "Convolutional Neural Networks for Epileptic Seizure Prediction", "comments": "accepted for MLESP 2018", "journal-ref": "2018 IEEE International Conference on Bioinformatics and\n  Biomedicine (BIBM)", "doi": "10.1109/BIBM.2018.8621225", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Epilepsy is the most common neurological disorder and an accurate forecast of\nseizures would help to overcome the patient's uncertainty and helplessness. In\nthis contribution, we present and discuss a novel methodology for the\nclassification of intracranial electroencephalography (iEEG) for seizure\nprediction. Contrary to previous approaches, we categorically refrain from an\nextraction of hand-crafted features and use a convolutional neural network\n(CNN) topology instead for both the determination of suitable signal\ncharacteristics and the binary classification of preictal and interictal\nsegments. Three different models have been evaluated on public datasets with\nlong-term recordings from four dogs and three patients. Overall, our findings\ndemonstrate the general applicability. In this work we discuss the strengths\nand limitations of our methodology.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:09:18 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 13:58:56 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Eberlein", "Matthias", ""], ["Hildebrand", "Raphael", ""], ["Tetzlaff", "Ronald", ""], ["Hoffmann", "Nico", ""], ["Kuhlmann", "Levin", ""], ["Brinkmann", "Benjamin", ""], ["M\u00fcller", "Jens", ""]]}, {"id": "1811.00941", "submitter": "Yuri A. Dabaghian", "authors": "Andrey Babichev, Dmitriy Morozov and Yuri Dabaghian", "title": "Replays of spatial memories suppress topological fluctuations in\n  cognitive map", "comments": "21 pages, 5 figures, 3 supplementary figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spiking activity of the hippocampal place cells plays a key role in\nproducing and sustaining an internalized representation of the ambient\nspace---a cognitive map. These cells do not only exhibit location-specific\nspiking during navigation, but also may rapidly replay the navigated routs\nthrough endogenous dynamics of the hippocampal network. Physiologically, such\nreactivations are viewed as manifestations of \"memory replays\" that help to\nlearn new information and to consolidate previously acquired memories by\nreinforcing synapses in the parahippocampal networks. Below we propose a\ncomputational model of these processes that allows assessing the effect of\nreplays on acquiring a robust topological map of the environment and\ndemonstrate that replays may play a key role in stabilizing the hippocampal\nrepresentation of space.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 15:43:40 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Babichev", "Andrey", ""], ["Morozov", "Dmitriy", ""], ["Dabaghian", "Yuri", ""]]}, {"id": "1811.01043", "submitter": "Fatma Deniz PhD", "authors": "Michael C.-K. Wu and Fatma Deniz and Ryan J. Prenger and Jack L.\n  Gallant", "title": "The unified maximum a posteriori (MAP) framework for neuronal system\n  identification", "comments": "affiliations changed", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The functional relationship between an input and a sensory neuron's response\ncan be described by the neuron's stimulus-response mapping function. A general\napproach for characterizing the stimulus-response mapping function is called\nsystem identification. Many different names have been used for the\nstimulus-response mapping function: kernel or transfer function, transducer,\nspatiotemporal receptive field. Many algorithms have been developed to estimate\na neuron's mapping function from an ensemble of stimulus-response pairs. These\ninclude the spike-triggered average, normalized reverse correlation, linearized\nreverse correlation, ridge regression, local spectral reverse correlation,\nspike-triggered covariance, artificial neural networks, maximally informative\ndimensions, kernel regression, boosting, and models based on leaky\nintegrate-and-fire neurons. Because many of these system identification\nalgorithms were developed in other disciplines, they seem very different\nsuperficially and bear little relationship with each other. Each algorithm\nmakes different assumptions about the neuron and how the data is generated.\nWithout a unified framework it is difficult to select the most suitable\nalgorithm for estimating the neuron's mapping function. In this review, we\npresent a unified framework for describing these algorithms called maximum a\nposteriori estimation (MAP). In the MAP framework, the implicit assumptions\nbuilt into any system identification algorithm are made explicit in three MAP\nconstituents: model class, noise distributions, and priors. Understanding the\ninterplay between these three MAP constituents will simplify the task of\nselecting the most appropriate algorithms for a given data set. The MAP\nframework can also facilitate the development of novel system identification\nalgorithms by incorporating biophysically plausible assumptions and mechanisms\ninto the MAP constituents.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 15:13:09 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 20:16:30 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Wu", "Michael C. -K.", ""], ["Deniz", "Fatma", ""], ["Prenger", "Ryan J.", ""], ["Gallant", "Jack L.", ""]]}, {"id": "1811.01199", "submitter": "Christoph von der Malsburg", "authors": "Christoph von der Malsburg", "title": "Concerning the Neural Code", "comments": "28 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The central problem with understanding brain and mind is the neural code\nissue: understanding the matter of our brain as basis for the phenomena of our\nmind. The richness with which our mind represents our environment, the\nparsimony of genetic data, the tremendous efficiency with which the brain\nlearns from scant sensory input and the creativity with which our mind\nconstructs mental worlds all speak in favor of mind as an emergent phenomenon.\nThis raises the further issue of how the neural code supports these processes\nof organization. The central point of this communication is that the neural\ncode has the form of structured net fragments that are formed by network\nself-organization, activate and de-activate on the functional time scale, and\nspontaneously combine to form larger nets with the same basic structure.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 12:35:44 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["von der Malsburg", "Christoph", ""]]}, {"id": "1811.01701", "submitter": "Ahsan Adeel", "authors": "Ahsan Adeel", "title": "Role of Awareness and Universal Context in a Spiking Conscious Neural\n  Network (SCNN): A New Perspective and Future Directions", "comments": "Neural Computation | MIT Press Journals (In-Process)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Awareness plays a major role in human cognition and adaptive behaviour,\nthough mechanisms involved remain unknown. Awareness is not an objectively\nestablished fact, therefore, despite extensive research, scientists have not\nbeen able to fully interpret its contribution in multisensory integration and\nprecise neural firing, hence, questions remain: (1) How the biological neuron\nintegrates the incoming multisensory signals with respect to different\nsituations? (2) How are the roles of incoming multisensory signals defined\n(selective amplification/attenuation) that help neuron(s) to originate a\nprecise neural firing complying with the anticipated behavioural-constraint of\nthe environment? (3) How are the external environment and anticipated behaviour\nintegrated? Recently, scientists have exploited deep learning to integrate\nmultimodal cues and capture context-dependent meanings. Yet, these methods\nsuffer from imprecise behavioural representation. In this research, we\nintroduce a new theory on the role of awareness and universal context that can\nhelp answering the aforementioned crucial neuroscience questions. Specifically,\nwe propose a class of spiking conscious neuron in which the output depends on\nthree functionally distinctive integrated input variables: receptive field\n(RF), local contextual field (LCF), and universal contextual field (UCF). The\nRF defines the incoming ambiguous sensory signal, LCF defines the modulatory\nsignal coming from other parts of the brain, and UCF defines the awareness. It\nis believed that the conscious neuron inherently contains enough knowledge\nabout the situation in which the problem is to be solved based on past learning\nand reasoning and it defines the precise role of incoming multisensory signals\nto originate a precise neural firing (exhibiting switch-like behaviour). It is\nshown that the conscious neuron helps modelling a more precise human behaviour.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:12:23 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Adeel", "Ahsan", ""]]}, {"id": "1811.01757", "submitter": "Nikolaos Passalis", "authors": "Angeliki Papadimitriou, Nikolaos Passalis and Anastasios Tefas", "title": "Decoding Generic Visual Representations From Human Brain Activity using\n  Machine Learning", "comments": "Accepted at 1st Workshop on Brain-Driven Computer Vision - ECCV 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the most impressive recent applications of neural decoding is the\nvisual representation decoding, where the category of an object that a subject\neither sees or imagines is inferred by observing his/her brain activity. Even\nthough there is an increasing interest in the aforementioned visual\nrepresentation decoding task, there is no extensive study of the effect of\nusing different machine learning models on the decoding accuracy. In this paper\nwe provide an extensive evaluation of several machine learning models, along\nwith different similarity metrics, for the aforementioned task, drawing many\ninteresting conclusions. That way, this paper a) paves the way for developing\nmore advanced and accurate methods and b) provides an extensive and easily\nreproducible baseline for the aforementioned decoding task.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 14:48:15 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Papadimitriou", "Angeliki", ""], ["Passalis", "Nikolaos", ""], ["Tefas", "Anastasios", ""]]}, {"id": "1811.02290", "submitter": "Zhaofei Yu", "authors": "Qi Yan, Yajing Zheng, Shanshan Jia, Yichen Zhang, Zhaofei Yu, Feng\n  Chen, Yonghong Tian, Tiejun Huang, Jian K. Liu", "title": "Revealing Fine Structures of the Retinal Receptive Field by Deep\n  Learning Networks", "comments": "updated version", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks (CNNs) have demonstrated impressive\nperformance on many visual tasks. Recently, they became useful models for the\nvisual system in neuroscience. However, it is still not clear what are learned\nby CNNs in terms of neuronal circuits. When a deep CNN with many layers is used\nfor the visual system, it is not easy to compare the structure components of\nCNNs with possible neuroscience underpinnings due to highly complex circuits\nfrom the retina to higher visual cortex. Here we address this issue by focusing\non single retinal ganglion cells with biophysical models and recording data\nfrom animals. By training CNNs with white noise images to predict neuronal\nresponses, we found that fine structures of the retinal receptive field can be\nrevealed. Specifically, convolutional filters learned are resembling biological\ncomponents of the retinal circuit. This suggests that a CNN learning from one\nsingle retinal cell reveals a minimal neural network carried out in this cell.\nFurthermore, when CNNs learned from different cells are transferred between\ncells, there is a diversity of transfer learning performance, which indicates\nthat CNNs are cell-specific. Moreover, when CNNs are transferred between\ndifferent types of input images, here white noise v.s. natural images, transfer\nlearning shows a good performance, which implies that CNNs indeed capture the\nfull computational ability of a single retinal cell for different inputs. Taken\ntogether, these results suggest that CNNs could be used to reveal structure\ncomponents of neuronal circuits, and provide a powerful model for neural system\nidentification.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 11:20:46 GMT"}, {"version": "v2", "created": "Tue, 18 Feb 2020 11:49:38 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Yan", "Qi", ""], ["Zheng", "Yajing", ""], ["Jia", "Shanshan", ""], ["Zhang", "Yichen", ""], ["Yu", "Zhaofei", ""], ["Chen", "Feng", ""], ["Tian", "Yonghong", ""], ["Huang", "Tiejun", ""], ["Liu", "Jian K.", ""]]}, {"id": "1811.02459", "submitter": "Daniel Hernandez Diaz", "authors": "Daniel Hernandez, Antonio Khalil Moretti, Ziqiang Wei, Shreya Saxena,\n  John Cunningham and Liam Paninski", "title": "Nonlinear Evolution via Spatially-Dependent Linear Dynamics for\n  Electrophysiology and Calcium Data", "comments": "8 figs, Accepted at NBDT", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.LG q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent variable models have been widely applied for the analysis of time\nseries resulting from experimental neuroscience techniques. In these datasets,\nobservations are relatively smooth and possibly nonlinear. We present\nVariational Inference for Nonlinear Dynamics (VIND), a variational inference\nframework that is able to uncover nonlinear, smooth latent dynamics from\nsequential data. The framework is a direct extension of PfLDS; including a\nstructured approximate posterior describing spatially-dependent linear\ndynamics, as well as an algorithm that relies on the fixed-point iteration\nmethod to achieve convergence. We apply VIND to electrophysiology, single-cell\nvoltage and widefield imaging datasets with state-of-the-art results in\nreconstruction error. In single-cell voltage data, VIND finds a 5D latent\nspace, with variables akin to those of Hodgkin-Huxley-like models. VIND's\nlearned dynamics are further quantified by predicting future neural activity.\nVIND excels in this task, in some cases substantially outperforming current\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 16:10:56 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2019 16:18:42 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2020 18:00:58 GMT"}], "update_date": "2020-06-18", "authors_parsed": [["Hernandez", "Daniel", ""], ["Moretti", "Antonio Khalil", ""], ["Wei", "Ziqiang", ""], ["Saxena", "Shreya", ""], ["Cunningham", "John", ""], ["Paninski", "Liam", ""]]}, {"id": "1811.02507", "submitter": "Takashi Morita", "authors": "Takashi Morita, Hiroki Koda", "title": "Superregular grammars do not provide additional explanatory power but\n  allow for a compact analysis of animal song", "comments": "Accepted for publication by Royal Society Open Science", "journal-ref": null, "doi": "10.1098/rsos.190139", "report-no": null, "categories": "q-bio.NC cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A pervasive belief with regard to the differences between human language and\nanimal vocal sequences (song) is that they belong to different classes of\ncomputational complexity, with animal song belonging to regular languages,\nwhereas human language is superregular. This argument, however, lacks empirical\nevidence since superregular analyses of animal song are understudied. The goal\nof this paper is to perform a superregular analysis of animal song, using data\nfrom gibbons as a case study, and demonstrate that a superregular analysis can\nbe effectively used with non-human data. A key finding is that a superregular\nanalysis does not increase explanatory power but rather provides for compact\nanalysis: Fewer grammatical rules are necessary once superregularity is\nallowed. This pattern is analogous to a previous computational analysis of\nhuman language, and accordingly, the null hypothesis, that human language and\nanimal song are governed by the same type of grammatical systems, cannot be\nrejected.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 05:07:37 GMT"}, {"version": "v2", "created": "Fri, 14 Jun 2019 12:06:15 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Morita", "Takashi", ""], ["Koda", "Hiroki", ""]]}, {"id": "1811.02650", "submitter": "Jian Li DR", "authors": "Jian Li", "title": "Visual Attention is Beyond One Single Saliency Map", "comments": "arXiv admin note: text overlap with arXiv:1605.01999", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Of later years, numerous bottom-up attention models have been proposed on\ndifferent assumptions. However, the produced saliency maps may be different\nfrom each other even from the same input image. We also observe that human\nfixation map varies across time greatly. When people freely view an image, they\ntend to allocate attention at salient regions of large scale at first, and then\nsearch more and more detailed regions. In this paper, we argue that, for one\ninput image visual attention cannot be described by only one single saliency\nmap, and this mechanism should be modeled as a dynamic process. Under the\nfrequency domain paradigm, we proposed a global inhibition model to mimic this\nprocess by suppressing the {\\it non-saliency} in the input image; we also show\nthat the dynamic process is influenced by one parameter in the frequency\ndomain. Experiments illustrate that the proposed model is capable of predicting\nhuman dynamic fixation distribution.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2018 04:10:50 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Li", "Jian", ""]]}, {"id": "1811.02694", "submitter": "Ran Wang", "authors": "Ran Wang, Yao Wang, Adeen Flinker", "title": "Reconstructing Speech Stimuli From Human Auditory Cortex Activity Using\n  a WaveNet Approach", "comments": "6 pages, 3 figures. Conference of 2018 IEEE Signal Processing in\n  Medicine and Biology Symposium (SPMB 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.LG eess.AS q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The superior temporal gyrus (STG) region of cortex critically contributes to\nspeech recognition. In this work, we show that a proposed WaveNet, with limited\navailable data, is able to reconstruct speech stimuli from STG intracranial\nrecordings. We further investigate the impulse response of the fitted model for\neach recording electrode and observe phoneme level temporospectral tuning\nproperties for the recorded area of cortex. This discovery is consistent with\nprevious studies implicating the posterior STG (pSTG) in a phonetic\nrepresentation of speech and provides detailed acoustic features that certain\nelectrode sites possibly extract during speech recognition.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 22:19:28 GMT"}, {"version": "v2", "created": "Thu, 8 Nov 2018 02:17:16 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Wang", "Ran", ""], ["Wang", "Yao", ""], ["Flinker", "Adeen", ""]]}, {"id": "1811.02795", "submitter": "Tomoya Kitamura", "authors": "Tomoya Kitamura, Yuu Hasegawa, Sho Sakaino, and Toshiaki Tsuji", "title": "Estimation of Relationship between Stimulation Current and Force Exerted\n  during Isometric Contraction", "comments": "(C) 2018 IEEE. Personal use of this material is permitted. Permission\n  from IEEE must be obtained for all other uses, in any current or future\n  media, including reprinting/republishing this material for advertising or\n  promotional purposes, creating new collective works, for resale or\n  redistribution to servers or lists, or reuse of any copyrighted component of\n  this work in other works", "journal-ref": "The 44th International Conference on Industrial Electronics,\n  Control and Instrumentation, pp. 5080-5085 (2018)", "doi": "10.1109/IECON.2018.8591190", "report-no": null, "categories": "cs.HC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we developed a method to estimate the relationship between\nstimulation current and volatility during isometric contraction. In functional\nelectrical stimulation (FES), joints are driven by applying voltage to muscles.\nThis technology has been used for a long time in the field of rehabilitation,\nand recently application oriented research has been reported. However,\nestimation of the relationship between stimulus value and exercise capacity has\nnot been discussed to a great extent. Therefore, in this study, a human muscle\nmodel was estimated using the transfer function estimation method with fast\nFourier transform. It was found that the relationship between stimulation\ncurrent and force exerted could be expressed by a first-order lag system. In\nverification of the force estimate, the ability of the proposed model to\nestimate the exerted force under steady state response was found to be good.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 08:20:26 GMT"}, {"version": "v2", "created": "Wed, 20 Jan 2021 09:06:40 GMT"}], "update_date": "2021-01-21", "authors_parsed": [["Kitamura", "Tomoya", ""], ["Hasegawa", "Yuu", ""], ["Sakaino", "Sho", ""], ["Tsuji", "Toshiaki", ""]]}, {"id": "1811.02861", "submitter": "Sven Goedeke", "authors": "Felipe Yaroslav Kalle Kossio, Sven Goedeke, Benjamin van den Akker,\n  Borja Ibarz, Raoul-Martin Memmesheimer", "title": "Growing Critical: Self-Organized Criticality in a Developing Neural\n  System", "comments": "6 pages, 4 figures, supplemental material: 10 pages, 7 figures", "journal-ref": "Phys. Rev. Lett. 121(5), 058301, 2018", "doi": "10.1103/PhysRevLett.121.058301", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments in various neural systems found avalanches: bursts of activity\nwith characteristics typical for critical dynamics. A possible explanation for\ntheir occurrence is an underlying network that self-organizes into a critical\nstate. We propose a simple spiking model for developing neural networks,\nshowing how these may \"grow into\" criticality. Avalanches generated by our\nmodel correspond to clusters of widely applied Hawkes processes. We\nanalytically derive the cluster size and duration distributions and find that\nthey agree with those of experimentally observed neuronal avalanches.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 12:47:11 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Kossio", "Felipe Yaroslav Kalle", ""], ["Goedeke", "Sven", ""], ["Akker", "Benjamin van den", ""], ["Ibarz", "Borja", ""], ["Memmesheimer", "Raoul-Martin", ""]]}, {"id": "1811.02881", "submitter": "Seong Hah Cho", "authors": "Seong Hah Cho, Cody A Cushing, Kunal Patel, Alok Kothari, Rongjian\n  Lan, Matthias Michel, Mouslim Cherkaoui, and Hakwan Lau", "title": "Blockchain and human episodic memory", "comments": "30 pages, 2 figures; Minor edits, added figures, revised and updated\n  sections", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We relate the concepts used in decentralized ledger technology to studies of\nepisodic memory in the mammalian brain. Specifically, we introduce the standard\nconcepts of linked list, hash functions, and sharding, from computer science.\nWe argue that these concepts may be more relevant to studies of the neural\nmechanisms of memory than has been previously appreciated. In turn, we also\nhighlight that certain phenomena studied in the brain, namely metacognition,\nreality monitoring, and how perceptual conscious experiences come about, may\ninspire development in blockchain technology too, specifically regarding\nprobabilistic consensus protocols.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 04:35:22 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 05:49:27 GMT"}, {"version": "v3", "created": "Tue, 16 Apr 2019 04:41:24 GMT"}], "update_date": "2019-04-17", "authors_parsed": [["Cho", "Seong Hah", ""], ["Cushing", "Cody A", ""], ["Patel", "Kunal", ""], ["Kothari", "Alok", ""], ["Lan", "Rongjian", ""], ["Michel", "Matthias", ""], ["Cherkaoui", "Mouslim", ""], ["Lau", "Hakwan", ""]]}, {"id": "1811.02923", "submitter": "Muhammad Saif-Ur-Rehman", "authors": "Muhammad Saif-ur-Rehman, Robin Lienk\\\"amper, Yaroslav Parpaley, J\\\"org\n  Wellmer, Charles Liu, Brian Lee, Spencer Kellis, Richard Andersen, Ioannis\n  Iossifidis, Tobias Glasmachers, Christian Klaes", "title": "Universal Spike Classifier", "comments": "21 Pages, 12 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In electrophysiology, microelectrodes are the primary source for recording\nneural data of single neurons (single unit activity). These microelectrodes can\nbe implanted individually, or in the form of microelectrodes arrays, consisting\nof hundreds of electrodes. During recordings, some channels capture the\nactivity of neurons, which is usually contaminated with external artifacts and\nnoise. Another considerable fraction of channels does not record any neural\ndata, but external artifacts and noise. Therefore, an automatic identification\nand tracking of channels containing neural data is of great significance and\ncan accelerate the process of analysis, e.g. automatic selection of meaningful\nchannels during offline and online spike sorting. Another important aspect is\nthe selection of meaningful channels during online decoding in brain-computer\ninterface applications, where threshold crossing events are usually for feature\nextraction, even though they do not necessarily correspond to neural events.\nHere, we propose a novel algorithm based on the newly introduced way of feature\nvector extraction and a supervised deep learning method: a universal spike\nclassifier (USC). The USC enables us to address both above-raised issues. The\nUSC uses the standard architecture of convolutional neural networks (Conv net).\nIt takes the batch of the waveforms, instead of a single waveform as an input,\npropagates it through the multilayered structure, and finally classifies it as\na channel containing neural spike data or artifacts. We have trained the model\nof USC on data recorded from single tetraplegic patient with Utah arrays\nimplanted in different brain areas. This trained model was then evaluated\nwithout retraining on the data collected from six epileptic patients implanted\nwith depth electrodes and two tetraplegic patients implanted with two Utah\narrays, individually.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 15:09:01 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Saif-ur-Rehman", "Muhammad", ""], ["Lienk\u00e4mper", "Robin", ""], ["Parpaley", "Yaroslav", ""], ["Wellmer", "J\u00f6rg", ""], ["Liu", "Charles", ""], ["Lee", "Brian", ""], ["Kellis", "Spencer", ""], ["Andersen", "Richard", ""], ["Iossifidis", "Ioannis", ""], ["Glasmachers", "Tobias", ""], ["Klaes", "Christian", ""]]}, {"id": "1811.03251", "submitter": "Dario Ringach", "authors": "Elaine Tring and Dario L. Ringach", "title": "On the Subspace Invariance of Population Responses", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In cat visual cortex, the response of a neural population to the linear\ncombination of two sinusoidal gratings (a plaid) can be well approximated by a\nweighted sum of the population responses to the individual gratings --- a\nproperty we refer to as {\\em subspace invariance}. We tested subspace\ninvariance in mouse primary visual cortex by measuring the angle between the\npopulation response to a plaid and the plane spanned by the population\nresponses to its individual components. We found robust violations of subspace\ninvariance arising from a strong, negative correlation between the responses of\nneurons to individual gratings and their responses to the plaid. Contrast\ninvariance, a special case of subspace invariance, also failed. The responses\nof some neurons decreased with increasing contrast, while others increased.\nAltogether the data show that subspace and contrast invariance do not hold in\nmouse primary visual cortex. These findings rule out some models of population\ncoding, including vector averaging, some versions of normalization and temporal\nmultiplexing.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 03:45:58 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Tring", "Elaine", ""], ["Ringach", "Dario L.", ""]]}, {"id": "1811.03335", "submitter": "Dr. Alexander Paraskevov", "authors": "A.V. Paraskevov, D.K. Zendrikov", "title": "A spatially resolved network spike in model neuronal cultures reveals\n  nucleation centers, circular traveling waves and drifting spiral waves", "comments": "14 pages, 7 figures", "journal-ref": "Phys. Biol. 14, 026003 (2017)", "doi": "10.1088/1478-3975/aa5fc3", "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn nlin.AO nlin.PS physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that in model neuronal cultures, where the probability of\ninterneuronal connection formation decreases exponentially with increasing\ndistance between the neurons, there exists a small number of spatial nucleation\ncenters of a network spike, from where the synchronous spiking activity starts\npropagating in the network typically in the form of circular traveling waves.\nThe number of nucleation centers and their spatial locations are unique and\nunchanged for a given realization of neuronal network but are different for\ndifferent networks. In contrast, if the probability of interneuronal connection\nformation is independent of the distance between neurons, then the nucleation\ncenters do not arise and the synchronization of spiking activity during a\nnetwork spike occurs spatially uniform throughout the network. Therefore one\ncan conclude that spatial proximity of connections between neurons is important\nfor the formation of nucleation centers. It is also shown that fluctuations of\nthe spatial density of neurons at their random homogeneous distribution typical\nfor the experiments $\\textit{in vitro}$ do not determine the locations of the\nnucleation centers. The simulation results are qualitatively consistent with\nthe experimental observations.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 09:56:49 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Paraskevov", "A. V.", ""], ["Zendrikov", "D. K.", ""]]}, {"id": "1811.03493", "submitter": "Gopal P. Sarma", "authors": "Gopal P. Sarma, Adam Safron, and Nick J. Hay", "title": "Integrative Biological Simulation, Neuropsychology, and AI Safety", "comments": "5 pages", "journal-ref": "Proceedings of the AAAI Workshop on Artificial Intelligence Safety\n  2019 co-located with the Thirty-Third AAAI Conference on Artificial\n  Intelligence 2019 (AAAI 2019)", "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a biologically-inspired research agenda with parallel tracks\naimed at AI and AI safety. The bottom-up component consists of building a\nsequence of biophysically realistic simulations of simple organisms such as the\nnematode $Caenorhabditis$ $elegans$, the fruit fly $Drosophila$ $melanogaster$,\nand the zebrafish $Danio$ $rerio$ to serve as platforms for research into AI\nalgorithms and system architectures. The top-down component consists of an\napproach to value alignment that grounds AI goal structures in neuropsychology,\nbroadly considered. Our belief is that parallel pursuit of these tracks will\ninform the development of value-aligned AI systems that have been inspired by\nembodied organisms with sensorimotor integration. An important set of side\nbenefits is that the research trajectories we describe here are grounded in\nlong-standing intellectual traditions within existing research communities and\nfunding structures. In addition, these research programs overlap with\nsignificant contemporary themes in the biological and psychological sciences\nsuch as data/model integration and reproducibility.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 01:38:24 GMT"}, {"version": "v2", "created": "Mon, 21 Jan 2019 19:04:47 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Sarma", "Gopal P.", ""], ["Safron", "Adam", ""], ["Hay", "Nick J.", ""]]}, {"id": "1811.03612", "submitter": "Hamdan Awan", "authors": "Hamdan Awan, Raviraj S. Adve, Nigel Wallbridge, Carrol Plummer, and\n  Andrew W. Eckford", "title": "Communication and Information Theory of Single Action Potential Signals\n  in Plants", "comments": "13 Pages, 15 Figures, Accepted for Publication in IEEE Transactions\n  on NanoBioscience", "journal-ref": null, "doi": "10.1109/TNB.2018.2880924", "report-no": null, "categories": "q-bio.NC cs.IT eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many plants, such as Mimosa pudica (the sensitive plant), employ\nelectrochemical signals known as action potentials (APs) for rapid\nintercellular communication. In this paper, we consider a reaction diffusion\nmodel of individual AP signals to analyze APs from a communication and\ninformation theoretic perspective. We use concepts from molecular communication\nto explain the underlying process of information transfer in a plant for a\nsingle AP pulse that is shared with one or more receiver cells. We also use the\nchemical Langevin equation to accommodate the deterministic as well as\nstochastic component of the system. Finally we present an information theoretic\nanalysis of single action potentials, obtaining achievable information rates\nfor these signals. We show that, in general, the presence of an AP signal can\nincrease the mutual information and information propagation speed among\nneighboring cells with receivers in different settings.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 18:55:38 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Awan", "Hamdan", ""], ["Adve", "Raviraj S.", ""], ["Wallbridge", "Nigel", ""], ["Plummer", "Carrol", ""], ["Eckford", "Andrew W.", ""]]}, {"id": "1811.04230", "submitter": "Subhankar Chattoraj", "authors": "Sawon Pratiher, Subhankar Chattoraj and Rajdeep Mukherjee", "title": "StationPlot: A New Non-stationarity Quantification Tool for Detection of\n  Epileptic Seizures", "comments": "This paper is accepted for presentation at IEEE Global Conference on\n  Signal and Information Processing (IEEE GlobalSIP), California, USA, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel non-stationarity visualization tool known as StationPlot is developed\nfor deciphering the chaotic behavior of a dynamical time series. A family of\nanalytic measures enumerating geometrical aspects of the non-stationarity &\ndegree of variability is formulated by convex hull geometry (CHG) on\nStationPlot. In the Euclidean space, both trend-stationary (TS) &\ndifference-stationary (DS) perturbations are comprehended by the asymmetric\nstructure of StationPlot's region of interest (ROI). The proposed method is\nexperimentally validated using EEG signals, where it comprehend the relative\ntemporal evolution of neural dynamics & its non-stationary morphology, thereby\nexemplifying its diagnostic competence for seizure activity (SA) detection.\nExperimental results & analysis-of-Variance (ANOVA) on the extracted CHG\nfeatures demonstrates better classification performances as compared to the\nexisting shallow feature based state-of-the-art & validates its efficacy as\ngeometry-rich discriminative descriptors for signal processing applications.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 10:34:16 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Pratiher", "Sawon", ""], ["Chattoraj", "Subhankar", ""], ["Mukherjee", "Rajdeep", ""]]}, {"id": "1811.04489", "submitter": "Milena \\v{C}uki\\'c Dr", "authors": "\\v{C}uki\\'c Milena, Stoki\\'c Miodrag, Radenkovi\\'c Slavoljub,\n  Ljubisavljevi\\'c Milo\\v{s}, Simi\\'c Slobodan, Danka Savi\\'c", "title": "Nonlinear analysis of EEG complexity in episode and remission phase of\n  recurrent depression", "comments": "23 pages, 6 figures", "journal-ref": "09 December 2019. IJMPR\n  https://onlinelibrary.wiley.com/doi/full/10.1002/mpr.1816", "doi": "10.1002/MPR.1816", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biomarkers of Major Depressive Disorder(MDD), its phases and forms have long\nbeen sought. Research indicates that the complexity measures of the cortical\nelectrical activity (EEG) might be candidates for this role. To examine whether\nthe complexity of EEG activity, measured by Higuchi fractal dimension (HFD) and\nsample entropy (SampEn), differs between healthy subjects, patients in\nremission and episode phase of the recurrent depression and whether the changes\nare differentially distributed between hemispheres and cortical regions.\nResting state EEG with eyes closed was recorded from 26 patients suffering from\nrecurrent depression and 20 age and sex-matched healthy control subjects.\nArtefact-free EEG epochs were analyzed by in-house developed programs running\nHFD and SampEn algorithms. Depressed patients had higher HFD and SampEn\ncomplexity compared to healthy subjects. Surprisingly, the complexity was even\nhigher in patients who were in remission than in those in the episode. Altered\ncomplexity was present in the frontal and centro-parietal regions when compared\nto the control group. The complexity in frontal and parietal regions differed\nbetween the two phases of depressive disorder. SampEn manifested higher\nsensitivity than HFD in some cortical areas. Complexity measures of EEG\ndistinguish between the three groups. Further studies are needed to establish\nwhether these measures carry the potential to aid clinically relevant decisions\nabout depression.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 21:55:23 GMT"}], "update_date": "2019-12-19", "authors_parsed": [["Milena", "\u010cuki\u0107", ""], ["Miodrag", "Stoki\u0107", ""], ["Slavoljub", "Radenkovi\u0107", ""], ["Milo\u0161", "Ljubisavljevi\u0107", ""], ["Slobodan", "Simi\u0107", ""], ["Savi\u0107", "Danka", ""]]}, {"id": "1811.04512", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Reframing Convergent and Divergent Thought for the 21st Century", "comments": "7 pages; 2 figures;", "journal-ref": "Published in 2019 in A. Goel, C. Seifert, & C. Freska (Eds.),\n  Proceedings of 41st Annual Meeting of the Cognitive Science Society. Austin\n  TX: Cognitive Science Society", "doi": null, "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convergent thought is defined and measured in terms of the ability to perform\non tasks where there is a single correct solution, and divergent thought is\ndefined and measured in terms of the ability to generate multiple different\nsolutions. However, this characterization of them presents inconsistencies, and\ndespite that they are promoted as key constructs of creativity, they do not\ncapture the capacity to reiteratively modify an idea in light of new\nperspectives arising out of an overarching conceptual framework. Research on\nformal models of concepts and their interactions suggests that different\ncreative outputs may be projections of the same underlying idea at different\nphases of this kind of 'honing' process. This leads us to redefine convergent\nthought as thought in which the relevant concepts are considered from\nconventional contexts, and divergent thought as thought in which they are\nconsidered from unconventional contexts. Implications for the assessment of\ncreativity are discussed.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 23:59:33 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 13:48:56 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 22:26:57 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1811.04549", "submitter": "Wenjing Wang", "authors": "Wenjing Wang, Xiang Li", "title": "Temporal Stable Community in Time-Varying Networks", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying community structure of a complex network provides insight to the\ninterdependence between the network topology and emergent collective behaviors\nof networks, while detecting such invariant communities in a time-varying\nnetwork is more challenging. In this paper, we define the temporal stable\ncommunity and newly propose the concept of dynamic modularity to evaluate the\nstable community structures in time-varying networks, which is robust against\nsmall changes as verified by several empirical time-varying network datasets.\nBesides, using the volatility features of temporal stable communities in\nfunctional brain networks, we successfully differentiate the ADHD (Attention\nDeficit Hyperactivity Disorder) patients and healthy controls efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 04:09:21 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Wang", "Wenjing", ""], ["Li", "Xiang", ""]]}, {"id": "1811.04581", "submitter": "Shigeko Takahashi", "authors": "Shigeko Takahashi", "title": "Topographic maps in the brain are fundamental to processing of causality", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ubiquity of topographic maps in the brain has long been known, and\nmolecular mechanisms for the formation of topographic organization of neural\nsystems have been revealed. Less attention has been given to the question of\nwhy are the maps topographical and why so ubiquitous. In this study, I explore\nthe implications of the topographic maps for brain function, by employing the\nmathematical framework of the Zeeman topology. I propose the notion about the\nmeaning of topographic order as generic mechanisms for the representation and\nanalysis of causal structure, implemented by the neural systems. This leads to\na much improved understanding of the division of labour between chemical\nsystems and neural systems in the formation of maps to deal with causality.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 06:42:42 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Takahashi", "Shigeko", ""]]}, {"id": "1811.04662", "submitter": "Navin Cooray", "authors": "Navin Cooray (1), Fernando Andreotti (1), Christine Lo (2), Mkael\n  Symmonds (3), Michele T.M. Hu (2) and Maarten De Vos (1) ((1) University of\n  Oxford, Institute of Biomedical Engineering, Dept. Engineering Sciences,\n  Oxford, UK, (2) Nuffield Department of Clinical Neurosciences, Oxford\n  Parkinson's Disease Centre (OPDC), University of Oxford, UK, (3) Department\n  of Clinical Neurophysiology, Oxford University Hospitals, John Radcliffe\n  Hospital, University of Oxford, UK)", "title": "Detection of REM Sleep Behaviour Disorder by Automated Polysomnography\n  Analysis", "comments": "20 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG eess.SP q-bio.NC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Evidence suggests Rapid-Eye-Movement (REM) Sleep Behaviour Disorder (RBD) is\nan early predictor of Parkinson's disease. This study proposes a\nfully-automated framework for RBD detection consisting of automated sleep\nstaging followed by RBD identification. Analysis was assessed using a limited\npolysomnography montage from 53 participants with RBD and 53 age-matched\nhealthy controls. Sleep stage classification was achieved using a Random Forest\n(RF) classifier and 156 features extracted from electroencephalogram (EEG),\nelectrooculogram (EOG) and electromyogram (EMG) channels. For RBD detection, a\nRF classifier was trained combining established techniques to quantify muscle\natonia with additional features that incorporate sleep architecture and the EMG\nfractal exponent. Automated multi-state sleep staging achieved a 0.62 Cohen's\nKappa score. RBD detection accuracy improved by 10% to 96% (compared to\nindividual established metrics) when using manually annotated sleep staging.\nAccuracy remained high (92%) when using automated sleep staging. This study\noutperforms established metrics and demonstrates that incorporating sleep\narchitecture and sleep stage transitions can benefit RBD detection. This study\nalso achieved automated sleep staging with a level of accuracy comparable to\nmanual annotation. This study validates a tractable, fully-automated, and\nsensitive pipeline for RBD identification that could be translated to wearable\ntake-home technology.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 11:13:51 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Cooray", "Navin", ""], ["Andreotti", "Fernando", ""], ["Lo", "Christine", ""], ["Symmonds", "Mkael", ""], ["Hu", "Michele T. M.", ""], ["De Vos", "Maarten", ""]]}, {"id": "1811.04698", "submitter": "Pascal Grange", "authors": "Pascal Grange", "title": "Topology of the mesoscale connectome of the mouse brain", "comments": "19 pages, 6 figures, 4 tables; V2: typos corrected, references added;\n  V3: more typos corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wiring diagram of the mouse brain has recently been mapped at a\nmesoscopic scale in the Allen Mouse Brain Connectivity Atlas. Axonal\nprojections from brain regions were traced using green fluoresent proteins. The\nresulting data were registered to a common three-dimensional reference space.\nThey yielded a matrix of connection strengths between 213 brain regions. Global\nfeatures such as closed loops formed by connections of similar intensity can be\ninferred using tools from persistent homology. We map the wiring diagram of the\nmouse brain to a simplicial complex (filtered by connection strengths). We work\nout generators of the first homology group. Some regions, including nucleus\naccumbens, are connected to the entire brain by loops, whereas no region has\nnon-zero connection strength to all brain regions. Thousands of loops go\nthrough the isocortex, the striatum and the thalamus. On the other hand,\nmedulla is the only major brain compartment that contains more than 100 loops.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 12:54:32 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 04:28:08 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 03:22:32 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Grange", "Pascal", ""]]}, {"id": "1811.05058", "submitter": "Maria Cabrera", "authors": "Maria E. Cabrera, Keisha Novak, Dan Foti, Richard Voyles and Juan P.\n  Wachs", "title": "Electrophysiological indicators of gesture perception", "comments": "29 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: While there has been abundant research concerning neurological\nresponses to gesture generation, the time course of gesture processing is not\nwell understood. Specifically, it is not clear if or how particular\ncharacteristics within the kinematic execution of gestures capture attention\nand aid in the classification of gestures with communicative intent. If indeed\nkey features of gestures with perceptual saliency exist, such features could\nhelp form the basis of a compact representation of the gestures in memory.\nMethods: This study used a set of available gesture videos as stimuli. The\ntiming for salient features of performed gestures was determined by isolating\ninflection points in the hands' motion trajectories. Participants passively\nviewed the gesture videos while continuous EEG data was collected. We focused\non mu oscillations (10 Hz) and used linear regression to test for associations\nbetween the timing of mu oscillations and inflection points in motion\ntrajectories. Results: Peaks in the EEG signals at central and occipital\nelectrodes were used to isolate the salient events within each gesture. EEG\npower oscillations were detected 343 and 400ms on average after inflection\npoints at occipital and central electrodes, respectively. A regression model\nshowed that inflection points in the motion trajectories strongly predicted\nsubsequent mu oscillations (R^2=0.961, p<.01). Conclusion: The results suggest\nthat coordinated activity in the visual and motor cortices are highly\ncorrelated with key motion components within gesture trajectories. These points\nmay be associated with neural signatures used to encode gestures in memory for\nlater identification and even recognition.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 00:58:16 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Cabrera", "Maria E.", ""], ["Novak", "Keisha", ""], ["Foti", "Dan", ""], ["Voyles", "Richard", ""], ["Wachs", "Juan P.", ""]]}, {"id": "1811.05105", "submitter": "Arjun Punjabi", "authors": "Arjun Punjabi, Adam Martersteck, Yanran Wang, Todd B. Parrish, Aggelos\n  K. Katsaggelos, and the Alzheimer's Disease Neuroimaging Initiative", "title": "Neuroimaging Modality Fusion in Alzheimer's Classification Using\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": "10.1371/journal.pone.0225759", "report-no": null, "categories": "cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated methods for Alzheimer's disease (AD) classification have the\npotential for great clinical benefits and may provide insight for combating the\ndisease. Machine learning, and more specifically deep neural networks, have\nbeen shown to have great efficacy in this domain. These algorithms often use\nneurological imaging data such as MRI and PET, but a comprehensive and balanced\ncomparison of these modalities has not been performed. In order to accurately\ndetermine the relative strength of each imaging variant, this work performs a\ncomparison study in the context of Alzheimer's dementia classification using\nthe Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset. Furthermore,\nthis work analyzes the benefits of using both modalities in a fusion setting\nand discusses how these data types may be leveraged in future AD studies using\ndeep learning.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 04:53:54 GMT"}], "update_date": "2020-07-01", "authors_parsed": [["Punjabi", "Arjun", ""], ["Martersteck", "Adam", ""], ["Wang", "Yanran", ""], ["Parrish", "Todd B.", ""], ["Katsaggelos", "Aggelos K.", ""], ["Initiative", "the Alzheimer's Disease Neuroimaging", ""]]}, {"id": "1811.05225", "submitter": "Claus Metzner", "authors": "Patrick Krauss, Alexandra Zankl, Achim Schilling, Holger Schulze, and\n  Claus Metzner", "title": "Analysis of structure and dynamics in three-neuron motifs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural networks with identical neurons, the matrix of connection weights\ncompletely describes the network structure and thereby determines how it is\nprocessing information. However, due to the non-linearity of these systems, it\nis not clear if similar microscopic connection structures also imply similar\nfunctional properties, or if a network is impacted more by macroscopic\nstructural quantities, such as the ratio of excitatory and inhibitory\nconnections (balance), or the ratio of non-zero connections (density). To\nclarify these questions, we focus on motifs of three binary neurons with\ndiscrete ternary connection strengths, an important class of network building\nblocks that can be analyzed exhaustively. We develop new, permutation-invariant\nmetrics to quantify the structural and functional distance between two given\nnetwork motifs. We then use multidimensional scaling to identify and visualize\nclusters of motifs with similar structural and functional properties. Our\ncomprehensive analysis reveals that the function of a neural network is only\nweakly correlated with its microscopic structure, but depends strongly on the\nbalance of the connections.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 11:34:50 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Krauss", "Patrick", ""], ["Zankl", "Alexandra", ""], ["Schilling", "Achim", ""], ["Schulze", "Holger", ""], ["Metzner", "Claus", ""]]}, {"id": "1811.05403", "submitter": "Olha Shchur", "authors": "Olha Shchur and Alexander Vidybida", "title": "First passage time distribution for spiking neuron with delayed\n  excitatory feedback", "comments": "11 pages, 3 figures", "journal-ref": "Fluctuation and Noise Letters, Vol. 19, No. 01, 2050005 (2020)", "doi": "10.1142/S0219477520500054", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A class of spiking neuronal models with threshold 2 is considered. It is\ndefined by a set of conditions typical for basic threshold-type models, such as\nthe leaky integrate-and-fire (LIF) or the binding neuron model and also for\nsome artificial neurons. A neuron is stimulated with a Poisson stream of\nexcitatory impulses. Each output impulse is conveyed through the feedback line\nto the neuron input after finite delay $\\Delta$. This impulse is identical to\nthose delivered from the input stream. We have obtained a general relation\nallowing calculating exactly the probability density function (PDF) $p(t)$ for\ndistribution of the first passage time of crossing the threshold, which is the\ndistribution of output interspike intervals (ISI) values for this neuron. The\ncalculation is based on known PDF $p^0(t)$ for that same neuron without\nfeedback, intensity of the input stream $\\lambda$ and properties of the\nfeedback line. Also, we derive exact relation for calculating the moments of\n$p(t)$ based on known moments of $p^0(t)$.\n  The obtained general expression for $p(t)$ is checked numerically using Monte\nCarlo simulation for the case of LIF model. The course of $p(t)$ has a\n$\\delta$-function type peculiarity. This fact contributes to the discussion\nabout the possibility to model neuronal activity with Poisson process,\nsupporting the \"no\" answer.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 16:55:56 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 15:42:23 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Shchur", "Olha", ""], ["Vidybida", "Alexander", ""]]}, {"id": "1811.06825", "submitter": "Jerome Feldman", "authors": "Jerome Feldman (ICSI and UC Berkeley)", "title": "Towards a Science of Mind", "comments": "18 pages and 1 Figure. The ancient mind/body remains a scientific and\n  existential mystery. This article develops a methodology for an incremental\n  Science of Mind and describes some ongoing prospects and successes. Updates\n  include additional phenomena, including emotions,and several more references.\n  A major addition is a postulated general (mysterious) brain-mind mapping", "journal-ref": null, "doi": "10.1007/s41470-019-00041-4", "report-no": null, "categories": "cs.GL cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ancient mind/body problem continues to be one of deepest mysteries of\nscience and of the human spirit. Despite major advances in many fields, there\nis still no plausible link between subjective experience (qualia) and its\nrealization in the body. This paper outlines some of the elements of a rigorous\nscience of mind (SoM) - key ideas include scientific realism of mind, agnostic\nmysterianism, careful attention to language, and a focus on concrete\n(touchstone) questions and results. A core suggestion is to focus effort on the\n(still mysterious) mapping from neural activity to subjective experience.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 18:02:40 GMT"}, {"version": "v2", "created": "Fri, 26 Apr 2019 20:44:15 GMT"}, {"version": "v3", "created": "Mon, 29 Jul 2019 16:58:06 GMT"}], "update_date": "2020-08-13", "authors_parsed": [["Feldman", "Jerome", "", "ICSI and UC Berkeley"]]}, {"id": "1811.06866", "submitter": "Ulisse Ferrari", "authors": "Ulisse Ferrari, St\\'ephane Deny, Abhishek Sengupta, Romain Caplette,\n  Jos\\'e-Alain Sahel, Deniz Dalkara, Serge Picaud, Jens Duebel, Olivier Marre", "title": "Optogenetic vision restoration with high resolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The majority of inherited retinal degenerations are due to photoreceptor cell\ndeath. In many cases ganglion cells are spared making it possible to stimulate\nthem to restore visual function. Several studies (Bi et al., 2006; Lin et al.,\n2008; Sengupta et al., 2016; Caporale et al., 2011; Berry et al., 2017) have\nshown that it is possible to express an optogenetic protein in ganglion cells\nand make them light sensitive. This is a promising strategy to restore vision\nsince optical targeting may be more precise than electrical stimulation with a\nretinal prothesis. However the spatial resolution of\noptogenetically-reactivated retinas has not been measured with fine-grained\nstimulation patterns. Since the optogenetic protein is also expressed in axons,\nit is unclear if these neurons will only be sensitive to the stimulation of a\nsmall region covering their somas and dendrites, or if they will also respond\nto any stimulation overlapping with their axon, dramatically impairing spatial\nresolution. Here we recorded responses of mouse and macaque retinas to random\ncheckerboard patterns following an in vivo optogenetic therapy. We show that\noptogenetically activated ganglion cells are each sensitive to a small region\nof visual space. A simple model based on this small receptive field predicted\naccurately their responses to complex stimuli. From this model, we simulated\nhow the entire population of light sensitive ganglion cells would respond to\nletters of different sizes. We then estimated the maximal acuity expected by a\npatient, assuming it could make an optimal use of the information delivered by\nthis reactivated retina. The obtained acuity is above the limit of legal\nblindness. This high spatial resolution is a promising result for future\nclinical studies.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 15:41:19 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Ferrari", "Ulisse", ""], ["Deny", "St\u00e9phane", ""], ["Sengupta", "Abhishek", ""], ["Caplette", "Romain", ""], ["Sahel", "Jos\u00e9-Alain", ""], ["Dalkara", "Deniz", ""], ["Picaud", "Serge", ""], ["Duebel", "Jens", ""], ["Marre", "Olivier", ""]]}, {"id": "1811.07012", "submitter": "Shashaank Vattikuti", "authors": "Benjamin P Cohen, Carson C Chow, Shashaank Vattikuti", "title": "Multi-scale variability in neuronal competition", "comments": "35 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We examine whether a single biophysical cortical circuit model can explain\nboth spiking and perceptual variability. We consider perceptual rivalry, which\nprovides a window into intrinsic neural processing since neural activity in\nsome brain areas is correlated to the alternating perception rather than the\nconstant ambiguous stimulus. The prevalent theory for spiking variability is a\nchaotic attractor called the balanced state; whereas, the source of perceptual\nvariability is an open question. We present a dynamical model with a chaotic\nattractor that explains both spiking and perceptual variability and adheres to\na broad set of strict experimental constraints. The model makes quantitative\npredictions for how both spiking and perceptual variability will change as the\nstimulus changes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 20:05:41 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Cohen", "Benjamin P", ""], ["Chow", "Carson C", ""], ["Vattikuti", "Shashaank", ""]]}, {"id": "1811.07020", "submitter": "Daniele Q.M. Madureira", "authors": "Daniele Q. M. Madureira, Vera Lucia P. S. Caminha and Rogerio Salvini", "title": "Brain Connectivity Impairments and Categorization Disabilities in\n  Autism: A Theoretical Approach via Artificial Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A developmental disorder that severely damages communicative and social\nfunctions, the Autism Spectrum Disorder (ASD) also presents aspects related to\nmental rigidity, repetitive behavior, and difficulty in abstract reasoning.\nMore, imbalances between excitatory and inhibitory brain states, in addition to\ncortical connectivity disruptions, are at the source of the autistic behavior.\nOur main goal consists in unveiling the way by which these local excitatory\nimbalances and/or long brain connections disruptions are linked to the above\nmentioned cognitive features. We developed a theoretical model based on\nSelf-Organizing Maps (SOM), where a three-level artificial neural network\nqualitatively incorporates these kinds of alterations observed in brains of\npatients with ASD. Computational simulations of our model indicate that high\nexcitatory states or long distance under-connectivity are at the origins of\ncognitive alterations, as difficulty in categorization and mental rigidity.\nMore specifically, the enlargement of excitatory synaptic reach areas in a\ncortical map development conducts to low categorization (over-selectivity) and\npoor concepts formation. And, both the over-strengthening of local excitatory\nsynapses and the long distance under-connectivity, although through distinct\nmechanisms, contribute to impaired categorization (under-selectivity) and\nmental rigidity. Our results indicate how, together, both local and global\nbrain connectivity alterations give rise to spoiled cortical structures in\ndistinct ways and in distinct cortical areas. These alterations would disrupt\nthe codification of sensory stimuli, the representation of concepts and, thus,\nthe process of categorization - by this way imposing serious limits to the\nmental flexibility and to the capacity of generalization in the autistic\nreasoning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 20:20:09 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Madureira", "Daniele Q. M.", ""], ["Caminha", "Vera Lucia P. S.", ""], ["Salvini", "Rogerio", ""]]}, {"id": "1811.07408", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "Why Cognitive Science is Needed for a Viable Theoretical Framework for\n  Cultural Evolution", "comments": "7 pages (10 point font); 1 table;", "journal-ref": "Forthcoming in Proceedings of the 41st Annual Meeting of the\n  Cognitive Science Society. Austin TX: Cognitive Science Society. (2019)", "doi": null, "report-no": null, "categories": "q-bio.PE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Darwinian models are rampant in the social sciences, social\nscientists do not face the problem that motivated Darwin's theory of natural\nselection: the problem of explaining how lineages evolve despite that any\ntraits they acquire are regularly discarded at the end of the lifetime of the\nindividuals that acquired them. While the rationale for framing culture as an\nevolutionary process is correct, it does not follow that culture is a Darwinian\nor selectionist process, or that population genetics provides viable starting\npoints for modeling cultural change. This paper lays out step-by-step arguments\nas to why a selectionist approach to cultural evolution is inappropriate,\nfocusing on the lack of randomness, and lack of a self-assembly code. It\nsummarizes an alternative evolutionary approach to culture: self-other\nreorganization via context-driven actualization of potential.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 21:33:34 GMT"}, {"version": "v2", "created": "Thu, 22 Nov 2018 22:16:28 GMT"}, {"version": "v3", "created": "Mon, 26 Nov 2018 16:55:25 GMT"}, {"version": "v4", "created": "Mon, 22 Apr 2019 02:20:05 GMT"}, {"version": "v5", "created": "Fri, 5 Jul 2019 22:21:50 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1811.07423", "submitter": "Vince Grolmusz", "authors": "Mate Fellner and Balint Varga and Vince Grolmusz", "title": "The Frequent Network Neighborhood Mapping of the Human Hippocampus Shows\n  Much More Frequent Neighbor Sets in Males Than in Females", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the study of the human connectome, the vertices and the edges of the\nnetwork of the human brain are analyzed: the vertices of the graphs are the\nanatomically identified gray matter areas of the subjects; this set is exactly\nthe same for all the subjects. The edges of the graphs correspond to the axonal\nfibers, connecting these areas. In the biological applications of graph theory,\nit happens very rarely that scientists examine numerous large graphs on the\nvery same, labeled vertex set. Exactly this is the case in the study of the\nconnectomes. Because of the particularity of these sets of graphs, novel,\nrobust methods need to be developed for their analysis. Here we introduce the\nnew method of the Frequent Network Neighborhood Mapping for the connectome,\nwhich serves as a robust identification of the neighborhoods of given vertices\nof special interest in the graph. We apply the novel method for mapping the\nneighborhoods of the human hippocampus and discover strong statistical\nasymmetries between the connectomes of the sexes, computed from the Human\nConnectome Project. We analyze 413 braingraphs, each with 463 nodes. We show\nthat the hippocampi of men have much more significantly frequent neighbor sets\nthan women; therefore, in a sense, the connections of the hippocampi are more\nregularly distributed in men and more varied in women. Our results are in\ncontrast to the volumetric studies of the human hippocampus, where it was shown\nthat the relative volume of the hippocampus is the same in men and women.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 23:07:27 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 10:10:16 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Fellner", "Mate", ""], ["Varga", "Balint", ""], ["Grolmusz", "Vince", ""]]}, {"id": "1811.07433", "submitter": "Hidenori Tanaka", "authors": "Hidenori Tanaka and David R. Nelson", "title": "Non-Hermitian Quasi-Localization and Ring Attractor Neural Networks", "comments": null, "journal-ref": "Phys. Rev. E 99, 062406 (2019)", "doi": "10.1103/PhysRevE.99.062406", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eigenmodes of a broad class of \"sparse\" random matrices, with interactions\nconcentrated near the diagonal, exponentially localize in space, as initially\ndiscovered in 1957 by Anderson for quantum systems. Anderson localization plays\nubiquitous roles in varieties of problems from electrons in solids to\nmechanical and optical systems. However, its implications in neuroscience\n(where the connections can be strongly asymmetric) have been largely\nunexplored, mainly because synaptic connectivity matrices of neural systems are\noften \"dense\", which makes the eigenmodes spatially extended. Here, we explore\nroles that Anderson localization could be playing in neural networks by\nfocusing on \"spatially structured\" disorder in synaptic connectivity matrices.\nRecently, neuroscientists have experimentally confirmed that the local\nexcitation and global inhibition (LEGI) ring attractor model can functionally\nrepresent head direction cells in Drosophila melanogaster central brain. We\nfirst study a non-Hermitian (i.e. asymmetric) tight-binding model with disorder\nand then establish a connection to the LEGI ring attractor model. We discover\nthat (i) Principal eigenvectors of the LEGI ring attractor networks with\nstructured nearest neighbor disorder are \"quasi-localized\", even with fully\ndense inhibitory connections. (ii) The quasi-localized eigenvectors play\ndominant roles in the early time neural dynamics, and the location of the\nprincipal quasi-localized eigenvectors predict an initial location of the \"bump\nof activity\" representing, say, a head direction of an insect. Our\ninvestigations open up a new venue for explorations at the intersection between\nthe theory of Anderson localization and neural networks with spatially\nstructured disorder.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 00:28:58 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Tanaka", "Hidenori", ""], ["Nelson", "David R.", ""]]}, {"id": "1811.07592", "submitter": "Giulio Bondanelli", "authors": "Giulio Bondanelli and Srdjan Ostojic", "title": "Coding with transient trajectories in recurrent neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following a stimulus, the neural response typically strongly varies in time\nand across neurons before settling to a steady-state. While classical\npopulation coding theory disregards the temporal dimension, recent works have\nargued that trajectories of transient activity can be particularly informative\nabout stimulus identity and may form the basis of computations through\ndynamics. Yet the dynamical mechanisms needed to generate a population code\nbased on transient trajectories have not been fully elucidated. Here we examine\ntransient coding in a broad class of high-dimensional linear networks of\nrecurrently connected units. We start by reviewing a well-known result that\nleads to a distinction between two classes of networks: networks in which all\ninputs lead to weak, decaying transients, and networks in which specific inputs\nelicit strongly amplified transient responses and are mapped onto orthogonal\noutput states during the dynamics. Theses two classes are simply distinguished\nbased on the spectrum of the symmetric part of the connectivity matrix. For the\nsecond class of networks, which is a sub-class of non-normal networks, we\nprovide a procedure to identify transiently amplified inputs and the\ncorresponding readouts. We first apply these results to standard\nrandomly-connected and two-population networks. We then build minimal, low-rank\nnetworks that robustly implement trajectories mapping a specific input onto a\nspecific output state. Finally, we demonstrate that the capacity of the\nobtained networks increases proportionally with their size.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 10:25:31 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 13:52:11 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Bondanelli", "Giulio", ""], ["Ostojic", "Srdjan", ""]]}, {"id": "1811.08068", "submitter": "Xiaochen Liu", "authors": "X. Liu, P. Sanz-Leon, P. A. Robinson", "title": "Gamma-Band Correlations in Primary Visual Cortex", "comments": "23 pages; 12 figures", "journal-ref": "Phys. Rev. E 101, 042406 (2020)", "doi": "10.1103/PhysRevE.101.042406", "report-no": null, "categories": "q-bio.NC physics.bio-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural field theory is used to quantitatively analyze the two-dimensional\nspatiotemporal correlation properties of gamma-band (30 -- 70 Hz) oscillations\nevoked by stimuli arriving at the primary visual cortex (V1), and modulated by\npatchy connectivities that depend on orientation preference (OP). Correlation\nfunctions are derived analytically under different stimulus and measurement\nconditions. The predictions reproduce a range of published experimental\nresults, including the existence of two-point oscillatory temporal\ncross-correlations with zero time-lag between neurons with similar OP, the\ninfluence of spatial separation of neurons on the strength of the correlations,\nand the effects of differing stimulus orientations.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 04:28:28 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Liu", "X.", ""], ["Sanz-Leon", "P.", ""], ["Robinson", "P. A.", ""]]}, {"id": "1811.08210", "submitter": "Xing Hsu", "authors": "Xing Hsu, Zhifeng Zhao, Rongpeng Li, Honggang Zhang", "title": "Brain-Inspired Stigmergy Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stigmergy has proved its great superiority in terms of distributed control,\nrobustness and adaptability, thus being regarded as an ideal solution for\nlarge-scale swarm control problems. Based on new discoveries on astrocytes in\nregulating synaptic transmission in the brain, this paper has mapped stigmergy\nmechanism into the interaction between synapses and investigated its\ncharacteristics and advantages. Particularly, we have divided the interaction\nbetween synapses which are not directly connected into three phases and\nproposed a stigmergic learning model. In this model, the state change of a\nstigmergy agent will expand its influence to affect the states of others. The\nstrength of the interaction is determined by the level of neural activity as\nwell as the distance between stigmergy agents. Inspired by the morphological\nand functional changes in astrocytes during environmental enrichment, it is\nlikely that the regulation of distance between stigmergy agents plays a\ncritical role in the stigmergy learning process. Simulation results have\nverified its importance and indicated that the well-regulated distance between\nstigmergy agents can help to obtain stigmergy learning gain.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 12:36:25 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Hsu", "Xing", ""], ["Zhao", "Zhifeng", ""], ["Li", "Rongpeng", ""], ["Zhang", "Honggang", ""]]}, {"id": "1811.08428", "submitter": "Hau-tieng Wu", "authors": "Sankaraleengam Alagapan, Hae Won Shin, Flavio Frohlich, Hau-tieng Wu", "title": "Diffusion geometry approach to efficiently remove electrical stimulation\n  artifacts in intracranial electroencephalography", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph physics.data-an q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical oscillations, electrophysiological activity patterns, associated\nwith cognitive functions and impaired in many psychiatric disorders can be\nobserved in intracranial electroencephalography (iEEG). Direct cortical\nstimulation (DCS) may directly target these oscillations and may serve as\ntherapeutic approaches to restore functional impairments. However, the presence\nof electrical stimulation artifacts in neurophysiological data limits the\nanalysis of the effects of stimulation. Currently available methods suffer in\nperformance in the presence of nonstationarity inherent in biological data. Our\nalgorithm, Shape Adaptive Nonlocal Artifact Removal (SANAR) is based on\nunsupervised manifold learning. By estimating the Euclidean median of k nearest\nneighbors of each artifact in a nonlocal fashion, we obtain a faithful\nrepresentation of the artifact which is then subtracted. This approach\novercomes the challenges presented by nonstationarity. SANAR is effective in\nremoving stimulation artifacts in the time domain while preserving the spectral\ncontent of the endogenous neurophysiological signal. We demonstrate the\nperformance in a simulated dataset as well as in human iEEG data. Using two\nquantitative measures, that capture how much of information from endogenous\nactivity is retained, we demonstrate that SANAR's performance exceeds that of\none of the widely used approaches, independent component analysis, in the time\ndomain as well as the frequency domain. This approach allows for the analysis\nof iEEG data, single channel or multiple channels, during DCS, a crucial step\nin advancing our understanding of the effects of periodic stimulation and\ndeveloping new therapies.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 17:37:17 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Alagapan", "Sankaraleengam", ""], ["Shin", "Hae Won", ""], ["Frohlich", "Flavio", ""], ["Wu", "Hau-tieng", ""]]}, {"id": "1811.08465", "submitter": "Marcos Trevisan Dr.", "authors": "Diego E Shalom and Mariano Sigman and Gabriel Mindlin and Marcos A\n  Trevisan", "title": "Fading of collective attention shapes the evolution of linguistic\n  variants", "comments": "8 pages, 2 figures, 3 supplementary figures", "journal-ref": "Phys. Rev. E 100, 020102 (2019)", "doi": "10.1103/PhysRevE.100.020102", "report-no": null, "categories": "cs.CL physics.soc-ph q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Language change involves the competition between alternative linguistic forms\n(1). The spontaneous evolution of these forms typically results in monotonic\ngrowths or decays (2, 3) like in winner-take-all attractor behaviors. In the\ncase of the Spanish past subjunctive, the spontaneous evolution of its two\ncompeting forms (ended in -ra and -se) was perturbed by the appearance of the\nRoyal Spanish Academy in 1713, which enforced the spelling of both forms as\nperfectly interchangeable variants (4), at a moment in which the -ra form was\ndominant (5). Time series extracted from a massive corpus of books (6) reveal\nthat this regulation in fact produced a transient renewed interest for the old\nform -se which, once faded, left the -ra again as the dominant form up to the\npresent day. We show that time series are successfully explained by a\ntwo-dimensional linear model that integrates an imitative and a novelty\ncomponent. The model reveals that the temporal scale over which collective\nattention fades is in inverse proportion to the verb frequency. The integration\nof the two basic mechanisms of imitation and attention to novelty allows to\nunderstand diverse competing objects, with lifetimes that range from hours for\nmemes and news (7, 8) to decades for verbs, suggesting the existence of a\ngeneral mechanism underlying cultural evolution.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 19:54:41 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 14:38:13 GMT"}, {"version": "v3", "created": "Wed, 19 Dec 2018 16:37:49 GMT"}, {"version": "v4", "created": "Fri, 21 Dec 2018 01:47:32 GMT"}], "update_date": "2019-08-21", "authors_parsed": [["Shalom", "Diego E", ""], ["Sigman", "Mariano", ""], ["Mindlin", "Gabriel", ""], ["Trevisan", "Marcos A", ""]]}, {"id": "1811.08498", "submitter": "Joseph Hart", "authors": "J.L. Hart and P.A. Gremaud and T. David", "title": "Global Sensitivity Analysis of High Dimensional Neuroscience Models: An\n  Example of Neurovascular Coupling", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity and size of state-of-the-art cell models have significantly\nincreased in part due to the requirement that these models possess complex\ncellular functions which are thought--but not necessarily proven--to be\nimportant. Modern cell models often involve hundreds of parameters; the values\nof these parameters come, more often than not, from animal experiments whose\nrelationship to the human physiology is weak with very little information on\nthe errors in these measurements. The concomitant uncertainties in parameter\nvalues result in uncertainties in the model outputs or Quantities of Interest\n(QoIs). Global Sensitivity Analysis (GSA) aims at apportioning to individual\nparameters (or sets of parameters) their relative contribution to output\nuncertainty thereby introducing a measure of influence or importance of said\nparameters. New GSA approaches are required to deal with increased model size\nand complexity; a three stage methodology consisting of screening (dimension\nreduction), surrogate modeling, and computing Sobol' indices, is presented. The\nmethodology is used to analyze a physiologically validated numerical model of\nneurovascular coupling which possess 160 uncertain parameters. The sensitivity\nanalysis investigates three quantities of interest (QoIs), the average value of\n$K^+$ in the extracellular space, the average volumetric flow rate through the\nperfusing vessel, and the minimum value of the actin/myosin complex in the\nsmooth muscle cell. GSA provides a measure of the influence of each parameter,\nfor each of the three QoIs, giving insight into areas of possible physiological\ndysfunction and areas of further investigation.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 21:44:16 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Hart", "J. L.", ""], ["Gremaud", "P. A.", ""], ["David", "T.", ""]]}, {"id": "1811.08578", "submitter": "Bernard Marius 't Hart", "authors": "Ahmed A. Mostafa, Bernard Marius 't Hart, Denise Y.P. Henriques", "title": "Motor Learning Without Moving: Hand Localization after Passive Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An accurate estimate of limb position is necessary for movement. Where we\nlocalize our unseen hand after a reach depends on felt hand position, or\nproprioception, but often only predicted sensory consequences based on\nefference copies of motor commands are considered. Both signals should\ncontribute, so here we use passive training with rotated visual feedback of\nhand position to prevent updates of predicted sensory consequences, but still\nrecalibrate proprioception. After this training we measure participants' hand\nlocation estimates based on both efference-based predictions and afferent\nproprioceptive signals with self-generated hand movements as well as based on\nproprioception only with robot-generated movements. The changes in hand\nlocalization are equally large after training with robot- and self-generated\nhand movements. Both motor and proprioceptive changes are only slightly smaller\nas those after training with self-generated movements, confirming that\nrecalibrated proprioception contributes to motor learning.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 02:58:11 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Mostafa", "Ahmed A.", ""], ["Hart", "Bernard Marius 't", ""], ["Henriques", "Denise Y. P.", ""]]}, {"id": "1811.08763", "submitter": "Fani Deligianni Dr", "authors": "Fani Deligianni, Jonathan D. Clayden and Guang-Zhong Yang", "title": "Comparison of Brain Networks based on Predictive Models of Connectivity", "comments": "7 pages, 4 figures", "journal-ref": "19th IEEE International Conference on Bioinformatics and\n  Bioengineering (IEEE BIBE, 2019)", "doi": "10.1109/BIBE.2019.00029", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study we adopt predictive modelling to identify simultaneously\ncommonalities and differences in multi-modal brain networks acquired within\nsubjects. Typically, predictive modelling of functional connectomes from\nstructural connectomes explores commonalities across multimodal imaging data.\nHowever, direct application of multivariate approaches such as sparse Canonical\nCorrelation Analysis (sCCA) applies on the vectorised elements of functional\nconnectivity across subjects and it does not guarantee that the predicted\nmodels of functional connectivity are Symmetric Positive Matrices (SPD). We\nsuggest an elegant solution based on the transportation of the connectivity\nmatrices on a Riemannian manifold, which notably improves the prediction\nperformance of the model. Randomised lasso is used to alleviate the dependency\nof the sCCA on the lasso parameters and control the false positive rate.\nSubsequently, the binomial distribution is exploited to set a threshold\nstatistic that reflects whether a connection is selected or rejected by chance.\nFinally, we estimate the sCCA loadings based on a de-noising approach that\nimproves the estimation of the coefficients. We validate our approach based on\nresting-state fMRI and diffusion weighted MRI data. Quantitative validation of\nthe prediction performance shows superior performance, whereas qualitative\nresults of the identification process are promising.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 19:43:12 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2019 14:38:10 GMT"}], "update_date": "2019-11-06", "authors_parsed": [["Deligianni", "Fani", ""], ["Clayden", "Jonathan D.", ""], ["Yang", "Guang-Zhong", ""]]}, {"id": "1811.09229", "submitter": "Eric Lucon", "authors": "Eric Lu\\c{c}on", "title": "Quenched asymptotics for interacting diffusions on inhomogeneous random\n  graphs", "comments": "V2: 58 pages; references added, hypotheses simplified, theorem 2.15\n  generalized and Section 3 on applications reorganized. This is the version to\n  consider", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR math.AP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the paper is to address the behavior in large population of\ndiffusions interacting on a random, possibly diluted and inhomogeneous graph.\nThis is the natural continuation of a previous work, where the homogeneous\nErd\\H os-R\\'enyi case was considered. The class of graphs we consider includes\ndisordered $W$-random graphs, with possibly unbounded graphons. The main result\nconcerns a quenched convergence (that is true for almost every realization of\nthe random graph) of the empirical measure of the system towards the solution\nof a nonlinear Fokker-Planck PDE with spatial extension, also appearing in\ndifferent contexts, especially in neuroscience. The convergence of the spatial\nprofile associated to the diffusions is also considered, and one proves that\nthe limit is described in terms of a nonlinear integro-differential equation\nwhich matches the neural field equation in certain particular cases.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 16:28:19 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 13:27:44 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Lu\u00e7on", "Eric", ""]]}, {"id": "1811.09588", "submitter": "Liane Gabora", "authors": "Liane Gabora and Mike Unrau", "title": "Social Innovation and the Evolution of Creative, Sustainable Worldviews", "comments": "14 pages; 5 figures", "journal-ref": "In Lebuda, I. & Glaveanu, V. (Eds.) The Palgrave Handbook of\n  Social Creativity Research (pp. 541-558). Palgrave Macmillan (2018)", "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ideas that we forge creatively as individuals and groups build on one\nanother in a manner that is cumulative and adaptive, forming open-ended\nlineages across space and time. Thus, human culture is believed to evolve. The\npervasiveness of cross-domain creativity--as when a song inspires a\npainting--would appear indicative of discontinuities in cultural lineages.\nHowever, if what evolves through culture is our worldviews--the webs of\nthoughts, ideas, and attitudes that constitutes our way of seeing being in the\nworld--then the problem of discontinuities is solved. The state of a worldview\ncan be affected by information assimilated in one domain, and this\nchange-of-state can be expressed in another domain. In this view, the gesture,\nnarrative, or artifact that constitutes a specific creative act is not what is\nevolving; it is merely the external manifestation of the state of an evolving\nworldview. Like any evolutionary process, cultural evolution requires a balance\nbetween novelty, via the generation of variation, and continuity, via the\npreservation of variants that are adaptive. In cultural evolution, novelty is\ngenerated through creativity, and continuity is provided by social learning\nprocesses, e.g., imitation. Both the generative and imitative aspects of\ncultural evolution are affected by social media. We discuss the trajectory from\nsocial ideation to social innovation, focusing on the role of\nself-organization, renewal, and perspective-taking at the individual and social\ngroup level.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 18:23:32 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 22:14:21 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Gabora", "Liane", ""], ["Unrau", "Mike", ""]]}, {"id": "1811.09699", "submitter": "Hossein Adeli", "authors": "Hossein Adeli, Gregory Zelinsky", "title": "Learning to attend in a brain-inspired deep neural network", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent machine learning models have shown that including attention as a\ncomponent results in improved model accuracy and interpretability, despite the\nconcept of attention in these approaches only loosely approximating the brain's\nattention mechanism. Here we extend this work by building a more brain-inspired\ndeep network model of the primate ATTention Network (ATTNet) that learns to\nshift its attention so as to maximize the reward. Using deep reinforcement\nlearning, ATTNet learned to shift its attention to the visual features of a\ntarget category in the context of a search task. ATTNet's dorsal layers also\nlearned to prioritize these shifts of attention so as to maximize success of\nthe ventral pathway classification and receive greater reward. Model behavior\nwas tested against the fixations made by subjects searching images for the same\ncued category. Both subjects and ATTNet showed evidence for attention being\npreferentially directed to target goals, behaviorally measured as oculomotor\nguidance to targets. More fundamentally, ATTNet learned to shift its attention\nto target like objects and spatially route its visual inputs to accomplish the\ntask. This work makes a step toward a better understanding of the role of\nattention in the brain and other computational systems.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 21:23:56 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Adeli", "Hossein", ""], ["Zelinsky", "Gregory", ""]]}, {"id": "1811.09739", "submitter": "Sabyasachi Shivkumar", "authors": "Sabyasachi Shivkumar, Richard D. Lange, Ankani Chattoraj, Ralf M.\n  Haefner", "title": "A probabilistic population code based on neural samples", "comments": "First three contributed equally to the work", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensory processing is often characterized as implementing probabilistic\ninference: networks of neurons compute posterior beliefs over unobserved causes\ngiven the sensory inputs. How these beliefs are computed and represented by\nneural responses is much-debated (Fiser et al. 2010, Pouget et al. 2013). A\ncentral debate concerns the question of whether neural responses represent\nsamples of latent variables (Hoyer & Hyvarinnen 2003) or parameters of their\ndistributions (Ma et al. 2006) with efforts being made to distinguish between\nthem (Grabska-Barwinska et al. 2013). A separate debate addresses the question\nof whether neural responses are proportionally related to the encoded\nprobabilities (Barlow 1969), or proportional to the logarithm of those\nprobabilities (Jazayeri & Movshon 2006, Ma et al. 2006, Beck et al. 2012).\nHere, we show that these alternatives - contrary to common assumptions - are\nnot mutually exclusive and that the very same system can be compatible with all\nof them. As a central analytical result, we show that modeling neural responses\nin area V1 as samples from a posterior distribution over latents in a linear\nGaussian model of the image implies that those neural responses form a linear\nProbabilistic Population Code (PPC, Ma et al. 2006). In particular, the\nposterior distribution over some experimenter-defined variable like\n\"orientation\" is part of the exponential family with sufficient statistics that\nare linear in the neural sampling-based firing rates.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 01:26:04 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Shivkumar", "Sabyasachi", ""], ["Lange", "Richard D.", ""], ["Chattoraj", "Ankani", ""], ["Haefner", "Ralf M.", ""]]}, {"id": "1811.09922", "submitter": "Takuma Tanaka", "authors": "Takuma Tanaka", "title": "The most probable neural circuit exhibits low-dimensional sustained\n  activity", "comments": "22 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cond-mat.dis-nn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cortical neurons whose activity is recorded in behavioral experiments has\nbeen classified into several types such as stimulus-related neurons,\ndelay-period neurons, and reward-related neurons. Moreover, the population\nactivity of neurons during a reaching task can be described by dynamics in\nlow-dimensional space. These results suggest that the low-dimensional dynamics\nof a few types of neurons emerge in the cerebral cortex that is trained to\nperform a task. This study investigates a simple neural circuit emerges with a\nfew types of neurons. Assuming an infinite number of neurons in the circuit\nwith connection weights drawn from a Gaussian distribution, we model the\ndynamics of neurons by using a kernel function. Given that the system is\ninfinitely large, almost all capable circuits approximate the most probable\ncircuit for the task. We simulate two delayed response tasks and a\nmotor-pattern generation task. The model network exhibits low-dimensional\ndynamics in all tasks. Considering that the connection weights are drawn from a\nGaussian distribution, the most probable circuit is the circuit with the\nsmallest connection weight; that is, the simplest circuit with the simplest\ndynamics. Finally, we relate the dynamics to algorithmic information theory.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 01:42:12 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Tanaka", "Takuma", ""]]}, {"id": "1811.10005", "submitter": "Yashaswini Murthy", "authors": "Yashaswini Murthy", "title": "Nonlinear Dynamics of Binocular Rivalry: A Comparative Study", "comments": "6 pages, 7 sets of figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When our eyes are presented with the same image, the brain processes it to\nview it as a single coherent one. The lateral shift in the position of our\neyes, causes the two images to possess certain differences, which our brain\nexploits for the purpose of depth perception and to gauge the size of objects\nat different distances, a process commonly known as stereopsis. However, when\npresented with two different visual stimuli, the visual awareness alternates.\nThis phenomenon of binocular rivalry is a result of competition between the\ncorresponding neuronal populations of the two eyes. The article presents a\ncomparative study of various dynamical models proposed to capture this process.\nIt goes on to study the effect of a certain parameter on the rate of perceptual\nalternations and proceeds to disprove the initial propositions laid down to\ncharacterise this phenomenon. It concludes with a discussion on the possible\nfuture work that can be conducted to obtain a better picture of the neuronal\nfunctioning behind this rivalry.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 13:16:07 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Murthy", "Yashaswini", ""]]}, {"id": "1811.10111", "submitter": "Abhay Koushik", "authors": "Abhay Koushik, Judith Amores and Pattie Maes", "title": "Real-Time Sleep Staging using Deep Learning on a Smartphone for a\n  Wearable EEG", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": null, "doi": null, "report-no": "ML4H/2018/114", "categories": "cs.HC cs.LG eess.SP q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first real-time sleep staging system that uses deep learning\nwithout the need for servers in a smartphone application for a wearable EEG. We\nemploy real-time adaptation of a single channel Electroencephalography (EEG) to\ninfer from a Time-Distributed 1-D Deep Convolutional Neural Network.\nPolysomnography (PSG)-the gold standard for sleep staging, requires a human\nscorer and is both complex and resource-intensive. Our work demonstrates an\nend-to-end on-smartphone pipeline that can infer sleep stages in just single\n30-second epochs, with an overall accuracy of 83.5% on 20-fold cross validation\nfor five-class classification of sleep stages using the open Sleep-EDF dataset.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 22:25:31 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 02:30:23 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Koushik", "Abhay", ""], ["Amores", "Judith", ""], ["Maes", "Pattie", ""]]}, {"id": "1811.10272", "submitter": "Fabrizio Lombardi", "authors": "Fabrizio Lombardi, Hans J. Herrmann and L. de Arcangelis", "title": "Avalanche Dynamics and Correlations in Neural Systems", "comments": "Conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.stat-mech nlin.AO q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existence of power-law distributions is only a first requirement in the\nvalidation of the critical behavior of a system. Long-range spatio-temporal\ncorrelations are fundamental for the spontaneous neuronal activity to be the\nexpression of a system acting close to a critical point. This chapter focuses\non temporal correlations and avalanche dynamics in the spontaneous activity of\ncortex slice cultures and in the resting fMRI BOLD signal. Long-range\ncorrelations are investigated by means of the scaling of power spectra and of\nDetrended Fluctuations Analysis. The existence of 1/f decay in the power\nspectrum, as well as of power-law scaling in the root mean square fluctuations\nfunction for the appropriate balance of excitation and inhibition suggests that\nlong-range temporal correlations are distinctive of \"healthy brains\". The\ncorresponding temporal organization of neuronal avalanches can be dissected by\nanalyzing the distribution of inter-event times between successive events. In\nrat cortex slice cultures this distribution exhibits a non-monotonic behavior,\nnot usually found in other natural processes. Numerical simulations provide\nevidences that this behavior is a consequence of the alternation between states\nof high and low activity, leading to a dynamic balance between excitation and\ninhibition that tunes the system at criticality. In this scenario, inter-times\nshow a peculiar relation with avalanche sizes, resulting in a hierarchical\nstructure of avalanche sequences. Large avalanches correspond to low-frequency\noscillations, and trigger cascades of smaller avalanches that are part of\nhigher frequency rhythms. The self-regulated balance of excitation and\ninhibition observed in cultures is confirmed at larger scales, i.e. on fMRI\ndata from resting brain activity, and appears to be closely related to critical\nfeatures of avalanche activity.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 10:22:53 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Lombardi", "Fabrizio", ""], ["Herrmann", "Hans J.", ""], ["de Arcangelis", "L.", ""]]}, {"id": "1811.10431", "submitter": "Liane Gabora", "authors": "Liane Gabora and Cameron M. Smith", "title": "Two Cognitive Transitions Underlying the Capacity for Cultural Evolution", "comments": "31 pages, 4 figures, 3 tables. arXiv admin note: text overlap with\n  arXiv:1310.4086", "journal-ref": "Journal of Anthropological Sciences, 96, 1-26 (2018)", "doi": "10.4436/jass.96008", "report-no": null, "categories": "q-bio.NC cs.MA q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes that the distinctively human capacity for cumulative,\nadaptive, open-ended cultural evolution came about through two\ntemporally-distinct cognitive transitions. First, the origin of Homo-specific\nculture over two MYA was made possible by the onset of a finer-grained\nassociative memory that allowed episodes to be encoded in greater detail. This\nin turn meant more overlap amongst the distributed representations of these\nepisodes, such that they could more readily evoke one another through\nself-triggered recall (STR). STR enabled representational redescription, the\nchaining of thoughts and actions, and the capacity for a stream of thought.\nSecond, fully cognitive modernity following the appearance of anatomical\nmodernity after 200,000 BP, was made possible by the onset of contextual focus\n(CF): the ability to shift between an explicit convergent mode conducive to\nlogic and refinement of ideas, and an implicit divergent mode conducive to\nfree-association, viewing situations from radically new perspectives, concept\ncombination, analogical thinking, and insight. This paved the way for an\nintegrated, creative internal network of understandings, and behavioral\nmodernity. We discuss feasible neural mechanisms for this two-stage proposal,\nand outline how STR and CF differ from other proposals. We provide\ncomputational evidence for the proposal obtained with an agent-based model of\ncultural evolution in which agents invent ideas for actions and imitate the\nfittest of their neighbors' actions. Mean fitness and diversity of actions\nacross the artificial society increased with STR, and even more so with CF, but\nCF was only effective if STR was already in place. CF was most effective\nfollowing a change in task, which supports its hypothesized role in escaping\nmental fixation. The proposal is discussed in the context of transition theory\nin the life sciences.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 06:11:50 GMT"}, {"version": "v2", "created": "Fri, 5 Jul 2019 22:02:14 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Gabora", "Liane", ""], ["Smith", "Cameron M.", ""]]}, {"id": "1811.11040", "submitter": "Jos\\'e Halloy", "authors": "Leo Cazenille, Nicolas Bredeche, Jos\\'e Halloy", "title": "Modelling zebrafish collective behaviours with multilayer perceptrons\n  optimised by evolutionary algorithms", "comments": "22 pages, 11 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:1808.03166", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective movements are pervasive behaviours among social organisms and have\nled to the development of many models. However, modelling animal trajectories\nand social interactions in simple bounded environments remains a challenge.\nMoreover, advances in the understanding of the sensory-motor loop and the\ninformation processing by animals are leading to revisions of the traditional\nassumptions made in decision-making algorithms. In this context, we develop a\nmethodology based on artificial neural networks (ANN) to describe the\ncollective motion of small zebrafish groups in a bounded environment. Although\nANN models are commonly used in artificial systems they are still\nunder-explored to model animal collective behaviours. Here, we present a\nmethodology to calibrate Multilayer Perceptrons by learning from real fish\nexperimental data. The ANNs are trained using either supervised learning or\nvarious forms of evolutionary reinforcement learning methods (using the CMA-ES\nand NSGA-III algorithms). We reveal that ANN models trained using evolutionary\nmethods are capable of generating realistic collective motions for groups of 5\nzebrafish including the tank wall effects, a feature that is lacking in\nprevious models. Finally, we also discuss the benefits of optimised ANNs as\ncandidates for driving robotic lure with biologically realistic behaviour, a\nmethod that is becoming increasingly popular to gather data and validate\nassumptions on collective behaviours.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 15:31:21 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Cazenille", "Leo", ""], ["Bredeche", "Nicolas", ""], ["Halloy", "Jos\u00e9", ""]]}, {"id": "1811.11236", "submitter": "Liane Gabora", "authors": "Liane Gabora", "title": "The Making of a Creative Worldview", "comments": "Chapter prepared for Suzanne Nalbantian and Paul Matthews (eds.)\n  'Secrets of Creativity': Oxford University Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research at the interface between cognitive psychology, neuroscience, and the\nscience of complex, dynamical systems, is piecing together an understanding of\nthe creative process, including how it works, how it can be fostered, and the\ndevelopmental antecedents and personality traits of particularly creative\npeople. This chapter examines the workings of creative minds, those with the\npotential to significantly impact the evolution of human culture.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 20:14:31 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Gabora", "Liane", ""]]}, {"id": "1811.11388", "submitter": "Pavel Tolmachev", "authors": "Pavel Tolmachev, Rishi R. Dhingra, Michael Pauley, Mathias Dutschmann,\n  and Jonathan H. Manton", "title": "Modeling the respiratory Central Pattern Generator with\n  resonate-and-fire Izhikevich-Neurons", "comments": "12 Pages, ICONIP 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational models of the respiratory central pattern generator (rCPG) are\nusually based on biologically-plausible Hodgkin Huxley neuron models. Such\nmodels require numerous parameters and thus are prone to overfitting. The HH\napproach is motivated by the assumption that the biophysical properties of\nneurons determine the network dynamics. Here, we implement the rCPG using\nsimpler Izhikevich resonate-and-fire neurons. Our rCPG model generates a\n3-phase respiratory motor pattern based on established connectivities and can\nreproduce previous experimental and theoretical observations. Further, we\ndemonstrate the flexibility of the model by testing whether intrinsic bursting\nproperties are necessary for rhythmogenesis. Our simulations demonstrate that\nreplacing predicted mandatory bursting properties of pre-inspiratory neurons\nwith spike adapting properties yields a model that generates comparable\nrespiratory activity patterns. The latter supports our view that the importance\nof the exact modeling parameters of specific respiratory neurons is\noverestimated.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 05:05:01 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Tolmachev", "Pavel", ""], ["Dhingra", "Rishi R.", ""], ["Pauley", "Michael", ""], ["Dutschmann", "Mathias", ""], ["Manton", "Jonathan H.", ""]]}, {"id": "1811.11423", "submitter": "Corentin Vallee", "authors": "Corouge Isabelle (VisAGeS), Corentin Vall\\'ee (VisAGeS), Pierre Maurel\n  (VisAGeS), Isabelle Corouge, Christian Barillot (VisAGeS)", "title": "Resting-state ASL : Toward an optimal sequence duration", "comments": null, "journal-ref": "International Society for Magnetic Resonance in Medicine, 2018,\n  Paris, France. https://www.ismrm.org/", "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resting-state functional Arterial Spin Labeling (rs-fASL) in clinical daily\npractice and academic research stay discreet compared to resting-state BOLD.\nHowever, by giving direct access to cerebral blood flow maps, rs-fASL leads to\nsignificant clinical subject scaled application as CBF can be considered as a\nbiomarker in common neuropathology. Our work here focuses on the link between\noverall quality of rs-fASL and duration of acquisition. To this end, we\nconsider subject self-Default Mode Network (DMN), and assess DMN quality\ndepletion compared to a gold standard DMN depending on the duration of\nacquisition.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 07:48:36 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Isabelle", "Corouge", "", "VisAGeS"], ["Vall\u00e9e", "Corentin", "", "VisAGeS"], ["Maurel", "Pierre", "", "VisAGeS"], ["Corouge", "Isabelle", "", "VisAGeS"], ["Barillot", "Christian", "", "VisAGeS"]]}, {"id": "1811.11658", "submitter": "Nadja Tschentscher", "authors": "Nadja Tschentscher, Anja Ruisinger, Helen Blank, Begona Diaz,\n  Katharina von Kriegstein", "title": "Reduced structural connectivity between left auditory thalamus and the\n  motion-sensitive planum temporale in developmental dyslexia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developmental dyslexia is characterized by the inability to acquire typical\nreading and writing skills. Dyslexia has been frequently linked to cerebral\ncortex alterations; however recent evidence also points towards sensory\nthalamus dysfunctions: dyslexics showed reduced responses in the left auditory\nthalamus (medial geniculate body, MGB) during speech processing in contrast to\nneurotypical readers. In addition, in the visual modality, dyslexics have\nreduced structural connectivity between the left visual thalamus (lateral\ngeniculate nucleus, LGN) and V5/MT, a cerebral cortex region involved in visual\nmovement processing. Higher LGN-V5/MT connectivity in dyslexics was associated\nwith the faster rapid naming of letters and numbers (RANln), a measure that is\nhighly correlated with reading proficiency. We here tested two hypotheses that\nwere directly derived from these previous findings. First, we tested the\nhypothesis that dyslexics have reduced structural connectivity between the left\nMGB and the auditory motion-sensitive part of the left planum temporale (mPT).\nSecond, we hypothesized that the amount of left mPT-MGB connectivity correlates\nwith dyslexics RANln scores. Using diffusion tensor imaging based probabilistic\ntracking we show that male adults with developmental dyslexia have reduced\nstructural connectivity between the left MGB and the left mPT, confirming the\nfirst hypothesis. Stronger left mPT-MGB connectivity was not associated with\nfaster RANnl scores in dyslexics, but in neurotypical readers. Our findings\nprovide first evidence that reduced cortico-thalamic connectivity in the\nauditory modality is a feature of developmental dyslexia, and that it may also\nimpact on reading related cognitive abilities in neurotypical readers.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 16:31:43 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Tschentscher", "Nadja", ""], ["Ruisinger", "Anja", ""], ["Blank", "Helen", ""], ["Diaz", "Begona", ""], ["von Kriegstein", "Katharina", ""]]}, {"id": "1811.11687", "submitter": "Giulia De Bonis", "authors": "Marco Celotto, Chiara De Luca, Paolo Muratore, Francesco Resta, Anna\n  Letizia Allegra Mascaro, Francesco Saverio Pavone, Giulia De Bonis, Pier\n  Stanislao Paolucci", "title": "Analysis and Model of Cortical Slow Waves Acquired with Optical\n  Techniques", "comments": "26 pages, 19 figures, 1 table", "journal-ref": "Methods Protoc. 2020, 3(1), 14", "doi": "10.3390/mps3010014", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Slow waves (SWs) are spatio-temporal patterns of cortical activity that occur\nboth during natural sleep and anesthesia and are preserved across species. Even\nthough electrophysiological recordings have been largely used to characterize\nbrain states, they are limited in the spatial resolution and cannot target\nspecific neuronal population. Recently, large-scale optical imaging techniques\ncoupled with functional indicators overcame these restrictions, and new\npipelines of analysis and novel approaches of SWs modelling are needed to\nextract relevant features of the spatio-temporal dynamics of SWs from these\nhighly spatially resolved data-sets. Here we combined wide-field fluorescence\nmicroscopy and a transgenic mouse model expressing a calcium indicator\n(GCaMP6f) in excitatory neurons to study SW propagation over the meso-scale\nunder ketamine anesthesia. We developed a versatile analysis pipeline to\nidentify and quantify the spatio-temporal propagation of the SWs. Moreover, we\ndesigned a computational simulator based on a simple theoretical model, which\ntakes into account the statistics of neuronal activity, the response of\nfluorescence proteins and the slow waves dynamics. The simulator was capable of\nsynthesizing artificial signals that could reliably reproduce several features\nof the SWs observed in vivo, thus enabling a calibration tool for the analysis\npipeline. Comparison of experimental and simulated data shows the robustness of\nthe analysis tools and its potential to uncover mechanistic insights of the\nSlow Wave Activity (SWA).\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:12:53 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 13:34:21 GMT"}, {"version": "v3", "created": "Fri, 31 Jan 2020 09:13:31 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Celotto", "Marco", ""], ["De Luca", "Chiara", ""], ["Muratore", "Paolo", ""], ["Resta", "Francesco", ""], ["Mascaro", "Anna Letizia Allegra", ""], ["Pavone", "Francesco Saverio", ""], ["De Bonis", "Giulia", ""], ["Paolucci", "Pier Stanislao", ""]]}, {"id": "1811.11688", "submitter": "Jeremy Guillon", "authors": "Jeremy Guillon, Mario Chavez, Federico Battiston, Yohan Attal,\n  Valentina La Corte, Michel Thiebaut de Schotten, Bruno Dubois, Denis\n  Schwartz, Olivier Colliot and Fabrizio De Vico Fallani", "title": "Disrupted core-periphery structure of multimodal brain networks in\n  Alzheimer's Disease", "comments": "5 figures, 1 table, 1 supplementary figure, 2 supplementary tables", "journal-ref": "Network Neuroscience 2019", "doi": "10.1162/netn_a_00087", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Alzheimer's disease (AD), the progressive atrophy leads to aberrant\nnetwork reconfigurations both at structural and functional levels. In such\nnetwork reorganization, the core and peripheral nodes appear to be crucial for\nthe prediction of clinical outcome due to their ability to influence\nlarge-scale functional integration. However, the role of the different types of\nbrain connectivity in such prediction still remains unclear. Using a multiplex\nnetwork approach we integrated information from DWI, fMRI and MEG brain\nconnectivity to extract an enriched description of the core-periphery structure\nin a group of AD patients and age-matched controls. Globally, the regional\ncoreness - i.e., the probability of a region to be in the multiplex core -\nsignificantly decreased in AD patients as a result of the randomization process\ninitiated by the neurodegeneration. Locally, the most impacted areas were in\nthe core of the network - including temporal, parietal and occipital areas -\nwhile we reported compensatory increments for the peripheral regions in the\nsensorimotor system. Furthermore, these network changes significantly predicted\nthe cognitive and memory impairment of patients. Taken together these results\nindicate that a more accurate description of neurodegenerative diseases can be\nobtained from the multimodal integration of neuroimaging-derived network data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 17:14:48 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 16:41:21 GMT"}], "update_date": "2019-06-10", "authors_parsed": [["Guillon", "Jeremy", ""], ["Chavez", "Mario", ""], ["Battiston", "Federico", ""], ["Attal", "Yohan", ""], ["La Corte", "Valentina", ""], ["de Schotten", "Michel Thiebaut", ""], ["Dubois", "Bruno", ""], ["Schwartz", "Denis", ""], ["Colliot", "Olivier", ""], ["Fallani", "Fabrizio De Vico", ""]]}, {"id": "1811.11876", "submitter": "Rajesh Rao", "authors": "Rajesh P. N. Rao", "title": "Towards Neural Co-Processors for the Brain: Combining Decoding and\n  Encoding in Brain-Computer Interfaces", "comments": "Invited submission to the journal Current Opinion in Neurobiology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of brain-computer interfaces is poised to advance from the\ntraditional goal of controlling prosthetic devices using brain signals to\ncombining neural decoding and encoding within a single neuroprosthetic device.\nSuch a device acts as a \"co-processor\" for the brain, with applications ranging\nfrom inducing Hebbian plasticity for rehabilitation after brain injury to\nreanimating paralyzed limbs and enhancing memory. We review recent progress in\nsimultaneous decoding and encoding for closed-loop control and plasticity\ninduction. To address the challenge of multi-channel decoding and encoding, we\nintroduce a unifying framework for developing brain co-processors based on\nartificial neural networks and deep learning. These \"neural co-processors\" can\nbe used to jointly optimize cost functions with the nervous system to achieve\ndesired behaviors ranging from targeted neuro-rehabilitation to augmentation of\nbrain function.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 23:13:24 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 18:56:32 GMT"}], "update_date": "2018-12-31", "authors_parsed": [["Rao", "Rajesh P. N.", ""]]}, {"id": "1811.12091", "submitter": "Patrick Krauss", "authors": "Patrick Krauss, Karin Prebeck, Achim Schilling, Claus Metzner", "title": "Stochastic resonance in three-neuron motifs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic resonance is a non-linear phenomenon, in which the sensitivity of\nsignal detectors can be enhanced by adding random noise to the detector input.\nHere, we demonstrate that noise can also improve the information flux in\nrecurrent neural networks. In particular, we show for the case of three-neuron\nmotifs that the mutual information between successive network states can be\nmaximized by adding a suitable amount of noise to the neuron inputs. This\nstriking result suggests that noise in the brain may not be a problem that\nneeds to be suppressed, but indeed a resource that is dynamically regulated in\norder to optimize information processing.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 12:12:47 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Krauss", "Patrick", ""], ["Prebeck", "Karin", ""], ["Schilling", "Achim", ""], ["Metzner", "Claus", ""]]}, {"id": "1811.12153", "submitter": "Diego Fasoli", "authors": "Diego Fasoli, Stefano Panzeri", "title": "Stationary-State Statistics of a Binary Neural Network Model with\n  Quenched Disorder", "comments": "30 pages, 6 figures, 2 supplemental Python scripts", "journal-ref": null, "doi": "10.3390/e21070630", "report-no": null, "categories": "q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the statistical properties of the stationary firing-rate states of a\nneural network model with quenched disorder. The model has arbitrary size,\ndiscrete-time evolution equations and binary firing rates, while the topology\nand the strength of the synaptic connections are randomly generated from known,\ngenerally arbitrary, probability distributions. We derived semi-analytical\nexpressions of the occurrence probability of the stationary states and the mean\nmultistability diagram of the model, in terms of the distribution of the\nsynaptic connections and of the external stimuli to the network. Our\ncalculations rely on the probability distribution of the bifurcation points of\nthe stationary states with respect to the external stimuli, which can be\ncalculated in terms of the permanent of special matrices, according to extreme\nvalue theory. While our semi-analytical expressions are exact for any size of\nthe network and for any distribution of the synaptic connections, we also\nspecialized our calculations to the case of statistically-homogeneous\nmulti-population networks. In the specific case of this network topology, we\ncalculated analytically the permanent, obtaining a compact formula that\noutperforms of several orders of magnitude the\nBalasubramanian-Bax-Franklin-Glynn algorithm. To conclude, by applying the\nFisher-Tippett-Gnedenko theorem, we derived asymptotic expressions of the\nstationary-state statistics of multi-population networks in the\nlarge-network-size limit, in terms of the Gumbel (double exponential)\ndistribution. We also provide a Python implementation of our formulas and some\nexamples of the results generated by the code.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 14:11:24 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Fasoli", "Diego", ""], ["Panzeri", "Stefano", ""]]}, {"id": "1811.12231", "submitter": "Robert Geirhos", "authors": "Robert Geirhos, Patricia Rubisch, Claudio Michaelis, Matthias Bethge,\n  Felix A. Wichmann, Wieland Brendel", "title": "ImageNet-trained CNNs are biased towards texture; increasing shape bias\n  improves accuracy and robustness", "comments": "Accepted at ICLR 2019 (oral)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are commonly thought to recognise\nobjects by learning increasingly complex representations of object shapes. Some\nrecent studies suggest a more important role of image textures. We here put\nthese conflicting hypotheses to a quantitative test by evaluating CNNs and\nhuman observers on images with a texture-shape cue conflict. We show that\nImageNet-trained CNNs are strongly biased towards recognising textures rather\nthan shapes, which is in stark contrast to human behavioural evidence and\nreveals fundamentally different classification strategies. We then demonstrate\nthat the same standard architecture (ResNet-50) that learns a texture-based\nrepresentation on ImageNet is able to learn a shape-based representation\ninstead when trained on \"Stylized-ImageNet\", a stylized version of ImageNet.\nThis provides a much better fit for human behavioural performance in our\nwell-controlled psychophysical lab setting (nine experiments totalling 48,560\npsychophysical trials across 97 observers) and comes with a number of\nunexpected emergent benefits such as improved object detection performance and\npreviously unseen robustness towards a wide range of image distortions,\nhighlighting advantages of a shape-based representation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:04:05 GMT"}, {"version": "v2", "created": "Mon, 14 Jan 2019 13:59:09 GMT"}], "update_date": "2019-01-15", "authors_parsed": [["Geirhos", "Robert", ""], ["Rubisch", "Patricia", ""], ["Michaelis", "Claudio", ""], ["Bethge", "Matthias", ""], ["Wichmann", "Felix A.", ""], ["Brendel", "Wieland", ""]]}, {"id": "1811.12245", "submitter": "Greg Murray", "authors": "Greg Murray, Catherine Orr, Jamie E. M. Byrne, Matthew E. Hughes,\n  Susan L. Rossell, Sheri L. Johnson", "title": "Effect of time of day on reward circuitry: Further thoughts on methods,\n  prompted by Steel et al 2018", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The interplay between circadian and reward function is well understood in\nanimal models, and is of growing interest as an aetiological explanation in\npsychopathologies. Circadian modulation of reward function has been\ndemonstrated in human behavioural data, but understanding at the neural level\nis limited. In 2017, our group published results of a first step in addressing\nthis deficit, demonstrating a diurnal rhythm in fMRI-measured reward\nactivation. In 2018, Steel et al wrote a constructive critique of our findings,\nand the aim of this paper is to outline how future research could improve on\nour first proof-of-concept study. Key challenges include addressing divergent\nand convergent validity (by addressing non-reward neural variation, and testing\nfor absence of variation in threat-related pathways), preregistration and power\nanalysis to protect against false positives, wider range of fMRI methods (to\ndirectly test our post-hoc hypothesis of some form of reward prediction error,\nand multiple phases of reward), the parallel collection of behavioural data\n(particularly self-reported positive affect, and actigraphically measured\nactivity) to illuminate the nature of the reward activation across the day, and\nsome attempt to parse out circadian versus homeostatic/masking influences on\nany observed diurnal rhythm in neural reward activation.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 01:55:57 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 05:05:49 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Murray", "Greg", ""], ["Orr", "Catherine", ""], ["Byrne", "Jamie E. M.", ""], ["Hughes", "Matthew E.", ""], ["Rossell", "Susan L.", ""], ["Johnson", "Sheri L.", ""]]}, {"id": "1811.12314", "submitter": "Zhiqin Xu", "authors": "Zhi-Qin John Xu, Douglas Zhou, David Cai", "title": "Swift Two-sample Test on High-dimensional Neural Spiking Data", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To understand how neural networks process information, it is important to\ninvestigate how neural network dynamics varies with respect to different\nstimuli. One challenging task is to design efficient statistical approaches to\nanalyze multiple spike train data obtained from a short recording time. Based\non the development of high-dimensional statistical methods, it is able to deal\nwith data whose dimension is much larger than the sample size. However, these\nmethods often require statistically independent samples to start with, while\nneural data are correlated over consecutive sampling time bins. We develop an\napproach to pretreat neural data to become independent samples over time by\ntransferring the correlation of dynamics for each neuron in different sampling\ntime bins into the correlation of dynamics among different dimensions within\neach sampling time bin. We verify the method using simulation data generated\nfrom Integrate-and-fire neuron network models and a large-scale network model\nof primary visual cortex within a short time, e.g., a few seconds. Our method\nmay offer experimenters to use the advantage of the development of statistical\nmethods to analyze high-dimensional neural data.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 20:40:41 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Xu", "Zhi-Qin John", ""], ["Zhou", "Douglas", ""], ["Cai", "David", ""]]}, {"id": "1811.12496", "submitter": "Peter Solazzo", "authors": "Peter G. Solazzo", "title": "A Theory of Decision Making Based on Feynman's Path Integral Formulation\n  of Quantum Mechanics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarities between the non-deterministic nature of quantum theory and the\nunpredictable patterns of human cognition and decision making have been\nobserved and commented on many times since the invention of Quantum Mechanics\nin the first part of the 20th century. Niels Bohr himself took note of the\nparallels.[3] In fact, an entire field of study, Quantum Cognition, has been\nborne from the study of this analogy. [3] However, many of the attempts to\nmodel human behavior with quantum mechanics conflate the identity of a particle\nwith its own wavefunction, which is incorrect and invalidates the analogy. In\nthis paper, we seek to make explicit this error, make necessary corrections,\nand then deepen the analogy. We do this by creating a Quantum Decision Theory\nthat directly parallels Richard Feynman's novel formulation of quantum\nmechanics published in 1948 at Cornell University: Space-Time Approach to\nNon-Relativistic Quantum Mechanics\".\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 16:40:42 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 19:36:11 GMT"}], "update_date": "2019-09-08", "authors_parsed": [["Solazzo", "Peter G.", ""]]}, {"id": "1811.12642", "submitter": "Tomasz Rutkowski", "authors": "Tomasz M. Rutkowski, Qibin Zhao, Masao S. Abe, Mihoko Otake", "title": "AI Neurotechnology for Aging Societies -- Task-load and Dementia EEG\n  Digital Biomarker Development Using Information Geometry Machine Learning\n  Methods", "comments": "5 pages, 2 figures, NeurIPS 2018 AI for Social Good Workshop at the\n  Neural Information Processing Systems (NeurIPS = formerly NIPS) 2018.\n  Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dementia and especially Alzheimer's disease (AD) are the most common causes\nof cognitive decline in elderly people. A spread of the above mentioned mental\nhealth problems in aging societies is causing a significant medical and\neconomic burden in many countries around the world. According to a recent World\nHealth Organization (WHO) report, it is approximated that currently, worldwide,\nabout 47 million people live with a dementia spectrum of neurocognitive\ndisorders. This number is expected to triple by 2050, which calls for possible\napplication of AI-based technologies to support an early screening for\npreventive interventions and a subsequent mental wellbeing monitoring as well\nas maintenance with so-called digital-pharma or beyond a pill therapeutical\napproaches. This paper discusses our attempt and preliminary results of\nbrainwave (EEG) techniques to develop digital biomarkers for dementia progress\ndetection and monitoring. We present an information geometry-based\nclassification approach for automatic EEG-derived event related responses\n(ERPs) discrimination of low versus high task-load auditory or tactile stimuli\nrecognition, of which amplitude and latency variabilities are similar to those\nin dementia. The discussed approach is a step forward to develop AI, and\nespecially machine learning (ML) approaches, for the subsequent application to\nmild-cognitive impairment (MCI) and AD diagnostics.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 06:58:16 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Rutkowski", "Tomasz M.", ""], ["Zhao", "Qibin", ""], ["Abe", "Masao S.", ""], ["Otake", "Mihoko", ""]]}]